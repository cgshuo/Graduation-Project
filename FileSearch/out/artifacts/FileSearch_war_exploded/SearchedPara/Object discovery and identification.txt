 From an early age, humans and other animals [1] appear to orga nize the flux of experience into a series of encounters with discrete and persisting objects. Consider, for example, a young child who grows up in a home with two dogs. At a relatively early age the c hild will solve the problem of object discovery and will realize that her encounters with dogs correspond to views of two individuals rather than one or three. The child will also solve the problem of identification , and will be able to reliably identify an individual (e.g. Fido) each time it is encounter ed.
 This paper presents a Bayesian approach that helps to explai n both object discovery and identifica-tion. Bayesian models are appealing in part because they hel p to explain how inferences are guided by prior knowledge. Imagine, for example, that you see some p hotographs taken by your friends Alice and Bob. The first shot shows Alice sitting next to a larg e statue and eating a sandwich, and the second is similar but features Bob rather than Alice. The statues in each photograph look identical, and probably you will conclude that the two photo graphs are representations of the same statue. The sandwiches in the photographs also look identic al, but probably you will conclude that the photographs show different sandwiches. The prior knowl edge that contributes to these infer-ences appears rather complex, but we will explore some much s impler cases where prior knowledge guides identification.
 A second advantage of Bayesian models is that they help to exp lain how learners cope with un-certainty. In some cases a learner may solve the problem of ob ject discovery but should maintain uncertainty when faced with identification problems. For ex ample, I may be quite certain that I have met eight different individuals at a dinner party, even if I a m unable to distinguish between two guests who are identical twins. In other cases a learner may n eed to reason about several related problems even if there is no definitive solution to any one of t hem. Consider, for example, a young child who must simultaneously discover which objects her wo rld contains (e.g. Mother, Father, Fido, and Rex) and organize them into categories (e.g. people and d ogs). Many accounts of categorization seem to implicitly assume that the problem of identification must be solved before categorization can begin, but we will see that a probabilistic approach can a ddress both problems simultaneously. Identification and object discovery have been discussed by r esearchers from several disciplines, including psychology [2, 3, 4, 5, 6], machine learning [7, 8] , statistics [9], and philosophy [10]. Many machine learning approaches can handle identity uncer tainty, or uncertainty about whether two tokens correspond to the same object. Some approaches su ch such as BLOG [8] are able in addition to handle problems where the number of objects is no t specified in advance. We propose that some of these approaches can help to explain human learn ing, and this paper uses a simple BLOG-style approach [8] to account for human inferences.
 There are several existing psychological models of identifi cation, and the work of Shepard [11], Nosofsky [3] and colleagues is probably the most prominent. Models in this tradition usually focus on problems where the set of objects is specified in advance an d where identity uncertainty arises as a result of perceptual noise. In contrast, we focus on prob lems where the number of objects must be inferred and where identity uncertainty arises from partial observability rather than noise. A separate psychological tradition focuses on problems whe re the number of objects is not fixed in advance. Developmental psychologists, for example, have u sed displays where only one object token is visible at any time to explore whether young infants can in fer how many different objects have been observed in total [4]. Our work emphasizes some of the sa me themes as this developmental research, but we go beyond previous work in this area by prese nting and evaluating a computational approach to object identification and discovery.
 The problem of deciding how many objects have been observed i s sometimes called individua-tion [12] but here we treat individuation as a special case of obje ct discovery. Note, however, that object discovery can also refer to cases where learners infe r the existence of objects that have never been observed. Unobserved-object discovery has received relatively little attention in the psycho-logical literature, but is addressed by statistical models including including species-sampling mod-els [9] and capture-recapture models [13]. Simple statisti cal models of this kind will not address some of the most compelling examples of unobserved-object d iscovery, such as the discovery of the planet Neptune, or the ability to infer the existence of a hid den object by following another person X  X  gaze [14]. We will show, however, that a simple statistical a pproach helps to explain how humans infer the existence of objects that they have never seen. Object discovery and identification may depend on many kinds of observations and may be sup-ported by many kinds of prior knowledge. This paper consider s a very simple setting where these problems can be explored. Suppose that an agent is learning a bout a world that contains n w white balls and n  X  n w gray balls. Let f ( o i ) indicate the color of ball o i , where each ball is white ( f ( o i ) = 1 ) or gray ( f ( o i ) = 0 ). An agent learns about the world by observing a sequence of o bject tokens. Suppose that label l ( j ) is a unique identifier of token j  X  X n other words, suppose that the j th token is a token of object o l ( j ) . Suppose also that the j th token is observed to have feature value g ( j ) . Note the difference between f and g : f is a vector that specifies the color of the n balls in the world, and g is a vector that specifies the color of the object tokens obser ved thus far. We define a probability distribution over token sequences by assuming that a world is sampled from a prior P ( n, n w ) and that tokens are sampled from this world. The full generat ive model is: A prior often used for inferences about a population of unkno wn size is the scale-invariant Jeffreys prior P ( n ) = 1 n [15]. We follow this standard approach here but truncate at n = 1000 . Choosing some upper bound is convenient when implementing the model, and has the advantage of producing a prior that is proper (note that the Jeffreys prior is improp er). Equation 2 indicates that the number of white balls n w is sampled from a discrete uniform distribution. Equation 3 indicates that each token is generated by sampling one of the n balls in the world uniformly at random, and Equation 4 indicates that the color of each token is observed without no ise.
 The generative assumptions just described can be used to defi ne a probabilistic approach to ob-ject discovery and identification. Suppose that the observa tions available to a learner consist of a fully-observed feature vector g and a partially-observed label vector l obs . Object discovery and iden-tification can be addressed by using the posterior distribut ion P ( l | g, l obs ) to make inferences about the number of distinct objects observed and about the identi ty of each token. Computing the poste-rior distribution P ( n | g, l obs ) allows the learner to make inferences about the total number of objects in the world. In some cases, the learner may solve the problem of unobserved-object discovery by realizing that the world contains more objects than she has o bserved thus far.
 The next sections explore the idea that the inferences made b y humans correspond approximately to the inferences of this ideal learner. Since the ideal lear ner allows for the possible existence of objects that have not yet been observed, we refer to our model as the open world model. Although we make no claim about the psychological mechanisms that mig ht allow humans to approximate the predictions of the ideal learner, in practice we need som e method for computing the predictions of our model. Since the domains we consider are relatively sm all, all results in this paper were computed by enumerating and summing over the complete set of possible worlds. The introduction described a scenario (the statue and sandw iches example) where prior knowledge appears to guide identification. Our first experiment explor es a very simple instance of this idea. We consider a setting where participants observe balls that ar e sampled with replacement from an urn. In one condition, participants sample the same ball from the urn on four consecutive occasions and are asked to predict whether the token observed on the fifth dr aw is the same ball that they saw on the first draw. In a second condition participants are asked e xactly the same question about the fifth token but sample four different balls on the first four draws. We expect that these different patterns of data will shape the prior beliefs that participants bring to the identification problem involving the fifth token, and that participants in the first condition will be substantially more likely to identify the fifth token as a ball that they have seen before.
 Although we consider an abstract setting involving balls an d urns the problem we explore has some real-world counterparts. Suppose, for example, that a coll eague wears the same tie to four formal dinners. Based on this evidence you might be able to estimate the total number of ties that he owns, and might guess that he is less likely to wear a new tie to the ne xt dinner than a colleague who wore different ties to the first four dinners.
 Method. 12 adults participated for course credit. Participants int eracted with a computer interface that displayed an urn, a robotic arm and a beam of UV light. The arm randomly sampled balls from the urn, and participants were told that each ball had a uniqu e serial number that was visible only under UV light. After some balls were sampled, the robotic ar m moved them under the UV light and revealed their serial numbers before returning them to the u rn. Other balls were returned directly to the urn without having their serial numbers revealed. The se rial numbers were alphanumeric strings such as  X  X XR182 X  X  X ote that these serial numbers provide no in formation about the total number of objects, and that our setting is therefore different from the Jeffreys tramcar problem [15]. The experiment included five within-participant condition s shown in Figure 1. The observations for each condition can be summarized by a string that indicates t he number of tokens and the serial numbers of some but perhaps not all tokens. The 1 1 1 1 1 condition in Figure 1a is a case where the same ball (without loss of generality, we call it ba ll 1) is drawn from the urn on five consecutive occasions. The 5 1 2 3 4 condition in Figure 1b is a case where five different balls are drawn from the urn. The 1 condition in Figure 1d is a case where five draws are made, but only the serial number of the first ball is revealed. Within any of the five conditions, all of the balls had the same color (white or gray), but differ ent colors were used across different conditions. For simplicity, all draws in Figure 1 are shown a s white balls.
 On the second and all subsequent draws, participants were as ked two questions about any token that was subsequently identified. They first indicated whether th e token was likely to be the same as the ball they observed on the first draw (the ball labeled 1 in Figure 1). They then indicated whether the token was likely to be a ball that they had never seen befor e. Both responses were provided on a scale from 1 (very unlikely) to 7 (very likely). At the end of e ach condition, participants were asked to estimate the total number of balls in the urn. Twelve optio ns were provided ranging from  X  X xactly 1 X  to  X  X xactly 12, X  and a thirteenth option was labeled  X  X ore than 12. X  Responses to each option were again provided on a seven point scale.
 Model predictions and results. The comparisons of primary interest involve the identificat ion questions in conditions 1a and 1b. In condition 1a the open wo rld model infers that the total number of balls is probably low, and becomes increasingly confident that each new token is the same as the Figure 1: Model predictions and results for the five conditio ns in experiment 1. The left columns in (a) and (b) show inferences about the identification quest ions. In each plot, the first group of bars shows predictions about the probability that each new t oken is the same ball as the first ball drawn from the urn. The second group of bars shows the probabi lity that each new token is a ball that has never been seen before. The right columns in (a) and ( b) and the plots in (c) through (e) show inferences about the total number of balls in each urn. A ll human responses are shown on the 1-7 scale used for the experiment. Model predictions are shown as probabilities (identification questions) or ranks (population size questions). first object observed. In condition 1b the model infers that t he number of balls is probably high, and becomes increasingly confident that each new token is probab ly a new ball.
 The rightmost charts in Figures 1a and 1b show inferences abo ut the total number of balls and confirm that humans expect the number of balls to be low in cond ition 1a and high in condition 1b. Note that participants in condition 1b have solved the probl em of unobserved-object discovery and inferred the existence of objects that they have never seen. The leftmost charts in 1a and 1b show responses to the identification questions, and the final bar i n each group of four shows predictions about the fifth token sampled. As predicted by the model, part icipants in 1a become increasingly confident that each new token is the same object as the first tok en, but participants in 1b become increasingly confident that each new token is a new object. Th e increase in responses to the new ball questions in Figure 1b is replicated in conditions 2d and 2e o f Experiment 2, and therefore appears to be reliable. The third and fourth rows of Figures 1a and 1b show the predict ions of two alternative models that are intuitively appealing but that fail to account for our re sults. The first is the Dirichlet Process (DP) mixture model, which was proposed by Anderson [16] as an acco unt of human categorization. Un-like most psychological models of categorization, the DP mi xture model reserves some probability mass for outcomes that have not yet been observed. The model i ncorporates a prior distribution over partitions X  X n most applications of the model these partitio ns organize objects into categories, but Anderson suggests that the model can also be used to organize object tokens into classes that corre-spond to individual objects. The DP mixture model successfu lly predicts that the ball 1 questions will receive higher ratings in 1a than 1b, but predicts that r esponses to the new ball question will be identical across these two conditions. According to this model, the probability that a new token corresponds to a new object is  X  m +  X  where  X  is a hyperparameter and m is the number of tokens observed thus far. Note that this probability is the same reg ardless of the identities of the m tokens previously observed.
 The Pitman Yor (PY) mixture model in the fourth row is a genera lization of the DP mixture model that uses a prior over partitions defined by two hyperparamet ers [17]. According to this model, the probability that a new token corresponds to a new object is  X  + k X  m +  X  , where  X  and  X  are hyperparameters and k is the number of distinct objects observed so far. The flexibi lity offered by a second hyper-parameter allows the model to predict a difference in respon ses to the new ball questions across the two conditions, but the model does not account for the increa sing pattern observed in condition 1b. Most settings of  X  and  X  predict that the responses to the new ball questions will dec rease in condi-tion 1b. A non-generic setting of these hyperparameters wit h  X  = 0 can generate the flat predictions in Figure 1, but no setting of the hyperparameters predicts t he increase in the human responses. Although the PY and DP models both make predictions about the identification questions, neither model can predict the total number of balls in the urn. Both mo dels assume that the population of balls is countably infinite, which does not seem appropriate for the tasks we consider.
 Figures 1c through 1d show results for three control conditi ons. Like condition 1a, 1c and 1d are cases where exactly one serial number is observed. Like cond itions 1a and 1b, 1d and 1e are cases where exactly five tokens are observed. None of these control conditions produces results similar to conditions 1a and 1b, suggesting that methods which simply c ount the number of tokens or serial numbers will not account for our results.
 In each of the final three conditions our model predicts that t he posterior distribution on the number of balls n should decay as n increases. This prediction is not consistent with our data, since most participants assigned equal ratings to all 13 options, incl uding  X  X xactly 12 balls X  and  X  X ore than 12 balls. X  The flat responses in Figures 1c through 1e appear t o indicate a generic desire to express uncertainty, and suggest that our ideal learner model accou nts for human responses only after several informative observations have been made. Our second experiment focuses on object discovery rather th an identification. We consider cases where learners make inferences about the number of objects t hey have seen and the total number of objects in the urn even though there is substantial uncert ainty about the identities of many of the tokens observed. Our probabilistic model predicts that obs ervations of unidentified tokens can influ-ence inferences about the total number of objects, and our se cond experiment tests this prediction. Method. 12 adults participated for course credit. The same particip ants took part in Experiments 1 and 2, and Experiment 2 was always completed after Experime nt 1. Participants interacted with the same computer interface in both conditions, and the seve n conditions in Experiment 2 are shown in Figure 2. Note that each condition now includes one or more gray tokens. In 2a, for example, there are four gray tokens and none of these tokens is identifi ed. All tokens were sampled with replacement, and the condition labels in Figure 2 summarize the complete set of tokens presented in each condition. Within each condition the tokens were prese nted in a pseudo-random order X  X n 2a, for example, the gray and white tokens were interspersed wit h each other.
 Model predictions and results. The cases of most interest are the inferences about the total number of balls in conditions 2a and 2c. In both conditions particip ants observe exactly four white tokens and all four tokens are revealed to be the same ball. The gray t okens in each condition are never identified, but the number of these tokens varies across the c onditions. Even though the identities Figure 2: Model predictions and results for the seven condit ions in Experiment 2. The left columns in (a) through (e) show inferences about the identification q uestions, and the remaining plots show inferences about the total number of balls in each urn. of the gray tokens are never revealed, the open world model ca n use these observations to guide its inference about the total number of balls. In 2a, the proport ions of white tokens and gray tokens are equal and there appears to be only one white ball, suggest ing that the total number of balls is around two. In 2c grey tokens are now three times more common, suggesting that the total number of balls is larger than two. As predicted, the human response s in Figure 2 show that the peak of the distribution in 2a shifts to the right in 2c. Note, however, t hat the model does not accurately predict the precise location of the peak in 2c.
 Some of the remaining conditions in Figure 2 serve as control s for the comparison between 2a and 2c. Conditions 2a and 2c differ in the total number of tokens o bserved, but condition 2b shows that this difference is not the critical factor. The number of tok ens observed is the same across 2b and 2c, yet the inference in 2b is more similar to the inference in 2a t han in 2c. Conditions 2a and 2c also differ in the proportion of white tokens observed, but condi tions 2f and 2g show that this difference is not sufficient to explain our results. The proportion of wh ite tokens observed is the same across conditions 2a, 2f, and 2g, yet only 2a provides strong eviden ce that the total number of balls is low. The human inferences for 2f and 2g show the hint of an alte rnating pattern consistent with the inference that the total number of balls in the urn is even. On ly 2 out of 12 participants generated this pattern, however, and the majority of responses are nea r uniform. Finally, conditions 2d and 2e replicate our finding from Experiment 1 that the identity l abels play an important role. The only difference between 2a and 2e is that the four labels are disti nct in the latter case, and this single difference produces a predictable divergence in human infe rences about the total number of balls. Experiment 2 suggested that people make robust inferences a bout the existence and number of unob-served objects in the presence of identity uncertainty. Our final experiment explores categorization in the presence of identity uncertainty. We consider an extr eme case where participants make infer-ences about the variability of a category even though the tok ens of that category have never been identified.
 Method. The experiment included two between subject conditions, an d 20 adults were recruited for each condition. Participants were asked to reason about a ca tegory including eggs of a given species, where eggs in the same category might vary in size. The interf ace used in Experiments 1 and 2 was adapted so that the urn now contained two kinds of objects: no tepads and eggs. Participants were told that each notepad had a unique color and a unique label wr itten on the front. The UV light played no role in the experiment and was removed from the inte rface: notepads could be identified by visual inspection, and identifying labels for the eggs we re never shown.
 In both conditions participants observed a sequence of 16 to kens sampled from the urn. Half of the tokens were notepads and the others were eggs, and all egg tok ens were identical in size. Whenever an egg was sampled, participants were told that this egg was a Kwiba egg. At the end of the con-dition, participants were shown a set of 11 eggs that varied i n size and asked to rate the probability that each one was a Kwiba egg. Participants then made inferen ces about the total number of eggs and the total number of notepads in the urn.
 The two conditions were intended to lead to different infere nces about the total number of eggs in the urn. In the 4 egg condition, all items (notepad and eggs) w ere sampled with replacement. The 8 notepad tokens included two tokens of each of 4 notepads, su ggesting that the total number of notepads was 4. Since the proportion of egg tokens and notepa d tokens was equal, we expected participants to infer that the total number of eggs was rough ly four. In the 1 egg condition, four notepads were observed in total, but the first three were samp led without replacement and never returned to the urn. The final notepad and the egg tokens were a lways sampled with replacement. After the first three notepads had been removed from the urn, t he remaining notepad was sampled about half of the time. We therefore expected participants t o infer that the urn probably contained a single notepad and a single egg by the end of the experiment, and that all of the eggs they had observed were tokens of a single object.
 Model. We can simultaneously address identification and categoriz ation by combining the open world model with a Gaussian model of categorization. Suppos e that the members of a given category (e.g. Kwiba eggs) vary along a single continuous dimension ( e.g. size). We assume that the egg sizes are distributed according to a Gaussian with known mea n and unknown variance  X  2 . For convenience, we assume that the mean is zero (i.e. we measure size with respect to the average) and use the standard inverse-gamma prior on the variance: p (  X  2 )  X  (  X  2 )  X  (  X  +1) e  X   X   X  2 . Since we are interested only in qualitative predictions of the model, th e precise values of the hyperparameters are not very important. To generate the results shown in Figure 3 we set  X  = 0 . 5 and  X  = 2 . Before observing any eggs, the marginal distribution on siz es is p ( x ) = R p ( x |  X  2 ) p (  X  2 ) d X  2 . Sup-pose now that we observe m random samples from the category and that each one has size ze ro. If m is large then these observations provide strong evidence th at the variance  X  2 is small, and the posterior distribution p ( x | m ) will be tightly peaked around zero. If m , is small, however, then the posterior distribution will be broader. Figure 3: (a) Model predictions for Experiment 3. The first tw o panels show the size distributions inferred for the two conditions, and the final panel shows the difference of these distributions. The difference curve for the model rises to a peak of around 1.6 bu t has been truncated at 0.1. (b) Human inferences about the total number of eggs in the urn. As predicted, participants in the 4 egg condition believe that the urn contains more eggs. (c) Th e difference of the size distributions generated by participants in each condition. The central pe ak is absent but otherwise the curve is qualitatively similar to the model prediction.
 The categorization model described so far is entirely stand ard, but note that our experiment considers a case where T , the observed stream of object tokens, is not sufficient to de termine m , the number of distinct objects observed. We therefore use the open world m odel to generate a posterior distribution over m , and compute a marginal distribution over size by integrati ng out both m and  X  2 : p ( x | T ) = R p ( x |  X  2 ) p (  X  2 | m ) p ( m | T ) d X  2 dm . Figure 3a shows predictions of this  X  X pen world + Gaussian X  model for the two conditions in our experiment. Note that the difference between the curves for the two conditions has the characteristic Mexican-hat shape pr oduced by a difference of Gaussians. Results. Inferences about the total number of eggs suggested that our manipulation succeeded. Figure 3b indicates that participants in the 4 egg condition believed that they had seen more eggs than participants in the 1 egg condition. Participants in bo th conditions generated a size distribution for the category of Kwiba eggs, and the difference of these di stributions is shown in Figure 3c. Although the magnitude of the differences is small, the shap e of the difference curve is consistent with the model predictions. The x = 0 bar is the only case that diverges from the expected Mexican hat shape, and this result is probably due to a ceiling effect  X 80% of participants in both conditions chose the maximum possible rating for the egg with mean size ( size zero), leaving little opportunity for a difference between conditions to emerge. To support th e qualitative result in Figure 3c we computed the variance of the curve generated by each individ ual participant and tested the hypothesis that the variances were greater in the 1 egg condition than in the 4 egg condition. A Mann-Whitney test indicated that this difference was marginally signific ant ( p &lt; 0 . 1 , one-sided). Parsing the world into stable and recurring objects is argua bly our most basic cognitive achieve-ment [2, 10]. This paper described a simple model of object di scovery and identification and eval-uated it in three behavioral experiments. Our first experime nt confirmed that people rely on prior knowledge when solving identification problems. Our second and third experiments explored prob-lems where the identities of many object tokens were never re vealed. Despite the resulting uncer-tainty, we found that participants in these experiments wer e able to track the number of objects they had seen, to infer the existence of unobserved objects, and t o learn and reason about categories. Although the tasks in our experiments were all relatively si mple, future work can apply our ap-proach to more realistic settings. For example, a straightf orward extension of our model can handle problems where objects vary along multiple perceptual dime nsions and where observations are cor-rupted by perceptual noise. Discovery and identification pr oblems may take several different forms, but probabilistic inference can help to explain how all of th ese problems are solved.
 [1] E. A. Tibbetts and J. Dale. Individual recognition: it is good to be different. Trends in Ecology [2] W. James. Principles of psychology . Holt, New York, 1890. [3] R. M. Nosofsky. Attention, similarity, and the identific ation-categorization relationship. Jour-[4] F. Xu and S. Carey. Infants X  metaphysics: the case of nume rical identity. Cognitive Psychology , [5] L. W. Barsalou, J. Huttenlocher, and K. Lamberts. Basing categorization on individuals and [6] L. J. Rips, S. Blok, and G. Newman. Tracing the identity of objects. Psychological Review , [7] A. McCallum and B. Wellner. Conditional models of identi ty uncertainty with application [8] B. Milch, B. Marthi, S. Russell, D. Sontag, D. L. Ong, and A . Kolobov. BLOG: Probabilistic [9] J. Bunge and M. Fitzpatrick. Estimating the number of spe cies: a review. Journal of the [10] R. G. Millikan. On clear and confused ideas: an essay about substance concep ts . Cambridge [11] R. N. Shepard. Stimulus and response generalization: a stochastic model relating generaliza-[12] A. M. Leslie, F. Xu, P. D. Tremoulet, and B. J. Scholl. Ind exing and the object concept: [13] J. D. Nichols. Capture-recapture models. Bioscience , 42(2):94 X 102, 1992. [14] G. Csibra and A. Volein. Infants can infer the presence o f hidden objects from referential gaze [15] H. Jeffreys. Theory of Probability . Oxford University Press, Oxford, 1961. [16] J. R. Anderson. The adaptive nature of human categoriza tion. Psychological Review , 98(3): [17] J. Pitman. Combinatorial stochastic processes, 2002. Notes for Saint Flour Summer School.
