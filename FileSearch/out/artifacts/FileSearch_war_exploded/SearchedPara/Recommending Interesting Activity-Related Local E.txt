 When searching for entities with a strong local character (e.g., a museum), people may also be interested in discovering proximal activity-related entities (e.g., a caf X ). Geographical proximity is a necessary, but not sufficient, qualifier for recommending other entities such that they are related in a useful manner (e.g., interest in a fish market does not imply interest in nearby bookshops, but interest in other produce stores is more likely). We describe and evaluate methods to identify such activity-related local entities. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process, selection process. Algorithms, Measurement, Experimentation. Local entities, entity resolution, entity-entity matching. People are frequently interested in finding out information about specific local entities, say the Museum of Modern Art (MOMA) in the city of New York, NY. They may be tourists and planning a trip, or residents exploring their city. In addition to retrieving Web documents matching users X  search queries for the specific local entity, modern Web search engines may provide a rich and di-verse results page with additional information related to the query. Understanding the local user intent behind such users X  queries offers an opportunity to surface recommendations about other interesting activity-related local entities. For example, after visit-ing MOMA, a shopping trip or a visit to a local bar may be com-mon activities. These relationships may not be commutative: an interest in a bar is unlikely to imply an interest in nearby cultural centers. Similarly, an interest in a cupcake shop may mean an interest in other nearby cupcake shops, not some different class of local entity. Lastly, as observed by Jones et al. [2], the nature of the entity and/or corresponding activity may imply a different willingness to travel. Thus for suggesting activity-related local entities, an interest in a major city attraction may indicate an in-terest in other city attractions several miles away, but an interest in a bar may only suggest interest in other nearby bars or caf X s. This work describes a procedure for identifying related local enti-ties. Xiao et al. [6], similarly motivated about local relatedness , observed behavior in geographic (local map vertical) search logs and derived mechanisms to identify co-located queries at different geographic region resolutions. Our algorithms are unrelated to theirs, and we focus on identifying entities , not queries. Note that although we conduct our study in the context of Seattle, WA, the methods described could be applied to any city of reasonable size. Unlike Wang et al.  X  X  approach [4], which works to extract domi-nant locations (either explicit or implicit) associated with queries , we focused on identifying an entity  X  X  location. The first step in-volves the identification of URLs that may be relevant to the loca-tion of interest. We obtained clickthrough logs from the Bing Web search engine and mined queries and the URLs that users clicked on for those queries, providing us with implicit associations be-tween queries and URLs. We extracted URLs containing  X  X eattle X  in the associated query string, and identified address-based que-ries and their query-URL mapping. For example, the query [ pike place market, pike street, seattle ] could map to pikeplacemar-ket.org, describing the local entity Pike Place Market. To remove infrequently-visited sites, we also use browsing logs from a wide-ly-distributed browser plugin, and retained URLs that appear in those logs and the clickthrough logs. This left us with a set of five to ten thousand URLs, potentially describing a local Seattle entity. To determine the physical location for each entity we use the Bing Maps Geocoding API (microsoft.com/maps/developers), which processes queries and returns their geocoded locations. Geocoding results over 100 miles from Seattle were removed from analysis. We employ entity resolution to get from a URL to other URLs that refer to the same entity. Starting from every URL in the set created using the steps above we find the query which sends the most traffic to that URL (the canonical query). We then look at the top URLs by clickthrough rate for this query, and select those which attract more than 5% of the total click count. These URLs comprise an entity cluster, and we assign as the canonical entity the URL with the highest total click count of the set. Entities are represented by their canonical URL from Section 2.2. Entity-entity matching algorithms recommend related entities by processing entity information, location information, and click-through or session data, to generate an affinity matrix, . The matrix is  X  , where is the number of entities, and the entry Click graph: Search engine result-page clickthrough data from one year of Bing search logs are incorporated by using the canon-ical URLs as starting points and performing a two-step graph walk (URL to queries then back out to URLs) to obtain related URLs. Search sessions: The frequency of URL co-occurrence in search sessions from one-week of browsing logs, comprising search en-gine queries and post-query navigation (as described in [5]), is used to compute the degree of relatedness between entities. We also study a number of extensions to each of these methods: Merged: We combine the two matrices using a convex weight. Max-flow: We run a max-flow algorithm on the merged affinity matrix to generate a new affinity matrix , where corre-sponds to the maximum amount of flow that can be pushed from entity to entity [1]. For efficiency, this is restricted to a two-hop max-flow where flow can travel up to two edges. Hitting time: We run a hitting time algorithm on the merged affin-ity matrix to create a new matrix , where is proportional to the expected time before a random walk from reaches [3]. Evaluating our entity resolution and recommendations requires ground truth data, preferably from human raters, who may be able to determine inter-entity relationships. To this end, we recruited judges from Amazon Mechanical Turk ( turkers ). We generated sets of URL-URL pairs via a graph walk over : for every canonical URL, we pull a few URLs from that cluster, a few URLs which are one hop away, two hops away, etc. to form the other half of the URL-URL pair. This ensures that we have pairs covering a spectrum from unrelated to exact matches to be judged. Judges considered the following scenario: You are planning an outing in the city and you are searching for ideas for what to do. There are a few locations you have heard about or are already looking to visit, and you would like to find more attractions / res-taurants / shopping / etc. to round out your day . We presented people with URL-URL pairs for each of the suggested URLs in each cluster, and asked them to rate the relatedness between the entity associated with the recommended entity and the reference entity on a four-point scale: 1= URLs are unrelated , 2= URLs are related , 3= URLs are obviously related , and 4= URLs are the same entity . Distance data estimating the physical distance between the recommended entity and the reference entity were also provided. Three of the authors judged a set of 20 entities and cluster URLs to establish a gold standard data set that was used in selecting turkers. For example, for Seattle Art Museum (seattleartmuse-um.org), visiting the Seattle Aquarium (seattleaquarium.org) may be a good related activity and received an average rating of three, whereas a visit to a local garden and stone company (lakeview-stone.com) received an average rating of one. The Fleiss X  X  kappa ( ) between authors was 0.74, signifying substantial agreement and suggesting that the task was reasonable for remote judges. We scaled out the study to turkers. To control for the quality of the ratings, we did two things. First, we assigned a qualification test drawn from our gold standard truth data, in which each of the volunteers had to attain over 50% correct to attempt any of our human intelligence tasks (HITs). Next, each HIT contained three questions, one drawn from our gold standard set and two novel questions. Each time a HIT was submitted we verified that the turker answer matched our ground truth. We used this to update the qualification score, taking a running average with a weight of 0.05. This continual assessment strategy was employed to ensure that turkers did not work hard to pass the initial qualification and then not devote similar effort to the post-qualification tasks, whose ratings were important for our study. Turkers with qualifi-cation below 50% had their ratings excluded from our test data. In total, we obtained 3,426 URL-URL rating pairs. These raw numbers include both duplicates and those which raters did not agree on. Fleiss X  X  was 0.43, signifying moderate agreement between our raters. Each URL-URL pair rated by three separate turkers, and the rating was used only if all three turkers agreed. We had just over 800 questions where all three raters agreed. We use those questions for the evaluation of the performance of our entity resolution and entity-entity recommendations. Many different URLs can refer to the same local entity (e.g., for the local entity bethscafe.com, we may also return the yelp.com and citysearch.com pages for the same caf X ). Recommending duplicates may create a poor user experience, and we did not want to reward an algorithm for finding duplicate entities. We use the method for resolving entities described in Section 2.2, and evalu-ate it using our human labeled data. Two URLs are regarded as the same entity iff the human rating is four. The score, the harmonic mean of precision and recall, was 0.63, suggesting that we can detect duplicate entities with reasonable accuracy. To evaluate entity recommendation, two entities are considered related if turkers assigned a rating of two or three, and unrelated if the rating was one. Any non-zero entry in was counted as a classification. Table 1 shows the scores for each of the recom-mendation algorithms described earlier. We used since we wanted to weight precision and recall equally. Table 1. scores for entity recommendation algorithms. Merging the click-graph and search-sessions methods led to im-proved performance over either method alone (0.44 vs. 0.39/0.26). Enhancements to the merged model using max-flow and hitting time algorithms led to further improvements. One explanation for the poor performance of the search sessions is less data (one week of browsing versus one year of click logs). However, the fact that it can still obtain an score that is 72% of the click graph score with much less data suggests that sessions may be valuable. We studied methods for identifying related local entities and iden-tifying duplicate entities using search and browsing behavior. Our methods performed well in both tasks. Entity recommendations based on a combination of clicks and session data performed par-ticularly well, especially when enhanced with max-flow and hit-ting time. Future work involves developing new and improved algorithms with more log data, evaluating models with a larger set of judgments, and scaling recommendations to multiple locations. [1] Ford, L.R. and Fulkerson, D.R. (1956). Maximal flow through [2] Jones, R., Zhang, W.V., Rey, B., Jhala, P., and Stipp, E. [3] Mei, Q., Zhou, D., and Church, K. (2008). Query suggestion [4] Wang, L., Wang, C., Xie, X., Forman, J., Lu, Y., Ma, W-Y., [5] White, R.W. and Drucker, S.M. (2007). Investigating behav-[6] Xiao, X., Wang, L., Xie, X., and Luo, Q. (2008). Discovering 
