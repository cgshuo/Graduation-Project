 Name ambiguity is a common problem when carrying out web searches or retriev-ing articles from an archive of news articles. For example, the name  X  X ichael Jordan X  represents more than ten persons in the Google search results: a basketball player, a professor, a football player and a actor, etc. Along with the rapid growth of the World Wide Web, name ambiguity problem has become more and more serious in areas such as web person search, data integration, link analysis and knowledge extraction.
Basedonthetaskof entity linking proposed in the Knowledge Base Population (KBP) track of the Text Analysis Conference (TAC) [1], name disambiguation can be defined as linking mentions of entities within specific contexts to their corresponding entries in an existing knowledge base, e.g., Wikipedia.

Conventionally, name disambiguation methods compute lexical relatedness between mentions (possibly with surrounding contexts) and the document describing one can-didate entity, either using vector space model [2,3] or language model [4]. The major challenge of this approach is to resolve name/term ambiguities, which are usually due to polysemy and synonymy . A synonymous name means that more than one name vari-ations refer to the same entity. To solve the synonymy problem, we may consider using query expansion [4] to enrich the query model so that other possible expressions of the same concept or entity can be included. However, the expanded query is still directly matched with words of document, leaving the polysemy problem unsolved.

A polysemous name means that it corre sponds to more than one entities. The the-matic context of the name can be used for its disambiguation. Pilz and Paa X  [5], Kozareva and Ravi [6] conducted some preliminary work on name disambiguation using such an idea. Intuitively, different name entities may correspond to different thematic context. For example,  X  X ichael Jordan X  (a basketbal l star) tends to appear in articles related to sports, while  X  X ichael Jordan X  (a professor in UC Berkeley) tends to appear in articles related to research. However, Pilz and Paa X  [5] used a supervised ranking framework, which requires a set of training data that may not be available for names in general. In a more realistic setting for general ad hoc retrieval, we do not have manually annotated names.

In this paper, we propose to use both lexical knowledge and thematic knowledge for name disambiguation. Gene rally speaking, lexical knowledge captures more accurate and specific context while thematic knowle dge captures more abstract and general con-text. Specifically, we propose to combine two ranking functions: one is based on trans-lation language models and the other is based on unsupervised topic models. These two functions capture useful information respectively on lexical level and thematic level.
Specifically, the main contributions of this paper are as follows: 1. We leverage the name references on Wikipedia to train a translation model to cap-2. We use topic-based ranking function to capture more abstract thematic context. We 3. In our experiments, we show that the combination of both lexical and thematic This paper is organized as follows. We first formulate the name disambiguation problem and review the related work in Section 2. Section 3 describes how to leverage lexical and thematic features to enhance the ability to resolve name ambiguities. The experimental results are presented and discussed in Section 4. Finally, we conclude this paper and point out some future work in Section 5. 2.1 Problem Description In this paper, we use Wikipedia as a knowledge base. Our goal is to assign the correct Wikipedia article to a name mention found in a text. This task can be used in several places: when a user inputs a query involv ing a name mention, or when a Web page is created by a user. It is useful to automatically link the name mention to the correct encyclopedia article. In this paper, we use Wikipedia as our encyclopedia data, but our method can be used on other resources.
In general, we consider a name mention a s a query. This name mention may appear in some context. Given a name mention (i.e., a person name) q , by matching the surface forms of it we can get a set of candidate entities { e i } from Wikipedia. We denote the context which surrounds q as D ( q ) , and denote the text for entity e in Wikipedia as D ( e ) . Our task is to determine the correct match  X  e  X  X  e i } for name mention q .Table 1 shows an example of one mention together with its context sentence. We adopt a ranking-based approach to this problem, which can be formulated as follows where e =argmax e i score ( q,e i ) ,and  X  is a threshold which determines whether there is a match or not in { e i } . Note that we also consider the case where no correct entity corresponds to the name mention in knowl edge base (hereinafter referred to as 2.2 Related Work In this section, we will describe the related work in name disambiguation. Most name disambiguation systems employed methods based on context similarity. Mihalcea and Csomai [7] used cosine similarity to capture the compatibility between name mention and its candidate entities. Bunescu [2] and Cucerzan [3] extended this Bag of Words based method by employing several disambiguation resources, such as Wikipedia entity pages, redirection pages, categories, and hyperlinks. However, their methods rely heavily on word match, and they all suffer from the synonymy problem.
There are also some name disambiguation methods that use thematic information of documents. Kozareva and Ravi [6] proposed an approach to disambiguate names using Latent Dirichlet Allocation (LDA) to learn a distribution over topics which correspond to candidate entities. After the topic model of name mention had been trained, they used it to infer the correct entity of ambiguous name mention. Pilz and Paa X  [5] used topic model probabilities directly to repres ent documents, and found the correct entity according to the thematic distance between document and candidate entities. However, Pilz and Paa X  [5] adopted a supervised ranking framework, which relied on training data and may not be suitable for evolving topics and new texts.

Recently there are also some name disa mbiguation methods based on inter-dependency. The idea is that the refere d entity of a name mention should be coher-ent with its unambiguous contextual entities. Medelyan et al X  X  work [8] name mentions with just one matched entity are considered to be unambiguous, and their correspond-ing correct entity entries are collected and used as context articles to disambiguate the remaining name mentions. This is done by computing the weighted average of lexi-cal relatedness between the candidate en tity and its unambiguous contextual entities. Milne and Witten [9] extended this method by adopting typical classifiers to balance the semantic relatedness, the commonne ss of entries and the context quality.
In this paper, we leverage the name references on Wikipedia to train a translation model to capture the lexical relationships between terms. Such a translation model can help determine the correspondence between the lexical contexts of a name mention and an entity. To capture the more abstract thematic contexts, we use LDA. The two types of contextual information are then comb ined to produce a final selection of the entity for a mention. Our method uses both lexical and thematic relatedness in the score function. In the following subsections, we will first describe the use of lexical relatedness using a trans-lation model. We then describe a thematic model and the combination of lexical and thematic relatedness. 3.1 Using Lexical Relatedness Previous methods [2][3][4] try to make use of lexical relatedness between name men-tion and the documents of candidate entities for name disambiguation. However, these methods rely heavily on word match, and they all suffer from the synonymy problem. To address this problem, we propose to use translation-based language models. Han and Sun [10] also use translation model in the entity linking task. The major difference is that they utilize translation model only to estimate transition probabilities between an entity name and a mention name, while we apply translation model to all terms. This allows us to relate similar terms in the context around the name mention to those in the candidate entity documents. In addition, we use translation models in a language model based retrieval framework, while they use it to estimate one of the factors in a Bayesian framework.

Before introducing translation-based la nguage models, we first discuss the ranking framework based on language models for name disambiguation.
 Language Models Based Ranking Function. Given a name mention q and a candidate entity e ,wescore e based on the KL-divergence defined as: where  X  q and  X  e are the query language model and the entity language model, respec-tively.

To estimate  X  q , typically we can use the empirical query word distribution: Instead of using query expansions like [4], we take a simpler approach by merging name mention with its surrounding context.

To estimate  X  e , we can follow the standard maximum likelihood estimation:
As shown in [11], smoothing is very important for language models in information retrieval. We can extend it by using Dirichlet smoothing: where  X  C is a background language model estimated from the whole collection, and  X  is the Dirichlet prior.

The above model relies on a direct word matching. To account for related terms, we use a translation based language model for estimating entity language model  X  e . Translation-Based Language Models. Translation Model was introduced in informa-tion retrieval by [12]. The main idea is to br idge the vocabulary gap between different languages by learning term-to-term probab ilities. Similar to that, in our task, we face the problem of vocabulary gap between query document and target entity document.
Assuming a translation model that provides the probability p ( w | w ) , the entity model  X  can be estimated as follows [13]: where  X  is the self-translation boosting factor and V is the vocabulary.

In practice, it would be too expensive to enumerate all intermediate terms w in V , so we take a top-K version of that: where T w is the set of top K terms ranked by translation probabilities p ( w | X  ) .For w  X  T , there is a generating probability p ( w | w ) p ml ( w |  X  e ) computed by following the chain d  X  w  X  w .Evenifterm w is not in the entity document of e , p ( w |  X  e ) can archive a high value when D ( e ) includes other terms in T w .
 To learn translation probabilities, we automatically build a parallel training set using Wikipedia, by assuming that a passage including a name and the referred Wikipedia document to be parallel. The Wikipedia data used in our experiments will be described in Section 4.

We adopt a heuristic approximation to estimate the translation model, which is shown efficient by [14]: where w S ,w T are terms respectively from  X  X ource language X  ( D ( q ) ) and  X  X arget lan-and c ( w T ) is the count of term w T that occurs in the training data.

In practice, it is infeasible to store all the term-to-term translation probabilities, for each term w  X  X  , we only keep the probabilities of the top K terms ranked by p ( w | X  ) , which is consistent with Equation 3.

After learning term translation probabilities, we can use Equation 3 to estimate  X  e , and then rank candidate entities using Equation 1. 3.2 Using Thematic Relatedness Topic models (e.g., LDA) are unsupervised generative models that learn hidden topics and capture underlying semantic structure of documents. Intuitively, thematic context is useful to help name disambiguation. For example,  X  X ichael Jordan X  which appears in a sports article tends to be the baseball star instead of the professor. Pilz and Paa X  [5] and Kozareva and Ravi [6] conducted some preliminary work on name disambiguation by leveraging thematic semantics. The main idea is to utilize topic models to learn underlying thematic semantics to resolve disambiguates. However, as we stated earlier, Pilz and Paa X  [5] adopted a supervised ranking framework, which relied on training data and may not be suitable for evolving topics and emerging text.

In this section, we first represent entities as topic distribution vectors, and then use an unsupervised ranking function to score those candidate entities.
 Topic-Based Entity Representation. In topic models, a document can be represented in a low-dimensional latent space, and the we ights of different di mensions are defined as the probabilities of topic distribution given the document. Since we can easily learn the topic-based representation of entity documents, the main difficulty is to represent name mention in topic dimensions. It has been reported that standard topic models (e.g., PLSA and LDA) do not work very well on short text [15], so we take a heuristic method to expand the query following [5]. To assign more importance to the local context, we repeat both name mention and its surrounding context with a window size of 25 for five times, then attach it to the query document 1 . We use the topic distributions of the new generated documents as representations of queries.

We use Latent Dirichlet Allocation (LDA) to infer the probability of an topic in an document. These yield topic distributions of both the query document with name mention q and the candidate entities e as follows: Topic-Based Ranking Function Given two distributions over topics P ( q ) and P ( e ) , we define a function to measure the thematic relatedness between them: We have three options to define score tr based on the topic-based entity representation. First, we adopt the symmetric Kullback-Leibler divergence [16] which is commonly used in the topic model literature [17] as measuring function: The symmetric Kullback-Leibler divergen ce indicates the similarity degree between two distributions: a small value means they are very similar and vice versa.
The other two alternative functions are Kullb ack-Leibler divergence and cosine sim-ilarity respectively: 3.3 Combining Lexical Relatedness and Thematic Relatedness The lexical and thematic relatedness defined in the previous section produce two rank-ing functions for name disambiguation: one is based on translation language models and the other is based on topic models. Generally speaking, lexical feature captures more accurate and specific context w hile thematic feat ure captures more abstract and general context. The question now is: can we leverage both features to enhance the ability of resolving disambiguation? The question can be formulated as: where score lr is the lexical relatedness score which defined by Equation 1 and score tr is the the thematic relatedness score which defined by Equation 4.

In this paper, we test three ways to combine both lexical relatedness and thematic relatedness. First, we adopt the linear form: where  X  is a parameter between 0 and 1, which controls the weight of score lr and score tr . Linear form assumes that the total score is the linear combination of the two scores. Each score X  X  contribution to the total score is controlled by  X  . The linear form has constant partial derivatives, which means this form has same level of sensitivity towards small and large scores.
 The Cobb-douglas form assumes that total score is the product of the two scores. This form is insensitive to small scores and sensitive to large scores: The harmonic form assumes the total score is the weighted harmonic average of the two scores: 4.1 Experimental Settings Data Sets. In Wikipedia, entity pages are connect ed by hyperlinks: the anchor text is the entity name and the outgoing link points to the referent entity. These entity names are treated as annotated name mentions [9]. In this paper, we treat the pairs of annotated name mention and its corresponding referent entity as parallel data, and use them to train translation models.

We use the July 22, 2011 English version of Wikipedia as knowledge base and ex-tract 16,730 person mentions which contain at least two candidate referent entities (on average 5.23 candidate referent entities for each name) and its corresponding correct referent entity is a person entity. Following [5], we randomly select one fifth of men-tions as uncovered mentions ( nil ) by removing their corresponding correct entities from the collection, and randomly select 60% of the data set for training and the remaining for testing.

We also evaluate our methods on the TAC-KBP 2010 data set [18]. It is the standard test collection used in entity linking task. Its knowledge base was constructed from Wikipedia with 818,741 entries. Our paper is focused on person name disambiguation, so we select all queries of person type in this data set. Then, we get 1,251 queries and 751 of them are used as test data. Some statistics of these data set are shown in Table 2. Evaluation Metrics. Similar to the standard information retrieval scenario, we adopt precision, recall and F-measure as evaluatio n metrics. Precision is defined as the ratio between the number of correctly linked queries and the total number of queries which have not been identified as nil . Recall is defined as the ratio between the number of cor-rectly linked queries and the total numbe r of queries which have a corresponding entity in our test collection. In addition, to test the performance on detecting uncovered enti-ties, we also report the accuracy for these me ntions separately, denoted as Accuracy nil . Methods to Compare. To examine the effectiveness of our methods, we compare the following methods:  X  LR basic and LR trans : the methods that use lexical relatedness defined by Equa- X  TR skld ,TR kld and TR cos : the methods that use thematic relatedness defined by  X  R line ,R cobb and R har : the methods that combine lexical relatedness and thematic 4.2 Experimental Results Examining Lexical Relatedness. In Table 3, we compare the basic language model of context window, the translation-based l anguage model always outperforms the ba-sic language model in terms of F-measure. This result strongly supports our hypoth-esis that lexical relatedness between terms in the context is highly useful for name disambiguation.

From Table 3, we can also see the impact of context window size. When a context window is used (window &gt; 0), the result is always better than that of no context (win-dow = 0) is used. This indicates that context information around the name is highly useful for the task.

If we further zoom into the results, we see LR trans achieves its optimal performance with a relative short context window (i.e, 10) compared with LR basic , which needs an optimal window size of 30. LR trans can more effectively lever age lexical information at a relatively small window size. With th e increase of context window, more noise is included; therefore the length of context window cannot be too large.
 Examining Thematic Relatedness. We now further analyze the impact of topic-based ranking functions TR skld ,TR kld and TR cos . In Table 4, we observe that TR cos ,which uses cosine similarity, yields the best results. Comparing Table 4 with Table 3, we can see that overall using thematic relatedness is more effective than using lexical related-ness, especially in terms of Accuracy nil .
 Examining the Combination of Lexical Relatedness and Thematic Relatedness. Table 5 shows optimal performance using lexical relatedness, thematic relatedness and their combination. We find that by leveraging both lexical information and thematic information, all three combined ranking functions can greatly improve their perfor-mances.

In particular, R line achieves the best performance: compared with LR best and TR best (the optimal method of using lexical relatedness and thematic relatedness respectively), it brings 11.5% and 7.4% improvement on F-measure respectively. This indicates that the combination of different types of information is highly useful.

It also shows that lexical information and thematic information can both capture part of evidence between query document and entity document. Performance of TR best is slightly better than that of LR best , but the thematic relatedness is still not enough to capture all evidence for name disambiguation. However, their combination can bring more improvement for name disambiguation.
 Examining Our Method on TAC-KBP Data Set. As our task is similar to entity linking task, we compare our best combined method with state of the art methods [4] on TAC-KBP 2010 data set. The result is shown in Table 6. We can see that our method is better than Gottipati X  X  method, especially on non-nil queries.
 4.3 Parameter Sensitivity Recall that we have a few parameters to be t uned for different r anking functions.  X  (Dirichlet prior) is empirically set to 2500;  X  (self-translation boosting factor) is set to 0.5; and  X  is the threshold to filter out uncovered queries which automatically set on the training data set. We use the Mallet [19] to implement LDA and we use its default parameter settings. We have three more parameters to be tuned in our methods: K , T and  X  . We take a heuristic method to seek the final parameter settings on Wikipedia data set: start with empirical settings, then each time we tune one single parameter and fix the others.
In Figure 1, we present the results of different K (the total number of translated words) ranging from 100 to 1000 with a step of 100. Recall that K controls the number of top translated words defined in Equation 3. The translated word number K affects the efficiency of the model: a larger K makes the processing more slowly. The optimal K value is 700 for the translation-based language model. We can find that the performance is robust to different settings of K .

In Figure 2, we present the results by varying  X  from 0.0 to 1.0 with a step of 0.1.  X  controls the weight of these three combined ranking functions. As we can see, the best performance are all achieved when  X &gt; 0 . 5 . This indicates that lexical relatedness requires a larger weight when considering combination 2 .

Besides, we have tried different topic number T in the range from 50 to 500 with a step of 50, and find that the performance has no major change after the number of topics is increased above 150. In this paper we approach the problem of name ambiguity using lexical and thematic information. We compare our approach to two state-of-the-art methods that exploit only lexical information or thematic information. Our approach is able to combine both lex-ical and semantic information, which can exploit more information than others. We significantly improve the performance of name disambiguation and successfully detect names which are not covered in the knowledge base.

In this paper, linear combination achieves the best performance. However, we believe that there will be more effective methods to combine these two types of information. So we need to explore more combination methods, which is an open question. Acknowledgments. This work is supported by RenRen Games Grant QXWJ-YX-201206017 and NSFC with Grant No. 60933004, 61073082.

