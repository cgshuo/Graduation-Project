  X  { junzhu,epxing } @cs.cmu.edu  X  { lijiali,feifeili } @cs.stanford.edu to a number of computer vision tasks such as objection annotation and scene classification due The standard unsupervised LDA ignores the commonly available supervision information, and thus models which can explore side information for discovering predictive topic representations have been proposed, such as the sLDA [4, 25] and MedLDA [27]. A common characteristic of these topic assignment variables. Another type of supervised topic models are the so-called upstream contrast to downstream supervised topic models (dSTM), which are mainly designed by machine learning researchers, upstream supervised topic models (uSTM) are well-motivated from human vision and psychology research [18, 10] and have been widely used for scene understanding tasks. For example, in the recently developed scene understanding models [23, 13, 14, 8], complex scene images are modeled as a hierarchy of semantic concepts where the most top level corresponds to a learn an upstream scene model, maximum likelihood estimation (MLE) is the most common choice. However, MLE can make the prediction model estimation independent of latent topic discovery and result in an imbalanced prediction rule for scene classification, as we explain in Section 3. In this paper, our goal is to address the weakness of MLE for learning upstream supervised topic models. Our approach is based on the max-margin principle for supervised learning which has put prediction [24]. For the dSTM, max-margin training has been developed in MedLDA [27], which has achieved better prediction performance than MLE. In such downstream models, latent topic as-constraints based on existing max-margin methods (e.g., SVM). However, for upstream supervised rior distributions, which makes the max-margin training more delicate.
 Specifically, we present a joint max-margin and max-likelihood estimation method for learning up-stream scene understanding models. By using a variational approximation to the posterior distri-between posterior probabilistic inference and max-margin parameter learning. The parameter learn-ing solves an online loss-augmented SVM , which closely couples the prediction model estimation categorization. Finally, we demonstrate the advantages of our max-margin approach on both the 8-category sports [13] and the 67-class MIT indoor scene [20] datasets. Empirical results show that max-margin learning can significantly improve the scene classification accuracy. The paper is structured as follows. Sec. 2 presents a generic scene understanding model we will work on. Sec. 3 discusses the weakness of MLE in learning upstream models. Sec. 4 presents the max-margin learning approach. Sec. 5 presents empirical results and Sec. 6 concludes. will be used to demonstrate the large margin learning of upstream scene understanding models. 2.1 Image Representation How should we represent a scene image? Friedman [10] pointed out that object recognition is scenes, human vision researchers Navon [18] and Biederman [2] also showed that people perform scene images. To obtain a generic model, we represent a scene by using its global scene features patches X . These region features are represented as visual codewords. To describe detailed local [16] features, which are insensitive to view-point and illumination changes. To model the global scene representation, we extract a set of global features G [19]. In our dataset, we represent an image as a tuple ( r , x , g ) , where r denotes an instance of R , and likewise for x and g . 2.2 The Joint Scene and Object Model The model is shown in Fig. 1 (a). S is the scene random variable, taking values from a finite set S = { s 1 ,  X  X  X  ,s M representation features G . Each scene is represented as a mixture over latent objects O and the mixing weights are defined with a generalized linear model (GLM) parameterized by  X  . By using similar to the correlated topic models (CTMs) [3]. Here, we assume that for different scenes, the functions of S and G , the generating procedure of an image is as follows: The generative model defines a joint distribution scene classification, we infer the maximum a posteriori prediction manually annotated objects are provided. Since collecting fully labeled images with annotated ob-categorization, where only scene categories are provided and objects are treated as latent topics or themes [9]. In this paper, we focus on scene classification. Some empirical results on object annotation will be reported when labeled objects are available.
 We use this joint model as a running example to demonstrate the basic principe of performing max-margin learning for the widely applied upstream scene understanding models because it is well-motivated, very generic and covers many other existing scene understanding models. For example, if we do not incorporate the global scene representation G , the joint model will be reduced to a model similar as [14, 6, 23]. Moreover, the generic joint model provides a good framework for has been shown to be useful for scene classification [20] and object detection [17] tasks. To learn an upstream scene model, the most commonly used method is the maximum likelihood estimation (MLE), such as in [23, 6, 14]. In this section, we discuss the weakness of MLE for learning upstream scene models and motivate the max-margin approach.
 Let D = { ( I d ,s d ) } D where L s age features given the scene class, and  X   X   X  denotes all the parameters except  X  . This decoupling will result in an imbalanced combination between the conditional scene and object models for prediction, as we explain below.
 GLM, and it can be efficiently solved with gradient descent methods, such as quasi-Newton methods posterior p (  X ,o | s, r , x ,  X ) and using the Jensen X  X  inequality, we can derive a lower bound with the variational prediction rule Maximizing  X  inference of q s as involved in the prediction rule (5) and the estimation of  X   X   X  . based on L  X   X  (i.e., the blue bar), which only considers local image features. a better balanced combination between the scene and the object models. The strong coupling is due to solving an online loss-augmented SVM , as we explain below. Note that we are not claiming any weakness of MLE in general. All our discussions are concentrated on learning upstream supervised topic models, as generically represented by the model in Fig. 1. Now, we present the max-margin method for learning upstream scene understanding models. 4.1 Problem Definition function, which is more complicated than the commonly chosen linear form, in the sense we will of the prediction rule (1) on D as The problem with the above definition is that exactly computing the posterior distribution tightest lower bound is an approximation of the intractable discriminant function Then, the margin is  X  F d ( s ;  X ) =  X   X   X  f d ( s ) + max q Using the variational discriminant function in Eq. (7) and applying the principle of regularized as solving where  X ( X ) is a regularizer of the parameters. Here, we define  X ( X ) , 1  X  or covariance matrix  X  s , a similar  X  2 -norm or Frobenius norm can be used without changing our likelihood. When  X   X   X  , the problem (8) reduces to the standard MLE of the joint scene model MLE (2). Here, we minimize a hinge loss, which is defined on the joint prediction rule, while MLE Therefore, our approach can be expected to achieve a closer dependence between the conditional scene model and the latent object model. More insights will be provided in the next section. 4.2 Solving the Optimization Problem The problem (8) is generally hard to solve because the model parameters and variational distribu-rewrite the problem (8) as a min-max optimization problem where the factor 1 /D in R hinge is absorbed in the constant C . This min-max problem can be q = arg max q s L  X   X  ( q s ) for each s and each training image. Then, we solve and q s estimate the parameters by solving the following problem Since inferring q  X  as a two-step EM-procedure that iteratively performs posterior inference of q s and max-margin parameter estimation. Another way to understand this iterative procedure is from the definitions. The first step of inferring q  X  Then, we update the model parameters  X  by solving a large-margin learning problem. For brevity, we present the parameter estimation only. The posterior inference is detailed in Appendix A.1. Parameter Estimation : This step can be done with an alternating minimization procedure. For in a closed-form as in a standard MLE of CTMs [3] by using a loss-augmented prediction of s . For brevity, we defer the details to the Appendix A.2. Now, we present the step of estimating  X  , Specifically, the optimum solution of  X  is obtained by solving the sub-problem 3 is that we have the additional term discovery procedure, which finds an optimum posterior distribution q  X  . If  X  L  X  scene s d , then the term  X  L  X  a correct prediction on this image by using the prediction rule (5). If  X  L  X  a linear SVM, but with an online updated loss function  X   X  d ( s )  X   X  L  X  online loss-augmented SVM . Solving the loss-augmented SVM will result in an amplified influence of the scene classification model in the joint predictive rule (5) as shown in Fig. 1 (b). Now, we present empirical evaluation of our approach on the sports [13] and MIT indoor scene [20] datasets. Our goal is to demonstrate the advantages of the max-margin method over the MLE for learning upstream scene models with or without global features. Although the model in Fig. 1 can also be used for object annotation, we report the performance on scene categorization only, which is our main focus in this paper. For object annotation, which requires additional human annotated 5.1 Datasets and Features images. The indoor scene dataset [20] contains 15620 scene images from 67 categories as listed in Table 2. We use the method [1] to segment these images into small regions based on color, bright-quantize them into 30, 50 and 120 codewords, respectively. Similarly, the SIFT features extracted from the small patches within each region are quantized into 300 SIFT codewords. We use the gist SIFT sparse codes [26], can be directly done without changing the model or the algorithm. 5.2 Models For the upstream scene model as in Fig. 1, we compare the max-margin learning with the MLE method, and we denote the scene models trained with max-margin training and MLE by MM-Scene and MLE-Scene , respectively. For both methods, we evaluate the effectiveness of global features, and we denote the scene models without global features by MM-Scene-NG and MLE-Scene-NG , respectively. Since our main goal in this paper is to demonstrate the advantages of max-margin we just compare with one example of downstream models X  X he multi-class sLDA (Multi-sLDA) [25]. Systematical comparison with other methods, including DiscLDA [12] and MedLDA [27], is deferred to a full version. For the downstream Multi-sLDA, the image-wise scene category variable S is generated from latent object variables O via a softmax function. For this downstream model, the parameter estimation can be done with MLE as detailed in [25].
 changes to learn the loss-augmented SVM in our max-margin method. 5.3 Scene Categorization on the 8-Class Sports Dataset The average overall accuracy of scene categorization on 8 categories and its standard deviation are shown in Fig. 3. The result of logistic regression is shown in the left green bar in Fig. 1 (c). We also show the confusion matrix of the max-margin scene model with 100 latent topics in Table 1, and example images from each cat-egory are shown in Fig. 2 with predicted labels. Over-all, the max-margin scene model with global features achieves significant improvements as compared to all other approaches we have tested. Interestingly, al-though we provide only scene categories as supervised information during training, our best performance with global features is close to that reported in [13], where additional supervision of objects is used. The outstanding performance of the max-margin method for scene classification can be understood from the following aspects.
 Max-margin training : from the comparison of the max-margin approach with the standard MLE learning can improve the performance dramatically, especially when the scene model uses global features (about 3 percent). This is due to the well-balanced prediction rule achieved by the max-margin method, as we have explained in Section 3.
 Global features : from the comparison between the scene models with and without global features, rization accuracy in both MLE and max-margin training. We also did some preliminary experiments and sparse codes features, we can achieve dramatic improvements in both max-margin and MLE methods. Specifically, the max-margin scene model achieves an accuracy of about 0.83 in scene classification, and the likelihood-based model obtains an accuracy of about 0.80. Object modeling : the superior performance of the max-margin learned MM-scene model comparing classification model is influenced by the latent object modeling through the term  X  L  X  improve the decision boundary of a standard linear SVM for those images that have negative scores of  X  L  X  d ( s ) , as we have discussed in the online loss-augmented SVM. However, object modeling does not improve the classification accuracy and sometimes it can even be harmful when the scene representation) (e.g., MM-MLE-NG) alone performs much worse than global feature models (e.g., logistic regression), as shown in Fig. 1 and Fig. 3, and the standard MLE learns an imbalanced coupled and well-balanced max-margin learning. These results indicate that further improvements can be expected by improving the local object model, e.g., by incorporating rich features. We also compare with the theme model [9], which is for scene categorization only. The theme model uses a different image representation, where each image is a vector of image patch codewords. The theme model achieves about 0.65 in classification accuracy, lower than that of MM-Scene. Table 1: Confusion matrix for 100-topic MM-Finally, we examine the influence of the loss function  X   X  d ( s ) on the performance of the max-margin scene model. As we can see in problem (11), the loss function  X   X  d ( s ) is another important factor that influences the estimation of  X  and its relative importance in the predic-tion rule (5). Here, we use the 0 / X  -loss function, that is,  X   X  d ( s ) =  X  if s  X  = s d ; otherwise 0 . Fig. 4 shows the performance of the 100-topic MM-Scene model when using different loss functions. When  X  is set between 10 and 20, the MM-Scene method stably achieves the best performance. The above results in Fig. 3 and Table 1 are achieved with  X  selected from 5 to 40 with cross-validation during training. 5.4 Scene Categorization on the 67-Class MIT Indoor Scene Dataset The MIT indoor dataset [20] contains complex scene images from 67 categories. We use the same training and testing dataset as in [20], in which each category has about 80 images for training and about 20 images for testing. We compare the joint scene model with SVM, logistic regression (LR), and the prototype-based methods [20]. Both the SVM and LR are based on the global gist features only. For the joint scene model, we set the number of latent topics at 70. The overall performance of different methods are shown in Fig. 5 and the classification accuracy of each class is shown in Table 2. For the prototype-based methods, we cite the results from [20]. We can see that the joint scene model (both MLE-Scene and MM-Scene) significantly outperforms SVM and LR that use global features only. The likelihood-based MLE-Scene slightly outperforms the ROI-Gist(segmentation), automatically segmented regions [20]. By using max-margin training, the joint scene model (i.e., MM-Scene) achieves significant improvements compared to MLE-Scene. Moreover, the margin-based MM-Scene, which uses automatically segmented regions to extract features, outperforms the ROI-Gist(annotation) method that uses human annotated interested regions. In this paper, we address the weak coupling problem of the commonly used maximum likelihood estimation in learning upstream scene understanding models by presenting a joint maximum mar-gin and maximum likelihood learning method. The proposed approach achieves a close interplay between the prediction model estimation and latent topic discovery, and thereby a well-balanced prediction rule. The optimization problem is efficiently solved with a variational EM procedure, which iteratively learns an online loss-augmented SVM. Finally, we demonstrate the advantages of max-margin training and the effectiveness of using global features in scene understanding on both an 8-category sports dataset and the 67-class MIT indoor scene data. J.Z and E.P.X are supported by ONR N000140910758, NSF IIS-0713379, NSF Career DBI-0546594, and an Alfred P. Sloan Research Fellowship to E.P.X. L.F-F is partially supported by an NSF CAREER grant (IIS-0845230), a Google research award, and a Microsoft Research Fellow-ship. We also would like to thank Olga Russakovsky for helpful comments.

