 In this paper, we address the important issue of uncertainty in the edge influence probability estimates for the well stud-ied influence maximization problem  X  the task of finding k seed nodes in a social network to maximize the influence spread. We propose the problem of robust influence maxi-mization, which maximizes the worst-case ratio between the influence spread of the chosen seed set and the optimal seed set, given the uncertainty of the parameter input. We de-sign an algorithm that solves this problem with a solution-dependent bound. We further study uniform sampling and adaptive sampling methods to effectively reduce the uncer-tainty on parameters and improve the robustness of the in-fluence maximization task. Our empirical results show that parameter uncertainty may greatly affect influence maxi-mization performance and prior studies that learned influ-ence probabilities could lead to poor performance in robust influence maximization due to relatively large uncertainty in parameter estimates, and information cascade based adap-tive sampling method may be an effective way to improve the robustness of influence maximization.
 social networks, influence maximization, robust optimiza-tion, information diffusion
In social and economic networks, Influence Maximization problem has been extensively studied over the past decade, due to its wide applications to viral marketing [13 , 19 ], out-break detection [ 22], rumor monitoring [6 ], etc. For example, a company may conduct a promotion campaign in social net-works by sending free samples to the initial users (termed as seeds), and via the word-of-mouth (WoM) effect, more and more users are influenced by social links to join the campaign and propagate messages of the promotion. This problem is first introduced by Kempe et al. [ 19 ] under an algorithmic framework to find the most influential seeds, and they propose the independent cascade model and lin-ear threshold model, which consider the social-psychological factors of information diffusion to simulate such a random process of adoptions.

Since Kempe et al. X  X  seminal work, extensive researches have been done on influence maximization, especially on im-proving the efficiency of influence maximization in the inde-pendent cascade model [ 11 , 10 , 16 , 4, 28 ], all of which assume that the ground-truth influence probabilities on edges are exactly known. Separately, a number of studies [26 , 27 , 15 , 25 , 24 ] propose learning methods to extract edge influence probabilities. Due to inherent data limitation, no learning method could recover the exact values of the edge proba-bilities, and what can be achieved is the estimates on the true edge probabilities, with confidence intervals indicating that the true values are within the confidence intervals with high probability. The uncertainty in edge probability esti-mates, however, may adversely affect the performance of the influence maximization task, but this topic has left mostly unexplored. The only attempt addressing this question is a recent study in [ 18], but due to a technical issue as explained in [18 ], the results achieved by the study is rather limited.
In this paper, we utilize the concept of robust optimiza-tion [3 ] in operation research to address the issue of influ-ence maximization with uncertainty. In particular, we con-sider that the input to the influence maximization task is no longer edge influence probability on every edge of a social graph, but instead an interval in which the true probability may lie. Thus the input is actually a parameter space  X , which is the product of all intervals on all edges. For any seed set S , let  X   X  ( S ) denote the influence spread of S under parameter setting  X   X   X . Then we define robust ratio of S as achieving the maximum influence spread under parameter  X  . Intuitively, robust ratio of S indicates the (multiplicative) gap between its influence spread and the optimal influence spread under the worse-case parameter  X   X   X , since we are unsure which  X   X   X  is the true probability setting. Then our optimization task is to find a seed set of size k that maxi-mize the robust ratio under the known parameter space  X   X  we call this task Robust Influence Maximization (RIM) .
It is clear that when there is no uncertainty on edge proba-bilities, which means  X  collapses to the single true parameter  X  , RIM degenerates to the classical influence maximization problem. However, when uncertainty exists, solving RIM may be a more difficult task. In this paper, we first pro-pose an algorithm LUGreedy that solves the RIM task with a solution-dependent bound on its performance, which means that one can verify its performance after it selects the seed set (Section 3). We then show that if the input parameter space  X  is only given and cannot be improved, it is possible that even the best robust ratio in certain graph instances could be very small (e.g. O (log n/ number of nodes in the graph). This motivates us to study sampling methods to further tighten parameter space  X , and thus improving the robustness of our algorithm (Section 4). In particular, we study both uniform sampling and adaptive sampling for improving RIM performance. For uniform sam-pling, we provide theoretical results on the sample complex-ity for achieving a given robust ratio of the output seed set. For adaptive sampling, we propose an information cascade based sampling heuristic to adaptively bias our sampling ef-fort to important edges often traversed by information cas-cades. Through extensive empirical evaluations (Section 5), we show that (a) robust ratio is sensitive to the width of the confidence interval, and it decreases rapidly when the width of the confidence interval increases; as a result prior studies that learned edge probabilities may result in poor robust ra-tio due to relative large confidence intervals (and thus high uncertainty); (b) information cascade based adaptive sam-pling method performs better than uniform sampling and other baseline sampling methods, and can significantly im-prove the robustness of the influence maximization task.
In summary, the contribution of our paper includes: (a) proposing the problem of robust influence maximization to address the important issue of uncertainty in parameter estimates adversely impacting the influence maximization task; (b) providing the LUGreedy algorithm that guaran-tees a solution-dependent bound; and (c) studying uniform and adaptive sampling methods to improve robust influence maximization.

Due to space constraint, the proofs of some technical re-sults are omitted. The complete proofs of all results can be found in the full technical report [9 ].
Influence maximization has been extensively studied and we already point out a number of closely related studies to our work in the introduction. For a comprehensive survey, one can refer to the monograph [ 8]. We discuss a few most relevant work in more detail here.
 To the best of our knowledge, the study by He and Kempe [18 ] is the only attempt prior to our work that also tries to address the issue of uncertainty of parame-ter estimates impacting the influence maximization tasks. However, besides the similarity in motivation, the technical treatments are quite different. First, their central problem, called influence difference maximization, is to find a seed set of size k that maximizes the additive difference between the two influence spreads of the same seed set using different parameter values. Their purpose is to see how large the in-fluence gap could be due to the uncertainty in parameter space. However, our goal is still to find the best possible seed set for influence maximization purpose, while consider-ing the adverse effect of the uncertainty, and thus we utilize the robust optimization concept and use the worse-case mul-tiplicative ratio between the influence spread of the chosen seed set and the optimal seed set as our objective function. Second, their influence difference maximization turns out to be hard to approximate to any reasonable ratio, while we provide an actual algorithm for robust influence maximiza-tion that has both a theoretical solution-dependent bound and performs reasonably well in experiments. Third, we further consider using sampling methods to improve RIM, which is not discussed in [18 ].

In the context of robust optimization, Krause et al. X  X  work on robust submodular optimization [20 ] is possibly the clos-est to ours. Our RIM problem can be viewed as a specific instance of robust submodular optimization studied in [ 20]. However, due to the generality of problem scope studied in [ 20 ], they show strong hardness results and then they have to resolve to bi-criteria solutions. Instead, we are working on a particular instance of robust submodular optimization, and their bi-criteria solution may greatly enlarge the selected seed set size, which may not be allowed in our case. Fur-thermore, they work on finite set of submodular functions, but in our case our objective function is parametrized with  X  from a continuous parameter space  X , and it is unclear how their results work for the continuous case.
 In a parallel work that will appear in the same proceeding, He and Kempe study the same subject of robust influence maximization [17 ], but they follow the bi-criteria approxi-mation approach of [20 ], and thus in general their results are orthogonal to ours. In particular, they use essentially the same objective function, but they work on a finite set of influence spread functions  X , and require to find k  X  ln |  X  | seeds to achieve 1  X  1 /e approximation ratio comparing to the optimal seed set of size k ; when working on continuous parameter space  X , they show that it is equivalent to a finite spread function space of size 2 n and thus requiring  X  ( kn ) seeds for a bi-criteria solution, which renders the bi-criteria solution useless. Thus their bi-criteria approach is suitable when the set of possible spread functions  X  is small.
Adaptive sampling for improving RIM bears some resem-blance to pure exploration bandit research [ 5], especially to combinatorial pure exploration [ 7] recently studied. Both use adaptive sampling and achieve some optimization objec-tive in the end. However, the optimization problem modeled in combinatorial pure exploration [7 ] does not have a robust-ness objective. Studying robust optimization together with combinatorial pure exploration could be a potentially inter-esting topic for future research. Another recent work [21 ] uses online algorithms to maximize the expected coverage of the union of influenced nodes in multiple rounds based on online feedbacks, and thus is different from our adap-tive sampling objective: we use feedbacks to adjust adaptive sampling in order to find a seed set nearly maximizing the robust ratio after the sampling is done.
As in [19 ], the independent cascade (IC) model can be equivalently modeled as a stochastic diffusion process from seed nodes or as reachability from seed nodes in random live-edge graphs. For brevity, we provide the live-edge graph description below. Consider a graph G = ( V,E ) comprising a set V of nodes and a set E of directed edges, where every edge e is associated with probability p e  X  [0 , 1], and let n = | V | and m = | E | . To generate a random live-edge graph, we declare each edge e as live if flipping a biased random coin with probability p e returns success, declare e as blocked otherwise (with probability 1  X  p e ). The randomness on all edges are mutually independent. We define the subgraph L Algorithm 1 Greedy ( G,k, X  ) Input: Graph G , budget k , parameter vector  X  1: S 0  X  X  X  2: for i = 1 , 2 ,...,k do 3: v  X  arg max v/  X  S 5: end for 6: return S k consisting of V and the set of live edges as the (random) live-edge graph . Given any set S  X  V (referred as seeds ), let R L ( S )  X  V denote the reachable set of nodes from S in live-edge graph L , i.e., (1) S  X  R L ( S ), and (2) for a node v /  X  S , v  X  R L ( S ) iff there is a path in L directing from some node in S to v .

For convenience, we use parameter vector  X  = ( p e ) e  X  E denote the probabilities on all edges. The influence spread function  X   X  ( S ) is defined as the expected size of the reach-able set from S , that is where Pr  X  [ L ] is the probability of yielding live-edge graph L under vector  X  . From [19 ], we know that the influence spread function is non-negative (  X  S  X  V ,  X   X  ( S )  X  0), monotone (  X  S  X  T  X  V ,  X   X  ( S )  X   X   X  ( T )), and submodular (  X  S  X  T  X  V ,  X  v  X  V  X   X  ( S  X  X  v } )  X   X   X  ( S )  X   X   X  ( T  X  X  v } )  X   X 
The well-known problem of Influence Maximization raised in [19 ] is stated in the following.

Problem 1 (Influence Maximization [ 19]). Given a graph G = ( V,E ) , parameter vector  X  = ( p e ) e  X  E fixed budget k , we are required to find a seed set S  X  V of k vertices, such that the influence spread function  X  maximized, that is, It has been shown that Influence Maximization problem is NP-hard [19 ]. Since the objective function  X   X  ( S ) is sub-modular, we have a (1  X  1 e ) approximation using standard greedy policy Greedy ( G,k, X  ) in Algorithm 1 (assuming a Greedy ( G,k, X  ). As a convention, we assume that both opti-mal seed set S  X   X  and greedy seed set S g  X  in this paper are of fixed size k implicitly.

On the other hand, it is proved by Feige [ 14] that such an approximation ratio could not be improved for k -max cover problem, which is a special case of the influence maximiza-tion problem under the IC model.

However, the knowledge of the probability on edges is usu-ally acquired by learning from the real-world data [26 , 27 , 15 , 25 , 24 ], and the obtained estimates always have some inaccuracy comparing to the true value. Therefore, it is natural to assume that, from observations of edge e , we can obtain the statistically significant neighborhood [ l e ,r the confidence interval where the true probability p e lies in with high probability. This confidence interval prescribes the uncertainty on the true probability p e of the edge e , and such uncertainty on edges may adversely impact the in-fluence maximization task. Motivated by this, we study the problem of robust influence maximization as specified below.
Suppose for every edge e , we are given an interval [ l e (0  X  l e  X  r e  X  1) indicating the range of the probability, and the ground-truth probability p e  X  [ l e ,r e ] of this edge is unknown. Denote  X  =  X  e  X  E [ l e ,r e ] as the parameter space of network G , and  X  = ( p e ) e  X  E as the latent parameter vector. Specifically, let  X   X  ( X ) = ( l e ) e  X  E and  X  + ( X ) = ( r the minimum and maximum parameter vectors, respectively, and when the context is clear, we would only use  X   X  . For a seed set S  X  V and | S | = k , define its robust ratio under parameter space  X  as where S  X   X  is the optimal solution of size k when the proba-bility on every edge is given by  X  .

Given  X  and solution S , the robust ratio g ( X  ,S ) charac-terizes the worst-case ratio of influence spread of S and the underlying optimal one, when the true probability vector  X  is unknown (except knowing that  X   X   X ). Then, the Robust Influence Maximization (RIM) problem is defined as follows. Problem 2 (Robust Influence Maximization).
 Given a graph G = ( V,E ) , parameter space  X  =  X  e  X  E [ l and a fixed budget k , we are required to find a set S  X  V of k vertices, such that robust ratio g ( X  ,S ) is maximized, i.e.,
The objective of this problem is to find a seed set S  X   X  has the largest robust ratio, that is, S  X   X  should maximize the worst-case ratio between its influence spread and the opti-mal influence spread, when the true probability vector  X  is unknown. When there is no uncertainty, which means  X  collapses to the true probability  X  , we can see that the RIM problem is reduced back to the original influence maximiza-tion problem.

In RIM, the knowledge of the confidence interval is as-sumed to be the input. Another interpretation is that, it can be viewed as given an estimate of probability vector  X   X  = (  X  p e ) e  X  E with a perturbation level  X  e on each edge e , such that the true probability p e  X  [  X  p e  X   X  e ,  X  p e which constitutes parameter space  X  =  X  e  X  E [ l e ,r e ]. Notice that, in reality, this probability could be obtained via edge samplings, i.e., we make samples on edges and compute the fraction of times that the edge is live. On the other hand, we can also observe information cascades on each edge when collecting the trace of diffusion in the real world, so that the corresponding probability can be learned.

However, when the amount of observed information cas-cade is small, the best robust ratio max S g ( X  ,S ) for the given  X  can be low so that the output for a RIM algorithm does not have a good enough guarantee of the performance in the worst case. Then a natural question is, given  X , how to further make samples on edges (e.g., activating source node u of an edge ( u,v ) and see if the sink node v is activated through edge e ) so that max S g ( X  ,S ) can be efficiently im-proved? To be specific, how to make samples on edges and output  X  0 and S 0 according to the outcome so that (a) with high probability the true value  X  lies in the output parame-ter space  X  0 , where the randomness is taken according to  X  , and (b) g ( X  0 ,S 0 ) is large. This sub-problem is called Sam-pling for Improving Robust Influence Maximization , and will be addressed in Section 4. Algorithm 2 LUGreedy ( G,k,  X ) Input: Graph G = ( V,E ), budget k , parameter space  X  = 1: S g  X   X   X  Greedy ( G,k, X   X  ) 2: S g  X  +  X  Greedy ( G,k, X  + ) 3: return arg max S  X  n S g
Consider the problem of RIM, parameter space  X  =  X  bility  X   X   X . Let  X   X  = ( l e ) e  X  E and  X  + = ( r e ) e  X  E
Our first observation is that, when  X  is a single vector ( l e = r e ,  X  e  X  E ), it is trivially reduced to the classical Influence Maximization problem. Therefore, we still have the following hardness result on RIM [19 , 14 ]:
Theorem 1. RIM problem is NP -hard, and for any  X  &gt; 0 , it is NP -hard to find a seed set S with robust ratio at least 1  X  1 e +  X  .

To circumvent the above hardness result, we develop al-gorithms that achieves reasonably large robust ratio. When we are not allowed to make new samples on the edges to improve the input interval, it is natural to utilize the greedy algorithm of submodular maximization in [19 ] (i.e., Algo-rithm 1) as the subroutine to calculate the solution. In light of this, we first propose Lower-Upper Greedy Algorithm and the solution-dependent bound for g ( X  ,S ), and then discuss g ( X  ,S ) in the worst-case scenario.
Given parameter space  X  =  X  e  X  E [ l e ,r e ] with the min-imum and maximum parameter vectors  X   X  = ( l e ) e  X  E and  X  + = ( r e ) e  X  E , our Lower-Upper Greedy algorithm ( LUGreedy ( G,k,  X )) is described in Algorithm 2 which out-puts the best seed set S LU  X  for the minimum parameter vector  X   X  such that
To evaluate the performance of this output, we first define the gap ratio  X  ( X )  X  [0 , 1] of the input parameter space to be Then, LUGreedy achieves the following result:
Theorem 2 (solution-dependent bound). Given a graph G , parameter space  X  and budget limit k , LUGreedy outputs a seed set S LU  X  of size k such that
Proof. For any seed set S , g ( X  ,S ) = min  X   X   X   X   X  ( S ) definition. Obviously, it is a fact that  X   X  ( S ) is monotone on  X  for any fixed S . From the definition of optimal solutions and the greedy algorithm, we can get  X   X  ( S  X   X  )  X   X   X  +  X  g ( X  ,S )  X  min Use seed set S LU  X  from LUGreedy , and it follows immediately
We refer  X  ( X )(1  X  1 e ) as the solution-dependent bound of g ( X  ,S LU  X  ) that LUGreedy achieves, because it depends on the solution S LU  X  . The good thing is that it can be evaluated once we have the solution, and then we know the robust ra-tio must be at least this lower bound. Note that the bound is good if  X  ( X ) is not too small, and thus it in turn indi-cates that the influence spread  X   X  ( S LU  X  ) we find has a good performance under any probability vector  X   X   X .

It is worth remarking that the choice of using  X  ( X ) =  X  ing reasons: (a) Intuitively, S g  X   X  is expected to be the best possible seed set we can find that maximizes  X  (b) Meanwhile, we consider S g  X  + as a potential seed set for the later theoretical analysis (in the proof of Theo-rem 6), which requires the alignment of the same seed set for the numerator and denominator. Thus,  X  ( X )  X   X  + and  X   X  tend to the same value  X  , RIM is tending to-wards the classical Influence Maximization, and thus the result  X   X  ( S g  X  ). The approach adopted by LUGreedy is simi-lar to the sandwich approximation used in [23 ].

The following example shows that for certain problem in-stances, the gap ratio  X  ( X ) of LUGreedy could match the robust ratio g ( X  ,S LU  X  ), which also matches the best possible robust ratio max | S | = k g ( X  ,S ).

Example 1. Consider a graph G = ( V,E ) where the set of nodes are equally partitioned into 2 k subsets V =  X  2 k such that every V i contains t + 1 nodes. Let V i = { v j j  X  t + 1 } and set E =  X  2 k i =1 E i where E i = { ( v j  X  t + 1 } . That is, every ( V i ,E i ) forms a star with v being the node at the center, all stars are disconnected from one another. For the parameter space we set the interval on every edge to be [ l,r ] . When LUGreedy selects k nodes, since all v 1 i  X  X  have the same (marginal) influence spread, w.l.o.g., set the true probability vector  X   X   X  s.t. p e = l for every to check that max | S | = k g ( X  ,S ) = g ( X  ,S LU  X  ) =  X  ( X ) = The intuition from the above example is that, when there are many alternative choices for the best seed set, and these alternative seed sets do not have much overlap in their in-fluence coverage, the gap ratio  X  ( X ) is a good indicator of the best possible robust ratio one can achieve.

In the next subsection, we will show that the best robust ratio could be very bad for the worst possible graph G and parameter space  X , which motivates us to do further sam-pling to improve  X .
For the theoretical perspective, we show in this part that if we make no assumption or only add loose constraints to the input parameter space  X , then no algorithm will guarantee good performance for some worst possible graph G .

Theorem 3. For RIM, 1. There exists a graph G = ( V,E ) and parameter space 2. There exists a graph G = ( V,E ) , constant  X  =  X  3. Consider random seeds set  X  S of size k . There exists a
In the first case, we allow the input  X  to be an arbi-trary parameter space. It is possible that  X  =  X  for some graph G , which means there is no knowledge at all for edge probabilities. Then any seed set may achieve O k n -approximation of the optimal solution in the worst case. Intuitively, a selected seed set S may rarely activate other nodes (i.e., O ( k )), while optimal solution (to the latent  X  ) may cover almost the whole graph (i.e.,  X ( n )).
In the second case, an additional constraint is assumed on the parameter space  X  +  X   X   X   X   X   X  , i.e., for every e  X  E , r  X  l e  X   X  , to see if we could obtain a better performance when  X  is small. However, even though  X  is in the order of O (1 /n ), the robust ratio can be as small as O (log n/n ). The proof is related to the phase transition in the Erd  X os-R  X enyi graph for the emergence of giant component. In particu-lar, if we have a graph G consisting of two disconnected, equal-sized Erd  X os-R  X enyi random graphs with edge probabil-ities close to the critical value of generating a giant con-nected component, then whenever we select a seed in one component, that component could be just below the thresh-old resulting in O (log n ) influence spread while the other component is just above the threshold leading to  X  ( n ) in-fluence spread. Thus, the worst-case ratio for any one-node seed set is always O (log n/n ). A similar discussion can be found in [ 18 ].

In the third case, we allow the algorithm to be random-ized, namely the output seed set  X  S is a random set of size k . Even in this case, the robust ratio could be as bad as O (log n/
From the previous section, we propose LUGreedy algo-rithm to check the solution-dependent bound of the robust ratio, and point out the worse-case bound could be small if  X  is not assumed to be tight enough.

Theorem 3 in the previous subsection points out that the best possible robust ratio max S g ( X  ,S ) can be too low so that the output for RIM could not provide us with a satis-fying seed set in the worst case. Then a natural question is: given the input  X , can we make efficient samples on edges so that  X  is narrowed into  X  0 (this means the true  X   X   X  with high probability) and then output a seed set S 0 that makes g ( X  0 ,S 0 ) large? This problem is called Sampling for Improving RIM .

In this section we study both uniform sampling and adap-tive sampling for improving RIM. According to the Cher-noff X  X  bound, the more samples we make on an edge, the narrower the confidence interval we get that guarantees the true probability to be located within the confidence inter-val with a desired probability of confidence. After sampling to get a narrower parameter space, we could use LUGreedy algorithm to get the seed set.
In Sampling for improving RIM, the goal is to design a sampling and maximization algorithm A that outputs  X  and S 0 such that with high probability the robust ratio of S 0 in  X  0 is large. After sampling edges, we can use Cher-noff X  X  bound to compute the confidence interval, and the confidence interval can be further narrowed down with more samples. However, the key issue is to connect the width of confidence interval with the stability of influence spread. We propose two ideas exploiting properties of additive and multiplicative confidence interval respectively to this issue, and incorporate into Uniform Sampling algorithm (in Algo-rithm 3) with theoretical justification (in Theorem 6).
Our first idea is inspired by the following lemma from [12 ] to build the connection in the additive form.

Lemma 4 (Lemma 7 in [ 12 ]). Given graph G and pa-rameter space  X  such that  X   X  1 , X  2  X   X  , k  X  1  X   X  2 k then,  X  S  X  V ,
We use a tight example (in the order of | V | and | E | ) to illustrate the connection and give an insight of this lemma as follows. Consider graph G = ( V,E ) with | V | = n and | E | = m ( m n ). Let G be two disjoint cycles, each containing exactly n 2 nodes and n 2 edges. We arbitrarily assign the rest m  X  n edges between two cycles. Then, for every edge e in the cycle, the interval is l e = r e = 1, and l 0, r e =  X  for those between two cycles, which constitutes budget k = 1. For any single-node set S , it is easy to check that for  X   X  = ( l e ) e  X  E ,  X   X   X  ( S ) = n 2 , and for  X   X   X  + ( S )  X  n 2 + n 2 ( m  X  n )  X  , thus |  X   X  + ( S )  X   X  n )  X  in this case. As a comparison, from Lemma 4, we know that |  X   X  + ( S )  X   X   X   X  ( S ) | X  mn X  .

Therefore, the above lemma establishes the guidance that we may sample every edge for sufficient times to shrink their confidence intervals in  X , and feed LUGreedy with  X  as same as solving RIM, then the performance is guaranteed by The-orem 2, which matches our intuition that LUGreedy performs well with the satisfactory  X .

On the other hand, our second idea is to use the multi-plicative confidence interval to reduce the fluctuation of in-fluence spread, then LUGreedy still applies. The next lemma is crucial to achieve this goal. Algorithm 3 US-RIM Input: Graph G = ( V,E ), budget k , ( , X  ) Output: Parameter space  X  out , seed set S out 1: for all e  X  E do 2: Sample e for t times, and observe x 1 e ,...,x t e 3: p e  X  1 t P t i =1 x i e , and set  X  e according to Theorem 6 4: r e  X  min { 1 ,p e +  X  e } , l e  X  max { 0 ,p e  X   X  e } 5: end for 7: S out  X  LUGreedy ( G,k,  X  out ) 8: return ( X  out , S out ) Lemma 5. Given graph G = ( V,E ) and parameter space  X  . If there exists  X   X  0 , for all edge e  X  E , s.t., r (1 +  X  ) l e , then for any nonempty set S  X  V , and In this lemma, the ratio of influence spread can be bounded based on the relation of l e and r e in the multiplicative form. To unify both ideas mentioned above, we propose Uniform Sampling for RIM algorithm ( US-RIM ) in Algorithm 3, and the theoretical result is presented in Theorem 6. Basically, the algorithm samples every edge with the same number of times, and use LUGreedy to obtain the seed set. We set different t and  X  e for the two ideas. Henceforth, we explicitly refer the first setting as Uniform Sampling with Additive form ( US-RIM-A ), and the second one as Uniform Sampling with Multiplicative form ( US-RIM-M ).

Theorem 6. Given a graph G = ( V,E ) , budget k , and accuracy parameter , X  &gt; 0 , let n = | V | and m = | E | , then for any unknown ground-truth parameter vector  X  = ( p e ) e  X  E , Algorithm US-RIM outputs ( X  out , S out ) such that with Pr[  X   X   X  out ]  X  1  X   X  , where the randomness is taken according to  X  , if we follow either of the two settings: 2. Assume we have p 0 such that 0 &lt; p 0  X  min e  X  E p
In general, the total number of samples summing up all for US-RIM-M with an additional constant p 0 , the lower bound probability on all edge probabilities. The difference is that the former has a higher order of m , and the latter requires the knowledge of p 0 and has an extra dependency on O (1 /p 0 ). Since the sample complexity for both settings can be calculated in advance, one may compare the values and choose the smaller one when running the uniform sam-pling algorithm. An intuitive interpretation is that: (1) with high probability (  X  1  X   X  ), the algorithm always outputs an (1  X  1 e  X  )-approximation solution guaranteed by US-RIM-A ; (2) if p 0 =  X ( k 2 m 2 ) (it is a loose assumption naturally satis-fied in practice), we may choose US-RIM-M to achieve better sample complexity.
In a real network, the importance of edges in an influ-ence diffusion process varies significantly. Some edges may have larger influence probability than others or connect two important nodes in the network. Therefore, in sampling it is crucial to sample edges appropriately. Moreover, we can adapt our sampling strategy dynamically to put more sam-pling effort on critical edges when we learn the edge proba-bilities more accurately over time.

For convenience, given graph G = ( V,E ), we define ob-servation set M = { M e } e  X  E as a collection of sets, where M the first t e samples on edge e . We allow that a parameter space  X  0  X   X  e  X  E [0 , 1] is given, which can be obtained by some initial samples M 0 (e.g., uniformly sample each edge of the graph for a fixed number of times).

The following lemma is used to calculate the confidence in-terval, which is a combination of additive and multiplicative Chernoff X  X  Bound. We adopt this bound in the experiment since some edges in the graph have large influence probabil-ity while others have small ones, but using either additive or multiplicative bound may not be good enough to obtain a small confidence interval. The following bound is adapted from [ 1] and is crucial for us in the experiment.

Lemma 7. For each e  X  E , let M e = x 1 e ,x 2 e ,...,x be samples of e in M = { M e } e  X  E , and t e be the sample number. Given any  X  &gt; 0 , let confidence intervals for all edges be  X  =  X  e  X  E [ l e ,r e ] , such that, for any e  X  E , at least 1  X   X  , the true probability  X  = ( p e ) e  X  E satisfies that  X   X   X  .

Our intuition for non-uniform sampling is that the edges along the information cascade of important seeds determine the influence spread, and henceforth they should be esti-mated more accurately than other edges not along impor-tant information cascade paths. Thus, we use the follow-ing Information Cascade Sampling method to select edges. Starting from the seed set S , once node v is activated, v will try to activate its out-neighbors. In other words, for every out-edge e of v , denote t e as the number of samples, then e will be sampled once to generate a new observation x e based on the latent Bernoulli distribution with success probability p e , and t e will be increased by 1. The process goes on until the end of the information cascade.
 We propose Information Cascade Sampling for RIM ( ICS-RIM ) algorithm in Algorithm 4, which adopts information cascade sampling described above to select edges.

Algorithm 4 is an iterative procedure. In the i -th itera-tion, Lemma 7 is used to compute the confidence interval Algorithm 4 ICS-RIM (  X  ): Information Cascade Sampling Input: Graph G = ( V,E ), budget k , initial sample M Output: Parameter space  X  out , seed set S out 1: i  X  0 2: repeat 3: Get  X  i based on M i (see Lemma 7). 4: S LU  X  i = LUGreedy ( G,k,  X  i ) 6: for j = 1 , 2 ,..., X  do 7: Do information cascade with the seed set S LU  X  i 8: During the cascade, once v  X  V is activated, sample 9: end for 10: i  X  i + 1 11: until  X  ( X  i ) &gt;  X  14: return ( X  out ,S out )  X  i from observation set M i . Then according to  X  i , we find the lower-upper greedy set S LU  X  i and use information cascade to update observation set M i +1 by absorbing new samples.
Since the robust ratio g ( X  ,S LU  X  i ) cannot be calculated ef-ficiently, we will calculate  X  ( X ) (defined in (3 )) instead. In our algorithm, we use a pre-determined threshold  X  (  X   X  (0 , 1)) as the stopping criteria. Therefore, for S the robust ratio g ( X  ,S out )  X   X  ( X ) 1  X  1 e &gt;  X  1  X  guaranteed by Theorem 2, and the true probability  X   X   X  out holds with probability at least 1  X   X  due to Lemma 7.
Compared with information cascade sampling method, calculating a greedy set is time-consuming. Therefore in Algorithm 4, we call LUGreedy once every  X  rounds of infor-mation cascades to reduce the cost. We conduct experiments on two datasets, Flixster 1 and NetHEPT 2 to verify the robustness of influence maximiza-tion and our sampling methods. cial movie discovery service (www.flixster.com). To trans-form the dataset into a weighted graph, each user is rep-resented by a node, and a directed edge from node u to v is formed if v rates one movie shortly after u does so on the common movie. The dataset is analyzed in [ 2], and the influence probability are learned by the topic-aware model. We use the learning result of [ 2] in our experiment, which is a graph containing 29357 nodes and 212614 directed edges. There are 10 probabilities on each edge, and each probabil-ity represents the influence from the source user to the sink on a specific topic. Since most movies belong to at most two topics, we only consider 3 out of 10 topics in our experi-ment, and get two induced graphs whose number of edges are http://www.cs.sfu.ca/  X  sja25/personal/datasets/ http://research.microsoft.com/en-us/people/weic/projects.aspx 23252 and 64934 respectively. For the first graph, probabil-ities of topic 8 are directly used as the ground truth param-eter (termed as Flixster(Topic 8)). For the second graph, we mix the probabilities of Topic 1 and Topic 4 on each edge evenly to obtain the ground-truth probability (termed as as Flixster(Mixed)). After removing isolated nodes, the number of nodes in the two graphs are 14473 and 7118 re-spectively.

In [2 ], the probability for every edge ( u,v ) is learned by rating cascades that reach u and may or may not reach v , and in this cases we view that edge ( u,v ) are sampled. Ac-cording to the data reported in [2 ], on average every edge is sampled 318 times for their learning process. We then use 318 samples on each edge as our initial sample M 0 . NetHEPT. The NetHEPT dataset [11 ] is extensively used in many influence maximization studies. It is an aca-demic collaboration network from the  X  X igh Energy Physics-Theory X  section of arXiv form 1991 to 2003, where nodes represent the authors and each edge in the network rep-resents one paper co-authored by two nodes. It contains 15233 nodes and 58891 undirected edges (including dupli-cated edges). We remove those duplicated edges and obtain a directed graph G = ( V,E ) , | V | = 15233 , | E | = 62774 (di-rected edges). Since the NetHEPT dataset does not contain the data of influence probability on edges, we set the proba-bility on edges according to the weighted cascade model [19 ] as the ground truth parameter, i.e.,  X  e = ( v,u )  X  E , let x be the in-degree of u in the edge-duplicated graph, y the number of edges connecting node v and u , then the true probability is p e = 1  X  (1  X  1 x line of Flixster, we initially sample each edge for 318 times as M 0 .
We test both the uniform sampling algorithm US-RIM and the adaptive sampling algorithm ICS-RIM , as well as an-other adaptive algorithm OES-RIM (Out-Edge Sampling) as the baseline (to be described shortly). Each algorithm is given a graph G and initial observation set M 0 . Note that the method to estimate the parameter space based on sam-pling results in Algorithm 3 and Algorithm 4 are different. In order to make the comparison meaningful, in this sec-tion, for all three algorithms, a common method according to Lemma 7 is used to estimate the parameter space. In all tests, we set the size of the seed set k = 50. To reduce the running time, we use a faster approximation algorithm PMIA (proposed in [10 ]) to replace the well known greedy algorithm purposed in [19 ] in the whole experiment. The accuracy requirement  X  = o (1) is set to be  X  = m  X  0 . 5 m is the number of edges.
 US-RIM . The algorithm is slightly modified from Algo-rithm 3 for a better comparison of performance. The modi-fied algorithm proceeds in an iterative fashion: In each iter-ation, the algorithm makes  X  1 samples on each edge, updates  X  according to Lemma 7 and computes  X  ( X ). The algorithm stops when  X  ( X )  X   X  = 0 . 8.  X  1 is set to 1000, 1000, 250 for NetHEPT, Flixster(Topic 8), Flixster(Mixed), respectively to achieve fine granularity and generate visually difference of  X  ( X ) in our results. ICS-RIM . As stated in Algorithm 4, in each iteration, the algorithm do  X  2 = 5000 times information cascade sampling based on the seed set from the last iteration, and then it updates  X  according to Lemma 7, computes  X  ( X ) and uses LUGreedy algorithm to compute the seed set for the next round. The algorithm stops when  X  ( X )  X   X  = 0 . 8. OES-RIM . This algorithm acts as a baseline, and it pro-ceeds in the similar way to ICS-RIM . Instead of sampling information cascades starting from the current seed set as in ICS-RIM , OES-RIM only sample out-edges from the seed set. More specifically, in each iteration, the algorithm sam-ples 5000 times of all out-edges of the seed set from last iteration, for the three graphs respectively, and then it up-dates  X  according to Lemma 7, computes  X  ( X ) and uses LUGreedy algorithm to compute the seed set for the next round. Note that for OES-RIM ,  X  ( X ) remains small (with the increase of the number of samples) and cannot exceed the threshold  X  even the iteration has been processed for a large number of times, therefore we will terminate it when  X  ( X ) is stable.
Theorem 2 shows that  X  ( X ) 1  X  1 e is a lower bound for the robust ratio g ( X  ,S LU  X  ). We would also like to find some upper bound of g ( X  ,S LU  X  ): If the upper bound is reasonably close to the lower bound or match in trend of changes, it indicates that  X  ( X ) 1  X  1 e is a reasonable indicator of the robust ratio achieved by the LUGreedy output S LU  X  . For any  X   X   X , we define  X   X  ( X  , X  ) =  X   X  ( LU  X  )  X   X   X  ( X  , X  ) is an upper bound for g ( X  ,S LU  X  ):  X   X  ( X  , X  ) =  X   X  ( S
The next question is how to find a  X  = (  X  e ) e  X  E  X   X  to make the upper bound  X   X  ( X  , X  ) as small as possible. In our experiments, we use the following two heuristics and take their minimum.

The first heuristic borrows the intuition from Example 1, which says that the gap ratio  X  ( X ) is close to the robust ratio g ( X  ,S LU  X  ) when (a) there are two disjoint seed sets with similar influence spead, (b) their cascade overlap is small, and (c) the reachable edges from one seed set use lower end parameters values while the reachable edges from the other seed set use upper end parameters. Thus in our heuristic, we use PMIA algorithm to find another seed set S 0 of k nodes when we remove all nodes in S LU  X  . We then do information cascades from both S LU  X  and S 0 for an equal number of times. Finally, for every edge e , if it is sampled more in the information cascade with seed set S LU  X  than with S , we set  X  e = l e , otherwise we set  X  e = r e . The second heuristic is a variant of the first one, where we run a number of information cascades from S LU  X  , and for any edge e that is sampled in at least 10% of cascades, we set  X  e = l e , otherwise we set  X  e = r e .

Other more sophisticated heuristics are possible, but it could be a separate research topic to find tighter upper bound for the robust ratio, and thus we only use the simple combination of the above two in this paper, which is already indicative. We henceforth use  X   X  ( X ) to represent the upper bound found by the minimum of the above two heuristics. Figure 1:  X  ( X ) and  X   X  ( X ) for different widths of con-fidence interval W . 5.2.1  X  ( X ) and  X   X  ( X ) with Predetermined Intervals
In the first experiment we explore the relationship between the width of confidence interval  X  =  X  e  X  E [ l e ,r e ] and  X  ( X ) together with  X   X  ( X ). For a given interval width W , we set l = min { p e  X  W 2 , 0 } ,r e = max { p e + W 2 , 1 }  X  e  X  E , where p e is the ground-truth probability of e . Then we calculate  X  ( X ) and  X   X  ( X ). We vary the width W to see the trend of changes of  X  ( X ) and  X   X  ( X ). Figure 1 reports the result on the three graphs with seed set size k = 50.

First, we observe that as the parameter space  X  becomes wider, the value of both  X  ( X ) and  X   X  ( X ) become smaller, which matches our intuition that larger uncertainty results in worse robustness. Second, there is a sharp decrease of  X  ( X ) between W  X  [0 , 0 . 1] and a much slower decrease af-terwards for all three graphs. The decrease of  X   X  ( X ) is not as sharp as that of  X  ( X ) but the decrease also slows down with larger W after 0 . 2. The overall trend of  X  ( X ) and  X   X  ( X ) suggests that the robust ratio may be sensitive to the uncertainty of the parameter space, and only when the un-certainty of the parameter space reduces to a certain level that we can obtain reasonable guarantee on the robustness of our solution.

As a comparison, we know that the average number of samples on each edge is 318 for the learned probabilities in the Flixster dataset. This corresponds to an average interval width of 0.293 for topic 8 and 0.265 for the mixed topic. At these interval widths,  X  ( X ) values are approximately 0 . 04 and 0 . 08 respectively for the two graphs, and  X   X  ( X ) are ap-proximately 0 . 12 and 0 . 2 respectively. This means that, even considering the upper bound  X   X  ( X ), the robust ratio is pretty low, and thus the learned probabilities reported in [ 2] may result in quite poor performance for robust influence maxi-mization.

Of course, our result of  X  ( X ) and  X   X  ( X ) is only targeted at the robustness of our LUGreedy algorithm, and there could exist better algorithm having higher robustness per-formance at the same uncertainty level. Finding a better RIM algorithm seems to be a difficult task, and we hope that our study could motivate more research in searching for Figure 2:  X  ( X ) and  X   X  ( X ) for different average number of samples per edge on graph NetHEPT. such better RIM algorithms. Besides S LU  X  , we also indepen-dently test the classical greedy seed set S g  X  for  X  = ( p on the lower parameter vector  X   X  (that is  X   X   X  ( S g  X  )  X  ( X )), and the average performance on each data point is 2 . 45%, 1 . 05%, 6 . 11% worse than S LU  X  for Flixster(Mixed), Flixster(Topic 8) and NetHEPT, respectively. Therefore, it shows that S LU  X  outperforms  X  g  X  in the worse-case scenario, and henceforth we only use S LU  X  in the following experiments.
Figures 2, 3 and 4 reports the result of  X  =  X  ( X ) and  X   X  =  X   X  ( X ) for the three tested graphs respectively, when the average number of samples per edge increases. For better presentation, we trim all figures as long as  X  ( US-RIM ) = 0 . 7. (For example, in Flixster(Topic 8), US-RIM requires 77318 samples in average for  X  to reach 0 . 8, while ICS-RIM only needs 33033, and for OES-RIM  X  sticks to 0 . 118.)
For the sampling algorithms, after the i -th iteration, the observation set is updated from M i  X  1 to M i , and the aver-age number of samples per edge in the network is calculated. Markers on each curve in these figures represent the result after one iteration of the corresponding sampling algorithm.
The results on all three graphs are consistent. First, for each pair of  X  ( X ) and  X   X  ( X ), even though there is still some gap, indicating either the lower bound or the upper bound may not be tight yet, the trends on both  X  ( X ) and  X   X  ( X ) are consistent: Both increase with the number of samples, even with similar slopes at each point; and among different algo-rithms, the ranking order and relative change are consistent with both  X  ( X ) and  X   X  ( X ). All these consistency suggests that gap ratio  X  ( X ) could be used as an indicator for the ro-bustness of Algorithm LUGreedy , and it is reasonable to use  X  ( X ) in comparing the performance of different algorithms.
Second, comparing the performance of three algorithms, we see that both US-RIM and ICS-RIM are helpful in im-proving the robust ratio of the selected seed set, and ICS-RIM is better than US-RIM , especially when the sample size increases. The baseline algorithm OES-RIM , however, per-forms significantly poorer than the other two, even though it is also an adaptive algorithm as ICS-RIM . The reason is Figure 3:  X  ( X ) and  X   X  ( X ) for different average number of samples per edge on graph Flixster(Topic 8).
 Figure 4:  X  ( X ) and  X   X  ( X ) for different average number of samples per edge on graph Flixster(Mixed). that, the lower-upper greedy set S LU  X  changes little after a certain number of iterations in OES-RIM , and thus only a small number of edges (out edges of S LU  X  ) are repeatedly sampled. The probabilities on these edges are already esti-mated very accurately while other edge probabilities are far from accurate. It is the inaccurate edges that make  X  ( X ) and the best robust ratio small. In contrast, ICS-RIM uses information cascades to sample not only edges directly con-necting to the seed set but also edges that can be potentially reached. This suggests that it is important for a sampling method to balance the sampling between critical edges and other potentially useful edges in order to achieve better ro-bustness in influence maximization.

Overall, the results suggest that information cascade based sampling method stands out as a competitive choice when we can adaptively sample more edges to achieve better robustness. If adaptive sampling is not possible, predeter-mined uniform sampling may also perform reasonably well.
In this paper, we propose the study of robust influence maximization to address the impact of uncertainty in edge probability estimates that would inevitably occur in practice to the influence maximization task. We propose the LU-Greedy algorithm with a proven solution-dependent bound, and further propose sampling methods, in particular infor-mation cascade based adaptive sample method to effectively reduce the uncertainty and increase the robustness of the LUGreedy algorithm. The experimental results validate the usefulness of the LUGreedy algorithm and the information cascade based sampling method ICS-RIM . Moreover, the re-sults indicate that robustness may be sensitive to the un-certainty of parameter space, and learning algorithms may need more data to achieve accurate learning results for ro-bust influence maximization.

Our work opens up a number of research directions. First, it is unclear what could be the upper bound of the best ro-bust ratio given an actual network and learned parameter space. Answering this question would help us to understand whether robust influence maximization is intrinsically dif-ficult for a particular network or it is just our algorithm that does not perform well. If it is the latter case, then an important direction is to design better robust influence maximization algorithms. Another direction is how to im-prove sampling methods and learning methods to achieve more accurate parameter learning, which seems to be cru-cial for robust influence maximization. In summary, our work indicates a big data challenge on social influence re-search  X  the data on social influence analysis is still not big enough, such that the uncertainty level in model learning may result in poor performance for influence maximization. We hope that our work could encourage further researches to meet this challenge from multiple aspects including data collection, data analysis, and algorithm design.
 The research of Wei Chen is partially supported by the National Natural Science Foundation of China (Grant No. 61433014). [1] A. Badanidiyuru, R. Kleinberg, and A. Slivkins. [2] N. Barbieri, F. Bonchi, and G. Manco. Topic-aware [3] A. Ben-Tal and A. Nemirovski. Robust [4] C. Borgs, M. Brautbar, J. T. Chayes, and B. Lucier. [5] S. Bubeck, R. Munos, and G. Stoltz. Pure exploration [6] C. Budak, D. Agrawal, and A. El Abbadi. Limiting [7] S. Chen, T. Lin, I. King, M. R. Lyu, and W. Chen. [8] W. Chen, L. V. Lakshmanan, and C. Castillo.
 [9] W. Chen, T. Lin, Z. Tan, M. Zhao, and X. Zhou. [10] W. Chen, C. Wang, and Y. Wang. Scalable influence [11] W. Chen, Y. Wang, and S. Yang. Efficient influence [12] W. Chen, Y. Wang, and Y. Yuan. Combinatorial [13] P. Domingos and M. Richardson. Mining the network [14] U. Feige. A threshold of ln n for approximating set [15] A. Goyal, F. Bonchi, and L. V. Lakshmanan. Learning [16] A. Goyal, W. Lu, and L. V. Lakshmanan. Celf++: [17] X. He and D. Kempe. Robust influence maximization. [18] X. He and D. Kempe. Stability of Influence [19] D. Kempe, J. Kleinberg, and  X  E. Tardos. Maximizing [20] A. Krause, H. B. McMahon, C. Guestrin, and [21] S. Lei, S. Maniu, L. Mo, R. Cheng, and P. Senellart. [22] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [23] W. Lu, W. Chen, and L. V. Lakshmanan. From [24] P. Netrapalli and S. Sanghavi. Learning the graph of [25] M. G. Rodriguez, D. Balduzzi, and B. Sch  X  olkopf. [26] K. Saito, R. Nakano, and M. Kimura. Prediction of [27] J. Tang, J. Sun, C. Wang, and Z. Yang. Social [28] Y. Tang, X. Xiao, and Y. Shi. Influence maximization:
 Uncertainty about models and data is ubiquitous in the com-putational social sciences, and it creates a need for robust so-cial network algorithms, which can simultaneously provide guarantees across a spectrum of models and parameter set-tings. We begin an investigation into this broad domain by studying robust algorithms for the Influence Maximization problem, in which the goal is to identify a set of k nodes in a social network whose joint influence on the network is maximized.

We define a Robust Influence Maximization framework wherein an algorithm is presented with a set of influence functions, typically derived from different influence models or different parameter settings for the same model. The different parameter settings could be derived from observed cascades on different topics, under different conditions, or at different times. The algorithm X  X  goal is to identify a set of k nodes who are simultaneously influential for all influ-ence functions, compared to the (function-specific) optimum solutions.

We show strong approximation hardness results for this problem unless the algorithm gets to select at least a loga-rithmic factor more seeds than the optimum solution. How-ever, when enough extra seeds may be selected, we show that techniques of Krause et al. can be used to approximate the optimum robust influence to within a factor of 1  X  1 /e . We evaluate this bicriteria approximation algorithm against natural heuristics on several real-world data sets. Our exper-iments indicate that the worst-case hardness does not nec-essarily translate into bad performance on real-world data sets; all algorithms perform fairly well.
 [ Human-centered computing ]: Social networks
Computational social science is the study of social and economic phenomena based on electronic data, algorithmic approaches and computational models. It has emerged as an important application of data mining and learning, while also invigorating research in the social sciences. Computa-tional social science is frequently envisioned as a foundation for a discipline one could term  X  X omputational social engi-neering, X  wherein algorithmic approaches are used to change or mitigate individuals X  behavior.

Among the many concrete problems that have been stud-ied in this context, perhaps the most popular is Influence Maximization. It is based on the observation that behav-ioral change in individuals is frequently effected by influence from their social contacts. Thus, by identifying a small set of  X  X eed nodes, X  one may influence a large fraction of the social network. The desired behavior may be of social value, such as refraining from smoking or drug use, using superior crops, or following hygienic practices. Alternatively, the behavior may provide financial value, as in the case of viral mar-keting, where a company wants to rely on word-of-mouth recommendations to increase the sale of its products.
Contrary to the  X  X ard X  sciences, the study of social net-works  X  whether using traditional or computational ap-proaches  X  suffers from massive amounts of noise inherent in the data and models. The reasons range from the funda-mental to the practical:
Since none of these issues are likely to be resolved anytime soon, both the models for social network processes and their inferred parameters must be treated with caution. This is true both when one wants to draw scientific insight for its own sake, and when one wants to use the inferred mod-els to make computational social engineering decisions. In-deed, the correctness guarantees for algorithms are predi-cated on the assumption of correctness of the model and the inferred parameters. When this assumption fails  X  which is inevitable  X  the utility of the algorithms X  output is com-promised. Thus, to make good on the claims of real-world relevance of computational social science, it is imperative that the research community focus on robustness as a pri-mary design goal.
We take an early step in this bigger agenda, studying ro-bustness in the context of the well-known Influence Max-imization problem. (Detailed definitions are given in Sec-tion 3.) In Influence Maximization, the algorithm selects a set S 0 of seed nodes , of pre-specified size k . The seed nodes are initially exposed to a product or idea; we say that they are active . Based on a probabilistic model of influence propagation 1 , they cause some of their neighbors to become active, who then cause some of their neighbors to become active, etc.; this process leads to a (random) final set of ac-tive nodes. The goal is to maximize the size of this set; we denote this quantity by  X  ( S 0 ).

The concerns discussed above combine to lead to signifi-cant uncertainty about the function  X  : different models give rise to very different functional forms of  X  , and missing ob-servations or approximations in inference lead to uncertainty about the models X  parameters.

To model this uncertainty, we assume that the algorithm is presented with a set  X  of influence functions, and assured that one of these functions actually describes the influence process, but not told which one. The set  X  could be finite or infinite. A finite  X  could result from a finite set of different information diffusion models that are being considered, or from of a finite number of different contexts under which the individuals were observed (e.g., word-of-mouth cascades for different topics or products), or from a finite number of different inference algorithms or algorithm settings being used to infer the model parameters from observations. An infinite (even continuous)  X  arises if each model parameter is only known to lie within some given interval; this model
We use the terms  X  X nfluence propagation X  and  X  X iffusion X  interchangeably. of adversarial noise, which we call the Perturbation Interval model, was recently proposed in [19].

Since the algorithm does not know  X   X  , in the Robust In-fluence Maximization problem, it must  X  X imultaneously op-timize X  for all objective functions in  X , in the sense of max-is an optimal solution knowing which function  X   X  is to be optimized. In other words, the selected set should simulta-neously get as close as possible to the optimal solutions for all possible objective functions.
Our work is guided by the following overarching questions: 1. How well can the objective  X  be optimized in principle? 2. How well do simple heuristics perform in theory? 3. How well do simple heuristics perform in practice? 4. How do robustly and non-robustly optimized solutions
We address these questions as follows. First, we show (in Section 4) that unless the algorithm gets to exceed the number of seeds k by at least a factor ln |  X  | , approximating the objective  X  to within a factor O ( n 1  X  ) is NP-hard for all &gt; 0.

However, when the algorithm does get to exceed the seed set target k by a factor of ln |  X  | (times a constant), much better bicriteria approximation guarantees can be obtained. Specifically, we show that a modification of an algorithm of Krause et al. [23] uses O ( k ln |  X  | ) seeds and finds a seed set whose influence is within a factor (1  X  1 /e ) of optimal.
We also investigate two straightforward heuristics: 1. Run a greedy algorithm to optimize  X  directly, picking 2. For each objective function  X   X   X , find a set S  X  (ap-
We first exhibit instances on which both of the heuristics perform very poorly. Next (in Section 5), we focus on more realistic instances , exemplifying the types of scenarios under which robust optimization becomes necessary. In the first set of experiments, we infer influence networks on a fixed node set from Twitter cascades on different topics . Individ-uals X  influence can vary significantly based on the topic, and for a previously unseen topic, it is not clear which inferred influence network to use. In additional sets of experiments, we derive data sets from the same MemeTracker data [25], but use different time slices , different inference algorithms and parametrizations , and different samples from confidence intervals.

The main outcome of the experiments is that while the al-gorithm with robustness as a design goal typically (though not even always) outperforms the heuristics, the margin is often quite small. Hence, heuristics may be viable in prac-tice, when the influence functions are reasonably similar. A visual inspection of the nodes chosen by different algo-rithms reveals how the robust algorithm  X  X edges its bets X  across models, while the non-robust heuristic tends to clus-ter selected nodes in one part of the network.
A bicriteria algorithm gets to pick more nodes than the optimal solution, but is only judged against the optimum solution with the original bound k on the number of nodes.
Given its prominent role in our model, the decision to treat the choice of  X   X  as adversarial rather than stochastic deserves some discussion.

First, adversarial guarantees are stronger than stochastic guarantees, and will lead to more robust solutions in prac-tice. Perhaps more importantly, inferring a Bayesian prior over influence functions in  X  will run into exactly the type of problem we are trying to address in the first place: data are sparse and noisy, and if we infer an incorrect prior, it may lead to very suboptimal results. Doing so would next require us to establish robustness over the values of the hy-perparameters of the Bayesian prior over functions.
Specifically for the Perturbation Interval model, one may be tempted to treat the parameters as drawn according to some distribution over their possible range. This approach was essentially taken in [2, 17]: Adiga et al. [2] assume that for each edge e independently, its presence/absence was mis-observed with probability , whereas Goyal et al. [17] assume that for each edge, the actual parameter is perturbed with independent noise drawn uniformly from a known interval. In both cases, under the Independent Cascade model (for example), the edge activation probability can be replaced with the expected edge activation probability under the ran-dom noise model, which will provably lead to the exact same influence function  X  . Thus, independent noise for edge pa-rameters, drawn from a known distribution, does not aug-ment the model in the sense of capturing robustness. In particular, it does not capture uncertainty in a meaningful way.

To model the type of issues one would expect to arise in real-world settings, at the very least, noise must be corre-lated between edges. For instance, certain subpopulations may be inherently harder to observe or have sparser data to learn from. However, correlated random noise would re-sult in a more complex description of the noise model, and thus make it harder to actually learn and verify the noise model. In particular, as discussed above, this would apply given that the noise model itself must be learned from noisy data.
Kempe et al. [21] formally defined the problem of finding a set of influential individuals as a discrete optimization prob-lem, proposing a greedy algorithm with a 1  X  1 /e approxi-mation guarantee for the Independent Cascade and Linear Threshold models. A long sequence of subsequent work fo-cused on more efficient algorithms for Influence Maximiza-tion (both with and without approximation guarantees) and on broadening the class of models for which guarantees can be obtained [3, 7, 9, 21, 22, 28, 34, 35]. See the recent book by Chen et al. [5] and the survey in [21] for more detailed overviews.

As a precursor to maximizing influence, one needs to in-fer the influence function  X  from observed data. The most common approach is to estimate the parameters of a partic-ular diffusion model [1, 11, 14, 15, 30, 32, 33]. Theoretical bounds on the required sample complexity for many dif-fusion models have been established, including [1, 30, 32] for the Discrete-Time Independent Cascade (DIC) model, [11] for the Continuous-Time Independent Cascade (CIC) model, and [30] for the Linear Threshold model. However, it remains difficult to decide which diffusion models fit the observation best. Moreover, the diffusion models only serve as a rough approximation to the real-world diffusion pro-cess. In order to sidestep the issue of diffusion models, Du et al. [12] recently proposed to directly learn the influence function  X  from the observations, without assuming any par-ticular diffusion model. They only assume that the influence function is a weighted average of coverage functions. While their approach provides polynomial sample complexity, they require a strong technical condition on finding an accurate approximation to the reachability distribution. Hence, their work remains orthogonal to the issue of Robust Influence Maximization.
 Several recent papers take first steps toward Influence Maximization under uncertainty. Goyal, Bonchi and Laksh-manan [17] and Adiga et al. [2] study random (rather than adversarial) noise models, in which either the edge activation probabilities p u,v are perturbed with random noise [17], or the presence/absence of edges is flipped with a known prob-ability [2].

Another approach to dealing with uncertainty is to carry out multiple influence campaigns, and to use the observa-tions to obtain better estimates of the model parameters. Chen et al. [8] model the problem as a combinatorial multi-armed bandit problem and use the UCB1 algorithm with regret bounds. Lei et al. [24] instead incorporate beta distri-bution priors over the activation probabilities into the DIC model. They propose several strategies to update the pos-terior distributions and give heuristics for seed selection in each trial so as to balance exploration and exploitation. Our approach is complementary: even in an exploration-based setting, there will always be residual uncertainty, in partic-ular when exploration budgets are limited.

The adversarial Perturbation Interval model was recently proposed in work of the authors [19]. The focus in that work was not on robust optimization, but on algorithms for detecting whether an instance was likely to suffer from high instability of the optimal solution. Optimization for multiple scenarios was also recently used in work by Chen et al. on tracking influential nodes as the structure of the graph evolves over time [10]. However, the model explicitly allowed updating the seed set over time, while our goal is simultaneous optimization.
 Simultaneously to the present work, Chen et al. [6] and Lowalekar et al. [27] have been studying the Robust Influ-ence Maximization problem under the Perturbation Interval model [19]. Their exact formulations are somewhat differ-ent. The main result of Chen et al. [6] is an analysis of the heuristic of choosing the best solution among three candi-dates: make each edge X  X  parameter as small as possible, as large as possible, or equal to the middle of its interval. They prove solution-dependent approximation guarantees for this heuristic.

The objective of Lowalekar et al. [27] is to minimize the maximum regret instead of maximizing the minimum ra-tio. They propose a heuristic based on constraint generation ideas to solve the robust influence maximization problem. The heuristic does not come with approximation guaran-tees; instead, [27] proposes a solution-dependent measure of robustness of a given seed set. As part of their work, [27] prove a result similar to our Lemma 1, showing that the worst-case instances all have the largest or smallest possible values for all parameters.
For concreteness, we focus on two diffusion models: the discrete-time Independent Cascade model (DIC) [21] and the continuous-time Independent Cascade model (CIC) [15]. Our framework applies to most other diffusion models; in particular, most of the concrete results carry over to the discrete and continuous Linear Threshold models [21, 33].
Under the DIC model, the diffusion process unfolds in dis-crete time steps as follows: when a node u becomes active in step t , it attempts to activate all currently inactive neigh-bors in step t + 1. For each neighbor v , it succeeds with a known probability p u,v ; the p u,v are the parameters of the model. If node u succeeds, v becomes active. Once u has made all its attempts, it does not get to make further ac-tivation attempts at later times; of course, the node v may well be activated at time t + 1 or later by some node other than u .

The CIC model describes a continuous-time process. As-sociated with each edge ( u,v ) is a delay distribution with pa-rameter  X  u,v . When a node u becomes newly active at time t , for every neighbor v that is still inactive, a delay time  X  u,v is drawn from the delay distribution.  X  u,v is the dura-tion it takes u to activate v , which could be infinite (if u does not succeed in activating v ). Commonly assumed delay dis-tributions include the Exponential distribution or Rayleigh distribution. If multiple nodes u 1 ,...,u ` attempt to activate v , then v is activated at the earliest time min i t u i +  X  Nodes are considered activated by the process if they are activated within a specified observation window [0 ,T ].
A specific instance is described by the class of its influence model (such as DIC, CIC, or others not discussed here in de-tail) and the setting of the model X  X  parameters; in the DIC and CIC models above, the parameters would be the influ-ence probabilities p u,v and the parameters  X  u,v of the edge delay distributions, respectively. Together, they completely specify the dynamic process; and thus a mapping  X  from ini-tially active sets S 0 to the expected number 3  X  ( S 0 ) of nodes active at the end of the process. We can now formalize the Influence Maximization problem as follows:
Definition 1 (Influence Maximization). Maximize the objective  X  ( S 0 ) subject to the constraint | S 0 | X  k .
For most of the diffusion models studied in the literature, including the DIC [21] and CIC [13] models, it has been shown that  X  ( S 0 ) is a monotone and submodular 4 function of S 0 . These properties imply that a greedy approximation algorithm guarantees a 1  X  1 /e approximation [31].
The main motivation for our work is that often,  X  is not precisely known to the algorithm trying to maximize influ-ence. There may be a (possibly infinite) number of candi-date functions  X  , resulting from different diffusion models or
The model and virtually all results in the literature extend straightforwardly when the individual nodes are assigned non-negative importance scores.
Recall that a set function f is monotone iff f ( S )  X  f ( T ) whenever S  X  T , and is submodular iff f ( S  X  X  x } )  X  f ( S )  X  f ( T  X  X  x } )  X  f ( T ) whenever S  X  T . parameter settings. We denote the set of all candidate in-fluence functions 5 by  X . We now formally define the Robust Influence Maximization problem.

Definition 2 (Robust Influence Maximization). Given a set  X  of influence functions, maximize the objective subject to a cardinality constraint | S | X  k . Here S  X   X  set with | S  X   X  | X  k maximizing  X  ( S  X   X  ) .

A solution to the Robust Influence Maximization prob-lem achieves a large fraction of the maximum possible influ-ence (compared to the optimal seed set) under all diffusion settings simultaneously. Alternatively, the solution can be interpreted as solving the Influence Maximization problem when the function  X  is chosen from  X  by an adversary.
While Definition 2 per se does not require the  X   X   X  to be submodular and monotone, these properties are necessary to obtain positive results. Hence, we will assume here that all  X   X   X  are monotone and submodular, as they are for standard diffusion models. Notice that even then,  X  is the minimum of submodular functions, and as such not neces-sarily submodular itself [23].

A particularly natural and important special case of Defi-nition 2 is the Perturbation Interval model recently proposed in [19]. Here, the influence model is known (for concrete-ness, DIC), but there is uncertainty about its parameters. For each edge e , we have an interval I e = [ ` e ,r e ], and the algorithm only knows that the parameter (say, p e ) lies in I ; the exact value is chosen by an adversary. Notice that  X  is (uncountably) infinite under this model. While this may seem worrisome, the following lemma shows that we only need to consider finitely (though exponentially) many functions:
Lemma 1. Under the Perturbation Interval model for DIC 6 , the worst case for the ratio in  X  for any seed set S achieved by making each p e equal to ` e or r e .

Proof. Fix one edge  X  e , and a seed set S 0 . Fix the acti-vation probabilities on all edges except  X  e , and consider the function f S 0 ( x ), the expected number of nodes activated by S 0 when the activation probabilities of all edges e 6 =  X  e are as fixed, and the activation probability of  X  e is x .
By explicitly writing the expectation as a distribution over live edge graphs (see [21]), one can observe that f S 0 ( x ) is a linear function of x . Hence, the optimum influence (over all S ) g ( x ), being a maximum of linear functions, is convex. one can show by considering its level sets, and noticing that { x | f S 0 ( x ) /g ( x )  X   X  } = { x | g ( x )  X  1 / X   X  f latter is a level set of a convex function, and thus convex.
Finally, because f S 0 ( x ) /g ( x ) is quasi-concave, it attains its minimum at the smallest or largest value of x . By re-peating this argument for all edges  X  e , we obtain a worst-case setting in which all parameter values are equal to the left or right endpoints of the respective intervals I e .
For computation purposes, we assume that the functions are represented compactly, for instance, by the name of the diffusion model and all of its parameters. The result carries over with a nearly identical proof to the Linear Threshold model. We currently do not know if it also extends to the CIC model. Even when  X  contains just a single function  X  , Robust Influence Maximization is exactly the traditional Influence Maximization problem, and is thus NP-hard. This issue also appears in a more subtle way: evaluating  X  ( S a given S 0 ) involves taking the minimum of  X  ( S 0 )  X  ( S  X   X   X . It is not clear how to calculate the ratio  X  ( S 0 for one of the  X  , since the scaling constant  X  ( S  X   X  ) (which is independent of the chosen S 0 ) is exactly the solution to the original Influence Maximization problem, and thus NP-hard to compute.

This problem, however, is fairly easy to overcome: instead of using the true optimum solutions S  X   X  for the scaling con-stants, we can compute (1  X  1 /e )-approximations S g  X  using the greedy algorithm, because the  X  are monotone and sub-modular [31]. Then, because (1  X  1 /e )  X   X  ( S  X   X  )  X   X  ( S  X  ( S  X   X  ) for all  X   X   X , we obtain that the  X  X reedy objective erty for all sets S : (1  X  1 /e )  X   X  g ( S )  X   X  ( S )  X   X  optimizing  X  g ( S ) in place of  X  ( S ) comes at a cost of only a factor (1  X  1 /e ) in the approximation guarantee. We will therefore focus on solving the problem of (approximately) optimizing  X  g ( S ).

Because each  X  is monotone and submodular, and the  X  ( S g  X  ), just like the  X  ( S  X   X  ), are just scaling constants,  X  is a minimum of monotone submodular functions. However, we show (in Theorem 2, proved in the full version [20]) that even in the context of Influence Maximization, this mini-mum is impossible to approximate to within any polynomial factor. This holds even in a bicriteria sense, i.e., the algo-rithm X  X  solution is allowed to pick (1  X   X  ) ln |  X  | X  k nodes, but is compared only to solutions using k nodes. The result also extends to the seemingly more restricted Perturbation Interval model, giving an almost equally strong bicriteria approximation hardness result there.

Theorem 2. Let  X , &gt; 0 be any constants, and assume that P 6 = NP. There are no polynomial-time algorithms for the following problems: 1. Given n nodes and a set  X  of influence functions on 2. Given a graph G on n nodes and intervals I e for edge
The hardness results naturally apply to any diffusion model that subsumes the DIC or CIC models. However, an exten-sion to the DLT model is not immediate: the construction relies crucially on having many edges of probability 1 into a single node, which is not allowed under the DLT model.
Theorem 2 implies that to obtain any non-trivial approx-imation guarantee, one needs to allow the algorithm to ex-ceed the seed set size by at least a factor of ln |  X  | . In this Algorithm 1 Saturate Greedy ( X , k , precision  X  ) 1: Initialize c min  X  0, c max  X  1. 2: while ( c max  X  c min )  X   X  do 3: c  X  ( c max + c min ) / 2. 5: S  X  Greedy Mintss ( H ( c ) ,k,c  X |  X  | ,c  X   X / 3). 6: if | S | &gt;  X   X  k then 7: c max  X  c . 8: else 9: c min  X  c  X  (1  X   X / 3), S  X   X  S . 10: end if 11: end while 12: Return S  X  . section, we therefore focus on such bicriteria approxima-tion results, by slightly modifying an algorithm of Krause et al. [23].

The slight difference lies in how the submodular coverage subproblem is solved. Both [23] and the Greedy Mintss algorithm [18] greedily add elements. However, the Greedy Mintss algorithm adds elements until the desired submodu-lar objective is attained up to an additive  X  term, while [23] requires exact coverage. Moreover, directly considering real-valued submodular functions instead of going through frac-tional values leads to a more direct analysis of the Greedy Mintss algorithm [18].

The high-level idea of the algorithm is as follows. Fix a real value c , and define h ( c )  X  ( S ) := min( c,  X  ( S ) P all  X   X   X . But because by definition, h ( c )  X  ( S )  X  c for all  X  , the latter is equivalent to H ( c ) ( S )  X |  X  | X  c . (If any term in the sum is less than c , no other term can ever compensate for it, because they are capped at c .)
Because H ( c ) ( S ) is a non-negative linear combination of the monotone submodular functions h ( c )  X  , it is itself a mono-tone and submodular function. This enables the use of a greedy ln |  X  | -approximation algorithm to find an (approxi-mately) smallest set S with H ( c ) ( S )  X  c |  X  | . If S has size at most k ln |  X  | , this constitutes a satisfactory solution, and we move on to larger values of c . If S has size more than k ln |  X  | , then the greedy algorithm X  X  approximation guaran-tee ensures that there is no satisfactory set S of size at most k . Hence, we move on to smaller values of c . For efficiency, the search for the right value of c is done with binary search and a specified precision parameter.

A slight subtlety in the greedy algorithm is that H ( c ) take on fractional values. Thus, instead of trying to meet the bound c |  X  | precisely, we aim for a value of c |  X  | X  . Then, the analysis of the Greedy Mintss algorithm of Goyal et al. [18] (of which our algorithm is an unweighted special case) applies. The resulting algorithm Saturate Greedy is given as Algorithm 1. The simple greedy subroutine  X  a special case of the Greedy Mintss algorithm  X  is given as Algorithm 2.

By combining the discussion at the beginning of this sec-tion (about optimizing  X  vs.  X  g ) with the analysis of Krause et al. [23] and Goyal et al. [18], we obtain the following ap-proximation guarantee. The (straightforward) missing de-tails are given in the full version [20]. Algorithm 2 Greedy Mintss ( f , k , threshold  X  , error  X  ) 1: Initialize S  X  X  X  . 2: while f ( S ) &lt;  X   X   X  do 3: u  X  argmax v/  X  S f ( S  X  X  v } ). 4: S  X  S  X  X  u } . 5: end while 6: Return S .

Theorem 3. Let  X  = 1+ln |  X  | +ln 3  X  . Saturate Greedy finds a seed set  X  S of size |  X  S | X   X k with where S  X   X  argmax S : | S | X  k  X  ( S ) is an optimal robust seed set of size k .

Theorem 3 holds very broadly, so long as all influence functions are monotone and submodular. This includes the DIC, DLT, and CIC models, and allows mixing influence functions from different model classes. Notice the contrast between Theorems 3 and 2. By allowing the seed set size to be exceeded just a little more (a factor ln |  X  | + O (1) instead of 0 . 999 ln |  X  | ), we go from  X ( n 1  X  ) approximation hardness to a (1  X  1 /e )-approximation algorithm.
In addition to the Saturate Greedy algorithm, our ex-periments use two natural baselines. The first is a sim-ple greedy algorithm Single Greedy which adds  X k ele-ments to S one by one, always choosing the one maximizing  X  ( S  X  X  v } ). While this heuristic has provable guarantees when the objective function is submodular, this is not the case for the minimum of submodular functions.

The second heuristic is to run a greedy algorithm for each objective function  X   X   X  separately, and choose the best of the resulting solutions. Those solutions are exactly the sets S g  X  defined earlier in this section. Thus, the algorithm consists of choosing argmax  X   X   X   X  g ( S g  X  ). We call the resulting algorithm All Greedy .

In the worst case, both Single Greedy and All Greedy can perform arbitrarily badly, as seen by the following class of examples with a given parameter k . The example consists of k instances of the DIC model for the following graph with 3 k + m nodes (where m k ). The graph comprises a di-rected complete bipartite graph K k,m with k nodes x 1 ,...,x on one side and m nodes y 1 ,...,y m on the other side, as well as k separate edges ( u 1 ,v 1 ) ,..., ( u k ,v k ). The edges ( u have activation probability 1 in all instances. In the bipar-tite graph, in the i th scenario, only the edges leaving node x have probability 1, while all others have 0 activation proba-bility.

The optimal solution for Robust Influence Maximization is to select all nodes x i , since one of them will succeed in activating the m nodes y j . The resulting objective value will be close to 1. However, All Greedy only picks one node x i and the remaining k  X  1 nodes as u j . Single Greedy instead picks all of the u j . Thus, both All Greedy Single Greedy will have robust influence close to 0 as m grows large. Empirical experiments confirm this analysis. For example, for k = 2 and m = 100, Saturate Greedy achieves  X  = 0 . 985, while Single Greedy and All Greedy only achieve 0 . 038 and 0 . 029, respectively.
 The most time-consuming step in all of the algorithms is the estimation of influence coverage, given a seed set S . Na  X   X ve estimation by Monte Carlo simulation could lead to a very inefficient implementation. The problem is even more pro-nounced compared to traditional Influence Maximization as we must estimate the influence in multiple diffusion settings. Instead, we use the ConTinEst algorithm of Du et al. [13] for fast influence estimation under the CIC model. For the DIC model, we generalize the approach of Du et al. To ac-celerate the Greedy Mintss algorithm, we also apply the CELF optimization [26] in all cases. Analytically, one can derive linear running time (in both n and |  X  | ) for all three algorithms, thanks to the fast influence estimation. This is borne out by detailed experiments 7 , which also show that Saturate Greedy is slower than the heuristics by about a factor of ten.
We empirically evaluate the Saturate Greedy algorithm and the Single Greedy and All Greedy heuristics. Our goal is twofold: (1) Evaluate how well Saturate Greedy and the heuristics perform on realistic instances. (2) Quali-tatively understand the difference between robustly and non-robustly optimized solutions.
 Our experiments are all performed on real-world data sets. The data sets span the range of different causes for un-certainty, namely: (1) influences are learned from cascades for different topics; (2) influences are learned with different modeling assumptions; (3) influences are only inferred to lie within intervals I e (the Perturbation Interval model).
We first focus on the case in which the diffusion model is kept constant: we use the DIC model, with parameters spec-ified below. Different objective functions are obtained from observing cascades (1) on different topics. We use Twitter retweet networks for different topics. (2) at different times. We use MemeTracker diffusion network snapshots at differ-ent times.

The Twitter networks are extracted from a complete col-lection of tweets between Jan. 2010 and Feb. 2010. We treat each hashtag as a separate cascade, and extract the top 100/250 users with the most tweets containing these hash-tags into two datasets (Twitter100 and Twitter250). The hashtags are manually grouped into five categories of about 70 X 80 hashtags each, corresponding to major events/topics during the data collection period. The five groups are: Haiti earthquake (Haiti), Iran election (Iran), Technology, US pol-itics, and the Copenhagen climate change summit (Climate). Examples of hashtags in each group are shown in Table 1. Whenever user B retweets a post of user A with a hashtag belonging to category i , we insert an edge with activation probability 1 from A to B in graph i . The union of all these edges specifies the i th influence function.

Our decision to treat each hashtag as a separate cascade is supposed to capture that most hashtags  X  X pread X  across Twitter when one user sees another use it, and starts posting with it himself. The grouping of similar hashtags captures that a user who may influence another to use the hashtag, say, #teaparty, would likely also influence the other user omitted here due to space constraints (c) Meme2000 ( k = 50) to a similar extent to use, say, #liberty. The pruning of the data sets was necessary because most users had showed very limited activity. Naturally, if our goal were to evaluate the algorithmic efficiency rather than the performance with respect to the objective function, we would focus on larger networks, even if the networks were less easily visualized. Category Hashtags Iran #iranelection, #iran, #16azar, #tehran Haiti #haiti, #haitiquake, #supphaiti, #cchaiti Technology #iphone, #mac, #microsoft, #tech US politics #obama, #conservative, #teaparty, #liberty Climate #copenhagen, #cop15, #climatechange Table 1: Examples of hashtags in each category
The MemeTracker dataset [25] contains memes extracted from the Blogsphere and main-stream media sites between Aug. 2009 and Feb. 2010. In our experiments, we extract the 2000/5000 sites with the most posting activity across the time period we study (Meme2000 and Meme5000). We extract six separate diffusion networks, one for each month. The network for month i contains all the directed links that were posted in month i (in reverse order, i.e., if B links to A , then we add a link from A to B ), with activation probability 1. It thus defines the i th influence function.

The parameters of the DIC model used for this set of experiments are summarized in Table 2.

Recalling that in the worst case, a relaxation in the num-ber of seeds is required to obtain robust seed sets, we al-low all algorithms to select more seeds than the solution they are compared against. Specifically, we report results in which the algorithms may select k , 1 . 5  X  k and 2  X  k seeds, respectively. The reported results are averaged over three independent runs of each of the algorithms.
 The aggregate performance of the different algorithms on the four data sets is shown in Figure 1.

The first main insight is that (in the instances we study) getting to over-select seeds by 50%, all three algorithms achieve a robust influence of at least 1.0. In other words, 50% more seeds let the algorithms perform as though they knew exactly which of the (adversarially chosen) diffusion settings was the true one. This suggests that the networks in our data sets share a lot of similarities that make influ-ential nodes in one network also (mostly) influential in the other networks. This interpretation is consistent with the observation that the baseline heuristics perform similarly to (and in one case better than) the Saturate Greedy algo-rithm. Notice, however, that when selecting just k seeds, Saturate Greedy does perform best (though only by a small margin) among the three algorithms. This suggests that keeping robustness in mind may be more crucial when the algorithm does not get to compensate with a larger num-ber of seeds.
 To further illustrate the tradeoffs between robust and non-robust optimization, we visualize the seeds selected by Sat-urate Greedy (robust seeds) compared to seeds selected non-robustly based on only one diffusion setting. For legibil-ity, we focus only on the Twitter250 data set, and only plot 4 out of the 5 networks. (The fifth network is very sparse, and thus not particularly interesting.)
Figure 2 compares the seeds selected by Saturate Greedy with those (approximately) maximizing the influence for the Iran network. Notice that Saturate Greedy focuses mostly (though not exclusively) on the densely connected core of the network (at the center), while the Iran-specific optimization also exploits the dense regions on the left and at the bottom. These regions are much less densely connected in the US politics and Climate networks, while the core remains fairly densely connected, leading the Saturate Greedy solution to be somewhat more robust.

Similarly, Figure 3 compares the Saturate Greedy seeds (which are the same as in Figure 2) with seeds for the Cli-mate network. The trend here is exactly the opposite. The seeds selected based only on the Climate network are ex-clusively in the core, because the other parts of the Climate network are barely connected. On the other hand, the robust solution picks a few seeds from the clusters at the bottom, left, and right, which are present in other networks. These seeds lead to extra influence in those networks, and thus more robustness.
In choosing a diffusion model, there is little convincing empirical work guiding the choice of a model class (such as CIC, DIC, or threshold models) or of distributional assump-tions for model parameters (such as edge delay). A possible solution is to optimize robustly with respect to these differ-ent possible choices.

In this section, we evaluate such an approach. Specifically, we perform two experiments: (1) learning the CIC influence network under different parametric assumptions about the delay distribution, and (2) learning the influence network under different models of influence (CIC, DIC, DLT). We again use the MemeTracker dataset, restricting ourselves to the data from August 2008 and the 500 most active users. We use the MultiTree algorithm of Gomez-Rodriguez et al. [16] to infer the diffusion network from the observed cas-cades. This algorithm requires a parametric assumption for the edge delay distribution. We infer ten different networks G i corresponding to the Exponential distribution with pa-rameters 0.05, 0.1, 0.2, 0.5, 1.0, and to the Rayleigh distri-bution with parameters 0.5, 1, 2, 3, 4. The length of the observation window is set to 1.0.

We then use the three algorithms to perform robust in-fluence maximization for k = 10 seeds, again allowing the algorithms to exceed the target number of vertices. The influence model for each graph is the CIC model with the same parameters that were used to infer the graphs. The performance of the algorithms is shown in Figure 4(a). All methods achieve satisfactory results in the experiment; this is again due to high similarity between the different diffusion settings inferred with different parameters.
For the second experiment, we investigate the robustness across different classes of diffusion models. We construct three instances of the DIC, DLT and DIC model from the ground truth diffusion network between the 500 active users. For the DIC model, we set the activation probability uni-formly to 0 . 1. For the DLT model, we follow [21] and set the edge weights to 1 /d v where d v is the in-degree of node v . For the CIC model, we use an exponential distribution with parameter 0 . 1 and an observation window of length 1 . 0. We perform robust influence maximization for k = 10 seeds and again allow the algorithms to exceed the target number of seeds.

The results are shown in Figure 4(b). Similarly to the case of different estimated parameters, all methods achieve satis-factory results in the experiment due to the high similarity between the diffusion models. Our results raise the intrigu-ing question of which types of networks would be prone to significant differences in algorithmic performance based on which model is used for network estimation.
To investigate the performance when model parameters can only be placed inside  X  X onfidence intervals X  (i.e., the Per-turbation Interval model), we use the ConNIe algorithm [29] to infer the (fractional) parameters of a DIC model from the same 500-node MemeTracker data set used in the previous section. Following the approach of [19], we then assign  X  X on-fidence intervals X  I e = [(1  X  q ) p e , (1 + q ) p e ], where the p the inferred parameters, and q  X  X  10% , 20% , 30% ,..., 100% } .
While Lemma 1 guarantees that the worst-case instances have activation probabilities (1  X  q ) p e or (1 + q ) p e leaves 2 | E | candidate functions, too many to include. We generate an instance for our experiments by sampling 10 of these functions uniformly, i.e., by independently making each edge X  X  activation probability either (1  X  q ) p e or (1+ q ) p This collection is augmented by two more instances: one where all edge probabilities are (1  X  q ) p e , and one where all probabilities are (1 + q ) p e . Notice that with the inclusion of these two instances, the All Greedy heuristic general-izes the LUGreedy algorithm by Chen et al. [6], but might provide strictly better solutions on the selected instances be-cause it explicitly considers those additional instances. The algorithms get to select 20 seed nodes; note that in these experiments, we are not considering a bicriteria approxima-tion. (a) Different Distributions. Figure 4: Performance of the algorithms (a) un-der different delay distributions following the CIC model, and (b) under different classes of diffusion models. The x -axis shows the number of seeds se-lected, and k = 10 . Figure 5: Performance of the algorithms under networks sampled from the Perturbation Interval model. The x axis shows the (relative) size of the perturbation interval I e , and k = 20 .

The results are shown in Figure 5. Contrary to the pre-vious results, when there is a lot of uncertainty about the edge parameters (relative interval size 100%), the Saturate Greedy algorithm more clearly outperforms the Single Greedy and All Greedy heuristics. Thus, robust opti-mization does appear to become necessary when there is a lot of uncertainty about the model X  X  parameters.

Notice that the evaluation of the algorithms X  seed sets is performed only with respect to the sampled influence func-tions, not with respect to all 2 | E | functions. Whether one can efficiently identify a worst-case parameter setting for a given seed set S 0 is an intriguing open question. Absent this ability, we cannot efficiently guarantee that the solutions are actually good with respect to all parameter settings.
Our work marks an early step, rather than the conclu-sion, in devising robust algorithms for social network tasks, and more specifically Influence Maximization. An interest-ing unresolved question is whether one can efficiently find an (approximately) worst-case influence function in the Pertur-bation Interval model. This would allow us to empirically evaluate the performance of natural heuristics for the Per-turbation Interval model, such as randomly sampling a small number of influence functions. Furthermore, it would allow us to design  X  X olumn generation X  style algorithms for the Perturbation Interval model, where we alternate between finding a near-optimal seed set for all influence functions encountered so far, and finding a worst-case influence func-tion for the current seed set, which will then be added to the encountered functions.

In the context of the bigger agenda, one could conceive of other notions of robustness in Influence Maximization, per-haps tracing a finer line between worst-case and Bayesian models. Also, much more research is needed into identi-fying which influence models best capture the behavior of real-world cascades, and under what circumstances. It is quite likely that different models will perform differently de-pending on the type of cascade and many other factors, and in-depth evaluations of the models could give practitioners more guidance on which mathematical models to choose. While our model of robustness allows us to combine in-stances of different models (e.g., IC and LT), this may come at a cost of decreased performance for each of the models individually. Thus, it remains an important task to identify the influence models that best fit real-world data. We would like to thank Shaddin Dughmi for useful pointers and feedback, Shishir Bharathi and Mahyar Salek for useful discussions, and anonymous reviewers for useful feedback. The research was sponsored in part by NSF research grant IIS-1254206 and by the U.S. Defense Advanced Research Projects Agency (DARPA) under Social Media in Strate-gic Communication (SMISC) program, Agreement Number W911NF-12-1-0034. The views and conclusions are those of the authors and should not be interpreted as represent-ing the official policies of the funding agency, or the U.S. Government. [1] B. Abrahao, F. Chierichetti, R. Kleinberg, and [2] A. Adiga, C. J. Kuhlman, H. S. Mortveit, and [3] C. Borgs, M. Brautbar, J. Chayes, and B. Lucier. [4] K. E. Campbell and B. A. Lee. Name generators in [5] W. Chen, L. V. Lakshmanan, and C. Castillo.
 [6] W. Chen, T. Lin, Z. Tan, M. Zhao, and X. Zhou. [7] W. Chen, Y. Wang, and S. Yang. Efficient influence [8] W. Chen, Y. Wang, Y. Yuan, and Q. Wang.
 [9] W. Chen, Y. Yuan, and L. Zhang. Scalable influence [10] X. Chen, G. Song, X. He, and K. Xie. On influential [11] H. Daneshmand, M. Gomez-Rodriguez, L. Song, and [12] N. Du, Y. Liang, M.-F. Balcan, and L. Song. Influence [13] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha. [14] M. Gomez-Rodriguez, D. Balduzzi, and B. Sch  X  olkopf. [15] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. [16] M. Gomez-Rodriguez and B. Sch  X  olkopf. Submodular [17] A. Goyal, F. Bonchi, and L. V. S. Lakshmanan. A [18] A. Goyal, F. Bonchi, L. V. S. Lakshmanan, and [19] X. He and D. Kempe. Stability of influence [20] X. He and D. Kempe. Robust influence maximization. [21] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [22] S. Khanna and B. Lucier. Influence maximization in [23] A. Krause, H. B. McMahan, C. Guestrin, and [24] S. Lei, S. Maniu, L. Mo, R. Cheng, and P. Senellart. [25] J. Leskovec, L. Backstrom, and J. Kleinberg.
 [26] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [27] M. Lowalekar, P. Varakantham, and A. Kumar.
 [28] E. Mossel and S. Roch. Submodularity of influence in [29] S. A. Myers and J. Leskovec. On the convexity of [30] H. Narasimhan, D. C. Parkes, and Y. Singer.
 [31] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An [32] P. Netrapalli and S. Sanghavi. Learning the graph of [33] K. Saito, M. Kimura, K. Ohara, and H. Motoda. [34] C. Wang, W. Chen, and Y. Wang. Scalable influence [35] Y. Wang, G. Cong, G. Song, and K. Xie.

