 Processing user-generated text data is getting more popular recently as a way to gather information, such as collecting facts about certain events (Rit-ter et al., 2015), gathering and identifying user pro-files (Layton et al., 2010; Li et al., 2014; Spitters et al., 2015), or extracting information in open domain (Ritter et al., 2012; Mitchell et al., 2015).
Most recent work focus on the texts generated through Twitter, which, due to the design of Twitter, contain a lot of announcement-like messages mostly intended for general public. In contrast, SMS was designed as a way to communicate short personal messages to a known person, and hence SMS mes-sages tend to be more conversational and more in-formal compared to tweets.

As conversational texts, SMS data often contains references to named entities such as people and lo-cations relevant to certain events. Recognizing those references will be useful for further NLP tasks. One way to recognize those named entities is to first cre-ate a list of candidates, which can be further filtered to get the desired named entities. Nadeau (Nadeau and Sekine, 2007) lists several methods that work upon candidates for NER. As all named entities are nouns, recognizing noun phrases (NP) is therefore a task that can be potentially useful for further steps in the NLP pipeline to build upon. Figure 1 shows an example SMS message within which noun phrases are highlighted. As can be seen from this example, recognizing the NP information on such a dataset presents some additional challenges over conven-tional NP recognition tasks. Specifically, the texts are highly informal and noisy, with misspelling er-rors and without grammatical structures. The correct casing and punctuation information is often missing. The lack of spaces between adjacent words makes the detection of NP boundaries more challenging.
Furthermore, the lack of available annotated data for such informal datasets prevents researchers from understanding what effective models can be used to resolve the above issues. In this work, we focus on tackling these issues while making the following two main contributions:  X  We build a new corpus of SMS data that is fully  X  We propose and build a new variant of semi-Our text corpus comes from the NUS SMS Corpus (Chen and Kan, 2013), containing 55,835 SMS mes-sages from university students, mostly in English. We used the 2011 version of the corpus, containing 45,718 messages, as it is more relevant to modern phone models using full keyboard layout.

We note that there are a small portion of the messages written in non-English language, such as Tamil and Chinese. As we are focusing on English, we excluded messages written by non-native En-glish speakers based on the metadata (21.3% of all messages). We also excluded messages which con-tain only one word (6.1%) and we remove duplicate
We assigned the remaining 27,700 messages to 64 university students who conduct annotations, each annotating 500 with 100 messages co-annotated by two other annotators. After manual verification we excluded annotations with low quality from 3 stu-dents. We used the resulting 26,500 messages as our dataset. The students were asked to annotate the top-level noun phrases found in each message using the structed to highlight character spans to be marked as noun phrases. The number of noun phrases per message can be found in Table 1.

Due to the noisy nature of SMS messages, there may not be proper capitalization or punctuation, and in some cases there might be missing spaces be-tween words. Figure 1 shows a sample SMS mes-sage taken from the corpus. We can see that  X  X r teh X  is not properly capitalized and  X  X he X  in  X  X utshe X  X  X  is missing spaces around it. NPs which do not have clear boundaries ( improper NPs) constitutes 4.0% of all NPs.

We then use this dataset to evaluate some models on base NP chunking task, where, given a text, the system should return a list of character spans denot-ing the noun phrases found in the text. In this paper, we will build our models based on a class of discriminative graphical models, namely conditional random fields (CRFs) (Lafferty et al., 2001), for extracting NPs. The edges in the graph represents the dependencies between states and the features are defined over each edge in the graph. Though CRFs are undirected graphical models, we can use directed acyclic graphs with a root, a leaf, A path in the graph from the root to the leaf rep-resents one possible label assignment to the input. In the labeled instance, there will be only one sin-gle path from the root to the leaf, while for the un-labeled instance, the graph will compactly encode all possible label assignments. The learning proce-dure is essentially the process that tries to tune the feature weights such that the true structures get as-signed higher weights as compared to all other alter-native structures in the graph.

In general, a CRF tries to maximize the following objective function: L ( T ) =
X where T is the training set, ( x , y ) is a training in-stance consisting of the sentence x and the label sequence y  X  Y n for a label set Y , w is the fea-ture weight vector, E ( x , y ) is the set of edges which form the path in the labeled instance, f ( e ) is the fea-ture vector of the edge e , Z w ( x ) is the normaliza-tion term which sums over all possible paths from the root to the leaf node, and  X  is the regularization parameter.

The set of edges and features defined in each model affects the feature expectation and the nor-malization term. Computation of the normalization term, being the highest in time complexity, will de-termine the overall complexity of training the model. The set of edges and the normalization term in each model will be described in the following sections. 3.1 Linear CRF A linear-chain CRF, or linear CRF is a standard ver-sion of CRF which was introduced in (Lafferty et al., 2001), where each word in the sentence is given a set of nodes representing the possible labels, and edges are present between any two nodes from ad-jacent words, forming a trellis graph. Here we con-sider only the first-order linear CRF.

The normalization term Z w ( x ) is calculated as: where f x ( y 0 ,y,i ) represents the feature vector on the edge connecting state y 0 at position i  X  1 to state y at position i . The time complexity of the inference procedure for this model is O ( n |Y| 2 ) . 3.2 Semi-CRF In semi-CRF (Sarawagi and Cohen, 2004), in addi-tion to the edges defined in linear CRF, there are ad-ditional edges from a node to all nodes up to L next words away, representing a segment within which the words will be labeled with a single label.
The normalization term Z w ( x ) is calculated as: where g x ( y 0 ,y,i  X  k,i ) represents the feature vector on the edge connecting state y 0 at position i  X  k to state y at position i . The time complexity for this model is O ( nL |Y| 2 ) . 3.3 Weak Semi-CRF Note that in semi-CRF, each node is connected to L  X |Y| next nodes. Intuitively, the model tries to decide the next segment length and type at the same time. We propose a weaker variant that makes the two decisions separately by restricting each node to connect to either only the nodes of the same label up to L next words away, or to all the nodes only in the next word. We call this Weak Semi-CRF .

To implement this, we need to split the original nodes into Begin and End nodes, representing the start and end of a segment. The End nodes connect only to the very next Begin nodes of any label, while the Begin nodes connect only to the End nodes of same label up to next L words. The term Z w ( x ) is: where g x ( y,i  X  k,i ) represents the feature vector on the edge connecting the Begin node with state y at position i  X  k to the End node with the same state y at position i . Note that, different from the g x func-tion defined in Equation (3), this new g x function is defined over a single (current) y label only, making the time complexity O ( n |Y| 2 + nL |Y| ) . Theoret-ically this model is slightly more efficient than the conventional semi-CRF model.
 Unlike conventional (first-order) semi-Markov CRF, this new model does not allow us to capture the dependencies between one segment and its ad-jacent segment X  X  label information. We argue that, however, such dependencies can be less crucial for our task. We will empirically assess this aspect through experiments. Figure 2 illustrates the differ-ences among the three models. In linear CRF, the baseline feature set considers the previous word, current word, and the tag transition.
In semi-CRF, following (Sarawagi and Cohen, 2004) we put all words not part of a noun phrase in its own segment, and put each noun phrase in one segment, possibly spanning over multiple words. Here we set L = 6 and ignored NPs with more than six words during training, which is less than 0.5% of all NPs. For each segment, we defined the following features as the baseline: (1) indexed words inside current segment, running from the start and from the end of the segment, (2) the word before and after current segment, and (3) the labels of last segment and current segment.

In weak semi-CRF we use the same feature set as semi-CRF, adjusting the features accordingly where segment-specific features (1) are defined only in the Begin-End edges, and transition features (3) are de-fined only in the End-Begin edges.

For each model we then add the character pre-fixes and suffixes up to length 3 for each word ( +a ), Brown cluster (Brown et al., 1992) for current word ( +b ), and word shapes ( +s ). For Brown cluster fea-tures we used 100 clusters trained on the whole NUS SMS Corpus. The cluster information is then used directly as a feature.

Word shapes can be considered a generic repre-sentation of words that retains only the  X  X hape X  in-formation, such as whether it starts with capital let-ter or whether it contains digits. The Brown clusters and word shapes features are applied to each of the word features described in each model. All models were built by us using Java, and were optimized with L-BFGS. Models are all tuned in the development set for optimal  X  . The optimal  X  values are noted in Table 2.

Since the models that we consider are all word-tokenizer similar to the wordpunct_tokenize function in Python NLTK package. We also in-cluded some rules to consider special anonymization tokens in the SMS dataset (Chen and Kan, 2013).
The gold character spans are converted into word labels in BIO format, reducing or extending the character spans as necessary to the closest word boundaries. The converted annotations are regarded as gold word spans. Note that this conversion is lossy due to the presence of improper NPs, which makes it impossible for the converted format to rep-resent the original gold standard.

We evaluated the models in the original character-level spans and also in the converted word-level spans, to see the impact of the lossy conversion on the scores. In character-level evaluation, the system output is converted back into character boundaries and compared with the original gold standard, while in the word-level evaluation, the system output is compared directly with the gold word spans. For this reason, we anticipate that the scores in word-level evaluation will be higher than in the character-level evaluation. The results are shown in Table 3. The scores for  X  X old X  in the character-level evaluation mark the upperbound of word-based models due to the presence of improper NPs.

The average time per training iteration on the base models is 1.311s, 2.072s, and 1.811s respectively for Linear CRF, Semi-CRF, and Weak Semi-CRF. 5.1 Discussion First, we see that the two semi-CRF models perform better compared to the baseline linear CRF model, showing the benefit of using segment features over only single word features.

It is also interesting that, while being a weaker version of the semi-CRF, the weak semi-CRF can actually perform in the same level within 95% con-fidence interval as the conventional semi-CRF. This shows that some of the dependencies in the con-ventional semi-CRF do not really contribute to the strength of semi-CRF over standard linear CRF. As noted in Section 3.3, weak semi-CRF makes the de-cision on the segment type and length separately. This means there is enough information in the lo-cal features to decide the segment type and length separately, and so we can remove some combined features while retaining the same performance.
This result, coupled with the fact that the weak semi-CRF requires 12.5% less time than the conven-tional semi-CRF (1.811s vs 2.072s), shows the po-tentials of using this weak semi-CRF as an alterna-tive of the conventional semi-CRF. With more label types (here only two), the difference will be larger, since the weak semi-CRF is linear in number of label types, while conventional semi-CRF is quadratic. Ritter et al. (2011) previously showed that off-the-shelf NP-chunker performs worse on informal text. Then they trained a linear-CRF model on additional in-domain data, reducing the error up to 22%. How-ever no results on semi-CRF was given.
 Semi-CRF has proven effective in chunking tasks. Other variants of semi-CRF models also exist. Nguyen et al. (2014) explored the use of higher-order dependencies to improve the performance of semi-CRF models on synthetic data and on hand-writing recognition. They exploited the sparsity of label sequence in order to make the training efficient.
It is also known that feature selection is an impor-tant aspect when trying to use semi-CRF models to improve on the linear CRF. Andrew (2006) reported an error reduction of up to 25% when using features that are best exploited by semi-CRF. In this paper we present a new NP-annotated SMS corpus, together with a novel variant of the semi-CRF model, which runs in significantly lower time while maintaining similar accuracy on the NP chunking task on the new dataset. Future work in-cludes the application of the weak semi-CRF model to other structured prediction problems, as well as performing investigations on handling other types of informal or noisy texts such as speech transcripts. We make the code and data available for download at http://statnlp.org/research/ie/ .
 We would like to thank Alexander Binder, Jie Yang, Dinh Quang Thinh as well as the 64 undergraduate students who helped us with annotations. We would also like to thank the three anonymous reviewers for their helpful comments. This work is supported by SUTD grant SRG ISTD 2013 064 and MOE Tier 1 grant SUTDT12015008.
