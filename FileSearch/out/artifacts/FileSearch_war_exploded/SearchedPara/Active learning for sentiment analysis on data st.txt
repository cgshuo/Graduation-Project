 1. Introduction
This paper addresses a data mining scenario at the intersection of active learning, sentiment analysis, stream mining and service-oriented knowledge discovery architectures effectively solved by on-line workflow implementation of the developed active learning methodology for sentiment analysis from streams of Twitter data.

Active learning is a well-studied research area ( Sculley, 2007; Settles, 2011; Settles &amp; Craven, 2008 ), addressing data mining scenarios where a learning algorithm can periodically select new examples to be labeled by a human annotator and add them to the training dataset to improve the learner X  X  performance on new data. Its aim is to maximize the performance of the algorithm and minimize the human labeling effort. Sentiment analysis ( Liu, 2012; Pang &amp; Lee, 2008;
Turney, 2002 ) is concerned with the detection of the author X  X  attitude, emotion or opinion about a given topic expressed  X  in the text. The task of sentiment analysis is especially challenging in the context of analyzing user generated content from paradigm, aiming to incorporate the information from the evolving data stream into the model, without having to re-learn the model from scratch; while batch learning is a finite process that starts with a data collection phase and ends with a sta-tionary model, the online learning process starts with the arrival of some training instances and lasts as long as there is new validation phase in a single continuous cycle.

This paper introduces a cloud-based scientific workflow platform, which is able to perform on-line dynamic adaptive sen-timent analysis of microblogging posts. Even though there are many on-line platforms which apply sentiment analysis on microblogging texts, there is still no such pltaform that could be used for on-line dynamic adaptive sentiment analysis and would thus be able to handle changes in data streams and adapt its components over time. In order to provide contin-uous updating of the sentiment classifier with time we used an active learning approach. In this paper, we address this issue by presenting an approach to interactive stream-based sentiment analysis of microblogging messages in a cloud-based sci-entific workflow platform ClowdFlows. 1 With the aim to minimize the effort required to apply labels to tweets, this browser-based platform provides an easy way to share the results and a Web interface for labeling tweets.

ClowdFlows is a new open-sourced data mining platform designed as a cloud-based Web application in order to over-come several deficiencies of similar data mining platforms, providing a handful of novel features that benefit the data mining community. ClowdFlows was first developed as a data mining tool for processing static data ( Kranjc, Podpecian, &amp; Lavraci, 2012a, 2012b ), which successfully bridges different operating systems and platforms, and is able to fully utilize available server resources in order to relieve the client from heavy-duty processing and data transfer as the platform is entirely
Web based and can be accessed from any modern browser. ClowdFlows also benefits from a service-oriented architecture which allows users to utilize arbitrary Web services as workflow components. In this paper we present the adaptation of the ClowdFlows platform, enabling it to work on real time data streams. As a result, workflows in ClowdFlows are no longer limited to static data on the server but can connect to multiple data sources and can process the data continuously. One such data source is the Twitter API which provides a potentionally infinite stream of tweets which are the subject of sentiment analysis in this paper.

The paper is structured as follows. Section 2 presents the related work. Comparable data mining and stream mining plat-forms are presented and their differences and similarities with ClowdFlows are discussed. Related work concerning active learning in data streams is also presented. Section 3 presents the technical background and implementation details of the
ClowdFlows platform. The architecture of the system is presented along with specific methods that allow stream mining in a workflow environment. The proposed sentiment analysis and active learning methods are presented in Section 4 . The implementation details and the workflow enabling active learning for sentiment analysis are presented in Section 5 . In Sec-tion 6 we conclude the paper by presenting the directions for further work. 2. Related work
This section presents an overview of data mining platforms and their key features: visual programming and execution of scientific workflows, diversity of workflow components, service-oriented architectures, remote workflow execution, big data processing, stream mining, and data sharing. The overview is followed presenting current research in the field of active learning on data streams. 2.1. Data mining platforms
Visual construction and execution of scientific workflows is one of the key features of the majority of current data mining software platforms. It enables the users to construct complex data analysis scenarios without programming and allows to easily compare different options. All major data mining platforms, such as Weka ( Witten, Frank, &amp; Hall, 2011 ), RapidMiner
Curk, 2004 ) support workflow construction. The most important common feature is the implementation of a workflow canvas where complex workflows can be constructed using simple drag, drop and connect operations on the available components.
The range of available components typically includes database connectivity, data loading from files and preprocessing, data and pattern mining algorithms, algorithm performance evaluation, and interactive and non-interactive visualizations.
Even though such data mining software solutions are reasonably user-friendly and offer a wide range of components, some of their deficiencies severely limit their utility. Firstly, all available workflow components provided by any of these platforms are specific and can be used only in the given platform. Secondly, the described platforms are implemented as standalone applications and have specific hardware and software dependencies. Thirdly, in order to extend the range of available workflow components in any of these platforms, knowledge of a specific programming language is required. This also means that they are not capable of using existing software components, implemented as Web services, freely available on the Web.
As a benefit of service-oriented architecture concepts, software tools have emerged, which are able to make use of Web services, and can access large public databases (some supporting grid deployment and P2P computing). Environments such for the integration of Web services as workflow components. However, with the exception of Orange4WS and Web Extension for RapidMiner, these environments are mostly specialized to domains like systems biology, chemistry, medical imaging, ecology and geology. Lastly, all mentioned platforms are still based on technologies that do not benefit from modern Web technologies which enable truly independent software solutions. On the other hand, Web-based workflow construction environments exist, which are however too general and not coupled to any data mining library. For example, Oryx Editor ( Decker, Overdick, &amp; Weske, 2008 ) can be used for modeling business processes and workflows while the Galaxy ( Blankenberg et al., 2001, chap. 19 ) genome analysis tool (implemented as a Web application) is limited exclusively to the workflow components provided by the project itself.
 Remote workflow execution (on different machines than the one used for workflow construction) is employed by KNIME
Cluster execution and RapidMiner using the RapidAnalytics server. This allows the execution of workflows on more powerful machines and data sharing with other users, with the requirement that the client software is installed on the user X  X  machine.
The client software is still used for designing workflows which are executed on remote machines, while only the results can be viewed using a Web interface.

In support of the ever increasing amount of data several truly distributed software platforms have emerged. Such plat-forms can be categorized into two groups: batch data processing and data stream processing. A well known example of a distributed batch processing framework is Apache Hadoop, 2 (parallelization of a variety of learning algoriths using an adaptation of MapReduce is discussed by Chu et al. (2006) ). Apache
Hadoop is also the base framework of Apache Mahout, 3 a machine learning library for large data sets, which currently supports recommendation mining, clustering, classification and frequent itemset mining. Radoop, tion, is based on RapidMiner and Mahout, and uses RapidMiner X  X  data flow interface.

For data stream processing, two of the most known platforms were released by Yahoo! (the S4 platform (Storm 6 ). SAMOA ( Morales, 2013 ) is an example of a new generation platform which is targeted at processing big data streams.
In contrast with distributed data mining tools for batch processing using MapReduce (e.g., Apache Mahout), SAMOA features a pluggable architecture on top of S4 and Storm for performing the most common tasks such as classification and clustering. How-ever, the platform is under development, no software has been released yet and it is not known whether the platform will sup-port visual programming with workflows. MOA (Massive On-line Analysis) is a non-distributed framework for mining data two is possible. MOA itself does not support visual programming of workflows but the ADAMS project ( Reutemann &amp; Vanschoren, 2012 ) provides a workflow engine for MOA which uses a tree-like structure instead of an interactive canvas.
Sharing data and experiments has been implemented in the OpenML Experiment Database ( Vanschoren &amp; Blockeel, 2009 ), which is a database of standardized machine learning experimentation results. Instead of a workflow engine it fea-tures a visual query engine for querying the database, and an API for submitting experiments and data. 2.2. Active learning for data streams
There exist three different scenarios for active learning: (i) membership query synthesis, (ii) pool-based sampling, and (iii) stream-based selective sampling ( Settles, 2010 ). In the membership query synthesis scenario, the learning algorithm can select examples for labeling from the input space or it can produce new examples itself. In the pool-based scenario, the learner has access to a collection of previously seen examples and may request labeling for any of them. In this study, we are interested in the third scenario: the stream-based active learning approach. More specific, we are interested in the active learning on stream data for sentiment analysis of Twitter posts. In this scenario, examples are constantly arriving from a data stream and the learning algorithm has to decide in real time whether to select an arriving example for labeling or not.
Therefore, the approach which would handle this scenario has to:
In the stream-based active learning setting, there exist several approaches to deciding whether or not to request hand labels for examples which come from a data stream. One of the simplest strategies is to use some informativeness measure and request labeling for the examples which are the most informative. For instance, the examples for which the learner has the highest uncertainty can be considered the most informative and be selected for labeling. Zhu, Zhang, Lin, and Shi (2007) used uncertainty sampling to label examples within a batch of data from the data stream. Z
Holmes (2011) propose strategies that are based on uncertainty, dynamic allocation of labeling efforts over time and ran-domization of the search space. Our active learning approach also employs randomization of the search space, but in contrast ples are best for labeling can be made by a single evolving classifier ( Z for Twitter posts.
 2011 ). The closely related contribution was made in ( Settles, 2011 ), where the author demonstrated the application of DUAL-
IST, an active learning annotation tool, to Twitter sentiment analysis. The author intended to show the generality of the annotation tool, since it is not adjusted specifically to tweets. On the other hand, our approach is particularly adjusted to Twitter data. Regarding the on-line platform which would handle active learning on stream data for sentiment analysis of
Twitter posts, to best of our knowledge, we are the first addressing this issue. 3. The ClowdFlows platform
In this section the ClowdFlows platform is presented. The enabling technologies are presented briefly and displayed in the architecture of the system. To validate the design of the platform we present a stress test with many simultaneous users executing their workflows. The graphical user interface and the workflow model are presented. Finally the real-time analysis features of ClowdFlows are described. 3.1. Platform design
As a new generation data mining platform, ClowdFlows ( Kranjc et al., 2012a, Kranjc, Podpec  X  an, &amp; Lavrac  X  , 2012b )is designed and implemented using modern technologies and computing paradigms. It is essentially a cloud-based Web application that can be accessed and controlled from anywhere while the processing is performed in a cloud of computing nodes. To achieve the goal of developing a platform that can be accessed and controlled from anywhere and executed on a cloud, we have designed it as a cloud-based Web application. As such it can be, based on the technologies used, logically separated on two sides  X  the client side, and the server side. The architecture of the platform accessed by multiple users is shown in Fig. 1 . A similar architecture figure was previously published in ( Kranjc et al., 2012a ), with some major differences. In contrast to the previously published architecture, the platform now features a relational database for storing workflows, a broker for delegating tasks to worker nodes and a stream mining daemon for processing data streams.

The client side of the platform consists of operations that involve user interaction. The user interacts with the platform primarily through the graphical user interface in a contemporary Web browser. We have implemented the graphical user interface in HTML and JavaScript, with an extensive use of the jQuery library. client-side scripting, and is the most popular JavaScript library in use today.
The server side is written in Python and uses the Django Web framework. that encourages rapid development and provides an object-relational mapper and a powerful template system. The object-rela-tional mapper provides an API that links objects to a database, which means that the ClowdFlows platform is database agnostic. PostgreSQL, MySQL, SQLite and Oracle databases are all supported. MySQL is used in the public installation of ClowdFlows.
In order to allow consumption of Web services and importing them as workflow components, the PySimpleSoap library is used. PySimpleSoap is a light-weight library written in Python and provides an interface for client and server Web service communication, which allows importing WSDL Web services as workflow components, and exposing entire workflows as WSDL Web services.

ClowdFlows may also be installed on multiple computers, which is enabled by using the RabbitMQ a Django implementation of Celery, 12 a distributed task queue, which allows passing asynchronous tasks between servers. With this tools it is possible to install ClowdFlows on worker nodes which execute workflows. To demonstrate the scalability of the platform with these tools we have performed a stress test which we describe in Section 3.2 .
 ClowdFlows is publically available for use at http://clowdflows.org . The source code is open sourced under the General
Public Licence and can be downloaded at http://github.com/janezkranjc/clowdflows . Detailed installation instructions are provided with the source code. 3.2. Scalability of the platform
In order to test the scalability of the ClowdFlows platform and validate the design decisions described in Section 3.1 enabling big data analytics for data streams we have performed a stress test in which we simulated several users executing their workflows simultaneously and measured the average execution time.
 The test was conducted on a simplified workflow that performs 10-fold cross validation with the Naive Bayes algorithm. The workflow is shown in Fig. 2 . In order to simulate concurrent users we have implemented a simulation of a user that executes her workflow continuously for 60 s without a pause. This settings is also equivalent to executing a streaming pro-cess for 1 min. After 60 s have passed the user waits until the final workflow execution results are returned. We tested the platform against different sets of concurrent users: 1 user, 10 users, 20 users, 50 users, and 100 users for different setups of the worker nodes.

A worker node is a headless installation of the ClowdFlows platform that executes workflows. We tested the platform with a single worker node, two worker nodes, and three worker nodes. Each of these worker nodes was installed on equiv-alent computers with 8 cores. The workers were setup to work on 8 concurrent threads. For the final test we have setup an additional worker on a computer with 16 cores to run 16 threads. We have measured the execution times for each workflow and calculated the average execution time from the beginning of the request until the result was received. The results are shown in Table 1 .

The results show that a single user continuously executing her cross validation workflow will be able to execute it 18 or 19 times on any setup if she is the only user executing workflows. In order for ten concurrent users to execute their work-flows at a comparable speed at least two worker nodes are needed. The most efficient current setup is three workers with 8 threads each and one worker with 16 threads which still allows a hundred users to issue workflow execution requests to the platform at a reasonable response time.

The platform has succesfully passed the stress test. The results show that the ClowdFlows platform can serve many con-current users that continuously execute workflows. The average execution times can be controlled by adding or removing worker nodes. The worker nodes can be added and removed during runtime, which means that heavy loads can be resolved simply by adding more computing power to the ClowdFlows worker cluster. As adding worker nodes at times with lower loads does not improve the average processing time, we would like to implement a mechanism for automatically spawning and removing worker nodes on services such as the Amazon Elastic Compute Cloud in future work. 3.3. The workflow model
The integral part of the ClowdFlows platform is the workflow model which consists of an abstract representation of work-flows and workflow components. Workflows are executable graphical representations of complex procedures. A workflow in
ClowdFlows is a set of processing components and connections. A processing component is a single workflow processing unit with inputs, outputs and parameters. Each component performs a task considering its inputs and parameters, and then stores the results of the task on its outputs. Connections are used to transfer data between two components and may exist only between an output of a widget and an input of another widget. Data is transffered between connections, so each input can only receive data from a connected output. Parameters are similar to inputs, but need to be entered manually by users.
Inputs can be transformed into parameters and vice versa, depending on the users X  needs. 3.4. The graphical user interface
The graphical user interface used for constructing workflows follows a visual programming paradigm which simplifies the representation of complex procedures into a spatial arrangement of building blocks. The building blocks (workflow com-ponents) in ClowdFlows are referred to as widgets. The graphical user interface implements an easy to use way to arrange widgets on a canvas to form a graphical representation of a procedure. The ClowdFlows graphical user interface rendered in a Web browser is shown in Fig. 2 .

The graphical user interface of the ClowdFlows system consists of a workflow canvas and a widget repository. The widget repository is a set of widgets ordered in a hierarchy of categories. Upon clicking on a widget in the repository, that widget appears on the canvas. The workflow canvas implements moving, connecting, issuing commands to execute and delete wid-gets. Widgets can be arbitrarily arranged on the canvas by dragging and dropping. Connections between widgets can be added by selecting an output of a widget and an input of another widget.
 Information on each operation the user performs on the workflow canvas is sent to the server using an asynchronous
HTTP POST request. The operation is validated on the server and a success or error message with additional information is passed to the user interface (the client X  X  browser) formatted in JavaScript Object Notation (JSON) or HTML.
On the top of the graphical user interface is a toolbar where entire workflows can be saved, deleted, and executed. 3.5. The widget repository
Widgets in ClowdFlows are separated into four groups based on their purpose: regular widgets, visualization widgets, interactive widgets and workflow control widgets.

Regular widgets perform specific tasks that transform the data from the inputs and the parameters to data on the outputs, and provide success or error messages to the system. The task of a widget is written as a Python function that takes a Python dictionary of inputs and parameters as its arguments and returns a dictionary of outputs. The function is called each time the widget is executed. Widgets that implement complex procedures can also implement a progress bar, that displays progress to the user in real time.

Visualization widgets are extended versions of regular widgets as they also provide the ability to render an HTML tem-plate with JavaScript to the client X  X  browser. These are useful for data visualizations and presentation of more detailed feed-back to the user. Visualization widgets are regular widgets with the addition of a second Python function which controls the rendering of the template. This function is only invoked when the workflow is executed from the user interface.
An interactive widget is a widget that requires data before execution in order to prompt the user for the correct param-eters. These widgets are extensions of regular widgets as they perform three functions. The data preparation function exe-cutes first and takes the inputs and parameters as the arguments. The second function is a rendering function where a modal window is prepared by using an HTML template which prompts the user to manipulate the data. The final function X  X  argu-ments are the user X  X  input and the inputs and parameters of the widget. A widget can also be a combination of an interactive and a visualization widget, where it executes a fourth rendering function to display the results.

Three special widgets provide additional workflow controls. These are the Sub-workflow , Input , and Output widget. When-ever a Sub-workflow widget is added to a workflow, an empty workflow is created that will be executed when the sub-work-flow widget is executed. The Sub-workflow widget has no inputs and outputs by default, so they have to be added to the workflow by the user using the Input and the Output widget. Whenever an Input or Output widget is put on a workflow that is a sub-workflow of another workflow, an actual input or output is added to the widget representing the sub-workflow. Workflows can be indefinitely nested this way.

Two variations of the input and output widget provide ways to loop through sub-workflows. The input and output wid-gets can be replaced by the For Input and For Output widgets. Whenever a workflow contains these two widgets, the work-flow execution engine will attempt to break down the object on the input and execute the workflow once for each piece of data that is on the input. With these controls a workflow can be executed on a list or array of data. 3.6. The workflow execution engine
The job of the workflow execution engine is to execute all executable widgets in the workflow in the correct order. The engine is implemented twice, both in Python and JavaScript due to performance issues when the user wishes to see the order of the executed widgets in real time.

The two implementations of the workflow execution engine are similar with two differences. The JavaScript engine is enabled by default due to the requests for executing separate widgets being asynchronous HTTP requests. Each request is handled by the server separately and executes a single widget, saves the changed and returns the results to the client where the execution continues. The server side Python implementation only receives one HTTP request for the entire workflow and multiprocessing had to be implemented manually. For performance issues, sub-workflows and loops are executed by the
Python implementation, while top-level workflows executed from the user interface are processed by the JavaScript imple-mentation. The JavaScript implementation shows the results of the execution of each widget in real time, while the user can only see the results of the Python implemented workflow execution after it has finished in full.
 When a workflow is running, the execution engine perpetually checks for widgets that are executable and executes them.
Executable widgets are widgets which either have no predecessors, or their predecessors have already been successfully exe-cuted. Whenever two or more widgets are executable at the same time they are asynchronously executed in parallel, since they are independent. The implemented widget state mechanism ensures that no two widgets where the inputs of a widget are dependent on an output of another widget will be executable at the same time. The execution of a workflow is complete when there are no executable or running widgets. 3.7. Public workflows
Since workflows in ClowdFlows are processed and stored on remote servers they can be accessed from anywhere with an internet connection. By default, each workflow can only be accessed by its author. We have implemented an option that allows users to create public versions of their workflows.

The ClowdFlows platform generates a specific URL for each workflow that has been saved as public. Users can then simply share their workflows by publishing the URL. Whenever a public workflow is accessed by a user, a copy of the workflow is created on the fly and added to the user X  X  private workflow repository. The workflow is copied with all the data to ensure the repeatability of experiments. Each such copied public workflow can also be edited, augmented or used as a template to cre-ate a new workflow, which can be made public as well. 3.8. Real-time data analysis in ClowdFlows
In comparison with the early implementations of the ClowdFlows platform described in ( Kranjc et al., 2012a, 2012b ) the novelty of this work is the ability of ClowdFlows to process real-time data streams. Its workflow engine has been augmented with continuous parallel execution and the halting mechanism and several specialized widgets for stream data processing were developed. In the following we describe the new data stream processing capabilities of the ClowdFlows platform. 3.8.1. Continuous workflow execution with the halting mechanism
Regular workflows and stream mining workflows are primarily distinguished by their execution times. A widget in a sta-tic workflow is executed a finite amount of times and the workflow has a finite execution time. Widgets in a stream mining workflow are executed a potentially infinite amount of times and the workflows are executed until manually terminated by users. Another major difference between regular workflows and stream mining workflows is the data on the input. The data that is processed by regular workflows is available in whole during the entire processing time, while data entering the stream mining workflows is potentially infinite and is only exposed as a small instance at any given time.
In order to handle potentially infinite data streams we have modified the workflow execution engine to execute the work-flow multiple times at arbitrarily small temporal intervals in parallel. The amount of parallelism and the frequency of the execution are parameters that can be (providing the hardware availability) modified for each stream to maximize the throughput.
 The execution of the workflows is delegated by a special stream mining daemon that issues tasks to the messaging queue.
The stream mining daemon X  X  task is to issue commands to execute streaming workflows. The daemon can also prioritize exe-cution of some streams over others based on the users X  preferences. Tasks are picked up from the messaging queue by work-ers that execute the workflow. To ensure that each execution of a workflow processes a different instance of the data, special widgets and mechanisms were developed, which can halt the execution of streaming workflows. This halting mechanism can be activated by widgets in a streaming workflow to halt the current execution.

Workflows that are executed as a stream mining process need to be saved as streaming workflows and executed sepa-rately. The user cannot inspect the execution of the workflow in real time, as many processes are running in parallel. The user can, however, see the results from special stream visualization widgets. 3.8.2. Specialized workflow widgets for real-time processing
Widgets in stream mining workflows have, in contrast to widgets in regular workflows, the internal memory and the abil-ity to halt the execution of the current workflow. The internal memory is used to store information about the data stream, such as the timestamp of the last processed data instance, or an instance of the data itself. These two mechanisms were used to develop several specialized stream mining widgets.

In order to process data streams, streaming data inputs had to be implemented. Each type of stream requires its own wid-get to consume the stream. In principle, a streaming input widget connects to an external data stream source, collects instances of the data that it had not yet seen, and uses its internal memory to remember the current data instances. This able in the stream itself. If the input widget encounters no new data instances at the stream source it halts the execution of the stream. No other widgets that are directly connected to it via its outputs will be executed until the workflow is executed again.

Several other popular stream mining approaches ( Ikonomovska, Loskovska, &amp; Gjorgjevik, 2007 ) were also imple-mented as workflow components. The aggregation widget was implemented to collect a fixed number of data instances before passing the data to the next widget. The internal memory of the widget is used to save the data instances until the threshold is reached. While the number of instances is below the threshold, the widget halts the execution.
The internal memory is emptied and the data instances are passed to the next widget once the threshold has been reached.

The sliding window widget is similar to the aggregation widget, except that it does not empty its entire internal memory upon reaching the threshold. Only the oldest few instances are forgotten and the instances inside the sliding window are released to other widgets in the workflow for processing. By using the sliding window, each data instance can be processed more than once.

Sampling widgets are fairly simple. They either pass the instance to the next widget or halt the execution, based on an arbitrary condition. This condition can be dependent on the data or not (e.g. drop every second instance). The internal mem-ory can be used to store counters, which are used to decide which data is left in the sample.

Special stream visualization widgets were also developed for the purpose of examining results of real-time analyses. Each instance of a stream visualization widget creates a special Web page with a unique URL that displays the results in various formats. This is useful because the results can be shared without having to share the actual workflows. 4. Active learning for sentiment analysis
In this section we first describe the dataset we use for the default tweet sentiment classifier, preprocessing techniques and the algorithm for sentiment analysis. The approach to tweet preprocessing and classifier training is implemented using the LATINO 13 software library of text processing and data mining algorithms. The section continues with a description of the active learning algorithm and the strategy used to select data instances for labeling. 4.1. The data used for the default sentiment classifier
The default tweet sentiment classifier is trained on a collection of 1,600,000 (800,000 positive and 800,000 negative) tweets collected and prepared by Stanford University ( Go, Bhayani, &amp; Huang, 2009 ), where the tweets were labeled based on positive and negative emoticons in them. Therefore, the emoticons approximate the actual positive and negative senti-tweets containing both positive and negative emoticons, retweets and duplicate tweets were removed ( Go et al., 2009 ).
The emoticons, which approximate sentiment labels, were also already removed from the tweets in order not to put too much weight on them in the training phase, and therefore the classifier learns from the other features of tweets. The tweets in this collection do not belong to any particular domain. 4.2. Data preprocessing
Preprocessing of data is an important step when using supervised machine learning techniques. On the Twitter data, we apply both standard and Twitter-specific text preprocessing to better define the feature space. The specific text preprocess-ing is especially important for Twitter messages, since user generated content on the Internet often contains slang ( Petz et al., 2012 ) and messages from social media are considered noisy, containing many grammatical and spelling mistakes ( Petz et al., 2013 ). Therefore, with our Twitter-preprocessing, we try to overcome these problems and improve the quality of features.
 As a part of the Twitter preprocessing step ( Agarwal, Xie, Vovsha, Rambow, &amp; Passonneau, 2011; Go et al., 2009;
Smailovic  X  , Grc  X  ar, Lavrac  X  ,&amp;Z  X  nidar X ic  X  , 2013; Smailovic  X  , Grc  X  ar, &amp; Z in a tweet of the form @TwitterUser by a single token named USERNAME and writing different Web links by a single token named URL . Moreover, letters which repeat for more than two times are replaced by one occurrence of such letter; for exam-EXCLAMATION and question marks by a single token QUESTION .

Besides the Twitter-specific text preprocessing, we also apply standard preprocessing techniques ( Feldman &amp; Sanger, 2007 ) in order to better define and reduce the feature space. These involve text tokenization (text splitting into individual etc.), stemming (converting words into their base or root form) and N-gram construction (concatenating 1 to N stemmed words appearing consecutively in a tweet). The resulting terms are used as features in the construction of feature vectors representing the tweets, where the feature vector construction is based on term frequency feature weighting scheme. We do not apply a part of speech (POS) tagger, since it was indicated by Go et al. (2009) and Pang and Lee (2002) that POS tags are not useful when using SVMs for sentiment analysis. Also, Kouloumpis, Wilson, and Moore (2011) showed that POS fea-tures may not be useful for sentiment analysis in the microblogging domain. 4.3. The algorithm used for sentiment classification
Sentiment analysis methods ( Liu, 2012; Pang &amp; Lee, 2008; Turney, 2002 ) aim at detecting the authors attitude, emotions or opinion about a given topic expressed in text. There are three generally known approaches to sentiment analysis ( Pang &amp;
We use a machine learning approach, applying the linear Support Vector Machine (SVM) ( Cortes &amp; Vapnik, 1995; Vapnik, 1995, 1998 ), which is a typical algorithm used in document classification. The SVM training algorithm represents the labeled training examples as points in the space and separates them with a hyperplane. A hyperplane is placed in such a way that the examples of the separate classes are divided from each other as much as possible. New examples are then mapped into the same space and classified based on the side of the hyperplane they are. For training the tweet sentiment classifier, we use the SVM perf ( Joachims, 2005, 2006; Joachims &amp; Yu, 2009 ) implementation of the SVM algorithm. In order to test its classification accuracy, we trained the SVM classiffier on the collection of 1,600,000 smiley labeled tweets ( Go et al., 2009 ) and tested it on 177 negative and 182 positive manually labeled tweets, prepared and labeled by Stanford University ( Go et al., 2009 ). We applied both standard and Twitter specific preprocessing. In this experiment we achieved the accuracy of 83.01% (which is a comparable result with ( Go et al., 2009 )).

The reason for using a machine learning approach and not lexicon-based or linguistic methods is the following. In the context of active learning for sentiment analysis on data streams, the linguistic methods pose several challenges, as they tend to be too computationally demanding for the use in a streaming near real time setting. Also, there is the lack of readily available tools for parsing tweets. On the other hand, lexicon-based methods are faster, but they usually rely on explicit notion of sentiment and dismiss the terminology that bears sentiment more implicitly. For example, the word  X  X reece X  bears negative sentiment in the light of the financial crisis, but in general it is neutrally or even positively connoted word.
Nevertheless, in order to compare lexicon and machine learning methods, we have tested a lexicon method classification accuracy on the same collection of 177 negative and 182 positive manually labeled tweets ( Go et al., 2009 ), as for the machine learning approach. In the lexicon-based method, we used an opinion lexicon containing 2006 positive and 4783 many misspelled words which are frequently used in social media language. We applied Twitter specific preprocessing on the test tweets and calculated positive and negative score for each tweet, based on the occurrences of positive and negative lexicon lexicon words for that specific class in the observed tweet. For example, a tweet could contain a word  X  X icely X . On the other negative score are labeled as positive, since the positive lexicon list contains less words. In this experiment we achieved the accuracy of 76.04% on the test set.

Since the accuracy on the test set obtained with the machine learning approach was higher than the accuracy obtained with the lexicon-based approach, we decided to focus on the machine learning approach in our study. 4.4. Active learning
In active learning, the learning algorithm periodically asks an oracle (e.g., a human annotator) to manually label the examples which he finds most suitable for labeling. Using this approach and an appropriate query strategy, the number of examples that need to be manually labeled is largely decreased. Typically, the active learning algorithm first learns from an initially labeled collection of examples. Based on the initial model and the characteristics of the newly observed unlabeled examples, the algorithm selects new examples for manual labeling. After the labeling is finished, the model is updated and the process is repeated for the new incoming examples. This procedure is repeated until some threshold (for example, time active and new examples are arriving.

In our software, the active learning algorithm first learns from the Stanford smiley labeled data set as an initial labeled data set. According to this initial model, the algorithm classifies new incoming tweets from the data stream as positive or negative. Tweets, which come from the data stream, are split into batches. The algorithm selects most suitable tweets from a first batch for hand-labeling and puts them in a pool of query tweets. The process is repeated for every following batch and every time the pool of query tweets is updated and the tweets in the pool are reordered according to how suitable they are for hand-labeling. When the user decides to conduct manual labeling, she is given a selected number of top tweets from the pool of query tweets for hand-labeling. The user can label a tweet as positive, negative or neutral. After the labeling, labeled tweets are placed in the pool of labeled tweets and removed from the pool of query tweets. Periodically, using the initial and manually positively and negatively labeled tweets from the pool of labeled tweets, the model is retrained. This process is repeated until it is terminated by the user.

The selection of tweets, which are suitable for manual labeling is based on uncertainty strategy and randomization of the search space. The randomization of the search space was also used by Z proportions of random tweets and tweets which are closest to the SVM hyperplane in order to find the best combination of them. Additionally, we performed one experiment in which we did not apply the active learning strategy, i.e., the sentiment classifier was static and did not update over time. In order to automatically conduct these experiments, we hand-labeled a data set of 11,389 financial tweets (4861 positive, 1856 negative and 4672 neutral tweets) discussing the Web search engine provider Baidu, 15 which were collected for a period from March 11 to December 9, 2011. The evaluation method was based on a where concept drift is assumed. The classifier X  X  performance is tested on a new batch of tweets which come from the data to label them. The newly labeled tweets are added to the training set and used for updating the sentiment model. This procedure is repeated for every new batch of tweets from the data stream. We calculate the accuracy, precision and recall for every batch and at the end of the simulation we report the overall average measures for all the batches. In our off-line evaluation experi-ments, we select 100 tweets from every batch, which contains 1000 tweets, and then update the model. The results are pre-sented in Table 2 . As can be seen from the table, the accuracy of the sentiment classification is higher when the active learning approach is applied. Among the querying strategies, the highest accuracy is obtained by selecting 75 random tweets and 25 tweets which are closest to the SVM hyperplane.

In contrast to the experimental setting described above, the workflow developed for practical use (shown in Fig. 3 )by default splits tweets from the data stream into batches which contain 100 tweets, and selects 10 for hand labeling. Following the best strategy from Table 2 , the algorithm selects 3 tweets that are closest to the SVM hyperplane and puts them into the pool of query tweets, so that the top most are the ones which are closest to the hyperplane, i.e., the most uncertain ones for the classifier. The other 7 tweets are chosen randomly from the batch and put into a separate pool of random tweets. With time, as new tweets arrive, the pools are updated. Whenever the user decides to label some tweets, she is presented with a set of tweets to label, which contains 3 most uncertain ones from the pool of query tweets and 7 random ones from the pool of random tweets. The hand-labeled tweets are placed in the pool of labeled tweets. Periodically, using the initial and man-ually labeled tweets from the pool of labeled tweets, the model is retrained. 5. Active learning sentiment analysis workflow implementation in ClowdFlows
In this section we present the implementation of an active learning sentiment analysis use case on Twitter data in the form of an executable workflow. The use case description is written as a step-by-step report on how the workflow was con-structed. Following the description in this section, it is possible for the reader to construct a fully functioning streaming active learning sentiment analysis process and observe its results.

The aim of the use case is to monitor the Twitter sentiment on a given subject with the possibility to manually label tweets to improve the classification model. For the purpose of this use case we have selected to monitor tweets containing the keyword Snowden , as it is one of the trending keywords during the time of writing this article. We wish to measure the
Twitter sentiment over time regarding Edward Snowden, who leaked details of several top-secret documents to the press. 5.1. Rationale We have decided to implement this stream-mining workflow in the ClowdFlows platform for several reasons.
 The execution of the stream-mining workflow is bottlenecked by the rate of incoming Tweets, which is imposed by the
Twitter API. Therefore any stream mining platform capable of processing tweets at a higher rate than the API X  X  incoming rate would be as efficient as ClowdFlows for this use case. However, the benefit of using ClowdFlows for this task is its extensible user interface which allows for human X  X omputer interaction during the course of the stream mining process. In this use case the user interface is used during runtime for labeling Tweets. The user interface can also be used to modify the workflow by using the intuitive visual programming paradigm interface. Moreover, the ability to share workflows allows us to publish this workflow on the Web and allow single click deployment of it to the users. The users can also augment, extend or modify the workflow to suit their needs without any coding knowledge just by rearranging the workflow components on the canvas. 5.2. Development of necessary components
To construct the workflow we required a stream input widget that can collect tweets based on a query, a sampling widget that should discard any non-English tweets, a widget to perform sentiment analysis on tweets, a stream splitter to split the stream of tweets into a stream of positive and a stream of negative tweets, and three types of visualization widgets to display the line chart of the sentiment over time, a word cloud of positive or negative tweets, and the latest tweets. 5.2.1. Streaming input, filtering, and visualizations
To consume the incoming stream we implemented a widget that connects to Twitter via the Twitter API. accepts several parameters: the search query, by which it filters the incoming tweets, the geographical location (optional), which filters tweets based on location, and the credentials for the Twitter API. The widget works both in a streaming and non-streaming environment. Whenever the widget is executed it will fetch the latest results of the search query. For streaming workflows, the internal memory of the widget holds the ID of the latest tweet, which is passed to the Twitter API, so that only the tweets that have not yet been seen are fetched.

Since tweets returned by the Twitter API are annotated with their language, we constructed a widget for filtering tweets based on their language. This widget discards all tweets that are not in English.

A simple widget was implemented that splits the stream of tweets into two streams, based on their sentiment. This was done so that positive and negative tweets could be separately inspected.

To visualize the sentiment we implemented a line chart that displays the volume of all tweets, the volume of positive tweets, the volume of negative tweets, and the difference of positive and negative tweets. The visualization was imple-mented with the HighCharts JavaScript visualization library.
To inspect separate tweets a simple table was implemented where each tweet is colored red or green based on its sen-timent (red for negative and green for positive).

The word cloud visualization was implemented to show most popular words in recent tweets. This visualization is dynamic and changes with the stream. Looking at the word cloud and seeing popular words appearing and unpopular words disappearing is a novel way to inspect data streams in real-time. The visualization was developed with the D3.js JavaScript library ( Bostock, Ogievetsky, &amp; Heer, 2011 ). 5.2.2. Sentiment classification and active learning
To implement sentiment classification and active learning discussed in Section 4 , which was developed in the.NET frame-work, we exposed it as a Web service that provided several operations: classify a set of tweets for a specific workflow, return a set of tweets for manual labeling for a specific workflow, update a model for a specific workflow.

The service keeps track of multiple workflows and builds a model for workflows separately (in order to better conform the models for specific topics and to avoid malicious labeling affecting the models for legitimate users). Whenever the service is queried a unique identifier of the processing component is also passed along to determine which model to use. The Classify a set of tweets operation accepts a set of tweets and an identifier of the processing component at the input.
Upon execution it loads the appropriate model and applies it to the tweets. The loading times of the models were reduced to become shorter than the waiting time required to conform to the rate limit of the Twitter API in order to guarantee the pro-cessing of all the tweets. The operation returns a set of labels for the tweets.

Return a set of tweets for manual labeling is an operation that accepts the unique identifier of the processing component and returns ten tweets for manual labeling for that specific model. The tweets are then deleted from its pool of query tweets.
The Update model operation accepts a set of labeled tweets and a unique identifier of the processing component to update the model. The updating of a model takes several minutes so special care was taken in order to only update models when really necessary.

The functions were implemented into a workflow processing component in the following way: we have developed a streaming workflow component that receives a list of tweets at the input. These tweets are provided by the Twitter API usu-sentiment labels that are returned from the Web service are appended to the tweets which are sent to the visualization wid-gets in the workflow. The active learning workflow component also has a special view that functions as an interactive visu-alization. This view is accessible the same way as other visualizations of the workflow (by special URLs). Whenever this view is accessed the Web service is polled for tweets that require manual labeling. If there are no query tweets in the pool, a friendly message is displayed to the user, prompting her to come back later. If there are query tweets in the pool they are displayed to the user along with a simple form that can be used to manually label the tweets either as positive, negative, or neutral. When the user labels the tweets and clicks the Submit labels button, the labeled tweets are saved into the internal memory of the active learning sentiment analysis component. The Update model operation is invoked once a day for every streaming workflow that has an active learning widget with new labeled tweets. 5.3. Constructing the workflow
The workflow was constructed using the ClowdFlows graphical user interface. Widgets were selected from the widget repository and added to the canvas and connected as shown in Fig. 3 .
 Parameters were set after the workflow was constructed. Parameters of a widget are set by double clicking the widget.
Twitter API credentials and the search query were entered as parameters for the Twitter widget. The language code en was entered as a parameter of the Filter tweets by language widget. We have also added three sliding window widgets with the size 500 (entered as parameter) to the workflow. This is done because the visualization widgets that display tweets and word clouds only display the last data that was received as an input for these widgets. By setting the size of the window to 500 the word cloud will always consist of the words of most recent 500 tweets.

The workflow was saved by clicking the save button in the toolbar. We have also marked the workflow as public so that the workflow can be viewed and copied by other people. The URL of the workflow is http://clowdflows.org/workflow/1041/ .
We have then navigated to the workflows page ( http://clowdflows.org/your-workflows/ ) and clicked the button  X  X  X tart stream mining X  X  next to our saved workflow. By doing this we have instructed the platform to start executing the workflow with the stream mining daemon. A special Web page was created where detailed information about the stream mining pro-cess is displayed. This page also contains links to visualization pages that were generated by the widgets. The stream mining process was left running from the 14th of June until the 10th of July 2013. 5.4. Monitoring the results
We have put several stream visualization widgets in the workflow which allowed us to inspect the results during the pro-cess of stream mining. ClowdFlows has generated a Web page for each stream visualization widget, which can be viewed by anybody since the workflow is public.

The Sentiment graph visualization displaying the line chart of volumes of tweets, volumes of positive tweets, negative vol-ume of negative tweets and the difference of positive and negative sentiment is available at http://clowdflows.org/streams/ data/4/9056/ and is shown in Fig. 4 . By looking at this visualization we can see that the sentiment in the tweets mentioning
Snowden is generally more positive than negative. We can observe several spikes in the volume which correspond to the times when news articles regarding this subject were published. On June 23rd, news of Edward Snowden X  X  departure from
Hong Kong and arrival in Moscow was published. On the first of July Edward Snowden released a statement on the Wikileaks website and lots of news reports focused on possible countries that could offer asylum to Edward Snowden.
The word cloud visualization of negative tweets is available at http://clowdflows.org/streams/data/4/9065/ and is shown in Fig. 5 . This visualization helps put the stream into another perspective and can display changing trends in real-time. When the word cloud is opened in the browser and the stream mining process is active the words change positions and sizes cor-responding to their occurrences in the tweets. Links to the visualizations of other stream visualization widgets are also pres-ent on the two provided visualization pages.

The workflow presented in this use case is general and reusable. The query chosen for monitoring was arbitrary and can be trivially changed. This type of workflow could also be used for monitoring sentiment on other subjects, such as monitor-ing the Twitter sentiment of political candidates during an election, or monitoring the sentiment of financial tweets with stock symbols as queries. 5.5. Labeling the tweets
Similar to stream visualization widgets the Active learning sentiment analysis widget provides a special URL that can be accessed by human annotators. Propagating this link is an easy way to crowdsource labeling of tweets.
 The labeling interface for this use case is available at http://clowdflows.org/streams/data/16/12326/ and is shown in the button Submit annotations the labeled tweets are saved into the widget X  X  internal memory. These tweets are accessed and sent to the sentiment analysis Web service once a day, if there are any new labeled tweets on that particular day. 6. Conclusion and further work
We have implemented an active learning scenario for sentiment analysis on Twitter data in a cloud-based data mining platform. In order to do so we adapted the platform to work with data streams by use of two mechanisms: widget memory and the halting mechanism.

We have developed a Web service that utilizes the Support Vector Machine algorithm to build and update sentiment analysis models. The service also applies the models on unlabeled tweets and determines which tweets require manual labeling by the user. We have developed workflow components that utilize this Web service in order to provide an intuitive interface for labeling tweets and setting up new active learning sentiment analysis scenarios from scratch without the need of programming or installing complex software. For each active learning workflow a special Web page is created where tweets can be labeled. By propagating the address of this Web page, crowdsourcing and collaborative knowledge discovery can be utilized to label vast amounts of tweets.

In future work we wish to implement several different strategies for selecting the tweets suitable for labeling and to allow the user to select the most appropriate one. We also wish to allow more control over the generation of the initial models and a richer selection of initially labeled datasets. In the current version of our software, we assume sentiment analysis to be a two class classification problem and classify tweets only as positive or negative, in order to enable simple and efficient cal-culations in real time. But, tweets can also be neutral, and our current implementation of the software does not allow 3 class future work we plan to adapt and implement this method for inclusion in ClowdFlows.

The source code of the platform is released under an open source licence (GPL) and can be obtained at http://github.com/ janezkranjc/clowdflows .
 Acknowledgements This workwas supportedinpart by the EuropeanCommission FP7FET-Openproject FOC(Forecasting financialcrises, Grant
No. 255987), the FP7 European Commission project MUSE (Machine understanding for interactive storytelling, grant agree-ment no: 296703), the project ConCreTe, which acknowledges the financial support of the Future and Emerging Technologies (FET) programme within the Seventh Framework Programme for Research of the European Commission, under FET Grant No. 611733, and by the Slovenian Research Agency through the research program Knowledge Technologies under Grant P2-0103. The research was also supported by Ad Futura Programme of the Slovenian Human Resources and Scholarship Fund. References
