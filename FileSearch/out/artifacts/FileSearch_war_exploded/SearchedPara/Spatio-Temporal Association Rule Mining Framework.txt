 In this paper, we present a da ta mining framework to estimate missing or corrupted data in se nsor network applications  X  a frequently occurring phenomenon in this domain. The framework is naturally germane to the spatio-temporal analysis of relational data stream evolution. Our met hod utilizes association rules to capture spatio-temporal correlations in multivariate, dynamically evolving, and unbounded sensor data streams. Existing approaches that tackled this problem do not account for the multi-dimensionality of the node data and their relationship; furthermore they entail simplistic and/or premature assumptions on the temporal and spatial factor s to overcome the complexity of the streaming environment. Our technique, called Mining Autonomously Spatio-Temporal Environmental Rules (MASTER), comprehensively form ulates the problem of mining patterns in sensor data streams, and yet remains provably adaptive to bounded time and space costs while probabilistically assuring a bounded estimation error. Simu lation experiments show MASTER X  X  efficiency in terms of overhead as well as the quality of estimation.
 G.2.2 [ Graph Theory ]: Graph Labeling, Trees G.3 [ Probability and Statistics ]: Statistical Computing, Distribution Functions Algorithms, Performance, Experimentation Spatio-temporal data mining, Sens or databases, Data estimation In recent years, data streams have captured a significant interest in various computing fields spanning a spectrum of problem domains such as sensor networks , remote-sensing image data, and internet traffic. The clear need to explore the inherent data stream trends and patterns in these newl y emerging applications has in turn triggered a substantial attention in the data mining community [10,11]. Additionally, there have been many works aiming at recognizing the stream -mining associated challenges induced by the characteristics of the streaming environment i.e., unbounded data volume and the real-time continuous high-rate data collection and processing. Throughout the works on data streams, it has been established that the traditional multi-pass algorithm methodology is computa tionally inadequate for mining data in streaming applications. Moreover, the need for a compact data representation and incremental storage scheme became highly acclaimed. In this paper, we propose an online spatio-temporal mining framework, which uses the single-scan incremental data processing methodology, to estimate missing or corrupted sensor data streams and to analyze multiple sensor data streams trend evolution. We have reported on our latter application in [9]. Here, we focus on the estimation problem. Though our mining framework can potentially be applied in any data stream application, sensor network m onitoring applications are of particular interest to us. To ela borate, it is important to raise the fact that data corruption and loss are inevitable in sensor networks given the current wireless technology that is susceptible to interferences, signal losses, overl oaded networks, temporary node black-outs, node battery outages, etc. A direct way to try to get around this problem is to send repeated queries attempting to obtain the missing data; however, this approach remains na X ve as it is still not guaranteed to make av ailable the original readings or would at least quicken the power exhaustion of the network. In this paper, we argue that estimating missing or corrupted values is an efficient and power-aware alternative in compensating for the lost sensor information. Besides filling in data gaps, the notion of estimation can be used to derive adaptive in-network data transmission (i.e ., data not communicated if they can be estimated accurately enough). We further argue that data mining, particularly spatio-tempor al mining, conceptually offers competitive advantage over non-mining prediction techniques for the purpose of estimating sensor node values. We adopt the concept of temporal association rules and adapt it to the characteristics of sensor data streams, i.e., real-valued and multivariate node data. Such adoption is non-trivial and requires extensions to the original notion of association rules [7] in addition to requiring appropriate data structures capable of capturing these associations, while providing suitable ground to overcome the challenges of stream-mining. For a review of the related literatu re, see [8,9]. In Section 2, we showcase the formal notion of associ ation rules. In Section 3, we touch on our MASTER-Tree, a resource-bounded data structure from which association rules can be computed. Section 4 presents our iterative estimation algorithm, which not only can be timed-out on command, but also assures a probabilistic estimate error bound. Section 5 illustrates our em pirical evaluation. Section 6 offers the conclusion and points for future work. Since most sensornets are deployed to monitor a physical environment, it shall be suspected that collected data from sensors exhibit intrinsically correlating properties both in terms of time and space as well as the different monitored attributes. An association rule can be a good idealization of the relations between these physical properties m easured by different sensors. As an example, consider the fo llowing observation:  X  X ny time in the early morning hours, when a sensor A reports a temperature between 15 and 20 degree Celsius then a separate sensor B is likely to report a temperature in the range of 18 to 22 Celsius. X  This informally stated  X  X ssociation rule X  can include a complication of additional sens ors and other relating physical parameters as well. Before we formalize our association rule definition, let us assume that each sensor reading is multivariate, and hence all data belong to a vector space of dimension in the order of the monitored attributes. If we further suppose that each attribute admits natural upper a nd lower bounds then the network data lie in a constrained vector space (an Orthotope (i.e., a box) in R where d is the number of attributes). Formally, an association rule can be expressed in the following terms: Note that generically the association rule is an implication i.e., given a set of node facts (antecedent rule part), a different set of node facts is implied (consequent pa rt). The two parts are sperated by a right-pointing arrow (  X  ). The &lt; time-expression &gt; indicates the time clause of the rule. V denotes the constrained vector space that encapsulates all data. sub i ( V ) denotes a particular subspace { M 1 ,..., M j } represents the consequent set of nodes. The left-pointing arrow (  X  ) indicates the data subspace with respect to which its corresponding node particip ates in the rule. As in the traditional association rule para digm, our association rules are qualified in terms of two parameters: (1) the rule support or the joint probability of the antecedent and consequent parts, and (2) the rule confidence or the probability of the consequent part conditioned on the antecedent portion. Both support and confidence need to surpass minimum thresholds to ultimately qualify the rule. The aim of the MASTER-Tree is to serve as a data structure from which association rules of interest can be computed. Evidently, by the data stream processing re quirement mentioned in the motivating paragraphs, our data structure needs to satisfy the compact and incremental properties. Consider a collection c of sensors nodes. An association may potentially contain any subset of nodes from c . Therefore, there exists a bijection between the set of all potential associations of nodes in c and the power set of c . The power set of c can be equivalently represented graphica lly as a binary hypercube of dimension in the order of the cardinality of c i.e., the number of nodes in the collection. Pattern-Trees [6] were proposed in the context of traditional associati on rules. A Pattern-Tree over the items in c can in fact be defined as a spanning tree of the corresponding hypercube over c , and a data counter is defined for each element in the tree allowing the calculation of the support and the confidence parameters of any rule. For our purposes, sensor nodes are not discrete items, but they are coupled with vector subspaces. We need to tailor the Pattern-Tree for such association rule context. Consider the Orthotope V that spans the bounded vector space where any sensor may report. Assume a particular discretization of V into cells (elemental subspaces). Now we associate a da ta counter with every cell in the discretization of V , we dub such grid structure a GS. The idea is to then store at each element of the Pattern-Tree a collection of GSs. At any level in the tree, each GS captures the posterior distribution of the corresponding sensor node conditioned on the set of parent nodes over the co rresponding sequence of parent cells. Though this may conceptua lly seem as an exponentially-growing structure in terms of the tree depth, tree allocation is in practice done cell-wise and adaptively as data points fall in the corresponding cells. Further the collection c is presumed to be cost-bound-proof (more on this shortly). Because data counters are incremental, the tree satisfies an additive property. So if one is obtain a posterior distribution conditioned on subspaces that are not elemental (i.e. cover multiple cells), it is sufficient to additively combine the tree substructures to yield data for the desired subspaces. Sneaking the fact that our forthcoming iterative estimation algorithm will require arbitrary (potentially covering partial cells) subspaces for the missing nodes requires us to make further amendments to our current structure. To capture the in-cell data distribution we store along with the data counter, power sums from which raw sample moments can be computed and in turn data distribution inside any cell. Using such distributions data counts over partial cells can be evaluated using a numerical integration method. In our implem entation, we store power sums up to the 4 th order and we use the Pearson system [12] to approximate the probability density function. Note that the power sums are indeed incremental and so the additive property is still maintained. The moment information allows us to deduce posterior distributions over arbitrary subspaces. However, because our tree model is a downward-directed graph, posterior distributions over arbitrary subspaces can only be obtained from their parent nodes as chosen by the tree. To accommodate for the requirement of the estimation algorithm, we need to readily have every node as child of every combination of parents. To this end, note that the leaf node in any Pattern-Tree is not problematic. Consider an automorphic tree to the fixed Pattern-Tree chosen initially in which the leaf node is distinct from its image in the original tree. Merging such two trees yields a graph in which the posterior distribution of the two distinct leaf nodes can be computed independently of the di scretization scheme. Iteratively, we invoke the autmorphic operator on each distinct node and merge all tree graphs. Each tree automorphism is chosen so that the longest path from the root to the leaf contains in ascending order the nodes that closest to the leaf. This will have good implication from the standpoint of the complexity of the estimation algorithm. To be able to capture association rules over any desired time expression, we devise a time basis of elemental cycles. We define a time expression as any union com position of two or more times from the basis. We store a snapshot of the MASTER-Tree for every basic period (element of the time basis). Because the MASTER-Tree is additive, data over any time period may be obtained by combining the snapshots from its composing basic periods. The inherent assumption of this temporal scheme is that network data exhibit repeatable (cyclic) patterns. To complete the MASTER-Tree construction, note that the tree theoretically admits an exponentia l complexity in terms of the cardinality of the node collection. We need to assure good scalability in terms of the network size. To do this, we define a pruning algorithm by the aid of which we optimize the time and space complexity of the MASTER-Tree. The algorithm accepts user-defined bounds for the storage and data-update time and yields a network clustering c onfiguration. The MASTER-Tree (including all of its snapshots) is then constructed separately for each node cluster. The pruning algorithm follows a bottom-up hierarchical clustering and terminates when any further re-clustering breaks either one of the user bounds. The optimizing clustering algorithm is not conceptually bound to any particular similarity metric. Note that the storage bound or tree compactness is assured by the fact that V admits a finite discretization and that each cell in the discretization has a finite consumption. For full theoretical treatment of th is algorithm, see [8]. The task of the estimation pro cedure is to autonomously and efficiently explore the rule space to (1) determine the relevant time period over which data shall be considered for rule evaluation, (2) determine the set of sensor nodes and their respective subspaces that cons titute the rule (where the consequent node is the missi ng node), and (3) compute the estimate of the missing node as its expected value over its consequent subspace. The computed rule is evidently more interesting if its consequent missing node subspace has a  X  X mall span X  as it would in turn suppre ss the variance of the estimate. The search over the rule space needs to be properly orchestrated so as our estimation procedure is both effective and efficient. We propose an iterative estimation me thod in which the estimate is adjusted progressively. The fine-tuning of the estimate can be carried on until the user-set erro r margin is met or until the estimation execution time is up. This way anytime the control process decides to time out the mining (when the user time bound is reached), we will always have some  X  X eady-to-graduate X  estimate. Since a data round may have several missing nodes each having several missing attribut es, we shall run different estimation threads, each estimating one particular missing attribute of one particular mi ssing node. That way we guarantee that the estimation time is fairly allocated amongst all estimations while each estimation thread progressively fine-tunes its estimate. Now that we reduced the estim ation method to estimating one particular missing attribute only, any estimation-sought rule is only required to imply a singl eton consequent node whose subspace shall be viewed and constrained with the respect to the missing attribute in question. The algorithm starts by identifying the most relevant temporal period for the current estimation problem. This is fixed to the elemental period that contains the current data time stamp. The algorithm then obtains the prior distribution of the missing attribute to be estimated from the MASTER -Tree . The algorithm then attempts to contain the stretch of such distribution by ignoring data in the two end margins while satisfying the support and confidence thresholds. This rule can be viewed as  X   X  M where M is the missing node (i.e. nothing implies M ). If the last step fails to satisfactorily constrain the span of M then relevant information from other streams need s to be acquired to refine the distribution of M . Meanwhile an estimate can be backed up from the rule just obtained, and in such case, the consequent subspace of M has span higher than the a llowed minimum span threshold (error bound). In reference to this parameter relaxation, such rule will be referred to as a relaxe d rule. The algorithm chooses one new antecedent node to imply the posterior distribution of M  X  X  missing attribute. The node closes t to the missing node is chosen as the new additional antecedent node. Such new node can be fetched in a constant time from our tree model. The initial relevant subspace for the anteced ent node is chosen as the one that contains the current reading reported by the added node. If enough support cannot be found, the relevant subspace is augmented iteratively (cell by cell) until the support condition is met. In each iteration, the cell whose centroid is closed to the current reading of the new node is added. After assuring enough rule support , the same principle of trying to constrain the posterior distribution of the missi ng attribute is applied. The new support and confidence can be incrementally updated with every change of the relevant or consequent subspaces. The integration of a new antecedent node is repeated until the estimation procedure reaches one of the three possible conditions: (1) a rule meeting the minimum support , confidence , and a consequent subspace span is f ound, (2) the mining is timed-out and a relaxed rule is found, or (3) no more nodes to add to the prior node set (antecedent rule part) and a relaxed rule is obtained. The procedure then returns the estimate value as the final expected value computed over the consequent subspace. We ran simulation expe riments to compare our method with the recent works on the estimation of missing data streams, namely FARM [2], WARM [3], SPIRIT [4], and TinyDB [5]. It was reported in [2] that [2-4] have performed better than the standard regressive statistical estimati on approaches; hence we do not include those methods in our comparison. To provide a common comparison ground, we let the compared methods view a multidimensional node as virtually separate nodes each sampling data from one-single attribute str eam. To assess the contributions of our temporal mining, and multiv ariate node rules, we also ran two additional reduced versions of MASTER where in one we turned off the temporal mining and in the other, we only looked at single-dimensional data. We collected datasets from the real-life NASA deployed sensor network [1], which monitored the attributes of temperature , humidity , and flux in several locations within the Botanical gardens in San Marino, CA. In all experiments, we simulated missing data every 30 (plus a random noise) sensor reading rounds. Also a missing value may be missing for few consecutive rounds. All experiments were run on 2.49 GHz PC with 3.5 GB of RAM memory running a 2002 version of Windows XP Professional. To test the significance and consistency of our results, we collected four datasets, DS1-DS4, during 4 different time periods of variable lengths: DS1 contai ns samples from a 3-day period, DS2 includes samples from a 1-week period, DS3 a 4-week period, and DS4 a 1-year peri od. The NASA network sampled data every 5-minutes. We compar ed the accuracy of all methods, which was assessed in terms of the Mean Absolute Error (MAE). In addition to the comparative accuracy experiments, we ran extensive accuracy/overhead sensitivity and network-size scalability experiments not reported here due to lack of space. Such experiments affirm an efficient, bounded, and linearly scalable time/space overhead. Again due to space limitation, we only show the accuracy in estimating the temperature va lues. Analogous results were observed for other missing attributes. Table 1 shows the MAE of each method over each of the 4 da tasets considered. MASTER X  X  defaults were set to r ealistic averages (i.e., minSup =1%, minConf= 90%, and 4 nodes per cluster). The defaults of the candidates were chosen either from recommendations in the literature or by extensive experimentation to pick the best parameters. MASTER and its tw o derivatives had consistently the lowest and thus the best MAE. By observing the MAE records in the 4 th and 5 th rows of Table 1 (i.e., MASTER with non-temporal mining (NT) and MASTER with single dimensional data (SD)), it is evident that the tem poral mining contributes more to the accuracy of estimation than does information across attributes. MASTER X  X  default temporal pe riods consisted of all data snapshots over each 2-hour period (beginning from 12am) of every weather season. The increase in MASTER X  X  error in terms of the data set is due to the increasing number of records from the 1 to the 4 th dataset. However, note that we can, for instance, lower the error over the 4 th dataset to about the same error as the 3 dataset by considering additional temporal snapshots over each month of the year. By this same principle, the error can be lowered as desired by considering more snapshots as appropriate. This paper proposed a technique for estimating missing sensor values. A comprehensive temporal association rule tailored for the context of multidimensional sensor network data was defined. The method is able to capture te mporal sensor rules while coping with the complexity of the streaming environment. The iterative nature of the estimation procedure makes it possible to limit the estimation time while the new notion of association rules naturally defines a probabilistic bound on the error. Simulation experiments showed effectivene ss of our approach by assuring QoS in terms of estimate quality. We plan to test our framework in other applications, namely data anomaly detection, in-network sampling, and adaptive network deployment. [1] NASA/JPL Sensor Webs Project, [2] L. Gruenwald, H. Chok, M. Aboukhamis, Using Data [3] Mihail Halatchev, Le Gruenwal d; Estimating Missing Values [4] S. Papadimitriou, J. Sun, C. Faloutsos. Streaming Pattern [5] S. R. Madden, M. J. Franklin , J. M. Hellerstein, W. hong. [6] C. Giannella, J. Han, J. Pei, X. Yan, and P. Yu. in H. [7] R. Agrawal; T. Imielinski; A. Swami: Mining Association [8] H. Chok.  X  X patio-Temporal Association Rule Mining [9] H. Chok, L. Gruenwald. To appear in the 13 th Int X  X  Database [10] L. Cohen, G. Avrahami-Bakis h, M. Last, A. Kandel, O. [11] B. Saha, M. Lazarescu, S. Venkatesh. Infrequent Item [12] W. P. Elderton, N. L. Johns on.  X  X ystems of Frequency 
