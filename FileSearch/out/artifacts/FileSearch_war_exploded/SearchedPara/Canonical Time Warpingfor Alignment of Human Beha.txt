 poral alignment of human behavior is a fundamental step in many applications such as recognition [1], temporal segmentation [2] and synthesis of human motion [3]. For instance consider Fig. 1a which shows one subject walking with varying speed and different styles and Fig. 1b which shows two subjects reading the same text.
 Previous work on alignment of human motion has been addressed mostly in the context of recog-Markov models [4, 5, 6], weighted principal component analysis [7], independent component anal-and normalizing sets of time series.
 Figure 1: Temporal alignment of human behavior. (a) One person walking in normal pose, slow paper proposes canonical time warping (CTW) for accurate spatio-temporal alignment between two spatial correlation between two behavioral samples coming from two subjects. To accommodate for CCA as a measure of spatial alignment. To allow temporal changes CTW incorporates DTW. CTW extends DTW by adding a feature weighting mechanism that is able to align signals of different dimensionality. CTW also extends CCA by incorporating time warping and allowing local spatial transformations.
 warping and canonical correlation analysis. Section 3 describes the new CTW algorithm. Section 4 extends CTW to take into account local transformations. Section 5 provides experimental results. This section describes previous work on canonical correlation analysis and dynamic time warping. 2.1 Canonical correlation analysis a combination of the original variables that minimizes: ( v x X , v several component analysis methods and a review of numerical techniques to efficiently solve the generalized eigenvalue problems.
 In computer vision, CCA has been used for matching sets of images in problems such as activity proposed an extension of CCA with parameterized warping functions to align protein expressions. deal with feature weighting. 2.2 Dynamic time warping dynamic time warping [14] is a technique to optimally align the samples of X and Y such that the following sum-of-squares cost is minimized: where m is the number of indexes (or steps) needed to align both signals. The correspondence p p This section describes the energy function and optimization strategies for CTW. 3.1 Energy function for CTW Eq. 2 can be rewritten as: to align X and Y . In Eq. 4 the matrices W x and W y encode the alignment path. For instance, w convenience, we denote, D x = W T x W x , D y = W T y W y and W = W T x W y . Observe that Eq. (features), while DTW applies binary transformations to the columns (time).
 (as CCA) to the least-squares form of DTW (Eq. 4). Moreover, this transformation allows aligning DTW and CCA by minimizing: jecting the sequences into the same coordinate system. W x and W y warp the signal in time to achieve optimum temporal alignment. Similar to CCA, to make CTW invariant to translation, rota-V is the main contribution of this paper. CTW is a direct and clean extension of CCA and DTW to align two signals X and Y in space and time. It extends previous work on CCA by adding temporal alignment and on DTW by allowing a feature selection and dimensionality reduction mechanism for aligning signals of different dimensions. 3.2 Optimization for CTW Algorithm 1 : Canonical Time Warping input : X , Y output : V x , V y , W x , W y begin end DTW, and optimally computing the spatial projections using CCA. These steps monotonically de-crease J ctw and since the function is bounded below it will converge to a critical point. generalized eigenvalue problem is solved by regularizing the covariance matrices adding a scaled the algorithm to converge when the difference between two consecutive values of J ctw is small. have been shown to provide better performance [3, 24, 25]. This section extends CTW by allowing multiple local spatial deformations. 4.1 Energy function for LCTW linear combination of k x or k y bases. Let be V x = [ V x 1 T ,  X  X  X  , V x k [ V warping by minimizing: =
X weight) of the c th x basis for the i th frame of X (similarly for r y jc 1 y ) for each frame. The last two regularization terms, F x order differential operators of r x c Observe that J ctw is a special case of J lctw when k x = k y = 1 . 4.2 Optimization for LCTW Algorithm 2 : Local Canonical Time Warping input : X , Y output : W x , W y , V x , V y , R x , R y begin end being the identity matrix the starting value for V x c The main difference between the alternating scheme of Alg. 1 and Alg. 2 is that the alternation off between time warping and spatial transformation, we propose a stochastic selection process. " p w  X  p v 0 This section demonstrates the benefits of CTW and LCTW against state-of-the-art DTW approaches facial expressions made by two people. 5.1 Synthetic data in time) to evaluate the performance of CTW and LCTW. The first two spatial dimensions and the or (1  X  n y ) extra row to X and Y respectively, with zero-mean Gaussian noise (see Fig. 3a-b). We compared the performance of CTW and LCTW against three other methods: (i) dynamic time warping (DTW) [14], (ii) derivative dynamic time warping (DDTW) [15] and (iii) iterative time warping (IMW) [3]. Recall that in the case of synthetic data we know the ground truth alignment matrix W truth = M x M T y . The error between the ground truth and a given alignment W alg is computed by the area enclosed between both paths (see Fig. 3g).
 Fig. 3c-f show the spatial warping estimated by each algorithm. DDTW (Fig. 3c) cannot deal with (Fig. 3d) warps one sequence towards the other by translating and re-scaling each frame in each can be observed CTW and LCTW obtain the best performance. IMW has more parameters ( O ( dn ) ) CTW and LCTW have a feature selection mechanism which effectively cancels the third dimension. [  X  . 002 ,  X  . 001 ,  X  . 071] T . 5.2 Motion capture data In the second experiment we apply CTW and LCTW to align human motion with similar behavior. The motion capture data is taken from the CMU-Multimodal Activity Database [26]. We selected a pair of sub-sequences from subject 1 and subject 3 cooking brownies. Typically, each sequence LCTW are manually set to k x = 3 ,k y = 3 and p w = . 5 ,p v = . 3 ,p r = . 2 . warping is computed by (c) derivative dynamic time warping (DDTW), (d) iterative time warping (IMW), (e) canonical time warping (CTW) and (f) local canonical time warping (LCTW). The en-ergy function and order of optimizing the parameters for CTW and LCTW are shown in the top right (h) Mean and variance of the alignment error. Figure 4: Example of motion capture data alignment. (a) PCA. (b) CTW. (c) LCTW. (d) Alignment path. (e) Motion capture data. 1 st row subject one, rest of the rows aligned subject two. components for both sequences can be seen in Fig. 4a. CTW and LCTW project the sequences in a low dimensional space that maximizes the correlation (Fig. 4b-c). Fig. 4d shows the alignment third subject for DTW, CTW and LCTW. Observe that CTW and LCTW achieve better temporal alignment. 5.3 Facial expression data In this experiment we tested the ability of CTW and LCTW to align facial expressions. We took 29 subjects from the RU-FACS database [27] which consists of interviews with men and women of varying ethnicity. The action units (AUs) in this database have been manually coded, and we For the alignment of AU12 we only used 18 landmarks corresponding to the outline of the mouth, so for each frame we have a vector ( R 36  X  1 ) with ( x,y ) coordinates.
 We took subject 14 and 30 and ran CTW and LCTW on the segments where the AU12 was coded. with CTW and LCTW has better alignment than DTW in Fig. 5a. Fig. 5d shows the position of alignment paths found by CTW and LCTW are closer to the manually labeled peak than the ones found by DTW. This shows that CTW and LCTW provide better alignment because the manually alignment. Figure 5: Example of facial expression alignment. (a) PCA. (b) CTW. (c) LCTW. (d) Alignment path. (e) Frames from an AU12 event. The AU peaks are indicated by arrows. In this paper we proposed CTW and LCTW for spatio-temporal alignment of time series. CTW integrates the benefits of DTW and CCA into a clean and simple formulation. CTW extends DTW by CTW extends CCA by adding temporal alignment and allowing temporal local projections. We illustrated the benefits of CTW for alignment of motion capture data and facial expressions. This material is based upon work partially supported by the National Science Foundation under Grant No. EEC-0540865.
