 sometimes converges too slowly.
 Given priors on models M model M probability. By Bayes X  rule this is arg max of (BMA). The resulting distribution p bma ( x n ) = P quential setting, the probability of a data sequence x n := x accumulated log loss that is incurred if we sequentially pre dict the x Here the i th term represents the loss incurred when predicting x which turns out to be equal to the posterior average: p bma ( x length of p model indices, the difference between  X  log p bma ( x n ) =  X  log( P sideration. However, it is often possible to combine p smaller codelength than p models, say M because M how to improve them. Thus M p Ideally we should predict the initial 100 000 outcomes using p only starts to behave like p codelength of p making better predictions of those outcomes: since at n = 100 000 , p The general pattern that first one model is better and then another occurs widely, both on real-world data and in theoretical set-tings. We argue that failure to take this effect into account leads to the suboptimal rate of convergence achieved by Bayes fac-tor model selection and related methods.
 We have developed an alternative method to combine distributions p single distribution p sw , which we call the switch-distribution , defined in Section 2.
 Figure 1 shows that p sw behaves like p initially, but in contrast to p bma it starts to mimic p starts making better predictions; it essen-of both theorems. Preliminaries Suppose X  X  = ( X . . . , x X prediction strategy should issue a conditional density p ( X density p ( X or the counting measure (if X is countable). In the latter case p ( X function. It is natural to define the joint density p ( x m | x n ) = p ( x marginal distribution for X m we impose the natural requirement that for any k  X  Z + and any fixed event A probability P ( A observed data x n from a potentially infinite list of candidate models M parametric models , which are sets { p ( d the model M We associate each model M meta-strategy based on the prediction strategies in M example AIC and LOO,  X  p out with a prior w on  X  When  X  p  X  p fines a prediction strategy  X  p an estimator. From now on we sometimes call the distribution s induced by  X  p model M = { p Bernoulli random variables with P likelihood (ML) estimator based on the past, i.e. using  X   X  ( x n ) = n  X  1 P n x  X  p The Switch-Distribution Suppose p case where the list is finite.) We first define a family Q = { q defined as sizes, called switch-points , at which to switch between them. For s = (( t  X  define t from context, e.g. we write t to simplify notation; we always take t mixture of the elements of Q according to a prior  X  on S : marginal distribution for X n is given by paper it will only be applied to combine prediction strategi es  X  p past observations x n . Formally, K  X  the consistency of standard Bayes factor model selection. Bayes factor model selection is consistent if for all k, k  X  6 = k ,  X  P singular, that is, if there exists a measurable set A  X  X   X  such that  X  P of that, for all k  X  6 = k and all x n  X  X  X  , the distributions  X  P mutually singular. For example, if X if singularity is automatically implied by ordinary mutual si ngularity of  X  P Let E the set of all possible extensions of s to more switch-points. Let  X  p strategies with respective parameter spaces  X  of the corresponding switch-distribution.
  X  The requirement that c  X  ( s )  X   X  ( E where  X  for some 0  X   X  &lt; 1 . In this case c =  X / (1  X   X  ) . Suppose X estimator  X  P relative to P  X  as equal to P  X  ( X prediction strategies  X  p , For a union of parametric models M = S the switch-distribution defined relative to estimators  X  P prior  X  in (4) is of the form (7), and satisfies Thus,  X  or exponentially (as required for Theorem 1);  X  we could set  X  example, if the models M bounded from below and above by some positive constants.
 a function of the sample size, i.e. rounding up to the nearest integer.  X  p  X  p M 1 , M 2 , . . . sometimes happen that, for some P  X  , some k , some n  X  &gt; n , R and in cases where, uniformly for all k , sup expect that the sup Theorem 2. Define P sw for some model class M =  X  nh ( n ) / (log n ) 2  X  X  X  . Then els M in the parametric setting where P  X   X  M not clear whether similar techniques can be used to bound the individual risk. Algorithm 1 sequentially computes the posterior probabili ty on predictors p  X  is a prior of the form in (7), and  X  imposes a geometric distribution for  X  n . We do require slightly more space to cope with  X  Algorithm 1 S WITCH ( x N ) consistency in this case as well. If  X  Proof of Theorem 1. Let U select an incorrect model. It is sufficient to show that To see this, suppose the theorem is false. Then there exists a  X   X   X  (6) does not hold for any  X   X   X   X  . But then by definition of  X  P Now let A = { s  X  S : k We observe that for each s  X   X  U of switch-points and predictors on the first n + 1 outcomes (this implies that K or s  X   X  E s . Therefore Defining the mixture r ( x n ) = P Using (13) and the fact that P mutually singular with  X  P implies mutual singularity of Q event such that Q B of distributions that are mutually singular with P R Proof of Theorem 2. We will show that for every  X  &gt; 1 , where  X  Let  X  is minimax optimal, i.e. it achieves the infimum in (10). If su ch a  X  t than q this q a logarithmic number m  X  1 of switch-points: m  X  1 &lt; log c &gt; 0 , uniformly for all n , x n  X  X  n ,  X  log p sw ( x n ) =  X  log X applying (8), and then (16), and then (8) again, we find that
X For i appearing in the second sum, with t Summing over i , we get P m (17), it follows that P n requirement of Theorem 2 that nh ( n ) / (log n ) 2  X  X  X  .

