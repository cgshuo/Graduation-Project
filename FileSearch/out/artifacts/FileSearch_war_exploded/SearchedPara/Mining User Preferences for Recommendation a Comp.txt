 Recent years have witnessed the unprecedented prevalence and significance of building recommender systems, which aim to recommend proper items for users with respect to their personal preferences. On the Internet, there are a large number of items with ratings of particular users such as books, movies and food. The ratings could effectively reflect user preferences on the items, and become important resources to mine user preferences and implement recommendations. two commonly used approaches for recommendation. CF analyzes the similarity of users X  preferences or items and recommends items for active users, using data rated by a great quantity of users. However, since it does not directly analyze the content of items, it may suffer from the so called cold start problem, which makes it fail to recommend items that have not been previously rated in the community [1]. Meanwhile, the CBR approach focuses on analyzing the simi-larity between item contents and user preferences, so it can process new items without user ratings. Traditional CBR method is generally divided into three steps: Firstly, it confirms item representation through extracting content fea-tures. Secondly, it mines the user preference and represents the preference with features by leveraging the past rating information. Finally, it recommends the most similar item set to the user, by comparing the user preference representa-tion and the representation of the new item [2]. However, the CBR approaches always excessively rely on the results of content analysis, which cannot take full advantage of the explicit rating data.
 ploiting the competition perspective from game theory, which sufficiently makes use of both the content of items and user ratings. Unlike previous works, which each level rating is considered as independent category, this paper discusses to mine user preferences with competition relationship of items rated different rat-ings. It is assumed that each item consists of several content features. Ratings on items are used to estimate a unique user preference value for each feature by Bradley-Terry model. The rating for a new item can therefore be predicted by user preference values of all features in the item. The basic idea is: a user U gives a higher rating to item A than that of B for the reason that A is better than B in the competition of U X  X  preferences. If A and B are represented by textual features, then it is supposed that features of A have overall stronger competitiveness than those of B. Therefore, the competition between two items with various ratings is decomposed into competitions among content features of two items. The user preference value of each feature could be estimated, which is obtained by competitions for several times. Thus, when a new text C turns up, the user preference value for C can be calculated through summing up the value of each feature in C. In this way, this model can integrate both user ratings and the content of items for mining user preferences.
 related work. The user preferences mining approach based on pairwise compar-isons is presented in Section 3. Section 4 reports experiments and results. Finally, Section 5 summarizes our conclusions and discusses directions of future work. Generally, the related works of this paper can be grouped into three categories. The first is the CBR. CBR algorithms usually apply vector space model (VSM) to represent items. Recommendation results are normally obtained by machine learning algorithms, such as the nearest neighbor method (find K rated items most similar with the new item, use the user preference of K items to judge the preference of the new item), Rocchio algorithm (obtain user preference vector to features from liked and disliked items, calculate the similarity of the vector and the feature value vector of the new item as user preference of the new item), the decision tree algorithm (build the tree structure to use its branch to classify the new item with features), the linear classifier algorithm (find a plane in the higher dimensional space to separate class points) and the Naive Bayes algorithm (calculate probabilities of features in all categories to predict the new item). But these methods are too dependent to the content, with rating information as an auxiliary tool.
 to memory-based and model-based algorithms. The user-based and item-based algorithms are common memory-based methods. The user-based algorithm cal-culates the similarity between the active user and other users, then recommends favorite items of users who are very similar to the active user [3]. The item-based algorithm analyzes items rated by the active user, and recommends items that are similar to ones that he rated [4]. In order to avoid overfitting phe-nomenon from the item-based algorithm, Lemire and Maclachlan [5] proposed a slope one algorithm. In terms of model-based algorithms, to reduce the dimen-sion of the user-item-rating matrix, latent semantic models such as probabilistic latent semantic analysis, Latent Dirichlet allocation, the Single Value Decom-position (SVD) algorithm and its follow-up improvement algorithms appeared [6-11]. Yang et al [12] studied user choice behavior in a series of items under the background of CF, obtaining better recommendation effect. No matter what kind of CF algorithms, there is always the cold start problem.
 ommendation results, and make feature augmentation, such as using content features to offset users X  simple ratings, or training users X  ages and genres of movies in a classifier [13-16], and so on. Although there are many combination methods, they are not effective in a specific issue all the time.
 features from ratings data of items, basing on a pairwise comparison model. Preference values of features are then used to rate new items. 3.1 Motivation Discussion Given a user u and an item set I = f 1, 2, ... , I g , r ( u , i ) denotes the rating for an item i 2 I by u. To solve the problem of rating a new item i a = 2 I , the user preference value of u on i is introduced, denoted by p ( u , i ). For any two items i similar with p ( u , i B ). The higher the rating is, the stronger the preference is, and vice versa. For example, items with rating 5 are supposed to have similar preferences, and the preference for the item rated with 5 is stronger than the one for the item rated with 4.
 Considering an item consists of some content features, it is therefore assumed that preference value of u on i correspondingly consists of preference values of u on features in i . Given a feature set F = f 1, 2, ... , F g for all items, if i consists of feature subset F i F and each feature f i 2 F i is independent, p ( u , i ) is determined by combination of f p ( u , f i ) g . So, for a new item i a , its preference value can be calculated by f p ( u , f ia ) g .
 estimated. Second, p ( u , i ) of an item i is calculated. Finally, r ( u , i ) is acquired basing on p ( u , i ). The details are given in 3.2, where Bradley-Terry model is used for p ( u , f ) estimation and p ( u , i ) calculation. The nearest neighbor method (KNN) is used to get r ( u , i ) from p ( u , i ). 3.2 Model Description Bradley-Terry model is first given for p ( u , f ) estimation and p ( u , i ) calculation, and then KNN is used for getting r ( u , i ) from p ( u , i ).
 turn, items have matches on the level of user interest, resulting in the survival of the fittest. There is obvious competitive relationship among them. For the comparison between things, the Bradley-Terry (BT) model [17] is a popular competitive relationship probability model. This model is used to measure the ability of competitive object in the pairwise comparison. It assumes that the contestant X  X  win rate is proportional to his own competitiveness. And it trains and quantifies the capacity of the contestant basing on the assumption. The competitor X  X  winning probability is described by the original BT model in the pairwise comparison. It is shown in Formula (1).
 where o refers to overall competition level of the individual o . Different from an individual, the content of a item consists of multiple features. So this article makes use of the generalized BT model for multi-player team competition. It is illustrated by Formula (2).
 Note one feature can appear in multiple items here. Through competitions among items for many times, the competitiveness of each feature may be ultimately determined, that is, the user preference value.
 two items with various ratings can play a game. The content describing the item can be analogous to a team participating in a competition, and features acted like players. The content of the item that is higher rated by the user is the winning team in the game. During the competitions, the user preference values of features in the winning team increase, meanwhile the values of features in the losing team correspondingly reduce. In the end, through iterative calculation of all sessions, user preference values of features settle out.
 denote user preference values of n features with parameters p ( u ; f 1 ), p ( u ; f 2 ), items in a competition. If an item i consists of M features, p ( u , i ) could be computed by Formula (3). In other words, the preference value of each item is the product of features X  values, following the assumption of the generalized BT model [18]. The N in-dependent match results among contents, R 1 , R 2 , ..., R N , are get from the corpus. So the probability of the game j result can be written as Formula (4). The objective of the model is to maximize the probability of these games X  results, and the objective function L is shown by Formula (5).
 p ( u ; f w ) could be iteratively calculated, by setting the feature w as the only variable in one iteration. Thus Formula (4) could be rewritten as Formula (6). as constants. So the logarithm of L is shown in Formula (7). approximation function m at an initial point p 0 ( u ; f ) to make m ( p 0 ( u ; f )) = point to be computed is found, at which the approximation function value is max. As p ( u ; f w ) either occurs in winners or losers, we set p ( u ; f w ) as x , and omit constants to get the minorizing function (8) W N w is the sum of occurrence number of w in all winning teams. g ( x ) is the total preference value of all teams in the game. With the thought that maximizes m ( x ), the iterative formula (9) of p ( u ; f w ) is All of the preference values are confirmed when L is maximized.
 i ) of the new item i a is calculated by Formula (3). If f ia = 2 F , p ( u , f ia ) is set as 1. According to our first assumption, p ( u , i a ) can predict r ( u , i a ), which could be achieved by KNN easily. It is to find k items I k I of which f p ( u , i ) is a scale value, the absolute value of difference between p ( u , i A ) and p ( u , i B ) is used as the similarity measure. So the similarity formula (10) is Then r ( u , i a ) is set as the most frequent r ( u , i k ) in I k . Firstly, prediction precision based on CBR and CF recommendation algorithms are compared with our method on two movie datasets. Secondly, the relationship between competitive scales and recommendation effect is discussed. 4.1 Recommendation Effect Experiments The algorithms are evaluated on two datasets, MovieLens and Netflix [20-21], which are the most famous datasets in the field of recommender system. The MovieLens dataset is the real data crawled by the MovieLens movie recom-mender system ( http://movielens.umn.edu ). It contains rating data scored by numbers from 1 to 5 which contains 943 unique users X  10,000 ratings to 1,682 movies. The data of 600 users who rate movies more than 45 times are selected in the experiment. The content of each movie consists of director names, major movie star names and film styles (such as action, sci-fi, etc.), which are crawled from the IMDB website ( http://www.imdb.com ). The feature set includes all words in the content of items. The Netflix dataset is the Netflix Prize data, 1 to 5 rating data of about 10 billion times rating from 480,189 anonymous users on about 17,770 movies. About 100,000 users are randomly selected as experimental samples, with the same setting of movie content and source as the MovieLens dataset. On account of the large amount of data in the Netflix dataset, there are lots of internal competition relations. To train parameters faster, the training part of the competitive method is calculated by parallel processing in Beijing Computing Center ( http://www.bcc.ac.cn ).
 to evaluate the recommendation performance.
 actual ratings in the test set. p i is the prediction rating of a test sample, v i is the actual rating, N is the number of test samples.
 rating, more emphasizing on large errors. The formula is as follows. s. The CBR recommendation algorithm uses term frequency-inverse document frequency (TF-IDF) values generated from VSM as content feature values, and then makes use of KNN to predict ratings. So it is named TFIDF-KNN here. It also includes all words in its feature set. Our method names BT-KNN. Three methods are evaluated on average errors of predict ratings by 5 cross-validation. Since BT-KNN uses independent personal data, the metrics are finally per-user average values. The experimental results are shown in Table 1 and Table 2. atively stable, both on the MovieLens dataset and the Netflix dataset. It achieves good performance even at small K, and is better than TFIDF-KNN significantly at the same time. The predictive rating error of TFIDF-KNN gradually decreases along with the increase of the neighbor number, and stabilizes at a big K. When K = 1, BT-KNN improves the MAE performance of TFIDF-KNN by 19.4% on the MovieLens dataset and by 20.7% on the Netflix dataset. BT-KNN improves the RMSE performance of TFIDF-KNN by 18.6% on the MovieLens dataset and by 20.3% on the Netflix dataset. About the methods X  best recommendation effect, comparing to TFIDF-KNN, MAE of BT-KNN is increased by 3.5% on the MovieLens dataset and by 1.5% on the Netflix dataset, and RMSE is increased by 6.0% on the MovieLens dataset and 4.9% on the Netflix dataset. Compared to RSVD, BT-KNN has increased MAE by 38.1% and RMSE by 24.7% on the MovieLens dataset, while MAE by 19.9% and RMSE by 6.6% on the Netflix dataset.
 isons on time are in Table 3.
 higher predictive accuracy and stronger robustness. It reduces prediction im-pacts of the case brought by CBR, which items X  content vectors are similar with inconsistent user preferences. CF focuses on decreasing the overall rating matrix error, so the adaptability of predicting personalized ratings is not strong. And competitive approach is faster than others in recommending. 4.2 The Relationship between Competitive Scales and The quantity of ratings reflects the competitive scale. The fewer ratings are, the lower competition scale is. For example, if the rating scale is only two indicated by  X  X ood X  and  X  X ad X , there is only one type of competitive relationship. For 5 ratings scale, every two level rating items have competitive relationships to each other.
 based on pairwise comparisons, the recommendation effect of the method is re-searched under different competitive scales. Using the MovieLens dataset, we simulated 2 ratings data with ff 1, 2, 3 g , f 4, 5 gg (original ratings), as well as 3 ratings data with ff 1, 2 g , f 3 g , f 4, 5 gg . Combined with the previous 5 ratings data, there are 3 different kinds of competitive scale data. Improved rates of BT-KNN with respect to TFIDF-KNN are observed in 3 cases. The relationship between competitive scale and recommendation effect is discovered. Recommen-dation effect of BT-KNN and TFIDF-KNN are demonstrated in Fig. 1 and Fig. 2, using 2 ratings data and 3 ratings data.
 variations of BT-KNN can be obtained in 3 kinds of competitive scale data. Fig. 3 shows them as follows.
 TFIDF-KNN on 2 ratings data under the condition of a small competitive s-cale. But as the increasing of the competitive scale, effect of BT-KNN is better than TFIDF-KNN on both 3 and 5 ratings data, and it is more obvious on 5 ratings data. The result illustrates the method X  X  recommendation effect is better on the larger competition scale. This article describes the basic idea of the user preferences mining approach based on pairwise comparisons. It unites the content and user rating of an item together with the competitive relationship, and obtains a unique identification of the user preference on a feature. The method provides better recommenda-tion accuracy and less recommended time. And it demonstrates that the larger competitive scales of data, the better recommendation effect.
 to have just a user preference value, regardless of the influence of its context on its user preference. In the future, to use the binary features with the context will be investigated to verify the reasonableness of the assumption. And the overall value is the product of its members X  values, which is the hypothesis of the generalized BT model, is rather simple. Hereafter, the composite mode adapted data will be studied, to improve the recommendation performance of the approach.
 Acknowledgments. The work in this paper is supported by the National Sci-ence Foundation of China (No. 61273365) and National High Technology Re-search and Development Program of China (No. 2012AA011103).

