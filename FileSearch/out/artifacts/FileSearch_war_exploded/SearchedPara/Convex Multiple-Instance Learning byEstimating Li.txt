 Multiple Instance Learning (MIL) has been proposed over 10 y ears ago as a methodology to learn models under weak labeling constraints [1]. Unlike traditi onal binary classification problems, the a number of keys and faces a locked door. To enter the door, we o nly need one matching keys. MIL is a natural weak labeling formulation for text categori zation [2] and computer vision problems [3]. In document classification, one is given files made of man y sentences, and often only a few are useful. In computer vision, an image can be decomposed in to different regions, and only some of object parts from bounding box information in images [4]. Although efforts have been made to provide datasets with increasingly more detailed supervis ory information [5], without automation video [6, 7]. In this case, one necessarily needs to resort to multiple-instance learning. sory information. However the state-of-the-art in MIL is of ten obtained by simply using a weighted sum of kernel values between all instance pairs within the ba gs, while ignoring the prediction of cannot achieve better performance, as constraints at insta nce level seems abundant  X  none of the positive instances and should help classification in input s pace.
 A major challenge is the non-convexity of many instance-lev el MIL algorithms [2, 11, 12, 13, 14]. This procedure usually gives only a local optimum since the o bjective is non-convex. The benchmark performance of MIL methods is overall quite similar, althou gh techniques differ significantly: some formulations [14]; some optimize using conventional alter nating minimization, others use convex-concave procedures [11].
 Gehler and Chapelle [15] have recently performed an interes ting analysis of the MIL costs, where deterministic annealing (DA) was used to compute better loc al optima for several formulations. In the case of a previous mi-SVM formulation [2], annealing met hods did not improve the performance significantly. A newly proposed algorithm, ALP-SVM, was als o introduced, which used a preset pa-results were obtained with this witness rate parameter set to the correct value. However, in prac-count for the non-convexity of the MIL problem. It remains ho wever unclear whether the observed performance variations are caused by non-convexity or by ot her modeling aspects. Although performance considerations have hindered the app lication of MIL to practical problems, the methodology has started to gain momentum recently [4, 16 ]. The success of the Latent SVM for mization MI-SVM algorithm in [2]) can achieve good results i f properly initialized. However, prop-independent formulation for MIL. Recently Li et al. [17] pro posed a convex instance-level MIL algorithm based on multiple kernel learning, where one kern el was used for each possible combi-solver. Although the formulation is convex, its scalabilit y drops significantly for bags with many instances.
 In this paper we make an alternative attempt towards a convex formulation: we establish that non-the positive and negative classes for each instance. We tran sform the multiple-instance learning the likelihood is very large.
 A support vector regression scheme is implemented to estima te the likelihood ratio, and it is shown to separate positive and negative instances well. However, determining the correct threshold for art results in practical datasets, demonstrating the vast p otential of the proposed approach. Let us consider a learning problem with n training instances in total, n In negative bags, every instance is negative, hence we do not separately define such bags  X  instead we directly work with the instances. Let B = { B { x positive bag B x .
 The MIL problem can be characterized by two properties. 1) negative-exclusion : if none of the max x is concave. Reformulation into a sum constraint such as P f ( x )  X  0 would be convex, when only one x context.
 ratio, convexity can be achieved. For example, the constrai nt: can ensure both of the MIL properties. Positive-identifiability is satisfied when Pr( y = 1 | x When the size of the bag is large, the assumption Pr( y = 1 | x Therefore, we exploit large deviation bounds to reduce the q uantity | B ambiguous, i.e. Pr( y = 1 | x can become much smaller, hence we can adopt a significantly lo wer threshold at some degree of violation of the negative-exclusion property. To this end, a common assumption is the low label noise [18, 19]: This assumes that the posterior Pr( y = 1 | x examples are not very ambiguous, which is usually reasonabl e. In [18, 19, 20], a number of results have been obtained implying that classifiers learned under t his assumption converge to the Bayes supports learning with fewer observations.
 Assuming M Theorem 1  X   X  &gt; 0 , for each x Pr
X is at most  X  .
 The proof is given in an accompanying technical report [21]. From Theorem 1, we could weaken When  X  is large, the reduction is significant. For example, for  X  = 2 and  X  = 0 . 05 , the right-whenever | B based on global i.i.d. of labels [8]. To estimate the likelihood ratio, one possibility would be t o use kernel methods as nonparametric estimators over a RKHS. This approach was taken in [22], wher e predictions of the ratio provided to optimize jointly as min optimization would not be convex if a framework in [22] were t aken. we are outside a classification setting, we can optimize over divergence measures D convex w.r.t. both f and g . These measures are common. For example, the f -divergence family that includes many statistical distances, satisfies the followi ng properties [23]: In principle, any of the measures given above can be used to es timate the likelihood ratio. An important issue is the relationship between the likeliho od ratio estimation and our final goal: sistent learners by minimizing the mean of a surrogate loss f unction of the data. In this paper we sign( f ( x )  X  1) . The Bayes risk is then R  X  = inf f R ( f ) .
 For a generic loss function C (  X , X  ) , let  X  = Pr( y = 1 | x ) , we can define the C-risk as R excess-C risk R the classification loss. Let us further define the optimal con ditional risk as H (  X  ) = inf and H  X  (  X  ) = inf  X  is essentially the largest convex lower bound of g [20].
 scaling of the loss function for positive and negative examp les. Let  X  R ( f )  X  R  X  = R  X  ( f )  X  R  X   X  + R + ( f )  X  R  X  + . We derived the following theorem: Theorem 2 a) For any nonnegative loss function C (  X , X  ) , any measurable f : X  X  R , and any probability distribution on X  X { X  1 } ,  X  following conditions are equivalent: (1) C is classification-calibrated; (2) For any sequence (  X  and every probability distribution on X  X  { X  1 } , R minimizing R Theorem 3 in [20] which has the form  X  ( R ( f )  X  R  X  )  X  R from the different loss transforms used for the positive and the negative examples. We consider an f -divergence of the likelihood as the loss function, i.e., C (  X , X  ) = D (  X ,  X  easily seen that H (  X  ) = C (  X  accurate when Pr( y misclassified positive examples with large Pr( y of high penalties, as shown in fig. 1(b).
 In fig. 1(a) we plot  X  functions for different losses. We prefer an L function estimation in RKHS using an epsilon-insensitive L Figure 1: Loss functions and their influence on the estimatio n bias. (a) The function  X  appearing in the losses used for likelihood estimation ( L loss is going to be extremely large if an example with very lar ge Pr( y Example estimated likelihood for a synthetic example. The e stimated likelihood is biased towards If we only know the label of the negative examples (blue) and t he maximal positive example (red), determining the optimal threshold becomes non-trivial. where || f || 2 is the RKHS norm; D 1, with appropriately chosen values for constants  X  and  X  ;  X  + training set. In this paper we use  X  = 2 and  X  = 0 . 05 , which gives the estimate of the bound for each bag as D senter theorem [24] would convert it to an optimization on ve ctors, which we omit here. The problem can be solved by different methods. The one easiest to implem ent is the alternating minimization between solving for the SVM and projecting on the constraint sets given by P y j  X  0 primal subgradient projection algorithms (in the case of li near SVM) can be used. In this paper we implement the alternating minimization approach, which is provably convergent since the optimiza-tion problem (4) is convex. In the accompanying technical re port [21] we derive an SMO algorithm based on the dual of (4) and characterize the basic propertie s of the optimization problem. 1) should give the optimal classifier. However as previously ar gued, the joint estimation on f and  X  of the correct threshold would make the algorithm outperfor m competitors by a large margin (fig. 2). This means that based on the learned likelihood ratio, th e positive examples are usually well separated from the negative ones. Developing a theory that w ould advance these aspects remains a promising avenue for future work. The main difficulty stems from the compound source of bias which arises from both the estimation of  X  + and the loss minimization over  X  + and f . ratios for each bag into a vector of length max Figure 2: Synthetic dataset (best viewed in color). (a) The true decision boundary. (b) Training points at 40% witness rate. (c) The learned regression function. (d) Bag misclassification rate of rate and true witness rate. where a vector and a binary label is given for each bag, and a li near SVM is learned to solve the practice and we always fix C to very large values. Effectively no parameter tuning is nee ded. 1 proach and take the mean between two instances: the one with t he highest likelihood among training positive bags with a score higher than the previous one. This approach is derived from the basic MIL assumption that all instances in a negative bag are negat ive.
 witness rate is 100% , it may be more effective to use a conventional learning appr oach. 5.1 Synthetic Data We start with an experiment on the synthetic dataset of [15], where the controlled setting helps understanding the behavior of the proposed algorithm. This is a 2-D dataset with the actual decision boundary shown in fig. 2 (a). The positive bags have a fraction of points sampled uniformly from the white region and the rest sampled uniformly from the blac k region. An example of the sample at 40% witness rate is shown in fig. 2 (b). In this figure, the plotted i nstance labels are the ones Table 1: Performance of various MIL algorithms on weak label ing benchmarks. The best result on each dataset is shown in bold. The second group of algorithms either not provide instance labels (MI-Kernel and miGraph) or require a parameter that can be di fficult to tune (ALP-SVM). SVR-SVM appears to give consistent results among algorithms tha t provide instance labels. The row denoted  X  X st. WR X  gives the estimated witness rates of our me thod.
 from negatives. This illustrates how our proposed approach converts multiple-instance learning into the problem of deciding a one-dimensional threshold.
 SVM. BEST THRESHOLD refers to a method where the best thresho ld was chosen based on the the AW-SVM from [15]. SVR-SVM generally works well when the w itness rate is not very low. From instance classification, one can see that the original m i-SVM is only competitive when the approach in [15], AW-SVM and mi-SVM perform quite the opposi te  X  competitive when the witness rate is small but degrade when this is large. Presumably this is because deterministic annealing is [15]. When the witness rate is large, annealing does not impr ove performance. On the contrary, the proposed SVR-SVM does not appear to be affected by the witnes s rate. With the same parameters that important room for improvement exists. 5.2 MIL Datasets The algorithm is evaluated on a number of popular MIL benchma rks. We use the common ex-perimental setting, based on 10-fold cross-validation for parameter selection and we report the test results averaged over 10 trials. The results are shown in Tab le 1, together with other competitive methods in from the literature [12, 15, 10] (for some of these methods standard deviation estimates are not available).
 In our tests, the proposed SVR-SVM gives consistently good r esults among algorithms that provide methods. Overall, the performance of SVR-SVM is slightly wo rse than miGraph and ALP-SVM. But we note that results in ALP-SVM are obtained by tuning the witness rate to the optimal value, which may be difficult in practical settings. The slightly lo wer performance compared to miGraph Table 2: Results from 20 Newsgroups . The best result on each dataset is shown in bold, pairwise nating in 10 datasets, whereas SVR-SVM is dominating in 14 .

Dataset MI-Kernel miGraph [10] miGraph (web) SVR-SVM Est. W R alt.atheism 60.2  X  3.9 65.5  X  4.0 82.0  X  0.8 83.5  X  1.7 1.83 % comp.graphics 47.0  X  3.3 77.8  X  1.6 84.3  X  0.4 85.2  X  1.5 5.19 % comp.windows.misc 51.0  X  5.2 63.1  X  1.5 70.1  X  0.3 66.9  X  2.6 2.23 % comp.ibm.pc.hardware 46.9  X  3.6 59.5  X  2.7 79.4  X  0.8 70.3  X  2.8 2.42 % comp.sys.mac.hardware 44.5  X  3.2 61.7  X  4.8 81.0  X  0 78.0  X  1.7 4.58 % comp.window.x 50.8  X  4.3 69.8  X  2.1 79.4  X  0.5 83.7  X  2.0 5.36 % misc.forsale 51.8  X  2.5 55.2  X  2.7 71.0  X  0 72.3  X  1.2 4.29 % rec.autos 52.9  X  3.3 72.0  X  3.7 83.2  X  0.6 78.1  X  1.9 2.75 % rec.motorcycles 50.6  X  3.5 64.0  X  2.8 70.9  X  2.7 75.6  X  0.9 2.86 % rec.sport.baseball 51.7  X  2.8 64.7  X  3.1 75.0  X  0.6 76.7  X  1.4 4.31 % rec.sport.hockey 51.3  X  3.4 85.0  X  2.5 92.0  X  0 89.3  X  1.6 6.52 % sci.crypt 56.3  X  3.6 69.6  X  2.1 70.1  X  0.8 69.7  X  2.5 3.22 % sci.electronics 50.6  X  2.0 87.1  X  1.7 94.0  X  0 91.5  X  1.0 4.29 % sci.med 50.6  X  1.9 62.1  X  3.9 72.1  X  1.3 74.9  X  1.9 5.23 % sci.space 54.7  X  2.5 75.7  X  3.4 79.4  X  0.8 83.2  X  2.0 3.64 % soc.religion.christian 49.2  X  3.4 59.0  X  4.7 75.4  X  1.2 83.2  X  2.7 3.30 % talk.politics.guns 47.7  X  3.8 58.5  X  6.0 72.3  X  1.0 73.7  X  2.6 3.23 % talk.politics.mideast 55.9  X  2.8 73.6  X  2.6 75.5  X  1.0 80.5  X  3.2 3.88 % talk.politics.misc 51.5  X  3.7 70.4  X  3.6 72.9  X  2.4 72.6  X  1.4 2.82 % talk.religion.misc 55.4  X  4.3 63.3  X  3.5 67.5  X  1.0 71.9  X  1.9 2.87 % 5.3 Text Categorization witness rate. Thus they serve as a better MIL benchmark compa red to the previous ones. These are derived from the 20 Newsgroups corpus, with 50 positive and 50 negative bags for each of the 2 0 news categories. Each positive bag has around 3% witness rate. We run 10-fold cross validation 10 times on each dataset and compute the average accuracy and st andard deviations, C is fixed to 100 ,  X  comparison, identified as miGraph (paper) and miGraph (webs ite), respectively. Our SVR-SVM performs significantly better than MI-Kernel an d miGraph (paper). It is comparable with miGraph (web), and offers a marginal improvement. It is interesting that even though we use a suboptimal second step, SVR-SVM fares well with the state-o f-the-art. This shows the potential of methods based on likelihood ratio estimators for multiple i nstance learning. We have proposed an approach to multiple-instance learning based on estimating the likelihood ratio ratio function and identify better threshold estimation pr ocedures.
 Acknowledgements This work is supported, in part, by the European Commission, under a Marie Curie Excellence Grant MCEXT-025481. [1] Dietterich, T.G., Lathrop, R.H., Lozano-Perez, T.: Sol ving the multiple-instance problem with [2] Andrews, S., Tsochantaridis, I., Hofmann, T.: Support v ector machines for multiple-instance [3] Maron, O., Lozano-P  X erez, T.: A framework for multiple-instance learning. In: NIPS. (1998) [4] Felzenszwalb, P.F., McAllester, D.A., Ramanan, D.: A di scriminatively trained, multiscale, [5] Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T .: Labelme: A database and web-[6] Cour, T., Sapp, B., Nagle, A., Taskar, B.: Talking pictur es: Temporal grouping and dialog-[9] Tao, Q., Scott, S., Vinodchandran, N.V., Osugi, T.T.: Sv m-based generalized multiple-instance [11] Cheung, P.M., Kwok, J.T.: A regularization framework f or multiple-instance learning. In: [12] Fung, G., Dandar, M., Krishnapuram, B., Rao, R.B.: Mult iple instance learning for computer [15] Gehler, P., Chapelle, O.: Deterministic annealing for multiple-instance learning. In: AISTATS. [18] Mammen, E., Tsybakov, A.B.: Smooth discrimination ana lysis. Annals of Statistics 27 (1999) [21] Li, F., Sminchisescu, C.: Convex multiple instance lea rning by estimating likelihood ratio. [22] Nguyen, X., Wainwright, M., Jordan, M.I.: Estimating d ivergence functionals and the likeli-[23] Liese, F., Vajda, I.: Convex Statistical Distances. Te ubner VG (1987)
