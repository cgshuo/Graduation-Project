 1. Introduction
Causality or Causal relation refers to  X  X  X he relation between a cause and its effect or between regularly nects one event to the other with causal relation. In this paper, we aim to extract possible causal relations that exist between noun phrases. The causality patterns are used for connecting the cause and effect noun phrases. Cue phrase is a lexical, phrasal or structural causal cue between the cause and effect noun phrases.
Cue phrases that connect two noun phrases are known to be causal verbs ( Girju, 2003; Girju &amp; Moldovan, 2002 ). For example, in (1a), the verb  X  X  X ause X  X  is a cue phrase to connect the two noun phrases  X  X  X he oral bacteria X  X  and  X  X  X um disease X  X . In (1b), the two noun phrases  X  X  X arly childhood sun exposure X  X  and  X  X  X kin can-cer X  X  are not directly connected by one verb. To determine such long-distance causal relation, we introduce tree structured cue phrases. (1a) The oral bacteria that cause gum disease appear to be the culprit. (1b) Early childhood sun exposure is particularly important in the development of skin cancer.
Some word pairs in noun phrase pairs indicate the causality of the noun phrase. The word pair  X  X  X acte-ria X  X  and  X  X  X isease X  X  is an example of a causal word pair. When the noun phrase pair  X  X  X ral bacteria X  X  and  X  X  X um disease X  X  are causally related, we can infer that the noun pair  X  X  X owel bacteria X  X  and  X  X  X owel disease X  X  may be causally related. Causal word pairs are learned from cause X  X ffect noun phrase pairs. We define word cept classes  X  X  X acteria X  X  and  X  X  X isease X  X  (in MeSH, [B03] and [C23.550.288] relation between noun phrase pairs. Concept pair probability is defined as the probability of the concept pair that has causal relation. Cue phrases connecting two causal noun phrases are also considered to have con-nection probability. We define cue phrase probability as the probability of the cue phrase that connects cau-sal noun phrase pairs.

We use cue phrases as a filter to find causality candidates and we transfer the causality extraction prob-the Na X   X  ve Bayes classifier. These probabilities are learned from the raw corpus in an unsupervised manner.
In Section 2, selected works are compared for causality extraction. Our classification model will be ex-plained in Section 3. If we have a causality classifier, a set of new cue phrases is acquired from the auto-matically generated causality-annotated corpus. Furthermore, the long distance causality recognition will be resolved with the binary tree-styled cue phrases and their incremental learning method. The cue phrase learning method will be explained in Section 4. Finally, an evaluation is given for the proposed models. 2. Related works
Previous works on causality analysis mainly used the pattern matching approach. The probabilistic clas-sification approach is applied to related research domain like rhetorical structural analysis. This work uses the cue phrase filter and introduces a new classification model based on cue phrase and word pair proba-bilities. A learning method for cue phrase and classifier is also proposed. 2.1. Causality recognition and inference
Causal relations are expressed in various forms in the literature: between the subject and object position of noun phrases as in (2a), between two sentences or phrases as in (2b), or in the intra-structure of a noun phrase as in (2c). Causal relation also exists between paragraphs that describe events. (2a) Gum disease is caused by plaque. (2b) Because gum disease is usually painless, you may not know you have it. (2c) Disease-causing sticky film of bacteria.

In the above examples, each cause event is connected to its effect event by the causative verb ( X  X  X ause X  X ), causal connectives ( X  X  X ecause X  X ), or intra-NP structure. In this paper, we focus on the causal relation between noun phrases as in (2a).

The inference model on causality, including the Bayesian approach of Cooper and Herskovits (1991) and the conditional independency pattern searching approach of Spirtes, Glymour, and Scheines (1993) , are not the focus of this paper. We concentrate on the search for causal relations that are explicitly represented on the raw corpus. 2.2. Causality analysis
Initial works on causality analysis used hand-made causality patterns to find causality ( Joskowsicz, Ksie-zyk, &amp; Grishman, 1989; Kaplan &amp; Berry-Rogghe, 1991 ). Low, Chan, Choi, Chin, and Lay (2001) used hand-made causal semantic templates and a concept term dictionary for the restricted domain. For the financial news domain, they reported finding causality related to Hong Kong stock movement with a pre-cision of 76%. Khoo, Kornfit, Oddy, and Myaeng (1998, 2000) used the semi-automatic causality pattern learning on the syntactically analyzed corpus and introduced the cue phrase learning method. However, the causality pattern matching method has a limited performance since not all sentences selected by patterns guarantee causality. They reported that the precision of the causality identifier pattern was about 76%.
Girju and Moldovan (2002) used the inter-noun phrase causal relation to improve the question-answer-ing performance. To extract inter-noun phrase causal relations, they used the cue phrase filter and the noun class ranking based on WordNet ( Miller, 1995 ). We call this the  X  X  X ictionary-based ranking model X  X . With simple rules reflecting the meaning of head nouns, each noun phrase pair is classified into 5ranked classes, which are called the  X  X  X oun class rank X  X . The ranking rules are summarized as follows: rank 1 is given if the feature X  X  and  X  X  X vent X  X  among the WordNet synsets; rank 2 if only the effect head nouns  X  senses belong to the causation class; rank 3 if the effect head noun is enumerated to the causation class the cause head nouns are  X  X  X ausal agents X  X ; and finally, rank 5is given based on the number of senses and the frequency of verbs.

The examination regarding ranks 1 X 4 as causal relations shows a precision score of 65.5%. Their decision works, cue phrases were verb phrases automatically acquired from WordNet and the corpus. After they collected causal noun phrase pairs from WordNet gloss definitions, they found the corresponding causality patterns form of &lt;noun phrase-1, verb/verb expression, noun phrase-2&gt; from the corpus. Finally, 72 cue phrases (which are verbs) were selected to connect the noun phrase pairs from the corpus.
Marcu and Echihabi (2002) used the inter-sentence word pair probability for discriminating the rhetor-ical relation between sentences. To distinguish the causal relation from other rhetorical relations, they used were classified as either  X  X  X ausal X  X  or not. The result showed an accuracy of 57% in inter-sentence causality extraction.

For the supervised learning of the causality classifier, a causality-annotated corpus is required. However, the construction of such a corpus would take much effort. The supervised method has the limitation of being scaled up. We learned the word pair and cue phrase probabilities through the unsupervised learning where a dictionary or WordNet is used as the basis of causality, the unregistered words in the dictionaries hinder the search for correct causal relation. We solved this unknown word problem by using the word pair probability. If the dictionary or word-sense mapping module is not available, then the proposed model is more attractive.

The proposed classification and learning models with modifications will be described in detail, and some examinations on cue phrase learning and concept pair probability will be added. The cue phrases from pre-vious works on causality analysis were simple verb patterns given by humans or semi-automatically learned. In this paper, we introduce a binary tree-styled cue phrase for considering the long distance cau-sality. Then, we also try to automate the cue phrase acquisition. 3. Causality extraction model 3.1. Causality extraction system
Consider our proposed causality extraction system flow in Fig. 1 . Causality candidates were extracted from the raw corpus through a noun phrase chunking with syntactic analysis. We used cue phrases as a filter to find causality candidates. The causality analysis problem was redefined as a classification problem to assign one of two causal classes,  X  X  X ausal X  X  or  X  X  X on-causal X  X , to the causality candidates. Causal noun phrase pairs were selected by the cue phrase, word pair and concept pair probabilities. 3.2. Causality representation: cue phrases and causality candidates
Consider sentences (3a) X (3c). The two noun phrases are not directly connected by a verb phrase. When we limit the cue phrase to a verb or verb pattern, these long distance causal relations are hardly captured. (3a) Radon is the nation  X  s second-leading cause of lung cancer. (3b) Sun exposure is particularly important in the development of skin cancer. (3c) Skin cancer had occurred because of the sunburn.

A Cue phrase is re-defined as a verb-rooted syntactic tree, which connects one noun phrase to the other with causal relation. Fig. 2 shows syntactic trees for sentences (3a) X (3c) and their corresponding cue phrases which are included in boxes. These syntactic patterns normalize the syntactic variation such as the passive or the verbal chain. With a dependency tree-based cue phrase, we can consider the syntac-tic variation of the cue phrase. Here  X  X  X NP X  X  and  X  X  X NP X  X  refer to the cause and effect noun phrases, respectively.

The input of the classifier is a causality candidate that is filtered by cue phrases. The causality candidate is expressed by a ternary composed of a noun phrase pair and a cue phrase: &lt;cause noun phrase candidate, cue phrase, effect noun phrase candidate&gt;. To represent and match the syntactic tree pattern, the preorder W in the root string l is defined as
For each node of the syntactic tree encountered, the corresponding label l is entered in the preorder string W . And for each return to the previous node a 0 is entered in W . With this expression, the cue phrase pattern matching time was reduced to the sublinear time. 4 (3a) and its cue phrase matching sequence. The cue phrase matching algorithm is as follow: (1) Find the cue phrase root word (e.g.  X  be  X  ) from the preordered string of the sentence. (2) Match the cue phrase and the preorder string. (3) When it mismatched, skip a subtree that is the same number of labels and 0  X  s. (4) Noun phrases can be matched with the CNP and ENP slot. (5) The cue phrase matching success only if all slots and words of the cue phrase are matched. Causality candidates extracted from sentences (3a) X (3c) were as follows: (4a) &lt; X  X  X adon X  X ,  X  X  X e CNP 0 cause of ENP 0 0 0 0 X  X ,  X  X  X ung cancer X  X &gt; (4b) &lt; X  X  X un exposure X  X ,  X  X  X e CNP 0 important 0 in development of ENP 0 0 0 0 0 X  X ,  X  X  X kin cancer X  X &gt; (4c) &lt; X  X  X unburn X  X ,  X  X  X ccur ENP 0 because of CNP 0 0 0 0 X  X ,  X  X  X kin cancer X  X &gt; 3.3. Na X   X  ve Bayes causality classifier
The causality classifier classified the causality candidate ternary ( t ity ( c 0 ) X  X . The class c * of the ternary t i was computed as shown in Formula (1) :
When we consider the cue phrase CP t the ternary t i , P ( t i j c j ) in Formula (1) will be rewritten as Formula (2) . total number of word pairs in ternary t i . We assumed that these features are all independent each other.
In Formula (2) , P  X  CP t ability and the word pair probability, respectively, which were defined in Section 1. These probabilities can be learned from the causality-annotated ternary set. However, the construction of the causality-annotated ternary set consumes time and effort. In this paper, we used a raw corpus rather than causality-annotated corpora. To make it possible, the EM (Expectation X  X aximization) procedure was used with the Na X   X  ve Bayes classifier. In the next section, we summarize the unsupervised causal classifier learning method in
Chang and Choi (2005) . 3.4. Classifier learning with EM
The Na X   X  ve Bayes classifier is bootstrapped from the initial classifier. The training data is the causality candidate ternary set that was filtered by cue phrases. There are three training stages. In the initializa-we use the noun class rank described in Section 2.2. It is a dictionary-based classifier and does not need the extra training sequence. After the whole training corpus is classified with the initial classifier, highly ranked ternaries are selected as the initial causality-annotated set. From this selected annotation is from the automatically causality-annotated NP pairs that is a noisy data. To counter this problem, we use only the high causality-ranked small set initially, and use the raw corpus together on the EM learning sequence.

The second training stage is called the Expectation step. The whole training corpus, including the anno-the newly classified data, parameters are re-estimated. Parameters trained in EM are prior probability P ( c cue phrase probability P  X  CP t parameters are estimated with Laplace smoothing method ( Laplace, 1814, 1995 ) for word pairs unseen in the training data. The Expectation step and Maximization step are repeated while the classifier param-eters improve. 3.5. Causality classification model
The trained classifier can be combined with the noun class rank probability and the cue phrase confidence score. Thenoun class rank probability, P  X  c j j rank t noun class rank of the ternary. The cue phrase confidence score, P  X  c
We propose some classification models. The classification model CP + LP uses the cue phrase probabil-ity and the word pair probability as shown in (3) . In this model, the noun class rank is also used as a back-off model. If the cue phrase probability and the word pair probability, P ( c causal class, the noun class rank probability is used. To do this, a discrimination value, Dist( t duced as shown in (4) . The threshold h is a constant.

The classification model CP + LP + NC uses the cue phrase probability and the word pair probability combined with the noun class rank probability as shown in (5) . The sum of weights w
The cue phrase confidence score is also learned from the automatically annotated corpus. The classifi-cation model CP + LP + NC + CPC uses the cue phrase probability and the word pair probability com-bined with the noun class rank probability and the cue phrase confidence score as shown in (6) . The sum of weights w lp , w nc and w cpc must be 1.
 4. Cue phrase learning
The causality classifier was bootstrapped from an initial classifier with the raw corpus. The causality classifier requires a pre-defined set of cue phrase. Cue phrases were also learned from the set of causal noun phrase pairs and the open set of web pages. When we decide that two noun phrases are causally connected, the path connecting these two noun phrases on the syntactic tree is possibly a cue phrase. Fig. 4 shows the cue phrase learning flow that is composed of three steps: the initial noun phrase pair selection, the cue phrase candidate extraction, and the cue phrase selection.

From the causal noun phrase pairs, we selected initial noun phrase pairs such as  X  X  X un exposure X  X  and  X  X  X kin cancer X  X . Sentences that contain initial noun phrase pairs were extracted from the web pages. Cue phrase candidates were generated from these sentences after the noun phrase was replaced with the noun phrase slot. The extracted cue phrase candidates were sorted with the confidence score that was calculated by the causality classifier. Then the cue phrase candidates with low confidence scores were removed. These new cue phrases took part in the causality classifier. 4.1. Initial noun phrase pair selection The initial noun phrase pairs were extracted from 5million news articles which are a part of TREC (Text
REtrieval Conference; Harman, 1992 ) corpus. The corpus was automatically annotated with the causality of a noun phrase pair ep i is computed with the causal probabilities of ternaries { t appeared frequently and with a high causal probability.

The set of initial noun phrase pairs was selected based on the total causality of the given noun phrase pair. From the 200000 causal noun phrase pair candidates in the corpus, we selected 584 causal noun phrase pairs (0.3%) under the following conditions: (1) The noun class rank of the noun phrase pair is higher than 4. (2) The total causality of the noun phrase pair is over than 1.

Table 1 shows a part of the automatically selected initial noun phrase pairs. 4.2. Cue phrase candidate extraction
Sentences that contain initial noun phrase pairs were gathered from web pages. For each event pairs, we collected 100 sentences in maximum. After syntactic analysis, the keyword noun phrase of the syntactic tree was replaced with the noun phrase slot, CNP and ENP. From the normalized syntactic tree, the syntactic patterns including the two noun phrase slots were selected as cue phrase candidates. From 15000 sentences, we found 1142 syntactic patterns as cue phrase candidates. 4.3. Cue phrase selection
Cue phrase candidates were sorted with the confidence score. The confidence score of the cue phrase can-didates could be learned with the causal classifier. Fig. 5 shows the cue phrase selection flow.
To obtain the confidence score of the cue phrase candidates, the new classifier that uses the original cue phrases and all new cue phrase candidates were learned. The classifier learning sequence is the same as that in Section 3.4. The initial classifier for the cue phrase learning is the noun class rank and the word pair probability. For every step of new classifier learning, the cue phrase confidence score was up-dated. After removing the cue phrase candidates with low confidence scores, the cue phrases were set-tled. Cue phrases with low confidence score were omitted and the new pattern was added to the cue phrases. These new cue phrases took part in the causality classifier. Table 2 shows a part of these cue phrases.
 4.4. The incremental cue phrase learning
The causality classifier proposed in Section 3.1 is bootstrapped from an initial classifier and the raw cor-pus. It uses pre-defined cue phrases. Cue phrases are learned with the established classifier and the causality-annotated corpus as shown in Figs. 4 and 5 . After new cue phrases are added, new classifier is re-estimated and new cue phrase candidates are selected again from the annotation of this new classifier. Fig. 6 show these two learning system together.

The cue phrase learning sequence requires an existing causality classifier. The first Na X   X  ve Bayes cau-sality classifier is bootstrapped from the dictionary-based classifier that uses only 72 causal verbs defined in Girju and Moldovan (2002) . From the initial causality classifier and the initial cue phrase set, cue phrases and the causality classifier are incrementally learned by turns. The incremental cue phrase learn-ing process can be repeated in a fixed number or while new patterns with high confidence scores are discovered.

When we added the candidate to the patterns, we added only some candidates that have high confidence scores. In the first loop, 19 cue phrases were selected from the 1142 cue phrase candidates. Finally, 81 cue phrases were added by the incremental cue phrase learning method.
 5. Evaluation 5.1. Training and test set
A part of the TREC corpus was used for causality extraction. The training corpus was composed of 5 million sentence-sized articles from the LA TIMES (1989 X 1990) and Wall Street Journal (1987 X 1990). We used two test sets, which were selected from different domains. The first one was from Wall Street Journal articles. The other was from the Medline medical encyclopedia of A.D.A.M. Inc. All sentences in the test sets included the word  X  X  X ancer X  X . The first one, which we called as cTREC , came from the general domain.
The other, which we called as cADAM , came from the medical domain. Table 3 shows the specification of
Two human annotators manually classified the test sets; one was the first author and the other the med-ical domain expert. They had a 72.8% agreement on the results. A gold standard was made after discussions between the annotators.
 5.2. Evaluation
The cue phrase probability ( CP ) and the word pair probability ( LP ) were trained on the training set. As with noun classes and highly ranked ternaries were selected as a causality-annotated set. As a result, ter-naries ranked by 1 X 3 were annotated to  X  X  X ausal X  X  ( c 1 ), and parts of ternaries ranked by 5were annotated classifier was bootstrapped from the causality-annotated set and the unlabeled training set. Table 4 shows the evaluation result on the test sets. The classification model NC follows the model of
Girju and Moldovan (2002) , which uses the cue phrase filter and the noun class rank. The classification model LP with No EM follows the classification model of Marcu and Echihabi (2002) , which uses the word pair probability without EM process.

The last three models are the proposed models. For the classification model CP + LP , we assigned 0 to the value of the threshold h . And for the noun class ( NC ) weight w ( CPC ) weight, 0.1 was assigned. For the evaluation, we used the pre-defined cue phrases based on the 72 causal verbs of Girju and Moldovan (2002) .

Contribution o fthe cue phrase probability and the word pair probability . The proposed model CP + LP showed an F -value of 70.20%, which was an improvement of 13.97 percentage points from the baseline model ( NC ). In all the proposed models, the causality extraction performance was increased. We can say that the cue phrase probability and the word pair probability are useful for causality extraction.
Contribution o fthe noun class on domains . For the general domain test set ( cTREC ), the result of the combined with the noun class ( CP + LP + NC ) improved the performance in both the recall and the pre-cision from the non-combined ( CP + LP ). However, for the medical domain test set ( cADAM ), the perfor-mance was decreased by 3.0 5percentage points. This was caused by unknown words in the medical domain test set. Terminologies and pronouns in the specific domain included more unknown words than in the general domain. For the baseline model NC , the unknown words in cADAM decreased the performance by 15.1% in precision and by 11.1% in the recall. We can say that the noun class is useful in the general but not in the specific domain.

Contribution o fthe cue phrase confidence score . The classification model combined with the cue phrase confidence score ( CP + LP + NC + CPC ) did not show any significant improvement over the non-com-bined model ( CP + LP + NC ). This is because the cue phrase probability and the cue phrase confidence score shared the same information space.

Robustness o fthe proposed model . In the proposed model ( CP + LP ), 37.5% of the unknown word-caus-ing errors in the baseline system ( NC ) were correctly classified. The proposed model did not refer the word sense. It only referred the word pair frequency in the corpus. We can say that the proposed model is free from unknown words.
 High performance of unsupervised learning . The proposed models are learned in an unsupervised manner. They do not require the pre-annotated data. Nevertheless, the performance is relatively high.
Contribution o fconcept pair probability . We proposed the usage of concept pair probability, which is based on the concept class of the noun phrases. To find the concept class of each noun phrase, we can use a dictionary like WordNet. However, this is not the simple way since there are many noun phrases that represent two or more concept classes. To bypass the word sense disambiguation, we consider the head word pair of the noun phrases as the concept pair. Table 5 shows the performance evaluation of the concept pair probability ( SP ). In the table, they show meaningless improvements with the concept pair probability.
It indicates that the headword pair was not enough and the word sense disambiguation problem had to be solved for causality extraction.

Contribution o fthe incremental cue phrase learning method . The effect of incremental cue phrase learn-ing was evaluated in Fig. 7 . In the first step, we added 19 patterns to the cue phrases. In the next step, 16 were added. Finally, we had a total of 153 cue phrases. From the F -value curve, the performance was maximized in the case where the number of cue phrases was 127. With small scarification of the preci-sion, we can get greater recall value through the incremental cue phrase learning method. As a result, the total performance ( F -value) was increased by 6.09 percentage points. About 17% of the causal noun phrase pairs were extracted by cue phrases that were added by the incremental learning process. Table 6 shows the performance contrast between the original 72 causal verbs and the trained tree-styled cue phrases.

Applicability o fthe proposed causality extraction and learning method . Terminologies of test corpus might affect the performance of the causality extraction. Table 7 shows the causality extraction performance on the new test set named wTREC . All sentences in wTREC are from general domain articles and include the word  X  X  X ar X  X . wTREC contains 1827 sentences and 107 causalities. Although the recall is comparatively low,
F -value is elevated with the causality classifier and the cue phrases learning sequences. The final result showed an F -value of 72.13% on the new test set. This result says that the proposed causality extraction and learning method is applicable to all sentences.
 6. Conclusion
An improved approach was introduced in this paper for causality extraction. Previous works on causal-ity extraction mainly used the lexical pattern matching and WordNet. We use lexical patterns as a filter to find causality candidates and we transfer the causality extraction problem to the binary classification. With this approach, we managed to combine possible classification features and introduce any kind of learning method.

The bootstrapping method was found useful for learning the Na X   X  ve Bayes causality classifier on the raw corpus. Empirical results suggested feasible features for the causality extraction. The cue phrase and the word pair probabilities are two of them, and noun class rank showed good performance in such domain that dictionary works well. The main advantage of the proposed causality extraction model over that of
Girju (2003) is the robustness. The proposed model empirically shows high performance without dictio-nary-based feature. The benefit of the binary tree-styled cue phrase expression is its ability to match the long distance causality. With this cue phrase expression and the incremental cue phrase learning method, we automate the cue phrase learning sequence. In summary, we proposed the improved methods on cau-sality extraction and cue phrase learning. The results of evaluations were promising.

The proposed causality extraction was used for the causal question answering. The causal question answering is available on the web; the causal browsing that uses the proposed system can be accessed there 8 shows the causal network for the term  X  X  X rotein X  X . It was automatically generated from 2000 document-sized biological domain paper abstracts ( Tsujii, 2003 ). In the figure, the dotted line shows the hypernym relation. The solid line shows the causal relation in which the numeric label on each edge represents the causal probability described in documents. 6 The causality between  X  X  X L-5 X  X  and  X  X  X rotein X  X  is originated from the sentence (5a). In the sentence (5b) and (5c),  X  X  X L-5 X  X  also causes two noun phrases that have common hypernym,  X  X  X rotein X  X . These three causality and two hypernym relations are represented in the figure.
The cue phrases  X  X  X nduce CNP 0 ENP 0 0 X  X  and  X  X  X ctivate CNP 0 ENP 0 0 X  X  worked as filter. (5a) IL-5 induced two proteins that bound to the gamma-activating sequence. (5b) The 94 kDa STAT5B protein was activated by both IL-5 and GM-CSF. (5c) We found that IL-5 induces two GAS-binding proteins in eosinophils.

The focus of this paper is restricted within the inter-NP causality. In the medical domain, especially for medical encyclopedia corpus, the cause and effect are rarely in one sentence. We are now expanding the search space to the inter-sentences causality. The preliminary trial on Korean inter-sentence causality extraction showed a little chance to be improved ( Chang &amp; Choi, 2005 ).
 Acknowledgment
This research was supported in part by KISTEP Strategic National R&amp;D Program under brain science program and by KOSEF under contract for bank of language resources.
 References
