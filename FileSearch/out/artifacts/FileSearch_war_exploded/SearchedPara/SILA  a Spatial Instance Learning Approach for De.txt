 Deep Web pages convey very relevant information for dif-ferent application domains like e-government, e-commerce, social networking. For this reason there is a constant high interest in efficiently, effectively and automatically extract-ing data from Deep Web data sources. In this paper we present SILA, a novel Spatial Instance Learning Approach, that allows for extracting data records from Deep Web pages by exploiting both the spatial arrangement and the presen-tation features of data items/fields produced by layout en-gines of Web browsers in visualizing Deep Web pages on the screen. SILA is independent from the internal HTML encod-ings of Web pages, and allows for recognizing data records in pages having multiple data regions in which data items are arranged by many different presentation layouts. Exper-imental results show that SILA has very high precision and recall and that it works much better than MDR and ViNTs approaches.
 [ Knowledge Management (KM) ] Algorithms, Experimentation Web Information Extraction, Deep Web, Instance Learning, Web Wrapping
The Deep Web is the part of the Internet that is not ac-cessible by conventional search engines. Deep Web pages are dynamically generated from databases in response to queries submitted via search forms filled in by keywords. The Deep Web continue to grow as organizations and com-panies, operating in fields like e-government, e-commerce and social networking, make available their large amounts of data by providing Web-access facilities to their databases. Consequently, there is a constant high interest in efficiently extracting data from Deep Web data sources.

A large body of work on approaches for extracting data from Deep Web sources is already available in literature. Al-ready existing approaches can be classified, for the scopes of this paper, in two main groups: (i) approaches that mainly use the internal representation of Deep Web pages [1, 5, 6], and (ii) approaches that exploit the visual appearance of Deep Web pages [2, 7]. Approaches in both groups are still limited in many aspects. Methods based on the inter-nal structure of Deep Web pages suffer of the complexity of today Web pages encodings. In fact, they need to be up-dated for facing the adoption of new standards and tags. In particular, the growing adoption of scripts and CSS style sheets, for presenting data to human users, makes Web pages more complex than ever. Even if the layout of information on Web pages provides visual cues that help human readers to make sense of Web pages contents, current approaches that exploit the visual appearance of Web pages adopt page segmentation algorithms and heuristics that require specific and, sometime, complex tunings.

In this paper we present a novel spatial instance learn-ing approach for Deep Web pages that exploits both the spatial arrangement and the presentation features of data records and data items/fields produced by layout engines of Web browsers. Main contributions are: (i) The definition of a novel spatial data model for Web pages named PDOM, i.e. Positional Document Object Model. (ii) A novel visual similarity measure that computes similarity between sets of PDOM nodes by exploiting their spatial and presentation features. (iii) The definition of an efficient and effective in-stance learning algorithm, based on a hierarchical clustering technique and heuristic aggregation methods, that allows for recognizing data records and data items in Deep Web pages independently from their visual arrangement.
 The SILA algorithm has been tested on a dataset of 210 Deep Web pages randomly selected from most known Deep Web sites. Experimental results have shown the effective-ness of SILA. In particular, carried out experiments have shown that SILA: (i) allows for recognizing data records and items having any spatial arrangement and spread on multiple (data) regions of a single page. (ii) has very high precision and recall and works much better than already ex-isting and well known MDR [1], and ViNTs [7] approaches. In this section we firstly introduce the notion of Positional Document Object Model (PDOM) of Web pages. Then we describe how PDOMs are created by considering both the traditional DOM representation and the spatial arrange-ment of Web pages obtained from layout engines of Web browsers.

A Web page can be seen as a 2-dimensional Cartesian plane on which are placed 2-dimensional objects (e.g. data records and items) surrounded by Minimum Bounding Rect-angles (MBRs), as shown in Figure 1. In spatial reason-ing [3], MBRs are the most common approximations of 2-dimensional objects because they need only two points for their representation in the Cartesian space. The concept of MBR is defined as follows.

Definition 1. Minimum Bounding Rectangle. Let o be a 2-dimensional object, the minimum bounding rectangle (MBR) of o is the minimum rectangle r that surrounds o and has sides parallel to the axes ( x and y ) of the Cartesian plane. We call r x and r y the segments that are obtained as the projection of r on the x -axis and the y -axis respec-tively. Then, each side of the rectangle is represented by the segments ( r  X  x ,r + x ) and ( r  X  y ,r + y ), where r  X  the infimum on the x -axis ( y -axis) and r + x (resp. r + the supremum on the x -axis ( y -axis) of the segments r x r .

Considering MBRs, directional and containment relations among 2-dimensional objects can be simply modeled. For representing directional relations we adopt the Rectangular Cardinal Relation (RCR) spatial reasoning model [3]. We define the Positional Data Object Model (PDOM) of Web pages which the proposed spatial instance learning ap-proach is based on. A PDOM is a tree structure where: (i) the parent-child relation represents spatial containment between nodes (PNodes) and (ii) each PNode, named po-sitional node (PNode), represents one or more DOM nodes laid out on the screen by the layout engine of a Web browser. PNodes are equipped by both spatial (i.e. the position in which DOM nodes are visualized on the screen by the lay-out engine of a Web browser) and presentation features (i.e. font color, font or image size, font style, background color, borders, etc.). In order to explain why we adopt a spatial representation of Deep Web pages we point out that Web de-signers frequently use very involved and undergoing HTML structures for obtaining visual appearance of data records in Deep Web pages that make sense for human readers, as al-ready discussed in [4]. Such structures pose many problems to already existing instance learning and wrapper induction techniques. At the contrary, the PDOM, allows for repre-senting Web pages in a quite simple way. So, pages that show the same visual pattern to human readers, may have very different internal HTML encodings, as shown in Figure 2a-b. By the PDOM representation such pages can be made more easy to process for instance learning and wrapper in-duction approaches. Furthermore, frequently it is possible to obtain the same PDOM represetation for different pages as shown in Figure 2c-d.
 Figure 2: DOMs fragments of Web pages represent-ing friend lists in social networks: (a) Care2.com, and (b) Bebo.com. PDOMs -(c) and (d) -repre-senting the visual arrangement for page fragments in (a) and (b) respectively.

It is worthwhile noting that in Deep Web pages data records are usually arranged either as lists or matrices where data items can be indifferently organized in vertical or hor-izontal way as depicted in Figure 2.

A human-oriented visual pattern for data records can be obtained from very different HTML encodings. The PDOM has the property to generalize different possible HTML en-codings by combinations of only four different structural pat-terns that we call: standard , flat , nested , and non-contiguous . In the standard PDOM record pattern, each data record is represented by a single PNode which subtree constitute all data items of the data record as depicted in Figure 4a. In the nested PDOM record pattern, groups of data records have a common parent PNode, as sketched in Figure 4b. In the flat PDOM record pattern, data items of data records of a data region have the same parent PNode, as shown in Figure 4c. Finally, in the non-contiguous PDOM record pat-tern, groups of data items of different data records can have different parents as shown in Figure 4d.
 PNodes and the PDOM are formally defined as follows. Definition 2. PNode. A PNode is a 3-tuple of the form: where: Figure 3: Examples of visual arrangements of data records in deep web pages: (a) list arrangement and (b) matrix arrangement
Definition 3. PDOM. A PDOM is a 3-tuple of the follow-ing form: where: For computing the PDOM, the SILA system embeds the Mozilla browser by exploiting the Mozilla XULRunner 1 ap-plication framework that allows for implementing the func-tion mbr (see Definition 1).

In the DOM there are chains of nodes that are rendered in the same MBR. For this reason, a PNode p can represents more DOM nodes. Let D be a DOM, a PDOM P is built on the base of the containment relations among the MBRs of nodes in D , starting from the root node of D . More in detail, for each pair of nodes u and v in D , we have: https://developer.mozilla.org/en/XULRunner 1.9.2 Relea se Notes Figure 4: Structural PDOM patterns that represent the same visual arrangement of data records.
In this section we present a novel visual similarity mea-sure that is one of the pillars which the instance learning approach proposed in this paper is based on. The main ideas which the visual similarity measure if founded on are: (i) a data record can be seen as a set of visually similar PN-odes; (ii) two set of PNodes are visually similar if they con-tain nodes which leafs are spatially arranged in similar way on the rendered Web page and that have similar presenta-tion features. Spatial arrangement of PNodes are computed by using the Rectangular Cardinal Relation model (RCR) [3] widely adopted in spatial reasoning. Roughly speaking, given a set of PNodes, the spatial context represents, for each pair of PNodes in the set, reciprocal RCRs. The spa-tial context of a set of PNodes is computed by means the function Context : 2 V  X  2 V  X  V  X  RCR  X  RCR , that for each pair of PNodes in the input set of PNodes compare coordi-nates and computes direct and inverse RCR relations.
In this section we present the spatial instance learning algorithm that extracts data records and items from Deep Web pages by exploiting visual patterns created by Web designers in order to help human readers in making sense of Deep Web pages contents. The Algorithm 1 takes as input a PDOM and returns a set of data records instances with aligned data items.

Algorithm 1 consists of the two steps described below: 1. Data region and data record identification . In this step 2. Data records and data item extraction . In this step
The instance learning approach presented in the paper has been experimentally evaluated on a dataset of 210 Deep Web Pages randomly selected from most known Deep Web Sites 2 . Table 5 shows results obtained by applying the SILA algorithm, and compares such results with those obtained on the same dataset by applying MDR [1] and ViNTs [7] approaches. It is noteworthy that versions of MDR and ViNTS available on the Web allow for performing only data record extraction. Precision and Recall of SILA, in extract-ing data records, have been 99,79%, and 98,19% respectively. Whereas, MBR has Precision 25,61%, and Recall 46,75%, and ViNTs has Precision 53,57%, and Recall 50,47%. Pre-cision and Recall of SILA, in extracting data items, have
The adopted dataset, and a more complete ver-sion of experimental results, are available at www.icar.cnr.it/ruffolo/SILA/dataset been 95,68%, and 99,40% respectively. Whereas MDR and ViNTs are unable to extract data items.
 Table 1: Precision and Recall Scores for 210 pages from 70 Deep Web sites
In this paper has been presented SILA a novel spatial instance learning approach for Deep Web pages. SILA is based on: (i) the novel Positional Document Object Model (PDOM) that represents both spatial and presentation fea-tures of data records and data items/fields produced by lay-out engines of Web browser in rendering Deep Web pages; (ii) the novel visual similarity measure that computes simi-larity between sets of PDOM nodes by exploiting their spa-tial and presentation features. Such a measure considers two set of PDOM nodes similar if leaf nodes they contain have a similar spatial arrangement and similar presentation fea-tures on the Deep Web page. This visual similarity measure exploits the rectangular cardinal relation model [3] widely adopted in spatial reasoning. So at the best of our knowl-edge this is the first paper in which models and results com-ing from the spatial reasoning fields have been applied to automatic instance learning on the Web and Web informa-tion extraction. Experiments carried out on 210 Deep Web pages randomly selected from well known Deep Web sites, show very high precision and recall. [1] B. Liu, R. Grossman, and Y. Zhai. Mining data records [2] W. Liu, X. Meng, and W. Meng. Vide: A vision-based [3] I. Navarrete and G. Sciavicco. Spatial reasoning with [4] E. Oro, M. Ruffolo, and S. Staab. Sxpath -extending [5] N. K. Papadakis, D. Skoutas, K. Raftopoulos, and [6] Y. Zhai and B. Liu. Structured data extraction from [7] H. Zhao, W. Meng, Z. Wu, V. Raghavan, and C. Yu.
