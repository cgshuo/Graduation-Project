 Semantic Role Labelling (SRL, M  X  arquez et al., 2008) is generally understood as the task of iden-tifying and classifying the semantic arguments and modifiers of the predicates mentioned in a sentence. For example, in the case of the following sentence: we are to find out that for the predicate token  X  X lays X  with sense  X  X lay a role X  (play.02) the phrase headed by the token  X  X aag X  is referring to the player (A0) of the play event, and the phrase headed by the token  X  X lianti X  is referring to the role (A1) being played. SRL is considered as a key task for applications that require to answer  X  X ho X ,  X  X hat X ,  X  X here X , etc. questions, such as Information Extraction, Question Answering and Summarization.

Any real-world SRL system needs to make sev-eral decisions, either explicitly or implicitly: which are the predicate tokens of a sentence (predicate identification), which are the tokens that have se-mantic roles with respect to these predicates (argu-ment identification), which are the roles these to-kens play (argument classification), and which is the sense of the predicate (sense disambiguation).
In this paper we use Markov Logic (ML), a Statis-tical Relational Learning framework that combines First Order Logic and Markov Networks, to develop a joint probabilistic model over all decisions men-tioned above. The following paragraphs will moti-vate this choice.

First, it allows us to readily capture global cor-relations between decisions, such as the constraint that a predicate can only have one agent. This type of correlations has been successfully exploited in several previous SRL approaches (Toutanova et al., 2005; Punyakanok et al., 2005).

Second, we can use the joint model to evaluate the benefit of incorporating decisions into the joint model that either have not received much attention within the SRL community (predicate identification and sense disambiguation), or been largely made in isolation (argument identification and classification for all predicates of a sentence).

Third, our ML model is essentially a template that describes a class of Markov Networks. Algorithms can perform inference in terms of this template with-out ever having to fully instantiate the complete Markov Network (Riedel, 2008; Singla and Domin-gos, 2008). This can dramatically improve the effi-ciency of an SRL system when compared to a propo-sitional approach such as Integer Linear Program-ming (ILP).
 Finally, when it comes to actually building an SRL system with ML there are  X  X nly X  four things to do: preparing input data files, converting out-put data files, and triggering learning and inference. The remaining work can be done by an off-the-shelf Markov Logic interpreter. This is to be con-trasted with pipeline systems where several compo-nents need to be trained and connected, or Integer Linear Programming approaches for which we need to write additional wrapper code to generate ILPs.
Empirically we find that our system is competitive X  X ur best model would appear on par with the best entry in the CoNLL 2008 shared task open track, and at the 4th place of the closed track X  X ight behind systems that use significantly better parsers 1 to generate their input features.
We also observe that by integrating frame disam-biguation into the joint SRL model, and by extract-ing all arguments for all predicates in a sentence simultaneously, significant improvements compared to more isolated systems can be achieved. These improvements are particularly large in the case of out-of-domain data, suggesting that a joint approach helps to increase the robustness of SRL. Finally, we show that despite the joint approach, our system is still efficient.

Our paper is organised as follows: we first intro-duce ML (section 2), then we present our model in terms of ML (section 3) and illustrate how to per-form learning and inference with it (section 4). How this model will be evaluated is explained in section 5 with the corresponding evaluation presented in sec-tion 6. We conclude in section 7. Markov Logic (ML, Richardson and Domingos, 2005) is a Statistical Relational Learning language based on First Order Logic and Markov Networks. It can be seen as a formalism that extends First Or-der Logic to allow formulae that can be violated with some penalty. From an alternative point of view, it is an expressive template language that uses First Or-der Logic formulae to instantiate Markov Networks of repetitive structure.

Let us describe ML by considering the predicate identification task. In ML we can model this task by first introducing a set of logical predicates 2 such as isPredicate(Token) or word(Token,Word) . Then we specify a set of weighted first order formulae that define a distribution over sets of ground atoms of these predicates (or so-called possible worlds ).
Ideally, the distribution we define with these weighted formulae assigns high probability to possi-ble worlds where SRL predicates are correctly iden-tified and a low probability to worlds where this is not the case. For example, a suitable set of weighted formulae would assign a high probability to the world 3 and a low one to In Markov Logic a set of weighted formulae is called a Markov Logic Network (MLN). Formally speak-ing, an MLN M is a set of pairs (  X , w ) where  X  is a first order formula and w a real weight. M assigns the probability to the possible world y . Here C  X  is the set of all possible bindings of the free variables in  X  with the constants of our domain. f  X  c is a feature function that returns 1 if in the possible world y the ground formula we get by replacing the free variables in  X  by the constants in c is true and 0 otherwise. Z is a normalisation constant. Note that this distri-bution corresponds to a Markov Network (the so-called Ground Markov Network ) where nodes repre-sent ground atoms and factors represent ground for-mulae.
For example, if M contains the formula  X  then its corresponding log-linear model has, among others, a feature f  X  placed by the constant t 1 and that returns 1 if is true in y and 0 otherwise.

We will refer predicates such as word as observed because they are known in advance. In contrast, is-Predicate is hidden because we need to infer it at test time. Conceptually we divide our SRL system into three stages: one stage that identifies the predicates of a sentence, one stage that identifies and classifies the arguments of these predicates, and a final stage that predicts the sense of each predicate. We should stress that this architecture is intended to illustrate a typical SRL system, and to describe the pipeline-based approach we will compare our models to. However, it does not correspond to the way in-ference is performed in our proposed model X  X e jointly infer all decisions described above.
Note that while the proposed division into con-ceptual stages seems somewhat intuitive, it is by no means uncontroversial. In fact, for the CoNLL 2008 shared task slightly more than one half of the par-ticipants performed sense disambiguation before ar-gument identification and classification; most other participants framed the problem in the reverse or-der. 4
We define five hidden predicates for the three stages of the task. Figure 1 illustrates these pred-icates and the stage they belong to. For predicate identification, we use the predicate isPredicate . is-Predicate(p) indicates that the word in the position p is an SRL predicate. For argument identifica-tion and classification, we use the predicates isAr-gument , hasRole and role . The atom isArgument(a) signals that the word in the position a is a SRL ar-gument of some (unspecified) SRL predicate while hasRole(p,a) indicates that the token at position a is an argument of the predicate in position p . The pred-icate role(p,a,r) corresponds to the decision that the argument at position a has the role r with respect to the predicate in position p . Finally, for sense disam-biguation we define the predicate sense(p,e) which signals that the predicate in position p has the sense e .

Before we continue to describe the formulae of our Markov Logic Network we would like to high-light the introduction of the isArgument predicate mentioned above. This predicate corresponds to a decision that is usually made implicitly: a token is an argument if there exists a predicate for which it plays a semantic role. Here we model this decision explicitly, assuming that there exist cases where a token clearly has to be an argument of some pred-icate, regardless of which predicate in the sentence this might be. It is this assumption that requires us to infer the arguments for all predicates of a sentence at once X  X therwise we cannot make sure that for a marked argument there exists at least one predicate for which the argument plays a semantic role.
In addition to the hidden predicates, we define observable predicates to represent the information available in the corpus. Table 1 presents these pred-icates. 3.1 Local formulae A formula is local if its groundings relate any num-ber of observed ground atoms to exactly one hidden ground atom. For example, two groundings of the local formula lemma ( p, + l 1 )  X  lemma ( a, + l 2 )  X  hasRole ( p, a ) can be seen in the Factor Graph of Figure 2. Both connect a single hidden hasRole ground atom with two observed lemma ground atoms. The + notation indicates that the MLN contains one instance of the rule, with a separate weight, for each assignment of the variables with a plus sign ( ? ).

The local formulae for isPredicate , isArgument and sense aim to capture the relation of the tokens with their lexical and syntactic surroundings. This includes formulae such as which implies that a certain token is a predicate with a weight that depends on the subcategorization frame of the token. Further local formulae are con-structed using those observed predicates in table 1 that relate single tokens and their properties.
The local formulae for role and hasRole focus on properties of the predicate and argument token X  X he formula illustrated in figure 2 is an example of this X  and on the relation between the two tokens. An ex-ample of the latter type is the formula which implies that token a plays the semantic role r with respect to token p , and for which the weight de-pends on the syntactic (dependency) path d between p and a and on the actual role to assign. Again, further formulae are constructed using the observed predicates in table 1; however, this time we consider both predicates that relate tokens to their individual properties and predicates that describe the relation between tokens.

Unfortunately, the complete set of local formulae is too large to be exhaustively described in this pa-per. Its size results from the fact that we also con-sider conjunctions of several atoms as conditions, and lexical windows around tokens. Hence, instead of describing all local formulae we refer the reader to our MLN model files. 5 They can be used both as a reference and as input to our Markov Logic En-gine, 6 and thus allow the reader to easily reproduce our results. 3.2 Global formulae Global formulae relate several hidden ground atoms. We use this type of formula for two purposes: to ensure consistency between the predicates of all SRL stages, and to capture some of our background knowledge about SRL. We will refer to formulae that serve the first purpose as structural constraints .
For example, a structural constraint is given by the (deterministic) formula which ensures that, whenever the argument a is given a label r with respect to the predicate p , this argument must be an argument of a as denoted by hasRole(p,a) . Note that this formula by itself models the traditional  X  X ottom-up X  argument identification and classification pipeline (Xue and Palmer, 2004): it is possible to not assign a role r to an predicate-argument pair ( p, a ) proposed by the identification stage; however, it is impossible to assign a role r to token pairs ( p, a ) that have not been proposed as potential arguments.

An example of another class of structural con-straints is which, by itself, models an inverted or  X  X op-down X  pipeline. In this architecture the argument classifi-cation stage can assign roles to tokens that have not been proposed by the argument identification stage. However, it must assign a label to any token pair the previous stage proposes.

For the SRL predicates that perform a labelling task ( role and sense ) we also need a structural con-straint which ensures that not more than one label is assigned. For instance, forbids two different semantic roles for a pair of words.

There are three global formulae that capture our linguistic background knowledge. The first one is a deterministic constraint that had been frequently applied in the SRL literature. It forbids cases where distinct arguments of a predicate have the same role unless the role describes a modifier:
The second  X  X inguistic X  global formula is role ( p, a, + r )  X  lemma ( p, + l )  X  sense ( p, + s ) which implies that when a predicate p with lemma l has an argument a with role r it has to have the sense s . Here the weight depends on the combination of role r , lemma l and sense s .

The third and final  X  X inguistic X  global formula is It implies that if a predicate p has the lemma l and an argument a with POS tag p it has to have the sense s . This time the weight depends on the combination of POS tag p , lemma l and sense s .

Note that the final two formulae evaluate the se-mantic frame of a predicate and become local for-mulae in a pipeline system that performs sense dis-ambiguation after argument identification and clas-sification.

Table 2 summarises the global formulae we use in this work. Assuming that we have an MLN, a set of weights and a given sentence then we need to predict the choice of predicates, frame types, arguments and role labels with maximal a posteriori probabil-ity (MAP). To this end we apply a method that is both exact and efficient: Cutting Plane Infer-ence (CPI, Riedel, 2008) with Integer Linear Pro-gramming (ILP) as base solver .

Instead of fully instantiating the Markov Network that a Markov Logic Network describes, CPI begins with a subset of factors/edges X  X n our case we use the factors that correspond to the local formulae of our model X  X nd solves the MAP problem for this subset using the base solver. It then inspects the solution for ground formulae/features that are not yet included but could, if added, lead to a different solution X  X his process is usually referred to as sep-aration . The ground formulae that we have found are added and the network is solved again. This pro-cess is repeated until the network does not change anymore.

This type of algorithm could also be realised for an ILP formulation of SRL. However, it would re-quire us to write a dedicated separation routine for each type of constraint we want to add. In Markov Logic, on the other hand, separation can be gener-ically implemented as the search for variable bind-ings that render a weighted first order formulae true (if its weight is negative) or false (if its weight is positive). In practise this means that we can try new global formulae/constraints without any additional implementation overhead.

We learn the weights associated with each MLN using 1-best MIRA (Crammer and Singer, 2003) Online Learning method. As MAP inference method that is applied in the inner loop of the on-line learner we apply CPI, again with ILP as base solver. For training and testing our SRL systems we used a version of the CoNLL 2008 shared task (Surdeanu et al., 2008) dataset that only mentions verbal predi-cates, disregarding the nominal predicates available in the original corpus. 7 While the original (open track) corpus came with MALT (Nivre et al., 2007) dependencies, we observed slightly better results when using the dependency parses generated with a Charniak parser (Charniak, 2000). Hence we used the latter for all our experiments.

To assess the performance of our model, and it to evaluate the possible gains to be made from consid-ering a joint model of the complete SRL pipeline, we set up several systems. The full system uses a Markov Logic Network with all local and global for-mulae described in section 3. For the bottom-up sys-tem we removed the structural top-down constraints from the complete model X  X revious work Riedel and Meza-Ruiz (2008) has shown that this can lead to improved performance. The bottom-up (-arg) sys-tem is equivalent to the bottom-up system, but it does not include any formulae that mention the hid-den isArgument predicate.

For the systems presented so far we perform joint inference and learning. The pipeline system dif-fers in this regard. For this system we train a sep-arate model for each stage in the pipeline of figure 1. The predicate identification stage identifies the predicates (using all local isP redicate formulae) of a sentence. The next stage predicts arguments and their roles for the identified predicates. Here we in-clude all local and global formulae that involve only the predicates of this stage. In the last stage we pre-dict the sense of each identified predicate using all formulae that involve the sense , without the struc-tural constraints that connect the sense predicate to the previous stages of the pipeline (these constraints are enforced by architecture). Table 3 shows the results of our systems for the CoNLL 2008 development set and the WSJ and brown test sets. The scores are calculated using the semantic evaluation metric of the CoNLL-08 shared task (Surdeanu et al., 2008). This metric measures the precision, recall and F 1 score of the recovered semantic dependencies. A semantic dependency is created for each predicate and its arguments, the label of such dependency is the role of the argu-ment. Additionally, there is a semantic dependency for each predicate and a ROOT argument which has the sense of the predicate as label.

To put these results into context, let us compare them to those of the participants of the CoNLL 2008 shared task (see the last three rows of table 3). 8 Our best model, Bottom-up, would reach the highest F 1 WSJ score, and second highest Brown score, for the open track. Here the best-performing participant was Vickrey and Koller (2008).

Table 3 also shows the results of the best (Jo-hansson and Nugues, 2008) and fourth best sys-tem (Zhao and Kit, 2008) of the closed track. We note that we do significantly worse than Johansson and Nugues (2008), and roughly equivalent to Zhao and Kit (2008); this places us on the fourth rank of 19 participants. However, note that all three sys-tems above us, as well as Zhao and Kit (2008), use parsers with at least about 90% (unlabelled) accu-racy on the WSJ test set (Johansson X  X  parser has about 92% unlabelled accuracy). 9 By contrast, with about 87% unlabelled accuracy our parses are sig-nificantly worse.

Finally, akin to Riedel and Meza-Ruiz (2008) we observe that the bottom-up joint model performs better than the full joint model.
 6.1 Joint Model vs. Pipeline Table 3 suggests that by including sense disam-biguation into the joint model (as is the case for all systems but the pipeline) significant improvements can be gained. Where do these improvements come from? We tried to answer this question by taking a closer look at how accurately the pipeline predicts the isP redicate , isArgument , hasRole , role and sense relations, and how this compares to the result of the joint full model.

Table 4 shows that the joint model mainly does better when it comes to predicting the right predi-cate senses. This is particularly true for the case of the Brown corpus X  X ere we gain about 10% points. These results suggest that a more joint approach may be particularly useful in order to increase the robust-ness of an SRL system in out-of-domain scenarios. 10 6.2 Modelling if a Token is an Argument In table 3 we also observe that improvements can be made if we explicitly model the decision whether a token is a semantic argument of some predicate or not. As we mentioned in section 3, this aspect of our model requires us to jointly perform inference for all predicates of a sentence, and hence our results justify the per-sentence SRL approach proposed in this paper.

In order to analyse where these improvements come from, we again list our results on a per-SRL-predicate basis. Table 5 shows that by including the isArgument predicate and the corresponding for-mulae we gain around 0.6% and 1.0% points across the board for WSJ and Brown, respectively. 11 As shown in table 3, these improvements result in about 1.0% improvements for both WSJ and Brown in terms of the CoNLL 2008 metric. Hence, an ex-plicit model of the  X  X s an argument X  decision helps the SRL at all levels.

How the isArgument helps to improve the over-all role labelling score can be illustrated with the example in figure 3. Here the model without a hidden isArgument predicate fails to attach the preposition  X  X n X  to the predicate  X  X tart.01 X  (here 01 refers to the sense of the predicate). Apparently the model has not enough confidence to assign the preposition to either  X  X tart.01 X  or  X  X et.03 X , so it just drops the argument altogether. However, because the isArgument model knows that most preposi-tions have to be modifying some predicate, pres-sure is created that forces a decision between the two predicates. And because for the role model  X  X tart.01 X  looks like a better fit than  X  X et.03 X , the correct attachment is found.
 6.3 Efficiency In the previous sections we have shown that our joint model indeed does better than an equivalent pipeline system. However, usually most joint approaches come at a price: efficiency. Interestingly, in our case we observe the opposite: our joint model is actually faster than the pipeline. This can be seen in table 6, where we list the time it took for several different system to process the WSJ and Brown test corpus, respectively. When we compare the times for the bottom-up model to those of the pipeline, we note that the joint model is twice as fast. While the indi-vidual stages within the pipeline may be faster than the joint system (even when we sum up inference times), extracting results from one system and feed-ing them into another creates overhead which offsets this potential reduction.

Table 6 also lists the run-time of a bottom-up system that solves the inference problem by fully grounding the Markov Network that the Markov Logic (ML) model describes, mapping this network to an Integer Linear Program, and finding the most likely assignment using an ILP solver. This sys-tem (Bottom-up (-CPI)) is four times slower than the equivalent system that uses Cutting Plane Inference (Bottom-up). This suggests that if we were to imple-ment the same joint model using ILP instead of ML, our system would either be significantly slower, or we would need to implement a Cutting Plane algo-rithm for the corresponding ILP formulation X  X hen we use ML this algorithm comes  X  X or free X .
 In this paper we have presented a Markov Logic Net-work that jointly models all predicate identification, argument identification and classification and sense disambiguation decisions for a sentence. We have shown that this approach is competitive, in particular if we consider that our input parses are significantly worse than those of the top CoNLL 2008 systems.
We demonstrated the benefit of jointly predicting senses and semantic arguments when compared to a pipeline system that first picks arguments and then senses. We also showed that by modelling whether a token is an argument of some predicate and jointly picking arguments for all predicates of a sentence, further improvements can be achieved.

Finally, we demonstrated that our system is effi-cient, despite following a global approach. This ef-ficiency was also shown to stem from the first order inference method our Markov Logic engine applies. The authors are grateful to Mihai Surdeanu for pro-viding the version of the corpus used in this work. Eugene Charniak. A maximum-entropy-inspired parser. In Proceedings of NAACL-2000 , 2000. Koby Crammer and Yoram Singer. Ultraconserva-tive online algorithms for multiclass problems.
Journal of Machine Learning Research , 3:951 X  991, 2003.
 Richard Johansson and Pierre Nugues. Dependency-based semantic role labeling of propbank. In Pro-ceedings of EMNLP-2008. , 2008.
 Llu  X   X s M  X  arquez, Xavier Carreras, Ken Litkowski, and
Suzanne Stevenson. Semantic role labeling. Com-putational Linguistics , 34(2), 2008. Introduction to the Special Issue on Semantic Role Labeling. J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kuebler, S. Marinov, and E. Marsi. Malt-
Parser: A language-independent system for data-driven dependency parsing. Natural Language Engineering , 13(02):95 X 135, 2007.
 V. Punyakanok, D. Roth, and W. Yih. General-ized inference with multiple semantic role label-ing systems. In Ido Dagan and Dan Gildea, ed-itors, CoNLL  X 05: Proceedings of the Annual Conference on Computational Natural Language Learning , pages 181 X 184, 2005.
 Matthew Richardson and Pedro Domingos. Markov logic networks. Technical report, University of Washington, 2005.
 Sebastian Riedel. Improving the accuracy and ef-ficiency of map inference for markov logic. In
UAI  X 08: Proceedings of the Annual Conference on Uncertainty in AI , 2008.
 Sebastian Riedel and Ivan Meza-Ruiz. Collective semantic role labelling with markov logic. In Conference on Computational Natural Language Learning , 2008.
 P. Singla and P. Domingos. Lifted First-Order Belief Propagation. Association for the Advancement of Artificial Intelligence (AAAI) , 2008.
 Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu  X   X s M ` arquez, and Joakim Nivre. The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Lan-guage Learning (CoNLL-2008) , 2008.
 Kristina Toutanova, Aria Haghighi, and Christo-pher D. Manning. Joint learning improves seman-tic role labeling. In ACL  X 05: Proceedings of the 43rd Annual Meeting on Association for Compu-tational Linguistics , Morristown, NJ, USA, 2005. David Vickrey and Daphne Koller. Applying sen-tence simplification to the conll-2008 shared task. In Proceedings of CoNLL-2008. , 2008.
 Nianwen Xue and Martha Palmer. Calibrating fea-tures for semantic role labeling. In EMNLP  X 04:
Proceedings of the Annual Conference on Em-pirical Methods in Natural Language Processing , 2004.
 Hai Zhao and Chunyu Kit. Parsing syntactic and se-mantic dependencies with two single-stage max-imum entropy models. In CoNLL 2008: Pro-ceedings of the Twelfth Conference on Computa-tional Natural Language Learning , Manchester,
England, 2008.
