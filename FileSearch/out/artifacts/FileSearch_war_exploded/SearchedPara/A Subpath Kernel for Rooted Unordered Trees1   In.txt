 Daisuke Kimura 1 ,TetsujiKuboyama 2 , Tetsuo Shibuya 3 , and Hisashi Kashima 1 Recently, machine learning methods for com plex-structured data such as strings, trees and graphs, have been becoming incr easingly important. In natural lan-guage processing, sentences are often re presented as strings, and parsed sen-tences are represented as trees [2]. In bioinformatics, there are various kinds of sequential-structure data such as DNAs, RNAs and proteins, and tree-structured data such as glycans and secondary stru ctures of RNAs. Som etimes structures of chemical compounds and proteins are represented as graph-structured data. In Web mining, documents are written i n tree-structured XML and HTML, and access and purchase behaviors of visito rs to Web pages are represented as trees or graphs. Effective and efficient analysis of such complex-structured data play key roles in businesses, healthcare and scientific researches.

In this paper, we focus on learning with tr ee-structured data, m ore specifically, rooted unordered trees. In general learni ng problems, data are represented as vectors in a feature space. If we can pro perly define the bases of the feature space, we can just pass the feature vect ors to learning algorithms. However, when we handle more complex-structured data such as sequences, trees, and graphs that have structures among their constituent elements, proper vector representation is not obvious, and the step of feature design can be difficult and time-consuming.

Probably, one of the reasonable strategies for handling such complex-structured data is to use their local structures as features, for example, sub-strings and subsequences for strings, subtrees and tree-structured subgraphs for trees, and paths and subgraphs for graphs. The feature vectors can be con-structed by using the numbers of times such substructures appear in target data as features. However, as the numbers of such substructures are enormous, it is sometimes prohibitive to explicitly enumerate them to construct feature vectors. There is also another serious problem ca lled  X  X urse of dimensionality X , which is degradation of predictive performance in high-dimensional feature spaces.
Kernel methods [3] are one of the promising approaches to learning with complex-structured data. Kernel methods use only the inner products of feature vectors when they access data. This mean s that even if the dimensionality of the feature vector is extremely large, the dimensionality does not explicitly af-fect the computational cost as long as efficient procedures to compute the inner products are available. The functions computing the inner products efficiently are called  X  X ernel functions X , and kern el methods can work efficiently in high dimensional feature spaces by using kernel functions. Moreover, a well-known kernel method, the support vector machine(SVM), is known to have good gen-eralization properties, both theoretically and experimentally, and overcome the  X  X urse of dimensionality X  problem in high dimensional feature spaces [4].
Haussler [5] introduced convolution kernels, a general framework for handling discrete data structures with kernel methods. In convolution kernels, structured data are decomposed into their parts, and kernel functions are defined in terms of the parts. By using this framework, Collins and Duffy [6] designed a convolu-tion kernel for parse trees used in natural language processing. They implicitly constructed feature vectors by using th e number of times each tree-structured subgraph appears in parse trees, and defined a kernel function as the inner product of those feature vectors. They proposed an efficient kernel computation algorithm by using dynamic programming. After the seminal work by Collins and Duffy [6], various kernels for more general trees were developed including labeled ordered trees [7,8] and variants of ordered trees such as positional trees [9] and syntactic trees [10]. However, the re are only a few works on kernel design for rooted unordered trees because of the hardness result for computing gen-eral kernels for unordered trees [11]. Vishwanathan et al. [1] proposed a simple but efficient kernel for unordered trees ba sed on subtrees. It converts trees into strings, and boils down tree comparison to string comparison. By employing ap-propriate data structures such as suffix trees and suffix arrays, their kernel can be computed in linear time, that is, O( | T 1 | + | T 2 | ). The feature space spanned by the linear-time tree kernel is constructe d not by using tree-structured subgraphs, but by using subtrees. Therefore, the kernel is suitable for capturing horizon-tal substructures, but not for vertical s ubstructures such as paths from root to leaves.

On the other hand, in the context of information retrieval, Ichikawa et al. [12] proposed a tree similarity using subpaths of paths from tree root to leaves, and showed its effectiveness in text retrieval tasks. Inspired by their work, we propose a new tree kernel for rooted unordered trees based on tree subpaths, and a fast and space-efficient algorithm to compute the kernel by extending the multikey quicksort algorithm [13] for sorting strings. The computational complexity of linear-time tree kernel by vishwanathan et al. [1]. However, in practice, it is very efficient, and actually, faster than the lin ear-time kernel in our experiments.
Finally, we demonstrate the predictiv e accuracy and efficiency of the proposed kernel by using two tasks, XML classification task in Web mining, and glycan classification tasks in bioinformatics. The results show our kernel is competitive with the linear-time tree kernel in predictive performance, and is faster than the linear-time kernel.

This paper is organized as follows. Sect ion 2 reviews the existing tree ker-nels such as the parse tree kernel [6], th e labeled ordered tree kernel [7], and especially the linear-time tree kernel [1]. In Section 3, based on the idea of tree subpaths [12], we propose a new tree kernel by using the subpaths. We also propose an efficient algorithm for computing the proposed kernel function. In Section 4, we show experimental results on two kinds of classification tasks, one with XML data, and the other one with glycan data. Section 5 reviews the re-lated work, and Section 6 gives discussion and future work, and concludes this paper. Vishwanathan et al. [1] proposed a linear-time kernel for rooted labeled un-ordered trees, whose computational complexity is O( | T 1 | + | T 2 | ). The substruc-tures that the kernel can use as features ar e restricted to a subset of those used by the previous tree kernels. However, thanks to this simplification, they achieved the linear-time complexity.

The basic idea of their tree kernel is to convert two trees into two strings and then apply the string kernel to them. First, it converts the two trees into two string as follows. Let us denote by T one of the target trees, and by label ( n s )the label of a node n s in T . tag ( n s ) denotes the string repre sentation of the subtree of T rooted at n s . Therefore, tag ( n root ) is the string representation of T ,where n root is the root of T . We recursively apply the following steps in a bottom-up manner to obtain tag ( n root ).
  X  If the node n s is a leaf, let tag ( n s )=[ label ( n s )].  X  If the node n s is not a leaf and has c children n 1 ,n 2 ,...,n c ,sort Figure 1 shows an example of the tree-to-string conversion. In the resultant string, a substring starting from  X  [ X  and ending at  X  ] X  with the same number of  X  [ X  X  and  X  ] X  X  corresponds to a subtree rooted at a particular node. We apply the above conversion to two trees T 1 and T 2 to obtain two strings S 1 and S 2 . Now we define the tree kernel between T 1 and T 2 viathetwostrings S 1 and S 2 as where  X   X  is the set of substrings of S 1 and S 2 , num ( S 1 s )and num ( S 2 s )are the numbers of times a substring s appears in S 1 and S 2 , respectively. w | s | is a weight parameter for substrings of length | s | . Typical choices for w | s | are:  X  constant weighting (defined as w | s | =1),  X  k -spectrum weighting (defined as w | s | =1if | s | = k ,and w | s | =0otherwise),  X  exponential weighting (defined as w | s | =  X  | s | where 0  X   X &lt; 1 is a decaying To compute the kernel (1), it is sufficient to enumerate all of the common sub-strings of S 1 and S 2 , and to count the numbers of times they occur in each of S 1 and S 2 . It can be done in O( | S 1 | + | S 2 | ) time by employing suffix trees or suffix arrays [1,14]. If we assume the maximum number of bits needed to describe a node label is constant, the lengths of the converted strings are | S 1 | =O( | T 1 | ) and | S 2 | =O( | T 2 | ), respectively. Therefore, th e computational complexity of computing the kernel function (1) is O( | T 1 | + | T 2 | ).

Despite the efficiency of the linear-time tree kernel, there is a drawback of the linear-time tree kernel. The drawback is that the kernel considers only subtrees as features, namely, subtrees were required to match some portion of the labeled unordered tree perfectly. Such a proper ty is not preferred in the case of large trees and many kinds of node labels. 3.1 Subpath Set In this section, we propose another efficien t tree kernel that can capture vertical structures in trees without false positi ve enumerations of common substructures. Since tree-structured data often represe nt hierarchical stru ctures such as inclu-sive relations of tags in HTML and XML documents, it is important for tree kernels to take such vertical structures into account. We employ the idea of sub-path sets introduced by Ichikawa et al. [12], who modeled a sentence as a tree and used tree similarities for information retrieval. A substring of a path from the root to one of the leaves is called a subpath, and a subpath set is a set of subpaths included in trees. They defined a similarity measure using the subpath set. Figure 2 shows an example of a subpath set.
 3.2 A Subpath Tree Kernel Let us assume that we want to define a tree kernel K ( T 1 ,T 2 ) between two trees T 1 and T 2 . By using the subpath set,we define our tree kernel as where S is the subpath set of T 1 and T 2 , | p | is the number of nodes included in a subpath, and num ( T 1 p )and num ( T 2 p ) are the numbers of a subpath p included in T 1 and T 2 , respectively. w | p | is the weight parameter introduced in Section 2.
Therefore, the proposed kernel defines its features as a subpath set, and takes the inner product of two feature vectors with weights according to subpath lengths. Figure 3 shows an example of a common subpath set of two trees. 3.3 An Efficient Algorithm for the Subpath Tree Kernel Since the size of a subpath set of a tree T is O( | T | 2 ) generally, naive computation of the subpath tree kernel (2) costs O( | T | 2 )-computation tim e. In this subsec-tion, we propose a more efficient algorithm by extending the multikey quicksort algorithm [13].

The basic idea behind our algorithm is to enumerate prefixes of common suffixes of two trees, where a suffix of a tree is the string starting from a node and ending at the root. For example, in Figure 2, the set of suffixes of the tree is {
A, BA, CA, DBA, EBA } . When the number of nodes in a tree is n ,thenumber of suffixes is also n .
 where label ( m ) denotes the label of node m and label ( n root ) denotes the root label. Let d be the number of nodes included in this suffix. We call path set is defined as the substrings of a path from the root to a leaf, prefixes of all suffixes of a tree are identical to the set of (reversed) subpaths. Therefore, we can compute the kernel (2) by enumerating all prefixes of common suffixes of two trees.

Next, we describe an efficient way to e numerate all prefixes of common suf-fixes of two trees. We extend the idea of the multikey quicksort algorithm [13], which is a simple and efficient algorithm for sorting a set of strings. The multikey quicksort algorithm resembles the general quicksort algorithm, but is different from the quicksort in the following two points. (1) The multikey quicksort al-phabetically compares labels in strings from their beginning to the end one by one (not the whole strings). The comparison starts at the first labels, and pro-ceed to the next position if sorting is no t completed yet. (2) At each step of the algorithm, the multikey quicksort sets a pivot, and divides the strings into three groups by comparing the labels at the current position with the pivot.
The following is a brief description of the algorithm of the multikey quicksort. 1. Initialize the current position h as h := 1, and the current set S as the set 2. For strings included in the current set S , The multikey quicksort recursively divides the dataset by using pivots just as the quicksort algorithm with incrementing the current position. If the number of target strings is n , the multikey quicksort runs in O( n log n ) on average, and O( n 2 )intheworstcase.

Extending the idea of the multikey quicksort, the algorithm for computing the proposed kernel function (2) between two trees T 1 and T 2 is described as follows. 1. Initialize the kernel function value k as k := 0, the current position h as 2. For nodes included in the current set S , The proposed algorithm recursively computes the kernel function in a bottom-up manner. At each recursion of the algorit hm, we recursively divide a current node set into three non-overlapping sets just like the multikey quicksort. Therefore, and O(( | T 1 | + | T 2 | ) 2 ) in the worst case, which is more efficient the original tree kernels. The time complexity is slightly worse than that of [1], but in practice, our algorithm is more efficient than the linear-time kernel, which will be demon-strated in the experimental section. Note that the pointers from nodes to parents can be constructed in linear time b y using the depth first search.

Figure 4 shows an illustration of how the algorithm works for the two trees given in Figure 3. At the first step, the algorithm initializes the current position h and the kernel function value k as h =: 1 and k := 0, respectively. It sets the current set S as the union set of all nodes in T 1 and T 2 . For example in Figure 3, T 1 : D indicates that S includes a node with label  X  D  X  X n T 1 .AtStep 2(a), the algorithm chooses one of the node labels in S as a pivot at random. In this example, let us assume that we choose B as the pivot label. Then in Step 2(b), we compare the labels in S with the pivot label, and divide the nodes in the current set into three sets, S small (= { T 1 : A , T 2 : A } ), S equal (= { T 1 : B , T 2 : B the algorithm recursively calls itself for each of S small and S large (at Step 2(c) and Step 2(d)). As for S equal ,itupdates k and h , and recursively applies the algorithm for S := parents ( S equal ) (at Step 2(e)).

This algorithm enumerates all of the prefixes of the common suffixes of two trees, but it does not explicitly construct all of the suffixes in memory. The memory required for the explicit construction is O( | T 1 | 2 + | T 2 | 2 ), which can not achieve the time complexity of the proposed algorithm.

We can imagine that other efficient data structures such as the suffix tree of a tree can be an option for efficient computat ion of the kernel. Several linear-time construction algorithms of the suffix tree of a tree were proposed, e.g. by [15]. However, to apply it to the kernel computation, if one node has several children with an identical label, we need to merge them to one node, which changes the structure of the target tree and res ults in imprecise kernel values.
In addition to the practical efficiency of the proposed algorithm, another virtue of the algorithm is its simpleness. This is contrast with the fact that efficient implementations of the linear-time approaches using suffix arrays or suffix trees are very complex. In this section, we demonstrate the performance of the proposed tree kernel for binary classification tasks by using three datasets.

First, we compare the predictive perfor mance of the proposed kernel (denoted by  X  X ubpath X ) and the linear-time tree kernel [1] (denoted by  X  X ishwanathan X ) combined with the three weighting schem es [14], the consta nt weighting (CW), the k-spectrum weighting (kSW) and the exponential weighting (EW) defined in Eqs. (2) and (1). We also use the three baseline kernels based on similarity measures proposed by Kailing et al. [16] (denoted by  X  X ailing X ). In Kailing ker-nels, each kernel is defined as the L 1 distance of histograms of heights, degrees or node labels. All of the performance results are evaluated in AUC measured by using the 10-fold cross-validation.

Next, we compare the execution time of the proposed kernel (Subpath) to the linear-time tree kernel (Vishwanathan). We use the the linear-time tree kernel implemented by Teo and Vishwanathan [17]. We run all the experiments on a Core2 Duo 2.00GHz Windows machine. In all of the experiments, we use LIBSVM [18] as the SVM implementation. 4.1 An XML Classification Dataset In this subsection, we show experimental results using an XML dataset. We use the XML dataset provided by Zaki and Aggarwal [19]. The dataset collects the access behaviors of visitors within the Web site of some computer science department during three weeks. The access b ehaviors of a particular visitor are represented as an unordered tree. Each data is assigned either of two classes,  X  X du X  or  X  X ther X , where  X  X du X  means that the visitors came from educational domains such as universities, while  X  X ther X  corresponds to visitors from the other domains. The goal of this classification task is to discriminate visitors from  X  X du X  domain and those from the other domains. Since the dataset includes many small trees, we use only trees whose depths are more than 4. The size of the resultant dataset is 3,183 (773  X  X du X  X  and 2,410  X  X ther X  X ).
 We show the SVM classification results with the XML dataset in Figure 5. For Subpath kernel and Vishwanathan with the three weighting schemes, the constant weighting (CW), the k-spectrum weighting (kSW) and the exponen-tial weighting (EW)2). The hyper-par ameters are determined by using cross-validation.

The AUCs of the Subpath kernels with two weighting schemes (CW and EW) are higher than the Kailing kernel using node labels. Since the Kailing kernel based on node labels does not consider tr ee structures at all, this result shows that Subpath kernel can capture tree structures appropriately. Moreover, the AUC of the Subpath kernel is the highest among all of the results. In contrast to Subpath kernel, the AUCs of Vishwanathan kernel are lower than those of the Kailing kernel. This is probably because the number of different node label is very large in this XML dataset, and therefore subtrees are not appropriate as features. According to the results, the proposed Subpath kernel performs well in the XML classification task. 4.2 Glycan Classification Datasets Next, we show experimental results on glycan classification, which is an impor-tant task in bioinformatics. Glycans are carbohydrate chains, which are consid-ered to play an important role in various fundamental biological processes such as cell-cell interaction. The structure o f a glycan is abstractly represented as a tree structure by representing carbohydrates as nodes and their covalent bonds as edges. The glycan structure dataset used in the experiment was retrieved from the KEGG/GLYCAN database [20], and the annotations were retrieved from the CarbBank/CCSD database [21]. The tree structures obtained from the glycan data include 29 distinct node labels, while all the edge labels are omitted for simplicity. We evaluated the predictive performance of our tree kernels on the following two sets of glycan data, leukemia and cystic fibrosis. In the leukemia data set, the glycan structures annotated as leukemic cells were used as pos-itive training examples, while those annotated as the other blood components erythrocyte , serum ,and plasma without leukemia were used as negative training examples. The numbers of positive and ne gative data were respectively 191 and 289. In the cystic fibrosis data set, the glycan structures annotated as cystic fibrosis (a lethal genetic disorder affecting mainly the lungs and respiratory sys-tem) were used as positive training examples, while those annotated including the substring bronch and respir without cystic fibrosis were used as negative training examples. The numbers of posit ive and negative data were respectively 89 and 71.

For the cystic dataset, the overall trend in the results shown in Fig. 6 is similar to that for the XML dataset. Subpath kernel outperforms Vishwanathan kernel with any of the weighting schemes, which shows that a vertical path is effective as features. Especially, the ex ponential weighting performs the best. Vishwanathan kernel performs only slightly better than the Kailing kernel based on label nodes, although the number of node label is not so large and the size of trees is comparatively small in this dataset. This implies that subtrees are not effective features for this dataset. For the leukemia dataset, Vishwanathan kernel with the constant weight (CW) performs the best among all of the methods and the subtrees are effective as features, but Subpath kernel outperforms the linear-time kernel for the other two weighting schemes. From those results, we conclude Subpath kernel is competitive with Vishwanathan kernel in glycan classification tasks. 4.3 Comparison of Execution Times of the Proposed Kernel and In the previous subsections 4.1 and 4.2, we demonstrated that the proposed kernel (Subpath kernel) is competitive with the linear-time tree kernel (Vish-wanathan kernel) in predict ive performance by using rea l-world datasets. Here, we compare the execution time of Subpath kernel to that of Vishwanathan ker-nel on the three datasets. We calculat ed the gram matrices of the two kernels, and measured the average computation t imes needed for a single evaluation of a kernel function (by dividing the computation time of a whole gram matrix by the number of elements in the gram matrix). Figure 7 shows the average times of Subpath kernel and Vishwanathan kernel for the three datasets. The results show that Subpath kernel is consistently faster than Vishwanathan kernel, which means our kernel is quite efficient in practice despite of its worst case complexity. Since Haussler [5] introduced the framewo rk of the convolution kernel, kernel functions for various kind of discrete structures, for example, strings [22,23,24], trees [6,7,1,8,10,9], and graphs [25,26] have been proposed.

The first tree kernel was proposed for parse trees by Collins and Duffy [6], and then it was generalized for labeled orde red trees [7,8], syntactic trees [10], and positional trees [9]. However, all of these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore cannot be direct ly applied to unordered tr ees. For unordered trees, a hardness result for tree kernels using gen eral tree-structured features was shown by Kashima [11]. Vishwanathan et al. [1] proposed an efficient linear-time kernel based on subtrees.

Another approach to complex-structured data is to use the pattern min-ing methods studied in the field of data m ining [27,19]. They first enumerate substructure-patterns that frequently a ppear in datasets, and construct explicit feature vectors using the substructures. Since the number of substructures are enormous, it is not usually possible to construct the feature vectors within poly-nomial time, and various heuristic techniques for fast enumeration of substruc-tures have been proposed.
 In this paper, we proposed a new kernel fo r rooted labeled unordered trees based on tree subpath sets, and an efficient algorithm for computing the kernel func-tion. The proposed algorithm is based on the multikey quicksort algorithm [13], which is more efficient than the subgraph-based tree kernels using dynamic pro-gramming. We performed experiments on classification tasks, XML classification and glycan classification, and showed that the predictive accuracy of the pro-posed kernel was competitive with the ex isting unordered tree kernel [1], and is faster than the linear-time tree kernel in practice.

One of the possible future work is to f urther accelerate the proposed algo-rithm so that its worst case complexity is linear. Another direction is to allow mismatches of subpaths when computing t he proposed kernels. To this goal, the techniques used in the mismatch string kernel [24] should be incorporated into the proposed algorithm.

