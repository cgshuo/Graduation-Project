 Spok en dialogue systems are emer ging as an effec-tive means for humans to access information spaces through natural spok en interaction with comput-ers. A significant enhancement to the usability of such systems would be the automatic acquisition of new kno wledge through spok en interaction with its end users. Such kno wledge would include both the spelling and pronunciation of a new word, ide-ally leading to a successful match to an entry in a lar ge external database. To tak e adv antage of an inte grated approach to recognizing the spok en and spelled forms of a new word, there is a need for a high-quality reversible phoneme-grapheme map-ping system. This is a dif ficult task for English due to the man y inconsistencies in letter -to-sound rules as a consequence of borro wings from multiple lan-guage groups.

It is also increasingly the case that dialogue sys-tems must dynamically adjust the recognizer vocab-ulary to handle changing database contents. If a sys-tem can reliably predict the pronunciation of a new word algorithmically , especially if substantiated by a spok en pronunciation of the word during acti ve us-age, it will be far more effecti ve in satisfying chang-ing user needs.

In this paper , we describe a new reversible grapheme-to-phoneme frame work based on combin-ing formal linguistic kno wledge with statistical data-dri ven techniques. We first describe and moti vate our choice for the linguistic model. Section 3 de-scribes the iterati ve process for obtaining a subw ord baseforms lexicon used to train the statistical model. Sections 4 and 5 present experiments and results for sound-to-letter modeling on 5000 nouns. We con-clude after a brief section on related work. Our linguistic model is based on syllable structure, but we felt that whole-syllable units would be too lar ge to adequately generalize to unseen data. We thus decided to decompose syllables into onsets and rhymes, which would then become subw ord pronun-ciation units in a lexical baseforms file. These sub-word units would, in turn, be specified in terms of phonemic baseforms in a separate subw ord lexicon. Thus the words in our training set are represented in terms of subw ord units, which are con verted into phonemic baseforms by simple lookup of the sub-word pronunciations.

A dif ficult aspect for English is to decide where to place the syllable boundary within a sequence of intersyllabic consonants. To guide this decision, we made use of sonority constraints combined with maximal stress and maximal onset principles. For a select subset of intersyllable consonants, we in-voke the special cate gory  X  X mbi X  for  X  X mbisyllabic,  X  to allo w the consonant to be ambiguously assigned. In addition to onset and rhyme, we also include the cate gory  X  X f fix,  X  to account for those instances of (usually coronal) consonants that would lead to a violation of sonority principles in the coda position (e.g.,  X  X if ths , X   X  X ep t  X , etc.), follo wing linguistic the-ory (Ble vins, 1995).

We decided to distinguish the first stressed and the first unstressed syllable from all other stressed and unstressed syllables in the word, in order to en-code separate statistics for the pri vile ged first posi-tion. We also combined onset and rhyme into a sin-gle whole syllable unit for a selected subset of rel-atively frequent unstressed syllables. In total, our current inventory consists of 678 unique symbols.
An example hierarchical representation in our for -malism is illustrated in Figure 1, for the word  X  X c-celerometer . X  Our approach is based on a technique that exploits a conte xt-free grammar applied to a lar ge lexicon to aid in the preparation of a baseforms file encoding the lexicon in terms of a set of linguistically moti-vated subw ord units. The subw ord units, which en-code syllabification and pronunciation, are initially acrostics -ax+ kr+ -aas t -axk +s actualities -aek ch+ -uw+ -ael -ax+ tf -iy+ +z fabrications f+ -aeb r+ -ax+ k -ey+ shaxn +z preferences pr+ -ehf rsyl -axn +s -axz skepticism sk+ -ehp t -ax+ s+ -ihz -m striplings str+ -ihp l+ -ihng +z Figure 2: Sample entries from the subw ord lexicon. deri ved automatically from a phonemic baseforms file through simple rewrite rules. The grammar is developed manually , a process that amounts to iden-tifying all the possible ways to spell each subw ord unit. In an iterati ve procedure, parse failures are manually corrected either by modifying erroneous pronunciations or by augmenting the rules govern-ing permissible letter sequences for the subw ord units. Through this process we have now con verted phonemic baseforms for a lexicon of 140,000 words into the new subw ord units. Example entries in the baseforms file are sho wn in Figure 2.

Once a grammar and a lar ge lexicon of subw ord baseforms are available, the next step is to cre-ate a statistical language model encoding the letter -subw ord mappings. We have decided to create a new set of subw ord units, which we call  X  X pellnemes,  X  combining the letter sequence and associated pro-nunciation into a single symbolic tag, as illustrated in Figure 3. The sequence of spellnemes associated with each word in the lexicon can easily be obtained by parsing the word, constrained by its subw ord re-alization. The spellneme sequences for each word in the lexicon are then used to train a trigram language model. Our formalism currently has 2541 unique spellnemes, on average nearly a 4-fold expansion over the number of pronunciation-bas ed subw ords.
Deri vative sound-to-letter and letter -to-sound sys-tems are straightforw ard. For sound-to-letter , a pro-vided phonemic transcript is exhausti vely expanded to a graph of all possible subw ord realizations, and subsequently into a graph of all spellnemes asso-Figure 3: Sample entries from the tagged corpus which is used to train the statistics of the -gram language model. The numeric tags encode the asso-ciated subw ord unit, each of which maps to a unique phonemic sequence. ciated with each subw ord. The trigram language model is applied to produce an N-best list of the top-scoring hypothesized spellneme sequences. The letter -to-sound system exhausti vely expands the let-ter sequence into all possible spellneme sequences. After applying the trigram language model, the N-best list of spellneme sequences can be mapped to the pronunciations by concatenation of the phone-mic realizations of the indi vidual subw ords. We imagine a two-stage speech recognition frame-work for a word spok en in isolation, in which the first stage uses subw ord units that encode only pro-nunciation, and produces an N-best list of hypothe-sized pronunciations, represented as phonemic base-forms. The second stage is task ed with hypothe-sizing possible spellings from the pro vided phone-mic baseforms, and then verifying them by a match with a lexical entry . For the purposes of this paper , we assume a perfect phonemic baseform as input, and investigate the quality of the N-best list of hy-pothesized spellings automatically generated by the sound-to-letter system. We quantify performance by measuring the depth of the correct word in the gen-erated N-best list.

Our experiments were conducted on a set of nearly 5000 nouns and proper nouns, a sub-set of the 8000 word Phonebook vocab ulary that were identified as nouns using the Web site http://www .comp.lancs.ac.uk/ucrel /claws/. We se-lected this set of words for two reasons: (1) the y contain a substantial number of nouns not included in our original training lexicon, and (2) the y will al-low us to conduct speech recognition experiments from the available Phonebook corpus of words spo-ken in isolation over the telephone.

The trigram training corpus was restricted to a subset of 55,159 entries in our original lexicon, containing the words that were tagged as nouns in Comle x. We are interested in quantifying the gap between in-v ocab ulary (IV) and out-of-v ocab ular y (OO V) words, with respect to the training corpus. We also measure the gains that can be realized through manual repair of automatically generated baseforms for training the sound-to-letter system. Thus we conducted experiments on the follo wing four conditions: 1. Train on 55,159 nouns, test on the 3478 word 2. Train on 55,159 nouns, test on the 1518 OO V 3. Augment the training set with entries for the 4. Augment the training lexicon with manually
Items (3) and (4) will sho w us the degree to which impro vements can be gained through auto-matic methods, once a new list of nouns becomes available, as well as how much further gain can be realized after manual correction. Automatic meth-ods will be feasible for a dialogue system which can extract from the Web a list of nouns appropriate for the domain, but has no phonemic baseforms avail-able for those nouns. Results are sho wn in Table 1. With an N-best list of 30, the system has a very low failure rate for all conditions. Ho we ver, there is a mark ed dif ference in performance in terms of the depth of the correct an-swer . The mean depth is 2.07 for the OO V words, as contrasted with only 1.15 for the IV words. Fully automatic methods to impro ve the sound-to-letter system lead to substantial gains, reducing the mean depth to 1.54. Manual correction pro vides signifi-cant further gains, achie ving a mean depth of 1.13, comparable to that of the original IV subset. There were two cases where an incorrect match to a lexical entry was found at a higher level in the N-best list See text for discussion. than the correct match. These were the homon ym pairs: carolyn/caroline and jasmine/jazzman.
Nouns that fail to appear in the top 30 can poten-tially still be reco vered through simple spell check-ing methods. Using a conserv ative approach of al-lowing only a single letter insertion, substitution or deletion, and further , of requiring that the grammar could parse the corrected word under the constraints of the system X  s proposed subw ords, we were able to reco ver over 60% of the failures. Man y researchers have work ed on letter -to-sound modeling for text-to-speech con ver-sion (R. I. Damper and Gustafson, 1998). The topic of bi-directional phoneme-to-grapheme con version is becoming important for application to unkno wn words and new word acquisition in speech understanding systems (Chung et al., 2003), although it is dif ficult to compare results due to dif ferent representations and data sets. In (Meng, 1996), a hierarchical approach was used for bi-directional sound-letter generation. (Rentzepopoulos and Kokkinakis, 1996) describes a hidden Mark ov model approach for phoneme-to-grapheme con version, in seven European languages evaluated on a number of corpora. (Marchand and Damper , 2000) uses a fusion of data-dri ven and pronunciation-by-a nalog y methods, obtaining word accuracies of 57.7% and 69.1% for phoneme-to-grapheme and grapheme-to-phoneme experiments respecti vely , when evaluated on a general dictionary . (Llitjos and Black, 2001) report impro vements on letter -to-sound performance on names by adding language origin features, yielding 61.72% word accurac y on 56,000 names. (Galescu and Allen, 2002) addresses bi-directional sound-letter gener -ation using a data-dri ven joint -gram method on proper nouns, yielding around 41% word accurac y for sound-to-letter and 68% word accurac y for letter -to-sound. In this paper , we report on a new technique for reversible letter -to-sound sound-to-letter modeling, which is based on linguistic theory and statistical modeling. The system was evaluated on a set of nearly 5000 nouns from the Phonebook domain, separately for in-v ocab ulary and out-of-v ocab ular y subsets, with respect to the training corpus for the sound-to-letter system. In future work, we plan to evaluate the effecti veness of the model for automatic new word acquisition in spok en dialogue systems.
