 Sequence data processing has been studied extensively in the liter-ature. In recent years, the warehousing and online-analytical pro-cessing (OLAP) of archived sequence data have received growing attentions. In particular, the concept of sequence OLAP is recently proposed with the objective of evaluating various kinds of so-called Pattern-Based Aggregate (PBA) queries so that various kinds of data analytical tasks on sequence data can be carried out efficiently. This paper studies the evaluation of ranking PBA queries, which rank the results of PBA queries and return only the top-ranked ones to users. We discuss how ranking PBA queries drastically improve the usability of S-OLAP systems and present techniques that can evaluate various kinds of ranking PBA queries efficiently. H.2.0 [ Database Management ]: General Algorithms, Design
Sequence data is ubiquitous. Any data that exhibit an ordering among their items form data sequences. Examples include work-flow data, data streams and RFID logs, in which time can be con-sidered as an ordering dimension. Techniques for processing var-ious kinds of sequence data have been studied extensively in the literature (e.g., [17, 18, 15, 1, 3, 19]). Recently, issues related to warehousing and online analytical processing (OLAP) of archived sequence data (e.g., stock ticks archive, passenger traveling his-tories) have received growing attentions [8, 7, 13]. In particular, [13] developed a sequence OLAP system (called S-OLAP) that ef-ficiently supports various kinds of pattern-based aggregate queries  X  . The authors are supported by Hong Kong Research Grants Council GRF grant HKU 713008E.  X  . The author is supported by ICRG grants (Project Numbers: 1-ZV5R and A-PC0N) from The Hong Kong Polytechnic University. so as to facilitate the warehousin g and analysis of huge volumes of sequence data.

The S-OLAP system developed in [13] has several distinguishing features. First, while traditional OLAP systems group data tuples basedontheir attribute values , an S-OLAP system treats patterns as dimensions and it groups sequences based on the patterns they possess. Common aggregate functions such as COUNT can then be applied to each group. The resu lting aggregate values form the cells of a so-called sequence data cuboid, or s-cuboid . Second, several high-level OLAP operations that are specific to sequence data analysis are proposed. These operations allow data analysts to explore and to navigate among different levels of summarization (s-cuboids) of sequence data. The collection of s-cuboids forms a sequence data cube .

Since an s-cuboid displays the aggregate values of sequences that are grouped by the patterns they possess, one can view an s-cuboid as the answer to a pattern-based aggregate ( PBA ) query . To illus-trate PBA queries and s-cuboids, let us consider the sequence data set shown in Figure 1. The dataset models a collection of passenger traveling records registered by the Washington DC X  X  metro system. The records can be captured electronically by SmarTrip ,whichis an RFID-card-based stored-value e-payment system. Each row in Figure 1 shows a sequence of events of a passenger. An event con-sists of a number of attributes, such as Time , Location , Action and Amount . For example, the event [ t 9 ; Wheaton; exit; 1.9] of passen-ger 623 indicates that passenger with SmarTrip card id 623 exited Wheaton Station at time t 9 and paid $1.9 dollars for his trip.
Figure 2 shows a PBA query  X ( X, Y, Z, X ), COUNT  X  X ndafew cells of the resulting s-cuboid. A PBA query basically consists of two components 1 : A pattern template T (e.g., ( X, Y, Z, X )) and an aggregate function F (e.g., COUNT ). For example, the pattern tem-plate ( X, Y, Z, X )definedonthe Location attribute specifies that passenger sequences are grouped together if the passengers first visited certain stations X , Y , Z in that order and then came back to X . Here, X , Y , Z are called pattern symbols and they are in-stantiated with values of a given pattern dimension ( Location in our example). Each instantiation, such as (Clarendon, Wheaton, Penta-gon, Clarendon), gives a pattern. Data sequences that possess the pattern are grouped into a cell. Each data sequence gives a value (or measure ) to be aggregated. For example, a passenger sequence could be associated with the amount of fare paid, or the number of trips the passenger make per month, or simply  X 1 X  if we only care about the cardinality of a cell (as under the COUNT aggrega-
A complete specification of a PBA query is a lot more elaborate [13]. For example, one has to specify whether a pattern is a sub-string pattern or subsequence pattern. We simplify our description here so as to focus on the main issues. In particular, we assume the substring pattern semantics is used. tion function). The aggregation function F is then applied to the values of the sequences of each cell to obtain an aggregate value of the cell. In this paper, if P represents a pattern (e.g., (Clarendon, Wheaton, Pentagon, Clarendon)), we use C ( P ) to denote the cell of pattern P (i.e., C ( P ) = the set of sequences containing pattern P ), and we use F ( C ( P )) to denote the aggregate value of the cell. An s-cuboid consists of all the aggregate values of the cells derived from all possible instantiations of the pattern template. For exam-ple, Figure 2 shows that there are 2,654 sequences that possess the pattern (Clarendon, Wheaton, Pentagon, Clarendon). In our nota-tion: COUNT ( C ((Clarendon, Wheaton, Pentagon, Clarendon))) = 2,654.

Notice that in the above example, the pattern symbols X , Y , Z form the three dimensions of the s-cuboid. While there are only a fixed number of dimension attributes for traditional OLAP systems, the number of dimensions of an s-cuboid in S-OLAP is given by the number of distinct pattern symbols that are contained in the PBA query. This potentially leads to the problem of gigantic cuboids  X  cuboids with large numbers of cells. For example, there are 86 stations in DC X  X  metro network. Therefore, the s-cuboid in Figure 2 with three distinct pattern symbols consists of 86 3 = 636 cells. In fact, the number of cells is exponential to the number of distinct symbols in the pattern template. For applications such as DNA analysis, where interesting patterns are often long and com-plex, analysts would definitely be overwhelmed by the myriad cells of gigantic cuboids.

To avoid information overload, one can focus on a small number of highly-ranked cells, such as those whose aggregate values are the top-k ones among all the cells in the s-cuboid. The objective of this paper is to study how top-k PBA queries can be efficiently supported in an S-OLAP environment. Using our running example, if an operational manager is interested in knowing the three most heavily followed traveling patterns according to the ( X, Y, Z, X ) template, then an S-OLAP system should rank the results shown in Figure 2 and present only the top-3 values. This presentation of the result is more comprehensible than a full s-cuboid in two ways: (1) Uninteresting cells, such a s (Rockville, TwinBrook, Suitland, Rockville) with only 5 passenger sequences, are not displayed. (2) The most interesting cells, such as (Pentagon, Glenmont, Wheaton, Pentagon) with a very large count would appear at the top of the result. Besides a more comprehensible view of the result, comput-ing the top-k values is potentially more efficient than computing the full s-cuboid, since a large number of uninteresting cells need not be fully calculated.

The problem of top-k aggregate queries has previously been stud-ied for traditional OLAP systems [20]. The algorithm proposed in [20], namely AR, is based on the idea of thresholding ,whichis a classical idea in traditional ranking query processing [5, 2, 10]. Here, let us briefly describe AR. Assume that AR has computed the aggregate values of a small number of cells of the cuboid. Let  X  be the value of the k th -ranked cell among the computed ones.  X  serves as a pruning threshold . For each of the other cells, AR estimates an upper bound of the cell. These upper bounds serve two purposes. First, if a cell X  X  upper bound is less than  X  , the cell can be pruned. Second, the cell C with the largest upper bound U C is likely to have a large value and thus be part of the top-k answer. AR thus computes the aggregate value F ( C ) of cell C .If F ( C ) C will be included into the currrent top-k answer and  X  is updated. AR repeats the above process until every cell is either pruned or is confirmed to be part of the top-k answer.
 For traditional OLAP, we note that the computation of the value F (
C ) of a cell C allows the upper bounds of some other cells be tightened. For example, if one knows that the yearly sales is 10M and one has computed the first quarter sales to be 8M, then one knows that the sales in any of the other three quarters cannot ex-ceed 2M. Hence, knowing the value of the first-quarter cell (8M) allows us to refine the upper bounds of other-quarter cells (from 10M to 2M). These bounds are determinable because of the sum-marizability property of traditional OLAP systems  X  the value of a coarse-granular cell (yearly sales) can be computed from those of fine-granular cells (quarter sales). In other words, the summa-rizability property allo ws upper bounds to be determined which in turn allows effective cell pruning. The summarizability property, however, does not hold for S-OLAP. The reason is that while the cells of a traditional cuboid form a pa rtition of the data tuples (i.e., each tuple belongs to one and only one cell), a sequence can belong to multiple cells in an s-cuboid. To see this, consider the pattern template ( X , Y ) and three instantiations (cells): ( a 1 and ( a 3 , a 1 ). We note that the sequence S = a 1 , a 2 contains all three patterns and thus S contributes to all three cells. As a result, knowing that certain sequences belong to a particular s-cuboid cell does not allow us to preclude them from any other cells. Hence, upper bounds of those cells cannot be effectively de-termined. Designing an effective pruning algorithm for top-k PBA queries in an S-OLAP system is thus a challenging task.
In [13], it is shown that PBA queries can be efficiently evaluated by constructing inverted-indices (IIs). Based on IIs, we derive a few algorithms for solving the top-k PBA query problem. A naive method is to (1) evaluate the full s-cuboid using IIs and the algo-rithm proposed in [13], (2) rank the cells and (3) return the top-k cells. We note that this naive method is inefficient because much unnecessary computation is done on evaluating low-valued (non-top-k ) cells. A slightly smarter approach would be to incorporate the idea of thresholding to the inverted-index-based algorithm. We call this algorithm TIA (Thresholding with Inverted-index Algo-rithm). As we will see later, the pruning power of TIA is limited by the non-summarizability property of S-OLAP.
 To improve efficiency, we further devised two techniques, namely Eager Pruning (EP) and Plan Selection (PS), on top of TIA. On one hand, EP optimizes TIA by exploiting some unique property of sequence data so that the pruning power of thresholding is signifi-cantly improved. On the other hand, PS optimizes TIA by improv-ing the inverted-index join algorithm proposed in [13]. As we will show in our experiments, EP and PS bring significant performance improvement to TIA.

To sum up, this paper identifies a new type of query, top-k pattern-based aggregate (top-k PBA) queries, that can drastically improve the usability of an S-OLAP system. Furthermore, a basic top-k PBA evaluation algorithm TIA and two optimization techniques EP and PS are proposed. An extensive set of experiments has been car-ried out. Experimental results show that our proposed techniques can evaluate top-k PBA queries efficiently.

The rest of this paper is organized as follows. Section 2 presents a naive method to evaluate top-k PBA queries. Section 3 presents the details of algorithm TIA and the details of the two TIA X  X  op-timizations: EP and PS. Section 4 reports the performance result, followed by a discussion of related work in Section 5. Section 6 concludes our study with a discussion of future work. In this section we discuss a naive method for evaluating top-k PBA queries. This naive algorithm simply applies the inverted-index-based (II) method proposed in [13] to materialize a full s-cuboid, 2 sorts the cells based on their aggregate values and returns the top-k cells to users. This naive algorithm is not very efficient for processing top-k PBA queries because it does not apply any pruning techniques to avoid evaluating low-valued cells. We dis-cuss the naive algorithm here as a baseline method based on which our pruning algorithms are derived.

The II method in [13] follows a semi-online computation strat-egy. Specifically, a set of inverted-indices are pre-computed in ad-vance. Each inverted-index consists of a set of inverted-lists. An inverted-list, denoted by L [ P ] , is associated with a length-m pat-tern P =( v 1 ,...,v m ). Each element ( v i ) in pattern P is chosen from the domain of a pattern dimension at a particular abstraction level. The inverted-list L [ P ] is a list of sequence identifiers (e.g., passenger ids) such that a sequence id is in the list if and only if the corresponding sequence contains the pattern P . Given a pat-tern template T , the inverted-index I T is the set of inverted-lists L [
P ] such that pattern P is an instantiation of the template T .Fig-ure 3 shows several example inverted-indices I ( X,Y,Z ) , I I ( X,X ) . For instance, the first inverted-list l 1 in I ( X,Y,Z ) that sequences s 2 , s 27 and s 34 all contain the pattern (Clarendon, Pentagon, Glenmont). 3
A PBA query can be evaluated (or equivalently an s-cuboid can be constructed) from a set of inverted-indices. For example, given
Besides the II method, [13] also proposed the counter-based method (CB). It is shown in [13] that the II method generally out-performs the CB method. The performance advantage is particu-larly significant for iterative queries . Therefore, we focus on the II method in this paper.
Symbols in a pattern template are unbound variables. So, the inverted-indices I ( X,Y ) and I ( Z,U ) are the same. Multiple occur-rences of the same variable in a template, however, have the same binding. So, the indices I ( X,X ) and I ( X,Y ) are different.
Output: Materialized inverted-list L [ P ] . 1. if L [ P ] has been materialized 2. return L [ P ] ; 6. L [ P ] = post-filter R . 7. return L [ P ] .
 Figure 4: A recursive algorithm for materializing an inverted-list the set of inverted-indices shown in Figure 3, the PBA query  X ( Z, X ), COUNT  X  can be evaluated as follows. First the inverted-index I is retrieved. Each inverted-list L [ P ] in I ( Z,X ) gives the sequences that contain pattern P , which is an instantiation of the template ( Z , X ). These sequences thus form the cell C ( P ) of the s-cuboid and COUNT ( C ( P )) = | L [ P ] | gives the aggregate value of the cell. For example, the value of the cell C ((Glenmont, Clarendon)) is 4 because the inverted-list l 8 contains four sequences.

The II method in [13] computes all length-2 inverted-indices (at different abstraction levels) in advance. To compute the s-cuboid of a PBA query with a length-m pattern template T ,theinverted-index I T is retrieved. If I T is not available, it is constructed by joining the inverted-indices I T 1 and I T 2 where T 1 and T length-( m -1) prefix and the length-2 suffix of T , respectively. (If I 1 is not available, it is recursively constructed.) For example, the inverted-index I ( X,Y,Z,X ) can be constructed by joining I and I ( Z,X ) . We represent this index join by I ( X,Y,Z,X ) = I ( Z,X ) . An inverted-list L [( v 1 ,v 2 ,v 3 ,v 1 )]  X  obtained by first intersecting two inverted-lists L [( v 1 I L [( v 3 ,v 1 )] , followed by a post-filtering step such that false posi-tive sequences in R (i.e., those that do not contain the sub-string pattern ( v 1 ,v 2 ,v 3 ,v 1 )) are removed. We use L [( For example, the inverted-list L [(Clarendon, Pentagon, Glenmont, Clarendon)] is obtained by intersecting l 1 and l 8 giving R s 34 } .If s 27 is Glenmont, Clarendon, TwinBrook, Clarendon, Pentagon, Glenmont , it does not contain the desired pattern (Claren-don, Pentagon, Glenmont, Clarendon) and thus it is removed. The don, Pentagon, Glenmont, Clarendon)] = l 1 l 8 = { s 34 } 4 depicts the procedure M ATERIALIZE that is used to compute the inverted-list L [ P ] given a pattern P . Line 6 in Figure 4 captures the post-filtering step, in which sequences identified in R are retrieved to verify if they contain the desired pattern P .

After the construction of a complete s-cuboid, the naive algo-rithm sorts the cells based on their values and returns the top-k cells to the user. In this section we first present the details of TIA in Section 3.1. Following that, we present the two optimization techniques for TIA: Eager Pruning (Section 3.2) and Plan Selection (Section 3.3). With-out loss of generality, we assume that larger cell values are pre-ferred, and so the top-k cells are those with the k largest values. Also, we assume patterns are sub-string patterns and focus on the COUNT aggregation function. Extensions to other patterns (such as sub-sequence patterns) and other S-OLAP specific aggregate func-tions are straightforward and we omit them here due to space limi-tations.
The Thresholding with Inverted-Index Algorithm (TIA) integrates the thresholding technique into the II method in order to prune low-valued cells for efficient processing of top-k PBA queries.
TIA basically follows the II method in computing the aggregate values of the cells in an s-cuboid. To reiterate, given a PBA query  X  T , F  X  with pattern template T and aggregate function F ,ifthe inverted-index I T is available, it is retrieved. Each inverted-list L [ P ] in I T allows us to compute the aggregate value of the cell C (
P ) . These aggregate values are sorted and the top-k ones are presented to the user. If I T is not available, instead of material-izing all the inverted-lists in I T as in the baseline algorithm, we use thresholding to prioritize the cells (and therefore the associated inverted-lists) to be computed and to prune low-valued cells.
As we have explained in Section 1, the biggest challenge of applying thresholding to compute top-k PBA queries is the non-summarizability property of S-OLAP, which makes the traditional way of estimating cells X  upper bounds inapplicable. Fortunately, we can show that if the aggregate function F is monotonic ,we have an alternative way to estimate a cell C ( P )  X  X  upper bound by considering the sub-patterns of P . This upper bound estimation forms the core of the TIA algorithm.
 monotonic iff given two sets A and B , we have
In this paper we focus on the sub-string semantics. That is, a sequence S is said to contain a pattern P if P is a sub-string of S . Based on this semantics, we define sub-pattern and super-pattern . pattern P , a pattern P s is called a sub-pattern of P iff P string of P .Weuse P s P to denote the sub-pattern relationship. We a l s o c a l l P a super-pattern of P s , denoted by P P
Note that if a sequence S contains a pattern P ,then S must con-tain any sub-pattern P s of P . For any monotonic function F ,the following lemma holds:
L EMMA 1. Given a pattern P ,let C ( P ) be the cell that corre-sponds to pattern P .(Hence, C ( P ) represents the set of sequences that contain the pattern P .) Let F ( C ( P )) denote the aggregate value obtained by applying a monotonic aggregate function F to the sequences in C ( P ) . We have, for any sub-pattern P
P ROOF .Since P s is a sub-pattern of P , any sequence S that contains P must also contain P s . Therefore, C ( P )  X  C Since F is monotonic, by definition, F ( C ( P ))  X  F ( C From the lemma, we arrive at the following corollary.

C OROLLARY 1. Given any pattern X ,let F ( C ( X )) denote an upper bound of F ( C ( X )) . We have, for any pattern P ,
If the sub-sequence semantics is used instead, then P s is a sub-pattern of P iff P s is a sub-sequence of P .
 Algorithm TIA
Input: (a) k ; (b) PBA query with pattern template T and a
Output: Top-k cells 3. Set a size-k priority queue Q as empty and threshold  X  4. //Estimate the upper bounds of cells 5. for each pattern P instantiated from T 7. while there are any unseen cell C such that F ( C ) &gt; X  8. Select an unseen cell C ( P ) whose upper bound 10. F ( C ( P )) = compute aggregation function F on L [ P 11. if F ( C ( P ))  X   X  12. Insert C ( P ) into Q ; 13. Update  X  ; 14. Prune all cells C ( P ) where F ( C ( P )) &lt; X  ; 15. return the top-k cells stored in priority queue Q . P ROOF . This follows directly from the fact that F ( C ( F ( C ( P s ))  X  F ( C ( P s )) for all sub-pattern P s of P .
From Corollary 1, we see that F ( C ( P )) = min P s P { F is a valid upper bound of F ( C ( P )) . Following the II method, un-der TIA, length-2 inverted-indices are pre-computed in advance. Therefore, an upper bound can always be determined for any length-2 or longer pattern P using Corollary 1. For example, an up-per bound of the cell (Pentagon, Wheaton, Wheaton) can be es-timated by the values of the cells (Pentagon, Wheaton) and (Whea-ton, Wheaton). As another example, if F ( C ( (Pentagon, Wheaton) = 10, F ( C ( (Wheaton, Wheaton) )) =20and F ( C ( (Wheaton, Clar-endon) )) = 30, then F ( C ( (Pentagon, Wheaton, Wheaton, Claren-don) )) = 10 is a valid upper bound of the length-4 pattern (Penta-gon, Wheaton, Wheaton, Clarendon).

Figure 5 shows the pseudo-code of algorithm TIA. TIA first checks and sees if the inverted-index I T for the query X  X  pattern tem-plate is available. If so, the top-k answers can be computed from that index directly (lines 1 X 2). If the inverted-index is unavailable (lines 3 X 14), TIA maintains a priority queue Q which keeps track of the top-k cells among those that the algorithm has computed (or seen ) so far (line 3). Then, TIA estimates the upper bounds of all cells (lines 5 X 6). Next, TIA examines the unseen cells one-by-one based on their estimated upper bounds (the while loop from lines 7 to 14). To find the aggregate value of a cell C ( P ) , TIA invokes the procedure M ATERIALIZE ( L [ P ] ), shown in Figure 4, and applies the aggregate function F (e.g., COUNT ) on the resulting list (lines 9 X 10). If the newly evaluated cell C has a value that is larger than the top-k threshold  X  , it is inserted into the priority queue Q and the top-k threshold is updated (lines 12 X 13). For all unseen cells whose upper bounds are smaller than the updated threshold, they are pruned (line 14). The algorithm continues until all unseen cells are pruned and after that the top-k cells in Q are reported as the final result.
TIA is much more efficient than the naive method in evaluat-ing top-k PBA queries because it prunes low-valued cells and thus avoids the computation of those cells X  inverted-lists. The efficiency of TIA thus hinges upon pruning effectiveness. For existing thresh-olding algorithms [5, 2, 10, 9, 20] such as those devised for tradi-tional OLAP systems, cell pruning is triggered by two means: (1) When the pruning threshold  X  is updated, unseen cells whose up-per bounds are smaller than  X  are pruned. (2) When the value of a cell C is computed, the tuples that belong to C are determined. By the summarizability property of traditional OLAP, those tuples cannot be members of other cells and thus the upper bounds of some other cells can be refined (to smaller values). This triggers the pruning of some cells if their refined upper bounds fall below the threshold  X  . As we have discussed in Section 1, s-cuboids are non-summarizable. As a result, for TIA, the upper bounds of cells are never refined and so condition (2) mentioned above never gets trig-gered. The pruning effectiveness and hence the efficiency of TIA is limited. In particular, since cells X  upper bounds do not change after they are first estimated, TIA evaluates cells following a static order (in decreasing values of the cells X  upper bounds). So, if the bounds are loose such that the k th -ranked cell appears late in the order, TIA has to examine many cells before all the top-k cells are discovered.

From Figure 5, we see that when TIA selects a cell C ( P ) uate, if the inverted-list L [ P ] is unavailable, TIA will completely materialize L [ P ] (by calling M ATERIALIZE ( L [ P ] )). We observe that there are two opport unities to achieve effective pruning during the materialization of L [ P ] . To understand those, let us consider another corollary of Lemma 1:
C OROLLARY 2. Given patterns P x and P y such that P y P x and a monotonic function F ,
P ROOF . This follows directly from Lemma 1 that F ( C ( P F ( C ( P x )) as P y P x .
 In other words, if a cell C ( P x ) can be pruned then all cells C ( P y ) such that P y is a super-pattern of P x can also be pruned. There are two places in M ATERIALIZE ( L [ P ] ) (Figure 4) at which this pruning rule can be aggressively exploited.
 First, M ATERIALIZE is a recursive procedure; the execution of M
ATERIALIZE ( L [ P ] ) may recursively execute M ATERIALIZE sub-pattern P 1 (line 4), and so on. This recursive execution will therefore cause the inverted-lists of a number of sub-patterns of P to be built. We note that as soon as an inverted-list L [ P s P , is built, we can immediately compute F ( C ( P s )) can then use F ( C ( P s )) to update the upper bounds of all cells C (
P y ) such that P s P y (see Corollary 1). Also, by Corol-lary 2, if F ( C ( P s )) &lt; X  then all those super-pattern cells can be pruned immediately. These cells include C ( P ) itself and therefore M ATERIALIZE ( L [ P ] ) can be terminated immediately.
 As an example, let us consider the evaluation of a top-1 query with pattern template ( X, Y, Z, X, W ) using TIA. Assume that after some cells are seen, the threshold  X  is 10. Furthermore, let us assume the cell ( a, b, c, a, d ) is the next cell to be evaluated. In order to compute the value of that cell, TIA invokes M ALIZE to compute the inverted-list L [( a, b, c, a, d )] . Let us assume that only size-2 inverted-lists are available at the time the function is executed. Then, after two recursive calls, the algorithm material-izes the inverted-list L [( a, b, c )] by joining L [( a, b which are available. Let X  X  say F ( C (( a, b, c ))) = 6 &lt; X  By Corollary 2, we conclude that the cell C (( a, b, c, a, d be pruned and therefore L [( a, b, c, a, d )] needs not be material-ized. The recursive call can thus be terminated early. In fact, all
Output: Materialized inverted-list L [ P ] if C ( P ) is not pruned. 1. if L [ P ] has been materialized 2. return L [ P ] ; 6. return ; 8. if F ( R ) &lt; X  9. Prune C ( P ) and all C ( P ) where P P 10. return ; // Post-filtering step is saved. 11. L [ P ] = Post-filtering R . 12. if F ( L ( P )) &lt; X  13. Prune C ( P ) and all C ( P ) where P P 14. Update F ( C ( P )) to min { F ( C ( P )) ,F ( L ( P 15. return L [ P ] .

Figure 6: Materializing an inverted-list with Eager Pruning cells that are associated with any super-pattern of ( a, b, c ( a, b, c, a,  X  ) and ( c, a, b, c,  X  ) 5 can be pruned as well. For the second pruning opportunity, we note that in line 5 of M
ATERIALIZE , an intermediate result R = L [ P 1 ]  X  L [ P puted. The inverted-list L [ P ] is extracted from R by removing false-positive sequences (line 6). We note that this post-filtering step requires data sequences be retrieved from the database for ver-ification and hence this step is I/O intensive. Let F ( L the aggregate value obtained by applying F to the sequences in inverted-list L .Since L [ P ]  X  R and F is monotonic, F ( F (
R ) .Soif F ( R ) &lt; X  , the cell C ( P ) can be pruned and L needs not be materialized. The post-filtering step can thus be saved.
The two strategies are pruning cells eagerly by seizing every opportunity. We thus call the method Eager Pruning (EP). We modify M ATERIALIZE to incorporate the two pruning strategies. The resulting procedure, called EP-M ATERIALIZE ,isshownin Figure 6. The first difference between M ATERIALIZE and EP-M
ATERIALIZE is that the EP version attempts to prune cells once after list intersection (line 8 to line 10) and once after post-filtering (lines 12 and 13). If the cell is pruned, the recursion stops immedi-ately (lines 6 and 10). The second difference is that the EP version refines the upper bounds of the remaining cells (line 14), that leads TIA to select the next cell based on tighter bounds (see line 8 in Figure 5). Applying EP in TIA is straightforward  X  we can sim-ply replace line 9 of Figure 5 with EP-M ATERIALIZE ( L [ execute lines 10 to 14 only if C ( P ) is not pruned after line 9.
Our second optimization technique, Plan Selection (PS), opti-mizes TIA by selecting more efficient inverted-list joining plans so that the effort of computing some inverted-lists is saved. Con-sider M ATERIALIZE (and EP-M ATERIALIZE ). For a pattern P ( v 1 ,...,v m ) ,if L [ P ] has to be materialized, it is computed by joining two lists L [ P 1 ] and L [ P 2 ] where P 1 =( v 1 and P 2 =( v m  X  1 ,v m ) are the length-( m -1) prefix and the length-2 suffix of P , respectively. Let us call this joining plan (since it joins a length-( m -1) prefix pattern with a length-2 suffix pattern). We note that there are many other joining plans besides the ( m  X  1) 2 scheme. Some of them may allow the same materialization be evaluated more efficiently.  X * X  is a wild-card symbol referring to any instantiation.
To illustrate, let us consider the evaluation of a top-1 PBA query with pattern template ( X, Y, Z, X ) using TIA (with or without EP). Following the ( m  X  1) 2 plan, the evaluation of a cell, say C (( a, b, c, a )) , is done by joining the inverted-lists L L [( c, a )] to form L [( a, b, c, a )] .Now,if L [( a, b, c able, it must be constructed on-the-fly. However, if the inverted-list L [( b, c, a )] is available, then L [( a, b, c, a )] joining L [( a, b )] with L [( b, c, a )] instead. Note that we assume all length-2 inverted-lists are pre-computed, computing L [( a, b, c, a =
L [( a, b )] L [( b, c, a )] therefore does not require the materi-alization of any sub-pattern X  X  inverted-list. The join can thus be done very efficiently. We remark that it is a common scenario in which one inverted-list (e.g., L [( a, b, c )] ) is unavailable while an-tion of a top-k PBA query. For instance, if the cell C (( evaluated after the cell C (( b, c, a, b )) , then the inverted-list L ,a )] is built (when we compute L [( b, c, a, b )] = L [( b, c, a L [( a, b )] ) before the evaluation of cell C (( a, b, c, a that by considering alternate joining plans, the effort spent on com-puting the inverted-list L [( a, b, c )] can be saved.

Given a pattern P =( v 1 ,...,v m ) , there are many binary join-ing plans of the form: L [ P ]= L [ P 1 ] L [ P 2 ] ,where P are sub-patterns of P . We limit our search of a good joining plan by focusing on binary joining plans and restricting P 1 and P the following conditions: 1. P 1 is a length-x prefix of P , i.e., P 1 =( v 1 ,...,v 2. P 2 is a length-( m -y +1) suffix of P , i.e., P 2 =(
Since y  X  x , the prefix pattern P 1 andthesuffixpattern P lap. For example, we consider the joining plan L [( a, b, c, a L [( a, b, c )] L [( b, c, a )] but not the plan L [( a, b, c, a L [( c, a )] . The reason is that by requiring that the two sub-patterns overlap, the intermediate result R = L [ P 1 ]  X  generally smaller than the case without the requirement. The post-filtering step can thus be done more efficiently (see Figure 4). With the restriction, there are O ( m 2 ) possible joining plans (see Appendix). We propose three heuristics for picking a plan. The first heuristic chooses the plan that requires the fewest number of sub-pattern inverted-lists to be materailized. Given a joining plan JP , the cost of JP under Heuristic 1 is given by: Using our previous example again, this heuristic picks the plan L [( a, b, c, a )] = L [( a, b )] L [( b, c, a )] over the plan L =
L [( a, b, c )] L [( c, a )] because the inverted-lists L L [( b, c, a )] are both available while the inverted-list L not. As we have argued, this heuristic avoids building unnecessary inverted-lists (such as L [( a, b, c )] in the example).
When there are multiple plans which are tie with respect to the first heuristic, we apply the following second heuristic to break tie. Given a joining plan JP : L [ P ]= L [ P 1 ] L [ P 2 ] , we estimate the sizes of the inverted-lists of the two sub-patterns: size ( and size ( L [ P 2 ]) . If, say L [ P 1 ] is available, then |
L [
P 1 ] | ; otherwise, we estimate the worst-case size of L the following way: We consider all sub-patterns P s of P 1 inverted-list L [ P s ] has been materialized. The worst-case size is given by the size of the smallest such inverted-lists. That is,
The cost of the joining plan JP under Heuristic 2 is then given by:
Essentially, cost 2 estimates the worst-case size of the interme-diate result R = L [ P 1 ]  X  L [ P 2 ] (seeFigure4),whichinturnre-flects the amount of post-filtering work needed. Heuristic 2 thus prefers the joining plan with the smallest such cost. As an ex-ample, let L 1 = L [( a, b, c, d, e )] , L 2 = L [( a, b, c, d L [( c, d, e )] . Consider computing L 1 by the joining plan: L 1 = L 2 L 3 and suppose L 2 is not materialized and that the size of the shortest inverted-list of any sub-pattern of ( a, b, c, d then size ( L 2 ) = 100 . Suppose L 3 has been materialized and that size ( L 3 )= | L 3 | =80 ,then cost 2 ( JP 1 )=min( { 100 80 .

In case there are still ties after the first two heuristics, we apply the following third heuristic. Given a joining plan JP : L L [
P 1 ] L [ P 2 ] , the cost of it under Heuristic 3 is equal to the sum of the sizes of the to-be-materialized L [ P 1 ] and L [ P cost 3 thus estimates the cost of constructing sub-pattern inverted-lists. Using our previous example. Since L 2 is not materialized but L 3 is, we have cost 3 ( JP 1 ) = 100  X  1+80  X  0 = 100 .

Finally, in case there are still ties after applying all three heuris-tics, we will break the ties arbitrarily.
We have carried out an extensive set of experiments to evalu-ate the techniques in this paper. This section shows the results of comparing four methods to evaluating top-k PBA queries: the TIA algorithm (TIA), the TIA algorithm with EP enabled (TIA+EP), the TIA algorithm with PS enabled (TIA+PS) and the TIA algo-rithm with both EP and PS enabled (TIA+EP+PS). Since the naive method (full s-cuboid materialization) is for theoretical interest only and is not useful in practice, we exclude it from the study. The plat-form for the experiments is Intel Core 2 Duo with 2.83GHz CPU and 4GB RAM. The algorithms are implemented using C++ (gcc 4.2.3) and run on Linux (kernel 2.6.24). Our experiments are car-ried out on both real data and synthetic data.
The real sequence dataset is a collection of clickstream sequences of Gazelle.com, a legwear and legcare web retailer, whose online store was closed on 2000-08-18. It was prepared by [11] for KDD Cup 2000 and was used by [13] in evaluating their proposed counter-based and inverted-index-based algorithms. The dataset contains 50,524 sequences and there are 148,924 (click) events in total. The pattern templates are defined on the Page attribute in the dataset and the domain of Page has 44 distinct values. (Hence, PBA query  X  (
X ) , COUNT  X  and PBA query  X  ( X, X ) , COUNT  X  both result in s-cuboids of 44 cells whereas PBA query  X  ( X, Y ) , COUNT  X  results in an s-cuboid of 44 2 = 1936 cells.)
Following [13], the set of length-2 inverted-indices are pre-com-puted in advance. The pre-computation step took 24 seconds and the resulting indices are 0.89M B in size. We generated one hun-dred random PBA queries for each experiment and measured their average query execution time. Each random query Q consists of a randomly generated pattern template T .Weuse F = COUNT as the aggregate function. To generate T , we first pick a length which is uniformly distributed within the range [ 3 ... 7 number of distinct pattern symbols n in T is randomly picked uni-formly over the range [ 1 ... min {| T | , 4 } ]. The final pattern tem-plate is then randomly selected from all possible pattern templates with length | T | and n distinct symbols. Table 1 shows the parame-ters of query generation and their default values.

Figure 7 shows the performance of the four methods under dif-ferent values of k . From the figure, we see that the execution times of the algorithms increase as k increases. This is because a larger k means more cells need to be computed and returned to the user. We observe that TIA X  X  execution time increases rapidly with k (it X  X  curve has a relatively large slope). This is because a larger k im-plies a smaller pruning threshold (  X  ), since  X  is set as the value of the currently-known k th -ranked cell that have been seen by the al-gorithm. A smaller  X  leads to less effective pruning because there are fewer cells whose upper bounds are below  X  . The performance of TIA thus degrades quickly with k due to poor pruning at large k .
By applying PS to TIA, we reduce the execution time by 10% to 20%. PS achieves the saving by reducing the number of sub-pattern inverted-lists that have to be materialized. Since PS does not help pruning, we see that the curve of TIA+PS increases with k in a similar fashion as TIA X  X .

The effect of EP, however, is very outstanding. First, we observe that EP reduces the running time of TIA by a factor of 1.7 to 2.2. This is due to the effective pruning brought about by EP as it contin-uously refines the upper bounds of cells. Second, the upper-bound refinement allows TIA+EP to pick a good candidate cell to mate-rialize (see line 8 of Figure 5). This has the effect of getting us a larger pruning threshold  X  (lines 9-14 of Figure 5), which partially combats the problem of  X  X maller  X  under larger k  X . The curve of TIA+EP thus has a smaller slope.

Finally, by applying PS and EP together to TIA, we achieve the best performance. We see that EP+PS reduces the running time of TIA by a factor of as much as 3. Also, we see that the curve TIA+EP+PS is even flatter than TIA+EP. The reason is that Heuris-tics 2 and 3 of PS prefer joining plans that use sub-patterns whose inverted-lists are small (see Section 3.3). The materialization of these small inverted-lists allow EP to compute small upper bounds (see lines 12-14 of EP-M ATERIALIZE ) for cells. This leads to very effective pruning. From this discussion, we see that when EP and PS are applied together, we achieve the best performance provided by the synergy of the two optimization techniques.
In order to evaluate our algorithms under different scenarios and settings, we have performed another set of experiments on synthetic data. With synthetic data, we are able to vary the various character-istics of queries and data. Similar to our experiment on the real data set, in our synthetic data experiments, the set of length-2 inverted-indices are pre-computed in advance. The pre-computation took 19 seconds (for 10K sequences) to 55 seconds (for 50K sequences) and the sizes of the pre-computed inverted-indices range from 0.8MB to 3.7MB.
We use the data generator of [13] to generate datasets of syn-thetic sequences. The data generator allows us to control four parameters: (1) the number of sequences ( D ), (2) the maximum length of a sequence ( L ), (3) the domain size of the pattern dimen-sion ( M ), and (4) a skewness factor  X  . The skewness factor is a non-negative number which controls the distribution of the occur-rence frequencies of the events in sequences. Intuitively, a larger  X  causes the data to be more skewed in the sense that a small portion of the patterns have very high occurrence frequencies while most of the other patterns occur much less frequently. Table 2 shows the baseline settings of the parameters.

We compare the performance of the four algorithms by varying the four parameters D , L , M and  X  . When we vary one parameter, the other three are given their baseline settings (Table 2). In these experiments, 100 random queries are generated in the same manner as in the real-data experiments. We use k =10 in the experiments. We report the average query execution times over the 100 queries under different settings.

In this experiment, we vary the number of sequences in the data set from 10K to 50K. Figure 8 shows the results. We can see that the results in this experiment are consistent with our experiments on real data: both EP and PS offer remarkable improvement to TIA. The use of EP+PS speeds up TIA by 2 to 2.7 times. Also, we can see that all four algorithms scale fairly linearly with respect to the dataset size.

In this experiment, we vary the number of distinct values in a pattern dimension (i.e., we vary the domain size). Figure 9 shows the result. There are two factors that affect the performance of the methods as we vary M . First, the number of cells in an s-cuboid equals M n where n is the number of distinct pattern symbols. A larger M means more cells in the s-cuboid and thus more cells will have to be processed in order to discover the top-k results. It thus increases the execution times of the algorithms. We call this the M n -cell factor. Second, given the same number of data sequences D =30 K ,alarger M means fewer sequences in each cell. In other words, in general, the inverted-list of each cell is expected to be shorter, and the materialization time of an inverted-list is therefore shorter too. This favors smart algorithms that can localize their search of the top-k cells by focusing on a relatively small number of promising cells. We call this the shorter-list factor.
From Figure 9, we see an interesting result exhibiting the op-posing effects of these two factors. We see that when M is small ( M&lt; 15 ), the M n -cell factor is relatively mild. The shorter-list factor causes the curves to drop initially. When M is large ( M&gt; 15 ), the curves started to go up due to the more significant M n -cell factor. For TIA, which does not prune as much as the other methods, the M n -cell factor easily wins out because a large num-ber of cells have to be processed. The execution time of TIA thus increases rapidly with M , particularly when M is very large. For TIA+PS, it helps by avoiding the materialization of some inverted-lists. Since it does not help much in pruning, its execution time also increases substantially as M increases, and again particularly for large M . For TIA+EP, however, EP provides great pruning and thus even though there are many more cells in the s-cuboid, EP is able to limit its search over those promising ones. It is thus less affected by the M n -cell factor. The shorter-list factor counterbal-ances the M n -cell factor nicely and the result is a mild increase in execution time as M increases. Finally, for TIA+EP+PS, the syn-ergy between PS and EP significantly enhances the pruning power of EP (see Section 4.1) so that the curve of TIA+EP+PS stays low and relatively flat.
In this experiment, we vary the maximum number of events per sequence. Figure 10 shows the result. As L increases, the data se-quences are longer and thus they contain more patterns. In other words, each cell contains more members and thus the inverted-lists of cells are generally longer. The time taken to materialize the inverted-lists are thus longer. This explains why the curves go up when L increases. However, the relative performance of the four methods follows consistently with our previous observation. In particular, TIA+EP+PS is the best performing algorithm, which is 2 times faster than the basic TIA algorithm.
In this experiment, we vary the data skewness of the generated data, using four different  X  values: 0, 0.5, 0.9 and 1.0. Figure 11 shows the results. As  X  increases, the data become more skewed. This implies (1) there are fewer cells that contain very large values while most of the others contain very low values, and (2) the dif-ference between the values of top-k and non-top-k cells becomes bigger. The first factor implies that the upper bounds of non-top-k cells become smaller, while the second factor implies that the pruning threshold  X  becomes larger. Both of these factors improve pruning effectiveness. Therefor e, the execution times of all algo-rithms go down. Again, we observe similar relative performance among the four methods as in our previous experiments.
Overall, we see that EP, PS and EP+PS consistently improve the performance of TIA, regardless of the data characteristics. Fur-thermore, we can also see that EP is a more effective optimization than PS. Due to the synergy of PS and EP, the two optimization techniques shall be used together. Experimental results show that TIA+EP+PS has the best performance in all cases.
In this set of experiments, we use a default data set and study the performance of the proposed techniques by changing certain char-acteristics of the queries. The data set is generated based on the parameters given in Table 2. In the following, we report experi-ments on queries with different values of k , different lengths of the pattern template and different numbers of distinct pattern symbols in a template.

In this experiment, we fix the pattern template as ( X, Y, Z, X and vary k . Since the domain size is 20 and there are three pattern symbols ( X , Y , Z ), there are 20 3 = 8000 cells in the full s-cuboid. We experimented on four values of k , covering the extremely se-lective queries (top-1 out of 8,000) to not-so-selective queries (top-1000 out of 8000). Figure 12 shows the results. We see that when k is very large ( k = 1000 ), there are fewer (non-top-k ) cells to be pruned and the pruning threshold  X  (which is equal to the current k th -ranked cell) is very small. The pruning methods are therefore less effective and the savings in execution time are thus relatively small. However, when k is very small ( k =1 ), the opposite is true. That is, most of the cells are non-top-k and the pruning threshold  X  is given very large value. This implies very effective pruning and therefore the relative performance gains by the pruning algorithms are more substantial. In particular, TIA+EP+PS is 2.6 times faster than the basic TIA algorithm. In this experiment, we vary the length of the pattern template. We fix k =10and n = 3. Figure 13 shows the result. Note that patterns are longer when | T | is larger. Therefore, materializing a pattern P requires the recursive procedure M ATERIALIZE ( P )(and EP-M ATERIALIZE ( P )) to go deeper in the recursion resulting in more index joining. Hence, the materialization of a cell is more costly. The execution times of the algorithms thus increase with |
T | . From the figure, we see that the saving brought about by PS increases with | T | . This is because the number of joining plans in-creases as | T | increases, and with more plans to choose from, it is more likely that PS can pick one that can save the most number of inverted-list materialization. Also, we see that EP can significantly reduce the execution time. As we have explained, EP refines cells X  upper bounds aggressively, and it tends to terminate the execution of EP-M ATERIALIZE early (see Section 3.2). With deep recursion (i.e., large | T | ), this early termination of the recursive calls signif-icantly reduces the execution time. Finally, TIA+EP+PS achieves a speedup of a factor of 3.2 over TIA when | T | =6 due to the improved pruning power when PS is added to TIA+EP.
In this experiment, we vary n and keep | T | =4 and k =10 ure 14 shows the result. Since the number of cells in an s-cuboid is M n , the number of cells increases exponentially with n .The execution times of the algorithms thus increase drastically as n in-creases. Without very effective pruning, TIA suffers the most. TIA thus does not scale well with n . It is thus very important to ap-ply effective pruning strategies such as EP to the algorithm. As we can see from the figure, applying EP+PS to TIA makes it 5.5 times faster.

Overall, we can see that EP and PS substantially improve the per-formance of TIA, regardless of the query characteristics. We also observe that EP+PS makes TIA more scalable to the length of the patten template ( | T | ) as well as the number of pattern dimensions ( n ). The techniques EP and PS we propose in this paper thus al-low longer and more complex top-k PBA queries be answered with reasonable response times.
Sequence data processing has been studied extensively in the literature. The PREDATOR system [17] first proposes the stor-ing and querying of sequence data based on the object-relational model. Then, the DEVise system [15] discusses the processing of sequence data based on the relational model. In order to query se-quence data, [16] develops an extension to SQL, namely, SQL-TS, to express various kinds of pattern-based queries. Beyond native processing of sequence data, recently, the processing of live stream data (e.g., [1, 3, 6]) and the online analytical processing (OLAP) of archived sequence data [8, 7, 13] have attracted and held the at-tention of increasingly more researchers. Among those, the work on building an OLAP system for warehousing and analyzing se-quence data in [13] is closely related to our work. In particular, the concept of Sequence OLAP (S-OLAP) is introduced in [13]. Users can pose various kinds of pattern-based aggregation queries so as to facilitate various kinds of sequence data analysis such as stock analysis, workflow management and customer relationship man-agement. Two algorithms, the inverted-index-based method and the counter-based method, are developed for the efficient evaluation of pattern-based aggregation queries. Experiments in [13] show that the inverted-index-based algorithm is generally the more efficient one, especially in dealing with iterative queries.

The focus of this paper is the efficient evaluation of ranking PBA queries. Ranking query processing has been studied from the per-spective of RDBMS optimizations (e.g., [2, 10, 4, 12]), middleware (e.g., [5]) and many other applications (e.g., [9, 14]). In the field of data warehousing and OLAP, [20] studied the efficient evaluation of ranking aggregate queries on traditional data cubes. However, data in traditional cubes are in general summarizable whereas se-quence data, as explained, are non-summarizable. Therefore, it is necessary to devise alternate techniques for the evaluation of rank-ing pattern-based aggregate queries on sequence data.
This paper studies the efficient evaluation of ranking PBA queries in Sequence OLAP systems. We show that ranking PBA queries are much more useful than plain PBA queries by presenting more com-prehensible views of result to users. A basic ranking PBA query evaluation algorithm TIA is presented. Furthermore, two promis-ing TIA optimizations, Eager Pruning and Plan Selection, are dis-cussed. Experimental results on both real and synthetic data show that our proposed techniques are able to evaluate a variety of rank-ing PBA queries efficiently. As future work, we will investigate the use of chunk-based verification to reduce the I/O overhead of the post-filtering phase. Also, we will investigate the issues of main-taining the pre-built inverted-indices when the data are updated. [1] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. [2] N. Bruno and H. Wang. The threshold algorithm: From [3] J. Chen, D. J. DeWitt, F. Tian, and Y. Wang. Niagaracq: a [4] G. Das, D. Gunopulos, N. Koudas, and D. Tsirogiannis. [5] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation [6] L. Golab and M. T.  X zsu. Issues in data stream management. [7] H. Gonzalez, J. Han, and X. Li. FlowCube: Constructuing [8] H. Gonzalez, J. Han, X. Li, and D. Klabjan. Warehousing [9] U. G X ntzer, W.-T. Balke, and W. Kie X ling. Optimizing [10] I. F. Ilyas, R. Shah, W. G. Aref, J. S. Vitter, and A. K. [11] R. Kohavi, C. Brodley, B. Frasca, L. Mason, and Z. Zheng. [12] C. Li, K. C.-C. Chang, and I. F. Ilyas. Supporting ad-hoc [13] E.Lo,B.Kao,W.-S.Ho,S.D.Lee,C.K.Chui,andD.W.
 [14] A. Marian, N. Bruno, and L. Gravano. Evaluating top-k [15] R. Ramakrishnan, D. Donjerkovic, A. Ranganathan, K. S. [16] R. Sadri, C. Zaniolo, A. Zarkesh, and J. Adibi. Optimization [17] P. Seshadri, M. Livny, and R. Ramakrishnan. Sequence query [18] P. Seshadri, M. Livny, and R. Ramakrishnan. The design and [19] F. Wang and P. Liu. Temporal management of rfid data. In [20] T. Wu, D. Xin, and J. Han. Arcube: supporting ranking Given a pattern P =( v 1 ,...,v m ) ,thereare O ( m 2 ) of possible joining plans to compute the inverted-list L [ P ] under the restric-tions stated in Section 3.3. Here is the proof.

P ROOF . Given a pattern P =( v 1 , ..., v m ) , we only consider the joining plans which have the form: such that 2  X  y  X  x  X  m  X  1 .

In the valid plans, x ranges from 2 to m  X  1 . Given an x ,we have y ranges from 2 to x . That is, given an x ,thereare valid y  X  X . So, the number of joining plans should be:
However, if v 1 ,...,v m are not distinct, there could be duplicate joining plans in the previous calculation. For example, to mate-rialize L [ P ] for P =( a, a, a, a ) , we may consider the follow-ing two plans that are essentially the same: L [ P ]= L [( L [( a, a, a )] and L [ P ]= L [( a, a, a )] L [( a, a )] L [
P ]= L [( v 1 , ..., v x )] L [( v y , ..., v m )] and L L [( v y , ..., v m )] are duplicate plans if ( v 1 , ..., v ( v y , ..., v m )=( v 1 , .., v x ) ,and x = x . Therefore, ( 1) / 2 is an upper bound of the number of joining plans to be con-sidered.
