 1. Introduction
In recent years, the study of how to develop high-performance controllers in industrial engineering world has been a subject engaging the curiosity of many researchers and practitioners in the area of industrial and systems engineering. Traditional robust design methods such as m  X  X nalysis, H 2 ,H N has been done using different norm-bounded uncertainty ( Wolovich, 1994 ; Crespo, 2003 ). As each norm has its particular features addressing different types of performance objectives, it may not be possible to achieve all the robustness issues and loop performance goals simulta-neously. In fact, the difficult mixed norm-control methodology such as H 2 /H N has been proposed to alleviate some of the issue of meeting different robustness objectives ( Baeyens and Khargonekar, 1994 ). However, these are based on the worst case scenario considering in the most possible pessimistic value of the perfor-mance for a particular member of the set of uncertain models ( Savkin et al., 2000 ). Consequently, the performance characteristics of such norm-bounded uncertainties robust designs often degrades for the most likely cases of uncertain models as the likelihood of the worst-case design is unknown in practice ( Smith et al., 2005 ).
Recently, genetic algorithms (GAs) have also been deployed for multi-objective robust control design considering the robust sta-bility and the mixed H 2 and H N norms, simultaneously ( Herreros et al., 2002 ). However, in order to reduce the conservatism involved with such robust design methods or to account more for the most likely plants with respect to uncertainties, the probabilistic uncertainty, as a weighting factor, must be considered accordingly. In fact, probabilistic uncertainty specifies set of plants as the actual dynamic system to each of which a probability density function (PDF) is assigned ( Crespo and Kenny, 2005 ).
Therefore, such additional information regarding the likelihood of each plant allows a reliability-based design in which probability is incorporated in the robust design. The notion of stochastic robust-ness and probability of instability have been first mentioned by Stengel (1986 )and Stengel and Ryan (1989 ). The analysis of Monte
Carlo simulation (MCS) has also been introduced by Stengel to evaluate stochastic stability and performance of probabilistic uncertain systems ( Ray and Stengel, 1993 ). A lot of research exists in the areas of reliability analysis and computation of probability of failure. Monte Carlo simulation (MCS) is a direct and simple numerical method but can be computationally expensive. Some of early methods of analytical probabilistic analysis are first-order reliability method (FORM) and second-order reliability method (SORM), whose have come into much wider use in the past decade. Transformation of uncertain parameters of system into a standard normal space and approximating the limit state surface with a simpler lower order hyper surface are the basis of the both FORM and SORM techniques for calculation of probability of failure ( Smith et al., 2005 ; Crespo and Kenny, 2005 ). FORM and SORM methods approximate the limit state function with a first-order and second-order approximation, respectively. However, the approximation error increases as the limit state function nears the origin in standard normal space, therefore, these methods are only effective when looking at very low levels of probability of failure ( Crespo and Kenny, 2005 ).

System identification techniques are applied in many fields in order to model and predict the beh aviors of unknown and/or very complex system based on given inp ut X  X utput data. L. He develops an integrated simulation, infer ence, and optimization method (ISIOM) for identifying the optima l groundwater remediation stra-tegies at petroleum-contaminated aquifers ( He et al., 2008 ). Step-wise quadratic surface analysis method (SQRSA) is used to find the relationships between explanator y and the response variables. Also, predicting performance of the surrogated model is checked by four statistics, root mean-square error (RMSE), R 2 , F -value, and p -value.
Authors in He et al. (2008) develop a simulation-based fuzzy chance-constrained programming (SFCCP) model based on possibi-lity theory and applied it to a petroleum-contaminated aquifer located in western Canada for supporting the optimal design of groundwater remediation systems. In this study, Soil porosity, longitudinal dispersivity, transverse dispersivity and environmental standard for benzene are considered as fuzzy parameters (uncertain parameters). Estimation of possibilities in uncertain space is calcu-lated via artificial neural networks to mapping the input data to output. Also, simulated annealing algorithm is then employed to find an optimal model. Authors, in another study, developed a nonlinear chance-constrained programming (NCCP) model for opti-mizing surfactant-enhanced aquifer remediation (SEAR) processes ( He et al., 2008) .

Rogers proposed a new approach to nonlinear groundwater management methodology which optimized aquifer remediation in conjunction with artifici al neural networks (ANNs) ( Rogers and
Dowla, 1994 ). In this research, ANNs is first trained using some input X  X utput data obtained from a two-dimensional hybrid finite-difference/finite-element flow and transport code, and then using the trained ANN search through man y pumping realizations to find an optimal one for successful remediation. The conjugate gradient method and weight eliminatio n procedures are used to speed convergence and improve performance of ANNs, respectively. Same authors, in another study, developed a nonlinear optimization model using artificial neural networks and genetic algorithm and used in creating contaminant transport models that can be applied in groundwater management initiatives ( Rogers et al., 1995 ). All these research devised previously have been based on single objective optimization.

In this research, Multi-objective genetic algorithms are used to evolutionary designed the generalized-structure of GMDH-type (GS-GMDH) neural network ( Nariman-Zadeh et al., 2005 ; Jamali et al., 2009 ) in which connectivity configuration in such networks is not limited to adjacent layers for modeling and prediction of probability of failure of some objective function have been used in robust controller design. The important conflicting objectives of
GS-GMDH that are considered in this work are, namely, training error and prediction error. Moreover, optimal Pareto front of such
GMDH are obtained which exhibit the trade-off between the objective functions. In this way, some input X  X utput data consist-ing of uncertain parameters of system and controller parameters as inputs and probability of failure of some cost functions as output are used for training such GMDH-type neural networks. In order to demonstrate the prediction ability of evolved GMDH-type neural networks, input X  X utput data set have been divided into two different sets, namely, training and testing sets. The training set which consists of randomly selected inputs X  X utput data pairs is used for training the neural network models using the evolutionary method. The testing set which consists of remaining unforeseen inputs X  X utput data samples during the training process is merely used for testing to show the prediction ability of such evolved GMDH-type neural network models during the training process.

In this paper, some polynomial meta-models based on the evolved GMDH-type neural networks are obtained to simply calculate the probability of failures, instead of direct solution of dynamic equation of system. Moreover, the derived meta-models to predict the probability of failure are employed in conjunction with a multi-objective genetic algorithm has been used for Pareto optimal design of PI and PID controllers for a first order and a second order uncertain system with time delay. The objective functions that have been considered for Pareto multi-objective optimization are namely, probability of failure of settling time ( P
TS ) and probability of failure of overshoot ( P OS ). Such multi-objective Pareto optimization of these robust controllers unveils some very important and informative trade-offs among those objective functions. Consequently, some optimum robust con-trollers can be compromisingly chosen from the Pareto frontiers. The effectiveness of using neural networks to accurately predict the probabilities of failures of those objective functions needed to optimally design the PI and PID controllers during the MCS is shown based on the execution time of the proposed method. 2. Stochastic reliability-based analysis
Optimization design process is traditionally based on the deter-ministic approach in which nomin al values of the parameters are observed. But in most real engineer ing design problems, there are a variety of typical sources of uncertainty which have to be considered through robust design approach. Actually, optimization without applying uncertainty generally lead s to non-optimal and potentially high risk solution ( Lim et al., 2005 ). Generally, there are two categories of uncertainty, namely, structured and unstructured uncertainty. The structured uncer tainty concerns about the model uncertainty due to unknown values of parameters in a known structure, whilst unstructured u ncertainty concerns about the unknown dynamic of the structure. Moreover, it is very desirable to find robust design whose performance variation in the presence of uncertainties is not high. Moreover, performance variation of such robust design approach must be logically bounded in the presence of the uncertainties. Totally, t here are two non deterministic approaches addressing the stochas tic robustness behavior, namely, robust design optimization (RDO) and reliability-based design optimization (RBDO) ( Papadrakakis et al., 2004 ). Both approaches represent non deterministic optimization formulations in which the probabilistic uncertainty is incorporated into the stochastic optimal design process. Therefore, the propagation of a priori knowledge regarding the uncertain parameters through the system provides some probabilistic metrics such as random variables (e.g., settling time, maximum overshoot, closed loop poles, y ), and random processes (e.g., step respo nse, Bode or Nyquist plot, y )inacontrol system design ( Smith et al., 2005 ). In RDO approach, the stochastic performance is required to be less sensitive to the random variation induced by uncertain parameters so that the performance degrada-tion from ideal deterministic behavior is minimized. In RBDO approach, some evaluated reliability metrics subjected to probabil-istic constraints are satisfied so that the violation of design require-ments is minimized. In this case, limit state functions are required to define the failure of the control system. Fig. 1 depicts the concept of these two design approaches where f is to be minimized.
As mentioned in this figure, the slimmest diagram is shown  X  X  X ore robust design X  X , because it is less sensitive to the random variation induced by uncertain parameters. Also, upper bound of the diagram has been shown the  X  X  X ore reliable des ign X  X  is less than other charts.
Regardless the choice of any of these two approaches, random variables and random processes should be evaluated reflecting the effect of probabilistic nature of uncertain parameters in the performance of the control system. With the aid of ever increas-ing computational power, there have been a great amount of research activities in the field of robust analysis and design devoted to the use of Monte Carlo simulation ( Crespo, 2003 ; Crespo and Kenny, 2005 ; Stengel, 1986 ; Stengel and Ryan, 1989 ; Ray and Stengel, 1993 ; Papadrakakis et al., 2004 ; Kang, 2005 ).
In fact, Monte Carlo simulation (MCS) has also been used to verify the results of other methods in RDO or RBDO problems when sufficient number of sampling is considered ( Wang and Stengel, 2001 ; Kalos and Whitlock, 1986 ) Monte Carlo simulation (MCS) is a direct and simple numerical method but can be computationally expensive. In this method, random samples are generated assum-ing pre-defined statistical distributions for uncertain parameters.
The system is then simulated with each of these randomly generated samples and the percentage of cases produced in failure region defined by limit state function approximately reflects the probability of failure.

Let X be a random variable, then the prevailing model for uncertainties in stochastic randomness is the probability density function (PDF), f X ( x ) or equivalently by the cumulative distribu-tion function (CDF), F X ( x ), where the subscript X refers to the random variable. This can be given by F  X  x  X  X  Pr X r x  X  X  X  where Pr(.) is the probability that an event ( X r x ) will occur.
In the reliability-based design, it is required to define reliability-based metrics via some inequality constraints. Therefore, in the presence of uncertain parameters of plant ( p ) whose PDF or CDF can can be given as
P  X  p  X  X  Pr  X  g i  X  p  X  r 0  X  X  e i  X  1 , 2 , ... , k  X  X   X  2  X 
In Eq. (2) , P f i denotes the probability of failure (i.e., g the i th reliability measure and k is the number of inequality constraints (i.e., limit state functions) and e is the highest value of desired admissible probability of failure. It is clear that the desirable value of each P f i is zero. Therefore, taking into consideration the stochastic distribution of uncertain parameters ( p )as f can now be evaluated for each probability function as
P  X  p  X  X  Pr g i  X  p  X  r 0  X 
This integral is, in fact, very complicated particularly for systems with complex g ( p )( Wang and Stengel, 2002 ) and Monte
Carlo simulation is alternatively used to approximate Eq. (3) .Inthis value of 1 in the case of failure ( g ( p ) r 0) and the value of zero otherwise,
I  X 
Consequently, for each limit state function the integral of Eq. (3) can be rewritten as
P  X  p  X  X 
Where G( p ) is the uncertain plant model and C( k ) is the controller to be designed in the case of control system design problems. Based on Monte Carlo simulation ( Ray and Stengel, 1993 ; Wang and Stengel, 2001 , 2002 ; Kalos and Whitlock, 1986 ), the probability using sampling technique can be estimated using
P p  X  X  X  1 N where N is the number of samples. In other words, the probability of failure is equal to the number of samples in the failure region divided by the total number of samples. Therefore, high time cost is required for calculation of probability of failure using Eq. (6) because complex dynamic equations of system must be solved for each generated sample. For time cost reduction, in this paper, polynomial meta-models based on the evolved group method of data handling (GMDH) neural networks are obtained to simply represent dynamic equation of system. Using such obtained polynomial neural network models the probability of failure is calculated. However, there have been many research activities on s ampling techniques to reduce the number of samples keeping a high le vel of accuracy. Alternatively, the quasi-MCS has now been increasingly accepted as a better sampling technique which is also known as Hammersley Sequence
Sampling (HSS) ( Smith et al., 2005 ; Crespo and Kenny, 2005 ). In this paper, HSS has been used to generate samples to build a meta-model of system using GMDH-type neural network. 3. Modeling using GMDH type neural networks
By means of the GMDH algorithm, a model can be represented as a set of neurons in which different pairs of them in each layer are connected through a quadratic polynomial and, thus, produce new neurons in the next layer. Such representation can be used in modeling to map inputs to outputs. The formal definition of the identification problem is to find a function ^ f that can be approxi-mately used instead of the actual one, f in order to predict output its actual output y . Therefore, given M observations of multi-input, single output data pairs so that y  X  fx i 1 , x i 2 , ... , x in  X  X  i  X  1 , 2 , ... , M  X  X   X  7  X 
It is now possible to train a GMDH type neural network to predict the output values ^ y for any given input vector X  X  x ... , x in  X  , that is ^ y  X  ^  X  X  i  X  1 , 2 , ... , M  X  X   X  8  X 
The problem is now to determine a GMDH type neural net-work so that the square of the differences between the actual output and the predicted one is minimized, that is ^  X  X  y i hi 2
The general connection between the inputs and the output variables can be expressed by a complicated discrete form of the
Volterra functional series in the form of y  X  a 0  X  where is known as the Kolmogorov-Gabor polynomial ( Farlow, 1984 ). This full form of mathematical description can be repre-sented by a system of partial quadratic polynomials consisting of only two variables (neurons) in the form of ^ y  X  Gx i , x j  X  a 0  X  a 1 x i  X  a 2 x j  X  a 3 x i x j  X  a 4
In this way, such partial quadratic description is recursively used in a network of connected neurons to build the general mathematical relation of the inputs and output variables given in
Eq. (10) . The coefficients a i in Eq. (11) are calculated using regression techniques ( Farlow, 1984 ; Ivakhnenko, 1971 ; Iba et al., 1996 ), so that the difference between the actual output, y , minimized. Indeed, it can be seen that a tree of polynomials is constructed using the quadratic form given in Eq. (11) whose coefficients are obtained in a least squares sense. In this way, the coefficients of each quadratic function G i are obtained to fit optimally the output in the whole set of input X  X utput data pairs, that is E  X 
In the basic form of the GMDH algorithm, all the possibilities of two independent variables out of the total n input variables are taken in order to construct the regression polynomial in the form of in a least squares sense ( Nariman-Zadeh et al., 2005 , 2003 Jamali et al., 2009 ;). In this paper, the general structure of GMDH-type neural network (GS-GMDH) has been proposed by some authors ( Nariman-Zadeh et al., 2005 ; Jamali et al., 2009 ) is used for modeling and prediction of probability of failure of some objective function in design of controllers for some systems with probabilistic uncertain parameters. Moreover, the multi-objective genetic algorithms have been used for Pareto optimal design of structure of such GMDH-type neural network. The important conflicting objectives of GS-GMDH that are considered in this work are, namely, training error and prediction error. 4. Multi-objective optimization
Multi-objective optimization problem (MOP) that is also called multi-criteria optimization or vector optimization has been defined as finding a vector of decision variables satisfying con-straints to give optimal values to all objective functions ( Coello
Coello and Christiansen, 2000 ; Coello Coello et al., 2002 ). In general, it can be mathematically defined as: Find the vector X  X  X  x 1 n , x 2 n , , x n n T to optimize F  X  X  X  X  X  f 1  X  X  X  , f 2  X  X  X  , , f k  X  X  X  T  X  13  X 
Subject to m inequality constraints l  X  X  X  r 0 , i  X  1to m  X  14  X 
And p equality constraints h  X  X  X  X  0 , j  X  1to p  X  15  X  where, X n E R n is the vector of decision or design variables, and
F  X  X  X  E R k is the vector of objective functions. Without loss of generality, it is assumed that all objective functions are to be minimized. Such multi-objective minimization based on the Pareto approach can be conducted using some general definitions.
The Pareto dominance of a vector of objective functions is defined as follows. A vector U  X  X  u 1 , u 2 , ... , u k E R k dominates to vector V  X  X  v 1 , v 2 , , v k E R k (denoted by U ! V ) if and only if 8 i
A f 1 , 2 , ... , k g , u i r v i 4( j A f 1 , 2 , ... , k g , u there is at least one u j which is smaller than v j whilst the rest u  X  X  are either smaller or equal to corresponding n  X  X .
The Pareto optimality of a vector of design variables is also defined as follows. A point X n A O ( O is a feasible region in R satisfying Eqs. (14) and (15) ) is said to be Pareto optimal (minimal) with respect to all X A O if and only if FX n ! F  X  X  X  .Alternatively, it can be readily restated as 8 i A f 1 , 2 , ... , k g , 8 X g , f i X n r f i  X  X  X  4( j A f 1 , 2 , ... , k g , f j X n r f the solution X n is said to be Pareto optimal (minimal) if no other solution can be found to dominate X n using the definition of Pareto dominance. Consequently, for a given MOP, a Pareto set P n is a set in the decision variable space consisting of all the Pareto optimal no other X 0 in O that dominates any X A P n . Finally, for a given MOP, are obtained using the vectors of decision variables in the Pareto set P n ,thatis, PF n  X f F  X  X  X  X  f 1  X  X , f 2  X  X  X  , ... , f from P n .

Some unique natural properties of evolutionary algorithms like their parallel or population-based search scheme have been reasons to use them for multi-objective optimization problems. It should be noted that keeping the genetic diversity in the popula-tion or the Pareto front is one of the important and main issue of these methods ( Nariman-Zadeh et al., 2010 ; Jamali et al., 2008 , 2010 ; Deb et al., 2002 ). The Pareto-based approach of NSGA-II ( Deb et al., 2002 ) has been used in a wide range of engineering MOPs because of its simple yet efficient non-dominance ranking procedure in yielding different levels of Pareto frontiers. However, the crowding approach in such a state-of-the-art MOEA ( Coello Coello and Becerra, 2003 ) works efficiently for two-objective optimization problems as a diversity-preserving operator which is not the case for problems with more than two objective functions ( Nariman-Zadeh et al., 2010 ; Jamali et al., 2008 , 2010 ).
In this work, a multi-objective uniform-diversity genetic algo-rithm method MUGA ( Nariman-Zadeh et al., 2010 ; Jamali et al., 2008 , 2010 ) is used for the multi-objective robust optimal design of PI and PID controllers for both first and second order uncertain system with time delays. MUGA uses non-dominated sorting mechanism together with a e -elimination diversity preserving algorithm to get Pareto optimal solutions of MOPs more precisely and uniformly. In fact, the basic idea of sorting of non-dominated solutions originally proposed by Goldberg (1989 ) which has been used in different evolutionary multi-objective optimization algo-rithms, more importantly in NSGA II by Deb et al. (2002 ), has been adopted here. In order to improve the genetic diversity among the population, the e -elimination diversity approach is used in which all the clones and e -similar individuals are recognized and simply eliminated from population. Therefore, based on a value of e as the elimination threshold, all the individuals in a front within this limit of a particular individual are eliminated. More detailed description of MUGA such as pseudo code of main algorithm, e -elimination algorithm etc., can be found in Nariman-Zadeh et al. (2010) , Jamali et al. (2008 , 2010 ). 5. Illustrative examples In this section, multi-objective Pareto optimal design of PI and PID controllers for a first-order and a second-order uncertain system with time delay is considered using the proposed method of this paper. GMDH-type neural networks have been employed to build a meta-model for two objective functions which are namely, probability of failure of settling time ( P TS ) and probability of failure of overshoot ( P OS ). The effectiveness of using neural networks to accurately predict the probabilities of failures of those objective functions needed to optimally design the PI and
PID controllers during the MCS is shown based on the execution time of the proposed method.

A proportional X  X ntegral X  X erivative controller (PID controller) is a generic controller widely used in industry. According to a survey for process control systems conducted in 1989, more than 90 percent of the control loops was of the PID type. The PID controller involves three separate parts, are namely, proportional ( K p ), integral ( K derivative ( K d ). The proportional part reduces a large part of the overall error; the integral part reduces the final error in a system by summing even a small error over ti me produces a drive signal large enough to move the system toward a smaller error; and the derivative part counteracts the K p and K i terms when the output changes quickly and reduce overshoot. 6. First case study: PI controller design for first-order system with time delay
Many industrial systems can be adequately presented by a first-order system with time delay ( Toscana 2005 ; Sree et al., 2004 )as
Gs  X  X  X  ke
In the case of stochastic robust design, parameters of the plant given by Eq. (16) vary according to a priori known probabilistic distribution functions around a nominal set of parameters. In order to compare the obtained results in this work with those suggested by Toscana (2005) , Jamali (2009) and Hajiloo et al. (2007 ), beta distributions with the coefficients of 2 and 2 with the limits of 7 50% of the nominal values of plant parameters, k  X  t  X  T  X  1, have been selected. Simple structure PI Controllers are widely used for many industrial processes represented by the transfer function of Eq. (17) . The transfer function, C(s), of the standard PI Controller of the feedback control system shown in Fig. 2 is
Cs  X  X  X  K p  X  K i s  X  17  X  where the design vector K  X f K p , K i g has to be optimally deter-mined based on the reliability-based multi-objective Pareto approach for the uncertain first-order system using some sto-chastic evaluation metrics.

The performance of a controlled closed-loop system is usually evaluated by variety of goals ( Wolovich, 1994 ; Sree et al., 2004 ).
Two objective functions that have been considered are namely, probability of failure of settling time ( P TS ) and probability of failure of overshoot ( P OS ). The overshoot is the maximum swing above final value, and increases with damping ratio of the system.
The settling time is the time for departures from final value to sink below some specified level, say 3% to 5% of final value.
The limit state functions of two objective functions can be defined as, P  X  P Settling time Z 10 s  X  X   X  18a  X  P  X  Pg Ts p  X  X  r 0  X  g  X  p  X  X  10 settling time  X  18c  X  and
P  X  P Overshoot Z 20%  X  X   X  19a  X 
P  X  Pg ov p  X  X  r 0  X  g  X  p  X  X  20% Overshoot  X  19c  X  where p is vector of uncertain parameters of system. In this paper,
GMDH-type neural network are now used for calculation of probability of failures of the objective functions. In order to build a polynomial meta-model using GMDH-type neural, a total number of 5000 random input X  X utput data set have been used considering five parameters as inputs, namely, K P , K i , k , t one output which is the probability of failure of overshoot ( P given by Eq. (19) . In order to demonstrate the prediction ability of evolved GMDH-type neural networks, input X  X utput data set have been divided into two different sets, namely, training and testing sets. The training set which consists of randomly selected 3000 out of 5000 inputs X  X utput data pairs is used for training the neural network models using the evolutionary method of this paper. The testing set which consists of remaining 2000 unfore-seen inputs X  X utput data samples during the training process is merely used for testing to show the prediction ability of such evolved GMDH-type neural network models during the training process. The optimal structure of the evolved 2-hidden layer
GMDH-type neural network which has been selected by a multi-objective GAs ( Nariman-Zadeh et al., 2005 ; Jamali et al., 2009 ) is shown in Fig. 3 . The corresponding recursive polynomial representation of such model for P OS is as follows:
Y  X  0 : 8199  X  0 : 5923 K i  X  0 : 7883 k  X  0 : 3176 K i k 0 : 1793 K
Y  X  0 : 7116  X  1 : 5737 t d  X  0 : 1270 T 0 : 3705 t d T  X  0 : 1312 t
Y  X  0 : 0313 0 : 0513 k  X  1 : 0489 Y 1  X  0 : 0135 kY 1 0 : 1126 k
Y
P  X  0 : 2754  X  0 : 5172 Y 3  X  0 : 7222 Y 4  X  0 : 0519 Y 3 Y
The same procedure has been used for meta-model modeling of
The optimal structure of the evolved 2-hidden layer GMDH-type neural network have been selected by multi-objective GAs is shown in Fig. 4 . The corresponding polynomial representation of such model for P TS is as follows,
Y  X  2 : 3855 4 : 5303 K p 1 : 7062 K i  X  3 : 2265 K p K i  X  0 : 5774 K
Y  X  1 : 1798 1 : 6881 K i 0 : 1475 k  X  0 : 6219 K i k  X  0 : 1643 K
Y  X  0 : 212  X  0 : 5748 k  X  0 : 1657 t d  X  0 : 1636 k t d  X  0 : 112 k
Y  X  1 : 2263 0 : 811 t d 2 : 78367 T  X  1 : 1261 t d T  X  3 : 212 t
Y
Y P
The objective functions P OS , P TS represented by Eqs. (20) and (21) , respectively, are now considered in a Pareto optimization process to obtain some important trade-offs among these con-flicting objectives. Therefore, the vector of objective functions to be optimized in a Pareto sense is given as follows: cf !  X  fcn  X  P os , P TS  X  22  X 
Therefore, these objective functions are not computed directly any more, rather are computed using Eqs. (20) and (21) that are obtained GMDH-type neural networks approach of this paper.
Such procedure is conducive to a sharp decline of run time in optimization problem solution.
 The optimization process of the robust PI controller given by
Eq. (17) is accomplished by 200 Monte Carlo evaluations for each candidate control law during the evolutionary process. A popula-tion size of 60 and generation number of 400 has been chosen with crossover probability ( P c ) and mutation probability ( P 0.95 and 0.01, respectively. The vector of objective functions given by Eq. (22) is used to obtain non-dominated optimum PI controllers to find the trade-offs among those objective functions.
A total number of 9 non-dominated optimum design points have been obtained and shown in Fig. 5 in the plane of P OS and P this figure, the design points B and C stand for the best P best P OS , respectively. It is clear from this figure that all the optimum design points in the Pareto front are non-dominated and could be chosen by a designer as an optimum PI controller. Evidently, choosing a better value for any objective function in the
Pareto front would cause a worse value for another objective. The corresponding decision variables of the Pareto front shown in Fig. 5 are the best possible design points so that if any other set of decision variables is chosen, the corresponding values of the pair of objectives will locate a point inferior to this Pareto front. Such inferior area in the space of the two objectives is in fact top/right side of Fig. 5 . Clearly, there are some important optimal design facts between these two objective functions which can now be discovered by the Pareto optimum design approach. Such impor-tant design facts could not have been found without the use of multi-objective Pareto optimization process. It is now desired to find a trade-off optimum design point compromising both objec-tive functions. Point A representing a PI controller with K  X  0 : 525 and K i  X  0.414 can be optimally chosen from a trade-off point of view for objectives P OS and P TS . The objective functions and design variable values corresponding to design point A, B, C and references ( Toscana, 2005 ; Jamali, 2009 ; Hajiloo et al., 2007 ) are given in Table 1 . It is evident from this table that the performance of the proposed trade-off design point A is resonably better than those mentioned in other research works.

Also, in order to show the robust behavior of the robust trade-off optimum point A of this work a MCS with 5000 evaluations has been performed using different design given in Table 1 .Itis very evident from Fig. 6 which exhibits the upper and lower bounds of the step responses that the stochastic performance of the controller of this paper is superior to those of other refrences. As it can be seen from this figure, the probabilistic step response of design points resulted from proposed method, represent more robust behavior because have less areas between upper and lower bounds. In the other hand, the probabilistic step responses corresponding to proposed design points depict areas that are less affected by the uncertainty.

The probabilistic performances of 9 non-dominated design points obtained by the proposed meta-modeling of this paper have also been re-evaluated without using GMDH models for those probabilities in MCS with 5000 evaluation. The results of such analysis, for both probabilities of failure of settling time and of overshoot, have been shown in Table 2 . The very close agreement of these results with the results of using the GMDH model to compute the probabilities, demonstrates the effective-ness and accuracy of the approach of this paper.

Moreover, there is a significant decrease in run time correspond-ing to the calculation of probability of failure processes using GMDH models. Three different MCS have been accomplished for 1000, 2000 and 3000 samples with/without GMDH models which the results are depicted in Table 3 . It is very clear from this table that the proposed meta-modeling GMDH-type neural network of this work significantly decreases the computa tional time in comparison with direct MCS method without using those meta-models which, there-fore, makes the use of MCS very pr actical and plausible for robust control system designs. 7. Second case study: PID controller design for second-order lag with time delay system
The proportional X  X ntegral X  X erivative (PID) controllers are widely used in many industrial control systems for several decades since Ziegler and Nichols proposed their first PID tuning method. This is because the PID controller structure is simple and its principle is easier to understand than most other advanced controllers. On the other hand, the general performance of PID controller is satisfactory in many applications. For these reasons, the majority of the controllers used in industry are of PID type ( Toscana 2005 ). Many industrial systems can be adequately presented by a first-order system with time delay as:
Gs  X  X  X  ke
Similary, beta distributions with the coefficients of 2 and 2 with the limits of 7 50% of the nominal values of plant parameters, K  X  t d  X  a 0  X  a 1  X  1 have been selected. Simple struc-ture PID controllers are widely used for many industrial processes represented by the transfer function of Eq. (24) . The transfer function, C ( s ), of the standard PID controller of the feedback control system shown in Fig. 2 is:
Cs  X  X  X  K p  X  K i s  X  K d s  X  24  X  mined based on the reliability-based multi-objective Pareto approach for the uncertain second-order system using some stochastic evaluation metrics. Two objective functions that have been considered are namely, probability of failure of settling time ( P ) and probability of failure of overshoot ( P OS ). The limit state functions of two objective functions can be defined as, g  X  p  X  X  10 settling time  X  25  X  g  X  p  X  X  10% overshoot  X  26  X 
Again, GMDH-type neural network have been used for modelling and prediction of these objective fun ctions. In this way, input-output data consisting of seven inputs, namely, K P , K i , K d , k , t one output P OS or P TS . The optimal structures of the evolved 2-hidden layer GMDH type neural network for P OS and P TS shown in Figs. 7 and 8 , respectively. The corresponding polynomial representations of such model for P OS and P TS are given by Eqs. (27) and (28) , respectively.

Y  X  0 : 4119 0 : 5308 K P  X  0 : 333 a 1  X  0 : 1312 K P a 1 0 : 1237 K
Y  X  0 : 5539 0 : 4577 K d  X  0 : 746 t d  X  0 : 4608 K d t d  X  0 : 0891 K
Y  X  0 : 3073  X  1 : 6617 k 0 : 5451 a 1 0 : 0831 ka 1  X  0 : 0769 k
Y  X  0 : 172 0 : 889 K i 0 : 0037 a 0 0 : 2239 K i a 0  X  0 : 0928 K
Y
Y P
OS  X  0 : 4466  X  1 : 1263 Y 5  X  0 : 7904 Y 6 0 : 3631 Y 5 Y
Y  X  0 : 9046 0 : 9044 K P  X  0 : 0518 a 1  X  0 : 3514 K P a 1
Y  X  0 : 9177 0 : 2298 K d 0 : 1754 t d  X  0 : 6417 K d t d  X  0 : 2607 K Y  X  0 : 9527 0 : 9524 k  X  0 : 1674 a 0 0 : 0831 ka 0  X  0 : 0769 k Y  X  1 : 1953 0 : 0815 K i 0 : 484 a 0  X  0 : 0116 K i a 0  X  0 : 027 K Y Y  X  1 : 341  X  3 : 4129 Y 4 5 : 6216 Y 3 2 : 2359 Y 4 Y 3  X  2 : 5183 Y P TS  X  2 : 5086  X  3 : 2813 Y 5  X  3 : 4129 Y 6  X  0 : 1688 Y 5
The confelecting objective functions P OS and P TS are now considered simultaneously in a Pareto optimization process to obtain some important trade-offs among the objectives. Similary, the optimization process design of the robust PID controller given by Eq (24) is accomplished by 200 Monte Carlo evaluations for each candidate control law during the evolutionary process. A population size of 60 and generation number of 400 has been chosen with crossover probability ( P c ) and mutation probability ( P m ) as 0.95 and 0.01, respectively.

A total number of 7 non-dominated optimum design points have been obtained and shown in Fig. 9 . It is clear from this figure that all the optimum design points in the Pareto front are non-dominated and could be chosen by a designer as optimum PID controller. In Fig. 9 , the design points E and F are candidates for the lowest P TS and P OS , respectively. An important trade-off point can also be observed from this Pareto front. Point D representing a optimally chosen from a trade-off point of view for objectives P and P TS .

The objective functions and design variable values correspond-ing to design point D, E, F and references ( Jamali 2009 ; Nariman-zadeh et al., 2007 ) are given in Table 4 . It is evident from this table that the performance of the proposed trade-off design point D is reasonably better than those mentioned in other research works. Also, in order to show the robust behavior of the robust trade-off optimum point D of this work a MCS with 5000 evaluations has been performed using different design given in Table 4 . It is very evident from Fig. 10 which exhibits the upper and lower bounds of the step responses that the stochastic performance of the controller of this paper is superior to those of other refrences because have less areas between upper and lower bounds.
The probabilistic performances of seven non-dominated design points obtained by the proposed meta-modeling of this paper have also been re-evaluated without using GMDH models for those probabilities in MCS with 5000 evaluation. The results of such analysis, for both probabilities of failure of settling time and of overshoot, have been shown in Table 5 . The very close agreement of these results with the results of using the GMDH model to compute the probabilities, demonstrates the effective-ness and accuracy of the approach of this paper.

Moreover, there is a significant decrease in run time corre-sponding to the calculation of probability of failure processes using GMDH models. Three different MCS been accomplished for 1000, 5000 and 10000 samples with/without GMDH models which are the results are depicted in Table 3 . It is very clear from this figure that the proposed meta-modeling GMDH-type neural network of this work significantly decreases the computational time in comparison with direct MCS method without using those meta-models which, therefore, makes the use of MCS very practical and plausible for robust control system designs.
However, the proposed method is not sensitive to the type of probability distributions of uncertain parameters. In order to show the probability of failure of proposed optimum design points in this work, a HSS with 5000 evaluations has been accomplished for Normal, Guassian and Beta distributions, which are depicted in Table 6 . As it is shown in this table, there are not any significant discrepancies among the probability of failure corresponding to various distributions.
 8. Conclusion
GMDH-type neural networks have been successfully used to obtain some polynomial meta-models to simply calculate the probability of failure of some objective function of uncertain control systems such as settling time and overshoot in the MCS, instead of direct solution of dynamic equation of system. The derived meta-models of system in conjunction with multi-objective genetic algorithm and MCS have been used for Pareto optimal design of PI and PID controllers for first and second order uncertain system with time delay, respectively. Also, the effec-tiveness of using neural networks to accurately predict the probabilities of failures of those objective functions needed to optimally design the PI and PID controllers during the MCS was shown based on the execution time of the proposed method. The meta-model proposed by this work can be generally used for any other control systems and plant with probabilistic uncertain parameters. Moreover, multi-objective genetic algorithms are used to evolutionary designed the generalized-structure of
GMDH-type neural network in which connectivity configuration in such networks is not limited to adjacent layers for modeling and prediction of probability of failure of some objective function have been used in robust controller design. The important con-flicting objectives of GS-GMDH that are considered in this work are, namely, training error and prediction error. It is clear that the proposed meta-model GMDH-type neural network of this work significantly decreases the computational time in comparison with direct MSC method without using those meta-model which, therefore makes the use of MSC very practical and plausible for robust control system design.
 References
