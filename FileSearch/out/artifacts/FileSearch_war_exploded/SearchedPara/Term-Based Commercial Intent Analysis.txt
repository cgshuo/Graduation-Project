 In this work, we investigate the contribution of query terms and their corresponding ad click rates on commercial intent of queries. A probabilistic model is proposed following the hypothesis that a query is likely to receive ad clicks based on contributions from its individual terms.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Experimentation, Measurement In Web search, the intent of a user may correspond to one of the classic categories defined by Broder [2]: navigational , informational , and transactional . In order to identify search query intention, implicit feedback techniques take advantage of user behaviour to understand their interests and prefer-ences [1, 6]. For sponsored search and ad display, we may also wish to know if a user has online commercial intent , the intention to purchase a product or service [3].

In this paper, we study the impact of previously recorded  X  X d X  click information on query intent analysis for sponsored search. In particular, we investigate the relationship be-tween query terms and ad click behavior. The results are based on a data set obtained from Microsoft adCenter, con-sisting of roughly 100 million search result pages and ad clickthrough logs sampled over a number of months. We calculated the frequency of the terms appeared in clicked and non-clicked queries of the data set. As seen in Ta-ble 1, strong commercial terms, such as sale , cheap , and store appear among the top frequent terms in the clicked queries. Some terms, such as free , appear in both. These observations motivate our hypothesis about contributions of individual terms and their ad clicks towards commercial in-tent of the queries. We describe a strategy for reliably and quickly producing a large batch of manually labeled queries in order to validate this hypothesis. If a query receives ad click, we assume the user intent is more likely to be commercial than if it does not. We define P ( c = Table 1: List of most frequent terms in the data set 1 | q ) as the probability that a click occurs ( c = 1) when the query q is entered by a user. Similarly, we define P ( c = 0 | q ) as the probability that a click does not occur when q is entered. As there are two hypotheses in this model (click or no click), we consider the ratio of the posterior probability of a query under these hypotheses. The relative value of the likelihood-ratio is used for making a decision between the two hypotheses. Given a query q , the log-likelihood-ratio is calculated as follows: Given q consisting of n terms w 1 , ..., w n , where n &gt; 0, we estimate P ( q | c = 1) and P ( q | c = 0) by assuming indepen-dence between the query terms. Apply the Bayes X  theorem, the log-likelihood-ratio for q can be written as:
In addition, the probability of each term contributing or not contributing to a click can be estimated as follows: pears in clicked and non-clicked queries respectively. Q c Q w are correspondingly the number of all terms in clicked and non-clicked queries. Moreover, P ( c = 1) and P ( c = 0) may be estimated in terms of ratio of the number of queries resulting in a click ( Q c ) to the total number of queries ( Q ): For evaluation purposes, a contiguous block of 4000 queries were selected from an arbitrary point in the log data. 1000 queries for this set were labeled by three researchers from our group. If the presumed purpose of submitting a query is to make an immediate or future purchase of a product or service, the query was labeled as  X  X ommercial X . Otherwise, it was labeled as  X  X on-commercial X . The final labeling of each query was based on majority agreement between these Figure 1: ROC curve of prediction from on ad click data vs. the prediction from on organic click data annotators. In order to increase the set of manually labeled queries relatively cheaply and reliably, we employed Ama-zon Mechanical Turk 1 in order to label the remained 3000 queries (called the MT set ). The 1000 initial queries were used as a seed set to validate the results obtained from Me-chanical Turk.

The entire set of selected queries were divided into 40 batches with each batch containing 25 seed queries and 75 MT queries. These batches were submitted to Mechanical Turk and labeled according to instructions that we provided to their workers. For each batch labeled by a worker, we compared the labels assigned to the seed queries in the batch with the labels previously assigned by our annotators. If the agreement of the worker with our annotators was found to be above 60% (well above the random case), the labels assigned by this worker were accepted. If the agreement was found to be above 75%, we awarded a bonus to the worker. Otherwise, the labels were rejected and the same batch of queries were submitted for labeling by a different worker. We repeated the process until all batches were successfully labeled by five different workers. The final label of each query was based on majority agreement among the workers.
The log-likelihood-ratio value for each of the 4000 queries was calculated according to Equation 1. The queries were then sorted by that value, and a cut-off point was deter-mined so that all the queries with the value above the point would be considered as commercial and all below the point would be considered as non-commercial . The predicted la-bel for each query is then compared with the one assigned through Mechanical Turk in order to determine the accu-racy of prediction based on a cut-off point. Finally, the true positive rate (sensitivity) is plotted in function of the false positive rate (1-specificity) for different cut-off points as the ROC curve in Figure 1. For comparison purposes, the figure also plots a similar result based on organic clickthrough data taken from the same commercial search engine.

Each point on the ROC curve represents a sensitivity/ speci-ficity pair corresponding to a particular decision threshold (cut-off point). It is observed that the curve obtained from ad clicks represents a much stronger curve in comparison to the one based on organic data (closer to the upper left of the ROC space). This appears to confirm that terms with respect to their ad clickthrough are effective in detecting the commercial intent of queries that include such terms.
We further analyzed the results obtained from ad click data by removing the queries falling within a specific mar-http://www.mturk.com/
Figure 2: ROC curves for varying margin values gin above and below the cut-off point. Our reasoning is that queries with a value close to the cut-off point could be considered to have an ambiguous intent (i.e. they could be placed in any of the two categories). We tested this hypoth-esis with four values as the margin: 0.5, 1, 1.5, and 2. The resulted ROC curve based on each margin value is plotted in Figure 2 beside the original ROC curve from the previous figure. As is shown in the figure, the greater the margin, the closer the curve is to the upper left corner. We have proposed a probabilistic model based on Bayes X  theorem and following the hypothesis that a query is likely to receive clicks based on contributions from its individual terms. This is similar to what is reported by Regleson and Fain [5] that different terms have an inherently different like-lihood of receiving sponsored click. In [4], Jansen et al. also deal with particular terms that appear along different query types in order to identify characteristics of each query cate-gory. Our contribution in this work applies to any arriving query with respect to the terms that appears in it and with respect to the ad clickthrough of such terms in the log data so that a prediction can be made regarding the commercial intent of the query. The results suggest that click behavior predicted from the terms in a query correlates with the inten-tion underlying the query. The results appear even stronger when a margin of ambiguous queries is removed. We would like to thank Microsoft Research and Microsoft adCenter for providing the data sets and for partially fund-ing this work. [1] R. Baeza-Yates, L. Calder  X an-Benavides, and [2] A. Broder. A taxonomy of Web search. ACM SIGIR [3] H. Dai, L. Zhao, Z. Nie, J. Wen, L. Wang, and Y. Li. [4] B. Jansen, D. Booth, and A. Spink. Determining the [5] M. Regelson and D. Fain. Predicting clickthrough rate [6] D. Rose and D. Levinson. Understanding user goals in
