 This demonstration presents an infrastructure for computing multilingual semantic relatedness and correlation for twelve natural languages by using three distributional semantic mod-els (DSMs). Our demonsrator -DInfra (Distributional In-frastructure) provides researchers and developers with a highly useful platform for processing large-scale corpora and con-ducting experiments with distributional semantics. We in-tegrate several multilingual DSMs in our webservice so end user can obtain a result without worrying about the com-plexities involved in building DSMs. Our webservice allows the users to have easy access to a wide range of comparisons of DSMs with different parameters. In addition, users can configure and access DSM parameters using a easy to use API.
 H.1.0 [ Information Systems ]: MODELS AND PRINCI-PLES.
 Distirbutional Infrastructure, Multilingual Semantic Relat-edness, Distributional Semantic Models
Dinfra is an implementation of Explicit Semantic Anal-ysis (ESA), Latent Semantic Analysis (LSA) and Random Indexing based on the EasyESA [4] and S-Space [7] . It runs as a JSON 1 webservice, which allows users to submit queries for similar terms in a multilingual fashion bases on a seman-tic relatedness measure which use Spearman X  X  correlation to test relatedness scores.
 The Dinfra webservice allows the user to obtain semantic JSON -Java Script Object Notation similarity using Spearman correlation for 12 natural lan-guages 2 . Our service can be tested online 3 . It includes two components: 1-Semantic Relatedness (Figure 1) that cal-culates the words similarity, 2-Correlation (Figure 2) that calculates the spearman X  X  rank correlation.
Ferret [5] tested corpust-based approaches for measuring semantic similarity. He also chose to use limited means be-cause of deficit of linguistic tools are not, or at least freely available, for all popular languages. Bullinaria et al. [3, 2] have built semantic vectors from very small co-occurrence windows, together with a cosine distance measure, stop-words, word stemming, and dimensionality reduction using singular value decomposition to improve performance. The BNC and (British National Corpus) 4 and ukWaC 5 corpus were used In [2] and [3], respectively. Three word similarity datasets WordSim353 (W353), the Rubenstein &amp; Goodenough (RG) (1965) and Miller &amp; Charles (MC) (1991) have been used in Dinfra. All these datasets consist of human similarity ratings for word pairings. We also consider Wikipedia 6 corpus the years (2006, 2008, 2014) and ukWaC [1] corpus from which to build the vectors. In Dinfra, three DSMs were instantiated. Latent Semantic Analysis (LSA) [9], Random Indexing (RI) [10] and Explicit Semantic Analysis (ESA) [6]. The different combinations of DSMs and corpora were evaluated for the computation of semantic similarity and relatedness measures.

For the semantic relatedness component (Figure 1), four parametrs such as main term, target set, language and simi-larity measure are used. The user can compare target words to main word with three similarity measures in twelve dif-ferent languages. For the example, we compared ( Wife , Child and love ) with mother , also we used the Correlation measure, Figure 1 shows the results that is returned by our English, Portuguese, German, Spanish, French, Swedish, Italian, Dutch, Chinese, Russian, Arabic and Persian http://vmdgsit04.deri.ie:8008 http://www.natcorp.ox.ac.uk/ 2 billion word corpus constructed from the Web limiting the crawl to the .uk domain and using medium-frequency words from the BNC http://en.wikipedia.org/wiki/Wikipedia:Database download
A mean-adjusted version of Cosine as defined in [8] webservice. The semantic relatedness measure is a real num-ber within the [0,1] interval, representing the degree of se-mantic proximity between two terms. Semantic relatedness can be used for semantic matching in the context of the de-velopment of semantic systems such as question answering, text entailment, event matching and semantic search[4] and also for entity/word sense disambiguation tasks.

The correlation component (Figure 2) calculates the Spear-man X  X  rank correlation for the three similarity datasets, twelve different languages and three similarity measures (Cosine, Euclidean distance, Correlation) 8 .

All three datasets WS353, RG and MC were translated and localised by native speakers for each of the target 11 languages. More importantly the localised datsets for each language underwent a linguistic quality assurance by a well know localisation company. Hence, we are confident that our localised datasets per language are of high translated quality.
See [8] page 3 for definitions of these similarity measures.
This publication has emanated from research conducted with the financial support of Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289.

We would like in particular to thank Alexandros Poulis and Juha Vilhunen from the Lionbridge Natural Language Solutions ensuring the production word of high quality trans-lations for our similarity datasets. [1] M. Baroni, S. Bernardini, A. Ferraresi, and [2] J. A. Bullinaria and J. P. Levy. Extracting semantic [3] J. A. Bullinaria and J. P. Levy. Extracting semantic [4] D. Carvalho, C. Call X , A. Freitas, and E. Curry. [5] O. Ferret. Testing semantic similarity measures for [6] E. Gabrilovich and S. Markovitch. Computing [7] D. Jurgens and K. Stevens. The s-space package: an [8] D. Kiela and S. Clark. A systematic study of semantic [9] T. K. Landauer, P. W. Foltz, and D. Laham. An [10] M. Sahlgren. Vector-based semantic analysis:
