 Artak Amirbekyan  X  Vladimir Estivill-Castro Abstract Finding the nearest k objects to a query object is a fundamental operation for many data mining algorithms. With the recent interest in privacy, it is not surprising that there is strong interest in k -NN queries to enable clustering, classification and outlier-detection tasks. However, previous approaches to privacy-preserving k -NN have been costly and can only be realistically applied to small data sets. In this paper, we provide efficient solutions for k -NN queries for vertically partitioned data. We provide the first solution for the L  X  (or Chessboard) metric as well as detailed privacy-preserving computation of all other Min-kowski metrics. We enable privacy-preserving L  X  by providing a practical approach to the Yao X  X  millionaires problem with more than two parties. This is based on a pragmatic and implementable solution to Yao X  X  millionaires problem with shares. We also provide privacy-preserving algorithms for combinations of local metrics into a global metric that handles the large dimensionality and diversity of attributes common in vertically partitioned data. To manage very large data sets, we provide a privacy-preserving SASH (a very successful data structure for associative queries in high dimensions). Besides providing a theoretical analysis, we illustrate the efficiency of our approach with an empirical evaluation. Keywords Privacy-preserving data mining  X  Secure multi-party computation  X  Nearest-neighbour classification  X  Yao X  X  millionaires problem 1 Introduction The diffusion of global threats, like terrorism, requires collaboration and partnership between many governments and/or corporations. Data mining has been identified as one of the most useful tools for the fight on terror and crime [ 41 ]. However, the information needed resides with many different data holders, and such collaboration may be required among parties that mutually do not trust each other, or between parties that have conflicts of interest. But all parties are aware of the benefits brought by such collaboration. For this kind of collaboration, data privacy becomes extremely important. In the privacy-preserving model, all parties of the collaboration promise to provide their private data to the collaboration, but all want to minimize what the others or any third party may learn about their private data. Collection of data by several agencies results in large databases, those demand efficient methods for data retrieval. For most data mining algorithms, the data is encoded as vectors in high dimensional space. 1 For these algorithms, a measurement of similarity (or dissimilarity) is necessary and often fundamental for their operation. Similarity queries on multi-dimensional data are usu-ally implemented by finding the closest feature vector(s) to the feature vector of the query data. More importantly, in large databases, the high dimensional space can be subject to the curse of dimensionality, and in such settings, content-based retrieval under the vector model must typically be implemented as k -nearest-neighbour ( k -NN) queries, whose result consists of the k items whose features most closely resemble those of the query vector according to the similarity measure. This type of query is known as a nearest neighbor (NN) query [ 46 ], it has been extensively studied in the past [ 5 , 10 , 15 ] and constitutes the basis of one of the top 10 algorithms in data mining [ 61 ]. A closely related query is the -range query where all feature vectors that are within the -neighborhood of the query point q are retrieved.
Similarity search is widely used as a common form of query in modern database appli-cations such as multimedia information systems [ 50 ], geographical information systems (GIS) [ 14 ], time-series databases [ 24 ], medical imaging [ 38 ], and bioinformatics [ 34 ]. The similarity between two objects is defined with a distance function, e.g., Euclidean distance, between the corresponding feature vectors. For example, in image databases, the query can ask for the most similar images to a given image [ 4 ]. 3D shape histograms are used in molec-ular biology to find similar 3D proteins [ 3 ]. Consider a database consisting of DNA sequence of people with cancer. Users can search this database to see if their DNA sequence is simi-lar to the ones in the database. Here privacy-preserving similarity search is very important. While range queries enable distance-based clustering (as in DBSCAN with R -Trees) and out-lier detection [ 54 ], k -NN queries also enable Local Outlier Detection [ 12 ], Shared Nearest Neighbour Clustering [ 47 ]and k -NN Classification [ 2 , 35 , 47 ].

This wide variety of data mining task, for which k -NN or range queries are a fundamental operation, has recently prompted approaches to privacy-preserving k -NN [ 2 , 35 , 47 , 54 , 55 ]. However, these approaches do have some serious shortcomings. For example, the suite of privacy-preserving algorithms [ 55 ] to create a privacy-preserving version of Fagin X  X  A0 algo-rithm [ 23 ] proved costly even though the authors argued that disclosure of some additional information (the union of all items in a set required to get k intersecting items) was necessary for reasonable efficiency. Other common limitations have been the need to compute all pairs of distances [ 54 ], to have the query-point public [ 35 ], or to deal with horizontally partitioned data [ 2 , 47 ].
 In this paper we use n for the number of data vectors when this is a small set. In such a case, the additional cost of privacy should be clearly an absolute priority. In a sense, these are relatively few values and releasing information is a large relative loss. We will use N when we are referring to a large dataset, as it is usually the case in data mining applications, and here we accept that the cost of information leak (relative to the dataset size) and the necessity for efficiency justifies a small leakage of information as long as that leakage can be identified as inconsequential and innocuous. Previous work has not produced totally secure algorithms [ 47 , 55 ].

When the dataset is large, data structures that efficiently support k -NN search are essen-tial to many applications. This family includes classic search structures like k -d-trees [ 8 ]and R -Trees [ 29 ], and newer structures and techniques such as SR-trees [ 37 ], X-trees [ 9 ]and iDistance [ 64 ]. The central role of these indices in data mining algorithms is illustrated by therolethat R -Trees play in the efficiency of the popular data mining clustering algorithm DBSCAN [ 1 , 20 ].

This paper shows how to compute distances in a privacy-preserving context. This allows privacy-preserving k -NN queries. Finally, we apply protocols for computing distances to a very successful data structure for associative queries in high dimensions, the SASH .We emphasize the SASH [ 31 ] as this data structure makes minimal assumptions about the nature of the metric for associative queries. The SASH is neither a spatial index nor a metric index: it makes no assumptions on the nature of the database elements other than the existence of a pairwise distance measure, nor does it require the measure to satisfy the triangle inequality. Houle [ 31 ] has shown that for approximate k -NN ( k -ANN) queries on very large sets, the SASH consistently returns a high proportion of the true k -NNs at speeds of roughly two orders of magnitude faster than sequential search. Houle X  X  research also demonstrates that the SASH offers better performance, and significantly better control over the time-accuracy trade-off, than previous approximation methods based on metric indices. The SASH has already been successfully applied to clustering and navigation of very large, very high dimensional text data sets [ 30 ], and spatial data mining of web documents [ 42 ]. Two papers [ 31 , 32 ]present the details of the SASH structure and its query methods. The SASH becomes of particular interest for its potential for data mining because the involvement of many parties results in data of high dimensions that is vertically partitioned. However, the current form of the SASH would be inappropriate for privacy preservation. Therefore, this paper develops a SASH and its algorithms so that parties are confident that privacy of their data is pragmatically protected. Naturally, the result of k -NN queries by one party on the union of the data reveals information on the other party X  X  private data since significant information can be inferred from the result of the query alone. Privacy is threatened further if queries are repeated or malicious queries are issued. This paper aims at offering a pragmatic (practical and efficient) solution while specifying the departure from some theoretical ideal solutions. 2 Private collaborations We study collaboration between several parties that wish to compute a function of their col-lective databases. In fact, they are to conduct data mining tasks on the joint data set that is the union of all individual data sets. Each wants the others to find as little as possible of their own private data. To focus the discussion on privacy-preserving collaboration, we will regularly use two parties Alice and Bob. We focus on vertically partitioned data [ 56 ](Fig. 1 ).
Every record in the database is an attribute-value vector. Alice owns one part of that vector and Bob owns the other part. In the case of more than two parties, then every party will own some part (a number of attributes) from the attribute-value vector. Note that, for vertically partitioned data, the more parties are involved, the more attributes are involved and the higher the dimensions of the attribute-vectors. For simplicity, we can identify each attribute (column or field) with one party (so the dimension m of the records is also used as the number of parties). Obviously, there would be fewer parties than dimensions (for example, in Fig. 1 the two parties hold 9D records). However, we consider Alice as four virtual parties (one for each of the columns) and Bob as five virtual parties each controlling one of Bob X  X  columns. This simplifies the notation in the algorithms (and communication between two virtual parties of the same party does not need to occur).

A direct use of data mining algorithms on the union of the data requires one party to receive data (every record) from all other parties, or all parties to send their data to a trusted central place. The recipient of the data would conduct the computation in the resulting union. This naive solution is unacceptable from the privacy perspective. However, the cost of this distrib-uted non-private solution ( DNPS ) has been used in the past as a benchmark for evaluating the overhead required for privacy.

Our approach will make reference to the theory developed under the name of  X  X ecure multi-party computation X  (SMC) [ 27 ]. Yao X  X  millionaires problem [ 63 ] provides the origin for SMC. In this problem, Alice holds a number a while Bob holds b . They want to identify who holds the larger value (they compute if a &gt; b ) without either learning anything else about the other X  X  value.

Secure multi-party computation under the semi-honest model [ 27 ] has regularly been used for privacy-preserving data mining [ 17 , 19 , 26 , 53 ]. Here we use as the fundamental point of reference the semi-honest model as well, which means all parties will follow the protocol since all are interested in the results. However, all parties can use all the information collected during the protocol to attempt to discover information on the private data or some private val-ues from another party. We accept that any information that can be inferred from the privately computed output and the inputs of one party, is acceptable for that party to discover. 2
The current k -NN privacy-preserving algorithms at some stage make use of the theoreti-cal generic  X  X ecret shares X  result for computation with data split across several parties. The SMC literature has a general solution for all polynomially bound computations [ 28 ]. This generic  X  X ecret shares X  solution computes f ( x , y ) for a polynomial-time f using private input x from Alice and private input y from Bob. Alice learns nothing about y except what can be computed from f ( x , y ) and similarly Bob learns nothing about x except what can be inferred from f ( x , y ) and y . Why, if such a solution exists, is there so much interest in protocols for SMC? The first consideration is that the general solution requires f to be explicitly represented as a Boolean circuit of polynomial size. Second, even if represented as a circuit of polynomial size in its input, the input must be very small for the construction of the circuit to be practical. This means, the sub-task that uses this result must be on small inputs, a constraint difficult to meet in data mining applications. Third, the constants involved are not small. The circuit must be described for each input size n ; once the circuit is described the parties enter into a protocol holding shares of the inputs to gates and shares of the outputs of gates. Fourth, the literature shows that much more efficient solutions exist for special cases of f . In other cases, researchers are prepared to describe pragmatic solutions that reveal some information that can be considered innocuous. Also, the usage of a circuit-based protocol as a subroutine in another protocol enables construction of more complex and secure protocols, but transmits the impracticality of the generic  X  X ecret shares X  result further. 2.1 Yao X  X  two millionaires problem X  X olution with shares One advantage of the  X  X ecret shares X  theoretical result is that one can decompose the result f ( x , y ) into a share s A for Alice and a share s B for Bob, so that s A + s B = f ( x , y ) ,but neither party can find f ( x , y ) from their share. This allows us to use a protocol for one task (like Yao-comparison of two values) in a larger protocol (e.g. sorting).

We present here a solution to Yao X  X  millionaires problem, that provide the output in secret shares. Recall that here Alice holds a and Bob holds b , but then, after the protocol, they do not share knowledge of the output ( a &gt; b ?), but the output for Alice is r a and for Bob r b , where There are several privacy-preserving data-mining algorithms [ 35 , 47 , 54 ] that invoke a subrou-tine for Yao-comparison with shares, and all of them rely on the (circuit evaluation) generic  X  X hares X  theoretical solution by Goldreich [ 27 ]. 3 Hence, they seem laborious for implemen-tation. We present here a practical and inexpensive solution that we apply in our algorithms. This solution can also alleviate the implementation issues for the above-mentioned protocols. It will be close to an ideal solution in the semi-honest model. It uses a third untrusted party 4 (also commonly used in the privacy-preserving literature [ 19 ]). It is also common that when there are more than two parties, they take turns performing the role of the third party for two others [ 53 ]. Even for fundamental protocols, like oblivious transfer, there has been an inter-est in using a third party [ 45 ]. In some protocols, like unconditionally secure commitment schemes, the third party is absolutely necessary for perfect concealment [ 11 ].

Clearly, checking whether a &gt; b is the same as checking whether a + (  X  b )&gt; 0. In our protocol, we will use an untrusted non-colluding third party (also called semi-trusted [ 13 ]). Such a party only assists in performing the calculations. By definition, this party does not collude with Bob, neither with Alice (and Alice and Bob would not collude since they are two millionaires that do not trust each other). Therefore, in this case, the semi-honest model with three or more parties is equivalent to semi-honest model with two parties.
 Protocol 1 sign-based protocol with secret shares for Yao X  X  millionaires problem. 1. The third party generates a random number R a and sends R a to Alice. 2. Alice generates a random number R ,where R  X  X { 0 } and sends ( R , a  X  R + R a ) to 3. Bob adds  X  b  X  R , and sends ( a  X  b ) R + R a to the third party. 4. The third party subtracts R a and checks whether ( a  X  b ) R &gt; 0. 6. If sign ( R ) = 1 (i.e. R &gt; 0) Alice and Bob use as their shares the random numbers 2.1.1 Illustration of Yao X  X  two millionaires problem X  X olution with shares Assume that Alice holds a := 25 and Bob holds b := 37. They want to know whether a &gt; b with shares. 1. The third party generates a random number R a := 45 and sends R a to Alice. 2. Alice generates random number R :=  X  14, where R  X  X { 0 } and sends ( R , a  X  R + R a ) = 3. Bob adds  X  b  X  R = X  37  X  (  X  14 ) , and sends R ( a  X  b ) + R a = X  14 ( 25  X  37 ) + 45 = 213 4. The third party subtracts R a and checks whether R ( a  X  b )&gt; 0  X  213  X  45 &gt; 0. 6. Because sign ( R ) = X  1, each picks as their share the random number received as the 2.1.2 The security of the sign-based protocol with shares Let us see what every party obtains from this protocol. 3. The third party obtains R a , ( r 1 a ) , ( r 0 a ) , ( r 1 b ) , ( r 0 b ) ,and ( a  X  b ) R . From the discussion above, the following result follows.
 Theorem 1 If a = b, the sign-based protocol with shares is secure within the semi-honest model of computation.
 We emphasize that in the sign-based protocol neither Alice nor Bob learn anything. Alice does not receive any messages nor values from Bob and what she receives from the third party is random numbers. Similarly, Bob receives ( R ,( a ) R + R a ) ; this is the only message from Alice and since R a is a random number he cannot infer a . Neither can he infer the choice by the third party.

Some researchers use the tools by Goldreich [ 27 ] to establish the security of the proto-col. In particular, a proof by simulation is sometimes performed there [ 54 ]. Here a proof of Theorem 1 by simulation is obvious.
 Proof Bob just needs to get a random value for ( a ) R + R a and in polynomial time can add (  X  b ) R . The output is given by the third party. Alice X  X  simulation is even more trivial since she receives nothing from Bob, and the only output is also from the third party. Let a = b , the third party only receives ( a  X  b ) R where R is a random number, thus it can also be simulated.

We have chosen to define a Yao-comparison also when a = b . When values are equal, the predicate a &gt; b ? receives the value true or false by considering the party that supplies the second argument as the holder of a larger value. This implements implicitly and effectively a comparison where a later indexed party is considered to have a larger value among parties with equal values (which is useful for computing the Chessboard distance later in Protocol 5 ). 2.1.3 The implementation of the sign-based solution with shares Theorem 1 proves the ideal protocol is secure, but as presented it uses real numbers and cannot be considered efficient. Implementation requires some adaptation, as for example, the value R  X  X { 0 } generated by Alice cannot be any non-zero real. However, all implementations of a solution to Yao X  X  millionaires problem assume that the values of a for Alice and b for Bob are in a large but bounded interval; that is a , b  X  X  0 , M ] where M is very large (and known to both Alice and Bob). Alice and Bob will map their values from whatever total order by a strictly monotonic function to [ 0 , M ] . Even those solutions that do not provide the answer with shares require this and typically assume further that a and b are integers in a very large field. Therefore, our implementation of the sign-based solution also assumes that a and b are integers with a , b  X  X  0 , M ] ,and M is known to the implementer.

The implementation will not reveal any information about Bob X  X  value to Alice, since nothing that Alice receives depends on Bob X  X  b except the output of the protocol. The imple-mentation faces two challenges, namely limiting what Bob may learn about Alice X  X  value and limiting what the third party learns on Alice X  X  value, Bob X  X  value or both. We address first the second case.

Note that the third party does not know the value a  X  b ,since sign ( R )  X  X  X  1 , 1 } .Asmall concern is that in the case a = b , the third party learns that a = b , although it does not learn anything else (the values a and b remain inaccessible to the third party). Theorem 1 does not cover this case.
Risk that the third party learns | a  X  b | . The trusted party does learn ( a  X  b ) R and because | R | is bounded (in fact, the most conservative assumption is that the distribution of | R | will be known to the third party), this party learns approximations to | a  X  b | . That is, the third party will not learn whom between Alice and Bob holds the larger value, but will gain an idea on the gap that exists between the two. Thus, the implementation of our protocol no longer satisfies Theorem 1 for the third party.

Risk that the third party learns something about a (and thus something about b ). If we consider the values of | a  X  b | given that a , b  X  X  0 , M ] ,wecanseethat | a  X  b | X  X  0 , M ] ; however, the combinations that lead to a value are not equally many. For example, if | a  X  b |= M , then we know that ( a = 0  X  b = M )  X  ( a = M  X  b = 0 ) .Thatis,thereare only two possibilities. If | a  X  b |= M  X  1, then we know that there are only 4 possibilities (this are a = 0  X  b = M  X  1, a = 1  X  b = M , a = M  X  1  X  b = 0, and a = M  X  b = 1).
However, for other values of | a  X  b | , we do not gain additional information. For example | a  X  b |= M / 2 can be produced with any value of a  X  X  0 , M ] . Therefore, when the third party obtains the value R ( a  X  b ) , if the particular value of R has a few possibilities (for example, it is the maximum possible value) and | a  X  b | is one of those extreme values with few possibilities, then the third party may reduce the universe of possibilities for | a | (and therefore for | b | ).
 We evaluated the possibility of the third party bounding the range for | a  X  b | and found the third party would still have large amounts of noise. We conducted experiments where we kept | a  X  b | constant. For each value of | a  X  b | at least 250 executions of the sign-based protocol were executed. In each, the third party used the mechanism above to estimate | a  X  b | . The range of values for which the estimate of | a  X  b | was explored was 1 to 4,000. Figure 2 shows that with 95% confidence the expected relative error is around 50%, and the maximum relative error is over 99%. The plot of relative error zooms into the range | a  X  b | X  X  1 , 1 , 000 ] to show that even with small values, the relative error remains essentially constant. We regard this leak of information in the sign-based protocol as innocuous given the estimates of | a  X  b | have at least 50% expected relative error.
Secondly, the risk of a leak because of extreme values is very low already. If M is at least 255 and R  X  X  256 , 1 , 024 ] , then the value | a  X  b |= M would happen with probability 2 / 255 2 and R would be largest with probability 1 / 768, thus the chance of the sign-based protocol implementation running into these values is less than 2 in 10 million.

Nevertheless, we provide a further enhancement that will result in an efficient implemen-tation, but it will not be the of the sign-based protocol as presented earlier. Theorem 1 will not hold for the implementation, but we will introduce other formal aspects regarding its security. The implementation will be parameterized so that it is possible to arbitrarily increase the uncertainty in the third party. To hide information on | a  X  b | from the third party, Alice and Bob will perform an additional number of tests. Here Alice and Bob use dummy values a and b , some of which have a = b . Only Alice and Bob know the index of the test that actually corresponds to the comparison of their private values.
 Protocol 2 Iteration of Comparison-Tests 1. Alice and Bob (without the third party X  X  involvement), agree on a integer parameter r 3. Alice and Bob agree on random values c 1 ,..., c e that are in the range of a and b . 4. Alice and Bob run the sign-based protocol r times, providing dummy values except In our experiments with real databases we found that equal distance values are extremely rare in some databases and common in others. Thus, handling this issue properly is essential, but we will not emphasize it much further (implementations for settings were a and b are of a small enumerated type, for example Boolean values, will use more rounds of the Iteration of Comparison-Tests with more dummy tests).

While the Iteration of Comparison-Tests is formally not compliant with the semi-honest model because the third party knows that one of these tests gives some idea of the range of | a  X  b | , the certainty on any particular value decreases monotonically with the number of iterations. 5 An alternative model for assessing the privacy of protocols in privacy-preserving data mining is the weak model. The weak model was used for many algorithms involv-ing matrix operations and in particular, linear regression [ 18 , 56 ]. In this model, security is regarded with respect to certainty. Therefore, one party is considered to not have breached the security as long as there are an infinite number of possibilities for the values of the other parties. This model has been criticized, and in many cases rejected, because it can consider secure a protocol where one party learns significant information about another party X  X  data. For example, Alice could learn that Bob X  X  b value is in a small range. While there are an infinite number of rationals (or reals) in this interval, this could provide enough precision for it to be considered a security leak. Learning or discovering an interval is discovering a distribution of the value. If the distribution has very small variance, although a large range, the security leak could be serious.

While some protocols for vector and matrix operations have been dismissed as only secure on the weak-model and not in the semi-honest model, we believe one cannot discard the merit of these protocols; particularly if they are regarded as not secure in the semi-honest model by a technicality. Case in point is the protocol for scalar product that provides the output in shares [ 19 ]. This protocol is regarded as secure in the weak-model sense because it requires a commodity server. We argue here that the commodity server does not contradict the spirit of the semi-honest model. We can consider the commodity server as a third party in the protocol, with empty input and empty output. Then, the three parties would be interested in computing f ( x , y , X ) = s A + s B , where the input  X  of the third party (the commodity server) is empty and will not affect the output value s A + s B discovered by Alice and Bob with respected private shares. As we mentioned before, many times a protocol in the semi-honest model among more than two parties requires a sub-protocol in which two parties compute a value with the assistance of a third. We hope that the above discussion makes clear that our iterated sign-based protocol is not only secure on the weak model but is arbitrarily close to being secure in the semi-honest model.

We make this last statement formal with the notions of perfect secrecy 6 and of statistical secrecy . 7 We now present the specific definitions of perfect security and statistical security we will use. 8 Consider an encryption scheme ES ( K , E k , D k ) ,where K is a random variable (representing the distribution of the keys), E k is the family of encryption functions (which can possibly be randomized) and D k is the decoding function. That is, D k ( E k ( p )) = p for all possible plain texts p .
 Definition 2.1 The encryption scheme has perfect security if for any two plain-text instances p 1 and p 2 and a cipher-text c ,wehave where probability is taken over the distribution of k  X  K .

For example, consider how well are Alice and Bob hiding the secret  X  i th round is the actual round to compare their values X . It is not hard to see that for any set T  X  X  1 , r ] ,we have Pr [ actual round  X  T ]= T / r . This proves the following result. 9 Theorem 2 Protocol 2 Iteration of Comparison-Tests , hides which round is the round involving the actual values a and b form Alice and Bob with perfect secrecy.
 However, it is intuitively clear that when a = b , there would be more rounds where the third party observes a Yao-comparison with a = b than if a = b . Thus, the protocol is not perfectly secure in this regard, but we will show it is statistically secure and parameterized to achieve any level of statistical security. First, we must recall the definition of statistical distance. Definition 2.2 Let X and Y be two distributions over { 0 , 1 } t . The statistical distance between X and Y, denoted ( X , Y ) is Moreover, if ( X , Y )  X  , then we say the distributions are -equivalent and write X  X  Y. We are now in a position to define statistical secrecy. An encryption scheme is -secure if can now establish the following result.
 Theorem 3 Protocol 2 Iteration of Comparison-Tests , is a parameterized protocol by the number of rounds r that hides the secret whether a = b with statistical security at any required security level.
 Proof The definition of statistically secure requires that whatever event T in the probability space, the probability of observing any ciphertext landing in T (that is, E k ( p 1 ) = c  X  T )is within of the probability of observing any other ciphertext E k ( p 2 ) = c  X  T . But the num-ber e of rounds in the protocol where equal inputs are provided by the parts is distributed as the Binomial distribution with r  X  1 trials and probability 1 / 2when a = b , and shifted by one when a = b . But the Binomial distribution converges to the Normal distribution and for r sufficiently large, the number of rounds where the third party observes a = b will have probability close to whether it is the case that the actual values are equal or whether they are not.

Even more levels of statistical security for | a  X  b | can be obtained by Alice and Bob engaging in a previous protocol that chooses randomly a constant number of monotonic 10 functions from [ 0 , M ] to [ 0 , M ] (without knowledge from the third party). In fact, they can also chose anti-monotonic 11 functions. In this way, they can change the magnitude of | a  X  b | to | f ( a )  X  f ( b ) | with a slight trade-off. Namely, because [0, M ]has M +1 values, there may be cases where f ( a ) = f ( b ) but a = b . Nevertheless, the family of monotonic functions on [ 0 , M ] is rich enough to select a subfamily to suit the balance between strict comparison and a randomized comparison that, with small probability, returns that a = b rather than the true comparison of a and b .

Lets now look at the risk that Bob learns something about a . Since Bob will learn R and aR + R a ,thevalue R a produced by the commodity server must mask aR (otherwise Bob may learn some bits about a ). Since aR can have as many bits as log 2 M + log 2 R , we typically let Alice chose R so that | R | &gt; M and the trusted party chooses | R a | &gt; M 2 . For example, Alice can chose R uniformly in [ X  2 M , M )  X  ( M , 2 M ] . 12
However, Bob learns the value of R and the most conservative assumption is that Bob knows the distribution (typically uniform distribution) of R a . Therefore, when Bob receives a  X  R + R a and although R may be equally likely in its range [ R l , R h ] and R a is equally R a  X  X  R a , l = 100 , R a , h = 1 , 000 ] and suppose R = 21 &gt; M . The possible values that Alice may send to Bob have a distribution as per Fig. 3 a.

For example, for the values a  X  R + R a in [ 101 , 120 ] X  X  1 , 190 , 1 , 210 ] , there is only one value of a . That is, if Bob receives 1,192, he would be able to find that Alice X  X  value is a = 1. Similarly, for the values a  X  R + R a in [ 121 , 141 ] X  X  1 , 169 , 1 , 189 ] , there are only two possible values for a (if Bob gets 1,189, he learns a = 10 or a = 9). However, in the range [ 310 , 1 , 000 ] , Bob remains uncertain among the 11 possible values for a . Clearly, given R , analyzing the frequencies of the value a  X  R + R a does not support one value of a more than it supports another one that can be expressed this way. For illustration, consider again the setting of the distribution in Fig. 3 a. Knowing that 1,153 corresponds to three values of a does not favour any of these three values (although fewer than the original 11 possibilities for a , Bob will still be equally uncertain about a = 10, a = 9or a = 8). Thus, direct implementation of our protocol no longer satisfies Theorem 1 for Bob.
However, there are far more values that leave Bob as uncertain (in the example above 691 values of the from a  X  R + R a maintain the 11 possible values for a ). More realistic values are In this case, the number of values of the form a  X  R + R a that reduce the M + 1isnomore than 2 MR . This represents less than 4% of the values Bob can see. Thus, most of the time Alice does not have to worry about what Bob will learn. However, if this is an issue, (for example, it is harder for Alice to hide the values a = 0or a = M than a = M / 2 ), Alice can actually request several values R a from the commodity server and chose one that lands in [ R a , l + RM , R a , h  X  RM ] . Then, it lets the third party know which of the several values it selected without disclosing this to Bob.
 Moreover, because Alice and the third party can set parameters of the protocol before Bob, we can produce a parameterized version of the protocol that can be made statistically secure for any desired level &gt; 0.
 Theorem 4 For every &gt; 0 , there is a parameter s so that we can tune the implementation of the sign-based protocol , so that the protocol is statistically secure at level . Proof Recall that [ 0 , M ] is the range of values for Alcie X  X  a and Bob X  X  b with M a constant. Given &gt; 0 chose s such that 2 M /( 2 s + 1 )&lt; . Recall that Bob receives ( aR + R a ). We can consider this as the encryption scheme E ( a ) = a + R a / R . Since an implemen-sider the random variable K = R a / R has a range V of integer values given by V = { X  s ,  X  ( s  X  1 ),...,  X  1 , 0 , 1 ,..., s  X  1 , s } . Then, the third party and Alice agree so that That is, the probabilities are uniform in V . For simplicity of notation, for any value c ,let V + c denote the set { X  s + c ,  X  ( s  X  1 ) + c ,...,  X  1 + c , c , 1 + c ,..., s  X  1 + c , s + c } of values in V shifted by c . Then, for any two integer values a 0 , a 1  X  X  0 , M ] we have Note that the probability for any event T  X  , is the same as analyzing it for T = T  X  V . Moreover, We are interested in an event T that maximizes | Pr [ E ( a 0 )  X  T ] X  Pr [ E ( a 1 )  X  T ] .Butif t  X  T is such that t  X  V + a 0  X  V + a 1 ,then Pr [ E ( a 0 ) = t ]= Pr [ E ( a 1 ) = t ] .Atthe t ]| = 1 /( 2 s + 1 ) .
 Therefore, the event T that maximizes | Pr [ E ( a 0 )  X  T ] X  Pr [ E ( a 1 )  X  T ]| is Moreover the maximum value is bounded by T 0 /( 2 s + 1 )  X  2 M /( 2 s + 1 )&lt; as required. Protocol 3 Implementable sign-based protocol with secret shares 1. Alice an the third party agree on distributions of R and R a so that R / R a has a range V 2. They proceed with the sign-based protocol .

We have implemented the sign-based solution presented above in combination with Pro-tocol 2 . Note that for nominal or categorical types that are converted to ordinal types for comparisons (like Boolean values) the value of M is small and the choice of distributions for R and R a is simple. The implementation trades-off uncertainty for the size of ranges in the implementation. This implementation minimizes exchanged messages and operations. Other implementations of SMC are recognized as expensive, originally directly implement-ing circuit evaluation [ 40 ], but recent efforts have made them feasible [ 43 ]. To the best of our knowledge, ours is the first implementation for Yao X  X  millionaires problem with shares (we have a C++ implementation over sockets). Second, it is far more efficient that other solutions to Yao X  X  millionaires problem, even without shares. Cachin X  X  solution [ 13 ] is linear on the number 13 of bits of a + b ; however, it also requires a trusted party and very heavy cryptographic machinery. A solution that has been demonstrated to be efficient enough for ETHERNET networks [ 33 ] requires quadratic time and quadratic number of messages on log 2 ( a + b ) and also as many oblivious transfers as log 2 ( a + b ) . Other practical protocols [ 6 ] also require O ( log 2 ( a + b )) rounds of oblivious transfer. Oblivious transfer implemen-tations usually require at least two messages with a key each. The sign-based protocol requires three messages in total with size log 2 ( a + b ) (one from the trusted party to Alice, one from Alice to Bob and one from Bob to the trusted party). In the last round, messages have constant size 2 bits. So we have linear complexity on the size of the message (with a constant value 2) and constant number of messages. The complexity analysis is so over-whelming clear in favor of the sign-based protocol that we feel direct comparison to any other implementation of a solution to Yao X  X  millionaires unnecessary. The sign-based protocol requires little machinery and thus it is also much easier to implement than any of the others. The fact that we may chose | R a | &gt; M 2 or even M 3 only adds liner complexity to the size of the very few messages our protocol requires. Note also that our protocol is connection-less, facilitating significantly the complexity of the networking machinery and also reducing other security risks. Note, however, that this also illustrates the power of the third party. Some of the other protocol mentioned here trade-off their independence from a third party by additional machinery. 3 Privacy-preserving metrics One of the contributions of this paper is to show how to carry out the SMC computation of all Minkowski metrics (among them, the Euclidean metric) and also of the L  X  distance. Also, we expect that in applications of vertically partitioned data, the fields (or columns) may be very diverse, including many units, and types, some being categorical and others ordinal or numerical. It is well known that in Instance-based Learning [ 60 ]or k -NN classification, typically the metric is a weighted convex combination of metrics for each attribute. The discussion of algorithms for Minkowski and L  X  will enable algorithms for combinations of local metrics into a global metric. Equipped with this, we can show that data structures for associative queries are then readily suitable for privacy-preserving algorithms. The protocols in the previous section are involved in the computation of L  X  metrics but not Minkowski distances. 3.1 Minkowski metrics Obviously, if all parties know the r th Minkowski distance M ( p , q ) between two points p and q in the database, they will also know the value [ M ( p , q ) ] r by each raising the Minkowski and find the desired distance value. Since the i th party knows a range of the attributes of the vectors p and q , it is not hard to see that
Letting v i be the r th Minkowski distance of those attributes known to the i -party, then [ distributed among m parties (each contributes the knowledge of the r th Minkowski distance raised to the power r in the projection that they own). Protocols that compute distributed sums have received many names (for example, secure sum [ 56 ]), so we reproduce here the necessary variant for clarity.
 Protocol 4 the Minkowski distance protocol :Addthe m values among m  X  3 parties. 1. The first party (Alice) generates a random number R andpassesittothe m th party (this 2. The m th party adds its value v r m to the random number R and passes the result to the 3. For i = m  X  1downto2,the ( i  X  1 ) th party adds v r i to the value received and passes
Note that if we halt at step 3 with Bob (the second party), then we have a protocol for the Minkowski distance with shared values between Bob and Alice. This means In some applications (in particular, k -NN queries) the calculation of the metric is an inter-mediate step. Although the disclosure of distance values may be considered the release of innocuous information in some cases, it is more acceptable to use shares as this adheres to the ideal principle of SMC where parties learn only what is implied by the final output. In fact, we can use encryption modulo a field F so that the shares s a of Alice and s b of Bob are such that s a + s b =[ M ( p , q ) ] r mod F .Ina k -NN query, only the ids of the k records is the ideal answer and it is preferable than all the parties learning some exact values of the metrics to the query point.

The Minkowski distance protocol with shares is trivial in the case m = 2 parties, since in this case, each party uses its projected metric value as its share and they exchange no mes-sages at all. In the core operations for the SASH (or similar data structures) rather than being ? X . For additional privacy, then, it is better if each party contributes the difference of its projections. That is, let v r i be the Minkowski distance (raised to the r th degree) between p and q in the projection owned by the i th party, and let u r i be the Minkowski distance of r th degree between p and r in the projection owned by the i -party. Then, to answer the question we compute the sum of the m values (v r i  X  u r i ) owned distributively by the m parties, and each party then can check where the sum stands relative to zero. SMC of the Euclidean distance is achieved by the above Minkowski algorithm in the case r = 2. Note also that if we consider s known to Alice and ( s b  X  s b ) known to Bob.
 Theorem 5 If three or more parties use the Minkowski distance protocol , no party learns other parties X  private data represented as an attribute in the feature vector. If the pro-tocol is the shares distance version, even with two parties, no party learns any information. Proof The protocol calculates the distance between p = ( p 1 ,..., p m ) and q = ( q 1 ,..., q ). During the calculation each party P l ( l = 2 ,..., m ) obtains where R is a random number produced by the 1 st party. Thus, because R is random, for party P R and taking r th root from the sum. Here, because several terms are involved in the sum, the 1 st party cannot learn any attribute p i or q i ,where i = 2 ,..., m .
 The case for shares follows by the discussion above.
 Note that in the formulation of the theorem we have not mentioned the semi-honest model. However, this protocol is considered secure among the data mining community [ 56 ] because each party can be simulated individually in polynomial time from its inputs and outputs and a random oracle assuming no proper subset of the parties colludes. 3.2 SMC chessboard or L  X  distance While Minkowski metrics combine the discrepancy in each attribute with a sum there is also the alternative of selecting the maximum difference as the overall metric. This leads to the L  X  metric (some researchers prefer the name  X  X hessboard distance X  which is defined
Note that if x and y are owned by several parties on vertically partitioned data, each party reduces to which of the m parties has the largest value (thus, from now, we assume party i holds | v x i  X  v y i | and the vectors have dimension m ).

A first approach can use a version of Yao X  X  protocol (without shares) as a subroutine to deploy a finding maximum algorithm based on m  X  1 comparisons. For example, for i = 1 to m  X  1 compare the maximum found in the i th first parties with the ( i + 1 ) party. While this works well, the ( i + 1 ) th party must interact using the sign-based protocol with the holder of the maximum among the first i parties (thus, learning who holds the maximum so far and has won some comparisons). So this approach is not secure in the ideal sense of the semi-honest SMC since additional information besides the maximum among all m entries is leaked. Again, some may consider this information leak innocuous, and in that case, par-ties may use this proposed approach. However, we now present an approach that with some additional machinery is secure and practical. The additional machinery is how to compare two numbers and distribute the output into shares (Sect. 2.1 ).
 Protocol 5 Find maximum value with shares.
 The protocol starts with each party comparing its value to every other party. Note here that, the &lt; Alice vs Bob &gt; comparison is not the same as the &lt; Bob vs Alice &gt; comparison. For instance, if Alice compares with Bob and it happens to be that Alice X  X  value is smaller than Bob X  X , then they will have shares C A AB and C B AB ,where C A AB + C B AB = 0, 14 but if Bob com-pares with Alice the shares should add up to one. However, we do not need to compare again Bob X  X  number with Alice in order to have shares C A BA and C B BA ,where C A AB + C B AB = 1, since they are already provided by the third party in our sign-based protocol (see the Sect. 2.1 ). Thus, we will use it as the shares for the Bob vs Alice comparison. 1. Alice (the first party) compares her value with all others, then sums up her parts of the 2. Bob (the second party) compares his value with all others, 15 then sums up his parts of 3. The protocol continues until each party X  X  value will be compared with all others.
This provides the information shown in the Table 1 ,where C i ij belongs to P i , C j ij belongs to P j ,and Note that now, each column is owned by one party only; therefore we can treat them as the separate vectors distributed to each party. Moreover, for each party P i ,thesumofthe elements in the i th row is v were smaller than v i . The problem now reduces to finding the id of the maximum value in a sum of vectors. 16 This can be performed by SMC with the Maximum Value in the Sum of Vectors protocol [ 2 ] where no party learns anything except the id of the entry holding the maximum value. 17 If a version with shares is needed, the party P holding the maximum value M can generate a random number s P = R ,sothat s = M  X  R is made public to another party. The two parties then will hold values so that s p + s = M mod F . Theorem 6 Whenever a secure Yao algorithm with shares is used for its comparisons. Pro-tocol 5 is secure (in the semi-honest model).
 That is, in theory, Protocol 5 will fit the semi-honest model where each party can be simulated, because parties do not learn who holds the larger value in each comparison since they are all encoded in distributed shares. In practice, we would use or sign-based protocol and the mechanisms discussed earlier (Protocol 2 ). Together, these protocols ensure the information learned by a helper party about the party declared to have a larger value (in case projections of distances are equal and one is later in the ranking of parties) is extremely small. 3.2.1 Illustration of SMC Chessboard of L  X  distance calculation are owned by four parties (Alice, Bob, Charles and Daniel) each holding one attribute. Since problem reduces to which of the 4 parties has the largest value. Thus, at present Alice holds | 12  X  13 |= 1, Bob holds | X  23  X  5 |= 28, Charles holds | 5  X  (  X  7 ) |= 12 and Daniel holds | 8  X  13 |= 6.

The protocol starts with each party comparing its value to every other party. This provides the information in Table 2 ,where C i ij is the share that P i holds, C j ij is the share that P j holds, and
Assume the C i kj are as in Table 3 . If we sum up all the components 18 in each row we will obtain Since the ID of the maximum is 2, the winner is Bob, the second party. 3.3 Combinations of metrics Protocol 5 for the Chessboard distance and Protocol 4 with shares illustrated with the Minkowski metric are powerful enough to handle the fact that, in k -NN queries among par-ties sharing vertically partitioned data, it is likely the attributes may belong to very diverse domains. Each party may be applying a local metric M P i to the projection the party holds of the two records p and q . This results in the value v i = M P i ( p , q ). Thus, the global metric could be a weighted sum m i = 1  X  i v i of the local metric values v i . The problem of computing it would be solved by our Protocol 4 as we illustrated with the Minkowski distance (with both versions, with shares or disclosing the global metric value). Alternatively, the global metric could be a weighted maximum max m i = 1  X  i v i . In this case, our Protocol 5 (previously illustrated with the Chessboard metric) generalizes to compute the global metric from the local metric values on the attributes known to each corresponding party. This allows for very flexible metrics that take into account issues like different units of measure and data types on the attributes.

Note however, that, if the global metric is a sum of local metrics, one may be tempted to parallelize Protocol 4 . Then Alice would add one random vector R a = ( R a ,..., R a ) to its projection of all the metrics, and pass it to the m -party, which would add its projection and pass the vector down to the ( m  X  1 ) th party, and so on. This does not represent a real saving except using one rather than n random values generated by Alice, but it allows each party to learn the distribution of the projection of the distance values for the previous parties in the line-up. 3.4 Other metrics Other metrics common for large records (for example, between Web visitation paths [ 22 ]) are very important for high dimensional settings. The first one of these metrics is the Hamming distance H .Here H ( p , q ) is the number of entries where the vectors p and q differ. One realizes that for vertically partitioned data, secure multi-party computation of this reduces to computing again the sum of the Hamming distance in the projection by each party. If we now consider metrics, like the usage/access metrics or frequency metrics, we see that these metrics have the form p T  X  q / p 2 q 2 . That is, they are the cosine of the angle between the vectors p and q . The dot (scalar) product p T  X  q is, again, the sum of values that correspond to the dot-product in the local projection of each party, and we have already indicated how to perform Euclidean distances like p 2 .However,whilethevalue can be computed securely by our earlier protocols, we now show that it also can be computed securely and split in shares s a + s b = cos ( X ) where again, s a is known by Alice only and s is known by Bob only. This will pave the way for using this metric in our associative query algorithms later. Since dot products on vertically partitioned data are sums and can be computed with shares by our Protocol 4 we have constants A 1 , A 2 and A 3 known only by Alice and B 1 , B 2 and B 3 only known by Bob so that Using the Scalar Product [ 19 ] with shares, 19 we obtain values A 4 and B 4 so that A 4 + B 4 = (
A and A 5 = A 2 A 3 + A 4 we have the derivation. where A 5 is only known by Alice and B 5 is known by Bob.

This last division could be computed securely by applying a secure division protocol [ 17 ]; however, this does not result in a metric split on additive shares useful for k -NN queries. The next subsection handles this. 3.4.1 New division protocol with secret shares The most common SMC division protocol [ 17 ], does not provide an answer with shares, it gives an answer to one party only.
 for Alice is to obtain A and for Bob to obtain B ,where 1. Alice produces random number r 1 and Bob produces random number r 2 . 2. Using the scalar product protocol ([ 17 ]or[ 19 ] 20 ) which provides an answer to 3. Alice and Bob again perform the scalar product [ 19 , 26 ], which provides an answer Clearly, all these protocols for alternative metrics are secure in the semi-honest model as com-monly applied among the data community (i.e., when more than three parties, we assume no subset colludes). 3.5 Private k -nearest neighbours We are now in a position to describe our first algorithm for k -NN queries. Given a set of vectors together with a vector q = ( q 1 , q 2 ,..., q m ) (where m is the number of parties involved in the computation), we must find P ( q , k ) where P ( q , k ) is the ids for the k nearest neighbours to the vector q .
 Protocol 7 PP k -NN . 1. The parties calculate metrics with shares. After this, we can assume the first party Alice 2. Alice computes the matrix D A whose ij entry is | s a i  X  s a j | , while Bob computes the 3. Alice and Bob engage in Yao-comparisons with shares for each respective entry of D A 4. Let Alice compute the vector V A whose i th entry is n j = 1  X  a ij while Bob X  X  V B is such 5. Alice and Bob use the secure add vectors protocol 21 where Alice obtains  X   X  1 ( V A + 6. Alice sorts and sends the top k fake-ids to Bob. Bob broadcast  X   X  1 ( fakeIDs ) (IDs for mechanisms of the semi-honest model), it cannot be simulated just from its inputs and out-puts. Note that, if we use a metric like Minkowski (where all parties satisfy the semi-honest simulated (this follows from the  X  X omposition Theorem [ 27 ] 22 ). If Step 5 in Protocol 7 is replaced by the  X  X inding the k th largest element X  [ 55 ], then provided there are no collusions of any subset of parties, Protocol 7 is secure under the semi-honest model. For this, we use the versions with shares over a field for our protocols that compute metrics, and then it is possible to use the binary search over a field for the top k -neighbours [ 55 ]. The field binary search requires Yao-comparisons with shares (which we have now made more practical). This prevents Alice from learning the distribution of the distance values at the expense of the O ( n log | F | ) Yao-comparisons. Moreover, because the data is vertically partitioned, and the algorithm is distributed, it is impossible for one party to repeat an associative query many times without the participation (or knowledge) of the other parties. This is an extra security aspect of our context. However, if we use our protocol for the L  X  metric, and the parties participate as helpers in sign-based protocol computations, in theory, they could not be simulated, but in practice, by Protocol 2 , they would learn innocuous information. Protocol 7 is quadratic on n ; for our implementation, we preferred the following protocol. Although it reveals what we believe is innocuous information, it requires O ( n log n ) time. Protocol 8 Fast PP k -NN . 1. Same as Protocol 7 . 2. Bob (the second party) uses a random value R b only know to him and adds the vector 3. Alice and Bob use the add-vectors protocol for s a known to Alice and s b + R b 4. Alice sorts and sends the top k fake-ids to Bob. Bob broadcast  X   X  1 ( fakeIDs ) (IDs for Theorem 7 The PP k -NN protocol does not allow any party to learn other parties X  private data represented as an attribute in the feature vector.
 Proof Clearly each party except Bob and Alice participate in the protocol with an input that looks random (under the theory of SMC, all these parties can be simulated by polynomial algorithms that use as inputs guessed values from an oracle). Bob also participates in the protocol with what can be random input until Alice passes to him  X   X  1 of the ids that consti-tute the result. This is secure because in the semi-honest model, Bob can learn anything that can be inferred from the result. Alice learns the distribution of the distance values translated by a random number. No other information is disclosed. Alice cannot be simulated with a polynomial algorithm that uses guessed values from an oracle or the protocol would fail. However, from a pragmatic point of view, Alice cannot link any of the values she receives to any party (because she ignores  X  , neither any of the distance values becomes known because they have R b added to them and only Bob knows R b ). 4 The private SASH data structure For a privacy-preserving SASH , we must ensure that it is possible to implement all ADT-Dictionary operations ( construct , insert , delete , search , etc.) and that each party will hold enough information to learn the desired output while being unable to discover data from records of other parties. The SASH data structure considers a universe of n objects (not nec-essarily vectors) for which a similarity measure dist ( u ,v) exists between any two objects u and v .A SASH is a directed edge-weighted graph with the following main properties.  X  Each database object corresponds to a unique node. Little distinction will be made between  X  The nodes are organized into a hierarchy of levels, ranging from a bottom level contain- X  Edges within the SASH connect nodes from consecutive levels. Each node can have edges  X  Every node v (other that the root) has an edge directed to one parent g (v) that is desig-In our privacy-preserving SASH , all parties will know the entire graph structure of the SASH . That is, all parties will know how many nodes are at each level and what record cor-responds to each node. Each party knows what are the parents and children of a node as well as who is its guarantor or the dependant of a node. For illustration, consider for a moment two parties with database objects as vectors in 2 D and each coordinate known only by one party. Thus, Alice holds the first coordinate and Bob holds the second coordinate of each record. While both may know that, say, the fifth record in the database corresponds to the root of the SASH , neither will know the value of the other coordinate. The operations in the privacy-preserving SASH will inform all parties of the identifier of the record pointed by a node, its parents and its children, but will not reveal any values of the attribute-valued vector that describes the object. Distance values stored in edges are in fact distributed in shares (and not recomputed), this avoids the potential risk that repeated computation of a metric on the same vector may result in information leak to one party. 4.1 Constructing the SASH The edges of the SASH heuristically minimise the distances between their endpoints. During the construction, each new node is attached to a small number of its near neighbours from the level above it. At the start of construction, the SASH is empty, and we insert all objects in a random and uniform order. We denote by SASH i the graph induced by the nodes from level 1 through i ,for1  X  i  X  h . Thus, SASH i is a SASH in itself. Iteratively construct-ing SASH 1 , SASH 2 ,..., SASH h results in the construction of the entire SASH (that is, SASH h ). The following algorithm shows how to construct SASH l given SASH l  X  1 securely (for 1  X  l  X  h ). This is where we add edges between nodes of the current last two levels (Fig. 5 ).
 Algorithm privacy_Preserving_Connect_SASH_Level(l): 1. If l = 2, then every node of level 2 will have the root node as its sole parent and guaran-2. Otherwise, for the remaining steps, we have l &gt; 2. For each node v of level l , choose 3. We assign the parents of v to be the nodes of P l  X  1 (v, p ) in all replicas of the SASH . 4. Now, we create the child edges for the nodes of level l  X  1, as follows: 5. Using the edges between ids, each party determines (for each node v of level l ), whether 6. For each orphan node v at level l , a node at level l  X  1 is needed to act as its guarantor.
The previous discussion (regarding SMC metrics and PP-k -NN as building blocks, and the algorithms of the SASH construction) confirm that we can produce a privacy-preserving SASH . 4.2 Private approximate k -NN queries A simple and effective way to retrieve an approximation to the k -nearest neighbours of a query object q is to generate the candidate parents as in the SASH construction. This allows q as the result of the query. Since all nodes are reachable from the root, there is a level j with more than k elements where | P j ( q , k ) |= k .Thus,exactly k elements will be returned, (provided that the number of elements in the database is at least k ).

The authors of the SASH propose a search pattern that improves both accuracy and search time [ 31 ] (a variable number k i = max { k 1  X  h 1  X  i  X  h ). The number of objects k i selected from level i does not depend on the query object q . We can implement this privacy-preserving variant as follows.
 Algorithm Privacy_Preserving_FindNearNeighbors(q,k): 4.3 Private range queries The SASH can also be used to perform approximate range queries by iteratively computing approximate k -NN queries for some increasing sequence of value k = s 1 , s 2 , s 3 , ... .For iteration would continue until either an element outside the desired range is discovered (at which time all generated elements that lie within the range are reported as the solution to the range query), or the entire database has been visited (which occurs only when most or all of the database elements lie within the query range). If we use this doubling strategy, we can guarantee a competitive ration of two; namely, the final value k is guaranteed to be at most twice the true number of elements lying in the desired range. Because range queries are based upon privacy-preserving approximate k -NN queries, (ie, we use approximate k -NN queries for some increasing sequence of value k = s 1 , s 2 , s 3 , ... ), this immediately means that constructing a SASH and performing approximate k -NN queries in the privacy-preserving context suffices to have range queries in the privacy-preserving context.

While we have not shown Delete or other ADT-Dictionary operations here, the description on insertion/construction should suffice to perform the necessary extensions. 5 Performance evaluation Algorithms which do not ensure some level of privacy will not be considered when pri-vacy is needed. However researchers compare secure and non-secure versions to identify the overhead of privacy-preserving algorithms over a distributed non-private setting. We show that for our protocols and algorithms, the cost is essentially as for a distributed non-private setting ( DNPS ) where parties would still need to incur local calculations and communication costs between them or to a central party. Also, the implementation of our privacy-preserving algorithms is feasible.

There are solutions for a Yao-comparison without shares with complexity linear on the number of bits (Sect. 2.1 ). This is very efficient, and if one is prepared to disclose the outcome of comparisons in the Chessboard distance calculation (Sect. 3.2 ), even this metric can be computed in time linear in the number of parties and linear in the number of bits used for the metric values with a communication cost also linearly proportional to number of parties and to the number of bits. The constants involved in the O -notation are also small. Our Yao-comparison with shares trades un-feasibility of theoretical circuit evaluation for a third party who can be played by one of the other parties in settings with three or more parties. Our solution is also linear in the number of bits and the local computation time is at most a few (constant number of) operations (additions and multiplications). Using our Yao-com-parison with shares and our Protocol 5 increases the complexity of the Chessboard distance to quadratic in the number of parties. However, the number of parties would be of the order of no more than 100, and usually about 10. This is very affordable for the additional privacy.
In the Minkowski metrics, one can easily see that the main cost we have is the communica-tion cost, which is clearly affordable. In fact any other local cost (computing local projections of the metric) would also be performed in a non-private setting. The communication cost is also comparable to a non-private setting where the parties would have to communicate with each other or to a central party their local metric values. The local cost for generation of a pseudo-random number and the subtraction operation is totally subsumed with the cost of the local metric. Moreover, there are usually fewer parties than dimensions; thus, passing a value among the m parties to compute a global metric is usually well within the order of cost of computing the global value without privacy. For the combinations metrics introduced here (Sect. 3.3 ) (like sum/max of local metrics) the performance will be the same as for the Minkowski metrics for sums and Chessboard for maximums. Finally, our private cosine metric calculation is also within minimal overhead over a non-private setting. The communication cost is again essentially the same as for parties computing this metric without privacy and is still linear in the number of parties and bits of the floating-point values. There are constant (less than 8) numerical computations (addition/multiplication) between the two parties left with computing the metric value with shares. They engage in privacy-preserving computation of dot products of dimension 2.

For the overwhelming majority of methods for k -NN queries and associative queries, the major cost is not the computation of distances per se, but how many of these computations are performed. That is, as long as computing distances are proportional to the number of dimensions, the cost (associated with k -NN queries or associative queries) is essentially the number of evaluations of distances. To perform k -NN queries, the only possible competitor to our privacy-preserving SASH method is the privacy-preserving version [ 55 ]ofFagin X  X  A0 algorithm [ 23 ]. However, for a vertically partitioned database with N records, this algo-rithm X  X  complexity (time and communication cost) includes as a factor the number S of candidates generated. It is well recognised that S can be as large as N and in the best case as small as k . The accepted [ 23 , 55 ] worst-case theoretical analysis is that the complexity is O ( N ( m  X  1 )/ m k 1 / m ) where m is the number of parties.

However, there are no studies on what is the expected performance of this algorithm. Our intuition is that Fagin X  X  algorithm must perform poorly in general because in order to perform well it requires that the cylinders around the query vector q , that constitute the projection to the k -nearest neighbour in each party, contain together as few elements as k . This seems unlikely. To confirm this we evaluated the size S of the union of Fagin X  X  AO algorithm in five well-known large data sets. The CoIL 2000 Challenge [ 58 ] dataset (Database 1) contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. We repeated the following experiment 100 times. We partitioned the attributes randomly into m parties, we selected random metrics for each party (among Euclidean, Hamming, Chess-board and Minkowski with r = 1), we selected a random query point from the data and computed the k -nearest neighbours using Fagin X  X  A0 algorithm. Table 4 shows the average size S of the union in Fagin X  X  AO algorithm for this data set with 95% confidence intervals. This data set has 5 , 822 records and we can see that most of the entries in the table are close to or above 3 , 000 while several are above 5 , 000. It is rather disappointing that when asking for 10 neighbours among 8 parties we expect a union size to be 78% of the size N of the database. We also recorded the best and worst observed size S of the union. Rather than showing another table we present this data for m = 8 parties in Fig 6 a. Note that the worst case for all query sizes k is above 5 , 000 and that the size of the union in the best observed case is well above 500  X  k , and rapidly above 50% of the size of the file. Similar results occur for the Census-Income Database holding multivariate PUMS census data (Database 2) from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990 (from KDD UCI repository). Combining test and training databases we get 299,285 records with 40 dimensions/attributes.

The inefficiency of A0 is also reflected in three large datasets previously used for approx-imate nearest neighbour queries [ 25 ].

The dataset named Histogram (Database 3) corresponds to a colour histogram, while the one named Stock (Database 4) corresponds to a stock market price. Stock has dimension 360 and 6,500 records corresponding to different companies. For m = 8 parties, the observed average, minimum and maximum size of the union for AO are shown in Fig 7 bforthe Stock dataset while the results for Histogram dataset are shown in Fig. 7 a. The histogram data set has dimension 64 and 12,103 records. The results for histogram show not only an aver-age case of O ( n ) but the worst case is essentially N . Finally, an aerial image dataset with dimension 60 and 275,465 (Database 5) records was tested and results for m = 8onthe size of the union for AO appear in Fig. 8 . Another reason for performing this analysis is that the privacy-preserving version of Fagin X  X  AO algorithm [ 55 ] leaks all the ids of the union. Therefore, the size S of the union not only determines the inefficiency of the method but is also a strong measure of the lack of security in the algorithm.

The privacy-preserving AO algorithm will perform at least as many distance evaluations as the number S of candidates (or the size of the union).

We have chosen the SASH because this data structure is very efficient invoking a num-ber of distance computations which is bounded by pcN log 2 N [ 31 , 32 ] (for construction), while the bound for an approximate k -NN query under the uniform search is ck log 2 N ,and k the SASH and k is the number of NN requested). Therefore, the SASH will easily outperform Fagin X  X  A0 algorithm, and will provide logarithmic response for k -NN queries and associative queries.

Naturally, the SASH invokes k -NN queries on small data sets. That is, the privacy-pre-serving SASH invokes Protocol 8 for small sets of size n . The natural question is why not use the searching for top k -queries in a field which requires ( n + 1 ) log | F | rounds, as opposed to our Protocol 8 which has complexity O ( n ) .

First, clearly all steps are equivalent until these protocols receive two vectors of dimen-sions n known to two distinct parties. Our protocol does require ( n log n ) time on Alice X  X  side for sorting and O ( n ) time on Bob X  X  side to add a random value to all the shares it holds and to generate the random permutation  X  , but the constants involved are small and clearly values are | F |= 10 6 , which makes a larger constant in the O ( n ) for this alternative.
More importantly, each of these rounds involves a Yao-comparison with shares and a final round where each party totals n values. Clearly, the local computation is far more in this aspect alone than our algorithm. In terms of communication cost, our approach is also more efficient. Bob sends exactly n values, and Alice sends back k values. The binary search in a field performs the communications needed for ( n + 1 ) log | F | Yao-comparisons. To further illustrate the practicality of our approach, we have implemented our Protocol 8 . Overall, Protocol 8  X  X  complexity depends on the number m of parties, the number n of vectors and the number k of near neighbors we are looking for.

In Fig. 9 a X  X , we illustrate these dependencies. The implementation confirms the logarith-mic performance time for m and n . The dependency from k oscillates (in a small region) but it remains bounded by constant. This is clear, because the sorting component is O ( n log n ) while the selection of k values is O ( k ) , with k much less than n . For communication cost, the mn + k complexity is dominated by n again.

We have also implemented the SASH method and evaluated the performance on the same five databases used with Fagin X  X  A0 algorithm. The performance depends directly on the number of candidates generated at all levels of the SASH (the sum of P i ( q , k i ) for all lev-els [ 31 , page 8]). Our results for all five databases are shown in Table 5 (with 95% confidence intervals). The SASH candidate generation does not depend on m , and shows remarkably small numbers for all data sets.

We have used the default parameters for the SASH recommended by the authors. 23 That is, we set the maximum number p of parents per node is 4 and the maximum number c of children per node is 4 p (that is 16) [ 31 ]. The geometric search pattern [ 31 ] is the one used for k -NN queries. The impact of this geometric pattern in our experiments is noticed in the Figs. 10 a, b, 11 a, b and 12 a. In particular, across these figures, the number of generated candidates remains essentially constant for k below k = 50. This is clear, because during the construction of the SASH the parameters p and c determine the size of the local collection of information about closest near neighbours for each node (see Sects. 4.1 , 4.2 ). In particular, this influences the values of the geometric pattern used for k -NN query. In this geometric pattern, a variable number k i = max { k 1  X  h 1  X  i  X  h ). Let us examine, for instance, Fig. 11 a. In this dataset, the value n = 12 , 103 and during the construction of the SASH , a total of 11 levels are contracted, so h = 11. When k ( i = h ) only the number of generated candidates will be different, but this will not affect the outcome as much, due to the very small difference. Moreover, the generated extra candidates could not be distinct from the candidates already included in the list. This is exactly what happens here. Starting from k &gt; 42 the last two levels produce more distinct candidates, so an increase in the overall number of generated candidates is noticeable (see Fig. 11 a). An increase of the value of k will affect more levels of the SASH . In particular, for every node from a level above the affected levels, the number of distinct children sought will be more than 1 2 pc = 32. This, obviously, affects the overall result.
 We alert the reader that the scale of the y -axis in Figs. 10 a, b, 11 a, b and 12 a is logarithmic. Figure 12 b collates all the data for the SASH with logarithmic performance.
Thus, the number of SASH candidates is much better than the number of Fagin X  X  A0 can-didates (at least several orders of magnitude). This demonstrates the efficiency of the SASH approach. 6 Final remarks If we accept the theoretically secure Yao-comparisons protocol with shares, this paper provides formally secure solutions to computing all the metrics discussed including all Minkowski metrics. Moreover, our Protocol 7 is a formally secure protocol for k -NN in the semi-honest model (Theorem 7 ) when no parties collude. In particular, Protocol 7 is totally secure for two parties. This is a first contribution that is fulfilling in the theoreti-cal sense. However, the protocols for metrics and Protocol 7 would be impractical by the many limitations of the theoretical solutions about Yao-comparisons with shares and because Protocol 7 requires quadratic complexity on the size of the database. We have described a Yao-comparison protocol that is secure in the formal sense (Theorem 1 ); however, because it uses real numbers, for its implementation we must trade-off security for efficiency. We have identified all the security risks and discussed how they can be minimized while maintaining very useful properties, like constant number of messages, and linearity on the number of bits involved (which makes it much faster than any other implementation we are aware of). As a result, we obtain an implementable version that is parameterized to achieve statistical secrecy.
While the relevance of k -NN queries have been recognized for many data-mining tasks, it has not been accepted that the current solutions for privacy-preserving computation of these queries are impractical. We have shown that the current alternative, the privacy-preserving adaptation of Fagin X  X  AO algorithm is essentially unfeasible because of its reliance on the-oretical generic solutions for Yao-comparison with shares and the assumption that the size of the union generated by Fagin X  X  is affordable. We have shown that this option is not viable and as an alternative we provided the SASH for logarithmic performance on the size of the database (as opposed to linear). We believe this generic privacy-preserving version of the SASH is the best trade-off between privacy and computational requirements. Along the way, we converted secure algorithms for the computation of metrics into practical solutions to be used in k -NN queries (we swap into them our efficient implementation of Yao-comparisons with shares and remove the theoretical Yao-comparison). Solving k -NN queries is central for many data mining tasks. Doing so separately, rather than the union of the databases risk accuracy of results. For example, it has been shown before [ 21 , 53 ], for vertically partitioned data, that the results of each party clustering separately can be radically different, and in fact incorrect, if each party clusters in their own projection. Since we have made the only element needed a dist function, the applications of our approach go beyond objects codified with an id and an attribute-vector per party to unstructured data, like video and audio.

Why is the SASH less accepted in the context of data mining? One issue that remains to be elegantly solved for the SASH are altering insertions and deletions (that is a graceful dynamic behavior). Accumulating insertions and marking deleted items as such while peri-odically rebuilding the SASH may be considered sufficient for dynamic behavior. However, for privacy-preserving this is not satisfactory as some queries would be repeated on the same elements and the risk of information leak increases then.
 References Author Biographies
