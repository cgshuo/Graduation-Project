 1. Introduction users the capability of simultaneously searching multiple remote information sources (i.e. search engines or specialized web sites) through a single interface. The importance of DIR has particularly augmented in recent years as the prohibitive size and rate of growth of the web ( Lyman &amp; Varian, 2003 ) make it impossible to be indexed completely. More importantly, a large number of web sites, collectively known as invisible web ( Bergman, 2001; Raghavan &amp; Garcia-Molina, 2001; Sherman, 2001 ) are either not reachable by search engines or do not allow their content to be indexed by them, offering their own search capabilities. Even publicly available, up-to-date and authoritative government information is often not indexable by search engines ( Miller, 2007 ). Studies by Bergman (2001) have indicated that the size of the invisible web may be 2 X 50 times the size of the web reachable by search engines.

The distributed information retrieval process can be perceived as three separate but interleaved sub-processes: source ated. This process takes place before the user poses a query to the DIR system. Source selection ( Callan, Lu, &amp; Croft, 1995; chosen to process the query, once it has been submitted and results merging ( Craswell, Hawking, &amp; Thistlewaite, 1999; Pal-result list which is returned to the user.
 This paper deals with the source selection problem. Previous research ( Callan et al., 1995; Nottelmann &amp; Fuhr, 2003a; Si &amp; the retrieval process. Research by Si and Callan (2004) has differentiated the source selection problem in two distinct but interrelated subproblems; the high-recall and high-precision goals.

The former deserves particular attention, since its definition is differentiated from the definition of recall for classical, centralized information retrieval environments. The high-recall goal for DIR environments is aimed at source recommenda-tion applications, where the aim is to select a small set of the available resources that contain as many relevant documents as possible. A likely scenario of usage of such an application would be to recommend to users hidden web sites that are likely to contain significant amounts of information relevant to their information need, for browsing purposes. Recent work by Seo and Croft (2008) explicitly views the Blog Distillation task, under which the goal is to direct users to blogs that have a central and recurring interest in topic X, as a special case of source selection for source recommendation applications, achieving one of the best performances in the corresponding task in TREC 2007 ( Macdonald, Ounis, &amp; Soboroff, 2007 ). The high-recall task may in some ways be related to Broder X  X  navigational queries under his taxonomy of web search ( Broder, 2002 ), according to which a large percentage (approx. 68%) of users are mainly interested in reaching  X  X  X  site that provides good information X  on a specific topic. The above hypothesis remains an open research topic since no user-oriented studies have been done in fed-erated search environments to verify it.

An alternative definition of high-recall for DIR environments is the elimination of collections that contain no relevant doc-uments. The differences between the two definitions are subtle but could potentially lead to different approaches in dealing with the problem, from maximizing the number of relevant documents in recommended collections to minimizing the num-ber of collections recommended that have no relevant documents. This definition may be closer to the definition of recall as it is applied in classic IR, but the initial given definition is the one that has been followed by most researchers and is the one that is adopted in this paper.

The high-precision goal aims at providing the user a final merged result list with the most relevant documents appearing in the top ranks and is related to classic IR precision. Although the two tasks are highly associated, they are implicitly dis-tinct. Algorithms that perform adequately on one, are not guarantied to perform similarly on the other. The apparent discord is based on the ability (or lack of) of the remote collections to actually return their most relevant documents for merging, having been selected in the source selection phase. Therefore, for example, a collection with a significant number of relevant documents may not be able to retrieve them for merging, while another collection containing fewer relevant documents may retrieve most of them, thus significantly contributing to the quality of the final merged document list. The observation was originally made by Craswell (2000) and has been further explored in Si and Callan (2004), Si and Callan (2005) and Shokouhi (2007) .

The source selection algorithm that is presented here explicitly focuses on both of the above goals, using a novel and sim-ple metric for estimating the relevance of information sources by modeling each collection as a integral using the relevance score and the intra-collection rank of its sampled documents. In order to achieve the goal of high-recall , the algorithm selects the collections that cover the largest area in the rank-relevance space. For the high-precision goal, the algorithm divides the area covered by the remote collections into segments, each representing an estimation of the potential benefit of including their top-ranked documents in the final merged list and calculates the optimal distribution of retrieved documents in order to maximize the overall gain.

The rest of the paper is structured as follows. Section 2 reports on prior work. Section 3 describes the new methodology proposed in this paper. Section 4 describes the setup of the experiments conducted. Section 5 reports and discusses the re-sults obtained and Section 6 concludes the paper, summarizing the findings. 2. Prior work
Source selection has received considerable attention in research the last years. In this section we present the most prom-inent work.

The STARTS initiative by Gravano, Chang, Garcia-Molina, and Paepcke (1997) is an attempt to facilitate the task of que-rying multiple document sources through a commonly agreed protocol. It provides a solution for acquiring resource descrip-tions in a cooperative environment, where remote collections provide important statistics about their contents.
When cooperation from collections is not available (i.e. isolated environments), techniques have been developed that al-low for the estimation of their contents. Query-based sampling ( Callan &amp; Connell, 2001 ) is such a technique that creates col-lection samples through multiple one-term queries. Estimation of collection sizes is also possible through sample X  X esample ( Si &amp; Callan, 2003a ) or capture X  X ecapture ( Shokouhi, Zobel, Scholer, &amp; Tahaghoghi, 2006 ) methodologies.
GlOSS by Gravano, Garcia-Molina, and Tomasic (1999) is a source selection algorithm that uses document frequency and the sum of term weights within each remote collection. However, it is based on certain unrealistic assumptions about the distribution of terms and term weights within the documents ( high-correlation and disjoint scenarios). CVV by Yuwono and Lee (1997) produces a ranking of collections based on the degree to which terms distinguish documents in the collection from those in the other collections. CORI ( Callan et al., 1995 ) is one of the most widely used source selection algorithms and is based on inference networks. It has been found to be more effective than the previous approaches ( Powell &amp; French, 2003 ).
A decision-theoretic framework (DTF) was presented by Fuhr (1999) which produces a ranking of collections with the goal of minimizing the occurring costs, under the assumption that retrieving irrelevant documents is more expensive than retrieving relevant ones. It was one of the first attempts to approach the problem of source selection from a theoretical point of view. However, implementations of the approach by Nottelmann and Fuhr (2003a) have been reported to perform slightly worst than CORI, particularly on short queries. A second theoretical approach, based on Kullback X  X eibler divergence lan-guage model ( Si et al., 2002 ), for source selection and results merging was also presented in recent years.
A hybrid approach to source selection, which combines centralized and federated search in web-based environments was presented by Hawking and Thomas (2005) . It was found to be very effective in web-oriented tasks, such as homepage find-ing. Its applicability however is limited to environments where crawling some of the collections is possible.
In more recent years, there has been a shift of focus in research on source selection, from considering remote collections as simple aggregations of documents and estimating the relevance of each, to explicitly estimating the number of relevant documents in each. ReDDE by Si and Callan (2003a) has exactly that purpose. It is based on utilizing a centralized sample index, comprised of all the documents that are sampled in the query-sampling phase and ranks the collections based on the number of documents that appear in the top ranks of the centralized sample index. Its performance is similar to CORI 2003a). Two similar approaches called CRCS(l) and CRCS(e) were presented by Shokouhi (2007) , assigning different weights to the returned documents depending on their rank, in a linear or exponential fashion. They attained improvements in pre-cision over previous approaches, but their recall was usually lower.

The Unified Utility Maximization (UUM) framework, presented by Si and Callan (2004) is one of the first algorithms to specifically differentiate between the two tasks in source selection. Its performance was found to be similar to ReDDE in some testbeds and better in others. A variant of the algorithm was presented by Si and Callan (2005) that also took into con-sideration the effectiveness of the retrieval at the remote collections. However, both approaches must go through an ex-tended training phase requiring human judgments before they can be successfully utilized.

Previous approaches at source selection by Si and Callan (2003a, 2004, 2005) , such as ReDDE and UUM, have relied on the scale factor for collection i ( SF i ) is defined as: where b N i is the estimated size for collection i and N i collection. SF i represents the inverse portion of the collection documents that have been sampled from collection i . The moti-be approximately SF i documents in the actual collection that will have about the same score. The same intuition is applied to all the documents returned by the centralized sample index.

However, there have been studies examining whether the samples created through query-based sampling are truly ran-dom. Shokouhi et al. (2006) demonstrated that the resulting sample is heavily biased. Thomas and Hawking (2007) pre-sented various novel approaches of sampling, but still failed to produce unbiased samples in certain environments.
Even if a truly random sample were possible, it is still unlikely that the above assertion will hold true. That is because there is no evidence that an unbiased sampling of documents results in a uniformity in the distribution of document scores, in regard every query posed to the collection. The randomness of sampling refers to the ability of the sampling procedure to retrieve documents in a random fashion ( Shokouhi et al., 2006 ), i.e. the distribution of documents over multiple sampling processes in a true random sampling should simulate the Poisson distribution. Potentially, a sampling process that takes place during query time, such as the Lightweight Probe technique by Hawking and Thistlewaite (1999) , may provide a solu-tion to the above issue.

The approach presented here relaxes the necessity for a random sampling and a per-query uniform distribution of doc-ument scores by utilizing SF i only once per collection avoiding making assumptions about the unsampled documents of the collection.

The algorithm departs from traditional practice in federated search in an additional manner. Previous approaches in DIR have relied on the number of collections that will be queried as well as the number of documents that will be retrieved from each being pre-specified, usually by the user. Since in most cases, information concerning the actual distribution of relevant documents amongst remote collections is unavailable (hence the need for source selection), such decisions are usually based on arbitrary rules. The algorithm that is presented here requires that only one decision be made: the number of documents in the final merged list. The decision on how many collections to query and how many documents to retrieve from each is determined by the algorithm, through a dynamic programming process. As it will be shown, although the system receives the minimum information, the results that are produced are equivalent or better to those produced by more information-demanding systems.
The works of Liu, Meng, and Yu (2000) Wu, Meng, Yu, and Li (2001) also discuss the problem of source selection in fed-erated information retrieval environments but they either assume that the retrieval algorithms at the remote collections are known (i.e. dot-product functions) ( Liu et al., 2000 ) or that the remote collections are cooperative and provide information about their most relevant document in regard to every query posed ( Wu et al., 2001 ). The study in this paper focuses on set-tings where remote collections provide no cooperation at all and no information is available about the retrieval algorithm that they employ and thus they are not examined further. 3. Integral based source selection 3.1. Collection-integral source selection for high-recall
The motivation behind the new source selection algorithm is to differentiate between the two distinct tasks in source selection, high-recall and high-precision without requiring any training, thus making it applicable in dynamic environments such as the web, using a simple and novel integral-based metric for collection relevance.

In order for the algorithm to function, a centralized sample index (CSI), which is comprised of all the sampled documents indexed together, is built. The centralized sample index is considered as a representative of the single global index that would be created if all the documents were available for indexing, providing estimates of global collection statistics (such as global idf), necessary for the estimation of collection-independent document relevance scores.

The use of the CSI in federated search environments has been standard practice for a number of years and most state-of-the-art source selection approaches, as well as results merging algorithms make use of it, especially in uncooperative environments.

The query is directed to the centralized sample index and a list of documents with relevance scores is returned. We used the INQUERY retrieval algorithm ( Callan, Croft, &amp; Harding, 1992 ) to query the centralized sample index, but any effective algorithm would do. The returned documents are assigned to the collections from which they were originally sampled, cre-ating a vector of scores for each collection i : v i  X f score originating from the sample of collection i .

Each collection is represented as a plot, using the scores and the rank of the returned documents as points: {  X  1 ; score 1  X  ;  X  2 ; score 2  X  ; ... ;  X  n i ; score and the ranking of documents only in reference to the other intra-collection documents is utilized. By making usage of the relevance scores of the documents in reference to the centralized sample index and not of their rankings, the algorithm is able to retain intricacies in scores, which are not apparent in ranking. For example, a difference of one in ranking (i.e. 2 and 3) may be due to a minimal (i.e. 0.63 and 0.62) or more substantial (0.6 and 0.5) difference in scores. Using scores instead of rankings, makes the algorithm more  X  X  X ensitive X  to such subtle differences. 3.1.1. Incorporating collection sizes
We incorporate the estimates for the size of the collections into the algorithm. Research ( Shokouhi, 2007; Si &amp; Callan, 2003a) has indicated that using the estimated size of the collections improves effectiveness, especially in environments with skewed collection sizes.

Our approach is based on the following assumption. Supposing that collection i has n ized sample index, then we assume that there should be about actual remote collection. An example will make the above clearer. Suppose a collection of estimated size of 3000 documents from which we have sampled 300 documents. If the sample of the collection returns 50 documents, we assume that if the assumption about the relevance of the unsampled documents or the distribution of their scores is made, only about the over-all number of returned documents.

The main contribution of the above assumption is to provide a rough estimate of the number of documents that are ex-pected to be returned if the query is directed to the actual remote collection. The hypothesis is less strong than previous approaches (i.e. Si &amp; Callan, 2003a, 2004 ) that assume that not only the number of documents returned by the sample col-lection is proportional to the number of documents that would be returned by the remote collection but extend the above hypothesis to the distributions of scores. Nonetheless, as discussed above, the sampling of remote collections is usually biased and therefore such strong correlations are rarely seen in realistic environments. The approach adopted here therefore makes a less strong assumption and additionally the accuracy of the hypothesis influences the effectiveness of the algorithm in only a limited manner. The robustness of the algorithm will be analyzed and explained below.
 Additionally, we assume that the relevance score of the last document is close to zero. Taking into consideration that the
SF is O (100) O (1000) in most cases, it is safe to assume that the last document that is retrieved from a collection would most likely have a very low relevance score, therefore justifying the above score. The exact value of the score does not influ-ence the performance of the algorithm.

We insert a last tuple at the tail of each collection graph, as document n
Although the above assumptions and the coordinates of the last point may be considered somewhat ad-hoc, the process is in accordance with previous research in IR. Previous approaches in source selection by Si and Callan (2003a) and Shokouhi (2007) consider the top N documents returned from the centralized sample index to be relevant and disregard the rest as irrelevant. The same modeling of relevance is also utilized by most automatic relevance feedback methods. In order to avoid using a step function to simulate the relevance of the documents retrieved from the remote collection, a score close to zero is assigned to the last document, in effect slowly reducing the probability of relevance of the potentially retrieved documents from the remote collection.

Taking into consideration that, as discussed above, the sampling is usually non-random and the estimates of the collec-tions sizes are less than accurate, with a mean-average error ratio of 0.23 at best as observed by Si and Callan (2003a) , the algorithm is able to function effectively even in environments where the  X  X  X nitial conditions X  for source selection (i.e. the sampling of the remote collections and the estimation of their sizes) are less than perfect. The robustness of the algorithm to the above issues is discussed below and is demonstrated in the experiments, reported in Section 5 . 3.1.2. Definition of interpolant line segments We define the family of linear interpolant functions for each collection i that pass through the points ( Fig. 1 ): example F (2.5) = score 2 + (2.5 2)( score 3 score 2 )). Although it is possible to fit a single higher-degree function through the points via interpolation, applying a single curve unavoidably results in diminished accuracy, therefore a family of linear func-tions was chosen that is guaranteed to pass through all the points in the plot. The idea and motivation behind the use of the plot is to have a first estimate about the relevance of the documents in the sample collections in regard to the particular query. One would expect that a collection that is a good candidate for selection to have certain properties, such as a non-trivial number of documents in the plot and at least some of them with high relevance scores. 3.1.3. Applying modifications to the initial collection graph
We enhance and quantify the above intuitions by applying two transformations to the initial graph. The transformations involve assigning different weights to the documents depending on the ranking and the relevance score they attained. The process of applying different weights to the returned documents has been a tested practice in DIR ( Shokouhi, 2007; Si &amp; Call-an, 2003a) as well as in other fields, such as metasearch ( Aslam &amp; Montague, 2001 ) or expert finding ( Macdonald &amp; Ounis, 2006 ). Here, we transfer this practice to the appropriate modeling of the collections as plots.

First, the original tuples are transformed in the following manner: ( j , score mation is shown in Fig. 2 . As it can be observed, the interval between the top left-most points in the plot is increased, while it is steadily decreased as the values in the x -axis increase. The reason and the effects of the transformation will become appar-ent when the final collection-ranking function is defined, but the overall purpose is twofold. First of all, it increases the area covered by the top, high-ranking documents and gradually decreases it for the ensuing documents. That is because high-scoring documents mark higher in the y axis and with the above transformation the segments that they cover on the x axis also increase, effectively augmenting the area that they cover in relation to documents with lower scores, thus promoting the collections they belong. This way, collections that have documents with high scores are rewarded in comparison to collec-tions that have average-scoring documents. The property is both important and desirable since collections that have at least some high-scoring documents are expected to be more appropriate for selection than others that have mainly documents with average scores.

Additionally, the above transformation dampens the effect of collections returning a large number of documents, effec-tively moderating their contribution to the area covered by the collection. Although a large number of documents may be indicative of the appropriateness of the collection for selection, the expected correlation is not proportional (i.e. a collection that returns 30 documents is not necessarily twice as relevant as one returning only 15
At this point, we return to the claim that the algorithm is robust to the accuracy of the collection size estimates and to the coordinates of the last artificial document  X  n i N mation, since applying the log function to the x coordinates of all points minimizes any differences between the actual and the estimated collection size. For example, collection ap90_5 from the  X  X  X rec123-100col-bysource X  testbed that will be de-scribed in Section 4 contains 9605 documents and its estimated size, using the sample X  X esample technique by Si and Callan (2003a) is 7650 documents, an error of about 20%. Applying the log transformation 2.4%, thus greatly reducing the dependency of the source selection algorithm to the accuracy of the collection size estimation algorithm.

The level of the reward that is granted to collections with high-scoring documents and the degree of the dampening effect both depend on the base of the logarithm (the m value) and is left as a parameter of the model.
 and Ounis (2006) and Ogilvie and Callan (2003) . The Lemur Toolkit probability of documents ( Ogilvie &amp; Callan, 2001 ), therefore applying the above transformation returns the score to the prob-ability scale. The above transformation has the additional effect of further boosting the scores of high-scoring documents and
Summarizing the two transformations  X  j ; score j  X ! X  log functions F i ( x ) for collection i (Eq. (2) ), we get D We are now able to define the ranking function R ( i ) for collection i , on the basis of which collections are ranked: which can intuitively be defined as the area between the transformed function D
It should be noted here that the approach of modeling information sources as integrals in the rank-relevance space may be considered empirically-driven but it extends previous approaches on relative modeling of collections as the sum of impact values of their sampled documents ( Shokouhi, 2007 ) or as an estimation of the percentage of relevant documents they con-tain ( Si &amp; Callan, 2003a ). Further study is needed in order to investigate and exploit the modeling presented here and its properties more fully.

In summarizing the algorithm, the user query is initially submitted to the centralized sample index, using the INQUERY retrieval algorithm. The retrieved documents are assigned to the collections from which they originated from, creating a vector of documents scores for each collection. Each collection is represented as a graph using as points the scores and the intra-collection rank of the returned documents. A last artificial point, incorporating the collection sizes into the algo-rithm, is introduced at the end of the plot at coordinates  X  the area that is covered by them, i.e. the area between the linear segments and axis x is calculated. The estimated area is the score R ( i ) for each collection.

The process is depicted in Fig. 3 for collection app8_4 and trec query 51  X  X  X irbus Subsidies X . The top left image is the initial plot created for the collection. Five documents were returned from the centralized sample index that were originally sam-can be observed that the new point dominates the collection integral. To remedy this problem the log transformation is ap-plied at the x axis and the modified plot is depicted at the bottom left graph. Finally, the exponential function is applied to the documents scores and the final plot for the collection is shown at the bottom left image. The score R ( i ) for collection app8_4 is the area between the line segments and axis x .

The newly proposed algorithm was named Collection-integral Source Selection (CiSS). The algorithm as it was presented as far, that selects the collections that cover the largest area in the rank-relevance space, was utilized to address the high-recall problem and was therefore named CiSS-HiRe (CiSS for High Recall ). 3.2. CiSS for high-precision
Previous research by Si and Callan (2003a, 2004) has shown that the high-recall and the high-precision goals are often not attainable without special consideration for the specifics of each particular goal, especially in testbeds with skewed collec-tion sizes and distribution of relevant documents. In Si and Callan (2004) a clear distinction between the two related but not necessarily equivalent goals was applied for the first time and the source selection problem was explicitly differentiated. Re-cent research on source selection ( Shokouhi, 2007; Si &amp; Callan, 2005) has focused on the high-precision goal, considering the high-recall goal of secondary importance.

Addressing the high-precision goal requires that the CiSS algorithm focuses on maximizing the area that is covered by segments of the collection integrals, thus estimating the potential benefit of including the top-ranked documents of each remote collection in the final merged list, rather than straightforward ranking the collections by the area that they cover.
The basis of the above estimation is the modeling of the collections as integrals in the transformed rank-relevance space, as it was presented above. Rather than computing the space covered by the whole graph, as it was done for CiSS-HiRe, the integral is divided into smaller segments, each one representing the benefit of including the top-ranked documents from the collection in the merged list. An example of such a segmentation is given in Fig. 4 . For readability reasons, a segmentation of the initial plot is presented, but the algorithm is based on the transformed plot (Section 3.1 ). In order to simplify calculations we assume that remote collections return documents at lists of 10 documents per page. The methodology presented can also be applied to lists of greater granularity (i.e. one, three, five, etc.).

One observation that needs to be made here is that the segments are not of equal length on the x -axis, as one might ex-pect. In fact, the segments are wider at the top ranks and slowly decrease as the x values increase. The fact derives from the observation that most of the relevant and therefore useful documents that a collection will return for merging will be located at the top ranks and therefore the widths of the left-most segments should be wider in order to reflect the above observation.
Experimental results, presented by Paltoglou et al. (2007) showed that increasing the number of requested documents from the remote collections, does not necessarily result in an increase in precision in the final merged list, therefore indicating that most of the relevant documents of a collection will be placed in the top ranks. We therefore assume that the gain of dele-gating the user query to the particular collection and including its retrieved documents in the final merged list, will derive primarily from its top-ranking documents.

The actual decrease of probability of relevance in relation to document rankings is open to question and depends on a variety of factors, such as the actual number of relevant documents the remote collection contains, its size and potentially the effectiveness of the retrieval algorithm employed. Previous studies by Jansen, Spink, and Saracevic (2000), Le Calv X  and
Savoy (2000) and Shokouhi (2007) have indicated that the probability of relevance of a document (and therefore the gain of retrieving it) has a negative exponential or logistic relation with its rank.

One of the important properties of the logistic function that make it attractive to this estimation ( Nottelmann &amp; Fuhr, 2003c ) is that it can produce a large variety of curves, by simply modifying a and b. Fig. 5 demonstrates the general expected correlation between probability of relevance and ranking using a logistic function with various parameter values. Based on the above studies, a rough division of the x -axis for collection i is designed based on the following formula: where a = 2 and b = 0.75; x is the cardinality of the result page (1st,2nd, ... ) and represents the general gain of observing/ retrieving the documents in the x th result page of the remote collection. The contents of the log of the ( n i + 1) document as defined in Section 3.1.1 , hereafter noted as x of the decrease of relevance of the returned documents from the remote collections.

The above function has the significant drawback that the series of the first part (the sum of its values for x =1,2, ... )is greater than 1, meaning that the segments at the x -axis would extend beyond the last point ( n
In order to keep the slope of the decrease but remedy the above problematic feature, we divide the original H c are set is given in Section 4 .

It is notable that the series of H i  X  x  X  is less than 1 log considered. The above means that some documents belonging to the remote collections will never be considered for retrieval and merging. The conclusion is in accordance with the results presented by Shokouhi et al. (2006) , where it is reported that approximately 10% of the webpages in the WT10g collection ( Bailey, Craswell, &amp; Hawking, 2003 ) were not retrieved during the extraction of one hundred query-based samples, indicating that some documents may be irretrievable, at least by few-term queries.

Note that the produced decline is dependent only on the number of returned sampled document for collection i and its estimated size. A more fine-tuned definition of the above decline individually for each collection i , i.e. dynamic estimation of parameters a , b and c upon query time is left as future work.

We define the function G i ( x ) that calculates the area of the x th segment of the i th collection and thus estimates the gain of retrieving it:
We are now ready to define the vector gainV i that will contain the estimated gains G
Each element k of the above vector represents the gain of including the k th result page from the i collection into the final merged list.

Having generated the vector gainV i for each collection i , the algorithm proceeds to a dynamic programming solution, in order to estimate the optimal distribution of documents from remote collections that maximize the area covered by the col-lection segments. The process takes as input the gainV i vectors for all the available collections and the total number of re-quested documents in the final merged list. The purpose of the dynamic programming is to maximize the gain (i.e. overall area covered) of the final merged list. The problem is non-trivial and is viewed as an typical  X  X  X ptimal allotment prob-lem X  ( Lew &amp; Mauch, 2006 ) with a limitation on the number of users. The implementation of the solution be either be recur-sive (which is very inefficient in regard to the time necessary to locate the optimal solution) or through storing the values of each iteration, until the maximum value and the optimal distribution is calculated under the pre-specified limitation, which was the preferred way in the experiments that were conducted.

The output of the process is a final vector gain ={ gain 1 uments that will be requested from the respective remote collection for merging. For example if gain = {10,0,20,0, ... ,0} then the algorithm will request 10 documents from the first collection, 0 from the second, 20 from the third and so fourth.
Summarizing the version of the algorithm that aims to solve the high-precision problem, we segment the original graph for collection i with vertical line segments that pass through points  X  H for the created segments, as shown in Eq. (6) . The calculated integrals for each collection i are stored in a vector gainV is used as input for the dynamic programming algorithm. The output of the algorithm is the final vector gain , that represents the number of documents that will be requested from each available remote collections.
 Fig. 6 shows an example of the estimated graph segments for collection ap88_4 and trec query 51  X  X  X irbus Subsidies X .
This version of the algorithm was named CiSS-HiPre (CiSS for high-precision ). 4. Experiment setup
We used a variety of testbeds to evaluate the proposed algorithm. The trec123 and trec4 testbeds ( Powell et al., 2000 ) have been used extensively in distributed information retrieval experiments ( Callan et al., 1995; Callan &amp; Connell, 2001;
Si &amp; Callan, 2003b; Shokouhi, 2007; Si &amp; Callan, 2005 ), so we briefly present them below
Trec123-100col-bysource ( X  X  X niform  X  ): The documents in TREC 1, 2, 3 CDs are divided in 100 non-intersecting collections, organized by source and publication date. Its contents are somewhat heterogeneous.

Trec4-kmeans ( X  X  X means  X  ): The documents in TREC 4 CD are divided in 100 non-intersecting collections by a k -means clus-tering algorithm. The collections are very homogeneous and the word distribution is very skewed.

Three more testbeds with skewed collection sizes and distribution of relevant documents were created from the trec123 testbed, in order to provide a more complete simulation of realistic environments ( Shokouhi, 2007; Si &amp; Callan, 2004; Si &amp; Callan, 2005 ).

Trec123-2ldb-60col( X  X  X epresentative  X  ): The collections in the Uniform testbed are organized in alphabetical order and every fifth collection starting with the first is merged into a single collection. The same process is also applied starting with the second collection, resulting in two large collections of about 650 MBs each and 60 smaller ones of about 30 MBs each. All the collections have the same density of relevant documents. The Representative partitioning aims to simulate environ-ments where a limited number of large collections contain a significant number of relevant documents, and a larger num-ber of smaller collections also contain some relevant documents. It should be noted that the large collections are an order of magnitude bigger in size than the small ones.

Trec123-AP-WSJ-60col ( X  X  X elevant  X  ): The 24 Associated Press and the 16 Wall Street Journal collections are merged into two large collections. Those two collections are both larger in size than the rest of the collections (the former being about 750
MBs and the latter about 520 MBs) and hold most of the relevant documents. The Relevant testbed simulates an environ-ment where all of the relevant documents are contained within a limited number of significantly larger collections.
Trec123-FR-DOE-81col ( X  X  X onRelevant  X  ): The 13 Federal Register and 6 Department of Energy collections are merged into two collections. Although these collections are much larger in size than the rest, they have very few relevant documents.
The NonRelevant testbed has a twofold function: First of all, it functions as a baseline to ensure that the designed source selection algorithms are not heavily influenced by the collection sizes (ranking the largest collections first regardless of whether they contain any relevant documents) and secondly to simulate environments where the largest collections con-tain no relevant documents at all.

The advantages of the above testbeds are that they offer qualitative content in a way similar to authoritative web re-sources, such as hidden web, government or enterprise resources. Their drawback is that they are artificially made, not web-based and they offer a limited degree of distribution. In order to better evaluate the proposed algorithm we also utilized a web-based testbed, first presented by Paltoglou et al. (2007) , which is based on the WT10g collection ( Bailey et al., 2003 ).
The advantages of the last test collection are that it is web-based, naturally divided into collections as they were created by their authors and offers a much greater distribution than the standard trec collections. Details about the collections and the queries are provided in Tables 1 and 2 .

WT10g-1000col-byUrl ( X  X  X eb  X  ): The documents from the WT10g collection are divided into 11,653 collections based on their URLs and the 1000 collections with the largest number of documents are selected. The collections are very diverse both in word distribution as well as in size.

We used query-based sampling ( Callan &amp; Connell, 2001 ) to create representatives for the remote collections, sending 75 one-word queries and downloading the first 4 documents, obtaining approximately 300 documents per collection. The above process may not produce optimal representatives as noted by Thomas and Hawking (2007) , but has become standard prac-tice when evaluating source selection algorithms ( Shokouhi, 2007; Si &amp; Callan, 2004, 2005 ). In order to estimate the size of the remote collections we used the sample X  X esample technique by Si and Callan (2003a) . To make the experiments more realistic, we assigned three different information retrieval algorithms to the remote collections in a round robin fashion:
INQUERY ( Callan et al., 1992 ), a language model based on KL divergence ( Zhai &amp; Lafferty, 2001 ) and Okapi BM25 ( Robertson et al., 1994 ).

Source selection algorithms for source recommendation applications ( high-recall goal) are compared using a recall mea-sure R k ( Callan et al., 1995; Nottelmann &amp; Fuhr, 2003a; Si &amp; Callan, 2005 ): where E is the collection ranking provided by the source selection algorithm under investigation and B is a baseline ranking, usually the relevance based ranking (also referred to as optimal ranking), under which collections are ranked by the number of relevant documents they possess. For example, suppose that a distributed setting contains four collections, { C for a particular query each contains 5, 20, 0, 10 relevant documents respectively. The optimal ranking therefore would be
B ={ C 2 , C 4 , C 1 , C 3 }. Supposing a source selection algorithm that produces the following ranking E ={ C of R k for various values of k is: R 1  X  10 20  X  0 : 5, R imum effectiveness searching only few collections, so we report results for selecting up to 20 collections.
In order to avoid any interference from the results merging algorithm in precision-oriented environments, we opted to locally download and re-rank all the returned documents, using the centralized sample index as a  X  X  X eference statistics data-base X  ( Craswell et al., 1999; Si &amp; Callan, 2003b ) for the estimation of collection-independent idf values. The above method-ology may not be the most efficient, but it is the most effective, as indicated by Craswell et al. (1999) . The above decision was made to minimized any  X  X  X oise X  introduced in the process by the merging algorithm and present the source selection algo-rithms under the best attainable performance. Alternatively, SSL ( Si &amp; Callan, 2003b ) could be utilized but previous research by Paltoglou et al. (2007) and Shokouhi (2007) has indicated that the algorithm performs optimally only when the collec-tions return a significant number of documents (i.e. 100), which would result in an artificial deteriorated effectiveness of
CiSS-HiPre in environments where only few documents are requested from a collection. Note that the downloaded docu-ments can afterward either be kept at the centralized sample index, practically updating it or alternatively be deleted. In the line of experiments that were conducted, the second approach was adopted so that previous queries would not effect the results of subsequent queries. Since users rarely look past the top 20 results as reported by Jansen et al. (2000) , we report precision measurements up to that rank.

We compared the new source selection algorithm with approaches that do not require training: CORI ( Callan et al., 1995 ), which is one of the most widely used source selection algorithms, ReDDE ( Si &amp; Callan, 2003a ) which attains particularly good performance in recall-oriented settings and testbeds with collections of varying size and CRCS(l) and CRCS(e) ( Shokouhi, 2007 ) that are precision-oriented source selection algorithms. We used the default parameter values for all the above algo-rithms, as suggested in their respective papers. The ReDDE algorithm is utilized as baseline in precision measurements, be-cause it has been reported to have a more stable performance across all testbeds as reported by Si and Callan (2003a), Hawking and Thomas (2005) and Shokouhi (2007) . Measurements in bold and  X  report statistically significant better performance (paired t -test p &lt; 0.1 and p &lt; 0.05 respectively) and measurements in italic statistically worse performance (paired t -test p &lt; 0.1).

Although no single value of the parameter m for CiSS is optimal for every testbed and setting, preliminary experiments showed that the algorithm is robust across a range of parameter values ( 1.0001 X 10). Presenting results with different values of m would result in presenting the algorithm highly optimized, therefore we eventually set the value of m to a constant value of 1.07 which provided with a good enough (though not optimal) performance across all testbeds. As the testbeds are very different, in terms of collection sizes, distribution of relevant documents, number of available collections and con-tent (i.e. newswire articles and webpages) we believe that the results are representative of the potential of the methodology and its effectiveness. We leave the goal of automatically setting the value on each testbed to the optimal value, potentially based on the skewedness of the sizes of the remote collections, as future work. We used queries 51 X 100 for setting the values of parameters a , b and c using MAP at the Uniform testbed as the optimization criteria. The produced values ( a =2, b = 0.75 and c = 4.15) were applied at every conducted experiment. As an optimization method we simply evaluated the performance of the algorithm on a successively smaller grid over the set of parameters.

A significant difficulty in comparing source selection algorithms in precision-oriented environments is that CiSS-HiPre receives as input only the number of requested documents, dynamically estimating the number of collections that are se-lected as well as the number of documents that are retrieved from each. In order to present all the algorithms under the best possible light and in as equal terms as possible, the following settings are applied: CiSS-HiPre is set to retrieve 100 docu-ments in total and the rest of the source selection algorithms, including CiSS-HiRe, are set to select seven collections each one returning twenty documents. Even though the above setting results in CiSS-HiPre retrieving less documents in total for merging (100 versus 140), potentially it can contact more information sources for merging (to a maximum of 10). The motivation between the above setting is that when CiSS-HiPre is set to retrieve 100 documents, on average it was found to contact seven collections. Studies by Shokouhi (2007) and Avrahami et al. (2006) have shown that increasing the number of collections does not necessarily result in an increase of retrieval quality so we believe that the above settings present all the algorithms under the best possible conditions. 5. Results 5.1. Recall-oriented settings
The results of the experiments in recall-oriented settings, i.e. for source recommendation applications where recall is of importance, are presented in Figs. 7 X 12 . The performance of CiSS-HiRe is measured in this setting as it produces a ranking of collections.

In the Uniform testbed ( Fig. 7 ), most of the algorithms perform similarly. The relative uniformity of the distribution of relevant documents at this testbed and the lack of complete information about the collections, make the goal of locating the collections that have the greatest number of relevant documents very difficult. CiSS-HiRe is able to show improvements over other approaches at settings of up to six collections, while performing equally to CORI from that setting and on. In the
Representative and Relevant testbeds ( Figs. 8 and 9 ), CiSS-HiRe locates the collections with the greatest number of relevant documents very effectively and thus attains a clear advantage. The results may be indicative that the new algorithm has a preference for large collections over smaller, but the results from the NonRelevant testbed ( Fig. 10 ), where the two largest collections have almost no relevant documents and all algorithms perform similarly show that this is not the case.
The above results support the utilization of the estimated collection sizes as it was introduced into the algorithm, making it  X  X  X ensitive X  to collections with a significant number of relevant documents, regardless of their size. The Representative and
Relevant are testbeds where ReDDE is typically very effective ( Si &amp; Callan, 2003a, 2004 ). The experiments suggest that CiSS presents an effective solution at collections with skewed collection sizes and concentration of relevant documents.
In the Kmeans testbed ( Fig. 11 ), all the algorithms perform similarly with some fluctuations although CORI and CRCS(l) do seem to be slightly more effective at settings of up to eight collections. Lastly, in the WT10g ( Fig. 12 ) testbed CiSS-HiRe has an advantage for the first five collections, after which it is surpassed by CRCS(e), although the difference between the two algorithms remains small. It can be observed that the wide diversity of the testbeds makes the goal of locating the collections with the greatest number of documents under every condition rather difficult. Nonetheless, the newly proposed algorithm has a more stable and effective performance across all testbeds, and is able to locate collections with the greatest number of documents equally or better than other state-of-the-art source selection algorithms. The above results indicate that the mod-eling of collections as integrals in the rank-relevance space does have some merit. 5.2. Precision-oriented settings
The results from precision-oriented environments, where the precision of the final, merged list is of importance, are pre-sented in Tables 3 X 5 . In the Uniform testbed ( Table 3 ), both CiSS algorithms are more effective than other source selection algorithms. CiSS-HiPre also performs better than CiSS-HiRe and is able to maintain a high retrieval effectiveness even in low-er ranks, despite the fact that it has 40% less documents available for merging. It is noteworthy that CiSS-HiPre is the only algorithm that attains a statistically significant better performance at this testbed than ReDDE, indicating the effectiveness of the segmentation of the collection integrals and the maximization the estimated gain of retrieving the top-ranked docu-ments from remote collections.

In the Representative and the Relevant testbeds ( Table 3 , right and 4, left respectively), both CiSS algorithms perform effectively indicating that they are both able to correctly identify the two collections containing most of the relevant documents.Aspreviously,the results mayhave been dueto apreferenceof the algorithmsforbigger collections,butthe results from the NonRelevant testbed ( Table 4 ), where additionally CiSS-HiPre is able to produce a statistically significant improve-ment over the baseline, show that this is not the case.

CORI and the CRCS family of algorithms produce a statistically worse performance than ReDDE at the Representative and the Relevant testbeds, indicating the importance of an effective utilization of collection sizes (CORI makes no provisions for collection size) at testbeds with skewed collection sizes where most of the relevant documents are concentrated at a limited number of sources. At the NonRelevant testbed nonetheless, CORI is as effective as CiSS-HiPre.

CiSS-HiPre is also particularly effective in the Kmeans testbed ( Table 5 ), especially in comparison to CiSS-HiRe. The CRCS family of algorithms are also very effective in this testbed, with CRCS(e) being particularly effective at P@5. It is noteworthy pointing out that CRCS(l) that attains better recall at this testbed ( Fig. 11 ) does not perform as well in precision-oriented settings. The results show, as previously stated, that often a high-recall effectiveness does not necessarily translate into a high-precision performance. The results are in agreement with findings by Craswell (2000) and Si and Callan (2004) .
The relatively low effectiveness of all the algorithms in the Web testbed ( Table 5 ), is due to the fact that the distribution of relevant documents in this testbed is particularly skewed. The CRCS family of algorithms and CiSS-HiPre are slightly more effective in this testbed, although the differences observed are small and not statistically significant, due to the non-trivial number of queries that returned few relevant documents.

It can be concluded that the new algorithm and in particular CiSS-HiPre, provides a robust solution to the high-precision problem in federated search environments being better or at least as effective as other state-of-the-art source selection algo-rithms, in the majority of settings, especially considering that the algorithm utilized 100 documents, instead of 140, a reduc-tion of approximately 28%. 5.3. Parameter variation
All the results with CiSS-HiPre that have been presented so far in the paper make use of the initially set values of the parameters a , b and c as described in Section 4 . In this part of the paper we test the sensitivity of the algorithm in regard to those values by presenting results from all available testbeds with altered parameter values. We would like to note that our aim is not to explore the parameter space in a full, comprehensive manner, but rather to examine the robustness of the algorithm within a simple, yet diverse enough scheme. We leave the former goal as future work.

Fig. 13 shows a graph of the logistic function used in H i b . As explained in Section 3.2 , the aim of the H i ( x ) function is to model the decrease of relevance of the returned documents from the remote collections. It can be observed that several curves can be obtained by varying the parameter values. For example, using parameter values a = 20 and b = 7.5 models an environment where a lot of relevant documents are expected to be returned in the first 20 ranks, but almost none at ensuing rankings. Since the produced graphs are quite diverse, they were deemed as appropriate for the purposes set forth in this section. We will therefore limit the presented experiments to those values.

Tables 6 and 7 present the results. As previously, measurements in bold and  X  report statistically significant better per-formance compared to ReDDE (paired t -test p &lt; 0.1 and p &lt; 0.05 respectively) and measurements in italic statistically worse performance (paired t -test p &lt; 0.1). We also present results with the initial values of the parameters, for comparison reasons ( Table 6 , left column). For each set of values for parameter sets a and b we also report the respective normalization param-eter c for function H i  X  x  X  that was set at a value to approximate the sum of the series Focusing on the results in Table 6 , it can be observed that using a = 20 and b = 7.5 produces slightly better results at the
Uniform and Relevant testbeds, especially in P@5, while performing slightly worse in the Representative testbed and even more so at the Kmeans testbed. Nonetheless, most of the differences are not statistically significant in comparison with the original reported performance, with the exception of the Kmeans testbed. In addition, most of the original conclusions regarding the performance of the algorithm compared to the ReDDE baseline also remain valid at this setting. Considering the difference between the curves produced by the original parameter values and the one produced by the new values, potentially demonstrates that the algorithm remains effective in a wide range of parameter values.

The results in Table 7 are also very interesting. Using parameters a = 4 and b = 0.75 produces better results at the Relevant testbed, but the original values produce better results at the rest of the testbeds. On the contrary, using values a = 0.6 and b = 0.75 steadily results in better performance in all testbeds. The fact that the curve produced by the above values ( Fig. 13 )is the steepest, potentially provides an indication that the assumption that most of the relevant documents returned from the remote collections can be found at the top few ranks may hold some merit.

Overall, the results demonstrate that although changing the parameter values of the CiSS-HiPre algorithm produces slightly different scores, as expected, the algorithm remains relatively robust across all testbeds. Additionally, the results indicate that a more thorough investigation of the parameter space may produce even better results. Future work will focus on automatic setting of the parameter values, taking into consideration the expected distribution of scores of the returned documents ( Robertson, 2007; Nottelmann &amp; Fuhr, 2003b, 2003c ), as well as the distribution of collection sizes and poten-tially the effectiveness of the retrieval algorithm employed by the remote collections. 6. Conclusions and future work
In this paper, a new source selection algorithm for uncooperative distributed information retrieval environments was presented. The algorithm is based on modeling each collection as in integral in the rank-relevance space of its sampled doc-uments. Based on the above novel metric, the algorithm explicitly focuses on addressing the two goals of source selection; high-recall , which is important for source recommendation applications and high-precision which is important for the quality of the final merged result list.

In the experiments that were conducted it was demonstrated that the algorithm is equally or more effective than other state-of-the-art source selection algorithms, both in recall and in precision-oriented settings, overall constituting a very effective solution to the source selection problem. Additional experiments also showed that the algorithm remains compet-itive across a range of parameter values and occasionally performs better.

One of the key novelties of the algorithm, in precision-oriented environments is that it only requires the number of doc-uments in the final merged list be specified by the user, dynamically estimating the number of collections that are selected as well as the number of documents that are retrieved by each. Although no user-oriented studies were conducted we believe that the above feature is very important in realistic DIR environments, where information about the distribution of relevant documents is unknown.

In the future, we intend to investigate and exploit the modeling presented here and its properties more fully, providing a general modeling of collections as integrals in n -dimensional space, based on a number of additional evidence about the appropriateness of collections for selection, such as clickthrough data, past response time, potential occurring costs, effec-tiveness of retrieval etc.

We also aim to produce a methodology of estimating the decline of relevance of the documents in remote collections dynamically during the source selection phase, thus segmenting the x -axis individually for each collection. Additionally, we intend to extend the dynamic solution of the CiSS-HiPre algorithm in order to be able to directly limit the maximum number of collections the algorithm selects.
 Acknowledgments
This paper is part of the 03ED404 research project, implemented within the framework of the  X  X  X einforcement Programme of Human Research Manpower X  (PENED) and co-financed by National and Community Funds (25% from the Greek Ministry of Development  X  General Secretariat of Research and Technology and 75% from EU  X  European Social Fund).

Additionally, we would like to thank the anonymous reviewers for their very valuable comments. Their input has consid-erably increased the quality of this paper.
 References
