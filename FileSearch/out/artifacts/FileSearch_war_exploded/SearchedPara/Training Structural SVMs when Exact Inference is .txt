 Thomas Finley tomf@cs.cornell.edu Thorsten Joachims tj@cs.cornell.edu Discriminative training methods like conditional ran-dom fields (Lafferty et al., 2001), maximum-margin Markov networks (Taskar et al., 2003), and struc-tural SVMs (Tsochantaridis et al., 2005) have substan-tially improved prediction performance on a variety of structured prediction problems, including part-of-speech tagging (Altun et al., 2003), natural language parsing (Tsochantaridis et al., 2005), sequence align-ment (Yu et al., 2007), and classification under multi-variate loss functions (Joachims, 2005). In the context of structural SVMs, in all these problems, both the in-ference problem (i.e., computing a prediction) and the separation oracle required in the cutting-plane training algorithm can be solved exactly. This leads to theoret-ical guarantees of training procedure convergence and solution quality.
 However, in many important problems (e.g., cluster-ing (Culotta et al., 2007; Finley &amp; Joachims, 2005), multi-label classification, image segmentation, ma-chine translation) exact inference and the separation oracle are computationally intractable. Unfortunately, use of approximations in these settings abandons many of the existing theoretical guarantees of structural SVM training, and relatively little is known about dis-criminative training using approximations.
 This paper explores training structural SVMs on prob-lems where exact inference is intractable. A pairwise fully connected Markov random field (MRF) serves as a representative class of intractable models. This class includes natural formulations of models for multi-label classification, image segmentation, and cluster-ing. We identify two classes of approximation algo-rithms for the separation oracle in the structural SVM cutting-plane training algorithm, namely undergener-ating and overgenerating algorithms, and we adapt loopy belief propagation (LBP), greedy search, and linear-programming and graph-cut relaxations to this problem. We provide a theoretical and empirical anal-ysis of using these algorithms with structural SVMs. We find substantial differences between different ap-proximate algorithms in training and inference. In particular, much of the existing theory can be ex-tended to overgenerating though not undergenerat-ing methods. In experimental results, intriguingly, our structural SVM formulations using the overgen-erating linear-programming and graph-cut relaxations successfully learn models in which relaxed inference is  X  X asy X  (i.e., the relaxed solution is mostly integral), leading to robust and accurate models. We conclude that the relaxation formulations are preferable over the formulations involving LBP and greedy search. Algorithm 1 Cutting plane algorithm to solve OP 1. 1: Input: ( x 1 , y 1 ) ,..., ( x n , y n ), C , 2: S i  X  X  X  for all i = 1 ,...,n 3: repeat 4: for i = 1 ,...,n do 5: H ( y )  X   X ( y i , y )+ w T  X  ( x i , y )  X  w T  X  ( x i 6: compute  X  y = argmax y  X  X  H ( y ) 7: compute  X  i = max { 0 , max y  X  S i H ( y ) } 8: if H (  X  y ) &gt;  X  i + then 9: S i  X  S i  X  X   X  y } 10: w  X  optimize primal over S i S i 11: end if 12: end for 13: until no S i has changed during iteration Several discriminative structural learners were pro-posed in recent years, including conditional ran-dom fields (CRFs) (Lafferty et al., 2001), Perceptron HMMs (Collins, 2002), max-margin Markov networks (M 3 Ns) (Taskar et al., 2003), and structural SVMs (SSVMs) (Tsochantaridis et al., 2005). Notational differences aside, these methods all learn (kernelized) linear discriminant functions, but differ in how they choose model parameters. 2.1. Structural SVMs Structural SVMs minimize a particular trade-off be-tween model complexity and empirical risk. From a training set S = (( x 1 , y 1 ) ,..., ( x n , y n )), an SSVM learns a hypothesis h : X  X  Y to map inputs x  X  X to outputs y  X  Y . Hypotheses take the form h ( x ) = argmax y  X  X  f ( x , y ) with discriminant function f : X  X Y  X  R , where f ( x , y ) = w T  X  ( x , y ). The  X  combined feature vector function relates inputs and outputs, and w are model parameters. The loss func-tion  X  : Y  X Y  X  R indicates how far h ( x i ) is from true output y i . To find w balancing model complex-ity and empirical risk R  X  S ( h ) = 1 n P n i =1  X ( y i ,h ( x SSVMs solve this quadratic program (QP) (Tsochan-taridis et al., 2005): Optimization Problem 1. (Structural SVM) min  X  i,  X  y  X  X \ y i : w T  X  ( x i , y i )  X  w T  X  ( x i , y )+ X ( y Introducing a constraint for every wrong output is typ-ically intractable. However, OP 1 can be solved by the cutting plane algorithm in Algorithm 1. This it-eratively constructs a sufficient subset S i S i of con-straints and solves the QP only over this subset (line 10). The algorithm employs a separation oracle to find the next constraint to include (line 6). It finds the cur-rently most violated constraint (or, a constraint that is violated by at least the desired precision ). If a polynomial time separation oracle exists, OP 1 and Al-gorithm 1 have three theoretical guarantees (Tsochan-taridis et al., 2005): Polynomial Time Termination: Algorithm 1 ter-minates in a polynomial number of iterations, and thus overall polynomial time.
 Correctness: Algorithm 1 solves OP 1 accurate to a desired precision , since Algorithm 1 terminates only when all constraints in OP 1 are respected within (lines 8 and 13).
 Empirical Risk Bound: Since each  X  i upper bounds training loss  X ( y i ,h ( x i )), 1 n P n i =1  X  i bounds empirical risk.
 Unfortunately, proofs of these properties rely on the separation oracle (line 6) being exactly solvable, and do not necessarily hold with approximations. We will later analyze which properties are retained. 2.2. Markov Random Fields in SSVMs A special case of structural SVM that we will examine throughout this paper is M 3 N (Taskar et al., 2003). In this,  X  ( x , y ) is constructed from an MRF with graph structure G = ( V,E ) and the loss func-tion is restricted to be linearly decomposable in the cliques, i.e.,  X ( y ,  X  y ) = P k  X  cliques ( G )  X  k ( y Here, y is the value assignment to variables,  X  k are sub-component local loss functions, and  X  k are po-tential functions representing the fitness of variable assignment y { k } to clique k . The network potential f ( x , y ) serves as a discriminant function representing the variable assignment y in the structural SVM, and h ( x ) = argmax y  X  X  f ( x , y ) serves as the maximum a posteriori (MAP) prediction.
 OP 1 requires we express (3) in the form f ( x , y ) = w T  X  ( x , y ). First express potentials as  X  k ( y { k } ) = w T  X  ( x ,y { k } ). The feature vec-tor functions  X  k relate x and label assignments y { k } . Then, f ( x , y ) = w T  X  ( x , y ) where  X  ( x , y ) = P In the following, we use a particular linearly decom-posable loss function that simply counts the percent-age proportion of different labels in y and  X  y , i.e., cations, labels are binary (i.e., each y u  X  B = { 0 , 1 } ), and we allow only  X  u (1) and  X  uv (1 , 1) potentials to be non-zero. This latter restriction may seem oner-ous, but any pairwise binary MRF with non-zero  X  (0) , X  uv (0 , 0) , X  uv (0 , 1) , X  uv (1 , 0) has an equivalent MRF where these potentials are zero.
 To use Algorithm 1 for MRF training and prediction, one must solve two argmax problems: Prediction: argmax y  X  X  w T  X  ( x , y ) Separation Oracle: argmax y  X  X  w T  X  ( x , y )+ X ( y i , y ) The prediction problem is equivalent to MAP infer-ence. Also, we can state the separation oracle as MAP inference. Taking the MRF we would use to solve argmax y  X  X  w T  X  ( x , y ), we include  X ( y i , y ) in the argmax by incrementing the node potential  X  u ( y ) by 100 | V | for each wrong value y of u , since each wrong variable assignment increases loss by 100 | V | . Thus, we may express the separation oracle as MAP inference. Unfortunately, MAP inference is # P -complete for gen-eral MRFs. Fortunately, a variety of approximate in-ference methods exist. For prediction and the separa-tion oracle, we explore two general classes of approxi-mate inference methods, which we call undergenerat-ing and overgenerating approximations. 3.1. Undergenerating Approximations Undergenerating methods approximate argmax y  X  X  by argmax y  X  X  , where Y  X  Y . We consider the following undergenerating methods in the context of MRFs: Greedy iteratively changes the single variable value y u that would increase network potential most. LBP is loopy belief propagation (Pearl, 1988). Combine picks the assignment y with the highest network potential from both greedy and LBP.
 We now theoretically characterize undergenerating learning and prediction. All theorems generalize to any learning problem, not just MRFs. Due to space constraints, provided proofs are proof skeletons. Since undergenerating approximations can be arbi-trarily poor, we must restrict our consideration to a subclass of undergenerating approximations to make meaningful theoretical statements. This analysis fo-cuses on  X  -approximation algorithms, with  X   X  (0 , 1]. What is a  X  -approximation? In our case, for predic-tive inference, if y  X  = argmax y w T  X  ( x , y ) is the true optimum and y 0 the  X  -approximation output, then Similarly, for our separation oracle, for y  X  = argmax y w T  X  ( x , y ) +  X ( y i , y ) as the true optimum, and if y 0 corresponds to the constraint found by our  X  -approximation, we know  X  w T  X  ( x , y  X  )+ X ( y i , y  X  )  X  w T  X  ( x , y 0 )+ X ( y For simplicity, this analysis supposes S contains ex-actly one training example ( x 0 , y 0 ). To generalize, one may view n training examples as 1 example, where in-ference consists of n separate processes with combined outputs, etc. Combined  X  -approximation outputs may be viewed as a single  X  -approximation output. Theorem 1. (Polynomial Time Termination) If  X  R = max i, y  X  X  k  X ( x i , y ) k ,  X   X  = max i, y  X  X  k  X ( y are finite, an undergenerating learner terminates after adding at most  X  2 ( C  X   X  2  X  R 2 + n  X   X ) constraints. Proof. The original proof holds as it does not depend upon separation oracle quality (Algorithm 1, l.6). Lemma 1. After line 6 in Algorithm 1, let w be the current model,  X  y the constraint found with the  X  -approximation separation oracle, and  X   X  = H (  X  y ) the slack associated with  X  y . Then, w and slack  X  Proof. If we knew the true most violated constraint y , we would know the minimum  X   X  such that w , X   X  was feasible in OP 1. The proof upper bounds  X   X  . Theorem 2. When iteration ceases with the result w , X  , if  X  y was the last found most violated constraint, we know that the optimum objective function value v  X  for OP 1 lies in the interval k w k 2 + C X   X  v  X   X  Proof. Lemma 1 applied to the last iteration. So, even with  X  -approximate separation oracles, one may bound how far off a final solution is from solving OP 1. Sensibly, the better the approximation, i.e., as  X  approaches 1, the tighter the solution bound. The last result concerns empirical risk. The SVM mar-gin attempts to ensure that high-loss outputs have a low discriminant function value, and  X  -approximations produce outputs within a certain factor of optimum. Theorem 3. (  X  -Approximate Empirical Risk) For w , X  feasible in OP 1 from training with single ex-ample ( x 0 , y 0 ) , the empirical risk using  X  -approximate prediction has upper bound (1  X   X  ) w T  X  ( x 0 , y 0 ) +  X  . Proof. Take the y 0 = h ( x 0 ) associated constraint, then apply known bounds to its w T  X  ( x 0 , y 0 ) term. If also using undergenerating  X  -approximate training, one may employ Theorem 2 to get a feasible  X  . 3.2. Overgenerating Approximations Overgenerating methods approximate argmax y  X  X  by argmax y  X  Y , where Y  X  Y . We consider the following overgenerating methods: LProg is an expression of the inference problem as a relaxed integer linear program (Boros &amp; Hammer, 2002). We first add y uv  X  B values indicating if y u = y v = 1 to linearize the program: We relax B to [0 , 1] to admit fractional solutions.
Importantly, there is always some optimal solution where all y u ,y uv  X  X  0 , 1 2 , 1 } (Hammer et al., 1984). Cut is quadratic pseudo-Boolean optimization using a graph-cut (Kolmogorov &amp; Rother, 2004). This is a different relaxation where, instead of y  X  B | V | , we have y  X  X  0 , 1 ,  X  } | V | .
 The LProg and Cut approximations share two im-portant properties (Boros &amp; Hammer, 2002; Hammer et al., 1984): Equivalence says that maximizing so-lutions of the Cut and LProg formulations are trans-mutable. One proof defines this transmutation proce-dure, where  X  (in cuts optimization) and 1 2 (in LP optimization) variable assignments are interchange-able (Boros &amp; Hammer, 2002). The important practi-cal implication of equivalence is both approximations return the same solutions. Persistence says unambigu-ous labels (i.e., not fractional or  X  ) are optimal labels. As a final detail, in the case of LProg, P Cut X  X  functions have similar formulations.
 Theorem 4. (Polynomial Time Termination) If  X  are finite ( Y replacing Y in the overgenerating case), an overgenerating learner terminates after adding at most  X  2 ( C  X   X  2  X  R 2 + n  X   X ) constraints. Proof. The original proof holds as an overgenerating learner is a straightforward structural learning prob-lem on a modified output range Y .
 Theorem 5. (Correctness) An overgenerating Al-gorithm 1 terminates with w , X  feasible in OP 1. Proof. The learner considers a superset of outputs Y  X  Y , so constraints in OP 1 are respected within . With these  X  X xtra X  constraints from overgenerating inference, Algorithm 1 X  X  solution may be suboptimal w.r.t. the original OP 1. Further, for undergenerat-ing methods correctness does not hold, as Algorithm 1 may not find violated constraints present in OP 1. Theorem 6. (Empirical Risk Bound) If prediction and the separation oracle use the same overgenerating algorithm, Algorithm 1 terminates with 1 n P i  X  i upper bounding empirical risk R  X  S ( h ) .
 Proof. Similar to the proof of Theorem 4. 3.3. Related Work In prior work on discriminative training using approx-imate inference, structural SVMs have learned mod-els for correlation clustering, utilizing both greedy and LP relaxed approximations (Finley &amp; Joachims, 2005). For M 3 Ns, Anguelov et al. (Anguelov et al., 2005) pro-posed to directly fold a linear relaxation into OP 1. This leads to a very large QP, and is inapplicable to other inference methods like LBP or cuts. Further-more, we will see below that the linear-program re-laxation is the slowest method. With CRFs, likeli-hood training requires computing the partition func-tion in addition to MAP inference. Therefore, the par-tition function is approximated (Culotta et al., 2007; He et al., 2004; Kumar &amp; Hebert, 2003; Vishwanathan et al., 2006), or the model is simplified to make the par-tition function tractable (Sutton &amp; McCallum, 2005), or CRF max-likelihood training is replaced with Per-ceptron training (Roth &amp; Yih, 2005).
 The closest work to ours is a theoretical analysis of MRF structural learning with LBP and LP-relaxation approximations (Kulesza &amp; Pereira, 2007). It defines the concepts separable (i.e., there exists w such that  X  ( x i , y i )  X  S , y  X  Y , w T  X  ( x i , y i )  X  w T  X  ( x gorithmically separable (i.e., there exists w so that em-pirical risk under the inference algorithm is 0), and learnable (i.e., the learner using the inference method finds a separating w ). The paper illustrates that using approximate inference, these concepts are not equiv-alent. Our work X  X  major differences are our analy-sis handles non-zero training error, generalizes to any structural problem, uses structural SVMs, and we have an empirical analysis. Before we move into learning experiments, it helps to understand the runtime and quality performance char-acteristics of our MAP inference algorithms.
 For runtime, Figure 1 illustrates each approximate in-ference method X  X  average time to solve a single pair-wise fully connected MRF with random potentials as the number of nodes increases. 1 Note that cuts are substantially faster than LBP, and several orders of magnitude faster than the linear relaxation while maintaining equivalence.
 For evaluating solution quality, we generate 1000 ran-dom problems, ran the inference methods, and exhaus-tively count how many labelings with higher discrim-inant value exist. The resulting curve for 10-node MRFs is shown in Figure 2. For cut,  X  labels are randomly assigned to 0 or 1. The lower the curve, the better the inference method. LBP finds  X  X erfect X  labelings more often than Greedy, but also tends to fall into horrible local maxima. Combined does much better than either alone; apparently the strengths of Greedy and LBP are complimentary.
 Finally, note the apparent terrible performance of Cut, which is due to assigning many  X  labels. At first glance, persistence is an attractive property since we know unambiguous labels are correct, but on the other hand, classifying only when it is certain leads it to leave many labels ambiguous. Our goal in the following experiments is to gain insight about how different approximate MRF inference meth-ods perform in SSVM learning and classification. Our evaluation uses multi-label classification using pairwise fully connected MRFs as an example application. Multi-label classification bears similarity to multi-class classification, except classes are not mutually exclu-sive, e.g., a news article may be about both  X  X raq X  and  X  X il. X  Often, incorporating inter-label dependen-cies into the model can improve performance (Cesa-Bianchi et al., 2006; Elisseeff &amp; Weston, 2002). How do we model this labeling procedure as an MRF? For each input x , we construct an MRF with a vertex for each possible label, with values from B = { 0 , 1 } (1 indicates x has the corresponding label), and an edge for each vertex pair (i.e., complete graph MRF). What are our potential functions? In these problems, inputs x  X  R m are feature vectors. Each of the ` possible labels u is associated with a weight vector w u  X  R m . The resulting vertex potentials are  X  u (1) = w u T x . Edge potentials  X  uv (1 , 1) come from individual values in w , one for each label pair. Thus, the overall parameter vector w  X  R `m + ( ` 2 ) has `m weights for the ` different w 1 , w 2 ,..., w ` sub-component weight vec-tors, and ` 2 parameters for edge potentials. In terms of  X  functions,  X  u ( x , 1) vectors contain an offset ver-sion of x to  X  X elect out X  w u from w , and  X  uv ( x , 1 , 1) vectors have a single 1 entry to  X  X elect X  the appropri-ate element from the end of w . 5.1. Datasets and Model Training Details We use six multi-label datasets to evaluate perfor-mance. Table 1 contains statistics on these datasets. Four real datasets, Scene (Boutell et al., 2004), Yeast (Elisseeff &amp; Weston, 2002), Reuters (the RCV1 subset 1 data set) (Lewis et al., 2004), and Me-diamill (Snoek et al., 2006), came from the LIBSVM multi-label dataset collection (Chang &amp; Lin, 2001). Synth1 is a synthetic dataset of 6 labels. Labels fol-low a simple probabilistic pattern: label i is on half the time label i  X  1 is on and never otherwise, and label 1 is always on. Also, each label has 1000 related bi-nary features (the learner does not know a priori which feature belong to each label): if i is on, a random 10 of its 1000 are set to 1. This hypothesis is learnable without edge potentials, but exploiting label depen-dency structure may result in better models. Synth2 is a synthetic dataset of 10 labels. In this case, each example has exactly one label on. There are also 40 features. For an example, if label i is on, 4 i randomly chosen features are set to 1. Only models with edge potentials can learn this concept.
 We used 10-fold cross validation to choose C from 14 possible values { 1  X  10  X  2 , 3  X  10  X  2 , 1  X  10  X  1 This C was then used when training a model on all training data. A separate C was chosen for each dataset and separation oracle. 5.2. Results and Analysis Table 2 reports loss on the test set followed by stan-dard error. For each dataset, we present losses for each combination of separation oracle used in learning (the rows) and of predictive inference procedure used in classification (the columns). This lets us distinguish badly learned models from bad inference procedures as explanations for inferior performance.
 We also employ three additional methods as a point of comparison. Our Baseline is an MRF with no edge potentials, and our Default classifier always predicts the best-performing single labeling; results for these appear in Table 1. The Exact classifier is one which exhaustively searches for the argmax; to enable com-parisons on Reuters and Mediamill, we pruned these datasets to the 10 most frequent labels.
 Cut is omitted from Table 2. Its equivalence to LProg means the two are interchangeable and always produce the same results, excepting Cut X  X  superior speed. In all datasets, some edged model always exceeds the performance of the edgeless model. On Mediamill and Reuters, selecting only the 10 most frequent labels robs the dataset of many dependency relationships, which may explain the relatively lackluster performance. 5.2.1. The Sorry State of LBP, but Relax Let X  X  first examine the diagonal entries in Table 2. Models trained with LBP separation oracles yield gen-erally poor performance. What causes this? LBP X  X  tendency to fall into horrible local maxima (as seen in Section 4) misled Algorithm 1 to believe its most violated constraint was not violated, leading it to early termination, mirroring the result in (Kulesza &amp; Pereira, 2007). The combined method remedies some of these problems; however, LProg still gives signifi-cantly better/worse performance on 3 vs. 1 datasets. How does LProg training compare against exact train-ing? Table 2 shows that both methods give similar performance. Exact-trained models significantly out-perform relaxed-trained models on two datasets, but they also lose on two datasets. 5.2.2. Relaxation in Learning and Prediction Observe that relaxation used in prediction performs well when applied to models trained with relaxation. However, on models trained with non-relaxed meth-ods (i.e., models that do not constrain fractional solu-tions), relaxed inference often performs quite poorly. The most ludicrous examples appear in Yeast, Reuters, Mediamill, and Synth2. Table 3 suggests an explana-tion for this effect. The table lists the percentage of ambiguous labels from the relaxed classifier (fractional in LProg,  X  in Cut). Ignoring degenerate LBP-trained models, the relaxed predictor always has the fewest ambiguous judgments. Apparently, SSVMs with re-laxed separation oracles produce models that disfavor non-integer solutions. In retrospect this is unsurpris-ing: ambiguous labels always incur loss during train-ing. Minimizing loss during training therefore not only reduces training error, but also encourages parame-terizations that favor integral (i.e., exact) solutions. Undergenerating and exact training do not control for this, leading to relaxed inference yielding many am-biguous labelings.
 On the other hand, observe that models trained with the relaxed separation oracle have relatively consistent performance, irrespective of the classification inference procedure; even LBP never shows the catastrophic fail-ure it does with other training approximations and even exact training (e.g., Mediamill, Synth2). Why might this occur? Recall the persistence property from Section 3: unambiguous labels are optimal labels. In some respects this property is attractive, but Section 4 revealed its dark side: relaxation predictors are very conservative, delivering unambiguous labels only when they are certain . By making things  X  X bvious X  for the relaxed predictors (which are the most conservative w.r.t. what they label), it appears they simultaneously make things obvious for all predictors, explaining the consistent performance of relaxed-trained models re-gardless of prediction method.
 SSVM X  X  ability to train models to  X  X dapt X  to the weak-ness of overgenerating predictors is an interesting com-plement with Searn structural learning (Daum  X e III et al., 2006), which trains models to adapt to the weak-nesses of undergenerating search based predictors. 5.2.3. Known Approximations How robust is SSVM training to an increasingly poor approximate separation oracle? To evaluate this, we built an artificial  X  -approximation separation oracle: for example ( x i , y i ) we exhaustively find the optimal y  X  = argmax way, we build an approximate undergenerating MRF inference method with known quality.
 Table 4 details these results. The first column indi-cates the approximation factor used in training each model for each dataset. The remaining columns show train and test performance using exact inference. What is promising is that test performance does not drop precipitously as we use increasingly worse ap-proximations. For most problems, the performance remains reasonable even for  X  = 0 . 9. This paper theoretically and empirically analyzed two classes of methods for training structural SVMs on models where exact inference is intractable. Focus-ing on completely connected Markov random fields, we explored how greedy search, loopy belief propa-gation, a linear-programming relaxation, and graph-cuts can be used as approximate separation oracles in structural SVM training. In addition to a theoreti-cal comparison of the resulting algorithms, we empir-ically compared performance on multi-label classifica-tion problems. Relaxation approximations distinguish themselves as preserving key theoretical properties of structural SVMs, as well as learning robust predictive models. Most significantly, structural SVMs appear to train models to avoid relaxed inference methods X  tendency to yield fractional, ambiguous solutions. Acknowledgments This work was supported under NSF Award IIS-0713483 and through a gift from Yahoo! Inc.
 References
