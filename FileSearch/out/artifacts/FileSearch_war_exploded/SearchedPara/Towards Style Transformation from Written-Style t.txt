 We live in a world with an ever increasing amount and variety of information. A great deal of that con-tent is in a textual format. Mobile technologies have increased our expectations as to when, where, and how we can access such content. As such, it is not uncommon to want to gain access to this information when a visual display is not convenient or available (while driving or walking for example). One way of addressing this issue is to use audio displays and, in particular, have users listen to content read to them by a speech synthesizer instead of reading it them-selves on a display.

While listening to speech opens many opportu-nities, it also has issues which must be considered when using it as a replacement for reading. One im-portant consideration is that the text that was origi-nally written to be read might not be suitable to be listened to. Journalists, for example, write differ-ently for audio (i.e. radio news broadcast) compared to writing content meant to be read (i.e. newspaper articles) (Fang, 1991).

One key reason for the difference is that under-standing is more important than grammar to a radio news writer. Furthermore, audio has different per-ceptual and information qualities compared to read-ing. For example, the use of the negations not and no should be limited since it is easy for listeners to miss that single utterance. Listener cannot relisten to a word; and, missing it has a huge impact on mean-ing.

In this paper, we address the problem of changing the writing-style of text to make it suitable to being listened to instead of being read.

We start by researching the writing-style differ-ences across text and audio in the linguistics and journalism literatures. Based on this study, we sug-gest a number of linguistic features that set the two styles apart. We validate these features statistically by analyzing their distributions in a corpus of paral-lel text-and audio-style documents; and experimen-tally through a style classification task. Moreover, we evaluate the impact of style transformation on the user experience by conducting a user study.
The rest of this paper is organized as follows. In the next section, we examine the related work. In Section 3, we summarize the main style differences as they appear in the journalism and linguistics lit-eratures. In Section 4, we describe the data that we collected and used in this work. The features that we propose and their validation are discussed in Section 5. In Section 6, we describe the user study and dis-cuss the results. We conclude in Section 7. There has been a considerable amount of research on the language variations for different registers and genres in the linguistics community, including re-search that focused on the variations between writ-ten and spoken language (Biber, 1988; Halliday, 1985; Esser, 1993; Whittaker et al., 1998; Esser, 2000). For example, Biber (1988) provides an ex-haustive study of such variations. He uses compu-tational techniques to analyze the linguistic charac-teristics of twenty-three spoken and written genres, enabling identification of the basic, underlying di-mensions of variation in English.

Halliday (1985) performs a comparative study of spoken and written language, contrasting the prosodic features and grammatical intricacy of speech with the high lexical density and grammat-ical metaphor or writing. Esser (2000) proposes a general framework for the different presentation structures of medium-dependent linguistic units.
Most of these studies focus on the variations be-tween the written and the spontaneous spoken lan-guage. Our focus is on the written language for audio, i.e. on a style that we hypothesize being somewhere between the formally written and spon-taneous speech styles. Fang (1991) provides a prag-matic analysis and a side-by-side comparisons of the  X  X riting style differences in newspaper, radio, and television news X  as part of the instructions for jour-nalist students learning to write for the three differ-ent mediums.

Paraphrase generation (Barzilay and McKeown, 2001; Shinyama et al., 2002; Quirk et al., 2004; Power and Scot, 2005; Zhao et al., 2009; Madnani and Dorr, 2010) is related to our work, but usually the focus has been on the semantics, with the goal of generating relevant content, and on the syntax to generate well formed text. In this work the goal is to optimize the style, and generation is one approach to that end (we plan addressing it for future work)
Authorship attribution (Mosteller and Wallace, 1964; Stamatatos et al., 2000; Argamon et al., 2003; Argamon et al., 2007; Schler and Argamon, 2009) is also related to our work since arguably differ-ent authors write in different styles. For exam-ple, Argamon et al. (2003) explored differences between male and female writing in a large sub-set of the British National Corpus covering a range of genres. Argamon el al. (2007) addressed the problem of classifying texts by authors, author per-sonality, gender of literary characters, sentiment (positive/negative feeling), and scientific rhetorical styles. They used lexical features based on tax-onomies of various semantic functions of different lexical items (words or phrases). These studies fo-cused on the correlation between style of the text and the personal characteristics of its author. In our work, we focus on the change in writing style ac-cording to the change of the medium. In this section, we summarize the literature on writ-ing style differences across text and audio. Style dif-ferences are not due to happenstance. Writing styles for different media have evolved due to the unique nature of each medium and to the manner in which its audience consumes it. For example, in audio, the information must be consumed sequentially and the listener does not have the option to skip the informa-tion that she finds less interesting.

Also, the listener, unlike the reader, cannot stop to review the meaning of a word or a sentence. The eye skip around in text but there is not that option with listening. Moreover, unlike attentive readers of text, audio listeners may be engaged in some task (e.g. driving, working, etc.) other than absorbing the information they listen to, and therefore are paying less attention.

All these differences of the audio medium affect the length of sentences, the choice of words, the structure of phrases of attribution, the use of pro-nouns, etc.

Some general guidelines of audio style (Biber, 1988; Fang, 1991) include 1) the choice of sim-ple words and short, declarative sentences with ac-tive voice preferred. 2) Attribution precedes state-ments as it does in normal conversations. 3) The subject should be as close to the predicate as feasi-ble. 4) Pronouns should be used with a lot of wari-ness. It is better to repeat a name, so that the lis-tener will not have to pause or replay to recall. 5) Direct quotations are uncommon and the person be-ing quoted is identified before the quotation. 6) De-pendent clauses should be avoided, especially at the start of a sentence. It is usually better to make a sep-arate sentence of a dependent clause. 7) Numbers should be approximated so that they can be under-stood. For example, the sum of $52,392 could be stated as more than fifty thousand dollars . 8) Adjec-tives and adverbs should be used only when neces-sary for the meaning. In order to determine the differences between the text and audio styles, we needed textual data that ideally covered the same semantic content but was produced for the two different media. National Public Radio (NPR) has exactly this type of data. Through their APIs we obtained the same semantic content in the two different styles: written text style (articles, henceforth) and in audio style (transcripts, henceforth). The NPR Story API output contains links to the Transcript API when a transcript is avail-able. With the Transcript API, we were able to get full transcripts of stories heard on air 1 . To the best of our knowledge, this is the first use of this collection for NLP research.

We collected 3855 news articles and their corre-sponding transcripts. The data cover a varied set of topics from four months of broadcast (from March 6 to June 3, 2010). Table 2 shows an example of such article-transcript pairs. Based on the study of style differences outlined in section 3, we propose a number of document-level, linguistic features that we hypothesized distinguish the two writing styles. We extracted these fea-tures for each article and transcript. The analysis of these features (will be discussed later in the sec-tion) showed that they are of different importance to style identification. Table 1 shows a list of the top features and their descriptions. 5.1 Statistical Analysis The goal of this analysis is to show that the values of the features that we extracted are really different across the two styles and that the difference is sig-nificant. We compute the distribution of the values of each feature in articles and its distribution in tran-scripts. For example, Figure 1 shows the distribu-tions of 3 features for both articles and transcripts. The figure clearly shows how the distributions are different. A two-tailed paired Student X  X  T-test (with alpha set to 0.05) reveals statistically significant dif-ference for all of the features (p &lt; 0.0001).
This analysis corroborated our linguistic hypothe-ses, such as the average sentence length is longer for articles than for transcripts, complex words (more than 3 syllables) are more common in articles, arti-cles contain more adverbs, etc. 5.2 Classification To further verify that our features really distinguish between the two writing styles, we conducted a clas-sification experiment. We used the features de-scribed in Table 1 (excluding the Direct Quotation feature) and the dataset described in section 4 to train a classifier. We used Libsvm (Chang and Lin, 2001) with a linear kernel as our classifier. We per-formed 10-fold cross validation on the entire dataset. Our classifier achieved 87.4% accuracy which is high enough to feel confident about the features.
We excluded the Direct Quotation feature from this experiment because it is a very distinguishing feature for articles. The vast majority of the articles in our dataset contained direct quotations and none of the transcripts did. When this feature is included, the accuracy rises to 97%.

To better understand which features are more im-portant indicators of the style, we use Guyon et al. X  X  (2002) method for feature selection using SVM to rank the features based on their importance. The ranks are shown in the last column in Table 1. Up to this point, we know that there are differences in style between articles and transcripts, and we for-malized these differences in the form of linguistic features that are easy to extract using computational techniques. However, we still do not know the im-pact of changing the style on the user experience. To address this issue, we did manual transformation of style for 50 article paragraphs. The transformation was done in light of the features described in the pre-vious section. For example, if a sentence is longer than 25 words, we simplify it; and, if it is in passive voice we change it to active voice whenever possi-ble, etc. We used a speech synthesizer to convert the original paragraphs and their transformed versions into audio clips. We used these audio clips to con-duct a user study.

We gave human participants the audio clips to lis-ten to and transcribe. Each audio clip was divided into segments 15 seconds long. Each segment can be played only once and pauses automatically when it is finished to allow the user to transcribe the seg-ment. The user was not allowed to replay any seg-ment of the clip. Our hypothesis for this study is that audio clips of the transformed paragraphs (audio style) are easier to comprehend, and hence, easier to transcribe than the original paragraphs (text style). We use the edit distance between the transcripts and the text of each audio clip to measure the transcrip-tion accuracy. We assume that the transcription ac-curacy is an indicator for the comprehension level, i.e. the higher the accuracy of the transcription the higher the comprehension.

We used Amazon Mechanical Turk to run the user study. We took several precautions to guarantee the quality of the data (burch, 2009). We restricted the workers to those who have more than 95% approval rate for all their previous work and who live in the United States (since we are targeting English speak-ers). We also assigned the same audio clip to 10 different workers and took the average edit distance of the 10 transcripts for each audio clip.

The differences in the transcription accuracy for the original and the transformed paragraphs were statically significant at the 0.05 level according to a 2-tailed paired t-test. The overall average edit dis-tance was 0.69 for the 50 transformed paragraphs and 0.56 for the original article paragraphs. This re-sult indicates that the change in style has an impact on the comprehension of the delivered information as measured by the accuracy of the transcriptions. In this paper, we presented the progress on an on-going research on writing style transformation from text style to audio style. We motivated the topic and emphasized its importance. We surveyed the lin-guistics and journalism literatures for the differences in writing style for different media. We formalized the problem by suggesting a number of linguistic features and showing their validity in distinguishing between the two styles of interest, text vs audio. We also conducted a user study to show the impact of style transformation on comprehension and the over-all user experience.

The next step in this work would be to build a style transformation system that uses the features discussed in this paper as the bases for determining when, where, and how to do the style transforma-tion.

