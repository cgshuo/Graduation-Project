 In multi-relational databases, a view, which is a context-a nd content-dependent subset of one or more tables (or other views), is often used to preserve privacy by hiding sensitiv e information. However, recent developments in data mining present a new challenge for database security even when tra-ditional database security techniques, such as database ac -cess control, are employed. This paper presents a data min-ing framework using semi-supervised learning that demon-strates the potential for privacy leakage in multi-relatio nal databases. Many different types of semi-supervised learnin g techniques, such as the K-nearest neighbor (KNN) method, can be used to demonstrate privacy leakage. However, we also introduce a new approach to semi-supervised learning, hyperclique pattern based semi-supervised learning (HPSL ), which differs from traditional semi-supervised learning ap -proaches in that it considers the similarity among groups of objects instead of only pairs of objects. Our experimental results show that both the KNN and HPSL methods have the ability to compromise database security, although HPSL is better at this privacy violation than the KNN method. Categories and Subject Descriptors: H.1 [Information Systems-Models and Principles]:Miscellaneous General Terms: Security, Algorithms.
 Keywords: Semi-supervised Learning, Database Security, Hyperclique Patterns, Privacy Preserving Data Mining.
This paper investigates privacy leakage in database views belonging to the same class. In addition, the KNNS method predicts an equal number of objects for each object with a class label; that is, this method gives each labeled object equal weight as a predictor. This may not be appropriate in real-world data sets where, typically, objects from a hig h-density cluster predict more objects with a higher accuracy . In the worst case, a labeled object can be noise or an outlier that is completely unsuitable for prediction.

The TOP-K NNS method. For n given objects with class labels, the TOP-K NNS method finds the k objects with the highest level of similarity from the neighborhood o f these n objects. The TOP-K NNS method assigns different predictive power to different labeled objects. Thus, unlike the KNNS method, the TOP-K NNS method can avoid pre-diction errors that result when some labeled objects are noi se or outliers. However, like KNNS, the prediction mechanism of the TOP-K NNS method is also solely based on pairwise similarity. In real world data sets, it is possible that two objects can be nearest neighbors without belonging to the same class. Therefore, Top-K NNS can also generate many prediction errors.

Hyperclique pattern based semi-supervised learn-ing (HPSL) method. Recently, we have defined a new pattern for association analysis X  X he hyperclique pattern [7] X  that demonstrates a particularly strong connection betwee n the overall similarity of a set of attributes (or objects) an d the itemset (local pattern) in which they are involved. The hyperclique pattern possesses the strong affinity property , i.e.; the attributes (objects) in a hyperclique pattern hav e a guaranteed level of global pairwise similarity to one an-other as measured by the cosine similarity measure. Intu-itively, a hyperclique pattern includes objects which tend to be from the same class category. Based on this observation, we propose a new semi-supervised learning approach, the hyperclique pattern based semi-supervised learning (HPSL ) method. By considering the similarity among all objects in a hyperclique instead of the similarity between only pairs of objects, we can improve semi-supervised learning result s over those based on KNN approaches.

More specifically, for an object with a class label, we find a maximal hyperclique pattern that contains this object and then label all other objects in the pattern with the label of this object. If the hyperclique pattern contains objects with different class labels, then our algorithm assigns an unlabeled object the class label of the labeled object that has the highest similarity to the unlabeled object. A simila r strategy can be applied when an unlabeled object is located in two different maximal hyperclique patterns.

There are several benefits of the HPSL method. First, this method, like KNNS and TOP-K NNS, only predicts class la-bels for objects strongly connected to objects with known class labels. Second, unlike these two approaches, HPSL considers the similarity among groups of objects instead of just pairs of objects. Third, hyperclique patterns represe nt unique concepts that may potentially help guide better in-formation inference in databases. Finally, the applicatio n of the HPSL method for attacking database security reveals an interesting direction for multi-relational data mining [2 ].
In this section, we discuss some experimental results to (1) show the information leakage in databases via the HPSL method with experiments on several real-world data sets, and (2) compare the relative performance of HPSL, KNNS,
