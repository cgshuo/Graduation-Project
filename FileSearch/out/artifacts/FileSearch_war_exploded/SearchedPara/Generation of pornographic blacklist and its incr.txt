 Lung-Hao Lee, Cheng-Jye Luh * 1. Introduction rapidly grown web content varies considerably in quality. Even worse, many kinds of inappropriate materials including por-nography, violence, gambling and crime are spreading more rapidly than ever. Thus, rating and filtering web content has attracted intensive attention for protecting children or anyone else from inappropriate materials ( Caulkins, Ding, Duncan,
Krishnan, &amp; Nyberg, 2006; Weitzner, 2007 ). A majority of effort has gone into blocking pornography content according to a survey by Open Net Initiative. 1 inappropriate materials issue ( Rosenberg, 2001 ). The filtering mechanism typically employs different approaches including are mainly server-side controlled. Further details are presented below.
 requirement. This phenomenon has been revealed in several surveys. For example, Lee et al. (2002) reported that only 11% of English web content used PICS labels. More recently, the present study found that among ten thousands bilingual pornographic ously, the self or third party ratings approach to web content filtering still has a long way to go.

Secondly, the URL blocking approach rejects any requests to URLs on the blacklist; while accepting requests to URLs that are not blacklisted. Several projects such as SquidGuard 5 and DansGuardian 6 have used self-built or public domain blacklists with the squid proxy software to block inappropriate web content. This approach has the advantages of (a) consuming no com-putational resource for content analysis and (b) being safe from virus infection. However, the growth dynamics of the web re-quires such a blacklist to be constantly updated for sustainable blocking performance.

Thirdly, the keyword matching and filtering approach rejects any request to web pages on which the total number of fea-under blocking. For example, sexual education web pages are often blocked by a low threshold because they typically consist of a few sexual words. By contrast, raising the threshold may instead make some real pornographic web pages survive block-ing. Several studies have proposed the use of crucial properties such as the probability of occurrence of every feature to re-duce over and under blocking.

Lastly, the intelligent content analysis approach attempts to gain a semantic understanding of the context in which the features (either words or image pixels) appear. Several proposed methods, although differing in the numerical algorithms they use, are mainly based on statistical computing of the discriminative features to makeclassification decision. Of them Chen, 2006 ). The strength of intelligent content analysis lies in its superior precision rate achieved by analyzing both texts and images on web pages. However, comparatively more training time and human intervention are needed for the claimed performance.

Additionally, one interesting web phenomenon is that web sites with common interests tend to group together by adding ods to uncover such cyber-communities. Further, expanding a seed set into a larger community is suggested by Andersen and Lang (2006) to be a common procedure in link-based analysis. Two distinct but related types of pages, called  X  X  X ubs X  and  X  X  X uthorities X  by Kleinberg (1999) , can be located by analyzing link structure of web pages. That is, a hub points to many authorities; an authority is pointed to by many hubs. We believe that exploring the linking structure of seed pornographic web pages is a good start in the discovery of pornographic hubs and authorities. More importantly, exploring the external links on pornographic hubs will, in turn, lead to locating newly added pornographic web pages.

This study presents an inverse chi-square based classification system, along with an incremental update mechanism, for incremental generation of pornographic blacklist. The classification system is intended to accurately classify bilingual (Eng-lish and Chinese) web pages into one of three categories:  X  X  X orn, X   X  X  X nsure X  and  X  X  X on-porn X  based on an indicator value of pornography obtained from each individual web page X  X  textual content. The URLs of pornographic web pages are put on a blacklist, which is then regularly updated by the incremental update mechanism. Subsequently, the generated blacklist can serve as a solid base for web content filtering by URL matching and blocking.

The rest of this paper is organized as follows: Section 2 describes the proposed system architecture and details on inverse chi-square classification, calculation of pornographic indicator value, and incremental update. Section 3 presents several experimental results on performance evaluation. Section 4 discusses the experimental findings. Finally, section 5 concludes this study along with future research. 2. Pornographic web content classification
Fig. 1 shows an overview of the proposed system, which consists of two major processes: a regular classification process and an incremental update process. In the regular classification process (shown with solid lines), the web crawling sub-pro-cess gathers suspect web pages from well-known search engines by queries with pornographic keywords. The inverse chi-square classification process classifies a given page into one of three categories:  X  X  X orn, X   X  X  X on-Porn, X  and  X  X  X nsure X  based on an indicator value obtained by combining the porn tendency weights of the terms that appear on the given page in inverse chi-square calculation. The URLs of the pornographic web pages are then placed on a blacklist. In the incremental update process (shown with dotted lines), the  X  X  X inding Hub Sites X  sub-process periodically discovers representative hub sites from the web sites already on the blacklist, and then the  X  X  X xploring Hub Sites X  sub-process gathers the links on these hub sites as new seed URLs to be crawled and classified by the regular process. The resulting pornographic URLs are added to the black-list. In this way, we can regularly find newly added pornographic web pages from representative hub sites to update the blacklist. 2.1. Inverse chi-square classification tags, detects its language encoding, split the remaining textual content into a series of terms, and consults the proper lingual feature set to find the matched features. Herein the feature set refers to the subset of most discriminative terms we previ-ously selected from training documents. Then the given test document is encoded as a feature vector with elements repre-sented by the porn tendency weights of the matched features. The porn tendency weight of a term, as defined in Eq. (1) , measures the degree that a term t is related to pornography and is in the range of 0 to 1 ( Lee &amp; Luh, 2007 ).
The classification process then performs inverse chi-square calculations on the elements of the resulting feature vector to obtain an indicator value. A classification decision is then reached by comparing the indicator value with a pair of lower and upper thresholds: firstly, an indicator value below the lower threshold denotes  X  X  X on-Porn X ; secondly, an indicator value above the upper threshold denotes  X  X  X orn X ; lastly, an indicator value in between the lower and upper thresholds denotes  X  X  X nsure X .

Notably, the selected feature set includes positive and negative features. In terms of the porn tendency weight, features that have values above (or below) 0.5 are considered positive (or negative) to the pornography category. Using positive and negative features is preferable to categorize objectionable materials; particularly for resolving the ambiguity of gray-area web sites such as sex education. The gray-area web sites not only have some content similar to that of pornographic web sites but also have some normal content. If we consider positive features from the pornographic part only, sex education web sites would be easily classified as pornographic. But interestingly, the negative features from the normal part are very likely to neutralize the effects of the positive features when combined in inverse chi-square calculations; thereby preventing a sex education site from being classified as  X  X  X orn X . What category sex education sites should belong to is dependent on the weights learned from the pre-categorized training set. 2.2. Calculation of pornographic indicator value
An indicator value of pornography is calculated for each document being classified by an inverse chi-square calculation method derived from anti-spamming research ( Robinson, 2003 ). Details were presented in our previous study ( Lee &amp; Luh, 2007 ). A brief description is presented herein.

Formally, the indicator value of pornography is calculated using two P -values derived from inverse chi-square distribu-tion as defined in the following equations: where p ( t ) denotes the porn tendency weight of term t ; n denotes the number of terms; Q n p  X  t  X  denotes the maximum like-lihood estimator; 2 ln Q n p  X  t  X  is approximately a chi-square distribution with 2n degrees of freedom ( Casella &amp; Berger, 2002 ); C 1 () denotes the inverse chi-square function to derive the P -value from a chi-square distributed random variable.
The P -values are derived on the base of likelihood ratio test, assuming the null hypothesis H 0 that the present web page is a random collection of terms, each independent of the others, is true. Virtually, a particular web page usually has a telling number of correlated terms of one type or the other. For example, web pages consisting of the term  X  X  X aked X  are very likely to also contain the term  X  X  X ex X ; similarly, web pages consisting of the term  X  X  X itcher X  are very likely to also contain the term  X  X  X aseball. X  This nonrandom tendency produces intended results of small P -value (either R or G ) to reject the null hypothesis. Then the indicator value of pornography I , denoting the difference between the values of R and G , is normalized to be in the range of 0 X 1 by Eq. (4) .

Notably, such inverse chi-square calculations exploit statistical dependencies between features, but not rely on the sta-tistical significance of a single term. Thus, intentionally or unintentionally replacing some of the objectionable words e.g.,  X  X  X orn X  with  X  X  X ron X  would have very little effect on the classification analysis unless all pornographic web pages have mis-spelled most of the objectionable words.

The inverse chi-square calculations have empirically demonstrated to produce satisfactory results as expected. Specifi-cally, a pornographic web page has a much smaller value of G than that of R ; thus causing the indicator value close to 1. By contrast, a non-pornographic web page has a much smaller value of R than that of G ; consequently, generating an indi-cator value close to 0. Additionally, some mixed web pages such as forum on sex education or selling adult products have indicator values close to 0.5. This is consistent with practical experience that people often assign very different categories to such web pages. 2.3. Incremental update mechanism The incremental update mechanism includes two sub-processes: Finding Hub Sites and Exploring Hub Sites. The Finding Hub Sites sub-process seeks to discover prospective pornographic hubs by analyzing the linking structure of pornographic web sites already on the blacklist. A pornographic hub denotes a web site that consists of many outgoing links pointing to other pornographic web sites. More specifically, a pornographic hub contribution (PHC) is calculated for each pornographic web site undergoing analysis: where Ni denotes the number of internal links on the present pornographic web site i ; and PSi denotes the total number of distinct pornographic web sites pointed to by the web site i itself plus those pointed to by its internal web pages. A link on a web site is said to be  X  X  X nternal X  if it refers to an URL that has the same domain name as that of the web site. For example, a pornographic web site xxx.com has the home page xxx.com/index.html and there are three links on this page, referring to xxx.com/a.html, xxx.com/b.html and xyz.com/index.htm (a porn site). By definition, the links referring to xxx.com/in-dex.html, xxx.com/a.html, and xxx.com/b.html are internal links on xxx.com, that is N i = 3. Suppose the outgoing links on web pages xxx.com/a.html and xxx.com/b.html together point to 20 distinct pornographic web sites, then PS i = 20 + 1 (for xyz.com/index.html) = 21, and finally PHC i is 7 (21/3). As a rule, a web site would be selected as a pornographic hub site if its PHC value exceeds the PHC threshold. We set the PHC threshold to the average plus two times standard deviation of the PHC values of all web sites undergoing analysis.
 nates the results as a new set of suspect URLs to be next crawled and classified by the regular classification process. Finally, the URLs being classified as pornographic are added to the blacklist. 3. Experiments and performance evaluation call and false positive rate of the proposed system. Secondly, the incremental results of pornographic hub sites were com-pared with those of non-hub sites. Finally, an experiment was conducted to compare the hit ratio of the generated blacklists with those of three public domain blacklists against popular pornographic web sites extracted from our campus proxy access log.
 is governed by the number of terms considered in the inverse chi-square calculations and the threshold pair for making the classification decision. For each testing web page, we used at most 150 of its porn tendency weights to calculate the indicator above 0.65, or otherwise  X  X  X nsure X . 3.1. Performance evaluation the following meaning in the context of our study: lated using the equation:
The test data set we used in this experiment consists of 2500 English web pages and 2500 Chinese web pages crawled from the web, of which 60% (=3000) are normal pages and the remaining 40% (=2000) are pornographic pages. Also, various kinds of pornographic and normal content are included. The resulting confusion matrixes for Chinese and English test web pages are presented in Tables 2 and 3 .

Finally, the performance evaluation results are shown in Table 4 . Our system scored a precision of 97.60%, a recall of 81.2%, and a false positive rate of 1.33% for Chinese web pages as compared to a precision of 96.62%, a recall of 80.4% and a false positive rate of 2.06% for English web pages. 3.2. Incremental effects
Fig. 3 shows the distribution of the pornographic hub contribution of 2500 distinct web sites randomly selected from the blacklist we collected in this study. According to the histogram of distribution, 10 significant outliers among the 2500 web sites were selected as pornographic hubs using the Chebyshev X  X  inequality with constant k = 2 .

A linking structure experiment was then conducted once per month to compare the amount of newly discovered porno-graphic web sites from the selected 10 pornographic hubs with that from another 10 randomly selected non-hub sites during three months. The monthly average increases from a hub site, as observed from the experimental results shown in Table 5 , are about eleven times as many as that from a non-hub site. 3.3. Comparison of pornographic hit ratio
A good blacklist should keep up with the changing web for achieving a sustainable blocking effect. In order to understand how well does a blacklist keep up-to-date, an experiment was conducted to compare the hit ratios achieved by several black-lists against popular pornographic web sites found from our campus proxy access log. Among the five blacklists under con-sideration, the blacklist generated in our previous study ( Lee &amp; Luh, 2007 ) comprises about 50 thousands distinct pornographic host names (called InChi-BL v1) up to June, 2005. Through the proposed incremental update mechanism, this blacklist has grown to 78 thousands host names (called InChi-BL v2) up to July, 2006. The three others are public domain blacklists from SquidGuard, Shalla 7 and URLBlack.com. Their collections comprise about 34 thousands, 660 thousand, and 520 thousands URLs, respectively.
 tracted and manually examined from the access log as from January 2007 to March 2007 provided by the information service center of our institute. Each of the testing URLs was checked against the blacklists mentioned above. A hit occurs once the
URL of a web site finds a match in a blacklist; otherwise, a miss happens. The hit ratio denotes the proportion of hits to the total number of URLs under test. Table 6 shows the experimental results among blacklists. The blacklist with incremental update (InChi-BL v. 2) notably performed the best, achieving a hit ratio of 83.2%. 4. Discussion
We did classification solely by the content of web pages, without using any PICS/ICRA label information at all. Moreover, a regularly updated blacklist has been generated by an incremental update mechanism to perform better than some public domain blacklists in hit ratio against locally popular pornographic web sites. Nevertheless, several issues deserve careful investigation so as to figure out how to further improve the system.

English pages. Since the comparison was based on one set of results and thereby cannot be generalized to infer that our sys-tem always performs better for Chinese web pages than for English web pages. Factors that influence the precision rate in-clude the feature selection method and the feature weighting metric, the training and testing data sets, and the classifier parameters. For example, one of our recent studies conducted on a larger data set shows that our system performed 2% better for English web pages than for Chinese web pages when using Correlation Coefficient instead of TFIDF-based tendency weight as the feature metric. As for the particular experimental results presented in this study, the classifier has produced comparatively more false positive cases (i.e. falsely classified as porn) of English web pages, especially on some blog articles about sex education, which hindered it X  X  performance in precision for English web pages.

Secondly, the feature selection method used in this study still requires some human intervention to fine-tune the feature set. For each of unknown words, we did not judge whether it is an intentional or unintentional replacement of a known word. What we did is simply conducting spell checking on each of unknown words and then selecting the most match one from the list of suggested words to replace it, for example replacing  X  X  X ron X  with  X  X  X orn X . Some of unknown words (e.g. bbw) that have not a close match were discarded from the feature set. However, human intervention in adjustment of the feature set does not always contribute to performance improvement. For example, we mistakenly discarded the word  X  X  X bw X  from the feature set because we did not know it is an abbreviation commonly used for  X  X  X ig Breast Women X  on por-nographic web pages at the time of experimentation.

Thirdly, among the mistakenly classified cases in the performance evaluation experiment there are 51 false positives and 94 false negatives. A false positive occurs when a normal web page is classified as pornographic; while a false negative occurs when a pornographic web page is classified as non-pornographic. Users typically raise serious concerns about accidentally blocking important web pages due to the occurrences of false positives. The proposed system notably achieved an average false positive rate of 1.7%, which compares favorably with that of existing methods. However, all the false negatives hap-pened on web pages that comprise many sexual images and almost no textual content. Adding an image analysis mechanism seems necessary to increase the capabilities of the proposed system.

Finally, conducting linking analysis of pornographic hubs is revealed from the experimental results to be a comparatively efficient way of locating newly added pornographic web sites. Thus, discovering and exploring the productive pornographic hubs is crucial to the generation of an up-to-date blacklist. The proposed blacklist incremental update mechanism, as indi-cated from the experimental results of hit ratios, has been responsive to the growth dynamics of pornography sites, though not enough. A more intelligent and aggressive blacklist refresh mechanism, needless to say, is required to keep up with the constantly changing web. 5. Conclusions
This study presented an inverse chi-square based classification system to classify web pages into pornographic, non-por-nographic and unsure categories. The proposed system has been empirically verified to classify bilingual web pages at an average precision rate of 97.11% and also maintained a favorably low false positive rate. The resulting pornographic URLs were collected on a blacklist, which can be used in server-controlled web content filtering. The pornographic blacklist is then periodically updated by an incremental update mechanism for achieving a sustainable blocking rate given the constantly changing web.

Future work is investigated along several directions. First, an attempt to increase the multilingual coverage of the blacklist with Japanese and possibly other lingual web sites is ongoing. Secondly, the feature selection method used in this study still needs some human intervention to fine-tune the feature set. We are investigating a domain independent, cost-effective fea-ture selection method that can achieve superior performance without human intervention. Thirdly, a more aggressive black-list refresh mechanism is required to constantly update the blacklist for keeping up to date with the changes of pornographic web sites. Fourthly, we have noticed that the system performance is moving downwards gradually as time goes by. Thus, we are investigating an evolution mechanism that would enable the feature selection method be adaptable and learn from the mistakenly classified cases. Finally, we would like to implement and test the proposed system in an online content filtering environment with the help of our campus information service center.
 Acknowledgements The authors would like to thank the anonymous reviewers for their constructive comments. This work was funded by National Science Council, Taiwan under Grants NSC 93-2213-E-155-035 and NSC 94-2213-E155-051.
 References
