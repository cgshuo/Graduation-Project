 1. Introduction
Over the course of decades of research in information retrieval, many different information retrieval models have been proposed and studied. While significant progress has been made, no single retrieval model has proven to be most effective, and several major challenges remain. For example, theoretical guide-lines and formal principles have rarely led to good performance directly; instead, a theoretically well-defined formula often needs to be heuristically modified in order to perform well empirically. It is thus a significant scientific challenge to develop principled retrieval approaches that also perform well empiri-cally. In addition, most retrieval models have been developed based on the assumption of independent relevance X  X he relevance value of a document is assumed to be independent of that of other documents, including those already viewed by a user. Clearly, this assumption does not hold in real applications. A major challenge is to develop models that can relax such an assumption.

In this paper, we present a probabilistic information retrieval framework that begins to address these challenges. The basic idea of the framework is to formally treat the task of information retrieval as a sta-tistical decision problem. Specifically, given a collection of documents, a query, and any other information that we know about the user, a retrieval system needs to choose a subset of documents and present them in an appropriate way. For example, ranking all the documents according to a query, as is done in a typical retrieval system, can be regarded as a decision problem where the decision involves choosing the best rank-ing. We formalize this view of retrieval using Bayesian decision theory. In particular, we treat a query and a document as observations from a probabilistic model, called a statistical language model, and encode retrieval preferences with a loss function defined on the language models and a retrieval action. According sion involves choosing a ranking) is the one that minimizes the Bayes risk, which is the expected loss asso-ciated with the chosen action given the observed query and documents.

This framework unifies several existing retrieval models, including the recently proposed language mod-eling approach, within a single probabilistic framework, and provides guidance on how one can further im-prove a retrieval model and systematically explore new approaches to information retrieval. Several new retrieval models derived using the risk minimization framework have been shown to be quite effective empirically.

In addition to its generality, this risk minimization framework has several potential advantages over a language models as components in a retrieval framework. Statistical language models provide a principled way to model text documents and queries, making it possible to set retrieval parameters through statistical inference and estimation methods. Second, the risk minimization framework makes it possible to system-atically and formally study optimal retrieval strategies. For example, through making different assumptions about the loss function for ranking we can derive an optimal ranking principle, which is similar to the prob-minimization framework extends the traditional notion of independent, topical relevance. For example, it is possible to formalize retrieval models for a non-traditional retrieval task where the goal is to retrieve as many different subtopics of a general topic as possible.

The rest of the paper is organized as follows. In Section 2, we briefly review existing retrieval models and discuss how the risk minimization framework is related to them. In Section 3, we present the basic idea and setup of the risk minimization framework. In Sections 4. 1and 4.2, we derive several special cases of the framework, demonstrate how it can cover existing retrieval models and also how it can facilitate develop-ment of new retrieval models, including those appropriate for the non-traditional subtopic retrieval task, as discussed in detail in Section 5. Finally, we summarize the contributions of the paper in Sections 6 and 7. 2. Existing retrieval models Through years of research, many different retrieval models have been proposed, studied, and tested.
Their mathematical basis spans a large spectrum, including algebra, logic, set theory, and probability and statistics. Although it is impractical to provide a complete survey of all the existing retrieval models in this paper, we can roughly classify the existing models into three broad categories, depending on how they define and measure relevance. In one category, relevance is assumed to be correlated with the similarity between a query and a document. In another category, a binary random variable is used to model relevance and probabilistic models are used to estimate the value of this relevance variable. In the third category, the uncertainty of relevance is modeled by the uncertainty in inferring queries from documents or vice versa. In order to place the risk minimization framework in context, we discuss each of these three categories below. 2.1. Similarity-based models
In a similarity-based retrieval model ( Dominich, 2000, 2001 ), it is assumed that the relevance status of a document with respect to a query is correlated with the similarity between the query and the document at some level of representation; the more similar to a query a document is, the more relevant the document is assumed to be. In practice, we can use any similarity measure that preserves such correlation to generate a relevance status value (RSV) for each document and rank documents accordingly.

The vector space model is the most well-known model of this type ( Salton, Wong, &amp; Yang, 1975a ; Salton &amp; McGill, 1983 ; Salton, 1989 ), in which a document and a query are represented as two term vectors in a high-dimensional term space and each term is assigned a weight that reflects its  X  X  X mportance X  X  to the doc-ument or the query. Given a query, the relevance status value of a document is given by the similarity be-tween the query vector and document vector as determined by some vector similarity measure, such as the cosine of the angle formed by the two vectors.

The vector space model naturally decomposes a retrieval model into three components: (1) a term vector representation of a query; (2) a term vector representation of a document; (3) a similarity/distance measure between a document vector and a query vector. However, the  X  X  X ynchronization X  X  among the three compo-nents is generally unspecified; in particular, the similarity measure does not dictate the representation of a document or query. Thus, the vector space model is actually a general retrieval framework , in which the representation of query and documents as well as the similarity measure are all, in principle, arbitrary.
The flexibility of the vector space approach makes it easy to incorporate different indexing models. For example, the 2-Poisson probabilistic indexing model can be used to select indexing terms or assign term weights ( Harter, 1975 ; Bookstein &amp; Swanson, 1975 ). Latent semantic indexing can be applied to reduce the dimension of the term space and to capture the semantic  X  X  X loseness X  X  among terms, in an effort to improve the representation of the documents and query ( Deerwester, Dumais, Landauer, Furnas, &amp; Harsh-man, 1990 ). A document can also be represented by a multinomial distribution over the terms, as in the distribution model of indexing proposed in Wong and Yao (1989) .

The main criticism of the vector space model is that it provides no formal framework for the represen-tation, making the study of representation inherently separate from the estimation of relevance. The sep-aration of the relevance function from the weighting of terms has the advantage of being flexible, but the disadvantage of making difficult the study of the interaction between representation and relevance mea-surement. The optimality of a similarity/relevance function is highly dependent on the actual representation (i.e., term weights) of the query and the document. As a result, the study of representation in the vector space model has been largely heuristic. The two central problems in document and query representation are the extraction of indexing terms, or other units, and the weighting of the indexing terms. The choice of different indexing units has been extensively studied, but no significant improvement has been achieved over the simplest word-based indexing ( Lewis, 1992 ), although recent evaluation has shown more promis-ing improvement through the use of linguistic phrases ( Evans &amp; Zhai, 1996 ; Strzalkowski, 1997 ; Zhai, 1997 ). Many heuristics have also been proposed to improve term weighting, but again, no weighting method has been found to be significantly better than the heuristic TF-IDF term weighting ( Salton &amp;
Buckley, 1988 ). To address the variance in the length of documents, an effective weighting formula also needs to incorporate document length heuristically ( Singhal, Buckley, &amp; Mitra, 1996 ). Salton and others introduced the idea of the discrimination value of an indexing term ( Salton, Yang, &amp; Yu, 1975b ), which is the increase or decrease in the mean inter-document distance caused by adding the indexing term to the term space for text representation. They found that the middle frequency terms have higher discrimi-nation value. Given a similarity measure, the discrimination value provides a principled way of selecting terms for indexing. However, there are still two deficiencies. First, the framework is not modeling relevance, for the weighting of terms. Other criticisms about the vector-space model can be found in Bollmann-Sdorra and Raghavan (1993) and Dominich (2002) .

As seen below, the risk minimization framework suggests a new formal similarity-based retrieval model in which the representation of query and documents is associated with statistical language models. The use of statistical language models makes it possible to replace the traditional ad hoc tuning of parameters with statistical estimation of parameters. 2.2. Probabilistic relevance models
In a probabilistic relevance model, one is interested in the question  X  X  X hat is the probability that this document is relevant to this query? X  X  ( Sparck Jones, Walker, &amp; Robertson, 2000 ). Given a query, a docu-ment is assumed to be either relevant or non-relevant, but the system relies on a probabilistic model to infer this value.

Formally, let random variables D and Q denote a document and query, respectively. Let R be a binary random variable that indicates whether D is relevant to Q or not. It takes two values which we denote as r
Depending on how this probability is modeled and estimated, there are several special cases of this general probabilistic relevance model.
 relevance variable R is assumed to be dependent on  X  X  X eatures X  X  that characterize how well D matches Q .
Such a regression model was first introduced, with some success, by Fox (1983) , where features such as term frequency, authorship, and co-citation were combined using linear regression. Fuhr and Buckley (1991) used polynomial regression to approximate relevance. Gey used logistic regression involving information such as query term frequency, document term frequency, IDF, and relative term frequency in the whole collection, and this model shows promising performance in three small testing collections ( Gey, 1994 ). Regression models provide a well-studied framework in which to explore the use of heuristic features.
One important advantage of regression models is their ability to learn from all the past relevance judg-ments, in the sense that the parameters of a model can be estimated based on all the relevance judgments, including the judgments for different queries or documents. However, a large amount of data and empirical experimentation may be needed in order to find a set of good features. The regression framework thus pro-vides only limited guidance for extending a retrieval model.

Alternatively, p ( R = r j D , Q ) can be estimated indirectly using a generative model, and documents can be ranked according to the following log-odds ratio:
There are two different ways to factor the conditional probability p ( D , Q j R ), corresponding to document (BIR) model ( Robertson &amp; Sparck Jones, 1976 ; Fuhr, 1992 ) is perhaps the most well-known classical prob-abilistic model. It assumes that terms are independently distributed in each of the two relevance models, so is essentially a na X   X  ve Bayes classifier for document ranking ( Lewis, 1998 ).
There have been several efforts to improve the binary representation. Van Rijsbergen extended the bin-ary independence model by capturing some term dependency as defined by a minimum-spanning tree weighted by average mutual information ( van Rijbergen, 1977 ). Croft (1981) investigated how the heuristic term significance weight can be incorporated into probabilistic models in a principled way. Another effort to improve document representation is to introduce the term frequency directly into the model by using a multiple 2-Poisson mixture representation of documents ( Robertson et al., 1981 ). While this model has not shown superior empirical performance itself, an approximation of the model based on a simple TF formula into the model is implicit in text categorization approaches which view a document as being generated from a unigram language model ( Kalt, 1996 ; McCallum &amp; Nigam, 1998 ).
 the Probabilistic Indexing model proposed in Maron and Kuhns (1960) is the very first probabilistic retrie-val model, in which the indexing terms assigned to a document are weighted by the probability that a user who likes the document would use the term in the query. That is, the weight of term t for document D is independence indexing (BII) model proposed in Fuhr (1992) is another special case of the query generation model. It allows the description of a document (with weighted terms) to be estimated based on arbitrary queries, but the specific parameterization makes it difficult to estimate all the parameters in practice. In
Lafferty and Zhai (2003) , it has been shown that the recently proposed language modeling approach to re-trieval can be viewed as a special probabilistic relevance model when query generation is used to decompose the generative model. This work provides a relevance-based justification for this new family of probabilistic models based on statistical language modeling.
 The language modeling approach was first introduced by Ponte and Croft (1998) and also explored in
Hiemstra and Kraaij (1998) , Miller, Leek, and Schwartz (1999) , Berger and Lafferty (1999) , Song and Croft component in the language modeling approach. Indeed, most work in this direction differs mainly in the language model used and the way of language model estimation. Smoothing of a document language model with some kind of collection language model has been very popular in the existing work. For example, geo-metric smoothing was used in Ponte and Croft (1998) ; linear interpolation smoothing was used in Hiemstra and Kraaij (1998) , Berger and Lafferty (1999) , and was viewed as a 2-state hidden Markov model in Miller et al. (1999) . Berger and Lafferty explored  X  X  X emantic smoothing X  X  by estimating a  X  X  X ranslation model X  X  for mapping a document term to a query term, and reported significant improvements over the baseline lan-guage modeling approach through the use of translation models ( Berger &amp; Lafferty, 1999 ).
The language modeling approach has two important contributions. First, it introduces an effective prob-abilistic ranking function based on the query generation. While the earlier query generation models have all encountered difficulty in estimating the parameters, the model proposed in Ponte and Croft (1998) explicitly addresses the estimation problem through the use of statistical language models. Second, it reveals the con-nection between the difficult problem of text representation in IR and the language modeling techniques that have been well studied in other application areas such as statistical machine translation and speech recognition, making it possible to exploit various kinds of language modeling techniques to address the rep-resentation problem. 2
Although the classic document generation probabilistic models and the language modeling approach can be seen as being based on the same notion of relevance and are probabilistically equivalent, they have several important differences from an estimation perspective, as they involve different parameters for esti-estimate a model for  X  X  X elevant queries X  X  based on a document than to estimate a model for relevant docu-ments based on a query. Indeed, the BIR model has encountered difficulties in estimating p ( t j Q , r ) and &amp; Harper, 1979 ; Robertson &amp; Walker, 1997 ). Recently, Lavrenko and Croft made progress in estimating the relevance model without relevance judgments by exploiting language modeling techniques ( Lavrenko &amp;
Croft, 2001 ). On the other hand, when explicit relevance judgments are available, the classic models, being based on document generation, have the advantage of being able to naturally improve the estimation of the component probabilistic models by exploiting such explicit relevance information. This is because the rel-then be applied to new documents. The same relevance judgments can also provide direct training data for relevant. Thus, the directly improved models can not be expected to improve our ranking of other unjudged documents. Interestingly, such improved models can potentially be beneficial for new queries X  X  feature unavailable in document generation models.

Instead of imposing a strict document generation or query generation decomposition of the joint prob-(1994) explored a passage-based generative model using hidden Markov model (HMM), which can be regarded as such a case. In this work, a document query pair is represented as a sequence of symbols, each corresponding to a term at a particular position of the document. All term tokens are clustered according to the similarity between the token and the query. In this way, a term token at a particular position of a doc-ument can be mapped to a symbol that represents the cluster the token belongs to. Such symbol sequences are modeled as the output from an HMM with two states, one corresponding to relevant passages and the other to the background noise. The relevance value is then computed based on the likelihood ratio of the sequence given the passage HMM model and the background model.

As seen below, probabilistic relevance models can be shown to be a special case of the risk minimization framework when a  X  X  X onstant cost X  X  relevance-based loss function is used. 2.3. Probabilistic inference models
In a probabilistic inference model, the uncertainty of relevance of a document, with respect to a query, is modeled by the uncertainty associated with inferring the query from the document. Different inference models are possible depending on what it means to  X  X  X nfer a query from a document. X  X 
Van Rijsbergen introduced a logic-based probabilistic inference model for text retrieval ( van Rijsbergen, 1986 ). In this model, a document is relevant to a query if (and only if) the query can be inferred from the document. The Boolean retrieval model can be regarded as a simple special case of this model. To cope with the inherent uncertainty of relevance, van Rijsbergen introduced a logic for probabilistic inference, in which the probability of a conditional, such as p ! q , can be estimated based on the notion of possible worlds.
Wong and Yao (1995) extended the probabilistic inference model and proposed a unified framework for supporting probabilistic inference with a concept space and a probability distribution defined over the con-cepts in the space. The probabilistic concept space model is shown to recover many other text retrieval models such as the Boolean, vector space, and the classic probabilistic models through different ways of modeling terms (thus document and query representations) in the concept space. Fuhr shows that some particular form of the language modeling approach can also be derived using this general probabilistic con-cept space model ( Fuhr, 2001 ). tially a Bayesian belief network that models the dependency between the satisfaction of a query and the observation of documents. The estimation of relevance is based on the computation of the conditional probability that the query is satisfied given that the document is observed. Other similar uses of Bayesian belief networks in retrieval have been presented in Fung and Favero (1995) , Ribeiro and Muntz (1996) ,
Ribeiro-Neto, Silva, and Muntz (2000) . Kwok  X  s network model may also be considered as performing a probabilistic inference ( Kwok, 1995 ), though it is based on spread activation. The inference network model of observing documents and the satisfaction of a user  X  s information need, one can obtain many different text retrieval models as special cases, including the Boolean, extended Boolean, vector space, and conven-tional probabilistic models. More importantly, it can potentially go beyond the traditional notion of topical relevance. 3. The risk minimization framework
Informally, a retrieval system can be regarded as an interactive information service system that answers a user  X  s query by presenting a list of documents. Usually the user would examine the presented documents and reformulate a query if necessary; the new query is then executed by the system to produce another problem X  X t needs to choose a subset of documents and present them to the user in some way, based on the available information to the system, which includes the current user, the user  X  s query, the sources of doc-uments, and a specific document collection. For example, the system may decide to select a subset of doc-uments and present them without any particular order (as in Boolean retrieval); alternatively, it may decide could be many choices for the decision space, and we can regard the process of information retrieval as consisting of a series of such decision making tasks.

We now formally define this decision problem. We view a query as being the output of some probabilistic process associated with the user U , and similarly, we view a document as being the output of some prob-abilistic process associated with an author or document source S choosing a model, and then generating the query (document) using that model. A set of documents is the result of generating each document independently, possibly from a different model. (The independence assumption is not essential, and is made here only to simplify the presentation.) The query model could, in principle, encode detailed knowledge about a user  X  s information need and the context in which the query is made. Similarly, the document model could encode complex information about a document and its source or author.
 More formally, let h Q denote the parameters of a query model, and let h document model. A user U generates a query by first selecting h Using this model, a query q is then generated with probability p ( q j h use the same text query for different information needs, strictly speaking, the variable U should be regarded as corresponding to a user within the current context. Since this does not affect the presentation of the framework, we will simply refer to U as a user. Similarly, the source selects a document model h to a distribution p  X  h D jS X  , and then uses this model to generate a document d according to p ( d j h have Markov chains U ! h Q ! q and S! h D ! d . This is illustrated in Fig. 1 .

Let C  X f d 1 ; ... ; d N g be a collection of documents obtained from sources responds to a possible response of the system to a query. For example, one can imagine that the system would return an unordered subset of documents to the user. Alternatively, a system may decide a ranking of documents and present a ranked list of documents. Yet another possibility is to cluster the (relevant) documents and present a structured view of documents. Formally, a retrieval action can be defined as a compound decision involving selecting a subset of documents D from C and presenting them to the user who has issued query q according to some presentation strategy p . Let P be the set of all possible presen-tation strategies. We can represent all actions by A  X f X  D ; p  X g , where D C is a subset of C and p 2 P is some presentation strategy.

In the general framework of Bayesian decision theory, to each such action a  X  X  D ; p  X 2 A there is asso-h  X  h Q ; f h i g N i  X  1  X  as well as any relevant user factors F  X  U  X  and document source factors F  X  the model that generates document d i . For convenience of notation, we will typically assume that the user factors F  X  U  X  are included as part of the query model h cluded as part of the document models h i ; thus our loss function can be written as L ( a , h ). The expected risk of action a is given by where the posterior distribution is given by
The Bayes decision rule is then to choose the action a * having the least expected risk: Thus, the document set D * is selected and presented to the user with strategy p *.

Note that this gives us a very general formulation of retrieval as a decision problem, which involves searching for D * and p * simultaneously. The presentation strategy can be fairly arbitrary in principle, e.g., presenting documents in a certain order, presenting a summary of the documents, or presenting a clus-tering view of the documents. However, we need to be able to quantify the loss associated with a presen-tation strategy.

We now consider several special cases of the risk minimization framework. 3.1. Set-based retrieval
Let us consider the case when the loss function does not depend on the presentation strategy, which means that all we are concerned with is to select an optimal subset of documents for presentation. In this case, the risk minimization framework leads to the following general set-based retrieval method.
The loss function can encode the user  X  s preferences on the selected subset. Generally, the loss function will depend on the relevance status of the documents selected so that the optimal subset should contain the documents that are most likely to be relevant. But other preferences, such as the desired diversity and the desired size of a subset, can also be captured by an appropriate loss function.

The traditional Boolean retrieval model can be viewed as a special case of this general set-based retrieval framework, where the uncertainty about the query models and document models is not modeled (e.g., h = q and h i = d i ), and the following loss function is used: loss function will always result in a retrieval strategy that involves making an independent binary retrieval decision for each document according to d . In particular, the function d can be defined on a structured query. One can easily imagine many other possibilities to specialize the set-based retrieval method. 3.2. Rank-based retrieval
Let us now consider a different special case of the risk minimization framework where the selected doc-uments are presented to the user as a ranked list of documents, so a possible presentation strategy corre-sponds to a possible ranking of documents. Such a ranking strategy has been assumed in most modern retrieval systems and models.

Formally, we may denote an action by a =( D , p ), where p is a complete ordering on D . would then mean presenting the selected documents in D one by one in the order given by p . This means that we can denote an action by a sequence of documents. So we will write a =( d p ( j ) is the index of the document ranked at the j -th rank according to the permutation mapping p .
Let us further assume that our actions essentially involve different rankings of documents in the entire N documents in C . To simplify our notation, we will use p to denote action a  X  X  C ; p  X  .
In this case, the optimal Bayes decision is given by the following general ranking rule: documents.

How do we characterize the loss associated with a ranking of documents? Presenting documents by rank-ing implies that the user would apply some stopping criterion X  X he user would read the documents in order and stop wherever is appropriate. Thus, the actual loss (or equivalently utility) of a ranking would depend on where the user actually stops. That is, the utility is affected by the user  X  s browsing behavior, which we could model through a probability distribution over all the ranks at which a user might stop. Given this setup, we can now define the loss for a ranking as the expected loss under the assumed  X  X  X topping distribution. X  X  Formally, let s i denote the probability that the user would stop reading after seeing the top i documents. We have the user actually views the whole list.

Assuming that the user would view the documents in the order presented, and the total loss of viewing i documents is the sum of the loss associated with viewing each individual document, we have the following reasonable decomposition of the loss: where  X  ( d p ( j ) j d p (1) , ... , d p ( j 1) , h ) is the conditional loss of viewing d  X  d
Putting all of this together, we have
Now, define the following conditional risk: which can be interpreted as the expected risk of the user  X  s viewing document d been previously viewed. We can then write
This is the general framework for ranking documents within the risk minimization framework. It basically says that the optimal ranking minimizes the expected conditional loss (under the stopping distribution) associated with sequentially viewing each document.

We see that the optimal ranking depends on the stopping distribution s optimal decision would be more affected by the loss associated with the top ranked documents; otherwise, it will be more equally affected by the loss associated with all the documents. Thus, the stopping probability stopping) preference. The sequential decomposition of the loss is reasonable when presenting a ranked list to the user. Clearly, when using other presentation strategies (e.g., clustering), such a decomposition would not be appropriate. 4. Loss functions for ranking
In this section we discuss specific loss functions, and show that the risk minimization framework includes several traditional retrieval models as special cases. 4.1. Independent loss functions Let us first consider the case when the loss of viewing each document is independent of viewing others.
That is which means In this case, the expected risk for ranking p is
We see that the risk of p is a weighted sum of the risk of viewing each individual document. As the rank increases, the weight decreases, with the weight on the first rank being the largest (i.e., optimal ranking p *, independent of { s i }, is in ascending order of the individual risk:
This is equivalent to the situation where we assume a possible action is to present a single document. The egy which is very similar to the Probability Ranking Principle ( Robertson, 1977 ); this connection will be further discussed in Section 6.

In general, there could be many different ways of specifying the loss function, which lead to different ranking functions. We now show that with appropriate choices of loss functions, many existing rank-based retrieval models can be derived in the risk minimization framework, including the vector space model, the classic probabilistic retrieval model, and the recently proposed language modeling approach. We also show oped using the risk minimization framework. 4.1.1. Relevance-based loss functions
To show that the traditional relevance-based probabilistic models are special cases of risk minimization, we consider the special case where the loss function L is defined through some binary relevance variable R .
Specifically, we assume that for each document d i , there is a hidden binary relevance variable R of d i with respect to q ( 1for relevant and 0 for non-relevant); see Fig. 2 . The random variable R when we have the user  X  s relevance judgment on d i , and is unobserved otherwise. Let us assume that R observed for now. Note that because the query model h Q can encode detailed knowledge about the user U , the distribution of this relevance variable can be user-specific.

Introducing the variable R into our parameter space, Eq. (1) becomes:
Now let us assume that the loss function  X  depends on h only through the relevance variable R . That is, let  X  be defined where c 0 and c 1 are two cost constants, and c 0 &gt; c 1
From Eq. (2) , we have
This means that the risk minimization ranking criterion is in this case equivalent to ranking based on p ( R =1 j q , d ), i.e., the probability of relevance given q and d . retrieval models. Thus, we have shown that the variants of the probabilistic relevance models reviewed in sic document generation probabilistic retrieval models and the language modeling approach, which is based on query generation ( Lafferty &amp; Zhai, 2001 ). 4.1.2. Proportional distance loss functions
Let us now consider a loss function  X  which is proportional to a distance or similarity measure D between h
Q and h D , i.e., where c is a constant cost. Intuitively, if the models h , h small, reflecting a user  X  s goal of retrieving documents whose models are close to the query model.
With this loss function, from Eq. (1) , we have
This means that the risk minimization ranking criterion is now equivalent to ranking based on the expected model distance. To make this distance easier to compute, we can approximate it by its value at the posterior mode of the parameters. That is, where b h Q  X  arg max h included when comparing the risk for different documents. This is critical when incorporating query-inde-pendent link analysis, or other extrinsic knowledge about a document. Thus we see that under these assumptions and approximations, r  X  d j q ; C ; U ; ~ S X / D  X  special case of this general similarity model, in which b mated heuristically and the distance function is the cosine or inner product measure.
 As a special case of the distance-based model, we assume that h language models, and choose as the distance function the Kullback X  X eibler divergence. This leads to
Thus the ranking function is essentially the cross entropy of the query language model with respect to the document language model. The dropped constant is minus the query model entropy. The value of the cross entropy is always larger than or equal to the query model entropy. The minimum value (i.e., query model entropy) is achieved when b h d is identical to b h q , which makes sense for retrieval.

The KL-divergence model covers the popular query likelihood ranking function as a special case. In-deed, suppose b h q is just the empirical distribution of the query q =( q model given by where d ( w , q i ) is the indicator function. We obtain
This is precisely the log-likelihood criterion used by Ponte and Croft (1998) in introducing the language modeling approach, which has been used in all work on the language modeling approach to date. In Zhai and Lafferty (2001) , new methods were developed to estimate a model performance over the use of the empirical distribution b h 4.1.3.  X  X  X inned X  X  distance loss functions
We now consider another special loss function based on a distance function, indexed by a small constant : where D : H Q H D ! R is a model distance function, and c is a constant positive cost. Thus, the loss is zero when the query model and the document model are close to each other, and is c otherwise, capturing a user  X  s preference for retrieving documents whose models are close to the query model.
 We can show that this loss function leads to a family of two-stage language models explored in Zhai and
Lafferty (2002) . First, we see that the risk is where S ( h D )={ h Q j D ( h Q , h D )&lt; }.

Now, assuming that p  X  h D j d ; ~ S X  is concentrated on an estimated value of the integral over H D by the integrand  X  s value at b h purpose of ranking. Thus, using the notation A rank B to mean that A and B have the same effect for ranking, we have that When h Q and h D belong to the same parameter space (i.e., H integral can be approximated by the value of the function at and the constant can again be ignored for the purpose of ranking. That is,
Therefore, using this loss we will be actually ranking documents according to p  X  probability that the user used the estimated document model as the query model. Applying Bayes  X  formula, we can rewrite this as
Eq. (3) is the basic two-stage language model retrieval formula, in which p  X  q j estimated document model b h D explains the query, whereas p  X  would use b h D as the query model. It can also be regarded as a natural generalization of the basic language modeling approach (i.e., the simple query likelihood method). In Zhai and Lafferty (2002) this two-stage language model is shown to achieve excellent retrieval performance through completely automatic setting of parameters. 4.2. Dependent loss functions
We have demonstrated how the risk minimization framework can recover existing retrieval models and can motivate some interesting new retrieval models through independent loss functions. However, an inde-pendent loss function is rarely an accurate model of real retrieval preferences; the loss of viewing one doc-ument generally depends on the documents already viewed. For example, if the user has already seen the same document or a similar document, then the document should incur a much greater loss than if it were completely new to the user. In this section, we discuss dependent loss functions.

When an independent loss function is used, we can derive the exact optimal ranking strategy (i.e., Eq. (1) ) which does not depend on the stopping probability distribution and can be computed efficiently. However, when a dependent loss function is used, the complexity of finding the optimal ranking makes the computa-tion intractable. One practical solution is to use a greedy algorithm to construct a sub-optimal ranking. Spe-cifically, we can  X  X  X row X  X  the target ranking by choosing the document at each rank, starting from the very resent the ordering ( d p (1) , ... , d p ( i ) , d k ). Then, the increase in risk due to choosing d
Thus, at each step we just need to evaluate and choose the k that minimizes d 0 ( k j p (1: i )).
This gives us a general greedy and context-dependent ranking algorithm. Interestingly, due to the use of a greedy strategy, we see again that the  X  X  X ptimal X  X  ranking does not depend on the stopping probabilities s
In the next section, we discuss how we may instantiate this general algorithm with specific dependent loss functions in the context of a non-traditional ranking task X  X ubtopic retrieval. 5. Models for subtopic retrieval 5.1. The problem of subtopic retrieval
A regular retrieval task is often framed as the problem of retrieving relevant documents based on the assumption that a single document is the information unit under consideration. However, a topic usu-ally has some degree of subtopic structure. For example, a student doing a literature survey on  X  X  X a-chine learning X  X  may be most interested in finding documents that cover representative approaches to the field and the relations between these approaches. If a topic often has a unique structure that involves many different subtopics, a user with a high recall retrieval preference may prefer a ranking of docu-ments where the top documents cover different subtopics. This problem, referred to as  X  X  X spect retrie-val X  X , was investigated in the TREC interactive track ( Over, 1998 ), where the purpose was to study how an interactive retrieval system can help a user to efficiently gather diverse information about a topic.

How can we formally define a retrieval model for such a subtopic retrieval problem? Clearly, this re-quires non-traditional ranking of documents, since ranking solely based on relevance would not be optimal.
We thus need non-traditional ranking models that can not only model relevance but also model redun-dancy, novelty, and subtopics. To model the subtopic retrieval task in the risk minimization framework we require a dependent loss function. In this section we present two different types of dependent loss func-tions that are appropriate for this task.

The first type of loss function is the maximal marginal relevance (MMR) loss function, in which we stein, 1998 ). In essence, the goal is to retrieve relevant documents and, at the same time, minimize the chance that the user will see redundant documents as he or she goes through the ranked list of documents.
Intuitively, as we reduce the redundancy among documents, we can expect the coverage of the same sub-topic to be minimized and thus the coverage of potentially different subtopics to increase.
The second type of loss function is the Maximal Diverse Relevance (MDR) loss function, in which we encode a preference for retrieving documents that best supplement the previously retrieved documents, in terms of covering different subtopics. We thus need to model both topical relevance and subtopic structure of documents. Intuitively, an MDR loss function will assess which subtopics have been well covered and which are under-covered, and then prefer a document that best treats those under-covered subtopics.
We now discuss both types of dependent loss functions in detail. 5.2. Maximal marginal relevance (MMR) loss functions
The idea of Maximal Marginal Relevance (MMR) ranking was first proposed and formalized in Carbo-nell and Goldstein (1998) . It is based on the assumption that one should consider not only the relevance value, but also the novelty (or equivalently, redundancy) in the presented documents. Informally, given a set of previously selected documents, the next best document is one that is both relevant to the query topic and different from the already selected documents. In the risk minimization framework, we can encode such preferences with a conditional loss function  X  ( d k j d 1 the redundancy value of a document.

If  X  MMR  X  d k j d 1 ; ... ; d k 1 ; h Q ; h 1 ; ... ; h k
If we assume that the parameters h are concentrated at the mode imately equivalent to ranking based on the value of the loss function at the mode, i.e.,
An MMR loss function requires the combination of a relevance measure and a novelty measure. While there may be many different ways to specify such a loss function, the problem of deriving a well motivated loss of this type largely remains an open research question ( Zhai, 2002 ).

Suppose we make the simplifying assumption that a relevance score and a novelty score can be computed independently. In this case we can define our loss function as a direct combination of the two scores. Let S ( h k ; h Q ) be any relevance scoring function and S N ( h
MMR loss function can then be defined as a combination of the two scoring functions as where l 2 [0,1] is a relevance-novelty trade-off parameter, such that One such combination is the linear interpolation of S R and S which is precisely the original MMR formula presented in Carbonell and Goldstein (1998) . Clearly, this loss function makes sense only when the ranges of the functions S
When relevance and novelty/redundancy are computed with a probabilistic model, we can use the fol-lowing general loss function: p (New j d ) is the probability that d is new with respect to documents d
We may reasonably assume that c 3 = c 4 , since whether or not a non-relevant document carries new infor-mation is presumably not interesting to the user. We can also reasonably assume that there is no cost in-curred if the document is both relevant and (completely) new, i.e., c have
For any reasonable loss function, both c 2 and c 3 should be some positive cost, and usually c eral, c 2 and c 3 may change according to k , or even the actual documents d cost of seeing a relevant but redundant document, whereas c
Clearly, when c 2 = 0, so that the user is assumed not to care about redundancy, the loss function is based on the probability of relevance. We assume below that c 2 &gt; 0, which allows us to rewrite the loss function in the following equivalent form for the purpose of ranking documents:
Note that a higher p (New j d ) always helps to reduce the loss, and when c implies a smaller loss. However, reduction in loss affected by the cost ratio c cost of seeing a non-relevant document compared with seeing a relevant but redundant document. When has low tolerance for any non-relevant document, the optimal ranking would essentially be relevance-based, and not affected by the novelty of documents. When c p (Rel j d ) p (New j d ), which is essentially the scoring formula for generating temporal summaries proposed a compromise between retrieving documents with new content and avoiding non-relevant documents. In
Zhai (2002) and Zhai, Cohen, and Lafferty (2003) , this loss function is investigated with p ( Rel j d ) being assumed to be proportional to p ( q j d ) and p (New j d ) being estimated with a mixture language model.
A deficiency in the way the MMR loss function combines the relevance score and the novelty score lies in the assumption of independent relevance and novelty. In other words, one does not have a direct measure of the relevance of the novel information contained in a new document. Thus, a document formed by con-catenating a previously seen (and therefore redundant) relevant document with new but irrelevant informa-tion may be ranked highly, even though it is useless to the user. Several alternative MMR loss functions that directly measure the relevance of the new information are explored in Zhai (2002) . 5.3. Maximal diverse relevance (MDR) loss functions
We now discuss a different type of loss function for the subtopic retrieval task. MMR loss functions aim to increase the subtopic coverage indirectly through eliminating the redundancy among documents. Here the goal is to improve the subtopic coverage more directly by modeling the possible subtopics in the documents. 5.3.1. A general subtopic retrieval model
To model the subtopics, we consider the generative model illustrated in Fig. 3 . We assume that there is a space of A subtopics, each characterized by a unigram language model. Formally, let s =( s vector of subtopics, where s i is a unigram language model and p ( w j s according to the subtopic s i .

Now, let us assume that a user, with an interest in retrieving documents to cover some of these A sub-topics, would first pick a probability distribution h Q over the subtopics, and then formulate a query accord-ing to a query generation model p ( q j s , h Q ). Intuitively, h general would have the probability mass concentrated on those subtopics that are most interesting to the user. Furthermore, among these  X  X  X nteresting subtopics, X  X  the distribution is generally non-uniform, reflect-ing the fact that some subtopics are more important than others. Similarly, we also assume that the author or source of a document d would first pick a subtopic coverage distribution h ing to a document generation model p ( d j s , h D ). A simple example of such a model p ( d j s , h ture model, in which h D are the mixing weights and s are the component unigram language models. That is, with d = d 1 d 2 ... d n , we have However, the derivation below is not restricted to such a mixture model.

To derive a subtopic retrieval model, we start with the following general greedy ranking formula:
This conditional risk gives us a way to evaluate the remaining documents and pick the best d have already selected d 1 , ... , d k 1 . With the generative models given above, h  X  X  s ; h
We now consider the following loss function: where l 2 (0,1] is a parameter indicating how much redundancy we would like to model.

The idea behind this loss function is that we expect h Q to indicate which subtopics are relevant X  X  X  high similar  X  X  X ubtopic coverage distribution X  X  given by all the documents d probabilities to some subtopics, then we would expect to cover these (presumably relevant) subtopics more than other subtopics. The best d k is thus the one that can work together with d erage distribution that is most similar to the desired subtopic coverage based on the query, i.e., p ( a j h parameter l controls how much we rely on the previously chosen documents d topics. If we do not rely on them (i.e., l = 0), we will be looking for a d viously chosen documents, and the best d k would be one that best covers those  X  X  X nder-covered X  X  relevant subtopics. Essentially, we are searching for the d k that best supplements the coverage provided by the pre-viously selected documents with respect to the desired coverage h
Putting this loss function and the subtopic generative model into the conditional risk formula, we have and where b s  X  arg max s p  X  s j q ; C ; U ; ~ S X  , and C k  X f d
Note that we have assumed that s can be estimated using all the documents in the collection, so p  X  s j q ; C ; U ; ~ S X  does not depend on d k and can be ignored for the purpose of ranking d where b h Q  X  arg max h
Thus, we have obtained the following ranking procedure: (1) Estimate s , i.e., b s  X  arg max s p  X  s j q ; C ; U ; (2) Rank all the documents in a greedy fashion, using the conditional risk r  X  d (3) Compute r  X  d k j d 1 ; ... ; d k 1 ; q ; C ; U ; ~ S X  by first computing
In order to make this general subtopic retrieval model operational, we need to specify a query model ( p ( q j s , h Q ) and p  X  h Q j s ; U  X  ) and a document model ( p ( d j s , h
In general, we can plug in any specific subtopic-based generative models to the general subtopic retrieval model, leading to potentially different retrieval formulas. For example, the Latent Dirichlet Allocation (LDA) model ( Blei, Ng, &amp; Jordan, 2003 ) has been explored in Zhai (2002) . 6. Discussion 6.1. A decision-theoretic vie wof retrieval
Treating retrieval from a decision-theoretic view is not new; in the 1970s, researchers were already study-ing how to choose and weight indexing terms from a decision-theoretic perspective ( Bookstein &amp; Swanson, on optimizing the statistical decision about whether to retrieve a document ( Robertson, 1977 ). However, the action/decision space considered in all this early work was limited to a binary decision regarding whether to retrieve a document or assign an index term to a document.

In the risk minimization framework, we have explicitly and formally treated the retrieval problem as a deci-sion-making problem. The decision problem is a more general one where the action space, in principle, con-an interactive process that involves cycles of a user reformulating the query and the system presenting infor-mation. Indeed, a user variable ( U ) and a document source variable ( S ) have been explicitly and formally introduced into the retrieval models in order to allow this level of generality.

A difference between the risk minimization framework and the early decision-theoretic treatment of index-current user and the available evidence. The decision-theoretic view of retrieval allows the risk minimization framework to be more general than other retrieval frameworks such as the probabilistic inference framework proposed in Wong &amp; Yao (1995) and the inference network framework ( Turtle &amp; Croft, 1991 ). 6.2. Risk minimization and the probability ranking principle
The probability ranking principle (PRP) has often been taken as the foundation for probabilistic retrie-val models. As stated in ( Robertson, 1977 ), the principle is based on the following two assumptions: (a) The relevance of a document to a request is independent of the other documents in the collection; (b) The usefulness of a relevant document to a requester may depend on the number of relevant documents
Under these assumptions, the PRP provides a justification for ranking documents in descending order of probability of relevance, which can be evaluated separately for each document.

Using the risk minimization framework, we have derived a general ranking formula for ranking docu-ments based on an ascending order of the expected risk of a document, which can also be computed sep-arately for each document. And we have also made two assumptions: (a) Independent loss . The loss associated with a user  X  s viewing of one document does not depend on any (b) Sequential browsing . When presented with a ranked list of documents, a user will browse through the It is interesting to note the relationship between these two assumptions and the two assumptions made in
Robertson (1977) . The sequential browsing assumption is also made in Robertson (1977) , though it is not explicitly stated, but our independent loss assumption is stronger than the independent relevance assump-tion, since it is possible to define a dependent loss function based on independent relevance. Indeed, the second assumption in Robertson (1977) implies that the utility (or equivalently, the loss) of retrieving one document depends on the number of relevant documents that are ranked above this document, though it does not directly depend on the relevance status of any specific document. The price for this weaker assumption, however, is that the PRP is no longer guaranteed to give a ranking that is optimal globally, but only one that is optimal as a greedy algorithm. The assumption that a greedy algorithm is used to con-single document rather than choosing a ranking of all documents. In contrast, under our assumptions, ranking based on the expected risk can be shown to be globally optimal.

The PRP has several limitations as discussed in, e.g., ( Cooper, 1994 ). First, it assumes that document usefulness is a binary property, but in reality it should really be a matter of degree. The independent loss risk minimization framework by assuming that the loss function depends only on a binary relevance var-iable. Second, a ranking of documents by probability of usefulness is not always optimal. Cooper gave such an example, which essentially shows that the independent relevance assumption may not be true. Robertson discussed informally two ways to extend the PRP to address the possible dependency among documents ( Robertson, 1977 ). Both have been captured in the risk minimization framework. The first is to go from ranking based on probability of relevance to ranking based on expected utility, which we achieve by using a loss function in the risk minimization framework. The second is essentially the greedy algorithm for rank-ing based on the conditional loss function. Thus, in the risk minimization framework we provide a formal way to go beyond the PRP. As stated in Robertson (1977) :
The estimation of probability of relevance for each document may not be the most appropriate form of prediction. The two main questions are:  X  On the basis of what kinds of information can the system make the prediction?  X  How should the system utilize and combine these various kinds of information? These questions represent, indeed, the central problem of retrieval theory.

The risk minimization framework provides a formal answer to both of the questions. The information available to the system includes the user ( U ), the document source ( ( C ). A  X  X  X rediction X  X  consists of selecting a subset of documents and presenting them in some way. However, one can easily imagine other possible  X  X  X redictions. X  X  These factors are combined in a Bayesian decision the-oretic framework to compute an optimal prediction. 6.3. The notion of relevance
The risk minimization framework was originally motivated by the need for a general ranking procedure language modeling approach, within the same unified framework. As discussed in the existing literature, the retrieval problem may be decomposed into three basic components: representation of a query, representa-tion of a document, and matching the two representations. With an emphasis on the implementation of the framework and probabilistic modeling, we make three corresponding assumptions: (1) A query can be viewed as an observation from a probabilistic query model; (2) A document can be viewed as an observa-tion from a probabilistic document model; (3) The utility of a document with respect to a query (i.e., the ranking criterion) is a function of the query model and document model. Flexibility in choosing different query models and document models is necessary to allow different representations of queries and docu-ments. The flexibility of choosing the loss function is necessary in order to cover different notions of rele-vance and different ranking strategies.

As a result of these assumptions, the representation problem is essentially equivalent to that of model estimation, while the matching problem is equivalent to the estimation of the value of a utility function based on the observed query and document. In Bayesian decision theory, utility is modeled by a loss func-tion; a loss value can be regarded as a negative utility value. Thus, we can say that the notion of relevance taken in the risk minimization framework is essentially the expected utility value, which reflects both the user  X  s preferences and the uncertainty of the query and document models. Such a notion of relevance is clearly more general than the traditional notion of independent topical relevance, since the utility can de-may include a user  X  s perception of redundancy or special characteristics of documents or the collection.
This can be seen formally from the dependency of the loss function on variables such as U ,
The traditional notion of independent relevance can be obtained as a special case of this general utility notion by making an independence assumption on the loss function. Under this assumption, the optimal ranking is to rank documents based on their respective expected loss/risk. This expected risk essentially  X  X  X easures X  X  the relevance status of a document with respect to a query. It is interesting to note that such a measure explicitly captures two different types of uncertainty. First, it is assumed that the  X  X  X ontent X  X  or  X  X  X opic X  X  (represented by a model) underlying a document or query is uncertain; given a document or a query, we can only estimate the model. This uncertainty reflects the system  X  s inability to completely under-stand the underlying content/topic of a query or document, so it can be called  X  X  X opic uncertainty. X  X  Second, even if we know the true model for the query and the document, the relevance value of the document model with respect to the query model is still uncertain and vague. This uncertainty reflects our incomplete knowl-is handled through computing an expectation over all possible models, while the relevance uncertainty is resolved through the specification of a concrete loss function.

As we make different assumptions to simplify the computation of the risk minimization formula, we end up resolving this uncertainty in different ways. In the similarity-based model, for example, we resolve the topic uncertainty by choosing the most likely model and relying on a similarity/distance function to mea-sure the relevance uncertainty. The probabilistic relevance model (including the language modeling ap-proach), however, assumes a binary relevance relationship between a query and a document, and addresses the relevance uncertainty and the topic uncertainty within a single probabilistic model. With a binary relevance relationship, a document is either relevant or non-relevant to a query. Thus, the degree of relevance is not modeled. 7. Conclusions This paper presents a general probabilistic framework for text retrieval based on the framework of
Bayesian decision theory. In this framework, queries and documents are modeled using statistical language models, user preferences are modeled through loss functions, and retrieval is cast as a risk minimization problem. This risk minimization framework not only unifies several existing retrieval models within a single probabilistic framework, but also facilitates the development of new approaches to text retrieval through the use of statistical language models. We have discussed how special cases of the framework cover existing retrieval models and lead to new models for subtopic retrieval that go beyond independent relevance.
A fundamental difference between the risk minimization framework and previous retrieval frameworks is that the approach presented here treats retrieval as a decision problem, and incorporates statistical lan-guage models as major components in the framework. While previous work has treated indexing in a deci-sion-theoretic view, no previous work has given a complete decision-theoretic formal model. The decision space may in principle consist of all the possible actions that the system can take in response to a query.
Such a general decision-theoretic view allows retrieval to be modeled as an interactive process that involves cycles of a user  X  s reformulating the query and the system  X  s presenting information. Indeed, one can condi-tion the current retrieval decision on information about the retrieval context, the user, and the interaction history, in order to perform context-sensitive retrieval.

The risk minimization framework makes it possible to systematically and formally study general optimal retrieval strategies. For example, through making different assumptions about the loss function for ranking we have derived an optimal ranking principle, which addresses several limitations of the probability ranking principle. Specifically, when assuming an independent loss function and a sequential browsing model, we can show that the optimal ranking is according to the expected risk of each document, which can be com-puted independently for each document. An interesting implication is that such a ranking is optimal whether the user has a high-precision or high-recall retrieval preference.

The risk minimization framework incorporates statistical language models systematically in a retrieval framework. As a result, the retrieval parameters are usually introduced as part of a statistical language model. This makes it possible to exploit statistical estimation methods to improve retrieval performance erality in formalizing retrieval tasks, the risk minimization retrieval framework further allows for incorpo-rating user factors beyond the traditional notion of topical relevance. We presented language models and dependent loss functions that lead to non-traditional ranking models for the subtopic retrieval task. Preli-minary exploration of these non-traditional retrieval models has shown promising results, demonstrating that the risk minimization framework facilitates modeling non-traditional retrieval problems ( Zhai, 2002 ; Zhai et al., 2003 ).

The special cases discussed in this paper represent only a small step toward exploring the full potential of the risk minimization framework, and interesting future research directions remain. For example, it is pos-sible to further exploit the framework to study automatic parameter setting, document structure analysis, isfying a user  X  s information need is often accomplished through a series of interactions between the user and the retrieval system. With the risk minimization framework, one can formally incorporate these vari-ables and derive personalized and context-sensitive interactive retrieval models. An interesting direction would be to extend the risk minimization framework to formalize an interactive retrieval process, optimiz-ing the utility over a sequence of retrieval interactions.
 Acknowledgement We thank Jamie Callan, Jaime Carbonell, David A. Evans, W. Bruce Croft, Stephen Robertson, William W. Cohen, Rong Jin, Xiaojin Zhu, and several anonymous reviewers for helpful comments on this work. This research was sponsored in part by the Advanced Research and Development Activity in Information
Technology (ARDA) under its Statistical Language Modeling for Information Retrieval Research Pro-gram, contract MDA904-00-C-2106.
 References
