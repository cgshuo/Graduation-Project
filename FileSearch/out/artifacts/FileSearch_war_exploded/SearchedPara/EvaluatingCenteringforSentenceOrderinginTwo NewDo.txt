 As most literature in text linguistics argues, a felicitous text should be coher ent which means that the content has to be organised in a way that mak es the text easy to read and comprehend. The easiest way to demonstrate this claim is by arbitrarily reordering the sentences that an understandable text consists of. This process very often gives rise to documents that do not mak e sense although the information content remains the same. Hence, deciding in which sequence to present a set of preselected information-bearing items is an important problem in automatic text production. Entity coher ence , which arises from the way NP referents relate subsequent sentences in the text, is an important aspect of textual felicity . Centering Theory (Grosz et al., 1995) has been an inuential frame work for modelling entity coherence in computational linguistics in the last two decades. Karamanis et al. (2004) were the rst to evaluate Centering-based metrics of coherence for ordering clauses in a subset of the GNOME corpus (Poesio et al., 2004) consisting of 20 artef act descriptions. The y introduced a novel experimental methodology that treats the observ ed ordering of clauses in a text as the gold standard, which is scored by each metric. Then, the metric is penalised proportionally to the amount of alternati ve orderings of the same material that score equally to or better than the gold standard.
 This methodology is very similar to the way Barzilay and Lapata (2005) evaluate automatically another model of coherence called the entity grid using a lar ger collection of 200 articles from the North American Ne ws Corpus (NEWS) and 200 accident narrati ves from the National Transportation Safety Board database (A CCS). The same data and similar methods were used by Barzilay and Lee (2004) to compare their probabilistic approach for ordering sentences with that of Lapata (2003).
This paper discusses how the Centering-based metrics of coherence emplo yed by Karamanis et al. can be evaluated on the data prepared by Barzilay and Lapata. This is the rst time that Centering is evaluated empirically as a sentence ordering constraint in more than one domain, verifying the results reported in Karamanis et al.

The paper also contrib utes by emphasising the follo wing methodological point: To conduct our experiments, we need to produce several alternati ve orderings of sentences and compare them with the gold standard. As the number of possible orderings gro ws factorially , enumerating them exhausti vely (as Barzilay and Lee do) becomes impractical. In this paper , we mak e use of the methods of Karamanis (2003) which allo w us to explore a referents, CB, transition and violations of CHEAPNESS (denoted with a suf cient number of alternati ve orderings and return more reliable results than Barzilay and Lapata, who used a sample of just 20 randomly produced orderings (often out of several millions). 2.1 Centering data structur es Example (1) presents the rst two sentences of a text in NEWS (Barzilay and Lapata, Table 2): Barzilay and Lapata automatically annotated their corpora for the grammatical role of the NPs in each sentence (denoted in the example by the subscripts S, O and X for subject, object and other respecti vely) 1 as well as their coreferential relations. This information is used as the basis for the computation of the entity grid: a two-dimensional array that captures the distrib ution of NP referents across sentences in the text using the aforementioned symbols for their grammatical role and  X  sentence. Table 1A illustrates a fragment of the grid for the sentences in example (1). 2
Our data transformation script computes the basic structure of Centering (kno wn as CF list) for each row of the grid using the referents with the symbols S, O and X (Table 1B). The members of the CF list are rank ed according to their grammatical role (Brennan et al., 1987) and their position in the grid. 3 The deri ved sequence of CF lists can then be used to compute other important Centering concepts: 2.2 Metrics of coher ence Karamanis (2003) assumes a system which recei ves an unordered set of CF lists as its input and uses a metric to output the highest scoring ordering. He discusses how Centering can be used to dene man y dif ferent metrics of coherence which might be useful for this task. In our experiments we made use of the four metrics emplo yed in Karamanis et al. (2004): Table 2: Comparing M.NOCB with M.CHEAP , M.KP and M.BFP in the NEWS corpus. 2.3 Experimental methodology As already mentioned, pre vious work assumes that the gold standard ordering (GSO) observ ed in a text is more coherent than any other ordering of the sentences (or the corresponding CF lists) it consists of. If a metric tak es a randomly produced ordering to be more coherent than the GSO, it has to be penalised.

Karamanis et al. (2004) introduce a measure called the classication rate which estimates this penalty as the weighted sum of the percentage of alternati ve orderings that score equally to or better than the GSO. 4 When comparing several metrics with each other , the one with the lowest classication rate is the most appropriate for sentence ordering.

Karamanis (2003) argues that computing the classication rate using a random sample of one million orderings pro vides reliable results for the entire population of orderings. In our experiments, we used a random sample of that size for GSOs which consisted of more than 10 sentences. This allo ws us to explore a suf cient portion of possible orderings (without having to exhausti vely enumerate every ordering as Barzilay and Lee do). Ar guably , our experiments also return more reliable results than those of Barzilay and Lapata who used a sample of just a few randomly produced orderings.

Since the Centering-based metrics can be directly deplo yed on unseen texts without any training, we treated all texts in NEWS and ACCS as testing data. 5 Table 3: Comparing M.NOCB with M.CHEAP , M.KP and M.BFP in the ACCS corpus. The experimental results of the comparisons of the metrics from section 2.2 are reported in Table 2 for the NEWS corpus and in Table 3 for ACCS. Follo wing Karamanis et al., the tables compare the baseline metric M.NOCB with each of M.CHEAP , M.KP and M.BFP . The exact number of GSOs for which the classication rate of M.NOCB is lower than its competitor for each comparison is reported in the second column of the Table. For example, M.NOCB has a lower classication rate than M.CHEAP for 155 (out of 200) GSOs from NEWS. M.CHEAP achie ves a lower classication rate for just 44 GSOs, while there is a single tie in which the classication rate of the two metrics is the same. The p value returned by the two-tailed sign test for the dif ference in the number of GSOs, rounded to the third decimal place, is reported in the fth column of Table 2. 6
Ov erall, the Table sho ws that M.NOCB does signicantly better in NEWS than the other three metrics which emplo y additional Centering concepts. Similarly , M.CHEAP and M.KP are overwhelmingly beaten by the baseline in ACCS. Also note that since M.BFP fails to signicantly overtak e M.NOCB in ACCS, the baseline can be considered the most promising solution in that case too by applying Occam' s razor .

Table 4 sho ws the results of the evaluation of the metrics in GNOME from Karamanis et al. These results are strikingly similar to ours despite the much smaller size of their sample. Hence, M.NOCB is the most suitable among the investigated metrics for ordering the CF lists in both NEWS and ACCS in addition to GNOME. Table 4: Comparing M.NOCB with M.CHEAP , M.KP and M.BFP in the GNOME corpus. Our experiments have sho wn that the baseline M.NOCB performs better than its competitors. This in turn indicates that simply avoiding NOCB transitions is more rele vant to sentence ordering than the additional Centering concepts emplo yed by the other metrics.
 But how lik ely is M.NOCB to come up with the GSO if it is actually used to guide an algorithm which orders the CF lists in our corpora? The aver age classication rate of M.NOCB is an estimate of exactly this variable.

The average classication rate for M.NOCB is 30.90% in NEWS and 15.51% in ACCS.
 The pre viously reported value for GNOME is 19.95%. 7 This means that on average M.NOCB tak es approximately 1 out of 3 alternati ve orderings in NEWS and 1 out of 6 in ACCS to be more coherent that the GSO. As already observ ed by Karamanis et al., there results suggest that M.NOCB cannot be put in practical use.

Ho we ver, the fact that M.NOCB is sho wn to overtak e its Centering-based competitors across several corpora means that it is a simple, yet rob ust, baseline against which other similar metrics can be tested. For instance, Barzilay and Lapata report a ranking accurac y of around 90% for their best grid-based sentence ordering method, which we tak e to correspond to a classication rate of approximately 10% (assuming that there do not exist any equally scoring alternati ve orderings). This amounts to an impro vement over M.NOCB of almost 5% in ACCS and 20% in NEWS.
 Given the deciencies of the evaluation in Barzilay and Lapata, this comparison can only be pro visional. In our future work, we intend to directly evaluate their method using a substantially lar ge number of alternati ve orderings and M.NOCB as the baseline. We will also try to supplement M.NOCB with other features of coherence to impro ve its performance.

