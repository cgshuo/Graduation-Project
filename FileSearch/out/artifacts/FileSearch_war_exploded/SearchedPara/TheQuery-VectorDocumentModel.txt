 Categories &amp; Subject Descriptors: H.3.1 Content Anal-ysis and Indexing General Terms: Algorithms Keywords: Document Partitioning, Collection Selection, Document Model Introduction. Modern Web IR systems have to manage collections of billions of documents. The indexes used to represent them are very large data structures, the form of which can have a big impact on the quality and the speed of IR algorithms. Traditionally, two main ways are used to model the documents available: the bag-of-words model, and the vector-space model.

In the query-vector document model, documents are mod-eled with the list of queries they match, along with the rank they get for each. The query-vector representation of a doc-ument is built out of a query-log. A reference search engine is used in the building phase: for every query in the training set, the system stores the first 100 results along with their rank. This creates a matrix, with documents on columns and queries on rows, where each entry is the rank of a doc-ument for a given query.

To be more precise, let Q be a query log containing queries q ,q 2 ,...,q m .Let d i 1 ,d i 2 ,...,d in i be the list of documents returned as results to query q i . Furthermore, let r ij be the rank that document d j gets as result of query q i (0 if the document is not a match).

Adocument d j is represented as an m -dimensional vector d j =[ r ij ] T ,where r ij  X  [0 , 1] is the normalizated value of r
The r ij values form a contingency matrix R (proof in [4]), where we can perform the co-clustering algorithm by Dhillon et al. [3]. This approach creates, simultaneously, clusters of rows (queries) and columns (documents) out of an initial matrix, with the goal of minimizing the loss of information. The result of co-clustering is a matrix b P defined as: coverage of the top results fro m a reference search engine 1 when using only a subset of the available collection: when we measure the coverage at 5 , we see how many of the first top 5 results are present in the first chosen sub-collection, the first 2 collections and so on.

The query-vector representation is built using, as a train-ing set, the first three weeks of our query log, which comprise about 190,000 unique queries. This means that, at the log-ical level, documents are represented by vectors in R 190 , 000 .
Techniques no. 4 and 5 divided the available documents into 16 clusters. The 17th cluster is the overflow cluster, composed of the documents that are never recalled by queries in the training set, represented by empty query-vectors. The overflow cluster is always selected as the last one. In the other cases, the documents are distributed evenly over 17 clusters.

In all cases, we assigned each document cluster to a server of our distributed IR system, and then we used the standard CORI [2] technique to perform collection selection. CORI collects some statistics about the distribution of terms in the collections, and then weights the collections accordingly. With co-clustering, we also used PCAP. With PCAP, the overflow cluster is always queried as the last one. We used the fourth week from the query-log as our test set: the queries from the fourth week were submitted to the dis-tributed search engine, and we measured the coverage we get by returning only documents from 1, 2, 4, 8, 16 and all clusters.

The quality of coverage increases dramatically when we shift from random allocation, k-means on shingles and URL-sorting, to techniques which use the query-vector represen-tation. The simple k-means on the query-vectors is able to reach about 30% coverage (1.47 out of 5) when using only one sub-collection out of 17. Co-clustering improves this fig-ure to 1.57. When we use our collection selection strategy based on PCAP, we are able to cover 34% of the top five documents using only one sub-collection.

These figures are confirmed when we measure the coverage of top-10 and top-20 results, and we shift to later queries (not shown). In general, our proposed approach is able to dramatically reduce the number of collections we need to query to reach a chosen coverage.
 Footprint of the Representation. Every collection selec-tion strategy needs a representation of the collections, which is used to perform the selection. Let X  X  call dc the number of document collections, t the number of terms, qc the number of query clusters and t the number of terms in the queries.
The CORI representation is dominated by a datum called df i,k , which is the number of documents in collection i con-taining term k . Its size it is O ( dc  X  t ). Overall, the CORI representation is composed of about 48.6 million entries be-fore compression.

On the other side, the PCAP representation is composed of the PCAP matrix, with the computed b p , O ( dc  X  qc ), and the index for the query clusters, which can be seen as n i,k , the number of occurences of term k in the query cluster i , for each term occurring in the queries, O ( qc  X  t ). These two terms sum up to about 9.4 million entries, significantly smaller (more than 5x) than the CORI representation. Empty Query-vectors. At the end of the training period,
Zettair, available at http://www.seg.rmit.edu.au/zettair/.
