 In the recent past, the language modeling approach has become popular IR model based on its sound theoretical basis and good empirical success [3], [4], [5], [8], [9], language modeling could have trouble with incorporation of the relevance feedback or query expansion. Relevance feedback (or pseudo relevance feedback) is the well-model, relevance feedback can be well explained in its framework, while language does not explicitly assume a relevance document set [15]. Risk minimization framework and query model concept, suggested by Lafferty and Zhai [8], extend the language modeling approach to incorporate relevance feedback or query expansion. In risk minimization framework, language modeling is re-designed by KL(Kullback-Leiber) divergence between query model and document model. Query model is probabilistic version of user X  X  query sample, which encodes knowl-edge about a user X  X  information need. processing such as pseudo relevance feedback is highly dependent on initial retrieval performance. To improve initial retrieval, query expansion based on word co-occurrence can be one of good strategies. In language modeling approach, word co-occurrence is formulated into translation model [1], [8]. First translation model, sug-gested by Berger and Lafferty, is document-query translation model [1]. This model is expanded with Markov chain word translation model by Laffery and Zhai [8]. Both translation models, expanded language modeling approaches, showed significant improvements over baseline performance. It is highly provable that translation model is useful for query expansion problem. 
However, Markov chain word translation model yields high time complexity. Es-plexity so that the translation model can be easily used in practical situations. 
To achieve this goal, we propose to use parsimonious translation model. This model conceptually belongs to Markov chain translation model, but there is difference in using document language model. In parsimonious translation model, document language model is mixture model with  X  X ocument specific topic model X  and global collection language model. On the other hand, in non-parsimonious translation model, it is mixture model with  X  X LE document model X  and global collection language model. Document specific topic model is the model that eliminates global common portion and leaves document topic portion from MLE document model. framework of the language modeling approaches and query model estimation prob-lem. In Section 3 we examine our query model estimation method, including con-cludes and points out possible directions for future work. 2.1 Kullback-Leiber Divergence Framework Basically, the language modeling approach ranks documents in the collection with the query-likelihood (formula 1) that a given query q would be observed during repeated random sampling from each document model [3], [4], [13], [19], [23]. 1 is document language model for D . 
Laffery and Zhai [8], proposed Kullback-Leiber divergence framework for lan-guage modeling so that allows modeling of both queries and documents and incorpo-rates relevance feedback or query expansion. The risk between documents and query is defined as follows. where p ( w|  X  Q ) is query model, and documents are ranked in inverse proportion to its risk. 2.2 Query Model Estimation Problem Laffery and Zhai [8] suggested Markov chain word translation model, where word translation events occur by random work processes on Markov chain [8], so that train-translation model based on this Markov chain, model construction has high time com-plexity. For given term q, translation model on Markov chain (using one step) is cal-culated as follows. 
Translation model t ( w | q ) means the probability to generate w from document topi-are suggested in relevance model of Lavrenko and Croft [10]. 
We can rewrite formula (3). two terms q and w . To obtain single translation probability, these co-occur probabili-ties must be summed across whole documents. Its time complexity is O ( N ) for given pair w and q , where N is the number of documents. 
At retrieval time, it is not practical to calculate translation probability for entire vo-cabulary for each query term. To make this calculation quickly, a well known strategy is to restrict extraction of term pairs within local context : small windows such as few words or phrase level or sentence level [7], [18], [19], [20]. However, in most applica-tion (e.g, word sense disambiguation), topical context and local context play different roles [7]. Therefore co-occurrence from only local context cannot completely substi-tute co-occurrence from global context. Especially, in query expansion problem,  X  X opically X  related terms should be select ed and expanded. Co-occurrence statistics on context. co-occurrence statistics on only these terms, ignoring non-topical terms of document. To determine highly topical terms in document, document specific topic language model is constructed, which is a type of parsimonious language model for MLE document model [3]. Parsimonious language model enables us to build models that We called this translation model by parsimonious translation model, discriminating from original translation model. this translation model. It is more elaborat ed by applying refinement process. In addi-constructing two-dimensional features such as bi-gram and tri-gram. 3.1 Estimating Document Specific Topic Model As noted in Section 2, document language models are constructed by mixing MLE document language model and global collec tion language model. MLE for document is far from document specific model because it contains global common words. To construct document specific topic model, we assume that documents are generated given document D , the likelihood of document is as follows. where is p ( w |  X  D s ) document specific topic model fo r estimatation (i.e. parsimonious document language model). To maximize the document likelihood, we apply EM algorithm [2]. 
E-step: 
M-step: iterations increase, global collection model is not changed and only document specific topic models are iteratively updated. 
Next, selection process is performed, where only highly topical terms are selected, between 50 and 100). Another method is select_ratio ( P ), where top terms are selected ( P is about between 0.6 and 0.9). 3.2 Parsimonious Translation Model w in the document that includes given term q . Since word translation model is mixture model of different document models, it is one of document language model. As sub-stituting document language model of formula (4) into summation of document spe-cific model and global coll ection model, we further derive translation model. where  X  is a smoothing parameter for mixing document specific model, and collection language model. Conceptually, although  X  corresponds to the smoothing parameter  X  for initial retrieval, we treat  X  differently to  X  . 
Translation model consists of three summation parts: Document specific co-as model which divides document specific co-occurrence model by global likeli-hood p ( q ). 
At offline indexing stage, of these quantities, we need to pre-calculate only docu-calculated easily from information of basic language modeling. 
When using select_top ( k ) method for document specific model, time complexity 2500 which is largely reduced value compared with K 2  X  10,000. In this case, reduction ratio of time complexity is about 4 times. 3.3 Estimation of Pseudo Query Model following, similar to [8]. where  X  Q t is inferred query model directly from translation model. 
Final pseudo query model  X  R t is acquired by mixing MLE query model and above inferred relevance document model using parameter  X  . 3.4 Refinement of Pseudo Query Model Pseudo query model (relevance document model) can be more refined by using KL divergence metric between relevance document and mixture model. Relevance docu-ment model is assumed by mixture model with query model for estimation and global collection model. where  X  is mixing parameter.  X  is selected to minimize KL divergence formula (13). To minimize (13), we apply EM algorithm, similarly to estimation of document specific model. 
E-step: 
M-step: where p [ w  X  Q ] is posterior probability that w belongs to query specific term. 
Here, mixture parameter  X  should be set in proportion to the ratio of query specific portion that included in relevance document model, against global common portion. In this sense,  X  depends on smoothing parameter  X  in translation model. As smoothing next section, experimentation result shows that even if  X  set to 1.0 with non-ous translation model, there is some portion of global topic words. Our EM algorithm [21], and constructing parsimonious relevance model from feedback documents [3], except that KL divergence measure is used instead of likelihood. Our evaluation database is constructed using the KT 1.0 collection and NTCIR-3 test The number of documents (# Docs), the average number of unique terms in docu-ments (UniTerms/Doc.), the number of topics (# Topics), and the number of relevant documents. KT 1.0 collection has the small number of documents in computer science domain, where each document describes abstract level of an article. 
For indexing, we performed preliminary experimentations using various indexing methods (Morphology, word, and bi-character). It is well known that bi-character (n-used in this experimentation. 
In NTCIR-3 Korean collection (NTCIR-3 K), we compare four different versions and (TDNC) combining all topics. Table 2 shows the average number of terms in each query topic. 
For baseline language modeling approach, we use Jelinek smoothing, setting the smoothing parameter  X  into 0.25. This smoothing parameter value is acquired empiri-cally, by performing several experimentations across different parameters. As evaluation measures, in addition to non-interpolated average precision(AvgPr), R-precision (R-Pr, the average precision at the R -th position, where is R is total number of relevant documents) and precision at 10 documents (Pr@10) are also considered. 4.1 Effectiveness of Query Model For query model, each parameter is selected empirically which relatively well per-respectively. In NTCIR-3,  X  ,  X  and  X  are 1.0, 0.1, and 0.4, respectively. 
To construct parsimonious translation model for two different collections, se-lect_top(k) method in Section 3 is used. For each document, K, the number of effec-document. For KT 1.0, K is 32, and 45 for NTCIR-3. 
Evaluation results are shown in Table 3. QM indicates our proposed methods that uses query model from the parsimonious translation model in two different collec-yields better performances and sometimes show significant improvements over baseline method. 
We observe that QM is more robust than baseline, especially when low perform-this experimentation is achieved, where it reaches to 29%. QM sometimes shows low precision at 10 retrieved documents (Pr@ 10). In these topics, many high precise query terms are contained, so that it seems that recall improvement by expansion does not sufficiently complement the precision degradation by down-weighting high pre-shows much better performance over baseline, in overall. 4.2 Effect of the Number Top Selected Terms The important parameter is the number of t op selected topical terms to construct par-simonious translation model. If we use the number as very small value, the time com-changes of effects of query model according to the number of top selected terms, in NTCIR-3 test collection. The parameter  X  ,  X  and  X  are same values to those of Sec-tion 4.1. 
Query models constructed by using small k (such as 5 or 10) increase baseline per-formance, showing comparative performance to query model by using large k (such as reduced in the case of small k . At k = 5, the space complexity is only 5.74% of com-plexity at k = 45 (Time complexity also was significantly reduced). At Pr@10, some experimentation, we have an empirical evidence that high topical terms in documents provide more important effects of query expansion rather than other non-topical that small k s may show better average precisions over large k after post retrieval proc-essing such as pseudo relevance feedback, because pseudo relevance feedback is highly dependent on precision of top retrieved documents. 4.3 Incorporating Relevance Feedback To perform pseudo relevance feedback, we adopt Zhai X  model-based feedback ap-proach using generative model [22]. Zhai X  X  method set final query model as mixture model combining query model acquired from feedback documents (feedback query model) and original query model as follows. where  X  Q X  and  X  F are final query language model and feedback query model respec-tively, and  X  Q is original query model.  X  is mixture parameter between original query model and feedback query model. more expanded by using parsimonious translation model. 
In this experimentation, we performed only non-expanded query model for evalua-Parameter  X  is 0.9. The results of pseudo relevance feedback from baseline feedback documents (baseline + PRF), and pseudo relevance feedback from feedback docu-ments using different selection number k values, are described in Figure 4. 
Interestingly, we found that as k is smaller, performance result of pseudo relevance achieved, which is the best performance in our all experiments. The reason for this is performed using small k values. Although exhaustive experimentations are necessary in the future, from this experimentation, we can conjecture that parsimonious transla-feedback for each selection value k . Summing up, we propose effective construction method for co-occurrence statistics using parsimonious translation model. Parsimonious translation model involves an elegant method for selecting highly topi cal terms in documents, by document specific topic model. Basically, our idea is to use the several state of art methods in language modeling approach for information retrieval. Fr om our experimentation on two differ-ent collections, it seems reasonable to conclude that query model based on parsimoni-models. This work was supported by the KOSEF through the Advanced Information Technol-ogy Research Center(AITrc) and by the BK21 Project. 
