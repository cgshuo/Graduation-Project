 Peer Data Management Systems (PDMS) are a natural extension of heterogeneous database systems. One of the main tasks in such systems is efficient query processing. Insisting on complete an-swers, however, leads to asking almost every peer in the network. Relaxing these completeness requirements by applying approxi-mate query answering techniques can significantly reduce costs. Since most users are not interested in the exact answers to their queries, rank-aware query operators like top-k or skyline play an important role in query processing. In this paper, we present the novel concept of relaxed skylines that combines the advantages of both rank-aware query operators and approximate query process-ing techniques. Furthermore, we propose a strategy for processing relaxed skylines in distributed environments that allows for giving guarantees for the completeness of the result using distributed data summaries as routing indexes.
 H.2.4 [ Database Management ]: Systems X  Query Processing, Distributed Systems ; E.1 [ Data ]: Data Structures X  Distributed Data Structures, Trees Algorithms, Performance, Experimentation P2P, PDMS, Query Processing, Relaxed Skylines, Distributed Data Summaries, QTree, Indexing Multidimensional Data Schema-based Peer-to-Peer (P2P) systems, also called Peer Data Management Systems (PDMS), are a natural extension of feder-ated database systems. In addition to the characteristics evolv-ing from the P2P paradigm (namely autonomous peers with equal rights and opportunities, self-organization as well as avoidance of global knowledge), each peer in a PDMS provides its own data with its own schema. All peers can answer and process queries and are Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. linked to a small number of neighbors via mappings representing schema correspondences.

The expected advantages of such an architecture like robustness, scalability and self-organization do not come for free. Two of the main challenges of query processing in PDMS are (i) dealing with large-scaled settings and (ii) coping with the dynamic behavior, autonomy, and heterogeneity of such systems. As a first conse-quence of the mere size of these systems query strategies should avoid exhaustive flooding of the network whenever possible. Sec-ond, though in general data placement and cost information are not available at a central instance or may change over time, execution costs should be minimized. These considerations lead us to the following two orthogonal approaches that aim at reducing query execution costs by minimizing the number of asked peers and/or the amount of transferred data when processing a query: (a) Routing indexes representing characteristics of data in a given (b) Relaxing exactness or completeness requirements that are usu-Another fact that makes such relaxations and approximations even more interesting is that in large-scaled and highly dynamic P2P systems it is nearly impossible to guarantee a complete and exact query result. The reasons for this are among others possibly in-complete or incorrect mappings, data heterogeneities, as well as incomplete or outdated information about data placement and data distribution. Thus, the most appropriate kind of queries are cer-tainly similarity/fuzzy operations in combination with rank-aware queries in order to restrict the result size to the most relevant ob-jects.

As a special case of these query classes this paper considers sky-line queries [2]. Such queries return for a given set of data objects all those objects that are not dominated by any other object. An object dominates another one if it is as good as or better in all dimensions and better in at least one dimension. As an example assume a query asking for a set of astronomical objects that should be both as bright as possible and as close as possible to a given point in space. In most situations it is not obvious, whether the user would prefer (i) an object that is very close to the given coordi-nates but not as bright as others, or (ii) a rather bright object that is farther away. It is important to present all interesting answers that might meet the user X  X  needs so that he or she can choose the most promising objects. Such a set of interesting objects is provided by skylines.

In this paper, we present an approach for efficiently evaluating skyline queries in distributed environments by applying the two principles mentioned above. Hence, we (1) introduce how to pro-cess skylines efficiently using a subclass of routing indexes that we denote as distributed data summaries. (2) We apply the idea of re-laxation to skyline queries in order to further reduce execution costs and propose a corresponding strategy. (3) We discuss the require-ments that have to be met by routing indexes in order to be useful to our techniques. Furthermore, we propose a tree-based structure for summarizing data as a basis for such routing indexes.
In centralized database systems global knowledge can be ex-ploited for query processing. In such systems the query result is always complete and correct with respect to the given data since all data has been considered. In dynamic environments like P2P systems in general and PDMS in particular flooding the network is much too expensive. Since such systems usually do not provide any global knowledge routing indexes are used to route queries to only those peers that are most likely to contribute to the final result. We discuss such structures in the second part of this section.
Due to the semantic losses and other characteristics of PDMS obtaining exact and complete query answers is difficult or even im-possible. To counteract the problems of dynamics and data het-erogeneities as well as to reduce query execution costs, similarity-based and approximating query operators seem to be ideal for use in such systems. Such operators and strategies leverage the re-quirements of completeness and correctness by avoiding expensive flooding of the network. Hence, some peers have to be left out run-ning the risk of missing some  X  X elevant X  data. This reduces costs but we have to quantify the approximation error and then output that quantification to the user as a guarantee. The most important types of such guarantees are: A probabilistic guarantee could for example have the following form:  X  X ith a probability of 90 percent there is no relevant data in the system that has been left out X . An example is the top-k algo-rithm proposed in [14] for centralized systems. It quantifies the risk of stopping the top-k search by means of a probabilistic guaran-tee that can be influenced by the user. A distance-based guarantee could be used to indicate the deviation limits that have been consid-ered, for example  X  X ithin a deviation of x around the output result items all relevant data has been considered  X . We adopted this sec-ond concept to in our strategy for processing relaxed skylines that we will present in Section 4.
The most prominent examples of approximate query operators are top-k and skyline. Especially in the last few years several ap-proaches have been proposed not only for centralized systems but also for distributed environments.

After having introduced the skyline operator into the field of database research [2] several algorithms have been proposed for centralized systems, e.g., [5, 8]. Recently, there has also been some work regarding skyline computation in the data warehouse scenario [10, 16]. One of the first algorithms that considered processing sky-line queries in distributed environments has been proposed in [1]. On principal, these algorithms are based on the TA algorithm [6, 9] which makes them hardly applicable to non specialized P2P systems since they cannot provide lists in globally sorted order. Such a need for global knowledge is the main problem of exist-ing strategies. Recently, [15] proposed an algorithm that considers distributed processing of skyline queries in structured overlay net-works (CAN). In contrast to PDMS these systems provide informa-tion about data location. In PDMS, however, we do not have such knowledge.
As already motivated in the introduction local routing indexes [3] can be used to enable efficient routing in systems that do not provide any global knowledge. For this purpose we assume that each peer or at least a set of (super-)peers maintains such indexes. Thus, these structures form a crucial part of query processing on that we make the following demands: These requirements let us focus on histograms and tree structures. Histograms are very popular for summarizing data. All kinds of histograms rely on the idea of partitioning the value domain into disjunct buckets and keeping only little information about their contents, e.g., frequency information. In classical database systems histograms are successfully used to provide statistics for selectiv-ity estimation, particularly for arbitrary data distributions. Further-more, recent work proposes the use of histograms not only for ap-proximate query processing in centralized database systems [12], but also for building routing indexes in P2P environments [11]. Multidimensional histograms [13] fulfill another requirement that we pose on data summarizing structures applicable to routing in-dexes  X  they provide information about attribute correlation. But they have one drawback: they do not cope well with sparse data. Moreover, as stated in [4], incremental construction and mainte-nance of histograms are either impossible or at least inefficient.
Indexes based on tree structures are widely used for organizing and accelerating access to large data sets. There are numerous vari-ants of different tree structures, most of them are based on the B-tree or on the R-tree as its multidimensional extension. Sparse data can be handled efficiently and incremental updates as well as incre-mental construction are supported in general. The only drawback of traditional tree structures is that they do not approximate the data, rather they keep information about each single data item. Al-though this is necessary for accelerating access to local data, in the context of routing indexes we need summarizing structures. Sev-eral extensions have been suggested for this problem. One of the most interesting ones for our purpose is the CF-tree that is used for clustering in the BIRCH approach [17]. The nodes of a CF-Tree represent regions where each subtree is summarized by its parent node. The tree can be pruned at any level and regions represent spheric regions  X  described by cluster features.

Though we evaluate our approach for processing relaxed sky-lines using QSummaries (see Section 5.1) other index structures could be used as well as long as they fulfill the above mentioned requirements and allow for identifying regions of data where each region is assigned to one of the neighboring peers. In the follow-ing such structures are referred to as distributed data summaries (DDS) .
In this section we at first define the skyline over regions that allows for integrating DDS data into skyline processing and thus enables an efficient decision on which neighbors to forward the query to. We then propose a distributed query processing strategy that exploits this concept and aims at minimizing the number of asked peers and thus execution costs.
As motivated in the introduction skyline queries are character-ized by the  X  X ominates X  relation -in the following denoted as . An example scenario is shown in Figure 1. It illustrates all infor-mation that an arbitrary peer possesses when processing a skyline query. Assume p 1 , p 2 , p 3 , and p 4 are data points stored locally by this peer. Thus, the exact coordinates of these points are known. Without loss of generality assume that the information of the peer X  X  DDS can be visualized as rectangles. This means that we can con-clude by means of the DDS that there are other non-local data items in those regions without knowing their exact coordinates. In case both dimensions are to be minimized points p 1 and p 2 are members of the result skyline and regions A , B , and C provide further result elements. This is because only the following dominations occur: A p 3 , A p 4 , C E , C p 4 , p 2 p 4 , B D , and B p 4 . Note that A p 2 because a point in the bottom right corner of A would not dominate p 2 . Furthermore, A C since it might be possible that data items exist in A that are located to the  X  X ight X  of C and thus not all data items in A would dominate all data items in C . Considering this dominates relation regions only those neighbors providing information about relevant regions have to be asked in order to answer the query correctly. The main benefit that we gain from these considerations is that we can process a skyline with locally available index information instead of asking the neighbors for all their actual data sets. This gives us the chance to reduce execution costs by far.

The main idea of generalizing the  X  X ominates X  relation in a way that it can be applied not only to data items but also to arbitrary regions ( A and B ) can be formalized as follows: This relation is not limited to regions: one or both of the arguments could just as well be a data item interpreted as a region without extension. For skyline queries Reg can be determined using the idea of a worst and a best data item. If an a worst  X  A and a b can be constructed such that holds, then A Reg B if and only if a worst b best .

All regions containing data items that are elements of the result-ing skyline are elements of the skyline over regions. The reason is that if an arbitrary region B contains a point b that would be part of the result skyline, there cannot exist any other region A that dom-inates B . Assuming that such an A exists leads to a contradiction: All possible elements in A had to dominate all possible elements in B -thus, b had to be dominated by all elements in A . Furthermore, as A is not empty there exists at least one element a  X  A . Conse-quently, we would have found an element a for that a b holds. This is a contradiction to: b is part of the result skyline.
In the following we simply write and apply it on regions, data points as well as on their combinations. Based on this relation it is possible to compute a skyline over the local data of a peer enriched by all the regions that the DDS provide information for.
The considerations above directly lead us to a processing strategy that we can use for processing exact skyline queries in a distributed manner. The algorithm is defined by the following steps that are executed at each peer that receives a skyline query: 1. Calculate the skyline over the local data and all regions pro-2. Forward the query to only those peers that own data de-3. Combine the peers X  answers to a preliminary skyline and Part I of Figure 2 shows more details about local query processing based on using a local cache as well as on the concept of query and answer messages. At first, the initiator computes the skyline ( SL B ) over its local data and the regions described by its DDS (line I.1) using the dominates relation Reg of Equation 1. Then it stores SL B into the cache (line I.2). Finally, it forwards the query to those neighbors that provide data in the regions that are element of SL B (line I.3). Figure 3 reveals more details about this step. In case there are no neighbors that the query has to be forwarded to, the initiator outputs its skyline to the user and query execution is finished. A query that is forwarded to other peers contains all those data items that are part of the locally processed skyline and whose exact coordinates are known, i.e., SL B without regions. Having their exact coordinates the receiving peer can use them to prune some of its neighbors from consideration.
 In principle, each peer that receives a query acts in the same way. Part II of Figure 2 shows how any peer in the network reacts upon receiving a skyline query from another peer. In contrast to the ini-tiator such a peer has to ignore those regions of its DDSs that are provided by the peer that it has received the query from. Then (line II.2) the peer computes a skyline over regions ( SL , using Equa-tion 1) based on the remaining regions, its local data, and those data items that have been received along with the query ( SL sender Those data items that are part of SL are stored in the cache and forwarded to those neighbors that provide data in regions that are part of SL using again the algorithm described by Figure 3.
When a peer receives an answer message (part III of Figure 2) it checks the received data for dominance by any of its cached data items. This result is either stored in the cache or in case all asked neighbors have already answered forwarded to the sender of the query. Finally, the initiator has received all answers of those neigh-bors that the query has been forwarded to and displays the result to the user.
In the previous section we have introduced a strategy that ex-ploits DDS for processing exact skylines. Based on that strategy this section focuses on how to reduce execution costs by relaxing the completeness requirement. Thus, this section first gives a defi-nition of relaxed skylines and then presents a strategy for process-ing them.
The exact skyline algorithm as stated in Section 3.2 uses dis-tributed data summaries to avoid expensive flooding. In order to further reduce network load, we propose computing a relaxed sky-line that makes it possible to significantly reduce query execution costs at the expense of result quality. The idea was inspired by the concept of thick skylines [7] that not only contain the actual sky-line points but also all points within a certain distance around them. Quite contrary to this, we allow a skyline point to be represented by any point within a predefined distance.

Before formally defining a relaxed skyline let us illustrate the idea by means of Figure 4. Assuming a skyline query asks for min-imizing both dimensions 4(a) shows the exact answer with solid black circles indicating result points. 4(b) shows the corresponding relaxed skyline where many skyline points can be represented by only a few points (solid black circles). Each light grey area illus-trates the region that is represented by the one representative in its center. As this example suggests and as our evaluation will show relaxed skylines can be used to reduce query execution costs. Formal Definition . Given a set D of data objects, a skyline a distance function d : D  X  D  X  R , and a limit  X   X  R , then any subset R of D for that holds, is called a relaxed skyline . Furthermore, if for r, s d ( r, s )  X   X  holds, r is called a representative of s . Thus, a relaxed skyline can be defined as a set R  X  D that contains a representa-tive for each skyline point s  X  S S ( D ) . Note that there are usually many R  X  D that fulfill Equation 2. Furthermore, several skyline points can be represented by one single representative. This fact is a main advantage in comparison to classic skyline queries. As already shown in [2] skylines of anti-correlated data sets can result in skylines with large numbers of points; querying a relaxed sky-line reduces the result set but still provides the user with the  X  X ig picture X .
The concept of relaxation reduces costs at the expense of accu-racy. Thus, the higher the user-defined relaxation the lower are the costs but the higher is the loss of accuracy. In general, that loss can be neglected. For some applications, however, this might be a problem. Assume we are looking for hotels that are both cheap and close to the beach. The best hotel for a user, e.g., a hotel that clearly dominates its representative, might not be part of the relaxed skyline. Booking the representative hotel is not the optimal choice. The user most likely issued the query to find out about his options without having to define what is more important to him in advance (distance to the beach or price). So, after having made a decision, he can still issue a more specific query that concentrates on one of the represented regions only.
Since the  X  value limits the maximum approximation error that the algorithm is allowed to make it has to be specified in advance and added to the query definition. The same applies to the distance function that is used for processing the query. The strategy for processing relaxed skylines is based on the one for exact skylines presented in Section 3.2. The most important difference between the two strategies is that now after having processed the skyline over regions locally each peer tries to represent the skyline regions with already known data items. Doing so the number of peers to be asked can be reduced. In analogy to the algorithm for process-ing exact skylines, Figure 5 illustrates the algorithm for relaxed skylines that can be summarized by the following steps that are executed at each peer: 1. Calculate the skyline over regions on the union of (i) sky-2. Try to find local representatives for all regions in the sky-3. Forward the query to all p i  X  P ask . The query includes all 4. After all queried neighbors have answered: determine the 5. Try to minimize the number of representatives of the skyline The algorithm includes several peculiarities that deserve further ex-planation. In the following, we at first describe how to determine representatives for regions (lines I.2 and II.3 of Figure 5). Next, we discuss how to compute skylines over representatives since this is necessary in step 4 (line III.1). Finally, we present how to minimize the number of representatives in step 5 (lines III.2 and III.3). Determine Representatives . In step 2 it is necessary to find rep-resentatives for regions in order to reduce the number of peers to forward the query to. The algorithm chooses representatives out of the set of known data items, i.e., all data items whose exact co-ordinates are already known. In the best case all regions that are part of the skyline over regions (resulting from step 1) can be rep-resented by known data items so that the query does not have to be forwarded at all.

More precisely, choosing representatives means: Given a skyline region B , a distance function d and a distance  X  ,wehavetofind a set of local data items D loc that represents B w.r.t. the given skyline specification, so that for any point p  X  B , there exists a local data item l  X  D loc for that d ( p, l )  X   X  holds. Since we do not know where the original data of the region is located it is not sufficient to represent a region with just one representative for its best point w.r.t. the skyline specification.

Figure 6(a) illustrates this aspect -consider a skyline query where both dimensions have to be minimized. Given a region B and a representative r the best possible data item that might be el-ement of B is b . One might think that r is a proper choice for representing region B as the distance between b and r is smaller than  X  (w.l.o.g. assuming Euclidean distance). But in case B only represents points s 1 and s 2 representing B with r is not correct be-cause no data item is chosen that is near s 1 and s 2 although both could be member of the exact skyline.

This is why it is not possible to represent such a large region correctly with only one representative. 6(b) shows an example of how to do this correctly. The problem we encounter is to find a minimal set of representatives that correctly represents a region. Unfortunately, this is a hard problem. Heuristics seem to be a good possibility to solve this problem. To keep things even more simple, our implementation so far only represents regions when it is pos-sible to represent them by means of one single representative  X  as illustrated by Figure 6(c). Whenever this is not possible we forward the query to the corresponding peer. Skyline Computation over Representatives . Step 4 computes a skyline over the answer data of neighbors, the local result and rep-resentatives for those regions of neighbors that the query has not been forwarded to. Consequently, we have to extend the dominates relation once more so that it can be applied on representatives as well. In order to do this, we generalize the dominates relation over regions Reg to a relation Rep over representatives. We consider each representative R to be a pair ( r, B ) where B is the represented region of the skyline and r denotes the set of data items that is used to represent B (as we use only one data item for representing re-gions, r only consists of one data item). Considering two arbitrary representatives R =( r, B ) and R =( r ,B ) , we define Rep follows: It can easily be shown that if any representative R dominates an-other representative R no data item in the represented region B of R can be part of the resulting skyline. Thus, discarding a domi-nated R is safe and will not lead to any failures in terms of missed or non-represented skyline points.
 Minimizing the Number of Representatives . Finally, step 5 needs to minimize the number of representatives that remained in the skyline. For this purpose, we split the representatives in two lists: R for the data items that represent the regions and regions that are represented. Given these two lists we try to find a minimal subset of R that still represents all skyline regions As this is the NP-complete problem S ET C OVER we either have to come up with a specialized algorithm that leverages certain proper-ties of our data set or  X  X epresents X  relation or we could use a heuris-tic to efficiently solve this problem. As we want to provide a gen-eral solution we use the heuristic sketched in Figure 7. Figure 7: Method minimizeRepresentatives( reps ) After having split the representatives as described above, sorted in descending order by the number of regions the entries could represent. We start with an empty set of chosen represen-tatives. For each region B  X  X  we try to find an already chosen pair of ( r ,B ) where r can represent the merged region B without violating the approximation constraints defined by d and  X  . In such a case we merge the two regions and obtain a larger region that is represented by r . If there is no such pair that has al-ready been chosen we choose an element of R that could represent B . Since we have sorted R , those r  X  R that could represent the most regions are considered first and therefore favored. After all regions of B are represented, the algorithm returns the new (hope-fully smaller) list of representatives.
 In this section we have introduced the notion of a relaxed skyline. We have also presented a strategy for distributed query processing that allows for reducing the number of peers to be asked by effec-tive query planning deploying the concept of a skyline over regions and taking information about regions of the data space into account. Note that as long as the information provided by the DDS are cor-rect the algorithm does not make any errors since all information that has been left out is correctly represented by representatives . The next section proposes an example structure for DDS that sup-ports our skyline strategy. In Section 2.2 we have identified the basic characteristics of DDS: indexing multidimensional data, efficient look-ups, effi-ciently dealing with sparse data, and supporting incremental con-struction and updates. As already discussed histograms are a promising basis for DDS. Representing regions is a native char-acteristic of R-trees. Combining these two approaches leads us to the QTree that inherits the benefits of both approaches. In this sec-tion we first define the structure of a QSummary as an example for DDS using the QTree  X  that we present afterwards  X  as basis. We only sketch construction and maintenance aspects since the focus of this paper is not index maintenance but processing relaxed sky-lines. Note that the QTree and the QSummary are not restricted to the strategy presented in this paper. Instead, the structure can be used for any query processing strategy that wants to exploit infor-mation about the data neighboring peers provide.
Since there exists no global knowledge in PDMS that could tell us where to look for relevant data with respect to a given query, each peer has to maintain a data summary. This summary has to summarize all the data that can be accessed by forwarding the query to the peer X  X  neighbors such that the requirements of Section 2.2 are fulfilled. To enable query routing (and thus to avoid flooding) the information about what data can be accessed via which neighbor has to be kept separately for each neighboring peer. Consequently, we need a base structure that represents the data of each neighbor. This base structure does not only represent the neighbor X  X  local data but also aggregates the data that is accessible via that neighbor in a predefined hop count horizon [3]. Definition: QSummary . In this paper, we present the QSummary as an example for DDS using the QTree as base structure. Before defining the QTree in Section 5.2 let us first define a QSummary with Figure 8 as an illustration. A QSummary maintains one QTree for each neighbor. The resource consumption for a QSummary is restricted and defined at the QSummary level. Thus, there is no restriction on how to use the given resources. This is an advantage since  X  as long as it reduces the overall approximation error  X  it is for example possible to use three quarters of the resources for describing the data of just one neighbor.
The QTree is a tree-based structure that consist of nodes each of which defined by means of a rectangular multidimensional bound-ing box. Such a minimal bounding box (MBB) describes the region in the data space that is represented by the subtree with the box owning node as root node. Thus, just as in R-trees, a child node X  X  bounding box is completely enclosed by the one of its parent. In order to limit memory and disk space we replace subtrees with spe-cial nodes that we named buckets . Buckets are always leaf nodes and leaf nodes are always buckets. Only buckets contain statistical information about those data items that are contained in their MBB. The smallest buckets consist of only one data item. Consequently, their MBB has no extension. Buckets may contain almost any kind of statistical data. However, in this paper we only consider buck-ets providing the number of data items that are contained in their MBBs. Each QTree is characterized by two parameters: In contrast to R-trees a QTree does not necessarily have to be bal-anced. Enforcing balancing would result in a rather large main-tenance overhead and yield some difficulties for rebalancing algo-rithms since buckets only approximate the data and do not have global information about each single data item. Furthermore, un-balanced QTrees usually yield a better approximation quality than balanced trees since balancing is often a contrary goal to clustering and minimizing the approximation error.

Figure 9 illustrates a two-dimensional QTree with the following parameters: f max =3 , b max =5 . Figure 9(a) describes the original data, Figure 9(b) the QTree X  X  bounding boxes, and Figure 9(c) the QTree with its buckets and inner nodes. Inner nodes are represented by ellipses and buckets by rectangles.
The QTree is constructed iteratively by inserting one data item after another in a top-down fashion. In case there already exists a bucket whose MBB encloses the data item, then the only thing to do is to adapt that buckets X  statistics. In case there is no such bucket a new bucket is created with only the data item as content. When inserting a bucket B we start at the root node and iteratively choose that child node whose MBB totally encloses B  X  X  MBB. In case B is contained in more than one child X  X  MBB we proceed with that child whose MBB center coordinates have the least distance to the center of B  X  X  MBB. Having found node n i that is the first to have no child whose MBB totally encloses B , B is inserted as a child of n . Of course, the constraints defined by f max or b max have to be checked and enforced.
For this purpose, we maintain a priority queue that contains pairs of sibling-buckets (i.e., buckets with the same node as parent) and a penalty that indicates the increase of approximation error that is committed when merging the pair of buckets. Hence, we always choose those two sibling buckets for merging that minimize the penalty function defined by Equation 3 (greedy strategy). For two arbitrary buckets ( B 1 , B 2 )  X  denotes the penalty for merging these two buckets.
 The QTree owes its name to this structure that allows for efficiently reducing the number of buckets while minimizing the increase of the approximation error. The penalty function P M as introduced above represents a measure for the approximation error that we face when we merge buckets. Since we are aiming at clustering data into buckets we are interested in rather  X  X mall X  MBBs since they promise to minimize the approximation error. Thus, an easy but quite effective penalty is defined by the MBBs maximum extension in any dimension:
N.low [ i ] and N.high [ i ] ( N.low [ i ]  X  N.high [ i ] lower and upper boundaries of node N  X  X  bounding box in dimen-sion i .
Concerning construction and maintenance there are three special aspects to consider: 1. constructing DDS for a fresh network 2. peers joining and leaving the network 3. peers updating their local data The second aspect can be regarded as a special case of the third one. The main reason for this is that a peer that leaves or joins the network can send an update message to its neighbors. Such a message encodes that all the peer X  X  data was removed or added so that the neighbors can adapt their DDS accordingly.
 Construction . The construction of QSummaries can be imagined as flooding the network from the leaf nodes to the root (first phase) and back (second phase), see Figure 10 for an illustration. For ini-tializing the network we assume to know most of the peers that par-ticipate in the network. These peers could just as well be regarded as the super peers of a super peer architecture. Consequently, it is possible to synchronize the peers so that the first phase is started at the same time synchronously at the leaf nodes. These are all those nodes that have only one neighbor, i.e., only one link to another peer. All such peers send their local data by means of a QTree to their neighbors. These neighboring peers (i) receive the data, (ii) add that information to their local QSummary, i.e., adding the buckets to the QSummary X  X  QTree that corresponds to the data X  X  sender. If all neighbors except one have sent their QTree then the receiving peer (iii) builds a QTree that contains the buckets of the received QTrees and its local data and (iv) sends the result to the one neighbor that has not yet sent its QTree.

In case data of all neighbors has been received, the second phase begins (for illustration see Figure 10 right hand side). In this case the peer sends the received information along with information about its local data to its neighbors (for each message excluding the information originating from the receiving peer itself). Note that there is the possibility that there exist more than just one such peer. Once all leaf nodes have received such messages the con-struction process is completed.
 Maintenance . After having constructed QSummaries in the initial-ization phase these structures have to be maintained and updated. In order to propagate changes efficiently we propose a threshold prop-agation strategy ( TPS ) that propagates changes when a predefined threshold of changes is reached. Before presenting this strategy more detailedly we have to discuss two basic principles: (i) how to encode updates, (ii) how to measure changes of data.

The first problem can be solved by using AR (Add/Remove) lists where each update can be represented by at most two entries (one  X  X emove X  and one  X  X dd X  entry). Each entry of such a list is de-fined by the tag  X  X dd X  or  X  X emove X , the coordinates (i.e., indexed attribute values) of the data item, and a hop distance that indicates the distance of the peer which the change originates from. In case a hop count is defined this value allows for pruning the entries.
Solving the second problem means defining a measure for the changes in relation to the amount of data. Since we are working with QTrees and each peer maintains a QTree for its local data, we define the change of local data  X  L as the average change of the QTree X  X  buckets. The change of a bucket is twofold, first there is the change of the MBB X  X  size and second there is the change of statistics.

The enlargement of a bucket X  X  size is defined as follows: where E denotes the maximum extension (length) of a bucket in all dimensions. E is defined as ( b.high and b.low indicating bucket b  X  X  upper and lower boundaries): As a measure for the change of a bucket X  X  statistics we use Equa-tion 7 which defines the average percentage change of bucket b  X  X  statistics, where stat denotes the number of data items that b is representing. In order to define an appropriate measure  X  for the change of one bucket we have to combine the measures of Equations 5 and 7, obtaining:  X  ( b )=  X  1  X   X  1 ( b )+  X  2  X   X  2 ( b ) , X  1 , X  2  X  [0 , 1] where  X  1 and  X  2 are weighed according to the corresponding weights  X  1 and  X  2 . So the average change of all buckets that ex-presses the change that occurs in one QTree can be defined as fol-lows: where B represents the set of all buckets that the QTree contains.
A change propagation message received from neighbor i con-tains all the changes for that neighbor. So we can determine the change rate for neighbor i by adapting the QSummary X  X  QTree for i and computing the change rate  X  i of that QTree as defined by Equation 9. Thus, we define the total change rate  X  T by the follow-ing equation: where NB is the set of all neighbors.

Figure 11 sketches the TPS algorithm for a peer that receives up-dates ( U R ) from one of its neighbors ( N origin ). At first, the index structure (QSummary) is adapted, i.e., the QTree corresponding to N origin is adapted (lines 1-5). In case local updates occurred a peer adapts the QTree for its local data ( localQT ree ) in the same way  X  that QTree originates from the one that has been built in the construction phase. In both cases the QTree remembers the updates that have not yet been forwarded to neighboring peers. If the total change rate  X  T (lines 6-7) exceeds the threshold  X  then all known updates from the time when the last propagation took place up to this moment are forwarded to the neighbors (lines 9-16). Note that we have to take care not to send updates back to a neighbor that they were received from in the first place (line 13). Furthermore, we have to prune the updates according to the limited horizon de-fined by the hop count (line 11). Using such a limitation is common for routing indexes since this allows for reducing update costs. Af-ter all update messages have been sent to the neighbors the update records that are maintained by the QTrees are reset (lines 15-16). As an indication that there are no recent updates, error rates  X   X 
T are 0 at this moment. Figure 11: Method thresholdPropagation( U R , N origin )
In this section we evaluate the performance of the skyline algo-rithms presented in Sections 3 and 4. As an example for DDS we use the QSummary that we introduced in Section 5. For the tests in this section we used four different setups. Each of these setups is based on the same cycle-free topology of 100 peers where each peer has 50 four-dimensional data items (all dimensions/attributes are restricted to [0 , 1000] ), uses a maximum fanout ( f a maximum number of buckets ( b max )of 50 for its QSummary. The characteristics that distinguish these setups are: 1. Random Data, Random Distribution : The attribute values 2. Clustered Data, Random Distribution : 100 cluster cen-3. Clustered Data, Clustered Distribution : A cluster center is 4. Anti-correlated Data, Random Distribution : For each data In order to arrange a setup based on which we can evaluate our skyline processing strategies we used the construction algorithm of Section 5.3 to build up QSummaries. In the following we want to evaluate the performance of relaxed skylines without interference from non complete index information. Thus, we do not limit the horizon of the indexes.
For all our tests we used the Euclidean distance as distance func-tion and defined the skyline as MIN(attribute1), MIN(attribute2), i.e., minimizing both dimensions. At first, let us illustrate the dif-ference between an exact skyline and a relaxed skyline by means of Figures 12(e) and 12(f). Each box represents the data space and shows data items (grey points), skyline points (black points), rep-resentatives (crosses), and buckets (rectangles). Only buckets that are represented by one of the representatives  X  and therefore part of the final result  X  are pictured. Both figures illustrate the influ-ence of the relaxation parameter  X  on the result that is displayed to the user using two different setups. The box labeled with  X  corresponds to the result of an exact skyline evaluation. We see that the data and its location in the network have an impact on the relaxed skyline. If each peer owns a cluster of data it is difficult to find a local representative for a neighbor X  X  data. Thus, having such a cluster configuration as in Figure 12(e) regions can only be represented when allowing relatively large values for  X  . The other extreme is anti-correlated data that is distributed randomly among all peers. The results are shown in Figure 12(f). In that case even using a small  X  enables peers to represent data of other peers with local elements.

As we have explained in Section 4.2 the algorithm checks whether one representative can represent more than just one re-gion. Merging representatives also means merging the represented regions. So far, we only consider rectangular regions. Hence, merg-ing results in bigger rectangular regions that become more impre-cise the larger they grow  X  as Figure 12(f) indicates. To counteract this problem, we could choose not to merge regions at all or to use polygons to define them.

Figures 12(a) and 12(b) show the influence of the relaxation pa-rameter  X  on the resource usage (number of asked peers, data vol-ume) that is necessary to answer the query. The first thing to notice is that in comparison to a simple flooding of the network using QSummaries as routing indexes reduces execution costs. In the cases of setups  X  X andom Data, Random Distribution X  and  X  X lus-tered Data, Random Distribution X  the reduction is not as big as for the other setups because when clustered data or random data is randomly distributed among peers it is hard to find local represen-tatives for a small  X  . The basic tendencies for all four setups are pretty much the same. The higher  X  the less peers have to be asked and thus the number of messages as well as the data volume are reduced.

But how  X  X ood X  is the query result in relation to the exact re-sult? Figure 12(c) answers this question. It shows the average deviation (Euclidean distance) of each exact result item from the corresponding relaxed result item in dependency on the chosen  X  . Of course, flooding the network always leads to a deviation of 0 (a) Number of Messages, Forwarding Local Skyline (d) Number of Messages, Not Forwarding Local Skyline since it always leads to the exact result. The deviations for the other setups are also relatively small in comparison to the allowed one (  X  ). Only in the case of clustered data in a clustered distribu-tion we have to deal with a higher deviation. This is because when we choose a local representative for a region we have to choose a local data item which is part of another cluster and thus, the dis-tance is higher than it would probably be in a random distributed scenario. Consequently, the deviation for the setup where cluster data was distributed randomly is significantly lower. Note that this is only the deviation from the exact result not an  X  X rror X . As long as the QSummaries are correct in terms of reflecting the current state of the network, our algorithm does not commit an error. It only accepts a deviation between the returned result and the exact one. But since the algorithm quantifies this deviation when returning the result (in terms of representatives and regions), the algorithm does not commit an error.

The number of messages that we see in Figure 12(b) reveals an astonishing effect, namely that the flooding approach performs well in terms of data volume though performing bad in the number of messages. The reason for this is that our algorithm forwards the local skyline result along with the query and representatives along with the answer. Of course, this increases the data volume. Fig-ure 12(d) shows what happens to the number of messages when we do not forward the local result along with the query. In comparison to Figure 12(a) we see that the number of messages rises when we do not forward the local result. This is because each peer can only use its local data to prune its neighbors from consideration. Since preceding peers might already have found  X  X trong X  skyline points that would dominate additional regions, forwarding the local re-sult along with the query reduces the number of peers and thus the number of messages. Since minimizing the number of messages and thus reducing the number of peers to ask is in general more im-portant than minimizing the data volume we can accept the increase of data volume.
As we have already seen above, the data and its distribution have an impact on the performance of query processing strategies. The reason for this is that routing is based on indexes that summarize the data of neighboring peers. So what impact has the setup on the indexes we use, i.e., on a QTree? Figure 13(a) reveals the an-swer to this question. E as defined by Equation 6 is a measure for the approximation quality  X  normalized by the maximum pos-sible extension of a bucket ( [0 , 1000] for our data). Obviously, the higher the number of buckets that we allow a QTree to have the better the approximation and the lower the error. This should be the case for all summarizing structures: using more resources has to improve the approximation quality. Of course, random data is hard to summarize because there simply are no clusters that could be represented with low losses. Derived from this a higher cluster radius should lead to a lower approximation quality. This is exactly what the two clustered data lines show us. Remember dist is the interval [-dist , dist ] that we used as offset to the cluster centers. We also examined the performance of the Threshold Propagation Strategy (TPS) that we presented in Section 5.3. Figures 13(b) and 13(c) show the results of our tests in that we varied the threshold  X  .  X  =0 means that updates are spread immediately. The average global error is defined as the total change rate  X  T (Equation 10) averaged over the whole simulation and over all peers. For these tests we used the  X  X andom data, random distribution X  setup that we used in the tests before. A change size of x % means that the change in each dimension of a data item is limited to at most x of the total dimension range ( [0 , 1000] ). Low frequency means that in each time step only 10 data items in the network are updated and the total number of updates is 250 ( 5% of all data items in the network). High frequency means that there are 40 updates per time step and the total number of updates is 1000 ( 20% ). The total number of messages that are needed to spread all these updates in the network is shown in Figure 13(b). The general tendency is quite clear: (i) the higher the change rate and the change frequency the higher is the corresponding number of messages and (ii) the higher  X  the less messages. In comparison to Figure 13(c) we see that as the number of messages decreases the error rises  X  due to the higher value of  X  . In this section we have shown that the costs for processing skyline queries can be reduced by using routing indexes  X  QSummaries in our case. Execution costs can further be reduced by applying the concept of relaxed skylines using distributed data summaries. As long as the indexes are correct a relaxed skyline does not commit an error because the worst case deviation from the exact answer is output to the user as a guarantee in the form of representatives and regions. Keeping in mind that the reason for issuing a skyline query is giving a ranked overview over  X  X ood X  data items in the system without defining any weights, a user most likely prefers to retrieve only some representatives rather than all the points of the exact skyline where many of them differ only slightly in their attribute values. Additionally, the user is also provided with further infor-mation: (i) the number of data items that are represented by each representative and (ii) the corresponding regions (buckets). If the user is interested in a certain region he might issue a more specific query. The user benefits in two ways: (i) getting an overview rather than being glutted with detailed information, (ii) reducing response time because less peers have to be asked and less data volume is generated the more the skyline is relaxed.

We also showed how the approximation quality of the QSum-maries is influenced by the data they summarize. The threshold propagation algorithm that we proposed for maintaining QSum-maries reduces maintenance costs at the expense of approximation quality. Dependent on the approximation error the user is willing to take, maintenance costs can significantly be reduced.
In this paper, we have presented strategies for processing sky-line queries in distributed environments using a subclass of routing indexes called distributed data summaries. Using such structures allows for reducing query execution costs by efficiently routing the query to only those peers that provide relevant data with respect to a given query. In order to reduce execution costs any further we introduced the concept of relaxed skylines. In conjunction with distributed data summaries processing such queries is efficient and still provides the user with the big picture. The maximum relax-ation, i.e., the maximum distance between a representative data item and the worst point of the represented region, is defined by the user when issuing the query. So the user himself specifies the maximum relaxation he is willing to take. Though we evaluated these strategies by using QSummaries  X  combining the advantages of histograms and R-trees  X  any other kind of routing index that ful-fills the requirements of distributed data summaries can be used as well. Our evaluations show that execution costs can significantly be reduced by applying the query processing strategies we proposed in this paper. In future work we plan to further improve this strategy  X  for instance to find heuristics how to represent a bucket with more than just one representative. Additionally, future work will focus on maintenance and construction of the QTree and the QSummaries. [1] W.-T. Balke, U. G  X  untzer, and J. Xin Zheng. Efficient [2] S. B  X  orzs  X  onyi, D. Kossmann, and K. Stocker. The skyline [3] A. Crespo and H. Garcia-Molina. Routing Indices For [4] D. Barbar  X  a et al. The new jersey data reduction report. IEEE [5] P. Godfrey, R. Shipley, and J. Gryz. Maximal vector [6] U. G  X  untzer, W.-T. Balke, and W. Kiessling. Optimizing [7] W. Jin, J. Han, and M. Ester. Mining thick skylines over large [8] D. Kossmann, F. Ramsak, and S. Rost. Shooting stars in the [9] A. Lotem, M. Naor, and R. Fagin. Optimal aggregation [10] J. Pei, W. Jin, M. Ester, and Y. Tao. Catching the best views [11] Y. Petrakis, G. Koloniari, and E. Pitoura. On Using [12] V. Poosala, V. Ganti, and Y. Ioannidis. Approximate query [13] V. Poosala and Y. Ioannidis. Selectivity estimation without [14] M. Theobald, G. Weikum, and R. Schenkel. Top-k query [15] P. Wu, C. Zhan, Y. Feng, B. Zhao, D. Agrawal, and A. El [16] Y. Yuan, X. Lin, Q. Liu, W. Wang, J. Xu Yu, and Q. Zhang. [17] T. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: An
