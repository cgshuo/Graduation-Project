 Expertise retrieval has received increased interests in recent years, whose task is to suggest people with relevant exper-tise. Motivated by the observation that communities could provide valuable insight and distinctive information, we in-vestigate two community-aware strategies to enhance exper-tise retrieval. We first propose a new smoothing method us-ing the community context instead of the whole collection for statistical language model in the document-based model. Furthermore, a query-sensitive AuthorRank is proposed to model the authors X  authorities according to the community co-authorship networks, and then an adaptive ranking re-finement method is developed to further enhance expertise retrieval. Experimental resu lts demonstrate the effective-ness and robustness of both community-aware strategies. Categories and Subject Descriptors: H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  retrieval models, search process General Terms: Algorithms, Experimentation Keywords: Expertise retrieval, language model, commu-nity, AuthorRank
Expertise retrieval refers to the process of identifying a set of persons with relevant expertise for the given query. Tradi-tionally, the expertise of a person is characterized based on the documents associated with the person. One of the state-of-the-art approaches [1, 3] is the document-based model us-ing a statistical language model to rank experts. However, previous algorithms mainly consider the documents that are associated with the experts, while ignoring the community information that is affiliated with the documents and the experts. Therefore, it is essential to utilize the community-based information to enhance the expertise retrieval.
Given a set of documents and their authors, it is possi-ble and often desirable to discover and infer the community information, in which contains a number of documents and Figure 1: An example graph with two communities authors for each community. Our approach is to deal with the expert-finding task in a real-world academic domain. Thus, it is reasonable to assume the academic communities have been formed automatically in the form of conferences and journals, where the researchers publish their papers, ex-change their ideas, and co-author with each other.
We assume each document d i canonlybelongtoonecom-munity C k , and each author a j of the document is affiliated with the corresponding community C k , so a single author may belong to multiple communities. An illustrated graph with two communities is sketched in Fig. 1. In this exam-ple, d 1 and d 2 as well as their associated authors form the community C 1 , and meanwhile d 3 , d 4 and d 5 as well as their authors form the community C 2 . With such information, the community can be represented from two different perspec-tives, so as to obtain the community context (text informa-tion) based on the papers and the community co-authorship network based on the authors.

In this paper, we propose two community-aware strate-gies to enhance the expertise retrieval. The first one is the community-based smoothing method for statistical lan-guage model, which is employed to identify the most rel-evant documents so as to reflect the expertise retrieval in the document-based model. Moreover, the second strategy is developed to boost the document-based model using the community-sensitive authorities. More specifically, we pro-pose a query-sensitive AuthorRank to model the authors X  authorities based on the co-authorship networks, and de-velop an adaptive ranking refinement method to aggregate the ranking results. To illustrate our methodology, we ap-ply the proposed methods to the expert finding task using the DBLP bibliography data. Experimental results demon-strate the effectiveness and robustness of the community-aware strategies.
Generally, there are two principal models for expertise re-trieval: the candidate-based models [1, 2, 5] and the document-based models [1, 3, 5]. According to the comparison in [1], the document-based model could achieve better performance than the candidate-based model. Therefore, we choose the document-based model as the baseline, and propose several methods to further enhance this model.

This work is related to existing works in statistical lan-guage models [10, 11], which is employed to discover docu-ments related to a query in the document-based model. Typ-ically, a necessary step for the language model is to perform smoothing for the unseen query terms in the document, and several different smoothing methods have been proposed, such as Jelinek-Mercer smoothing and Bayesian smoothing using Dirichlet priors [11]. However, these smoothing meth-ods only consider the collection as a whole, while our pro-posed smoothing method uses the community context infor-mation to smooth the language model.

Besides the categories described above, there are various methods proposed to extend or enhance the expertise re-trieval. In [4], the authors propose a graph-based re-ranking model and apply it to expert finding for refining the ranking results. Furthermore, Karimzadehgan et al. [6] leverage the organizational hierarchy to enhance expert finding. Never-theless, our proposed community-aware strategies are differ-ent from previous methods. In this work, We develop the query-sensitive AuthorRank as well as the adaptive ranking refinement strategy for the enhanced model.
The problem of identifying experts is to estimate the prob-ability of a candidate a i being an expert given the query topic q . Using Bayes X  theorem, the probability can be formu-lated as follows: p ( a i | q )= p ( a i ,q ) p ( q )  X  p ( a p ( q ) is a constant, so it can be ignored for ranking purposes. To derive p ( a i | q ), it is equivalent to estimate the joint proba-bility p ( a i ,q ). In [3], Deng et al. propose a document-based model to aggregate the expertise of an expert according to the relevance and importance of the associated documents. The joint probability can be decomposed as where p ( d j ) is the prior probability of a document, p ( q means the relevance between q and d j ,and p ( a i | d j )repre-sents the association between the candidates and the docu-ments. Under this model, p ( d j ) is estimated based on the citation of the document N c ( d ): p ( d )  X  log (10 + N Suppose a document has multiple authors in total, each au-thor is assumed to have the same knowledge about the topics described in the document, where N a ( d ) is the number of authors for the document.
In the document-based model, one of the key challenges is to determine the probability of a query given a document p ( q | d ). According to the statistical language model, we infer a document language model  X  d for each document. The relevance score of document d with respect to query q is then defined as the conditional probability p ( q |  X  d ), Figure 2: A graph representation of the relation-ships between documents, communities and the en-tire collection. where p ( t |  X  d ) represents the maximum likelihood estimator of the word in a document d . In order to assign nonzero probabilities to unseen words, it is important to incorpo-rate the smoothing methods in estimating the document language model.

In general, each word is smoothed by the same collection language model. However, the community provides distinc-tive information for its documents. Figure 2 illustrates the relationships between the documents, the communities and the whole collection. Basically, a document will somewhat share much more common information with its community C d rather than the whole collection G . Therefore, it would be more reasonable to employ the distinctive community language model, instead of the whole collection language model, to smooth different document models. The commu-nity language model is defined as One popular way to smooth the maximum likelihood esti-mator is the Jelinek-Mercer smoothing method: where  X  is the parameter to control the amount of smooth-ing, n ( t i ,d ) is the count of word t i in the document d , and | d | is the number of the words in d. Accordingly, the community-smoothed language model is obtained Note here the document d belongs to the community C d . So far, there are two different language models, i.e., the collection-smoothed language model (baseline model) and the community-smoothed language model, for calculating p ( q |  X  d j ). Therefore, two different models can be combined as shown in the upper part of Table 1.
In a community, the authors X  relationships can be de-scribed using a co-authorship network, which is an impor-tant category of social networks [8].To quantify the edge weight, the co-authorship frequency [7] is proposed as the sum of values for all papers co-authored by a i and a j , f paper d k ,otherwise  X  k i =0,and n k is the number of au-thors in paper d k . This gives more weight to authors who Figure 3: Co-authorship graph with: (a) co-authorship frequency, and (b) normalized weight. co-publish more papers together. Let us take the commu-nity C 1 in the Fig. 1 as an example, the graph with the co-authorship frequency is illustrated in Fig. 3(a). In general, the link weight w ij from a i to a j is defined by normaliz-ing the co-authorship frequency from a i as w ij = f ij n This normalization ensures that the weights of an author X  X  relationships sum to one, as shown in Fig. 3(b) for C 1 .
For each community, a weighted co-authorship graph can be easily built. We therefore utilize AuthorRank [7], a mod-ification of PageRank [9], to measure the authority for the authors within this community as p ( a i | C k )=(1  X   X  ) 1 where N a ( C k ) is the number of authors in the community C ,and p ( a i | C k ) is the authority (i.e., AuthorRank) of the author a i satisfying i p ( a i | C k )=1.
The AuthorRank described above calculates the author-ities for the authors within a community, but it is inde-pendent of any particular query topic. To identify a set of experts for a given query, we propose a community-sensitive AuthorRank to generate query-specific authority scores for authors at query time.

Given a query q , we compute the probability for each com-munity C k the following: where p ( t i | C k ) is easily computed from the community lan-guage model as Eq. (4). The quantity p ( C k ) is not as straight-forward. We model it as related to the number of authors N ( C k ) and the average citation per paper N c ( C k )inthe community C k ;thatis The underlying idea is that the community prior is propor-tional to the size and quality of the community.

According to Eq. (8), we retrieve top-k communities that are highly related to the query. Finally, we compute the query-sensitive authority score for each author as follows, The authors are ranked according to the composite score p ( a i | q ). The above community-sensitive AuthorRank has the following probabilistic interpretation. Suppose C k be a  X  X irtual X  document, it becomes the document-based model as Eq. (1). Thus the community-sensitive AuthorRank can be regarded as a high-level document-based model that cap-tures the high-level and general aspects for a given query.
Based on the document-based model and the community-sensitive AuthorRank (i.e., community-based model), we ob-tain two kinds of ranking results Rd and Rc , which reflect the authors X  expertise from different perspectives. The ranking list Rd captures more specific and detailed aspects matching with the given query, as it measures the contribution of each document individually. In contrast, the ranking list Rc re-flects more general and abstract aspects matching with the given query. Therefore, we consider the ranking refinement strategy by leveraging the community-sensitive AuthorRank to boost the document-based model.

If the community-sensitive AuthorRank could retrieve many common authors within the top-k resultsasidentifiedby the document-based model, the community-sensitive Au-thorRank may contribute a lot to refine the document-based model; otherwise vice versa. Based on this scheme, we uti-lize the Jaccard coefficient to measure the similarity between two top-k ranking results, which is defined as J = Then we adopt this measurement for an adaptive ranking refinement as follows, where Rd ( a i ) be the rank of author a i in Rd ,  X  Rc ( a rank of author a i in  X  Rc (i.e., Rd Rc ), and  X  ( a i )=1if a is one of the intersected authors, otherwise  X  ( a i )=0. The intuition behind this method is that the authors, which are identified in both Rd and Rc , should be boosted ahead in the ranking results. The final results are ranked according to the refined score S ( a i ). By applying the ranking refine-ment strategy to the previous t wo different document-based models, we obtain two enhanced models as shown in Table 1.
We evaluate the performance of our proposed models with different settings. In this section, we first introduce the ex-perimental setup, and then present the experimental results.
The dataset that we study is the DBLP bibliography data, which contains over 1,100,000 XML records as of March 2009. In summary, the data collection for experiments in-clude 1,184,678 papers, 696,739 authors, and 3,143 commu-nities. In order to measure the performance of our proposed Method P@10 P@20 R-prec MAP DM(w) 0.688 0.503 0.485 0.363 DM(wc) 0.688 0.527 0.494 0.377 EDM(w) 0.706 0.55 0.532 0.403 EDM(wc) 0.712 0.568 0.533 0.409 DM(wc)/DM(w) 0% +4.7% +2.0% +3.8% EDM(w)/DM(w) +2.6% +9.4% +9.8% +10.9%
EDM(wc)/DM(wc) +3.4% +7.8% +7.9% +8.4% methods, we manually created the ground truth because of the scarcity of such data that can be examined publicly. For each query, a list of experts is collected through the method of pooled relevance judgments with human assessment ef-forts. The benchmark dataset used for the evaluation con-tains 17 query topics and 17 expert lists. In our experiments, we report the results of P@10, P@20, R-prec, and MAP.
To validate the effect of the community-based smooth-ing method, we evaluate and compare the performance of four different methods. In Table 2, the first part shows the absolute precisions of these methods, and the second part illustrates the percentages of relevant improvements.
According to the first part, it is obvious that EDM ( wc ) achieves the best performance in all the metrics, such as 0.568 for P@20 and 0.409 for MAP. When looking at the rel-ative improvements, we can see that DM ( wc ) improves over DM ( w )from2 . 0% to 4 . 7% in most metrics besides P@10. This is because the smoothing method using community con-text can boost the performance of the language model. As expected, the enhanced models EDM ( w )and EDM ( wc ) perform better than their corresponding document-based models DM ( w )and DM ( wc ), respectively. For MAP met-ric, we can see that EDM ( wc ) improves over DM ( wc )by 8 . 4%, and EDM ( w )over DM ( w )by10 . 9%. In terms of the comparisons using other metrics, we observe similar substan-tial improvements. All the experimental results demonstrate the effectiveness of the enhanced model, which could further boost the performance of document-based models.
As mentioned before, we only retrieve the top-k 1 relevant documents for the document-based model, and identify top-k 2 relevant communities for the community-sensitive Au-thorRank as well. The parameters k 1 and k 2 used in pre-vious subsections are set to 5,000 and 10, individually. To investigate the effect of these two parameters, we designed the following experiments.

To examine the effect of k 1 , we choose the document-based model DM ( wc ), and evaluate it with 4 different values (from 1,000 to 10,000). The experimental results for differ-ent k 1 are illustrated in Fig. 4(a). In this figure, we can see the performance becomes better for greater k 1 used in the document-based model. We believe the reason is that more documents can better capture the complete expertise. How-ever, larger k 1 may result in longer processing time. There-fore, a good tradeoff is to set k 1 = 5000. To investigate the effect of k 2 ,wefix k 1 = 5000, and choose to compare the model EDM ( wc ) with several different values from 0 to 50. Figure 4: The effect of varying the parameters ( k 1 and k 2 ) in (a) the document-based model DM ( wc ) and (b) the enhanced model EDM ( wc ) .
 Here, k 2 =0in EDM ( wc ) represents its document-based model DM ( wc ). As shown in Fig. 4(b), when incorporat-ing the community-sensitive AuthorRank in the enhanced model ( k 2 &gt; 0), the performance is improved compared to the document-based model ( k 2 = 0). The precisions first increase then level off as k 2 grows. In general, the enhanced model EDM ( wc ) is relatively robust for different k 2 ,and achieves good results when k 2 = 10.
In this paper we present the c ommunity-aware strategies for enhancing expertise retrieval, including the new smooth-ing method with the community context and the community-sensitive AuthorRank based on the co-authorship networks. Extensive experiments show that the improvements of our enhanced models are significant and consistent. This work is supported by two grants from the Research Grants Council of the Hong Kong SAR, China (Project No. CUHK4128/08E and Project No. CUHK4158/08E).
