 In this paper, we present the methodology followed by Inductis in developing the predictive models for Quantum Physic s task in KDD Cup 2004 . We discuss many challenges t hat we faced in approaching the task and how we overcame them. We explored the solution space with various classification approaches and finally used stochastic gradient boosting offered on the TreeNet platfo rm. A set of TreeNet models was fit va rying vari ous parameters and its performance was measured. Stochastic Gradient Boosting, Logistic Regression, MARS , KDD Cup, TreeNet Inductis decided to attempt this problem as a part of its efforts to keep itself updated on the frontiers of p redictive modeling and to tak e learnings from here to its business consulting space. This document presents the various approaches and analysis that we used for solving the KDD cup problem. Section 2 describes the challenges, section 3 discusses the pre -pr ocessing, section 4 presents the modeling summary including MARS, logis tic regression with MARS and TreeNet models. Inductis primarily work s by merging analytics with business consulting practice where problem context and managerial proble m definition are fundamental to a successful solution. Defining the right problem is as important as finding the best analytical model. Our approach is guided by distinctive framework of Decideright which guides to define correct problem and search for the best answer. In KDD Cup 2004, the problem  X  X  contextual knowledge had no significant bearing on the outcome. Hence the focus was on finding as good a predictive model as possible. We focused extensively on data understanding for finding t he right meaning of variables . We utilized a variety of options from our traditional methodological framework for exploratory data analysis highlighting the characteristics of the problem space. We then developed a series of classification models and finally used stochasti c gradient boosting based on its ability to extract information from a large number of variables. Our exploratory data analysis using Inductis proprietary tools included u nivariate and bivariate analys e s of variables. We looked a t the distributions of various independent variables and plotted their relationships with dependent variable. A series of bivariate plots between dependent variable and various covariates concluded that only 10 out of 78 variables have any observable relat ionship with the dependent variable . We also identified a set of multivariate patterns which had higher predictive relationships with dependent variables. Based on the first stage we imputed missing values with mean for various variables, understood multi variate outliers and capped the same. W e classified the variables as categorical and continuous based on number of levels. We also created dummy i ndi cator variables for outliers, missing values and important interactions effects. We took a 2/3 training and 1/3 validation sample on the training data and used it for modeling. Within 2/3 training set we used 20% sample for testing models in CART/ MARS and TreeNet. We utilized MARS in two different ways : (1) To creat e variables approximating functional form specifications for use in logistic regression models . We identified various basis functions representing functional form approximations and interactions among variables. (2) To model the problem on MARS with princi pal components of variables . For developing the model using MARS we did a variable reduction exercise for overc o m ing multi -co l linearity problems in the data. W e varied a series of parameters in MARS for controlling complexity of resultant model. W e however found that the MARS results were not superior to TreeNet preliminary results on this problem. A typical set of result s from the exercise are presented in table 1.
 We approached the problem with a large set of logistic regression runs using a combination of imputations, approximating functional forms using MARS created variables etc. However we found that the results from this approach stuck at ceiling performance of around 71% on the holdout sample. We decided to use stochastic gradien t boosting algorithms. We used evaluation version of Salford Systems product TreeNet in this application. We made use of our learnings from exploratory data analysis and earlier modeling phase in choosing the parameter space as well as d ata treatment. We used logistic likelihood as the loss function and varied parameters like learning rate, number of trees, classification costs, nodes per tree and studied implications on holdout sample accuracy. Results from our best model are presented below.
 Compared to this our results on the KDD dataset dropped a bit but were still comparable to what we had been achieving . We thank the team at Inductis comprising Arpita Chowdhary, Don Yan, Dinesh Bharule, Sandeep Tyagi, Titiksha Gautam who contributed in this effort. Lalit Wangikar is the Vice President at Inductis (India) Private Ltd where he heads the India Consulting Operations . He has worked on various analytic consulting assignments in financial sector. In his recent engagement, he worked on predicting attrition with a large financial institution. He holds an MBA from Indian Insti tute of Management Ahmedabad. Vineet Agrwal is a Modeler at Inductis (India) where he has been working on variety of modeling problems in financial industry . Vineet is B.Tech from Indian Institute of Technology Mumbai, India.
 Vivek Gupta is Senior Modeler with Inductis (India) where he has worked on variety of modeling problems in Insurance and pharma. Vivek has worked on modeling problems in CPG, telecom sector in the past. His recent published work has been on choice modeling application in emerging mark ets. He holds a PhD from Indian Institute of Management Ahmedabad, India where his research was supported by Infosys Research Fellowship.
