 The explosion in online advertisement urges to better es-timate the click prediction of ads. For click prediction on single ad impression, we have access to pairwise relevance among elements in an impression, but not to global interac-tion among key features of elements. Moreover, the exist-ing method on sequential click prediction treats propagation unchangeable for different time intervals. In this work, we propose a novel model, Convolutional Click Prediction Mod-el (CCPM), based on convolution neural network. CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression. Ex-periment results on two public large-scale datasets indicate that CCPM is effective on click prediction.
 H.3 [ Information Storage and Retrieval ]: Information Filtering Click Prediction, Convolution Neural Network
Recently, online advertising has become the most popular approach to do brand promotion and product marketing for the advertiser , and contributes the overwhelming majority of income for the commercial web publisher .

Nowadays, click prediction on single ad impression [10] has received much attention, and many different approaches have been proposed. For simplicity and effectiveness, Lo-gistic Regression (LR) [7, 9] has been widely used in click prediction. Representing each element (e.g. query, ad, user and other contexts) of a single ad impression by a value, LR is not capable enough to describe the latent features of This author contributed equally as the first author.  X  an element or reveal the complicated relation among these elements. As a widely-used technique in recommendation systems, matrix factorization (MF) method [4] in the Col-laborative Filtering approach is also employed for click pre-diction. MF method factorizes and rebuilds the dependency matrix to learn latent semantic representations of pages and ads. Later, Factorization Machines (FM) [5, 6], a extension of MF in multiple element space, obtains latent semantic in-formation of each pairwise elements, which is able to better model relation of various elements. However, MF and FM models capture relevance of pairwise elements in single ad impression and overlook the high-order interaction among these elements.

Different from traditional works taking single ad impres-sion as input instance and overlooking dependency of histor-ical impressions, Recurrent Neural Network (RNN) model [10] is leveraged for click prediction of sequential ad impres-sion. Taking full advantage of historical click sequences, the recurrent structure enhances the accuracy of click prediction further. The model takes each user X  X  browsing history as a sequence and obtains internal sequential dependency of var-ied impressions. Historical click sequence of a certain user is divided by different time intervals, sequence signals of one time interval can be propagated to next interval by the recur-rent connection matrix. Due to the fact that the recurrent connection matrix of a trained RNN model is a constan-t one, the propagations of sequence signals between every two consecutive time intervals remain all the same. Howev-er, in real-world scenarios, since users X  attitudes toward ads change over time, RNN models may has its limitation for these scenarios due to using the unchangeable propagations.
In order to mine significant semantic features in complex and dynamic sceneries, deep neural network is a good choice. As stated above, for click prediction on single ad impression, the MF and FM methods only reveal the relevance between pairwise elements, but convolutional neural network (CNN) can treat varied elements in a single ad impression as a w-hole and obtain complex interaction among them. On the other hand, the unchangeable propagations of RNN models on sequential ad impression has the limitation in effective-ly modeling dynamic click predictions, while pooling and convolutional layers of a deep CNN architecture can fully extract local-global key features from sequential ad impres-sion. In addition, some recent studies about CNN architec-ture have successfully model significant semantic features in varieties of fields. CNN approaches to speech recognition [1], image recognition [3], information retrieval [8] have achieved much improvement in respective fields. Moreover, proved as a effective sentence model in natural language process-ing, Dynamic Convolutional Neural Network (DCNN) [2] can analyses semantic content and extracts key features of sentences.
 We propose a Convolutional Click Prediction Model (C-CPM) for click prediction in sceneries of the single ad im-pression and sequential ad impression. An input instance of CCPM is composed by elements of an ad impression or ele-ments related to a sequential ad impression. Convolutional layers extract local-global features of input instances, and the dynamic pooling layers can obtain significant features. CCPM investigates significant semantic features of an ad im-pression and sequential relevance of impression history into enhancing the accuracy of click prediction. Experiments are conducted to validate the CCPM model X  X  effectiveness in modeling different kinds of input instances and reveal that CCPM achieves great improvement on the accuracy of click prediction comparing the state-of-the-art models such as L-R, FM and RNN. To the best of our knowledge, CCPM is the first approach that attempts to leverage CNN to improve the accuracy of click prediction.
In an event of single ad impression , there are some no-ticeable elements like user, query, ad, impression time, site category, device type, etc. On the other hand, sometimes system can collect sequential ad impression of each individ-ual user, where user X  X  behaviors on ads yield high dependen-cy on how the user behaved along with the past time. This sequential ad impression is comprised of a series of single ad impressions. The goal of this work is to predict the click probability based on these two kinds of impressions.
We model above input instances using a convolutional architecture that alternates wide convolutional layers with flexible p -max pooling layers. The whole procedure of CCP-M is illustrated in Figure 1. In the network the width of an intermediate feature map varies with the length of the input instance. It is remarkable to state that the proposed model can handle input instances with varied length, which make it can be used widely.
Given an input instance with n elements, to obtain the first layer of CCPM, we take an embedding e i  X  R d for each element in the instance and construct the instance matrix The values in the embeddings e i are estimated during the training process, which contributes to more suitable rep-resentations for input instances. A convolutional layer in the network is obtained by convolving a weight matrix w  X  R d  X   X  with the activation matrix at the layer below in an one-dimensional row-wise way. For example, the second lay-er is obtained by applying a convolution on the input in-stance matrix s . Dimension d and filter width  X  are hyper-parameters of input instances. The resulting matrix r has dimensions d  X  ( n +  X   X  1). Given w i  X  R  X  , s i  X  R n r  X  R ( n +  X   X  1) as the i -th row of corresponding matrix, we can obtain one-dimensional convolution as where the index j ranges from 1 to n +  X   X  1. Out-of-range values s i,k (where k &lt; 1 or k &gt; n ) are set to zero.
The optimized weights in the filter w detects features and recognizes specific ranges of neighborhood in input in-stances. Applying one-dimensional row-wise convolution on two-dimensional matrix of activations, has the following ad-vantage over simply using two-dimensional convolution. Usu-ally we apply two-dimensional convolution in image identi-fication for the reason that the detectors need to recognize special two-dimensional features, such as edges of an objec-tive. However, in the click prediction model, each dimension of the embedding represents a distinct aspect of an element in an instance. Therefore, each row of the resulting matrix r obtains distinct features from the activation matrix.
Here, we describe the flexible p -max pooling layer. Giv-en a vector r i  X  R n , p -max pooling selects a sub-vector s  X  R p , which contains the p biggest values in the original vector r i . Due to the fact that input instances are of var-ied length, the vector lengths of intermediate convolutional layer change accordingly, consequently the following pooling layer need to be flexible enough to select prominent features smoothly. Considering all facts mentioned above, we let p be a function of length of the input instance and depth of the network. In spite of many possible functions, we select the following one where l is the total number of convolutional layers of the network, n is the length of the input instance and p i repre-sents the parameter of the i -th pooling layer. For example, given an input instance of length n = 18, in a network of three convolutional layers, whose pooling parameters are as follows: p 1 = 16, p 2 = 6 and p 3 = 3.

This selected function has many advantages. Firstly, the last pooling layer has a fixed parameter, so it is guaranteed that the matrix of the fully connected layer for output has a unified dimensionality, despite varied lengths of different input instances. Secondly, the power-exponential function changes slowly at first compared with linear function, which avoids losing too many important features at the beginning.
The flexible p -max pooling layer can not only select the p most key features, but also preserve the relative order of those features, which plays a critical role in the sequential click prediction.
We apply a non-linear function for outputs of pooling lay-ers. The non-linear function is also called as activation func-tion, which obtains activations of threshold values: So far, convolutional layer, flexible p -max pooling layer and non-linear function have been applied to input instances. In this way, we can obtain a first order feature map. Moreover, the three operations above can be repeated again and again to yield multiple order feature maps and a architecture of deeper layers. We denote an i -th order feature map by F At a certain layer, many feature maps can be computed in parallel. For example, F i j represents the j -th feature map of those i -th order feature maps, an is computed by summing the convolutional results of a distinct weight matrix w and each feature map F i  X  1 k of the lower order i  X  1, where m i denotes the number of feature map in correspond-ing i -th order layer, and  X  refers to the one-dimensional row-wise convolution described in Sec. 2.1. Similarly, flexible p -max pooling and non-linear function can be applied to fea-ture map F i j successively. Finally, there is a fully connected layer, and the prediction is made via softmax.
To empirically evaluate the performance of our method on the click prediction with single and sequential impres-sion data, we perform experiments on two public real-world datasets: Avazu 1 and Yoochoose 2 . The Avazu dataset in-cludes several days of ad click-through data, ordered chrono-logically. In each piece of click data, there are 17 data fields such as ad id, site id, click, etc. These above data fields indi-cate elements of a single ad impression. We use this dataset to assess the performance of click prediction on the single ad impression. Collected during several months in 2014, the Yoochoose dataset contains many sessions of browse and purchase events from an online retailer, where each session encapsulates the click events of an individual user. Some ses-sions contain purchase events, which means that the session ends with the user purchasing something. Here, we treat products as ads, then the browse behavior can be viewed as a single ad impression and the purchase behavior as an impression with click. This dataset is employed to evalu-ate the performance of click prediction on the sequential ad impression. https://www.kaggle.com/c/avazu-ctr-prediction/data http://recsys.yoochoose.net
Three state-of-the-art methods are used for empirical com-parison, which are LR [7], FM [6] and RNN [10]. (1) As a widely used algorithm for click prediction in industry, LR is easy to understand, quick to train, and efficient enough to be implemented by search engines as an integral part of their advertising system. (2) FM is a general regression model that captures interaction between pairs of elements by using factors. FM has proved to be useful in different tasks and domains. In particular, it can be efficiently used to model the interaction with various elements of ad impressions. (3) RNN models the dependency on user X  X  sequential behaviors into the click prediction process, which depends on not only the current input features, but also the sequential histori-cal information. Since Avazu does not contain sequential ad impression, we only implement RNN model on Yoochoose. In all experiments, we randomly select 90% of dataset as training data and the rest 10% as test data. For CCPM, we apply a CNN architecture of three layers in this work. The parameters of CCPM are set as d =11, m =[4,4,2], w =[6,5,3] for the Avazu dataset, and d =8, m =[3,4,2], w =[6,5,3] for Yoochoose ( m, w are the number of feature maps and filter width in three layers).

In the real-world scenarios, the probability of click is ex-tremely low, similar to [7], we adopt logloss as the evaluation metric to measure the accuracy of CTR prediction. log loss =  X  1 n where p i = P ( y i = 1 | s ) represents the predicted click proba-bility. and s donotes an ad impression. y i is the correspond-ing observed label, y i = 1 means the user has click the ad impression. m is the total number of input instances.
Left part of Figure 2 illustrates the click prediction per-formance of CCPM and other competitive compared meth-ods on single ad impression and sequential ad impression. We identify that on both datasets, CCPM outperfom the conventional methods. Since FM can describe the latent features of an element and reveal the relation of pairwise elements, it achieves significant improvement over the that of LR on both datasets. On sequential ad impression, RNN and the Yoochoose dataset. illustrates the results on the Yoochoose dataset. leverages sequential dependency of varied impressions, and enhance the effectiveness of click prediction further. Since CCPM obtain underlying semantic information of input in-stances and extracts local-global features by using convolu-tional layers, and use k -max pooling to select key features, it can not only reveal the high-order interaction among var-ious elements of a single ad impression but also capture the historical propagation pattern in sequential ad impression.
Furthermore, in the right part of Figure 2, we illustrate the logloss values of CCPM on both datasets with varying dimensionality d of latent vector. On the Avazu dataset, the performance of CCPM achieves the best result at d = 11, while on Yoochoose CCPM yields the best performance when the dimensionality d = 6. It may be because the Yoo-choose dataset is more sparse than the Avazu, latent vector with small dimension can be well estimated. After CCPM obtains the best results on both datasets, the performance decreases gradually with increasing d due to overfitting.
Finally, on both datasets, the parameter impacts of the filter width w and the number of feature map m in cor-responding layer are studied. As illustrated in Figure 3, setting smaller corresponding filter width in deeper convo-lutional layer will contribute to higher accuracy of click pre-diction. The filters w of convolution layers can learn to rec-ognize specific neighborhoods that have size less or equal to the filter width w . Therefore as reflected in the experiment results, w 1 in the first layer is often set to large enough to grasp all possible neighborhoods. Considering that pooling layers will drop some less significant items, input length of following convolutional layer can decreases. As a result, key features of input instances are further extracted at a deeper layer and kernel size gets smaller. For the sake of enriching the representation of input instances from various angles, there are many parallel feature maps in one layer. Similarly, we can also set smaller number of feature maps in deeper layer to reach better click prediction results. As a layer goes deeper, key features have already been extracted and noise eliminated, deeper layers just need small number of feature maps to extract key features.
In this paper, we have proposed a convolutional click pre-diction model based on CNN for single and sequential ad impression. Extensive experiments on two public datasets have demonstrated the effectiveness of the proposed model. This work is jointly supported by National Basic Research Program of China(2012CB316300), and National Natural Science Foundation of China (61403390, U1435221, 61175003, 61420106015).
