 Modern Spoken Dialogue Systems (SDS) are typi-cally developed according to a well-defined ontol-ogy , which provides a structured representation of the domain data that the dialogue system can talk about, such as searching for a restaurant or shop-ping for a laptop. Unlike conventional approaches employing a substantial amount of handcrafting for each individual processing component (Ward and Is-sar, 1994; Bohus and Rudnicky, 2009), statistical ap-proaches to SDS promise a domain-scalable frame-work which requires a minimal amount of human in-tervention (Young et al., 2013). Mrk  X  si  X  c et al. (2015) showed improved performance in belief tracking by training a general model and adapting it to specific domains. Similar benefit can be observed in Ga  X  si  X  c et al. (2015), in which a Bayesian committee ma-chine (Tresp, 2000) was used to model policy learn-ing in a multi-domain SDS regime.

In past decades, adaptive NLG has been stud-ied from linguistic perspectives, such as systems that learn to tailor user preferences (Walker et al., 2007), convey a specific personality trait (Mairesse and Walker, 2008; Mairesse and Walker, 2011), or align with their conversational partner (Isard et al., 2006). Domain adaptation was first ad-dressed by Hogan et al. (2008) using a generator based on the Lexical Functional Grammar (LFG) f-structures (Kaplan and Bresnan, 1982). Although these approaches can model rich linguistic phe-nomenon, they are not readily adaptable to data since they still require many handcrafted rules to define the search space. Recently, RNN-based lan-guage generation has been introduced (Wen et al., 2015a; Wen et al., 2015b). This class of statistical generators can learn generation decisions directly from dialogue act (DA)-utterance pairs without any semantic annotations (Mairesse and Young, 2014) or hand-coded grammars (Langkilde and Knight, 1998; Walker et al., 2002). Many existing adapta-tion approaches (Wen et al., 2013; Shi et al., 2015; Chen et al., 2015) can be directly applied due to the flexibility of the underlying RNN language model (RNNLM) architecture (Mikolov et al., 2010).
Discriminative training (DT) has been success-fully used to train RNNs for various tasks. By op-timising directly against the desired objective func-tion such as BLEU score (Auli and Gao, 2014) or Word Error Rate (Kuo et al., 2002), the model can explore its output space and learn to discriminate be-tween good and bad hypotheses. In this paper we show that DT can enable a generator to learn more efficiently when in-domain data is scarce.

The paper presents an incremental recipe for training multi-domain language generators based on a purely data-driven, RNN-based generation model. Following a review of related work in section 2, sec-tion 3 describes the detailed RNN generator archi-tecture. The data counterfeiting approach for syn-thesising an in-domain dataset is introduced in sec-tion 4, where it is compared to the simple model fine-tuning approach. In section 5, we describe our proposed DT procedure for training natural lan-guage generators. Following a brief review of the data sets used in section 6, corpus-based evaluation results are presented in section 7. In order to assess the subjective performance of our system, a quality test and a pairwise preference test are presented in section 8. The results show that the proposed adap-tation recipe improves not only the objective scores but also the user X  X  perceived quality of the system. We conclude with a brief summary in section 9. Domain adaptation problems arise when we have a sufficient amount of labeled data in one domain (the source domain), but have little or no labeled data in another related domain (the target domain). Domain adaptability for real world speech and language ap-plications is especially important because both lan-guage usage and the topics of interest are constantly evolving. Historically, domain adaptation has been less well studied in the NLG community. The most relevant work was done by Hogan et al. (2008). They showed that an LFG f-structure based gener-ator could yield better performance when trained on in-domain sentences paired with pseudo parse tree inputs generated from a state-of-the-art, but out-of-domain parser. The SPoT-based generator proposed by Walker et al. (2002) has the potential to address domain adaptation problems. However, their pub-lished work has focused on tailoring user prefer-ences (Walker et al., 2007) and mimicking person-ality traits (Mairesse and Walker, 2011). Lemon (2008) proposed a Reinforcement Learning (RL) framework in which policy and NLG components can be jointly optimised and adapted based on on-line user feedback. In contrast, Mairesse et al. (2010) has proposed using active learning to miti-gate the data sparsity problem when training data-driven NLG systems. Furthermore, Cuayhuitl et al. (2014) trained statistical surface realisers from unla-belled data by an automatic slot labelling technique.
In general, feature-based adaptation is perhaps the most widely used technique (Blitzer et al., 2007; Pan and Yang, 2010; Duan et al., 2012). By ex-ploiting correlations and similarities between data points, it has been successfully applied to problems like speaker adaptation (Gauvain and Lee, 1994; Leggetter and Woodland, 1995) and various tasks in natural language processing (Daum  X  e III, 2009). In contrast, model-based adaptation is particularly use-ful for language modeling (LM) (Bellegarda, 2004). Mixture-based topic LMs (Gildea and Hofmann, 1999) are widely used in N-gram LMs for domain adaptation. Similar ideas have been applied to appli-cations that require adapting LMs, such as machine translation (MT) (Koehn and Schroeder, 2007) and personalised speech recognition (Wen et al., 2012).
Domain adaptation for Neural Network (NN)-based LMs has also been studied in the past. A feature augmented RNNLM was first proposed by Mikolov and Zweig (2012), but later applied to multi-genre broadcast speech recognition (Chen et al., 2015) and personalised language modeling (Wen et al., 2013). These methods are based on fine-tuning existing network parameters on adaptation data. However, careful regularisation is often nec-essary (Yu et al., 2013). In a slightly different area, Shi et al. (2015) applied curriculum learning to RNNLM adaptation.

Discriminative training (DT) (Collins, 2002) is an alternative to the maximum likelihood (ML) crite-rion. For classification, DT can be split into two phases: (1) decoding training examples using the current model and scoring them, and (2) adjusting the model parameters to maximise the separation between the correct target annotation and the com-peting incorrect annotations. It has been success-fully applied to many research problems, such as speech recognition (Kuo et al., 2002; Voigtlaender et al., 2015) and MT (He and Deng, 2012; Auli et al., 2014). Recently, Auli and Gao (2014) trained an RNNLM with a DT objective and showed im-proved performance on an MT task. However, their RNN probabilities only served as input features to a phrase-based MT system. The neural language generation model (Wen et al., 2015a; Wen et al., 2015b) is a RNNLM (Mikolov et al., 2010) augmented with semantic input features semantics of the generated output. At every time step t , the model consumes the 1-hot representation of both the DA d t and a token w t 2 to update its in-ternal state h t . Based on this new state, the output distribution over the next output token is calculated. The model can thus generate a sequence of tokens by repeatedly sampling the current output distribu-tion to obtain the next input token until an end-of-sentence sign is generated. Finally, the generated The Semantically Conditioned Long Short-term Memory Network (SC-LSTM) (Wen et al., 2015b) is a specialised extension of the LSTM net-work (Hochreiter and Schmidhuber, 1997) for language generation which has previously been shown capable of learning generation decisions from paired DA-utterances end-to-end without a modu-lar pipeline (Walker et al., 2002; Stent et al., 2004). Like LSTM, SC-LSTM relies on a vector of mem-ory cells c t  X  R n and a set of elementwise multi-plication gates to control how information is stored, forgotten, and exploited inside the network. The SC-LSTM architecture used in this paper is defined by the following equations, where n is the hidden layer size, i t , f t , o t , r [0 , 1] n are input, forget, output, and reading gates re-spectively,  X  c t and c t are proposed cell value and true cell value at time t , W 5 n, 2 n and W dc are the model parameters to be learned. The major difference of the SC-LSTM compared to the vanilla LSTM is the introduction of the reading gates for controlling the semantic input features presented to the network. It was shown in Wen et al. (2015b) that these reading gates act like keyword and key phrase detectors that learn the alignments between individual semantic input features and their corresponding realisations without additional supervision.

After the hidden layer state is obtained, the com-putation of the next word distribution and sampling from it is straightforward, where W ho is another weight matrix to learn. The entire network is trained end-to-end using a cross entropy cost function, between the predicted word distribution p t and the actual word distribution y t , with regularisations on DA transition dynamics, where  X  = { W 5 n, 2 n , W dc , W ho } , d T is the DA vector at the last index T, and  X  and  X  are constants set to 10  X  4 and 100 , respectively. Given training instances (represented by DA and sentence tuples { d i ,  X  i } ) from the source domain S (rich) and the target domain T (limited), the goal is to find a set of SC-LSTM parameters  X  T that can perform acceptably well in the target domain. 4.1 Model Fine-Tuning A straightforward way to adapt NN-based models to a target domain is to continue training or fine-tuning a well-trained generator on whatever new target do-main data is available. This training procedure is as follows: 1. Train a source domain generator  X  S on source 2. Divide the adaptation data into training and val-Although this method can benefit from parameter sharing of the LM part of the network, the parame-In other words, realisation of any unseen slot-value pair in the target domain can only be learned from scratch. Adaptation offers no benefit in this case. 4.2 Data Counterfeiting In order to maximise the effect of domain adapta-tion, the model should be able to (1) generate accept-able realisations for unseen slot-value pairs based on similar slot-value pairs seen in the training data, and (2) continue to distinguish slot-value pairs that are similar but nevertheless distinct. Instead of ex-ploring weight tying strategies in different training stages (which is complex to implement and typically relies on ad hoc tying rules), we propose instead a data counterfeiting approach to synthesise target do-main data from source domain data. The procedure is shown in Figure 1 and described as following: 1. Categorise slots in both source and target do-2. Delexicalise all slots and values. 3. For each slot s in a source instance ( d i ,  X  i )  X  4. Train a generator  X   X  T on the counterfeited 5. Refine parameters on real in-domain data. This This approach allows the generator to share realisa-tions among slot-value pairs that have similar func-tionalities, therefore facilitates the transfer learning informable slots requestable slots act type of rare slot-value pairs in the target domain. Further-more, the approach also preserves the co-occurrence statistics of slot-value pairs and their realisations. This allows the model to learn the gating mechanism even before adaptation data is introduced. In contrast to the traditional ML criteria (Equation 1) whose goal is to maximise the log-likelihood of cor-rect examples, DT aims at separating correct exam-ples from competing incorrect examples. Given a training instance ( d i ,  X  i ) , the training process starts by generating a set of candidate sentences Gen ( d i ) using the current model parameter  X  and DA d i . The discriminative cost function can therefore be written as where L ( X  ,  X  i ) is the scoring function evaluating candidate  X  by taking ground truth  X  i as reference. p ( X  | d i ) is the normalised probability of the candi-date and is calculated by  X   X  [0 ,  X  ] is a tuned scaling factor that flattens the distribution for  X  &lt; 1 and sharpens it for  X  &gt; 1 . The unnormalised candidate likelihood log p ( X  | d i , X  ) is produced by summing token likelihoods from the RNN generator output,
The scoring function L ( X  ,  X  i ) can be further gen-eralised to take several scoring functions into ac-count where  X  j is the weight for j -th scoring function. Since the cost function presented here (Equation 2) is differentiable everywhere, back propagation can be applied to calculate the gradients and update pa-rameters directly. In order to test our proposed recipe for training multi-domain language generators, we conducted experiments using four different domains: finding a restaurant, finding a hotel, buying a laptop, and buy-ing a television. Datasets for the restaurant and hotel domains have been previously released by Wen et al. (2015b). These were created by workers recruited by Amazon Mechanical Turk (AMT) by asking them to propose an appropriate natural language realisa-tion corresponding to each system dialogue act ac-tually generated by a dialogue system. However, the number of actually occurring DA combinations in the restaurant and hotel domains were rather lim-ited (  X  200) and since multiple references were col-lected for each DA, the resulting datasets are not suf-ficiently diverse to enable the assessment of the gen-eralisation capability of the different training meth-ods over unseen semantic inputs.

In order to create more diverse datasets for the laptop and TV domains, we enumerated all possible combinations of dialogue act types and slots based on the ontology shown in Table 1. This yielded Figure 2: Results evaluated on TV domain by adapting models from laptop domain. Compar-ing train-from-scratch model ( scratch ) with model fine-tuning approach ( tune ) and data counterfeiting method ( counterfeit ). 10%  X  700 examples. about 13K distinct DAs in the laptop domain and 7K distinct DAs in the TV domain. We then used AMT workers to collect just one realisation for each DA. Since the resulting datasets have a much larger input space but only one training example for each DA, the system must learn partial realisations of con-cepts and be able to recombine and apply them to unseen DAs. Also note that the number of act types and slots of the new ontology is larger, which makes NLG in both laptop and TV domains much harder. We first assess generator performance using two ob-jective evaluation metrics, the BLEU-4 score (Pap-ineni et al., 2002) and slot error rate ERR (Wen et al., 2015b). Slot error rates were calculated by aver-aging slot errors over each of the top 5 realisations in the entire corpus. We used multiple references to compute the BLEU scores when available (i.e. for the restaurant and hotel domains). In order to better Figure 3: The same set of comparison as in Figure 2, but the results were evaluated by adapting from SF restaurant and hotel joint dataset to laptop and TV joint dataset. 10%  X  2 K examples. compare results across different methods, we plotted the BLEU and slot error rate curves against different amounts of adaptation data. Note that in the graphs the x -axis is presented on a log-scale. 7.1 Experimental Setup The generators were implemented using the Theano library (Bergstra et al., 2010; Bastien et al., 2012), and trained by partitioning each of the collected cor-pora into a training, validation, and testing set in the ratio 3:1:1. All the generators were trained by treat-ing each sentence as a mini-batch. An l 2 regulari-sation term was added to the objective function for every 10 training examples. The hidden layer size was set to be 100 for all cases. Stochastic gradient descent and back propagation through time (Werbos, 1990) were used to optimise the parameters. In or-der to prevent overfitting, early stopping was imple-mented using the validation set.

During decoding, we over-generated 20 utter-ances and selected the top 5 realisations for each DA according to the following reranking criteria, where  X  is a tradeoff constant, F (  X  ) is the cost gen-erated by network parameters  X  , and the slot error rate ERR is computed by exact matching of the slot tokens in the candidate utterances.  X  is set to a large value (10) in order to severely penalise nonsensical outputs. Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below were aver-aged over 5 randomly initialised networks. 7.2 Data Counterfeiting We first compared the data counterfeiting ( coun-terfeit ) approach with the model fine-tuning ( tune ) method and models trained from scratch ( scratch ). Figure 2 shows the result of adapting models be-tween similar domains, from laptop to TV. Because of the parameter sharing in the LM part of the network, model fine-tuning ( tune ) achieves a bet-ter BLEU score than training from scratch ( scratch ) when target domain data is limited. However, if we apply the data counterfeiting ( counterfeit ) method, we obtain an even greater BLEU score gain. This is mainly due to the better realisation of unseen slot-value pairs. On the other hand, data counterfeit-ing ( counterfeit ) also brings a substantial reduction in slot error rate. This is because it preserves the co-occurrence statistics between slot-value pairs and realisations, which allows the model to learn good semantic alignments even before adaptation data is introduced. Similar results can be seen in Figure 3, in which adaptation was performed on more disjoint domains: restaurant and hotel joint domain to laptop and TV joint domain. The data counterfeiting ( coun-terfeit ) method is still superior to the other methods. 7.3 Discriminative Training The generator parameters obtained from data coun-terfeiting and ML adaptation were further tuned by applying DT. In each case, the models were opti-mised using two objective functions: BLEU-4 score and slot error rate. However, we used a soft version of BLEU called sentence BLEU as described in Auli and Gao (2014), to mitigate the sparse n-gram match problem of BLEU at the sentence level. In our ex-periments, we set  X  to 5.0 and  X  j to 1.0 and -1.0 for Figure 4: Effect of applying DT training after ML adaptation. The results were evaluated on laptop to TV adaptation. 10%  X  700 examples.
 BLEU and ERR, respectively. For each DA, we ap-plied our generator 50 times to generate candidate sentences. Repeated candidates were removed. We treated the remaining candidates as a single batch and updated the model parameters by the procedure described in section 5. We evaluated performance of the algorithm on the laptop to TV adaptation sce-nario, and compared models with and without dis-criminative training ( ML+DT &amp; ML ). The results are shown in Figure 4 where it can be seen that DT consistently improves generator performance on both metrics. Another interesting point to note is that slot error rate is easier to optimise compared to BLEU (ERR  X  0 after DT). This is probably be-cause the sentence BLEU optimisation criterion is only an approximation of the corpus BLEU score used for evaluation. Since automatic metrics may not consistently agree with human perception (Stent et al., 2005), human testing is needed to assess subjective quality. To do Method scrALL 2.64 2.37 2.54 2.36 * p &lt; 0.05, ** p &lt; 0.005 Table 2: Human evaluation for utterance quality in two domains. Results are shown in two metrics (rating out of 3). Statistical significance was com-puted using a two-tailed Student X  X  t-test, between the model trained with full data ( scrALL ) and all others. this, a set of judges were recruited using AMT. We tested our models on two adaptation scenarios: lap-top to TV and TV to laptop. For each task, two systems among the four were compared: training from scratch using full dataset ( scrALL ), adapting with DT training but only 10% of target domain data ( DT-10% ), adapting with ML training but only 10% of target domain data ( ML-10% ), and training from scratch using only 10% of target domain data ( scr-10% ). In order to evaluate system performance in the presence of language variation, each system gen-erated 5 different surface realisations for each input DA and the human judges were asked to score each of them in terms of informativeness and naturalness (rating out of 3), and also asked to state a prefer-ence between the two. Here informativeness is de-fined as whether the utterance contains all the infor-mation specified in the DA, and naturalness is de-fined as whether the utterance could plausibly have been produced by a human. In order to decrease the amount of information presented to the judges, utter-ances that appeared identically in both systems were filtered out. We tested about 2000 DAs for each sce-nario distributed uniformly between contrasts except that allowed 50% more comparisons between ML-10% and DT-10% because they were close.

Table 2 shows the subjective quality assessments which exhibit the same general trend as the objective results. If a large amount of target domain data is available, training everything from scratch ( scrALL ) achieves a very good performance and adaptation is not necessary. However, if only a limited amount of in-domain data is available, efficient adaptation is critical ( DT-10% &amp; ML-10% &gt; scr-10% ). More-Table 3: Pairwise preference test among four ap-proaches in two domains. Statistical significance was computed using two-tailed binomial test. over, judges also preferred the DT trained genera-tor ( DT-10% ) compared to the ML trained genera-tor ( ML-10% ), especially for informativeness . In the laptop to TV scenario, the informativeness score of DT method ( DT-10% ) was considered indistinguish-able when comparing to the method trained with full training set ( scrALL ). The preference test results are shown in Table 3. Again, adaptation methods ( DT-10% &amp; ML-10% ) are crucial to bridge the gap be-tween domains when the target domain data is scarce ( DT-10% &amp; ML-10% &gt; scr-10% ). The results also suggest that the DT training approach ( DT-10% ) was preferred compared to ML training ( ML-10% ), even though the preference in this case was not statisti-cally significant. In this paper we have proposed a procedure for train-ing multi-domain, RNN-based language generators, by data counterfeiting and discriminative training. The procedure is general and applicable to any data-driven language generator. Both corpus-based eval-uation and human assessment were performed. Ob-jective measures on corpus data have demonstrated that by applying this procedure to adapt models be-tween four different dialogue domains, good perfor-mance can be achieved with much less training data. Subjective assessment by human judges confirm the effectiveness of the approach.
The proposed domain adaptation method requires a small amount of annotated data to be collected of-fline. In our future work, we intend to focus on train-ing the generator on the fly with real user feedback during conversation.
 Tsung-Hsien Wen and David Vandyke are supported by Toshiba Research Europe Ltd, Cambridge Re-search Laboratory.

