 We show how to programmatically model processes that hu-mans use when extracting answers to queries (e.g.,  X  X ho invented typewriter? X ,  X  X ist of Washington national parks X ) from semi-structured Web pages returned by a search en-gine. This modeling enables various applications including automating repetitive search tasks, and helping search en-gine developers design micro-segments of factoid questions.
We describe the design and implementation of a domain-specific language that enables extracting data from a web-page based on its structure, visual layout, and linguistic patterns. We also describe an algorithm to rank multiple answers extracted from multiple webpages.

On 100,000+ queries (across 7 micro-segments) obtained from Bing logs, our system LaSEWeb answered queries with an average recall of 71%. Also, the desired answer(s) were present in top-3 suggestions for 95%+ cases.
 H.2.3 [ Database Management ]: Languages X  query lan-guages ; H.3.3 [ Information Storage and Retrieval ]: In-formation Search and Retrieval X  clustering, search process, information filtering Semi-structured data; domain-specific languages; structure extraction; Web programming; question answering.
The creation of search engines changed the way people locate information on the Web. 91% of online adults cur-rently use search engines to find information on the Web, 59% of them daily [ 21]. 84% of research undertaken by col-lege students begins with a search engine query [3 ], and  X  Work done during an internship at Microsoft Research. the same trend is observed for faculty and professional re-searchers [11 ]. Search engines dictate our habits of knowl-edge discovery on the Web.

Even though many of the queries submitted to search en-gines represent one-off tasks, a significant percent of them are repetitive. First, end-users often have to process batch data that requires making a series of similar queries to a search engine. A typical example is finding a similar piece of information about every item in a given list, e.g. acquiring contact information about a list of people, getting BibTeX entries for a list of articles, etc.

Second, so called factoid questions ( X  X ho invented ra-dio? X ,  X  X hat is the population of Germany? X , etc.) still con-stitute a significant portion of all user queries in search en-gine logs [23 ]. Search engines have recognized the importance of factoid questions, and introduced a notion of a micro-segment of queries  X  a specific category of questions, for which the search engine shows the instant answer under-neath the search bar, along with the list of search results. The source of data for answering micro-segment questions is typically a structured knowledge database, such as Free-Base. This implies that (a) the information presented in an answer is limited to the content of the database; (b) an-swer extraction code is hard-coded for every micro-segment; (c) time-sensitive information is not tracked consistently. In constrast, any desired knowledge is usually present in the free-text Web data, but it is usually unstructured or semi-structured (i.e., partially labeled to be accessible and recog-nizable by humans, but not by data collection algorithms).
Even when a search engine provides instant response, it may not be exactly what the end-user wants. According to [24 ], people prefer to locate their target in iterations, by observing the context of an answer and refining the query as necessary. They mostly look at multiple pages related to their desired answer, although seldom at more than ten [ 13 ]. Moreover, there may be multiple possible  X  X nswers X  to a user X  X  query, and the user is often interested in exploring the context related to each of them. For this, end-users like to ex-plore the list of search results manually, since the task of ex-tracting and ranking multiple answer candidates along with their context lies beyond the capabilities of current micro-segment search. This is the problem addressed in this paper.
All mentioned repeatable search tasks share the same ge-neric features. A repeatable search task is a parameterized Web query that takes a tuple of string arguments , and re-turns a set of string answers . Essentially, a parameterized Web query is a function over the Web data, which is defined once, and later executed multiple times for various specific arguments. Currently, the only automated component in the execution of such a function is a search engine. The rest of the execution is defined by end-users X  search strategies over the search engine results, and is entirely manual.

We observe that for any repeatable search task people fol-low similar strategies in extracting knowledge from the Web. They compose a search query aimed to bring a list of results with high recall, but not necessarily high precision (i.e. the desired knowledge is present among the suggested links, but it may not be ranked high enough by the search engine). People then navigate to the suggested links, and explore the content of webpages to build a list of answer candidates and associated context. In order to locate an answer candidate on a webpage, they use a set of patterns that form a basis of their search strategy . These patterns include: These patterns serve as a way to create structure and add semantics on top of the semi-structured content of the Web.
In this paper, we present LaSEWeb 1  X  a system for au-tomating repetitive search tasks from end-users X  descriptions of their search strategies involving the above-mentioned pat-terns. LaSEWeb consists of a novel domain-specific lan-guage (DSL) for programming search strategies, and an in-terpreter for it, built on top of the search engine Bing. A LaSEWeb program takes a tuple of user query arguments, and returns a set of answer strings from the Web, ranked by their confidence scores, along with their corresponding source URLs. It does so by (a) exploring the list of search results returned by Bing for our seed query , (b) executing a LaSEWeb query on each webpage in the list to extract mul-tiple answer string representations from it, and (c) clustering these representations using an application-specific similarity function . The language of LaSEWeb queries includes tex-tual, structural, and visual search patterns that we collected from our observations of typical search strategies. The inter-preter for this language makes use of semi-structured con-tent of a webpage and CSS attributes of HTML nodes along with state-of-the-art natural language processing (NLP) al-gorithms and programming by example (PBE) algorithms. We intend LaSEWeb to be used by both end-users and micro-segment developers.

We evaluated LaSEWeb on two different applications of Web programming: (a) 7 factoid micro-segments, repre-sented by 100,000+ user queries from Bing logs, and (b) 5 re-peatable academic search tasks, related to PLDI-2014 com-mittee. The system achieved 95%+ precision in all micro-segments, and 73% precision in repeatable search, with an average recall of 71%.

This paper makes the following contributions:
La nguage for S tructure E xtraction.
We begin with two scenarios that illustrate the problem of Web programming. These scenarios are: factoid micro-segments in search engines, and repetitive Web searches.
Scenario 1. Alice is a software developer in a search en-gine department. She is responsible for a  X  X icro-segment X  search: providing instant answers to simple factoid questions underneath the search bar, along with a list of usual search results. She wants to implement a new micro-segment that can answer questions about inventors/creators of various products or discoveries. A fraction of this information exists in FreeBase and similar databases, but they lack data about (a) less fundamental inventions, like  X  X aper clip X , and (b) ambiguous attributions, like  X  X adio X  (N. Tesla vs. G. Mar-coni vs. A. Popov, etc.) Such information is available on the Web, in the list of provided search results. However, in or-der to discover any contextual information, a user has to navigate to every webpage in the list manually.

Instead of hard-coding FreeBase information, Alice might want to implement the following pseudocode, which repre-sents her own search strategy in locating inventor infomation on the Web. This pseudocode describes a set of linguistic patterns that match sentences about inventors on webpages, returned by a search engine. In this pseudocode Syn ( s ) matches any word that is syn-onymic to s ,  X  matches any number of words, POS ( Prep ) matches a preposition, Entity ( Person ) matches several words that constitute a person name (such as  X  X ohn Atanasoff X ).  X  denotes string concatenation.

When executed against a user query w =  X  computer  X , this program produces a set of results, similar to the following:
We note that with this approach, every micro-segment turns into a  X  X epetitive search X : a parameterized search task that is defined once by a search engine developer, and exe-cuted multiple times with different arguments by end-users. The input of this search task are micro-segment arguments  X  Figure 1: Screenshot of the personal webpage of Dr. Shaz Qadeer 2 (retrieved in October 2013). for example, for  X  X nventor X  micro-segment this is the prod-uct name. The output of the task are answers to the factoid question of the micro-segment, ranked by confidence scores, along with their source URLs for additional context.
Scenario 2. Sofus has a table of KDD 2014 committee member names, which he wants to fill in with their corre-sponding phone numbers. Phone numbers can be extracted from their personal webpages automatically via regular ex-pressions, but there are two challenges: (a) these webpages have to be identified first; (b) regular expressions may have false positives. Consider a webpage in Fig. 1 . A simple reg-ular expression for phone numbers will match both  X  X hone X  and  X  X ax X  lines on the page. Moreover, on different webpages it might also match a secretary X  X  phone number, lab num-bers, university numbers, etc. Also, retrieval of all personal webpages is still manual and tedious.

Without any automation, a human typically looks for a phone number on a personal webpage using visual and lin-guistic cues: proximity to header, words like  X  X hone X  or  X  X ax X , string pattern (regular expressions), table-like struc-ture  X   X  field name  X  :  X  value  X   X . The following pseudocode de-scribes this manual search strategy: We note that the information on a webpage could be pre-sented in an entirely different format: as a series of lines with a separator other than a colon, as an HTML table, with different layout, etc. However, people interpret any of these formats as a generic  X  X able-like X  structure, and locate information in them in a similar manner.

In this scenario, the repetitive search task lies in collecting similar knowledge for each item in the list. The input is a person X  X  name, and the output is the set of found phone numbers. There may be multiple  X  X orrect X  answers (e.g., home/cell phone number).
Examples in  X  2.1 show two different applications of pa-rameterized Web queries, and expose several features that most people share in their search strategies. We summa-rize the list of our observations about these features below. They form the foundation for the definition of the problem of Web programming (which we tackle in this paper), and the LaSEWeb system (which is our approach to solving it).
Repetitive search tasks are parameterized . People often need to use the same strategy for a series of simi-lar Web search tasks with different parameters. Scenario 2 showed a case of an end-user dealing with a single problem of finding a phone number, applied to multiple people. In Scenario 1 the task is defined by a micro-segment developer, and later used multiple times by different end-users.
Search tasks have multiple answers . Depending on the nature of the search task, there may be multiple pieces of information that should be extracted from the Web as possible  X  X nswers X . A user is often interested in (a) exploring different answers ranked by some measure of their respective confidence/relevance, and (b) exploring some context related to the various answers.
 These observations motivate our problem definition:
Definition 1. A Web program is a process that takes a tuple of user query arguments , and returns a set of answer strings , ranked by their confidence, along with corresponding source URLs for every answer string.

A Web program is essentially defined as a function from strings to sets of strings. The execution of such a function happens over data on the Web. The definition of such a function consists of various typical patterns that constitute humans X  search strategy . Both definition and execution of Web programs are currently entirely manual, with the search engine being the only automatic bridge between the user X  X  goal and the Web data; our LaSEWeb system automates the execution of such Web programs.
We propose LaSEWeb , our approach to Web program-ming. It implements a Web program by automating a typi-cal human X  X  search strategy for it. The automation is based on our observations about common features of such search strategies, summarized below.

Exploring multiple webpages . When there are multi-ple  X  X orrect X  answers to the question, people explore mul-tiple webpages in order to adjust their confidence in some of these answers. In order to retrieve a list of relevant web-pages to explore, an end-user typically starts with a query to a search engine. This initial query is expected to yield a set of results with high recall but possibly low precision. A simple combination of arguments does not necessarily con-stitute a good initial query for a search engine: based on the application, the user might want to use additional keywords or some features of a search engine front-end in the query.
In our approach, every LaSEWeb program contains a seed query builder  X  a function that composes the initial query to a search engine (  X  3.1 ).

Answers have multiple representations . A single an-swer can be found on the Web in multiple string represen-tations. For example, a person X  X  name can be written with or without middle initial, with given name or family name first, with or without proper capitalization, etc. The nature of such multiple representations depends on the application.
We cluster multiple representations of the same answer to-gether using a similarity function that defines an application-specific logic of answer similarity (  X  3.1). We then rank the resulting clusters by our measure of answer confidence, and choose a representative answer for every cluster (  X  4.2).
People look for patterns . When looking for an answer on a particular webpage, people use a set of patterns that lo-cate relevant information within the content of the webpage. These patterns can be categorized as follows: 1. Linguistic patterns , as in Scenario 1 , use syntax 2. Structural patterns , as in Scenario 2 , use structured 3. Visual patterns , as in Scenario 2 , use spatial lay-We present an appropriate query language that includes lin-guistic, structural, and visual patterns of search strategies (  X  3.2 ). This language is the main component of LaSEWeb
In this section, we present the language of LaSEWeb  X  3.1 introduces LaSEWeb programs  X  our representation of parameterized queries, described and motivated before in  X  2. We describe the syntax and semantics of LaSEWeb queries , the main component of LaSEWeb programs, in  X  3.2 . The implementation of our interpreter for LaSEWeb programs is discussed in  X  4.
Every LaSEWeb program P represents a single param-eterized query that takes a tuple of user query arguments  X  X  and returns a set of answer strings, annotated with their confidence scores along with their source URLs. The exe-cution of a LaSEWeb program P on a tuple of user query arguments  X  X  is defined as P :  X  X   X  X  X { X  a i , X  i ,U i  X  X  , where a the i th answer string ,  X  i is its confidence score , and U set of its source URLs . Higher confidence scores correspond to more relevant answers.

The syntax and semantics of LaSEWeb programs is based on our observations, summarized in  X  2.2 . A LaSEWeb pro-gram P first constructs a seed query for Bing, executes a LaSEWeb query on each of the returned search results, ex-tracts the desired answer strings from the matches of the LaSEWeb query, and clusters these answer strings together, according to the similarity function .

Definition 2. A LaSEWeb program P is parameterized by  X  X  that is replaced by a tuple of user-provided arguments at runtime for every specific search invocation. It is defined as a tuple  X  q, X , Q , X  a  X  , where:
Example 1. In Scenario 1 the  X  X nventor X  micro-segment is described with LaSEWeb program P =  X  q, X , Q , X  a  X  , where: Specific search invocations of P apply it on specific user pa-rameters, such as  X  X  = ( X  computer  X ) , or  X  X  = ( X  paper clip  X ) .
The rest of this section focuses on the syntax and seman-tics of the main component of a LaSEWeb program  X  a LaSEWeb query Q . Our interpreter for LaSEWeb pro-grams, which makes use of the other components as well ( q ,  X  , and  X  a ), is described in  X  4.
A LaSEWeb query Q is executed against a webpage. A webpage is a tree of HTML nodes N . For each HTML node N we define two auxiliary functions BBox ( N ) and Text ( N ), which are used by LaSEWeb to determine the result of the execution. BBox ( N ) returns a rectangle b that is the smallest bounding box of node N on the page, when rendered by a browser (assuming a fixed resolution). Text ( N ) is a string that is a displayed textual content of N , with all HTML tags stripped off. The result of executing a LaSEWeb query Q against such a webpage is a multi-set of possible answer strings , each labeled with some label  X   X  the subexpression of Q that matched this answer string. A subset of this multi-set that is labeled with the  X  X nswer label X   X  a in the definition of P , is selected for the final answer set.
 Fig. 2 shows the syntax of LaSEWeb . A LaSEWeb query Q unites three types of expressions: visual expressions B , structural expressions S , and linguistic expressions L . They are aligned in a hierarchical structure of three layers that match separate webpage elements: Figure 2: (a) LaSEWeb query language syntax. v k denotes the k argument in a tuple of user query arguments  X  X  , k denotes Together these three expression types cover the entire range of typical patterns of search strategies, defined in  X  2.2.
A LaSEWeb query Q is parameterized with a tuple of parameters  X  X  , which are replaced by user-provided query arguments v k (before its execution on a webpage). Thus, in Fig. 2 every string (which is not a label name) can be either a constant string literal w , or a user query argument v k
We begin with an explanation of linguistic expressions in  X  3.2.1 , and proceed with structural expression in  X  3.2.2 , and visual expressions in  X  3.2.3 . Examples 4 and 5 give examples of full LaSEWeb queries on applications from  X  2.
A linguistic expression L consists of a linguistic pattern E and a linguistic constraint  X . Here linguistic patterns, when executed against an input string t , collect multiple matches M , and linguistic constraints filter out matches with unde-sired properties.
 A linguistic pattern E is executed against an input string t . In our system, we consider strings as lists of tokens . A token is a natural language primitive (word, punctuation, etc.).
The result of the execution of E on t is a set W of linguis-tic matches M . Every linguistic match M is a mapping from ID labels  X  of E  X  X  subexpressions to matched substrings of t . Intuitively, E acts similarly to a regular expression: when E finds a succesful match within t , every subexpression of E corresponds to some substring t  X  of t . Some of these subex-pressions  X  : E are explicitly marked with labels  X  ; this is similar to named capturing groups in regular expressions.
Linguistic patterns are similar to regular expressions in a sense of their composition methods. They are divided into three kinds as described below.

Primitive . A linguistic pattern Word matches any sin-gle token. We usually denote  X  : Word simply as  X  , since la-bel  X  is essentially a variable that captures a word match in the mapping M . Linguistic patterns ConstWord ( s ) and ConstPhrase ( s 1 ,...,s k ) match a fixed token s or a fixed se-quence of tokens  X  s 1  X  ...  X  s k  X , respectively, in t .
Composite . Operators +, ?, and  X  (Kleene star) borrow their semantics from regular expressions. Each of them has a single linguistic pattern as a subexpression, and their result-ing mappings M are composed from the matches found in subexpressions. For + and  X  , whose subexpression matches multiple times in the substring, we put all the found map-pings in the final linguistic match M . Thus, the same label  X  may occur multiple times in the linguistic match M .
Linguistic predicates . Most of the forms of linguistic patterns are predicates , which match a token or a sequence of tokens only if it satisfies some linguistic property. We show several representatives of linguistic predicates in Fig. 2 ; more can be implemented, assuming the existence of corre-sponding NLP algorithms. In this paper we use the following representative predicates: We assume the existence of corresponding functions IsNP ( s ), PosValue ( s ), AreSynonyms ( s 1 ,s 2 ), EntityValue ( s ), which im-plement required NLP algorithms on strings.  X  4 discusses our implementation of these functions.

Linguistic constraints . Every match M , returned by a linguistic pattern E , is filtered through a linguistic constraint  X . The final set of matches W , returned by a linguistic ex-pression L , consists only of those matches M that haven X  X  been filtered out by  X .

We present two representatives of linguistic constraints:
Example 2. The  X  X nventor X  micro-segment in Scenario 1 can be described with the following linguistic expression:
Suppose the specific search invocation looks for the inventor of typewriters. We set  X  X  = ( X  typewriter  X ) and apply the re-sulting query to strings found on the pages returned by Bing. One of these strings is t =  X  X n 1714, a patent to something like a typewriter was granted to a man named Henry Mill in England, but no example of Mills X  invention survives. Finally, in 1867, a Milwaukee, Wisconsin printer-publisher-politician named Christopher Latham Sholes, with assis-tance from Carlos Glidden and Samuel Soule, patented what was to be the first useful typewriter. X  3
E 2 will capture no matches. E 1 , however, will capture 4 matches. In each of them  X  q will capture the word  X  type-writer  X , and  X  ans will capture named entities  X  Henry Mill  X ,  X  Christopher Latham Sholes  X ,  X  Carlos Glidden  X ,  X  Samuel Soule  X , respectively. All of them are possible matches of because there is a word  X  patented  X , the synonym of  X  in-vent  X , between them and the last occurence of  X  typewriter  X  in t . However, the first match will be eliminated by  X  , be-cause captures of  X  ans and  X  q occur in different sentences. The final result of L is a multi-set W of three matches. Out of them, all three can be considered  X  X nventors X  of the typewriter, although one (Christopher Latham Sholes) is ar-guably more relevant than two others.
 We note several features of LaSEWeb in this example:
A structural expression S is executed against an HTML node N and returns an answer set W . Two representative constructors of structural expressions, AttrLookup ( L and VLOOKUP ( L 1 , L 2 , L 3 ), describe two structural patterns that arise in the real-word webpages. A structural pattern is a particular alignment of structured information on a web-page, such as a relational table or a list of attributes. For such structured forms we can use any relational techniques (of which VLOOKUP and AttrLookup are two examples) to select the required information from the structure.
In real-world webpages, the information is seldom present in a clean tabular format. However, the information is of-ten semi-structured : it follows a recognizable pattern, from which the implicit tabular structure can be recovered. For example, consider a list of  X   X  attribute  X  :  X  value  X   X  lines, each presenting an attribute and its value, separated by a colon. Such a list can be interpreted as a 2-column table of at-tributes along with their corresponding values. We call such implicit tables logical tables and assume the existence of a Tables ( N ) function that returns a set of logical tables present in the HTML node N . Each table T is indexed from 1 through the number of rows/columns. Each cell T [ j,k ] is the textual content of the corresponding logical cell (e.g. the con-line in a paragraph, etc.). We discuss our implementation of Tables ( N ) in  X  4. Figure 3: Textual attribute table about the typewriter in-ventor. Two separate HTML &lt;table&gt; s are highlighted. Constructor VLOOKUP ( L 1 , L 2 , L 3 ) represents a Microsoft Excel VLOOKUP operation. Its arguments are the key expres-sion L 1 , the header expression L 2 , and the content expres-sion L 3 . Given a logical table T , if L 1 matches a cell T [ j,k in j th row, and L 2 matches a header cell T [1 ,k ] in k of the first row, LaSEWeb executes the content expression L 3 on the intersection cell T [ j,k ], and returns the result.
Constructor AttrLookup ( L 1 , L 2 ) represents a two-column attribute lookup operation. Its arguments are the attribute expression L 1 and the content expression L 2 . Given a logical table T of  X  2 columns where L 1 matches any cell T [ j, 1] in the j th row of the first column (attribute name), LaSEWeb executes the content expression L 2 on the neighboring cell T [ j, 2], and returns the result.

Example 3. Fig. 3 shows an example of a logical table about the inventor of a typewriter, taken from the Web. This table is not a 2-column &lt;table&gt; tag, as it might appear to the viewer. Instead, it is represented as two &lt;table&gt; tags (highlighted in green), with pieces of plain text information within. Nevertheless, if N is a &lt;div&gt; containing both &lt;ta-ble&gt; s, our function Tables ( N ) extracts a single 2-column attribute table from it.

The following structural expression is used to extract in-formation from such logical table:
This expression is not parameterized with any user argu-ments, it extracts the attribute value for any  X  X nventor X  row. In order to bind S to the particular invention ( X  typewriter  X ), we introduce additional constraints on it in Example 4 .
A visual expression B is executed against a bounding box b . We use bounding boxes instead of HTML nodes here, because not every visually distinguishable webpage element is represented by a single HTML node. We made LaSEWeb accessible to end-users, according to our observations of their search strategies. As  X  2.2 shows, they often make use of the stylistic properties of the webpage, as seen by end-users .
The result of the execution of B is a tuple of a linguistic answer set W , matched by the lower subexpressions, and a visual match V . A visual match is a mapping of ID labels of visual expressions  X  to bounding boxes b .

Constructor Union ( B 1 , B 2 ) matches a union of two bound-ing boxes unite ( b 1 ,b 2 ) if its subexpressions B 1 and B b and b 2 , respectively. The union of two bounding boxes is the smallest rectangle that contains both b 1 and b 2 .
Visual constraints . The top-level LaSEWeb query Q consists of a visual expression B with a visual constraint  X . Similarly to linguistic constraints, visual constraints filter out false positive matches V , returned by the execution of B . We present three representatives of visual constraints here:
Example 4. The complete LaSEWeb query for the  X  X n-ventor X  micro-segment is shown below:
Example 5. Scenario 2 shows a repetitive task of collect-ing phone numbers from multiple personal contact pages of researchers, similar to the one shown in Fig. 1 . The follow-ing LaSEWeb query collects the desired phone number(s) from such a webpage:
When Q is executed with the arguments  X  X  = ( X  Shaz Qadeer  X ) , it matches any phone number in a logical attribute table such that  X  X haz Qadeer X  can be found above the table within the proximity threshold, and is somehow emphasized.
In this section, we discuss our implementation of the inter-preter for LaSEWeb programs. It consists of two important components: the interpreter for LaSEWeb queries Q , and the execution engine for the entire LaSEWeb program P . We discuss important aspects of the LaSEWeb query inter-preter implementation in  X  4.1 , and present our LaSEWeb program execution algorithm in  X  4.2 .
The key ideas in our interpretation of linguistic expres-sions are: (a) usage of state-of-the-art NLP algorithms, and (b) our refinement of the semantics of E for better perfor-mance on large webpages, called anchoring .

NLP algorithms . To support interpretation of linguis-tic predicates, our implementation requires algorithms for the functions IsNP ( s ), PosValue ( s ), EntityValue ( s ). They are implemented using state-of-the-art algorithms in NLP: Stan-ford CoreNLP [ 7, 15 , 26 ] and MSR SPLAT [ 22 ] for named entity recognition, syntactic parsing, and part-of-speech tag-ging. To implement the AreSynonyms ( s 1 ,s 2 ) function, we used S. W.-t. Yih X  X  PILSA word synonymy library [ 27 ].
Anchoring . A na  X   X ve implementation of matching a lin-guistic expression E against a string t would try to find a linguistic match for every possible starting token in t . This Figure 4: (a) A logical table on the Amazon website, built with a grid of &lt;div&gt; elements (shown in green). (b) A logical table, built in plain text with commas as column separators. is extremely inefficient, especially when dealing with Kleene star operator  X  . Instead, we anchor our matching procedure, identifying a set of constant strings ( anchors ), if any, that must match as particular subexpressions of E . If anchors are given, we start the matching with a linear search for an-chor occurences in text, and proceed with matching other subexpressions of E around every occurence. If no anchors are given, the algorithm resorts to na  X   X ve matching.
The key idea in our interpretation of structural expres-sions is the Tables ( N ) function, which implements logical table detection . Its goal is to extract any information from the HTML node N that is likely to be perceived as a ta-ble by an end-user. We implement three basic strategies for detecting logical tables within an HTML node:
HTML tables . A &lt;table&gt; tag defines a logical table un-less it is used for webpage layout (i.e. has multiple non-primitive pieces of content within it, possibly nested tables).
Visual tables . Any grid of &lt;div&gt; s or similar block ele-ments constitutes a logical table if its bounding boxes are precisely aligned in a grid structure. Fig. 4a shows an ex-ample of a logical table built with &lt;div&gt; elements. We de-tect such tables by collecting a tree of bounding boxes of all HTML nodes within N , and then building grids of those bounding boxes that are aligned next to each other.
Plain text tables . Often the information is presented as a table by marking it with punctuation signs and separators in plain text, instead of HTML tags. Fig. 1 and Fig. 3 show examples of such plain text tables, with colon being a sepa-rator between two columns. Fig. 4b shows another example, where the intended table is relational, and the separator be-tween the columns is comma.

The simplest approach for detecting plain text tables would be to maintain a set of common separators (i.e. a colon, a comma, a space, etc.), and attempt to split entire para-graphs of text by them, picking the one that gives most results. However, even if the separator is  X  X orrect X  (i.e., it actually splits the logical columns in the paragraph), it can also be present within some of the logical cells. For exam-ple, if Fig. 4b used whitespace instead of comma for column Figure 5: LaSEWeb program execution algorithm. It takes a LaSEWeb program P and tuple of user query arguments  X  X  , and returns a set of triples  X  a i , X  i ,U i  X  where a i is an answer,  X  is its confidence score, U i is a set of its source URLs. separation, this na  X   X ve algorithm would detect four columns instead of three for  X  X ort Worth X  and  X  X rand Prairie X  rows.
However, there exists an approach to figure out correct splits automatically. Fix a candidate separator from the com-mon list. For this separator and a fixed HTML node N , we first build a list of lines in Text ( N ) that have consistent split-ting with respect to this separator (i.e. the same number of columns &gt; 1). The rest of the lines are passed to the PBE system FlashFill [ 9], which automatically figures out likely syntactic string transformations from few examples by using sophisticated ranking schemes. We use their publicly avail-able implementation from the Microsoft Excel spreadsheet system. The list of consistent lines is used as a list of positive examples for FlashFill. The output of FlashFill is the list of correct outputs (splits) for the rest of the lines, or a failure signal. Our LaSEWeb program interpreter automatically checks the correctness of this output later, by comparing it with other answer candidates during clustering.
The key idea in interpretation of visual expressions is us-age of runtime presentational attributes of HTML nodes N . Specifically, we ask a browser to render each webpage in memory, on a virtual canvas of 1920  X  1080 pixels. After ren-dering, we collect the information about the bounding box of each HTML node N , and use it as a value of BBox ( N ). Similarly, we collect the run-time values of CSS attributes, and use them for evaluating visual constraints  X .
Fig. 5 shows the algorithm of LaSEWeb program execu-tion. It takes a LaSEWeb program P and a tuple of user query arguments  X  X  , and returns a set of answer strings , aug-mented with their confidence scores and source URLs .
The execution algorithm is shown as Search ( P , X  X  ) func-tion. It starts with querying the search engine for URLs with a seed query (line 1) and filling in user arguments in the LaSEWeb query Q (line 2). After that it proceeds with matching the query Q with every URL in the obtained list of search results U .

During matching, the algorithm maintains a set of clus-ters C . Every cluster C i  X  C represents a single logical an-swer. A cluster is a multi-set of string representations s augmented with sets of their source URLs. A cluster can contain multiple occurences of the same answer string s and the same answer string may occur multiple times on a single webpage (URL). Every time the algorithm finds a new answer string s k on some webpage u j , it constructs a new singleton cluster { X  s k , { u j } X  X  and merges it with all existing clusters in C that contain strings similar to s k , according to the similarity function  X  (lines 7-11).

After matching, the algorithm extracts logical answers and their confidence scores from the collected set of clusters C (lines 12-16). For each cluster C i  X  X  , it considers the most frequent answer string in it as a representative answer of this cluster. Its confidence score is calculated with Bayes Law: where | S j | is the number of answer strings extracted from u and c ( s,u j ) is the number of times s was found in u j
We implemented LaSEWeb in C# programming language in approximately 5000 lines of code. In this section, we present the results of its evaluation over two applications of para-metrized Web programming, shown in  X  2. It aims to verify the following usability requirements of LaSEWeb : 1. Low number of iterations (refinements) during LaSEWeb 2. High total number of correctly answered real-life queries.
For the first goal, we observed that in all experiments, the number of iterations required to compose and evaluate every program on our own search strategies was at most 5. We present the detailed results of evaluating the second goal below for every application.

Micro-segments . We extracted 100,000+ user queries across 7 micro-segments from the logs of a popular search engine over the 12 month period. These micro-segments were chosen by our Bing partners as possible targets because of a substantial query traffic. Since LaSEWeb does not have an NLP front-end, we used regular expressions to extract user queries that belonged to certain factoid micro-segments. Fig. 6a reports the results of micro-segment evaluation. For each micro-segment we show the recall (fraction of an-swered user queries), and comparison with the existing Bing question answering module. Given the absence of ground truth data for real-life user queries, we evaluated LaSEWeb precision by manually sampling 30-50 queries for each micro-segment at random. On average, the top 3 results contained  X  X orrect X  answers to the query in 95% of cases.

As Fig. 6a shows, LaSEWeb handles a much greater frac-tion of user queries than Bing question answering module. Bing module gives definite answers from structured databases, thus achieving 100% precision, but low recall. Additionally, LaSEWeb found alternative answer options for many ques-tions, providing additional context, whereas Bing provided only a single answer from the database. Low recall of  X  X SCII X  and  X  X yrics X  micro-segments can be improved by additional refinement of our LaSEWeb programs.

We refrained from comparison of LaSEWeb with state-of-the-art Web question answering engines for two reasons. First, question answering engines mostly operate on a lin-answered by LaSEWeb (recall), fraction of queries, answered by Bing. guistic level, taking a query in natural language, and con-verting it into a logical representation. LaSEWeb solves an orthogonal problem: it takes a query in a logical represen-tation, and searches for answers on the Web. Second, prior question answering approaches were evaluated on a narrow set of unique factoid questions (e.g. TREC corpus). In con-trast, LaSEWeb focuses on large micro-segments of simi-lar questions. Both of these aspects make direct comparison of approaches infeasible: LaSEWeb does not focus on user query analysis, and spending time on writing LaSEWeb programs for 500 different TREC questions was not mean-ingful. We note that any state-of-the-art user query analysis module can be used as a LaSEWeb front-end that converts a query into a logical representation, as discussed in  X  6.
The running time of LaSEWeb on a single webpage ranges from 0.1 to 20 seconds, and the time to interpret a single query is linearly proportional to the number of webpage ex-amined. Since this performance is not sufficient for answer-ing user queries in real-time, our engine can be used to gen-erate answers to logged queries offline, and the results can be stored in a database to answer future queries in real-time.
Repeatable search tasks . We chose 5 categories of re-peatable academic search tasks, and used them for LaSEWeb evaluation. The test data for 3 people-related tasks is a list of PLDI 2014 committee members (37 people), and the data for 2 conference-related tasks is a list of 21 st century POPL and PLDI conferences (28 items). We evaluated precision and recall of all results manually.

Fig. 6b shows the results of the evaluation. Most of the desired information was easily extracted from the Web. The average precision is 73%, which is lower than that of a micro-segment search due to (a) inconsistensies in named entity recognition for organizations, and (b) name collisions for some of committee members. The recall in influenced by the recall of Bing results (for this application it is much lower that that of a factoid questions). In some of the cases we couldn X  X  find the correct answers ourselves (e.g., for some invited talks). Also, LaSEWeb currently does not handle non-HTML formats: for example, a researcher X  X  PhD insti-tution is often listed in the CV, in PDF format, and Bing couldn X  X  find any alternative sources of information.
Question answering . The problem of answering factoid questions in natural language has been studied for several decades. The most notable examples include Watson [12 ], KnowItAll [6], START [ 14 ], AskMSR [4 ], etc.

Most of these systems focus on understanding user intent, expressed as a question in natural language, and assume the existence of structured knowledge databases. In contrast, LaSEWeb extracts data from semi-structured sources on the Web, by restructuring this data according to the guid-ance, provided by an end-user in a form of a program in our language. These two efforts are orthogonal and can be inte-grated to provide a natural language front-end for extracting arguments for programs in our query language.

Some of the question answering systems [ 4, 6] use an auto-matic approach to extract answers from the Web. LaSEWeb is semi-automatic: it does not generalize the patterns au-tomatically, mostly because it allows for specifying struc-tural/visual patterns in addition to linguistic patterns, used by question answering systems. This allows for higher re-call of LaSEWeb , but requires an end-user to construct a program manually, by exploring several examples. The in-tegration of NLP technologies for user intent understanding will eliminate the need for manual program construction.
Repeatable search . A concept similar to our definition of repeatable search tasks are Web mashups, which are web-sites that combine information from public APIs into a single visualization. Ennals and Gay [ 5] proposed MashMaker, a GUI and a language for creating mashup websites. However, mashups use only structured information from public APIs as their data sources. In contrast, LaSEWeb allows to auto-mate arbitrary repeatable search task over semi-structured Web data. Unlike MashMaker, LaSEWeb doesn X  X  provide a GUI for constructing programs in our language, but we in-tend to explore automated synthesis of such programs from examples or natural language [ 10 ]. A similar work has been done on mashups: Vegemite [19 ] generates mashup expres-sions using programming by demonstration.
 CoScripter [18 ] is a system that automates repetition of Web-based tasks using demonstration. It records scripts of actions on a webpages into a central public repository, from which they are later available for execution. CoScripter fo-cuses on multiple Web-based tasks, not necessarily search-related. However, it is limited in a way in which scripts can process information on a webpage. LaSEWeb includes a wide range of webpage features, generalized from our obser-vations of typical search strategies, which allow for a more precise capturing of the end-user X  X  search intent.

SXPath . SXPath [20 ] is the language that extends pop-ular XML query language XPath [ 2] towards queries upon visual layout of XML elements. It is built on the system of visual axes and bouding boxes in addition to XPath concepts.
LaSEWeb includes visual expressions as part of its query language, because they often appear in patterns that end-users use to extract information from the Web. In contrast to SXPath, LaSEWeb also includes linguistic and structural expressions, which allow for querying a HTML document on the levels, semantically different from XML.

Table detection . An important portion of LaSEWeb is its logical table detection algorithm, that lies in the core of structural expression matching. Table detection has been studied in the past. Tengli et al. [ 25 ] develop an algorithm that extracts information from semi-structured HTML and plaintext tables using examples  X  marked row/column la-bels. Kr  X  upl et al. [ 16 ] and, similarly, Gatterbauer et al. [8 ] propose techniques for using visual cues (bounding boxes) for automatic table extraction. Cafarella et al. [1 ] perform table extraction from linguistic cues.

LaSEWeb integrates all table extraction approaches (tex-tual, visual and structural) in a single automatic function. Our implementation also uses a state-of-the-art PBE sys-tem [9 ] in a novel manner for parsing plain text tables with inconsistent separators. However, any off-the-shelf table ex-traction technique (e.g., [1 , 16 , 17 , 25 ]) can be used to com-plement the logical table extraction module for LaSEWeb .
This paper investigated the problem of Web program-ming  X  a novel programming model, where functions are de-fined as repeatable search procedures, operating over semi-structured content of webpages returned by a search engine. These functions can be used multiple times with different user query arguments. We explored two of the many possi-ble applications of Web programming, namely factoid micro-segments in search engines, and repeatable batch queries.
We present a DSL that allows end-users and software de-velopers to express semantic patterns of their search strate-gies, eliminating the need for manual exploration of search engine results. Our implementation of the DSL leverages cross-disciplinary technologies: browser rendering APIs, state-of-the-art NLP tools, and programming by example tech-nologies. Our system LaSEWeb achieves good precision and recall in practice, and is an important step towards automa-tion of knowledge discovery on the Web.

LaSEWeb can be seen as bridging the gap between PL technologies for processing structured data formats, and nu-merous semi-structured data on the Web. Our programming model is a natural evolution of the prior effort on integrating structured Web queries into programming environments.
We thank Saurabh Tiwary and the Bing team for provid-ing us access to the valuable user search query data. [1] M. J. Cafarella, C. Re, D. Suciu, O. Etzioni, and [2] J. Clark, S. DeRose, et al. XML path language [3] C. De Rosa, B. Gauder, D. Cellentani, T. Dalrymple, [4] S. Dumais, M. Banko, E. Brill, J. Lin, and A. Ng. Web [5] R. Ennals and D. Gay. User-friendly functional [6] O. Etzioni, M. Cafarella, D. Downey, S. Kok, A.-M. [7] J. R. Finkel, T. Grenager, and C. Manning.
 [8] W. Gatterbauer and P. Bohunsky. Table extraction [9] S. Gulwani. Automating string processing in [10] S. Gulwani. Synthesis from examples: Interaction [11] R. Housewright, R. C. Schonfeld, and K. Wulfson. [12] A. Ittycheriah, M. Franz, W.-J. Zhu, A. Ratnaparkhi, [13] B. J. Jansen and A. Spink. How are we searching the [14] B. Katz, G. Marton, G. C. Borchardt, A. Brownell, [15] D. Klein and C. D. Manning. Accurate unlexicalized [16] B. Kr  X  upl, M. Herzog, and W. Gatterbauer. Using [17] V. Le and S. Gulwani. FlashExtract: a framework for [18] G. Leshed, E. M. Haber, T. Matthews, and T. Lau. [19] J. Lin, J. Wong, J. Nichols, A. Cypher, and T. A. Lau. [20] E. Oro, M. Ruffolo, and S. Staab. SXPath: extending [21] K. Purcell, J. Brenner, and L. Rainie. Search engine [22] C. Quirk, P. Choudhury, J. Gao, H. Suzuki, [23] A. Spink, H. C. Ozmutlu, E. Aversa, and C. Manley. [24] J. Teevan, C. Alvarado, M. S. Ackerman, and D. R. [25] A. Tengli, Y. Yang, and N. L. Ma. Learning table [26] K. Toutanova, D. Klein, C. D. Manning, and [27] W.-t. Yih, G. Zweig, and J. C. Platt. Polarity
