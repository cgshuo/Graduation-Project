
Sequences of events are a common type of data arising in various scientific as well as business applications, e.g., teleco mmunication network management, web access ( t , e ) ,where t is the occurrence time and e is the type of event. The occurrence series, which typically contains observations at determined time points. An event event sequences arising in applications can be quite long, containing hundreds of the changes X  X uch as occurrences of other kinds of events or values of covariates.
Stochastically, a sequence consisting o f (conditionally) independent events can be seen as being produced by a Poisson process , which has some underlying intensity describing the frequency of events. Time-dependent intensity functions can be used in modelling the frequencies of event sequences.

In this paper, we show that piecewise constant functions provide flexible tools elling approach and reversible jump Markov chain Monte Carlo (MCMC, RJMCMC) methods, which provide a framework for expressing the available knowledge of the values of the model parameters by assigning probability distributions to the param-eters.

MCMC-based approaches are fairly slo w and hence we study faster approaches based on the maximum-likelihood approach. We show that, if the best fitting piece-wise constant function X  X nstead of the distribution of functions X  X s to be computed, the optimal solution can be found by using dynamic programming in time O where n is the number of events and k is the number of pieces. This may be too slow as well. We introduce simple heuristics that can be used to prune the number of the potential change points of the functions. Speedups of several orders of mag-nitude in the performance of the dynami c programming algorithm are reached with samples of approximately 0.5 X 5% of the total number of potential change points is sufficient for near ly optimal results.

Although the Bayesian posterior average and the piecewise constant intensity function giving the maximum likelihood do not describe the same quantity, they do reflect the same phenomenon; that is, highly probable intensity values of the process that generated the data sequence. Hence, it is interesting to compare the results of the two approaches. We show that the resulting piecewise constant intensity functions correspond closely to the posterior averages produced by the MCMC methods.
The rest of this paper is organized as follows. In Sect. 2, we introduce the con-cepts of event sequence and intensity function. In Sect. 3, we describe the Bayesian modelling approach and Markov chain Monte Carlo simulation methods. The methods are applied to a telecommunication network alarm data in Sect. 4. In Sects. 5 and 6, we describe the dynamic programming approach and some simple techniques for earlier version of this paper appeared in Mannila and Salmenkivi (2001).
We next define some notation, following Arjas (1989). Let T be the random variable indicating the waiting time for the next event from a fixed starting time of a process containing events of a single type and let G ( t ) = function of T .Then G ( t ) is the probability that (after the starting time, some time t the waiting time before the next event is not longer than t . Assume that the density function  X ( t ) is defined as follows:
Thus,  X ( t ) expresses the instantaneous probability of occurrence of an event at time t , given that no event occurred before t .
 rences per time unit. Assume that events of an event type occur at a constant inten-sity  X  c . Then the survival function G ( t ) = exp (  X  t tion function of the time intervals between the occurrences ( T )is G
This is the distribution function of the exponential distribution; thus, the time inter-vals T  X  Exp ( X  c ) .
 and therefore and tion  X  A for each event type A .

Piecewise constant functions A piecewise constant intensity function values {  X  1 , ...,  X  i } X  R + are the intensity values in i pieces and are the change points of the function.
 stant functions are relatively simple. The arithmetic operations between such func-tions result in piecewise constant functions. These operations, as well as integration, interpret.
Poisson likelihood Consider an intensity function  X  e ( t and consider an event sequence S e ={ ( e , t 1 ),...,( e i = 1 ,..., n . The Poisson likelihood of the data S e is given by (see, e.g. Guttorp 1995) where t 0 = T s . Because integration is done over the whole time range likelihood can also be written in the form
Next, we briefly describe the Bayesian modelling approach for finding piecewise constant intensity models. For more details, see, e.g. Bernardo and Smith (1994) and Gelman et al. (1995).

Bayesian modelling Assume that a full probability model M denote the vector of the model parameters  X  ={  X  1 ,..., X  by x ={ x 1 ,..., x n } and the data Y . The joint probability distribution determined by
M is given by
Here P ( X ) is the prior distribution of  X  and P ( Y |  X )
Finding out the posterior distribution P ( X  | Y ) is the core of Bayesian data analy-sis. According to Bayes X  rule,
As the probability of the data P ( Y ) does not depend on is proportional to the product of the prior distribution and the likelihood.
The desired quantities are often presented as expected values of a function on the posterior distribution. To know the posterior expectation of a function g , one needs integrate over posterior density function f ,
In practical situations integration ca nnot be done analytically or even with classical numerical methods due to the complexity of the density functions.

Markov chain Monte Carlo methods (see, e.g. Gamerman 1997) approximate the target distribution f by constructing a Markov chain that has f as the equilibrium distribution. The sample set x 1 ,... , x N drawn from f can then be used for implicit Monte Carlo integration,
Metropolis X  X astings algorithm Denote by T ( x , y ) the probability of moving from x and y ,wehave aperiodic (Tierney 1994), then the revers ibility condition implies that the equilibrium Markov chain, we should find a function T satisfying Eq. (7).
 density q ( x , x ) . If, for instance, for some x , x , we have f then the simulation process moves too often from x to x . To correct the unbalance, the Metropolis X  X astings algorithm rejects a part of the proposals to move from x to x .
 x to x is defined to be 1, we can write f ( x ) q (  X ( x , x ) is the probability of accepting a move from x to x (Chib and Greenberg 1995). Thus,  X ( x , x ) is given by draws candidate states  X  and accepts them with the above probability. It is straight-forward to show that the method gives a Markov chain the equilibrium distribu-the Metropolis X  X astings algorithm can be applied provided these densities can be calculated.

Reversible jump MCMC For the case of piecewise constant functions, we need current state x is m and a candidate state x of a higher dimension n is generated.
Let u be a vector of random numbers used when proposing the candidate state x in state x . To ensure that both sides of the reversibility equation (Eq. 7) have densities on spaces of equal dimension, it must hold that m + given u ;i.e. x = h ( x , u ) . Then the acceptance rate of the Metropolis X  X astings algorithm generalized by Green (1995) to stat e spaces of variable dimensions yields x and u . The generalization is known as the reversible jump Markov chain Monte
Carlo (RJMCMC). For a detailed description of the RJMCMC, see Green (1995).
Bayesian intensity modelling with p iecewise constant representations In many cases, it is natural to assume the real intensities to be continuous, not step functions.
Even then, the intensity can be represented by using piecewise constant functions, if the number of pieces is one of the model parameters. RJMCMC methods can be used to approximate the posterior distribution of the intensity.

In the following, we describe a simple model where the intensity currences of an event is modelled using a piecewise constant function with a variable number of pieces. The levels of the function  X  j , the change times c ber of pieces k are random variables with the following prior specifications. Here  X ,  X  and  X  are fixed constants and T observation period, respectively:
An approximation for the posterior expectation of intensity can be computed from the simulation results in the following way. Each simulation round generates a single piecewise constant realization from the posterior distribution f the intensity value at time instant t i in the m th realization by
Carlo approximation of the posterior expectation of the intensity at t of  X  m ( t i ) ,i.e.
 where N is the number of iterations of the MCMC simulation.

We now proceed to introducing an applica tion from the field of telecommunica-tions.
Telecommunication network software collects lots of information about the perform-cations of smaller or larger problems in the network (H X t X nen et al. 1996).
This data contains hundreds of different event types. It is collected automatically and, accordingly, the amount of data can be several orders of magnitude larger than changes in the network structure. Thus, automatic methods are needed in the analysis of the data.

In this section, we apply the RJMCMC methods to modelling fault alarm se-quences. In Sects. 5 and 6, dynamic progr amming methods are used to find piece-wise constant intensity functions yielding maximum likelihood, given the number of pieces.

Our methods can, e.g. be used to detect change points of the intensities between stable periods. The change points can be used to create condensed representations of very long sequences. Original or condensed sequences can be used to find interaction whether there are event types the increasing intensity of occurrences of which is constant model can easily be extended to more subtle analysis of interaction between several event types or covariate effects (Eerola et al. 1998).

Uniform ( 0 . 00001 , 1 , 500 ) for the intensity-level parameters. We investigated the time period between 180,000 and 380,000 seconds from the start point of the observa-tion. The prior used for the change points was Uniform(180,000, 380,000). From an initial state with 20 pieces, 5,000,000 initial ite rations were run before collecting the parameter values. Then 1,000,000 iterations were run, during which the parameter values were collected from every round. The total run time was 55 minutes (Pentium 700 MHz).
 time instants are shown on the left in Fig. 1. The marginal posterior distribution of shown in Fig. 2, for the time points t 0 = 210,000 and t 0 both of the conditional distributions depicted here are summarised by three statistics in the left panel of Fig. 1; the percentiles at 2 , 100  X  cate the interval, where 99% of the values of the conditional intensity reside and the posterior average approximates the expectation of the distribution. The conditional distribution at 210,000 seconds provides onl y a little more information than the aver-300,000 seconds, instead, reveals more detailed information about the distribution of the intensity at the time instant.
The Bayesian approach and the MCMC methods provide clear conceptual as well as available knowledge of the parameter values. There are, however, problems com-monly encountered when applying the methods in practice. First, the convergence ment of the problems, see, e.g. Brooks and Giudice (1999) and Brooks and Roberts (1998).

For these reasons, the MCMC methods are not very suitable in circumstances for mining very large event sequences.
 original sequence of events.

Once the change points of the optimal piecewise constant intensity function are known, computing the intensity values giving the maximum-likelihood solution is presses the average number of occurrences per time unit.

The task of finding the optimal change points is not trivial, however. An im-points of the optimal piecewise constant function are always at occurrence times of the data sequence. (A change point between two events could be moved exactly to likelihood, Eq. (2)).

Hierarchical algorithm We now describe a greedy algorithm for finding change points, here called the hierarchical algorithm. The algorithm was introduced by Hawk-ins (1976); the presentation below is based on the version of Guralnik and Srivastava (1999).
 is split and the candidate is removed from the candidate set. Two new candidates intervals of the new change point. Splitting is continued until the stopping criterion is met.
 and k is the number of change points. The space needed is O not allow removing change points once they have been selected. However, a change point of the optimal solution with m pieces is not necessarily a change point of the optimal solution with n pieces ( m &lt; n ).

Dynamic programming algorithm We now introduce an algorithm based on the dynamic programming idea. The algorithm always finds the optimal solution for the change point detection problem.
 of E by t i , 1  X  i  X  n . Thus, T s &lt; t 1 &lt; ... &lt; of the optimal piecewise constant intensity function with k pieces are known, and denote them by  X  c 1 ,...,  X  c k  X  1 .Then  X  c 1 , ...,  X  piecewise constant function with k  X  1 pieces in the subperiod t as the end point of the time period by C ( k , t i of the optimal piecewise constant functions with k pieces in the optimal function with k + 1 pieces.
 piecewise constant intensity f unction with the number of pieces k and the observation interval [ t i , t j ] . Then the maximum likelihood of the function with k given by algorithm computes the optimal division into k pieces in the time interval best divisions into k + 1 pieces (see Fig. 4).
 following equations:
Thus, the dynamic programming algorithm not only finds the optimal solution in the time range [ T s , T e ] but also for all the subranges [ for loops of the algorithm lead to the time requirement O is O ( nk ) due to storing values for all the subranges and division sizes.
As a preliminary experiment, we generated 20 piece intensity functions using both the hierarchical and dynamic programming algorithms on an alarm dataset of 46,662 events. The results showed considerable differences between the solutions: only 5 out of 19 change points were common to both algorithms and 13 of them were clearly different. The change points are presented in Fig. 5. The corresponding log-likelihood values with different numbers of pieces are given in Fig. 7. The execution times were less than ten seconds for the hierarchical algorithm and nearly 15 hours for the dynamic programming algorithm (Pentium 800 MHz). The results show that the hierarchical method can produce clearly nonoptimal solutions, while the basic dynamic programming algorithm is unacceptably slow.

Because of infeasible run times of the dyna mic programming algorithm on large data change points.
 was carried out by picking up every m th occurrence of the event sequence to the 2 &lt; n ,and n is the number of events in the sequence. Then we decreased q by 1, down to 0, in which case all the occurrence times belonged to the candidate set. In was used in the preliminary trial above.
 predefined regular steps but rather by some heuristic methods for evaluating the value of an occurrence time as a potential change point.
 m th occurrence time of an event by t ( m ) and the size of the window by t = t ( m )  X  t ( m  X  w) and t h ( observation period was divided into segme nts such that each segment contained the same number of occurrences. Then the occurrence time with the best value in each segment was selected to the candidate set. The segmentation was done to avoid wide gaps between the candidates. We also used two or three different window sizes in the same run and selected the best value to represent the occurrence time in comparison.
We first ran the preliminary trial described above, now using the modified dynamic programming algorithm that selected candidate values with regular steps. When the candidate set of the potential change points included at least every 128th event of the whole data set, the algorithm resulted in higher likelihood values than the hierarchical algorithm. The execution time in the case was reduced from 14 as shown in Table 1. Results very near the optimal solution were obtained when at least every 8th event was included; the time needed was 14 minutes 16 seconds. The are also given in Table 1.

We then ran the experiment using the modified dynamic programming algorithm that selected candidates using the heuristic function of Eq. (12). The results shown in
Fig. 6 indicate that the algorithm utilizing thi s heuristic produced clearly better results than the hierarchical algorithm even when less than 250 candidates (0.5%) were used as potential change points. With more than 500 candidates, the likelihoods were very near that of the optimal solution. The execution time was only a few seconds. When using the heuristic selection, the algorithm needed a remarkably smaller number of candidates to reach the same quality of solu tions as in the case of the selection with regular steps. The results were also quite robust to the window size (Fig. 6).
In Fig. 7, the changes in log-likelihood values are shown when divisions up to 100 pieces were computed on alarm data s ets of 46,662 and 15,704 events. The the optimum, especially with relatively low numbers of splits. Instead, the divisions generated by the heuristic dynamic progr amming algorithm with different sizes of candidate sets are very close to the optimal solutions.

We also generated four artificial data sets and conducted similar trials on the intensity in data set 2, piecewise constant intensity in data set 3, and in the case of data set 4, we randomly changed the intensity at every occurrence time. The data sets and results are described in detail in the Appendix. Here we only illustrate the actual intensity (dashed line) and the 500 piece function produced by the modified dynamic programming algor ithm with 4,676 candidates.
We now investigate more deeply the influence of increasing the number of candidates on improvement in the likelihood values. The trials were run on the generated data sets 2, 3 and 4 (see Appendix).

We started the trials with less than 200 candidates (0.2% of total number of events) and doubled the number of candidates until the maximum number of 25,000 events (25% of the total) was reached.

Figures in the middle left show that 780 candidates out of 100,000 (0.78%) are suffi-cient to yield solutions very close to the optimal. Even using 390 candidates (0.39%) is, from 20 to 100 pieces.
 well; the actual intensity of the process is piecewise constant, and the changes in in-tensity values between adjacent pieces are rel atively large. Thus, the applied heuristic is reliable and selects candidates that really are good change points. Hence, a small number of candidates is sufficient to approximate the optimal solutions from 20 to 100 pieces accurately.

The results on the second and fourth data sets are somewhat different. In the case of the second set, 1,560 candidates (1.56% of all events) are enough to produce nearly optimal solutions for small numbe rs of pieces. When it comes to solutions for 70 or more pieces, the results improve rather strongly even if 25,000 candidates (25%) are used instead of 12,500. It took about 40 seconds to compute the solutions with 1,560 candidates and about 2 hours whe n 12,500 candidates were included in the candidate set.

The fourth data set was generated by changing intensity after every event (for details, see Appendix). Thus, intuitively, one might expect that it would be a difficult task to find good approximations using piecewise constant functions. However, as
Fig. 9, on the bottom-left, shows, in the case of a small number of pieces, the results improve only slightly when more than 877 candidates (0.88%) are available. When at least 3,500 candidates (3.5%) are employed, increasing candidates does not lead to strong improvements even if the solutions for 100, 150 or 200 pieces are considered.
On the other hand, even 200 pieces is not many when approximating the intensity that changes 100,000 times. The right-side picture indicates that the log likelihoods piece solution with 3,506 candidates is illustrated in Appendix in Fig. 15.
To reach nearly optimal so lutions with a small number of splits, i.e. when 877 candidates were used, the computations took 30 seconds. To yield the level of 3,500 candidates, 10 minutes were needed. It should be noticed that the run times are in-fluenced by the maximum number of pieces us ed. While the trials on the other data sets were run until 25,000 candidates were included in the candidate set, the trial on the fourth set was already stopped after 14,000 candidates. This was done because of the larger maximum number of pieces, which made the run times longer. The maximum number of pieces adopted in the case of the second set was 100. In the case of the fourth set, we us ed the maximum of 200 pieces.
 Now we proceed to comparing the presen ted results with those produced by the
MCMC methods.
In Sect. 4, we applied the Bayesian modelling approach and MCMC methods to alarm sequence data. The specified model f or the overall intensity was piecewise constant. Smooth posterior intensity curves could be produced due to the number of pieces being one of the model parameters.
 the best fitting piecewise constant intens ity with a predefined number of pieces reflect the same phenomenon. Thus, it is of interest to compare the results. Figure 10 illus-trates the correspondence of the two appro aches in trials on the alarm data set with 15,683 events. The time interval in both figures is from 5 seconds, the whole range being [ 0 , 11753 . 5  X  10 2 produced by the MCMC methods is compared with a 500-piece intensity function, which was generated by the modified dynamic programming algorithm. The candi-date set contained 1,964 possible change points, which is 12.5% of the total number of occurrences in the first data set. The average number of pieces during the MCMC simulation was 510.

The posterior average intensity and the piecewise constant intensity are close to produced by dynamic programming than the changes of the posterior curve. This is due to the strategy of maximizing likelihood, which tends to exaggerate the changes.
To put it more accurately, an optimal change point is always at some occurrence in the higher segment and, correspondi ngly, lowered in the other segment.
During the MCMC simulation, however, the distribution is detected instead of the produced from the different realizations, the changes are slightly more gradual.
The 99% posterior interval, shown at the bottom in Fig. 10, indicates the spread of the distributed intensity values. The maximum-likelihood solutions reside between the percentile curves.

We have considered finding piecewise constant intensity descriptions from event se-quences. With MCMC techniques, piecewise constant functions can be used in a flex-ible way to represent continuous intens ities. However, the MCMC methods needed for approximation of the posterior distribution are time consuming and the results may be sensitive to the choices of the simulation technical details, such as proposal-generating strategies and distributions.
 likelihood of the data were developed in Sect. 5. We showed that dynamic program-ming methods can be used to find the best fitting intensity function in O where n is the number of events in the sequence and k is the number of pieces of the intensity function. To speed up the dynamic programming algorithm, we applied heuristic methods. The approaches were based on using subsets of all the occurrence times as potential change points. We presented experimental results that indicated very remarkable speedups with minor loss in accuracy of results.

We generated data sets such that time intervals between events were distributed ex-ponentially with known time-dependent intensities. The sequence of the occurrence known. The modified dynamic programming algorithm using the heuristic selection performance of the algorithm in different known circumstances. We next describe the four datasets used in the experiments. Each set contained 100,000 events. The intensities of the data sets are presented in Fig. 11.

Set 1 The first set was generated us ing the constant intensity intervals  X  between events were exponentially distributed such that
Set 2 Second, piecewise constant intensity with 100 pieces was used. The intensity of 100,000 indices were selected randomly; denote the set of the selected indices by I . These indices determined the change points of the intensity function C c ,..., c was increased by 1. Thus, the intensity function was as follows: times t i ) according to  X  . Thus, at T s , the time interval and occurrence time was set to t 1 = T s +  X  1 . Then, at t from Exp ( 1 ) if 1 /  X  I ; otherwise, it was generated from Exp was given to t 2 , etc. Finally,  X  100,001 was drawn from Exp
Set 3 Like the second data set, the third set was generated using piecewise constant intensity with 100 pieces. Also, the change points were selected similarly, i.e. 99 out of all the occurrence indices were chosen randomly. Now, however, the intensities in each piece were drawn from the uniform distribution in range  X   X  Unif ( 0 . 0001 , 70 ) for each 0 &lt; i  X  100.

Set 4 Finally, we generated 100,000 events such that the intensity value was changed at each occurrence time. The intensities  X  1 ,..., X  100 distribution such that  X  i  X  Norm ( t i , X  2 ) ,where t i occurrence times and  X  2 is a fixed constant.

In Fig. 12, 10-and 20-piece intensity functions produced by the modified dynamic programming algorithm on the first data set are shown together with the real inten-sity  X  = 2. A candidate set of 1,494 candidates was used. The results are clear; the variance of the time intervals in the d ata is reflected by occasional peaks in the piecewise constant intensities. The improvements in results with the increasing num-the intuition that approximating the constant intensity with a small number of splits gives accurate solutions.
 occurrence times. Figure 12 shows the 30-and 80-piece approximations of the dy-namic programming algorithm as well as the real intensity. The 30-piece approx-
The 80-piece solution does not make any progress; the clear direction has been re-of events in the data per time unit in a period of 5 time units. The successive points correspond to successive time periods. The periods are not allowed to overlap; thus, each event influences one point only.
 likelihoods, until slowing down after 10 pi eces. Very slight improvements are yielded from then on.
 shown with 50-and 80-piece solutions of the modified dynamic programming al-gorithm using 2,441 candidates. Again, points are used to give an idea about the location of events in the data.

The 50-piece function does not have enough parameters to detect all the substan-tial changes in the data. However, the overall result is good. Figure 13, bottom left, confirms the interpretation: the functi ons with more than 80 pieces cannot make any considerable progress compared with the 80-piece solution. The 50-piece function yields nearly as high likelihood value.

For this reason, divisions up to 200 pieces , instead of 100 pieces used above, were produced in the trials on the fourth data set.
 levels in quite a convincing way. A more detailed view is given in Fig. 8 in Sect. 6.1. trials.

