
Broadcast Ne ws (BN) sho ws typically include multiple unrelated stories, interspersed with anchor presentations of headlines and commercials. Tran-sitions between each story are frequently mark ed by changes in speaking style, speak er participation, and lexical choice. Despite recei ving a consider -able amount of attention through the Spok en Doc-ument Retrie val (SDR), Topic Detection and Track-ing (TDT), and Text Retrie val Conference: Video (TRECVID) research programs, automatic detec-tion of story boundaries remains an elusi ve prob-lem. State-of-the-art story segmentation error rates on English and Mandarin BN remain fairly high and Arabic is lar gely unstudied. The NIGHTINGALE system searches a diverse news corpus to return an-swers to user queries. For audio sources, the iden-tication of story boundaries is crucial, to segment material to be searched and to pro vide interpretable results to the user .
Pre vious approaches to story segmentation have lar gely focused lexical features, such as word sim-ilarily (K ozima, 1993), cue phrases (Passonneau and Litman, 1997), cosine similarity of lexical win-dows (Hearst, 1997; Galle y et al., 2003), and adap-tive language modeling (Beeferman et al., 1999). Segmentation of stories in BN have included some acoustic features (Shriber g et al., 2000; T  X  ur et al., 2001). Work on non-English BN, generally use this combination of lexical and acoustic measures, such as (W ayne, 2000; Le vow, 2004) on Mandarin. And (Palmer et al., 2004) report results from feature selection experiments that include Arabic sources, though the y do not report on accurac y. TRECVID has also identied visual cues to story segmentation of video BN (cf. (Hsu et al., 2004; Hsieh et al., 2003; Chaisorn et al., 2003; Mayb ury , 1998)).
The training data used for NIGHTINGALE in-cludes the TDT -4 and TDT5 corpora (Strassel and Glenn, 2003; Strassel et al., 2004). TDT -4 in-cludes newswire text and broadcast news audio in English, Arabic and Mandarin; TDT -5 contains only text data, and is therefore not used by our system. The TDT -4 audio corpus includes 312.5 hours of English Broadcast Ne ws from 450 sho ws, 88.5 hours of Arabic news from 109 sho ws, and 134 hours of Mandarin broadcasts from 205 sho ws. This material was dra wn from six English news sho ws  X  ABC  X W orld Ne ws Tonight X , CNN  X Head-line Ne ws X , NBC  X Nightly Ne ws X , Public Radio International  X The World X , MS-NBC  X Ne ws with Brian Williams X , and Voice of America, English three Mandarin newscasts  X  China National Ra-dio, China Tele vision System, and Voice of Amer -ica, Mandarin Chinese  X  and two Arabic newscasts  X  Nile TV and Voice of America, Modern Standard Arabic. All of these sho ws aired between Oct. 1, 2000 and Jan. 31, 2001.
Our story segmentation system procedure is es-sentially one of binary classication, trained on a variety of acoustic and lexical cues to the presence or absence of story boundaries in BN. Our classi-er was trained using the JRip machine learning al-gorithm, a Java implementation of the RIPPER al-gorithm of (Cohen, 1995). 1 All of the cues we use are automatically extracted. We use as input to our classier three types of automatic annotation produced by other components of the NIGHTIN-GALE system, speech recognition (ASR) transcrip-tion, speak er diarization, sentence segmentation. Currently , we assume that story boundaries occur only at these hypothesized sentence boundaries. For our English corpus, this assumption is true for only 47% of story boundaries; the average reference story boundary is 9.88 words from an automatically rec-ognized sentence boundary 2 . This errorful input im-mediately limits our overall performance.

For each such hypothesized sentence boundary , we extract a set of features based on the pre vious and follo wing hypothesized sentences. The classi-er then outputs a prediction of whether or not this sentence boundary coincides with a story boundary . The features we use for story boundary prediction are divided into three types: lexical, acoustic and speak er-dependen t.

The value of even errorful lexical information in identifying story boundaries has been conrmed for man y pre vious story segmentation systems (Beefer -man et al., 1999; Stok es, 2003)). We include some pre viously-tested types of lexical features in our own system, as well as identifying our own `cue-w ord' features from our training corpus. Our lexical fea-tures are extracted from ASR transcripts produced by the NIGHTINGALE system. The y include lexi-cal similarity scores calculated from the TextT iling algorithm.(Hearst, 1997), which determines the lex-ical similarity of blocks of text by analyzing the co-sine similarity of a sequence of sentences; this al-gorithm tests the lik elihood of a topic boundary be-tween blocks, preferring locations between blocks which have minimal lexical similarity . For En-glish, we stem the input before calculating these fea-tures, using an implementation of the Porter stem-mer (Porter , 1980); we have not yet attempted to identify root forms for Mandarin or Arabic. We also calculate scores from (Galle y et al., 2003)' s LCse g method, a TextT iling-lik e approach which weights the cosine-similarity of a text windo w by an addi-tional measure of its component LEXICAL CHAINS , repetitions of stemmed content words. We also iden-tify `cue-w ords' from our training data that we nd to be signicantly more lik ely (determined by  X  2 ) to occur at story boundaries within a windo w preceed-ing or follo wing a story boundary . We include as features the number of such words observ ed within 3, 5, 7 and 10 word windo ws before and after the candidate sentence boundary . For English, we in-clude the number of pronouns contained in the sen-tence, on the assumption that speak ers would use more pronouns at the end of stories than at the be-ginning. We have not yet obtained reliable part-of-speech tagging for Arabic or Mandarin. Finally , for all three languages, we include features that repre-sent the sentence length in words, and the relati ve sentence position in the broadcast.

Acoustic/prosodic information has been sho wn to be indicati ve of topic boundaries in both sponta-neous dialogs and more structured speech, such as, broadcast news (cf. (Hirschber g and Nakatani, 1998; Shriber g et al., 2000; Le vow, 2004)). The acous-tic features we extract include, for the current sen-tence, the minimum, maximum, mean, and standard deviation of F0 and intensity , and the median and mean absolute slope of F0 calculated over the en-tire sentence. Additionally , we compute the rst-order dif ference from the pre vious sentence of each of these. As a approximation of each sentence' s speaking rate, we include the ratio of voiced 10ms frames to the total number of frames in the sentence. These acoustic values were extracted from the audio input using Praat speech analysis softw are(Boersma, 2001). Also, using the phone alignment information deri ved from the ASR process, we calculate speak-ing rate in terms of the number of vowels per second as an additional feature. Under the hypothesis that topic-ending sentences may exhibit some additional phrase-nal lenghthening, we compare the length of the sentence-nal vowel and of the sentence-nal rhyme to average durations for that vowel and rhyme for the speak er, where speak er identify is available from the NIGHTINGALE diarization component; otherwise we use unnormalized values.

We also use speak er identication information from the diarization component to extract some fea-tures indicati ve of a speak er' s participation in the broadcast as a whole. We hypothesize that partici-pants in a broadcast may have dif ferent roles, such as an anchor pro viding transitions between stories and reporters beginning new stories (Barzilay et al., 2000) and thus that speak er identity may serv e as a story boundary indicator . To capture such infor -mation, we include binary features answering the questions:  X Is the speak er preceeding this boundary the rst speak er in the sho w? X ,  X Is this the rst time the speak er has spok en in this broadcast? X ,  X The last time? X , and  X Does a speak er boundary occur at this sentence boundary? X . Also, we include the percent-age of sentences in the broadcast spok en by the cur -rent speak er.

We assumed in the development of this system that the source of the broadcast is kno wn, specif-ically the source language and the sho w identity (e. g. ABC  X W orld Ne ws Tonight X , CNN  X Head-line Ne ws X ). Given this information, we constructed dif ferent classiers for each sho w. This type of source-specic modeling was sho wn to impro ve per -formance by T  X  ur (2001).
We report the results of our system on En-glish, Mandarin and Arabic in Table 5. All results use sho w-specic modeling, which consistently im-pro ved our results across all metrics, reducing er-rors by between 10% and 30%. In these tables, we report the F-measure of identifying the precise lo-cation of a story boundary as well as three metrics designed specically for this type of segmentation task: the pk metric (Beeferman et al., 1999), Win-dowDif f (Pe vzner and Hearst, 2002) and C = 0.3) (Doddington, 1998). All three are deri ved from the pk metric (Beeferman et al., 1999), and for all, lower values imply better performance. For each of these three metrics we let k = 5 , as prescribed in (Beeferman et al., 1999).

In every system, the best peforming results are achie ved by including all features from the lexical, acoustic and speak er-dependen t feature sets. Across all languages, our precision X and false alarm rates X  are better than recall X and miss rates. We belie ve that inserting erroneous story boundaries will lead to more serious downstream errors in anaphora res-olution and summarization than a boundary omis-sion will. Therefore, high precision is more impor -tant than high recall for a helpful story segmentation system. In the English and Mandarin systems, the lexical and acoustic feature sets perform similarly , and combine to yield impro ved results. Ho we ver, on the Arabic data, the acoustic feature set performs quite poorly , suggesting that the use of vocal cues to topic transitions may be fundamentally dif ferent in Arabic. Moreo ver, these dif ferences are not simply dif ferences of degree or direction. Rather , the acous-tic indicators of topic shifts in English and Man-darin are, simply , not discriminati ve when applied to Arabic. This dif ference may be due to the style of Arabic newscasts or to the language itself. Across congurations, we nd that the inclusion of features deri ved from automatic speak er identication (fea-ture set S), errorful as it is, signicantly impro ves performance. This impro vement is particularly pro-nounced on the Mandarin material; in China Ne ws Radio broadcasts, story boundaries are very strongly correlated with speak er transitions.

It is dif cult to determine how well our system performs against state-of-the-art story segmentation. There are no comparable results for the TDT -4 cor -pus. On the English TDT -2 corpus, (Shriber g et al., 2000) report a C of .0670 is half that, we hesitate to conclude that our system is signicantly better than this system; since the (Shriber g et al., 2000) results are based on a word-le vel segmentation, the discrepanc y may be in-uenced by the disparate datasets as well as the per -formance of the two systems. On CNN and Reuters stories from the TDT -1 corpus, (Stok es, 2003) re-port a Pk score of 0.25 and a WD score of 0.253. Our Pk score is better than this on TDT -4, while our WD score is worse. (Chaisorn et al., 2003) re-port an F-measure of 0.532 using only audio-based features on the TRECVID 2003 corpus , which is higher than our system, howe ver, this allo ws for  X correct X  boundaries to fall within 5 seconds of ref-erence boundaries. (Franz et al., 2000) present a sys-tem which achie ves C darin BN and 0.081 on English audio in TDT -3. This suggests that their system may be better than ours on Mandarin, and worse on English, although we trained and tested on dif ferent corpora. Finally , we are una ware of any reported story segmentation re-sults on Arabic BN.
In this paper we have presented results of our story boundary detection procedures on English, Mandarin, and Arabic Broadcast Ne ws from the TDT -4 corpus. All features are obtained automati-cally , except for the identity of the news sho w and the source language, information which is, howe ver, available from the data itself, and could be automat-ically obtained. Our performance on TDT -4 BN ap-pears to be better than pre vious work on earlier cor -pora of BN for English, and slightly worse than pre-vious efforts on Mandarin, again for a dif ferent cor -pus. We belie ve our Arabic results to be the rst reported evaluation for BN in that language. One important observ ation from our study is that acous-tic/prosodic features that correlate with story bound-aries in English and in Mandarin, do not correlate with Arabic boundaries. Our further research will adress the study of vocal cues to segmentation in Arabic BN.

This research was partially supported by the De-fese Adv anced Research Projects Agenc y (D ARP A) under Contract No. HR0011-06-C-0023.

