 1. Introduction The satisfiability problem (SAT) which is known to be
NP-complete ( Cook, 1971 ) plays a central problem in many applications in the fields of VLSI computer-aided design, comput-ing theory, and artificial intelligence. Generally, a SAT problem is defined as follows. A propositional formula F  X  V m j  X  1 clauses and n Boolean variables is given. Each Boolean variable, x ; i A f 1 ; ... ; n g , takes one of the two values, True or False . Each clause C j , in turn, is a disjunction of Boolean variables and has the form
C  X  where I j ; I j D f 1 ; ... ; n g ; I \ I j  X  | , and x i .

The task is to determine whether there exists an assignment of values to the variables under which F evaluates to True . Such an assignment, if it exists, is called a satisfying assignment for F , and F is called satisfiable. Otherwise, F is said to be unsatisfiable.
Since we have two choices for each of the n Boolean variables, the size of the search space S becomes j S j X  2 n . That is, the size of the search space grows exponentially with the number of variables.
Since most known combinatorial optimization problems can be reduced to SAT ( Gary and Johnson, 1979 ), the design of special methods for SAT can lead to general approaches for solving combinatorial optimization problems. Most SAT solvers use a conjunctive normal form (CNF) representation of the formula F .
In CNF, the formula is represented as a conjunction of clauses, with each clause being a disjunction of literals, and a literal being a Boolean variable or its negation. For example, P 3 Q is a clause containing the two literals P and Q . The clause P 3 Q is satisfied if either P is True or Q is True . When each clause in F contains exactly k literals, the resulting SAT problem is called k -SAT. (GSATRW) strategy with learning capability, taking the form of learning automata. Learning automata have been used to model biological systems ( Tsetlin, 1973), and have attracted consider-able interest in the last decade because they can learn the optimal actions when operating in (or interacting with) unknown stochastic environments. Furthermore, they combine rapid and accurate convergence with low computational complexity. overview of potential application areas, with an emphasis on artificial intelligence. Then, in Section 3 we provide an overview of selected algorithms for the SAT problem. Furthermore, we take a closer look at the GSAT random walk algorithm, before we in
Section 4 explain how the latter algorithm can be enhanced with learning capability, using the basic concepts of learning automata.
In Section 5, we report the results obtained from testing the new approach on an extensive test suit of problem instances. Finally, in
Section 6 we present a summary and the conclusions of our work. 2. Artificial intelligence methods and applications several researchers have applied AI techniques in various fields and brought benefits to our societies, such as expert systems, neural networks, genetic algorithms, supervised learning meth-ods, multi-agent systems, and fuzzy set theory. In several areas of
AI, and computer science in general, advanced combinatorial optimization problems appear. Indeed, combinatorial optimiza-tion plays a central role in many applications in the fields of VLSI computer-aided design, computing theory, and artificial intelli-gence. Engineering applications include bounded model checking and logistics problems. In their full generality, these problems are NP-complete and consequently algorithmically intractable.
AI methods have also been applied in the research area of high energy physics, where the goal is to discover the fundamental properties of the physical universe ( Whiteson and Whiteson, 2009). Also, predicting hard drive failures to allow users to back up their data ( Murray et al., 2005 ) is of importance.
Furthermore, software engineering is a fruitful area for combinatorial optimization in particular and AI in general. Indeed many software development tasks could be formulated as optimization and learning problems, thus being approached in terms of AI techniques ( Zhang and Tsai, 2003 ).

AI methods have furthermore proven to provide better accuracy than statistical methods for the prediction of tumor behavior ( Qureshi et al., 2000 ). AI techniques have similarly shown their superiority compared to logistic regression when predicting the childhood obesity ( Zhang et al., 2009 ) by over 10%.
In the field of logistics, the SAT problem has turned out to be particularly applicable for logistics planning. Logistics planning is essential to reduce the delivery costs, increase the reliability of delivery, and improve the service quality in logistics systems.
Several research studies reveal the excellent capacity of AI techniques at estimating and predicting travel-time. Indeed, the average travel time prediction error obtained by using state-of-the-art AI techniques is approximately 4% of practical travel time (Lin et al., 2005 ).

Prediction of energy production and consumption is a particularly difficult problem, since prediction errors impact high-stake decision making. As a pioneering approach, artificial neural networks were applied for the first time to build a predictive model used to forecast United States natural gas production ( Mohaghegh, 2000 ). In recent years, artificial intelli-gence, in its many forms, has been making significant steps toward becoming more and more accepted in the field of oil and gas industry such as reservoir characterization ( Finol et al., 2002 ), production engineering issues ( Alimonti and Falcone, 2002 ), and drilling ( Balch et al., 2002 ). 3. Stochastic local search techniques
The SAT problem has been extensively studied due to its simplicity and applicability. The simplicity of the problem coupled with its intractability makes it an ideal platform for exploring new algorithmic techniques. This has led to the development of several local search algorithms for solving SAT problems.

Local search algorithms typically start with an initial assign-ment of truth values to variables, randomly or heuristically generated. Satisfiability can then be formulated as an iterative optimization problem in which the goal is to minimize the number of unsatisfied clauses. Thus, the optimum is obtained when the value of the objective function equals zero, which means that all clauses are satisfied. During each iteration, a new value assignment is selected from the  X  X eighborhood X  of the present one, by performing a  X  X ove X . Most local search algorithms use a 1-flip neighborhood relation, which means that two truth value assignments are considered to be neighbors if they differ in the truth value of only one variable. Performing a move, then, consists of switching the present value assignment with one of the neighboring value assignments. The search terminates if no better neighboring assignment can be found. Note that choosing a fruitful neighborhood, and a method for searching it, is usually guided by intuition  X  theoretical results that can be used as guidance are sparse.
 One of the earliest local search algorithms for solving SAT is GSAT ( Selman et al., 1992 ). Basically, GSAT begins with a random generated assignment of values to variables, and then uses the steepest descent heuristic to find the new variable-value assign-ment which decreases the numbers of unsatisfied clauses the most. After a fixed number of moves, the search is restarted from a new random assignment. The search continues until a solution is found or a fixed number of restarts have been performed. An extension of GSAT, referred to as random-walk ( Selman and Kautz, 1993) has been realized with the purpose of escaping from local optima. In a random walk step, a randomly unsatisfied clause is selected. Then, one of the variables appearing in that clause is flipped, thus effectively forcing the selected clause to become satisfied. The main idea is to decide at each search step whether to perform a standard GSAT or a random-walk strategy with a probability called the walk probability.

Another widely used variant of GSAT is the WalkSAT algorithm, originally introduced in Selman et al. (1994). It first picks randomly an unsatisfied clause c , and then, in a second step, one of the variables with the lowest break count , appearing in the selected clause, is randomly selected. The break count of a variable is defined as the number of clauses that would be unsatisfied by flipping the chosen variable. If there exists a variable with break count equals to zero, this variable is flipped, otherwise the variable with minimal break count is selected with a certain probability (noise probability). It turns out that the choice of unsatisfied clauses, combined with the randomness in the selection of variables, enable WalkSAT to avoid local minima and to better explore the search space.

Extensive tests have led to the introduction of new variants of the WalkSAT algorithm referred to as Novelty and R-Novelty (McAllester et al., 1997 ). These two variants use a combination of two criteria when choosing a variable to flip from within an unsatisfied clause. Quite often, these two algorithms can, however, get stuck in local minima and fail to get out. To this end, recent variants have been designed ( Li and Huang, 2005; Li et al., 2007; Hoos, 2002 ) using a combination of search intensification and diversification mechanisms, leading to good performance on a wide range of SAT instances.
 Other algorithms ( Glover, 1989; Hansen and Jaumand, 1990; Gent and Walsh, 1995, 1993 ) use history-based variable selection strategies in order to avoid flipping the same variable. In parallel to the development of more sophisticated versions of randomized improvement techniques, other methods, based on the idea of modifying the evaluation function ( Wu and Wah, 2000; Hutter et al., 2002; Thornton et al., 2004; Schuurmans and Southey, 2000; Schuurmans et al., 2001 ) in order to prevent the search from getting stuck in non-attractive areas of the underlying search space, have become increasingly popular in SAT solving. The key idea is to associate the clauses of the given CNF formula with weights. Although these clause weighting SLS algorithms differ in the way clause weights should be updated (probabilistic or deterministic), they all choose to increase the weights of all the unsatisfied clauses as soon as a local minimum is encountered. A new approach to clause weighting known as divide and distribute fixed weights (DDFW) ( Ishtaiwi et al., 2005 ) exploits the transfer of weights from neighboring satisfied clauses to unsatisfied clauses in order to break out from local minima. Recently, a strategy based on assigning weights to variables (Prestwich, 2005 ) instead of clauses greatly enhances the perfor-mance of the WalkSAT algorithm, leading to the best known results on some benchmarks.

Lacking the theoretical guidelines while being stochastic in nature, the deployment of several meta-heuristics involves exten-sive experiments to find the optimal noise or walk probability settings. To avoid manual parameter tuning, new methods have been designed to automatically adapt parameter settings during the search ( Li et al., 2007; Patterson and Kautz, 2001 ), and results have shown their effectiveness for a wide range of problems. The work conducted in Granmo and Bouhmala (2007) introduced learning automata (LA) as a mechanism for enhancing random walk algorithm, thus laying the foundation for novel LA-based
SAT solvers. Finally, a new approach based on an automatic procedure for integrating selected components from various existing solvers in order to build a new efficient algorithm that draw the strengths of multiple algorithms ( Xu et al., 2008;
KhudaBukhsh et al., 2009 ). 4. Solving SAT using finite learning automata
We base our work on the principles of learning automata (Narendra and Thathachar, 1989; Thathachar and Sastry, 2004 ).
Learning automata have been used to model biological systems (Tsetlin, 1973), and have recently attracted considerable interest because they can learn the optimal actions when operating in (or interacting with) unknown stochastic environments. Further-more, they combine rapid and accurate convergence with low computational complexity. Learning automata solutions have been proposed for several other combinatorial optimization problems ( Oommen and Ma, 1988; Gale et al., 1990; Granmo et al., 2007; Misra and Oommen, 2005; Oommen and Roberts, 2002; Oommen and St. Croix, 1996; Oommen and Hansen, 1987 ).
The work reported in Granmo and Bouhmala (2007) was the first to combine the traditional random walk with learning automata for the satisfiability problem. Inspired by the success of the above solution scheme, we will in the following propose how the classical GSAT-random-walk algorithm can be enhanced with learning capability, using learning automata. 4.1. The GSAT-random-walk algorithm (GSATRW)
This section is devoted to explaining the details of the GSATRW algorithm as it is embedded into our finite learning automata based strategy. The main motivation behind choosing the
GSATRW algorithm is the fact that all state-of-the-art SAT solving algorithms are derivatives of GSATRW. Indeed, they all have the general GSATRW backbone architecture with some additional features, such as restart-, clause weight-, and Tabu list mechan-isms. Therefore a comparison with GSATRW would be very informative.

As argued above, the introduction of an element of random-ness (i.e., noise) into local search methods is common practice for improving effectiveness through diversification ( Blum and Roli, 2003). In this spirit, the GSATRW algorithm, shown in Fig. 1 , starts with a randomly chosen assignment.

Thereafter, two possible strategies are used for selecting the variable to be flipped at each iteration of the algorithm. The first strategy is taking a walk-step , which amounts to randomly selecting a currently unsatisfied clause and then flipping one of its variables, also in a random manner. Thus, at each walk-step, at least one unsatisfied clause becomes satisfied.

The other strategy uses a greedy search to choose a random variable from the set PossFlips , which contains the variables that when flipped (individually) achieve the largest decrease (or the least increase) in the total number of unsatisfied clause. total number of unsatisfied clauses even when purely improving flips would have been possible. 4.2. A learning SAT automaton sequence of actions on an environment . The environment can be seen as a generic unknown medium that responds to each action with some sort of reward or penalty, perhaps stochastically .
Based on the responses from the environment, the aim of the finite learning automaton is to find the action that minimizes the expected number of penalties received. Fig. 2 illustrates the interaction between the finite learning automaton and the environment. Because we treat the environment as unknown, we will here only consider the definition of the finite learning automaton (LA). The finite learning automaton can be defined in terms of a quintuple ( Narendra and Thathachar, 1989 ): f F ; a ; b ; F  X  ;  X  ; G  X  ;  X g :
F  X f f 1 ; f 2 ; ... ; f s g is the set of internal automaton states. a  X f a 1 ; a 2 ; ... ; a r g is the set of automaton actions. And, b  X f b 1 ; b 2 ; ... ; b m g is the set of inputs that can be given to the automaton. An output function a t  X  G  X  f t determines the next action performed by the automaton given the current automaton state. Finally, a transition function f t  X  1  X  F  X  f t ; b new automaton state from (1) the current automaton state and (2) the response of the environment to the action performed by the automaton. Based on the above generic framework, the crucial issue is to design automata that can learn the optimal action when interacting with the environment. Several designs have been proposed in the literature, and the reader is referred to
Narendra and Thathachar (1989) and Thathachar and Sastry (2004) for an extensive treatment. In this paper we target the SAT problem, and our goal is to design a team of learning automata that seeks the solution of SAT problem instances. We build upon the work of Tsetlin and the linear two-action automaton ( Tsetlin, 1973; Narendra and Thathachar, 1989 ). For each literal in the SAT problem instance that is to be solved, we construct an automaton with States: F  X f N 1 ; N ; ... ; 1 ; 0 ; ... ; N 2 ; N g . Actions: a  X f True ; False g .
 Inputs: b  X f reward ; penalty g .

Fig. 3 specifies the G and F matrices. The G matrix can be summarized as follows. If the automaton state is positive, then action True will be chosen by the automaton. If on the other hand the state is negative, then action False will be chosen. Note that since we initially do not know which action is optimal, we set the initial state of the learning SAT automaton randomly to either  X  1 X  or  X 0 X .

The state transition matrix F determines how learning proceeds. As seen in the figure, providing a reward input to the automaton strengthens the currently chosen action, essentially by making it less likely that the other action will be chosen in the future. Correspondingly, a penalty input weakens the currently selected action by making it more likely that the other action will be chosen later on. In other words, the automaton attempts to incorporate past responses when deciding on a sequence of actions. 4.3. Combining learning automata with GSATRW(LA-GSATRW)
Overview : In addition to the definition of the LA, we must define the environment that the LA interacts with. Simply put, the environment is a SAT problem instance as defined in Section 1. Each variable of the SAT problem instance is assigned a dedicated
LA, resulting in a team of LA. The task of each LA is to determine the truth value of its corresponding variable, with the aim of satisfying all of the clauses where that variable appears. In other words, if each automaton reaches its own goal, then the overall SAT problem at hand has also been solved.

Pseudo-code : With the above perspective in mind, we will now present the details of the LA-GSATRW that we propose. Fig. 4 contains the complete pseudo-code for solving SAT problem instances, using a team of LA. As seen from the figure, an ordinary
GSATRW strategy is used to penalize an LA when it  X  X isagrees X  with GSATRW, i.e., when GSATRW and the LA suggest opposite truth values. Additionally, we use an  X  X nverse X  GSATRW strategy for rewarding an LA when it agrees with GSATRW. Note that as a result, the assignment of truth values to variables is indirect, governed by the states of the LA. At the core of the LA-GSATRW algorithm is a punishment/rewarding scheme that guides the team of LA towards the optimal assignment. In the spirit of automata based learning, this scheme is incremental, and learning is performed gradually, in small steps.
 Remark 1. Like a two-action Tsetlin automaton, our proposed LA seeks to minimize the expected number of penalties it receives. In other words, it seeks finding the truth assignment that minimizes the number of unsatisfied clauses among the clauses where its variable appears.
 Remark 2. Note that because multiple variables, and thereby multiple LA, may be involved in each clause, we are dealing with a game of LA ( Narendra and Thathachar, 1989 ). That is, multiple LA interact with the same environment, and the response of the environment depends on the actions of several LA. In fact, because there may be conflicting goals among the LA involved in the LA-GSATRW, the resulting game is competitive. The convergence properties of general competitive games of LA have not yet been successfully analyzed, however, results exists for certain classes of games, such as the Prisoner X  X  Dilemma game ( Narendra and Thathachar, 1989 ). In our case, the LA involved in the LA-GSATRW are non-absorbing, i.e., every state can be reached from every other state with positive probability. This means that the probability of reaching the solution of the SAT problem instance at hand is equal to 1 when running the game infinitely. However, the LA-GSATRW may linger in local optimums for an extended amount of time, and may move away from a global optimum (the solution) after it has been found. However, since LA-GSATRW always keeps the best truth value assignment found so-far, moving away from the global optimum is not a problem (the algorithm stops when the global optimum has been found). Also note that the solution of the SAT problem corresponds to a Nash equilibrium of the game.
 Remark 3. In order to maximize speed of learning, we initialize each LA randomly to either the state  X  1 X  or  X 0 X . In this initial configuration, the variables will be flipped relatively quickly because only a single state transition is necessary for a flip. Accordingly, the joint state space of the LA is quickly explored in this configuration. However, as learning proceeds and the LA move towards their boundary states, i.e., states  X  N  X  and  X  N 1 X , the flipping of variables calms down. Accordingly, the search for a solution to the SAT problem instance at hand becomes increas-ingly focused.
 Remark 4. In many cases, stochastic optimization usually involves significant computation load and slow calculation speed. In this perspective, LA distinguishes themselves by combining rapid and accurate convergence with low computational com-plexity. For the LA-GSATRW case, this is achieved by relying directly on finite state machines, with each learning step being nothing more than a transition from one state to another in the machine. Indeed, in addition to rapid convergence and high learning accuracy, the computational simplicity of LA is perhaps one of their main advantages when contrasted to other learning True False schemes. However, for many learning problems, such as neural network based pattern recognition, it is not obvious how to apply
LA. Note that recent results in pattern recognition ( Thathachar and Sastry, 2004 ) show that LA also can improve the performance of traditional pattern recognition systems.

Remark 5. Generalization capability is an important character-istic in many learning problems such as training of pattern classifiers. For SAT problems, on the other hand, we are not looking for significant patterns, but we are rather interested in single solution instances  X  that is, a single assignment of truth values that satisfies the Boolean expression in question. However, when LA have been applied in pattern recognition problems, they have obtained excellent generalization capability, under particu-larly noise conditions ( Thathachar and Sastry, 2004 ). 5. Experimental results 5.1. Benchmark Instances selected a benchmark suite from different domains including
Benchmark instances of SAT competition Beijing held in 1996. All these benchmark instances are available from the SATLIB website (www.satlib.org ). All the benchmark instances used in this experiment are satisfiable instances and have been used widely in the literature in order to give an overall picture of the perfor-mance of different algorithms. Due to the randomization of the algorithm, the number of flips required for solving a problem instance varies widely between different runs. Therefore, for each problem instance, we run LA-GSATRW and GSATRW 100 times with a cutoff parameter (maxflips) setting which is high enough (10 ) to guarantee a success rate close to 100%.

In order to test the robustness of our scheme, we use the following wide range of benchmark instances, for comparison purposes. Some are obtained from real-life industrial engineering problems, while others are artificially generated.

Uniform random -3-SAT : A random 3-sat problem is obtained by randomly generating 3-CNF formulas.

SAT-encoded bounded model checking ( BMC ): BMC is used in industry for chip design, including automatic formal verification of finite state transition systems.

SAT-encoded logistics problems : The logistics planning problems we use in our comparison of approaches involve planning of when and where to move packages using trucks and air planes. The goal is to decide whether a plan of a given length exists. SAT-encoded Block World Planning problems : The Block World
Planning problem is a problem well-known in the AI field. It involves blocks and a table, with a plan being sought for how to move blocks into a pile, while obeying certain constraints. In our case, the goal is to decide whether a plan of a given length exists.
SAT-encoded quasi-group problems : The quasi-group problem involves composing of quasi-group multiplication tables in order to solve linear equations. 5.2. Configuring LA-GSATRW
The results of our experiments are truly conclusive and confirm the power of the LA-GSATRW scheme. Although numer-ous experiments were conducted for various settings and number of automata, we report, for the sake of brevity, the results with 4-state LA, i.e., for N = 2. It turns out that performance improves when increasing the number of automaton states, i.e., by giving the LA more memory. However, from N = 3, the LA is unable to efficiently converge within the number of flips we allowed in the experiments, resulting in a steadily decreasing performance as we increase N beyond 2. This is the case for most of our benchmark instances. In other words, our experiments indicate that in practice, one can ignore N by fixing it to 2. Thus, for this memory size, we performed an ensemble of several independent replications with different random number streams minimize the variance of the reported results. 5.3. Search space
The manner in which LA converges on assignment is crucial to a better understanding of LA-GSATRW behavior. In Fig. 5 ,we show how the best and current assignment progresses during the search on a problem from SAT-encoded logistics problem.
The plot located on the left of the figure suggests that problem solving with LA-GSATRW happens in two phases. The first phase which corresponds to the early part of the search (the first 5% of the search) LA-GSATRW behaves as a hill-climbing method. This phase which can be described as a short one, up to 95% of the clauses are satisfied. The best assignment climbs rapidly at first, and then flattens off as we mount the plateau, marking the start of the second phase. The plateau spans a region in the search space where flips typically leave the best assignment unchanged. The long plateau becomes even more pronounced as the number of flips increases, and occurs more specifically in trying to satisfy the last few remaining clauses. To further investigate the behavior of LA-GSATRW once ontheplateau,welookedatthecorrespondingaveragestateof automaton as the search progresses. The plot located on the right of Fig. 5 shows the reported observations. The start of plateau search coincides in general with an increa se in the average state. The longer plateau, the higher average state. An automaton with high average state needs to perform a series of actions before its current state changes to either 1 or 0, thereby making the flipping of the corresponding variable possible. The transition between each plateau correspondstoachangetotheregionwhereasmallnumberofflips gradually improves the score of the current solution ending with an improvement of the best assignment. 5.4. Run-length-distributions (RLDs)
As an indicator of the behavior of the two algorithms when trying to solve a given problem instance in 100 trials, and to get an idea of the variability of the search cost, we analyzed the cumulative distri-bution of the number of search flips needed by both LA-GSATRW and GSATRW. Due to non-deterministic decisions involved in the algorithm (i.e., initial assignment, random moves), the number of flips needed by both algorithms to find a solution is a random variable that varies from run to run. More formally, let k denotes the total number of runs, and let f 0  X  j  X  denotes the number of flips for the of all successful runs, sorted according to increasing number of flips, then the cumulative empirical RLD is defined by ^ P  X  f 0  X  j  X  r f  X   X jf j j f 0  X  j  X  r f g = k .Eachproblemwassolved100timesusingan extremely high cutoff parameter setting of Maxsteps =10 7 obtain a maximal number of successful tries.
 Figs. 6 and 7 show RLDs obtained by applying LA-GSATRW and
GSATRW to individual large random problems. As can be seen from the three plots, we observe that both algorithms reach a success rate of 100% for f600 and f1000. However, on the large problem f2000, GSATRW shows a low asymptotic solution probability corresponding to 0.37 compared to 0.45 for
LA-GSATRW. Note also that there is a substantial part of trials that are dramatically hard to solve which explains the large variability in the length of the different runs of the two algorithms. Both algorithms show the existence of an initial phase below which the probability for finding a solution is 0. Both methods start the search from a randomly chosen assignment which typically violates many clauses. Consequently, both methods need some time to reach the first local optimum which possibly could be a feasible solution. The two algorithms show no cross-over in their corresponding RLDs even though it is somewhat hard to see for f600 but it becomes more pronounced for f1000 and f2000. The median search cost for LA-GSATRW is 3%, 29%, and 17% of that of GSATRW for f600, f1000 and f2000, respectively. As can be seen from these plots, LA-GSATRW gives consistently higher success probabilities while requiring fewer
Fraction Solved
Fraction Solved #Flips search steps compared to GSATRW. Looking at Figs. 8 and 9 and applying the RLD analysis to SAT-encoded logistics problems, there is no clear success rate winner between the two algorithms.
The number of search steps varies between the different trials and is significantly higher with GSATRW than that of LA-GSATRW. The median search cost for LA-GSATRW is 4%, 29%, 34% and 51% of that of GSATRW for Logistics-d, Logistics-b, Logistics-c, and
Logistics-a, respectively. We now turn to single SAT-encoded instances from the Block World Planning domain. The crossing of the two RLDs at different points as shown in Figs. 10 and 11 indicates that there is no complete dominance of one algorithm over the other when applied to the same problem. Looking at
Fig. 10 and taking the smallest problem (medium) as an example, we notice that for smaller cutoff times, GSATRW achieves higher solution probabilities, while for larger cutoff times, LA-GSATRW shows increasingly superior performance. It may be noted that
GSATRW performs better than LAGSATRW for the smallest problem (up to 49% more steps than LA-GSATRW). However, this gap is fairly small and is within 5% for medium size problems (bw-large.a, bw-huge). On the other hand, for the large problem bw-large.b, the situation is reversed. GSATRW requires 16% more steps than LA-GSATRW. Finally, the plots in Figs. 12 and 13 explore the behavior of the RLDs of both algorithms when applied to BMC problems. Both algorithms reach a success rate of 100% with the one exception that, for the medium size problem (bmc-ibm3), the success rate was around 95%. Returning to Fig. 12 then, for the smaller problem (bmc-ibm-2) GSATRW dominates LA-GSATRW on the major part of the runs (i.e., approx 80%), as it reaches high solution probabilities while requiring lower search cost. On the other hand, for the medium size problem (bmc-ibm-3) the situation is similar but reversed. Fig. 13 shows the RLD for both algorithms for the large problem (bmc-ibm-6). As can be seen from the figure, the RLDs for both algorithms have roughly the same shape. The presence of heavy tails in both RLDs indicates that both algorithms get stuck in local minima for a relatively small number of trials. The median search cost for GSATRW is 15% of that of LA-GSATRW for the bmc-ibm-2. However, LA-GSATRW shows a better performance for the medium (improvement of approx. 8% in the median) and larger problem (improvement of approx. 5%). 5.5. Excess deviation from the solution
Quite often, we observed stagnation behavior with extremely low asymptotic solution probabilities when applied to SAT-encoded quasi-group problems. The two algorithms were exe-cuted to the allowed maximal number of steps and the percentage excess over the solution was recorded. Figs. 14 and 15 show the excess deviation over the solution sorted in increasing order. As it can be seen from the plots, both algorithms suffer from severe stagnation indicating incomplete behavior of the two algorithms when applied to this class of problems. At the exception of the problem qg3-08 where LA-GSATRW achieved a maximal success rate of 0.04% compared to 0.03% for GSATRW, we observe a rapid deterioration of their performance (success rate equals to 0%) with growing problem size. LA-GSATRW appears to have an asymptotic convergence which is better than GSATRW to around 3 X 10% in average excess of the solution. 5.6. Wilcoxon rank-sum test
The number of search flips needed by a meta-heuristic to find a feasible solution may vary significantly from run to run on the same problem instance due to random initial solutions and subsequent randomized decisions. As RLDs are unlikely to be normally distributed, we turn towards the non-parametric Wilcoxon rank test in order to test the level of statistical confidence in differences between the median search cost of the two algorithms. The test requires that the absolute values of the differences between the mean search costs of the two algorithms are sorted from smallest to largest and these differences are ranked according to absolute magnitude. The sum of the ranks is then formed for the negative and positive differences separately. As the size of the trials increase, the rank sum statistic becomes normal. If the null hypothesis is true, the sum of ranks of the positive differences should be about the same as the sum of the ranks of the negative differences. Using two-tailed P value, significance performance difference is granted if the Wilcoxon test is significant for P o 0 : 05. An initial inspection of Table 1 #Flips reveals two results. Firstly, the success rate of LA-GSATRW was better in 12 problems and the difference in the median search cost was significant in 6 problems. On the other hand, GSASTRW gave better results in 5 problems in terms of success rate but its performance was significant in only 2 cases. 6. Conclusions
In this work, we have introduced a new approach based on combining learning finite automaton with GSATRW. Thus, in order to get a comprehensive picture of the new algorithm X  X  performance, we used a set of benchmark problems containing different problems from various domains. Some of the selected problems were widely used by different authors in the context of evaluating the performance of meta-heuristics. GSATRW suffers from stagnation behavior which directly affects its performance.
This same phenomenon is, however, observed with LA-GSATRW only for large instances. Based on the analysis of RLDs, we observe that the probability of finding a solution within any arbitrary number of search steps is higher with GSATRW compared to that of LA-GSATRW. Results indicate that the harder the problem, the better asymptotic convergence reached by LA-GSATRW as opposed with GSATRW. The finite automaton learning mechanism employed in LA-GSATRW offers an efficient way to escape from highly attractive areas in the search space leading to a higher probability success as well as reducing the number of local search steps to find a solution. The broad conclusion that may be drawn from the experiments is that the finite automaton learning framework does appear in general to speed up GSATRW or improve the asymptotic convergence of GSATRW. Finally, other subjects for further work include combining LA with state-of-the-art heuristics while extending the range of problem classes. References
