 Suppose that Twitter user  X  X ohn X  posts a tweet, and in 10 minutes it is retweeted by 3,000 people. Is this suspicious? Not necessarily. Suppose that this happens for the next 5 tweets of John: roughly the same 3,000 people all retweet his post in a few minutes.
 users is not natural. This is exactly the main intuition behind our work: events (like retweet threads) that belong to the same group are suspicious if they are highly synchronized; that is, if all of the retweet threads for John X  X  tweets are synchronized. The challenge therefore is, given many events belonging to many groups (retweet threads for user  X  X ane X , etc.), find the suspicious groups. We assume that organic behavior is the norm, and deviations from it constitute suspicious (anomalous, fraudulent) behavior.
 individual level (e.g. a single retweet thread in our example) [ 3 , 12 , 20 ] as well as group [ 25 ]or collective anomalies [ 6 ]. While most anomaly detection focused on a cloud of p -dimensional points (entities), extensions to more complex data have been proposed [ 6 ], such as for rare subsequences, subgraphs, and image subregions. Here, we propose a novel, general approach to collective anomaly detection, informally defined as follows: Informal Problem 1 (Synchronicity Fraud Detection)
Given : N groups of entities; a representation for each entity in a p -dimensional space;
Identify groups of entities abnormally synchronized in some feature subspaces. At a high level, our proposed ND-Sync methodology is as follows: 1. Extract p features from each entity (i.e. retweet thread), such as the average inter-arrival time of retweets, variance of it, and number of retweets. 2. Analyze the collective behavior of each group (the set of retweet threads for posts from a given user), and compare it to the behavior of the rest of the threads. Using the concepts of  X  X ntra-synchronicity X  and  X  X nter-synchronicity X  (see Section 4.2 ), assign a suspiciousness-score to each user in all 2 subspaces.
 3. Combine the scores for each user and report the most suspicious such groups. unts whose posts trigger fake retweet threads. In Figure 1a each point is a user plotted in terms of two dimensions that reflect deviation from normal users X  behavior. The vertical dashed line clearly separates fraudulent from normal users. The most  X  X nomalous X  users (at the rightmost part of the figure) correspond to bot accounts acting as professional promoters of content or other users. Figures 1b and 1c depict the retweet threads of normal users (grey points) along with the retweet threads of the  X  X ignificantly outlying X  caught users RTFraudster1 and RTFraudster2 projected in 2-D subspaces with respect to two pairs of our proposed features. Compared to honest retweet threads, we can clearly observe fraudulent users X  retweet threads are abnormaly clustered together.  X  Methodology : ND-Sync is a general, effective pipeline that automatically  X  Feature engineering : we customize ND-Sync for the case of retweet fraud, Reproducibility: We share our (anonymized) data at: http://oswinds.csd.auth. gr/project/NDSYNC . We first discuss approaches addressing fraud detection in Twitter, and then review efforts on collective anomaly detection. Table 1 compares the methods that are most relevant to our problem setting.
 require textual content, graph structure, or user attributes (such as account creation date) to detect fraudsters.
 Fraud on Twitter: Retweet Fraud Detection identifies Twitter users that obtain fake retweets for their posted content (RT fraudsters). Fraud is a serious problem and varying degrees of automation. [ 9 ] lists several such attempts of fraudsters to mimick organic behavior, for example by re-broadcasting others X  posts. Earlier work focuses on account tweeting activity and/or social connectivity. [ 27 ] ana-lyzes the relationships of fraudsters inside and outside of criminal communities to infer types of accounts serving as criminal supporters. [ 7 , 8 ] leverage tweet-ing behavior, tweet content and account properties to compute the likelihood of an unknown user being a human, bot or cyborg. In general, such feature-based methods (e.g. username pattern, age) have been shown to fail to catch more sophisticated fraud schemes that exploit real users X  accounts, such as the pyramid follower markets [ 22 ]and account compromization [ 1 ]. [ 23 ] shows the effectiveness of temporal features for distinguishing between account types. [ 11 ] addresses a problem similar to ours but uses the URLs found in tweets instead of retweet threads in conjunction with a time and user-based entropy to classify posting activity and content.
 Collective anomaly detection: The goal of collective anomaly detection is to find groups of entities that jointly exhibit abnormal behavior. Variants exist for sequential [ 5 ], spatial [ 13 ] and graph [ 19 ] data, while other approaches are more general, simply assuming p -dimensional points [ 25 , 26 , 28 ]. Synchronized ( X  X ock-step X ) behavior is often an indication of fraud, like e.g. users Liking the same Facebook Pages at the same time [ 2 ] or following the same accounts [ 16 , 17 , 21 ]. This section provides the necessary background for ND-Sync sure the suspiciousness of a group of 2-D points, given a large set of 2-D points (Section 3.1 ) and a robust multivariate outlier detection method (Section 3.2 ). 3.1 Measuring Group Strangeness Given a large cloud of 2-D points E , and a set of points with respect to E ?[ 16 ] gave such a score, namely, the residual score ( rs score , see Eq. 4 below). The definition needs some auxiliary concepts: synchronicity (how coherent/lockstep is the subset E )and normality (how similar it is to the presumed-normal cloud E ). In the next 3 paragraphs, we give their mathematical definitions, as well as the equation for a crucial lower-bound.
 Synchronicity: For a group E , it is the average closeness between all pairs of its members The closeness c ( e, e ) of two entities e and e , is a similarity function -in [ 16 ], it was binary: after dividing the address space into grid-cells, the closeness is 1, if the elements are in the same grid-cell, and zero otherwise.
 E , is the average closeness of the members of E to the members of (superset) group E , the synchronicity sync ( E ) is lower-bounded by sync where M is the count of non-empty grid-cells for E ,and s of E .
 Residual score: For group E with synchronicity sync ( E norm ( E )wrt E ,the residual score is given by: 3.2 Robust Outlier Detection ROBPCA-AO [ 15 ] is a robust Principal Component Analysis (PCA) and outlier detection method that is suitable for multivariate, high-dimensional data and independent of their features X  distribution. Proposed as a robust alternative to classic PCA, ROBPCA-AO identifies Principal Components (PCs) that best describe the uncontaminated data, while at the process, it detects outliers. them into the (restricted) space they span. Then, the dimensionality of data is reduced by keeping only the first k PCs of the data X  X  covariance matrix. Taking into account the possibility of skewed data, ROBPCA-AO robust k -subspace V r that fits the majority of observations and projects them on it. Outliers are detected on subspace V r based on two distance-based scores: (a) the orthogonal distance ( od ) of each observation from its projection on V and (b) robust score distance ( sd ), which is taken as the adjusted outlyingness of the observation. Adjusted outlyingness is a measure suitable for multivari-ate, asymmetric data that estimates the distance of a given observation from the bulk of observations as its maximum robust distance (outlyingness) over B directions. Each such direction is perpendicular to the subspace spanned by k randomly sampled observations. Observations whose od or sd score surpasses a data-dependent cutoff threshold (defined as the upper whisker of the adjusted boxplot [ 15 ]) are characterized as outliers. 4 Proposed Method: ND-S YNC This section first outlines Retweet Fraud Detection as a special case of the Syn-chronicity Fraud problem, and then presents ND-Sync , an effective and robust solution. 4.1 Problem Defintition Retweet fraud detection ( RTFraud ) is a problem of various dimensions since: (a) it can be practiced by different types of user accounts (automated or bot orchestrated, semi-automated, human managed), (b) the inflation of content X  X  popularity can be the sole purpose of the suspected user account or an occasional tactic hidden ( camouflaged ) in organic activities, (c) the promoted content can attract both fake and honest retweets. Thus, it is important to find features able to separate such diverse fraudulent activities from honest user behavior, and to design a method that can effectively leverage their variety. To study the retweeting activity in terms of time and retweeting users, given a user u ( author ) we represent the i th tweet posted by u m with tw where t m,i is the tweet X  X  creation time. A retweet thread is defined as follows: Definition 1 (Retweet thread). Given an author u m and a tweet tw retweet thread R m,i is defined as the set of all tweets that retweeted tw Here, we formulate RTFraud as an instance of the Synchronicity fraud ( SyncFraud ) problem, which is defined at two levels (group and entity) below: Problem 1 ( SyncFraud ).

Given : N groups of entities G , where each group g m  X  G comprises a vari-able number of entities e m,i  X  E m ,andasetof p features for the entities X  representation, Extract : a set of features at the group-level, and Identify : suspicious groups S that exhibit highly synchronized characteristics. Even though essentially, the RTFraud problem involves three levels instead of two  X  lower (individual retweets), middle (retweet threads) and upper (users)  X  we simplify it by collapsing a post X  X  retweets into a single retweet thread and by defining features for its characterization. Then, RTFraud mapped to the SyncFraud problem where each user u m has a group g taining all retweet threads R m,i for that user, and the suspicious groups S are the detected fraudsters (RT fraudsters). 4.2 Proposed Approach In this section we provide the pipeline of ND-Sync SyncFraud problem, and describe its steps. Then, we propose a 7-dimensional feature space for representing the retweet threads in the ND-S YNC Pipeline. ND-Sync comprises three main steps: (1) Feature sub-space sweeping , which generates and bins all entity-wise feature subspaces and projects entities in them; (2) User scoring , which calculates the group-based suspiciousness score vectors; (3) Multivariate outlier detection , which identifies suspicious groups based on their deviation from normal behavior.
 pipeline is outlined in Algorithm 1 .
 Feature subspace sweeping. How can we detect microclusters in a p -dimensional space? Given N groups of entities represented in a p  X  feature space, first: (a) projects all entities into the desired feature subspaces, and then (b) reduces the statistical noise in each subspace to prepare the data for synchronic-ity detection. Given a p -feature space, we take all possible q -feature combinations for q  X  [1 ,p ]; this produces 2 p possible subspaces to analyze. In anomaly detec-tion, it is difficult to estimate apriori the most effective feature combinations for discriminating suspicious groups from normal ones. Thus, a straightforward approach is to generate and apply ND-Sync  X  X  next steps on all 2 spaces. In cases when p is too high, though, practitioners can select a subset of subspaces for extra efficiency. As we show in Section 5.2 , considering only the 3-D and 2-D subspaces is relatively effective for RTFraud subsection 3.1 ); we choose logarithmic binning, in powers of 2, for each dimen-sion/feature.
 User scoring. At this point, we need to combine the entity-level features in a way that reflects the synchronicity of the group. These group features should allow us to identify the suspicious set S from the normal groups. Here, on each entity-feature subspace f i , where i  X  [1 , 2 p ], we calculate the intra-synchronicity intra sync ( g m ,f i )and inter-synchronicity inter sync ( g group of entities g m , based on Eq. 1 and Eq. 2 , respectively.
 synchronicity compared to normal groups. However, depending on the feature subspace, the deviation between the intra-synchronicity of suspicious and normal groups may vary (due to differences in the features X  discriminative power and dis-tribution). Thus, given F =2 p feature subspaces, we generate an F -dimensional feature vector for each group g m , i.e. the suspiciousness score vector, SV , where each dimension represents the group X  X  suspiciousness , susp , in the corresponding subspace (given in Definition 2 ). The susp scores correspond to our user-level features.
 Definition 2 (Suspiciousness). For subspace f l and group g synchronicity intra sync ( g m ,f l ) and inter-synchronicity inter sync ( g group X  X  suspiciousness is given by susp ( g m , f l )= rs score ( projection ( g Definition 3 (Suspiciousness score vector). For group g m the suspiciousness vector is given by SV ( g m )=[ susp ( g Unlike previous approaches, here we do not assume that suspicious groups are characterized by low inter-synchronicity. We claim that inter-synchronicity is more difficult to interpret as an indication of normality vs. suspiciousness, since its value depends on the selected features and their distribution over all entities in normal and suspicious groups. For example, our experiments on RTFraud indicated that normal users are approximately at the same scale of inter-synchronicity, whereas suspicious users can have either very low values (retweet threads have rare feature values) or very high (retweet threads of sev-eral suspicious users have the same feature values, e.g. zero inter-arrival time of retweets; for normal users the corresponding values are more diverse). Multivariate outlier detection. The last step of ND-Sync takes as input the set of groups G with their F -dimensional suspiciousness score vectors, and proceeds to the identification of the suspicious groups S . First, we standardize the vectors using their median and mean average deviation (MAD), which are considered as robust estimators of center and scale. ND-Sync then spots as suspicious the groups that largely deviate from the majority of groups in G , considering their standardized scores in all feature subspaces, based on the outlier detection approach described in Section 3.2 .
 To address the non-deterministic nature of this outlier detection method, mainly in terms of entities positioned close to the distance cutoffs, applies it iteratively, maintains a list of the identified outliers in each iteration, and classifies a group as suspicious based on the majority vote over all runs. Our experiments on RTFraud revealed that even a small number of iterations (e.g. 10) is enough to estimate the suspicious groups. Moreover, to eliminate the need for selecting parameters in ND-Sync : 1. We propose automatic selection of the k principal components via a heuris-tic technique such as the 95% cumulative variance explained criterion [ 18 ].
According to this criterion, during dimentionality reduction, the first k com-ponents that together explain more than 95% of the data X  X  variance are maintained; 2. We use all entities, instead of a subset of them (as in the approach of Section 3.2 ), to estimate the robust feature subspaces. This is reasonable since typi-cally the percentage of outliers in a dataset is small, and difficult to estimate apriori.
 Feature Engineering for Retweet Threads. Earlier works have associated bot activity with temporal activity anomalies, such as low entropy in the time intervals between posts. Here, we also expect that the retweet threads of RT fraudsters will exhibit different inter-synchronicity and high intra-synchronicity compared to honest users, with respect to their temporal characteristics. In addition, due to automation tools, as well as due to the way retweet markets operate, we expect RT fraudsters to be synchronized in terms of the number of retweets their posts receive. Based on the above, after experimenting with several features which are omitted here for brevity, we ended up with the following features for a retweet thread X  X  representation:  X  Retweets : number of retweets  X  Response time : time elapsed between the tweet X  X  posting time and its first  X  Lifespan : time elapsed between the first and last (observed) retweet, con- X  RT-Q3 resp onse time : time elapsed after the tweet X  X  posting time to gen- X  RT-Q2 resp onse time : time elapsed after the tweet X  X  posting time to gen- X  Arr-MAD : mean absolute deviation of inter-arrival times for retweets  X  Arr-IQR : inter-quantile range of inter-arrival times for retweets To estimate the suitability of the proposed features for revealing retweet fraud, we examined the projections of the retweet threads of the Twitter dataset described in Section 5.1 in all 2-D feature subspaces derived by the proposed feature set. To assist visualization, we binned all feature subspaces and generated 2-D heatmaps in logarithmic scales.
 Figure 2 indicatively depicts the scatter plots of Lifespan vs. Arr-MAD and Retweets vs. Response time for all dataset X  X  users (Fig. 2c and 2f ), and only for those annotated as  X  X onest X  (Fig. 2a and 2d ) and  X  X raudulent X  (Fig. 2b and 2e ). The Lifespan vs. Arr-MAD plots reveal microclusters of fraudulent retweet threads (at very low values of Arr-MAD and at high Lifespan values), whereas the majority of honest users X  retweet threads seem to be concentrated around a certain area of the feature subspace, clearly separated from RT fraudsters. Similar observations are made from the Retweets vs. Response time plots where we observe a microcluster at abnormaly low values for both features, and another one for high Response time. Some of these results were anticipated based on our intuition, e.g. bots of the same network may retweet all at once, having on average a zero Arr-MAD, but it seems that our proposed features can reveal more complex retweet fraud practices. For example, promoted posts may continue to receive retweets for a prolonged period of time, which explains the microcluster of long Lifespan, whereas certain RT fraudsters may wait for some time, after posting their tweets, before applying to some retweet market for their promotion. In this section, we evaluate ND-Sync by conducting a series of experiments on a dataset crawled from Twitter which is comprised of over 130K retweet threads characterizing more than 11M retweets to posts of several hundred active Twitter users. We detail our data collection approach, describe the settings of our numerous experiments, and finally present the performance of our 5.1 Twitter Dataset The evaluation of ND-Sync requires a dataset of several, complete retweet threads of honest and fraudulent users, i.e. with no gaps in the tuples repre-senting a given post X  X  retweets. Due to the Twitter Streaming API X  X  constraint of allowing access to only a sample of published tweets, our requirement for com-plete retweet threads, and the lack of a relevant (labeled) dataset, we manually selected a set of target users for whom we could track all tweets and retweets in a given time period.
 Target user accounts were selected in several fashions. Firstly, we examined a recent, 2-day sample of the global Twitter timeline and identified the users who posted the most retweeted tweets and those who posted tweets containing keywords heavily used in spam campaigns ( casino , followback , etc). Our next approach involved selecting users based on  X  X witter Counter X  tion that publishes lists ranking Twitter users based on criteria including follower count and number of tweets. We chose users based on their posting frequency and influence  X  specifically, we kept only users who tweeted several times per week and received more than 100 retweets on their recent posts. Lastly, we col-lected users active in specific topics (European affairs and Automobile), given that they were added in such topic-related lists by other Twitter users. tion of their tweets X  content led to the discovery of spammy links to external web pages, spam-related keywords, and multiple posts with similar promotions or vacuous content (e.g. quotes), and (b) profile information was clearly fabricated. The rest of the target users were labeled as  X  X onest X . We monitored the set of target users for time periods spanning from 2 to 6 months and eliminated those who had less than 20 retweet threads or a maximum-length retweet thread of less than 50 retweets. This process left us with a total of 298 users in the dataset, of which 270 were labeled honest and 28 labeled fraudulent. For each user, we extracted the retweet threads and mapped them to our proposed 7-D feature space. The dataset includes 134,022 retweet threads (83,587 with respect to honest and 50,435 of fraudulent users) which in total comprise 11,727,258 retweets (2,939,455 to posts of honest and 8,787,803 to posts of fraudulent users). 5.2 Results Next, we present the experimental results of ND-Sync  X  X  application on the Twitter dataset described above. We discuss its effectivess when applied on (a) all available 2 7 feature subspaces, (b) a restricted subset of the feature subspaces.
 Preliminary Observations on the Data. Before applying the final outlier detection step of ND-Sync , we examine the distribution of standardized user-level scores for honest users with respect to each feature subspace. All score vari-ables were found to be significantly asymmetric, having a medcouple 0.16 and 0.46, and the corresponding p -values rejected the normality hypothesis at the 1% significance level. If honest users X  scores had symmetric distributions, we could apply typical thresholded outlier detection techniques that assume nor-mal distribution [ 10 , 14 ]. However, in our case, the skewness of the  X  X ncontami-nated X  data would likely result in many false positives. Conversely, outlier detection approach is rather suitable for the RTFraud Detection Effectiveness on Real Data. Figure 3 shows ND-Sync formance on detecting RT fraudsters in terms of F1-score and accuracy .To examine robustness of ND-Sync to the number of dimensions maintained ( k ) in the beginning of the outlier detection step, we provide perfomance measures for k from 1 to 10 and all feature subspaces considered for the users X  suspicious-ness estimation. We observe that ND-Sync is relatively robust with respect to k : we attain [95%  X  97%] accuracy and [0 . 73  X  0 . 82] F1-score. For k =6,based on the 95% cumulative variance explained criterion , ND-Sync performance with respect to precision-recall balance and accuracy. Our exper-iments with ND-Sync considering only the 3-D and the 2-D feature subpaces showed effectiveness in catching several cases of fraud. Specifically, the accu-racy (F1-score) with respect to the best performing ND-Sync subspaces was reduced only by 4.5% (0.4%) and 10.6% (1%) for 3-D and 2-D subspaces, respectively. Observations on the Outlier Map. Figure 1a illustrates the outlier map of sd and od scores generated for the best run of ND-Sync correspond to adaptive cutoff values for sd and od  X  the plot clearly discerns the outliers from the majority of users which lie in the bottom-left region. All discovered outliers have an abnormal sd score, whereas 36% also have outlying od scores (in the top-right quartile of the figure).
 A closer examination of RT fraudsters that were caught by that the ones who scored high in sd and od were exemplary bot accounts that are typically hired for promotion or advertisement. For example, RTFraudster1, enclosed within a rectangle in the top-right quartile of Figure 1a , is an example of such a promiscuous fraudster with 800 followers that had 65 retweet threads in a 4-month time period  X  80% (60%) of these were comprised of more than 1k (10k) retweets and had almost 0 Arr-IQR 3 . The remainder of the  X  X aught X  RT fraudsters have a more subtle profile, resembling cyborg behavior: the accounts often create vacuous posts, but occasionaly interact genuinely with other users, thus indicating a human operator. We found that the five false positives detected by ND-Sync (enclosed by a red circle in Figure 1a ) belonged to media accounts and politicians. Three of these accounts have significantly abnormal sd and od scores, while the others are situated very close to RT fraudsters, suggesting that they may have tampered with the organic behavior of their retweet threads. In this work, we broach the problem of discerning fraudulent, group-based activ-ity from organic online behavior. The contributions of this work are the following:  X  Methodology :wepresent ND-Sync , a general, effective pipeline, which  X  Feature engineering : a carefully designed set of features, that customize million retweets , where the proposed ND-Sync achieved excellent classification accuracy of 97% in distinguishing fraudulent from honest users.
 Reproducibility: For the reproducibility of our results we share an (anonymi-zed) version of our data at: http://oswinds.csd.auth.gr/project/NDSYNC .
