 Estimating similarity between vertices is a fundamental issue in network analysis across various domains, such as social networks and biological networks. Methods based on common neighbors and structural contexts have received much attention. However, both categories of methods are difficult to scale up to handle large networks (with billions of nodes). In this paper, we propose a sam-pling method that provably and accurately estimates the similarity between vertices. The algorithm is based on a novel idea of dom path . Specifically, given a network, we perform R random walks, each starting from a randomly picked vertex and walking T steps. Theoretically, the algorithm guarantees that the sampling size R = O (2  X   X  2 log 2 T ) depends on the error-bound  X  fidence level (1  X   X  ) , and the path length T of each random walk.
We perform extensive empirical study on a Tencent microblog-ging network of 1,000,000,000 edges. We show that our algo-rithm can return top-k similar vertices for any vertex in a net-work 300  X  faster than the state-of-the-art methods. We also use two applications X  X dentity resolution and structural hole spanner finding X  X o evaluate the accuracy of the estimated similarities. Our results demonstrate that the proposed algorithm achieves clearly better performance than several alternative methods.
 H.2.8 [ Database applications ]: Data Mining; J.4 [ Social and Be-havioral Sciences ]: Miscellaneous; H.4.m [ Information Systems Applications ]: Miscellaneous Algorithms, Experimentation Vertex similarity; Social network; Random path
Estimating vertex similarity is a fundamental issue in network analysis and also the cornerstone of many data mining algorithms c such as clustering, graph matching, and object retrieval. The problem is also referred to as structural equivalence in previous work [24], and has been extensively studied in physics, mathemat-ics, and computer science. In general, there are two basic prin-ciples to quantify similarity between vertices. The first principle is that two vertices are considered structurally equivalent if they have many common neighbors in a network. The second principle is that two vertices are considered structurally equivalent if they play the same structural role X  X his can be further quantified by de-gree, closeness centrality, betweenness, and other network central-ity metrics [9]. Quite a few similarity metrics have been developed based on the first principle, e.g., the Jaccard index [16] and Cosine similarity [2]. However, they estimate the similarity in a local fash-ion. Though some work such as SimRank [17], VertexSim [23], and RoleSim [18], use the entire network to compute similarity, they are essentially based on the transitivity of similarity in the net-work. There are also a few studies that follow the second princi-ple. For example, Henderson et al. [13] proposed a feature-based method, named ReFeX, to calculate vertex similarity by defining a vector of features for each vertex.

Despite much research on this topic, the problem remains largely unsolved. The first challenge is how to design a unified method to accommodate both principles. This is important, as in many ap-plications, we do not know which principle to follow. The other challenge is the efficiency issue. Most existing methods have a high computation cost. SimRank results in a complexity of O ( I | V | where | V | is the number of vertices in a network;  X  d is the average degree of all vertices; I is the number of iterations to perform the SimRank algorithm. It is clearly infeasible to apply SimRank to large-scale networks. For example, in our experiments, when deal-ing with a network with 500,000 edges, even the fast (top-sion of SimRank [22] requires more than five days to complete the computation for all vertices (as shown in Figure 1(b)).
Thus, our goal in this work is to design a similarity method that is flexible enough to incorporate different structural patterns (fea-tures) into the similarity estimation and to quickly estimate vertex similarity in very large networks.

We propose a sampling-based method, referred to as Panther, that provably and quickly estimates the similarity between vertices. The algorithm is based on a novel idea of random path . Specifi-cally, given a network, we perform R random walks, each starting from a randomly picked vertex and walking T steps. The idea be-hind this is that two vertices have a high similarity if they frequently appear on the same paths. We provide theoretical proofs for the error-bound and confidence of the proposed algorithm. Theoreti-cally, we obtain that the sample size, R = c o nly depends on the path length T of each random walk, for a given error-bound  X  and confidence level 1  X   X  . To capture the informa-tion of structural patterns, we extend the proposed algorithm by augmenting each vertex with a vector of structure-based features. The resultant algorithm is referred to as Panther++. Panther++ is not only able to estimate similarity between vertices in a connected network, but also capable of estimating similarity between vertices from disconnected networks. Figure 1(a) shows an example of top-k similarity search across two disconnected networks, where and v 5 are top-3 similar vertices to v 0 .

We evaluate the efficiency of the methods on a microblogging son of Panther, Panther++, and several other methods. Clearly, our methods are much faster than the comparison methods.

Panther++ achieves a 300  X  speed-up over the fastest comparison method on a Tencent subnetwork of 443,070 vertices and 5,000,000 edges. Our methods are also scalable. Panther is able to return top-k similar vertices for all vertices in a network with 51,640,620 vertices and 1,000,000,000 edges. On average, it only need 0.0001 second to perform top-k search for each vertex.

We also evaluate the estimation capability of Panther++. Specif-ically, we use identity resolution and top-k structural hole spanner finding, two important applications in social networks, to evaluate the accuracy of the estimated similarities. Figure 1(c) shows the accuracy performance of Panther++ and several alternative meth-ods for identity resolution. Panther++ achieves clearly better per-formance than several alternative methods. All codes and datasets Organization Section 2 formulates the problem. In Section 3, we detail the proposed methods for top-k similarity search, and pro-vide theoretical analysis. Section 4 presents experimental results to validate the efficiency and effectiveness of our methods. Section 5 reviews the related work. Finally, Section 6 concludes the paper.
We first provide necessary definitions and then formally formu-late the problem.

Definition 1. Undirected Weighted Network. Let G = ( V, E, W ) denotes a network, where V is a set of | V | vertices and E  X  V  X  V is a set of | E | edges between vertices. We use to represent a vertex and e ij  X  E to represent an edge between vertices v i and v j . Let W be a weight matrix, with each element w ij  X  W representing the weight associated with edge e ij . h ttp://t.qq.com http://aminer.org/Panther
We use N ( v i ) to indicate the set of neighboring vertices of ver-tex v i . We leave the study of directed networks to future work. Our purpose here is to estimate similarity between two vertices, e.g., and v j . We focus on finding top-k similar vertices. Precisely, the problem can be defined as, given a network G = ( V, E, W ) query vertex v  X  V , how to find a set X v,k of k vertices that have the highest similarities to vertex v , where k is a positive integer.
A straightforward method to address the top-k similarity search problem is to first calculate the similarity s ( v i , v j v and v j using metrics such as the Jaccard index and SimRank, and then select a set X v,k of k vertices that have the highest similarities to each vertex v . However it is in general difficult to scale up to large networks. One important idea is to obtain an approximate set X v,k for each vertex. From the accuracy perspective, we aim to minimize the difference between X  X  v,k and X v,k . Formally, we can define the problem studied in this work as follows.

Problem 1. Top-k similarity search. Given an undirected weighted network G = ( V, E, W ) , a similarity metric s ( . ) a positive integer k , any vertex v  X  V , how to quickly and approx-imately retrieve the top-k similar vertices of v ? How to guarantee that the difference between the two sets X  X  v,k and X v,k a threshold  X   X  (0 , 1) , i.e., with a probability of at least 1  X   X  .

The difference between X  X  v,k and X v,k can be also viewed as the error-bound of the approximation. In the following section, we will propose a sampling-based method to approximate the top-k similarity. We will explain in details how the method can guarantee the error-bound and how it is able to efficiently achieve the goal.
We begin with considering some baseline solutions and then pro-pose our path sampling approach. A simple approach to the prob-lem is to consider the number of common neighbors of v i and If we use the Jaccard index [16], the similarity can be defined as This method only considers local information and does not allow vertices to be similar if they do not share neighbors.

To leverage the structural information, one can consider algo-rithms like SimRank [17]. SimRank estimates vertex similarity by iteratively propagating vertex similarity to neighbors until conver-g ence (no vertex similarity changes), i.e.,
S SR ( v i , v j ) = C |N ( v where C is a constant between 0 and 1.

SimRank similarity depends on the whole network and allows vertices to be similar without sharing neighbors. The problem with SimRank is its high computational complexity: O ( I | V | which makes it infeasible to scale up to large networks. Though quite a few studies have been conducted recently [21, 22], the prob-lem is still largely unsolved.

We propose a sampling-based method to estimate the top-k lar vertices. In statistics, sampling is a widely used technique to es-timate a target distribution [35]. Unlike traditional sampling meth-ods, we propose a random path sampling method, named Panther. Given a network G = ( V, E, W ) , Panther randomly generates paths with length T . Then the similarity estimation between two vertices is cast as estimating how likely it is that two vertices appear on a same path. Theoretically we prove that given an error-bound,  X  , and a confidence level, 1  X   X  , the sample size R is independent of the network size. Experimentally, we demonstrate that the error-bound is dependent on the number of edges of the network.
The basic idea of the method is that two vertices are similar if they frequently appear on the same paths. The principle is similar to that in Katz [19].
 Path Similarity. To begin with, we introduce how to estimate ver-tex similarity based on T -paths. A T -path is defined as a sequence of vertices p = ( v 1 ,  X   X   X  , v T +1 ) , which consists of and T edges. 3 Let  X  denotes all the T -paths in G . Let w ( p ) weight of a path p . The weight can be defined in different ways. Given this, the path similarity between v i and v j is defined as: where P v Estimating Path Similarity with Random Sampling. To calcu-late the denominator in Eq (1), we need to enumerate all T G . However, the time complexity is exponentially proportional to the path length T , and thus is inefficient when T increases. There-fore, we propose a sampling-based method to estimate the path sim-ilarity. The key idea is that we randomly sample R paths from the network and recalculate Eq (1) based on the sampled paths. where P is the set of sampled paths.

To generate a path, we randomly select a vertex in G as the start-ing point, and then conduct random walks of T steps from v t ij as the transition probability from vertex v i to v j . where w ij is the weight between v i and v j . In a unweighted net-work, the transition probability can be simplified as 1 / |N ( v
B ased on the random walk theory [7], we define w ( p ) as
The path weight also represents the probability that a path sampled from  X  ; thus, w ( p ) in Eq. (2) is absorbed, and we can rewrite the equation as follows:
Algorithm 3 summarizes the process for generating the R ran-dom paths. To calculate Eq. (4), the time complexity is O ( RT ) because it has to enumerate all R paths. To improve the efficiency, we build an inverted index of vertex-to-path [2]. Using the index, we can retrieve all paths that contain a specific vertex v plexity of O (1) . Then Eq. (4) can be calculated with a complexity of
O (  X  RT ) , where  X  R is the average number of paths that contain a vertex and  X  R is proportional to the average degree  X  d lustrates the process of random path sampling. Details of the algo-rithm are presented in Algorithm 1, where lines 1-5 are processing, and line 6 is top-k similarity searching for a vertex.
We give theoretical analysis for the random path sampling al-gorithm. In general, the path similarity can be viewed as a prob-ability measure defined over all paths  X  . Thus we can adopt the results from Vapnik-Chernovenkis (VC) learning theory [35] to an-alyze the proposed sampling-based algorithm. To begin with, we will introduce some basic definitions and fundamental results from Vapnik-Chernovenkis theory, and then demonstrate how to utilize these concepts and results to analyze our method.
 Preliminaries. Let ( D , R ) be a range space, where D denotes a domain, and R is a range set on D . For any set B  X  D , P { B  X  A : A  X  R} is the projection of R on B . If P R ( B ) = 2 where 2 B is the powerset of B , we say that the set B is shattered by R . The following definitions and theorem derive from [28].
Definition 2. The Vapnik-Chervonenkis (VC) dimension of R , denoted as V C ( R ) , is the maximum cardinality of a subset of D that can be shattered by R .

Let S = { x 1 ,  X   X   X  , x n } be a set of i.i.d. random variables sam-pled according to a distribution  X  over the domain D . For a set A  X  D , let  X  ( A ) be the probability that an element sampled from  X  belongs to A , and let the empirical estimation of  X  ( A ) w here 1 A is the indicator function with the value of 1 A 1 if x  X  A , and 0 otherwise.
The question of interest is that how well we can estimate u sing its unbiased estimator, the empirical estimation  X  first give the goodness of approximation in the following definition.
Definition 3. Let R be a range set on D , and  X  be a probability distribution defined on D . For  X   X  (0 , 1) , an  X  -approximation to ( R ,  X  ) is a set S of elements in D such that One important result of VC theory is that if we can bound the V C -dimension of R , it is possible to build an  X  -approximation by randomly sampling points from the domain according to the distri-bution  X  . This is summarized in the following theorem. Theorem 1. Let R be a range set on a domain D , with V C ( R )  X  d , and let  X  be a distribution on D . Given  X ,  X   X  (0 , 1) let
S be a set of | S | points sampled from D according to  X  , with w here c is a universal positive constant. Then S is a  X  approximation to ( R ,  X  ) with probability of at least 1  X   X  Range Set of Path. In our setting, we set the domain to be the set of all paths with length T in the graph G . Accordingly, we define the range set R G on domain  X  to be It is a valid range set, since it is the collection of subsets of domain  X  . We first show an upper bound of the VC dimen-sion of R G in Lemma 1. The proof is inspired by Riondato and Kornaropoulos [28].
 Lemma 1. V C ( R G )  X  log 2 T 2 + 1 P ROOF . We prove the lemma by contradiction. Assume V C ( R G ) = l and l &gt; log 2 T 2 + 1 . By the definition of VC-dimension, there is a set Q  X   X  of size l that can be shattered by R
G . That is, we have the following statement: where P i is the i -th range. Since each subset S i  X  Q is different from the other subsets, the corresponding range P i that making Q = S i is also different from the other ranges. Moreover, the set is shattered by R G if and only if { P i  X  Q : P i  X  R} = 2 of
Q containing the path p . So there are also 2 l  X  1 distinct ranges in R G that contain the path p , i.e.
In addition, according to the definition of range set, R G { P v i ,v j : v i , v j  X  V } , a path belongs to the ranges corresponding to any pair of vertices in path p , i.e., to the pairwise combinations of the vertices in p . This means the number of ranges in R On the other hand, from our preliminary assumption, we have log Algorithm 1 : Panther
Input : A network G = ( V, E, W ) , path length T , parameters Output : top-k similar vertices with regard to v .

Calculate sample size R = c
G enerateRandomPath( G , R ); foreach p n  X  P v do
Retrieve top-k s imilar vertices according to S RP ( v, v Algorithm 2 : Panther++
Input : A network G = ( V, E, W ) , path length T , parameters Output : top-k similar vertices with regard to v .

Calculate sample size R = c
G enerateRandomPath( G , R ); foreach v i  X  V do
Build a kd-tree index based on the Euclidean distance between a ny vectors  X  ( v i ) and  X  ( v j ) ;
Query the top-k similar vertices from the index for v .
Hence, we reach a contradiction: it is impossible to have d istinct ranges P i  X  R G containing p . Since there is a one-to-one correspondence between S i and P i , we get that it is also impos-sible to have 2 l  X  1 distinct subset S i  X  Q containing p . There-fore, we prove that Q cannot be shattered by R G and V C ( R log Sample Size Guarantee. W e now provide theoretical guarantee for the number of sampled paths. How many random paths do we need to achieve an error-bound  X  with probability 1  X   X  ? We define a probability distribution on the domain  X  .  X  p  X   X  , we define
W e can see that the definition of S RP ( v i , v j ) in Eq.(1) is equiv-alent to  X  ( P v based method (empirical average) to estimate the original path sim-ilarity (true probability measure).
 Plugging the result of Lemma (1) into Theorem (1), we obtain:
T hat is, with at least R random paths, we can estimate the path similarity between any two vertices with the desired error-bound and confidence level. The above equation also implies that the sam-ple size R only depends on the path length T , given an error-bound  X  , and a confidence level 1  X   X  .
One limitation of Panther is that the similarities obtained by the algorithm have a bias to close neighbors, though in principle it con-Algorithm 3 : GenerateRandomPath Input : A network G = ( V, E, W ) and sample size R .

Output : Paths { p r } R r =1 and vertex-to-path index { P
Calculate transition probabilities between every pair of vertices according to Eq. (3) ;
Initialize r = 0 ; repeat until r = R ; siders the structural information. We therefore present an extension o f the Panther algorithm. The idea is to augment each vertex with a feature vector. To construct the feature vector, we follow the in-tuition that the probability of a vertex linking to all other vertices is similar if their topology structures are similar [14]. We select the top-D similarities calculated by Panther to represent the probabil-ity distribution. Specifically, for vertex v i in the network, we first calculate the similarity between v i and all the other vertices using Panther. Then we construct a feature vector for v i by taking the largest D similarity scores as feature values, i.e.,  X  ( v i ) = ( S RP ( v i , v (1) ) , S RP ( v i , v (2) ) , . . . , S where S RP ( v i , v ( d ) ) denotes the d -th largest path similarity be-tween v i and another vertex v ( d ) .

Finally, the similarity between v i and v j is re-calculated as the reciprocal Euclidean distance between their feature vectors: I ndex of Feature Vectors Again, we use the indexing techniques to improve the algorithm efficiency. We build a memory based kd-tree [36] index for feature vectors of all vertices. Then given a vertex, we can retrieve top-k vertices in the kd-tree with the least Euclidean distance to the query vertex efficiently. At a high level, a kd-tree is a generalization of a binary search tree that stores points in
D -dimensional space. In level h of a kd-tree, given a node the h % D -th element in the vector of each node in its left subtree is less than the h % D -th element in the vector of v , while the element of every node in the right subtree is no less than the th element of v . Figure 3 shows the data structure of the index built in Panther++. Based on the index, we can query whether a given point is stored in the index very fast. Specifically, given a vertex v , if the root node is v , return the root node. If the first element of v is strictly less than the first element of the root node, look for v in the left subtree, then compare it to the second element of Otherwise, check the right subtree. It is worth noting that we can easily replace kd-tree with any other index methods, such as r-tree. The algorithms for calculating feature vectors of all vertices and the similarity between vertices are shown in Algorithm 2, where lines 1-8 are preprocessing, and line 9 is top-k similarity searching for a vertex.
 Figure 3: Data structure of the index built in Panther++. T able 1: Time and space complexity for calculating top-k sim-ilar vertices for all vertices in a network. I  X  number of it-erations,  X  d  X  X verage degree, f  X  X eature number, D  X  vector dimension, and T  X  path length.
 Implementation Notes. I n our experiments, we empirically set the parameters as follows: c = 0 . 5 ,  X  = 0 . 1 , T = 5 ,  X  = p 1 / | E | . The optimal values of T , D and  X  are discussed in
In general, existing methods result in high complexities. For example, the time complexity of SimRank [17], TopSim [22], Random walk with restart (RWR) [27], RoleSim [18], and ReFex [13] is O ( I | V | 2  X  d 2 ) , O ( | V | T  X  d T the time and space complexities of the different methods. For Pan-ther, its time complexity includes two parts:
The space complexity for storing paths and vertex-to-path index is O ( RT ) and O ( | V |  X  d ) , respectively.
 Panther++ requires additional computation to build the kd-tree. The time complexity of building a kd-tree is O ( | V | log | V | ) querying top-k similar vertices for any vertex is O ( | V | log | V | ) where log | V | is small and can be viewed as a small constant Additional space (with a complexity of O ( | V | D ) ) is required to store | V | vectors with D -dimension. h ttp://www.cs.umd.edu/~mount/ANN/
In this section, we conduct various experiments to evaluate the proposed methods for top-k similarity search.
 Datasets. We evaluate the proposed method on four different networks: Tencent, Twitter, Mobile, and co-author.
 Tencent [37] : The dataset is from Tencent Weibo, 1 a popular Twitter-like microblogging service in China, and consists of over 355,591,065 users and 5,958,853,072  X  X ollowing X  relationships. The weight associated with each edge is set as 1.0 uniformly. This is the largest network in our experiments. We mainly use it to eval-uate the efficiency performance of our methods.

Twitter [15] : The dataset was crawled in the following way. We first selected the most popular user on Twitter, i.e.,  X  X ady Gaga X , and randomly selected 10,000 of her followers. We then collected all followers of these users. In the end, we obtained 113,044 users and 468,238  X  X ollowing X  relationships in total. The weight associ-ated with each edge is also set as 1.0 uniformly. We use this dataset to evaluate the accuracy of Panther and Panther++.

Mobile [6] : The dataset is from a mobile communication com-pany, and consists of millions of call records. Each call record con-tains information about the sender, the receiver, the starting time, and the ending time. We build a network using call records within two weeks by treating each user as a vertex, and communication be-tween users as an edge. The resultant network consists of 194,526 vertices and 206,934 edges. The weight associated with each edge is defined as the number of calls. We also use this dataset to evalu-ate the accuracy of the proposed methods.

Co-author [33] : The dataset is from AMiner.org, 5 and contains 2,092,356 papers. From the original citation data, we extracted a weighted co-author graph from each of the following conferences from 2005 to 2013: KDD, ICDM, SIGIR, CIKM, SIGMOD, ICDE, papers collaborated on by the two connected authors. We also use the dataset to evaluate the accuracy of the proposed methods. Evaluation Aspects. To quantitatively evaluate the proposed methods, we consider the following performance measurements:
Efficiency Performance: We apply our methods to the Tencent network to evaluate the computational time.

Accuracy Performance: We apply the proposed methods to rec-ognize identical authors on different co-author networks. We also compare our results to common neighbors and apply the methods to find top-k structural hole spanners on the Twitter and Mobile networks.

Parameter Sensitivity Analysis: We analyze the sensitivity of different parameters in our methods: path length T , vector dimen-sion D , and error-bound  X  .

Finally, we also use several case studies as anecdotal evidence to further demonstrate the effectiveness of the proposed method. All codes are implemented in C++ and compiled using GCC 4.8.2 with -O3 flag. The experiments were conducted on a Ubuntu server with four Intel Xeon(R) CPU E5-4650 (2.70GHz) and 1T RAM.
 Comparison methods. We compare with the following methods:
RWR [27] : Starts from v i , iteratively walks to its neighbors with the probability proportional to their edge weights. At each step, it h ttp://aminer.org/citation 2,867/7,637, ICDM: 2,607/4,774, SIGIR: 2,851/6,354, CIKM: 3,548/7,076, SIGMOD: 2,616/8,304, ICDE: 2,559/6,668. also has some probability to walk back to v i (set as 0.1). The sim-ilarity between v i and v j is defined as the steady-state probability that v i will finally reach at v j . We calculate RWR scores between all pairs and then search the top-k similar vertices for each vertex.
TopSim [22] : Extends SimRank [17] on one graph G to finding top-k authoritative vertices on the product graph G  X  G efficiently.
RoleSim [18] : Refines SimRank [17] by changing the average similarity of all neighbor pairs to all matched neighbor pairs. We calculate RoleSim scores between all pairs and then search the top-k similar vertices for each vertex.

ReFeX [13] : Defines local, egonet, and recursive features to cap-ture the structural characteristic. Local feature is the vertex degree. Egonet features include the number of within-egonet edges and the number of out-egonet edges. For weighted networks, they contain weighted versions of each feature. Recursive features are defined as the mean and sum value of each local or egonet feature among all neighbors of a vertex. In our experiments, we only extract re-cursive features once and construct a vector for each vertex by a total of 18 features. For fair comparison, to search top-vertices, we also build the same kd-tree as that in our method.
The codes of TopSim, RoleSim, and ReFex are provided by the authors of the original papers. We tried to use the fast versions of TopSim and RoleSim mentioned in their paper.
In this subsection, we first fix k = 5 , and evaluate the efficiency and scalability performance of different comparison methods us-ing the Tencent dataset. We evaluate the performance by randomly extracting different (large and small) versions of the Tencent net-works. For TopSim and RoleSim, we only show the computational time for similarity search. For ReFex, Panther, and Panther++, we also show the computational time used for preprocessing.
Table 2 lists statistics of the different Tencent sub-networks and the efficiency performance of the comparison methods. Clearly, our methods (both Panther and Panther++) are much faster than the comparison methods. For example, on the Tencent6 sub-network, which consists of 443,070 vertices and 5,000,000 edges, Panther achieves a 390  X  speed-up , compared to the fastest (ReFeX) of all the comparative methods.
 Figure 4(a) shows the speed-up of Panther++ compared to ReFeX on different scales of sub-networks. The speed-up is moder-ate when the size of the network is small ( | E |  X  1 , 000 , 000 continuing to increase the size of the network, the obtained speed-up is even superlinear. We conducted a result comparison between ReFeX and Panther++. The results of Panther++ are very similar to those of ReFex, though they decrease slightly when the size of the network is small. Figure 4(b) shows the efficiency performance of Panther and Panther++ on Tencent5 by varying the values of 5 to 100. We can see that, when k is much smaller than the number vertices in the network, the time costs of Panther and Panther++ are not very sensitive to k . The growth of time cost is slow when k gets larger. This is because k is only related to the time com-plexity of top-k similarity search based on a heap structure. When k gets larger, the time complexity approximates to O (  X  M log from O (  X  M ) , where  X  M is the average number of co-occurred ver-tices on the same paths. We can also see that the time cost is not very stable when k gets larger, because the paths are randomly gen-erated, which results in different values of  X  M each time.
From Table 2, we can also see that RWR, TopSim and RoleSim cannot complete top-k similarity search for all vertices within a reasonable time when the number of edges increases to 500,000. ReFeX can deal with larger networks, but also fails when the edge number increases to 10,000,000. Our methods can scale up to han-cannot finish the computation within a reasonable time. Sub-network |V| |E| RWR TopSim RoleSim ReFeX Panther Panther++ T encent5 230,103 1,000,000  X   X   X  31.50m+3.29s 15.31s+30.63s 49.83s+22.86s T encent6 443,070 5,000,000  X   X   X  24.15hr+8.55s 50.91s+2.82m 4.01m+1.29m T encent7 702,049 10,000,000  X   X   X  &gt;48hr 2.21m+6.24m 8.60m+6.58m T encent8 2,767,344 50,000,000  X   X   X   X  15.78m+1.36hr 1.60hr+2.17hr T encent9 5,355,507 100,000,000  X   X   X   X  44.09m +4.50hr 5.61hr +6.47hr T encent10 26,033,969 500,000,000  X   X   X   X  4.82hr +25.01hr 32.90hr +47.34hr F igure 4: (a) Performance ratio is calculated by Score(ReFex) w here score is evaluated by the application of structural hole spanner finding (see  X  4.3 for details.); Speed-up is calculated of Panther and Panther++. dle very large networks with more than 10,000,000 edges. On aver-age, Panther only needs 0.0001 second to perform top-k similarity search for each vertex in a large network. Identity Resolution. It is difficult to find a ground truth to eval-uate the accuracy for similarity search. To quantitatively evaluate the accuracy of the proposed methods and compare with the other methods, we consider an application of identity resolution co-author network. The idea is that we first use the authorship at different conferences to generate multiple co-author networks. An author may have a corresponding vertex in each of the generated networks. We assume that the same authors in different networks of the same domain are similar to each other. We anonymize author names in all the networks. Thus given any two co-author networks, for example KDD-ICDM, we perform a top-k search to find similar vertices from ICDM for each vertex in KDD by different methods. If the returned k similar vertices from ICDM by a method consists of the corresponding author of the query vertex from KDD, we say that the method hits a correct instance. A similar idea was also employed to evaluate similarity search in [11]. Please note that the search is performed across two disconnected networks. Thus, RWR, TopSim and RoleSim cannot be directly used for solving the task. ReFex calculates a vector for each vertex, and can be used here. Additionally, we also compare with several other methods including Degree, Clustering Coefficient, Closeness, Betweenness and Pagerank. In our methods, Panther is not applicable to this sit-uation. We only evaluate Panther++ here. Additionally, we also show the performance of random guess.

Figure 5 presents the performance of different methods on the task of identity resolution across co-author networks. We see that Panther++ performs the best on all three datasets. ReFex performs comparably well; however, it is not very stable. In the SIGMOD-ICDE case, it performs the same as Panther++, while in the KDD-ICDM and SIGIR-CIKM cases, it performs worse than Panther++, when k  X  60 .
 Approximating Common Neighbors. We evaluate how Panther can approximate the similarity based on common neighbors. The evaluation procedure is described as follows: 1. For each vertex u in the seed set S , generate top k vertices 2. For each vertex v  X  Top A,k ( u ) , calculate g ( u, v ) 3. Similarly, let f R,k denotes the result of a random algorithm. 4. Finally, we define the score for algorithm A as score ( A, k ) =
Specifically, we define g ( u, v ) to be the number of common neighbors between u and v on each dataset.

Figure 6 shows the performance of Panther evaluated on the ground truth of common neighbors in Twitter and Mobile net-works. Some baselines such as RWR and RoleSim are ignored on the datasets, because they cannot complete top-k similarity search for all vertices within a reasonable time. It can be seen that Pan-ther performs better than any other methods on both the datasets. Panther++ and ReFex perform worst since they are not devised to address the similarity between near vertices. Our method Panther performs as good as TopSim, the top-k version of SimRank, be-cause they both based on the principle that two vertices are consid-ered structurally equivalent if they have many common neighbors in a network. However, according to our previous analysis, TopSim performs much slower than Panther. tant applications in social networks, to evaluate the accuracy of the e stimated similarities. Our experimental results demonstrate that the proposed algorithm achieves clearly better performance than several alternative methods.
 [1] K. Aoyama, K. Saito, H. Sawada, and N. Ueda. Fast [2] R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern information [3] V. D. Blondel, A. Gajardo, M. Heymans, P. Senellart, and [4] R. S. Burt. Detecting role equivalence. Social Networks [5] R. S. Burt. Structural holes: The social structure of [6] Y. Dong, Y. Yang, J. Tang, Y. Yang, and N. V. Chawla. [7] W. Feller. An introduction to probability theory and its [8] L. C. Freeman. A set of measures of centrality based on [9] L. C. Freeman. Centrality in social networks conceptual [10] Y. Fujiwara, M. Nakatsuji, H. Shiokawa, T. Mishima, and [11] S. Gilpin, T. Eliassi-Rad, and I. Davidson. Guided learning [12] K. Henderson, B. Gallagher, T. Eliassi-Rad, H. Tong, [13] K. Henderson, B. Gallagher, L. Li, L. Akoglu, [14] P. W. Holland and S. Leinhardt. An exponential family of [15] J. Hopcroft, T. Lou, and J. Tang. Who will follow you back? [16] P. Jaccard.  X tude comparative de le distribution florale dans [17] G. Jeh and J. Widom. Simrank: a measure of [18] R. Jin, V. E. Lee, and H. Hong. Axiomatic ranking of [19] L. Katz. A new status index derived from sociometric [20] M. M. Kessler. Bibliographic coupling between scientific [21] M. Kusumoto, T. Maehara, and K.-i. Kawarabayashi.
 [22] P. Lee, L. V. Lakshmanan, and J. X. Yu. On top-k structural [23] E. Leicht, P. Holme, and M. E. Newman. Vertex similarity in [24] F. Lorrain and H. C. White. Structural equivalence of [25] T. Lou and J. Tang. Mining structural hole spanners through [26] M. E. Newman. Finding community structure in networks [27] J.-Y. Pan, H.-J. Yang, C. Faloutsos, and P. Duygulu. [28] M. Riondato and E. M. Kornaropoulos. Fast approximation [29] R. A. Rossi and N. K. Ahmed. Role discovery in networks. [30] P. Sarkar and A. W. Moore. Fast nearest-neighbor search in [31] H. Small. Co-citation in the scientific literature: A new [32] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. Pathsim: Meta [33] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. [34] C. E. Tsourakakis. Toward quantifying vertex similarity in [35] V. N. Vapnik and A. Y. Chervonenkis. On the uniform [36] I. Wald and V. Havran. On building fast kd-trees for ray [37] Y. Yang, J. Tang, C. W.-k. Leung, Y. Sun, Q. Chen, J. Li, and
