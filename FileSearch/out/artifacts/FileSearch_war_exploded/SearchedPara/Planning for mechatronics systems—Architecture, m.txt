 1. Introduction
Technical systems and machines are designed to fulfill tasks for humans. Technical progress continuously broadens the spec-trum of tasks and improves the quality of task fulfillment. Quality can be measured in various dimensions, application dependent and independent examples are: timeliness, resource consump-tion, processing accuracy (e.g. in case of machining tools), or comfort and driving pleasure (e.g. in case of vehicles). Usually, it is not possible to determine the relative importance of these qualities during the design of the systems because they usually depend on the current application situation. Thus, it is desirable that technical systems are able to adapt the relationships between these qualities or objectives depending on the current situation.

The term mechatronics refers to the close integration of electro-mechanical systems, electronics and information technol-ogy ( Isermann, 2005 ). Typically, a mechatronic system consists of mechanical skeleton, actuators, sensors, controllers, signal con-ditioning/modification devices, computer/digital hardware and software, interface devices, and power sources ( Kelly and De
Silva, 2004 ). To handle the complexity induced by so many different types of components, mechatronic systems are usually hierarchically structured ( VDI, 2004 , The Association of German Engineers) and a mechatronic system is usually composed by a number of function modules which realize specific sub functions.
In particular the integration of information technology enables mechatronic systems to adapt their behavior according to dynamic environments. The information processing in mechatro-nic and similar engineering system is often based on artificial intelligence and soft computing methods, e.g. for prediction (cf. Cheng et al., 2005 ; Lin et al., 2006 ; Ramasso and Gouriveau, 2010 ) for model predictive control (cf. Martinez et al., 1997 ; Zamerren  X  o and Vega, 1999 ; Wang et al., 2005 ), state estimations (cf. Lin and Yang, 2003 ; Li et al., 2006 , and diagnosis (cf. Miguel and Blazquez, 2005 ; Lebaroud and Clerc, 2009 ).

The information processing in advanced mechatronic systems is often organized by a multi-level-control system ( Isermann, 2005 ). Basically, the lower level of information processing can be handled with established methods from control engineering, focusing on safety and stability of the controlled processes. On the higher level of information processing, in particular on the level of management, new methods and algorithms are required. 1.1. Motivating example and use case
The railway vehicle RailCab is a good motivating example for planning in mechatronic systems as well as demonstrator for the use case in Section 6 . It is developed within the project  X  X  X eue Bahntechnik Paderborn X  X  (NBP) (cf. Henke et al., 2008 ) and consists of small autonomously driven rail-bound vehicles.
Fig. 1 shows an example of a planning problem: A RailCab has to travel along a number of track sections. A track section is a cut-out from the railway network, which is characterized by certain features (e.g. amount of track excitation, slope, etc.) and does not contain a switch (cf. Schmidt et al., 2008 regarding the extraction of track sections). Regarding their properties, track sections are grouped into classes (I and II in Fig. 1 ). On each track section, the
RailCab has to choose from different alternative behaviors or operation modes (a X  X ), which represent trade-offs between objec-tive functions (e.g. minimization of the body movement or energy losses) and the consumption of energy from the onboard storage.
In combination, the operation modes and the state of charge ( SOC ) of the RailCabs onboard energy storages define the state space sketch in Fig. 1 . A planning procedure explores this state space and defines for each track section which operation mode should be executed. As a general constraint, the SOC can never be below 0 and the availability of operation modes depends on the current state of charge. An appropriate planning procedure should select the operation modes in such a way that an objective function f is optimized overall track sections. 1.2. Contributions
In this paper we will define a class of planning problems to model the decision making process in the management level of mechatronic systems and introduce an architecture for the management level of mechatronic systems. Furthermore, we demonstrate how methods from artificial intelligence like plan-ning, machine learning, and probabilistic reasoning are employed to manage the basic mechanical and electrical processes in complex mechatronic systems. Our approach is to use planning for the determination of suitable objective functions for each sub-module in a mechatronic system. The planning process integrates several planning techniques and simulation in order to handle the challenges in mechatronic domains. Hybrid planning can be split up into four activities: 1. Initial planning. 2. Analyzing plan actions in simulation. 3. Modify plan. 4. Execute and monitor the currently active plan.

Basically it integrates several planning techniques and simula-tion. Just-in-case planning provides a number of alternative plans prior to the execution of a task assigned to a mechatronic systems, reflecting the uncertainty present in most application domains of mechatronic system. Simulation, interleaved with the execution of a plan, analyses the feasibility and applicability of single operations in the plan. Online planning is designed to provide real-time decision making in all situations, where no appropriate alternative plan was proactively created. In order to integrate the existing approaches Just-in-case or conditional planning and online planning into an architecture for decision making in mechatronic systems, these methods had to be exam-ined and refined to meet the specific requirements of mechatronic applications. 1.3. Structure of the paper a planning model for mechatronic systems. The third section describes the general problem addressed by the hybrid planning, reviews the related work regarding discrete X  X ontinuous planning, and briefly discusses the two building blocks which can be implemented with standard methods, offline planning and simu-lation. Since extensions of existing just-in-case and online plan-ning approaches are presented, these two planning methods are discussed in Sections 4 and 5. We will give a brief introduction to the general planning concept, discuss the relevant state of the art and introduce the specific realization for planning in mechatronic systems. The sixth section introduces the RailCab case study in more details and presents experimental results regarding the planning process. The seventh section discusses the results and gives an outlook to future work. 2. Planning for mechatronic systems something, usually it is about the future course of actions in order to accomplish something ( van Wezel and Jorne, 2001 ). This definition of planning is also suitable for planning for mechatronic systems. The planning for mechatronic system is the search for sequence of executed functions (e.g. accelerate  X  following an acceleration profile, drive at continuous speed , brake  X  following a deceleration profile) in order to fulfill a job or task assigned to the mechatronic system. Examples of such tasks are the transporta-tion of goods (in case of a vehicle) or the processing of a work piece in a machining center. Thus, usually tasks can be defined by a state before the execution (good is in place A, work piece is not processed) and a state after the execution (good is in place B, work piece is processed).
 in different ways. From the planning perspective, these different ways are distinguished from each other by how well they achieve the possible objectives and how they change the system state.
We refer to these different implementations of functions as operation modes . The planning process does not consider the specific technical implementation of an operation mode; instead it focuses on the relationship of objective achievement and change in system state, in particular resource consumption.
Thus, the planning problem for mechatronic systems can be formally described as follows: OM is a finite set of available operation modes,
S is a finite set of possible states of the system and the environment, where each state s A S is vector n state variables and s  X  i  X  is the value of the i -th position in the vector.

Furthermore for each operation mode om A OM : prec om is a set of precondition which must be true in order to execute the operation mode, post om is a set of conditional transition functions describing the change of each p A post om .

The planning problem is to identify a sequence of operation modes that fulfills the current system task. The duration of an operation mode depends on application domain specific condi-tions. It may be active for a fixed period of time, while traveling on way or track section with specific properties, or for a specific machining operation defined by numerical control (NC) program of a machining tool.

In a mechatronic planning domain most relevant variables are numerical, hence we restrict the state vector to real valued numerical variables. Furthermore, we assume that the pre-conditions of an operation mode have the following form:  X  x tion of the state vector. The transition function of an operation mode is a set of conditional numerical functions describing the change of influenced state variables. A condition is a logical expression (conjunctions and disjunctions) of comparison opera-tions. If a condition is true, the result of the corresponding numerical function is assigned to state variable p A post om in the next state of the plan. Obviously, the conditions have to be both disjoint and complete to make the planning model well defined.
Furthermore, only state variables and numerical primitives can be used to define both conditions and numerical functions.
This formal definition resembles a simplified version of a planning language, e.g. the Planning Domain Definition Language (cf. Fox and Long, 2003 ). Basically it enables a state-space-search from a given initial state s i A S towards a desired goal state s
Initial state s i and goal state s g define a job or task of the mechatronic systems. In order to evaluate possible plans during the planning process, the model must be extended by information about the achievement of objectives:
O is a set of external objectives, defining the user X  X  preferences, achieve : S O - X  0 ; 1 is a function denoting how well an opera-tion mode achieves an objective if executed in a given state.
Given a user X  X  preferences, e.g. via a weighted sum of objec-tives, the planning process can select the sequence of operation modes in such a way that these preferences are optimized. The planning process is usually performed on the system level. Thus, the planning process selects the mode of operations of the several mechatronic function modules such that they comply with the system X  X  user preferences. The underlying function modules may run a more or less complex optimization to determine their local behavior accordingly, e.g. solve an optimal control problem. 3. Hybrid planning
Given the formal planning problem for mechatronic systems, a challenge regarding planning for mechatronics is evident. While the planning model is based on a state-action formalism (like most planning problems in artificial intelligence) the continuous process trajectory is of crucial importance in mechatronic sys-tems. Since the planning process discretizes and abstracts system behavior, the current plan execution will never meet the plan exactly. As an example consider an operation that in the discrete planning model mode seems to produce a surplus of energy, but during (continuous) execution consumes all energy from storage before it ever starts to produce energy. Hence, there is a need to integrate the discrete and continuous aspects of the planning problem. 3.1. Related work on discrete X  X ontinuous planning
Most of the related work on discrete X  X ontinuous planning is based on hybrid models or automata (cf. Henzinger, 1996 ). A hybrid automaton describes continuous change and discrete switching of modes, where a different mode implies a different kind of continuous change, e.g. defined by differential equation. On certain jump conditions , e.g. time-dependent or dependent on state variables, the system changes its mode and a different continuous change trajectory is followed. The combination of continuous change and discrete switching between modes or states can be exploited to define fine granular planning models. Fox and Long (2006) introduce an extension of their PDDL 2.1 which supports a better modeling of mixed discrete X  X ontin-uous planning domains and problems. PDDL  X  is based on hybrid automata and provides a flexible modeling of continuous change through using autonomous processes and events. PDDL  X  uses a start-process-stop-model to express continuous change: An action (planned by the planning agent) or an event occur and start a process. This process runs and continuously changes numerical state variables until another action is executed or an event occurs, which ends the process (switching condition). Edelkamp (2001) introduced some first solution approaches for PDDL  X  problems. He exploited specific properties of the planning domains and problems, for instance an A* search based planner could be applied if the goal state was entirely propositional. In other domains, continuous actions were replaced manually by discrete variants. Della Penna et al. (2009) introduce a universal planning tool called UPMurphy for PDDL  X  domains. In order to apply an explicit model checker to the discrete X  X ontinuous domain, they approximate the hybrid model by a discretization. As a universal planner, UPMurphy delivers all feasible plans between a set of start states (the start cloud) and the desired tile of the discrete grid.

The application of deterministic hybrid automaton is only successful if the mode transitions and the continuous change in a certain mode are known with certainty. This assumption has to be dropped in most real word applications due to various and not exactly predictable influences towards the controlled systems. Maier and Sachenbacher (2009) use a probabilistic hybrid auto-maton (PHA) to partition the continuous space into a discrete grid. Using a PHA as model, the movement in the discretized continuous space is a Markov process. Thus, their planning method is able to find the sequence of modes which maximizes the probability to reach the desired mode. Bresina et al. (2002) also use a probabilistic hybrid automaton. In difference to Maier and Sachenbach the PHA are not used for planning directly, but for diagnosis. Subsequent to initial planning the plan is analyzed. Thus, a discrete plan is checked and evaluated on basis of a hybrid model and afterwards changed or even discarded.

Obviously, the operation modes introduced in Section 2 could be understood as modes in a hybrid automaton. Each operation mode had to be defined by one (deterministic) or a set of (probabilistic) differential equations. The possible benefit is the availability of continuous state trajectories, which could be checked for certain properties, e.g. never exceeding the energy storage of the system. But considering the planning horizon required on the management level and the resulting only coarse and imprecise information about the environmental settings, it is hardly possible to identify a computationally hand-able set of differential equations and possible initial conditions. Further-more, the planning problem has to identify a good or even optimal configuration of switching between system modes, such that the global system objectives are properly persuaded, but none of the available planning process for hybrid models is able to optimize a real valued objection function. 3.2. Hybrid planning architecture
Our basic approach is to handle the continuous behavior of the system with well established and well validated techniques from control engineering. The planning task is the determination of the objective functions, which are used to adapt the controller in the system. The adaption has to be performed in such a way that it complies with the overall system objectives. Fig. 2 presents our solution approach. The building blocks of the architecture can split into two groups, regarding the function they fulfill. The first group are the planning components, which generate plans regarding the future behavior of the systems, in such a way that the behavior of all subsystems satisfies the externally defined objectives. This group contains three elements: offline planning, just-in-case planning and online planning. The offline planning assumes a deterministic planning model and generates a good or optimal plan regarding this model. This plan is used as input for just-in-case planning, which analyzes the deterministic plan to identify likely and relevant plan deviations and generates before-hand alternative plans to handle these deviations. It was initially introduced as part of a dependability concept for mechatronic systems (cf. Kl  X  opper et al., 2012 ).

In combination, offline and just-in-case planning implement a weak anytime algorithm. An anytime algorithm can be stopped at an arbitrary time and returns a result, but the later the algorithms is stopped, the better is the calculated results ( Zilberstein, 1996 ).
In this sense, after the initial plan is generated, the just-in-case planning continuously improves the result. The more planning time is available, the better the generated alternative plan cover the possible execution trajectories. The online planning is a fallback level and implements a real-time selection for the operation modes for situations where no pre-calculated plan is available. It can work as well as anytime algorithms: it has to be able to provide a decision about the next operation mode in real-time and almost immediately, but if more calculation time is available, it should be used to provide better decisions. tion of plans. A simulation of the continuous system behavior checks if the action included the active plan are executable and opportune given the current environmental settings. Hence, the execution enforces the system to carry out the next operation modes specified in the plan and the comparisons check the resulting change against the data provided in the plan. The plan updates integrate the information and decides to change the active plan. For this purpose, it first checks if any pre-calculated plan for the new situation is available and if no suitable plan is available, and then queries the online planning for a plan modification. The plan modification has to be provided in real time, to ensure that the system is informed about which opera-tion mode to apply in the next step.
 planning and simulation block of the hybrid planning architec-ture. Both can be implemented by standard techniques. The planning process for mechatronic systems requires specific prop-erties regarding the just-in-case planning and the online plan-ning. Hence, these two building blocks will be explained in separate sections. 3.2.1. Offline planning plan is generated prior to its execution. Thus, offline planning refers to a planning process that is not interleaved with the execution. In this step, all the required activities are determined in such a way that the externally defined objectives are opti-mized. For this purpose, it defines a series of objective functions for each relevant sub-module. These objective functions are then used to determine the most appropriate control strategy for each mechatronic function module. During offline planning the focus is on solution quality. The planning algorithms are designed to produce a good or even optimal plan and solution time is only of secondary interest. Under soft real time constraints the current planning process might be outsourced from the mechatronic systems. Under such circumstances even the hard memory con-straints in embedded systems can be ignored (for an example of such an outsourcing of planning processes cf. Jedermann et al., 2007 ). Which planning algorithm is most appropriate for offline planning depends strongly on the planning problem. A general applicable solution approach is state-space-search, either forward or backward. For some applications there might be the opportu-nity to redefine the planning problem to a less complex problem class (e.g. shortest-path or fractal knapsack) or to define efficient approximation methods. 3.2.2. Simulation to the level of a consecutive set of operation modes. Each of the steps makes assumptions about pre-conditions as well as about the effect of the action. To handle the problem of inevitable plan deviations and to exploit new information available during plan execution, the generated plan is analyzed in a simulation step.
A system model including controller level behavioral models is executed against the planned set of actions. While simulating, assumptions about those environmental conditions are made that cannot be determined exactly in advance like road conditions or wheel excitations. To mitigate the resulting deviations, the simulation is repeated during run-time to include the system and environmental state determined up to that point in time. several physical properties of the system like energy consumption or acceleration levels are known. These can be checked against limits that could not be regarded during planning. As a result, the simulation is able to reject actions from the current plan as not applicable or disadvantageous. 4. Just-in-case planning
The actual result of every operat ion mode during execution will differ from the result in the offline plan. Reasons for these deviations are environmental influences, w hich cannot be known during the offline planning. The deviation from the offline plan might cancel each other out, but they might also result in a deviation that is a serious threat towards a successful plan execution.
 In this section we introduce a method for just-in-case planning .
By this term, also used by Bresina et al. (2002) , we emphasize that the system generates a plan just-in-case a certain state becomes true during execution. It is hardly possible to determine single events or a set of events, which is responsible for a relevant deviation since many small deviations, caused by different events, can sum-up to be a threat. Thus, our just-in-case planning focuses on which states may be achieved during planning rather than modeling events causing deviations. 4.1. Related work on just-in-case planning
The term just-in-case planning refers to the idea to provide proactively alternative plans for the case that specific deviations occur during plan execution. Thus, just-in-case planning corre-sponds to conditional planning as originally introduced by Warren (1976) , who describes a conditional planner for actions with two alternative post-condition. It basically constructs a plan with branches, where each branch is annotated with a condition. If the condition becomes true during plan execution, the system executes the corresponding branch. The main problem of conditional plan-ning is that the number of branches grows very large in complex problems, especially if numerical variables are considered.
Probabilistic conditional planners try to solve this problem by focusing on the most likely branches. C-Buridan ( Draper et al., 1994 ) increases a plan X  X  success probability by adding branches, until a threshold probability is meet or no more branches can be added. The planner introduced by Bresina et al. (2002) imple-ments the same basic principle emphasizing continuous action trajectories. Another conditional probabilistic planer is Paragraph by Little and Thiebaux (2006) . It extends the plangraph paradigm by adding an additional node type: for each possible effect of an action, a node is added to plangraph. Thus, the plangraph contains all possible execution trajectories and Paragraph searches all possible plans in the plangraph structure. Weaver , developed by
Blythe (1998) is particularly interesting since it uses Bayes Net-works to model the influence of external events towards the plan execution. Events are exogenous changes of environmental vari-ables and thus influence the success probability of a plan. Weaver works in two phases: first a plan is generated which ignores the possibility of exogenous events. Secondly, the success probability of the resulting plan is calculated. If it is below a threshold probability, a plan is generated that considers the threatening exogenous events.

None of the planners discussed is able to consider a real valued objective function, hence it is not possible to guarantee that a good or even optimal plan is found. All planners except Weaver provide no causal model to obtain the probabilities regarding the outcome of actions. Weaver focuses on single events which might be a threat to the successful execution of a plan. As explained above, this is not a promising approach for mechatronic domains, but splitting up between planning and a probabilistic analysis helps reducing the complexity of plan generation. Also, the idea to use Bayes Networks to model environmental influences on plan execution is transferred to hybrid planning. 4.2. Just-in-case planning with state probabilities Fig. 3 shows a sketch of our just-in-case planning approach. It consists of a deterministic planning model and planning algorithm and a probabilistic planning model and plan analysis. The probabilistic analysis identifies deviations which are a threat to the successful plan execution. The identified deviations are used to define new deterministic planning problems which are solved by the deterministic planning algorithms. In this way new branches are added to the just-in-case plan. Obviously, if the planning problem is quite large and to some extent uncertain, the number of threatening deviation grows large as well. Thus, the deviations are ordered according to their probability. This enables an anytime version of the just-in-case planning procedure, which goes on to add branches to the plan until planning time is over.
The deterministic planning model was explained in Section 2 , possible planning algorithms were outlined in Section 3.2.1 . The next step is the definition of the probabilistic version of the planning model. Obviously, the probabilistic planning model has to be coherent with the deterministic version. Thus, we start with the definition of a probabilistic state: s p is a vector of variables corresponding to the arity of the state vector in the deterministic problem s A S . domain  X  s p  X  i  X  X  -P  X  R  X  is a range of numerical values defining the domain of the i -th position in the probabilistic state vector.
Furthermore, a probabilistic version of operation modes is required, describing the dynamics in the probabilistic planning model. To enable a convenient, but comprehensive modeling of the dynamics we decided to use Bayes Networks. Bayes X  theorem enables more precise calculation of a posteriori probability dis-tribution on the basis of former a priori probabilities, when some additional knowledge about the world is given. This knowledge about the world is referred to as evidence. Hard and soft evidences are distinguished, where hard evidence denote a fact that is known for sure and a soft evidence means that an a posteriori probability of the fact is available.

A Bayesian Network is a directed, acyclic graph  X  G , V  X  ( Ben-Gal, 2007 ). The nodes in V represent discrete or continuous random variables. A directed edge e A G from node X i to node X j that variable X j depends on X i . This dependency is quantified by the conditional probability distribution P  X  X i 9 Parents  X  X node in the network. Bayes Networks can encompass both, discrete and continuous variables. Thus, using appropriate meth-ods for inference, arbitrary probability distribution and density functions can be used. For instance, Cobb et al. (2007) introduce an inference procedure approximating arbitrary distribution by a set of exponential functions. In summary, the application of Bayes
Networks to describe the dynamics in the probabilistic model has some advantages:
The causal structure of Bayes Networks is usually easily defined by the engineers designing the mechatronic systems.
A number of learning algorithms is available to obtain the distribution from collected data for each variable in the net-works (for instance cf. Neapolitan, 2003 ). The learning pro-cesses are rather efficient, if the structure is known.
A predictive inference from the causes to possible results is possible, as well as diagnostic inference from the results to the possible reason.

An operation mode om in the probabilistic plan model consists of: asubset in om s D pre om , the input variables of the operation mode, a subset out om s D post om , the output variables of the operation mode, a set of Bayes Networks bn om o , one for each o A out om
Using one Bayes Network for each effect or output variable of an operation mode has an obvious drawback: no information about any conditional dependencies (induced by common pre-decessors in the graph) are encoded in the network. Thus, the probability of a random event P  X  o 1  X  x , o 2  X  y  X  is not exactly calculated. On the other hand, it is much easier to describe causal relationships regarding a single variable and the resulting Bayes
Networks are smaller and less complex, which is very important if because inference in Bayes Networks is NP hard ( Pearl, 1988 ). With the Bayes Networks, the application of an operation mode changes the probability distribution of the state variables in the next state of the plan. Fig. 4 illustrates how the probability distribution of state i are updated: The distribution of the input variables in om s are used as soft evidence in the Bayes Network. The
Bayes Network is updated (an inference procedure is executed) and the new probability distribution of the output variable o is obtained. The probabilistic plan representation is searched for relevant branching states for which an alternative plan should be generated. Two different types are distinguished: primary and secondary branching states. A primary branching state is a state where the next operation mode can likely not be performed or the application of the last operation mode does likely not result in the goal state. The likeliness is modeled by a threshold probability:
If the probability of a branching state is below this threshold probability, it will not be considered. These primary branching states can be identified by the probability of those state variable assignments which falsify the preconditions of the operation mode. From such a branching point, the planning process tries to alter the next operation mode and if necessary the subsequent operation modes. Thus, we call the branching plans from these states reactive , since they react to a development that causes the original plan to be infeasible. A secondary branching state is state which likely leads to a primary branching state. Thus, we call branching plans from these states proactive , since they try to avoid a development that leads to the infeasibility of the original plan. The secondary branching states are identified in a backward search from a primary branching state. The Bayes Nets are used to calculate the most likely explanation of the state variable assign-ments causing the infeasibility of the plan. This inference results in an updated probability distribution of the input layer. The assignment with the highest probabilities is the most likely one. If the probability of its occurrence and the subsequent conditional occurrence of the (primary) branching state is larger than the threshold probability, the procedure continues with the preceding state. The earlier a secondary branching point occurs in the plan, the larger is the number of feasible plans from this branching point because all subsequent states can be reached by not changing the plan. Thus, it is possible to identify better plans from an early branching point, or it might be the only possible way to obtain a plan with acceptable success probability. in a plan is calculated using the Bayes Networks provided with the probabilistic operation modes. The procedure basically runs from the initial state towards the goal state and updates the probability distribution using some inference procedure. The identified branching points are stored in a priority list, with their occurrence probability as priority. The state variable assignments are used as new initial states for the deterministic planning procedure.
Depending on the specific planning problem, changing the objec-tive function can facilitate the identification of robust plans (e.g. prioritize saving energy ). The resulting alternative plan is again subject of the probabilistic analysis. The new branching states are stored in the same priority list (their probability multiplied by the probability that the alternative plan is applied). The just-in-case planning process can work as an anytime algorithm and adds branches and alternative plans until the planning time expires.
This just-in-case planning fulfills several requirements of hybrid planning for mechatronics. Most important, the hybrid planning process can distinguish relevant and irrelevant plan deviations. A plan is only altered if the success of the execution is otherwise remarkably threatened. Furthermore, the diagnostic process works directly on the state variables instead of analyzing the waste number of possible external events. Finally, the plan-ning process uses a rich probabilistic representation of the influences towards plan execution.
 Listing 1. Calculation of probabilistic plan states.

AnalyzePlan s c /*first state*/ s n /*successor of s c */ o /*first operation mode in plan*/
Do while there is next operation mode in plan
End AnalyzePlan 5. Online planning
Given limited calculation time, the just-in-case planning cannot generate an alternative plan in every possible branching point with arbitrary probability. Thus, there might be situations where no alternative plan is available. Furthermore, the simula-tion can reject any operation mode shortly before it is to be executed (cf. Section 3.2.2 ).

For these reasons it is necessary to provide a planning strategy that is able to provide a decision about the next operation mode for execution in short time . To be more precise, the decision should be made in a guaranteed (real time) and rather small time period. For this reason, it is not possible to outsource this decision (different from the offline planning). Since the information processing in mechatronic system is usually implemented in embedded systems, the memory requirements of the planning process are important as well. Here, we introduce a general planning strategy, which is able to return the next operation mode without constructing a complete plan. Such algorithms are usually referred to as online planning algorithms . Although the first priority is to provide the next operation mode in time , a good solution quality is desired. Thus, the online planning strategy is extended to an anytime algorithm, which returns better results in occasions, where more time is available. 5.1. Related work on online planning
Most online planning algorithms are based on depth-first searches. In order to speed up planning and to achieve an acceptable solution quality good heuristics are required. For instance, Sapena and Onaindia (2002) introduce an online planning system called SimPlanner for PDDL 2.1. This planner uses heuristic a relaxed version of the planning problem. The planning problem is relaxed by ignoring the delete list of the actions. This problem independent heuristic works not in numeric domains and is thus not applicable to the mechatronic domain. If an admissible problem specific heuristic is available, it is possible to use real time search algorithms like Real Time A* ( Koening, 2001 ). If no adequate heuristics are available, online search algorithms cannot be applied. It has to be noted, that a heuristic for online planning should not only be admissible in the sense that it does not overestimate the distance to the goal state. Considering th eimportanceofreliabilityand availability in mechatronic domains it is even more important that it leads to a feasible plan. Unfortunately, in most mechatronic applications quality and reliability are conflicting objectives, espe-cially if energy is a concern: operation modes with a high quality usually consume more energy.

Another strategy to handle online planning problems can be found in the online solution of a partially observable Markov decision process (POMDP). Ross et al. (2008) introduce a general algorithm for solving POMDP online, or more precisely in anytime fashion. The basic idea is to search the tree, spanned from applicable actions and resulting state only locally. The generic algorithms explore the search tree level by level and continuously back propagate the revenues of each action to its ancestors. If the process stops (planning time is over) the action with the highest reward function is selected. Since the evaluation of the current selectable nodes depends only on a limited horizon (which is in extreme cases of size (1), the feasibility of the planning problem for mechatronic systems (the fulfillment of the task) cannot directly be considered in the solution process. 5.2. Knowledge based online planning
Fig. 5 illustrates the basic idea of knowledge based online planning. Two phases are considered. During the offline phase all computational extensive tasks are performed and the required knowledge is acquired. The process steps are performed before the actual planning process. Thus, there are no real time con-straints to be considered and the knowledge acquisition does not have to be performed on the limited computational resources within the mechatronic systems. During the online phase the knowledge is exploited for decision making. Knowledge based online planning can be split into six steps (cf. Fig. 5 ): 1. An offline planer solves a number of example problems optimally. 2. The resulting plans are processed to a set training data. 3. A classifier analyzes the training data and acquires the deci-sion knowledge encoded in the plans. 4. During plan execution, simulation rejects an operation mode or a relevant deviation occurs. 5. The classifier is informed about the current decision situation. 6. Provides a new operation mode and updates the plan.
The central element of knowledge based planning is the classifier. It acquires and provides the knowledge how to select an appropriate operation mode. Classification is a supervised machine learning technique and places individuals in predefined classes based on training set of already labeled individuals ( Witten and Frank, 2005 ). In knowledge based planning the classification task is to map a planning task (individual) on the first operation mode (class) in a feasible and good solution the planning task. A planning task consists of: An initial state vector s i A S .
 A goal state vector s g A S .

A set of applicable operation modes (not rejected by simulation).

The training data has to consist of a pair of planning task and operation mode executed in the initial state of the planning problem. This data is extracted from the solutions of the offline planner. Each generated plan encompasses several training instances. Each tuple of state, applied operation mode, applicable operation modes and goal state vector is a planning task.
A good classification result depends strongly on the selection of an appropriate attribute vector. An attribute can be any variable from s i or s g , any value calculated from these variables, and of course the applicable operation modes. The same attri-butes are extracted from the current state during operation and are the information provided to the classifier. The classifier returns an operation mode that is a good candidate. The time required to classify an individual depends on the selected classi-fier and the number of attributes and attribute characteristics. In any case, it is possible to determine a worst-case-execution time for a known classifier and classification problem. Thus, it can be guaranteed that the classifier satisfies the real time require-ments. 5.3. Knowledge based anytime planning
The classifier guesses what operation mode an optimal algo-rithm would select. Since the classification can be incorrect, the guess can be wrong. This implies two not desirable properties of the online decision making: it is neither optimal nor complete.
Hence, we introduce an anytime algorithm to alleviate these properties. If there is sufficient time, the anytime algorithm returns an existing feasible solution. The classifier used for the anytime algorithm has to be a probabilistic classifier, e.g. a naive
Bayes classifier. Given an individual, a probabilistic classifier determines the probabilities that the individual belongs to a class. Hence, the output of the classification process is a prob-ability distribution over the discrete random variable of member-ship to a class. This ambiguity is exploited in the anytime algorithm ( Listing 2 ). Initially the most likely operation mode for the given planning task is selected as temporary solution.
Subsequently, the algorithm continuously tries to construct plans which reach the goal state. For this purpose, the operation modes are randomly drawn from probability distribution defined by the classifier for each intermediate state in the planning process. If the algorithm succeeds constructing a feasible plan (it reaches the goal state) the first operation mode from this plan is the new temporary solution. Compared to the previous temporary solution it has the advantage to be known to be feasible. Afterwards, the temporary solution is only changed if the constructed plan is feasible and offers a better result than the previous temp-orary solution. The temporary solution can be returned at anytime.
 Listing 2. Knowledge based anytime planning.
 suitable method for the online planning: algorithm randomly explores the solution space of the planning problem. Given, that no applicable operation mode has in any state a probability of zero, the algorithm will finally (may be after a very long time depending on the problem size and the prob-ability distributions) explore the whole solution space. If so, it will find a feasible and optimal solution, if there is any. If the classification accuracy is high, the algorithm likely finds a very good solution quite fast.
 memory for the classifier and the applicable operation mode and never holds more than a single state (an n-dimensional vector) in memory. The memory of the classifier is O  X  PQ a i c i  X  with attributes a i and c i the number of characteristics of the i -th attribute. In the worst case the classification process has to search the whole data structure and thus requires as well O  X  PQ processing steps.
 6. Engineering case study  X  hybrid planning for the RailCab systems
In order to exemplify the general concepts introduced in the previous sections, this section specifies an use case based on the
RailCab system mentioned in the introduction. A RailCab encom-passes several innovative subsystems that are designed to per-form specific tasks. At the University of Paderborn exists a test track with three vehicles in scale 1:1.25 ( Fig. 6 ).
The use case will consider three of the subsystems: the propulsion module, the hybrid energy storage system, and in particular the active suspension module.

The active suspension module increases the comfort for the passengers. The basic idea of the suspension system is to omit passive dampers as they would transmit high-frequency distur-bances from the rail track to the coach body. So the body is connected to the carriage only via springs. The necessary forces to damp the coach body movement are generated by displacing the spring bases via hydraulic cylinders depending on the current movement of the body. However, in order to achieve a high degree of riding comfort the active suspension module consumes energy either transferred directly from the propulsion system or the hybrid energy storage system. The actual energy consumption of the active suspension module depends heavily on influences which cannot be exactly predicted, e.g. sudden wind blasts or the number of collisions between wheel and rail. This decision problem related to the trade-off between energy consumption and comfort cannot be reasonably solved without information about the intended travel of the RailCab. Thus, it is solved by the planning process on systems level. The operation modes of the active suspension module are extracted from a multi-objective optimization problem solved during the design phase (for details cf. V  X  ocking and Tr  X  achtler, 2008 ). The multi-objective optimization considers two objective function f 1  X  t  X  and f 2  X  t  X  : f  X  t  X  X  f  X  t  X  X 
The objective function in Eq. (1) is to be minimized in order to optimize the traveling comfort. It represents the weighted average body acceleration in vertical ( i  X  1) and lateral ( i  X  2) direction and the weighted angular acceleration in rolling direction ( i  X  3). The objective of minimizing the energy consumption is expressed in Eq. (2). It describes the average hydraulic power of all cylinders of the suspension module and can be mapped on a corresponding electrical energy consumption. For the case study nine different operation modes are derived from th e multi-objective optimization and these nine operation modes are defined for 10 different track types, where each track type possess an individual profile of track excitation resulting in a different relation between the energy consumption and provided comfort. Table 1 shows the operation points that are derived from this multi-objective optimization: ascending from operation mode a to i the value of f 1 (to be minimized) decreases, which also results in lower energy consump-tion. Track class I is the smoothest track type resulting in higher comfort values with lower energy consumption. Energy consump-tion and the value of f 1 increases with the higher track classes.
The primary power supply of the on-board electrical system of the RailCab is the power transfer via the doubly fed linear motor. However, this power transfer depends on the operating conditions, thus it may be limited and to some extent not sufficient. To offer a continuous power supply of the function modules of the RailCab, a hybrid energy storage system (HES) is installed on the vehicle.
It consists of a combination of nickel-metal hydride (NiMH) batteries and double layer capacitors. Its main task is to compen-sate for the difference between the transferred power of the motor and the demanded power of the modules ( Romaus et al., 2009 ).
The primary task of the batteries is to balance the energy difference on a larger time horizon, whereas the double layer capacitors is responsible to absorb sudden peaks in the demanded energy. The occurrence of such peaks cannot be predicted in long-terms since they largely depend on the environmental settings at the track sections. Thus, the trajectory of power transfer to the active suspension module is checked in detailed simulation, short time before the RailCab enters a track section. The analysis checks, if the power peaks exceed the current capabilities of the capacitors. If an operation mode is rejected, there is real-time decision making is required and thus the online planning approach is applied.
The propulsion system of the RailCab vehicles is realized by a doubly fed linear drive. This drive is able to transfer power from the stator into the vehicle, which leads to the omission of overhead contact lines or conductor rails. In the use case, the planning system makes no decision about the operation mode of the propulsion system. Instead, it is assumed that operates in a steady mode. However, the ability of the propulsion system to transfer energy into the board system is influenced by environ-mental factors. These environmental factors will be considered during the just-in-case planning .

The offline planning procedure is a modified breadth-first-search, which exploits the steadiness of the objective function in order to prune irrelevant search branches. It generates both the initial plan for the just-in-case planning and the training samples for online planning . Details about the search procedure can be found in Kl  X  opper et al. (2011) . 6.1. Just-in-case planning  X  experimental evaluation
In this case study the state of charge (SOC) of the system batteries is of primary interest. In order to use the just-in-case planning method to determine alternative sequences of operation modes for traveling along a number of track sections, we must model the energy consumption in a Bayes Network (the resulting comfort is assumed to be fixed). Fig. 7 shows the structure of the used Bayes Network. The influences towards the active suspension and the propulsion module are modeled in the network. The operation modes are derived from the Pareto set describing the possible behavior of the active suspen-sion (cf. Table 1 ), while the propulsion module operates in a fixed mode. Hence the sum of f 1 from Eq. (1) overall track sections is considered as objective function. However, for certain environmental influences an increased energy consumption of both suspension (e.g. due to strong wind blasts) and propulsion module (e.g. due number of passengers or snow on the track) up to 50% is assumed. three different instances of the Bayes Networks are used during simulation, resulting in combination in nine different classes of tracks. In the deterministic model the average energy consump-tion generated from the Bayes Networks was assumed. The probabilistic analysis as described in Section 4 determines rele-vant branches. To generate alternative plans, a heuristic changes the operation on the track section with the best energy-comfort trade-off, until the threshold probabilities is met.
 hypothesises: 1. H1.1 : A lower threshold probability and a higher number of 2. H1.2 : Since the plan analysis focuses on state probabilities 3. H1.3 : The just-in-case planning is sensitive against systematic sensitivity of the approach towards the application of inaccurate probability distributions during the plan analysis, experiments where simulated in four different scenarios: 1. ( 7 0%): The energy consumptions drawn from track networks Snow Temperature SOC Transfered Energy 2. ( 7 15%): The energy consumptions drawn from track net-works were decreased or increased by random value up to 15%. 3. ( 15%): The energy consumptions drawn from track networks were always decreased or by random value up to 15%. 4. (  X  15%): The energy consumptions drawn from track networks were always increased or by random value up to 15%.

While ( 7 0%) are idealized circumstances for the just-in-case planning; ( 7 15%) emulates noisy deviation which can be expected, e.g. from learning the probability distributions from historical data; ( 15%) emulates a systematic overestimation of energy consumptions and should result in over pessimistic plan and thus reduced plan quality; and (  X  15%) finally emulates a systematic underestimation of the energy consumption and should reduce the reliability of the just-in-case planning.
The method was applied to 80 randomly generated instances of planning problems with a track length between 25 and 35 sections. The generated plans were tested 100 times in a monte carlo simulation. After each simulation run, a new planning problem was generated with the exact environmental settings and according energy consumptions from the simulation and then solved optimally. This result is a definite upper bound for the plan quality. It is not possible to achieve better results for the probabilistic problem. The available SOC at the beginning of the planning problem was calculated by  X  min e c  X  X  min e with min the sum of the average energy consumption of operation mode f on each track section and c a random variable between 0.05 and 0.13. This results in a rather low SOC , making the generated problems sensitive to deviations from the average energy consumptions.

The experiments were performed with different settings: 1. The threshold probability varies between 0.01 and 0.4. 2. The number of alternative plans considered varies between 0 and 10. 3. During execution the system is allowed to turn back to the initial plan or not.

Fig. 8 shows the percentage of failed plan execution during the simulation runs for different scenarios. Fig. 8 (a) and (b) show the comparison regarding the scenario [ 7 0%] with and without returning to the initial plan. The procedure without return fails less often because it sticks to an alternative plan with a rather low failure probability whereas the procedure with return change back from the safe plan if the residual initial plan complies with the threshold probability. Furthermore, it can be seen that in accor-dance with H1.1 the two parameters threshold value and number of alternative plans reduce the number of failed plan execution significantly. Fig. 8 (c) shows the results for the scenario ( with returning to the initial plan. The only slight difference regarding the failure rate compared to figure (a) supports H1.2. The sensitivity of the just-in-case planning regarding systematic underestimation of energy consumptions can be seen in Fig. 8 (d): Intial
Intial 2 Intial
Intial 2 as assumed in H1.1, the number of failed plan execution is increased. Nevertheless, the just-in-case performs still better than the planning based on average values and both lower threshold value higher number of alternative plans reduce the number of failed execution.

Fig. 9 shows the resulting plan quality (in percentage of the upper bound problem). Only successful plan executions were considered. The comparison of Fig. 9 (a) and (b) shows an important difference between the strategies with and without returning to the initial plan. The strategy without returning shows a strong relationship between the threshold probability and the achieved plan quality. Here, the method generates an over-pessimistic plan and keeps executing it although there might be no threat anymore. The number of considered alternative plans has also an influence on the plan quality. Basically, the relation-ship is the following: the more branching points with a pessimis-tic alternative plan are considered, the more often these plans are applied during operation. Case (a) clearly shows that returning to initial plan, when the course of execution eliminated the threat, helps reduce this effect. The trade-off between threshold probability and number of plans is significantly weaker. Fig. 9 (c) shows again the results from the scenario with noisy deviation of the energy consumption when using the strategy with returning to the initial plan. According to H1.2, the difference in the result is very small. Fig. 9 (d) shows the result in case the energy con-sumption is systematically overestimated. The surface in the graph is similar to Fig. 9 (a) and (c), but is lower than the two other scenarios. Nevertheless, if the energy consumption is systematic overestimated, the just in case planning generates over pessimistic plans resulting in a lower level of plan quality in accordance with H1.3.
 just-in-case planning and support the three hypothesises. The confirmation of H1.1 regarding the increasing number of alter-native plans, supports the concept of just-in-case planning as anytime algorithms.
 for each track (including reading model files) and the time required to perform the first inference, calculating the probability distribution of each state in the standard plan. The largest part of initialization time is caused by reading XML files and is thus only slightly influenced by the problem size. As expected, the time to perform the first inference from the initial state towards the goals state depends on the problem size. Due to the rather compact probabilistic model, the calculation times increase rather slowly (almost linearly) with the problem size. (c) 2 2 (c)
Table 3 shows the calculation times 2 required by the heuristic to generate an alternative plan. As to expect, higher threshold probabilities reduce the average calculation time. The heuristic performs less changing operations to meet the threshold prob-ability. Interestingly, the maximal calculation time measured during the experiments is rather independent of the threshold probability. Obviously, specific properties of some problem instances are the reason: if a standard plan includes many possible change operations with a good trade-off between reduced energy consumption and reduced comfort, but small absolute energy reduction, the heuristic performs many changing operations regardless the threshold probability. 6.2. Online planning  X  experimental evaluation
The forecasting of power peaks requires exact knowledge about the continuous process and precise information about the environment. Both are not given during the planning process, but it is collected by information systems located at the track: the track section controls. Thus, the RailCab would use information provided by the next track X  X  section control for a simulation of the planned operation mode. Since the information has to be detailed and up-to-date, most times the simulation will start just before entering the next track. Time for planning is limited, in particular since every newly suggested operation mode can gain be rejected by the simulation. The experiments presented in this section are supposed to evaluate three hypothesises: 1. H2.1 : Knowledge based strategies outperform random exploration of the solution space. 2. H2.2 : As tendency, higher number of training examples should result in better planning results. 3. H2.3 : The application of a probabilistic classifier enables the implementation of an anytime algorithms. 4. H2.4 : Knowledge based strategies can be used to implement a real-time decision making.

In our experiments we randomly created a list of tabu opera-tion modes for every track section, the length of a planning problem varied between 25 and 35 track sections. The set of operation modes in the experiments corresponds exactly to the result of the multi-objective optimization of the active suspen-sion. This set has two important properties. First, the ranking of the operations modes regarding both objective values comfort f and the energy consumption f 2 is the same for each track section.
Hence, the selection of operation modes might be rather inde-pendent regarding the current track section, but strongly depend on the current state of charge. Secondly, the selection of the next operation mode is independent of the previous one. In other words, the list of possible successors of any operation mode encompasses the complete list of operation mode. In order to test the sensitivity of the online planning regarding these to properties, a second set was generated from the first set. To do so, the combinations of f 1 and f 2 were randomly changed exchanged between operation modes (eliminating the first prop-erties) and for each operation mode, up to three operation modes were removed from the list of possible successors. Due to this second property, the modified BFS procedure cannot solve the corresponding planning problems. Instead, the random strategy with 10,000 iteration was used to find a good plan. Thus, the second test offers a sensitivity analysis in regarding three criteria: (1) variable ranking of operation modes depend on the environ-ment, (2) restriction regarding the availability of operation modes, and (3) learning from a solution procedure with a non-systematic (randomized) behavior.

We compared four types of planning strategies, two of them knowledge based. The first planning strategy is the modified breadth-first-search procedure. This procedure knows all tabus in advance and generates the optimal plan, which is used as a reference value for quality achieved by the other planners. The second comparison strategy is a random anytime strategy. It randomly selects operation modes in several iterations and returns the best found plan. The first knowledge based strategy is a pure online strategy (only classification returning the next operation mode) and the anytime algorithms introduced in Section 3.2 . Thus, in the experiments concerning the online strategy the possibility to improve plan quality and reliability is never used. This extreme test setting reflects an unlikely worst-case scenario, where virtually no time for decision making is available. For both knowledge based strategies we used the naive Bayes classifier from the WEKA library (cf. Hall et al., 2009 ). The classifier considered the attributes number of track sections left, current SOC , current tabu modes and the frequency of the track types. The two anytime algorithms are analyzed regarding the relationship between the number of iterations and the solution quality. Solution quality is again measured as deviation from the only theoretically possible optimal plan (operation mode set A) or the best solution found by a random strategy with 10,000 iterations (operation mode set B).

Table 4 shows the impact of the number of training instances on the planning results for the two operation mode sets A and B. The knowledge based anytime algorithms with a different num-ber of improvement runs (e.g. KA 25 : Knowledge based Anytime with 25 iterations) are compared to the online strategy (KO) and the random strategy. For operation mode set A H2.1 is fully supported: in any configuration, the knowledge based anytime planning outperforms the random strategy. As well H2.2 is fully supported: more training examples result in a smaller deviation from the optimal solution. Regarding operation mode set B the tendency is not as clear: 15 example plans are not enough to outperform the random strategy. Obviously, this small training set is not representative for planning problem from set B. Never-theless, from 45 training examples H2.1 and H2.2 can be con-firmed. Both test scenarios show that the application of a probabilistic classifier enables the implementation of a anytime algorithm: in all cases a higher number of iterations result in smaller deviations from the optimal respectively the best solution found. The largest difference between the two operation modes sets occurs regarding the online algorithms: both the deviation from the optimal algorithms and the number of failed execution are considerably higher then with the original data set. The reason is obviously the additional limitation of applicability of operation modes, it is not possible to arbitrarily change to low energy modes if the SOC decreases. This results intensifies the impression that anytime algorithm and online algorithm should apply different learning strategies.

Regarding H2.4 the results are ambiguous. A higher number of training instances does not necessarily result in less failed online planning runs. Obviously, smaller training sets sometimes offer a better abstraction of the planning problem. The smaller number of training samples the more likely is a heterogeneous set. Thus, the classifiers feature space is only roughly represented in the train-ing set. As a result, generally applicable operation modes, which occur in more training sample, acquire higher probabilities. In large training sets, the probability distributions seem to reflect specific properties of the training samples, thus the information is less general and robust. Here, the anytime algorithm benefits from its ability to exploit the ambiguity of the classification results. In the experiments the anytime algorithm always found a feasible solution after a small number of iterations ( r 5).
Table 5 finally shows the calculation times of the different approaches. As one should expect, there is a linear correlation between the number of iterations and the required calculation time. For the online algorithm, the time to return a decision about the next step was measured, not the overall time to generate a plan. Using Java as implementation language, it was not possible to measure calculation times smaller than one milliseconds. The online decision making procedure always returned in less than one millisecond. This result confirms the real-time abilities of the approach: Although the standard Java edition and a classifier from the shelf were used, the experiments show a clear upper bound time for decision making. 7. Critical discussion and conclusion
This paper introduced planning as method for a decision making in mechatronic systems consider ing larger time horizons then classical adaptive mechatronic s ystems. Planning problems for mechatronic systems possess a strong continuous component. We pointed out that conventional discrete X  X ontinuous approaches are not appropriate to perform planning on the management level of a mechatronic system.

Hence, a practical and powerful architecture for planning in mechatronic system was introduced. It integrates several techni-ques from artificial intelligence and simulation in order to be able to produce reasonable discrete plans for mechatronics systems and execute them efficiently. The main building blocks in this architecture are a just-in-case-planning, simulation and an online planning approach.
 enables the mechatronic system to differentiate between relevant and irrelevant deviations which inevitably occurs. The simulation analyzes the continuous character of the selected operations and prevents the system from the execution of possible disadvanta-geous operations. If deviations occur which are a threat to successful and corresponding alternative is proactively created or if the simulation rejects an operation on short notices, the online planning approach is able to make decisions in real time.
Since the online planning acquired knowledge from an optimal planning algorithms, it takes good decisions in most cases. All planning techniques were presented in an use case from the railway system RailCab. Results show that the hybrid planning architecture is a promising approach to enhance mechatronic systems by long-term planning capabilities.
 paper is only a first step towards proactively acting mechatronic systems. Currently, the approach is limited to closed planning horizons by the required definition of goal state. Actually, meach-tronic systems will frequently encounter open horizons ,wherefor instance new jobs appear constantly. An extension towards Markov decision process, e.g. to determ ine a reasonable goal state for the current job seems promising and will be investigated. A second issue is the consideration of systems with a less structured environments such as cars. Current strategies for discretizing environment and actions have to be adapted. Another, to our experience minor limitation is the restriction of the planning domains on numerical state variables. Nevertheless, th ere might be mechatronic planning domains where the consideration of propositional state attributes is important. The results from onli ne planning show that the approach is feasible, but also indicate possible improvement regarding the online decision making. Here, ex tending the learning process towards robust training examples has to be investigated. tive reasoning beyond the decision horizon of conventional feed forward controls offers new levels of utility, flexibility and robustness for mechatronic systems.
 Acknowledgments borative Research Center 614  X  X  X elf-Optimizing Concepts and Structures in Mechanical Engineering X  X  funded by the German Research Foundation (DFG).
 References
