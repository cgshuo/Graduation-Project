 Advances in neural network language models have demon-strated that these models can effectively learn representa-tions of words meaning. In this paper, we explore a varia-tion of neural language models that can learn on concepts taken from structured ontologies and extracted from free-text, rather than directly from terms in free-text.
This model is employed for the task of measuring semantic similarity between medical concepts, a task that is central to a number of techniques in medical informatics and informa-tion retrieval. The model is built with two medical corpora (journal abstracts and patient records) and empirically val-idated on two ground-truth datasets of human-judged con-cept pairs assessed by medical professionals. Empirically, our approach correlates closely with expert human assessors (  X  0.9) and outperforms a number of state-of-the-art bench-marks for medical semantic similarity.

The demonstrated superiority of this model for providing an effective semantic similarity measure is promising in that this may translate into effectiveness gains for techniques in medical information retrieval and medical informatics (e.g., query expansion and literature-based discovery).
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval] General Terms: Theory, Experimentation, Measurement Keywords: Neural Language Model; Skip-gram; Distributed Representations; Word2Vec; Semantic Similarity; Medical Information Retrieval.
A variety of neural network-based methods have emerged as effective approaches for generating representations of words [ 4, 16, 12]; these are referred to as neural language models. These methods learn word embeddings based on the opti-misation of an objective function. The term  X  X ord embed-dings X  generally refers to representations for words occupy-ing a real valued vector space where the similarity between linguistic units) can be modelled as a function of the degree of overlap of their linguistic contexts. In practice, the counts of contextual features are generally accumulated into a term-context matrix and a transformation is then applied which re-weights the accumulated counts.

Neural language models also construct representations for terms based on linguistic contexts; however, they do so by optimising an objective function involving the target term and its linguistic context. The representations produced are often called X  X ord embeddings X . Word embeddings were first developed in the context of language modelling to overcome some of the well known problems relating to data spar-sity that existed with n-gram based language models [ 4]. While NLMs were originally developed to model sequential term dependencies departing from the n-gram approach, a by-product of these models is that the constructed word representations were found to have useful semantic prop-erties [ 11]. NLMs have more recently been employed for a large variety of natural language processing tasks, such as semantic role labelling, part-of-speech tagging, chunking, sentiment analysis and named entity recognition [ 7, 13]; they were found to be as good as, or better than, other state-of-the-art methods.

A particular instance of a NLM is the continuous Skip-gram model of Mikolov et al. [ 11]. The Skip-gram model constructs term representations by optimising their ability to predict the representations of surrounding terms. In this paper, we evaluate the continuous Skip-gram model on the task of predicting the semantic similarity of concept pairs. We employ the Skip-gram model in a way not previously seen in the literature; specifically, we use it to learn embed-ding vectors for concepts taken from structured ontologies rather than for terms. While previous work has considered the use of compound terms (e.g., named entities) in NLMs [13], these compound terms are not actually used as features; in addition, ontology concepts have not been used (to our knowledge).

Given a sequence W = { w 1 ,...,w t ,...,w n } of training words, the objective of the Skip-gram model is to maximise the following average log probability where r is the context window radius. The context window radius determines which words surrounding the target term w t are considered for the computation of the log probability; the window is centred around the target term. The proba-bility of an output word is computed according to where the v w I and v w O are the vector representations of the input and output vectors, respectively, and W w =1 exp( v w ,v w I ) is the normalisation factor, whose role is to normalise the inner product results across all vocabulary words ( W is the vocabulary size). In practice, a hierarchical approximation to this probability is used to reduce computational complex-ity [ 11]. At initialisation, the vector representations of the words are assigned random values; these vector representa-tions are then optimised using gradient descent with decay-ing learning rate by iterating through sentences observed in the training corpus.
 Cav datasets. Three concepts appearing in the Ped dataset were not found in the translated corpora (two in Medtrack and one in OHSUMED) and were, therefore, removed. 1
A number of other corpus-based measures of semantic sim-ilarity were included as benchmarks for comparison against the neural language model approach: 1. Random Indexing (RI) 2. Latent Semantic Analysis (LSA) 3. Document Vector Cosine Similarity (DocCosine) 4. Positive Pointwise Mutual Information (+PMI) 5. Cross Entropy Reduction (CER) 6. Language Model + Jensen-Shannon divergence (LM A previous evaluation of the above models on the same task found that these were the most effective in terms of correla-tions with human judges [ 9]. We refer the reader to [ 9]for a description of each method. For the benchmark comparison methods (e.g., RI and LSA) we selected the parameter settings, e.g., latent space dimensionality, that produced the highest correlations with human experts as reported in previous work [9] 2 .
For the Skip-gram NLM, we adopted the word2vec im-plementation provided by Mikolov et al. [ 11] 3 .Weusedthe hierarchical soft-max classification layer and set the  X  X in-count X  parameter to 1, thus effectively not excluding any concept occurrence from the computation of statistics. Each corpora was processed using only one thread so that process-ing was purely sequential. We studied the effect of window
Removed concepts were C0702166, C0224701, C0029456 .
Tested dimensionalities: 50, 150, 300 and 500. http://word2vec.googlecode.com/ . does not seem to detriment NLM X  X  performance when con-sidering the Cav dataset.

We now consider how window radius and embedding di-mensionality affect performance of the studied NLM. We found that the best performing model was the Skip-gram model with the largest dimensionality and window radius. Overall we found that increasing both the embedding dimen-sionality and the window radius helped to improve perfor-mance, with larger window radius contributing more than larger dimensionalities. While not true in every case, the overall trend suggests as a guideline for building NLM mod-els for this tasks, that vectors with larger window radius and larger embedding dimensionality should be used.

The empirical results highlight that the investigated Skip-gram NLM constructs representations for concepts that, when used as a measure of semantic relations, strongly correlate with semantic similarity judgements provided by medical experts. We conjecture that the predictive nature of the objective function used by the considered Skip-gram NLM is the core feature that produces such strong performance. The validation of this intriguing conjecture would require further investigation; this is left for future work.
Neural network language models (NLM) have recently at-tracted attention because of promising results obtained in a number of natural language processing tasks, e.g., semantic role labelling and sentiment analysis, among others. The in-tuition behind these models is that effective representations that synthesise word meaning can be learnt by iteratively ob-serving word occurrences in the close surroundings of target words along with the optimisation of a task-specific function. In this paper, we have explored a variation of a specific NLM approach, the Skip-gram model, applied to the task of measuring the semantic similarity between medical concepts. While the traditional Skip-gram model creates distributed vector representations of words, the model in this study leverages distributed representations of UMLS concepts ex-tracted from medical corpora, including clinical records and medical journal abstracts.
 Empirical findings demonstrate that the concept-based Skip-gram NLM correlates more strongly to expert judge-ment of semantic similarity than established benchmark ap-proaches. Window radius in primis , along with embedding dimensionality, are factors that influence performance, with representations learnt with larger radius and dimensionali-ties more strongly correlating with expert judgements.
This work opens up a number of avenues for future re-search. One important research question is why the predic-tive nature of the objective function used by the Skip-gram NLM is conducive of such strong performance. We also con-jecture that the use of  X  X ixed X  features, e.g., learning repre-sentations from both term and concept corpora, may result in further improvements. Another factor that may influence performance is the ordering of the training data, consider-ing that the importance of data samples varies according to the learning rate parameter included in the gradient descent procedure. [1] P. Agarwal and D. B. Searls. Can literature analysis
