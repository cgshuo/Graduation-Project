 This paper predicts the stabilized tag set of a resource, with feedback of a small amount of us er annotations, aiming to reduce the requirement of sufficient user annotations and to resolve the cold-start problem in a social annotation system. H.3.3 [Information Storage and Retr ieval]: Information Search and Retrieval; H.4.m [Information Systems]: Miscellaneous; H.5.3 [Group &amp; Organizational Interf aces] Collaborative Computing Design, Experimentation, Performance Social Annotation, Spreading Activation, Tag Prediction With the progress of web 2.0, a variety of services promote web users from traditional information receivers to influential information propagators and even information sources. Social bookmark sites such as del.icio.us (http://del.icio.us) and Flickr (http://www.flickr.com) provide su ch web 2.0 services. Recently, applications and analyses of so cial annotations have attracted much more attentions [1][3][4]. We observe that limitations on the effectiveness of applying social annotations include: i) the requirement of sufficient annotations for a target resource; ii) the cold-start problem for resources newly arriving. To deal with the two issues, we design a supervised tag prediction model to predict the stabilized tag set for a target resource, with feedback of a small amount of user annotations. Prediction of a stabilized tag set needs a complex model to capture how users make inference from a resource to its tags. Some researches [1][4] indicate three important characteristics in a social annotation system, i.e., i) keywor ds in a resource are usually selected as tags by annotators; ii) similar resources are usually annotated by similar tags; iii) shared background knowledge and imitative annotation be tween users would take influence on annotation activities. The basic idea of the proposed prediction model follows these characteristics. The following section describes the framework and the details of our model. Our model predicts the stabilized tag set of a testing URL which has been annotated by severa l early users. The prediction algorithm is composed of two parts. In the first part (Section 2.1), we select candidate tags from the terms in the text content of a testing URL. We train a supervised scoring function from the training data to rank terms in th e text. In the second part (Section 2.2), we combine the early annotations for the testing URL with the candidate tags, and then perform spreading activation [5][6] on a tag-correlation graph to find tags highly correlated to the combined tag set. Equation 1 is employed to score terms in a document (URL text content) for content tag selection. The basic idea of the scoring function follows the statistical translation model in information retrieval [2], which estimates the probability that a query would be generated as a translation of a document. In Equation 1, P C ( t i | term j ) denotes the probability of t stabilized tag, i.e., a tag included in the stabilized tag set, when t and term j co-occur in the same document. N denotes the number of documents in the training data. P C ( t i | term Maximum Likelihood Estimation (MLE) over the training data. Assume D j is the set of documents where term j the set of documents in D j with t i as a stabilized tag. Let P  X  | D j,i | / | D j |. If P C ( t i | term j ) is not 0, then P naturally as equal to or larger than 1/ N . All terms in the document are ranked according to their scores. The content tag selection score of t i will be normalized and then used as the initial activation score of t i in the spreading activation of our prediction algorithm. A tag-correlation graph is construc ted for tag spreading activation. The tag-correlation graph is a network in which nodes represent tags and the edge(s) betwee n two nodes represents their containing t j also contain t i , is a asymmetric correlation representing the strength of the edge from t j to t graph. We also estimate P T ( t i | t j ) by MLE over the training data. The basic idea of spreading activation can be explained by a natural phenomenon. When we drop a stone into a pond, oscillation on surface transfers energy to neighborhood and becomes smaller and smaller in amplitude. Equation 2 and neighbors. At each iteration, node t j propagates a portion ( energy to its neighbors, and gains some energy from its neighbors too. In our experiments, spread ing activation is performed for a fixed number of iterations and ev entually tags of the highest energies are proposed as the predicted stabilized tags. A tag is an activation origin if it is a selected candidate content tag or if it is an early user-annotat ed tag. Except those activation origins, we initialize the energy for each tag to 0. For each energy E ( t i ) is its content se lection score CTScr( t by the highest content selection score of terms co-occurring with t in d . For each of the early user-annotated tags, the initial energy is its total tagging by early users. Fo r a content tag also annotated by early users, its initial energy is the sum of these two values. Our corpus is crawled from del.icio.us. In the corpus, total 15,934 URLs received more than 100 annotations form a sufficiently-annotated set. Total 2,000 URLs are randomly selected from this set as the testing data . Because the remaining URLs of the sufficiently-annotated set are not large enough for training, we increase the amount of traini ng data by 45,156 more URLs annotated by at least 20 users. For each URL in the training and testing sets, the stabilized tag set consists of the top 25 common tags of the highest frequencies. We use MAP, R-Precision and Re call rate to evaluate the performance of our tag prediction algorithm. The top 50 tags with the highest scores are proposed as the stabilized tags. Table 1 shows the performances of combining the results of content tag selection with the resu lts of different numbers of early user annotations. CTScr denotes content ta g selection only and User-n denotes n user annotations only. Combining CTScr with early user annotations always significantly improves the performance, no matter whether 5 or 10 early annotations are combined. It shows that the CTScr complements the early user annotations. CTScr tends to highly score a candidate tag that frequently occurs in the training data. Users tend to annotate the target URL with impressive an d singular terms, which may less frequently occur in the training data . Table 1 also indicates that a large portion of the stabilized tag set can be predicted with a small amount of early annotations, i. e., around 40% predictable with only 5 user annotations. Table 1. Performance of the content tag selection combined with early user tags Method R-Precision Recall MAP CTScr 0.2687 0.3569 0.1768 User-5 0.2359 0.2343 0.2077 CTScr + User-5 0.3972 0.4733 0.3439 User-10 0.3445 0.3436 0.3025 
CTScr + User-10 0.4591 0.5360 0.4154 Figure 1 shows the performances in R-Precision on the testing set under different parameter settings, i.e.,  X  in Equation 2 and number of iterations in spreading activation. Here the activation origins are initialized by User-5 combined with CTScr. Figure 1 shows that the peak performances with different values of very similar, while the curve of a larger  X  shows more gradual. When  X  is set to be 0.5, the performance in R-Precision of CTScr is improved from 0.3972 (see Table 1) to 0.4493 after 2 iterations of spreading activation. The relati ve improvement is 13.1% and is also significant. Recall and MAP are improved to 0.6072 and 0.3879, respectively. With spr eading activation, the relative improvement in Recall is the largest (28.3%). 
R-Precision Figure 1. Performance of th e tag prediction model with different parameters in the spreading activation In this paper, we propose a prediction model for social annotation, aiming to predict the stabilized tag set of a web resource with a small amount of early user anno tations. The experiment results show that our tag prediction model is able to predict a considerably large portion (~45%) of the stabilized tag set with only 5 user annotations. More sophi sticated approaches to estimate scoring functions are necessary in the future work. Research of this paper was partially supported by Excellent (97R0062-AE00-02) and Microsoft Research Asia (FY08-RES-THEME-087). [1] Bao, S. et al. Optimizing web s earch using social annotations. [2] Berger, A. and Lafferty, J. Information retrieval as statistical [3] Golder, S.A. and Huberman, B.A. Usage patterns of [4] Halpin, H. et al. The complex dynamics of collaborative [5] Hsu, M.-H., Tsai, M.-F., Chen, H.-H. Combining WordNet [6] Salton, G. and Buckley, C. On the Use of spreading activation 
