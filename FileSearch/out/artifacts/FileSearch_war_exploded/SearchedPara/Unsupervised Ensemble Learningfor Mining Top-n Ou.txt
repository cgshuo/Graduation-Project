 Outlier detection is an important knowle dge discovery problem in finding unusual events and exceptional cases from large data sets in many applications such as stock market analysis, intrusion detection, and medical diagnostics. Over the past several decades, the research on outlier detection varies from the global computation to the local analysis, and the descriptions of outliers vary from binary interpretations to prob-abilistic representations. Global outlier detection [3,4,5] identifies an observational ob-ject with a binary label by the global computation. Local outlier detection [6,7,8,9] provides a probabilistic likelihood called outlier score to capture how likely an object is considered as an outlier. Outlier scores can be used not only to discriminate outliers from normal data, but also to rank all the data in a database, such as the top-n outlier detection. There are other efforts that transform the unsupervised outlier detection to a classification via artificially generated outliers [10].

Although there are numerous outlier detec tion methods proposed in the literature, no one method performs better than the others under all circumstances, and the best method for a particular dataset may not be known a priori. Each detection method is proposed based on the specific priori knowledge. For example, the nearest neighbor based methods assume that the feature sp ace is well enough to discriminate outliers from normal data, while the classification based and the statistical methods need to suppose the distributions of outliers and norma l objects, respectively. Hence, their de-tection performances vary with the nature o f data. This setting motivates a fundamental information retrieval problem -the necess ity of an ensemble learning of different de-tection methods to overcome their drawbacks a nd to increase the generalization ability, which is similar to meta-search that aggregates query results from different search en-gines into a more accu rate ranking. Like meta-search , ensemble learning in the top-n outlier detection is more valuable than the fusion of the binary labels, especially in large databases. There is the literature on the ensemble learning of outlier detection, such as [13,14,15]. However, all these efforts state the problem of effectively detecting outliers in the sub-feature spaces. Since the work of L azarevic and others focuses on the fusion of the sub-feature spaces, these methods are v ery demanding in requiring the full spec-trum of outlier scores in the datasets that prevents them from the fusion of the top-n outlier lists in many real-world applications.

Although the problem of ensemble learni ng in the top-n outlier detection shares a certain similarity to that of meta-search , they have two fundamental differences. First, the top-n outlier lists from various individua l detection methods include the order infor-mation and outlier scores of n most outstanding objects. Different detection methods generate outlier scores in different scales. This requires the ensemble framework to pro-vide a unified definition of outlier scores to accommodate the heterogeneity of different methods. Second, the order-based rank aggr egation methods, such as Mallows Model [18], can only combine the information of the order lists with the same length, which prevents the application of these rank aggr egation methods in the fusion of top-k outlier lists. Because, for a particular dataset, there are always several top-k outlier lists with various length used to measure the performance and effectiveness of a basic outlier de-tection method. In order to address these issues, we propose a general framework of ensemble learning in the top-n outlier detection shown in Figure 1, and develop two fusion methods: the score-based aggregation method ( SAG ) and the order-based ag-gregation method ( OAG ). To the best of our knowledge, this is the first attempt to the ensemble learning in the top-n outlier detection. Specifically, the contributions of this paper are as follows:  X  We propose a score-based aggregation method ( SAG ) to combine the top-n outlier  X  We propose an order-based aggregation method ( OAG ) based on the distanced- X  Extensive experiments on real datasets va lidate the effectiveness of these aggre-The remainder of this paper is organized as follows. Section 2 introduces the framework of ensemble learning in the top-n outlier detection and the two novel aggregation meth-ods: the score-based and the order-based methods. Section 3 reports the experimental results. Finally, Section 4 concludes the paper. We first introduce the general framework and the basic notions of ensemble learning in the top-n outlier detection, and then intr oduce the score-based method with a unified outlier score and the order-based method based on the distance-based Mallows model, respectively. 2.1 Framework and Notions of Ensemble Learning Let X =[ x 1 ,x 2 ,x 3 ,...,x d ] be an object in a dataset D ,where d is the number of attributes and | D | is the number of all the objects.

As shown in Figure 1, there are K individual detection methods that process the orig-inal data in parallel. Essen tially, all the individual methods return outlier scores rather than binary labels to generate the top-n outlier lists, where the number n is determined by users. The top-n outlier list  X  i assigned to the i -th individual method is represented assigned to object X i .Let R n be the set of all the top-n orderings over | D | objects, and d : R n  X  R n  X  X  X  R be the distance between two top-n lists, which should be a right-invariant metric. This means that the value of d (  X ,  X  ) | X   X ,  X   X  R n does not depend on how objects are indexed.

The aggregation model combines K orderings {  X  i } K i =1 to obtain the optimal top-[13,14,15] can be included in this framework by using the detection model in a special sub-feature space as an individual method. In this paper, we only focus on the unsuper-vised aggregation models based on the order information and outlier scores. 2.2 Score-Based Aggregation Approach (SAG) Since a top-n outlier list  X  i contains the order informatio n and the corresponding outlier scores, it is straightforward that combining these outlier scores from different meth-ods improves the detection performance. As mentioned in the previous section, outlier scores of the existing methods have differen t scales. For example, outlier scores vary from zero to infinity for the nearest based method [6], while lying in the interval [  X  1 , 1] for the classification based method [10]. I n this subsection, an effective method is pro-posed to transform outlier scores to posterior probability estimates. Compared with outlier scores, the posterior probability based on Bayes X  theorem provides a robust esti-mate to the information fusion and a spontan eous measure of the uncertainty in outlier prediction. Without loss of generality, we assume that the higher S ( i ) , the more proba-ble X i to be considered as an outlier. Let Y i be the label of X i ,where Y i =1 indicates that X i is an outlier and Y i =0 if X i is normal. According to Bayes X  theorem, P ( Y i =1 | S ( i )) = function that classifies X i as normal or outlier. Hence, ln  X  ( i ) can be simplified to a linear function, proportional to the Z-Score of S ( i ) as follows: where  X  and std are the mean value and standard deviation of the original outlier scores, respectively. In large datasets, these statis tics can be computed by sampling the original X i can be assigned as an outlier. In all the experiments, the default value of  X  equals 1 . 5 based on Lemma 1.
 Lemma 1: For any distribution of outlier score S ( i ) , it holds that Proof: According to Chebyshev X  X  inequality, it holds that , Lemma 1 shows a loose bound of deviation proba bility regardless of the distribution of outlier scores. Supposing that outlier s cores follow a normal distribution,  X  =1 . 5 means that much less than 10% of the objects deviate from the majority of data, which follows the definition of Hawkins outlier [1].

For a top-n outlier list  X  i , objects in the dataset may not be ranked by  X  i .Thesimple average posterior probabilities are not appropriate to the top-n ranking aggregation. Clearly, objects that appear in all the ranking lists should be more probable to be outliers than ones that are only ranked by a single list. Hence, we apply the following fusion rules which are proposed by Fox and Show [12]. where n d is the number of the orderings that contain object X i and rel j ( i ) is the nor-malized outlier score of X i by the j -th individual method. When r =1 , the ultimate outlier score is composed of the number of the orderings n d and the sum of its outlier scores. When r =0 , the result is only the sum of its outlier scores. When r =  X  1 , it is equivalent to the average outlier scores of the orderings containing X i . According to Eq. 1 and Eq. 2, the posterior probabilities can be used to normalize outlier scores directly. The detailed steps of SAG are shown in Algorithm 1.
 Algorithm 1. Score-based aggregation method ( SAG ) 2.3 Order-Based Aggregation Approach (OAG) Given a judge ordering  X  and its expertise indicator parameter  X  , the Mallows model [16]generates an ordering  X  given by the judge according to the formula: where According to the right invariance of the distance function, the normalizing constant Z (  X ,  X  ) is independent of  X  , which means Z (  X ,  X  )= Z (  X  ) . The parameter  X  is a non-positive quantity and the smaller the value of  X  , the more concentrated at  X  the ordering  X  .When  X  equals 0 , the distribution is uniform meaning that the ordering given by the judge is independent of the truth.
 An extended Mallows model is proposed in [17] as follows: where  X  =(  X  1 ,  X  X  X  , X  K )  X  R K n ,  X  =(  X  1 ,  X  X  X  , X  K )  X  R K , P (  X  ) is a prior, and the normalizing constant In this extended model, each ordering  X  i is returned by a judge for a particular set of objects.  X  i represents the expertise degree of the i -th judge. Eq. 6 computes the probability that the true ordering is  X  , given the orderings  X  from K judges and the degrees of their expertise.

Based on the hypothesis of the distance-ba sed Mallow model, we propose a genera-tive model of OAG , which can be described as follows: Thetruelist  X  is sampled from the prior distribution P (  X  ) and  X  i is drawn from the Mallows model P (  X  i |  X  i , X  ) independently. For the ensemble learning of top-n outlier lists, the observed objects are the top-n outlier lists  X  from various individual detection methods, and the unknown object is the true top-n outlier list  X  . The value of the free parameter  X  i depends on the detection performance of the i -th individual method. The goal is to find the optimal ranking  X  and the corresponding free parameter  X  i which maximize the posteriori probability show n in Eq. 6. In this work, we propose a novel EM algorithm to solve this problem. For obtaining an accurate estimation of  X  i by the EM-based algorithm, we construct the observed objects by applying several queries the parameter  X  =(  X  1 ,  X  X  X  , X  K ) by considering the information of different scales. In this paper, the default value of Q is 4 and the lengths meet the following requirement: N q = q 2.4 Inference and Algorithm for OAG The EM algorithm is widely used for finding the maximum likelihood estimates in the presence of missing data. The procedure includes two steps. First, the expected value of the complete data log-likelihood with respect to the unobserved objects  X  = {  X  q |  X  q  X  R estimate  X  =(  X  1 ,  X  X  X  , X  K ) . Second, compute the optimal parameter  X  that maximizes the expectation value in the first procedure. According to the Mallows model and the extended Mallows model, we have the following Lemmas: Lemma 2: The expected log-likelihood  X  (  X  ,  X  ) meets the following formula where Lemma 3: The parameter  X  maximizing the expected value  X  (  X  ,  X  ) meets the following formula:
The proofs for Lamma 2 and Lamma 3 are omitted due to lack of space. As shown in Lamma 3, the value of the right-hand side of Eq. 12 and the analytical expression of the left-hand side should be evaluated under the appropriate distance function to ob-tain the optimal  X  . Before introducing the detailed procedure of our EM-based learning algorithm, we bring in an effective distance function d (  X ,  X  ) between the top-n order-ings  X  and  X  , which is proposed in [18]. To keep this work self-contained, this distance function is introduced as follows.
 Definition 1: Let F  X  and F  X  be the elements of  X  and  X  respectively. Z = F  X   X  F  X  with | Z | = z . P = F  X  \ Z , and S = F  X  \ Z (note that | P | = | S | = n  X  z = r ). Define the augmented ranking  X   X  as  X  augmented with the elements of S assigned the same index n +1 . Clearly,  X   X   X  1 ( n +1) is the set of elements at position n +1 (  X   X  is defined similarly). Then, d (  X ,  X  ) is the minimum number of the adjacent transpositions needed to turn  X   X  to  X   X  as follows, where I ( x )=1 if x&gt; 0 , and 0 otherwise. where
V i (  X   X ,  X   X  )=
U i (  X   X ,  X   X  )= In each iteration of the EM process,  X  is updated by solving Eq. 12. Based on Definition 1, E  X  i ( d (  X  q , X  i q )) is computed as follows: This function is a monotonous function of the parameter  X  i . For estimating the right-hand side of Eq. 12, we adopt the Metropolis algorithm introduced in [2] to sample from Eq. 6. Suppose that the current list is  X  t . A new list  X  t +1 is achieved by exchanging the objects i and j , which are randomly chosen from all the objects in  X  t .Let r = accepted with the probability r . Then,  X  can be computed by the line search approach with the average z of the samples. The steps of OAG are shown in Algorithm 2. Algorithm 2. Order-based aggregation method ( OAG ) We evaluate the aggregation performances of SAG and OAG methods using a number of real world datasets. We measure the robust capabilities of SAG and OAG methods to the random rankers, which are generated based on the Uniform distribution and the Gaussian distribution, respectively. 3.1 Aggregation on Real Data In this subsection, we make use of several state-of-the-art methods, including LOF [6], K-Distance [3], LOCI [7], Active Learning [10], and Random Forest [11] as the individ-ual methods to return the original top-n outliers lists. Since the performances of LOF and K-Distance depend on the parameter K that determines the scale of the neighbor-hood, we take the default value of K as 2 . 5% of the size of a real dataset. Both LOF and LOCI return outlier scores for each dataset based on the density estimation. However, K-Distance [3] only gives objects binary labels. Hence, according to the framework of K-Distance , we compute outlier scores as the distance between an object and its K th nearest neighbor. Active learning and Random Forest both transform outlier detection to classification based on the artificial outliers generated according to the procedures pro-posed in [10]. These two methods both compute outlier scores by the majority voting of the weak classifiers or the individual decision trees.

The real datasets used in this section consist of the Mammography dataset, the Ann-downloaded from the UCI database ex cept for the Mammography dataset. 1 Ta b l e 1 summarizes the documentations of these real datasets. All the comparing outlier de-tection methods are evaluated using precision and recall in the top-n outlier list  X  as follows where TN is the number of outliers in ordering  X  , AN is the length of  X  ,and ON is the number of outliers in the dataset. For the quantity AN equals ON in this work, precision has the same value with recall . Hence, only precision is used to measure the performance of each compared method in this section. Clearly, if all the objects in  X  are outliers, its precision and recall both achieve the maximum value 100% .The Breadth-first and Cumulative Sum methods proposed in Feature Bagging [13] are used as the baselines. For Feature Bagging does not introduce how to normalize heterogeneous outlier scores, the original outlier scores are processed by the typical normalization method: S norm ( i )= S ( i )  X  mean std ,where mean is the average score of all the objects and std is the standard deviation of outlier scores. Besides, Cumulative Sum requires that every object should be given an outlier score by every individual method. However, for the top-n outlier lists, some objects lying in the ordering  X  i may not be ranked by  X  . This means that Cumulative Sum cannot be applied in the fusion of the top-n outlier lists. Hence, we replace the sum of all the outlier scores with the average of the outlier scores from the individual methods containing the corresponding object for Cumulative Sum .The Mallows Model [18] is also used as the baseline. As discussed in the previous section, for this algorithm can not combine the basic lists  X  with various lengths to achieve the true list  X  , it needs to use all the datasets to compute the expertise indicator parameter  X  .

Table 2 lists the experimental results of the individual methods and all the aggre-gation methods. Figure 2 shows the pos terior probability curves based on SAG for the individual methods on the Mammography dataset. It is very clear that different detection methods have different scales of outlier sco res and posterior pr obability computed by SAG is a monotonic increasing function of outlie r scores. In the individual method pool, LOF achieves the best performance on the Mammography and the Shuttle-2 datasets, and K-Distance achieves the best performance on the Shuttle-1 dataset. LOCI detects the most outliers on the Coil 2000 dataset with Active learning . Random Forest is supe-rior to the other methods on the Ann-thyroi d and Shuttle-3 datasets. However, none of the outliers is detected by Random Forest on the Shuttle-1,2 datasets. The above results have verified the motivation that there is a need of ensemble learning in the top-n outlier detection.

From Table 2, we see that SAG with r =1 and SAG with r =0 achieve the similar performance on all the real datasets. Clearly, for the probability-based SAG method, the number n d of the individual top-n outlier lists contributes little to the final fusion performance. Compared with the above aggregation methods, the performance of SAG with r =  X  1 varies with the nature of the data dramatically. SAG with r =  X  1 achieves the best performance on the Coil 200 dataset. However, it performs more poorly than SAG with r = { 1 , 0 } and OAG on the other datasets. This demonstrates that the average of the unified outlier scores does not adapt to the fusion of the top-n lists. In general, since outlier scores are always either meaningless or inaccurate, the order-based ag-gregation method makes more sense than the score-based method. OAG achieves the best performance than SAG on the Mammography, the Ann-thyroid, and the Shuttle-1,3 datasets. Both Cumulative Sum and SAG are score-based fusion methods. Table 2 shows that the performance of SAG is more stable and effective, especially SAG with r =1 . Breath-first , Mallows Model ,and OAG are all the order-based fusion methods. Although Breath-first can be used in the aggregation of top-n outlier lists, it is sensitive to the order of the individual methods. Mallows Model supposes that there is a fixed expertise indicator parameter  X  for an individual method regardless of the nature of the data. Experiment results indicates that this hypothesis is not appropriate for the en-semble learning in the top-n outlier detection. Overall, SAG and OAG both achieve the better performances than Average of All and the aggregation methods Breadth-first , Cu-mulative Sum and Mallows Model , which means that the proposed approaches deliver a stable and effective performance independe nt of different datasets in a good scalability. 3.2 Robustness of Two Aggregation Methods In this subsection, the goal is to examine the behavior of the SAG and OAG methods when poor judges are introduced into the individual method pool. For a dataset D ,the top-n outlier lists of the poor judges are ge nerated from the underl ying distribution U . First, the outlier scores of all the data are sampled from the distribution U . Then, the random top-n outlier lists are obtained by sor ting all the data based on the outlier scores. In our experiments, two alternative definitions of U are used: Uniform distribution on the interval [0 , 1] and standard Gaussian distribution. The corresponding top-n lists are called Uniform-Noise and Gaussian-Noise . The individual method pool contains the previous five individual detection methods, and the K r random lists of the poor judges, where K r varies from 1 to 5 .

For lack of the space, only the results on the Mammography dataset and the Shuttle-3 dataset are shown in the Figure 3. Clearly, OAG is more robust to the random poor judges than SAG regardless of Uniform-Noise or Gaussian-Noise . Especially, OAG achieves a better performance when the number K r of random lists increases. Table 3 gives the value of the parameter  X  of the individual method pool on the Mammogra-phy and Shuttle-3 datasets. The parameter  X  of each Uniform-Noise or Gaussian-Noise is close to zero. This demonstrates that OAG learns to discount the random top-n lists without supervision. We have proposed the general framework of the ensemble learning in the top-n outlier detection in this paper. We have proposed the score-based method ( SAG ) with the nor-malized method of outlier scores, which is used to transform outlier scores to posterior probabilities. We have proposed the order-based method ( OAG ) based on the distance-based Mallows model to combine the order information of various individual top-n outlier lists. Theoretical analysis and empirical evaluations on several real data sets demonstrate that both SAG and OAG can effectively combine the state-of-the-art de-tection methods to deliver a stable and effective performance independent of different datasets in a good scalability, and OAG can discount the random top-n outlier lists with-out supervision.

