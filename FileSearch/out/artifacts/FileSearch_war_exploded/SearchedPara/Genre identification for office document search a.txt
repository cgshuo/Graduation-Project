 ORIGINAL PAPER Francine Chen  X  Andreas Girgensohn  X  Matthew Cooper  X  Yijuan Lu  X  Gerry Filby Abstract When searching or browsing documents, the genre of a document is an important consideration that com-plements topical characterization. We examine design con-siderations for automatic tagging of office document pages with genre membership. These include selecting features that characterize genre-related information in office docu-ments, examining the utility of text-based features and image-based features, and proposing a simple ensemble method to improve the performance of genre identification. Experi-ments were conducted on the open-set identification of four coarse office document genres: technical paper, photo, slide, and table. Our experiments show that when combined with image-based features, text-based features do not significantly influence performance. These results provide support for a topic-independent approach to identification of coarse office document genres. Experiments also show that our simple ensemble method significantly improves performance rela-tive to using a support vector machine (SVM) classifier alone. We demonstrate the utility of our approach by integrating our automatic genre tags in a faceted search and browsing appli-cation for office document collections.
 Keywords Genre identification  X  Office documents  X  Image features  X  Text features  X  Classification 1 Introduction Genre 1 is a popular way of categorizing movies, songs, and literature. Documents have also been categorized into genres such as fiction, opinion, brochure, slide presentation, techni-cal document, blog, and home page. Document genres such as these can improve document search. While entering query terms is the traditional method of searching for documents, genre provides a complementary, non-topical means to char-acterize documents and web pages and is useful metadata for indexing, organizing, and searching for documents.

Documents occur in different modalities, including plain text, web, and imaged documents. In enterprise intranets and on the web, there are many office documents , which we define as digital documents created and shared by office workers. These documents are in formats such as PDF, PowerPoint, and Word. In this paper, we focus on automatic identifica-tion of four coarse genres of office documents: technical paper, photo, slide, and table . We define technical papers as research-type papers such as conference papers, journal papers, and reports. Photos are pictures taken with a camera and may be embedded in documents, but do not include draw-ings or screenshots. Slides are defined as any page or doc-ument created for presentation in front of audience. Tables include tables from spreadsheets as well as tables in papers and other documents.

Although document genre is related to file format, they are not identical. A document creation tool, such as Word or PowerPoint, can be used to create documents in several genres. For example, in addition to its primary use in cre-ating slides, PowerPoint is also used to create figures and drawings for papers and also to create handouts of screen shots and photos. And some extensions, such as PDF, are associated with many genres, since files created in different formats are often converted to PDF for its portable represen-tation. Thus, if a user were looking for slides from talks and looked only at PowerPoint files, the user may be presented with extra files that are not slides; furthermore, the user will not see slides that are in other formats, such as PDF.
Layout has been useful in genre identification of scanned documents (e.g., [ 1 , 10 ]); it is encoded in the markup of web documents and has been found to convey strong cues about web genre (e.g., [ 27 ]). In office documents, one cannot assume that all documents contain encoded layout informa-tion. For example, some PDF documents are created from scanned documents. Furthermore, when the information is present, it may be inconsistent, e.g., not all PDF documents correctly encode column information. We thus identify genre from imaged document pages that have been OCR X  X , so that both layout and text information are available for all pages; this also obviates the need to determine whether layout information, when given, is correct.

Examples of the four office genres of (technical) paper, photo, table, and slide are shown in Fig. 1 . These examples illustrate some of the diversity within genres and also the ambiguity of the genres. Note in Fig. 1 b, the photo category is composed of not only photos taken from a camera but also document pages that are mostly photo (the top-right and the middle-right examples). Note also that the bottom-left slide in Fig. 1 d is composed mostly of photos. Thus, it can be appropriate for some pages to be tagged with more than one genre. We tag a page with a genre when at least half the page represents the target genre. With this definition, the middle-right page in Fig. 1 c is tagged as a table and as a paper, and the lower-right page is tagged as a table. Thus, tables that also contain text as footnotes and other informa-tion are tagged as tables.

While web search strongly relies on link information for ranking, office documents contain very little link informa-tion, making genre identification more valuable when search-ing office documents. The ability to automatically identify office document genre can allow search results to be grouped by genre or topical search queries to be augmented by genre. With our four proposed coarse genres, one could specify that technical papers on geysers are of interest, or if one was looking for a brochure, specify that none of the genres are of interest. These genres complement a number of finer genre classifications that are characterized primarily by differences in textual content. Examples of such genres include legal, scientific, non-fiction and fiction (e.g., [ 16 ]) and Editorials, Letters to the Editor, Reportage, and Spot News (e.g., [ 31 ]). Our office genres also complement web genres, such as home pages, blogs, and wikis.

For genre identification, we assume that the various page types that occur in a particular office document genre should be learned by the classifier. Thus, rather than classifying into page types such as title, table of contents, references, etc., we classify each page by genre. This eliminates the need to create classifiers for each possible page type and the need to map between page types and genre. For text-based genre classification, Kessler et al. [ 16 ] distinguish between  X  X ur-face X  cues, which are simple to extract, and  X  X tructural X  cues, which are related to linguistic structure. Here, we define a set of document-inspired, surface-type image features. It has been suggested that there are advantages to performing genre identification without text features, including language inde-pendence [ 27 ] and corpus independence [ 2 ]; image features may have these advantages if they perform well without text features. Since some documents belong to more than one genre, our genre identifier is open set, so that a document is tagged with zero or more genres. We then extend our page genre identification to predict document genre membership. The automatic genre identification results are used in a sys-tem developed for faceted search and browsing of enterprise collections that offers genre as one of the possible search facets.

The contributions of this paper center on an investigation of methods for office document genre identification. These include: (1) developing a set of document-inspired  X  X urface X  image features and experimentally comparing their utility to text-based features, (2) adding a simple ensemble method that efficiently makes use of the data to improve genre identi-fication performance, (3) developing a document genre iden-tification approach where the different page types associated with a genre are learned by the classifier, and (4) deploying the results in a faceted search and browsing system.
The rest of the paper is organized as follows. In Sect. 2 , we review earlier text-based and image-based genre identi-fication work and compare them to our approach. We also discuss current techniques for genre identification of web documents and why those techniques do not directly apply to office documents. In Sect. 3 , we describe the data set of representative office documents that we collected and labeled for this work. In Sect. 4 , we describe our proposed text-based and image-based feature sets, and the classification meth-ods used, including a simple ensemble method. In Sect. 5 , we present experimental results that show the utility of our image-based method over a text-based approach. In Sect. 6 , we discuss the combination of page genre scores to predict document genre, and then we illustrate the use of our genre tags in a document searching and browsing system. Conclu-sions and future directions are presented in Sect. 7 . 2 Related work Many sets of genre categories have been proposed for text genre identification and web genre identification. For web page genre, Roussinov et al. [ 24 ] conducted a study of useful genres and proposed five major web document genre groups, while Santini et al. [ 25 ] compiled and published more than 80 genres. 2 Henderson [ 12 ] conducted a study analyzing the computer folder structure of six knowledge workers and found genre to be the most common organizing factor. She also states that  X  X eople may deal with a vastly differing set of genres, depending on their job X . Thus, the set of useful genres depends, in part, on the planned application.
In our work, we focus on automatic genre identification of the types of documents used in a research lab, which are a subset of those found in an enterprise. Our genre set can be further refined to application-specific genres of interest using text-based methods.

Different modalities of features have been defined for use in genre identification. In works on genre identification based on textual features, e.g., [ 7 , 16 , 19 , 31 ], the features are pri-marily computed from surface cues, such as document terms and punctuation, or structural cues, such as part-of-speech tagging. Kessler et al. [ 16 ] found that performance using surface cues was similar to that using structural cues and recommended surface cues because they are much easier to compute. Stamatatos et al. [ 31 ] noted in an experiment on genre identification that using less than 50 of the most fre-quent terms in English, which are primarily stop words, plus punctuation, as  X  X tyle X  features was effective (greater than 97% accuracy) for classifying a subset of the Wall Street Journal text corpus into four genres. Lee and Myaeng [ 19 ] examined frequency-based methods for identifying terms that occur across genres and also across subject, i.e., topic, classes within a genre. The use of subject classes improved genre classification performance when used with a similarity-based approach, but when used with a Na X ve Bayes classi-fier, the best performance was when subject classes were not used. Since we take a classification-based approach, we do not use subject classes in our text-based genre classifier. As in [ 19 , 31 ], we use surface cues, but in addition, we use discriminative selection of text features.

Web genre detection commonly employs features that describe markup attributes of web pages, in addition to ana-lyzing the pages X  textual content. Link plus formatting or layout tags have been used, as well as web page URLs (e.g., [ 2 , 5 , 23 ]). Meyer zu Eissen and Stein [ 5 ] created a web genre identification system and found HTML markup to be more useful than text features. Levering, et al. [ 20 ] found that add-ing HTML features to text features improved performance. They also noted that adding visual features derived from the HTML tags sometimes helped and sometimes hurt perfor-mance, depending on genre. Recently, Scholl [ 27 ] presented a system for web genre detection that used only features derived from HTML markup and obtained relatively good accuracy. Thus one may ask whether features capturing layout in office documents are similarly more effective than text-based features for genre identification of office documents.

One approach that addresses the absence of encoded layout information in office documents is to perform image-based layout analysis (e.g., [ 1 , 10 ]). Each page is segmented into zones that are labeled with tags such as text body, pic-ture, and table. The tagged zones are then used to classify pages according to genre. As can be observed in a survey paper by Chen and Blostein [ 4 ] on classifying  X  X ostly-text X  document page images into a variety of types, the use of lay-out is predominant in document page image classification approaches. However, as noted in [ 4 ], layout analysis can be complex and error-prone.

A few prior works have explored genre identification based on image analysis without layout information. Das Gupta and Sarkar [ 8 ] describe a genre classifier based on identified salient feature points for discriminating between two genres, journal articles and memos, and tested on 80 page images. Shin et al. [ 28 ] used window-based features to identify page type, i.e., title page, cover page, reference page, table of contents, and form. They define over 20  X  X tructure-based X  features that include number of text column gaps, configuration of lines on a page, and classification of each window into the region types of text, image, or graphics. Analogous to the surface and structural types of cues for text features, these features may be thought of as structural cues, while simple visual features that can be extracted directly without classification are analogous to surface cues. We also use window-based features, and some of our features attempt to capture similar document characteristics. However, our features are primarily surface features and our goal is page and document genre identification, rather than page-type identification.

Most previous genre identification systems make use of either image-based or text-based features. Kim and Ross [ 18 ] compared image-based and text-based features for genre identification. For image-based features, they used sim-ple, surface-based features in tiles from the first page of a document to identify document genre. Kim and Ross also investigated the use of two types of text-based features. One is based on  X  X rolific X  terms, and the other is based on significant topical terms. We initially planned to use their image-based system and their prolific terms-based system as baseline systems. We did not consider the topical terms fea-ture because we wanted features that are topic-independent, and as mentioned earlier, other researchers achieved good results without topical terms. However, the prolific terms feature was problematic for our genre set, since two of our genres did not have any prolific terms as defined in [ 17 ]. We then decided to use Stamatatos et al. [ 31 ] as a baseline text system because their system demonstrated good accuracy. Kim and Ross X  X  image-based system was used as an image baseline.

As with the Kim and Ross image-based system, we forgo layout analysis and use tiles. However, in contrast, we develop a set of document-inspired features that attempt to capture layout characteristics and texture of the tiles without requiring region classification. Our work further differs from Kim and Ross in two ways. First, we examine the utility of combining feature types. Second, we develop an open-class system for identifying a set of genres.

Most prior image-based genre identification approaches focus on page genre identification. Those that perform doc-ument genre identification commonly use only the first page of a document (e.g., [ 1 , 18 ]), which is the most distinctive page for some genres. In contrast, we identify the genre for each page separately and then combine the page genre tags to identify document genre membership. With our approach, search and browsing can be performed based on document genre or page genre.

In summary, there has been much work on text, image, and web page genre identification. Also, HTML-based tags have shown to be very useful in differentiating web genres. There has been much less work on differentiating the genres of office documents. In this paper, we show how the genre of office documents, which commonly do not have link or tagged layout information, can be identified using surface image-based features. We also show that our text-based fea-tures, while exhibiting better performance than a baseline based on [ 31 ], are not as useful for identifying office docu-ment genres. We improve performance using a simple ensem-ble method and combine per-page genre labels to classify document genre. 3 Office document data set A benchmark data set of office documents that has been labeled with our target genres, slides, technical papers, tables and photos, does not exist. To create a corpus, we collected a set of documents and tagged them with our four target genre types. The documents were collected primarily from the web, with some documents also added from our corporate intra-net. We queried Google for 100 results per query, scraped the returned URLs for office document extensions, such as .pdf, .xls, and .doc, and downloaded those files. The que-ries included a number of document genres (e.g., table, bro-chure) as well as topical terms covering a variety of subjects (e.g., airline, baby, car, disease, dog, plants, semiconductor, shipping, software, stocks, vacation). We also added pho-tos obtained from Flickr and about 100 documents from our corporate intranet. Note that in addition to the Flickr photos, photos also occurred in some of the other documents, such as presentations and magazine articles.

In order to uniformly process all documents, each page of a document was represented as a JPEG image. We checked for duplicates, manually looking for those with identical or almost identical content, and removed them. The genre-based queries identified documents both within and outside the desired genre. For example,  X  X able X  contained document data tables, as well as periodic tables, and pages containing other senses of the word, such as  X  X able tennis X ,  X  X able eggs X ,  X  X able linens X , and the verb in  X  X able a motion X .

Eleven people participated in labeling the corpus pages with our four target genres. The labelers used an interface we developed for quickly selecting pages belonging to a specified genre. All pages of the documents in a folder were displayed in a scrollable window and the pages could be selected using common interface selection techniques.
Each labeler was instructed to find and mark pages for which one given genre (or one genre at a time for the person who labeled two genres) was apparent in at least half of the page. With this procedure, there may be pages with multiple genre labels and pages that are not labeled as any genre.
Labeling pages for a selected genre was sometimes ambig-uous. For example, a table of contents usually has two col-umns, but we decided not to include these as  X  X ables X  because they are more closely associated with genres such as reports and books, rather than generic tables. Another example is that the  X  X oundary X  defining technical papers is ambiguous, since some magazines and newsletters are on technical top-ics. To resolve this, we decided to define technical papers as research-type papers such as conference papers, journal papers, and reports.

The corpus contained 1,267 pages with no tags. As indi-cated by the ambiguous examples above, some of the pages without tags were relatively similar in layout to our four tar-get genres. There were also 3,727 pages with one tag and 104 pages with two tags. The center column of Table 1 shows the number of pages in the corpus tagged with each of the four genres. There were a total of 3,935 tags assigned to 5,098 pages.

Table 2 shows the agreement among our labelers for each genre, as measured by Fleiss X  kappa [ 6 ]. Fleiss X  kappa mea-sures the extent of labeler agreement above chance when there are more than two labelers. It ranges in value from negative (poor agreement) to 1.0 (complete agreement). The agreement among our labelers was relatively good. How-ever, there was some disagreement, indicating ambiguity in the page genres.

For our experiments, the labeled data were partitioned by document into three sets with equal numbers of documents (ignoring round-off). The partitioned data were used for performing 3-way cross-validation. 4 Genre identification In our approach to genre identification, the different page types associated with a genre are learned by the classifier model. That is, we do not create separate models for each page type, such as title page, table of contents, and reference pages, which are all page types associated with the technical papers genre. This is reflected in the instructions to the label-ers to select pages of a given genre, rather than page type. With these genre labels, we create one one-versus-rest model per genre.

In the rest of this section, we describe the features and clas-sifiers we use for page genre identification. We also propose a simple ensemble method for improving genre identification performance. 4.1 Features for genre identification We developed a set of image-based features to capture docu-ment layout characteristics. We also developed a set of text-based features that combine ideas proposed in earlier works and incorporate feature selection. 4.1.1 Image-based page genre features As an alternative to performing layout analysis of page images, we tile each page image and extract a set of features that capture local document characteristics, such as lines of text, within a tile . While this requires relatively large tiles, the tiles need to be sufficiently small to distinguish the different region types (e.g., heading, figure, body text). Empirically, we have found that dividing each page image into a grid of 5 tiles horizontally by 5 tiles vertically, for a total of 25 tiles, meets our requirements. A full  X  X age X  tile is also used to capture features that may span multiple tiles, such as table rule lengths. Figure 2 illustrates the tiling of a page.
Our feature set was designed to differentiate the types of regions identified in layout analysis, such as text, images, rules, and columns. The tile features are:
Image density. This feature is similar to the image fea-ture used by Kim and Ross [ 18 ], except our tile size is much larger. This feature attempts to capture areas where print is sparse and should help differentiate titles, regular text, and photos. To compute it, a page image is converted to a binary image and the ratio of the number of black pixels to the total number of pixels in each tile is calculated.

Horizontal projections. This feature attempts to capture the number of text lines and the distribution of text line heights. This helps differentiate genres such as slides, which are of a larger font, and photos, which have few, if any text lines. The feature can be computed based purely on image processing techniques (e.g., [ 33 ]) to project the pixels hori-zontally once the text foreground is identified. Alternatively, word bounding box locations, e.g., provided by an OCR sys-tem, can be used to compute the projections of the bound-ing boxes. We used the latter approach because each page was OCR X  X  for the text features. From a projection, the peak widths, roughly corresponding to text rows, are quantized into a five-bin histogram. This characterizes the number of rows and the distribution of font sizes.

Vertical projections. This feature attempts to capture the number of text columns and the distribution of their widths. This feature can help to differentiate papers and tables, which may have columns of varying widths. As with the horizon-tal projections, we project word bounding box locations and compute a five-bin histogram of column widths.

Color correlogram. Color correlograms represent the spatial correlation of colors in an image and have been used for image retrieval [ 14 ]. We select a subset of the correlo-gram values to capture texture and color variation. To com-pute this feature, the images are proportionally scaled to a maximum of 1,550 pixels in the horizontal and vertical direc-tions, and then a color autocorrelogram computed. The col-ors were quantized to 96 colors and distances of 0, 1, and 3 pixels were used, resulting in 288 dimensions per tile. To reduce the number of correlogram coefficients, feature selec-tion was performed using the Maximally Relevant Minimally Redundant (mRMR) feature selection method [ 22 ] to identify a subset of 50 features. Because the feature values depend in part on tile location (e.g., titles usually appear near the top of a page), the feature selection method performs bet-ter when implicit spatial information is preserved. This was done by concatenating the correlogram coefficients for each tile in a page into a vector and then performing feature selec-tion over all concatenated correlogram vectors in the train-ing set (Fig. 3 b). Our approach contrasts with the  X  X ag of visual words X  approach to image classification [ 29 ], where the locations of the image tiles are not preserved. To enable modeling of all region types in any tile, the final feature set is composed of the union across tiles of the selected feature positions (Fig. 3 c). Then for each page, the selected features for each tile are concatenated in a fixed order (Fig. 3 d, e). With the tile locations implicitly encoded in the feature vec-tor, a genre classifier can learn the feature values observed in each location.

The concatenated vector is combined with page-based features to create a feature vector representing a page. Two types of page-based features are computed: (a) (b) (c) (d) (e)
Lines. Tables often have many rules which extend horizontally and/or vertically. To identify rules on a page, run lengths of black pixels in a binary image are computed horizontally, allowing for short pixel jogs horizontally or vertically [ 33 ]. The number of lines in each tile is noted and the line lengths are uniformly quantized into a four-bin histogram. This differentiates lines that span a page width, a column, and shorter lines. Vertical line histograms are computed similarly.

Image size. The width and height of the image. Technical papers and slides commonly occur in standard page sizes. Photos and tables, on the other hand, may be cropped and also may occur in document pages and slides.

Although we use feature selection on the entire set of text terms as described in the following section, we do not use it on the entire set of image features. For our image-based features, the number of dimensions is relatively small, e.g., five-bin histograms per feature type, and each of the features is informative relative to the others. For example, the number of rules is independent of the number of lines of text. The exception is the color correlogram, where feature selection was employed as described above. 4.1.2 Text-based page genre features Prior to extracting text-based features, the page images are OCR X  X  with Microsoft Document Imaging 3 and then pre-processed. The recognized text, which contains errors and extraneous characters, was tokenized into terms and punc-tuation. Some token types were mapped to a unique term representing that type; these token types were: integers, float-ing point numbers, underscores, lines, and dates of the form  X  X d/dd/dddd X  where  X  X  X  is a digit. To reduce the number of terms due to OCR errors and to increase robustness, only terms that occurred in more than ten documents were kept. Stop words and punctuation were kept, since these tokens can be indicative of genre [ 16 , 23 , 31 ].

Previous text-based genre identification systems by [ 18 ] and [ 31 ] select frequent terms as features.  X  X rolific X  terms that occur in many of the documents in each genre were used as text features in [ 18 ] to capture writing style. A fixed set of frequent terms, which corresponds to a subset of stop words and punctuation, was used by [ 31 ]. The features in these sys-tems are primarily stop words and were motivated in part by the desire to select non-topical terms. However, these ear-lier methods do not consider whether the terms are good at discriminating among classes. For example, a frequent term may occur at approximately the same frequency in each class and therefore would not provide useful information for classification.

Non-discriminative selection methods, such as those used by [ 18 ] and [ 31 ], are suboptimal compared to Mutual Information (MI) and  X  2 based methods [ 21 ], which are popular feature selection methods. Since these feature selec-tion methods are greedy, redundant features may be selected. For our text-based classifier, we used a discriminative feature selection method that is an extension of the MI-based selec-tion method. The Maximally Relevant Minimally Redun-dant (mRMR) [ 22 ] method selects features that discriminate the different classes but minimize redundancy among the retained features.

We performed preliminary experiments using mRMR to select 50 terms per genre, but the results were poor. We hypothesize that this may be due, in part, to the sparseness of text in some documents. To address the sparseness problem, we next tried selecting 100 and 200 terms, which seemed to be the limit of the number of terms mRMR could select from our office document data set in a reasonable amount of time. The results with 200 terms were much better, and so we select 200 terms per genre.

For performing cross-validation experiments, the data were partitioned as described in Sect. 3 and term selection was performed separately for each partition. The selected terms for a partition form the text features for all partitions when that partition is used as the training set.

For each of our four target genres, the top ten terms selected by mRMR for one data partition are shown in Table 3 . Note that the  X  X aper X  genre includes the content words  X  X igure X ,  X  X hown X , and  X  X esults X , in addition to stop words. In contrast, the top mRMR features for the Slides genre are primarily all stop words, and the top mRMR fea-tures for the Tables genre are all content words. Note also that terms are present for the Photo genre. Although a few photos contain text that was OCR X  X , the terms are also from pages that are mostly photo, as described in Sect. 3 and illustrated by two examples in Fig. 1 b. We also used mRMR to select the maximally relevant ( not minimally redundant) terms for the four genres and observed that the terms were primarily stop words.

For each data partition, we combined the set of 200 terms selected using maximum relevance and 200 terms selected using mRMR for each of the target genres as the basis for the text feature vectors. Our text features contrast with Stamatatos, et al. [ 31 ], who found that using less than 50 of the most frequent terms provided good genre identifica-tion for their corpus. Including the maximally relevant terms provides some redundancy, which may be helpful for genres where text is sparse. It also adds primarily stopwords and punctuation, capturing some of the traits of the style fea-tures in [ 18 , 31 ]. The text feature vector for each document is then composed of the term counts for each of the selected terms. 4.2 Classification For most search systems, full coverage of all possible genres is not realistic. Instead, a genre identification system should be able to spot a subset of genres from a large possible set. For this, we create for each genre of interest a one-versus-rest model, where a classifier attempts to differentiate between the genre of interest and the  X  X est X  of the genres. As noted earlier, each classifier learns the variations in page types associated with a genre.

Based on the competitive performance of SVMs (Sup-port Vector Machine [ 3 ]) for many classification tasks (e.g., [ 5 , 15 ]), we used an SVM classifier. As commonly recom-mended for better SVM performance, the feature vector com-ponents are normalized. We use a normalization that scales and shifts the component values to range between 0 and 1, as recommended in [ 13 ]. Each vector element, x i is normalized using: x where { x j } are the observed values for one vector element in the training data; the same scaling factors are applied to both the training and test data.

An SVM classifier is a supervised, discriminative classi-fier that computes a hyperplane that best separates two clas-ses: w  X  x  X  b = 0 where x is a set of points from a training set. w and b are chosen to maximize the margin between the two classes. By applying the kernel trick [ 3 ] to the dot product, a linear SVM classifier can be transformed into a non-linear classifier. This may allow for better handling of the non-linear feature space with multiple subtypes within a genre. For our experiments, we used SVMlight [ 26 ], which allows specification of different kernels and cost-factors dur-ing training. In particular, we performed a parameter sweep with linear, polynomial, and radial basis kernels, with the order of the polynomial kernels ranging from 2 to 4. We also swept the cost-factor from 1 to 15, biased toward detection of a genre. Since an optimal model is found for each genre and data partition, the best kernel and parameter values varied for each trained model.

For our experiments, we performed 3-fold cross-valida-tion on the data. For each train/development/test combina-tion, one data partition was used for training the SVM, and a second data partition was used to tune the genre mod-els, selecting parameters to maximize the balanced F -score, F : F the harmonic mean of precision, P , and recall, R . These measures are defined [ 21 ]as: P = tp R = tp where tp is the number of true positives (both the system and the ground truth tagged a page with a given genre); fp is the number of false positives (the system but not the ground truth tagged a page with a given genre), and fn is the number of false negatives (the ground truth but not system tagged a page with a given genre). After tun-ing the genre models, the  X  X ptimal X  model for each genre was used to classify the page images in a third data parti-tion.

Using the features and classifiers we have described, we created systems to compare experimentally: image-based features with the Weka [ 32 ] Na X ve Bayes classifier ( imgfeats.NB ), image-based features with an SVM classi-fier ( imgfeats.SVM ), and text-based features with an SVM classifier ( txtfeats.SVM ). 4.3 A simple ensemble classifier To improve performance, we explored a simple ensemble method that makes better use of the data partitions for training and tuning our SVM-based system. We initially considered using a traditional classifier combination method that uses the results from different types of classifiers on the same data. But in preliminary studies comparing different classifiers, SVM performance was much better than the other classifi-ers that we tried X  X a X ve Bayes, k-Nearest-Neighbors, and Random Forests [ 32 ]. Consequently, we decided instead to use an SVM classifier trained on different partitions of the data and combine the results. In contrast to bagging, which avoids overfitting by selecting exemplars with replacement to form multiple training sets, we divide our training data into two mutually exclusive partitions to train separate classifiers. We chose this approach to minimize the number of models that need to be trained.
 In particular, the data set was divided into three partitions, A , B , and C , for cross-validation. The results from training on A , tuning on B , and testing on C to produce binary genre classifications g 1 were combined with the results from train-ing on B , tuning on A , and testing on C , to produce binary genre classifications g 2 . Thus, each test partition is labeled using two SVMs. Assume that the classification for genre k of page i by classifier c is g k c [ i ] . To create a higher precision classifier, we used this combination rule for the i th page: ( g It requires that at most one of the classifier pairs in a com-peting genre would label the page as the competing genre.
An illustration of the intuition behind this method is shown in Fig. 4 . Two classifiers trained on different data partitions identify different hyperplanes and have a portion of the space in common. We hypothesize that the common space is pri-marily pages of a given genre, and that the space covered by only one of the classifiers are pages that may be a com-bination of genres or a page that is otherwise ambiguous or unusual. When used with image-based features, we denote this system imgfeats.Ens . 4.4 Combination of text and image features for page genre We considered whether using a combination of text and image features can improve performance for our genre clas-sification task. In video analysis, Snoek et al. [ 30 ] compared  X  X ate fusion X , which combines output from separate text-based and image-based classifiers, with  X  X arly fusion X , which combines text and image features before classification. They observed mixed results across the set of classification con-cepts and suggested that the fusion strategy should depend on the concept to be classified. Since we were concerned about the sparseness of text in many of the photos and some of the slides, we chose to use  X  X arly fusion X  and combine the text and image information at the feature level. The features were used in a simple ensemble classifier. We refer to this system as txt+imgfeats.Ens . 5 Experiments and discussion We conducted experiments to investigate the effectiveness of the features and classification methods we have proposed for office document page genre identification. We first compared the utility of our text and image features against baseline fea-tures and against each other. We then tested the effectiveness of our partition-based ensemble classification method and of the combination of text and image features.

The pages in our office document data set may be labeled with zero, one, or multiple genres. For evaluation, we mea-sure performance by precision, recall, and F 1-score (see Eqs. 2  X  4 ), computing the macro-average across genres. The macro-average gives equal weight to each genre, while the micro-average gives equal weight to each page [ 21 ]. We did not use micro-average measures because we did not collect documents for our corpus in a way to insure that the distri-bution of genres is representative of the distribution of office documents on the web. In our experiments, the significance of observed differences in performance was tested using the paired Wilcoxon signed rank test. 5.1 Baseline image feature comparison Kim and Ross X  image-based system [ 18 ] was used as a base-line because their system is based on surface features in tiles and was developed for classifying document genres. We implemented their image-based feature extraction: each page was divided into a 62  X  62 grid, and each tile in the grid with at least one pixel of value less than 245 was assigned the value of  X 0 X . The other tiles were assigned a value of  X 1 X . For classification, Kim and Ross compared Na X ve Bayes, Na X ve Bayes with kernel density estimation, Random Forest, and SVM classifiers using the Weka software package [ 9 ]. They observed that the SVM classifier performed much worse on their image feature data than the other classifiers. Hence, for the baseline image feature experiments, the Kim and Ross image features were tested with the Weka Na X ve Bayes classifier using both the plain and the kernel density estima-tion versions, and the Weka Random Forest classifier. These systems are referred to as KR.NB, KR.NBK, and KR.RF, respectively, and form our image feature baseline models.
The page genre identification performance for these base-line models is shown in the top three lines of Table 4 . Similar to the image feature results in [ 18 ], where two different data sets were used, both Na X ve Bayes models performed better than Random Forests overall. However, the observed perfor-mance was not significantly different whether or not kernel density estimates were used with the Na X ve Bayes classifier. These results indicate that our office document data set is a challenging collection for page genre classification.
The last row of Table 4 , labeled imgfeats.NB, shows the performance of our document-inspired image features (described in Sect. 4.1.1 ) with the Weka Na X ve Bayes classi-fier. The overall performance as measured by F 1-score of our features was 0.7240 versus the best Kim and Ross F 1-score of 0.5326. In all cases, our document-inspired image features perform significantly better than the Kim and Ross features [ 18 ]. In the rest of the experiments, our document-inspired image features are used as the image features. 5.2 Baseline text feature comparison We use the text-based genre features proposed by Stamata-tos et al. [ 31 ] for our text baseline. These features are corpus independent and based on frequent terms. More specifically, we used the 30 most frequent stopwords and eight frequent punctuation marks specified in [ 31 ] as features. These fea-tures were used with the same SVM classifier as in our text-based method with feature selection. We refer to this baseline system as freqfeats.SVM .

Table 5 compares the page genre identification perfor-mance of the frequent terms-based baseline (freqfeats.SVM) and our text-based method with feature selection (txt-feats.SVM, as described in Sects. 4.1.2  X  4.2 ). Note that the overall performance measure, F 1-score, for the frequent terms was 0.4940 and for the feature selection method was 0.7470. While there was no significant difference in recall, our method employing feature selection performed significantly better than the frequent terms-based method in precision and F 1-score. These results indicate that using only frequent terms does not provide a rich enough set of features for identifying our target genres.
 Although we do not show significance for results across Tables 4 and 5 , we observed that our text-based features, txtfeats.SVM, exhibited significantly better F 1-score than any of the Kim and Ross image feature classifiers, but no significant difference in F 1-score with our image features, imgfeats.NB. 5.3 Image features and ensemble classification performance We examined the performance of our image features using the classification models described in Sect. 4 . Table 6 shows the performance of our image features with an SVM classifier (imgfeats.SVM), image features with our ensemble classifier (imgfeats.Ens), and the use of both image and text features with our ensemble classifier (txt+imgfeats.Ens). Compar-ing the image-based systems against our text-based method (txtfeats.SVM), Table 6 shows that for the three evaluation measures of precision, recall, and F 1-score, all methods with image-based features had statistically significant better per-formance than our text-based method. From this, we infer that image-based features can be more useful than text-based features for detecting some office document genres.
While it is not indicated in the tables, we also observed that the use of our image features with an SVM classifier, imgfeats.SVM, had significantly better performance, as mea-sured by F 1-score, over use of our image features with a Na X ve Bayes classifier, imgfeats.NB (from Table 4 ). Thus, the ensemble method was applied to the SVM classifier results. Examining the addition of our simple ensemble clas-sifier, imgfeats.Ens, we note statistically significant better F 1-score performance over imgfeats.SVM.

Although our text-based classifier did not perform as well as our image-based classifiers, we examined whether the combination of our text-based and image-based features enhances performance. The last two lines of Table 6 com-pare the combined features (txt+imgfeats.Ens) to the image features with the ensemble classifier method (imgfeats.Ens). Although precision improved and recall decreased when text features are added (txt+imgfeats.Ens), overall, there was no significant difference, as measured by F 1-score.

We also examine F 1-score performance by each of our methods for each target genre. Figure 5 shows that our image features (imgfeats.SVM) perform better than using text only features for all test genres. Both ensem-ble classifiers (imgfeats.Ens and txt+imgfeats.Ens) outper-form the best plain SVM classifier (imgfeats.SVM) for all genres. As might be expected for the Table genre, the F 1-score using the text-based method (txtfeats.SVM) is much lower than the methods that employ features that capture layout.

Comparing these results with Fleiss X  kappa labeler agree-ment shown in Table 2 , note that for the four genres, the rank order of the labeler kappa values is the same as the rank order of F 1-score for the two methods using an ensemble classi-fier (imgfeats.Ens and txt+imgfeats.Ens). This indicates that page genre identification performance is better when labeler agreement is higher. 5.4 Discussion Although Stamatatos et al. [ 31 ] had good results using text features, applying their text features to our data resulted in much poorer performance. We believe this is due in large part to the different sets of genres used. In [ 31 ], the corpus is a subset of Wall Street Journal documents composed of four genres: Editorials, Letters to the Editor, Reportage, and Spot News. Documents in these genres always contain words and are usually composed of complete sentences. Slides and tables tend to contain fewer words, and photos contain little or no words. With fewer stop words and punctuation charac-ters, the features used in [ 31 ] may have been too sparse. Thus, supplementing them with selected text terms led to improved performance for our coarse genres.

It has been suggested that there are advantages to perform-ing genre identification without text features. Scholl et al. [ 27 ] mention language independence and Kim and Ross [ 18 ] mention less language dependence and freeing the process from  X  X ext processing tools with encoding requirements and problems relating to special characters X . They also note that  X  pdftohtml failed to extract information from seventeen per-cent of the documents. X 
Boese and Howe [ 2 ] examined whether different features for web genre prediction are transferable between web page corpora. They noted that terms in a web page are generally not transferable. They also noted that the only features com-mon across the corpora they examined are a style readability measure, number of web links, and some HTML table tags. These features are independent of the terms in a document, as are our image-based features.

In agreement with earlier web page genre detection results by [ 20 , 27 ], our office document genre identification results indicate that using only text features is inferior to our image-based features. The latter are surface features capturing lay-out without requiring explicit segmentation into zones or classification into structural regions types. Our results also indicate that the addition of simple text features does not sig-nificantly influence performance for our four coarse genre types that exhibit differences in layout. Thus, we expect our image-based features with an ensemble classifier to be appli-cable to other collections of office documents. However, for finer grained genre classification where layout is similar, text features such as the stop words used by Stamatatos [ 31 ] and the surface cues proposed by Kessler et al. [ 16 ] could play an important role. 6 Application to document search We applied our genre identification work to document search. Since document search is commonly document -based, rather than page -based, we first discuss labeling documents by genre. In particular, we describe how we use our office doc-ument data set for the document genre identification task and our experiments in predicting document genre based on the page genre classifications. We then describe a document browsing interface that makes use of the predicted genres as search facets. 6.1 Document genre data set To d eve l o p a document genre identifier and evaluate perfor-mance, a set of documents where each document is labeled by genre is needed. Instead of performing a separate manual labeling of documents, we assign a document to a particular genre if at least half of its pages have been manually tagged as that genre. The right column of Table 1 shows the number of documents in the corpus tagged with each of the four genres. A total of 798 tags were assigned to 1,178 documents. Note that there are documents without any tags. 6.2 Document genre identification To automatically tag documents by genre, the genre scores for each page in a document are used. Since page classifica-tion is imperfect, we again employ learning and explore the utility of two feature representations for classifying a doc-ument based on the page scores. Since we biased the genre classifiers toward positively labeling a page as the specified genre, we assume that a negative page score does not con-tain much differentiating information; thus, we focused on the positive page scores. We investigated encoding the page scores in two different ways: (1) quantize the page scores in a document into a small number of bins and (2) combine the page scores produced by the classifiers for one genre into a single score.

The quantization method is illustrated in Fig. 6 . Quantiza-tion of the page scores produced by the pair of classifiers is performed by providing two bins for negative scores and four bins for positive scores, with bin breakpoints at {  X  X  X  ,  X  0.0, 0.33, 0.67, 1.0, +  X  }. To use the page scores as features, a feature vector is created that is composed of the counts of the quantized page scores for each of the four target genres, plus the number of pages in a document. Using Eq. 1 ,the feature vector values are scaled and shifted to range between 0 and 1 and then are used in an SVM.

In our second method, which is based on  X  X core fusion X , we combine a document X  X  page scores for one genre into a single score (Fig. 7 ) and use it as a feature in an SVM. We again focus on the positive scores produced by the classifi-ers. Instead of making a hard decision as in Sect. 4.3 ,the maximum page score, s max ( p , g ) , produced by each pair of classifiers for page p and genre g is used in computing the summary score (Fig. 7 b). To insure that the document genre score, S d ( g ) , for document d and genre g is  X  X ormalized X  to range between 0 and 1 and simultaneously focus on the positive scores in the predominant score range, each maxi-mum page score s max ( p , g ) is clipped to a maximum value of 1.0 and a minimum value of 0.0 (Fig. 7 c). S d ( g ) is computed as the average of the individual maximum page scores for a document (Fig. 7 d). Thus, S d ( g ) is computed from the pairs of scores as: S ( g ) = 1 where P is the number of pages in document d . S d ( g ) for each of the four genres plus the normalized number of pages in the document form the feature vector used in an SVM.
For each feature set, a separate classifier is optimized for each genre. The parameters of an SVM classifier are opti-mized using the same cross-validation approach as used for page classification. The method using quantized features is referred to as Quantized.SVM , and the method based on score fusion is referred to as Score.SVM . 6.3 Document genre performance In this section, we examine the performance of three methods for predicting document genre from page genre. Specifically, we compared the two methods described in the previous sec-tion, Quantized.SVM and Score.SVM, against a baseline vot-ing classifier. Voting is a common classification method for combining the results from different classifiers on the same data. Here, we use voting to combine classification results on different data: the pages of a document. In particular, the page classification scores from the SVM classifier are used to vote whether to tag a document with a genre.

We expect that a trained classifier should better model the noisy features due to page genre identification errors, result-ing in better performance than simple voting. Table 7 shows the results for the different document genre classification methods. The score fusion method, Score.SVM, had the best overall performance, with an F 1-score of 0.8695.

The supervised methods exhibited statistically significant better F 1-score performance than voting. Quantization was not better overall than our score fusion method. It may be that there is not enough data for good estimates in the larger number of dimensions, and that in the quantized represen-tation, the features for documents with a small number of pages are noisy, hurting performance. 6.4 Genres in document search Genre can play a valuable role when searching for office documents in a business organization. Unlike the web, where ranking of search results is strongly influenced by links between documents, business documents rarely contain links. Consequently, other methods for locating documents are needed. Faceted search has been used to locate documents based on their attributes (e.g., [ 11 ]), and automatically iden-tified genres have been proposed as a useful facet for such searches [ 12 ]. To explore this, we applied our genre identi-fication method to tag documents in a system we developed for faceted search and browsing of a collection of business documents. The system has been used internally to access 30,000 office documents and 2,30,000 images created over the past ten years.

The system provides users with search and navigation options through metadata and the document collection file structure. Filters for different facets, including automati-cally computed genre, are provided by the interface. The results are displayed within the user-created directory hier-archy (Figs. 8 , 9 ). Directories without matching documents are not displayed. Directories are visualized by three thumb-nails of sample documents, cropped to squares to better fill the directory box. If fewer than three matching documents exist in a directory tree, then only that number of thumbnails is presented.

To provide genre tags for the search and browse system, we used the genre models trained on the office document data set described in Sect. 3 to tag the documents and images in the corpus. A user can restrict the genres shown in the inter-face by selecting one of the genres listed in the genre option as shown in Fig. 8 . The pull-down menu includes  X  X lide X ,  X  X echnical Paper X ,  X  X hoto X ,  X  X able X , and  X  X ther X . The  X  X ther X  option contains any document that was not tagged with a genre. This option allows a user to use the genre facet to limit the documents presented to exclude the tagged genres. Examples of documents that fall into this category include memos, maps, and brochures.

Figure 8 displays the results of selecting the  X  X ech paper X  genre. Figure 9 shows the interface when the genre  X  X lide X  is selected. The background color of each directory is a differ-ent intensity of orange to indicate the strength of the match according to the match score. The darker intensities indicate that those directories have a higher proportion of documents tagged with the selected genre. Note in Figs. 8 and 9 that most of the thumbnails representing each directory are (cropped) technical papers and slides, respectively. The tool tip in Fig. 9 displays a larger image of the first slide from one of the pre-sentations. One can see that a different set of directories is listed in Figs. 8 and 9 and that directories appearing in both listings, such as  X  X ctivities X  or  X  X onferences X , are represented by different document thumbnails.

As would be expected given imperfect genre identification performance (and the subjectivity of manual genre labeling), there are some genre tagging errors. However, the number of errors is small and the directories and documents pre-sented are greatly reduced, enabling a user to more quickly browse for slides (or documents of another genre) in the directories.

The system has been demonstrated to many visitors who commented that the addition of genre as a search facet was very useful for narrowing the number of documents. They were excited by the directory thumbnail display that only showed documents of the selected genre. In one instance, we impressed a visitor by how quickly we could locate a slide from his previous visit ten years ago by using a combination of the slide genre and date facets. The system has also been used consistently by several people in our lab for finding old slides or photos to use when creating a new presentation. 7 Conclusions We investigated design considerations for systems that per-form coarse genre classification of office documents. Our set of document-inspired, visual, surface-type features do not require explicit classification into region types, unlike most earlier image-based systems. Experiments comparing these features against a simpler baseline set of image features showed that our visual features perform significantly better in identifying page genre as measured by precision, recall, and balanced F 1-score. Feature selection also improved performance of a text-based genre classifier over a baseline, frequent terms-based classifier, indicating that enhancing the feature set with selected additional terms can improve performance over use of stop words only.

The results show that our image features perform significantly better than our text features. Additionally, the text features do not significantly improve performance in combination with image-based features. Thus, image-based features that capture the layout of a document can be more informative for coarse genre identification than simple tex-tual features. As reported by others, performing genre identi-fication without textual features enables broader applicability to new languages and documents, since textual features may vary with topic.

A simple ensemble method using data partitioning significantly improved the performance of individual one-versus-rest SVM classifiers for page genre identification. Each of our genre models learned the features of the dif-ferent types of pages that occur in a genre, making creation of separate page-type identification models unnecessary.
We incorporated genre identification into a system for browsing and searching a collection of business documents, visibly reducing the document search space. We compared two methods for identifying document genre from page genre scores and used the best method to identify document genres in the collection.

In the future, we would like to investigate whether mod-eling the sequence of page genre labels improves document genre identification. We also would like to extend our meth-ods to identify other genres that would be useful for office documents. And finally, we would like to conduct a user study to examine how genre affects search performance and perceived workload.
 References
