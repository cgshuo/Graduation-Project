 In supervised classification, training is performed on a set of examples with assigned class labels, and the resultin g model is then evaluated on the accuracy of the class labels it assigns to unlabeled data. Semi-supervised classification differs from supervised classification in that additional unlabeled data is available for the algorithm to use in model construction [4]. Krogel and Scheffer [13], for example, experiment with using unlabel ed data to augment experiments on the KDD Cup data, and SSVA [17] uses unlabeled data to enhance a support vector machine.

Propositional learning algorithms represent examples as single objects with values for a given set of attributes. This can make it difficult to represent relation-ships between objects. Relational learni ng employs richer concept descriptions (such as restricted forms of first-order logic, e.g. like the one used in Foil [18]) to overcome this limitation and allow those relationships to be explicitly rep-resented and used in learning. However, this increased expressivity also causes higher computational cost, resulting in learning algorithms with an exponential time complexity.

Propositionalization [12]  X  the process of converting a relational representa-tion of data into a propositional one  X  aims to preserve the relationships within the data while producing a representation for the data that can be used with efficient propositional classification algorithms. This paper presents a two-tiered approach to semi-supervised relational classification that allows for the applica-tion of standard propositional learning algorithms to multi-relational data. In the first stage we propositionalize the relational data using randomly generated first-order rules (similar to the relational association rules generated by WarmR [10]), which are then converted into boo lean features, based on their coverage. The generation process tries to ensure that generated rules are likely to be useful for classification. This is done by requiring that rules cover a certain number of examples within user-specified minima and maxima, thus avoiding both overly specific and overly general rules. Alternatively, in a class-sensitive setting where class labels are actually present, rules c an be selected based on their class-specific coverage similar to the  X  X nrichment X  property of stochastic discrimination [11]. In either setting all rules are turned into boolean attributes generating a propo-sitional representation for the second stage, where the resulting propositional dataset is classified using any standard propositional classifier, such as SMO [16] or others.

This procedure holds promise for semi-supervised learning, as one of the main explanations for the success of semi-superv ised learning is the so-called cluster as-sumption [4]. The unlabeled data enables better estimation of cluster boundaries and can therefore also improve classific ation accuracy. In [1] random relational rules have been shown to work well for the clustering of relational data. Thus their usefulness for semi-supervised lea rning is investigated in this paper. There does not currently appear to be any directly related work on semi-supervised propositionalisation, which means that there is no outside standard with which the experimental results in this paper could be meaningfully compared.
The next section describes the algorit hms in more detail, Section 3 explains and discusses experiments and the final s ection draws conclusions and outlines future work. The RRP (Randomized Relational Propositionalization) algorithm is composed of two tiers: a first stage generates random rules and a second stage transforms these rules into Boolean features for a pro positional representation, which can be used as input for a propositional classification algorithm.

RRP generates definite clauses, which comprise both predicates containing variables and so-called theory constants, as well as tests on and comparisons be-tween these variables and theory constants. Functors and recursion are forbidden. For example, the Mutagenesis dataset comprises the following three predicates:
A molecule is described by two parameters: a unique identifier and a class label (active or inactive). An a tom is described by five parameters: the identifier of the Molecule it belongs to, a unique ident ifier, its element type, its quanta type, and its electrical charge. A bond is descr ibed by four parameters: the identifier of the molecule that it belongs to, the unique identifiers for the two atoms it is linking, as well as its own bond type. An example of a rule generated on that dataset is: active(MolID):-atom(MolID,_,_,_,Charge),
Charge &gt;= 0.078, bond(MolID,_,AtomID1,BondType1), bond(MolID,_,AtomID2,BondType2), BondType1 != BondType2, AtomID1 = AtomID2.

This rule describes all compounds that contain an atom with a charge above 0 . 078 and two bonds of different types that both include a particular atom. Underscores are used here for clarity, to denote variables not used in this rule.
Such random rules are generated in the following way: at each stage a predi-cate or test is chosen uniformly at random with the following restrictions: for a predicate exactly one variable (or parameter) must already appear in the rule; all other variables are new. This ensures that clauses are linked. Tests on the other hand may not add any new variables. Tests include the usual equal and not-equal comparisons to other variables or theory constants, as well as range comparisons for numeric arguments.

To ensure that the generat ed rules allow for classification, constraints are imposed on the generation process. For class-blind rule generation, only rules are accepted that cover more than a user-defined minimum number of instances, and also cover less than a user-defined maximum. This prevents both overly specific and overly general rules. For class-sensitive rule generation, rules are required to be  X  X nriched X , as per Kleinberg X  X  definition [11], where a rule is enriched for a particular class if it covers a greater proportion of examples of that class than it does of the other classes:
The above constraints operate on individual rules. In addition to this, each example should be covered by roughly the same number of rules. This constraint operates at the ruleset level. This  X  X ni formity of coverage X  is produced by gen-erating the random rules in small batches, and then adding the most uniformity-preserving non-zero subset of each batch of rules to the current ruleset. In our experiments the batch size was set to five rules. The coverage of each instance is tracked as rules are added to the ruleset, and the subset that, when added to the current ruleset, gives the smallest standard deviation of instance coverages is determined to be most uniformity-preserving. Algorithm 1. details RRP. Algorithm 1. Pseudocode for the RRP algorithm
The final propositional dataset comprising solely boolean attributes is gen-erated by evaluating each rule on each example in the original dataset. If an example is covered by the rule, the corresponding boolean attribute is set to true, otherwise it is set to false.

The complexity of RRP is the sum of the complexity of both stages. Usually, when using propositionalization in ILP, the propositionalization stage dominates the total complexity, and this is true for RRP as well. Even though generating a random rule is extremely fast, its coverage still has to be determined both for checking the coverage constraints and uniformity of coverage, as well as to generate the propositional dataset. In the worst case this coverage computation requires time exponential in the length of the rule [8]. The complexity of proposi-tional classification algorithms on the contrary is generally polynomial at worst. Still, in practice we find that RRP enjoys very acceptable runtimes. An evaluation of RRP on several datasets has been conducted. Rule generation was performed using three different setups:  X  Semi-supervised Class-blind -generating rules on the full dataset (labeled  X  Standard Class-blind -generating rules only on the labeled training data,  X  Standard Class-sensitive -generating rules only on labeled training data with
The propositionalization stage of RRP-SS is the same as that of RRC, de-scribed in [1]. RRP-CB and RRP-CS differ from RRC in that the propositional-ization is generated on a portion of the data and then applied to the remaining data. RRP-CS differs further in its use of enrichment instead of coverage range.
The resulting propositional data was classified as described in Algorithms 2.-4.  X  using SMO [16], with the  X  X omplexi ty constant X  parameter determined by Algorithm 2. RRP-SS process Algorithm 3. RRP-CB process internal ten-fold cross-validation on the training data. All experiments involved random stratified 50 : 50 splits, i.e. 50% of the data was labeled, and 50% was unlabeled. Twenty repetitions were computed for each setup to produce stable average results. Linear support vector ma chines were used because they proved to be efficient and effective for this type of problems, which comprise at most 2000 examples, but also 1000 attributes, as all setups generated 1000 random rules. Algorithms that are non-linear in the number of attributes (e.g. logistic regression) turned out to be less effectiv e. Competitive alternative algorithms included Random Forests [2] and Alternating Decision Trees [7].

The following standard ILP datasets were used: Mutagenesis (with and with-out regression-unfriendly instances) [19 ], Musk1 [5], Cancer [20], and Diterpenes [6]. Mutagenesis and Cancer only had acces s to low-level struct ural information as represented by atoms and bonds; additional information such as global prop-erties lumo or logP , or predefined functional groups were not included. They are known to improve classification accuracy significantly, thereby potentially masking the relational performance of the investigated algorithms.

For the Diterpenes dataset, as the  X  X nrichment X  procedure is currently limited to two-class problems, in addition to using the full 23-class dataset with RRP-SS and RRP-CB, three additional two-class versions were generated: all pairwise combinations of the three largest classes (called 3, 52 and 54), which could be used with all three algorithms.

For RRP-SS and RRP-CB, several different ranges for rule coverage were investigated: 0.05-0.5, 0.1-0.5, 0.25-0.5 and 0.25-0.75, as well as  X  X xtreme X , which denotes a coverage range limited only by being required to cover at least two Algorithm 4. RRP-CS process instances, and to not cover all instances . All numbers are proportions of the size of the training set.
 The results of this evaluation for the 0.05-0.5 coverage range are shown in Figure 1. All other coverage ranges disp layed similar properties, except for the  X  X xtreme X  setting which performed substantially worse than the other ranges on some of the datasets, particularly the Diterpenes subsets. The poorer per-formance of RRP-CS relative to RRP-CB o n Diterpenes is probably related to the poor performance of the  X  X xtreme X  co verage setting  X  RRP-CS requires that rules be enriched, but places no other restrictions on their coverage, so its rules have the same coverage limits as the  X  X xtreme setting X , and it seems to produce similar results. RRP-SS enjoys a small advantage over both RRP-CB and RRP-CS for Musk1, Cancer and both versions of the Mutagenesis dataset. However, on the Diterpenes datasets, RRP-CB occasionally outperforms RRP-SS.

A possible explanation for this unexpected behavior on the Diterpenes dataset, and in particular the derived two-class subsets thereof, is the fact that they seem to be easier to classify, as the generally high accuracies obta ined in classifica-tion show. This indicates that the number of labeled examples is sufficient to induce strong classifiers. Additional unlabeled data has previously been found to be either irrelevant or even detrimental under such circumstances [4]. To test this potential explanation, additional experiments were conducted with smaller numbers of labelled training examples: 10%, 4%, 2%, and 1%, and the remainder of the dataset in each case used as test ex amples. The results for twenty random train-test splits on Diterpenes(52,54) are depicted in Figure 2, in which the error bars show the standard deviations for the accuracy.
First of all it is surprising that even 1% of the data used for training (eight examples) can produce a model with 68% or even 74% accuracy, depending on the algorithm. The default accuracy for this problem is 55%. Secondly, when comparing mean accuracies, the semi-s upervised approach RRP-SS enjoys the biggest advantage for the smallest number of labeled examples. Furthermore, with larger numbers of labeled data the standard algorithm RRP-CB quickly catches up with the semi-supervised variant. This paper has described a two-tiered approach to semi-supervised relational learning, based on randomized propositionalization and an arbitrary proposi-tional classification algorithm and compared the results to standard train-test learning. The experimental results indicate that the usefulness of the extra infor-mation gained from semi-supervised learning in this case depends on the dataset, and that datasets that are already straightforward to classify with smaller pro-portions of labeled training instances do not benefit greatly from additional unlabeled data. On the other hand, for harder-to-classify datasets and smaller numbers of labeled data the semi-supe rvised approach RRP-SS enjoys a small, but consistent advantage over both standard learning algorithms RRP-CB and RRP-CS.

There are multiple avenues for future work. The propositionalization phase of RRP could be replaced by other propositionalization tools like RSD [22], or class-blind variants of relational rule learners like Foil or Progol [14]. It should also be possible to further exploit the unlabeled data in learning: after the gener-ation of the propositional model the mutual coverage of each boolean feature in the train and test set could be computed andcomparedandtakenintoaccount when inducing the propositional classifier. Preliminary experiments have shown that attributes with larg e differences in coverage between the training and the test set have a detrimental influence on classification accuracy. Such attributes could either be removed from the data, or down-weighted for algorithms capable of dealing with attribute weights.

One of the anonymous reviewers has suggested a intriguing fourth approach: calculating enrichment (which is class-sensitive) on the labeled data, but then determining uniformity on the labeled and unlabeled data. Future work will ex-plore this approach. Contrary to other relational learning algorithms that strive to induce the best possible set of rules, not all random rules have to be evaluated. If rule evaluation time were to exceed a pre -specified time limit, the evaluation could be aborted and the respective rule d iscarded. Again, future work will ex-plore this efficiency versus potential loss of information trade-off in more detail.
Furthermore, after propositionalization, any standard semi-supervised learn-ing algorithm is applicable to the resulting propositional problem, i.e. the method described in this paper is orthogonal to any such method like, e.g., LLGC [23, 15]. If one were to apply standard semi-supervised learning algorithms, which usually rely on some notion of distance or similarity, directly at the relational representa-tion instead of the propositionalization approach put forward in this paper, then relational notions of distance and similarity [21, 9] will need to be exploited. For clustering applications propositionalization has been found to outperform more direct approaches [1], but that may not be the case for semi-supervised learning, and will therefore also be explored in future work.
 Acknowledgments. This work has been funded by a Marsden Grant of the Royal Society of New Zealand.

