 In recent years there has been a growing interest in text quantification, a supervised learning task where the goal is to accurately estimate, in an unlabelled set of items, the prevalence (or  X  X elative frequency X ) of each class c in a prede-fined set C . Text quantification has several applications, and is a dominant concern in fields such as market research, the social sciences, political science, and epidemiology. In this paper we tackle, for the first time, the problem of ordinal text quantification , defined as the task of performing text quan-tification when a total order is defined on the set of classes; estimating the prevalence of  X  X ive stars X  reviews in a set of reviews of a given product, and monitoring this prevalence across time, is an example application. We present OQT, a novel tree-based OQ algorithm, and discuss experimental results obtained on a dataset of tweets classified according to sentiment strength.
 Ordinal Quantification; Quantification; Sentiment Analysis; Ordinal classification (OC  X  also known as ordinal regres-sion , or rating inference ) is the problem of automatically labelling data items x  X  X according to a set of classes C = { c 1 ,...,c |C| } such that |C| &gt; 2 and there is a total order  X  defined on the classes in C . OC is usually viewed as a su-pervised learning problem, whereby the classifier h : X  X  X  needs to be generated from training data. OC is different from standard single-label multi-class (SLMC) classification, since in SLMC there is no order defined on C .

OC is receiving increasing attention from the sentiment analysis and opinion mining community, due to the impor-tance of managing increasing amounts of product reviews  X  Fabrizio Sebastiani is currently on leave from Consiglio Nazionale delle Ricerche, Italy.
 (and opinion-laden data in general) in digital form. An ex-ample of a totally ordered set of classes { VeryNegative , Neg-ative , Fair , Positive , VeryPositive } , according to which cus-tomers may be asked to evaluate a product or service; the case of product reviews evaluated on a scale of 1 to 5 stars is another such example. More generally, OC is of key im-portance in the social sciences, since it is well-known that humans find it cognitively easier to express their judgments and evaluations on ordinal (i.e., discrete) scales.
In this paper we do not deal with ordinal classification, but with ordinal quantification (OQ). Quantification [6] is defined as the task of estimating the prevalence (i.e., rela-tive frequency) p T e ( c i ) of the classes c i  X  X  in an unlabelled set Te , given a set Tr of labelled training items. Quantifi-cation finds its natural application in contexts characterized by distribution drift , i.e., contexts where the unlabelled data may not exhibit the same class prevalences as the test data. Distribution drift may be due to different reasons, includ-ing the inherent non-stationary character of the context, or class bias that affected the selection of the training data.
A na  X   X ve way to tackle quantification is via the  X  X lassify and count X  (CC) approach, i.e., classify each unlabelled item independently and compute the fraction of the unlabelled items that have been attributed the class. However, a good classifier is not necessarily a good quantifier: assuming the binary case, even if ( FP + FN ) is comparatively small, bad quantification accuracy might result if FP and FN are significantly different (since perfect quantification coincides with the case FP = FN ). This has led researchers to study quantification as a task on its own right [1, 4, 6], rather than as a byproduct of classification.

However, while quantification has been studied both for the binary case and the SLMC case, no paper has tackled OQ yet. We do so for the first time by presenting an algorithm for OQ (dubbed OQT) based on  X  X Q-trees X .

In  X  2 we describe OQT, while in  X  3 we discuss experiments we have run on a tweet sentiment analysis dataset. In tackling OC our goal has been to design an algorithm that (a) leverages the information inherent in the class or-dering  X  , and (b) performs quantification in the style of the Probabilistic Classify and Count (PCC) method [1], since this is the method that has proven the best performer in our SLMC text quantification experiments of [7]. We first introduce PCC, since OQT uses it as a subroutine; we will then move on to presenting OQT itself. 1 Function GenerateTree ( C ,Tr,V a ); 2 for j  X  X  1 ,..., ( |C| X  1) } do 3 Train classifier h j from Tr j and Tr j ; 4 end 5 T C  X  Tree( C , { h j } ,V a ); 6 return T C ; 7 Function Tree ( C , H C ,V a ); 8 if C = { c } then 9 Generate a leaf node T c ; 10 return T c ; 12 h t  X  arg min h 13 Generate a node T C and associate h t to it; 16 LChild ( T C )  X  Tree( C t , H 0 C ,V a ); 17 RChild ( T C )  X  Tree( C t , H 00 C ,V a ); 18 return T C ;
Algorithm 1: Function GenerateTree for generating an OQ-tree. PCC, originally proposed in [1], consists of generating a clas-sifier from Tr , classifying the items in Te , and estimating p
T e ( c ) as the expected fraction of items predicted to belong membership in c of the unlabelled item x , (ii) by p T e ( X  c ) we indicate the fraction of items in Te predicted to be in c , and (iii) by E [ x ] we indicate the expected value of x , this corresponds to computing where the  X  X at X  symbol indicates estimation. The rationale of PCC is that posterior probabilities contain richer infor-mation than binary decisions, which are usually obtained from posterior probabilities by thresholding. We will tackle OQ by arranging the classes in C into an OQ-tree ; we thus dub our algorithm OQT. Given any j  X  of C , and C j = { c j +1 ,...,c |C| } will be called a suffix of C . Given any j  X  X  1 ,..., ( |C| X  1) } and a set S of items labelled according to C , by S j we denote the set of items in S whose class is in C j , and by S j we denote the set of items in S whose class is in C j . Our algorithm for training such a tree is described in concise form as Algorithm 1, and goes as follows.

Assume we have a training set Tr and a held-out valida-tion set V a of items labelled according to C . The first step (Line 3) consists of training ( |C| X  1) binary classifiers h j  X  X  1 ,..., ( |C| X  1) } . Each of these classifiers must separate C j and C j ; for training h j we will take the items in Tr the negative training examples and the items in Tr j as the positive training examples. We require that these classifiers, aside from taking binary decisions (i.e., predicting if a test item is in C j or in C j ), also output posterior probabilities, i.e., probabilities p ( C j | x ) and p ( C j | x ) = (1  X  p ( C The second step (Line 5) is building the OQ (binary) tree. In order to do this, among the classifiers h j we pick the one (let us call it h t ) that displays the highest quantification ac-curacy (Line 12) on V a , and we place it at the root of the binary tree. Here, quantification is performed according to the PCC method described in  X  2.1. We measure the quan-tification accuracy of h j via the standard measure for evalu-ating SLMC quantification, i.e., Kullback-Leibler Divergence ( KLD ) 1 , defined as where  X  p is the distribution estimated via PCC using the posterior probabilities generated by h j . We then repeat the process recursively on the left and on the right branches of the binary tree (Lines 14 to 17), thus building a fully grown quantification tree. The algorithm for estimating class prevalences by using an OQ-tree is described in concise form as Algorithm 2, and goes as follows. Essentially, for each item x  X  Te and for each class c  X  C , we compute (Line 6) p ( c | x ); the estimate  X  p
T e ( c ) is computed as the average, across all x  X  Te , of recursive, hierarchical way (Lines 13 to 18), i.e., as the prob-ability that, in a SLMC setting, the binary classifiers that lie on the path from the root to leaf c , would classify item x exactly in leaf c (i.e., that they would route x exactly to leaf c ). This probability is computed as the product of all the posterior probabilities returned by the classifiers that lie on the path from the root to leaf c .

An example quantification tree for a set of |C| = 6 classes is displayed in Figure 1; for brevity, classes are represented by natural numbers, the total order defined on them is the
Note that KLD is a measure of error, and not of accu-racy; i.e., lower values are better. Note also that KLD is lem, in computing KLD we smooth both p ( c j ) and  X  p ( c via additive smoothing, i.e., we compute where p s ( c j ) denotes the smoothed version of p ( c the denominator is just a normalizing factor (same for the  X  p ( c j ) X  X ); the quantity = 1 2  X | T e | is used as a smoothing fac-tor. The smoothed versions of p ( c j ) and  X  p ( c j ) are then used in place of the non-smoothed versions in Equation 3; as a result, KLD is always defined. 1 Function QuantifyViaHierarchicalPCC ( Te,T C ); 2 for c  X  X  do 3  X  p ( c )  X  0 4 end 5 for x  X  Te do 6 CPost( x ,T C , 1); /* Compute the { p ( c | x ) } */ 7 for c  X  X  do 8  X  p ( c )  X   X  p ( c ) + 9 end 11 return {  X  p ( c ) } 12 Procedure CPost ( x ,T C ,SubP ); 13 if T C = { c } then 14 p ( c | x )  X  SubP ; 16 CPost( x ,LChild ( T C ) ,p ( C t | x )  X  SubP ); 17 CPost( x ,RChild ( T C ) ,p ( C t | x )  X  SubP );
Algorithm 2: Function QuantifyViaHierarchicalPCC for estimating prevalences via an OQ-tree. order defined on the natural numbers, and sets of classes are represented by sequences of natural numbers. Note that, as exemplified in Figure 1, OQT generates trees for which (a) there is a 1-to-1 correspondence between classes and leaves of the tree, (b) leaves are ordered left to right in the same order as the classes in C , and (c) each internal node represents a decision between a suffix and a prefix of C .
 Point (c) is interesting, and deserves some discussion. In Figure 1, internal node  X 1234 vs. 56 X  is trained by using and items labelled as 5, or 6, as positive examples; however, by looking at Figure 1, it would seem intuitive that items labelled as 6 should not be used, since the node is root to a subtree where class 6 is not an option anymore. The reason why we do use items labelled as 6 (which is the reason why the node is labelled  X 1234 vs. 56 X  and not  X 1234 vs. 5 X ) is that, during the classification stage, the classifier associated with the node might be asked to classify an item whose true label is 6, and which has thus been misclassified high up in the tree. In this case, it would be important that this item be classified as 5, since this minimizes the contribution of this item to misclassification error; and the likelihood that this happens is increased if the classifier is trained to choose between 1234 and 56, rather than between 1234 and 5. Note also that this is one aspect for which OQT is a true ordinal quantification algorithm: if there were no order defined on the classes this policy would make no sense.

A second reason why OQT is a truly OQ algorithm is that the groups of classes (such as 1234 and 56) between which a binary classifier needs to discriminate are groups of contigu-ous classes. It is because of this contiguity that the trees we generate makes sense: if, say, our classes represent degrees of positivity of product reviews, with 1 indicating most neg-ative and 6 indicating most positive, group 56 may be taken to represent the positive reviews (to different degrees), while 1234 may be taken to represent the reviews that are not pos-itive; a group such as, say, 256, would instead be very hard to interpret, since it is formed of non-contiguous classes that have little in common with each other 2 . The evaluation measure we adopt for our experiments is the only one known for OQ, i.e., the Earth Mover X  X  Distance ( EMD ) [9], a measure well known in the field of computer vision and whose use in OQ was proposed in [4]. When there is a total order on the classes in C , EMD is defined as and can be computed in |C| steps from the estimated and true class prevalences. Like KLD in Equation 3, EMD is a measure of error, so lower values are better; EMD ranges between 0 (best) and |C| X  1 (worst).

The dataset we use is the one released within SemEval 2016 Task 4  X  X entiment Analysis in Twitter X  [8], and con-sists of tweets labelled according to five degrees of sentiment, from VeryNegative to VeryPositive . The dataset comes bro-ken down into subsets TRAIN (6000 tweets), DEV (2000 tweets), and DEVTEST (2000 tweets); we use them for training, parameter optimization, and testing, respectively.
The code that implements our method is available from http://alt.qcri.org/tools/quantification/ Table 1: EMD values obtained by the six meth-ods (lower is better) and percentage of deterioration with respect to the best performer.
 Each of these three sets is broken down into  X  X opics X  con-sisting of 100 tweets each; i.e., the task is to quantify the prevalence of a certain class (say, VeryPositive ) among the comments about a certain topic . One thus needs to com-pute EMD separately on each topic, and then average the results.

For lack of space (and because it is not the main focus of this paper) we do not describe the preprocessing steps we adopt to generate the vectorial representations for our tweets; the details are given in [7,  X  4.1].

We evaluate OQT against the following baselines. The 1st is a PCC SLMC quantifier; it does not take order  X  into account but, as shown in [7] it is a very strong SLMC classifier anyway. The 2nd is a CC quantifier (see  X  1) that uses the SVORIM OC learning algorithm [2]. The 3rd is an ACC ( X  X djusted Classify and Count X   X  see [6,  X  2]) quanti-fier that also relies on SVORIM. The 4th and 5th are again a CC quantifier and an ACC quantifier, this time using an adaptation to ordinal regression of the -SVR metric regres-sion algorithm [3]. While OQT and PCC are not inher-ently SVM-based, we choose SVMs as their base learner, also for better experimental uniformity with the other four methods, which are inherently SVM-based; from now on the two former methods will thus be called OQT(SVM) and PCC(SVM). We use the implementations of (i) standard SVMs, (ii) SVORIM, and (iii) -SVR, as available in the LIBSVM suite 3 . For each learning algorithm we have opti-mized the C parameter (which sets the tradeoff between the training error and the margin) on the DEV set, performing a grid search on all values of type 10 x with x  X  { X  6 ,..., 7 } . Note that both PCC(SVM) and OQT(SVM) (which depends on PCC(SVM)) require as input not the classifier X  X  binary decisions but its posterior probabilities. Since SVMs do not natively generate posterior probabilities, we use the -b op-tion of LIBSVM, which converts the scores originally gener-ated by SVMs into posterior probabilities according to the algorithm of [10].
 The results of our experiments are given in Table 1. Our OQT(SVM) method is the best performer, with PCC(SVM) the second best, with a +5.71% deterioration with respect to OQT(SVM). Two aspects are interesting to discuss here.
The first is that the two best methods are the ones that make use of posterior probabilities, i.e., where class preva-lences are computed as expected values of the binary class as-signments; the other 4 methods are based on CC and ACC, which do not make use of posterior probabilities and use
LIBSVM is available from http://www.csie.ntu.edu.tw/  X cjlin/libsvm/ the binary class assignments instead. This seems a further (albeit indirect) confirmation of the results of [7], where PCC(SVM) emerged as the best of 8 methods in SLMC tweet quantification. The good result of PCC(SVM) is even more striking if we consider that the other 4 methods, which PCC(SVM) beats by a wide margin, leverage the  X  class or-der while PCC(SVM) does not; this seems further evidence of the value of posterior probabilities in quantification.
A second observation is that ACC, a quantification method that has been consistently reported to perform better than CC [1, 5, 7, 6], here performs much worse than CC, in the context of both SVORIM and -SVR. This is an aspect that will deserve further investigation.

In Subtask E of the SemEval 2016 Task 4 shared task (a subtask which deals with ordinal tweet quantification by sentiment  X  see [8]), the system described in this paper ob-tained an EMD score of 0.243, ranking 1st in a set of 10 participating systems, with a high margin over the other ones (systems from rank 2 to rank 8 obtained EMD scores between 0.316 and 0.366). Overall, these results are encour-aging and preliminary at the same time. For the future we plan to run more experiments, using more datasets (e.g., product review datasets) and more baseline systems from the world of ordinal classification and SLMC quantification. [1] A. Bella, C. Ferri, J. Hern  X andez-Orallo, and M. J. [2] W. Chu and S. S. Keerthi. Support vector ordinal [3] H. Drucker, C. J. Burges, L. Kaufman, A. Smola, and [4] A. Esuli and F. Sebastiani. Sentiment quantification. [5] A. Esuli and F. Sebastiani. Optimizing text quantifiers [6] G. Forman. Quantifying counts and costs via [7] W. Gao and F. Sebastiani. From classification to [8] P. Nakov, A. Ritter, S. Rosenthal, F. Sebastiani, and [9] Y. Rubner, C. Tomasi, and L. J. Guibas. The Earth [10] T.-F. Wu, C.-J. Lin, and R. C. Weng. Probability
