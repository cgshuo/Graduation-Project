 Hartigan X  X  pioneering work, direct clustering [13], stimulated a vast amount of research on co-clustering. Co-clustering aims at identifying homogeneous local patterns, each of which consists of a subset of rows and a subset of of columns in a given two dimensional matrix. This idea has attracted genomic researchers, because it is compatible with our understanding of cellular processes, where a subset of genes are coregulated under a certain experimental conditions [5]. Madeira and Oliveira [15] surveyed biclustering algorithms and their applications to biological data analysis.

Cheng and Church [7] are considered to be the first to apply co-clustering, biclustering , to gene expression data. The greed y search heuristic generates bi-clusters, one at a time, which satisfy a certain homogeneity constraint, called mean squared residue . Since then, several similar approaches have been proposed to enhance the original work. For example, Cho et al . [8] developed two mini-mum sum squared co-clustering (MSSRCC) algorithms: one objective function is based on the partitioning model proposed by Hartigan [13] and the other one is based on the squared residue formulated by Cheng and Church [7]. The later is the residue of interest and defined in the next chapter.

Recently, Aguilar-Ruiz [1] shows th at the mean squared residue depends on the scaling variance in the considered data matrix. This finding issues the weak-ness of the residue and the need of new approaches to discover scaling patterns. Motivated by the work, we propose a simple remedy to find scaling patterns, still using the same residue measure. We suggest to take specific data transforma-tions so as to handle hidden scaling factors. In this paper, we apply several data transformations to data matrix models derived from varied scaling and shifting factors and analyze the effect of data transformations on the the second residue, RESIDUE(II) [8]. Furthermore, using MSSRCC, we empirically demonstrate the advantage of the data transformations with publicly available human cancer mi-croarrays. Both analysis and experimental results reveal that column standard deviation normalization and column Z-score transformation are effective.
The rest of this paper is organized as follows: In Section 2 we introduce some definitions and facts used in this paper. We describe the considered data transformations in Section 3. Then, we formally analyze the effects of data trans-formations and summarize the analysis results in Section 4. We discuss the ex-perimental results with human cancer ge ne expression datasets in Section 5. Finally, the paper is concluded with some remark. We adapt the following definitions in Agular-Ruiz [1], Cheng and Church [7], and Cho et al . [8] to fit for our context.
 Data matrix. A data matrix is defined as a real-valued rectangular matrix A  X  R m  X  n ,whose ( i, j ) -th element is denoted by a
For example, a microarray can be defined with two finite sets, the set of genes and the set of experimental conditions. No te that Aguilar-Ruiz [1] describes the microarray whose rows represent experim ental condition and columns represent genes. However, in this paper, we will consider a microarray which consists of examples of genes in rows and attributes as experimental conditions in columns. of the rows in a row cluster and the set of indices of the columns in a column cluster. A submatrix of A induced by the index sets I and J is called a co-cluster set I and J , respectively. In reality, rows and columns in a co-cluster are not necessary to be consecutive. However, for brevity we consider the co-cluster, A
IJ , whose entries consist of first 2.1 Sum Squared Residue In order to evaluate the coherence of such a co-cluster, we define RESIDUE(II) of an element a ij in the co-cluster determined by index sets I and J as below. Residue. RESIDUE(II) is defined as h ij = a ij  X  a iJ  X  a Ij + a IJ ,wherethe a row and column indices are in I and J by a IJ = 1 | I || J | i  X  I,j  X  J a ij . Sum squared residue (SSR). Let H IJ  X  R | I | X | J | be the residue matrix whose entries are described by RESIDUE(II). Then, the sum squared residue of H IJ is defined as SSR = H IJ 2 = i  X  I,j  X  J h 2 ij ,where X denotes the Frobenius norm of matrix X , i.e., X 2 = i,j x 2 ij . 2.2 Patterns We assume A contains both scaling and shifting factors. We borrow the concepts of  X  X ocal X  and  X  X lobal X  scaling and shifting from Cheng and Church [7], Cho et Global/local scaling and global/local shifting patterns. A bicluster con-tains both scaling and shifting patterns when it expresses a ij =  X  i  X   X  j +  X  j , (e.g., experimental condition) j ,and  X  j is the shifting factor for column (e.g., experimental condition) j . We classify the expression into the following four pat-scaling (lsc) and global shifting pattern (gsh) when a ij =  X  i  X   X  j +  X  ;andlocal scaling (lsc) and local shifting pattern (lsh) when a ij =  X  i  X   X  j +  X  j . Raw data values have a limitation that raw values do not disclose how they vary from the central tendency of the distribution. Therefore, transformation of the raw data is considered one of the most important steps for various data mining processes since the variance of a variable will determine its importance in a given model [16]. In this study, we investigate the following data transformations. No transformation (NT). No centering or scaling is taken. In other words, a Through DC, each entry of a data matrix A becomes a ij =(  X  i  X   X   X  )(  X  j  X   X   X  ). Note that we have a i  X  = a  X  j = 0 and consequently a  X  X  = 0, since DC transforms the data matrix to have both row means and column means to be 0.
 Column/row mean centering (MC). Column MC is defined as a ij = a ij  X  a a defined similarly with a i  X  . Therefore, row mean, column mean, and whole mean Column/row standard deviation normalization (SDN). Column SDN is column and row SDN each column and row has a unit variance, respectively. Column/row Z-score transformation (ZT). Column ZT is defined as a ij =  X  X utoscaling X , where the measurements are scaled so that each column/row has a zero mean and a unit variance [14]. Through ZT, the relative variation in intensity is emphasized, since ZT is a linear transformation, which keeps the relative positions of observations and the shape of the original distribution. Now, we analyze the effect of the data transformations on the sum squared residue, RESIDUE(II). Because of space limitation, we focus on analysis on the three data transformations including NT, column SDN, and column ZT, which clearly demonstrate the effect of th e specific data transformation. 4.1 No Transformation (NT) ( i, j )-th entry of row i  X  I and column j  X  J of co-cluster A IJ is described as a ij =  X  i  X  j +  X  j . Then, the mean of the base values of A IJ is computed by  X  and the mean of the shifting factors by  X   X   X  , and the mean of all the elements by a IJ =  X   X   X   X  ues, we obtain RESIDUE(II), h ij =(  X  i  X   X   X  squared residue (SSR) can be computed as SSR = H IJ 2 = i  X  I,j  X  J h 2 ij = and  X  2  X 
In fact, SSR shown above is a revisit of Theorems in Aguilar-Ruiz [1]. It shows with no data transformation that SSR is dependent on both the variance of base values and the variance of scaling factors, but independent from shifting factors. Accordingly, any shifting operations such as DC and MC to the given data ma-trix should not contribute to RESIDUE(II). As also shown in [1], RESIDUE(II) itself has an ability to discover shifting patterns. 4.2 Column Standard Deviation Normalization (SDN) Column SDN transforms A to have the constant global scaling factor, i.e. ,1,and the local shifting factors, i.e. ,  X  j  X  and whole mean of co-cluster A IJ are computed by a iJ = 1 | J | j  X  J 1  X   X  a spectively. Therefore, using RESIDUE(II) , we can capture the perfect co-cluster, i.e. , zero RESIDUE(II), for all the four expression patterns. 4.3 Column Z-Score Transformation (ZT) Column ZT transforms A to have the constant global scaling factor, i.e. ,1,and is transformed as a ij = 1  X   X  co-cluster A IJ is obtained by a iJ = 1  X  whole mean by a Ij = 1  X  REDIDUE(II) for all the possible combinations of scaling and shifting patterns. Now, we empirically show the effect of data transformations on the four pub-licly available human cancer microarray datasets including Colon cancer [2], Leukemia [12], Lung cancer [3], and MLL [3]. With MSSRCC [8][9], we generate 100  X  2 or 100  X  3 co-clusters with random and spectral initializations, setting  X  =10  X  3 A 2 and  X  =10  X  6 A 2 for batch and local search, respectively. De-tailed algorithmic strategies and their contributions are discussed in [9]. Data preprocessing. Since utilizing sophisticated feature selection algorithms is not a main focus, we just apply the simple preprocessing steps usually adopted in microarray experiments as in [6][10][11] to detect differential expression. De-tails are summarized in Table 1. Further, the gene expression values in Colon dataset were transformed by taking the base-10 logarithm.
 Tissue sample clustering evaluation measure. To evaluate the performance of sample clusterings, we quantify tissue sample clustering performance using the following clustering accuracy measure: accuracy (%) = 1 T l i =1 t i  X  100 , where T denotes the total number of samples, l the number of sample clusters, and t i the numbers of the samples correct ly clustered into a sample class i . Performance comparison. Figure 1 illustrates the average tissue sample ac-curacy using MSSRCC with RESIDUE(II). As reported in [9], spectral initial-ization and local search strategy play a significant role in improving MSSRCC performance. However, in this paper, we are more interested in how data trans-formations affect the tissue s ample accuracy performance.

NT, DC, and MC with random initialization ((a)-(d)) and NT and MC with spectral initialization ((e)-(h)) result in nearly similar accuracy. Note that RESIDUE(II) is not affected by shifting factors, but still affected by the scal-ing factors as first articulated in [1] and also revisited in the analysis. To be more specific, the residue with NT on data matrices with local scaling factors is (  X  dependent. In our experiment, DC with random initialization generates com-patible accuracy with that of other data transformations ((a)-(d)), however it is ered datasets, MC presents compatible performance that of NT, but not better than that of either SDN or ZT.
 As analyzed in the previous section, both column SDN and column ZT help MSSRCC with RESIDUE(II) capture perfect co-clusters, thus MSSRCC with column SDN or column ZT is supposed to generate similar accuracy and also better accuracy than those with NT, DC, or MC. Accordingly, they lead to the best accuracy values for most cases ((a)-(h)). Aguilar-Ruiz [1] issues the need of a new metric to discover both scaling and shifting patterns, showing that the sum squared residue can discover any shifted patterns but may not capture some scaled patterns. To answer this need, we propose a simple remedy that helps the residue resolve its dependency on scaling variances. We suggest to take specific data transformations through which the hidden scaling factors are implicitly removed. We analyze the effect of various data transformation on RESIDUE(II) [8] for data matrices with global/local scaling and global/shifting factors.

Both analysis and experimental results reveal that column standard deviation normalization and column Z-score transformation are effective for RESIDUE(II). To be more specific, through MSSRCC with RESIDUE(II) and the two data trans-factors. The transformed matrix contains the constant global scaling factor 1 and
Note that RESIDUE(II) is a special ca se (scheme 6) of the six Euclidean co-clustering schemes in Bregman co-clustering algorithms [4]. Our formal analysis can be applicable to any clustering/co-clustering algorithm that has a proposed analysis to the remaining co-clustering models in Bregman co-clustering algorithms and formally characterize each of Bregman co-clustering algorithms.
