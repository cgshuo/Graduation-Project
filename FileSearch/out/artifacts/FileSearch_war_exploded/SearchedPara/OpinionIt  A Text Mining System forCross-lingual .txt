 Opinion mining focuses on extracting customers X  opinions from the reviews and predicting their sentiment orientation. Reviewers usually praise a product in some aspects and be-moan it in other aspects. With the business globalization, it is very important for enterprises to extract the opinions toward different aspects and find out cross-lingual/cross-culture difference in opinions. Cross-lingual opinion mining is a very challenging task as amounts of opinions are writ-ten in different languages, and not well structured. Since people usually use different words to describe the same as-pect in the reviews, product-feature (PF) categorization be-comes very critical in cross-lingual opinion mining. Manual cross-lingual PF categorization is time consuming, and prac-tically infeasible for the massive amount of data written in different languages. In order to effectively find out cross-lingual difference in opinions, we present an aspect-oriented opinion mining method with Cross-lingual Latent Semantic Association (CLaSA). We first construct CLaSA model to learn the cross-lingual latent semantic association among all the PFs from multi-dimension semantic clues in the review corpus. Then we employ CLaSA model to categorize all the multilingual PFs into semantic aspects, and summarize cross-lingual difference in opinions towards different aspects. Experimental results show that our method achieves better performance compared with the existing approaches. With CLaSA model, our text mining system OpinionIt can effec-tively discover cross-lingual difference in opinions. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; I.2.7 [ Artificial Intelligence ]: Natural language processing X  text analysis Algorithms, Experimentation cross-lingual opinion mining, product feature categorization, latent semantic association
With the dramatic growth of web X  X  popularity, amounts of people can post their reviews or comments for various prod-ucts or services. These textual information exchanged on the Web is written in various languages. With the business glob-alization, it is very important for the enterprises to extract customers X  opinions and find out the cross-lingual distribu-tion difference in opinions. Cross-lingual opinion mining al-ready becomes a critical task for business intelligence. Figure 1: Cross-lingual Opinion Mining System OpinionIt. Pie charts compare the overall sentiment distribution. Bar charts compare the sentiment dis-tribution on product aspects in Chinese and English reviews.
In the real application, we build a cross-lingual opinion mining system OpinionIt . Our goal is to facilitate enterprise to better understand customer concerns. OpinionIt can pro-vide the overall sentiment distribution across languages, and find out fine-grained cross-lingual difference. As shown in Figure 1, the two pies compare the overall sentiment dis-tribution in Chinese and English reviews. The bar charts compare the ratio of positive and negative opinions towards different aspects. From such comparison, one can easily find out the cross-lingual differences in opinions. Since review-ers usually praise a product in some aspects and bemoan it in other aspects, such aspect-oriented cross-lingual opinion mining provides more business insights for enterprises.
Cross-lingual opinion mining is a very challenging task since amounts of opinions are written in different languages, and not well structured. In OpinionIt , in order to effectively find out cross-lingual difference in opinions, we present an aspect-oriented opinion mining method with Cross-lingual Latent Semantic Association (CLaSA). The proposed method first constructs CLaSA model to categorize all the multilin-gual PFs into unified semantic categories, and then sum-marizes cross-lingual difference in opinions towards different aspects. From the viewpoint of text mining, we essentially use CLaSA model as a latent semantic association frame-work to find out cross-lingual difference in opinions.
Since people may use various linguistic representations to refer to the same PF in the multilingual reviews, PF catego-rization is always the key challenge for cross-lingual opinion mining in the real applications. Its quality directly impacts cross-lingual opinion mining. Although some product speci-fications are provided by the merchants, customers and mer-chants may use different words to refer to the same aspect. For example, English PFs  X  photo  X ,  X  picture  X ,  X  image  X , a n d Chinese PFs  X  ZhaoXiang (i.e. photograph)  X  X nd X  PaiZhao (i.e. photograph)  X  all refer to the same aspect in digital camera reviews. It is tedious and time consuming to man-ually categorize all the PFs from the reviews in different languages. Hence, it raises the need for automatically cat-egorizing all the multilingual PFs into a unified semantic categorization framework. Although some methods [14, 23, 24, 3, 27, 8] have been presented to build individual model for clustering PFs in one language. In order to create a uni-fied cross-lingual PF categorization, all the PF clustering re-sults in different languages need to be manually merged or aligned. Such manual alignment is practically infeasible for the massive amount of multilingual data. Hence, we present a CLaSA model for cross-lingual PF categorization. It cate-gorizes all the multilingual PFs into unified semantic groups according to the multi-dimension cross-lingual latent seman-tic clues in the review corpus. These clues include: 1) the current PF term pf ;2) pf  X  X  machine translation pf T ;3)com-ponent words in pf and pf T ; 4) word-level latent semantic topics for component words in pf and pf T ; 5) monolingual PF-level latent semantic of pf .

One important contribution of our method is that we cre-ate cross-lingual virtual context document for each PF with a bag of PF, its machine translation and mono-lingual latent semantic clues. These language-mixed virtual documents ef-fectively characterize the latent association among PFs from different languages. The intuition behind our method is that words and terms in one concept set will have similar seman-tic features or latent semantic association, and share similar context in the corpus. They can be considered as behaving in the same way in the cross-lingual PF categorization. The proposed CLaSA model categorizes the multilingual PFs on a semantic level rather than by lexical comparison. It can better approximate the true underlying semantic category distribution in the domain without any labeled samples. Experimental results show that our method achieves better performance compared with the existing approaches. With CLaSA model, we can find out cross-lingual difference in opinions by effectively joining reviews between languages.
The remainder of the paper is organized as follows. Sec-tion 2 introduces some related work. Section 3 proposes cross-lingual latent semantic association method. Section 4 presents cross-lingual opinion mining with CLaSA model. The experimental results are discussed in Section 5. The conclusion is given in Section 6.
The task of opinion mining is to extract customers X  opin-ions from the reviews and predict their sentiment orienta-tion. Some papers [14, 10, 11, 12, 18, 20, 29, 22] focus on mining opinions from monolingual customer reviews. Many of these methods are dependent on the training data set, so are not generally applicable to cross-lingual opinion min-ing. Lu et al. [15] integrate monolingual expert reviews and customer reviews through semi-supervised topic modeling. Mei et al. [17] propose a mixture model to discover facets and opinions in the monolingual reviews at the same time. Several works also study cross-lingual analysis of sentiment and concerns [1, 19, 7, 5]. They analyze sentiment distri-bution in multilingual news and blogs collected with a topic keyword, and mine comparative difference of concerns. In this paper, we present a cross-lingual opinion mining method with CLaSA model. With CLaSA model, we can find out cross-lingual difference in opinions from customer reviews.
PF categorization is a key task for cross-lingual opinion mining. Some methods have been presented for monolin-gual PF categorization. Liu et al. [14] group PFs by the synonym set in WordNet and the semi-automated tagging of reviews. Titov and McDonald [23] employ rating infor-mation to identify coherent aspects in the reviews. They further propose a multi-grain topic model to cluster aspects [24], which considers the distributions of both global top-ics for a document and local topics for the local context of the word. Brananvan et al [3] cluster all the keyphrases in the monolingual reviews based on the lexical compari-son and the distribution similarity. The lexical comparison is based on the cosine similarity among the phrase words while the distributional similarity is quantified in terms of the co-occurrence of keyphrases across review texts. Wong et al. [27] extract and normalize product attributes from the structured product descriptions provided by merchants in multiple web sites. However, merchants and customers may use different words to refer to the same feature. Guo et al. [8] present a monolingual PF categorization method, which constructs the categorization model according to the internal latent semantic and external context snippets of the PFs in the reviews. Different from these methods, in this paper, we present CLaSA model for cross-lingual PF cate-gorization, which categorizes all PFs according to the multi-dimension cross-lingual latent semantic clues in the reviews.
Topic model has been successfully applied to mine topic patterns from text collections, and enhance document rep-resentations in text classification and information retrieval [2, 9, 28, 13, 26]. Our work adds another novel use of such models for cross-lingual PF categorization.
Since people may use various PF terms to refer the same aspect in the reviews, PF categorization is the key task in cross-lingual opinion mining. The challenge in PF catego-rization is how to capture latent semantic association among the PFs. In this section, we present CLaSA model to find out the cross-lingual association structures among the PFs.
Each product aspect often has various terms. For exam-ple, English PFs  X  photo  X ,  X  picture  X ,  X  image  X , and Chinese PFs  X  ZhaoXiang (i.e. photograph)  X  X nd X  PaiZhao (i.e. pho-tograph)  X  all refer to the same aspect. Hence, it is a big challenge for us to effectively capture latent semantic asso-ciation among multilingual PF terms from the reviews.
Cross-lingual PF categorization focuses on categorizing the PFs into a unified semantic category framework. Let X be a feature space to represent the multilingual PF in-stances, and let Y be the set of semantic category labels. Let p ( x, y )and p t ( x, y ) be the predicted underlying category distribution and the true underlying category distribution, respectively. In order to minimize the human efforts, we ex-pect to p s ( x, y ) better approximate p t ( x, y ) without using any labeled data.

Cross-lingual PF categorization based on lexical compari-son is usually not comprehensive enough to capture the un-derlying semantic distribution of various multilingual PFs. Many PF terms in the same aspect are not similar on the lexical level. However, these terms often appear in the sim-ilar semantic context. For instance, PF terms in the aspect  X  appearance  X  often occur around the indicates  X  beautiful  X ,  X  fashion  X ,  X  popular  X  etc. Such latent semantic association among words provides useful hints for capturing the under-lying semantic distribution in the domain.

Hence, we present CLaSA model  X  to capture cross-lingual latent semantic association among the multilingual PFs.  X  is learned from the unlabeled review corpus. In the learn-ing, each PF term is characterized by multi-dimension cross-lingual latent semantic clues. These clues include: 1) the current PF term pf ;2) pf  X  X  machine translation entry pf 3) component words in pf and pf T ; 4) word-level latent semantic topics for component words in pf and pf T ;5) monolingual PF-level latent semantic of pf . Semantic as-sociation feature in  X  is a hidden random variable that is inferred from data. Even though PF terms do not have the lexical similarity, but are in similar context, they still might have relatively high probability in the same semantic con-cept set. Obviously,  X  can better capture the cross-lingual latent semantic association among the PFs. With  X , we may better approximate the real semantic category distribution p ( y | x ;  X ) without using any labeled data.
In order to learn latent relationships among multilingual terms, each PF term is characterized by a cross-lingual vir-tual context document. Given a PF term pf , its cross-lingual virtual context document cvd pf is composed of the following multi-dimension latent semantic clues.
Hence,
For example, given pf =  X  X creen resolution X  ,Table1shows its cross-lingual virtual context document cvd ( X  screen reso-lution  X ) extracted from English and Chinese review corpus. Table 1: Cross-lingual virtual context document
In the cross-lingual virtual context document construc-tion, we generate monolingual word-level and PF-level la-tent semantic topics using the algorithms presented in [8]. Component words are grouped into a set of latent topics ac-cording to their context in the monolingual corpus. Mono-lingual PF-level latent semantic topics are generated accord-ing to their latent semantic structures and context snippets in the corresponding corpus. Section 4.1 will illustrate how to construct the cross-lingual virtual context document in CLaSA-based PF categorization. Full-document machine translation is usually employed to capture the semantic asso-ciation among PFs written in different languages. However, with the limitation of the existing machine translation tech-niques, data noise arose from full-document machine transla-tion often make a bad impact on the cross-lingual semantic association. In order to reduce the noise arose from ma-chine translation, the cross-lingual virtual context document employs PF term machine translation instead of full-review translation. cvd pf actually describes multi-dimension cross-lingual la-tent semantic features of pf in the reviews. We construct the feature vector of pf with all the observed features in cvd pf . Given the feature vector of cvd pf , Vector ( cvd = { x 1 , ..., x j , ..., x m } , x j denotes the jth context feature re-lated to pf , m is the total number of features in cvd pf weight of each context feature x j in cvd pf is calculated by Mutual Information [6] between pf and x j .
 where, P ( x j ,pf ) is the joint probability of pf and x occurred in the corpus, P ( x j ) is the probability of x curred in the corpus. P ( pf ) is the probability of pf occurred in the corpus. The weight is normalized to non-negative in the model training.
CLaSA model actually can be considered as a general probabilistic topic model. It can be learned from the un-labeled review corpus using the hidden topic models such as Latent Dirichlet Allocation (LDA) [2] and probabilistic Latent Semantic Indexing (pLSI) [9].

Topic models are statistical models of text that posit a hidden space of topics in which the corpus is embedded [2]. LDA is a probabilistic model that can be used to model and discover underlying topic structures of documents. LDA as-sumes that there are K  X  X opics X , multinomial distributions over words, which describes a collection. Each document exhibits multiple topics, and each word in the document is associated with one of the topics. LDA imposes a Dirichlet distribution on the topic mixture weights corresponding to the documents in the corpus. The topics derived by LDA seem to possess semantic coherence. Those words with sim-ilar semantics are likely to occur in the same topic. Algorithm 1 : CLaSA Model Training In the following, we illustrate how to learn LDA-style CLaSA model  X  on the cross-lingual virtual semantic con-text documents. Given the unlabeled review corpus R l 1 and R 2 written in the languages l 1 and l 2 . The cross-lingual vir-tual context document of each PF is first constructed (see Section 3.2.1). Given a PF term pf written in Language l . In cvd pf construction, latent topics of component words are generated using the monolingual word-level topic model  X  l Monolingual latent semantic of each PF is generated using the monolingual PF-level topic model  X  l mp The weight of each feature in cvd pf i is computed using Mutual Information (see Equation 1 in Section 3.2.1). Then, CLaSA model  X  with Dirichlet distribution is generated on the cross-lingual virtual context document set CV DSet using the algorithm presented by Blei et al [2]. In our experiments,  X  =0.1, and the number of iterations is 1000. Algorithm 1 describes the whole process in detail, where, Function MT ( pf i )de-notes that the machine translation result of pf i . Function TP ( data,  X  ) generates the latent topic for data using the la-tent topic model  X  ;  X  l wd denotes the monolingual word-level latent topic model for the given language l ;  X  l mp denotes the monolingual PF-level latent topic model for the given language l ;
CLaSA model learns the posterior distribution to decom-pose multilingual PFs and their virtual context documents into topics. It extends the traditional bag-of-words topic models to context-dependence cross-lingual concept associ-ation model.
In OpinionIt , we present an aspect-based cross-lingual opinion mining framework with CLaSA model. The pro-posed method first constructs CLaSA model to categorize the multilingual PFs into semantic aspects, then summarizes cross-lingual difference in opinions toward different aspects.
In the multilingual reviews, people often use various terms to refer to the same feature. It is very important to catego-rize PFs into semantic aspects in cross-lingual opinion min-ing. In order to capture latent semantic association among various opinions, we learn CLaSA-based cross-lingual PF categorization model  X  using Algorithm 1 in Section 3.2.2. Given the unlabeled review corpus R l 1 and R l 2 , the cross-lingual virtual context documents of all the PFs are first constructed from the review corpus. Then, PF categoriza-tion model  X  is trained on these virtual documents. It learns the posterior distribution to decompose multilingual PFs
In CLaSA-based PF categorization model learning, the cross-lingual virtual context document for each PF term is constructed from the review corpus as follows.

Component words in the PF term are important indica-tors for semantic categorization. Hence, in the cross-lingual virtual context document construction, given a PF term pf written in language l , we employ the word-level topic model  X  wd to generate the latent topics of component words in pf . where, TP ( w j , X  l wd ) generates word w j  X  X  topic using  X  Model  X  l wd is learned from the monolingual review corpus R l using the algorithm presented in [8]. It can effectively group the component words into a set of concepts accord-ing to their context in the corpus. In the model  X  l wd con-struction, each word is characterized by all the context units around it in the corpus. For example, given word k =  X  X creen X  , sen i =  X  X y new thinkpad is very good because its LCD screen is very large and nice X  . In the context window { -3, 3 (i.e. previous 3 words and next 3 words around word k in sen i ), the context feature set around  X  X creen X  in sen i cludes: 1) the current word: A c ( screen ); 2) left/right opinion sets (i.e., two left/right adjacent adjective units): O L O
L ( new ), O R ( large ), O R ( nice ); 3) the nearest left/right ad-jacent units: A L ( LCD ), A R ( is ); 4) the other two left/right adjacent context unit sets: C L ( its ), C L ( because ), C C R ( large ).
 Table 2: latent semantic topics of some component words in cell phone domain
Table 2 shows some latent topics of component words gen-erated by the model  X  l wd . As shown, words in the same topic actually are grouped into broad concept sets. For ex-ample, topic 4, 8, 12 and 16 are related to the concepts appearance , storage , screen and entertainment , respectively. Hence, in the cross-lingual virtual context document con-struction, we can effectively generate the latent semantic topics for the component words using the model  X  l wd . For ex-ample, S ( X  standard sd card  X ) = { T opic 32, T opic 8, T opic 2
In the cross-lingual virtual context document construc-tion, given a PF term pf written in language l ,weemploy the monolingual PF-level topic model  X  l mp to generate the monolingual latent semantic for pf ,thatis, where, TP ( pf,  X  l mp ) generates pf  X  X  monolingual latent topic using  X  l mp .Model  X  l mp is learned from the review corpus R using the algorithm presented in [8]. Model  X  l mp assigns a monolingual latent semantic topic to pf according to its internal latent topic structure and external context snip-pets in the corpus R l . The internal latent semantic struc-tures of pf (denoted by ts ( pf )) is defined as the topic la-bel sequence of all the words in pf ,thatis, X  t 1 t 2 .... t .... t n  X , w h e r e , t j denotes the jth word X  X  latent topic as-signed by the word-level latent topic model  X  l wd . For exam-ple, ts (  X  X tandard sd slot X  )=  X  Topic32 Topic8 Topic8  X . T h e external context set of pf in a sentence sen k is composed of a bag of all the non-stop words in sen k . For example, given pf =  X  X CD screen X  , sen k =  X  X ts LCD screen is very nice X  ,its context units consist of {  X  LCD  X ,  X  screen  X ,  X  nice  X  }
In LDA-style CLaSA model  X , the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all the cross-lingual virtual context documents. Hence, given aPF pf i in the reviews, we may perform posterior infer-ence to determine the conditional distribution of the hidden topic feature variables associated with pf i .Thesemantic category of pf i (denoted by Category ( pf i )) is generated us-ing Algorithm 2. Here, Mult( X ( cvd i )) refers to sample from the posterior distribution over topics given a cross-lingual virtual document cvd i .

With all the multi-dimension latent semantic clues ex-tracted from the reviews, the CLaSA-based PF categoriza-
Algorithm 2 : Generate semantic category for PF term pf i Using K -topic CLaSA Model tion model can better capture the cross-lingual semantic cat-egory distribution without any labeled data. Even though PF terms do not have the lexical similarity, but are in sim-ilar latent semantic context, they still might have relatively high probability in the same semantic category.
In OpinionIt , we focus on mining cross-lingual opinions towards different aspects. Given a collection of multilingual customer reviews, and CLaSA-based cross-lingual PF cate-gorization model  X . Our aspect-oriented opinion integration approach consists of the following stages. 1. Categorize all the multilingual PFs into semantic as-2. Extract the opinions towards different aspects. 3. Summarize cross-lingual difference in opinions towards
In OpinionIt , all the multilingual PFs are first categorized into sematic aspects using CLaSA model (see Algorithm 2). Then, we extract the PF-Opinion pairs from the mul-tilingual reviews and group them into the aspect-oriented opinion sets. We associate PF and opinions by their co-occurrence in the reviews. Given a PF term pf , we first find out its nearest neighboring opinion word within the clause using rule-based linguistic analysis. We attach this near-est adjacent opinion word to pf . Then we check a polarity lexicon for the sentiment polarity of the opinion word, and attach the sentiment polarity to the semantic aspect of pf . The sentiment strength for a product aspect c i is obtained by summing up all the attached sentiment orientation with the aspect. Finally, we summarize the cross-lingual/cross-culture difference in opinions, such as PF aspects ranking and finer-grained sentiment difference on each aspect. In the opinion integration, by projecting the multilingual PFs into a unified semantic category framework, we may well organize all the opinions towards different aspects, and find out cross-lingual difference in sentiment distribution.
In this section, we evaluate the proposed approach using both English and Chinese customer reviews in cell phone and laptop domains. We first evaluate the performance of cross-lingual PF categorization in both domains in detail. Then, we discuss the cross-lingual difference in opinions.
We build English and Chinese customer review corpus for cell phone and laptop domain (see Table 3). The English data for cell phone and laptop domains respectively are col-lected from the popular product review web sites. The Chi-nese data for cell phone and laptop domains respectively are collected from Chinese review web sites. We automati-cally extracted all the multilingual PFs from these data sets using the statistical-based PF extraction method presented in [8]. In the preprocess, we employ a Maximum Entropy part-of-speech (POS) tagger to generate POS tagging for English data, and employ HMM to segment Chinese words and generate POS tagging for Chinese data. All the PFs are translated by the machine translation engines.
 Table 4: Cross-lingual PF categorization evaluation sets for cell phone domain
We build evaluation sets on 15 PF aspects of cell phone domain and 10 aspects of laptop domain (see Table 4 and 5). These aspects are concerned by most reviewers. Here,  X  X MS X  denotes  X  short message  X . All the PFs are checked manually. If a PF term satisfies the specification of PF aspects, we give it the relevant label. The quality is ensured by cross-validation checking.
In the experiments, we categorize the multilingual PFs of each domain into semantic aspects, and mine aspect-oriented cross-lingual difference in opinions. In the follow-ing, we will analyze these experimental results in detail. Table 5: Cross-lingual PF categorization evaluation sets for laptop domain In this section, we evaluate the performance of cross-lingual PF categorization in the given two domains. In the experi-ments, all the extracted multi-lingual PF terms in each do-main are grouped into semantic aspects, respectively. The performance of PF categorization is evaluated using Rand Index [21], a measure of cluster similarity [3, 25, 4]. This measure varies from zero to one. Higher scores are better.
We compared our CLaSA method (see Algorithm 1 in Sec-tion 3.2.2) with k-means clustering [16] and LDA-based cat-egorization method (denoted as LDA-based ). In k-means clustering, each PF term is characterized by a bag of the current PF term pf , its machine translation pf T ,andtheir component words. In LDA-based categorization method, the virtual context document of each PF is also composed of pf , pf T , and their component words. LDA-based PF cate-gorization model is learned from the virtual context docu-ments using Blei X  X  algorithm [2]. Each PF is assigned to an aspect using this LDA-based model.
 Figure 2: Cross-lingual PF categorization samples of CLaSA model in cell phone domain
In the experiments, all the multi-lingual PF terms in each domain are categorized using these methods, respectively. Experimental results show that CLaSA effectively groups the multi-lingual PFs into semantic aspects. Figure 2 and 3 list some categorization samples of CLaSA in cell phone and laptop domains, respectively. As shown, English and Chinese PF terms in each aspect are representative. Even though some PFs in the same aspect have little similarity on the lexical level, they are also correctly categorized. This shows that CLaSA model can effectively capture the cross-lingual latent semantic association among the PFs. Figure 3: Cross-lingual PF categorization samples of CLaSA model in laptop domain
Selecting the right number of topics is also an important problem in the PF categorization. A range of 50 to 300 topics is typically used in the topic modeling literature. 50 topics are often used for small collections and 300 for rel-atively large collections [26]. However, in the cross-lingual PF categorization, the number of topics might be set in a different range. It is confirmed here by our experiments with different values of K (10, 20, ...,100) in the two domains.
We evaluate the accuracy curves of these methods with different number of topics K in each domain. Experimental results show that CLaSA and LDA-based methods achieve better accuracy than k-means in each domain, as shown in Figure 4 and 5. The major reason for significant perfor-mance enhancement is that CLaSA and LDA-based methods effectively capture the latent semantic association clues from the reviews. Moreover, CLaSA also outperforms LDA-based method at all the operation points in each domain by us-ing multi-dimension cross-lingual latent semantic clues. In the real applications, in order to provide non-trivial opinion mining and summarization, the number of the final product aspects is usually less than 20 topics. Experimental results show, at K =20 , the score of CLaSA method achieves 0.9150 and 0.8723 in cell phone and laptop domains, respectively. Compared with K-means , CLaSA significantly enhances the accuracy by 3.56% and 4.28% respectively. Compared with LDA-based method, CLaSA improves the accuracy by 1.98% and 0.88%, respectively. We perform t-tests on all the com-parison experiments in all the domains (see Figure 4 and 5). p-value &lt; 0.01 on both 20 comparison experiments of k-means and CLaSA , and 20 comparison experiments of LDA-based method and CLaSA . This shows that the enhancement is statistically significant.
 Figure 4: Cross-lingual PF categorization evaluation on cell phone domain with different number of topics Figure 5: Cross-lingual PF categorization evaluation on laptop domain with different number of topics
Table 6 shows the performance comparison of these meth-ods with different number of topics ( K ). The evaluation measure is average rand index score of each method on all the given domains with a predefined K . CLaSA always ob-tains much better average score than k-means and LDA-based methods at each predefined K . Moreover, the average score of CLaSA method is above 0.8937 at K=20.

We also evaluate the impact of CLaSA model on the mono-lingual PF categorization in cell phone and laptop domains. In this experiment, we respectively do English PF catego-rization and Chinese PF categorization using LDA, k-means and CLaSA. Both LDA and k-means construct the feature vector for each monolingual PF with a bag of the current PF and its component words. CLaSA model constructs the fea-ture vector for each PF with the language-mixed virtual con-text document which consists of the current PF, its machine translation and latent semantic clues. Experimental results show that monolingual PF categorization using language-mixed virtual context documents also outperforms doing it in one language alone. Figure 6 shows the average perfor-mance of English PF categorization in both domains. The Table 6: Comparison of k-means clustering, LDA-based method and CLaSA with different number of topics ( K ). The evaluation measure is the average rand index score of each method on all the domains with a predefined number-of-topics (K).  X  P denotes the percentage change in performance (measured in average rand index score) of CLaSA over k-means or LDA-based method. evaluation measure is the average rand index score of each method on all the domains with a predefined number-of-topics (K). As shown, at each operation point, the average score of English PF categorization is significantly enhanced by CLaSA model. The similar trends are observed on Chi-nese PF categorization (see Figure 7). We perform t-tests on all the comparison experiments on mono-lingual PF catego-rization in both domains, p-value &lt; 0.001 on both 40 com-parison experiments of k-means and CLaSA . And p-value &lt; 0.01 on 40 comparison experiments of LDA method and CLaSA . Both p-value show that the performance is signifi-cantly improved by CLaSA model.
 Figure 6: The impact of CLaSA model on English PF categorization. The evaluation measure is the average rand index score of each method on all the domains with a predefined number-of-topics (K).

All the above experimental results show that CLaSA pro-duces better cross-lingual PF categorizations than LDA-based method and K-means . The major reason for the sig-nificant enhancement is that CLaSA better captures deeper cross-lingual latent semantic association among the PFs. CLaSA better approximates the underlying semantic distri-bution without using any labeled data.
In this section, we discuss the cross-lingual opinion mining results of OpinionIt . In the experiments, we use the above CLaSA model to categorize all the multilingual PFs. Based on the CLaSA-based PF categorization, OpinionIt further integrates opinions towards different aspects, and summa-Figure 7: The impact of CLaSA model on Chinese PF categorization. The evaluation measure is the average rand index score of each method on all the domains with a predefined number-of-topics (K). rizes cross-lingual PF aspects and the finer-grained senti-ment distribution difference in both cell phone and laptop review corpus.

Table 7 shows the ranking lists of the PF aspects in cell phone and laptop domains. All the PF aspects are ranked according to their distribution ratio in the review corpus. Given an aspect c i , the distribution ratio of c i in the mono-lingual review corpus is defined as n N ,where, n is the number of the reviews in which c i is reviewed; N is the total number of the reviews. Experimental results show that the ranking is varied with the languages. For example, in cell phone do-main, Appearance is the top 1 aspect concerned in Chinese reviews while OS is the top 1 aspect concerned in English reviews. The different ranking in English and Chinese re-views indicates the cross-culture difference in the aspects concerned by people.
 Table 7: Ranking list of the PF aspects in English and Chinese reviews for cell phone and laptop do-mains
Figure 8 and 9 respectively demonstrate the distribution ratio of PF aspects in English and Chinese reviews for cell phone and laptop domains. From these experimental results, we may have the following observations. 1) In cell phone do-main (see Figure 8), the advanced applications Web Browser and Email are more concerned by English customers than Chinese customers. The basic aspects Appearance , Screen , Sound , Ringtone and SMS are more concerned by Chinese customers. Only aspect user-interface has the similar dis-tribution in both English and Chinese reviews. 2) In laptop domain (see Figure 9), the aspects screen , os , processor , bat-tery and keyboard are more concerned by English reviewers. Only the aspects appearance and fan are more concerned by Chinese reviewers. From all the above finer-grained statis-tical distribution, one can easily find out the cross-lingual difference in customer concerned aspects.
 Figure 8: Cross-lingual difference in the distribution ratio of PF aspects in the cell phone reviews Figure 9: Cross-lingual difference in the distribution ratio of PF aspects in the laptop reviews
Figure 10 and 11 respectively demonstrate the sentiment distribution of each aspect in English and Chinese reviews for two popular cell phone brands.  X  en  X  X nd X  zh  X  X enote English and Chinese. Each bar in both figures shows the percentage of positive (above x-axis) and negative (below x-axis) opinions on an aspect in the domain. Given an aspect c i , the overall distribution ratio of the positive (or negative) opinions on c i is defined as m M ,where, m is the number of the positive (or negative) opinions on c i , M is the total number of all the opinions in the monolingual cor-pus. The overall ratio is further normalized for cross-lingual comparison. These figures enable the user to clearly see cross-lingual difference in opinions. For example, for both brands, the advanced applications browser and email are more concerned by English customers while the basic as-pects appearance , SMS and sound are more concerned by Chinese customers. Especially, for brand 2, Aspect os is more concerned by English customers (see Figure 11) while aspect ringtone is more concerned by Chinese customers. Moreover, English customers express more negative opin-ions about aspects battery and keyboard while more Chinese customers have positive opinions about both aspects. Re-garding aspects screen and storage of both brands, there are similar sentiment distribution in both English and Chinese reviews.
 Figure 10: The sentiment distribution on PF aspects in English and Chinese reviews for brand 1 Figure 11: The sentiment distribution on PF aspects in English and Chinese reviews for brand 2
Cross-lingual opinion mining is a very challenging task since various opinions are written in different languages, and not well structured. Since people usually use differ-ent words to describe the same aspect in the multilingual reviews, PF categorization is critical for high-quality cross-lingual opinion mining. In our text mining system Opin-ionIt , we present an aspect-oriented cross-lingual opinion mining method with CLaSA model. The proposed method first constructs CLaSA model to categorize the PFs into semantic categories, and then summarizes cross-lingual dif-ference in opinions toward different product aspects. One important contribution of our work is that we present a CLaSA-based unified cross-lingual PF categorization frame-work. With language-mixed virtual context documents, the proposed unsupervised CLaSA model can better capture the semantic association between different languages. Experi-mental results show that our method achieves better per-formance compared with the existing approaches. With the CLaSA model, OpinionIt can find out finer-grained cross-lingual/cross-culture difference in opinions by effectively join-ing reviews between languages. Our proposed method is quite general, and can be applied to integrate cross-lingual opinions about any product in any domain, thus potentially has many interesting applications. [1] M. Bautin, L. Vijayarenu, and S. Skiena. International [2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [3] S. Branavan, H. Chen, J. Eisenstein, and R. Barzilay. [4] C. Cardie and K. Wagstaff. Noun phrase coreference [5] C. Cesarano, A. Picariello, D. Reforgiato, and [6] K. W. Church and P. Hanks. Word association norms, [7] T. Fukuhara, T. Utsuro, and H. Nakagawa.
 [8] H. Guo, H. Zhu, Z. Guo, X. Zhang, and Z. Su.
 [9] T. Hofmann. Probabilistic latent semantic indexing. In [10] M. Hu and B. Liu. Mining and summarizing customer [11] M. Hu and B. Liu. Mining opinion features in [12] W. Jin, H. H. Ho, and R. K. Srihari. Opinionminer: A [13] W. Li and A. McCallum. Pachinko [14] B. Liu, M. Hu, and J. Cheng. Opinion observer: [15] Y. Lu and C. Zhai. Opinion integration through [16] J. B. MacQueen. Some methods for classification and [17] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. [18] P. Melville, W. Gryc, and R. D. Lawrence. Sentiment [19] H. Nakasaki, M. Kawaba, T. Utsuro, and [20] B. Pang and L. Lee. Seeing stars: Exploiting class [21] W. M. Rand. Objective criteria for the evaluation of [22] Q. Su, X. Xu, H. Guo, Z. Guo, X. Wu, X. Zhang, [23] I. Titov and R. McDonald. A joint model of text and [24] I. Titov and R. McDonald. Modeling online reviews [25] K. Wagstaff, C. Cardie, S. Rogers, and S. Schroedl. [26] X. Wei and B. Croft. Lda-based document models for [27] T.-L. Wong, W. Lam, and T.-S. Wong. An [28] C. Zhai, A. Velivelli, and B. Yu. A cross-collection [29] L. Zhuang, F. Jing, and X. Zhu. Movie review mining
