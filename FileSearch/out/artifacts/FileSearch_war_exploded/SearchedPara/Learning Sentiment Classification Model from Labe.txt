 We propose a novel framework where an initial classifier is learned by incorporating prior information extracted from an existing sen-timent lexicon. Preferences on expectations of sentiment labels of those lexicon words are expressed using generalized expectation criteria. Documents classified with high confidence are then used as pseudo-labeled examples for automatical domain-specific feature acquisition. The word-class distributions of such self-learned fea-tures are estimated from the pseudo-labeled examples and are used to train another classifier by constraining the model X  X  predictions on unlabeled instances. Experiments on both the movie review data and the multi-domain sentiment dataset show that our approach at-tains comparable or better performance than exiting weakly-supervised sentiment classification methods despite using no labeled docu-ments.
 I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Text analysis ; H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Infor-mation filtering Algorithms,Experimentation Sentiment analysis, Opinion mining, Generalized expectation, Self-learned features, Weakly-supervised classification
With the explosion of people X  X  attitudes and opinions expressed in social media including blogs, discussion forums, tweets, etc, de-tecting sentiment or opinion from the Web is becoming an increas-ingly popular way of interpreting data. The objective of sentiment analysis is to determine the overall attitude, either positive, nega-tive, or neutral, expressed in a give piece of text. Most prior work in sentiment analysis view sentiment classification as a text classifi-cation problem where an annotated corpus with documents labeled with their sentiment orientation is required to train the classifiers. As such they lack of portability across different domains. More-over, the rapid evolution of user-generated contents demands sen-timent classifiers that can easily adapt to new domains with mini-mum supervision. This thus motivates the investigation of weakly-supervised or unsupervised sentiment analysis approaches.
While supervision for a sentiment classifier can come from la-beled documents, it can also come from labeled words. For exam-ple, the word  X  excellent  X  typically conveys positive sentiment. A simple approach of using such polarity words for sentiment classi-fication is to compare the frequency of occurrence of positive and negative terms in a document. However, it does not normally give good results. In recent years, much effort has been devoted to in-corporate prior belief of word-sentiment associations from a sen-timent lexicon into classifier learning by combining such lexical knowledge with a small set of labeled documents [1, 4, 7].
Other weakly-supervised sentiment analysis approaches typically adopt the self-training strategy [11, 8]. They start with some ini-tial seed sentiment lexicon and then use iterative training to en-large the lexicon. Documents classified at the current iteration are used as self-labeled instances to train a classifier for the next it-eration. Other approaches use ensemble techniques by combining lexicon-based and corpus-based algorithms [10]. Nevertheless, all these approaches are either complex or require careful tuning of domain and data specific parameters. More recently, Dasgupta and Ng [2] proposed a weakly-supervised sentiment classification algo-rithm by integrating user feedbacks into a spectral clustering algo-rithm. Features induced for each dimension of spectral clustering can be considered as sentiment-oriented topics. Nevertheless, hu-man judgement of identifying the most important dimensions dur-ing spectral clustering is required.

In this paper, we propose a simple and robust strategy that works by providing weak supervision at the level of features rather than instances. We obtain an initial classifier by incorporating prior in-formation extracted from an existing sentiment lexicon into a senti-ment classifier model learning, where preferences on expectations of sentiment labels of those lexicon words are expressed using gen-eralized expectation criteria [6]. Documents classified with high confidence by this initial classifier are used to derive a set of self-learned and domain-specific features that are related to the distribu-tion of the target classes. Such self-learned features are then used to train another classifier by constraining the model X  X  predictions on unlabeled instances.

We evaluate our proposed framework on the movie review data and the multi-domain sentiment dataset and show that our method attains comparable or better performance than other previously pro-posed weakly-supervised or semi-supervised methods for sentiment classification despite using no labeled instances. The rest of the pa-per is structured as follows. The proposed framework is introduced in Section 2. The experimental setup and results are presented in Section 3. Finally, Section 4 concludes the paper and outlines di-rections for future research.
We propose a novel framework for sentiment classifier learning from unlabeled documents. The process begins with a collection of unannotated text and a sentiment lexicon such as the MPQA sub-jectivity lexicon 1 . An initial classifier is trained by incorporating prior information from the sentiment lexicon which consists of a list of words marked with their respective polarity. For example, the word  X  good  X  typically conveys a positive sentiment. We refer such prior information as labeled features and use them directly to constrain model X  X  predictions on unlabeled instances using general-ized expectation (GE) criteria. The initially-trained classifier using GE is then applied on the unannotated text and the documents la-beled with high confidence are fed into the self-learned features ex-tractor to acquire domain-dependent features automatically. Such self-learned features are subsequently used to train another classi-fier which is then applied on the test set to obtain the final results.
The remainder of the section will describe the proposed frame-work in details.
Assuming that we have a total number of S sentiment labels de-noting by S = { positive, negative } in a typical sentiment clas-sification task; a corpus with a collection of D documents is de-noted by D = { w 1 , w 2 , ..., w D } where the bold-font variables denote the vectors; each document in the corpus is a sequence of N d words denoted by w = ( w 1 , w 2 , ..., w N d ) , and each word in the document is an item from a vocabulary V index with V distinct terms denoted by { 1 , 2 , ..., V } .

Suppose we have a classifier parameterized by  X  , the sentiment label s of a document w is found by maximizing P ( s | w ;  X ) . As-sume we have some labeled features where words are given with their prior sentiment orientation, we could construct a set of real-valued features of the observation to expresses some characteristic of the empirical distribution of the training data that should also hold of the model distribution. where  X  ( x ) is an indicator function which takes a value of 1 if x is true, 0 otherwise. Equation 1 calculates how often feature k and document label j co-occur in an instance.
 We define the expectation of the features as where  X  P ( w ) is the empirical distribution of w in document corpus D , and P ( s | w ;  X ) is a conditional model distribution parameter-ized at  X  .

We define a criterion that minimizes the KL divergence of the expected label distribution and a target expectation  X  f , which is es-sentially an instance of generalized expectation criteria that penal-izes the divergence of a specific model expectation from a target http://www.cs.pitt.edu/mpqa/ value.
 We can use the target expectation  X  f to encode human or task prior knowledge. For example, the word  X  excellent  X  typically represent a positive orientation. We would expect that this word more likely appears in positive documents.

The final objective function consists of a GE term for each la-beled features k  X  K with a zero-mean  X  2 variance Gaussian prior on parameters for regularization.
 In our experiments, we set  X  = 0 . 1 and use L-BFGS to estimate model parameters.

In order to build a classifier based on GE, we need to first se-lect the indicative feature words for each class, decide on their re-spective class labels, and suggest the target or reference word-class distribution for each feature. We will investigate various ways in doing these in Section 3.1.
An initial classifier is built using the labeled features obtained from a sentiment lexicon and is subsequently applied on the doc-ument collection to infer sentiment labels. Documents with their labels inferred with high confidence from the initial classifier are added into a labeled document pool which is used to extract self-learned features following Algorithm 1. There is then a question on how to automatically select high quality classification results. This is more crucial to self-training since the model prediction is error prone and therefore pseudo-labeled examples with wrong labels might degrade the model performance during the iterative train-ing process. In our algorithm presented here, we simply choose pseudo-labeled examples based on their posterior probability of class membership and use the class prediction probability thresh-old  X  to filter out low confidence pseudo-labeled examples. Our experimental results show that the proposed algorithm is not sen-sible to the setting of  X  and we can simply ignore this parameter and select all the self-labeled examples for word-class distributions estimation.

Given the pseudo-labeled examples generated, we first select the most indicative feature words for each class based on information gain. We set the information gain threshold  X  as the mean of the information gain scores of the top 200 most predictive features. The expected word-class distribution for a given word w  X  X  is defined the j th element is the probability of a sentiment label s = j being assigned given that word w is present in a document.
We evaluate our proposed framework on the two datasets, the movie review (MR) dataset 2 and the multi-domain sentiment (MDS) dataset 3 . The MDS dataset contains four different types of prod-uct reviews extracted from Amazon.com including Books, DVDs, Electronics and Kitchen appliances. Preprocessing was performed on both of the datasets by removing punctuation, numbers, non-alphabet characters and stopwords. The MPQA subjectivity lexi-con is used as a sentiment lexicon in our experiments. http://www.cs.cornell.edu/People/pabo/ movie-review-data/ http://www.cs.jhu.edu/~mdredze/datasets/ sentiment/ Algorithm 1 Self-learned features extraction Input: The document collection D = { w 1 , w 2 , ..., w D Output: Self-learned features with their expected distribution, F = { ( w ,  X  f ( w 1 )) , ( w 2 ,  X  f ( w 2 )) , ... } 1: Construct an initial classifier upon samples of D = { w } with prior information obtained from L 2: for each document w i  X  X  do 3: Infer its sentiment class label as s i = arg max s P ( s | w 4: if P ( s i | w i ;  X ) &gt;  X  then 5: Add labeled sample ( w i , s i ) into a labeled document pool B 6: end if 7: end for 8: for each distinct word w t from the labeled document pool B do 9: Calculate the information gain IG ( w t ) based on B 10: if IG ( w t ) &gt;  X  then 11: Calculate the target expectation of w t ,  X  f ( w t ) from B 12: Add ( w t ,  X  f ( w t )) into the self-learned feature list F 13: end if 14: end for
We randomly split the data with 90% data used as the training set and the remaining 10% data used as the test set. For all the results reported in this section, we performed 10 random splits and report the classification accuracy averaged over 10 such runs. It has to be noted that no labeled instances were used in the classifier training in our proposed framework.
We compare our proposed approach with several other methods as described below: Table 1 shows sentiment classification accuracies on the MR and MDS datasets using the different methods mentioned above. All the approaches outperform the baseline model which classifies doc-uments based solely on the aggregated sentiment scores calculated from a sentiment lexicon. Incorporating the prior knowledge from the sentiment lexicon and training a classifier using these labeled features based on the GE criterion brings the classification accuracy to over 70% for almost all the datasets except the Books data. Us-ing the Self-learned features , the classification accuracy is further improved by 3.35% to 8.95% with all improvements being statis-tically significant compared to other methods according to paired t -tests ( p &lt; 0 . 05 ).

We also notice that Self-labeled instances only improves the clas-sification accuracy marginally compared to Heuristic labeling and it performs consistently worse than Self-learned features . The re-sults suggest that Self-learned features appears to be a better choice since it does not introduce new examples with incorrect labels. In-stead, it calculates word-class association probabilities by averag-ing over many pseudo-labeled examples which essentially has a smoothing effect and makes it more tolerant to class prediction er-rors. Thus, contrary to self-training, it avoids the incestuous bias problem.

If the true document labels are revealed, the exact target expecta-tion for each feature can be calculated from the labeled corpus and we observe that Oracle labeling performs better than Self-learned features and achieves similar classification accuracies on the MR and Electronics datasets compared to the supervised Na X ve Bayes approach.
Li et al. [4] employed lexical prior knowledge extracted from a sentiment lexicon that was developed in the IBM India Research Labs [9] for semi-supervised sentiment classification based on non-negative matrix tri-factorization. Such domain-independent prior knowledge was incorporated in conjunction with domain-depen-dent unlabeled data and a few labeled documents for model learn-ing. With 10% of labeled documents for training, the non-negative matrix tri-factorization approach performed much worse than our approach with a difference of 8%-11% for Heuristic labeling and 13%-15% for Self-learned features on both MR and MDS. Even with 40% labeled documents, their approach is still slightly worse than Self-learned features which uses no labeled documents.
Lin and He [5] conducted a comparative study of three closely re-lated Bayesian models for sentiment classification, namely, the la-tent sentiment model (LSM), the joint sentiment-topic (JST) model, and the Reverse-JST model. They incorporated sentiment prior in-formation extracted from both the MPQA subjectivity lexicon and the appraisal lexicon 4 by modifying conditional probabilities used in Gibbs sampling during model learning. The best sentiment clas-sification results were obtained using LSM with 74.1% on MR and 69.3% on MDS. Our Heuristic labeling slightly outperforms LSM on MDS. Self-learned features gives a similar result on MR, but outperforms LSM on MDS by nearly 6%.

Dasgupta and Ng [2] proposed a weakly-supervised sentiment classification algorithm where user feedbacks are provided on the spectral clustering process in an interactive manner to ensure that text are clustered along the sentiment dimension. Users are allowed to specify the dimension along which they want the data points to be clustered via inspecting a small number of words. They re-moved words that occur in only a single review and the top 1.5% words after sorting the vocabulary by document frequency. And we did not perform such preprocessing. Their proposed approach achieved 70.9% classification accuracy on MR and an average of 68.95% on the MDS dataset. Our Heuristic labeling gives slightly better performance on both datasets and Self-learned features out-performs their approach by a margin of nearly 4% on MR and 6% on MDS.
In this paper, we have proposed a novel framework where prior knowledge from a generic sentiment lexicon is used to build a clas-sifier where preferences on expectations of sentiment labels of those lexicon words are expressed using generalized expectation criteria. Pseudo-labeled documents by this classifier are used to automati-cally acquire domain-specific feature words whose word-class dis-tributions are estimated and are subsequently used to train another classifier by constraining the model X  X  predictions on unlabeled in-stances. Experiments on both the movie review data and the multi-domain sentiment dataset show that our approach attains compara-ble or better performance than exiting weakly-supervised sentiment http://lingcog.iit.edu/arc/appraisal_ lexicon_2007b.tar.gz classification methods despite using no labeled documents. More-over, our approach is simple and robust and does not require careful parameter tuning. Although this paper primarily studies sentiment analysis, the proposed approach is applicable to any text classifica-tion task where some relevant prior knowledge is available.
A promising direction for future work is to incorporate ontology engineering into weakly-supervised model learning. By incorpo-rating domain-independent knowledge from a sentiment lexicon as well as domain knowledge from ontologies, we are hoping to reveal both topics and sentiment labels of a document simultaneously. [1] A. Andreevskaia and S. Bergler. When specialists and [2] S. Dasgupta and V. Ng. Topic-wise, Sentiment-wise, or [3] G. Druck, G. Mann, and A. McCallum. Learning from [4] T. Li, Y. Zhang, and V. Sindhwani. A non-negative matrix [5] C. Lin, Y. He, and R. Everson. A Comparative Study of [6] A. McCallum, G. Mann, and G. Druck. Generalized [7] P. Melville, W. Gryc, and R. D. Lawrence. Sentiment [8] L. Qiu, W. Zhang, C. Hu, and K. Zhao. Selc: a [9] G. Ramakrishnan, A. Jadhav, A. Joshi, S. Chakrabarti, and [10] S. Tan, Y. Wang, and X. Cheng. Combining learn-based and [11] T. Zagibalov and J. Carroll. Automatic seed word selection
