 1. Introduction and the iron ages and at present we are in the  X  X  X omposite age X  X .
Superior mechanical characteristics of composite materials such as high stiffness to weight ratio compared to conventional metals and their inherent amenability towards the tailoring of their proper-ties have made them indispensable. With their low cost and weight benefits, composite laminated plates, a class of composite materials, are extensively used in mechanical , automobile, aerospace, marine, biomedical, civil and other bran ches of engineering. Composite laminates are a series of lamina or plies of varying thicknesses and various fiber orientations stacked in a certain order to obtain desired directional stiffness and strength properties as required for an acceptable design. Diverse material behaviors, tailored to specific structural needs, can be obtained by slightly altering the properties of these composites. With such char acteristics at dispense the choice or the configuration of such materia ls is left to the manufacturer and is influenced by the application of the composite.

Composite design optimization typically involves identifying the optimal laminate stacking sequence, ply thickness and the optimal number of plies. Such design variables generally have very vast ranges which contribute to the enormity of the number of solutions offered. Hence manufacturers are often burdened with the laborious process of selecting the right combination of elements from the many choices available to them. Hence, optimization of the available solutions becomes necessary.
Composite design optimization involves tackling combinator-ial problems determined by their design variables with very vast solution spaces, rendering the problem under the class of con-strained non-linear optimization problems (CNOP). Of these solutions those with the least weight and cost are preferred over the rest. Specifically in aerospace applications, weight minimiza-tion and reducing manufacturing cost has always been a priority in the manufacturing industry owing to benefits such as reduced fuel consumption and an increased payload. Therefore, the focus is on combined minimization of manufacturing cost and struc-tural weight. This multi-objective nature of the problem and the difficulty in selecting the right values out of a large range of constrained design variables makes mathematical optimization a natural tool for the design of laminated composite structures ( Gurdal et al., 1999 ).

Optimum fiber orientations of lam inated composite plates, for the maximum strength taken as the objective function, using state space based methods under multiple in-pl ane loading conditions with Tsai-Wu failure criterion for several test problems are carried out by Kim et al. (1997) ). Adali et al. (1996) have discussed the weighted average method of multi-objective design of symmetrically laminated plates for different criteria like maximum strength, stiffness and minimum mass. Topal and Uzmana (2010) have developed a modified feasible direction (MFD) method for the multi-objective optimization of symmetrical angle-ply, square laminated plates subjected to biaxial compressive and uniform thermal loads in order to maximize the buckling load.

The emergence of heuristics such as Genetic Algorithm, Ant colony Optimization, Tabu Search, etc in solving functional optimization problems has brought in its wake the possibility of solving many problems like Traveling Salesman Problem, Quad-ratic Assignment and Graph problems, network routing, cluster-ing, data mining, job scheduling and problems of NP-complete nature ( Garey and Johnson, 1979 ) and proves to be a viable alternative to traditional mathematical tools which suffer from drawbacks such as local minimum trapping and single-path searching among others. The multi-objective design optimization of composite laminated structures, also being an NP-complete natured problem, has been solved using various nature-inspired algorithms ( Ghasemi and Ehsani, 2007 ; Pelletier and Senthil, 2006 ; Deka, 2005 ; Boyang et al., 2000 ; Luersen and Holdorf Lopez, 2009 ). Many researchers have developed different approaches to minimize the weight and cost of laminated composite structures. Of the many heuristic techniques available PSO has become increasingly popular andhasfoundmanyapplications.
 Particle swarm optimization (PSO) developed and introduced by Kennedy and Eberhart (1995) , is an effective stochastic, non-gradient based global optimization algorithm derived by simulating social behavior depicted by a flock of birds, where each individual gleans from its own as well as the whole flock X  X  discoveries. It is applicable for a wide range of non-linear function optimization problems. PSO X  X  global search capability and insensitivity to scaling design variables ( Schutte et al., 2005 ) makes it particularly suitable forproblems( Kovacs et al., 2004 ) similar to that considered in this paper. PSO supersedes Genetic algorithm ( Hassan et al., 2005 )inthe context of ease of implementation and proves computationally superior to traditional gradient-based algorithms ( Snyman, 2004 ).
Vector evaluated particle swarm optimization (VEPSO) ( Parsopoulos and Vrahatis, 2002 ), a multi-swarm variant of the PSO, an algorithm that adopts and modifies the main ideas of vector evaluated genetic algorithm (VEGA) ( Schaffer, 1985 )is particularly suited for multi-objective (MO) optimization pro-blems ( Goel et al., 2007 ; Deb, 2001 ) where often the objectives are competing, incommensurable and need simultaneous optimi-zation. VEPSO algorithm is based on the principle where each swarm is exclusively evaluated with one of the objective func-tions, but, information coming from other swarm(s) is used to influence its motion in the search space. The best position attained by each particle separately and the global best positions from a different swarm are the main guidance mechanisms of the swarm. The information exchange among swarms enables opti-mizing all the objective functions involved.

In the proposed case of the composite design optimization problem, because the minimization of weight does not necessarily ensure the minimization of the corresponding cost, because of the disparate nature of the objective functions, VEPSO has been adopted and fitness evaluations based on the objectives of minimizing the weight and cost are carried out by two separate swarms deployed in a vast solution space where mutual exchange of information between swarms governs them towards a convergence point  X  indicating movement of the swarms towards a near optimal solution. Despite its applicability and simplicity, PSO and its variant
VEPSO take long durations for the completion of the optimization process due to the application problem X  X  complexity and the nature of algorithms adopted which look to simulate socio-cognitive behavior by pursuing a sequential approach to phenom-ena that are innately parallel in nature.

Since the inception of computer science as a discipline, computer scientists and engineers have realized that a possible route to accelerating the execution of a computational task is to exploit the parallelism inherent in its program flow. Recent advancements in scientific computing techniques and the emergence of parallel programming platforms have help ed in achieving quicker execution of complex problems through parallelization of serial algorithms.
Such related work can be seen in literature ( Oh et al., 2009 ; Yua et al., 2007 ; Parsopoulos et al., 2004 ).

Of the many available paradigms, Message-passing on cluster computers is one of the main programming paradigms used for high performance scientific computing these days. Message passing interface (MPI) is a specification standard defined by a broadly based group of parallel computer vendors, library writers, and applications specialists ( William Gropp et al., 1996 ; The MPI
Forum, 1995 ). MPI is a de-facto standard for message-passing used for developing high-performanc e portable parallel applications ( Matsuda et al., 2008 ; Hempela and Walkerb, 1999 ). MPI standard defines a library of routines that implement the message-passing model ( Gropp et al., 1994 ). The function of MPI, as the name implies, is to help several concurrently computing processes communicate by passing messages between them ( William Gropp et al., 1996 ) .
Many researchers have carried out master-slave paradigm based parallel implementations using the message passing model ( Coello Coello and Sierra, 2004 ; Schutte et al., 2004 ; Dubreuil et al., 2006 ).
Long execution time owing to the computational complexity of the problem, despite the use of popular heuristics like PSO and its variant VEPSO, and the availability of parallel programming environments, and the need to test the suitability of the relatively unused peer-to-peer paradigm for this line of research, were the driving forces behind the present work leading to parallelization of the VEPSO algorithm for the composite design optimization problem. The novelty of this parallelization lies in the use of MPI X  X  collective operations, such as bcast and allreduce ( Bova and Carey, 2000 ), which enable the development of a decentralized/peer-to-peer relationship between communicating nodes to solve the composite problem, as opposed to point-to point operations such as send and receive ( Houzeaux and Codina, 2003 ), which support master-slave architecture ( Gorlatch, 2002 ).

To summarize, for this work, a novel parallel VEPSO algorithm is presented, based on decentralized/peer-to-peer paradigm, to optimize the design of composite plates, based on the principles of classical laminate plate theory (CLPT)  X  to determine the stresses at each layer subjected to Uniformly Distributed Load and Point load. To check for failure two failure criteria are used  X  Maximum Stress ( Narayana Naik et al., 2011 ) failure criterion and Tsai-Wu ( Narayana Naik et al., 2011 ) failure criter-ion. This computation problem has been decomposed into paral-lelizable parts and run concurrently on a Linux-based IBM P720 cluster computer in tandem with MPICH v.1.2.7, a high perfor-mance portable implementation of MPI. The decomposition is such that the computation roles of individual particles of the swarms, which solve the optimization problem, are assumed by the different nodes of the cluster computer and to enable com-munication among these particles/nodes, emulating swarm com-munication behavior, MPI X  X  collective communication primitives are made use of. Thus particles configured on different nodes, initialized with stochastically generated design configurations, perform calculations iteratively and in parallel to finally arrive at an optimum or near optimum design configuration. The results show a considerable decrease in the execution time of the parallel algorithm compared to the serial one. To further compare this parallel approach with a more commonly used heuristic for this problem domain, a parallel vector evaluated genetic algorithm has been implemented using MPI and executed on the same platform. Effective execution time comparisons of the algorithms are presented in the results and discussion sections. Execution time of the present parallel approach for VEPSO is found to be comparatively less than its GA counterpart. This approach, at the time of writing the paper, is the first to use MPI X  X  collective communication to develop a peer-to-peer based parallel VEPSO for composite plate optimization. This work is primarily a follow-up to a previous work ( Omkar et al., 2008 ) in our efforts to find faster ways of solving the composite optimization problem and confirming the efficacy of new methods (such as peer-to-peer parallelization) for the problem domain, starting with a smaller problem used here. The scalability and the speedup that this novel decentralized parallel technique offers shows promise in application to problems of higher complexity in the field and hence our future efforts will consider longer execution problems. explanation of basics of the multi-objective problems. Section 3 discusses the emergence of PSO and VEPSO. Section 4 elucidates the details of the problem and its formulation and outlines the optimization process. Section 6 explains the necessity of VEPSO.
Section 7 explains MPI X  X  role in the parallelization used for the algorithms and its implementation to the optimization problem.
Sections 8 and 9 includes the results, discussion, comparisons, and conclusions, respectively. 2. Multi-objective optimization (MO) f i  X  x  X  : S -R , i  X  1 , ... , k be objective k functions defined over S . Let, g i  X  x  X  r 0 , j  X  1 , ... , m be m inequality constraints, then MO problem is nothing but straints and optimizes the function F  X  x  X  X  X  f 1  X  x  X  , ... , f k  X  x  X  : R n -R k it is not possible to obtain the global minimum at the same point for all the objectives. The goal of such multi-objective optimiza-tion problems is to provide a set of Pareto optimal solutions ( Goel et al., 2007 ; Deb, 2001 ).
 tion means finding the global minimum) and u i r v i for at least one component. This property is known as Pareto dominance and it is used to define the Pareto optimal points. Thus, a solution x of the MO problem is said to be Pareto optimal if and only if there does not exist another solution y, such that F ( y ) dominates F ( x ). called Pareto optimal set and it is denoted as P T and PF  X  X  f 1  X  x  X  , ... , f k  X  x  X  X  9 x A P T is called Pareto front. 3. Particle swarm optimization (PSO) zation algorithm proposed by Eberhart and Kennedy while attempting to simulate the motion of bird flocks as part of a socio-cognitive study investigating the phenomenon of  X  X ollective intelligence X  in biological populations. In Particle swarm optimi-zation (PSO) each swarm unit/particle explores a possible solution depending on the point in the search space where it exists. Its trajectory is influenced by its own as well as the entire swarm X  X  learning. The personal best position is the best solution that is found by the particle in the course of flight. The best position of the whole flock is the global best solution. The former and latter are called personal best and global best, respectively. Every unit/ particle of the swarm continuously updates itself through the aforementioned best solutions. T hus, particles move in the defined solution space to finally converge at a possible optimal point. In practice, the fitness function, which is determined by the optimiza-tion problem, determines the quality of solutions at various points in the search space of the problem at hand.

If the population of swarm is N , then the current position of the i th, ( 8 i  X  1,2,3, y , N ) particle is expressed as X best position discovered by the i th particle is expressed as pBest i ( t ). The global best position of the whole swarm is expressed as gBest ( t ). Therefore, the i th swarm particle updates its own speed and position according to the following equations:
V  X  t  X  1  X  X  w V i  X  t  X  X f C p r 1  X  pBest i  X  t  X  X i  X  t  X  X g
X  X  t  X  1  X  X  X i  X  t  X  X  V i  X  t  X  1  X  X  2  X  where Cp is the Cognitive learning rate and Cg is the Social learning rate. The factors r 1 and r 2 are randomly generated within the range {0, 1} and w is the inertia factor. Eq. (2) updates the position of the particle while Eq. (1) updates the velocity and is composed of three components. The first component is the former speed, V i ( t )of the swarm particle, which shows its present state; the second component is the cognition modal, which expresses the thought of the individual swarm particle itself; the third component is the social modal. These three parts together determine the solution space searching ability. The first component balances the whole and searches local region. The second component empowers the swarm particle to search the whole search space and avoid local minimum. The third component is a reflection of the global influence on the particle. Under the influence of these three components, the swarm has good coverage and tends to converge at globally optimum positions. There are numerous methods for solving multiple objective problems using the PSO algorithm ( Parsopoulos and Vrahatis, 2002 ;
Hu and Eberhart, 2002 ; Hu et al., 2003 ; Coello Coello and Lechuga, 2002 ; Pulido and Coello Coello, 2004 ). One of the most common approaches is to aggregate all the objective functions with appro-priate weights into a single objective function ( Parsopoulos and
Vrahatis, 2002 ). This requires problem analysis to assign appropriate weights for each of the objective functions. The nature of the current problem and the objectives being considered compels separate evaluation of these objectives. Hence, we X  X e used Vector Evaluated
PSO proposed by Parsopoulos and Vrahatis, 2002 . 3.1. Vector evaluated PSO (VEPSO)
VEPSO is a multi-swarm variant of PSO, is an approach to multi-objective optimization ( Reyes-Sierra and Coello Coello, 2006 ), which is inspired by the vector evaluated genetic algorithm (VEGA) ( Schaffer, 1985 ).InVEPSO,twoormoreswarmsareemployedto probe the search space and information is exchanged among them ( Parsopoulos and Vrahatis, 2002 ). The key issue in these co-evolu-tionary algorithms is that the fitness of an individual in a population depends on the individuals of a di fferent population. Searching capabilities of the algor ithm using co-evaluation techniques enhance the capability of the VEPSO algori thm to better explore the search space ( Parsopoulos and Vrahatis, 2002 ; Shang-Jeng Tsai et al., 2010 ). The salient features of VEPSO are explained in detail below:
The VEPSO method assumes that M swarms S 1 , y , S M each of size N aim to optimize simultaneously M -objective functions. Each swarm is exclusively evaluated according to one of the objective functions. Let [ j ] S i ( t  X  1) be the new updated position,
V i ( t  X  1) the new updated velocity, [ j ] P i ( t ) the current personal of the i th particle in the j th swarm, respectively, at a given time t. Let [ k ] P gb ( t ) be the global best position of the k th swarm at the same time t . Then the VEPSO swarms are updated according to Eqs. (3) and (4)  X  t  X  1  X  X   X  j S i  X  t  X  X   X  j V i  X  t  X  1  X  X  4  X  where the superscripts represent the PSO parameters for the j th swarm. Cp is the Cognitive learning rate and Cg is the Social learning rate. The factors r 1 and r 2 are randomly generated within the range {0, 1} and w i is the inertia factor. The VEPSO assumes that the search behavior of a swarm is affected by a neighbouring swarm  X  k th swarm. The parameter k is determined by the information migration scheme between the multiple swarms. 4. Application of VEPSO for design optimization
In the present work, the design of a composite plate, simply supported on all four edges, subjected to uniformly distributed load and point load is considered. The design is governed by the arrangement of constituent plies that make up the composite plate, the stacking sequence, and the stresses and strains developed on each ply of the composite plate are obtained from classical laminate plate theory (CLPT). Using these stresses and strains, failure of a particular design configuration is checked using Maximum Stress and Tsai-Wu failure criteria. The solution to the application problem involves selecting that stacking sequence which minimizes both the weight and cost of the designed composite plate and at the same time passes the above mentioned failure check. This design config-uration being composed of many va riables with wide ranges renders the solution space enormous. To reduce the time taken to find the optimum or near optimum solution, VEPSO is made use of. Two different swarms, with objectives of minimizing weight and cost, respectively, are deployed in the search space. Initially, the particles of both the swarms are assigned a randomly generated design configuration. With this, the p articles communicate with other particles of their own swarm as well as certain particles from the other swarm, progressively explor ing the solution space, until all of them converge at a point which coincides with the globally optimum solution. In the remaining part of this section the experi-mental setup, how the CLPT, in tandem with failure criteria, is used to check for the feasibility of designing composite plates and how VEPSO benefits the process of select ing a cost and weight effective plate configuration among many feasible configurations has been discussed. 4.1. The composite laminate plate design
The Composite laminate plate considered in the present work is composed of a Carbon/Epoxy FRP. The material properties of which are listed in Table 2 .

The mathematical model, similar to the one used in Omkar et al. (2008) , for a plate simply supported on all four edges is discussed in Section 4.1.1 with a detailed description of the structural analysis in
Section 4.1.2 . From this mathematical formulation we obtain the deflections for different types of loading conditions from which we get the stresses required to evaluate if the design satisfies various failure criteria. 4.1.1. Simply supported rectangular plate
A thin rectangular composite laminated plate of length a in x-direction, width b in the y -direction, and thickness h in the z -direction as shown in Fig. 1 is considered in the present work.
The plate is assumed to be constructed of arbitrary number, n , of linearly elastic orthotropic layers. Each layer consists of homogeneous fiber reinforced composite material and the plate is simply supported on all four edges. A rectangular Cartesian coordinate system x , y and z is used to describe the infinitesimal deformations of an n -layer laminated composite plate. The laminate consists of n plies with the individual thicknesses h
Total thickness of the plate is h and bottom and top surfaces are located at z  X  h /2 and z  X  h /2, respectively. We assume that the middle surface of the undeformed plate coincides with the xy-plane. The principal fibre direction is oriented at an angle y to the x-axis. 4.1.2. Composite plate structural analysis
Classical lamination plate theory (CLPT) is used to develop an analytical solution for a specially orthotropic carbon/epoxy compo-site laminate plate with Stress Strain relations for a symmetric angle ply laminate. Navier methods are employed for designing of rectan-gular composite plate with all fo ur edges of the plate as simply supported. The mathematical model and the equations governing static bending in absence of in-plane and thermal forces are x elaborately discussed in Robert Millard (1999) and relations between mechanical properties of the plates (for example  X  fibre orientation) and the stresses and strains ind uced in them are established. 4.2. Types of loading work is subjected to two types of transverse loading conditions; uniformly distributed and point load and the deflections it under-goes under these loads yield the stresses that are need to evaluate their feasibility through failure criteria. 4.2.1. Uniformly distributed load uniformly distributed over the surface are of the composite plate and is defined by the function q ( x , y ). The deflections which the plate undergoes is again discussed in[Robert Jones, Mechanics of composite materials ( Section 5.3.1 )]. 4.2.2. Point load point on the surface and is given by the point load function q ( x , y ). The deflections which the plate undergoes is discussed in Robert
Millard, (1999) . 4.3. Failure criteria lamina failure criteria predicts failure in the laminate. Laminate failure is the eventual result of progressive failure processes taking place in the constituent laminas under loading. Failure envelopes are predicted by linear laminate analysis, providing an extremity for the solution, and defining a specified boundary and solution space ensuring a failsafe design. Various failure criteria proposed by different researchers have been used as an effective tool in evaluation of stress strain behavior and design of compo-site laminates ( Shi and Eberhart, 1998 ) and for this work X  X  analysis Maximum Stress and Tsai-Wu failure criteria are used. 4.3.1. Maximum stress failure criteria
The composite plate ply fails when one of the following conditions is violated ( Omkar et al., 2008 ).

X c Z s xx r X t , Y c Z s yy r Y t , S Z s xy r S  X  5  X  where X T ,X C ,Y T ,Y C are strengths of the lamina in X  X  Y directions.
S -shear strength of the lamina and s xx , s yy and s xy are the stresses induced in the principal direction. Eq. (5) stipulates the condition for non-failure for any particular ply of composite laminated plate. 4.3.2. Tsai-Wu failure criterion
Tsai-Wu brings in more complexity from a computational perspective and further reinforces Maximum Stress Failure criter-ion X  X  evaluation. This failure theory is based on the total strain energy failure theory of Beltrami. This is a generic model proposed by Tsai-Wu et al. Narayana Naik et al., 2011 . The failure theory states that the lamina failure occurs when the following condition is satisfied.
 F F F  X  where, F LL ,F TT ,F LT ,F L ,F T ,F SS are the strength parameters. X and Y t are the laminate compressive and tensile strengths in X , Y directions, respectively. S is the shear strength of the component in the X  X  Y plane. This criterion predicts the immanency of failure but not the failure modes. 4.4. Optimization problem
Once the failsafe set of design configurations are obtained the problem progresses into finding those configurations that yield minimum weight and cost for the composite plate. To do so the design variables which make up the solution space, the con-straints imposed on these sets of variables, the objective functions the govern the selection of a set of values for these variables, the algorithm that dictates the selection and progression of design configurations are discussed in following sections. 4.4.1. Design variables
The Design Variables in the present problem are the number of plies in each orientation, the number of layers, and thickness of each layer. The number of plies placed at different orientation angles with specific order of arrangement is known as stacking sequence. In our problem, a variable stacking sequence consisting of fiber orientation angles within the range of ( 90 1 ,  X  90 1 ]in steps of 15 1 is considered, leading to 12 different possible values of orientation angle y y  X  X  75 1 = 60 1 = 45 1 = 30 1 = 15 1 = 0 1 = 15 1 = 30 1
Here, the number of layers present at each of the different fiber orientation angles are considered as the actual design variables for the optimization process. The thickness of the lamina, a control variable in the plate optimization is also considered, within the range of 0.05 mm to 0.5 mm. In this paper, it is assumed that each layerisofthesamethickness t , retaining the practicality of the solution. The number of plies in each orientation generally varies between 1 and 200 which effectively translates to well over 200 different possible configuratio ns rendering a huge search space. 4.4.2. Objective functions
Multi-objective optimization indicates the use of two objective functions for the current problem as minimization of weight and total cost of the composite laminate. A conflict of objectives may arise where variation in one may affect the other owing to the formulation of these objective functions. This nature is purely to be based on the parameters used in the governing equations of the objectives. The design variables considered are number of plies, thickness of plies and orientation of the plies. 4.4.2.1. The weight function. The Weight of the laminate is found out by Eq. (7) with the total weight of the laminate being directly proportional to the number of layers and layer thickness t. Total height h of the composite plate of thickness t mm is given by: h  X  where, r  X  density of the material of the composite plate 4.4.2.2. The cost function. The composite plate is optimized with respect cost function  X  g  X , which is formulated using the cost function developed by Kovacs et al., (2004) for carbon-fiber-reinforced plastic (CFRP) sandwich-like structure wi th aluminum (Al). The cost in the design optimization of a composite structure is of major importance attributed to the high costs of the c omposite materials available in the market. The material cost attributes to the raw materials used for the composite plates. The manufacturing cost is a direct function of time associated with manufactur ing of the composite plate, which includes the time lost in press form preparation, layer cutting, layer sequencing and final working. The various costs incurred in the manufacture of a composite laminate in reality are to be considered. The total cost of the laminate is given by Eq. (8) below, Total cost  X  Material Cost  X  Manuf acturing Cost g  X  x  X  X  X  g matl f W t g X  g maf f X 
Considering cost due to manufacturing costs associated with non standard orientation ply angles then the total manufacturing cost is given by,
Manuf acturing cost  X  m  X  standard orientation plies  X  X  g  X  non standard orientation plies  X 
The indices g matl and g manufact are determined based on the material being used and the type of m anufacturing process employed.
For our work we have used g / m  X  6. This large fraction is deliberately used to make sure that during optimization the heuristic shows reduced inclination towards selecting non-standard plies. 4.5. Mathematical representation Let the set of permutations in the search space be represented by, P  X  X  n y 1 , n y 2 , ... , n y 12  X 
For different values of n y i from the search space such that 0 o n
If W ( p ) and C ( p ) are the weight and cost objective functions of permutation p A P , then in summary, the problem can be seen mathematically as finding that permutation S , such that S A P W( S ) r W ( p ) 8 p A P.
 C ( S ) r C ( p ) 8 p A P.

And the strength of S is greater than the minimum allowed, i.e., the conditions mentioned in Section 4.3 are not violated. 5. The need for VEPSO
The problem at hand looks to obtain a composite laminate which satisfies certain physical constraints such that it bears an applied load without failure. While doing so we deploy a heuristic that looks to minimize the weight and corresponding cost of laminate obtained. These objective functions can in simple terms be summarized as follows: 1. Weight function ( W  X  h * a * b * r where r  X  density h  X  P y i * t and t  X  thickness of each of the plies) a. weight p number of plies. b. weight p thickness of plies. 2. Cost Function ( C  X  (cost of each ply) number of plies  X  constant (weight of material)) a. cost p number of plies. b. cost p net weight of the composite laminate.

The results obtained by using PSO, assuming that cost gets minimized when weight gets minimized, to optimize weight of the composite laminate shows the following observations for two trials as seen in Table 1 .

Overall for the many trials we conducted, we observed that the optimum weight obtained for the problem ranges between approx. 81 X 85 units while corresponding costs ranges between approx. 700,000 X 400,000 units. This large va riation in cost can be explained by the variation of the number of the plies, required to withstand the same applied load, of varying thicknesses, varying between 0.05 mm to 0.5 mm ( Table 2 ).
 conducted trials keeping the thickness constant for each trial. The results of these trials for different thicknesses have been show in Figs. 4 and 5 : corresponding to optimum weight can vary quite drastically depending on the thickness of the plates. This essentially means that minimizing weight does not necessarily minimize weight. In fact there is a likelihood that any of the cost values in the range of 400,000 X 700,000 units may accompany the optimum weight obtained. This can be explained by cost being composed of the material component and the manufacturing component and this manufacturing component depends on the number of plies. As thickness decreases, the number of plies required to bear the applied load increase, which increases the manufacturing com-ponent of the cost function thus increasing the total cost.
These results are the impetus behind us choosing VEPSO to separately evaluate the cost and weight functions and minimize them. Results have shown that choosing VEPSO has worked well because we have obtained minimized cost and minimized weight with certainty for the trials conducted. 6. The optimization process using VEPSO
Vector evaluated particle swarm optimization in the current work has been modified for constrained non-linear optimization problems with discrete design variables unlike previous works carried out for optimizing systems with continuous variables ( Gies and Rahmat-Samii, 2004 ; Vlachogiannis and Lee, 2005 ). The key point in the constrained optimization process is dealing with the constraints associated with decision variables. In the current work, the constraints are effectively handled to preserve the feasibility of the solutions evolved. In order to constrain the optimum solution to the failure criteria constrained solution space, each particle is made to search the solution space keeping track of only the feasible solutions. Further, to increase the likelihood of finding more of such feasible solutions the particles are initialized within the feasible solution space. This process, however, does consume quite some time. The design variables involved in the current optimization problem are discrete in nature. The twelve variables corresponding to the number of layers at each of the twelve different fiber orientation angles are integers specified range making them discrete and finite in nature. Further, the layer thickness ( t )isalsoconsidered to be a discrete variable, capable of taking values between the specified ceiling and floor limits with a least count of 0.001 mm. This consideration has been taken in view of retaining the practicality of the evolved solution in terms of limitations posed on fabrication.
VEPSO employs two swarms to probe the search space and information is exchanged among them. Each swarm is exclusively evaluated with one of the objective functions, but, information coming from other swarm( s ) is used to influence its motion in the solution space. Specifically, in this case since there are two objective functions, two swarms ( X 1 , X 2 )of N particles each are used. X 1 evaluates the weight objective function and X 2 the cost objective function. There is no necessity for a complicated information migration scheme between the swarms as only two swarms are employed. Each swarm is exclusively evaluated according the respective objective function. The best particle of the second swarm ( X 2 ) is used for calculation of the new velocities of the first swarm X  X  ( X 1 ) particles and accordingly the best particle of the first swarm ( X 1 ) is used for calculation of the new velocities of the second swarm ( X 2 ). The particles X  velocity and position update Eqs. (9) and (10) for the first swarm  X  X 1 1 S i  X  t  X  1  X  X   X  X 1 S i  X  t  X  X   X  X 1 V i  X  t  X  1  X  X  10  X 
The particles X  velocity and position update Eqs. (11) and (12) for the first swarm  X  X 2 2 S i  X  t  X  1  X  X   X  X 2 S i  X  t  X  X   X  X 2 V i  X  t  X  1  X  X  12  X 
The particles of both the swarms ( X 1 , X 2 ) move in solution space according to the above mentioned equations. After an empirically derived maximum number of iterations or upon convergence at a point or small region in the solution space by a majority of the swarm, the optimization process is terminated and the results of the best particles of both swarms are reported. This maximum number is dependent on the number of particles employed for optimization process. The greater the number of particles the fewer iterations required for them to converge.
The performance of the PSO is very sensitive to the control parameter choices ( Shi and Eberhart, 1998 ; Engelbrecht, 2005 ). For our work, which uses VEPSO, we have tried different variations of these parameters and we have used those values which produces better convergence in terms of speed and quality. The number of swarm particles is decided empirically based on the limiting number of particles that make a difference in the quality of the solution obtained. The increase in the number of particles deployed is stopped when the increase makes no difference to the solution. Twice the number of dimensions of the problem is taken as the number of particles for each swarm. As the current problem is 13-Dimensional, 26 swarm particles are used for both the swarms as this number has been empirically found to be sufficient in effectively converging on the near optimum solution, found th us far in the trials conducted, in a relatively short time. During initialization, it is ensured that all the particles are within the failure criteria constrained solution space. So initialization itself may take a longer time if the population size is too large. Hence a lower population size significantly lowers the com-putational time. Further the rem aining parameters; the inertia weight w , cognition learning rate Cp and the social learning rate Cg are also fixed based various trials which allow better convergence rate and greater coverage of solution space. The same PSO para-meters as in ( Shi and Eberhart, 1998 ) have been the used for each swarm and for all simulation runs in this VEPSO work too. Here, the inertia weight parameter w i is adjusted dynamically during the optimization, as suggested by Shi and Eberhart (1998) .Astarting value of w i  X  1 is used to initially accommodate a more global search and is dynamically reduced to w i  X  0.4. The idea behind this approach is to terminate the PSO algorithm with a more local search. The w value is adaptively allocated as per Eq. (13). w where w max is the initial weight factor, w min is the final weight factor,  X  i  X  is the current iteration number and i max is the maximum number of iterations. The initial higher value may result in greater population diversity in the beginning of the optimization, whereas at a later stage lower values are favoured, causing a more focused exploration of the search space.

The parameters shown in Table 3 have been used for the same reasons as in Omkar et al. (2008) . 7. Message passing interface (MPI) and parallelization
MPI (message passing interface) is a specification for a stan-dard library which is used for message passing between con-current processes on distributed systems. The MPI standard defines only one API (or three to be more precise, one each for
FORTRAN, C, C  X  X  and C#). Every super-computer manufacturer offers its own implementation, optimized for its own hardware.
MPI forms the basis of a standard high level communication environment featuring collective communication, point-to-point communication.

The current work involves decomposing the serial computa-tion, which mainly consists of running computations of particles of the swarm one after another in a serial fashion, into paralle-lized chunks on basis of particles of the swarm. Hence the computations pertaining to each particle is run in parallel on different nodes of cluster computer. To enable communication and synchronization among them made particles/nodes MPI X  X  collective communication calls are made use of. 7.1. Synchronization
Particle swarm optimization algorithm requires results from different particles to be assessed and decisions for the ensuing calculations are based on them. To allow results from calculations performed different particles on different nodes of the cluster of a particular iteration to be completed and to allow temporary cessation of calculations until certain results are obtained some means of synchronization is required. Essentially, this ensures that before the swarm moves to the updating phase the fitness evaluations of all the particles are completed and assessed.
This is taken care by the MPI collective routine MPI_ALLREDUCE which temporarily stops the coordinating node from proceeding with the next swarm iteration until all of the computational nodes have responded with a fitness value. This, however, implies that the time required for a single parallel swarm fitness evaluation will be dictated by the slowest fitness evaluation in the swarm. 7.1.1. Use of MPI_ALLREDUCE for synchronization and broadcast of global best
MPI_ALLREDUCE combines multiple values from all processes and distributes the result of the operation on all these values specified in the call back to all processes. When the personal best of all the particles of the swarms are computed, we need to calculate the global best and this global best value should be made available to all. This is possible through the use of
MPI_ALLREDUCE with a minimization operator to help find the minimum of the personal bests and distribute this value to all the processes. To make available the entire configuration of the global best position, by distributing all the co-ordinates of that position the following procedure has been employed. 1. Agree on the global best within the swarm using MPI_REDUCE (If used with a minimization operator, this function call allows each process to receive a single, minimum of all data sent by different processes). 2. Obtain this global best and compare with particle X  X  current best.
 3. If global best does not match the particle X  X  current best then 4. Now perform MPI_ALLREDUCE on this set of global bests of the 5. The end result is that every particle is left with a copy of the 7.2. Summary of the algorithms optimization problem 1. For each particle of the weight and cost swarms assign random 2. Modify these values until all the particles of both swarms have 3. Perform fitness evaluations on the particles of both swarms. 4. Update particle X  X  personal best on comparison with current 5. From the above set, extract the best results of the personal 6. Each particle updates its positions on obtaining best values 7. If termination conditions are met then go to step 8 else step 3. 8. Report and exit. 7.2.1. Serial implementation
III Optimization ,
IV Report results and terminate 7.2.2. Parallel implementation
III. Initialization
III. Meeting design constraints
III. Optimization III. Report Results and terminate 8. Results and discussion This work is primarily concerned with design of a parallel
VEPSO algorithm for the multi-objective design optimization of laminated composite plates problem and to test its efficacy, in terms of execution time and coherence, it has been compared with sequential VEPSO. To further test how our work fares against other popular parallel heuristics we have compared it with parallel vector evaluated genetic algorithm (PVEGA) designed for the same problem. The structural problem for our work is similar to a previous work ( Omkar et al., 2008 ) but has two different variations, which is in the use of uniform distributed load and point load.
 8.1. Experimental platform To obtain these results, the parallel algorithm described in Section 7 has been executed on an IBM 720 Cluster with the following specifications: i. Sixty four 4-way SMP nodes (256 processors) P720 open ii. IBM Power-5 systems operating at 1.65 GHz. iii. 4-GB main memory per node with a total of 256 GB for the iv. Dual Gigabit network with Nortel 5510 gigabit switches. v. SUSE Enterprise Linux 9.0 operating system.

In tandem with the hardware mentioned above, MPICH v.1.2.7, a high performance portable implementation of MPI ( Coello
Coello and Sierra, 2004 ), has been used as the software platform to implement our parallel algorithm. As a metric of comparison we have exclusively used speedup. The speedup s is defined as the ratio of the serial execution time to the parallel execution time which gives us an indication of how much faster the parallel is than the serial approach.
 Where ,T serial is the time taken for serial execution. 8.2. Comparison of parallel VEPSO and sequential VEPSO execution time of the serial algorithm, the intent of this work is primarily to seek further improvement in execution time by parallelization and to explore the suitability of the peer-to-peer paradigm with MPI collectives. This paradigm is relatively unused for the problem domain and the results show its efficacy by showing how the model scales with particle size which motivates its application for more expensive problems in the domain.
For the serial version of the multi-objective design optimiza-tion of laminated composite plates using VEPSO we have used the same hardware platform as the parallel one but the program is run on a single node on a single processor whereas the parallel algorithm has used all of the available processors when necessary.
The codes developed for both the algorithms use the same governing mathematical equations and models to optimize the solution. On the software front, however, we have used an xlc compiler for the serial version and mpcc compiler, for the parallel program.

The key strategy employed by the sequential approach is that the computations pertaining to each particle of the swarm, involved in the optimization process, in executed one after another obviating the needs of set synchronization points. This is in stark contrast to the strategy employed by the parallel approach which leverages on the available parallel processors as described in Section 7. As expected we found marked reduction in the time taken for the parallel algorithm and have managed speedups of up to 10x .
Figs. 8 X 11 show coherence results and Figs. 12 X 20 show the plots for execution times and speedup curves for comparison of parallel VEPSO with sequential vector evaluated approaches, respectively. The cases have been briefly discussed below with an emphasis on coherence first and then on speedup. 8.2.1. Coherence
MPI is an API which is defined in C and standard C libraries are compatible for use with MPI libraries. The essence of this is that instruction sets and accuracies of operations remain the same. The serial version also being written in C makes it furthermore feasible to achieve absolute coherence. Although the parallel algorithm does not parallelize serial algorithm verbatim owing to programming paradigm shifting from the procedural with the introduction of MPI, the essence of the algorithm logic is pre-served and parallel results show nearly complete coherence with serial version.

Figs. 8 X 11 depicts the variation in optimum cost and the weight values of the serial and parallel implementations for a test case of the composite laminate problem subjected to uni-formly distributed load evaluated with maximum stress failure criterion, respectively. The curves in the figures represent the values obtained for parallel and the serial implementations, respectively. The curve profile indicates small variations in both the optimal weight values and cost values obtained for both serial and parallel implementations. In the cost evaluation there is a maximum variation of approximately 4.25% between the parallel and serial results for the trials conducted for both cost and weight swarms. In evaluating weight there is an even smaller variation of approximately1.25% between the parallel and serial results. This variation can be considered negligible for all practical purposes and they become insignificant when a mix of large number of trials are considered as the parallel and serials results become more coherent on an average. 8.2.2. Performance measurements
Case 1. Uniformly distributed load with maximum stress failure criterion.

Fig. 12 show both the execution times of serial and parallel implementation for the composite laminate problem subjected to a Uniformly Distributed Load (UDL) of 0.5 N/mm 2 with maximum stress failure criterion. The variation of the serial and the parallel running time plots indicate the latter X  X  execution time reduction and Fig. 13 speedup curve verifies the same.
 Case 2. Point load with maximum stress failure criterion.
Fig. 14 show the execution time of both serial and parallel implementation for the composite laminate plate problem subjected to a Point Load (PL) of 3000 N/mm 2 with maximum stress failure criterion. We observe results almost similar to the previous case with the parallel outperforming the serial in almost all cases. The corresponding speedup can be seen in Fig. 15 .
 Case 3. Uniformly distributed load with Tsai-Wu failure criterion.
Fig. 16 show the comparison of the serial and parallel execu-tion times for the optimization of composite laminate plate subjected to Uniformly Distributed Load (UDL) with Tsai-wu failure criterion. Similar results have been obtained with excep-tion of the actual computation times, which has generally increased owing to increased computational complexity brought in by Tsai-Wu failure criterion. The speedup is shown in Fig. 17 . Case 4. Point load with Tsai-Wu failure criterion.

Figs. 18 and 19 show the execution times of serial and parallel implementation for the composite laminate plate subjected to a
Point Load (PL) with Tsai-wu failure criterion and the correspond-ing speedup curve. 8.3. Comparison of parallel VEPSO with parallel VEGA
Comparison of the serial versions of both the nature inspired optimization techniques  X  VEPSO and VEGA along with the com-parison of different failure criteria evaluated for different loading conditions for multi-objective design optimization of composite laminated structures evaluated using different failure criteria is presented by Narayana Naik et al. (2011) and Omkar et al. (2008) .
An effective comparison of serial versions of PSO and GA is carried out by Eberhart and Shi (1998) . PSO has proven a flexible and well-balanced mechanism to enhance and adapt to the global and local exploration and exploitation abilities within a short calcula-tion time ( Eberhart and Shi, 1998 ). Our previous work regarding the comparison between serial PSO and GA ( Narayana Naik et al., 2011 ) prompted the comparison of their parallel counterparts for this application and hence in this section, the proposed parallel approach of VEPSO is compared with a parallel version of Vector
Evaluated Variant of the GA employed to solve the composite laminate problem under uniformly distributed load conditions evaluated with Maximum Stress Failure criterion. The parameters that govern the nature of the VEGA are consistent with those used in Narayana Naik et al. (2011) . Again the logical aspects of GA are perfectly preserved but some modifications have been made to accommodate MPI X  X  programming model. 8.3.1. Outline of the parallel vector evaluated genetic algorithm behaves for most part like a traditional genetic algorithm except that two populations are deployed to minimize the weight and cost. Hence, at the end of each generation, there is a high probability of choosing the design configurations of the two candidates with best fitness of particular population are used by the other population for ensuing generation and vice versa. This process is repeated until sufficient convergence is observed.
MPI X  X  MPI_Allgather collective communication primitive has been used instead of MPI_ALLREDUCE. This is because in genetic algorithm there is a chance that even the design configuration of the worst candidate may be chosen as the parent for a particular offspring of the next generation, however unlikely such an event is although be it a highly improbable event. Hence design configurations of the whole population are important in VEGA as opposed to just the best candidate, as in the case of VEPSO.
MPI_Allgather enables synchronization and dissemination of information of all candidates to each process and hence each pair of processes uses the same two distinct parents from the whole population using the information available locally to generate offspring of the next generation. Fig. 20 presents this idea more clearly. For convenience we will refer to each individual in a population as particle. The algorithm X  X  flowchart is presented in Fig. 20 .

I Initialization 1.  X  X  X  is the particle index so concurrently for i  X  1,2, 2. j  X  1 where  X  X  X  is the dimension index. 3. Randomly initialize particle positions ( xij X 1 and yij X 4. Randomly initialize thickness for each particle (xij X 5. If j o 14 increment j and go to step 2 II Meeting design constraints 1. j  X  1 2. increment x ij and y ij suitably 3. if j o 14 then increment j and go to 3 4. Synchronize
III Optimization 1. j  X  1(iteration index) 2. Concurrently for i  X  1,2 y ..,M evaluate fitness of f ij
Stop IV Report Results and terminate Fig. 21 depicts the execution times for both parallel VEPSO and VEGA, respectively. The curve profi le of both the parallel VEPSO and parallel VEGA indicates that in most cases parallel VEPSO fares slightly better than VEGA in terms of their execution times which is explained by the simplicity in the nature of VEPSO algorithm. The GA employing fairly heavier communication, which involves each particle getting to know about every other particle X  X  fitness and parent selections, results in fairly significant difference in execution times when smaller populations are used but as the population size is increased the communication overhead becomes the dominating factor in execution time of both algorithms and the execution time of the two algorithms seem to converge. 9. Conclusions In our work we have developed a novel parallel approach to VEPSO algorithm, which captures the essence of the peer-to-peer paradigm model of communication and synchronous evaluations, for the design optimization of composite structures using MPI parallel programming platform. MPI being widely available allows its collec-tive communication protocol to be used for a range of problems where peer-to-peer paradigm is intended to be used. The results show reduction in the running time by a considerable extent, achieving speedups of up to 10x while maintaining the same quality of solutions that the sequential approach yields. Our approach has also shown reduced execution time compared to a parallel approach Vector evaluated GA for a single case of the composite problem. Parallel VEPSO has fared better than sequential VEPSO and parallel VEGA in the cases we have investigated. The approach provides for faster selection of opt imum stacking sequence corresponding to the design of composite laminates with the objectives of minimizing weight and cost. The parallel approach clearly indicates the increase in speedup for adequate numbers of processors allocated. The parallel algorithm developed has shown to be scalable for increased particle sizes and populations. From the results obtained, we can conclude that, if each particle of the swarm is allocated to a dedicated processor then the parallel program X  X  execution time remains nearly invariant.
For increased swarm populations, the parallel algorithm remained almost invariant in execution time while the serial approach tended to linearly increase indicating the al gorithm X  X  scalability. Our future attempts will be in the direction of trying out parallel algorithms which incorporate higher degrees of parallelism enabling paralleliza-tion of each particle of the swarm using NVIDIA X  X  Compute Unified
Device Architecture (CUDA) platform and also adopting this work X  X  methods for longer execution problems in the domain.
 References
