 1. Introduction Traditional workload management methods mainly focus on the current system status [1,2]. For example, in a typical
RDBMS, the load controller only allows a certain number of complex queries to run concurrently. Also, if the system is in the danger of thrashing (i.e., admitting more transactions for execution will lead to excessive overhead and severe perfor-mance degradation [1]), the load controller may choose not to run any new transactions.

To support modern applications, users are continually requiring higher performance from RDBMSs. To meet this require-ment, it is natural to ask whether or not we can use information about the interaction between queued and running trans-actions to improve the existing workload management methods. The answer to this question is  X  X  X es. X  In fact, in many instances, it is possible to improve the throughput of an RDBMS through the utilization of such information. More specifi-cally, we can improve the throughput of an RDBMS that is processing a sequence of transactions by reordering these trans-actions before submitting them for execution. This is due to opportunities for either resource sharing among multiple transactions (e.g., sharing data in the buffer pool, or perhaps even sharing intermediate computations common to several transactions) or lowering resource contention (e.g., avoiding lock conflicts). Information about the interaction between queued and running transactions is essential in capturing such opportunities.

There are two main reasons why transaction reordering might be effective. The first is system independent  X  for example, actions and/or makes resource sharing possible. The second is system dependent  X  for example, a system may have a par-ticular implementation of buffer management or concurrency control that renders one order of transactions superior to another. Even reordering to exploit system dependent opportunities is useful. Commercial RDBMSs are large, complex pieces of code, and changes in functionality can require a very long design-implement-test-release cycle. In many cases it may be far simpler to do some reordering of transactions outside of the RDBMS before submitting them to the RDBMS for execution than it would be to change, say, the concurrency control subsystem of the RDBMS. This is especially true for database appli-cation developers who are unable to change the database engine.

This paper presents a general transaction reordering framework, which utilizes both the current system status and infor-mation about the interaction between queued and running transactions. The basic concept is simple and shown in Fig. 1 .In an RDBMS, generally, at any time there are M 1 transactions waiting in a FIFO transaction admission queue Q to be admitted to the system for execution, while another M 2 transactions forming a set S action admission queue Q is commonly used for load control purpose [1,2].

Those transactions in the transaction admission queue Q are the candidates for reordering. That is, the reorderer reorders the transactions waiting in Q so that the expected throughput of the reordered transaction sequence exceeds that of the ori-actions in Q and the properties it knows about the active transactions in S sequence. The more factors considered, the better quality the reordered transaction sequence has. However, the time spent on reordering cannot be unlimited, as we need to ensure that the reordering overhead is smaller than the benefit we gain in throughput. Also, we need to ensure acceptable transaction response time in the sense that no transaction is subject to starvation.

There are a wide range of reordering algorithms that could be used. At the extremes, we could: (1) Do no analysis. Run all the transactions in the order that they arrive at the RDBMS. (2) Take a snapshot of the system. Analyze every possible order of the transactions and record the corresponding through-
The first extreme may be undesirable if some amount of reordering can improve the throughput. The second extreme is obvi-ously unrealistic due to the exponential analysis overhead. Our goal is to find a good compromise between these two extremes. That is, under the constraint of acceptable transaction response time, we want to maximize the difference between the gain in throughput and the reordering overhead.

Reordering transactions requires CPU cycles. However, the increasing disparity between CPU and disk performance ren-ders trading CPU cycles for disk I/Os more attractive as a way of improving DBMS performance [3]. As shown in detail in
Section 4 below, some forms of transaction reordering can be regarded as a way to trade CPU cycles for disk I/Os. Also, our experiments in three commercial RDBMSs show that with minor overhead, our transaction reordering method greatly ses of transactions.

There are many resource allocation factors that can be considered for transaction reordering. In this paper, due to space fer pool performance (with an application to exploiting synchronized scans [5]).

Transaction reordering can be implemented in two places: (1) inside the RDBMS, or (2) outside the RDBMS as an add-on module. These two choices are shown in Fig. 2 , where the dotted rectangle denotes the RDBMS. The inside-RDBMS choice af-fords more opportunities for reordering, as the reorderer is tightly integrated with the RDBMS and can use detailed informa-synchronized scans) can only be implemented using the inside-RDBMS choice if it requires support of other modules in the RDBMS. The outside-RDBMS choice has the advantage of not needing to change the database engine and is especially suitable for database application developers. However, putting the reorderer outside the system means that it might have to treat the transaction (once in the reorderer, once in the system). Section 5.3 gives an example of the outside-RDBMS choice.
Reordering transactions itself is not a new idea. RDBMS users sometimes order their transactions themselves before sub-mitting those transactions to the DBMS [6]. However, to our knowledge the published literature has not considered a trans-action reordering module that attempts to increase concurrency and share resource utilization.

In related work, the operating system community has explored the approach of adding a module outside of a system to reorder web server requests based on the knowledge of OS buffer contents [7,8]. The database community has proposed mul-as the optimizer needs to wait for a sufficient number of incoming queries with common sub-expressions to arrive, and then before executing them, changes their query plans to share common sub-expressions. Our transaction reordering method is dynamic and online: there is no need for either changing the query plans or waiting.

This paper is an extended version of our previous workshop papers [11,12] , and includes new material on deadlock prob-ganized as follows. Section 2 presents our general transaction reordering framework. Section 3 describes how to use lock Section 5 investigates the performance of the transaction reordering method through an evaluation in three commercial
RDBMSs. We conclude in Section 6. 2. General transaction reordering framework Transaction reordering is a general technique to improve RDBMS performance. It can be applied to multiple applications.
In our discussion, we assume that all the transactions have the same priority. We assume that the strict two-phase locking work. In Sections 3 and 4 , we show how to use lock conflict analysis and buffer pool analysis as the reordering criterion, respectively.

As mentioned in the introduction, in our model there are two sets of transactions in the RDBMS ( Q and S action admission queue that keeps the transactions waiting for execution. S rently running. Transactions enter Q in the order that they are submitted to the RDBMS. Our goal is to reorder the transactions in Q so that the transaction throughput in the RDBMS is improved. We identify two specific methods to increase the transaction throughput: (1) increasing concurrency by preventing conflicting transactions from executing concurrently and (2) sharing resources among the (running) transactions.

In the general transaction reordering framework, we reorder transactions in the follow way: (1) Operation 1: Suppose we want to schedule a transaction for execution. We scan Q sequentially until a desirable trans-(2) Operation 2: Once a transaction is committed or aborted, it leaves S
The basic transaction reordering framework needs to be extended when we take different factors into consideration (see Sec-tions 3 and 4 for details).

When we search for the desirable transaction, we are essentially looking for a transaction that is compatible with the run-actions that are of compatible types. The idea of using transaction types to improve database performance has been investigated previously [13,14] . However, those methods are mainly used for concurrency control purpose rather than for reordering transactions. Also, their classification methods are different from ours: (2) The purpose of the classification in Garcia-Molina [14] is to allow non-serializable schedules which preserve consis-3. Using lock conflict analysis as the reordering criterion
In this section, we show how to use lock conflict analysis as the reordering criterion. Specifically, we use continuous data ground on continuous data loading.
 3.1. Continuous data loading
Today, an enterprise often has to make real-time decisions about its daily operations in response to the fast changes hap-pening all the time in the world [15]. As a result, enterprises are starting to use operational data warehouses to provide fresher data and faster queries [16,17] . In an operational data warehouse, the stored information is updated in real time or close to it. Also, materialized views are used to speed query processing.

Fig. 3 shows the architecture of a typical operational data warehouse [16] (Wal X  X art X  X  data warehouse uses this archi-tecture [18]). Clients store new data into operational data stores in real time, where an operational data store is an OLTP new data is transferred by continuous load utilities from operational data stores into a centralized operational data ware-house, where it is typically managed by an RDBMS. Then clients can query this operational data warehouse, which is the only place that global information is available.
 ized operational data warehouse with the operational data stores. As a result, existing commercial continuous load utilities
Since loading data into a database is a general requirement of database applications, most commercial RDBMS vendors large number of applications need such functionality, RDBMS vendors typically provide this functionality as a package for by RDBMS vendors and the applications that are written by application developers and provide data loading functionality. 3.1.1. Workload specification
Fig. 4 shows a typical architecture for loading data continuously into an RDBMS [6,21] . Data comes from multiple data
Then a continuous load utility loads the data into the RDBMS using update transactions. Each update transaction contains one or more modification operations. As is the case in data stream applications, the system has no control over the order in which modification operations arrive [22].

To decide which transformations are valid on the stream of load transactions, we discuss the semantics of continuous lowing assumptions for continuous data loading: (a) The RDBMS is running with standard ACID properties for transactions. The continuous load utility looks to the RDBMS (b) The RDBMS neither imposes nor assumes any particular order for these load transactions  X  indeed, their order is deter-(c) The RDBMS has no requirement on whether multiple modification operations can or cannot commit/abort together. In this paper, we make the same assumptions. Hence, in our techniques, we can do reordering and grouping arbitrarily.
The alert reader may notice that arbitrary reordering can cause certain anomalies. For example, such an anomaly arises if sonal communication with S. Brobst]. In other cases, the application ensures that the order in which modification operations either case, the continuous load utility does not need to worry about these anomalies.

To increase concurrency, a continuous load utility typically opens multiple sessions to the RDBMS (at any time, each ses-sion can have at most one running transaction [23, p. 320] ). These sessions are usually maintained for a long time so that to modification operations are usually pre-compiled into a stored procedure whose execution plan is stored in the RDBMS.
This not only reduces the network overhead (transmitting a stored procedure requires a much smaller message than trans-mitting multiple SQL statements) but also eliminates the overhead of repeatedly parsing and optimizing SQL statements. 3.1.2. Grouping modification operations
Continuous load utilities usually combine multiple modification operations into a single transaction rather than applying ber of modification operations that are combined into a single transaction as the grouping factor . 3.1.3. The partitioning method
In this section, we review the standard approach used to avoid deadlock in continuous load operations in the absence of materialized views. Suppose the continuous load utility opens k P 2 sessions S distribute the modification operations among the k sessions, transactions from different sessions can easily deadlock on X solution to this deadlock problem is to partition (e.g., hash on some attribute) the tuples among different sessions so that modification operations on the same tuple are always sent through the same session [6]. In this way, the deadlock condition (transactions from different sessions modify the same tuple) no longer exists and deadlocks will not occur. (Note: the par-titioning method may change the order that the tuples arrive at the RDBMS. However, as mentioned in Section 3.1.1, such reordering is allowed in existing continuous load utilities.) 3.2. Impact of immediate materialized view maintenance
In this section, we consider the general case in which materialized views are maintained in the RDBMS, and show that in this case the partitioning method of Section 3.1.3 is not sufficient to avoid deadlocks. We focus on an important class of view p  X  r  X  R 1 ffl R 2 fflffl R h  X  X  or an aggregate join view c  X  p  X  r  X  R
SQL allows the aggregate operators COUNT , SUM , AVG , MIN , and MAX . However, because MIN and MAX cannot be maintained incrementally (the problem is deletes [24]), we restrict our attention to the three aggregate operators that make the most sense for materialized aggregates: COUNT , SUM , and AVG .

In continuous data loading, we allow data to be loaded into multiple base relations concurrently. This is necessary if we want to keep the data in the RDBMS as up-to-date as possible. However, if a join view is defined on multiple base relations, changes the update transactions into update-read transactions. These reads can conflict with concurrent writes to the other is defined on A and B , where the join condition is A c  X  B d . Consider the following two modification operations: (1) O 1 : Modify a tuple t 1 in base relation A whose c  X  v . (2) O 2 : Modify a tuple t 2 in base relation B whose d  X  v .
 These modification operations require the following tuple-level locks on base relations A and B :
O 1 :  X  L 11  X  A tuple-level X lock on A for tuple t 1 .  X  L
O 2 :  X  L 21  X  A tuple-level X lock on B for tuple t 2 .  X  L
Suppose operation O 1 is executed by transaction T 1 through session S through session S 2 . If transactions T 1 and T 2 request the locks in the order (1) Step 1: T 1 requests L 11 . (2) Step 2: T 2 requests L 21 . (3) Step 3: T 1 requests L 12 . (4) Step 4: T 2 requests L 22 . a deadlock occurs. This is because L 11  X  L 22  X  contains a tuple-level X (S) lock on A for tuple t level X (S) lock on B for tuple t 2 .

A simple solution to the above deadlock problem is to do materialized join view maintenance in a deferred manner rather than immediately. That is, an update is inserted into the base relation as soon as possible; but the materialized join views that refer to that base relation only see the update at some later time, when the materialized join views are updated in a batch operation. Unfortunately, this makes the materialized join views at least temporarily inconsistent with the base rela-tions. The resulting semantic uncertainty may not be acceptable to all applications. This observation has been made else-where. For example, Graefe and co-workers [25,26] emphasizes that consistency is important for materialized views that are used to make real-time decisions. As another example, in the TPC-R benchmark, maintaining materialized views imme-diately with transactional consistency is a mandatory requirement [27], presumably as a reflection of some real world appli-are always maintained immediately, immediate materialized view maintenance should also be desirable in many cases. The reader might wonder whether using a multi-version concurrency control method can solve the above deadlock problem. maintenance transactions do both reads and writes. As a result, a multi-version concurrency control method cannot avoid the method to avoid conflicts between pure read transactions on materialized join views and immediate materialized join view
Allowing dirty reads is a standard technique to improve the concurrency of read-only queries. Since materialized join view maintenance has at its heart a join query, it is natural to wonder if dirty reads can be used here. Unfortunately, in tain join views makes the results of these dirty reads permanent in the join views [29]. Thus, although dirty reads would avoid the deadlock problem, they cannot be used.

Itisalso natural to question whether some extension ofthepartitioningmethod described in Section 3.1.3 canbe used to avoid respectively. Then for immediate materialized view maintenance, the deadlock problem will not occur. This is because in this (1) In continuous data loading, modification operations on a base relation R usually specify some (e.g., the primary key) (2) If multiple join views with different join attributes are defined on the same base relation R , then it is impossible to 3.3. Deadlock probability
In this section we show that, contrary to the situation in the absence of materialized join views, in the presence of mate-rialized join views, the probability of deadlock can easily be very high. For example, suppose (1) There are k &gt; 1 concurrent transactions. (2) Each transaction contains n modification operations and modifies either A or B with probability p and 1 p , (3) Within a transaction, each modification operation modifies a random tuple in A ( B ) and each of the n tuples to be mod-(4) There are totally s distinct values for A c  X  B d  X  . (5) s kn .

Then following a reasoning that is similar to Gray and Reuter [23, pp. 428 X 429] , we can show that the probability that any roughly estimate the probability that any particular transaction deadlocks.)
This probability can be derived as follows. Consider a particular transaction T of the k transactions. There are two cases: (1) Case 1: Transaction T modifies base relation A . From transaction T  X  X  perspective, there are k 1 other transactions, ability that transaction T deadlocks is PW  X  T  X  X  p PW 1  X  T  X  X  X  1 p  X  PW
For reasonable values of k , n , and s , this deadlock probability is unacceptably high. This is mainly due to the following reasons: (1) For efficiency purposes, n could be large (e.g., 600 [6]). (2) The deadlock probability formula that is in Gray and Reuter [23, p. 429] is of the form kn
As an example, if p  X  50 % ; k  X  8 ; n  X  32, and s = 10,000, this deadlock probability is approximately 9%. Doubling n to 64 to use the above formula to precisely predict the deadlock probability. Rather, we use the formula to give a rough estimate of the deadlock probability and demonstrate how severe the deadlock problem could be. In Section 5.1 below, we validate this formula through a study of the deadlock problem in a commercial RDBMS. 3.4. Solution with reordering
The deadlock problem occurs because we allow data to be concurrently loaded into multiple base relations of the same is  X  X  X o X  if we set the following rules: (1) Rule 1: At any time, for any join view JV , data can only be loaded into one base relation of JV . (2) Rule 2: Modification operations (insert, delete, update) on the same base relation use the partitioning method dis-(3) Rule 3: The system uses a high concurrency locking protocol (e.g., the V locking protocol [30], or the locking protocol
The reason is as follows: (1) Using rules 1 and 2, all deadlocks resulting from lock conflicts on the base relations are avoided. Since all possible deadlock conditions are eliminated, deadlocks no longer occur.

We now consider how to implement rules 1 X 3. It is easy to enforce rules 2 and 3. To enforce rule 1, we can use the fol-lowing reordering method to reorder the modification operations. Recall in Section 3.1.1, the semantics of the workload al-lows us to reorder modification operations arbitrarily. Consider a database with d base relations R views JV 1 ; JV 2 ; ... , and JV e . We keep an array J that contains d elements J number of transactions that modify base relation R i and are currently being executed. Each J
For each m  X  1 6 m 6 k  X  , we maintain a queue Q m recording transactions waiting to be run through session S
Q m  X  1 6 m 6 k  X  is initialized to empty. During grouping (see Section 3.1.2), we only combine modification operations on the same base relation into a single transaction.

If base relations R i and R j  X  1 6 i ; j 6 d ; i  X  j  X  are base relations of the same join view, we say that R able transaction if it does not conflict with any currently running transaction. Consider a particular base relation
R any time, if either w  X  0 or all the J s u  X  0  X  1 6 u 6 w  X  , then a transaction T modifying base relation R able transaction.

We schedule transactions as follows: (2) Action 2: When some transaction T modifying base relation R (3) Action 3: Whenever we try to schedule a transaction to the RDBMS for execution through session S
Reordering transactions may cause slight delays in the processing of load transactions that have been moved later in the load schedule. On balance, these delays will be offset by the corresponding transactions that were moved earlier in the schedule to take the place of these delayed transactions. For some applications, this reordering is preferable to the incon-sistencies that result from deferred materialized view maintenance. These are the target applications for our reordering technique.

The above discussion does not address starvation. There are several starvation prevention techniques that can be inte-to prevent the first transaction in any Q g from starvation  X  1
Q m  X  1 6 m 6 k  X  , we set r  X  m .If r  X  m  X  1 6 m 6 k  X  and the first transaction of Q by one (if m  X  k , we set r  X  1  X  .If Q r is empty, we keep incrementing r until either Q
Q m  X  1 6 m 6 k  X  is empty. In the later case, we set r  X  0. We make use of a pre-defined timestamp TS determined by appli-cation requirements. If pointer r has stayed at some v  X  1 header transaction. Whenever we are searching for a desirable transaction in some Q transaction. Otherwise transaction T is still not desirable and we continue the search. 4. Using buffer pool analysis as the reordering criterion In this section, we show how buffer pool analysis can be used as the reordering criterion. When we mention a transaction ing buffer management methods cannot utilize the synchronized scan technique efficiently when the RDBMS is heavily loaded. Then in Section 4.2, we provide a solution to this problem using transaction reordering. 4.1. Synchronized scans and load management
In a typical data warehouse, there are a few very large relations with multiple queries submitted against them simulta-all the indices that might be needed [32]. As ad hoc querying of data warehouses is becoming more common [27,33,34] , the of the disk I/O capability in the RDBMS and significantly decrease the amount of disk I/O capability available to the other commercial database systems: Teradata [31], Red Brick [5], Microsoft SQL Server [35], and IBM DB2 [33,34] . The main idea of the synchronized scan technique is that if two transactions are scanning the same relation, then we can group them together so that I/Os can be shared between them. This reduces the cumulative number of I/Os required by the scans while addition-ally saving CPU cycles that would otherwise have been required to process the extra I/Os.

Synchronized scans are typically implemented in the following way (minor differences in implementation details will not influence our transaction reordering algorithm). Consider a relation R containing K information is dropped out of DS when transaction T 1 finishes the scan). Also, transaction T rently scanning relation R or not. If so, e.g., suppose transaction T starts scanning relation R from the J th page. In this way, transactions T tion R to make up the previously omitted first J 1 pages (other transactions may do synchronized scan with transaction T for these J 1 pages). Note transactions T 1 and T 2 are not always locked together, but may drift apart if the required pro-cessing time for the scans differ too much from each other. For example, as long as the two scans are separated by less than
K gence exceeds K 2 pages, the two scans are separated and run independently, and no caching is performed. This prevents us from experiencing large response times due to a fast scan waiting for a slow scan to catch up.

From the above description, we can see that after transaction T does not consume many extra buffer pages (except for a few buffer pages to temporarily store the query results) unless sometime later the two scans drift too far away from each other. However, the latter situation does not occur frequently.
This is because the fast scan needs to be in charge of doing the time-consuming operation of fetching pages from disk into each other.
 The state-of-the-art buffer management algorithms cannot utilize the synchronized scan technique efficiently when the buffer pool are committed, no new transactions are allowed to enter the RDBMS for execution. (In fact, in a typical imple-even if some transaction T 1 is currently doing a full table scan on relation R , a new transaction T allowed to enter the system to join transaction T 1 for synchronized scan. However, in this case, synchronized scan would be buffer pages (except for a few buffer pages to temporarily store the query results). Later, when transaction T lowed to enter the system, transaction T 1 may have already finished execution so that transaction T leads to the waste of a large number of disk I/Os and CPU cycles. 4.2. Applying transaction reordering
To address the above problem, we use buffer pool analysis as another reordering criterion. This is to maximize the chance that the synchronized scan technique can be utilized. In the discussion below, we only apply synchronized scan to transac-joins) is left for future work.

Technique 1: We maintain an in-memory hash table HT that keeps track of all the full table scans in the transaction move some (or all) of the transactions in Q that does full table scan on relation R to S to move all such transactions in Q to S r for execution. For example, the system may not have enough threads to run all such transactions in Q . However, as long as the system permits, we move as many such transactions to S
Technique 2: When a new transaction T that does full table scan on relation R arrives, before it is blocked in Q , we first check the data structure DS to see whether some transaction in S we have threads available and the system is not on the edge of thrashing due to a large number of lock conflicts [1], we run conflict (on relation R ) with any transaction in S r , otherwise it is impossible to have a transaction in S a full table scan on relation R .

Multiple scans in the same synchronized scan group may occasionally get separated if their scanning speeds differ too much from each other (as explained in Section 4.1, such chance is very low). This would cause synchronized scan to consume tem may abort some running transactions). If this happens, or if the system is running out of threads or on the edge of thrashing due to a large number of lock conflicts, we stop using Technique 1 and Technique 2 until the system returns to normal state.

In a typical scenario, most long-running transactions in the RDBMS are I/O-bound rather than CPU-bound [3]. Our trans-action reordering method for exploiting synchronized scans requires a few CPU cycles and can be regarded as a way to trade scans and reduce the processing load on the database engine, while it has only a minor impact on the throughput of other use synchronized scans and basically do not compete with existing transactions on I/Os. 5. Performance evaluation
In this section, we describe experiments that were performed in three commercial parallel RDBMSs: IBM DB2, Teradata, and another commercial RDBMS. We investigated the performance of the transaction reordering method when either lock conflict analysis or buffer pool analysis was considered. In either case (except in Section 5.3), we focus on the throughput mixed workload environment, our method would greatly improve the throughput of the targeted class of transactions while the throughput of other classes of transactions would remain much the same. Our measurements were performed with the database client application and server running on an Intel x86 Family 6 Model 5 Stepping 3 workstation with four 400 MHz processors, 1 GB main memory, six 8 GB disks, and running the Microsoft Windows 2000 operating system. We allocated a processor and a disk for each data server, so there were at most four data servers on each workstation. 5.1. Experiments in IBM DB2
In IBM DB2, we investigated the performance of the transaction reordering method when lock conflict analysis was con-sidered for continuous data loading. 5.1.1. Experiment description
The relations used for the tests model a real world scenario. Customers interact with a retailer via phone/web to make a purchase. The purchase involves browsing available merchandise items and possibly selecting an item to purchase. The fol-lowing events occur: (1) Customer indicates desire for a specific item and event is recorded in the demand relation. (2) The inventory relation is checked for item availability. (3) If the desired item is on hand, a customer order is placed and the inventory relation is updated; otherwise a vendor
The schemas of the demand and inventory relations are listed as follows: demand (partkey, date, quantity, custkey , comment), inventory (partkey , date , quantity, extended_cost, extended_price).
 only consider today X  X  transactions that are related to these active parts. We believe that our conclusion would remain much of deadlocks caused by the transactions that are related to the active parts would remain much the same.
Suppose that the demand and inventory relations are frequently queried for sales forecasting, lost sales analysis, and assortment planning applications, so a join view onhand _ demand is built as the join result of demand and inventory on the join attributes partkey and date : create join view onhand_demand as select d.partkey, d.date, d.quantity, d.custkey, i.quantity from demand d, inventory i where d.partkey=i.partkey and d.date=i.date partitioned on d.custkey;
There are two kinds of modification operations that we used for testing, both of which are related to today X  X  activities: (2) O 2 : Update one tuple in the inventory relation with a specific partkey value and today X  X  date . sive all-node join operations for join view maintenance to cheap single-node join operations [39].
We evaluated the performance of the reordering method and the naive method in the following way: (1) We tested the largest available hardware configuration with four data server nodes. (2) We executed a stream of modification operations. A fraction p of these modification operations are O (3) In both the reordering method and the naive method, we only combine modification operations on the same base rela-(4) In the naive method (without reordering), if a transaction deadlocked and aborted, we automatically re-executed it (5) We performed three tests: 5.1.2. Concurrency test results
We first discuss the deadlock probability and throughput testing results from the concurrency test. 5.1.2.1. Deadlock probability. As mentioned in Section 3.3, for the naive method, we can use the unified formula deadlock probability of the naive method computed by the unified formula in Fig. 5 . (Note: all figures in Sections 5.1.2.1 and 5.1.2.2 use logarithmic scale for the x -axis.)
When both k and n are small, this deadlock probability is small. However, when either k or n becomes large, this deadlock probability approaches 1 quickly. For example, consider the case with n  X  64. When k  X  2, this deadlock probability is only 5%. However, when k  X  16, this deadlock probability becomes 77%. The larger k , the smaller n is needed to make this dead-lock probability become close to 1.

We show the deadlock probability of the naive method measured in our tests in Fig. 6 . Figs. 5 and 6 roughly match. This naive method. 5.1.2.2. Throughput. The throughput (number of modification operations per second) is an important performance metric of the continuous load utility. For the naive method, to see how deadlocks influence its performance, we investigated the rela-tionship between the throughput and the deadlock probability.

By definition, when the deadlock probability becomes close to 1, almost every transaction will deadlock. Deadlock has the following negative influences on throughout: (1) Deadlock detection/resolution is a time-consuming process. During this period, the deadlocked transactions cannot (2) The deadlocked transactions will be aborted and re-executed. During re-execution, these transactions may deadlock
Hence, once the system starts to deadlock, the deadlock problem tends to become worse and worse. Eventually, the through-put of the naive method deteriorates significantly.

We show the throughput of the naive method in Fig. 7 . For a given number of sessions k , when the grouping factor n is cient than executing a large number of small transactions, as discussed in Section 3.1.2. (In our testing, the performance tions, we could only run the database client application and server on the same computer. In this case, the overhead per transaction is fairly low. Amortizing such a small overhead with a large n cannot bring much benefit.) When n becomes large enough, if the naive method does not run into the deadlock problem, the throughput of the naive method approaches a con-stant, where the system resources become fully utilized. The larger k : (1) The higher concurrency in the RDBMS and the larger the constant. (2) The easier it becomes to achieve full utilization of system resources and the smaller n is needed for the throughput to
When n becomes too large, the naive method runs into the deadlock problem. The larger k , the smaller n is needed for the naive method to run into the deadlock problem. Once the deadlock problem occurs, the throughput of the naive method and re-executed due to deadlock.

For a given n , before the deadlock problem occurs, the throughput of the naive method increases with k . This is because the larger k , the higher concurrency in the RDBMS. However, when n is large enough (e.g., n  X  128  X  and the naive method runs into the deadlock problem, due to the extreme overhead of repeated transaction abortion and re-execution, the throughput of the naive method may decrease as k increases.

We show the throughput of the reordering method in Fig. 8 . The general trend of the throughput of the reordering method increases with both n and k . For a given k ,as n becomes large, the throughput of the reordering method approaches a con-stant. However, the reordering method never deadlocks. For a given k , the throughput of the reordering method keeps approaching that constant no matter how large n is. Once the naive method runs into the deadlock problem, the reordering method exhibits great performance advantages over the naive method, as the throughput of the naive method in this case deteriorates significantly.

In both the k  X  8 case and the k  X  16 case, when n becomes large enough, the throughput of the reordering method ap-utilized. In our testing, if we had a larger hardware configuration with more data server nodes, the constant for the k  X  16 case would be larger than that for the k  X  8 case.

We show the ratio of the throughput of the reordering method to that of the naive method in Fig. 9 . Before the naive method runs into the deadlock problem, the throughput of the reordering method is smaller than that of the naive method.
This is because the reordering method has some overhead in performing reordering and synchronization (i.e., switching from executing one type of transactions (say, transactions updating the inventory relation) to executing another type of transac-put of the reordering method is never lower than 96% of that of the naive method.

When the naive method runs into the deadlock problem, the throughput of the reordering method does not drop while the transactions deadlock in the naive method. The extreme overhead of repeated transaction abortion and re-execution ex-higher than that for the k  X  8 case. 5.1.3. Data ratio test results
In this section, we discuss the deadlock probability and throughput testing results from the data ratio test. Recall that in the data ratio test, we fixed k  X  16 ; n  X  64 ; p  X  50 % , and let the number of active parts s vary from 5000 to 20,000. We show the deadlock probability of the naive method computed by the unified formula and measured in our tests in uation. For the naive method, the deadlock probability increases linearly as s decreases.

We show the ratio of the throughput of the reordering method to that of the naive method in Fig. 11 . In all our testing cases, the naive method runs into the deadlock problem and the ratio is greater than 1. The smaller the number of active performance advantages the reordering method exhibits over the naive method. 5.1.4. Transaction ratio test results
In this section, we discuss the deadlock probability and throughput testing results from the transaction ratio test. Recall method) is symmetric around p  X  50 % : it reaches the maximum when p  X  50 % and keeps decreasing as p tends to either 0 or 1. This is easy to understand: (1) In the extreme case when either p  X  0or p  X  1, all modification operations are of the same type (either O (2) When p  X  50 % , the two kinds of modification operations ( O
We show the ratio of the throughput of the reordering method to that of the naive method in Fig. 13 . In all our testing the deadlock problem of the naive method and the greater the ratio. That is, the closer p is to 50%, the greater performance advantages the reordering method exhibits over the naive method. 5.1.5. Comments
In our tests, we used no more than k  X  16 sessions. In a typical real world scenario, the number of sessions would be much larger than 16. Hence, we would expect the reordering method to perform better. (In a typical real world scenario, even if the number of active parts s could be larger than what we used in the tests, we would expect the effect coming from ware restrictions, we could not open more than k  X  16 sessions.

In our tests, we have two base relations and one join view in the database. In a typical real world scenario, there would be dent of each other. Hence, we would expect our conclusion to remain much the same if such independent base relations are added into the database. (In this case, we would interpret k as the number of concurrent load transactions on those depen-cases with more base relations and join views. Unfortunately, such an experiment was not possible in our testing environ-ment due to the limited number of sessions. 5.2. Experiments in Teradata
In Teradata, we investigated the performance of the transaction reordering method when buffer pool analysis was con-sidered to exploit synchronized scans. 5.2.1. Experiment description
We created w relations R i  X  1 6 i 6 w  X  and a set S t of other relations. All the relations R actions that we used for the testing: (1) T i  X  1 6 i 6 w  X  : Perform a full table scan on relation R (2) U : Execute some query on the relations in S t .

We evaluated the performance of the transaction reordering method and the baseline method in the following way: (1) We tested the system configurations with four data server nodes  X  L  X  4  X  and eight data server nodes  X  L  X  8  X  . (2) We ran multiple long running U  X  X  so that most buffer pages in the buffer pool were committed. The remaining free (3) For each i  X  1 6 i 6 w  X  , we ran zT i  X  X . That is, we ran w zT (4) In the baseline method, we sent all the w zT i  X  X  to the database simultaneously (so that the original transaction (5) In the transaction reordering method, we used a centralized reorderer to reorder all the transactions. 5.2.2. Test results
We measured the throughput of the w zT i  X  X . The transaction throughput achieved by the transaction reordering method is shown in Fig. 14 . As long as w z , the transaction throughput of the baseline method does not depend on the specific matter how large z is, the probability that in the baseline method, the database runs multiple T currently is low. That is, the probability that the baseline method uses the synchronized scan technique is low.
When z &gt; 1, the transaction reordering method schedules the zT synchronized scan technique. Hence, the throughput of the transaction reordering method increases with z and becomes higher than that of the baseline method. When z becomes large enough (e.g., z  X  8  X  , the CPU becomes the bottleneck. Be-cause of this, the CPU speed approximately bounds the throughput achieved by the transaction reordering method. In more detail, as z increases, the throughput achieved by the transaction reordering method approaches a constant, where all CPUs are fully utilized. Since the 8-node configuration has twice the number of data server nodes than the 4-node configuration, and the sizes of the relation R i  X  X  remain the same, the throughput of the transaction reordering method in the 8-node con-figuration case is close to twice that of the 4-node configuration.
 continuously oscillate among the different tracks where different R achieved by the transaction reordering method decreases as y increases. However, when all CPUs become fully utilized (i.e., when z is large enough), the throughput achieved by the transaction reordering method approaches a constant that is inde-pendent of y , as that constant is almost solely determined by the CPU speed.
 We show the ratio of the transaction throughput of the transaction reordering method to that of the baseline method in
Fig. 15 . As explained above, (1) The throughput of the transaction reordering method approaches a constant as z increases while the throughput of the (2) The throughput of the transaction reordering method (the baseline method) in the 8-node configuration case is close (3) As z increases, the throughput achieved by the transaction reordering method approaches a constant that is indepen-
In our testing, we never observed that once joined for synchronized scan, two scans drifted too far away from each other and got separated. 5.3. Experiments in another RDBMS
To demonstrate the wide applicability of the transaction reordering method, we conducted experiments in the latest ver-sion of another commercial RDBMS from a major vendor and used the transaction ordering method with lock conflict anal-ysis to address certain system dependent issue without changing the database engine. This RDBMS uses a different concur-rency control mechanism than Teradata. In this system, if multiple transactions run concurrently, each updating a base rela-be desirable to reorder transactions for this system so that at any time, at most one such transaction runs in the database updating a base relation that has a materialized view defined on it.
 We analyzed the performance of the transaction reordering method in this RDBMS when lock conflicts were considered.
We created a set S 1 of relations and another set S 2 of relations. Each relation in S view. Different relations in S 1 may have different materialized join views defined on them. No materialized view is defined on any relation in S 2 . There are two kinds of transactions that we used for the testing: (1) T 1 : Insert multiple tuples into some relation in S 1 (2) T 2 : Execute some query/update on the relations in S
We evaluated the performance of the transaction reordering method and the baseline method in the following way: (1) We used a uni-processor database configuration. At any time, at most n transactions were allowed to run concurrently (3) In the baseline method, we sent all the transactions to the database simultaneously (so that the original transaction (4) In the transaction reordering method, we used a reorderer to reorder all the transactions so that at any time, at most
We show the ratio of the transaction throughput of the transaction reordering method to that of the baseline method in Fig. 16 . In the baseline method, if multiple T 1  X  X  run concurrently, all but one of these T
The probability that multiple T 1  X  X  run concurrently increases with u .When u is small, such probability is small. In this case, almost no transaction is aborted. Even if a transaction gets aborted, its first-time ex ecution has already fetched the necessary pages into memory. Re-executing the same tra nsaction a second time is quick. Hence, the throughput of the transaction reordering method is the same as that of the baseline method. However, when u becomes large, the prob-ability that multiple T 1  X  X  run concurrently also becomes large. This will cause a substantial percentage of the T aborted and re-executed in the baseline method. Some of those re-executed T first-time or re-executed) T 1  X  X  and get aborted and re-executed again. That is, in the baseline method, a T and re-executed multiple times before it is finally committed. The average number of times that a T executed increases with u .Hence,when u becomes large enough, the performance advantage of the transaction reorder-ing method, i.e., the throughput ratio, becomes significant and keeps increasing with u . In the extreme case, when u  X  100 line method. 6. Conclusions
This paper proposes the use of transaction reordering to improve the performance of an RDBMS. The general idea under-lying transaction reordering is that by combining knowledge about the currently running transactions and the transactions ond upon increasing buffer pool hit rates. Our experiments with three commercial systems are promising, showing that this technique can significantly improve throughput for certain workloads.

For continuous data loading, there are several interesting directions that we intend to pursue in future work: (1) We would like to give a fair comparison of the transaction response time in different methods: our reordering method, (2) As mentioned at the end of Section 3, reordering transactions may slightly delay the processing of some load trans-
It is an open question whether immediate materialized view maintenance or deferred materialized view maintenance is more desirable. The answer to this question depends on how efficiently immediate materialized view maintenance can be done. Also, it depends on how well the semantic discrepancy between materialized views and base relations can be mini-mized for deferred materialized view maintenance. We hope that the techniques in this paper can contribute to the discus-sion in this regard.

Developing and exploring ways to define and detect which transactions fit best is another rich area for future work. Such problems that arise due to idiosyncrasies of specific commercial systems. Both approaches are interesting  X  as commercial where it is interesting in some cases to view them as artifacts to be studied rather than as programs to be modified. Trans-action reordering research is one example of this approach.
 Acknowledgement We would like to thank Henry F. Korth for helpful discussions.

References
