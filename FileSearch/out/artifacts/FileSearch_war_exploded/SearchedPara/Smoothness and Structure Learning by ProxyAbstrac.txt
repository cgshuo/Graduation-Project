 Benjamin Yackley benj@cs.unm.edu Terran Lane terran@cs.unm.edu Probabilistic graphical models such as Bayesian net-works (Koller &amp; Friedman, 2009), which explain pat-terns in data through dependence relations among variables, are a useful tool because of the visibility and ease of interpretation of the models and because of the ability to estimate distributions given known values. However, generating these models from observed data runs into problems in a number of ways. If the data set has too many variables, the number of possible mod-els grows exponentially, and if there are too many data points, it becomes more time-intensive to analyze the relationships between them. Although this growth is only linear in the number of data points, modern data sets run into the gigabytes or larger. What is needed is a way to separate the size of the data set from the search process, and this is the purpose of the proxy. By training a function approximator on exact scores of a random sample of networks, we can then use that proxy in the search without ever needing to go back to the original data.
 We prove here that the BDe scoring function is rea-sonably smooth over a properly chosen topology, and this fact motivates the use of a Gaussian process re-gressor as a proxy to the exact function. Once the proxy is built, the original data set need never be touched again, and the search itself can proceed ex-tremely quickly. As our results show, even taking into account the additional time needed to score the train-ing samples and generate the proxy from them, we are often able to generate better-scoring models than an exact-scoring search in a smaller amount of time. 2.1. Bayesian networks A Bayesian network (Heckerman et al., 1995) is a sta-tistical model used to represent probabilistic relation-ships among a set of variables as a directed acyclic graph, where the distribution of a single variable is de-fined in terms of the values of that variable X  X  parents in the graph. Bayesian networks are commonly used to infer distributions over unobserved or query vari-ables given known values for others (for instance, spam classification (Sebastiani &amp; Ramoni, 2001) or disease diagnosis (Burge et al., 2009)). The process of learn-ing a Bayesian network given a set of observed data is difficult, and is in fact NP-complete in the case of finding an exact optimum (Chickering, 1996; Chicker-ing et al., 1995); most techniques are still limited in practice in the number of variables they can handle at once. One key component of many of these algo-rithms is a score function which, given a fixed data set, maps individual graphs onto real numbers; the optimal network is the one whose graph has the high-est score. In other words, the function sc ( G | D ) maps the space of directed acyclic graphs G n on n nodes, one for each variable x 1 ...x n , along with a data set D  X  N m  X  n with m i.i.d. observations of those vari-ables, and the desired output of the search process is arg max G sc ( G | D ). 2.2. The BDe score There are many Bayesian network scoring functions one could use as a basis for a search, but the BDe score (Heckerman et al., 1995), has several desired properties. First, it is decomposable, meaning that it can be expressed as a function of independent com-ponents, one for each node in the graph. Second, it is a Bayesian formulation that allows us to enforce a prior belief over graph structures independent of the data itself. Finally, the structure of the BDe score is straightforward, requiring only counts of queries over the data (which can be made easier using an ADTree (Anderson &amp; Moore, 1998), as described below) and the log-Gamma function, which itself is easily approx-imated numerically. The form of the BDe score is: sc ( G | D ) = Here, the variable i ranges over all of the n nodes of the graph, j ranges over all configurations of the parents of x i , and k over all possible values of x i , which I denote the set V i . The set C ( x i ) which j ranges over is defined as a Cartesian product, C ( x i ) = Q Pa( x N ijk is the count of all data instances where x i = k and the parents of x i are in state j , while N ij = P k N ijk Similarly,  X  ijk is a hyperparameter called a pseudo-count, the set of which defines the effect of our prior on the score when the network parameters (the CPTs) are integrated out, and  X  ij = P k  X  ijk . 2.3. Gaussian process regression In previous work (Yackley et al., 2008), we showed that a spline-based regression model could be used to esti-mate the BDe score of a network. However, this par-ticular model turned out to be unsuitable for search; while the values it returned were very close to the ex-act ones, the gradients (i.e. the differences between the scores of graphs differing in one edge) were mostly wrong. Motivated by this failure, we tried a different approach. Gaussian process regression is both math-ematically simpler than the previous model and gets the gradients mostly correct.
 The form of Gaussian process regressor (Rasmussen, 2004) we use is known as simple kriging, and takes the form: In this equation, g  X  X = { G 1 ,G 2 ,...,G n s } is a set of n s training objects (graphs defining Bayesian net-works, in our case) with all of the y s being their corre-sponding real-valued scores. K is a function that pro-duces a kernel matrix such that [ K ( g,h )] ij = k ( g i where the positive-definite kernel function k : X  X  X  X  R maps pairs of objects to a value which can be seen as a generalized inner product; the more alike the two objects are, the higher this value will be.  X  g is the new graph (or set of graphs) we are trying to approximate a score for, and  X  y is that resulting score. Once the train-ing data is scored, the matrix K ( g,g )  X  1 need only be calculated once; from then on, finding an approximate score for any previously-unseen graph is just a mat-ter of calculating K ( g,  X  g ) and performing the matrix multiplications.
 Finding a proper kernel function on a given set X is, in general, not a trivial task. However, because our objects are graphs which will always be on the same ordered collection of nodes, we can compare each of the n 2 possible edges directly between the two graphs. The form our kernel function takes is: The sum runs over all possible edges of the graph, adding a weight w e to the kernel X  X  value if that edge is present in both graphs. The weights are tuned us-ing the marginal likelihood gradient 1 ; although this process involves repeatedly taking a matrix inverse un-til the values converge, the size of this matrix is only n s  X  n s , and thus, with a small number of training samples, this is relatively fast. To do fast structure learning, we want to create a proxy to the exact score function, and this proxy must have two key traits -it must be quick to evaluate, and it must be a good approximation to the true func-tion. Using a Gaussian process regressor gets us the first; once trained, its calculation is a simple matrix product. To get the second, however, we need to know that the true function we are approximating is smooth enough for a Gaussian process to model. This requires, in turn, that we define some topology over the set of directed graphs over which we can say the function is smooth.
 The topology we use here, which we call the meta-graph (Yackley et al., 2008), is defined as the graph of some relation over a set of combinatorial objects. In this case, the objects are themselves directed graphs, and the relation between them is that of differing in exactly one edge. It has two desired properties that make it attractive as a topology over which to search. First, the edges correspond to the search operations we perform -addition and deletion of edges of the target graph. Second, the structure is highly symmetric, tak-ing the form of a hypercube with dimension equal to the possible number of edges of the target. Note that, although they are not valid as Bayesian networks, the metagraph nevertheless includes graphs which contain loops. This is not a problem for an approximator; none of the training structures will contain loops, and a search will still be constrained to that part of the space with no loops.
 Furthermore, there is no danger of the approximator being asked to score a graph with cycles (even though the approximation would work mathematically, the answer it returned would be meaningless). Between any two acyclic graphs, a path must exist which never encounters a graph with a cycle; this is trivially proven by considering the process of removing every edge from the first target graph, resulting in a graph with no edges, and then adding back all edges in the second. In general, a shorter path will exist, but this serves as a proof that the region of the metagraph corresponding only to acyclic graphs is fully connected. 4.1. Notation Let the data set D  X  N m  X  n denote a data matrix of discrete values consisting of m i.i.d. observations of n variables. Denote a Bayesian network over these variables as having the graph G and parameters  X , where G = &lt; X,E &gt; and X , the set of variables equals { x 1 ,x 2 ,...x n } . A score function sc ( G | D ) maps graphs onto real numbers given a fixed data set, with the con-vention that a higher score denotes a graph modeling a better explanation of the data. Each variable x i has a corresponding finite set of possible values V i and a possibly-empty set of parents in the graph Pa( x i ). The set of parent configurations C i for node x i is given by the Cartesian product C i = Q x tation N ijk denotes the count across the entire data set of the number of instances where x i = k and each variable in Pa( x i ) takes on a value as given by config-uration j  X  C i . Also, N ij = P k  X  V The hyperparameter  X  ijk , needed for the BDe func-tion below, indicates the strength of prior beliefs on the score of a network, needed for a proper Bayesian formulation. As with the N s,  X  ij = P k  X  V 4.2. Basic Definitions Consider the standard definition of the BDe score, as given in equation 1. In practice, we are more concerned with its logarithm: log sc ( G | D ) = X We assume here that the form of the prior is such that  X  ijk is equal for all k given a fixed i and j , and that this value is inversely proportional to the cardinality of C i . In other words,  X  ij = P k  X  ijk = #( V i )  X  Assuming that all nodes are binary, then we simply have  X  ij = 2  X  ijk for all i and j , and all subscripted  X  s are proportional to some base  X  . Note also that if all nodes are binary, then #( V i ) = 2 for all i , and In order to prove smoothness, we wish to find upper and lower bounds on the magnitude of the change in score given the addition or deletion of an edge in the graph. Without loss of generality, assume that we add an edge. Call the graph before addition G , and the graph after addition G 0 , with scores sc and sc 0 given the same data set D . Because the score takes the form of a sum over all nodes of the graph, the difference be-tween sc and sc 0 can be captured solely by a single term of the outermost sum, representing the node the new arc points to  X  call this node x  X  . We can therefore drop the i subscripts in the formula itself, and repre-sent the one differing term of the two sums using sc  X  and sc 0  X  respectively. Because all other terms of the sum remain unchanged, sc  X  sc 0 = sc  X   X  sc 0  X  . Also, the range of the initial j variable, C  X  , now splits into two sets, C 0 and C 1 , where the subscript indicates the value of the newly added parent. For each element of C  X  , there is a corresponding element both in C 0 and C , and #( C  X  ) = #( C 0 ) = #( C 1 ).
 4.3. Form of the bound on sc  X   X  sc 0  X  From the above, we have: = X Since  X  j 0 =  X  j 1 =  X  j / 2 and N j = N j 0 + N j 1 , we can simplify this to: where  X  = log  X (  X  ij )  X  2 log  X (  X  ij / 2). The only dif-ference between sc  X  and sc 0  X  is the set over which j ranges; if we abbreviate the preceding sum as sc P j  X  C 0 f ( j )+ P j  X  C 1 f ( j ). Note, however, that the two addends each take the same form as the expression for sc  X  , and that the sets C 0 and C 1 have the same size as C , with all elements in a one-to-one correspondence. With some relabeling of variables, we have: Some notation abuse takes place in the second equa-tion; j 0 and j 1 are the corresponding configurations in C 0 and C 1 to j in C  X  , with the value in the ad-ditional parent being 0 or 1 respectively. Because of this, N j 0 k + N j 1 k = N jk for any k , and likewise N 0 + N j 1 = N j . Also, we have  X  j 0 =  X  j 1 =  X  j / 2. Corresponding to the above definition of  X  , let  X  = log  X (  X  ij / 2)  X  2 log  X (  X  ij / 4). Even making these sim-plifications, the full expression for sc  X   X  sc 0  X  expands to a cumbersome form; to simplify it further, we in-troduce an auxiliary function denoted as  X  . 4.4. The function  X  ( a,b ) Let the function  X  ( a,b ) be defined as follows 2 : Using Stirling X  X  approximation for the log-gamma function (Abramowitz &amp; Stegun, 1964) (ln x ! = x ln x + x  X   X ( x )), we obtain a result which will be important later: Now, we can use  X  to simplify the equation for sc  X   X  sc N j 1 . We also split out the term inside the sum and call it t , for reasons given below. 4.5. Getting to the extrema We seek upper and lower bounds on sc  X   X  sc 0  X  given fixed  X  j (and therefore fixed  X  and  X  as well). We therefore differentiate the equation with respect to the four N s and set the four derivatives all equal to zero. Because the sum over j  X  C i is irrelevant (a sum over any number of worst cases will produce a worst case, and likewise for best cases), we only need to calculate bounds for t , which we will accomplish by taking its derivative with respect to the four N pq variables to find its minimum and maximum.
 Because t is defined in terms of  X  , which is itself de-fined in terms of the log  X  function, the results will involve the  X  function 3 . For space reasons, we abbre-viate expressions of the form  X  (  X  j 2 + N j a b + N j c  X  breviations, the derivative of t with respect to some N Taking the four derivatives of t and setting them equal to zero, we obtain the system of equations: By subtracting pairs of equations, we obtain: One solution is apparent from inspection. If we set N reduce to 0 = 0. One of our extrema, therefore, oc-curs there, corresponding to the case where we add an edge to split apart data which is already uniformly dis-tributed in both variables corresponding to the edge X  X  endpoints. In other words, this edge has no reason to exist in a Bayesian network, and should logically decrease the score by the most; this is a maximum. Since we are only concerned with the asymptotic be-havior of this function, we can drop the constant terms as well as the summation (which is over a constant number of terms independent of the value of any of the N s). From equation 7, we obtain: max sc  X   X  sc 0  X  = O ((4 log 2)(  X  j / 4 + N ) = O ((log 2)(  X  j + 4 N )  X  (log 2)(  X  j + 4 N ) +  X (log N )) = O (log N ) This indicates that, in cases where adding an edge low-ers the score, the worst it can lower it by is only loga-rithmic in the number of data points.
 The other solutions to the system occur where N j 1 0 = N 0 1 = 0 or N j 0 0 = N j 1 1 = 0, representing data which (in our binary-variable case) is perfectly aligned in such a way that both the marginal of the node and its new parent seem uniform, but adding the edge re-veals their values to be in perfect correspondence with one another. The reasoning behind is is as follows. Consider our expression for t above. The minimum value occurs when the first two (positive) terms of the sum are minimized and the negative term is max-imized. Because we know from section 4.4 that the  X  function is maximized when the arguments are equal and minimized when they are farthest apart, we can force this to happen by setting N j 1 0 = N j 0 1 = 0 or N 0 0 = N j 1 1 = 0 and the other two variables equal to one another. This case corresponds to having a marginal distribution over both variables which is uni-form, but where the joint indicates a perfect corre-spondence between the two. This is exactly the sort of situation where an edge ought to be added. min sc  X   X  sc 0  X  = O  X  ( Because  X  ( a,b ) is maximized for a fixed a + b when a = b , we can say that  X  (  X  j / 4 + N, X  j / 4) &lt;  X  (  X  N/ 2 , X  j / 4 + N/ 2), and so Both the minimum and maximum score jumps, then, are simply logarithmic in the number of data points, showing that, with respect to a topology derived from addition and deletion of edges, the BDe score is Lips-chitz smooth with a constant of K = O (log N ). 4.6. Implications As one would expect, the worst case scenario is to add an edge that provides no information at all. If the joint distribution between x i and its new parent is uniform, the model gains nothing by putting the edge there, while the score (as it should) penalizes the ad-dition. The best case, meanwhile, is for the new edge to link x i to a parent that perfectly matches its val-ues (or at least a permutation of them) in all cases, while the marginals of the joint distribution are en-tirely uniform and uninformative. These fit our intu-itions of how edges in a Bayesian network should be interpreted. Also, because the worst possible changes to the score are merely logarithmic in the size of the data set, the search landscape is sufficiently smooth that a Gaussian Process regressor is an appropriate choice to represent it.
 The Gaussian process regressor is a good choice for another reason  X  the fact that it is based on a kernel function means that its complexity is not based on the size of the training set or the size of the graphs (or, for that matter, the size of the original data set), but the VC dimension of the kernel space (Sch  X olkopf &amp; Smola, 2001).
 Note also that, once the training set is scored, there is no longer a need to keep around the original data set  X  all of the information we need to search has been encapsulated into the proxy. This is a clear win in the case where the data set has a large number of in-stances; instead of needing to count up values for N ijk across perhaps millions of data points every time we take a search step, we can simply refer to the proxy. 4.7. Other score functions It is an open question, and one we hope to address in the future, whether the same kind of smoothness bound can be proven for other Bayesian network score functions. For example, the BIC score (Schwarz, 1978) is defined as follows, in terms of a log-likelihood score and a penalty term. | B | = P n i =1 (# V i  X  1)# C i is the number of degrees of freedom across the parameter set  X . In this form, adding an edge to a network will split the set of parent configurations, as before, by adding another term to the product which defines C i . However, it will also alter the value of the penalty term | B | . To compare the effects of the proxy to an exact-scoring search, we selected six data sets on which to build Bayesian networks. Three of these, Adult1 , Adult2 , and Adult3 , came from the original paper that intro-duced the ADTree (Anderson &amp; Moore, 1998), where they were used as examples of data sets an ADTree could be built on. The ADTree is a structure which provides a caching mechanism to accelerate the process of scoring; it trades off an initial tree-build time and the memory needed to store the structure to achieve much faster speed at the kind of N ijk counts neces-sary to compute a BDe score. The results for those three data sets show that, even with ADTree-based acceleration, we are able to find comparable scores in much less time using the proxy. The proxy-based search was performed 5 times with randomly selected training samples each time; the results shown here are the mean and standard deviation. The algorithm was a standard greedy search, chosen to be a reasonable baseline. It should be mentioned, though, that the benefit of using a proxy would extend, in theory, to any search algorithm that uses a scoring function. The scores of the graphs as reported in the table are exact, not derived from the proxy. Although the val-ues that the proxy returns are often very far off from exact, the gradients remain intact, and this is why we can count on the proxy to drive a search in the right direction. The values for n s reported in Table 5 are those for which our proxy performed best; experiments were conducted for a small range of different values for n .
 The other three data sets are taken from the UCI Data Repository (Frank &amp; Asuncion, 2010); they are Census-Income , Tic2000 , and Musk . All of these are too large for an ADTree to fit in memory, and so the scores were calculated using the Bayes Net Toolkit (Murphy, 2001) and its accompanying Structure Learning Package (Leray &amp; Francois, 2004). The proxy-based searches on Census-Income and Tic2000 were performed five times, as above, while the Musk data set was large enough that it was only practical to perform a single search for each differing number of training samples. The algorithms were im-plemented in Matlab , on a Linux server running at 2.2 GHz with 32 gigabytes of RAM. 5.1. Discussion The effects of the proxy are clear; in all but one case, the networks found by the proxy-based search were either comparable to or significantly better than those found by the exact-scoring version, and always in a Adult1 15 15060 250 Adult2 15 30162 250 Adult3 15 45222 100 Cens-Inc 42 95130 250 Tic2000 86 9822 25 Adult1 91.32 22 . 70  X  1 . 36 Adult2 149.75 34 . 90  X  2 . 27 Adult3 209.59 18 . 00  X  0 . 20 Cens-Inc 733.4 501 . 4  X  41 . 3 Tic2000 45.2 23 . 24  X  0 . 83 shorter time. At present, we don X  X  know what property of the Census-Income data set made it perform so poorly.
 In every other case, however, the advantage of the smoothing induced by the proxy is clear, and this is most dramatic in the case of the Musk data set. With a relatively tiny number samples across the immense space of networks on 168 nodes, the proxy was never-theless able to find a network with a greatly improved score. The reason for this  X  and the reason smooth-ness is so important  X  is shown in Figure 5.1. These lines are the search trajectories, with search step on the x axis and score on the y axis. The thick line is the trajectory taken by the exact-scoring search, while the thinner blue lines are the ones taken by five runs of the proxy with different sets of 50 training samples. The exact search stops partway through, having encoun-tered a local maximum. However, the proxy will tend to smooth these local features out, letting the search process continue to greater heights. In fact, too many training samples can in fact hamper the proxy X  X  even-Adult1  X  1 . 219  X  1 . 265  X  0 . 028 Adult2  X  3 . 059  X  2 . 964  X  0 . 104 Adult3  X  4 . 879  X  4 . 679  X  0 . 169 Cens-Inc  X  8 . 205  X  9 . 614  X  0 . 66 Tic2000  X  3 . 498  X  3 . 050  X  0 . 09 tual score. Figure 5.1 plots each of the proxy X  X  runs with a different value of n s as a bubble in a time-score graph, with the size of the oval being one standard de-viation in either dimension. The lowest value, n s = 5, is at the bottom left, having taken a very short over-all time but producing a relatively bad network. The bubbles continue up and to the right, with both time and score growing, until we reach the farthest-right point on the graph when n s = 60. From there, the time continues to increase, but the score worsens. We believe that this is due to the proxy starting to learn the space too well, capturing the finer features of the score landscape while losing sight of the bigger picture. We are currently working on extending the proxy to other score-based search strategies, such as simulated annealing (Kirkpatrick et al., 1983), as well as to other combinatorial objects such as general 0-1 matrices and permutations. The success of these rests, it would seem, on finding a proper form for a kernel function on these objects, thus defining the topology of the space both traversed by the search method and used by the approximator.
 Another direction we wish to extend this in is to imple-ment the training phase on a massively parallel system, which would greatly reduce the time taken to train the proxy. This would also require the implementation of a way to combine the training results; a block-matrix in-version technique will be useful here, as well as adding the potential to add more training data in the middle of an ongoing search. This way, the space around an apparent local maximum could be examined in greater detail and refined. As data sets increase in size, it becomes more nec-essary to develop algorithms which can search for and identify models of them in reasonable amounts of time. However, the larger the data set gets, the more time this takes, and the larger the search space, the more chance there is of a search running into a local maxi-mum instead of the desired global. A proxy function will alleviate both of these problems; in particular, we showed that the BDe score considered over a search space of single-edge additions and deletions is smooth enough to make a proxy-based search viable, and the results bear this out.
 This process, building a proxy function from a set of random samples and then using it to drive a search, is readily applicable to any search algorithm that de-pends on calculating a series of scores, from a sim-ple greedy search to more sophisticated ones such as Markov Chain Monte Carlo. These new accelerated forms of algorithms will allow researchers in fields as diverse as astronomy (Kent, 1994), biology (Roy et al., 2007), and linguistics (Davies, 2009) to better analyze data and create hypotheses given their often stagger-ingly large data sets. Through the use of the proxy-based search accelerator, we will be able to find pat-terns in more complex data than had previously been feasible. The authors wish to thank Blake Anderson and Ed-uardo Corona for their ideas and support, as well as the Machine Learning Reading Group at the Univer-sity of New Mexico. This research was supported by National Science Foundation grant IIS-0705681 and Office of Naval Research grant N000141110139.

