 Translation coverage is a major concern in statis-tical machine translation (SMT) which relies on large amounts of parallel, sentence-aligned text. In (Callison-Burch et al., 2006), even with a training data size of 10 million word tokens, source vocab-ulary coverage in unseen data does not go above 90% . The problem is worse with multi-word OOV phrases. Copying OOVs to the output is the most common solution. However, even noisy transla-tions of OOVs can improve reordering and lan-guage model scores (Zhang et al., 2012). Translit-eration is useful but not a panacea for the OOV problem (Irvine and Callison-Burch, 2014b). We find and remove the named entities, dates, etc. in the source and focus on the use of paraphrases to help translate the remaining OOVs. In Sec. 5.2 we show that handling such OOVs correctly does im-prove translation scores.

In this paper, we build on the following re-search: Bilingual lexicon induction is the task of learning translations of words from monolin-gual data in source and target languages (Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). The distributional pro-file (DP) approach uses context vectors to link words as potential paraphrases to translation can-didates (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009). DPs have been used in SMT to assign translation can-didates to OOVs (Marton et al., 2009; Daum  X  e and Jagarlamudi, 2011; Irvine et al., 2013; Irvine and Callison-Burch, 2014a). Graph-based semi-supervised methods extend this approach and propagate translation candidates across a graph with phrasal nodes connected via weighted para-phrase relationships (Razmara et al., 2013; Saluja et al., 2014; Zhao et al., 2015). Saluja et al. (2014) extend paraphrases for SMT from the words to phrases, which we also do in this work. Bilin-gual pivoting uses parallel data instead of con-text vectors for paraphrase extraction (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Bannard and Callison-Burch, 2005; Callison-Burch et al., 2006; Zhao et al., 2008; Callison-Burch, 2008). Ganitkevitch and Callison-Burch (2014) published a large-scale multilingual Para-phrase Database (PPDB) http://paraphrase. org which includes lexical, phrasal, and syntactic paraphrases (available for 22 languages with up to 170 million paraphrases each).

To our knowledge, this paper is the first com-prehensive study of the use of PPDB for statistical machine translation model training. Our frame-work has three stages: 1) a novel graph con-struction approach for PPDB paraphrases linked with phrases from parallel training data. 2) Graph propagation that uses PPDB paraphrases. 3) An SMT model that incorporates new translation can-didates. Sec. 3 explains these three stages in detail.
Using PPDB has several advantages: 1) Re-sources such as PPDB can be built and used for many different tasks including but not limited to SMT. 2) PPDB contains many features that are useful to rank the strength of a paraphrase con-nection and with more information than distribu-tional profiles. 3) Paraphrases in PPDB are often better than paraphrases extracted from monolin-gual or comparable corpora because a large-scale multilingual paraphrase database such as PPDB can pivot through a large amount of data in many different languages. It is not limited to using the source language data for finding paraphrases which distinguishes it from previous uses of para-phrases for SMT.
 PPDB is a natural resource for paraphrases. However, PPDB was not built with the specific ap-plication to SMT in mind. Other applications such as text-to-text generation have used PPDB (Gan-itkevitch et al., 2011) but SMT brings along a specific set of concerns when using paraphrases: translation candidates should be transferred suit-ably across paraphrases. There are many cases, e.g. when faced with different word senses where transfer of a translation is not appropriate. Our proposed methods of using PPDB use graph prop-agation to transfer translation candidates in a way that is sensitive to SMT concerns.

In our experiments (Sec. 5) we compare our approach with the state-of-the-art in three differ-ent settings in SMT: 1) when faced with limited amount of parallel training data; 2) a domain shift between training and test data; and 3) handling a morphologically complex source language. In each case, we show that our PPDB-based approach outperforms the distributional profile approach. Our goal is to produce translations for OOV phrases by exploiting paraphrases from the mul-tilingual PPDB (Ganitkevitch and Callison-Burch, 2014) by using graph propagation. Since our ap-proach relies on phrase-level paraphrases we com-pare with the current state of the art approaches that use monolingual data and distributional pro-files to construct paraphrases and use graph prop-agation (Razmara et al., 2013; Saluja et al., 2014). 2.1 Paraphrases from Distributional Profiles A distributional profile (DP) of a word or phrase was first proposed in (Rapp, 1995) for SMT. Given a word f , its distributional profile is: V is the vocabulary and the surrounding words w i are taken from a monolingual corpus using a fixed window size. We use a window size of 4 words based on the experiments in (Razmara et al., 2013). DPs need an association measure A (  X  ,  X  ) to compute distances between potential paraphrases. A comparison of different association measures appears in (Marton et al., 2009; Razmara et al., 2013; Saluja et al., 2014) and our preliminary ex-periments validated the choice of the same asso-ciation measure as in these papers, namely Point-wise Mutual Information (Lin, 1998) (PMI). For each potential context word w i : To evaluate the similarity between two phrases we use cosine similarity. The cosine coefficient of two phrases f 1 and f 2 is: S ( f 1 ,f 2 ) = cos ( DP ( f 1 ) ,DP ( f 2 )) = q P where V is the vocabulary. Note that in Eqn. (2) w  X  X  are the words that appear in the context of f 1 or f 2 , otherwise the PMI values would be zero.
Considering all possible candidate paraphrases is very expensive. Thus, we use the heuristic ap-plied in previous works (Marton et al., 2009; Raz-mara et al., 2013; Saluja et al., 2014) to reduce the search space. For each phrase we keep candidate paraphrases which appear in one of the surround-ing context (e.g. Left Right ) among all occur-rences of the phrase. 2.2 Paraphrases from bilingual pivoting Bilingual pivoting uses parallel corpora between the source language, F , and a pivot language T . If two phrases, f 1 and f 2 , in a same language are paraphrases, then they share a translation in other languages with p ( f 1 | f 2 ) as a paraphrase score: S ( f 1 ,f 2 ) = p ( f 1 | f 2 ) = Figure 1: English paraphrases extracted by pivot-ing over German shared translation (Bannard and Callison-Burch, 2005). where t is a phrase in language T . p ( f 1 | t ) and p ( t | f 2 ) are taken from the phrase table extracted from parallel data for languages F and T . In Fig. 1 from (Bannard and Callison-Burch, 2005) we see that paraphrase pairs like ( in check , under con-trol ) can be extracted by pivoting over the German phrase unter kontrolle .

The multilingual Paraphrase Database (PPDB) (Ganitkevitch and Callison-Burch, 2014) is a published resource for paraphrases extracted using bilingual pivoting. It leverages syntactic information and other resources to filters and scores each paraphrase pair using a large set of features. These features can be used by a log linear model to score paraphrases (Zhao et al., 2008). We used a linear combination of these fea-tures using the equation in Sec. 3 of (Ganitkevitch and Callison-Burch, 2014) to score paraphrase pairs. PPDB version 1 is broken into different levels of coverage. The smaller sizes contain only better-scoring, high-precision paraphrases, while larger sizes aim for high coverage.
 Algorithm 1 PPDB Graph Propagation for SMT After paraphrase extraction we have paraphrase pairs, ( f 1 ,f 2 ) and a score S ( f 1 ,f 2 ) we can in-duce new translation rules for OOV phrases us-ing the steps in Algo. (1): 1) A graph of source phrases is constructed as in (Razmara et al., 2013); 2) translations are propagated as labels through the graph as explained in Fig. 2; and 3) new trans-lation rules obtained from graph-propagation are integrated with the original phrase table. 3.1 Graph Construction We construct a graph G ( V,E,W ) over all source phrases in the paraphrase database and the source language phrases from the SMT phrase table ex-tracted from the available parallel data. V cor-responds to the set of vertices (source phrases), E is the set of edges between phrases and W is weight of each using the score function S defined in Sec. 2. V has two types of nodes: seed (labeled) nodes, V s , from the SMT phrase table, and regu-lar nodes, V r . Note that in this step OOVs are part of these regular nodes, and we try to find transla-tion in the propagation step for all of these regu-lar nodes. In graph construction and propagation, we do not know which phrasal nodes correspond to OOVs in the dev and test set. Fig. 2 shows a small slice of the actual graph used in one of our experiments; This graph is constructed using the paraphrase database on the right side of the figure. Filled nodes have a distribution over translations (the possible  X  X abels X  for that node). In our setting, we consider the translation e to be the  X  X abel X  and so we propagate the labeling distribution p ( e | f ) which is taken from the feature function for the SMT log-linear model that is taken from the SMT phrase table and we propagate this distribution to unlabeled nodes in the graph. 3.2 Graph Propagation Considering the translation candidates of known phrases in the SMT phrase table as the  X  X abels X  we apply a soft label propagation algorithm in order to assign translation candidates to  X  X nlabeled X  nodes in the graph, which include our OOV phrases. As described by the example in Fig. 2 we wish two outcomes: 1) transfer of translations (or  X  X a-bels X ) to unlabeled nodes (OOV phrases) from la-beled nodes, and 2) smoothing the label distribu-tion at each node. We use the Modified Adsorption (MAD) algorithm (Talukdar and Crammer, 2009) for graph propagation. Suppose we have m dif-ferent possible labels plus one dummy label , a soft label  X  Y  X   X  m +1 is a m + 1 dimension probabil-ity vector. The dummy label is used when there is low confidence on correct labels. Based on MAD, we want to find soft label vectors for each node by optimizing the objective function below: min In this objective function,  X  i and P i,v are hyper-parameters (  X  v :  X  i P i,v = 1) . R v  X   X  m +1 is our prior belief about labeling. First component of the function tries to minimize the difference of new distribution to the original distribution for the seed nodes. The second component insures that nearby neighbours have similar distributions, and the final component is to make sure that the dis-tribution does not stray from a prior distribution. At the end of propagation, we wish to find a la-bel distribution for our OOV phrases. We describe in Sec. 4.2.2 the reasons for choosing MAD over other graph propagation algorithms. The MAD graph propagation generalizes the approach used in (Razmara et al., 2013). The Structured Label Propagation algorithm (SLP) was used in (Saluja et al., 2014; Zhao et al., 2015) which uses a graph structure on the target side phrases as well. How-ever, we have found that in our diverse experimen-tal settings (see Sec. 5) MAD had two properties we needed compared to SLP: one was the use of graph random walks which allowed us to control translation candidates and MAD also has the abil-ity to penalize nodes with a large number of edges (also see Sec. 4.2.2). 3.3 Phrase Table Integration After propagation, for each potential OOV phrase we have a list of possible translations with corre-sponding probabilities. A potential OOV is any phrase which does not appear in training, but could appear in unseen data. We do not look at the dev or test data to produce the augmented phrase ta-ble. The original phrase table is now augmented with new entries providing translation candidates for potential OOVs; Last column in Table 2 shows how many entries have been added to the phrase table for each experimental settings. A new fea-ture is added to the standard SMT log-linear dis-criminative model and introduced into the phrase table. This new feature is set to either 1 . 0 for the phrase table entries that already existed; or ` i which is the log probability (from graph propaga-tion) for the translation candidate i for potential OOVs. In case the dummy label exists with high probability or the label distribution is uniform, an identity rule is added to the phrase table (copy over source to target). 4.1 Propagation of poor translations Automatic paraphrase extraction generates many possible paraphrase candidates and many of them are likely to be false positives for finding transla-tion candidates for OOVs. Distributional profiles rely on context information which is not sufficient to derive accurate paraphrases for many phrases and this results in many low quality paraphrase candidates. Bilingual pivoting uses word align-ments which can also introduce errors depending on the size and quality of the bilingual data used. Alignment errors also introduce poor translations. Size Nodes Edges Max S 23K 31K 32 1.38 M 41K 69K 33 1.69 L 74K 199K 67 2.69 XL 103K 548K 330 5.33 XXL 122K 2073K 1231 16.968 XXXL 125K 7558K 5255 60.27 Table 1: Statistics of the graph constructed using the English lexical PPDB. We have built similar graphs for French and Arabic.
 In graph propagation, these errors may be propa-gated and result in poor translations for OOVs.
We could address this issue by aggressively pruning the potential paraphrase candidates to im-prove the precision. However, this results in a dra-matic drop in coverage and many OOV phrases do not obtain any translation candidates. We use a combination of the following three steps to aug-ment our graph propagation framework. 4.1.1 Graph pruning and PPDB sizes Pruning the graph avoids error propagation by re-moving unreliable edges. Pruning removes edges with an edge weight lower than a minimum thresh-old or by limiting the number of neighbours to the top-K edges (Talukdar, 2009). PPDB has different sizes with different levels of accuracy and cover-age. We can do graph pruning simply by choosing to use different sizes of PPDB. As we can see in Fig. 3 results vary from language to language de-pending on the pruning used. For instance, the L size results in the best score for French-English. We choose the best size of PPDB for each lan-guage based on a separate held-out set and inde-pendently from each of the SMT-based tasks in our experimental results. Our conclusion from our ex-periments with the different sizes of PPDB is that removing phrases (or nodes in our graph) is not desirable. However, removing unreliable edges is useful. As seen in Table 1, increasing the size of PPDB leads to a rapid increase in nodes fol-lowed by a larger number of edges in the very large PPDB sizes. 4.1.2 Pruning the translation candidates Another solution to the error propagation issue is to propagate all translation candidates but when providing translations to OOVs in the final phrase Figure 3: Effect of PPDB size on improving BLEU score for Spanish and French table to eliminate all but the top L translations for each phrase (which is the usual ttable limit in phrase-based SMT (Koehn et al., 2003)). Based on a development set, separate from the test sets we used, we found that the best value of L was 10. 4.1.3 External Resources for Filtering Applying more informative filters can be also used to improve paraphrase quality. This can be done through additional features for paraphrase pairs. For example, edit distance can be used to capture misspelled paraphrases. We use a Named Entity Recognizer to exclude names, numbers and dates from the paraphrase candidates. Even after remov-ing these tokens, 3.32% of tokens of test set are still OOVs . In addition, we use a list of stop words to remove nodes which have too many connec-tions. These two filters improve our results (more in Sec. 5). 4.2 Path sensitivity Graph propagation has been used in many NLP tasks like POS tagging, parsing, etc. but propa-gating translations in a graph as labels is much more challenging. Due to huge number of pos-sible labels (translations) and many low quality edges, it is very likely that many wrong transla-tions are rapidly propagated in few steps. Raz-mara et al. (2013) show that unlabeled nodes in-side the graph, called bridge nodes , are useful for the transfer of translations when there is no other connection between an OOV phrase and a node with known translation candidates. However, they show that using the full graph with long paths of bridge nodes hurts performance. Thus the propa-gation has to be constrained using path sensitivity . Fig. 4 shows this issue in a part of an English para-Figure 4: Sensitivity issue in graph propagation for translations.  X  X ager X  is a translation candidate for  X  X tock X , which is transferred to  X  X ajority X  af-ter 3 iterations. phrase graph. After three iterations, German trans-lation  X  X ager X  reaches  X  X ajority X  which is totally irrelevant as a translation candidate. Transfer of translation candidates should prefer close neigh-bours and only with a very low probability to other nodes in the graph. 4.2.1 Pre-structuring the graph Razmara et al. (2013) avoid a fully connected graph structure. They pre-structure the graph into bipartite graphs (only connections between phrases with known translation and OOV phrases) and tripartite graphs (connections can also go from a known phrasal node to an OOV phrasal node through one node that is a paraphrase of both but does not have translations, i.e. it is an unla-beled node). In these pre-structured graphs there are no connections between nodes of the same type (known, OOV or unlabeled). We apply this method in our low resource setting experiments (Sec. 5.3) to compare our bipartite and tripartite results to Razmara et al. (2013). In the rest of the experiments we use the tripartite approach since it outperforms the bipartite approach. 4.2.2 Graph random walks Our goal is to limit the number of hops in the prop-agation of translation candidates preferring closely connected and highly probable edge weights. Op-timization for the Modified Adsorption (MAD) objective function in Sec. 3.2 can be viewed as a controlled random walk (Talukdar et al., 2008; Talukdar and Crammer, 2009). This is formal-ized as three actions: inject , continue and aban-don with corresponding pre-defined probabilities P inj , P cont and P abnd respectively as in (Taluk-dar and Crammer, 2009). A random walk through the graph will transfer labels from one node to an-other node, and probabilities P cont and P abnd con-trol exploration of the graph. By reducing the val-ues of P cont and increasing P abnd we can control the label propagation process to optimize the qual-ity of translations for OOV phrases. Again, this is done on a held-out development set and not on the test data. The optimal values in our experiments for these probabilities are P inj = 0 . 9 ,P cont = 0 . 001 ,P abnd = 0 . 01 . 4.2.3 Early stopping of propagation In Modified Adsorption (MAD) (see Sec. 3.2) nodes in the graph that are closely linked will tend to similar label distributions as the number of it-erations increase (even when the path lengths in-crease). In our setting, smoothing the label distri-bution helps in the first few iterations, but is harm-ful as the number of iterations increase due to the factors shown in Fig. 4. We use early stopping which limits the number of iterations. We varied the number of iterations from 1 to 10 on a held-out dev set and found that 5 iterations was optimal. We first show the effect of OOVs on translation quality, then evaluate our approach in three dif-ferent SMT settings: low resource SMT, domain shift, and morphologically complex languages. In each case, we compare results of using para-phrases extracted by Distributional Profile (DP) and PPDB in an end-to-end SMT system.
 Important: no subset of the test data sentences are used in the bilingual corpora for paraphrase ex-traction process. 5.1 Experimental Setup fast align (Dyer et al., 2013) is used for word alignment, and weights are tuned by minimizing BLEU loss on the dev set using MIRA (Cram-mer and Singer, 2003). This setup is used for most of our experiments: oracle (Sec. 5.2), do-main adaptation (Sec. 5.4) and morphologically complex languages (Sec. 5.5). But as we wish to fairly compare our approach with Razmara et al. (2013) on low resource setting, we follow their setup in Sec. 5.3: Moses (Koehn et al., 2007) as SMT pipeline, GIZA++ (Och and Ney, 2003) for word alignment and MERT (Och, 2003) for tun-ing. We add our own feature to the SMT log-linear model as described in Sec. 3.3. Experiments OOV type/token Rules added Case 1 1830 / 2163 7.0K Case 2 -Med. 2294 / 4190 7.8K Case 2 -Sci. 5272 / 14121 10.4K Case 3 1543 / 1895 8.1K Table 2: Statistics of settings in Sec. 5. Last col-umn shows how many rules added in the phrase table integration step.

KenLM (Heafield, 2011) is used to train a 5-gram language model on English Gigaword (V5: LDC2011T07). For scalable graph propagation phrase length 10. For our experiments we use the Hadoop distributed computing framework ex-ecuted on a cluster with 12 nodes (each node has 8 cores and 16GB of RAM). Each graph propaga-tion iteration takes about 3 minutes.

For French, we apply a simple heuristic to de-tect named entities: words that are capitalized in the original dev/test set that do not appear at the beginning of a sentence are named entities. Based on eyeballing the results, this works very well in our data. For Arabic, AQMAR is used to exclude named-entities (Mohit et al., 2012). For each of the experimental settings below we show the OOV statistics in Table 2. 5.2 Impact of OOVs: Oracle experiment This oracle experiment shows that translation of OOVs beyond named entities, dates, etc. is poten-tially very useful in improving output translation. We trained a SMT system on 10K French-English sentences from the Europarl corpus(v7) (Koehn, 2005). WMT 2011 and WMT 2012 are used as dev and test data respectively. Table 4 shows the results in terms of BLEU on dev and test. The first row is baseline which simply copies OOVs to output. The second and third rows show the re-sult of augmenting phrase-table by adding transla-tions for single-word OOVs and phrases contain-ing OOVs. The last row shows the oracle result where dev and test sentences exist inside the train-ing data and all the OOVs are known (Fully ob-servers cannot avoid model and search errors). 5.3 Case 1: Limited Parallel Data In this experiment we use a setup similar to (Raz-mara et al., 2013). To have fair comparison, we use 10K French-English parallel sentences, randomly chosen from Europarl to train trans-lation system, as reported in (Razmara et al., data. We re-implement their paraphrase extraction method (DP) to extract paraphrases from French side of Europarl (2M sentences). We use unigram nodes to construct graphs for both DP and PPDB. In bipartite graphs, each node is connected to at most 20 nodes. For tripartite graphs, each node is connected to 15 labeled and 5 unlabeled nodes. For intrinsic evaluation, we use Mean-Reciprocal-Rank (MRR) and Recall. MRR is the mean of reciprocal rank of the candidate list compared to the gold list (Eqn. 5). Recall shows percentage of gold list covered by the candidate list (Eqn. 6). Gold translations for OOVs are given by concatenating the test data to training and running a word aligner.

MRR = Table 5 compares DP and PPDB in terms of BLEU, MRR and Recall. It indicates that PPDB (large size) outperforms DP in both intrinsic and extrinsic evaluation measures. Although tripartite graph did not improve the results for DP, it results in statistically significantly better BLEU score for PPDB in comparison to DP (evaluated by MultE-val (Clark et al., 2011)). Thus we use tripartite graph in the rest of experiments. The last row in the table shows the result of combining DP and PPDB by multiplying the normalized scores of both paraphrase lists.

This setting is included for three reasons: 1) we exploit the small data size to explore differ-ent choices in our approach such as, e.g. choos-ing bipartite versus tripartite graph structures; 2)
System MRR Recall BLEU baseline --28.89 DP-bipartite 5.34 11.90 29.27 DP-tripartite 5.34 11.95 29.27 PPDB fr (L)-bipartite 12.05 22.08 29.46 PPDB fr (L)-tripartite 10.22 22.87 29.52 Combined-tripartite --29.28
Table 5: Results of PPDB and DP techniques. to show how well our PPDB approach does com-pared to the DP approach in terms of MRR and recall; and 3) to show applicability of our ap-proach for a low-resource language. However we used French instead of a language which is truly resource-poor due to the lack of available para-phrases for a true resource poor language, e.g. Malagasy. 5.4 Case 2: Domain Adaptation Domain adaptation is another case that suffers from massive number of OOVs. We compare our approach with Marginal Matching (Irvine et al., 2013), a state of the art approach in SMT domain adaptation. We use their setup and data and com-pare our results to their reported results (Irvine et al., 2013). 250K lines of Hansard parliamentary proceeding are used for training MT. Dev and test sets are available for two different domains: Medi-cal and Science domains. For medical domain ran-dom subset of EMEA corpus (Tiedemann, 2009) and for the science domain a corpus of scientific articles (Carpuat et al., 2012) has been used. Un-igram paraphrases using DP are extracted from French side of Europarl.

Table 6 compares the results in terms of BLEU score. In both medical and science domains, graph-propagation approach using PPDB (large) performs significantly better than DP ( p &lt; 0 . 02 ), and has comparable results to Marginal Matching. Table 6: BLEU scores for domain adaptation. Table 7: BLEU score results for Arabic-English. Marginal Matching performs better in science do-main but graph-propagation approach with PPDB outperforms it in medical domain getting a +1 . 79 BLEU score improvement over the baseline. 5.5 Case 3: Morphologically Rich Languages Both Distribution Profiling and Bilingual Pivot-ing propose morphological variants of a word as paraphrase pairs. Even more so in PPDB due to pivoting over English. We choose Arabic-English task for this experiment. We train the SMT system on 685K sentence pairs (randomly selected from LDC2007T08 and LDC2008T09) and use NIST OpenMT 2012 for dev and test data. Arabic side of 1M sentences of LDC2007T08 and LDC2008T09 is used to extract unigram paraphrases for DP. Ta-ble 7 shows that PPDB (large; with phrases) re-sulted in +1 . 53 BLEU score improvement over DP which only slightly improved over baseline. Sentence level paraphrasing has been used for gen-erating alternative reference translations (Madnani et al., 2007; Kauchak and Barzilay, 2006), or augmenting the training data with sentential para-phrases (Bond et al., 2008; Nakov, 2008; Mirkin et al., 2009). Phrase level paraphrasing was done us-ing crowdsourcing (Resnik et al., 2010) or by us-ing paraphrases in lattice decoding (Onishi et al., 2010; Du et al., 2010).

Daum  X  e and Jagarlamudi (2011) apply a genera-tive model to domain adaptation based on canon-ical correlation analysis Haghighi et al. (2008). However, they use artificially created monolingual corpora very related to the same domain as test data. Irvine and Callison-Burch (2014a) gener-ate a large, noisy phrase table by composing un-igram translations which are obtained by a super-vised method (Irvine and Callison-Burch, 2013). Comparable monolingual data is used to re-score and filter the phrase table. Zhang and Zong (2013) use a large manually generated lexicon for do-main adaptation. In contrast to these methods, our method is unsupervised.

Alexandrescu and Kirchhoff (2009) use a graph-based semi-supervised model determine similarities between sentences, then use it to re-rank the n-best translation hypothesis. Liu et al. (2012) extend this model to derive some features to be used during decoding. These approaches are orthogonal to our approach. Saluja et al. (2014) use Structured Label Propagation (Liu et al., 2012) in two parallel graphs constructed on source and target paraphrases. In their case the graph con-struction is extremely expensive. Leveraging a morphological analyzer, they reach significant im-provement on Arabic. We can not directly com-pare our results to (Saluja et al., 2014) because they exploit several external resources such as a morphological analyzer and also had different sizes of training and test. In experiments (Sec. 5) we obtained comparable BLEU score improve-ment on Arabic-English by using bilingual pivot-ing only on source phrases. (Saluja et al., 2014) also use methods similar to (Habash, 2008) that expand the phrase table with spelling and morpho-logical variants of OOVs in test data. We do not use the dev/test data to augment the phrase table.
Using comparable corpora to extract parallel sentences and phrases (Munteanu and Marcu, 2006; Smith et al., 2010; Tamura et al., 2012) are orthogonal to the approach we discuss here.
Bilingual and multilingual word and phrase rep-resentation using neural networks have been ap-plied to machine translation (Zou et al., 2013; Mikolov et al., 2013a; Zhang et al., 2014). How-ever, most of these methods focus on frequent words or an available bilingual phrase table (Zou et al., 2013; Zhang et al., 2014; Gao et al., 2014). Mikolov et al. (2013a) learn a global linear projec-tion from source to target using representation of frequent words on both sides. This model can be used to generate translations for new words, but a large amounts of bilingual data is required to cre-ate such a model. (Mikolov et al., 2013b) also uses bilingual data to project new translation rules. Zhao et al. (2015) extend Mikolov X  X  model to learn one local linear projection for each phrase. Their model reaches comparable results to Saluja et al. (2014) while works faster. Alkhouli et al. (2014) use neural network phrase representation for para-phrasing OOVs and find translation for them using a phrase-table created from limited parallel data. Our experimental settings is different from the ap-proaches in (Alkhouli et al., 2014; Mikolov et al., 2013a; Mikolov et al., 2013b). In future work, we would like to include transla-tions for infrequent phrases which are not OOVs. We would like to explore new propagation meth-ods that can directly use confidence estimates and control propagation based on label sparsity. We also would like to expand this work for mor-phologically rich languages by exploiting other resources like morphological analyzer and cam-pare our approach to the current state of art ap-proaches which are using these types of resources. In conclusion, we have shown significant improve-ments to the quality of statistical machine transla-tion in three different cases: low resource SMT, domain shift, and morphologically complex lan-guages. Through the use of semi-supervised graph propagation, a large scale multilingual paraphrase database can be used to improve the quality of sta-tistical machine translation.
 The authors would like to thank Chris Callison-Burch and Juri Ganitkevitch for providing us the latest version of PPDB, the anonymous reviewers for their comments. The research was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC RGPIN 262313 and RGPAS 446348) to the last author.
