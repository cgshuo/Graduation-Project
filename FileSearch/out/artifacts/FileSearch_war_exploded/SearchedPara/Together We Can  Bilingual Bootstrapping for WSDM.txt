 The high cost of collecting sense annotated data for supervised approaches (Ng and Lee, 1996; Lee et al., 2004) has always remained a matter of concern for some of the resource deprived languages of the world. The problem is even more hard-hitting for multilingual regions ( e.g. , India which has more than 20 constitutionally recognized languages). To cir-cumvent this problem, unsupervised and knowledge based approaches (Lesk, 1986; Walker and Amsler, 1986; Agirre and Rigau, 1996; McCarthy et al., 2004; Mihalcea, 2005) have been proposed as an al-ternative but they have failed to deliver good accura-cies. Semi-supervised approaches (Yarowsky, 1995) which use a small amount of annotated data and a large amount of untagged data have shown promise albeit for a limited set of target words. The above situation highlights the need for high accuracy re-source conscious approaches to all-words multilin-gual WSD.

Recent work by Khapra et al. (2010) in this di-rection has shown that it is possible to perform cost effective WSD in a target language ( L compromising much on accuracy by leveraging on the annotation work done in another language ( L This is achieved with the help of a novel synset-aligned multilingual dictionary which facilitates the projection of parameters learned from the Wordnet and annotated corpus of L thus obviates the need for collecting large amounts of annotated corpora in multiple languages by rely-ing on sufficient annotated corpus in one resource rich language. However, in many situations such a pivot resource rich language itself may not be avail-able. Instead, we might have two or more languages having a small amount of annotated corpus and a large amount of untagged corpus. Addressing such situations is the main focus of this work. Specifi-cally, we address the following question: While addressing the above question we assume that even though it is hard to obtain large amounts of annotated data in multiple languages, it should be fairly easy to obtain a large amount of untagged data in these languages. We leverage on such untagged data by employing a bootstrapping strategy. The idea is to train an initial model using a small amount of annotated data in both the languages and itera-tively expand this seed data by including untagged instances which get tagged with a high confidence in successive iterations. Instead of using monolin-gual bootstrapping, we use bilingual bootstrapping via parameter projection. In other words, the pa-rameters learned from the annotated data of L L tively) and the projected model is used to tag the un-tagged instances of L
Such a bilingual bootstrapping strategy when tested on two domains, viz. , Tourism and Health us-ing Hindi ( L pair, consistently does better than a baseline strat-egy which uses only seed data for training without performing any bootstrapping. Further, it consis-tently performs better than monolingual bootstrap-ping. A simple and intuitive explanation for this is as follows. In monolingual bootstrapping a language can benefit only from its own seed data and hence can tag only those instances with high confidence which it has already seen. On the other hand, in bilingual bootstrapping a language can benefit from the seed data available in the other language which was not previously seen in its self corpus. This is very similar to the process of co-training (Blum and Mitchell, 1998) wherein the annotated data in the two languages can be seen as two different views of the same data. Hence, the classifier trained on one view can be improved by adding those untagged in-stances which are tagged with a high confidence by the classifier trained on the other view.

The remainder of this paper is organized as fol-lows. In section 2 we present related work. Section 3 describes the Synset aligned multilingual dictio-nary which facilitates parameter projection. Section 4 discusses the work of Khapra et al. (2009) on pa-rameter projection. In section 5 we discuss bilin-gual bootstrapping which is the main focus of our work followed by a brief discussion on monolingual bootstrapping. Section 6 describes the experimental setup. In section 7 we present the results followed by discussion in section 8. Section 9 concludes the paper. Bootstrapping for Word Sense Disambiguation was first discussed in (Yarowsky, 1995). Starting with a very small number of seed collocations an initial de-cision list is created. This decisions list is then ap-plied to untagged data and the instances which get tagged with a high confidence are added to the seed data. This algorithm thus proceeds iteratively in-creasing the seed size in successive iterations. This monolingual bootstrapping method showed promise when tested on a limited set of target words but was not tried for all-words WSD.
 The failure of monolingual approaches (Ng and Lee, 1996; Lee et al., 2004; Lesk, 1986; Walker and Amsler, 1986; Agirre and Rigau, 1996; McCarthy et al., 2004; Mihalcea, 2005) to deliver high accura-cies for all-words WSD at low costs created interest in bilingual approaches which aim at reducing the annotation effort. Recent work in this direction by Khapra et al. (2009) aims at reducing the annotation effort in multiple languages by leveraging on exist-ing resources in a pivot language. They showed that it is possible to project the parameters learned from the annotation work of one language to another lan-guage provided aligned Wordnets for the two lan-guages are available. However, they do not address situations where two resource deprived languages have aligned Wordnets but neither has sufficient an-notated data. In such cases bilingual bootstrapping can be used so that the two languages can mutually benefit from each other X  X  small annotated data.
Li and Li (2004) proposed a bilingual bootstrap-ping approach for the more specific task of Word Translation Disambiguation (WTD) as opposed to the more general task of WSD. This approach does not need parallel corpora (just like our approach) and relies only on in-domain corpora from two lan-guages. However, their work was evaluated only on a handful of target words (9 nouns) for WTD as op-posed to the broader task of WSD. Our work instead focuses on improving the performance of all words WSD for two resource deprived languages using bilingual bootstrapping. At the heart of our work lies parameter projection facilitated by a synset aligned multilingual dictionary described in the next section. A novel and effective method of storage and use of dictionary in a multilingual setting was proposed by Mohanty et al. (2008). For the purpose of current discussion, we will refer to this multilingual dictio-nary framework as MultiDict . One important de-parture in this framework from the traditional dic-tionary is that synsets are linked, and after that the words inside the synsets are linked . The ba-sic mapping is thus between synsets and thereafter between the words.
 Table 1 shows the structure of MultiDict, with one example row standing for the concept of boy . The first column is the pivot describing a concept with a unique ID. The subsequent columns show the words expressing the concept in respective languages (in the example table, English, Hindi and Marathi ). Af-ter the synsets are linked, cross linkages are set up manually from the words of a synset to the words of a linked synset of the pivot language. For exam-ple, for the Marathi word m lgA (mulgaa) ,  X  X  youth-ful male person X , the correct lexical substitute from the corresponding Hindi synset is lw X A (ladkaa) . The average number of such links per synset per lan-guage pair is approximately 3. However, since our work takes place in a semi-supervised setting, we do not assume the presence of these manual cross linkages between synset members. Instead, in the above example, we assume that all the words in the Hindi synset are equally probable translations of every word in the corresponding Marathi synset. Such cross-linkages between synset members facil-itate parameter projection as explained in the next section. Khapra et al. (2009) proposed that the various parameters essential for domain-specific Word Sense Disambiguation can be broadly classified into two categories: Wordnet-dependent parameters:  X  belongingness-to-dominant-concept  X  conceptual distance  X  semantic distance Corpus-dependent parameters:  X  sense distributions  X  corpus co-occurrence They proposed a scoring function (Equation (1)) which combines these parameters to identify the cor-rect sense of a word in a context: where,
J = Set of disambiguated words  X  i = BelongingnessT oDominantConcept ( S i ) V i = P ( S i | word ) W ij = CorpusCooccurrence ( S i , S j ) The first component  X  influence of the corpus specific sense of a word in a domain. The other component W the influence of interaction of the candidate sense with the senses of context words weighted by factors of co-occurrence, conceptual distance and semantic distance.

Wordnet-dependent parameters depend on the structure of the Wordnet whereas the Corpus-dependent parameters depend on various statistics learned from a sense marked corpora. Both the tasks of (a) constructing a Wordnet from scratch and (b) collecting sense marked corpora for multiple languages are tedious and expensive. Khapra et al. (2009) observed that by projecting relations from the Wordnet of a language and by projecting corpus statistics from the sense marked corpora of the language to those of the target language, the effort required in constructing semantic graphs for multiple Wordnets and collecting sense marked corpora for multiple languages can be avoided or reduced . At the heart of their work lies the MultiDict described in previous section which facilitates parameter projection in the following manner: 1. By linking with the synsets of a pivot resource rich language (Hindi, in our case), the cost of build-ing Wordnets of other languages is partly reduced (semantic relations are inherited). The Wordnet pa-rameters of Hindi Wordnet now become projectable to other languages. 2. For calculating corpus specific sense distribu-tions, P ( Sense S #( S i , W ) . By using cross linked words in the synsets, these counts become projectable to the tar-get language (Marathi, in our case) as they can be approximated by the counts of the cross linked Hindi words calculated from the Hindi sense marked cor-pus as follows: The rationale behind the above approximation is the observation that within a domain the counts of cross-linked words will remain the same across languages.
This parameter projection strategy as explained above lies at the heart of our work and allows us to perform bilingual bootstrapping by projecting the models learned from one language to another. We now come to the main contribution of our work, i.e. , bilingual bootstrapping. As shown in Algorithm 1, we start with a small amount of seed data ( LD and LD learn the parameters described in the previous sec-tion. We collectively refer to the parameters learned Algorithm 1 Bilingual Bootstrapping LD 1 := Seed Labeled Data from L 1 LD 2 := Seed Labeled Data from L 2 U D 1 := Unlabeled Data from L 1
U D 2 := Unlabeled Data from L 2 repeat until convergence from the seed data as models  X  respectively. The parameter projection strategy de-scribed in the previous section is then applied to  X  and  X  spectively. These projected models are then applied to the untagged data of L which get labeled with a high confidence are added to the labeled data of the respective languages. This process is repeated till we reach convergence, i.e. , till it is no longer possible to move any data from U D 1 (and U D 2 ) to LD 1 (and LD 2 respectively).
We compare our algorithm with monolingual bootstrapping where the self models  X  directly used to annotate the unlabeled instances in L models  X   X  Algorithm 2 Monolingual Bootstrapping LD 1 := Seed Labeled Data from L 1 LD 2 := Seed Labeled Data from L 2 U D 1 := Unlabeled Data from L 1
U D 2 := Unlabeled Data from L 2 repeat until convergence strapping is shown in Algorithm 2. in Khapra et al. (2010) for all our experiments. The data was collected from two domains, viz. , Tourism and Health. The data for Tourism domain was collected by manually translating English doc-uments downloaded from Indian Tourism websites into Hindi and Marathi. Similarly, English docu-ments for Health domain were obtained from two doctors and were manually translated into Hindi and Marathi. The entire data was then manually an-notated by three lexicographers adept in Hindi and Marathi. The various statistics pertaining to the total number of words, number of words per POS cate-gory and average degree of polysemy are described in Tables 2 to 5.

Although Tables 2 and 3 also report the num-ber of monosemous words, we would like to clearly state that we do not consider monosemous words while evaluating the performance of our algorithms (as monosemous words do not need any disambigua-tion).

We did a 4-fold cross validation of our algorithm using the above described corpora. Note that even though the corpora were parallel we did not use this property in any way in our experiments or algorithm. In fact, the documents in the two languages were randomly split into 4 folds without ensuring that the parallel documents remain in the same folds for the two languages. We experimented with different seed sizes varying from 0 to 5000 in steps of 250. The seed annotated data and untagged instances for boot-strapping are extracted from 3 folds of the data and the final evaluation is done on the held-out data in the 4th fold.

We ran both the bootstrapping algorithms ( i.e. , monolingual bootstrapping and bilingual boot-strapping ) for 10 iterations but, we observed that after 1-2 iterations the algorithms converge. In each iteration only those words for which P ( assigned sense | word ) &gt; 0 . 6 get moved to the labeled data. Ideally, this threshold (0.6) should have been selected using a development set. How-ever, since our work focuses on resource scarce lan-guages we did not want to incur the additional cost of using a development set. Hence, we used a fixed threshold of 0.6 so that in each iteration only those words get moved to the labeled data for which the assigned sense is clearly a majority sense ( P &gt; 0 . 6 The results of our experiments are summarized in Figures 1 to 4. The x -axis represents the amount of seed data used and the y -axis represents the F-scores obtained. The different curves in each graph are as follows: a. BiBoot : This curve represents the F-score ob-tained after 10 iterations by using bilingual boot-strapping with different amounts of seed data. b. MonoBoot : This curve represents the F-score ob-tained after 10 iterations by using monolingual bootstrapping with different amounts of seed data. c. OnlySeed : This curve represents the F-score ob-tained by training on the seed data alone without using any bootstrapping. d. WFS : This curve represents the F-score obtained by simply selecting the first sense from Wordnet, a typically reported baseline. In this section we discuss the important observations made from Figures 1 to 4. 8.1 Performance of Bilingual bootstrapping For small seed sizes, the F-score of bilingual boot-strapping is consistently better than the F-score ob-tained by training only on the seed data without us-ing any bootstrapping. This is true for both the lan-guages in both the domains. Further, bilingual boot-strapping also does better than monolingual boot-strapping for small seed sizes. As explained earlier, this better performance can be attributed to the fact that in monolingual bootstrapping the algorithm can tag only those instances with high confidence which it has already seen in the training data. Hence, in successive iterations, very little new information be-comes available to the algorithm. This is clearly evident from the fact that the curve of monolin-gual bootstrapping ( MonoBoot ) is always close to the curve of OnlySeed . 8.2 Effect of seed size The benefit of bilingual bootstrapping is clearly felt for small seed sizes. However, as the seed size in-creases the performance of the 3 algorithms, viz. , MonoBoot , BiBoot and OnlySeed is more or less the same. This is intuitive, because, as the seed size in-creases the algorithm is able to see more and more tagged instances in its self corpora and hence does not need any assistance from the other language. In other words, the annotated data in L add any new information to the training process of L 8.3 Bilingual bootstrapping reduces annotation The performance boost obtained at small seed sizes suggests that bilingual bootstrapping helps to reduce the overall annotation costs for both the languages. To further illustrate this, we take some sample points from the graph and compare the number of tagged words needed by BiBoot and OnlySeed to reach the same (or nearly the same) F-score. We present this comparison in Table 6. The rows for Hindi-Health and Marathi-Health in Table 6 show that when BiBoot is employed we need 1250 tagged words in Hindi and 1750 tagged words in Marathi to attain F-scores of 57.70% and 64.97% respectively. On the other hand, in the ab-sence of bilingual bootstrapping, ( i.e. , using Only-Seed ) we need 2250 tagged words each in Hindi and Marathi to achieve similar F-scores. BiBoot thus gives a reduction of 33.33% in the overall annota-tion cost ( { 1250 + 1750 } v/s { 2250 + 2250 } ) while achieving similar F-scores. Similarly, the results for Hindi-Tourism and Marathi-Tourism show that Bi-Boot gives a reduction of 43.75% in the overall an-notation cost while achieving similar F-scores. Fur-ther, since the results of MonoBoot are almost the same as OnlySeed , the above numbers indicate that BiBoot provides a reduction in cost when compared to MonoBoot also. 8.4 Contribution of monosemous words in the As mentioned earlier, monosemous words in the test set are not considered while evaluating the perfor-mance of our algorithm but, we add monosemous words to the seed data. However, we do not count monosemous words while calculating the seed size as there is no manual annotation cost associated with monosemous words (they can be tagged automati-cally by fetching their singleton sense id from the wordnet). We observed that the monosemous words of L vice versa. This is because for a given monose-mous word in L sponding cross-linked word in L tively) need not necessarily be monosemous. In such cases, the cross-linked polysemous word in L L tics of a monosemous word in L tively). This explains why BiBoot gives an F-score of 35-52% even at zero seed size even though the F-score of OnlySeed is only 2-5% (see Figures 1 to 4). We presented a bilingual bootstrapping algorithm for Word Sense Disambiguation which allows two resource deprived languages to mutually benefit from each other X  X  data via parameter projection. The algorithm consistently performs better than mono-lingual bootstrapping. It also performs better than using only monolingual seed data without using any bootstrapping. The benefit of bilingual bootstrap-ping is felt prominently when the seed size in the two languages is very small thus highlighting the useful-ness of this algorithm in highly resource constrained scenarios.
 We acknowledge the support of Microsoft Re-search India in the form of an International Travel Grant, which enabled one of the authors (Mitesh M. Khapra) to attend this conference.

