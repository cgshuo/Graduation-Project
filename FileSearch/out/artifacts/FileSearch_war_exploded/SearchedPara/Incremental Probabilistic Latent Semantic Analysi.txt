 With the fast development of web 2.0, user-centric publishing and knowledge management platforms, such as Wiki, Blogs, and Q &amp; A systems attract a large number of users. Given the availability of the huge amount of meaningful user generated content, incre-mental model based recommendation techniques can be employed to improve users X  experience using automatic recommendations. In this paper, we propose an incremental recommendation algorithm based on Probabilistic Latent Semantic Analysis (PLSA). The pro-posed algorithm can consider not only the users X  long-term and short-term interests, but also users X  negative and positive feedback. We compare the proposed method with several baseline methods using a real-world Question &amp; Answer website called Wenda. Ex-periments demonstrate both the e ff ectiveness and the e ffi the proposed methods.
 H.4 [ Information Systems Applications ]: Information Search and Retrieval-Information filtering Algorithms, Experimentation Incremental learning, PLSA, Recommendation System Social-network products are flourishing. Sites such as MySpace, Facebook, Orkut, and Yahoo! Answers attract millions of users a day. The rapid growth of the amount of users and items on social-network sites has made information finding increasingly challeng-ing. Content-based recommendation tries to solve the challenge by recommending items similar to those that a given user has liked in the past, whereas in Collaborative Filtering (CF) one identifies user whose tastes are similar to those of the given and recommended items they have liked.

For a typical recommender system, it is common that the old data (both users and items) keep changing, and the new data be-come available continually, such as articles in Google news [12]. In this case, we might retrain the model using both old and new data. However, it is infeasible in practice since batch training is computationally expensive. To speed up the performance, we need incremental Collaborative Filtering (ICF) [4] methods that can ef-ficiently handle new data arriving in a stream, instead of retraining the whole model from the scratches. The incremental ability of a recommendation algorithm can not only reduce its computational cost, but also makes it applicable to large-scale data sets.
In this work, we focus on an incremental learning recommenda-tion method using Probabilistic Latent Semantic Analysis (PLSA) for automatic question recommendation in a Question &amp; Answer (Q &amp; A) website. Probabilistic Latent Semantic Analysis (PLSA) is widely used in both content based recommendation [1] and col-laborative filtering [6]. It is based on the observation that user preference and item characteristics are often governed by a few latent semantics. To be more specific, PLSA introduces a latent variable, and decouples the probabilistic dependency between users and items into the dependency between users and latent semantics and the dependency between the latent semantics and items, both in a probabilistic way. Moreover, the probabilistic model could be learned using the Expectation Maximization (EM) algorithm [3], and the convergence is guaranteed [16].

Although PLSA has been successfully developed, there are two main shortcomings. First, the PLSA model is estimated only for those documents appearing in the training set. Each document is seen as a random mixture over latent topics. Latent Dirich-let Allocation (LDA) was proposed to deal with the weakness of PLSA, where LDA parameters were estimated by the approximate inference algorithms, such as variational EM and Gibbs Sampling. PLSA was shown to be a special variant of LDA with a uniform Dirichlet prior in a maximum a posteriori model [2]. Secondly, PLSA lacks the incremental ability, i.e. it cannot handle new data arriving in a stream. To handle streaming data, a naive approach is that we can re-train the model using both existing training data and new data. However, it is apparently not e ffi ciently since it is very computationally expensive. What is more, for some practical ap-plications, this is infeasible since the system needs real-time online update. Therefore, we need a fast incremental algorithm without compromising recommendation quality.

In this paper, we propose an incremental PLSA algorithm. The advantages of the proposed method can be summarized as: We study the proposed method using the data set from a real-world Question &amp; Answer website, compared with serval baseline meth-ods. Experiments demonstrate both the e ff ectiveness and e of the proposed methods.

The remainder of this paper is organized as follows: In Section 2 we describe Question &amp; Answer systems, and the problem of auto-matic question recommendation in Q &amp; A systems. In Section 3 we review basic ideas of PLSA, and describe how to recommend rele-vant questions using PLSA. In Section 4, we review previous work on incremental PLSA algorithms and point out the problems with these existing methods. In Section 5 we present the proposed in-cremental methods. In Section 6 we compare the proposed method against four baseline methods using a Q &amp; A data set. We then con-clude the paper and point out future research directions in Section 7.
Question &amp; Answer websites (referred to as Q &amp; A system af-terwards) are becoming popular in recent years, such as Yahoo! Answers 1 , Baidu Zhidao 2 etc. . In Q &amp; A systems, users post ques-tions to seek help from others. In the meanwhile, users also answer others X  questions. These sites are becoming huge knowledge bases in Internet, thus attract millions of users who either ask questions to seek help or reply questions to seek pleasure by helping others [19].

Wenda 3 is a Chinese Q &amp; A website launched by Google re-cently. Currently, Wenda has a hundred thousand users, and the number of users is still increasing. Given the huge number of users and questions, there is a challenge problem: it is hard for a user to precisely and quickly locate the questions and answers that might interest him [17]. To solve this problem, we implement automatic question recommend algorithms in Wenda, i.e. , when a user views a question, the system automatically displays related questions to the user based on the questions (answers) he posted and the question he is viewing. The recommendation mechanism is illustrated in Figure 1 (Left). There are two scenarios that incremental learning should be considered in Q &amp; A systems: (i) A new user registers in the system; and (ii) A new question (answer) is posted by existing users.

For a good recommendation system, we also need to consider two facts. First, users have both long-term and short-term interests. We can learn users X  long-term interests by accumulating users X  pref-erence for a long period. So users X  long-term interests are rela-tively stable. On the other hand, users X  short-term interests play a more important role on instant recommendation, although they are instantaneous and unstable. Our algorithm needs to capture both long-term and short-term interests of users. Secondly, users can give both positive and negative feedback to the recommended http://answers.yahoo.com http://zhidao.baidu.com http://wenda.tianya.cn items. If the user gives a high score on a given recommended item, we refer this as positive feedback , otherwise negative feedback . Our algorithm needs to learn both positive and negative feedback from users. The model updating flow is illustrated in Figure 1 (Right). We next introduce automatic question recommendation using Probabilistic Latent Semantic Analysis (PLSA).
In this section, we describe automatic question recommendation using Probabilistic Latent Semantic Analysis (PLSA). We first give a brief introduction to PLSA algorithm, and then describe how to apply it to automatic question recommendation.
For question recommendation tasks, it is reasonable to assume the following approximation: the word is independent of the user when a user wants to express some certain meaning (i.e. the la-tent semantics is known), so when the latent semantics under the questions and answers are found, we are able to make recommen-dation based on similarities on these latent semantics. Therefore, PLSA could be used to model the users X  profile (represented by the questions that the user asks or answers) and the questions as well through estimating the probabilities of the latent topics behind the words. Because the user X  X  profile is represented by all the questions that he / she asks or answers, we only need to consider how to model the question properly.

Suppose we have N questions denoted as Q and M words in the dictionary denoted as W . In addition, in order to capture the latent semantics, K latent topics are introduced notated by &lt; z Then we consider a user as a document that contains the words that he used in his questions or answers. A user X  X  interest is thus repre-sented by many dyadic pairs &lt; qustion i , word j &gt; where i and j are their index in the user set and word dictionary, respectively. Based on the independent assumption made above, we could rewrite the probability of co-occurrence &lt; q i , w j &gt; as follows:
Supposing a uniform distribution of P ( q i ) for all the questions, the learning task is boiled down to learning P ( z k | q i and to update them accordingly when the user X  X  profile changes. [1] provided a Expectation Maximization (EM) method for the PLSA model fitting.
The learning process is iterating the E-Step and M-Step alterna-tively until some convergence condition (such as Log likelihood) is satisfied. Typically, 20-50 iterations are needed before converging [1]. The problem is that, with this algorithm, whenever user X  X  pro-file changes, the whole model needs to be retrained from scratch. and feedback about our recommendations.
 This makes the update process could only be done o ffl ine. In the next section, we will see some existing work addressing this prob-lem.
To generate the recommended question list, we first learn P ( z | q ), the probability of the latent topic given a question, using all the questions that user has asked or answered. We then calculate P ( z | u ), the probability of the latent topic given a user, using the following Equation 5: or answered.

Based on P ( z | u ) and P ( z | q ), we can calculate two similarity mea-sures, namely question-question similarity and user-question simi-larity using the inner product as follows:
Given the similarity between user u i and question q j : S the similarity between other questions and the question that the user is viewing: S q c , q j , we could recommend the most related questions by simply sorting the scores computed as:
Note that the user-question and question-question similarities are computed online. Therefore, the recommendation list changes in-stantly whenever a user is viewing a di ff erent question or the user posts a new question or answer.

However, PLSA model retraining is a computational intensive task that can not be done in real time. We now proceed to explain how to retrain the model more quickly with the help of incremental learning.
Incremental ability is essential when the training examples in practical recommendation systems become available over time, usu-ally one at a time [4].

There are some existing work on incremental learning of PLSA. [1] provided a simple update scheme called Fold-In . The main idea However, P ( w | z ) can change significantly during EM iteration and a ff ect P ( z | q ) as well. Thus, the result of Fold-In might be biased.
Tzu-Chuan Chou et al [5] proposed Incremental PLSA ( IPLSA ), a complete Bayesian solution aiming to address the problem of on-line event detection. For the automatic question recommendation task, when a new question is posted, both P ( z | q ) and P ( w | z ) are updated as follows: 1. Fold in new questions: 2. Fold in new words: 3. Update PLSA parameters, all P ( w | z ) are normalized using
For the time complexity, the algorithm needs O ( n iter  X  ( n ( n questions added, where n nq is the number of new questions, and n oq is the number of old questions, and n nw is the number of new words and n ow is the number of old words, and K is the number of latent topics, and n iter is the number of iterations. Note that the computational complexity is the same as that of the batched PLSA algorithm, although less EM iterations are needed.
Chien and Wu proposed another PLSA incremental learning al-gorithm named MAP-PLSA [10]. Di ff erent from the traditional PLSA learning formula derived using Maximum Likelihood (ML) assumption, MAP-PLSA updates PLSA parameters using the Max-imum A Posterior (MAP) as follows:  X  where
The advantage of MAP-PLSA is its update e ffi ciency. The time complexity is O ( n iter  X  n nq  X k nq k X  K ), where k nq k is the average number of words of new questions. But the results can also be biased, especially for P ( w | z ) according to Equation (14). Besides the above work, [12], [9], and [7] modified the original PLSA model and provided some experimental results on how to achieve the balance between e ffi ciency and accuracy. Banerjee and Basu proposed online variants of other probabilistic model such as LDA [15] for news clustering. [8] proposed a novel incremental algorithm based on non-parametrical Dirichlet Process for the new topic detection problem.

Table 1 summarizes detailed qualitative comparisons among these algorithms and our proposed incremental PLSA algorithm. The  X  X ccuracy X  measure is the degree of approximation to the batched PLSA; this measure a ff ects recommendation precision in our ex-periments.  X  X ncremental Complexity X  is the measure of e ffi of the update algorithm;  X  X lexibility X  is the measure of whether the model can reflect the user X  X  latest interest while still reflecting user X  X  long-term interest.  X  X daptable to User X  X  Feedback X  indicates whether the model can update according to the user X  X  feedback.
We next describe our proposed incremental PLSA methods.
There are three issues we need to consider for the incremental task in Q &amp; A systems:
We next propose a novel incremental PLSA learning algorithm that address the above three problems.

When a user u posts a new question or answers an existing ques-dated accordingly, and so does the probability of words given a topic, P ( w | z ). We propose a modified EM scheme based on the Generalized Expectation Maximization (GEM) [14]. The formulae for incremental update are as follows: where the superscript ( n  X  1) denotes the old model parameters and ( n ) for the new ones, w 0  X  q w and  X  w  X  W are words in this question and all other words in the dictionary, respectively.
 After several EM iterations, we can get a stable value of P ( z | q ). After that, P ( z | u ) could be calculated as: and words. The values of  X  and  X  are hyper-parameters that man-ually selected based on empirical results (see Section ?? ). The de-tailed algorithm description are shown in Algorithm 1.

The time complexity of Algorithm 1 is O ( n iter  X  n nq  X k n K ), where n iter is the number of iterations, n nq is the number of new questions, k n nq k is the average number of words in these questions and k u q k is how many users are involved in the discussion of this question plus the number of users who provide feedback about this question.

The major advantage of the proposed algorithm is that we can take into account two di ff erent scenarios by adjusting the value of weight  X  .

In the first scenario, we want to consider both users X  long-term and short-term Interests. Suppose user u has posted N u questions (answers) before, and q is a new question posted by the user. In-tuitively, we can set the weight on question q as 1 N Algorithm 1 : Our Incremental PLSA learning algorithm.

Input : New question q , P ( z | u ) of the author u for all the latent
Output : For all the topics, output updated P ( z | u ) for the if user u is new then end else end for All the words w appear in the new question do end while not convergent do end for all the authors u in the question q do end achieve the balance between existing and new questions. However, to better reflect users X  X  short-term interests, we might increase the weight  X  on question q . Therefore,  X  needs to be larger than Therefore, we can set a higher  X  value for new questions to better reflect users X  short-term interests.

In the second scenario, in Q &amp; A systems, the user can give posi-tive or negative rating to a recommended question, which indicates whether he is interested in the given question or not. Users X  feed-back is important and we need consider this information in our in-cremental algorithm. For the positive feedback, we set the weight  X  a positive value. Otherwise, we set the weight  X  a negative value. Note that the probability value might be negative if we set  X  nega-tive. We need a shift operation to make the value of all probabilities larger than zero, and then a normalization operation to ensure the sum of all probabilities equals to one. Therefore, we can take both users X  positive and negative feedback into considerations.
We next apply the proposed incremental algorithm to a real-world data set from the Wenda website.
We implemented our proposed method together with other incre-mental PLSA implementations for the question recommendation task in the Wenda system. In this section, we give the performance details of these algorithms.
Our data set contains the questions and corresponding answers of users who registered in the Wenda website from October 2007 to April 2008. The details of the data set are shown in Table 2. Table 2: The Statistical Information of the Evaluation Data Set.
We apply two preprocessing steps on all the questions and an-swers: Chinese word segmentation and stop-word filtering. Finally, we get 62187 words and the average question length is 189 words. There are 7122 feedback provided by Wenda users about the rec-ommended questions. The average number of answers per question is around 3.62. Figure 2 shows the total number of questions and answers in the Wenda website since its launch.
 Figure 2: The increase of the number of questions and an-swers in Wenda. The x-coordinate is the number of days before 2008.4.30 and the y-coordinate is the number of questions and answers.
We use three measures to evaluate both the e ff ectiveness and ef-ficiency of the proposed method in comparison with four baseline methods, namely batched PLSA , Fold-In , IPLSA , and MAP-PLSA .
The first measure is the update time , which indicates how fast the algorithm to update existing model parameters when new data arrives. The measure of update time measures the e ffi ciency of the algorithm. To measure the e ff ectiveness of di ff erent algorithms, we propose to use two measures: perplexity [1] and precision [10].
The perplexity , widely used in language modeling, is to measure the generalization ability of the model, defined as: q . P ( w j | q i ) is calculated as follows: A lower perplexity score indicates better generalization ability.
Besides the perplexity, the users X  judgement of recommenda-tion results is important and essentially the ultimate goal of a rec-ommendation system. The better the recommendation results, the more the users will click on the recommended items. However, it is a subjective task to evaluate users X  judgement since it is hard or even impossible to get a well-defined ground-truth. We thus asked 10 volunteers to do manual ratings on di ff erent recommendation al-gorithms. That is, each user is asked to give two rates (relevant vs. non-relevant) independently to each of the 20 recommended ques-tions produced by di ff erent algorithms. Finally, the precision of the recommendation algorithm is calculated as:
There are some hyper-parameters in our algorithm. In our exper-iments, we set the number of latent topics 64, and the default  X  is 0 . 5. For the question or answer that the user posts, the  X  value in Equation 23 is 0 . 25. While for the user X  X  positive and negative feed-back, the  X  values are 0 . 5 and  X  0 . 5, respectively. We next present our experiment results. We first show the learned latent topics using the PLSA model. Figure 3 lists six topics from 64 latent topics. Each topic is rep-resented by its top 20 most probable words, i.e. , the words are or-dered according to P ( w | z ). We can see that the six latent topics are roughly mapping into six topics, namely Emotion, Health, Soft-ware, Travel, Family , and Work .

Table 3, 4, and Table 5 summarize the comparison results be-tween our algorithm and the four baseline methods in terms of up-date time , perplexity , and precision respectively.

Table 3 shows the total time spent to incremental update using 500 questions. We can see that batched PLSA is the slowest while Fold-In is the fastest method. This coincides well with our theoret-ical analysis of time complexity shown in the last column in Table 3. We can also see that it costs 0 . 54 second to process one ques-tion on average using our method. This indicates our incremental algorithm is applicable to real-time online systems.

Table 4 shows the perplexity comparison between our algorithm and four baseline methods. The smaller the value of perplexity, the better the performance. We can see that our method achieve the best perplexity results among all the methods. This indicates that our method enjoy a better generalization ability.

Table 5 summarizes the precision of the di ff erent algorithms. We
Figure 3: Top words in 6 topics (Ordered by probability). can see that our method outperforms the batched PLSA, and other incremental methods. The reason is that our method takes into ac-count uses X  short-term interests (setting a bigger weight  X  ) while batched PLSA somehow mixed both users X  long-term and short-term interests.

Figure 4 shows the comparison of recommendation results of four incremental algorithms with respect to di ff erent number of up-dates. We can see that the precision of our method improves with the the increase of update numbers, while this trend is not consis-tent for other methods.

Figure 5 and 6 show the recommendation precision after users giving positive and negative feedback about a recommendation re-spectively. We can see that the precision can change with the ad-justment of the weight  X  value. In specific, for positive feedback, we set  X  positive values for better performances, while for negative feedback, we set  X  negative values to achieve a higher precision. Note that the performance is linearly improved with respect to the value of  X  . Usually, the value of  X  is around 0 . 5, we achieved the best precision.

We illustrate the process of positive and negative feedback with an example shown in Figure 7. In the figure, the system first auto-matically recommends a list of questions to the user. The questions are roughly about two topics: language study related questions, and finance related questions. Note that the rankings of language and finance related questions are mixed. The user first gives a positive feedback about Question 1 on language. The system updates the recommendation list instantly, and provides an updated list (Figure 7 (ii)). In this list, language related questions are all ranked higher than those of finance related questions. After that, the user gives a negative feedback about a finance related question. Accordingly, our system updates the recommendation list a second time. We can see that all the recommended questions are related to language, and all finance related questions disappear from the recommendations (Figure 7 (iii)).
In this paper we presented an incremental automatic question recommendation algorithm based on probabilistic latent semantic analysis. The incremental algorithm can update existing model Figure 4: Comparison of recommendation precision of di ff ent incremental PLSA algorithms during 10 updates (20 itera-tions for each update). Figure 5: The recommendation precision for di ff erent  X  values after user giving a positive feedback about a recommendation. parameters when new data arrives without re-training the whole model from the scratches. Our method can also consider not only users X  short-term and long-term interests, but also users X  positive and negative feedback. Experiments on a real-world Q &amp; A data set demonstrated both the e ffi ciency and e ff ectiveness of the proposed algorithm.

We have two future work items. First, the proposed incremental algorithm is general as it can be not only applied to other recom-mendation tasks, but also extendable to other probabilistic latent topic models, such as Latent Dirichlet Allocation (LDA). In future, we plan to extend our work to both new models, such as LDA, and new recommendation applications. Second, it is crucial to evalu-ate performance of incremental algorithms. We think users X  click information is a good indicator of whether he likes (or dislikes) the recommended items. We will use this information for a better evaluation of di ff erent recommendation algorithms. Figure 6: The recommendation precision for di ff erent  X  values after user giving a negative feedback about a recommendation. We would like to thank Sha Huang for preparing the data and Xiance Si for generating some figures. [1] Thomas Hofmann. Unsupervised Learning by Probabilistic [2] M. Girolami and A. Kaban. On an Equivalence Between [3] Dempster A. P., Laird N. M., and Rubin D. B.. Maximum [4] Christophe G. Carrier. A Note on the Utility of Incremental [5] T. C. Chou and M.C Chen. Using Incremental PLSA for [6] T. Hofmann. Latent Semantic Models for Collaborative [7] L. Zhang and C. Li, etc. . An E ffi cient Solution to Factor [8] J. Zhang, Z. Ghahramani, and Y. Yang. A Probabilistic [9] Arun C. Surendran and Suvrit Sra. Incremental Aspect [10] J. T. Chien and M. S. Wu. Adaptive Bayesian Latent [11] B. Marlin. Collaborative Filtering: A Machine Learning  X   X  Figure 7: The recommendation list changes after the user giv-ing feedback about the recommended questions. [12] Das A., Datar M., Garg A. and Rajaram S.. Google News [13] D. M. Blei, A. Ng, and M. I. Jordan. Latent Dirichlet [14] R. M. Neal and G. E. Hinton. A View of the EM Algorithm [15] Arindam Banerjee and Sugato Basu. Topic Models over Text [16] Asela Gunawardana, William Byrne. Convergence Theorems [17] Y. B. Cao, H. Z. Duan, C. Y. Lin, Y. Yu, and H. W. Hon. [18] Lada A. Adamic, J. Zhang, and etc. . Knowledge Sharing and [19] Z. Gy  X  o ngyi, G. Koutrika, etc. . Questioning Yahoo! Answers.
