 1. Introduction
Several user-centred studies of electronic information resources have adopted variants of the think-aloud technique  X  where participants have been asked to verbalise their thoughts, interface actions and sometimes their feelings when using one or more resources to help them complete an information task or tasks. Some of these studies were conducted with the aim of identifying usability issues associated with systems used (e.g. Blandford, Stelmaszewska, &amp; Bryan-Kinns, 2001; Van den Haak, de Jong, &amp; Schellens, 2004 ). Other think-aloud studies have had the aim of identifying and understanding users X  information behaviour or specific aspects of it. However, Nielsen, Clemmensen, and Yssing (2002) highlight that most papers that present think-aloud studies  X  X  X o not discuss in detail what they did, nor reflect on the technique  X  (p. 102). This view is shared by Hoppmann (2009) , who argues that researchers should pay  X  X  X ore attention to detail  X  (p. 211) when describing the design, method and analysis of qualitative think-aloud studies of electronic information environments. This not only sug-gests the need for thorough discussion of the methodology employed in think-aloud studies of information behaviour, but also the need for reflection on methodological decisions made in order to assist researchers in planning and conducting these types of studies in the future.
 In this paper, we discuss and reflect on the methodology employed in a study of 22 practicing lawyers working in the
London office of a multinational law firm, who were asked to think-aloud whilst using one or more electronic information resources to  X  X ind information currently or recently needed for [their] work X . We begin by reviewing existing think-aloud studies of electronic information resources with an aim of identifying and understanding information behaviour. This is followed by a discussion and reflection on our methodology, which is framed around Blandford et al. X  X  (2008)  X  X RET A  X 
Rapporter X  ( X  X eady to report X ) framework  X  a framework that can be used to plan, conduct and describe user-centred studies of electronic information resource use from an information work perspective. The aim of this article is therefore twofold; to discuss the methodology employed in our study of lawyers in detail and to reflect on the methodological decisions made. 2. Existing think-aloud studies of information behaviour
There are many existing think-aloud studies of electronic information behaviour, conducted in different ways to address different research purposes. Some of these studies aimed to describe or model users X  broad information behaviour (e.g. Jones, 2006; Yang, 1997 ). Others sought to investigate particular aspects of information-seeking and use, such as electronic infor-mation resource users X  search behaviour ( Jenkins, Corritore, &amp; Widenbeck, 2003; Hirsh, 1999; Nahl &amp; Tenopir, 1996 ), their  X  X eeping X  and  X  X e-finding X  behaviour ( Bruce, Jones, &amp; Dumais, 2004 ) or their relevance selection behaviour ( Hirsh, 1999 ).
Some of these studies also sought to examine information behaviour from different perspectives; such a cognitive and affec-tive perspective ( Nahl &amp; Tenopir, 1996 ) or a mental models perspective ( Makri et al., 2007 ). Other information behaviour-focused think-aloud studies sought to examine the impact of particular study-related factors such as an evolving search task iour. There have also been think-aloud studies involving electronic information resource use with a purpose of investigating aspects of the think-aloud procedure itself. These studies (e.g. Branch, 2000; Branch, 2001 ) have typically resulted in the identification of information behaviour as a by-product.

Indeed, Branch X  X  (2000) study of adolescents using an electronic encyclopaedia, which compared think-alouds and think-afters, has been described as  X  X xceptional X  ( Nielsen et al., 2002 , p. 104) due to the high level of detail in which she describes the data collection and analysis process. For example, regarding data collection, Branch discusses the number of participants recruited (3 boys and 2 girls) and their demographics and background (they were aged 12 X 15, from academic families with computers and electronic encyclopaedias at home). Branch also describes the location and room setup (a lecture room at the
University of Alberta equipped with a laptop, tape recorder and two chairs in front of the computer), along with the session length (around 45 min) and privacy and confidentiality issues, such as providing the participants with the opportunity to withdraw from the study at any time. Branch also provides details of the think-aloud and think-after procedure employed  X  such as providing participants with the opportunity to ask questions before the study and to practice thinking aloud and using the system. Details are also provided of the search tasks the adolescents were asked to perform (e.g.  X  X escribe the male cardinal bird X  and  X  X ind in what year Queen Elizabeth II was born X ). Branch also discusses the nature and amount of researcher intervention (the researcher did not intervene unless the participant asked her a question).

Regarding data analysis, Branch describes how she coded the think-aloud data; she explains that the codes emerged by her reading the think-aloud transcripts as the data collection progressed and after it was complete, clustering major ideas, unique concepts and leftover categories. She then  X  X ut and paste X  parts of the transcripts and grouped them by code. In order to determine the amount of data generated by the think-aloud and think-afters, she also counted the number of words ver-balised by participants related to each search task.

Some other think-aloud studies of users X  interactive information behaviour also discuss their methodologies in reasonable detail. For example, Hirsh (1999) asked 10 elementary school children to think aloud whilst using their choice of an online catalogue, an electronic encyclopaedia, an electronic magazine index, the Yahooligans search engine and a selection of other
Internet resources to find information related to an on-going class assignment on sports figures. The purpose of this study was to explore the search strategies they employed and the relevance criteria they adopted. The children were asked to think aloud whilst collecting information for their project. During the think-aloud, they were asked open-ended questions to probe how they were making their relevance decisions. Some of the questions included  X  X hat are you doing now? X ,  X  X ow what are you thinking? X , and  X  X hy did you try that title? X  The researcher did not provide any assistance to participants during the task and shadowed them if they decided to browse the bookshelves for paper-based information. The researcher also took notes on the children X  X  non-verbal behaviour to supplement the audio transcripts.

Manglano et al. (1998) also provide some useful detail on the methodology employed in their study of medical students and professionals X  search behaviour. The medics were asked to think aloud whilst using one of two different interfaces of the medical digital library Medline to help them undertake a self-chosen research task. The aim of the study was to investigate the effect of interface design on the participants X  search behaviour. The authors provided the medics with information about the study and confidentiality issues and asked them pre-search questions on their status, training level, experience with computers and electronic databases, search purpose and expectations about Medline X  X  content. Participants were then asked to describe their information need and, whilst thinking aloud, describe their interface actions and what they thought Med-line was doing. This was with the aim of identifying misconceptions in the medics X  mental models. The session, which was not time-restricted, was concluded with post-search questions on their understanding of aspects of the interface, their sat-isfaction with the interaction and any search difficulties they encountered. The authors X  initial coding scheme was theory-driven  X  based on Fidel X  X   X  X earch moves X  ( Fidel, 1985 ) and Bates X   X  X earch tactics X  ( Bates, 1979 ). However, some codes were also data-driven. The codes and their descriptions were iteratively refined to ensure they accurately described the data.
Whilst these studies can be regarded as rare examples of detailed reporting, they only demonstrate a limited amount of reflection on the methodological decisions made when planning and conducting the study. This is also the case with the other studies cited in this section and highlights the need for researchers to include more reflection in published methodologies of information behaviour-related think-aloud studies and the need for more work with the primary aim of reflecting on methodological decisions made. This was the main motivation for writing this paper. 3. The PRET A Rapporter Framework
The PRET A Rapporter framework (PRETAR) ( Blandford et al., 2008 ) can be used to both discuss and reflect on a broad range of methodological decisions made when planning and conducting user-centred studies of interactive systems. Whilst
PRETAR is not tailored to an information behaviour context (it is intended to be used to plan and describe user-centred stud-ies in general), the authors illustrate through the discussion of several case studies that the framework can be used to de-scribe studies of electronic information resources and, more specifically, studies of information behaviour. When describing or reflecting on a user-centred study, the framework involves discussing: 1. The purpose of the study  X  the goals the study sought to address or questions the study sought to answer. 2. The resources available for conducting the study and the constraints which the study had to work within. 3. The ethical issues raised by the study. 4. The techniques adopted for collecting data. 5. The analysis of the data. 6. How the study was or will be reported .

We now discuss and reflect on these considerations in relation to our think-aloud study of practicing lawyers X  information behaviour. We cover data collection and analysis decisions in more detail than the other PRETAR stages as the issues raised provide the most opportunity for reflection. We also, at times, make reference to excerpts from the lawyers X  think-aloud transcripts (where  X  X  X  denotes a lawyer working in the Dispute Resolution department and  X  X  X  a lawyer working in the
Tax department). 4. Discussion and Reflection on our Think-Aloud Study 4.1. Purpose of the study
The purpose of our study was to gain a detailed understanding of the interactive information behaviour displayed by practicing lawyers when using electronic information resources as part of their everyday work. Our motivation was user-centred; we believed that in order to ensure that electronic information resources truly support their users, it would be nec-essary to gain a detailed understanding of their interactive behaviour when using these resources to satisfy real information needs. As we sought to gain as realistic an insight of their behaviour as possible, we decided to set the relatively broad infor-mation task of  X  X inding information you currently need or recently needed for your work. X  As explained by Blandford et al. (2001) , who had a similar motivation but sought to identify usability issues related to digital libraries rather than informa-tion behaviour, setting a broad information task that allows participants to conduct their everyday work avoids the need for
Although the broad information task set was highly-related to our study X  X  purpose and resulted in the display of a wide range of information behaviours, the fact that the task demanded that the lawyers  X  find information X  served to constrain the behaviours displayed somewhat. Whilst the task did not directly imply active information-seeking (as opposed to more pas-sive forms of information encountering such as receiving e-mail alerts), this was implicit in the wording of the question. Sim-ilarly, whilst this task was not intended to exclude information use behaviour, it primarily encouraged the display of information-seeking behaviour, without much demonstration of how the information found was used as part of their work.
We attempted to re-address the balance during data collection by asking wrap-up questions aimed at probing the bound-aries of the identified information behaviours and identifying behaviours that were not currently supported by existing elec-tronic legal information resources. We discuss the wrap-up questions further in Section 4.2.2 .

Whilst we considered alternative task wordings such as  X  X how me how you came across information you have used for your work X  and  X  X ind and/or make use of information you currently need or have recently needed for your work, X  we decided these wordings also had their own inherent problems; we felt the former was too vague and the latter too specific (in the sense that it implied the need for the lawyers to think of a task with a clear feed-in from information-seeking to information use). Therefore both were likely to cause confusion about what the task actually demanded. This was one of several meth-odological decisions made that involved trading off several potential approaches and making a final judgement based on which approach would, in our opinion, minimise the opportunity for data bias whilst maximising the opportunity for the collection of rich data that would give rise to the identification of a wide range of information behaviours. 4.2. Study resources and constraints 4.2.1. Participant recruitment process
We recruited an evolving theoretical sample of 22 practicing lawyers, where the sample size was only finalised during the course of the study. The main consideration for finalising the sample size was that it should be large enough to enable us to gain both a broad and detailed understanding of the lawyers X  information behaviour. As the firm was large, we were fortu-nate that we would be unlikely to run out of potential participants. However, it was necessary to demonstrate sensitivity to the time pressures faced by practicing lawyers  X  observations often needed to be rescheduled, sometimes on more than one occasion and often at short notice. By being understanding and flexible when arranging observations, we were able to ensure a high level of participation which, in turn, provided us with confidence in the generalisability of our findings. Whilst prac-ticing lawyers are likely to be particularly time-constrained, similar flexibility is likely to be necessary when observing other groups of busy professionals.

The lawyers that agreed to take part in our study were recruited from the mainly contentious  X  X ispute Resolution X  depart-ment (where they worked on cases with multiple parties and a dispute to litigate or resolve) and the mainly non-contentious
Tax department (where they worked on cases involving one or more corporations but no  X  X ispute X  as such) of the London office of a multinational law firm. We decided to recruit from these two departments as we were advised by a contact in the firm that although both departments made regular use of electronic information resources, their information needs (and therefore their electronic information resource usage and resulting information behaviours) were likely to be very dif-ferent. We found that although differences in information needs certainly existed (for example the Dispute Resolution lawyers were heavily reliant on a broad range of legal cases and legislation and the Tax lawyers more reliant on specialist tax-related legislation and articles), there was much overlap in the information behaviours displayed. We do not, however, regard the recruitment across department as an unnecessary complication to our methodology. Instead, we regard it as a useful indicator (but not firm evidence) that information behaviour might be similar across contentious and non-contentious departments. Hence our recruitment across departments provided us with added confidence in the generalisability of the information behaviours identified across all departments in the London office.

Our sample included both Trainees and Associates where they deemed that electronic information resource use (and the use of digital law libraries) was  X  X t least sometimes an important part X  of their work. No Partners were recruited as time pres-sures made it difficult for them to commit to taking part (and after some e-mail exchanges with Partners, it became clear that
Partners often delegate their information work to Associates or Trainees). We recruited at all levels of the company hierarchy below the level of Partner as we wanted to observe as broad a range of information behaviours as possible. As with our deci-sion to recruit across departments, the decision to recruit across the company hierarchy did not result in considerably dif-ferent information behaviour or a noticeable increase in  X  X nformation expertise X  from Trainee to Associate level. However, once again, we do not regret the decision to sample across the hierarchy as it provided us with extra confidence in the gen-eralisability of our findings.

Personal contact with a senior Partner in the firm was invaluable for enabling us to deal with the bureaucratic aspects of setting up the study, such as establishing a non-disclosure agreement and procedures for contacting participants and feeding back our findings to the firm. A list of Trainees and Associates in each department was provided by the firm and a designated contact was appointed to pre-authorise contact with individual participants, in order to avoid us contacting participants who had particularly high workloads. A personalised e-mail explaining the purpose of the study, the information task that would be undertaken and the duration of the study (no longer than an hour) was sent to each pre-authorised participant. The e-mail also informed participants that findings from the study would be used to inform the design of electronic legal information resources and would be shared with the firm itself. Several lawyers commented that they were happy to take part in a study that (a) only involved them doing research they were going to do anyway and (b) would hopefully lead to the design or improvement of the electronic information resources they regularly made use of (and often found difficult to use). Contacts within the firm proved to be particularly useful in encouraging participation; some lawyers suggested colleagues that might be interested in participating. In addition, once participation in the Tax department, which was smaller than the Dispute Res-olution department seemed to  X  X ry up, X  an Associate offered to forward our e-mail to her Trainees, who made time to par-ticipate as the Associate had suggested in her e-mail that the study was worthwhile. 4.2.2. Setting and equipment
Tax lawyers performed the broad information task at their desks, using their own computers, whilst Dispute Resolution lawyers used a computer in an office set up within their department. Whilst this decision was made to minimise disruption (as Dispute Resolution lawyers often shared their offices), this also prevented access to their personal bookmarks. Whilst this might have had a minor effect on the information behaviours displayed, we decided that minimising disruption was more important that providing access to an own computer for all lawyers  X  particularly since all computers had access to the same set of digital libraries and other electronic information resources. We believe this was a good decision as few of the Tax law-yers used personal bookmarks, even though they had access to them. All information resources could be accessed in the nor-mal way, with the exception of one digital law library  X  LexisNexis Butterworths. This was because on many of the Tax lawyers X  own computers, the digital library was set to remember their username and password. This setting-related differ-ence served to highlight difficulties in accessing electronic information resources (which we found to be an important infor-mation behaviour for all of the lawyers). However, in order to avoid this particular access issue preventing Dispute
Resolution lawyers from using LexisNexis Butterworths to undertake their chosen information task, those who encountered password difficulties were offered assistance to log in.

As we wanted to observe as broad and realistic a range of information behaviour as possible, we did not constrain the study by focusing on particular aspects of lawyers X  information behaviour or by specifying the use of particular electronic information resources. Although the firm subscribed to a wide range of electronic information resources, the information behaviour displayed by the lawyers was constrained by the functionality offered by the resources used. We tried to mitigate this issue by asking wrap-up questions after the think-aloud task that probed the nature and boundaries of the identified behaviours and sought to identify behaviours not currently supported by existing electronic information resources, for example  X  X hat would you do now that you have printed all the cases you thought would be useful? X  and  X  X ou mentioned you would read through the Act and make notes. How exactly would you do that? X  Asking wrap-up questions, plus the fact that the study allowed a broad range of information tasks to be undertaken and a wide range of electronic information re-sources and resource functionality to be used, allowed us to remain confident that we had identified a broad range of infor-mation behaviours. However, it also suggested that in order to identify a wider range of behaviours, it might be useful in future to conduct a complementary study such as a Contextual Inquiry (see Beyer &amp; Holtzblatt, 1998 ) designed to gain a more comprehensive understanding of lawyers X  informal and paper-based information behaviour. So why did we decide only to focus on lawyers X  electronic information behaviour in the first place? This was mainly for practical reasons; not only did we believe that practicing lawyers would have been unlikely to have had sufficient free time to take part in an in-depth observation, but we were also aware that the law firm had a strongly ingrained cultural practice of protecting client con-fidentiality. Therefore we believed that, even with a non-disclosure agreement in place, it would have been difficult to ob-tain agreement for extended observations. We also decided only to focus on electronic information behaviour as we believed that short, focused observations of lawyers attempting to satisfy one particular information need (rather than several dif-ferent needs, as would be necessary during a longer observation) would minimise the number of observations required in order to meet our aim of collecting a broad, rich set of behavioural data. Whilst we cannot reliably test this hypothesis, the breadth and depth of our findings suggested that we had made a good choice despite the complex trade-offs we were forced to make.

As we did not want to install any of our own software on the firm X  X  network, we decided only to audio (rather than both audio and screen-capture) the lawyers thinking aloud whilst performing their task. In order that we could accurately recall the lawyers X  interface actions when reviewing their think-aloud transcripts, we made time-stamped notes during the study  X  writing down actions such as  X  X licks browser back button X  and  X  X dits search terms to read  X  X orporation tax dividends. X  Most of the time, the audio and notes were sufficient for understanding their behaviour. When this was not the case, we found it useful to mirror users X  interactions ourselves on the information resource they used, whilst listening to the recorded think-aloud session and referring to the relevant notes. 4.3. Ethical issues
Blandford et al. (2008) highlight that it is good practice to consider issues surrounding keeping participant data as anonymous as possible and respecting participants X  confidentiality and privacy. They also highlight that it is good prac-tice to inform participants of the purpose of the study and what will be done with the data. On our informed consent form, we explained the purpose of the study and that it would be audio-recorded. We also explained that the study had gained ethical approval from our university ethical committee. We highlighted that the transcriptions resulting from their think-aloud session would be anonymised from the outset. When asked what this entailed, we explained to the lawyers that this involved the censoring of details that could be used to directly identify individuals (particularly names of staff or clients) or the firm (such as precise place names and the name of the firm X  X  in-house knowledge-management database). Whilst complete anonymisation is unlikely to be possible in studies such as this, where it is necessary to elicit detailed information surrounding the context of an information task, we believe that identifying a particular individual from the transcripts would require considerable effort. We also believe that adopting this procedure was preferable to the alternative of dissuading the lawyers from discussing specific details about their information task and excluding ac-cess to particular electronic information resources that might reveal the firm X  X  identity. We also highlighted on our in-formed consent form that the lawyers would be free to review or edit the transcript arising from their study, or request to withdraw at any time (whereby their audio and transcript would be deleted) and that our findings might be used in academic and non-academic publications and presentations. None of the lawyers asked to review their transcript or withdraw.

As maintaining the confidence of the firm (as well and their privacy and confidentiality) was an important concern, we asked the firm to designate a named individual to review all work arising from the study, including this paper. We also high-lighted on our informed consent form that data arising from the study would be shared with the firm itself and that the tran-scripts would be stored in accordance with the UK Data Protection Act 1998 which, in practice, involved safeguarding the data (by storing personal data -i.e. the lawyers X  names) separately from their transcripts and deleting this personal infor-mation when no longer needed. Whilst the Data Protection Act only covers personal information (and therefore not the anon-ymised transcripts themselves), we also decided to store hardcopies of the anonymised transcripts in a locked cabinet and softcopies on a password-protected computer, as this was in keeping with the spirit of the Act.

Blandford et al. (2008) also highlight that  X  X  X hile immediate respect of individuals is reasonably obvious, less obvious is the need to continue to respect participants X  privacy in future presentations of the work and to show similar respect to groups and organisations X  (p. 11). We found that our strict ethical procedures helped us to respect the long-term privacy of the firm and individual participants. We also found that sharing these procedures with the firm and obtaining their agree-ment to them before data collection began helped us to maintain the firm X  X  confidence. 4.4. Data collection technique 4.4.1. Why ask participants to think-aloud?
As highlighted by Jakob Nielsen in his guide to usability testing,  X  X  X he strength of the thinking aloud method is to show what the users are doing and why they are doing it while they are doing it in order to avoid later rationalizations X  ( Nielsen, 1993, p. 196 ). We decided on the need to elicit verbal data as we believed that this would provide us with as rich and accu-rate as possible an insight into the lawyers X  interactive information behaviour (i.e. what they were doing when using elec-tronic information resources to complete their task and why they were doing it). We believe that employing the think-aloud technique was highly useful for gaining an understanding of lawyers X  interactive information behaviour. 4.4.2. Think-aloud or think-after?
We also considered carefully whether to screen-record the lawyers undertaking their chosen task and ask them to explain their behaviour after completing the task (either as an alternative or supplement to asking them to think aloud during the task). Branch X  X  (2000) study comparing think-alouds and think-afters, discussed in section 2 , concluded that whilst think-alouds can provide rich data, some participants may find it difficult to think aloud during tasks that require cognitive processing (such as complex information tasks) and whilst think-afters may be useful in those situations, they  X  X  X ay be influ-enced by forgetting and fabrication  X  (p. 389). Another trade-off is highlighted by Bowers and Snyder (1990) , who found that participants who were asked to think aloud concurrently when using an interactive system tended to read what was on the screen and describe the procedures they were following (i.e. describe what they were doing) and those who were asked to think aloud retrospectively when using the same system tended to make more reflective statements about why they acted the way they did.

Aware that both options were likely to be highly suitable for addressing the purpose of our study and that there were competing benefits and drawbacks associated with each, we decided to ask our lawyers to think aloud during the task mostly based on practical reasons. In particular, Ericsson and Simon (1993) highlight that eliciting retrospective accounts can be time-consuming. As our study had to be restricted to around an hour (as we did not think lawyers would be able to commit for longer), we did not think this would be enough time to conduct and re-play a think-aloud session (espe-cially a session that was long enough to allow the lawyers to attempt their chosen information task in some detail and hopefully result in the demonstration of rich behaviour). Instead, we decided to take the advice of Branch (2000) , who suggests combining research methods to  X  X  X ather the most complete data  X  (p. 389). As part of the wrap-up questions asked at the end of the session (which probed the nature and boundaries of the information behaviours identified), we also asked questions that would better help us understand why the lawyers performed particular behaviours or interface ac-tions. Questions included  X  X hy did you use a plus sign when conducting your earlier search? X  and  X  X ou mentioned using  X  X asked proxy access X  to login to LexisNexis Butterworths. Why did you need to do that? X  Sometimes these questions also served to elicit participants X  understanding of their interface actions. For example, one Dispute Resolution lawyer ex-plained that him receiving no results in one of his digital library searches was likely to be due to the fact he had used a  X  X ubbish search string X : [DR6 Searches LexisNexis Butterworths using the terms  X  X art 36 offers AND  X  X  X ultiple claimants  X   X  and retrieves no results]. DR6: It X  X  found no documents.
 R: Why do you think that was?
DR6: Because that was a bit of a rubbish search string that I put in there, putting  X  X ultiple claimants X  together. 4.4.3. Instructing participants on completing the information task and thinking aloud Whilst some books from the Human X  X omputer Interaction domain (e.g. Dumas &amp; Redish X  X , 1999  X  X  Practical Guide to
Usability Testing X ) provide detailed guidance for instructing participants on how to think aloud, an assumption is made that the primary purpose of the think-aloud study is to identify usability issues related to the interactive systems being used, rather than to understand participants X  interactive behaviour. As we were unaware of any detailed guidance for conducting think-aloud studies of information behaviour, or interactive behaviour in general, we devised instructions for our study that we thought would best help us achieve our aim of gaining as detailed and accurate an understanding as possible of a broad range of behaviours.

In order for our think-aloud data to be accurate, we needed to ensure that the think-aloud sessions were as true to life as possible (within our study X  X  constraints). To achieve this, after explaining the purpose of our study, we also told the lawyers that it was our aim to observe behaviour that was as natural as possible and that they should undertake their self-chosen information task in the way that they normally would. The lawyers were told that if they chose to step-through a task they had recently undertaken, they should use the task as a springboard -what they did when looking for the information pre-viously was not important. We also reassured them that the study was not a test of their information skills.

After reading and signing the informed consent form, the lawyers were given a few minutes to think of a suitable infor-mation task and then asked to describe the context surrounding the task in detail. Whilst often not directly relevant to the lawyers X  information behaviour, gaining a detailed understanding of not only the information task, but the motivation be-hind it was extremely useful for gaining a richer understanding of their information behaviour. After choosing their task, the lawyers were asked to think aloud  X  verbalising their thoughts and interface actions as they used the electronic information resource or resources of their choice to undertake the task. The instructions read out to the lawyers are shown in Fig. 1 .

Although we considered giving the lawyers an opportunity to practice thinking aloud, we thought they might not regard this as a constructive use of their time. Therefore whilst we offered them the option to practice, we did not enforce a practice.
Consequently, none of the lawyers expressed a desire to practice. Whilst none of the lawyers demonstrated particular dif-ficulty thinking aloud, in subsequent think-aloud studies of interactive information behaviour (not yet reported), we have found it useful for the researcher to give a short (10 X 15 s) example of them thinking aloud when conducting a simple Internet search and looking through the results. This minimises the time required to introduce the study, whilst providing a concrete example of how to think aloud when using electronic information environments. 4.4.4. Intervening during the think-aloud session
Ericsson and Simon (1993) argue that any researcher comment, prompt or question whilst a participant thinks aloud makes their subsequent think-aloud data unreliable as the intervention alters the flow of information in the participant X  X  short-term memory during the task. However, when evaluating the use of interactive systems, Boren and Ramey (2000) highlight that it is often necessary to prompt for data about users X  expectations or explanations of their interface actions and that sometimes this data, which Ericsson and Simon would deem as  X  X nreliable, X  can be valued over more procedural information. We believe this is also the case when studying users X  interactive information behaviour and suggests the need for researchers to weigh up their priorities with regard to deciding whether to stick to Ericsson and Simon X  X   X  X o intervention X  rule. Indeed, Tamler (1998) suggests that in order to decide whether and how much to intervene in a think-aloud session, it is important to examine the purpose of the session. He suggests, for example, that if the purpose of the think-aloud session is to collect quantitative usability data, non-intervention may be particularly important. However,  X  X  X f the purpose is to gather qualitative date so as to identify significant user interface problems and recommend design solutions, then openly interacting with users in various ways may not only be useful, but also sometimes necessary  X  (p. 12). We felt that whilst a traditional think-aloud study with no intervention might provide us with a reasonable insight into what the lawyers were doing when using elec-tronic information resources to complete their chosen task (i.e. their interactive behaviour), the complicated and cognitive nature of information work meant we would be unlikely to gain a comprehensive and accurate understanding of their behav-iour without knowing why they performed certain actions. Therefore we decided to ask questions during the think-aloud session where we believed asking the question was (a) likely to provide us with a greater insight into the lawyers X  informa-tion behaviours and (b) unlikely to bias the lawyers X  future actions.

Whilst we asked questions during each of the think-aloud sessions, we took care to only intervene when we thought this would impact positively on our findings; the researcher remained passive for the vast majority of each session. Whilst we cannot be certain that asking questions did not introduce limited action or halo-effect bias, we believe that our interventions resulted in think-aloud data that was far richer than in might have been had we not intervened. It would be interesting to test this hypothesis in a future study.

The questions asked during the think-aloud session took the form of short and seemingly innocuous questions, posed at opportunistic moments during the study -usually to probe the lawyers X  interactive behaviour in more detail. At the begin-ning of the think-aloud session, we also found it necessary to ask questions to probe more detail on the context of the law-yers X  chosen information task and the underlying information need, which often gave us a clearer understanding of the goal of the task and the motivation behind it. For example, we asked one lawyer what information he needed to find and probed for further details when the lawyer proceeded to carry out the task without fully explaining it:
DR2: This one is a fairly straightforward example, which is that I had given a talk and paper to the Paris office on insurance and reinsurance law about 18 months ago and I was just looking for that paper in order to be able to update it for further talks that I was also giving. I X  X  typing in  X  X ntroduction to insurance law X  with the search preference on  X  X nsurance X .
 R: Was that the title of the paper?
DR2: The title of the paper was actually  X  X  Basic Introduction to Insurance and Reinsurance Law X , but the search results that have come up under  X  X ntroduction to insurance law X  are 1 of 756.

During the think-aloud itself, the most common question asked was  X  X hy did you do [x]? X   X  to gain an understanding of the lawyers X  interface actions or to check our understanding or assumptions. For example, when asked why he clicked on a question mark icon beside a greyed-out checkbox on the segmented field search in LexisNexis Butterworths, a Dispute Res-olution lawyer explained that he did so to see whether he had access to that particular search feature, since  X  X  X uite often there are sections that we haven X  X  subscribed to  X  (DR15). We also asked questions to seek elaboration on comments made or inter-face actions performed. For example, when one lawyer stated that his search had only returned one result, which  X  X didn X  X ] look relevant X  (T1), we asked  X  X hy don X  X  you think the result looks relevant? X  The lawyer X  X  answer provides an explanation of his search behaviour: one hit came up, which was a reference for something to do with the 2006 Budget  X  (T1).

Similarly when another lawyer mentioned that it was strange that he had not found any instances of a particular article number within the full-text of a legal case, we asked  X  X hat X  X  strange? X  Again, the lawyer X  X  answer provides a useful expla-nation of why he made the comment: [T3 searches for the article number  X 3(4)3 X  within the text of a legal case and finds no instances of the article number within the text].
 T3: That X  X  strange! R: What X  X  strange?
Questions were also asked to seek clarification on a comment made or interface action performed, often with the purpose of checking our understandings and assumptions. For example, when one lawyer spent time reading through the results list in LexisNexis Butterworths, we asked him which part(s) of the screen he was looking at. He told us he was only skimming the result headings, not reading the snippet of text below each heading presenting the search terms in the context of the doc-ument. Our intervention did not seem to bias his future actions; he continued to read the headings, and then edited his search. In another instance, when we asked a Tax lawyer whether he decided on the relevance of the search result he had clicked on by  X  X eighing up X  the results in the list and choosing the most promising one, we found out that he was actu-ally performing slightly different behaviour (i.e. making a binary decision about whether to click on each result in turn): R: Was it the case that you picked the most likely one to be relevant by weighing them up?
T3: No, it was a more gradual step-by-step thing. I looked at the first one and decided it was not relevant, then I looked at the second one and decided it was not relevant. But that was only because there was 4 of them. If there was like 30 I would have probably gaged them all against the other.

Aside from questions aimed at probing the lawyers X  interactive behaviour, we also found it useful to intervene when law-yers strayed away from their stated information task, slipped to providing abstract descriptions rather than demonstrating concrete interface actions or forgot to think-aloud. As an example of straying away from the chosen task, one lawyer offered to look at the history of a particular legal case even though this did not seem to be relevant to her chosen task. The researcher politely declined her offer and requested that she continue with her task. A couple of the lawyers also reverted to giving ab-stract descriptions of their actions, rather than demonstrating those actions.  X  X an you show me ...  X  questions were particu-larly useful for encouraging these lawyers to shift away from abstract descriptions of their behaviour and continue with their task:
T4: Then I did something a bit more general that didn X  X  just talk about Section 12 of the Capital Gains Tax Act, but talked about the remittance basis for Capital Gains Tax in general and I got a couple of more articles from Lexis.
 R: Could you show me what you did? T4: I just browsed through that initial list of 40 results [returns to results list].

Although the lawyers in our study managed to think aloud without difficulty, many of them went quiet when performing highly cognitive activities such as looking through search results or reading through a document. Asking  X  X hat are you doing now? X , as suggested by Dumas and Redish (1999) , was particularly useful for (indirectly) reminding them to resume verbali-sation. For example, Tax lawyer T6 read through a section of the Inland Revenue Manual in LexisNexis Butterworths and then browsed through subsequent headings in the manual X  X  contents tree. When asked  X  X hat are you doing now? X , he provided useful detail:
T6: I X  X  just looking in case any of these individual sections really jump out at me as being potentially helpful for the question that I X  X  considering, which none of them especially do.

We also intervened when participants had strayed away from their information task. For example, one lawyer started to explain the range of electronic information resources available to the team and suggested showing one of them to the re-searcher. The researcher then steered the participant back towards their information task:
DR6: CLI [digital law library] is the one which has commentary and the Legal Journal Index. And I can X  X  remember the name of the source where you look at the history of a case, but I could show you online, I know exactly where it is.
 R: Maybe you can show me later if we have time. So what did you do next in your search for legal cases?
Next, we intervened when we felt it would be useful to encourage participants to provide further details about how their interface actions fit in with their broader information task. The most common question asked for this purpose was  X  X hat did you do next?, X  as illustrated in this example:
DR7: So I always take the approach of skimming rather than reading in great detail, especially if I X  X e already gone and got quite a good overview by virtue of this kind of page [points at overview page of document].
 R: What did you do next? know that X  X  not the best way of finding Case Law, so I probably had a look to see if there was any headline type thing.
Finally, we intervened when the participant asked us a question during the think-aloud session. Where we deemed that answering the question was likely to bias the participant X  X  future actions or comments, we explained that we were unable to answer the question whilst the study was underway, but would answer it at the end. In other cases, as suggested by Dumas and Redish (1999) , we turned the questions around  X  answering them with another question in order to elicit participants X  understanding. For example DR5 commented on difficulties he was having when logging into LexisNexis Butterworths:
DR5: It was related to Cookies or something. Does that mean anything to you? Somebody said I had a Cookies problem once on my computer and that confused me! R: What do you think that might X  X e meant? DR5: I don X  X  know! It X  X  something to do with passwords or something or whatever. [DR5 laughs].

Overall, we found carefully-considered intervention to be extremely useful for the purpose of our study  X  gaining an understanding of lawyers X  interactive information behaviour. The resultant think-aloud data was not only rich enough to provide us with a deep insight into the lawyers X  behaviour, but also into the motivation behind this behaviour. The data also revealed no specific evidence to suggest that our interventions had biased the lawyers X  future comments or interface actions. 4.5. Data analysis 4.5.1. Transcribing the think-aloud data
The audio-recorded think-aloud data were transcribed verbatim and anonymised from the outset (i.e. no details that could be used to specifically identify the participant, firm or client were included on the transcript). We found the process of transcribing our own transcripts useful as it helped us gain familiarity with the data. Bold italics were used to denote when a lawyer emphasised a particular statement and square brackets were used to denote pauses of over five seconds.
We also found it particularly useful to summarise lawyers X  interface level actions (also in square brackets) as this assisted us when trying to understand the behaviour displayed in the transcript. In order to avoid biasing our analysis, we avoided interpreting any of the lawyers X  interface actions when summarising them. For example, one lawyer conducted a digital li-brary search for  X  X ndue influence X , when he intended to search for  X  X ndue influence.  X  Instead of jumping to a quick interpre-tation of his actions and transcribing them as  X  X participant misspells the word  X  X nfluence, X  which leads to an unsuccessful search], X  we summarised his actions without interpretation as  X  X participant enters the search terms  X  X ndue influence X  into the search box and submits the search, but receives no results]. X  4.5.2. Identifying information behaviour from the think-aloud data In order to identify information behaviour from our think-aloud data, we employed aspects of Glaser and Strauss X 
Grounded Theory methodology Glaser &amp; Strauss, 1967 ). Grounded Theory involves systematically gathering and analysing data during the research process ( Strauss &amp; Corbin, 1998, p. 12 ) and is  X  X rounded X  in the sense that the theory is heavily rooted in the data and emerges through the process of cyclic data-gathering and analysis. Therefore Grounded Theory should not be regarded as a data analysis technique per se, but a methodology for data collection and analysis  X  which, according to
Glaser and Strauss, should not be regarded as separate processes. This cyclic approach is known as the  X  X onstant comparative method X  and is a key tenet of Grounded Theory. Our data collection and analysis approach allowed us to constantly question and revise our understanding of the lawyers X  information behaviour during the analysis. We found it particularly useful to use some of the questions we asked during the think-aloud session as a means of checking our evolving understanding (as discussed in the previous section).

After transcribing a particular think-aloud session, we read the transcript sentence by sentence and assigned codes to parts of it that illustrated particular interactive information behaviour using the qualitative analysis software Atlas. Ti. Cod-ing was achieved by coding parts of the transcripts that appeared to refer to the same type of interactive behaviour with the same label and refining the analysis through a cyclic process of re-reading the transcripts several times, re-naming codes (for example when a better or more precise description of the behaviour could be identified), merging codes (when two identi-fied information behaviours were deemed to actually be the same), splitting codes (when an information behaviour that had previously been coded under one code was deemed to actually be different) and by re-coding parts of the data under a dif-ferent code name , by unlinking data from a particular code (when data no longer appeared to fit the code name that it had been assigned to) and by deleting codes entirely when they no longer seemed to be useful for describing the data. We considered coding without the use of a qualitative analysis software tool, by writing codes in the margins of the paper tran-scripts and using a different highlighter colour to represent each code. However, we decided that using a software tool would be particularly useful for our study. We found that using the software tool sped up the process of assigning codes (for exam-ple, by allowing us to create a list of codes and then assign codes from the list to part of a transcript without having to re-type the code name several times). We also found that using the software fit well with our cyclic process of data-gathering and analysis as it allowed us to re-name, re-code, delete, merge and split existing codes far quicker and easier than would have been possible by hand  X  eliminating the need to manually propagate changes across transcripts.

As an example of assigning a code and later re-coding the data, consider the interactive behaviour of looking through the first page of search results  X  reading either the document titles and/or the snippet below the title and then clicking on the first document that showed potential to be useful. Initially, we coded this behaviour as  X  X electing X , which we defined as  X  X are-fully choosing information X  (in this case, documents from the results list). As our data collection progressed, however, we noticed that we had coded two distinct types of behaviour  X  X electing X   X  the behaviour described above, where lawyers  X  X eighed up X  the results set (or part of it) and clicked first on the result that showed the most promise and a more general behaviour  X  where lawyers started from the first result and decided whether or not to click on it, before moving onto the next result and repeating the process. We decided that  X  X electing X  accurately described this behaviour, but that the  X  X eighing up X  results was best described as  X  X istinguishing X   X  an information behaviour that Ellis and Haugan define as  X  X  X anking sources or documents according to their relative importance based on own perceptions  X ( Ellis &amp; Haugan, 1997, p. 399 ). We therefore looked back through our transcripts and removed the code  X  X electing X  from parts of the transcript that seemed to demon-strate the  X  X eighing up X  of search results. We then assigned the new code,  X  X istinguishing X , to these instances. This example serves to illustrate how constantly comparing the interactive information behaviours displayed by different lawyers resulted in a richer theoretical picture and a more accurate description of their behaviour. Indeed, the process of re-reading the tran-scripts and asking  X  X hat is (really) going on here? X  was invaluable for understanding the lawyers X  behaviour.
As an example of deleting a code entirely, consider the interactive behaviour of  X  X eading X  information on-screen. Initially, we coded sections of the transcripts that involved lawyers reading out document titles or parts of the document text with the code  X  X eading X . For example, the following section of the transcript was coded as  X  X eading X :
DR7: Here we go, look! [DR7 reads out the title of an article listed in the search results].
 DR7:  X  X xtradition case could change law on Cartels, X  that X  X  quite interesting! I would definitely think that would be interesting.
However, it soon became apparent that  X  X xtracting X  ( X  X  systematically working though a particular source to identify material reading parts of the document or metadata in order to identify information of interest (rather than simply reading for the sake of it). An excerpt from a coded think-aloud transcript is shown in Fig. 2 .

We coded the data using the  X  X pen X  and  X  X xial X  coding elements of Grounded Theory in order to identify the interactive information behaviours displayed by the lawyers and how these behaviours might relate to each other. Strauss and Corbin (1998) define open coding as  X  X  X he analytic process through which concepts are identified and their properties and dimensions are common for researchers employing Grounded Theory to undertake a third stage of coding,  X  X elective coding X   X  defined as  X  X  X he
We made the choice to perform only open and axial coding (effectively  X  X topping short X  of generating a theory), based on the purpose of our study. Our aim was not to generate theory per se, but to identify a broad range of interactive information behaviours and to understand these behaviours in detail. We did not believe that attempting to identify a  X  X ore X  information behaviour and relating the other identified behaviours to it would be useful for this purpose. Indeed, we found it more useful to establish firm boundaries between codes in order to definitively categorise particular information behaviours than to establish fluid boundaries by considering the identified behaviours as highly inter-related and each linked to a particular behaviour that was more important to lawyers than the others.

Our decision to undertake only open and axial coding, but otherwise follow the core principles of Grounded Theory raised an important issue. The issue was related to how we describe our methodology and, more specifically, whether we should call it  X  X rounded Theory X  even though our study did not aim to or end up generating a theory. In this paper, we have taken care not to label our data collection and analysis procedure as a  X  X rounded Theory X . Instead, we have tried to be as precise and transparent as possible about exactly what we did and why, relating our methodological decisions back to the purpose of the study.

Although we did not perform integrative selective coding, we found the other aspects of Grounded Theory to be extre-mely useful. Strauss and Corbin (1998) state that  X  X  although researchers may pick and choose among some of the analytic tech-niques that we offer, the procedures of making comparisons, asking questions, and sampling based on evolving theoretical concepts are essential features of the methodology  X  (p. 46). Indeed all of these essential features of Grounded Theory were particularly useful in our study and, we believe, are likely to be useful for other studies aimed at gaining a detailed understanding of information behaviour in general or particular aspects of it.

A final consideration when identifying information behaviour from our think-aloud data was the need to avoid bias dur-ing analysis. In particular, we found that the information behaviours identified were similar to that found in many other studies of information behaviour  X  including studies that had led to the development of theoretical models of informa-tion-seeking. Therefore there was the potential to use existing information theory to guide our analysis. However, as Strauss and Corbin (1998) assert,  X  X  X he researcher does not want to be so steeped in the literature that he or she is constrained or even stifled by it  X  (p. 49). Therefore care was taken to avoid simply relating our data to different information-seeking models in order to identify a model or models which fitted the data best (which might be regarded as  X  X orcing X  as opposed to  X  X mer-gence X  in Grounded Theory terms).

Instead, the codes we assigned to parts of the think-aloud transcripts were based on our own terminology, and similar-ities between the types of behaviour described by our codes and existing theoretical models (notably Ellis X  X  behavioural model of information-seeking ( Ellis, 1989; Ellis et al., 1993; Ellis &amp; Haugan, 1997 )) emerged from the analysis. This led us to examine our data in the light of Ellis X  X  model, asking questions of our data such as  X  X re any of the information behaviours we identified amongst lawyers similar to those found by Ellis and his colleagues and, if so, which ones? X ,  X  X hich information behaviours identified by Ellis and his colleagues are not present in our data? X  and  X  X hich behaviours in our data were not identified by Ellis and his colleagues? X  These questions are related to those that Strauss and Corbin suggest should be asked when relating emerging concepts to previous work;  X  X  X re these concepts truly emergent, or am I seeing these concepts in the data because I X  X  so familiar with them? If they are truly emergent and relevant, then how are they the same as and how are they dif-ferent from, those in the literature  X  (p. 50).

To facilitate easy comparison with Ellis X  X  model, we chose to use Ellis X  X  existing code labels when we believed our data reflected identical (or highly similar) behaviour. Our comparison to Ellis X  X  model resulted in the validation of the model in the legal domain and its extension and refinement (see Makri, Blandford, &amp; Cox, 2008a ). However, we should stress that we did not seek to do this from the outset; the purpose of our study was to gain a detailed understanding of lawyers X  inter-active information behaviour in order to inform electronic information resource design. We regard the validation, exten-sion and refinement of Ellis X  X  model as an important  X  X heoretical by-product X . Comparing our findings to Ellis X  X  model helped us achieve our purpose by providing us with a useful reference for questioning the data, resulting in what we be-lieve to be a richer understanding of the lawyers X  interactive behaviour. Comparing our data to Ellis X  X  findings was also particularly useful as it highlighted a useful level of abstraction at which to describe the interactive behaviour in order to inform design. For example, we noted that electronic information resource developers might feasibly inform design by asking themselves:  X  X ow can we support or better support Ellis X  X   X  X istinguishing X  behaviour? X  We also noted that the same could be said of many of our identified codes (e.g.  X  X electing X , defined on the previous page). Ellis X  X  model therefore provided us with useful meta-theory for coding our data. Indeed, this partly inductive and partly deductive stance not only enabled us to relate our findings to previous research but to actively use existing studies to help us better understand our data and ways of analysing it.
 Overall, we found that using the open and axial coding techniques along with the other core principles behind Grounded
Theory was a highly useful way of identifying information behaviour from our think-aloud data. Although we do not seek to downplay the potential value of other qualitative and quantitative analysis techniques, we believe that this methodology and, in particular, the constant comparative method greatly assisted us in gaining a detailed and  X  X rue X  an understanding as possible of our data. 4.6. Reporting the findings
Our findings are reported in Makri (2009) . The practical findings included a rich description of the interactive information behaviours displayed by lawyers when using existing electronic information resources to find information for their work. The theoretical findings included the validation of Ellis X  X  behavioural model of information-seeking ( Ellis, 1989; Ellis &amp;
Haugan, 1997; Ellis et al., 1993 ) in the legal domain, the extension of the model to include behaviours pertinent to legal information-seeking, the broadening of scope of the model through the inclusion of information use (as well as informa-tion-seeking) behaviours and the enhancement of the potential analytical detail of the model through the identification of mostly mutually-exclusive pairs of behavioural subtypes and different levels at which many behaviours can operate.
The concepts of behavioural subtypes and levels are explained in Makri (2009) , pp. 89 X 91.
Our findings also fed into the development of the Information Behaviour (IB) methods; two user-centred methods that can be used to evaluate the functionality and usability of electronic information resources. Both these methods use the behaviours identified from our think-aloud study of lawyers X  information behaviour as their theoretical basis. An IB function-ality evaluation involves evaluators discussing whether and in what ways an electronic information resource currently sup-ports the information behaviours identified in our study. If the resource currently supports a particular behaviour, the method prompts evaluators to discuss additional ways in which it might support the behaviour. If the resource does not cur-rently support a particular behaviour, the method prompts evaluators to discuss ways in which the behaviour might be sup-ported. An IB functionality evaluation also involves evaluators discussing whether there are any behaviours or existing ways of supporting them that it may no longer be necessary to support. An IB usability evaluation involves evaluators setting a number of behaviour-focused tasks to existing or prospective users of the electronic information resource under evaluation.
As in a conventional think-aloud session, the users are asked to think aloud  X  verbalising their thoughts, interface actions and feelings whilst undertaking the tasks. The evaluators then identify usability issues from the resultant think-aloud data and make summary judgements on how severe they consider the issues to be and the amount of effort they consider to be re-quired in order to address them. The IB methods are described in more detail in Makri, Blandford, and Cox (2008b) and Makri (2009) .

Finally, we also fed our findings back to the law firm. As the firm was particularly interested in usability issues with their own in-house knowledge-management database, we also provided them with anonymised extracts from our transcripts where lawyers used or referred to the firm X  X  database. We also found it particularly useful to feed back our findings in the form of informal presentations to senior members of the firm (and to participants interested in the findings, who were also invited to attend). The findings were also presented as part of a workshop organised with staff working for LexisNexis
Butterworths. 5. Conclusion
Our think-aloud study of lawyers X  interactive information behaviour involved making many difficult methodological deci-sions and trade-offs. In these situations, we found it most useful to refer back to the purpose of our study in order to decide how best to proceed. For example, when deciding on the precise wording of our information task, we were guided by the need to ensure the think-aloud study resulted in a wide range of information behaviours. This need also provided support for our decision to ask wrap-up questions at the end of the think-aloud session. Similarly when deciding whether to observe lawyers at their desks even if another (often senior) colleague was present in the room, we were guided by the need to en-sure the think-aloud was conducted in as naturalistic a manner as possible. This meant avoiding the potential data bias that might have arisen from asking Dispute Resolution lawyers to think-aloud in a shared office. Our key decision to ask probing, opportunistic questions during the think-aloud session was based on both the need to identify a broad range of naturalistic information behaviours, but also to understand these behaviours in detail. Another important decision  X  to perform open and axial, but not selective coding  X  was made based on the knowledge that the aim of the study was not to generate a behavioural theory, but to understand the identified behaviours in detail and how they relate to one another. We also made some important decisions based on practical considerations. For example, we decided to ask the lawyers to think-aloud con-currently rather than retrospectively based on their time pressures and decided only to audio record the think-aloud sessions (rather than both audio and screen-record them) as we did not want to install additional software on the firm X  X  network.
Our discussion and reflection not only serves as a form of guidance to researchers who are considering planning a think-aloud study of interactive information behaviour, but also to highlight the important need for rigorous discussion and reflec-tion on the methodology employed and methodological decisions made in future information behaviour studies. Although there may not always be space to report all aspects of the methodology used when writing up a think-aloud study of inter-active information behaviour, it is important that sufficient detail is provided so that the reader can understand exactly how the authors sought to address the study X  X  purpose and appreciate the potential impact of any methodological decisions made on the results.
 Acknowledgements This work was supported by an EPSRC Studentship and an ESRC Post-Doctoral Research Fellowship.
 References
