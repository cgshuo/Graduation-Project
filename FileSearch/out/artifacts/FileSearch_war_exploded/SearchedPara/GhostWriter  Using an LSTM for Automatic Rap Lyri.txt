 Ghostwriting defines a distinction between the performer/presenter of text, lyrics, etc, and the cre-ator of text/lyrics. The goal is to present some-thing in a style that is believable enough to be credited to the performer. In the domain of rap specifically, rappers sometimes function as ghost-writers early on before embarking on their own public careers, and there are even businesses that of GhostWriter is to produce a system that can take a given artist X  X  lyrics and generate similar yet unique lyrics. To accomplish this, we must cre-ate a language model to produce text, while also understanding what  X  X tyle X  means in a quantitative sense.

The contribution of this paper is three-fold: (1) we present the ghostwriting problem of producing similar yet different lyrics; (2) we present compu-tational, quantitative evaluation methods for these two aspects; (3) we evaluate the performance of a Long Short-Term Memory (LSTM) vs n-gram model for this problem. Recent work (Sutskever et al., 2011; Graves, 2013) has shown the effectiveness of Recurrent Neural Networks (RNNs) for text generation. In their works, the authors use an RNN to create a language model at the character level. The results are inspiring, as the models learn various gram-matical and punctuation rules, such as opening and closing parentheses, plus learning a large vo-cabulary of English words at the character level. Graves (2013) uses a variation of an RNN called LSTM architecture which creates a better lan-guage model than a regular RNN.

Text generation for artistic purposes, such as po-etry and lyrics, has also been explored, often using templates and constraints (Oliveira et al., 2014; Barbieri et al., 2012). In regards to rap lyrics, Wu et al. (2013) present a system for rap lyric gener-ation that produces a single line of lyrics that are meant to be a response to a single line of input. However, the work that is most similar to ours is that of Malmi et al. (2015). The authors create fixed 16-line verses, generating the verse line-by-line using full lines from existing rap songs. The system predicts the best next line based on the pre-vious lines, using a system that records an 81.9% accuracy predicting next lines in already existing verses. The feature that provides the greatest accu-racy gain is a neural embedding of the lines, cre-ated from the character level.

Hirjee and Brown (2010b) have developed a rhyme detection tool based on a probabilistic model (Hirjee and Brown, 2010a) that analyzes phoneme patterns in words. The model is trained on a set of lyrics that were manually annotated for rhyming words. The statistics generated by the rhyme detection tool will be an important part of our evaluation (see Section 5). In a departure from previous work on poetry/lyric generation, our goal is to build a model that does not require templates/constraints to generate lyrics, while also being able to produce full verses, as opposed to single lines. The system must be able to model general human language in order to produce fluent lyrics, but it must also be able to model the style of a target artist, by understanding the artist X  X  vocabulary and rhythmic style, in order to fully execute the ghostwriting task of producing similar yet new lyrics. 3.1 LSTM Here we will give a very brief overview of RNNs and LSTMs. For a more detailed explanation please refer to (Graves, 2013). The foundation of an RNN (of which an LSTM is specific ar-chitecture) is a word embedding E that provides a vector representation for each of the words in our corpus. Given a history of words w k , ..., w 0 we want to determine P ( w k +1 | w k , ..., w 0 ; E,  X ) , where  X  is a set of parameters used by our model. In the context of an RNN we define this probability by: P ( w k +1 | w k , ..., w 0 ; E,  X ) = f ( x, s ) (1) At each time-step the RNN computes f given an observation x and a previous state s . The input goes through a transformation where it passes through one or several hidden layers.

The LSTM model uses a specific architecture for the hidden transformation, defined by the LSTM memory cell. The key feature to the LSTM memory cell is the presence of an input gate, out-put gate, forget gate, and cell/cell memory, which manifest themselves in the model as activation vectors. Each of these gates/cells has its own bias vector, and the hidden layer at each time-step is now a complex nonlinear combination of gate, cell, and hidden vectors. 3.2 Using LSTM for Lyrics Generation Since previous work has shown the power of RNNs to model language, we hope that it can cap-ture the rhythmic style of an artist by learning rhyme and meter patterns. As noted in Section 2, LSTMs have performed well at sequence forecast-ing, for example at learning punctuation, such as opening and closing parentheses. We see the task of rhyme detection as something similar in na-ture. Kaparthy et al. (2015) have also shown that LSTMs could successfully learn where to place the brackets and indentation in C++ code. In their model, certain LSTM cells activated specifically when encountering end of the line. We believe learning rhymes at the end of the line is concep-tually similar to such tasks. 3.3 Verse Structure and Rhyme Inference The goal of our model is to not just generate lyrics, but generate the structure for the lyrics as well. To do this, we have added  X  &lt; endLine &gt;  X  and  X  &lt; endVerse &gt;  X  tokens to the lyrics. From this, the system will generate its own line breaks, while also defining when a generated verse ends. This allows us to analyze non-rhyming features from (Hirjee and Brown, 2010a), such as number of syllables per line and number of lines per verse. We also desire that, by using the  X  &lt; endLine &gt;  X  token, the system has a better chance of un-derstanding rhyme schemes used by an artist. For example, the LSTM can capture the pat-tern of  X  X ame &lt; endLine &gt;  X  followed shortly by  X  X ame &lt; endLine &gt;  X  to understand that  X  X ame X  and  X  X ame X  are a rhyming pair. To do this effec-tively, the system would need sufficient training data where rhyming pairs occur frequently enough to actually dictate a pattern, similar to (Reddy and Knight, 2011; Addanki and Wu, 2013). 4.1 Dataset We collected songs from 14 artists from the site The Original Hip-Hop (Rap) Lyrics Archive -OHHLA.com -Hip-Hop Since 1992 2 . In the present lyrics generation experiments, we used the lyrics from the rapper Fabolous. For training, we used 219 verses with at least 175 words in each verse. We selected Fabolous because his lyrics produced the highest accuracy in the artist recog-nition experiments in (Hirjee and Brown, 2010a). We conjecture that because of this, he had the most consistent style, making him a good choice for ini-tial experiments. 4.2 Baseline To compare with the results of the LSTM model, we followed the work of (Barbieri et al., 2012) and created a Markov model for lyric generation. Since the goal of our work is to make an unsu-pervised system, we do not use any constraints or templates to produce the lyrics. Thus, our baseline simplifies to a basic n-gram model. Given a history of w k + n  X  1 ,..., w k , the system generates a new token t as follows: where | w k ...w k + n  X  1 t | is the amount of times the the context w k + n  X  1 ,..., w 1 is followed by t in the training data, and | w k ...w k + n  X  1  X  | is the amount of times the context appears followed by any token. There is the possibility that the context has never been encountered in the training data. When this occurs, we back off to a smaller n-gram model: The model may have to back-off multiple times before it encounters context it has seen in the training data. Once we back-off to the point where we compute P ( w n + k = t | w k ) , we are guaranteed to have at least one non-zero probability, because w k must have appeared in the vocabulary for it to have been generated previously.

Note that rather than backing off to a lower-order n-gram model, we use a skip-gram model which drops the words immediately preceding the predicted word. The main motivation for this is that it allows us to capture long-range dependen-cies, which makes it into a better baseline compar-ison for an LSTM. 4.3 Model Initialization When producing lyrics with either the LSTM or baseline model, we initialize with the  X  &lt; startVerse &gt;  X  token. Once the model produces a token, it becomes part of the context for the next step of token generation. Our models are closed in the sense that they only produce tokens that appear in the training vocabulary. 4.4 LSTM Implementation We used a Python implementation of an LSTM top of Theano (Bastien et al., 2012; Bergstra et al., 2010). Following (Graves, 2013), we set the amount of LSTM inputs/outputs to be equal to the vocabulary size. Also, to avoid the vanishing gra-dient problem when training RNNs, we clip the gradients in the range [-1,1]. We train our LSTM model using a Tesla K40 GPU on a single work-station. In this section, we present automated methods for evaluating the quality of generated lyrics. Ide-ally, judging system output in terms of, e.g. flu-ency, should be conducted using manual evalua-tion. However, conducting formal human evalua-tion is somewhat problematic. For a full qualita-tive evaluation of a given artist that would assess both similarity of style and novelty, the evaluator would need to know that particular artist X  X  body of work very well. Even finding annotators who are well-versed in the general art of rap lyrics can be challenging (Addanki and Wu, 2014). While this may be possible for the present experiments that focus on a single artist, it is hardly feasible for larger-scale studies that will use our full data set that contains the lyrics of 14 different artists. We therefore propose an automated evaluation method which we believe is able to capture two critical as-pects of ghostwriting, which are in fact quite tricky to capture together: being similar, yet different. 5.1 Similarity to existing lyrics In order to evaluate the novelty of generated lyrics, we compare the similarity of the generated lyrics to the lyrics in our training set. We used an algorithm proposed by (Mahedero et al., 2005) for calculating the similarity between produced lyrics and all verses from the same artist. This algorithm is based on the well-known Inverse Document Frequency, using cosine on document vectors to calculate distance. First, we build the Term-Document Matrix with weights for each term in each song: w where N is the total number of documents (verses, in our case), n j is the number of verses that contains term j and f ij is the frequency of term j in the ith verse. Using this matrix, we can calculate the cosine distance between verses and use it as a measure of similarity. When discussing similarity, we refer to the max similarity: of all verses it is most similar to, exactly how similar is it? The lower the max similarity score, the more novel the lyrics. 5.2 Numerical features of the lyrics We also produced the features from (Hirjee and Brown, 2010a) for our generated verses. The statistics of these features are meant to represent how effective we are in modeling an artist X  X  style. The point of the system is not to produce arbitrary rhymes; it is to produce rhyme types and rhyme frequency that are similar to the target artist. Fol-lowing (Malmi et al., 2015), the rhyme feature we examine in this work is rhyme density. Rhyme density is defined as the total number of rhymed syllables divided by the total number of syllables. For the lyrics generation experiments reported here, we used the rapper Fabolous as the artist whose style we tried to emulate. 6.1 Example of Generated Lyrics (Warning: Below is a sample of lyrics generated by the LSTM model:
Line 1: i m old enough to know better young enough to not give a fuck
Line 2: rather hold my head high and die then live and duck
Line 3: i got ta fuck be up and little niggaz go in
Line 4: when i m in the feds and scoped by uncle sam
Line 5: dope and hunn ed grams rope and hunn ed grams
Line 6: at the same time she jerking and wig-gling Line 7: smirking and giggling
While the pairs of rhyming end-lines in the gen-erated lyrics are taken from the training data (the max similarity is 0.41), no more than two lines appear from a single verse. Though the gener-ated lyrics aren X  X  novel in a strict sense, the LSTM model is more effective than the n-gram model at using lines from multiple verses (see next Sec-tion 6.3). The rhyme density of this verse is 0.35, which is almost equal to Fabolous X  X  average rhyme density (0.34). 6.2 Quantitative Analysis As previously mentioned, the key to effective ghostwriting is to mirror an artist X  X  style, but also providing original content. While vocabu-lary and lyrical content are key components for an artist X  X  style, this is inherently satisfied by using words only from the training data. Thus, rhyme style  X  specifically rhyme density  X  will be the key performance indicator for imitating an artist X  X  style. In terms of rap lyrics in general, a higher rhyme density is often better. Therefore for our system we would like a high rhyme density, but with a low max similarity score (a higher nov-elty). Figures 2 and 1 show the graph for rhyme density and max similarity for the LSTM and n-grams models, respectively. For the LSTM model the values are graphed compared to training iter-ation number  X  as the model becomes more fit to the data. For the n-gram model they are graphed dependent on n-gram value. For each n-gram value, we generate 10 verses and compute the av-erage value of the two metrics. One expects that a perfectly fit LSTM model without regularization would exactly reproduce lyrics from the training data, and a high n-gram value would would also produce duplicate lyrics. This is evident in the graphs.
 Figure 1: Values of rhyme density and max simi-larity versus n-gram value for the n-gram model. Figure 2: Values of rhyme density and max sim-ilarity versus iteration number when training the LSTM model. 6.3 Correlation of Rhyme Density and Max Since exact replication would assuredly give a higher rhyme density than randomly produced lyrics, we desire a low correlation between rhyme density and max similarity. The correlation be-tween rhyme density and max similarity for the LSTM model is 0.32, and for the n-gram model it is 0.47. When examining Figures 1 and 2 one may notice the anomalous points of high rhyme density (at n = 6 on the n-gram graph and 3,000 iterations for the LSTM model). After further inspection of the lyrics at these points, we see the lyrics con-tain repetitions of the exact same phrase. Since words are repeated frequently, the rhyme density of the lyrics is high (repeated words create rhymed phonemes, according to the rhyme detection tool). These points cause the similarity-density correla-tions to be artificially lower. After removing these data points, the LSTM model still has a lower correlation than the n-gram model, but the gap is much smaller: 0.71 compared to 0.75. Ultimately however, this shows that the LSTM model is better at generating original, rhyming lyrics. 6.4 Style Matching Unfortunately, the correlation numbers do not dic-tate specifically the effectiveness of the LSTM model in the ghostwriting task. Instead, we can look at that max similarity values of both systems when they generate lyrics that produce a rhyme density similar to the average rhyme density of the target rapper. Looking at 100 randomly se-lected verses, Fabolous has an average rhyme den-sity of 0.34. To do our analysis, first we create four regression lines, one for each metric (max similarity and rhyme density) in each model (we do not include the points of high rhyme density). Next we use the two rhyme density lines to deter-mine at which iteration/n value the systems gen-erate a rhyme density of 0.34. After that we plug these numbers into the two similarity lines to de-termine what similarity is needed to achieve the target rhyme density. The n-gram model line has a similarity of 1.28 at this point (above the max value of 1 for the metric), while the LSTM model has a value of 0.59. Based on these numbers, the LSTM model clearly outperforms the n-gram model when it comes to making original lyrics that are similar in style to our target rapper. In this work, we have shown the effectiveness of an LSTM model for generating novel lyrics that are similar in style to a target artist. We com-pare the performance of the LSTM model to a much simpler system: an n-gram model. The re-sults of our experiments show that, as an unsu-pervised, non-template model, the LSTM model is better able to produce novel lyrics that also re-flect the rhyming style of the target artist. In fu-ture work, we plan to use more data to train our model, making it easier for our system to actually identify rhyming pairs and use them in new con-texts. We also plan to encode phoneme features of words to improve rhyme discovery. Furthermore, we plan to generate lyrics from artists with a vary-ing vocabulary size to see if it is easier to generate lyrics for an artist with a smaller vocabulary. In terms of evaluation, we hope to incorporate some method to evaluate the fluency of generated lyrics (Addanki and Wu, 2014). Lastly, to further avoid over-fitting to the training data and reproducing lyrics with a high similarity, we plan to use weight noise (Jim et al., 1996) to regularize our model. We would like to thank the anonymous reviewers for their feedback.

