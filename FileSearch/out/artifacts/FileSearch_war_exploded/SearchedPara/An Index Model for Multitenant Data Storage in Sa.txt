 SaaS (Software as a Service) is a software delivery model in which software and as-sociated data is centrally hosted on the clou d [5]. It is beneficial to leverage economy of scale to reduce average cost of ownership relative to on-premises solutions [4]. Among storage models for SaaS applications, sparse table model is widely used in which data of multiple tenants is stored in a shared sparse table and fields of varying data types can be stored in a flex column based on tenants X  customization [3, 8, 9]. volumes increase steadily. However, most of existing indexing models are not de-signed for SaaS applications and cannot be aware of multitenant properties. 
In this paper, we put forward a feasible multitenant indexing model through estab-lishing appropriate shared and isolated storage for index data. We detach index data based on logic tables rather than tenants, thus preventing the skyrocketing increase of number of physical tables caused by the linear relativity between number of index data tables and number of tenants. And the index data tables are dense, consequently, the model is memory-saving, especially when multiple replicas exist [3]. In addition, we set a threshold for the number of indices that an index data table could sustain, thus achieving load balance and mitigating the negative effects of skew index types. 
The rest paper is organized as follows. The related work is analyzed in section 2. In section 3, we introduce the system architecture and storage model. In section 4, we explain isolation and maintenance strategies for the model. Section 5 shows experi-mental analyses. Section 6 concludes the whole paper and explores future work. Chen [10] proposed a storage model based on multiple sparse tables; each table pos-sesses various numbers of columns by estimates. The most suitable one is chosen to reduce nulls. Obviously, the model cannot dynamically adapt to customization. 
In Force.com platform [1], indices are implemented by synchronously copying data marked for indexing to the corresponding index data table which is based on a pivot table. However, the paper does not describe the schema of index data tables and the isolation strategy of index data. It supplies a direction for a multitenant index model. 
Mei Hui [2] provides Multi-Separated Indexing; they build an index for each tenant rather than for all tenants. It is not efficient since the number of indices grows linearly with the number of tenants and too many indices are created with fierce competitions 
The Cloud Global Index [6] establishes local indexes for each data node and pub-lishes some index nodes to the overlay networ k; thus local indices are located through searches on global indices. However, index data should resident in main memory; and redundant queries exist owing to broadcasting query patterns. Our underlying storage model is based on multiple data nodes, and sparse tables are created in each node on demand. In orde r to reduce number of distributed transac-tions, one replica of a tenant is stored and only stored in one data node; a data node can accommodate multiple replicas though. In a data node, data of a logical table which belongs to multiple tenants is stored in one sparse table. Mixing storage of business data inevitably increases the data volumes an operation manages. For a te-nant, data of different logical tables is stored in different sparse tables in a data node. Business data is stored in specific sparse table columns accordi ng to customization. Columns of a sparse table are of string types. We set an appropriate replica factor for business data and disperse these replicas to different data nodes to balance reading loads. The model supports creating replicas on tenant and logical table level. 
The system architecture is shown in Fig.1. The statistics manager collects requests and load statistics of data nodes to help to generate best execution plans. The transac-tion manager guarantees synchronization of replicas. The router transmits tenants X  requests to appropriate data nodes to achieve load balance. In summary, the data en-gine receives requests, generates optimal execution plans based on metadata and sta-tistics, and then fetches business data from appropriate data nodes; in the meantime, each data node should send table and index statistics to the statistics manager [11]. 
The data storage subsystem from the view of one data node is shown in Fig.2. The logical_ prefix indicates that the table has not been customized by tenants. The guid (globally unique identifier) column is the primary key of a sparse table; the tenID column marks the tenant a record belongs to , other flex columns record business data. Metadata within the dashed box locates in the data engine node. 4.1 Isolation Strategy As one replica of a tenant is stored and only stored in one data node, we manage in-dices in each data node separately. It is un feasible to create physical indices directly in sparse tables; therefore, we copy data marked for indexing to a corresponding in-dex data table. Tenants can create indices independently of one another for a logical table. We will consider both isolated and shared storage mechanism for index data. 
We notice that in SaaS applications, the number of logical tables is relatively stable (about dozens) and is smaller compared to that of tenants; and tenants tend to create indices of the same type (includes data types of the columns and unique constraints) in a logical table. In summary, isolating index data based on logical tables and index types but tenants could decrease the number of index data tables reasonably. 
An index-related query is converted into two queries, one in the index data table and one in the sparse table. A physical index may be shared among multiple tenants, thus memory buffers for index pages are utilized efficiently, because buffer-ing top index pages of a B+ Tree structure in memory will reduce the number of disk I/Os. As for insert or delete operations, owing to synchronization cost of source data, performances are degraded relative to those of operations with native physical indices. 4.2 Physical Structures same data node as the source data. An index structure from the view of a data node is shown in Fig.3. The metadata within the dashed box is stored in the data engine node. 
Index data tables are created on demand. We can get the index data table corres-ponds to an index in the metadata table of index data table -avlb_idx_dat_tab. The degree column records the number of indices sustained by current table. Take the degree value and the record number of this table into account, the system creates a new index data table for current logical table and index type if necessary, thus balanc-ing loads among all workable index data tables. The tenant_index table records meta-data of all indices. We create a physical index on the idxID column and index data columns of each index data table to implement B+ Tree structure. 4.3 Index Management and Index Related DML Index management operations include creating, dropping and rebuilding logical indic-es. Because an operation consists of a metadata management operation and a physical index management operation, it is no longer a pure data definition operation; business data and index data locates in different nodes to metadata; multiple replicas should also be considered; the ACID properties shou ld be guaranteed by the data engine by consolidating corresponding physical operations to an index management operation into a distributed transaction. As creating an index, the most suitable index data table is selected according to degree values and r ecord numbers of all available index data tables. As dropping an index, merge small index data tables if necessary. 
Index related DML (Data Manipulation Language) operations include index-related query operations and synchronization operations between source data and index data brought on by inserting, updating or deleting source data of indexed col-umns. We modified the cost-based optimizer of Mysql to make it be aware of logic indices. As a replica and corresponding index data tables locate in the same data node, ACID properties of the database are guarant eed by consolidating all related physical operations of a logical operation into one local transaction. For each request, the data engine first rewrite the original SQL statement, namely, transform logical tables and columns into physical ones based on customization [7]. In query processing, the op-timizer decides whether or not to adopt an index and select an optimal one based on real-time loads when alternate indices exist. If the adopted index is not a covering index, an index related query operation is transformed into two physical operations. In this section, we analyze our multitenant indexing model which is based on the data management platform of SaaS application delivery platform we have developed. This delivery platform supports ISVs to develop and deliver SaaS applications effectively in traditional development environments. All experiments are based on one replica of a logical table which locates in one data node entirely, as mentioned in section 4.1. We test average execution time of insert and query operations in the pro-totype system to verify validity of the index isolation strategy. Servers possess Intel X5620@2.4GHz processor, 8GB of memory, 500GB*2 of disk capacity with raid1, the operating systems are RHEL5, and the database is Mysql5.5. Clients possess Intel E7500@2.93GHz processor, 4GB of memory, 320GB of disk capacity. 
Each insert operation relates to one of 500 tenants. Each experiment is executed 20 rounds and each one consists of 100 insert operations; we record average execution time for each round, including time of rewriting a SQL statement. The result is shown in Fig.5. For Curve 1, the sparse table is empty and without indices. For Curve 2, the sparse table is empty and each tenant possesses a unique index which is built on a shared logical column. Contrasting these two curves, the performance decreases sig-nificantly owing to maintenance costs of index structures. The condition of curve 3 is same to that of curve 2 other than that each tenant possesses 5000 random records. Contrasting curve 3 with curve 2, the little differences indicate that the index struc-tures can support large data volumes. The condition of curve 4 is same to that of curve 3 other than that a unique concatenated index is created for each tenant on another two shared logical columns. Contrasting cu rve 1, 3, 4, the execution time will increase correspondingly as number of indices increases. 
Each query operation relates to one of 500 tenants, and each tenant possesses 5000 random records. Each experiment is executed 20 rounds and each one consists of 100 query operations. We record the average ex ecution time of each round under condi-tion of being without indices and being with a unique index for each tenant on a shared logical column. The cache is cleaned before each round. The result is shown in Fig.6. Apparently, indices significantly improve performance of query operations, indicating that the indexing model we proposed is effective in common use. In this paper, we proposed a multitenant indexing model based on pivot tables  X  and and experimental analyses show that this model improves performance of query oper-ations significantly and performance losses of other operations are mild; and the number of index data tables is controlled reasonably. In the future, we will consum-mate hierarchies of the indexing model, tune the candidate index selection mechanism to further optimize performances of this model. Acknowledgments. This work is funded by National Natural Science Foundation of China under Grant No. 61272241;Natural Science Foundation of Shandong Province of China under Grant No. ZR2010FQ010, No. ZR2010FQ026;Science and Technology Development Plan Project of Shandong Province No.2012GGX27036; Independent Innovation Foundation of Shandong University under Grant No. 2012TS075,No.2012TS074. 
