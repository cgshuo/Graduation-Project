 A central problem in computational neuroscience is to develop functional models that can accurately describe the relationship between external variables and neural spike trains. All attempts to measure information transmission in the nervous system are fundamentally attempts to quantify this relation-times generated in response to an external stimulus X .
 Recent work on the neural coding problem has focused on extensions of the Linear-Nonlinear-Poisson (LNP)  X  X ascade X  encoding model, which describes the neural encoding process using a linear receptive field, a point nonlinearity, and an inhomogeneous Poisson spiking process [2, 3]. While this model provides a simple, tractable tool for characterizing neural responses, one obvious shortcoming is the assumption of Poisson spiking. Neural spike trains exhibit spike-history depen-dencies (e.g., refractoriness, bursting, adaptation), violating the Poisson assumption that spikes in disjoint time intervals are independent. Such dependencies, moreover, have been shown to be es-sential for extracting complete stimulus information from spike trains in a variety of brain areas [4, 5, 6, 7, 8, 9, 10, 11].
 Previous work has considered two basic approaches for incorporating spike-history dependencies into neural encoding models. One approach is to model spiking as a non-Poisson inhomogeneous renewal process (e.g., a modulated gamma process [12, 13, 14, 15]). Under this approach, spike times are Markovian, depending on the most recent spike time via a (non-exponential) renewal density, which may be rescaled in proportion to the instantaneous spike rate. A second approach is to use a conditionally Poisson process in which the intensity (or spike rate) is a function of the recent spiking history [4, 16, 17, 18, 19, 20]. The output of such a model is a conditionally Poisson process, but not Poisson, since the spike rate itself depends on the spike history.
 The time-rescaling theorem, described elegantly for applications to neuroscience in [1] , provides a powerful tool for connecting these two basic approaches, which is the primary focus of this paper. We begin by reviewing inhomogeneous renewal models and generalized linear model point process models for neural spike trains. 2.1 Definitions and Terminology ally, this intensity is a function of some external variable (e.g., a visual stimulus). The cumulative intensity function is given by the integrated intensity, and is also known as the time-rescaling transform [1]. This function rescales the original spike times into spikes from a (homogeneous) renewal process, that is, a process in which the intervals are i.i.d. samples from a fixed distribution. Let { u i } denote the inter-spike intervals (ISIs) of the rescaled process, which are given by the integral of the intensity between successive spikes, i.e., Intuitively, this transformation stretches time in proportion to the spike rate  X  ( t ) , so that when the rate  X  ( t ) is high, ISIs are lengthened and when  X  ( t ) is low, ISIs are compressed. (See fig. 1B for illustration). Let q ( u ) denote the renewal density , the probability density function from which the rescaled-time intervals { u i } are drawn. A Poisson process arises if q is exponential, q ( u ) = e  X  u ; for any other density, the probability of spiking depends on the most recent spike time. For example, if q ( u ) is zero for u  X  [0 ,a ] , the neuron exhibits a refractory period (whose duration varies with  X  ( t ) ). To sample from this model (illustrated in fig. 1B), we can draw independent intervals u i from re-newal density q ( u ) , then apply the inverse time-rescaling transform to obtain ISIs in real time: We will generally define the intensity function (which we will refer to as the base intensity 2 ) in terms of a linear-nonlinear cascade, with linear dependence on some external covariates of the response (optionally including spike-history), followed by a point nonlinearity. The intensity in this case can be written: where x t is a vector representing the stimulus at time t , k is a stimulus filter, y t is a vector repre-senting the spike history at t , and h is a spike-history filter. We assume that the nonlinearity f is fixed. 2.2 The conditional renewal model We refer to the most general version of this model, in which  X  ( t ) is allowed to depend on both conditional renewal (CR) model (see fig. 1A). The output of this model forms an inhomogeneous renewal process conditioned on the process history. Although it is mathematically straightforward to define such a model, to our knowledge, no previous work has sought to incorporate both real-time (via h ) and rescaled-time (via q ) dependencies in a single model.
 Specific (restricted) cases of the CR model include the generalized linear model (GLM) [17], and the modulated renewal model with  X  = f ( x  X  k ) and q a right-skewed, non-exponential renewal density [13, 15]. (Popular choices for q include gamma, inverse Gaussian, and log-normal distributions). The conditional probability distribution over spike times { t i } given the external variables X can be derived using the time-rescaling transformation. In rescaled time, the CR model specifies a probability over the ISIs, A change-of-variables t i =  X   X  1 t times: This probability, considered as a function of the parameters defining  X  ( t ) and q ( u ) , is the likelihood function for the CR model, as derived in [13]. 3 The log-likelihood function can be approximated in discrete time, with bin-size dt taken small enough to ensure  X  1 spike per bin: where t i indicates the bin for the i th spike. This approximation becomes exact in the limit as dt  X  0 . We now turn to the tractability of estimating the CR model parameters from data. Here, we present an extension to the results of [21], which proved a convexity condition for maximum-likelihood estimation of a conditionally Poisson encoding model (i.e., generalized linear model). Specifically, [21] showed that the log-likelihood for the filter parameters  X  = { k , h } is concave (i.e., has no non-global local maxima) if the nonlinear function f is both convex and log-concave (meaning log f is concave). Under these conditions 4 , minimizing the negative log-likelihood is a convex optimization problem.
 By extension, we can ask whether the estimation problem remains convex when we relax the Poisson assumption and allow for a non-exponential renewal density q . Let us write the log-likelihood function for the linear filter parameters  X  = [ k T , h T ] T as D = {{ t i } , { X ( t ) }} represents the full set of observed data. The condition we obtain is: Theorem 1. The CR model log-likelihood L { D,q } (  X  ) is concave in the filter parameters  X  , for any observed data D , if: (1) the nonlinearity f is convex and log-concave; and (2) the renewal density q is log-concave and non-increasing on (0 ,  X  ] .
 Proof. It suffices to show that both terms in the equation (8) are concave in  X  , since the sum of two concave functions is concave. The first term is obviously concave, since log f is concave. For the second term, note that R f ( X  X   X  ) is a convex function, since it is the integral of a convex function over a convex region. Then log q [ R f ( X  X   X  )] is a concave, non-increasing function of a convex function, since log q is concave and non-increasing; such a function is necessarily concave. 5 The second term is therefore also a sum of concave functions, and thus concave.
 Maximum likelihood filter estimation under the CR model is therefore a convex problem so long as the renewal density q is both log-concave and non-increasing. This restriction rules out a variety of renewal densities that are commonly employed to model neural data [13, 14, 15]. Specifically, the log-normal and inverse-Gaussian densities both have increasing regimes on a subset of [0 ,  X  ) , as does the gamma density q ( u )  X  u  X   X  1 e  X  u X  when  X  &gt; 1 . For  X  &lt; 1 , gamma fails to be log-concave, meaning that the only gamma density satisfying both conditions is the exponential (  X  = 1 ). There are nevertheless many densities (besides the exponential) for which these conditions are met, including Unfortunately, no density in this family can exhibit refractory effects, since this would require a q that is initially zero and then rises. From an estimation standpoint, this suggests that it is easier to incorporate certain well-known spike-history dependencies using recurrent spike-history filters (i.e., using the GLM framework) than via a non-Poisson renewal density.
 An important corollary of this convexity result is that the decoding problem of estimating stimuli { x t } from a set of observed spike times { t i } using the maximum of the posterior (i.e., computing the MAP estimate) is also a convex problem under the same restrictions on f and q , so long as the prior over stimuli is log-concave. In practice, we may wish to optimize both the filter parameters governing the base intensity  X  ( t ) and the renewal density q , which is not in general a convex problem. We may proceed, however, bearing in mind that gradient ascent may not achieve the global maximum of the likelihood function. parametrically estimate renewal properties using a density on the unit interval. Let us define the mapping which is the cumulative density function (cdf) for the intervals from a conditionally Poisson process with cumulative intensity  X ( t ) . This function maps spikes from a conditionally Poisson process to i.i.d. samples from U [0 , 1] . Any discrepancy between the distribution of { v i } and the uniform dis-tribution represents failures of a Poisson model to correctly describe the renewal statistics. (This is the central idea underlying time-rescaling based goodness-of-fit test, which we will discuss shortly). We propose to estimate a density  X  ( v ) for the rescaled intervals { v i } using cubic splines (piecewise 3rd-order polynomials with continuous 2nd derivatives), with evenly spaced knots on the interval [0 , 1] . 6 This allows us to rewrite the likelihood function (6) as the product of two identifiable terms: where the first term is the likelihood under the conditional Poisson model [17], and the second is the probability of the rescaled intervals { v i } under the density  X  ( v ) . This formulation allows us to separate the (real-time) contributions of the intensity function under the assumption of conditionally Poisson spiking, from the (rescaled-time) contributions of a non-Poisson renewal density. (For a conditionally Poisson process,  X  is the uniform density on [0 , 1] , and makes zero contribution to the total log-likelihood).
 We fit this model to simulated data (fig. 2), and to real neural data using alternating coordinate ascent of the filter parameters and the renewal density parameters (fig. 4). In fig. 2, we plot the renewal distribution  X  q ( u ) (red trace), which can be obtained from the estimated  X   X  ( v ) via the transformation  X  q ( u ) =  X   X  (1  X  e  X  u ) e  X  u . 4.1 Incorporating dependencies between intervals The cdf defined by the CR model,  X ( v ) = R v 0  X  ( s ) ds , maps the transformed ISIs { v i } so that the marginal distribution over z i =  X ( v i ) is uniform on [0 , 1] . However, there is no guarantee that the resulting random variables are independent, as assumed in the likelihood (eq. 10). We can examine dependencies between successive ISIs by making a scatter plot of pairs ( z i ,z i +1 ) (see fig. 3). De-partures from independence can then be modeled by introducing a nonparametric estimator for the conditional distribution  X  ( z i | z i  X  1 ) . In this case, the likelihood becomes which now has three terms, corresponding (respectively) to the effects of the base intensity, non-conditionally Poisson renewal properties, and dependencies between successive intervals. If a particular point-process model provides an accurate description of a neuron X  X  response, then the cumulative intensity function defines a mapping from the real time to rescaled-time such that the rescaled interspike intervals have a common distribution. Time-rescaling can therefore be used as a tool for assessing the goodness-of-fit of a point process model [1, 22]. Specifically, after remapping a set of observed spike times according to the (model-defined) cumulative intensity, one can perform a distributional test (e.g., Kolmogorov-Smirnov, or KS test) to assess whether the rescaled intervals have the expected distribution 7 . For example, for a conditionally Poisson model, the KS test can be applied to the rescaled intervals { v i } (eq. 9) to assess their fit to a uniform distribution. This approach to model validation has grown in popularity in recent years [14, 23], and has in some instances been used as the only metric for comparing models. We wish to point out that time-rescaling based tests are sensitive to one kind of error (i.e., errors in modeling rescaled ISIs), but may be insensitive to other kinds of model error (i.e., errors in modeling the stimulus-dependent spike rate). Inspection of the CR model likelihood (eq. 10), makes it clear that time-rescaling based goodness-of-fit tests are sensitive only to accuracy with which  X  ( v ) (or equivalently, q ( u ) ) models the rescaled intervals. The test can in fact be independent of the accuracy with which the model describes the transformation from stimulus to spikes, a point that we illustrate with an (admittedly contrived) example in fig. 2.
 For this example, spikes were genereated from a  X  X rue X  model (denoted  X  X  X ), a CR model with a biphasic stimulus filter and a gamma renewal density (  X  = 10 ). Responses from this model were fit by two sub-optimal approximate models:  X  X  X , a Poisson (LNP) model, which was specified to have the correct stimulus filter; and  X  X  X , a CR model in which the stimulus filter was mis-specified (set to the negative of the true filter), and a renewal density  X  ( v ) was estimated non-parametrically from the rescaled intervals { v i } (rescaled under the intensity defined by this model).
 Although the time-varying spike-rate predictions of model (c) were badly mis-matched to those of model (a) (fig. 2, middle), a KS-plot (upper right) shows that (c) exhibits near perfect goodness-of-fit on a time-rescaling test, which the Poisson model (b) fails badly. We cross-validated these models by computing the log-likelihood of novel data, which provides a measure of predictive information about novel spike trains in units of bits/s [24, 18]. Using this measure, the  X  X rue X  model (a) provides approximately 24 bits/s about the spike response to a novel stimulus. The Poisson model (b) captures only 8 bits/s, but is still much more accurate than the mis-specified renewal model (c), for which homogeneous Poisson process with the correct rate).
 Fig. 3 shows that model (c) can be improved by modeling the dependencies between successive rescaled interspike intervals. We constructed a spline-based non-parametric estimate of the density wise dependency structure, and fit a cubic spline with 10 evenly spaced knots on [0,1] to the density within each bin). Rescaling these intervals using the cdf of the augmented model yields intervals that are both uniform on [0 , 1] and approximately independent (fig. 3, right; independence for non-successive intervals not shown). The augmented model raises the cross-validation score of model (c) to 1 bit/s, meaning that by incorporating dependencies between intervals, the model carries slightly more predictive information than a homogeneous Poisson model, despite the mis-specified stimu-lus filter. However, this model X  X espite passing time-rescaling tests of both marginal distribution and independence X  X till carries less information about spike times than the inhomogeneous Poisson model (b). Figure 4 shows several specific cases of the CR model fit to spiking data from an ON parasol cell in primate retina, which was visually stimulated with binary spatio-temporal white noise (i.e., flicker-ing checkerboard, [18]). We fit parameters for the CR model with and without spike-history filters, and with and without a non-Poisson renewal density (estimated non-parametrically as described above).
 As expected, a non-parametric renewal density allows for remapping of ISIs to the correct (uniform) marginal distribution in rescaled time (fig. 4, left), and leads to near-perfect scores on the time-rescaling goodness-of-fit test (middle). Even when incorporating spike-history filters, the model with conditionally Poisson spiking (red) fails the time-rescaling test at the 95% level, though not so badly as the the inhomogeneous Poisson model (blue). However, the conditional Poisson model with spike-history filter (red) outperforms the non-parametric renewal model without spike-history filter (dark gray) on likelihood-based cross-validation, carrying 14% more predictive information. For this neuron, incorporating non-Poisson renewal properties into a model with spike history dependent intensity (light gray) provides only a modest ( &lt; 1%) increase in cross-validation performance. Thus, in addition to being more tractable for estimation, it appears that the generalized linear modeling framework captures spike-train dependencies more accurately than a non-Poisson renewal process (at least for this neuron). We are in the process of applying this analysis to more data. We have connected two basic approaches for incorporating spike-history effects into neural encod-ing models: (1) non-Poisson renewal processes; and (2) conditionally Poisson processes with an intensity that depends on spike train history. We have shown that both kinds of effects can be re-garded as special cases of a conditional renewal (CR) process model, and have formulated the model likelihood in a manner that separates the contributions from these two kinds of mechanisms. Additionally, we have derived a condition on the CR model renewal density under which the likeli-hood function over filter parameters is log-concave, guaranteeing that ML estimation of filters (and MAP stimulus decoding) is a convex optimization problem.
 We have shown that incorporating a non-parametric estimate of the CR model renewal density en-sures near-perfect performance on the time-rescaling goodness-of-fit test, even when the model itself has little predictive accuracy (e.g., due to a poor model of the base intensity). Thus, we would argue that K-S tests based on the time-rescaled interspike intervals should not be used in isolation, but rather in conjunction with other tools for model comparison (e.g., cross-validated log-likelihood). Failure under the time-rescaling test indicates that model performance may be improved by incor-porating a non-Poisson renewal density, which as we have shown, may be estimated directly from rescaled intervals.
 Finally, we have applied the CR model to neural data, and shown that it can capture spike-history dependencies in both real and rescaled time. In future work, we will examine larger datasets and explore whether rescaled-time or real-time models provide more accurate descriptions of the depen-dencies in spike trains from a wider variety of neural datasets.
 Acknowledgments Thanks to E. J. Chichilnisky, A. M. Litke, A. Sher and J. Shlens for retinal data, and to J. Shlens and L. Paninski for helpful discussions.
