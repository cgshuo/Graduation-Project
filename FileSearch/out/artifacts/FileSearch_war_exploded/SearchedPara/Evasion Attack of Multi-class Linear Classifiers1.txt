 Researchers and engineers of information s ecurity have successfully deployed systems spam, recognizing threats, etc. [2,12]. These systems typically contain a classifier that flags certain instances as malicious based on a set of features. Unfortunately, evaded malicious instances that fail to be detected are inevitable for any known classifier. To make matters worse, there is evidence showing that adversaries have investigated sev-eral approaches to evade the classifier by disguising malicious instance as normal in-stances. For example, spammers can add unrel ated words, sentences or even paragraphs to the junk mail for avoiding detection of the spam filter [11]. Furthermore, spammers can embed the text message in an image. By adding varied background and distorting the image, the generated junk message can be difficult for OCR systems to identify but easy for humans to interpret [7]. As a reaction to adversarial attempts, authors of [5] employed a cost-sensitive game theoretic approach to preemptively adapt the decision boundary of a classifier by computing the adversary X  X  optimal strategy. Moreover, sev-eral improved spam filters that are more effect ive in adversarial environments have been proposed [7,3].

The ongoing war between adversaries and classifiers pressures machine learning re-searchers to reconsider the vulnerability of classifier in adversarial environments. The problem of evasion attack is posed and a query algorithm for evading linear classifiers is presented [10]. Given a malicious instance, the goal of the adversary is finding a dis-guised instance with the minimal cost to d eceive the classifier. Recently, the evasion problem has been extended to the binary convex-inducing classifiers [13].

We continue investigate the vulnerability of classifiers to the evasion attack and gen-eralize this problem to the family of multi-cl ass linear classifiers; e.g. linear support promising learning techniques for large sparse data with a huge number of instances and features. We propose an adversarial query algorithm for searching minimal-cost disguised instances. We believe that revealing a scar on the multi-class classifier is the only way to fix it in the future. The contributions of this paper are: 2. We prove that effective evasion attack based on the linear probing is feasible under 3. We propose a query algorithm for disguising an adversarial instance as any other Let X = { ( x 1 ,...,x D )  X  R D | L  X  x d  X  U for all d } be the feature space . Each component of an instance x  X  X  is a feature bounded by L and U which we denote terms  X  d . We assume that the feature space repres entation is known to the adversary, thus the adversary can query any point in X . 2.1 Multi-class Linear Classifier The target classifier f is a mapping from feature space X to its response space K ; i.e. f : X X  X  . We restrict our attention to multi-class linear classifiers and use K = { 1 ,...,K } ,K  X  2 so that where k =1 ,...,K and w k  X  R D ,b k  X  R . Decision boundaries between class k and other classes are characterized by w k and b k . We assume that w 1 ,..., w K are linearly independent. The classifier f partitions X into K sets; i.e. X k = { x  X  X | f ( x )= k } . 2.2 Attack of Adversary As a motivating example, consider a text classifier that categorizes incoming emails order to attract potential consumers while remaining inconspicuous.

We assume the adversary X  X  attack will be against a fixed f so the learning method of decision boundaries and the training data used to establish the classifier are irrelevant. The adversary does not know any parameter of f but can observe f ( x ) for any x by issuing a membership query . In fact, there are a variety of domain specific mechanisms that an adversary can employ to observe the classifier X  X  response to a query. Moreover, the adversary is only aware of an adversarial instance x A in some class, and has no information about instances in other classes. This differs from previous work which the most desired instance of adversary; e.g. the original spam. The adversary attempts to disguise x A so that it can be recognized as other classes.
 2.3 Adversarial Cost We assume that the adversary has the access to an adversarial cost function a ( x , y ): X X X X  R stances x , y in X from the adversary X  X  prospective. We focus on a linear cost function which measures the weighted 1 distance so that where 0 &lt;e d &lt;  X  represents the cost coefficient of the adversary associates with the d th feature, allowing that some features may be more important than others. In of using some instances as compared to others. Moreover, we use B ( y ,C )= { x  X  X| a ( x , y )  X  C } to denote the cost ball centered at y with cost no more than C . In generalizing work [10], we alter the definition of minimal adversarial cost (MAC). Given a fixed classifier f and an adversarial cost function a we define the MAC of class k with respect to an instance y to be the value 2.4 Disguised Instances We now introduce some instances with special adversarial cost that the adversary is interested in. First of all, instances with cost of MAC ( k, y ) are termed instances of minimal adversarial cost (IMAC), which is formally defined as naive way for an adversary to find the IMAC is performing a brute-force search. That is, the adversary randomly samples points in X and updates the best found instance repetitively. To formulate this idea, we further extend the definition of IMAC. Assume &amp; X is the set of adversary X  X  sampled or observed instances so far and &amp; X X  X  ,wedefine instance of sample minimal adversarial cost (ISMAC) of class k with respect to an instance y to be the value Note, that in practice the exact decision boundary is unknown to the adversary, thus finding exact value of IMAC becomes an infeasible task. Nonetheless, it is still tractable to approximate IMAC by finding -IMAC, which is defined as follows That is, every instance in -IMAC ( k, y ) has the adversarial cost no more than a fac--IMAC ( k, x A ) for all classes k = f ( x A ) while keeping as small as possible. We discuss the evasion attack from a theoreti cal point of view. Specifically, by describ-ing the feature space as a set of convex polytopes, we show that IMAC must be attained on the convex surface. Under a reasonable assu mption of adversarial cost function, ef-fective evasion attack can be performed by linear probing. Finally, we derive bounds probing.
 Lemma 1. Let X k = { x  X  X | f ( x )= k } , where the classifier f is defined in (1). Then X k is a closed convex polytope.
 Proof. Let x be a point in X k .As x  X  X  it follows that where 1 D is a D -dimensional unit vector (1 ,..., 1) . Moreover, since f ( x )= k ,it follows that  X  Thus, the foregoing linear inequalities define an intersection of at most ( K +2 D  X  1) half-spaces. Denote H + i = { x  X  X | -w i x T  X  &amp; b i } ,where 1  X  i  X  ( K +2 D  X  1) .Wehave X k = i H + i , which establishes a half-space representation of convex polytope [8,14].
 Lemma 1 indicates that the classifier f decomposes R D into K convex polytopes. Following the notations and formulations introduced in [8], we represent a hyperplane H i as the boundary of a half-space  X  X  + i ;i.e. H i =  X  X  + i = &amp; b } .Let X { none half-space in H k is defined by (3). Moreover, we define the p th facet of X k as F Theorem 1. Let y be an instance in X and k  X  X \ f ( y ) .Let x be an instance in IMAC ( k, y ) as defined in Section 2.3. Then x must be attained on the convex surface  X 
X Proof. We first show the existence of IMAC ( k, y ) . By Lemma 1, X k defines a feasible region. Thus minimizing a ( x , y ) on X k is a solvable problem. Secondly, X k is bounded in each direction of the gradient of a ( x , y ) , which implies that IMAC ( k, y ) exists.
We now prove that x must lie on  X  X k by contrapositive. Assume that x is not on  X 
X y with cost no more than a ( x , y ) . Due to the convexity of X k and B ( y ,C ) ,wehave less than a ( x , y ) , which implies that x is not IMAC ( k, y ) . Theorem 1 restricts the searching of IMAC to the convex surface. In particular, when cost coefficients are equal, e.g. e 1 =  X  X  X  = e D , we can show that searching in all axis-aligned directions gives at least one IMAC.
 Theorem 2. Let y be an instance in X such that X f ( y )  X  int X .Let P be the number of R } ,where d  X  X  1 ,...,D } .Let Q = { G each element differs from y on only one dimension. If the adversarial cost function defined in (2) has equal cost coefficients, then there exists at least one x  X  X  such that x is IMAC ( f ( x ) , y ) .
 of intersection of the lines G d with the hyperplanes H p ;i.e. I = { G d  X  H p | d = 1 ,...,D,p =1 ,...,P } .Let x =argmin x  X  X  a ( x , y ) .Then x is our desired instance. We prove that x  X  X  by contrapositive. Suppose x /  X  X  , due to the convexity of X f ( y ) , the line segment [ x , y ] intersects  X  point as z ,then z differs from y on only one dimension and a ( z , y ) &lt;a ( x , y ) .
Next, we prove x is IMAC ( f ( x ) , y ) by contrapositive. Let B ( y ,C ) denote the reg-cost ball has the same distance of C with y . Suppose x is not IMAC ( f ( x ) , y ) ,then there exists z  X  X  f ( x )  X  int B ( y ,C ) . By Theorem 1, z and x must lie on the same facet, which is defined by a hyperplane H  X  .Let Q  X  be intersection points of H  X  with lines G 1 ,...,G D ;i.e. Q  X  = { G d  X  H  X  | d =1 ,...,D } . Then there exists at least one point v  X  X   X  such that v  X  int B ( y ,C ) . Due to the regularity of B ( y ,C ) ,wehave a ( v , y ) &lt;a ( x , y ) .

We now define special convex sets for approximating -IMAC near the convex sur-and the corresponding exterior parallel body is defined as P + ( k )= Moreover, the interior margin of X k is M  X  ( k )= X k \P  X  ( k ) and the corresponding exterior margin is M + ( k )= P + ( k ) \X k . By relaxing the searching scope from the convex surface to a margin in the distance , Theorem 1 and Theorem 2 immediately imply the following results.
 Corollary 1. Let y be an instance in X and k  X  X \ f ( y ) . For all &gt; 0 such that M  X  ( k ) =  X  , -IMAC ( k, y )  X  X   X  ( k ) .
 Corollary 2. Let y be an instance in X and be a positive number such that P + ( f ( y )) facet, where p = { 1 ,...,P } .Let G d = { y +  X   X  d |  X   X  R } ,where d  X  X  1 ,...,D } . Let Q = { G d  X  F p | d =1 ,...,D,p =1 ,...,P } , in which each element differs from y on only one dimension. If adversarial cost function defined in (2) has equal cost coefficients, then there exists at least one x  X  X  such that x is in -IMAC ( f ( x ) , y ) . Corollary 1 and Corollary 2 point out an efficient way of approximating -IMAC with linear probing, which forms the backbone of our proposed algorithm in Section 4.
Finally, we consider the vulnerability of a multi-class linear classifier to linear prob-ing. The problem arises of detecting convex polytopes in X with a random line. As one can easily scale any hypercube to a unit hypercube with edge length 1 , our proof is restricted to the unit hypercube in R D .
 Definition 1 (Vulnerability to Linear Probing). Let X =[0 , 1] D , and X 1 ,..., X K be the sets that tile X according to the classifier f : X X  X  1 ,...,K } , with K  X  2 .Let G be a random line in R D that intersects X . Denote Z the number of sets intersect G ,the vulnerability of classifier f to linear probing is measured by the expectation of Z . When E Z is small, a random line intersects small number of decision regions and not much information is leaked to the adversary. Thus, a robust multi-class classifier that resists linear probing should have a small value of E Z .
 Theorem 3. Let f be the multi-class linear classifier defined in (1), then the expectation of Z is bounded by 1 &lt; E Z&lt; 1+ Proof. By Lemma 1, we have K convex polytopes X 1 ,..., X K .Let F be the union of all facets of polytopes. Observe that each time the line touches a convex polytope, it only touches its surface twice. The exit point is the entrance point for a new polytope, except at the end-point. Thus, the variable that we are interested in can be represented as where | X | represents the cardinality of a set. Obviously, E Z is bounded by 1 &lt; E Z&lt; K . We will give a tighter bound in the sequel.

Let G be the class of all lines of R D ,and  X  be the measure of G . Following the notation introduced in [15], we denote the measure of G that meet a fixed bounded convex set C as  X  ( G ; G X  X  =  X  ) . Considering an independent Poisson point process on G intensity measure  X  ,let N be the number of lines intersecting X . We emphasize that N is a finite number, so that one can label them independently G 1 ,...,G N . It follows that G n ,n =1 ,...,N are i.i.d. . Given a fixed classifier f ,wehave Remark that G 1 ,...,G N follow the Possion point process, we have E N =  X  ( G ; G X  X =  X  ) . Therefore we can rewrite (5) as, Next, we compute E N n =1 |F  X  G n | .Let M = |F| . Due to the convexity of X k ,any given line can hit a facet no more than once. Therefore, we have By substituting (7) into (6) we obtain Assume that  X  is translation invariant, by Cauchy-Crofton formula we can rewrite (8) as where A (  X  ) denotes the surface area 2 . Note, that the numerator of (9) depends on the to compute the exact value of E Z . Nonetheless, we can bound the expectation by using the fact A ( X ) &lt; M m =1 A ( F m ) &lt;A ( X )+ Remark that the surface area A ( X ) of a unit hypercube is 2 D . We yield which concludes our proof.
 We remark that Theorem 3 implies a way to construct a robust classifier that resists evasion algorithm based on linear probing, e.g. by jointly minimizing (9) and the error function in the training procedure. Based on theoretical results, we present an algorithm for deceiving the multi-class linear classifier by disguising the adversarial instance x A as other classes with approximately minimal cost, while issuing polynomially many queries in: the number of features, the range of feature, the number of classes and the number of iterations.
 An outline of our searching approach is presented in Algorithms 1 to 3. We use a K  X  D matrix  X  for storing ISMAC of K classes and an array C of length K for the corresponding adversarial cost of these instances. The scalar value W represents the maximal cost of all optimum instances. Additionally, we need a K  X  I matrix T for storing the searching path of op timum instances in each iteration. The k th row of matrix  X  is denoted as  X [ k, :] . We consider  X  ,T,C,W as global variables so they are accessible in every scope. After initializing variables, our main routine MLCEvading (Algorithm 1 line 4) first invokes MDSearch (Algorithm 2) to search instances that is close to the starting point x A in all classes and saves them to  X  . Then it repetitively selects instances from  X  as new starting points and searches instances with lower ad-versarial cost (Algorithm 3 line 6 X 7). The whole procedure iterates I times. Finally, we obtain  X [ k, :] as the approximation of -IMAC ( k, x A ) .

We begin by describing RBSearch in Algorithm 3, a subroutine for searching in-stances near decision boundaries along dimension d . Essentially, given an instance x , an upper bound u and a lower bound l , we perform a recursive binary search on the line segment { x +  X   X  d | l  X   X   X  u } through x . The effectiveness of this recursive algorithm another class. In particular, if the line segment meets an exterior margin M + ( k ) and -IMAC ( k, x ) is the intersection, then RBSearch finds an -IMAC. Otherwise, when the found instance y yields lower adversarial cost than instance in  X  does, Algorithm 4 is invoked to update  X  . The time complexity of RBSearch is O ( u  X  l ) .

We next describe Algorithm 2. Given x which is known as ISMAC ( k, x A ) and the current maximum cost W , the algorithm iterates ( D  X  1) times on P + ( X f ( x ) ) for finding instances with cost lower than W . Additionally, we introduce two heuristics to prune unnecessary queries. First, the searched dimension in the previous iteration of x is omitted. Second, we restrict the upper and lower bound of the searching scope on each dimension. Specifically, knowing W and a ( x , x A )= c , we only allow RBSearch to find instance in [ x d  X  W  X  c e adversarial cost higher than W . This pruning is significant when we have obtained ISMAC for every class. Special attentio n must be paid to searched dimensions of x (see Algorithm 2 line 5 X 7). Namely, if d is a searched dimension before the ( i  X  1) th iteration, then we relax the searching scope to [ x A d  X  W  X  c e cost instances will be missed.

Algorithm 1. Query algorithm for evasion of multi-class linear classifiers Algorithm 2. Multi-dimensional search from ISMAC ( k, x A ) Algorithm 3. Recursive binary search on dimension d
Algorithm 4. Update ISMAC ( k, x A ) Theorem 4. The asymptotic time complexity of our algorithm is O ( U  X  L DKI ) . Proof. Follows from the correctness of the algorithm and the fact that the time com-plexity of RBSearch is O ( u  X  l ) . We demonstrate the algorithm 3 on two real-world data sets, the 20 -newsgroups 4 and the 10 -Japanese female face 5 . On the newsgroups data set, the task of the adversary is to evade a text classifier by disguising a commercial spam as a message in other top-ics. On the face data set, the task of adversary is to deceive the classifier by disguising a suspect X  X  face as an innocent. We employ LIBLINEAR [6] package to build target multi-class linear classifiers, which return labels of queried instances. The cost coeffi-cients are set to e 1 =  X  X  X  = e D =1 for both tasks. For the groundtruth solution, we directly solve the optimization problem with linear constraints (3) and (4) by using the models X  parameters. We then m easure the average empirical for ( K  X  1) classes, which of disguised instance of class k . Evidently, small 0 indicates better approximation of IMAC. 5.1 Spam Disguising The training data used to configure the newsletter classifier consists of 7 , 505 docu-ments, which are partitioned evenly across 20 different newsgroups. Each document is represented as a 61 , 188 -dimensional vector, where each component is the number of occurrences of a word. The accuracy of the classifier on training data is 100% for every class. We set the category  X  X isc.forsale X  as the adversarial class. That is, given a random document in  X  X isc.forsale X , the adversary attempts to disguise this docu-ment as from other category; e.g.  X  X ec.sport.baseball X . Parameters of the algorithm are K =20 ,L =0 ,U = 100 ,I =10 , =1 . The adversary is restricted to query at most 10 , 000 times. The adversarial cost of each class is depicted in Fig. 1 (left). 5.2 Face Camouflage The training data contains 210 gray-scaled images of 7 facial expressions (each with 3 images) posed by 10 Japanese female subjects. Each image is represented by a 100 -dimensional vector using pri ncipal components. The accuracy of the classifier on train-ing data is 100% for every class. We randomly pick a subject as an imaginary suspect. Given a face image of the suspect, the adversary camouflage this face to make it be classified as other subjects. Parameters of the algorithm are K =10 ,L =  X  10 5 ,U = 10 5 ,I =10 , =1 . The adversary is restricted to query at most 10 , 000 times. The adversarial cost of each class is depicted in Fig. 1 (right). Moreover, we visualize dis-guised faces in Fig. 2. Observe that many disguised faces are similar to the suspect X  X  directly demonstrates the effectiveness of our algorithm.

It has not escaped our notice that an experienced adversary with certain domain knowledge can reduce the number of queries by careful selecting cost function and employing heuristics. Nonetheless, the goa l of this paper is not to design real attacks but rather examine the correctness and effectiveness of our algorithm so as to understand vulnerabilities of classifiers. Adversary and classifier are Yin and Yang of information security. We believe that un-in the future. In this paper, we showed that multi-class linear classifiers are vulnerable to the evasion attack and presented an algorith m for disguising the adversarial instance. Future work includes generalizing the evasion attack problem to the family of general multi-class classifier with non linear decision boundaries.

