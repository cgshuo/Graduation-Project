 In the last decade, there has been much research at the interface of computer science and game theory (see e.g. [ 19 , 22 ]). One fundamental class of computational problems in game theory is the computation of solution concepts of a finite game. Much of current research on computation of solution concepts has focused on complete-information games , in which the game being played is common knowledge among the players. However, in many multi-agent situations, players are uncertain about the game being played. Harsanyi [ 10 ] proposed games of incomplete information (or Bayesian games) as a mathematical model of such interactions. Bayesian games have found many applications in economics, including most notably auction theory and mechanism design. Our interest is in computing with Bayesian games, and particularly in identifying sample Bayes-Nash equilibrium. There are two key obstacles to performing such computations efficiently. The first is representational: the straightforward tabular representation of Bayesian game utility functions (the Bayesian Normal Form) requires space exponential in the number of players. For large games, it becomes infeasible to store the game in memory, and performing even computations that are polynomial time in the input size are impractical. An analogous obstacle arises in the context of complete-information games: there the standard representation (normal form) also requires space exponential in the number of players. The second obstacle is the lack of existing algorithms for identifying sample Bayes-Nash equilibrium for arbitrary Bayesian games. Harsanyi [ 10 ] showed that a Bayesian game can be interpreted as an equivalent complete-information game via  X  X nduced normal form X  or  X  X gent form X  interpretations. Thus one approach is to interpret a Bayesian game as a complete-information game, enabling the use of existing Nash-equilibrium-finding algorithms (e.g. [ 24 , 9 ]). However, generating the normal form representations under both of these complete-information interpretations causes a further exponential blowup in representation size. Most games of interest have highly-structured payoff functions, and thus it is possible to overcome the first obstacle by representing them compactly. This has been done for complete information games through (e.g.) the graphical games [ 16 ] and Action-Graph Games (AGGs) [ 1 ] representations. In this paper we propose Bayesian Action-Graph Games (BAGGs), a compact representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games with commonly encountered types of structure. The type profile distribution is represented as a Bayesian network, which can exploit conditional independence structure among the types. BAGGs represent utility functions in a way similar to the AGG representation, and like AGGs, are able to exploit anonymity and action-specific utility independencies. Furthermore, BAGGs can compactly express Bayesian games exhibiting type-specific independence : each player X  X  utility function can have different kinds of structure depending on her instantiated type. We provide an algorithm for computing expected utility in BAGGs, a key step in many algorithms for game-theoretic solution concepts. Our approach interprets expected utility computation as a probabilistic inference problem on an induced Bayesian Network . In particular, our algorithm runs in polynomial time for the important case of independent type distributions. To compute Bayes-Nash equilibria for BAGGs, we consider the agent form interpretation of the BAGG. Although a naive normal form representation would require an exponential blowup, BAGGs can act as a compact representation of the agent form. Computational tasks on the agent form can be done efficiently by leveraging our expected utility algorithm for BAGGs. We have implemented our approach by adapting two Nash equilibrium algorithms, the simplicial subdivision algorithm [ 24 ] and Govindan and Wilson X  X  global Newton method [ 9 ]. We show empirically that our approach outperforms the existing approaches of solving for Nash on the induced normal form or on the normal form representation of the agent form. We now discuss some related literature. There has been some research on heuristic methods for finding Bayes-Nash equilibria for certain classes of auction games using iterated best response (see e.g. [ 21 , 25 ]). Such methods are not guaranteed to converge to a solution. Howson and Rosenthal [ 12 ] applied the agent form transformation to 2-player Bayesian games, resulting in a complete-information polymatrix game. Our approach can be seen as a generalization of their method to general Bayesian games. Singh et al. [ 23 ] proposed a incomplete information version of the graphical game representation, and presented efficient algorithms for computing approximate Bayes-Nash equilibria in the case of tree games. Gottlob et al. [ 7 ] considered a similar extension of the graphical game representation and analyzed the problem of finding a pure-strategy Bayes-Nash equilibrium. Like graphical games, such representations are limited in that they can only exploit strict utility independencies. Oliehoek et al. [ 20 ] proposed a heuristic search algorithm for common-payoff Bayesian games, which has applications to cooperative multi-agent problems. Bayesian games can be interpreted as dynamic games with a initial move by Nature; thus, also related is the literature on representations for dynamic games, including multi-agent influence diagrams (MAIDs) [ 17 ] and temporal action-graph games (TAGGs) [ 14 ]. Compared to these representations for dynamic games, BAGGs focus explicitly on structure common to Bayesian games; in particular, only BAGGs can efficiently express type-specific utility structure. Also, by representing utility functions and type distributions as separate components, BAGGs can be more versatile (e.g., a future direction is to answer computational questions that do not depend on the type distribution, such as ex-post equilibria). Furthermore, BAGGs can be solved by adapting Nash-equilibrium algorithms such as Govindan and Wilson X  X  global Newton method [ 9 ] for static games; this is generally more practical than their related Nash equilibrium algorithm [ 8 ] that directly works on dynamic games: while both approach avoids the exponential blowup of transforming to the induced normal form, the algorithm for dynamic games has to solve an additional quadratic program at each step. 2.1 Complete-information Games We assume readers are familiar with the basic concepts of complete-information games and here we where N = { 1 ,...,n } is the set of agents; for each agent i , A i is the set of i  X  X  actions. We denote by a i  X  A i one of i  X  X  actions. An action profile a = ( a 1 ,...,a n )  X  Q i  X  N A i is a tuple of the agents X  actions. Agent i  X  X  utility function is u i : Q j  X  N A j  X  R . A mixed strategy  X  i for player i is a probability distribution over A i . A mixed strategy profile  X  is a tuple of the n players X  mixed strategies. We denote by u i (  X  ) the expected utility of player i under the mixed strategy profile  X  . We adopt the following notational convention: for any n -tuple X we denote by X  X  i the elements of X corresponding to players other than i .
 A game representation is a data structure that stores all information needed to specify a game. A normal form representation of a game uses a matrix to represent each utility function u i . The size of this representation is n Q j  X  N | A j | , which grows exponentially in the number of players. 2.2 Bayesian Games We now define Bayesian games and discuss common types of structure.
 Definition 1. A Bayesian game is a tuple ( N, { A i } i  X  N ,  X  ,P, { u i } i  X  N ) where N = { 1 ,...,n } is the set of players; each A i is player i  X  X  action set, and A = Q i A i is the set of action profiles;  X  = Q i  X  i is the set of type profiles, where  X  i is player i  X  X  set of types; P :  X   X  R is the type distribution and u i : A  X   X   X  R is the utility function for player i .
 As in the complete-information case, we denote by a i an element of A i , and a = ( a 1 ,...,a n ) an action profile. Furthermore we denote by  X  i an element of  X  i , and by  X  a type profile. The game is played as follows. A type profile  X  = (  X  1 ,..., X  n )  X   X  is drawn according to the distribution P . Each player i observes her type  X  i and, based on this observation, chooses from her set of actions A i . Each player i  X  X  utility is then given by u i ( a, X  ) , where a is the resulting action profile. Player i can deterministically choose a pure strategy s i , in which given each  X  i  X   X  i she deterministi-of the players X  mixed strategies.
 The expected utility of i given  X  i under a mixed strategy profile  X  is the expected value of i  X  X  utility under the resulting joint distribution of a and  X  , conditioned on i receiving type  X  i : A mixed strategy profile  X  is a Bayes-Nash equilibrium if for all i , for all  X  i , for all a i  X  A i , u that i plays a i with probability 1 given  X  i .
 In specifying a Bayesian game, the space bottlenecks are the type distribution and the utility functions. Without additional structure, we cannot do better than representing each utility function u i : A  X   X   X  R as a table and the type distribution as a table as well. We call this representation the Bayesian normal form . The size of this representation is n  X  Q n i =1 ( |  X  i | X | A i | ) + Q n i =1 |  X  i | . We say a Bayesian game has independent type distributions if players X  types are drawn independently, distribution P can be represented compactly using P i |  X  i | numbers.
 Given a permutation of players  X  : N  X  N and an action profile a = ( a 1 ,...,a n ) , let a  X  = ( a for all permutations  X  : N  X  N , we have u i ( a, X  ) = u  X  ( i ) ( a  X  , X   X  ) for all i  X  N . A Bayesian game is symmetric if its type distribution and utility functions are symmetric. The utility functions of such A Bayesian game exhibits conditional utility independence if each player i  X  X  utility depends on the action profile a and her own type  X  i , but does not depend on the other players X  types. Then the utility function of each player i ranges over at most | A ||  X  i | unique utility values. 2.2.1 Complete-information interpretations Harsanyi [ 10 ] showed that any Bayesian game can be interpreted as a complete-information game, such that Bayes-Nash equilibria of the Bayesian game correspond to Nash equilibria of the complete-information game. There are two complete-information interpretations of Bayesian games. A Bayesian game can be converted to its induced normal form , which is a complete-information game with the same set of n players, in which each player X  X  set of actions is her set of pure strategies in the Bayesian game. Each player X  X  utility under an action profile is defined to be equal to the player X  X  expected utility under the corresponding pure strategy profile in the Bayesian game.
 Alternatively, a Bayesian game can be transformed to its agent form , where each type of each player in the Bayesian game is turned into one player in a complete-information game. Formally, given a type of every player of the Bayesian game. We index the players by the tuple ( j, X  j ) where j  X  N and  X  j  X   X  j . For each player ( j, X  j )  X   X  N of the agent form game, her action set  X  A ( j, X  action set of j in the Bayesian game. The set of action profiles is then  X  A = Q j, X   X  the agent form and pure strategies of the Bayesian game. A similar correspondence exists for mixed strategy profiles: each mixed strategy profile  X  of the Bayesian game corresponds to a mixed strategy  X   X  of the agent form, with  X   X  ( i, X   X  u Bayesian game and Nash equilibria of its agent form.
 Proposition 2.  X  is a Bayes-Nash equilibrium of a Bayesian game if and only if  X   X  is a Nash equilibrium of its agent form. In this section we introduce Bayesian Action-Graph Games (BAGGs), a compact representation of Bayesian games. First consider representing the type distributions. Specifically, the type distribution P is specified by a Bayesian network (BN) containing at least n random variables corresponding to the n players X  types  X  1 ,..., X  n . For example, when the types are independently distributed, then P can be specified by the simple BN with n variables  X  1 ,..., X  n and no edges.
 Now consider representing the utility functions. Our approach is to adapt concepts from the AGG representation [ 1 , 13 ] to the Bayesian game setting. At a high level, a BAGG is a Bayesian game on an action graph , a directed graph on a set of action nodes A . To play the game, each player i , given her type  X  i , simultaneously chooses an action node from her type-action set A i, X  i  X  X  . Each action node thus corresponds to an action choice that is available to one or more of the players. Once the players have made their choices, an action count is tallied for each action node  X   X  X  , which is the number of agents that have chosen  X  . A player X  X  utility depends only on the action node she chose and the action counts on the neighbors of the chosen node.
 We now turn to a formal description of BAGG X  X  utility function representation. Central to our model is the action graph . An action graph G = ( A ,E ) is a directed graph where A is the set of action nodes, and E is a set of directed edges, with self edges allowed. We say  X  0 is a neighbor of  X  if there neighbors of  X  .
 For each player i and each instantiation of her type  X  i  X   X  i , her type-action set A i, X  i  X  X  is the set of possible action choices of i given  X  i . These subsets are unrestricted: different type-action sets may (partially or completely) overlap. Define player i  X  X  total action set to be A  X  i = S  X  We denote by A = Q i A  X  i the set of action profiles , and by a  X  A an action profile. Observe that the action profile a provides sufficient information about the type profile to be able to determine the outcome of the game; there is no need to additionally encode the realized type distribution. We note that for different types  X  i , X  0 i  X   X  i , A i, X  i and A i, X  0 numbers of available action choices depending on her realized type.
 A configuration c is a vector of |A| non-negative integers, specifying for each action node the numbers of players choosing that action. Let c (  X  ) be the element of c corresponding to the action  X  . Let C : A 7 X  C be the function that maps from an action profile a to the corresponding configuration c . Formally, if c = C ( a ) then c (  X  ) = |{ i  X  N : a i =  X  }| for all  X   X  A . Define C = { c :  X  a  X  A such that c = C ( a ) } . In other words, C is the set of all possible configurations. We can also define a configuration over a subset of nodes. In particular, we will be interested in configurations over a node X  X  neighborhood. Given a configuration c  X  C and a node  X   X  A , let the configuration over the neighborhood of  X  , denoted c (  X  ) , be the restriction of c to  X  (  X  ) , i.e., c least one player plays  X  . Let C (  X  ) : A 7 X  C (  X  ) be the function which maps from an action profile to the corresponding configuration over  X  (  X  ) . Definition 3. A Bayesian action-graph game (BAGG) is a tuple ( N,  X  ,P, { A i, X  i } i  X  N, X  i  X   X  i , G, { u  X  }  X   X  X  ) where N is the set of agents;  X  = Q i  X  i is the set of type profiles; P is the type distribution, represented as a Bayesian network; A i, X  i  X  A is the type-action set of i given  X  i ; G = ( A ,E ) is the action graph; and for each  X   X  X  , the utility function is u  X  : C (  X  )  X  R . Intuitively, this representation captures two types of structure in utility functions: firstly, shared actions capture the game X  X  anonymity structure: if two action choices from different type-action sets share an action node  X  , it means that these two actions are interchangeable as far as the other players X  utilities are concerned. In other words, their utilities may depend on the number of players that chose the action node  X  , but not the identities of those players. Secondly, the (lack of) edges between nodes in the action graph expresses action-and type-specific independencies of utilities of the game: depending on player i  X  X  chosen action node (which also encodes information about her type), her utility depends on configurations over different sets of nodes.
 Lemma 4. An arbitrary Bayesian game given in Bayesian normal form can be encoded as a BAGG storing the same number of utility values.
 Proof. Provided in the supplementary material.
 Bayesian games with symmetric utility functions exhibit anonymity structure, which can be expressed in BAGGs by sharing action nodes. Specifically, we label each  X  i as { 1 ,...,T } , so that each t  X  { 1 ,...,T } corresponds to a class of equivalent types. Then for each t  X  { 1 ,...,T } , we have A i,t = A j,t for all i,j  X  N , i.e. type-action sets for equivalent types are identical. 3.1 BAGGs with function nodes In this section we extend the basic BAGG representation by introducing function nodes to the action graph. The concept of function nodes was first introduced in the (complete-information) AGG setting [13]. Function nodes allow us to exploit a much wider variety of utility structures in BAGGs. In this extended representation, the action graph G  X  X  vertices consist of both the set of action nodes A and the set of function nodes F . We require that no function node p  X  X  can be in any player X  X  action set. Each function node p  X  X  is associated with a function f p : C ( p )  X  R . We extend c by defining can be used to describe intermediate parameters that players X  utilities depend on. To ensure that the BAGG is meaningful, the graph restricted to nodes in F is required to be a directed acyclic graph. As before, for each action node  X  we define a utility function u  X  : C (  X  )  X  R .
 Of particular computational interest is the subclass of contribution-independent function nodes (also introduced by [ 13 ]). A function node p in a BAGG is contribution-independent if  X  ( p )  X  X  , there exists a commutative and associative operator  X  , and for each  X   X   X  ( p ) an integer w  X  , such that given an action profile a = ( a 1 ,...,a n ) , c ( p ) =  X  i  X  N : a independent if all its function nodes are contribution-independent. Intuitively, if function node p is contribution-independent, each player X  X  strategy affects c ( p ) independently.
 A very useful kind of contribution-independent function nodes are counting function nodes , which set  X  to the summation operator + and the weights to 1. Such a function node p simply counts the number of players that chose any action in  X  ( p ) .
 Let us consider the size of a BAGG representation. The representation size of the Bayesian network for P is exponential only in the in-degree of the BN. The utility functions store P  X  | C (  X  ) | values. As in similar analysis for AGGs [ 15 ], estimations of this size generally depend on what types of function nodes are included. We state only the following (relatively straightforward) result since in this paper we are mostly concerned with BAGGs with counting function nodes.
 Theorem 5. Consider BAGGs whose only function nodes, if any, are counting function nodes. If the in-degrees of the action nodes as well as the in-degrees of the Bayesian networks for P are bounded by a constant, then the sizes of the BAGGs are bounded by a polynomial in n , |A| , |F| , P i |  X  i | and the sizes of domains of variables in the BN.
 This theorem shows a nice property of counting function nodes: representation size does not grow exponentially in the in-degrees of these counting function nodes. The next example illustrates the usefulness of counting function nodes, including for expressing conditional utility independence. Example 6 (Coffee Shop game) . Consider a symmetric Bayesian game involving n players; each player plans to open a new coffee shop in a downtown area, but has to decide on the location. The downtown area is represented by a r  X  k grid. Each player can choose to open a shop located within any of the B  X  rk blocks or decide not to enter the market. Each player has T types, representing her private information about her cost of opening a coffee shop. Players X  types are independently distributed. Conditioned on player i choosing some location, her utility depends on: (a) her own type; (b) the number of players that chose the same block; (c) the number of players that chose any of the surrounding blocks; and (d) the number of players that chose any other location.
 The Bayesian normal form representation of this game has size n [ T ( B + 1)] n . The game can be expressed as a BAGG as follows. Since the game is symmetric, we label the types as { 1 ,...,T } . A contains one action O corresponding to not entering and TB other action nodes, with each location corresponding to a set of T action nodes, each representing the choice of that location by a player with a different type. For each t  X  X  1 ,...,T } , the type-action sets A i,t = A j,t for all i,j  X  N and each consists of the action O and B actions corresponding to locations for type t . For each location ( x,y ) we create three function nodes: p xy representing the number of players choosing this location, p xy representing the number of players choosing any surrounding blocks, and p number of players choosing any other block. Each of these function nodes is a counting function node, whose neighbors are action nodes corresponding to the appropriate locations (for all types). graph has maximum in-degree 3, by Theorem 5 the representation size is polynomial in n , B and T . In this section we consider the problem of finding a sample Bayes-Nash equilibrium given a BAGG. Our overall approach is to interpret the Bayesian game as a complete-information game, and then to apply existing algorithms for finding Nash equilibria of complete-information games. We consider two state-of-the-art Nash equilibrium algorithms, van der Laan et al X  X  simplicial subdivision [ 24 ] and Govindan and Wilson X  X  global Newton method [ 9 ]. Both run in exponential time in the worst case, and indeed recent complexity theoretic results [ 3 , 6 , 4 ] imply that a polynomial-time algorithm for Nash equilibrium is unlikely to exist. 1 Nevertheless, we show that we can achieve exponential speedups in these algorithms by exploiting the structure of BAGGs.
 Recall from Section 2.2.1 that a Bayesian game can be transformed into its induced normal form or its agent form. In the induced normal form, each player i has | A i | |  X  i | actions (corresponding to her pure strategies of the Bayesian game). Solving such a game would be infeasible for large |  X  i | ; just to represent an Nash equilibrium requires space exponential in |  X  i | .
 A more promising approach is to consider the agent form. Note that we can straightforwardly adapt the agent-form transformation described in Section 2.2.1 to the setting of BAGGs: now the action set of player ( i, X  i ) of the agent form corresponds to the type-action set A i, X  i of the BAGG. The resulting complete-information game has P i  X  N |  X  i | players and | A i, X  i | actions for each player ( i, X  i ) ; a Nash equilibrium can be represented using just P i P  X  representation of the agent form has size P j  X  N |  X  j | Q i, X  and |  X  i | . Applying the Nash equilibrium algorithms to this normal form would be infeasible in terms of time and space. Fortunately, we do not have to explicitly represent the agent form as a normal form game. Instead, we treat a BAGG as a compact representation of its agent form, and carry out any required computation on the agent form by operating on the BAGG. A key computational task required by both Nash equilibrium algorithms in their inner loops is the computation of expected the agent form is equal to the expected utility u i (  X  |  X  i ) of the Bayesian game. Thus in the remainder of this section we focus on the problem of computing expected utility in BAGGs. 4.1 Computing Expected Utility in BAGGs u (  X  |  X  i ) = P a One approach is to directly apply Equation (1) , which has ( |  X   X  i | X | A | ) terms in the summation. For games represented in Bayesian normal form, this algorithm runs in time polynomial in the representation size. Since BAGGs can be exponentially more compact than their equivalent Bayesian normal form representations, this algorithm runs in exponential time for BAGGs.
 In this section we present a more efficient algorithm that exploits BAGG structure. We first formulate the expected utility problem as a Bayesian network inference problem. Given a BAGG and a mixed We start with the BN representing the type distribution P , which includes (at least) the random variables  X  1 ,..., X  n . The conditional probability distributions (CPDs) for the network are unchanged. We add the following random variables: one strategy variable D j for each player j ; one action count variable for each action node  X   X  X  , representing its action count, denoted c (  X  ) ; one function variable for each function node p  X  X  , representing its configuration value, denoted c ( p ) ; and one utility variable U  X  for each action node  X  . We then add the following edges: an edge from  X  j to D j for each player j ; for each player j and each  X   X  A  X  j , an edge from D j to c (  X  ) ; for each function variable c ( p ) , all incoming edges corresponding to those in the action graph G ; and for each  X   X  X  , for each action or function node m  X   X  (  X  ) in G , an edge from c ( m ) to U  X  in the IBN. The CPDs of the newly added random variables are defined as follows. Each strategy variable D j has domain A  X  j , and given its parent  X  j , its CPD chooses an action from A  X  j according to the a j  X  A j, X  j and 0 for all a j  X  A  X  j \ A j, X  j ; and if j = i we have Pr( D j = a i |  X  j ) = 1 . For each action node  X  , the parents of its action-count variable c (  X  ) are strategy variables that have  X  in their domains. The CPD is a deterministic function that returns the number of its parents that take value  X  ; i.e., it calculates the action count of  X  . For each function variable c ( p ) , its CPD is the deterministic function f p . The CPD for each utility variable U  X  is a deterministic function specified by u  X  . It is straightforward to verify that the IBN is a directed acyclic graph (DAG) and thus represents a Standard BN inference methods could be used to compute E [ U a i |  X  i ] . However, such standard algorithms do not take advantage of structure that is inherent in BAGGs. In particular, recall that in the induced network, each action count variable c (  X  )  X  X  parents are all strategy variables that have  X  in their domains, implying large in-degrees for action count variables. Applying (e.g.) the clique-tree algorithm would yield large clique sizes, which is problematic because running time scales exponentially in the largest clique size of the clique tree. However, the CPDs of these action count variables are structured counting functions. Such structure is an instance of causal independence in BNs [ 11 ]. It also corresponds to anonymity structure for complete-information game representations like symmetric games and AGGs [ 13 ]. We can exploit this structure to speed up computation of expected utility in BAGGs. Our approach is a specialization of Heckerman and Breese X  X  method [ 11 ] for exploiting causal independence in BNs, which transforms the original BN by creating new nodes that represent intermediate results, and re-wiring some of the arcs, resulting in an equivalent BN with small in-degree. Given an action count variable c (  X  ) with parents (say) { D 1 ...D n } , for each i  X  X  1 ...n  X  1 } we create a node M  X ,i , representing the count induced by D 1 ...D i . Then, instead of having D 1 ...D n as parents of c (  X  ) , its parents become D n and M  X ,n  X  1 , and each M  X ,i  X  X  parents are D i and M  X ,i  X  1 . The resulting graph has in-degree at most 2 for c (  X  ) and the M  X ,i  X  X . The CPDs of function variables corresponding to contribution-independent function nodes also exhibit causal independence, and thus we can use a similar transformation to reduce their in-degree to 2. We call the resulting Bayesian network the transformed Bayesian network (TBN) of the BAGG. It is straightforward to verify that the representation size of the TBN is polynomial in the size of the BAGG. We can then use standard inference algorithms to compute E [ U  X  |  X  i ] on the TBN. For classes of BNs with bounded treewidths, this can be computed in polynomial time. Since the graph structure (and thus the treewidth) of the TBN does not depend on the strategy profile and only depends on the BAGG, we have the following result. Figure 1: GW, varying players. Theorem 8. For BAGGs whose TBNs have bounded treewidths, expected utility can be computed in time polynomial in n , |A| , |F| and | P i  X  i | .
 Bayesian games with independent type distributions are an important class of games and have many applications, such as independent-private-value auctions. When contribution-independent BAGGs have independent type distributions, expected utility can be efficiently computed.
 Theorem 9. For contribution-independent BAGGs with independent type distributions, expected utility can be computed in time polynomial in the size of the BAGG.
 Proof. Provided in the supplementary material.
 Note that this result is stronger than that of Theorem 8, which only guarantees efficient computation when TBNs have constant treewidth. We have implemented our approach for computing a Bayes-Nash equilibrium given a BAGG by applying Nash equilibrium algorithms on the agent form of the BAGG. We adapted two algorithms, GAMBIT X  X  [ 18 ] implementation of simplicial subdivision and GameTracer X  X  [ 2 ] implementation of Govindan and Wilson X  X  global Newton method, by replacing calls to expected utility computations of the complete-information game with corresponding expected utility computations of the BAGG. We ran experiments that tested the performance of our approach (denoted by BAGG-AF) against two approaches that compute a Bayes-Nash equilibrium for arbitrary Bayesian games. The first (denoted INF) computes a Nash equilibrium on the induced normal form; the second (denoted NF-AF) computes a Nash equilibrium on the normal form representation of the agent form. Both were implemented using the original, normal-form-based implementations of simplicial subdivision and global Newton method. We thus studied six concrete algorithms, two for each game representation. We tested these algorithms on instances of the Coffee Shop Bayesian game described in Example 6. We created games of different sizes by varying the number of players, the number of types per player and the number of locations. For each size we generated 10 game instances with random integer payoffs, and measured the running (CPU) times. Each run was cut off after 10 hours if it had not yet finished. All our experiments were performed using a computer cluster consisting of 55 machines with dual Intel Xeon 3.2GHz CPUs, 2MB cache and 2GB RAM, running Suse Linux 11.1.
 We first tested the three approaches based on the Govindan-Wilson (GW) algorithm. Figure 1 shows running time results for Coffee Shop games with n players, 2 types per player on a 2  X  3 grid, with n varying from 3 to 7. Figure 2 shows running time results for Coffee Shop games with 3 players, 2 types per player on a 2  X  x grid, with x varying from 3 to 10. Figure 3 shows results for Coffee Shop games with 3 players, T types per player on a 1  X  3 grid, with T varying from 2 to 8. The data points represent the median running time of 10 game instances, with the error bars indicating the maximum and minimum running times. All results show that our BAGG-based approach (BAGG-AF) significantly outperformed the two normal-form-based approaches (INF and NF-AF). Furthermore, as we increased the dimensions of the games the normal-form based approaches quickly ran out of memory (hence the missing data points), whereas BAGG-NF did not.
 We also did some preliminary experiments on BAGG-AF and NF-AF running the simplicial subdivi-sion algorithm. Figure 4 shows running time results for Coffee Shop games with n players, 2 types per player on a 1  X  3 grid, with n varying from 3 to 6. Again, BAGG-AF significantly outperformed NF-AF, and NF-AF ran out of memory for game instances with more than 4 players. [1] N. Bhat and K. Leyton-Brown. Computing Nash equilibria of action-graph games. In UAI , [2] B. Blum, C. Shelton, and D. Koller. Gametracer. http://dags.stanford.edu/Games/ [3] X. Chen and X. Deng. Settling the complexity of 2-player Nash-equilibrium. In FOCS: [4] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash [5] C. Daskalakis and C. Papadimitriou. Computing equilibria in anonymous games. In FOCS: [6] P. W. Goldberg and C. H. Papadimitriou. Reducibility among equilibrium problems. In STOC: [7] G. Gottlob, G. Greco, and T. Mancini. Complexity of pure equilibria in Bayesian games. In [8] S. Govindan and R. Wilson. Structure theorems for game trees. Proceedings of the National [9] S. Govindan and R. Wilson. A global Newton method to compute Nash equilibria. Journal of [10] J.C. Harsanyi. Games with incomplete information played by  X  X ayesian X  players, i-iii. part i. [11] David Heckerman and John S. Breese. Causal independence for probability assessment and [12] J.T. Howson Jr and R.W. Rosenthal. Bayesian equilibria of finite two-person games with [13] A. X. Jiang and K. Leyton-Brown. A polynomial-time algorithm for Action-Graph Games. In [14] A. X. Jiang, A. Pfeffer, and K. Leyton-Brown. Temporal Action-Graph Games: A new [15] Albert Xin Jiang, Kevin Leyton-Brown, and Navin Bhat. Action-graph games. Games and [16] M.J. Kearns, M.L. Littman, and S.P. Singh. Graphical models for game theory. In UAI , pages [17] D. Koller and B. Milch. Multi-agent influence diagrams for representing and solving games. In [18] R. D. McKelvey, A. M. McLennan, and T. L. Turocy. Gambit: Software tools for game theory, [19] N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani, editors. Algorithmic Game Theory . [20] Frans A. Oliehoek, Matthijs T. J. Spaan, Jilles Dibangoye, and Christopher Amato. Heuristic [21] Daniel M. Reeves and Michael P. Wellman. Computing best-response strategies in infinite [22] Y. Shoham and K. Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic, and [23] S. Singh, V. Soni, and M. Wellman. Computing approximate Bayes-Nash equilibria in tree-[24] G. van der Laan, A.J.J. Talman, and L. van der Heyden. Simplicial variable dimension algorithms [25] Yevgeniy Vorobeychik. Mechanism Design and Analysis Using Simulation-Based Game Models .
