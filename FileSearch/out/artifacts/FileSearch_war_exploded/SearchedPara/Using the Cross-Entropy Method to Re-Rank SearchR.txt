 We present a novel unsupervised approach to re-ranking an initially retrieved list. The approach is based on the Cross Entropy method applied to permutations of the list, and re-lies on performance prediction. Using pseudo predictors we establish a lower bound on the prediction quality that is re-quired so as to have our approach significantly outperform the original retrieval. Our experiments serve as a proof of concept demonstrating the considerable potential of the pro-posed approach. A case in point, only a tiny fraction of the huge space of permutations needs to be explored to attain significant improvements over the original retrieval.
We present a novel unsupervised approach to the challenge of re-ranking a document list that was retrieved in response to a query so as to improve retrieval effectiveness. The ap-proach utilizes a Monte-Carlo-based optimization method, named the Cross Entropy (CE) method [13], which is ap-plied to permutations of the list. The approach relies on a retrieval performance predictor that can be applied to any ranking of the list.

Given the reliance on performance prediction, we present a novel pseudo predictor that enables to fully control the prediction quality. We use the pseudo predictor in our ap-proach to set a lower bound on the prediction quality that is needed so as to have our approach significantly outperform the initial ranking. Further empirical evaluation provides a proof of concept for our approach. Specifically, via the ex-ploration of a tiny fraction of the huge space of all possible permutations, our approach finds highly effective permuta-tions. The retrieval effectiveness of these permutations is substantially, and statistically significantly better, than that of the original ranking of the list.
The Cross Entropy (CE) method [13] that is used in our approach is a Monte Carlo framework for rare event estima-tion and combinatorial optimization. The CE method has been previously applied in many domains such as machine learning, simulation, networks, etc. [13]. To the best of our knowledge, our work is the first to use the CE method in the information retrieval domain.

Our approach relies on predicting the retrieval perfor-mance of permutations of a document list. Applying per-formance prediction to select one of two retrieved lists was explored in some work [2, 6, 3, 11]. However, the conclusions regarding the resultant effectiveness of using the proposed predictors were inconclusive. In contrast, we do not present a concrete predictor. Rather, we devise a pseudo predictor that enables to control prediction quality, and accordingly set a lower bound on the prediction quality required so as to have our approach outperform the initial ranking.
Using a simulation study, a lower bound on the prediction quality required for effective selective query expansion was set [8]. While this work focused on performance prediction over queries, our approach relies on prediction over rankings for the same query. Furthermore, our approach is not com-mitted to any ranking paradigm. In addition, rather than use a simulation, we propose a novel pseudo predictor that allows to control prediction quality.

Finally, we note that some list-wise learning to rank ap-proaches [10] are also based on finding effective permuta-tions of the same list, although not with the Cross Entropy method that we employ. Permutations are explored during the training phase and a ranker is induced. In contrast, our approach employs optimization over permutations as an unsupervised re-ranking mechanism. Let D k q denote the list of the k documents in a corpus D that are the most highly ranked by some initial search performed in response to query q . Let  X  D k of all k ! possible permutations (rankings) of the documents in D k q . Let  X   X   X  D k and let  X  ( d ) further denote the position (rank) of document d (  X  D k q ) in  X  . Let Q (  X  ) denote the retrieval performance (effectiveness) of the permutation  X  (  X   X  D k
The goal is to find a permutation  X  (  X   X  D k Q (  X  ) is maximized. Unfortunately, finding an optimal per-mutation is NP-Complete [1]. In addition, with no prior releva nce judgement on the documents in D k q , the true per-formance Q (  X  ) for any given permutation  X   X   X  D k known . Hence, the performance of any given permutation can only be predicted , and the task becomes even more chal-lenging.

Let b Q (  X  ) denote the predicted performance of the per-mutation  X  (  X   X  D k available pre-retrieval features [9] (e.g., induced from the query q and the corpus D ), post-retrieval features (e.g., in-duced from the result list D k q or the permutation  X  ) or their combination [4].
We next propose an optimization approach that effec-tively finds  X  X romising X  permutations which have the best predicted performance according to a given predictor b Q (  X  ).
Since the resultant retrieval effectiveness of the optimiza-tion procedure depends on the prediction quality of the pre-dictor employed, we empirically derive a lower bound for the prediction quality of  X  X ffective X  predictors. That is, if a predictor with a prediction quality higher than the lower bound is used in our approach then the approach is guaran-teed to find  X  as determined based on the benchmarks we have used  X  as a solution a permutation  X   X  whose retrieval performance is better than that of the initial ranking.
We propose a Monte-Carlo optimization approach to our permutation-based re-ranking task. The approach, which we term Cross Entropy Re-ranking Optimization (CERO), uses the Cross Entropy (CE) method [13]. Within the CE method, optimal solutions to hard problems (such as that we try to solve) are modeled as rare events whose occur-rence probability is effectively estimated [13]. Given such estimates, optimal solutions can then be efficiently gener-ated. Under a certain condition, the CE method is expected to converge to the optimal solution [12].

We now describe our algorithm and provide its pseudo code in Algorithm 1. The algorithm gets as an input the initial ranked list  X  D k several tuning parameters (mentioned below) that control the learning rate and convergence of the algorithm. The al-gorithm iteratively explores permutations in  X  D k dom sampling. To this end, the algorithm induces a proba-bility space of  X  X romising X  permutations over  X  D k feedback it gets about the relative performance of permuta-tions that were explored in previous iterations. It is easy to show that for a given k , a unique bijection exists between the permutation set  X  D k tonian paths in a complete graph with k nodes. Therefore, random permutations can be efficiently drawn by sampling Hamiltonian paths using a simple constrained random walk method [13]. Let P t ( i,j ) denote the the probability for a sin-gle step transition between node i and node j in the graph, which corresponds to the event  X  ( d j ) =  X  ( d i ) + 1, i.e., doc-ument d i is ranked in  X  one position before document d j With no prior knowledge on the permutations probability space, the algorithm is initialized with the uniform probabil-ity (having the maximum entropy) and  X  D k the current best performing permutation. The algorithm X  X  Algorithm 1 Cro ss Entropy Re-ranking Optimization goal is to converge (via cross entropy minimization) to the unkn own probability space of optimal permutations, from which optimal solutions can be generated [13].

On each iteration t , N random permutations are sampled based on the last induced promising permutations prob-ability space P t  X  1 . Next, the predicted performance of each sampled permutation is calculated and the performance of the current best performing permutation  X   X  is updated accordingly.  X  X ew X  promising permutations are then ex-plored by first sorting the sampled permutations accord-ing to their predicted performance and then updating the transition probabilities based on the top- X   X N  X  performing samples, whose minimum performance is  X  t . Given  X  t , each transition probability P t ( i,j ) is induced according to the rela-tive number of permutations out of the top- X   X N  X  permuta-tions (which have predicted performance equal to or higher than  X  t ) that also ranked document d i one position above document d j . A fixed smoothing scheme, controlled by pa-rameter  X  , further allows to trade between the exploration (given by P t ( i,j ) ) and the exploitation (given by P t  X  1 algorithm.

The algorithm continuous until some convergence crite-ria is met. In this work we follow the convergence crite-ria suggested in [13] and stop the algorithm if the sample (1  X   X  )-performance quantile  X  t does not change within sev-eral consecutive iterations.
The CERO algorithm is generic and can employ any per-formance predictor. Naturally, however, the prediction qual-ity of the predictor has significant impact on the retrieval effectiveness of the ranking produced by the algorithm.
Thus, we turn to devise a method for determining the lower bound of prediction quality that will result in the CERO algorithm outperforming the initial ranking of D k q The bound is independent of a prediction approach.
Herein, we measure retrieval performance using average precision (AP@k); i.e., Q (  X  ) in our case is the AP of the per-muta tion  X  . Following standard practice in work on query-performance prediction [4], prediction quality is measured by the Pearson correlation between the true AP of permu-tations ( Q (  X  )) and their predicted performance ( b Q (  X  )).
To derive a lower bound on prediction quality, we next present an approach for generating pseudo AP predictors, whose prediction quality can be controlled. Following previ-ous observations [5], we assume that true AP values follow a normal distribution 1 .

We first normalize the AP of the permutation  X  (  X   X  D k E
 X  D k q ( AP ) and V ar  X  D k q ( AP ) are the expectation and the variance of the true AP values of the permutations in  X  D k respectively. The two statistics can be estimated using max-imum likelihood estimation for normal distribution, by sam-pling a large enough random (uniform) sample of permuta-tions in  X  D k distribution, we get that as k  X   X  , for any permutation
Proposition 1 defines a  X  -correlated pseudo AP predictor; that is, a predictor with a  X  prediction quality (i.e., Pearson correlation with true AP). The proof is quite straightforward and is ommitted due to space considerations.

Proposition 1. Given a query q , initial result list D k q and permutation  X   X   X  D k tor, denoted b Q  X  (  X  ) , is obtained as follows: w here Q norm (  X  ) is the normalized true AP value according to Eq. 1 and X  X  N (0 , 1) .
The TREC corpora and queries used for experiments are specified in Table 1. Titles of TREC topics served for queries. The Apache Lucene 2 search library (version 4.3) was used for the experiments. Documents and queries were processed us-ing Lucene X  X  default analysis (i.e., tokenization, stemming, stopwords, etc). For each query, 100 documents were re-trieved using Lucene X  X  implementation, employed with de-fault free-parameter values, of each of the following retrieval methods: vector space model (TF-IDF), query-likelihood (QL with Dirichlet smoothing) and Okapi BM25. Thus, we
The assumption was further verified in our experiments using the  X  2 goodness-of-fit test. Details are omitted due to space considerations. http://lucene.apache.org obtained three initial lists, D k q , composed of k = 100 doc-uments, for each query. Mean average precision (MAP@k) serves as the evaluation measure. Statistically significant differences of performance are measured using the paired t-test with a 95% confidence level.

Each initial list was re-ranked using the CERO algorithm employed with pseudo AP predictors of varying prediction quality levels. To control prediction quality, the pseudo predictors were generated according to Eq. 2; the predic-tion quality was varied from  X  = 0 . 05 (worst predictor) to  X  = 1 . 0 (best predictor). Following previous recommenda-tions [13], the algorithm X  X  learning parameters were set as follows: N = 1000,  X  = 0 . 01 and  X  = 0 . 7.
 a parallelized version of the Cross Entropy method [7]. On average, CERO converged in 21.32 iterations (with a 15.6 standard deviation). CERO explores at each iteration a maximum of N = 1000 permutations. Thus, all together, CERO considered only about 21 k  X  36 k permutations out of the 100! possible permutations of the initial list. CERO X  X  effectiveness. We first study the potential of our permutation-based optimization approach; specifically, in finding highly effective permutations in the huge space (100!) of permutations. To this end, we neturilize the effect of pre-diction quality by applying CERO with a  X  X redictor X  which reports the true AP of the considered permutations (i.e.,  X  = 1 . 0). The resultant MAP performance is presented in Table 2. As reference comparisons we use the initial rank-ing and an optimal re-ranking where all relevant documents from the initial list are positioned at the highest ranks.
We can see in Table 2 that, overall, CERO results in very good approximations. Specifically, CERO X  X  MAP is at least as 91% as good as that of the optimal MAP. Recall from above that CERO explores only a tiny fraction of all permu-tations of the documents in the result list. It is worth noting that an even better approximation may be obtained by finer tuning of the algorithm (e.g., following [12]). We leave this exploration for future work, and view the results presented in Table 2 as a solid proof of concept for the optimization approach we have employed.
 the effect of the prediction quality of the pseudo AP pre-dictors used in CERO on its MAP retrieval performance. Evidently, and as should be expected, the higher the predic-tion quality (  X  ), the better the performance. Furthermore, as from  X  = 0 . 3 CERO improves over the initial ranking for all the retrieval methods and across all corpora; for  X   X  0 . 35 the improvements are always statistically significant. With higher prediction quality, the improvements over the initial ranking become very substantial.
We presented a novel approach to re-ranking an initially retrieved list. The approach is based on applying the Cross Entropy optimization method [13] upon permutations of the list. Query-performance predictors are used to evaluate the performance of permutations. Empirical evaluation pro-vided a proof of concept for our approach. That is, the optimization procedure finds highly effective permutations by exploring only a tiny fraction of the space of all pos-sible permutations. In addition, we devised novel pseudo predictors that allow to carefully control prediction quality and to infer the minimal prediction quality required for our approach to (significantly) outperform the original ranking.
Our main plan for future work is devising query-performance predictors that yield a prediction quality that is higher than that we established as a lower bound for effective applica-tion of our approach. We note that almost all previously proposed query-performance predictors [4] are not suited for this task as they operate over different queries rather than over different lists retrieved for the same query. We would like to thank David Carmel for discussions on an earlier version of this work. Oren Kurland X  X  work is sup-ported in part by the Israel Science Foundation under grant no. 433/12 and by a Google faculty research award. [1] N. Alon. Ranking tournaments. SIAM Journal on [2] G. Amati, C. Carpineto, and G. Romano. Query [3] N. Balasubramanian and J. Allan. Learning to select [4] D. Carmel and E. Yom-Tov. Estimating the Query [5] B. Carterette, J. Allan, and R. Sitaraman. Minimal [6] S. Cronen-Townsend, Y. Zhou, and W. B. Croft. A [7] G. E. Evans, J. M. Keith, and D. P. Kroese. Parallel [8] C. Hauff and L. Azzopardi. When is query [9] C. Hauff, D. Hiemstra, and F. de Jong. A survey of [10] T.-Y. Liu. Learning to Rank for Information Retrieval . [11] X. Liu and W. B. Croft. Experiments on retrieval of [12] L. Margolin. On the convergence of the cross-entropy [13] R. Y. Rubinstein and D. P. Kroese. The cross-entropy
