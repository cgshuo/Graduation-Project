 In recent years, c o -saliency has become a research hots pot . Due to more information can be obtained from multiple images shared common objects, co -saliency detection can extract common foreground more accuracy than saliency detection. Therefore, i t has a very wide range of applications in image retrieval [1] , co -segmentation [2][3] , video compression [4] , target tracking [5] and many other fields.

C o -saliency detection involves two parts: saliency detection and common detection from two or more relevant images. The theoretical basis of the saliency detection is derived from the theory of feature integration and the focus transfer strategy. In 19 9 8, Itti et al. [6] propose d a saliency model based on n eurobiology res earch firstly . Harel et al. [7] propose d a graph -based saliency model based on Itti model. T his model used the markov random field instead of ori ginal linear combination to fuse multi ple fe a-ture maps. H ou et al. [8] transfer ed image to frequency domain via fourier transform, then use d the spectral residuals to get a saliency map. P eng et al. [9] use d RGBD dataset to get depth information on channel D, this method ob tained good result by fusing depth saliency map and RGB saliency map. In order to address the problem of noisy detection results and limited representations from bottom -up methods, Tong et al. [10] propose d a novel algorithm for salient object detection via bootstrap learning. A fully connected convolutional networks based saliency model was propo sed by Burce et al. [11] , this model applied CNN network to obtain high level feature to d e-scribe saliency. Lee et al. [12] intr o duce d a encoded low level distance map to denote low level saliency information, which assist high level semantic feature gaine d by deep framework gain detect salie n cy regions. While saliency detection can find the regions with rich information, it cannot detect common foreground in multiple ima g-es. T o obtain the common foreground, co -saliency detection was proposed.

In order to optimize the thumbnail display of the photo album , t he con cept of co -saliency was first introduced by Jacobs et al. [13] in 2010 . In [ 14 ][ 15 ][ 16 ] , the man u-ally designed co -saliency cues are used to explore the co -saliency between images. For example, Fu et al. [16] proposed a very eff icient cluster -based algorith m, which measured the cluster -level co -saliency by using three bottom -up saliency cues. It cost much time to cluster similar pixels. O ur method saves much time because of supe r-pixel clustering instead of pixel clustering . M ultiple saliency maps are fused t o di s-cover co -saliency information from the collection of multiple related images in [17][18][19] . For example, Cao et al. [17] applied low -rank decomposition to exploit the relationship of the result maps of multiple existing saliency and co -saliency met h-ods to obtain the self -adaptive weights, and then use d these weights to combine the multiple result maps for generating the final co -saliency map. These methods co m-pute multiple saliency maps, increas e the c omputational complexity . We only co m-pute one sali ency map to guide the weak co -saliency map. Methods in [ 20 ] [21 ] tran s-ferred co -saliency detection problem to classifica tion problem for each image region, i.e., Zhang et al. [20] proposed a co -saliency detection framework which integrated deep information ( H igher -level represe ntation) and wide information (I nter -group restrict). In this way, they can capture the high -level semantic feature and suppress the common backgrounds in the image group. These methods haven  X  t been mature, and need much time to train t he model . We use the bottom -up cues to detect the co -saliecy can decrease the detection time.
 Co -saliency Detection is still a challenging problem due to the follo wing reasons. First, the change of illumination, occlusion, angle, etc. will impact the result of co -saliency detection seriously under complex background. Second, it  X  s difficult to o b-tain the co -saliency cue s on different scale s . Third, co -saliency detection needs to process multi ple images leading to high computation complexity.

To solve these problems, the framework of our proposed co -saliency detetion method is illustrated in Fig. 1. First of all, we generate a superpixel pyramid for each image in group, and then obtain the saliency map by computing the saliency value for each superpixel. On the other hand, we cluster all superpixels into several classes to capture global corr elation. By using the clustering results to calculate the three cues, we obtain weakly co -saliency maps. Finally, the saliency maps and weak co -saliency maps are fused to form the final co -saliency maps.

In summary, our paper offers the following contributi o ns: 1) A s common co -saliency detection methods are inefficient at calculating co -2) In the processing of saliency detection, m u l ti -scale v i sual saliency map is Our framework consists of fiv e major steps: build superpixel pyramid, saliency co m-putation, superpixel clustering, weak co -saliency computation, and Integration, as shown in Fig. 1 . We name our co -saliency detection method s u perpixel clustering based co -saliency detection (SCCD) , in which saliency detection method is named co n tent -sensitive based multi -scale saliency detection (CSMS) . 2.1 Build S uperpixel P yramid The principle of superpixel segmentation is dividing pixel -level image into district -level image. Superpixels are perceptually meaningful atomi c regions that can effe c-tively capture image features. Simple linear iterative clustering (SLIC) method was proposed by Achanta et al. [22] in 2010, and the superpixels obtained by SLIC are usually regular and compact, but lack of conten -sensitivity. To co mpute content -sensitive superpixels, Liu et al. [23] proposed manifold SLIC (MSLIC) method, which adopted the geometric flow method into a centroidal voronoi tessellation opt i-mization framework. BL [10] method use the superpixels segmented by SLIC to d e-tec t the saliency, and get good result. In this paper, for the sake of speed and perfo r-mance, we compute saliency and co -saliency of superpixels segmented MSLIC i n-stead of pixels.

To obtain content -sensitive superpixels on multi -scale, our idea is to build a supe r-pi x el pyra mid for each image. Firstly, w e build a Gaussian pyramid with three layers for the purpose of obtain saliency and co -saliency information on three scale in our e x pe r iment . Then we segment image on every scale by MSLIC [23] , using MSLIC to segment image we can capture content -sensitive superpixels, i.e., small superpixels in content -dense regions and large superpixels in content -sparse regions. 2.2 CSMS Detection After building the superpixel pyramid , we detect the salient object via bootstrap lear n-tures (RGB, CIELab and LBP) to generate training samples for a strong model. S e-cond, a strong classifier based on multiple kernel boosting is learned to me asure sal i-ency where three features are extracted and four kernels are used to exploit rich fe a-ture representations, and then a weak saliency map is obtained. Third , we fuse the weak saliency maps and strong saliency maps on different scales to generate th e final saliency map (see Fig. 2 ).

The proposed weak and strong saliency maps have complementary properties. The weak map is likely to detect fine details and to capture local structural information due to the cont rast -based measure. On the contrary, the strong map works well by focusing on global shapes for most images except the case when test background samples have similarity with the positive training set. Thus we integrate these two maps by a weighted combinat ion: w here is a balance factor for the combination , and to weight the strong map more than the weak map [ 10 ] . 2.3 S uperpixel Clusteri ng Superpixel clustering break s the limitation of the image, clustering the superpixels in different images togeth er . And the process can short the time of calculating co -saliency. We cluster superpixels of all images in same group on same scale for the g lobal correlation. The clustering conduct breaks the limit of an image, gathering the similar superpixels to same cluster, and prepares for the subsequent steps. We choose RGB, CIELab and Gabor filter as the clustering features . The Gabor filter responses with 8 orientations. The bandwidth is chosen to be 1 and one scale is extracted. We compute the texture feature by combining 8 orientations of Gabor filter.
In o ur method, K -means clustering method is used. There is a main challenge in the clustering process: how to choose a suitable cluster number for image group with different amounts of images? Fewer clusters results in assigning superpixels with sufficient dis crimination to same cluster, while too many clusters cause the superpi x-els with little discrimination in different clusters. For this reason, we adopt a flexible equations to set the cluster number as w here denotes t he superpixel numbers of image. W e set cluster number based on the number of images. But con sidering both the clustering effect and computation complexity, we adjust the cluster number in the range of 10 -30.

For notation, t he th superpixel is denoted by in image , where range from 1 to , denotes the superpixel number of the th image. Given images * + , we obta in clusters * + . The clusters are denoted by a set of vectors * + , in which denotes the cluster center. 2.4 WCS  X  Weak Co -saliency  X  Computation T he superpixels in same cluster have global relevance, but maybe not co -s aliency re gions because of the noise from similar background regions or other similar regions . The next step is to calculate the co -saliency cues of superpixels in every cl uster . Our method describes the co -saliency by calculating the contrast cue , the rep etition cue , ground regions often ha ve high contrast, and the human eye is often interested in the image center, so we use c ontrast cue and position cue to find the fore ground regions. The contrast cue of cluster is calculated by: where denotes the sum of superpixels in all images, and denotes the superp ixel number of cluster . And the position cue is expressed by: where ( ) equals:
The repetition cue describes the frequency of which cluster appears i n m ultiple i m-understand that the distribution of a cluster in all images is more uni form, its syner g y is stronger . We employ the variances of clusters to roughly measur e how widely is the cluster distributed among the multiple input images [ 16 ] . A M -bin histogram  X  *  X  + is adopted to describe the distribution of cluster in M images: where ( ) is the Kronecker delta function, ( ) returns the cluster index of supe r-pixel . Then, the repetition cue ( ) is defined as: where (  X  ) denotes the variance of histogra m  X  of the cluster . In order to avoid the denominator is 0, usually with 1. The cluster with the high repetition cue re presents that the superpixels in this cluster evenly distribute in each image. 2.5 Integration The process of co -saliency det ection mainly contains three integrating operation. As in Fig. 3 , integration 1 fus es three cues to form the weak co -saliency map on each scale. Here we adapt the method of pixel -wise multiplication, because the co -saliency regions have these three characteristics at the same time. The work of i ntegration 2 is fus es weak co -saliency maps on different scales by weighted fusion with the weight 2:3:5, weighting the higher scale maps more than lower scale maps , and then the weak saliency maps are generated. Integration 3 fuses weak co -saliency map and saliency map to form th e final co -saliency map. Firstly, we fuse these two maps by a linear summation with the purpose of fill up the salien t object in saliency map. Then, the final co -saliency map is generated by a multiplication method to filter the u n-common saliency regions. We evaluate our works on two aspects: the single image saliency detection, and the co -saliency detection on the multiple images. We compare our method with the state -of -the -art methods on a variety of benchmark datasets. All the experiments are carried out using MATLAB R2013R on a desktop computer with an Intel i7 -4790 CPU (3.60 GHz) and 12G RAM . For fair comparison, we use the original source code or the provided saliency detection results in the literature. 3.1 Evaluation of CSMS method We pre sent experimental results of four saliency detection methods including the proposed algorithms on benchmark MSRA [ 24 ] and PASCAL -S [ 25 ] dataset . 
Firstly, we present some results of saliency maps ge nerated by four methods for qual i tative comparison in Fig. 4 . We compare our method with other three methods: RARE [ 26 ], BL [ 10 ] and ELD [ 12 ], where BL method is our base method. In contrast, it can be seen that the RARE method can find the approximate saliency regions by cluste r ing, but it cannot be highlighted by the background accurately . The BL method is the prototype method o f CSMS. The calculated saliency maps are close to that o b-tained by CSMS, but the boundary and internal details of the salient object obtained by BL are rough. The ELD method can eliminate the complex background well, but the sal i ency regions generated are not complete because of the over -suppression to bac k ground ; the CSMS meth od can get more c omplete and saliency regions , and the res iduals of the background are also less. In summary , it is obviously that the bound a-ry and detail processing of CSMS is better, and the saliency maps are closer to the truth map, which shows that the improvement of BL method is successful.

We use the Precis ion and Recall (PR) curve to evaluate all the methods quantit a-tively . We set the fixed threshold from 0 to 255 for a saliency map with consistent gray va l ue, thus producing 256 binary masks. Using the pixel -wise ground truth data, 256 pairs of average prec ision and recall values of all images are computed. Fig. 5 shows the PR curves of these four methods on two datasets, we can find CSMS  X  s PR curve is close to the position of (0 , 0 ), this indicates the performance o f CSMS is better than other three methods. 3.2 Evaluation of SCCD method We present experimental results of four co -saliency detection methods including the proposed algorithms on two benchmark iCoseg [ 27 ] and MSRC [ 28 ] da taset . 
In the experiment, all the images in an image group are input as one input, and the co -saliency regions in each image are output. Our method (SCCD) is compared with the other three methods : CCD [ 16 ], CDRP [ 29 ] and MSG [ 30 ]. Fig. 6 and Fig. 7 show some results of co -saliency maps generated by four methods for qualitative compar i-son. The CCD method obtains global correlation by clustering of pixels. Therefore, when the foreground and background are close, it is difficult to calculate the co -saliency accurately. As sho wn in the Fig. 6 (c) , the color of the leopard is close to the color of the grass, so some regions in leopard are detected as background. The CDRP and MSG methods assign a certain co -saliency to the common backgrou nd (sky in Fig. 7 (d) (e) ) incorrectly. And the SCCD method can obtain a relatively complete co -saliency region. In conclusion, the SCCD method can obtain the meticulous co -salient object region by using the MSLIC , and the correlation among the images by the clu s-tering method . Therefore, the combination of the two can better detect the co -saliency among multiple images.

Fig. 8 shows the PR curves of these four co -saliency me thods on two datasets, we can find SCCD  X  s PR curve is close to the position of (0 , 0 ), this indicates the perfo r-mance of SCCD is better than other three methods.
Finally, we compare the average running t ime of these four methods. SCCD adopts the bottom -up cues to measure the co -saliency without heavy. Simultaneously, the superpixel clustering based method, comparing with the individual pixel based met h-ods , achieves an efficient and rapid computation. Table 1 shows the average running time of theses co -saliency detection methods. We can see that SCCD  X  s computation is faster than other three methods  X  . In this paper, we propose a novely co -saliency detection method SCCD . SCCD uses supe r pi xel clu s tering to break the limit of single image, making similar superpixels to gat h er in one cluster. Simu l taneously, using the superpixels instead of pixels to calc u-late the co -saliency shorts the computation time. A nd a n updated saliency detection (SCMS) is proposed. With the help of a content -sensitive s u pe r pixel segmentation method and supe r pixel pyr a mid, CSMS can d e scribe the boundary and internal detail posed approaches pe r form favo r ably .
 This work was partially supported by National Natural Science Foundation of China (NSFC Grant No. 61170124, 61272258, 6130129 9 , 61272005, 61572085), Provincial Natural Science Foundation o f Jiangsu (Grant No. BK20151254, BK20151260), Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University (Grant No. 93K172016K08), and Collaborative Innovation Center of Novel Software Technology and Industr ialization.

