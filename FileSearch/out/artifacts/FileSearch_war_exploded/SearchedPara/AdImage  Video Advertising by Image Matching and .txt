 With the prevalence of recording devices and the ease of media sharing, consumers are embracing huge amounts of Internet videos. There arise the needs for effective video advertisement systems following their phenomenal success in text. We propose a novel advertising system, AdImage , which automatically associates relevant ads by matching characteristic images, referred to as adImages (analogous to adWords) here. The proposed image matching method is invariant to certain distortions commonly observed in shared videos. AdImage also avoids the pitfalls of poor tagging qualities in shared videos and provides a brand-new venue to specify ad targets by image objects. Moreover, we formulate the image matching scores and the para meterized bidding information as a nonlinear optimization problem for maximizing the system revenues and user perception. H.3.5 [ Information Storage and Retrieval ]: Online Information Services  X  Web-based services Algorithms, Experimentation, Human Factor Web video advertising, image ma tching, content-aware, AdImage Due to the explosion of digital videos and online sharing services, investigating effective online video advertising system becomes a great interest for the industry and research communities. Online Publisher Association reports that 80% of users have watched a video ad online and 52% of them ha ve taken some sorts of actions (e.g., visiting the related website ). eMarketer reports that the spending on web video adver tising is $775 Million in 2007, expected to reach 4.3 Billion in 2011. A few online video sharing site s have conducted such video advertising services (e.g., Googl e X  X  InVideo). Like AdWord and AdSense [3], associating a relevant ad (video) to the user-viewed video is determined by word matching between ad keywords, provided by the advertisers, and user-provided tags along with the shared videos. Such text-based ad association has apparent pitfalls over these shared videos. First, conventional text (tag) matching does not necessarily bring coherence in context or content between ads and viewed videos. The videos are generally a few minutes long and the tags, if available, are asso ciated with the entire video rather than a specific time point. Second, user-provided tags are generally missing, inaccurate, or ambiguous [2]. Moreover, text-based matching methods are limited since the advertiser might need to specify an occasion that the text cannot express; for example, the time when the  X  X didas X  logo appears (cf. Figure 1). Especially, it has been recognized that perceived irrelevance in ads generally leads to negative impressions on user experiences [1]. high contrast, strong textures, or special structures. Such methods usually benefit from certain invariant properties and can avoid the common problems of image clutter, partial visibility, and even occlusion [4]. The proposed approach for image matching includes three major parts. First, for each image frame in the video, we adopt Lowe X  X  Difference of Gaussian method to detect feature points and scale-invariant feature transform [4] to represent properties within these feature points. For efficiency, we then adopt an approximate nearest neighboring indexing method (i.e., [5]) to locate matched feature points between the adImage and the inspected frame. Finally, spatial constraints by approximating appli cable affine transform between matched feature points are used to remove the outliers, which are the matched feature points not complying with the estimated affine transform. A candidate video frame contains an adImage once the number of the matched inliers is larger than a threshold. Note that all adImages are matched for each frame. In AdWord [3], each advertiser places bids on a number of keywords and specifies a maximum daily budget. As queries arrive during the day, certain ads will be displayed for their relevance. The objective is to maximize the total revenues while respecting the daily budgets and ad relevance. In our framework, after matching each adImage to the uniformly-sampled frames in the video, we will get a sequence of adImage matches with computed fitting scores. Motivated by AdWord [3] and given a ranking list of candidate ads, online ad insertion is formulated as an optimization problem, which aims at selecting a subset of ads to maximize not only contextual relevance but also total revenues. We also need to schedule the competing ads in a temporal order since some ad videos are likely to overlap in the viewed videos since ad videos are generally a few seconds long and two adImages might be temporally nearby. We conduct experiments on the movie,  X  X  Now Pronounce You Chuck and Larry, X  which consists of 3,092 (in 576 X 304 resolution) sampled video frames. We use 16 popular and characteristic images as adImages (such as logos for  X  X  uma X ,  X  X didas X , etc.). The online system showing a viewed video with candidate ad videos and associated scheduling scores by the ad scheduling algorithm is shown in Figure 1. In order to evaluate the adImage matching performance, we formulate the matching as a ra nking problem (over 3,092 video frames) and use the (non-interpolated) average precision (AP), approximating the area under the precision-recall curve for an adImage, as the major performance metric. Since AP only shows the performance for a single adImage, we compute mean average precision (MAP) to represent the system performance over the 16 selected adImages (three of them are shown in Figure 2). The matching performance across all adIm ages is 0.798 MAP and yields quite promising results. The AP drop in certain adImages is due to the fact that such adImages have very low resolutions. The explosive amount of videos from Internet sharing and digital TVs had entailed the needs for effective and less intrusive advertisement systems as users wa tch the videos. In light of the demand, we propose AdImage  X  a novel video advertising system which supports relevant video adve rtising based on image matching. 
