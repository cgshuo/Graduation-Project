 Last few years have witnessed the advancement of technologies which has made possible the use of brain signals for communication between human and com-puter. This growth in technologies allows research community to develop a sys-tem called Brain Computer Interface (BCI) which can control a device such as computer or wheel chair by human intentions rather than mechanical power of human. It may be very useful to physically challenged persons who are suffering from locomotor syndrome, Amyotrophic Lateral Sclerosis, Head trauma, severe cerebral palsy or multiple di sorders affect in body, which restricts such persons to operate any electronics device smoo thly and freely. With the development of BCI, these people can operate any el ectronics device with the help of just brain signals and does not depend on the brain X  X  normal output pathways of peripheral nerves and muscles. BCIs are often aimed for assisting, augment-ing or repairing human cognitive or motor sensory function. Various techniques such as Electroencephalogram (EEG), Electrocardiogram, functional magnetic resonance imaging, Magneto encephalographic (MEG) and Positron emission tomography (PET) are used for monitoring brain signals activities.

EEG is commonly used for BCI implementation due to its low cost, abil-ity to record brain signals and non-invasive nature. There are many compo-nents of a BCI system. However, the success of BCI system mainly depends on two components: feature extraction and classification method. The feature ex-tracted/selected from EEG should have high discriminative power to distinguish the different tasks and the classification methods used to distinguish the differ-ent tasks should be efficient in real time. There are many classification methods available in the field of data mining and machine learning[16,20,31]. The re-search work[22] discusses pros and cons of linear and classification methods for BCI research.

In literature, autoregressive (AR) models or adaptive AR models (AAR)[1,3,7,9,20,26] and power spectral density (PSD)[2,27] are commonly used for feature extraction from EEG for BCI system. However, these methods as-sume linearity, Gaussianality and minimum-phase within EEG signals, i.e., the amplitudes of EEG signals are normally distributed, their statistical properties do not vary over time, and their frequency components are uncorrelated. Under these assumptions, the EEG signal is considered as a linear superposition of sta-tistically independent sinusoidal or other wave components, and only frequency and power estimates are considered wh ile phase information is lost. Recently, Empirical Mode Decomposition (EMD) is suggested for feature extraction from EEG signal which is suitable for the analysis of non-linear and non-stationary time series. A disadvantage arising at this point is that the feature vector so obtained with EMD would be too large and the number of training samples available are in general relatively small number. Consequently, it is essential to do a feature selection in order to solve the problem of curse-of-dimensionality which arises due to small sample and large number of features[17]. Also, the re-sultant features may contain noisy, irrelevant or redundant features which make them inefficient for machine learning. In fact, the presence of irrelevant and re-dundant features may deteriorate the performance of the classifier and requires high computation time and other resources for training and testing the data. Hence, in order to enhance the performance of BCI system in terms of accuracy and time required to detect, there is need to identify a set of relevant features.
Feature selection is used to remove such noisy, irrelevant, and redundant fea-tures.There are two major approaches to feature selection: filter and wrapper approach[10,14,22]. Most filter methods employ statistical characteristics of data for feature selection which requires less computation. It independently measures the importance of features without involving any classifier. Since, the filter ap-proach does not take into account the learning bias introduced by the final learning algorithm, it may not be able to select the most relevant set of features for the learning algorithm. On the other hand, wrapper methods tend to find features better suited to the predetermined learning algorithm resulting in bet-ter performance. But, it tends to be computationally more expensive since the classifier must be trained for each candidate subset.

Feature ranking approaches have been widely investigated for feature selection[10,21,23] in literature. Since in most of feature ranking approaches, features are evaluated using statistical characteristics of the data, different fea-ture ranking methods measure different characteristics of data. Therefore, the informative features selected by differe nt ranking methods may be different. In literature to remove redundancy a forward/backward feature selection method or its combinations are used with a measure that selects relevant and non redun-dant features. Among the most widely use d filter methods for feature selection, there are techniques based on statistical separability measures which allow one to select a suitable subset of features by assigning the degree of interclass separabil-ity associated with each subset. In parti cular, ratio of scatter matrices, Chernoff distance measures[19] and linear regression[21] are commonly employed by re-search community in various area of data mining and pattern classification field but yet to be explored in feature selection of EEG data for mental task classi-fication. In this paper, we compare and evaluate these measures to determine relevant features for BCI system.

Our work is organized as follows: Feature extraction using empirical mode decomposition is included in Sect. 2. A brief introduction of separability measures employed for features selection are disc ussed in Sect. 3. Experimental data and results are discussed in Sect. 4 an d Sect. 5 contains conclusions. The feature extraction is carried out i n two phases [12]: in the first phase, the empirical mode decomposition is used, an d the second phase es timates different time and frequency parameters. 2.1 Empirical Mode Decomposition (EMD) Under the assumption that any signal is composed of a series of different intrinsic oscillation modes, the EMD can be used to decompose the incoming signal into its different Intrinsic Mode Function (IMF). An IMF is a function that satisfies two conditions[12]: 1. In the entire signal, the number of extremes and the zero-crossings must be 2. At any point, the mean value of the envelope defined by the local maxima Given the incoming signal x(t), the algorithm of EMD is based on a sifting process that can be summarized as[12,14]: 1. Interpolate all the local maxima and minima in the signal with a cubic spline 2. Repeat for the local minima to produce the lower envelope. 3. Compute the mean of both envelopes m 1 . 4. Extract the detail h 1 = x ( t )  X  m 1 5. Repeat the steps 1 to 4, and consider the detail h i as the data, until detail 6. After k iterations, the detail h k is an IMF and is designated as: IMF 1 = h k 7. Iterate steps 1 to 6 on the residual r j in order to obtain all the IMFs of the The procedure terminates when the residual r j is either a constant, a mono-tonic slope, or a function with only one extreme. The result of the EMD process produces n IMFs and a residue signal r n . The original signal x(t) can be recon-structed summing up the n extracted IMF and the residue: 2.2 Estimation of Various Parameters In order to obtain the IMFs of the signal, publicly available EMD toolbox for Matlab was utilized. The lower-order IMFs capture the faster oscillation modes of the signal, whereas the higher-order IMFs capture the slower oscillation modes. The EMD algorithm can be applied to each EEG 1 s segments. Afterward, the EMD is able to extract no more than five IMFs and the residue for each 1 s EEG segment. For each one of these five IMFs, d ifferent parameter s can be computed. The following parameters can be used to represent each EMD[5]: 1. Root Mean Square (RMS), 2. Variance, 3. Shannon entropy[23] 4. Lempel-Ziv Complexity Measure[13], 5. Central Frequency (50 % of spectrum energy) 6. Maximum Frequency (9 5 % of spectrum energy) Some parameters were chosen since they are commonly used in BCI (RMS, variance), LZ quantifies the complexity of a signal analysing its spatial-temporal patterns and was used to analyse EEG signals in other areas[10]. The central and maximum frequencies were used as descriptors of the bandwidth of each IMF. Entropy was used to measure the average amount of information in a signal. A disadvantage arising at this point is feature vector contains 180 parameters (5 IMFs x 6 parameters 6 channels). Consequently, it is essential to do a feature selection in order to solve the curse-of-dim ensionality inconvenience[24]. Feature ranking is commonly used to determine a s ubset of relevant features. However, the disadvantage of feature ranking method is that they ignore the correlations between features. Hence the features selected may contain redundant informa-tion and influences the classification capabilities of the feature subset that is selected. Some of the methods suggested in literature for removing redundancy are Chernoff distance measure[22], ratio of inter-class and with-in class scatter, and linear regression[19]. In order to obtain a quantitative measure of how sep-arable are two classes, a distance measure can be easily extracted from some parameters of the data. A very important aspect of probabilistic distance mea-sures is that a number of these criteria can be analytically simplified in the case when the class conditional p.d.f.s follows multivariate normal distribution. The class conditional probability densities functions p ( X k | C i ) of k-dimensional where  X  i k is a mean vector and i k is a covariance matrix for class C i .In literature, for multivariate normal distribution for two classes, CD measure is given as follows[5]: A major disadvantage of the class separability measure CD is that it is not easily computed, unless the Gaussian a ssumption is employed. In literature, a simpler criteria based on the scatters of feature vector samples is employed. To this end, the scatter matrices: within-cl ass scatter and between-class scatter are respectively defined as: From these definition of scatter matrices, it is straightforward to observe that the criterion takes large values when samples of the sel ected features space are well clustered around their mean within each class, and t he clusters of the different classes are well separated. Also, the criteria J have the advantage of being invariant under linear transformation.

The regression analysis considers the re lations between the selected features which minimizes redundancy. While using regression analysis for data, a multiple regression model is considered because there can be many features which could affect the presence or absence of samples from a particular class. A multiple regression model with a target variable y and multiple variables X is given by [15]: Where  X  0 ,  X  1 , ...  X  m are constants estimated by observed values of X and class label y and is estimated by normal distribution having mean zero and a variance  X  . The sum of square errors (SSE) is given by Where y and y p are observed and predicted value s respectively. A large value of SSE means that the regression is predicted poorly. The total sum of squares is given by Where  X  y is the average of y i . In a regression model the choice of features which best explains the class label depends on the value of R 2 which is given by The EEG data used in our experiment was acquired by Keirn and Aunon[29] us-ing the following procedure. The subjects were seated in an Industrial Acoustics Company sound controlled booth with dim lighting and noiseless fans for ven-tilation. An Electro-Cap el astic electrode cap was used to record from positions C3, C4, P3, P4, O1, and O2, defined by the 10-20 system of electrode placement. The electrodes were connected through a bank of Grass 7P511 amplifiers and bandpass filtered from 0.1100Hz. Data wa s recorded at a sampling rate of 250 Hz with a Lab Master 12 bit A/D conver ter mounted in an IBM-AT computer. Eye blinks were detected by means of a se parate channel of data recorded from two electrodes placed above and below the subjects left eye.

For our experiment, the data from six subjects except subject 5 performing five different mental tasks were analyzed. The five mental tasks are: the baseline(B) task, for which the subjects were asked to relax as much as possible; the letter(L) task, for which the subjects were instructed to mentally compose a letter to a friend or relative without vocalizing; the math(M) task, for which the subjects were given non-trivial multiplication problems, such as 49 times 78, and were asked to solve them without vocalizing or making any other physical movements; the visual counting(C) task, for which the subjects were asked to imagine a blackboard and to visualize numbers being written on the board sequentially; and the geometric figure rotation(R), for which the subjects were asked to visualize a particular three-dimensional block figure being rotated about an axis.
Data was recorded for 10 seconds during e ach task and each task was repeated five times per session. Most subject s attended two such sessions recorded on separate weeks, resulting in a total of 10 trials for each task. With a 250 Hz sampling rate, each 10 seco nd trial produces 2,500 samples per channel. These are divided into half-second segments that overlap by one quarter-second, producing at most 39 segments per trial segments containing eye blinks are discarded.
Features are extracted from each one of signal using EMD. Each signal is represented in terms of 180 statistics (5 IMFs x 6 parameters 6 channels). To remove redundancy from the selected pool of features, three feature selection measures are investigated: Chernoff distance measure, ratio of with-in class scat-ter and between class scatter and linear r egression. For Chernoff distance mea-sure, features are selected using 3 different values ranging from 0.1 to 0.9 with an increment of 0.4. We have used linear discriminate classifier (LDC), Quadratic discriminate classifier (QDC), k-nearest neighbor (KNNC) and Support vector machine (SVC) to evaluate the performan ce of the feature selection methods. The average classification accuracy is co mputed using ten cross-validations. All the simulations are done using matlab. Tables 1 and Table 2 show the mini-mum classification accuracy achieved wi th different classifiers and the number of features for different measures resp ectively. For Chernoff distance measure, the maximum classification accuracy achieved over different values of  X  is shown in Table 1. The best results in each category are indicated in bold. Figures 1-2 and Tables 1-2 show the variation of classification accuracies and minimum number of features for the different mental tasks respectively. Figures 1-2 shows at end of this manuscript. We observe the following from Tables 1-2: 1. The classification accuracy of all mental tasks classification improved signif-2. The maximum average classification accuracy of mental tasks is achieved 3. The average classification accuracy of mental tasks with SVC and LDC are 4. The performance of ratio of scatter matrices in combination of both LDC 5. The number of features required to obtain maximum classification accu-6. As the number of features required to obtain maximum classification accu-* WFS=Without feature selection The performance of a classifier depends on the choice of features and classifier for any pattern recognition system. Features based on Empirical Mode Decom-position from EEG signal is extracted. These features may contain irrelevant and redundant features which makes them inefficient for machine learning. Hence, rel-evant features which provide maximum cl assification accuracy are selected using ratio of scatter matrices, Chernoff dist ance measure and linear regression. The performance of different mental task usi ng different measures used for feature selection is compared and evaluated in t erms of classification accuracy. Experi-mental results show that classification accuracy of all mental tasks classification improve significantly with the use of feature selection methods. In particular the performance of ratio of scatter matrix is better for all classifiers except KNN. The time required to learn the model will decrease significantly as the number of features reduces with the use of feat ure selections.In f uture, there is need to develop a feature selection method for mental task classification which gives better performance by all classifiers. It is also required to find out a method of feature extraction which extracts minimal and most relevant features from EEG signal for mental task classification and does not require any further feature selection.

