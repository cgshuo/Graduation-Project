 In this paper, we revisit the dependence language model for information retrieval proposed in [1], and show that this model is deficient from a theoretical point of view. We then propose a new model, well founded theoretically, for inte-grating dependencies between terms in the language model. This new model is simpler, yet more general, than the one proposed in [1], and yields similar results in our experiments, on both syntactic and semantic dependencies.
 Categories and Subject Descriptors: B.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Algorithms, Theory Keywords: Information retrieval, language model, syntac-tic/semantic [1] introduces a dependence language model (that we will refer to as DLM ) for IR which, based on the standard lan-guage model ([5]), integrates syntactic dependencies in the computation of document relevance scores. This model re-lies on a variable L , loosely defined as a  X  X inkage X  over query terms, which is generated from a document accord-ing to P ( L | M d ), where M d represents a document model. The query is then generated given L and M d , according to P ( Q | L, M d ). In principle, the probability of the query, P ( Q | M d ), is to be calculated over all linkages Ls , but, for efficiency reasons, the authors make the standard assump-tion that these linkages are dominated by a single one, the most probable one: L = argmax L P ( L | Q ). P ( Q | M d ) is then formulated as: In the case of a dependcy parser, as the one used in [1], each term has exactly one governor in each linkage L , so that the above quantity can be further decomposed, leading to: log P ( Q | M d ) = log P ( L | M d ) + P i =1 ..n log P ( q where MI denotes the mutual information, and:  X  P ( R | q i , q j ) in the above equation represents the empirical estimate of the probability that concepts q i and q j are re-lated through a parse in document d .

As the reader may have noticed, there is a certain ambi-guity in the way the linkage L is used in the DLM model, ambiguity which is due, we believe, to the lack of a clear def-inition of what a linkage represents. In particular, according to equation 3, the probability P ( L | M d ) assumes the knowl-edge of the query terms, so that a linkage represents a set of dependencies over a set of known terms. However, in equa-tion 1, such an interpretation cannot hold, as it would lead to disregard the term P ( Q | L, M d ) (as all the query terms are known in L ), a quantity which is nevertheless necessary to derive the final form of the model given in equation 2. This ambiguity in the definition of L might not be impor-tant in practice, as it finally amounts to rely twice on the contribution of term pairs, which can be counter-balanced with appropriate smoothing. However, it is not completely satisfactory from a theoretical point of view.

Without loss of generality, we assume that a syntactic and/or semantic analysis of a query q can be represented as a graph G q = ( C, E ), where C is the set of terms (or concepts) in q , and E is a binary relation from C  X  C in The probability that the graph of query q is generated by the model of document d can be decomposed as 1 : Assuming that, conditioned on M d , query terms/concepts are independent of one another (a standard asumption in the language model), and that, conditioned on M d and C , edges are independent of one another (again a standard as-sumption, also made in DLM ), we can write:
In the DLM model, a query is also implicitly represented as a graph (in fact a dependency parse), as the only linkage used is the most probable one, obtained by a parser trained on the collection.

Equation 5 corresponds to the standard language model (potentially applied to concepts), and is similar to the sec-ond contribution of the right-hand term of equation 2. The estimated through maximum likelihood. Following stan-dard practice in language modeling, one can furthermore  X  X mooth X  this estimate by adding a contribution from the collection. This results in: and c j are linked in the document (collection). Similarly, D ( c i , c j ,  X R ) ( C ( c i , c j ,  X R )) is the number of times c are observed together in the document without being linked. The model we have just defined (which we will refer to as GLM , for Graph Language Model ) is well motivated from a theoretical point of view, and can be applied to any graphical representation of queries and documents. Furthermore, it relies on only two terms, which are easy to estimate, whereas the DLM model uses three terms, with a somewhat complex estimation of the term P ( L | M d ). Lastly, it is easy to see that the GLM model generalizes the bigram model presented in [6]. We now show how this model behaves experimentally.
In order to assess the GLM model and answer the above question, we conducted two series of experiments on the collection of ImageCLEF 2 . In the first series, we used Mini-Par ([3]) to produce a dependency parse for both queries and documents. In the second series, we derived a semantic graph for queries and documents from UMLS. In the latter case, we replaced all possible instances of concepts by their corresponding concept(s), and retained all the relations be-tween concepts provided in the semantic network associated with UMLS. As the collection in ImageCLEF focuses on pathologies and anatomic diseases, we did not take into ac-count the NCI and PDQ thesauri of UMLS, which focus on cancer. This filtering step is similar to the one proposed in [4]. In all cases, we retained only full words (ie words http://ir.shef.ac.uk/imageclef/. This collection consists of written diagnostic with associated images. We retrieved only the text part of documents as it enables the use of se-mantic relations presents in UMLS and thus allows testing the integration of syntactic and semantic graphs. corresponding to nouns, adjectives, verbs abd adverbs). In order to estimate the parameters of our models (namely the smoothing coefficients), we divided the 55 queries available from ImageCLEF 2005 and 2006 in two sets: 25 queries were randomly selected for training, and 30 for testing. Lastly, we retained two measures for evaluation: the mean average precision, and the precision at 5 documents. Also note that we use the DLM model as is on semantic relations, even though this use is not theoretically justified.

Table 1 shows that on both the syntactic and semantic dependencies, the models DLM and GLM performs in a similar way (no significant difference was detected using a Wilcoxon signed rank test at the level 0.05). On this collec-tion, there is furthermore no significant difference between these two models and the LM model, which does not make use of the relations between terms. This observation agreees with some of the results reported in eg [2]. Lastly, it is inter-esting to note that the semantic indexing we have retained significantly improves the results over the syntactic one, and shoud be preferred here.
In this paper, we have shown that the DLM proposed in [1] is flawed theoretically. We have then proposed a new model for integrating dependencies between terms that is (a) well founded theoretically, (b) simpler and (c) more general. Our experimental results suggests that this new, simpler model behave similarly to the DLM model, and may thus be preferred over it. [1] J. Gao, J.-Y. Nie, G. Wu, and G. Cao. Dependence [2] C. Lee, G. G. Lee, and M. G. Jang. Dependency [3] D. Lin. Dependency-based evaluation of MiniPar. In [4] Y. H. H. Lowe and W. Hersh. A pilot study of [5] J. M. Ponte and W. B. Croft. A language modeling [6] M. Srikanth and R. Srikanth. Biterm language models
