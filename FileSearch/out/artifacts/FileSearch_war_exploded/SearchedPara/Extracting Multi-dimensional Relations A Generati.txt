 Extracting relations among different entities from various data sources has been an important topic in data mining. While many methods focus only on a single type of re-lations, real world entities maintain relations that contain much richer information. We propose a hierarchical Bayesian model for extracting multi-dimensional relations among en-tities from a text corpus. Using data from Wikipedia, we show that our model can accurately predict the relevance of an entity given the topic of the document as well as the set of entities that are already mentioned in that document. H.5.3 [ Group and Organization Interfaces ]: Web-based interaction; I.2.7 [ Natural Language Processing ]: Text analysis; I.7.1 [ Document and Text Editing ]: Languages Algorithms, Languages, Experimentation web mining, text mining, relations extraction, social network extraction
Extracting relations among different entities from various data sources has been an important topic in data mining. Different types of relations are considered in the literature, such as co-authorship [15, 17] and social relations [13]. In fact, even when explicit relations are available among the en-tities concerned, it is still desirable to estimate the strengths of their relations [2, 20].  X  This work described in this paper was carried out when Au Yeung was a research associate at the NTT Communication Science Laboratories in Kyoto, Japan.

Previous works on relation extraction mainly focus on whether a relation exists between two entities. However, real world entities maintain relations that contain much richer information. A relation may only be defined in a particular context (topic). Taking social relations as an example, while Albert Einstein was closely related to other physicists, he, as a player of the violin, also maintained friendships with Fritz Kreisler and Bronislaw Huberman, two famous musicians.
While many methods for extracting relations exist, little attention has so far been given to the topic or context of the relations. We propose a hierarchical Bayesian model for ex-tracting communities of entities under different topics from a text corpus. We assume that entities in a document are generated by picking a community, whose probability distri-bution depends on the topic distribution of the document. Our model is versatile and can be applied to extract rela-tions among any type of entities found in a text corpus, such as persons and companies. Using data from Wikipedia, we show that our model can accurately predict the relevance of an entity given the topic of a document as well as the set of entities that are already mentioned in that document. 1
We also demonstrate that our model and the results it generates open up new opportunities of analysing social net-works and other relationships. The various distributions in-volving topics, communities and entities allow us to under-stand whether a particular entity is specialised or diverse in terms of its relations with other entities. This allows us to go beyond the limitations of abstract relations and gain more insight into the multi-dimensional nature of social relations. One early systems for extracting social networks is the Referral Web system [11], which constructs a social network based on co-occurrences by crawling the Web. More re-cently, Matsuo et al. [13] propose using a Web search engine to extract relations among a group of academic researchers. Tang et al. [17] describe a framework for extracting re-search profiles and social relations of academic researchers. However, this type of works does not consider the fact that relations among people have different dimensions.

Cai et al. [6] propose methods for determining the rel-ative weights of different types of relations in a social net-work. Tang and Liu [18] focus on classification of persons in a social network with the help of so-called  X  X atent social dimensions X . Tang et al. [16] describes a model of social in-fluence among researchers in different topics, which can be
Wikipedia: http://www.wikipedia.org/ used to estimate how researchers influence one another in different topics. These works are related to our work in the sense that they attempts to model the multiple dimensions of relations. However, they are mainly designed to operate on well-defined network structures.

Topic modelling is used by some to model relations among persons. McCallum et al. presents the Author-Recipient-Topic (ART) model in [14] for analysing email communi-cations. Wang et al . [19] propose the Group-Topic model to extract groups of people who have similar behaviours in some context, such as voting in the parliament. These works are similar to ours, but they are more specific and less suit-able for the general objective we want to achieve.

Some other works explore ways to extract specific relations between two given entities (e.g. [1] and [5]). These methods aim at discovering specific semantic relations among entities. Chang et al . [7] propose a hierarchical Bayesian model for extracting this kind of specific relations in a principled way. While these methods are very useful, they are less applica-ble to large corpus because the number of possible relations increases dramatically as the number of entities increases.
Joshi and Gatica-Perez [10] propose to use probabilistic latent semantic analysis (PLSA) to obtain latent topics in news articles. The topic distributions are then used to esti-mate the probabilities of people in a particular topic. In con-trast, our proposed method incorporates clustering of people into the process of topic modelling, and is therefore able to discover topics and communities that are more relevant to the relations among the people involved.
We attempt to capture multi-dimensional relations by con-sidering a generative process. In topic models such as LDA [4], each word in a document is generated by first sampling a topic and then by picking a word based on the word distribu-tion of the topic. We propose the Community Topic Model that extends this idea by assuming that entities found in a document is also generated using a similar process. We note the following two important formulations of our proposed model: (1) Entities are generated by communities, which are generated by topics with distributions proportional to the topics of the words in the document, a formulation sim-ilar to the one described in [9]; (2) Entities are generated in pairs instead of one at a time.

The first formulation is based on the fact that different groups of entities may exist under the same topic. Adding the community latent variable would allow us to discover more coherent groups of entities. As for the second assump-tion, we design the model in such a way that for each commu-nity, entities are generated in pairs. This has the effect that each entity in a document is considered multiple times with all other entities, such that even in the same document an entity can be generated from different topics and communi-ties. This increases the similarity between two entities when they appear together more frequently. We do not directly model every pair of relations. This is because this will result in exponential growth of parameters in the model. Entities that are assigned to the same community can be considered to be related to one another in that context.
Figure 1 shows the graphical model representation of the proposed Community Topic Model, along with the descrip-tions of the symbols. Formally, our proposed model assume the following generative process of a corpus D : 1. For each topic k = 1 ,...,T : 2. For each community g = 1 ,...,G : 3. For each document j in D :
To estimate the parameters of the model, we employ Gibbs sampling [8]. Let w be the words in the corpus, z be the topic assignment vector of words, c be the topic assignment vector of airs of entities, and g be the group assignment vector of pairs of entities. Firstly, we sample a topic for the i -th word in the j -th document conditioned on all other variables as follows: where N  X  ij kj represents the number of times a word in docu-ment j is assigned to topic k , and N  X  ij kw ber of times the word w ij is assigned to topic k in the whole corpus. The superscript  X  ij indicates that the instance ij is excluded from the counting in the above variables. M kj represents the number of times a pair of entities is assigned to topic k in document j . V is the total number of unique words in the corpus.

Next, we sample the a topic for the r -th pair of entities in the j -th document conditioned on all other variables as follows: assigned the topic l in the whole corpus except the instance rj under consideration. G is the total number of unique communities.

Finally, we sample a community of a pair r of entities ( a , b ) in the j -th document conditioned on all other variables as follows:
P ( g rj = h | z , w , c , g  X  rj ) where O  X  rj ha is the number of times the entity a is assigned the community h in the whole corpus except the instance of rj under consideration. Y is the total number of unique entities in the corpus.

As we go through the Gibbs sampling process, the count-ing variables N , M and O are updated accordingly. We can then estimate the parameters of the model as follows.
Our main objective here is to experiment with extraction of topical communities and relations, and to investigate the performance of our proposed model. We choose Wikipedia as our data source, such that we can easily extract names of entities, such as persons and companies, based on some heuristic rules. This allows us to focus on the task of re-lation extraction, instead of worrying about named entity recognition. Our English Wikipedia dataset is obtained by downloading the XML dump file generated on 17th August, 2010. 2 It contains all current versions of the articles in the English Wikipedia at the time it was generated.

We carry out experiments on two different types of en-tities, namely persons and companies. To obtain a list of person names, we extract entities whose Wikipedia pages are assigned the following categories:  X  X YYY births X  and  X  X YYY deaths X . Using this method, we obtain a total of 688,248 person names. Among all the articles, 1,055,611 articles contain one or more names from this list.

As we can see in Figure 2, the majority of person names appear only in a few articles. We extract only person names that appear most frequently to run our experiments. Ar-guably, the top persons are most interesting because they are more likely to be engaged in multi-dimensional relations with one another. Specifically, we generate three datasets, with the top 1,000, 2,000, and 3,000 person names respec-tively. For each of these, we obtain articles that mention 5 or more persons from the respective lists.

In addition, we also obtain a set of companies in Japan. http://dumps.wikimedia.org/enwiki/20100817/ Figure 2: Number of articles in which a person is mentioned. Most persons are only mentioned in a few articles.
 Table 1: Datasets extracted from the Wikipedia dump for use in our experiments.
 We use this to demonstrate the applicability of our method on other types of relations. The list of companies names are collected from the article  X  X ist of Companies of Japan X , from which we extract a list of 593 company names. We find 23,376 articles that mention one or more of these com-panies. 3 Table 1 summarises the statistics of our datasets.
Our aim is to study whether our model can capture accu-rately the relations between different entities. We evaluate our model using a practical task: predicting whether an en-tity is considered relevant in a particular context given a document and a list of other relevant entities. We carry out our experiments using the following procedures for each dataset. 1. From each article, an entity is randomly selected and 2. Different models are trained on the training dataset, http://en.wikipedia.org/wiki/List_of_companies_ of_Japan 3. For each article, we use the trained models to predict 4. The above procedures are performed for 10 trials for
We measure performance by accuracy, which refers to the number of times the test entity appears in the top K can-didates returned by a model, ranked by their probabilities. Let e d be the test entity of article d , we define accuracy as follows. where  X  represents a trained model, C K ( d,  X ) is the set of top K candidates returned by  X  for document d . The value of accuracy ranges from 0 to 1. Ideally, relevant enti-ties should receive high probability than irrelevant entities. Thus, a good model should achieve high accuracy for low values of K .

For comparison, we consider the following four different models in our experiments.

This method considers only co-occurrence information and ignores the words that are found in the article. For each pair of entities ( x,y ), it estimates P e ( y | x ), the probability that y would be mentioned if x is already mentioned in an article. P ( y | x ) can be estimated as follows.
 where D x and D y represent sets of documents that contain the entities x and y respectively. This model can be used to predict the missing entity given a set X of entities that have already been mentioned in the article. A ranked list of candidates can be obtained by estimating the probability of an entity y using the following equation:
In this model, both word co-occurrence and entity co-occurrence for an entity are considered. For an entity y , in addition to P e ( y | x ) for x in all other entities, we also es-timate P w ( y | v ) for every word v appearing in the corpus. P ( y | v ) is estimated by: where D v represents the set of documents containing the word v . A ranked list of candidates is computed using the following equation: This is a simplified version of the Community Topic Model. Every entity in a document is generated in a way similar to that of generating a word. A topic is first sampled from the topic distribution of the document, then an entity is sam-pled from P ( y | z ), the entity distribution conditioned on the topic. This model conceptually resembles existing models in which both words and authors are directly generated from the topic sampled for the document. To generate a list of candidates for the task in our experiment, we estimate the probability P ( y | d ) by the following equation:
Our model estimates the following distributions: P ( z | d ) (  X   X  entity for a given document, we can estimate P ( y | d ), i.e. the probability of an entity given a document using the following equation: in which we can use P ( g | c ) to approximate P ( g | z ), because c and z have the same distribution.
Due to space limitation, we only present the results ob-tained by the worst and the best models for each datasets. Figure 3 shows the performances of the four models. We ob-serve that the  X  X o-occurrence + Word X  model (Baseline 2) gives higher accuracy than the  X  X o-occurrence only X  model. This is expected as the former consider also the content of the articles. This consideration is of particularly importance when some special words are unique to an entity. Overall, we can see that the proposed model achieves the best results in all datasets. While we see that accuracy decreases as we have more entities and articles in the dataset (and thus the task becomes more difficult), our method still performs rel-atively better than other methods in all cases. The Entity Topic Model performance is comparable to the Community Topic Model in the JP-Companies dataset, but is consis-tently worse that the latter in the Person datasets. This shows clearly the advantage of incorporating a hierarchical structure (topics and communities) in the model.
We take a look at whether the model produces reason-able results by looking at two selected articles in the Per-son dataset, namely  X  X istory of Films X  and  X  X istory of Phi-losophy X . These two articles are relatively long and men-tion many different persons. We remove these two articles from the Person-1000 dataset, and train a Community Topic Model using the rest of the articles. We then use the trained model to generate a list of person names for these two arti-cles as follows.

Firstly, we estimate the topic distribution given an unseen Table 2: Top 20 person names generated for two selected articles. Names that already appear in the article are bolded. article by where P ( z | w ) can be obtained by using the Bayes X  rule: Next, we estimate P ( y | d ), the probability of a person y given document d by in which we can use P ( g | c ) to approximate P ( g | z ), because c and z have the same distribution. Using the above equation, we can then come up with a ranked list of person names based on the words appearing in an article.

Tables 2(a) and 2(b) show the top 20 person names gener-ated by our model trained on the Person-1000 dataset with 100 topics and 200 communities. The names generated by the model match very well the topic of the two articles. For both articles, 14 out of the top 20 names are already mentioned in the articles. This shows that the model can accurately capture the associations between the persons and their relevant topics. Even for the names that are not found in the articles, they are actually highly relevant to the top-ics. For example, Clint Eastwood and Woody Allen are both well-known directors, and Karl Marx and Nietzsche are both important figures in the history of philosophy.
Our proposed model estimates the probability distribution of entities for each community. If an entity is associated with more than one topic, it will be assigned relatively high probabilities in multiple communities. This idea allows us to explore the multi-dimensionality of an entity.

Let P ( g | y ) be the probability distribution of communities given a particular entity y . If y appears in only one very specific context (e.g. y is a tennis player), then P ( g | y ) will have a single peak at the community involving tennis play-ers. If y appears in two or more different contexts (e.g. y is both a politician and a science fiction writer), P ( g | y ) will be multi-modal. This naturally points us to using entropy of the distribution as a measure of multi-dimensionality.
To measure the entropy of P ( g | y ) of a particular y , we first need to obtain P ( g | y ). While training the model we estimate P ( y | g ), therefore, we can easily obtain P ( g | y ) using the Bayes X  rule: P ( g 0 ) can be obtained by marginalising out c in P ( g | c ), while P ( c ) is approximated by P ( z )  X  P d P ( z | d ) P ( d ). By com-puting the entropy of P ( g | y ) for each y in the datasets, we can understand the multi-dimensionality of the entities.
Table 3 shows the top and bottom groups of entities in two of our datasets ranked by the entropy. For Person-1000, we find at the top of the list people who have their names asso-ciated with quite a number of topics. For example, Arnold Schwarzenegger is a well-known actor and politician. On the other hand, at the bottom we find mostly names of profes-sional tennis players. We note that in general professional sportsmen and athletes have low entropy values. Table 3: The top and bottom entities ranked by entropy.
 We observe similar and reasonable results in the list of Japanese companies. In the top group, we find mostly large corporations and conglomerates involved in a wide range of businesses, such as Sony and Sumitomo. On the other hand, in the bottom group, we find companies such as local banks that have very specific businesses.
We have demonstrated that our proposed model outper-forms other models in predicting relevant entities given a document. We have also showed that it generates meaning-ful and reasonable results regarding the multi-dimensionality of the entities found in a corpus. Nevertheless, we are also aware of certain limitations of the models.

Firstly, in our model topics and communities are consid-ered independent. However, two or more communities may be related to one another or they may form a hierarchical structure. We can extend the current model by considering the relations among topics/communities, using methods de-scribed in, for example, [3] and [12]. Secondly, we consider two entities to be related to each other if they appear in the same article. However, very often a long article contains multiple sections which are only weakly related to one an-other. We plan to consider only pairs of entities that appear within a certain window of text, or take into account the document structure of a Wikipedia article.

Regarding applications, our proposed model can be used to accurately predict relevant entities given the content of an article. Hence, an immediate idea of applying this model is to assist Wikipedia editors to develop existing articles by suggesting relevant but missing entities to an article. The model can even provide an explanation of why a certain entity is suggested. This will greatly facilitate editing of articles in Wikipedia.
We proposed a generative model of documents that takes into account the relations among entities appearing in the documents. The proposed model can be used to predict the relevance of an entity given a document more accurately than several other models. We also demonstrated how the model can be used to investigate multi-dimensional relations among entities. It also represents a more general approach to studying relations than existing works on heterogeneous networks, which require explicit information on how a par-ticular type of network is formed. [1] Y. E. Agichtein. Extracting relations from large text [2] C.-m. Au Yeung and T. Iwata. Strength of social [3] D. M. Blei and J. D. Lafferty. Correlated topic [4] D. M. Blei, A. Ng, and M. Jordan. Latent dirichlet [5] D. T. Bollegala, Y. Matsuo, and M. Ishizuka.
 [6] D. Cai, Z. Shao, X. He, X. Yan, and J. Han. Mining [7] J. Chang, J. Boyd-Graber, and D. M. Blei.
 [8] T. L. Griffiths and M. Steyvers. Finding scientific [9] T. Iwata, T. Yamada and N. Ueda. Modeling Social [10] D. Joshi and D. Gatica-Perez. Discovering groups of [11] H. Kautz, B. Selman, and M. Shah. The hidden web. [12] W. Li and A. McCallum. Pachinko allocation: [13] Y. Matsuo, J. Mori, M. Hamasaki, K. Ishida, [14] A. McCallum, X. Wang, and A. Corrada-Emmanuel. [15] P. Mika. Flink: Semantic web technology for the [16] J. Tang, J. Sun, C. Wang, and Z. Yang. Social [17] J. Tang, D. Zhang, and L. Yao. Social network [18] L. Tang and H. Liu. Relational learning via latent [19] X. Wang, N. Mohanty, and A. McCallum. Group and [20] R. Xiang, J. Neville, and M. Rogati. Modeling
