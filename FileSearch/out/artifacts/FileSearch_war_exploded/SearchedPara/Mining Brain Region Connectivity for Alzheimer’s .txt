 Effective diagnosis of Alzheimer X  X  disease (AD), the most common type of dementia in elderly patients, is of primary importance in biomedical research. Recent studies have demonstrated that AD is closely related to the structure change of the brain network, i.e., the connectivity among different brain regions. The connectivity patterns will pro-vide useful imaging-based biomarkers to distinguish Normal Controls (NC), patients with Mild Cognitive Impairment (MCI), and patients with AD. In this paper, we investi-gate the sparse inverse covariance estimation technique for identifying the connectivity among different brain regions. In particular, a novel algorithm based on the block coordi-nate descent approach is proposed for the direct estimation of the inverse covariance matrix. One appealing feature of the proposed algorithm is that it allows the user feedback (e.g., prior domain knowledge) to be incorporated into the estimation process, while the connectivity patterns can be discovered automatically. We apply the proposed algorithm to a collection of FDG-PET images from 232 NC, MCI, and AD subjects. Our experimental results demonstrate that the proposed algorithm is promising in revealing the brain region connectivity differences among these groups. H.2.8 [ Database Management ]: Database Applications -Data Mining; J.3 [ Life and Medical Sciences ]: Health, Medical information systems Algorithm Brain network, Alzheimer X  X  disease, neuroimaging, FDG-PET, sparse inverse covariance estimation
Alzheimer X  X  Disease (AD) is a progressively neurodegen-erative disease. It is the most common type of dementia in elderly patients. Currently, approximately 5 million people (about 10% of the population over 60) in the U.S. are af-flicted by AD. The estimated direct cost to care the patients is over $100 billion per year. As the population ages over the next several decades, the AD cases and the associated costs are expected to go up dramatically. AD researchers have thus intensified their efforts to investigate ways to de-lay, cure, or prevent the onset and progression of AD.
Objective and quantitative criteria, so called, biomarkers, are essential to evaluate the effectiveness of a potential treat-ment or prevention strategy. Although clinical assessment and neuropsychological tests provide valuable information for AD diagnosis [19, 11], recent studies have demonstrated that imaging parameters from brain scans are more sensitive and consistent measures of disease progression than cogni-tive assessment [20]. Some studies have shown that imaging measures correlate with cognitive test performance in Mild Cognitive Impairment (MCI) and AD  X  an initial step in the validation of markers that accurately predict the course of the disease. Thus, the neuroimaging research offers great potential to identify the sensitive and specific biomarkers that can distinguish between different types of subjects and open up opportunities to implement treatments in the early stages of disease when intervention may be most beneficial.
There are two commonly used neuroimaging techniques for AD study: [18F]-2-fluoro-2-deoxy-D-glucose positron em-ission tomography (FDG-PET) and volumetric Magnetic Resonance Imaging (MRI). FDG-PET is a functional imag-ing technique that measures the cerebral metabolic rate for glucose. MRI is a high-resolution structural imaging tech-nique that allows for the visualization of brain anatomy with high degree of contrast between the brain tissues. There imaging techniques have been shown to be effective for AD study [1, 30].

Recent studies have demonstrated that AD is closely re-lated to the alternations of the brain network, i.e., the con-nectivity among different brain regions [7, 23, 24]. It has been shown that the brain regions are moderately or less inter-connected for AD patients, and cognitive decline in AD patients is associated with disrupted functional connec-tivity in the brain [24]. The connectivity patterns may be useful as imaging-based biomarkers to distinguish Normal Controls, MCI and AD patients. It is thus important to develop computational tools for identifying the connectivity among different brain regions.
 In this paper, we study the S parse I nverse C ovariance E stimation (SICE) for the identification of brain region con-nectivity. SICE originates from the more broad problem of covariance matrix estimation from data [3]. It has been ob-served that the covariance matrix can be estimated robustly when enough entries of the inverse covariance matrix are set to zero [8]. On the other hand, it has been demonstrated in the literature that many inverse covariance matrices are sparse, such as genetic interaction networks [13, 25]. Fur-thermore, the sparse inverse c ovariance can be interpreted from the perspective of the undirected graphical model [16] which models and explains the relationship among a set of variables. In practice, it is usually reasonable to assume that the patterns of some variables can be predicted by a small subset of all variables, which leads to the sparsity of the inverse covariance matrix in the multivariate Gaus-sian distribution. These observations in theory and practice motivate the wide use of the sparse inverse covariance es-timation. It has been shown to be useful in various appli-cations, including evaluating patterns of association among variables [9], exploration of genetic networks [17], senator voting records analysis [2], hyperspectral image classifica-tion [4], and speech recognition [5].

In this paper, we propose a novel algorithm for SICE. Un-like most of the existing algorithms [2, 6, 12, 15, 17, 18], the proposed SICE algorithm estimates the inverse covariance matrix directly. One appealing feature of the proposed al-gorithm is that it allows the user feedback (e.g., prior domain knowledge) to be incorporated into the estimation process by imposing additional constraints in the optimization for-mulation, while discovering the connectivity patterns auto-matically. We apply the proposed algorithm to a collection of FDG-PET images from 232 NC, AD, and MCI subjects enrolled in the Alzheimer X  X  Disease Neuroimaging Initiative (ADNI) 1 . The experimental results reveal several interesting connectivity patterns among different brain regions. Our re-sults also demonstrate the benefit of using the user feedback for the understanding of the brain network.

The rest of the paper is organized as follows. Section 2 provides the background on AD and two neuroimaging tech-niques including MRI and FDG-PET. In section 3, we re-view the sparse inverse covariance estimation. The proposed algorithm is presented in section 4. Section 5 presents the experimental results. Section 6 concludes the paper and dis-cusses some future work.
Alzheimer X  X  disease is an irreversible, progressive brain disease which slowly destroys memory and thinking skills, eventually even the ability to carry out simple daily tasks [14]. Most AD diagnosis is based on clinical and psychometric assessment. [19] summarizes the clinical criteria for clini-cally probable AD, which include insidious onset and pro-gressive impairment of memory and other cognitive func-tions. Mini Mental State Examination (MMSE) is one of a number of cognitive tests carried out to clinical patients for disease diagnosis (MCI, AD, and NC classification) [11]. http://www.loni.ucla.edu/ADNI/ Although clinical assessment and neuropsychological tests provide valuable information for AD diagnosis, recent stud-ies have demonstrated that imaging parameters from brain scans are more sensitive and consistent measures of disease progression than cognitive assessment [20].

Medical Imaging techniques like MRI and FDG-PET have been used widely in understanding the human brain. Volu-metric MRI is a high-resolution structural imaging technique that allows for the visualization of brain anatomy with high degree of contrast between the brain tissues. T1-weighting of the MRI procedure is now a routine for visualizing and inves-tigating brain gray, white and cerebrospinal fluid (CSF) tis-sue. With this procedure, the contrast between these differ-ent brain tissue types are high and segmentation of the MRI data to different tissue types becomes feasible. The struc-tural information is used to study the volumetric changes in the brain related AD, which causes significant shrinkages in the gray matter, regionally and globally.

PET is a functional imaging technique that captures the metabolic activity of various brain regions. The PET scan-ner detects pairs of gamma rays emitted by a positron-emitting radionuclide (tracer), which is introduced into the body on a biologically active molecule. If the biologically active molecule chosen for PET is FDG, an radioactive ana-logue of glucose, the concentrations of tracer imaged then give tissue metabolic activity, in terms of regional glucose uptake. FDG-PET 3D images used in this study were from 49 AD X  X , 67 NC X  X , 116 MCI X  X  downloaded from ADNI. All the FDG-PET images available from ADNI undergo various pro-cessing like co-registration to a common coordinate system, averaging, standardization of image and voxel size and uni-formity in resolution. Demographic information of the sub-jects is shown in Table 1. Using SPM5 2 , the PET images are normalized to the standard Montreal Neurological Institute (MNI) template space, and the normalization quality was visually inspected.
Our current research is based on the regions of interest (ROI) from the PET data. The whole brain volume is di-vided into 116 anatomical volumes of interest (AVOI), de-fined by Automated Anatomical Labeling (AAL) [28]. Then the average of the voxel intensities over each AVOI for each subject is extracted and used for our analysis. Neuroimag-ing AD researchers have identified a number of AD affected brain regions, such as hippocampus, that are a sub-set of the 116 AAL defined ROIs. The domain expertise is useful for http://www.fil.ion.ucl.ac.uk/spm/ understanding the results of future data analysis. Table 2 gives the names of the 116 AVOIs.
In this section, we briefly introduce the sparse inverse co-variance estimation as well as some related work with the emphasis on numerical algorithms.

Suppose we have n samples independently drawn from a multivariate Gaussian distribution, and these samples are denoted as x 1 ,  X  X  X  ,x n  X  X  (  X ,  X ), where x i is a p -dimension vector,  X   X  IR p is the mean, and  X   X  IR p  X  p is the covariance to be estimated. Let  X  =  X   X  1 be the inverse covariance (or precision) matrix. The empirical covariance is denoted as S :
It is straightforward to derive that the maximum log like-lihood of inverse covariance matrix under a multivariate Gaussian model. Formally, the maximum likelihood esti-mateof X = X   X  1 can be obtained by maximizing where tr ( S  X ) is the trace of S  X . Assume that S is nonsin-gular. Computing the derivative of f w.r.t.  X  and setting it to zero, we get Thus, the maximum likelihood estimate of the inverse co-variance  X  is  X  = S  X  1 . If the dimensionality is larger than the sample size, i.e., p&gt;n , some types of regularization are necessary in order to estimate  X  since S is singular. The connection between the estimation of  X  and S in Eq. (1) suggests the possibility that we can obtain shrunken esti-mates through maximization of the penalized log likelihood function. Formally, we estimate  X  =  X   X  1 by maximizing the following objective function: where J ( X ) is a penalty function. In particular, in this paper we consider the following formulation of J ( X ): where vec( X ) is the vector form of matrix  X . In other words, vec( X ) 1 denotes the sum of the absolute values of all ele-ments of the positive definite matrix  X .

It is well-known that model sparsity can often be achieved by applying the 1 -norm regularization [10, 26]. This has been introduced into the least squares formulation and the resulting model is called lasso [26]. Similarly, the formu-lation in Eq. (2) with J ( X ) defined in Eq. (3) produces a sparse estimate for  X . Specifically, if the ij th component of the inverse covariance matrix  X  is zero, then variables i and j are conditionally independent, given the other variables in the multivariate Gaussian distribution. Thus, it makes sense to impose the 1 penalty to the estimation of  X  to increase its sparsity as in lasso [26].
A number of papers in the literature are devoted to the estimation of covariance matrices. It is observed that the covariance matrix can be estimated robustly when enough entries of the inverse covariance matrix are set to zero [8]. Meanwhile, it has been demonstrated in the literature that many biomedical and genetic networks are not fully con-nected and many genetic interaction networks contain many genes with few interactions and a few genes with many in-teractions [25, 13]. Therefore, many biomedical and genetic networks are intrinsically sparse and the corresponding in-verse covariance matrix is sparse. These observations in the-ory and practice motivate the development of efficient and effective sparse inverse covariance estimates.

In Gaussian graphical model [16], it assumes that the mul-tivariate vector follows a multivariate normal distribution with a particular structure of the inverse covariance struc-ture, a.k.a. precision or concentration matrix. It usually as-sumes that the patterns of some variables can be predicted by a small subset of all variables. This assumption leads to sparsity in the precision matrix of the multivariate distribu-tion, and results in the so-called neighborhood selection or covariance selection problem [8]. In other words, zeros in the inverse covariance matrix correspond to conditional in-dependence properties among the variables. In this setting, a sparse inverse covariance matrix, if it fits the data well, is very useful to practitioners, as it simplifies the understand-ing, and provides the insights into the data.

To determine the zero patterns in the inverse covariance matrix, the traditional method is based on the greedy forward-backward search algorithm [16]. Recently, some algorithms are proposed to solve sparse inverse covariance matrix. A gradient descent algorithm is proposed in [17] in which the sparse inverse covariance is computed by defining a loss func-tion that is the negative of the log likelihood function. A pe-nalized maximum likelihood estimation is considered in [15]. In [6], a set of large-scale methods are proposed to solve problems where a sparse structure of inverse covariance is known a prior. The interior point method for the  X  X axdet X  problem is proposed [18]. In [2], the 1 -norm regularization is considered, and two efficient algorithms are proposed: one is based on Nesterov X  X  first-order algorithm [22] which yields a rigorous complexity estimate; the second one uses the block coordinate decent approach to update rows/columns of the covariance matrix sequentially. The block coordinate decent algorithm is further improved in [12].
In this section, we present the proposed algorithm for solv-ing the following optimization problem: where S is the empirical covariance matrix, and  X  is the regularization parameter.

One drawback of many existing algorithms [12, 2] is that they directly estimate the covariance matrix. Since the goal is to estimate the sparsity structure of the inverse covariance matrix, a better approach is to compute the inverse covari-ance matrix directly. This also facilitates the incorporation of the user feedback (e.g., prior domain knowledge) into the formulation. The proposed approach estimates the inverse covariance matrix  X  directly, and it also follows the frame-work of the block coordinate descent [12, 2]. Specifically, we partition S and  X  in the form of block matrix: IR . Then we can reformulate log det  X  as follows: Thus, the problem in Eq. (4) can be formulated as:
In the block coordinate descent approach, we update each row/column while fixing other elements of matrix  X  in each iteration. To compute the optimal  X , we use ( S +  X I )  X  1 the initial guess of  X , then update each row/column of  X  repeatedly until convergence.

Inthefollowing,weassumethat X  11 is fixed and we need to update  X  12 and  X  22 . We can apply similar techniques to update other rows/columns. The subdifferential of f w.r.t.  X  12 can be computed as follows:  X  X  =  X  2 where SGN( t ) is a set-valued mapping for t  X  IR , and it is defined as: In fact, SGN( t ) is the subdifferential of | t | . For the vector v  X  IR p ,SGN( v ) is defined component-wise, i.e., the i th component of SGN( v )isdefinedasSGN( v i )where v i is the i th component of v . Clearly, SGN( v ) is the subdifferential of v 1 .
We also compute the subgradient of f with respect to  X  22 Note that  X  22 &gt; 0. We have The inequality in Eq. (8) guarantees the positive definiteness of  X . Let It is clear that SGN(  X  )=  X  SGN(  X  12 ). Then we can repre-sent the subdifferential of Eq. (6) as: It is clear that  X  X  is (a constant multiple of) the subdiffer-ential of the following optimization problem: Thus, the problem in Eq. (4) is equivalent to the one in Eq. (9) if  X  11 is fixed. Note that the problem in Eq. (9) is equivalent to the following min-max problem: max The equivalence relationship can be verified easily by com-puting the derivative of h (  X ,  X  ) w.r.t.  X  : Thus,  X  can be eliminated and the resulting problem is equivalent to Eq. (9). In practice, we use the prox method [21] to solve the min-max problem.

When  X  is solved, we can recover  X  12 =  X  1 s 22 +  X   X  .Next we show how to derive  X  22 . From Eq. (8), we have
The outline of the proposed algorithm is given in Algo-rithm 1. The global convergence of Algorithm 1 is guaran-teed due to the separability of the non-smooth 1 penalty term [27]. We have following property:
Theorem 1. The produced  X  ( j ) at the j -th iteration is strictly positive definite, i.e., for 1  X  j  X  p,  X  ( j ) 0 .Fur-thermore, the updating of  X  12 and  X  22 at each iteration per-mits a unique solution.

Proof. Note that if  X  11 is positive definite, the problem in Eq. (9) is strictly convex, then the unique solution of  X  is guaranteed. Hence, we can obtain unique solutions of  X  and  X  22 . Therefore, it suffices to show that  X  ( i ) is positive definite at each step in Algorithm 1.

We use mathematical induction to prove the positive def-initeness of  X  ( i ) , 1  X  i  X  p .Notethat X  (0) 0, thus the Algorithm 1 Sparse Inverse Covariance Estimation Input: empirical covariance S , parameter  X 
Initialize  X  (0) := ( S +  X I )  X  1 repeat until converge proposition is true in the basis step. Next suppose that  X  i ) 0, we consider  X  ( i +1) after one iteration. It follows from Eq. (8) that at each step we have Thus, we have Note that  X  ( i ) 11 is positive definite since  X  ( i ) 0, thus  X  is also positive definite after this iteration.

We check the convergence of Algorithm 1 by comparing the  X  matrices between two consecutive iterations. More specifically, let  X  new and  X  old be the solutions at the current and previous iterations, respectively. Then, the algorithm stops if ||  X  new  X   X  old || F holds for a certain threshold . We set =10  X  4 in our experiments.

Compared with the algorithms discussed in the last sec-tion, the proposed Algorithm 1 directly estimates the inverse covariance matrix  X . Thus, it facilitates the incorporation of the user feedback (e.g., prior domain knowledge) by impos-ing constraints to guide the optimization problem. For ex-ample, we can set  X  ij =0ifthe i th region and the j th region are known to be disconnected. Note that  X  =  X  ( s 22 +  X  )  X  in each iteration of the block coordinate descent approach, thus  X  ij = 0 implies that the corresponding entry in  X  is 0. Hence, we can enforce the corresponding entries in  X  to be 0 in each iteration. For a given  X  11 , the optimization problem in Eq. (9) can be reformulated as follows: where V is the set of indices (based on the user feedback) corresponding to zero entries in  X  . Note that this problem is also strictly convex and can be solved efficiently. Similarly, we can recover  X  12 and  X  22 from  X  .
We have performed experiments on the PET-AAL data which is acquired and preprocessed using the methods dis-cussed in Section 2. We applied the proposed algorithm to three different groups, including Normal Control (NC), Mild Cognition Impairment (MCI) and Alzheimer X  X  Disease (AD) patients. We set  X  =1 . 1 in all experiments. The regions considered in this study are the ones marked in bold type in Table 2. These regions are identified as being significantly impacted by AD. The names of regions with  X  X  X  stand for regions in the left hemisphere of the brain, and those with  X  X  X  stand for regions in the right hemisphere.

The resulting connectivity among different brain regions for AD, MCI, and NC are shown in Figures 1, 2, and 3, respectively. The resulting spa rse inverse covariance matrix is represented using a graph, where nodes correspond to the regions of the brain, and the edges connecting the nodes de-fine the conditional partial correlation between the nodes. Specifically, if  X ( i, j ) = 0, then regions i and j are condi-tionally independent, and there is no edge between them.
From these figures, we observe several interesting patterns in the brain network for each of the 3 diagnostic groups. Comparing Figures 1, 2, and 3, we can observe that the Occipital regions and the Temporal regions in MCI X  X  are not as strongly connected as in NC X  X . As for the AD pa-tients, we can observe from Figure 1 that these two types of regions are completely set apart. It can also be ob-served that hippocampus and parahippocampal gyrus inter-act with other regions in NC X  X , while they become isolated in AD X  X  and MCI X  X . The connectivity among the these four re-gions including Hippocampus L, Hippocampus R, ParaHip-pocampal L, and ParaHippocampal R also becomes weaker in AD X  X  and MCI X  X . The hippocampus belongs to the lim-bic system and plays major roles in short-term memory and spatial navigation. In AD, the hippocampus is one of the first regions of the brain to suffer damage, which results in memory problems among the first symptoms. Our experi-mental results clearly demonstrate that AD patients show a decreased level of functional connectivity within this net-work, which is consistent of the findings in AD study [29].
We can observe from Figure 2 that the edge between Oc-cipital Mid R and Temporal Mid R is the only connection between the Occipital and Temporal regions, while these two regions are completely separated in AD as shown in Figure 1. To test the significance of the connectivity between these two types of regions, we run the algorithm under the con-straintthatOccipital Mid R and Temporal Mid Rareiso-lated. The results are summarized in Figure 4. It is shown that the Occipital and Temporal regions are still connected with a link between Occipital Inf R and Temporal Mid R.
Next, we investigate the robustness of the generated net-work in AD study. Recall that one key feature of the pro-posed SICE algorithm is that it allows the user feedback to be incorporated into the estimation process by imposing ad-ditional constraints in the optimization formulation. In this experiment we study how the connectivity changes as more constraints are enforced in th e network. Since the patterns in AD patients are of great interest, we focus on the AD sub-jects. Specifically, we remove five links in the network in Fig-ure 1: the link between Temporal Pole Mid RandTempo-ral Pole Inf R 8302, the link between Cingulum Post Land Cingulum Post R, the link between Hippocampus LandPar -raHippocampal L, the link between Temporal Sup Rand Temporal Mid R, the link between Temporal Pole Mid L and Temporal Pole Sup R. We then run the algorithm un-der the above constraints. T he results are summarized in Figure 5. It can be observed that the connectivity in the sub-graph including the occipital and parietal regions remains almost the same. The experimental results show that the perturbation tends to affect the local topology of the gen-erated network only. We performed several other similar studies and observed a similar trend.

We compute the empirical correlation between twelve oc-cipital and parietal regions (form a subgraph) of AD pa-tients. The results are summa rizedinTable3. Theentries corresponding to the connections in the network generated by the proposed algorithm are highlighted in bold type and red color. We can observe from the table that a large cor-relation usually implies connectivity in the graph. However, it is not always the case, e.g., the (2 , 6)th entry. This may be due to the fact that the correlation captures the pair-wise information only, while the sparse inverse covariance estimation captures the interaction among all regions.
In this paper, we propose a novel sparse inverse covariance estimation algorithm to discover the connectivity among dif-ferent brain regions for AD study. One appealing feature of the proposed algorithm is that it can incorporate the user feedback into the estimation process, while the connectivity patterns can be discovered automatically. Our experimental results on a collection of FDG-PET images demonstrate the effectiveness of the proposed algorithm for analyzing brain region connectivity for Alzheimer X  X  disease study. We plan to develop an interactive software tool to help AD domain experts to investigate the connectivity among different brain regions. The typical diagnosis is an interac-tive process, in which the prior knowledge can be obtained and updated. We aim to integrate such prior knowledge seamlessly and reveal the connectivity more precisely.
Functional magnetic resonance imaging (fMRI) is a pro-cedure that is widely used for human brain function anal-ysis in normal controls as well as in diseased individuals. Most recently, it has been used to study the intrinsic activity and connectivity of the brain under resting condition (i.e., there is no cognitive task), a.k.a the default mode network (DMN). Recent researches have found significantly different DMN differences between AD patients and NC, opening the possibility of using the resting DMN as an AD diagnosis biomarker. We plan to investigate the functional MRI data for Alzheimer X  X  disease study using the proposed algorithm. This research is sponsored in p art by the Arizona Alzheimer X  X  Consortium and by NSF IIS-0612069 and IIS-0812551.
Data collection and sharing for this research was funded by the Alzheimer X  X  Disease Neuroimaging Initiative (ADNI; PI: Michael Weiner; NIH grant U01 AG024904). ADNI is funded by the National Institute on Aging, the National In-stitute of Biomedical Imaging and Bioengineering (NIBIB), and through generous contributions from the following: Pfizer Inc., Wyeth Research, Bristol-Myers Squibb, Eli Lilly and Company, GlaxoSmithKline, Merck &amp; Co. Inc., AstraZeneca AB, Novartis Pharmaceuticals Corporation, Alzheimer X  X  As-sociation, Eisai Global Clinical Development, Elan Corpora-Cingulum_Post_L Cingulum_Post_R Parietal_Sup_R Parietal_Inf_R Temporal_Sup_L Precuneus L, and Precuneus R. removing one link between Occipital Mid RandTemporal Mid R. texts for details). tion plc, Forest Laboratories, and the Institute for the Study of Aging, with participation from the U.S. Food and Drug Administration. Industry partnerships are coordinated thro-ugh the Foundation for the National Institutes of Health. The grantee organization is the Northern California Insti-tute for Research and Education, and the study is coordi-nated by the Alzheimer X  X  Disease Cooperative Study at the University of California, San Diego. ADNI data are dissem-inated by the Laboratory of NeuroImaging at the University of California, Los Angeles. [1] G. Alexander and E. Reiman. Neuroimaging. In M.F. [2] O. Banerjee, L. El Ghaoui, and A. d X  X spremont. [3] O. Banerjee, L. El Ghaoui, A. d X  X spremont, and [4] A. Berge, A.C. Jensen, and A.H.S. Solberg. Sparse [5] J.A. Bilmes. Factored sparse inverse covariance [6] J. Dahl, L. Vandenberghe, and V. Roychowdhury. [7] X. Delbeuck, M. Van der Linden, and F. Collette. [8] A.P. Dempster. Covariance selection. Biometrics , [9] A.Dobra,C.Hans,B.Jones,J.R.Nevins,G.Yao, [10] D.L. Donoho. For most large underdetermined [11] M.F. Folstein, S. Folstein, and P.R. McHugh. [12] J. Friedman, T. Hastie, and R. Tibshirani. Sparse [13] T.S. Gardner, D. di Bernardo, D. Lorenz, and J.J. [14] L. Heston and J. White. The vanishing mind: A [15] J.Z. Huang, N. Liu, M. Pourahmadi, and L. Liu. [16] S.L. Lauritzen. Graphical models .OxfordUniversity [17] H. Li and J. Gui. Gradient directed regularization for [18] Y. Lin. Model selection and estimation in the Gaussian [19] G. McKhann, D. Drachman, and M. Folstein. Mental [20] S. Molchan. The Alzheimer X  X  disease neuroimaging [21] A. Nemirovski. Prox-method with rate of convergence [22] Y. Nesterov. Smooth minimization of non-smooth [23] C.J. Stam, B.F. Jones, G. Nolte, M. Breakspear, and [24] K. Supekar, V. Menon, D. Rubin, M. Musen, and [25] J. Tegner, M.K. Yeung, J. Hasty, and J.J. Collins. [26] R. Tibshirani. Regression shrinkage and selection via [27] P. Tseng. Convergence of block coordinate descent [28] N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, [29] S. Wakana, H. Jiang, L.M. Nagae-Poetscher, P.C. van [30] J. Ye, K. Chen, T. Wu, J. Li, Z. Zhao, R. Patel,
