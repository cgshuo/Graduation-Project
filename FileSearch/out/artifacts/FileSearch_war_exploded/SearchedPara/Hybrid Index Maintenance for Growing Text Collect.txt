 We present a new family of hybrid index maintenance strate-gies to be used in on-line index construction for monotoni-cally growing text collections. These new strategies improve upon recent results for hybrid index maintenance in dynamic text retrieval systems. Like previous techniques, our new method distinguishes between short and long posting lists: While short lists are maintained using a merge strategy, long lists are kept separate and are updated in-place. This way, costly relocations of long posting lists are avoided.
We discuss the shortcomings of previous hybrid methods and give an experimental evaluation of the new technique, showing that its index maintenance performance is superior to that of the earlier methods, especially when the amount of main memory available to the indexing system is small. We also present a complexity analysis which proves that, under a Zipfian term distribution, the asymptotical number of disk accesses performed by the best hybrid maintenance strategy is linear in the size of the text collection, implying the asymptotical optimality of the proposed strategy. H.2.4 [ Systems ]: Textual databases; H.3.4 [ Systems and Software ]: Performance evaluation Experimentation, Performance Information Retrieval, Index Construction, Index Mainte-nance, Merge, In-Place, Hybrid
Index maintenance strategies for text retrieval systems in dynamic search environments, where index update opera-tions are interleaved with search queries, have been studied intensively over the past few years. In general, every main-tenance strategy can be described as a trade-off between Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00. index maintenance performance and query processing per-formance. Index update operations can be carried out very efficiently if we do not care about query processing perfor-mance; spending more time on index reorganization tasks, on the other hand, usually results in lower response times when processing search queries.

Although fully dynamic text collections allow document insertions, deletions, and modifications, in this paper we only focus on document insertions and discuss the problem of maintaining an inverted index for a monotonically grow-ing text collection  X  a restriction that is quite common in this area [6] [7] [11] [13]. For a discussion of index mainte-nance strategies in the presence of document deletions, see Chiueh and Huang [3] or B  X  uttcher and Clarke [1].
Virtually all existing index maintenance strategies for monotonically growing text collections work by accumu-lating postings for incoming documents in main memory, building an in-memory inverted file, and only combining this in-memory index with the existing on-disk data structures when a certain, pre-defined memory utilization threshold is exceeded. This way, disk accesses can be amortized over a larger number of index update operations, resulting in increased indexing performance. The individual update strategies only differ in how they combine the accumulated in-memory data with the data stored on disk.

Traditionally, index maintenance strategies for text re-trieval systems based on inverted files have either employed an in-place [13] or a merge-based [6] update scheme. In an in-place update scheme, whenever the data in memory have to be combined with the existing on-disk index, the in-memory posting lists are appended to the existing ones on disk. In general, this requires relocating existing on-disk lists. These relocations are time-consuming and can be avoided by using an overallocation strategy that leaves some amount of free space after every on-disk posting list. Only when the amount of free space is too small for the postings that are currently held in memory, the whole posting list has to be moved to a new location, where there is enough space for all postings for the given term. In contrast, merge-based strategies create a new on-disk inverted file by combining an existing one with the in-memory data. Although this requires a great number of disk operations, since the entire on-disk index has to be read, it usually can be done fairly efficiently because the number of disk seeks involved is very small, thanks to the largely sequential disk access pattern.
Roughly speaking, merge-based strategies are better at dealing with short posting lists, while in-place methods are better at handling long posting lists. Recently, we have pre-sented a family of hybrid strategies, based on a distinction between short and long posting lists [2]. Hybrid strate-gies maintain short posting lists following a merge-based approach, while long lists are updated in-place. By com-bining the two paradigms, they achieve better indexing per-formance than either approach alone.

In this paper, we present a new family of hybrid index maintenance strategies. Our new approach is based upon the same idea to distinguish between short and long posting lists and to treat them in different ways, but it corrects some shortcomings that we found in our previous technique. The new approach is similar to the pulsing technique proposed by Cutting and Pedersen [4] and allows the indexing system to view a posting list as the concatenation of a long list and a short list. It offers better indexing performance than the old one, especially if main memory is stinted.

In the next section, we give a brief overview of related work in the area of both off-line and on-line index con-struction, summarizing existing techniques and discussing the shortcomings of our previous hybrid index maintenance method. Section 3 contains a description of the new method. This is followed by an experimental evaluation of old and new index maintenance strategies in section 4. Finally, we give a theoretical analysis of the new hybrid method, in-cluding a proof that, under a Zipfian term distribution, the hybridization of Logarithmic Merge provides an amortized per-posting index maintenance disk complexity of O (1).
In this section, we give a summary of existing results in the area of off-line and on-line index construction. Inverted Files and Off-Line Index Construction
Inverted files have been proved to be the most efficient data structure in high-performance retrieval systems for large text collections [17]. An inverted file realizes a map-ping from terms to their posting lists. A term X  X  posting list (also called inverted list ) is a list of all occurrences of that term. An inverted file is a collection of posting lists, stored on a storage medium supporting random access. It is equipped with some search data structure (usually a search tree) that can be used to find the posting list associated with a given term. An example is shown in Figure 1.
Off-line index construction methods for static text collec-tions usually follow a collection partitioning approach that splits the whole collection into a set of smaller subcollec-tions, where the size of the individual subcollections is de-termined by the amount of main memory in the system. After an inverted file has been created for each such sub-collection, all these sub-indices are combined in a multiway merge process, yielding the final index representing the en-tire collection. [9] [16] [5]
In the context of this paper, all inverted lists con-tain full positional information , i.e. the exact locations of all occurrences of a given term (as opposed to mere docu-ment numbers). Inverted lists are split up into chunks con-taining  X  30,000 postings, and each chunk is compressed using a byte-aligned gap compression method [10], resulting in an average storage requirement of  X  12 bits per posting.
The off-line process described above can be transformed into an on-line method. Search queries are then processed by fetching posting lists from all sub-indices created so far and concatenating them. Query processing performance of this strategy is very poor, of course, because all lists are heavily fragmented, implying a great number of disk seeks during query processing. We use this strategy as the baseline for index maintenance performance and refer to it as No Merge (because the inverted files are only merged after the whole collection has been indexed).

An important property of inverted files is that, as long as posting lists are stored in lexicographical order within the inverted file, the search data structure does not need to explicitly contain the position of each term X  X  posting list. For example, if we know the positions of the list for the terms  X  X mpaired X  and  X  X mpolite X , then we can easily find all postings for  X  X mplicit X  by reading all on-disk data be-tween  X  X mpaired X  and  X  X mpolite X . If the unexplored area between two such terms is fairly small (upper limit in our implementation: 128 KB), this can be done very efficiently and does not pose a performance problem. If we allow list relocations, we lose this implicit information.
 In-Place Index Maintenance
In-place index update schemes combine the existing on-disk inverted file with the in-memory data by appending all postings from the in-memory index to the correspond-ing list in the on-disk inverted file (creating a new list if necessary). To make this possible, they use overallocation strategies: Whenever a posting list is written to disk, more space is allocated than is actually needed. This space can then be filled with postings from the in-memory index when the system runs out of memory the next time. From time to time, of course, lists have to be relocated in order to create more room for new postings at the end of the list.
In general, there are two types of in-place update strate-gies: Those that require on-disk posting lists to be contigu-ous [8] and those that do not [13]. Forcing posting lists to be contiguous minimizes the number of disk seeks necessary to fetch a posting list (and thus maximizes query processing performance). Allowing posting lists to be non-contiguous, on the other hand, helps avoid list relocations. It therefore increases index maintenance performance, but deteriorates query performance, due to a greater number of disk seeks.
The main problem of in-place update with contiguous posting lists is that, due to the frequent relocation of post-ing lists, no pre-defined ordering on the terms in the inverted file can be guaranteed. Therefore, it is necessary to maintain an explicit vocabulary data structure, containing for every Figure 2: Total number of postings in the index vs. number of postings in long lists. After 50% of the GOV2 text collection have been indexed, more than 82% of all postings are found in lists longer than 1,000,000 postings. term the position of its on-disk posting list. This data struc-ture can then be used to update posting lists in the order in which they are stored on disk. Since the vocabulary can be-come very large (more than 50 million different terms for the text collection used in our experiments), it does not fit into main memory any more, and vocabulary maintenance  X  X s opposed to posting list maintenance  X  becomes a challenging task (see [8] for details).
 Merge-Based Index Maintenance
In merge-based index maintenance strategies, postings are never directly added to an existing on-disk inverted list. In-stead, whenever in-memory postings have to be combined with on-disk data, the in-memory index is merged with an existing on-disk inverted file, resulting in a new inverted file that replaces the old one. The simplest merge strategy is called Immediate Merge . At any given point in time, this strategy maintains at most one active on-disk inverted file. When the indexing system runs out of memory, the in-memory data are merged with this inverted file, resulting in a new inverted file that supersedes the old one. Since every such merge operation requires the system to read the entire current on-disk index, the total amount of disk operations necessary to index a text collection containing N tokens is where M is the number of postings that can be held in mem-ory. Despite its simplicity and its obviously problematic quadratic disk complexity, it seems to be very difficult to find an in-place update scheme that outperforms the Imme-diate Merge strategy (cf. Lester et al. [7] [8]).
Recently, it has been studied how allowing the indexing system to maintain more than one inverted file at a time affects the performance of merge-based update schemes. Lester et al. [6] analyzed the case where the search system is allowed to use k independent on-disk inverted files at a time (for constant k ). In this situation, an optimal index maintenance strategy has an overall disk complexity of For k = 2, we refer to this strategy as Sqrt Merge .
Lester et al. [6] and B  X  uttcher and Clarke [1] also looked at the case where the maximum allowable number of on-disk inverted files is not constant, but logarithmic in the current size of the on-disk index. The strategy proposed by B  X  uttcher and Clarke makes use of the concept of index generation .An on-disk inverted file is of Whenever there is more than one on-disk index of the same generation n , all indices of that generation are merged, re-sulting in a new inverted file of generation n +1. This pro-cess is repeated until there are no more such collisions. This strategy leads to a set of on-disk inverted files of exponen-tially increasing size. Its total indexing disk complexity is We refer to this strategy as Logarithmic Merge .
 Hybrid Index Maintenance
Hybrid index maintenance is motivated by the fact that, for large text collections, the vast majority of all postings is found in very long posting lists containing several million entries (as shown in Figure 2). Copying these very long lists during re-merge operations (as required by Immediate Merge , for example), is very costly and should be avoided. Even though more modern strategies, like Sqrt Merge and Logarithmic Merge , substantially reduce the number of disk operations, the problem in principle remains the same. Therefore, it seems promising to distinguish between long and short posting lists and to update only short lists using a merge strategy, while long lists are updated in-place.
Earlier this year, we have presented a family of hybrid index maintenance strategies based on this distinction be-tween short and long lists [2]. The basic idea is rather sim-ple: As soon as the posting list for a given term exceeds a certain length (we refer to this as the long list thresh-old, denoted as T ), is is declared long and moved from the merge-updated part of the on-disk index to the in-place-maintained part. Every posting list in the in-place part is stored in an individual file. Whenever a frequent term with long posting list is encountered during a merge operation, its postings are appended to the corresponding file instead of being transferred to the targ et index of the current merge operation. From the indexing system X  X  point of view, each long list is stored contiguously inside its file. The actual de-tails (contiguousness, relocations) are left to the file system implementation (in our experiments, the ext3 file system that is part of the Linux kernel).

This technique can be combined with all three merge strategies described above, resulting in three different hy-brid index maintenance strategies. Since these hybrid strate-gies require all long on-disk posting lists to be stored con-tiguously, we refer to them as HIM C (Hybrid Immediate Merge ), HSM C (Hybrid Sqrt Merge ), and HLM C (Hy-brid Logarithmic Merge )  X  where the subscript  X  X  X  in-dicates contiguous posting lists.
 Shortcomings Hybrid Index Maintenance
The hybrid index maintenance strategies described above have several serious flaws. For the sake of brevity, we only discuss two major problems: Figure 3: Index layout for a hybrid maintenance strategy with non-contiguous posting lists. Each term X  X  posting list is the concatenation of a num-ber of list segments found in the in-memory index, the merge-maintained index, and the in-place index. The sub-list found in the in-place part of the index may consist of several non-contiguous segments. 1. Delegating the in-place update to the file system 2. Assume the long list threshold of HIM C is chosen as In this paper, we remedy these problems. We present a new family of hybrid strategies that is less sensitive to mem-ory limitations and more amenable to a formal complexity analysis, allowing us to get a deeper understanding of the subtleties of index maintenance for dynamic text collections.
Instead of enforcing a strict distinction between short and long posting lists, as done in our previous approach to hybrid index maintenance, the new strategies allow each posting list to consist of two parts  X  a long one, updated in-place (realized by a single, append-only inverted file), and a short one, maintained using one of the merge strategies. Only when the length of the short, merge-maintained part of the posting list exceeds a pre-defined threshold value T ,itis removed from the merge part of the index and added to the in-place part of the index. This method is similar to the pulsing technique described by Cutting and Pedersen [4]. Figure 4: Commands #53,437 -#53,445, taken from the whole sequence consisting of 27,204 update com-mands and 27,204 queries.
 The resulting index layout is depicted in Figure 3.
The new hybrid strategies start like any of the non-hybrid merge strategies described in section 2 ( Immediate Merge Sqrt Merge ,or Log. Merge ). During a merge operation, however, whenever a term is encountered for which there are more than T postings participating in the merge operation, all these postings are moved to the in-place part of the index instead of the target inverted file of the merge operation. This is done by simply appending the postings to the single inverted file that represents the in-place part.

In contrast to the contiguous hybrid strategies discussed in the previous section, our new strategies introduce addi-tional non-contiguities in the on-disk posting lists (because new postings are simply appended to the existing inverted file), causing additional disk seeks at query time. By choos-ing a large enough value for T , however, these query-time disk seeks can be amortized over a longer, sequential read operation If, for example, we choose T =10 6 ,andthehard drive can read 50,000 postings (sequentially) in the time it requires to perform a single random disk seek, then the relative slowdown caused by the additional disk seeks is at ues T , it is possible to control index maintenance and query processing performance. Smaller T values mean better up-date performance (because more postings are moved to the in-place part of the index). Greater T values mean better query performance (by reducing the number of disk seeks during query processing). In particular, T =  X  represents a pure merge-based strategy, while T = 0 is equivalent to the No Merge strategy  X  both create the same amount of fragmentation in the on-disk posting lists. The exact effect of a given T value depends on hard drive characteristics. By measuring the disk X  X  bandwidth and its seek latency, it is possible to find the right T valuefortherelativeslowdown tolerated  X  which, presumably, will depend on the relative update and query load of the system. 1
Since, in the in-place part of the on-disk index, posting list segments are not stored in any particular order, we need an additional data structure that tells us for every term in the inverted file the location of all its list segments. This is similar to the problem we described when we discussed the shortcomings of in-place update in section 2. This time,
It needs to be mentioned here that the criterion that defines when postings are transferred to the in-place index is slightly grubby. In our system, all postings are compressed and thus have different sizes, between 1 and 6 bytes, depending on the term X  X  frequency and locality. This should be taken into account. However, we decided to ignore this detail because it would make the analysis of our method more complicated. Figure 6: Impact of memory size on index mainte-nance performance. HLM C is more sensitive to the amount of available main memory than HLM NC and non-hybrid Logarithmic Merge. however, the situation is different. Only frequent terms can make it into in-place index, and their number is very small (only 13,309 terms appear more than 10 5 times in the GOV2 text collection, for instance) . We can therefore afford to keep the meta-information that is necessary to efficiently find all list segments for a frequent term in memory.

Depending on which merge strategy serves as starting point for the respective hybrid strategy, we refer to the new strategy as HIM NC ( Immediate Merge ), HSM NC ( Sqrt Merge ), or HLM NC ( Logarithmic Merge ). In each case, the subscript  X  X C X  indicates non-contiguous posting lists
Our experiments were conducted using the GOV2 text col-lection used in the TREC Terabyte track 2 . GOV2 consists of 25.2 million documents with a total size of 426 GB. In order to be able to measure index maintenance and query process-ing performance at the same time, we created a mixed up-date/search sequence consisting of 27,204 update operations and 27,204 search queries (randomly taken from the 50,000 queries used in the effiency task of the 2005 TREC Terabyte track), simulating an on-line search environment. A short subsequence is shown in Figure 4. Search queries are of the form  X  X ind all documents containing at least one of the query terms, rank them by their BM2 5 score, and return the doc-ument IDs of the top 20 documents X . All experiments were run on a single Linux PC based on an AMD Athlon64 3500+ CPU with 2 GB of main memory and 7,200-rpm SATA hard drives. The input documents were read from a RAID-0 ar-http://www-nlpir.nist.gov/projects/terabyte/ ray built on top of two 7,200-rpm hard drives. The size of the final index, containing full positional information for all terms appearing in GOV2, was 61 GB.
 Indexing and Query Processing Performance
In our first series of experiments, we had our retrieval sys-tem process the command sequence, building an index for GOV2 and concurrently processing 27,204 search queries. We allowed the system to use 512 MB of main memory for the in-memory index. For the 3 different merge strategies and various threshold values T , we analyzed index mainte-nance and query processing performance. From the results shown in Figure 5, it is obvious that our new strategies exhibit significantly better indexing performance than the non-hybrid methods. For T =10 6 ,HLM NC builds the index 17% faster than its non-hybrid counterpart (HSM NC : 49%; HIM NC : 155%). On the other hand, query performance only drops by 4% (HSM NC :7%;HIM NC : 10%). Compared to
No Merge ,HLM NC ( T =10 6 ) with 512 MB RAM only needs 47% longer to build the final index (6.86 hours instead of 4.66), but exhibits a vastly superior query processing per-formance  X  1.4 seconds per query, instead of 4.8 seconds.
For the non-contiguous hybrid strategies, decreasing T consistently improves indexing performance and decreases query performance in all cases. Moreover, there is a strict ordering between the individual strategies. For instance, in order for HSM NC to outperform Logarithmic Merge  X  X  in-dexing performance on GOV2, it needs T  X  2  X  10 5 .Atthat point, however, its query processing performance is much worse than that of Logarithmic Merge (cf. Figure 5). Space vs. Time Trade-offs
Our second series of experiments serves the purpose of finding out how the amount of RAM available for the in-memory index affects the index maintenance performance of our strategies. We therefore varied the amount of mem-ory available for the in-memory index between 64 MB and 1,024 MB. The results depicted in Figure 6 show that, while the indexing performance of HLM NC is changed only in-significantly, HLM C suffers severely from the reduced size of the in-memory index, and index construction time steps up from 7.39 hours (1024 MB) to 9.21 hours (64 MB)  X  a 25% increase. For comparison, indexing time with HLM NC only increases by 14% ( Logarithmic Merge : 18%).
In this section, we generalize the experimental results pre-sented in this paper in order to make them applicable to other text collections. We present a complexity analysis, based on the number of disk operations (measured by the number of postings transferred to/from disk) performed by the respective strategy. More specifically, we determine the number of disk write operations necessary to index a text collection of a given size. Since the number of read opera-tions carried out during merge operations is upper-bounded by the number of write operations (nothing is read twice), this allows us to calculate the total number of disk opera-tions performed (up to a constant factor).

We show that the HLM NC method only needs  X ( N )disk operations to construct an index for a text collection of size N . Asymptotically, this is the optimal indexing performance and is only rivalled by the No Merge strategy used in off-line index construction (which provides incompetitive query performance if used in an on-line environment). Our analy-sis is based on the assumption that the term distribution can be expressed as a generalized Zipf distribution [15], i.e., that the number of times the i -th most frequent word appears in the text collection is inversely proportional to i  X  : (rounded to the nearest integer), for some constants c and  X  (Zipf originally proposed  X  = 1). The same assumption has been made before for similar purposes (see, for exam-ple, Cutting and Pedersen [4]). Figure 7 suggests that, for the GOV2 collection, we have a Zipf exponent  X  somewhere in the neighborhood of 1.2. While our analysis does not de-pend on the fact that the term distribution is exactly Zipfian (using a Zipf-Mandelbrot distribution [12] would lead to the same result), it does rely on the convergence of the sum: We therefore assume  X &gt; 1. The sum X  X  value is given by Riemann X  X  Zeta function  X  (  X  ) and can be approximated by where  X  is the Euler-Mascheroni constant [14] (  X  = 0 . 5772 ... ). For realistic Zipf exponents (  X &lt; 1 . 4), the relative approximation error is less than 1%. We will there-fore always use the integral representation when we refer to the value of the Zeta function. Also, we will denote the term  X  + 1  X   X  1 from (1) as  X   X   X  . In order to achieve
N = and make the term distribution function consistent with the size of the text collection N ,welet We now use this term distribution to determine for a text collection consisting of N tokens the number of postings that are found in long posting lists (i.e., in lists that contain more than T postings, as defined in section 3). This result is then applied twice, once to analyze the disk complexity of Hybrid Immediate Merge and then a second time to analyze the disk complexity of Hybrid Logarithmic Merge . Figure 7: Comparing the term distribution of the GOV2 collection with Zipf distributions for various values of  X  . Zipf with  X  =1 . 2 seems to provide a lower bound for the total number of postings found in lists that are longer than 1,000,000 elements.
We first determine for a collection of size N the number of terms whose posting lists are longer than T postings, de-noted as L ( N, T ). From the definition of f T ( i ), we know: Hence, we have The total number of postings found in these lists is It immediately follows that the total number of postings found in short lists, i.e. in lists shorter than T postings, is  X 
S ( N, T ):= N In other words, the relative number of postings found in short lists converges to zero, as N  X  rhythmically and inex-orably  X  is marching towards infinity. The speed of conver-gence depends on the Zipf parameter  X  .

In the remainder of this section, we refer to the total number of postings found in short lists as  X  S ( N, T ), to the number of postings found in long lists as  X  L ( N, T ), and to the number of long lists as L ( N, T ).
 An Analysis of Hybrid Immediate Merge
Consider the Hybrid Immediate Merge strategy with non-contiguous posting lists (HIM NC ), as defined in section 3. In order to index a text collection containing N postings, HIM NC needs to perform N M merge operations, where M is the number of postings that can be stored in main mem-ory. In every such merge operation, HIM NC moves all long posting lists (containing at least T postings)itencounters to the in-place-maintained part of the on-disk index. For the merge-updated part of the on-disk index, which is the result of this merge operation, this means that it does not contain any lists that are longer than T postings.
Now, consider the merge-updated part of the on-disk in-dex that results from the k -th merge operation, i.e., that is created after k  X  M tokens have been added to the collection. This inverted file contains two types of lists: The latter happens if, for instance, the posting list for a term was moved from the merge-maintained to the in-place-maintained part of the index in the ( k  X  1)-th re-merge op-eration and the number of postings accumulated for that term between the ( k  X  1)-th and the k -th merge operation is smaller than T so that the hybrid strategy leaves these new postings in the merge-updated part of the index.

We can easily give a lower bound for the number of post-ings  X  P that are stored in the merge part of the index after the k -th merge operation: (using equation 5). We can also give an upper bound: (using equations 3 and 5). It follows that Of course, this is also the number of disk write operations necessary to create the particular index. Since, for a text collection of size N , the number of disk operations spent on adding postings to the in-place part of the index is the total number of disk operations needed to build an in-verted index for such a text collection is: For  X  =1 . 2 and constant T , this gives us an index mainte-nance disk complexity of  X ( N 1 . 833 M ), clearly better than the  X ( N 2 M ) complexity of non-hybrid Immediate Merge . An Analysis of Hybrid Logarithmic Merge
Finally, let us consider the Hybrid Logarithmic Merge strategy with non-contiguous posting lists (HLM NC ), as de-fined in section 3. Like every index maintenance strategy discussed in this paper, HLM NC accumulates postings in main memory until there is no more memory available, at which point an on-disk sub-index is created from the in-memory data. After M tokens have been added to the col-lection, two on-disk inverted files are created: We refer to the merge-maintained inverted file, created after M tokens have been added, as an index of generation 0.
After the first on-disk inverted file has been created, when-ever 2 k  X  M tokens have been added to the collection (for some integer k ), we have to merge two merge-maintained sub-indices of generation k  X  1 into a new merge-maintained index of generation k . This is the standard procedure of Logarithmic Merge . Here, however, because we follow a hybrid strategy, all long lists encountered during this merge operations are moved to the in-place part of the index in-stead of the new merge-maintained inverted file of genera-tion k . Using the same argument as before (for HIM NC ), we can give a  X -bound for the number of postings  X  P in this new merge-maintained inverted file of generation k : Therefore, the total number of disk write operations D ( k ) performed during merge operations, before and including the creation of this new inverted file of generation k ,is: (using equation 7). Hence, we have: For a text collection of size N =2 k  X  M , the number of disk operations spent on adding postings to the in-place part of the index is  X  L ( N, T )  X   X ( N ). Thus, the total number of disk operations needed to build an inverted index for a text collection of size N is: Since T is a constant, this means we need  X ( N )diskopera-tions. HLM NC  X  X  disk complexity is asymptotically optimal. Validation
In order to convince the suspicious reader of the correct-ness of the results obtained in this section, we use them to predict how changing the amount of available main mem-ory M and the threshold value T affects the overall index maintenance performance of our system. We assume that the GOV2 collection, consisting of 42 billion tokens, obeys Zipf X  X  law with  X  =1 . 25.

HIM NC ,with T =2  X  10 6 and 512 MB of RAM, needs 32.46 hours to index the GOV2 collection. Since the No Merge strategy, using the same amount of main memory, indexes the collection in 4.66 hours, the index maintenance overhead of HIM NC ( T =2  X  10 6 ) is 27.80 hours. According to equation 6, altering T by a factor x changes the total index maintenance overhead by a factor x 1  X  1 / X  .Thus,the expected total indexing time is: The experimentally obtained index construction times are 37.42, 27.61, and 23.43 hours, respectively  X  close to the predicted numbers.

HLM NC ,with T =10 6 and 512 MB of RAM, needs 6.87 hours to build the index, performing 150 merge operations ( k  X  7). The overhead, compared to No Merge ,is2.21 hours. Decreasing the available amount of memory to 256 MB decreases M by a factor of 2 and increases k by 1. Ac-cording to equation 12, this increases the index maintenance overhead by a factor from 2.21 hours to 2.54 hours. We therefore predict a to-tal indexing time of 4.66 + 2.54 = 7.20 hours. The time measured in our experiments is 7.19 hours, very close to our prediction. Similarly, for 1024 MB of main memory, we pre-dict a total index construction time of 6.58 hours. Again, this is close to the experimentally obtained time, 6.66 hours.
We have presented a new family of hybrid index main-tenance strategies to be used in on-line index construction for growing text collections. Like previous hybrid strate-gies, they are based on a distinction between long and short posting lists. Our experimental evaluation has shown that the new strategies outperform previous index maintenance strategies, including existing hybrid strategies  X  which do not work very well if only a small amount of memory is available for the in-memory index.

We have given a theoretical analysis of the disk complexity of our hybrid strategies, proving that the combination of Logarithmic Merge (for short lists) and in-place update with non-contiguous list segments (for long lists) results in an overall index maintenance disk complexity of O ( N )fora text collection of size N . This is asymptotically optimal.
The main shortcoming of the new strategies is their slightly reduced query processing performance, caused by internal fragmentation in the on-disk posting lists. We think that this problem can be solved by integrating overal-location strategies (and possibly relocation strategies) into the in-place part. In particular, a comparatively simple proportional preallocation strategy for inverted lists in the in-place index will improve query performance, while not affecting the asymptotical index maintenance complexity. [1] S. B  X  uttcher and C. L. A. Clarke. Indexing Time vs. [2] S. B  X  uttcher and C. L. A. Clarke. A Hybrid Approach [3] T. Chiueh and L. Huang. Efficient Real-Time Index [4] D. R. Cutting and J. O. Pedersen. Optimization for [5] S. Heinz and J. Zobel. Efficient Single-Pass Index [6] N. Lester, A. Moffat, and J. Zobel. Fast On-Line [7] N. Lester, J. Zobel, and H. E. Williams. In-Place [8] N. Lester, J. Zobel, and H. E. Williams. Efficient [9] A. Moffat and T. C. Bell. In-Situ generation of [10] F. Scholer, H. E. Williams, J. Yiannis, and J. Zobel. [11] K. A. Shoens, A. Tomasic, and H. Garc  X   X a-Molina. [12] Z. K. Silagadze. Citations and the Zipf-Mandelbrot X  X  [13] A. Tomasic, H. Garc  X   X a-Molina, and K. Shoens. [14] E. W. Weisstein. Euler-Mascheroni Constant. From [15] G. K. Zipf. Human Behavior and the Principle of [16] J. Zobel, S. Heinz, and H. E. Williams. In-Memory [17] J. Zobel, A. Moffat, and K. Ramamohanarao. Inverted
