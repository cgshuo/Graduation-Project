 Matrix analysis techniques, e.g., singular value decomposition (SVD), have been widely used in various data analysis applications. An important class of applications is to predict missing elements given a partially observ ed random matrix. For example, putting ratings of users into a matrix form, the goal of collaborati ve filtering is to predict those unseen ratings in the matrix. To predict unobserv ed elements in matrices, the structures of the matrices play an importance role, for example, the similarity between columns and between rows. Such structures imply that elements assumption, many machine learning models are not applicable.
 In this paper , we model the random matrix of interest as a single sample drawn from a matrix-model under such a prior by matrix-variate t model (MVTM). Our study shows several interesting properties of the model. First, it continues the line of gradual generalizations across several known probabilistic models on random matrices, namely , from probabilistic principle component analysis (PPCA) [11], to Gaussian process latent-v ariable models (GPL VMs)[7], and to multi-task Gaussian processes (MTGPs) [13]. MVTMs can be further derived by analytically marginalizing out the hyper-parameters of these models. From a Bayesian modeling point of view, the marginalization of hyper-parameters means an automatic model selection and usually leads to a better generalization performance [8]; Second, the model selection by MVTMs explicitly encourages simpler predicti ve models that have lower ranks. Unlik e the direct rank minimizat ion, the log-determinant terms in the finite matrices to infinite stochastic processes.
 Figure 1: Models for matrix prediction. (a) MVTM. (b) and (c) are two normal-in verse-W ishart models, equivalent to MVTM when the covariance variable S (or R ) is marginalized . (d) MTGP , which requires to optimize the covariance variable S . Circle nodes represent for random variables, shaded nodes for (partially) observ able variables, text nodes for given parameters. ficult to make predictions by computing the mode or mean of the posterior distrib ution. We suggest an optimization method that sequentially minimizes a convex upper -bound of the log-lik elihood, which is highly efficient and scalable. In the experiments, the algorithm shows very good efficienc y and excellent prediction accurac y.
 t models in Section 2. The prediction methods are proposed in Section 3. In Section 4, the MVTM is compared with some other models. We illustrate the MVTM with the experiments on a toy example and on the movie-rating data in Section 5. We conclude in Section 6. 2.1 A Family of Probabilistic Models for Matrix Data In this section we introduce three probabilistic models in the literature. Let Y be a p  X  m observ ational matrix and T be the underlying p  X  m noise-free random matrix. We assume Y i,j = T i,j + i,j , i,j  X  N (0 ,  X  2 ) , where Y i,j denotes the ( i, j ) -th element of Y . If Y is partially observ ed, then Y I denotes the set of observ ed elements and I is the corresponding index set.
 Probabilistic Principal Component Analysis (PPCA) [11] assumes that y j , the j -th column vector W is a p  X  k loading matrix. By integrating out v j , we obtain the marginal distrib ution y j  X  N the place of WW &gt; , PPCA is similar 1 to rows, and identity covariance I m between columns. PPCA aims to estimate the parameter W by maximum likelihood.
 Gaussian Process Latent-V ariable Model (GPL VM) [7] formulates a latent-v ariable model in a to observ ations y j . Instead of treating v j as random variables, GPLVM assigns a prior on W and are independent Gaussian random variables. By marginalizing out W , we obtain a distrib ution that each row of Y is an i.i.d. sample from a Gaussian process prior with the covariance VV &gt; +  X  2 I m From a matrix modeling point of view, GPLVM estimates the covariance between the rows and assume the columns to be conditionally independent.
 Multi-task Gaussian Process (MTGP) [13] is a multi-task learning model where each column of Y is a predicti ve function of one task, sampled from a Gaussian process prior, y j = t j + j , and t Wishart prior is added for the covariance, MTGP utilizes the inverse-W ishart prior as the regularization and obtains a maxim um a posteriori (MAP) estimate of S . 2.2 Matrix-V ariate t Models The models introduced in the previous section are closely related to each other . PPCA models the row covariance of Y , GPLVM models the column covariance, and MTGP assigns a hyper prior to prevent ov er-fitting when estimating the (row) covariance. From a matrix modeling point of view, capturing the dependence structure of Y by its row or column covariance is a matter of choices, which are not fundamentally different. 2 There is no reason to favor one choice ov er the other . By introducing the matrix-v ariate t models (MVTMs), they can be unified to be the same model. From a Bayesian modeling viewpoint, one should marginalize out as many v ariables as possible [8]. We thus extend the MTGP model in two directions: (1) assume T  X  N p,m ( T ; 0 , S , I m ) that have covariances on both sides of the matrix; (2) marginalize the covariance S on one side (see Figure 1(b)). Then we have a marginal distrib ution of T degree-of-freedom definition in literature, we use the definition in [5].
 Following the definition in [6], the matrix-v ariate t distrib ution of p  X  m matrix T is given by where  X  is the degree of freedom; M is a p  X  m matrix;  X  and  X  are positi ve definite matrices of gamma function, and |  X  | stands for determinant.
 The model can be depicted as Figure 1(a). One important property of matrix-v ariate t distrib ution same degree of freedom (see Section 3.1). Therefore, we can expand it to the infinite dimensional stochastic process. By Eq. (1), we can see that Figure 1(a) and Figure 1(b) describe two equivalent models. Comparing them with the MTGP model represented in Figure 1(d), we can see that the difference lies in whether S is point estimated or integrated out.
 hierarchical generati ve process on the covariance R , as described in Figure 1(c), where R follows the same model. This implies that the model controls the comple xity of the covariances on both sides of the matrix. Neither PPCA nor GPLVM has such a property .
 term in log-lik elihood or KL-di vergence. The log-determinant term encourages the sparsity of ma-trix T with lower rank. This property has been used as the heuristic for minimizing the rank of the matrix in [3]. Student X  s t priors were applied to enforce sparse kernel machine [10]. Here we say a few w ords about the given parameters. Though we can use evidence frame work[8] or other methods to estimate  X  , the results are not good in many cases(see [4]). Usually we just set validation is a good choice. For the mean matrix M , in our experiments, we just use sample average for all observ ed elements. For some tasks, when we have prior knowledge about the covariance between columns or between rows, we can use the covariance matrices in the places of I m or I p . the individual mode of the marginal posterior distrib ution, i.e., arg max T there is no exact solution for the marginal posterior . We have two ways to approximate the optimal prediction.
 prediction problem is The computation of this estimation is usually easy. We discuss it in Section 3.3. An alternati ve way is to use the individual mean of the posterior distrib ution to approximate the we only need to compute the joint posterior distrib ution. The problem of prediction by means is written as However, it is usually difficult to compute the exact mean. One estimation method is the Monte Carlo method, which is computationally intensi ve. In Section 3.4, we discuss an approximation to compute the mean. From our experiments, the prediction by means usually outperforms the prediction by modes.
 Before discussing the prediction methods, we introduce a few useful properties in Section 3.1 and suggest an optimization method as the efficient tool for prediction in Section 3.2. 3.1 Properties The MVTM has a rich set of properties. We list a few in the following Theorem.
 Theor em 1. If then This theorem can be directly derived from Theorem 4.3.1 and 4.3.9 in [6] with a little calculus. It provides some insights about MVTMs. The marginal distrib ution in Eq. (5) has the same form as the can use it to approximate the posterior distrib ution, which we use in Section 3.4. We encounter log-determinant terms in computation of the mode or mean estimation. The following theorem provides a quadratic upper bounds for the log-determinant terms, which makes it possible to apply the optimization method in Section 3.2.
 holds when X is an orthonormal matrix.
 Proof. Let {  X  1 ,  X   X   X  ,  X  p } be the eigen values of X . We have ln | X | = Since ln  X  i  X   X  i  X  1 , we have the inequality . The equality holds when  X  i = 1 . Therefore, when X is an orthonormal matrix (especially X = I p ), the equality holds.
 Theor em 2. If  X  is a p  X  p positive definite matrix,  X  is an m  X  m positive definite matrix, and T and T 0 are p  X  m matrices, it holds that where The equality holds when T = T 0 . Also it holds that  X  T 3.2 Optimization Method Once the objecti ve is given, the prediction becomes an optimization problem. We use an EM-style optimization method to make the prediction. Suppose J ( T ) be the objecti ve function to be apply this method. there exists a global minimum point of Q ( T ; T 0 ) as well, because Q ( T ; T 0 ) is upper bound of J ( T ) . Since Q ( T ; T 0 ) is quadratic with the respect to T , we can apply the Newton-Raphson method to minimize Q ( T ; T 0 ) . As long as T 0 is not a local minimum, maximum or saddle point of maximum. If T 0 is a local maximum, we can reselect a point, which is not. After we find a T i , we saddle point of J . Repeating this procedure, T i converges a local minimum or saddle point of J , as long as T 0 is not a local maximum. 3.3 Mode Prediction Following Eq. (2), the goal is to minimize the objecti ve function where ` ( T ) def =  X  ln Pr( Y I ) = 1 2  X  2 As b J contains a log-determinant term, minimizing b J by nonlinear optimization is slow. Here, we introduce an auxiliary function, convex as well. Therefore, we can apply the optimization method in Section 3.2 to minimize b J . However, when the size of T is large, to find b T is still time consuming and requires a very large space. In many tasks, we only need to infer a small portion of b T . Therefore, we consider a low rank approximation, using UV &gt; to approximate T , where U is a p  X  k matrix and V is an m  X  k where U and V are semi-orthonormal and S is a k  X  k diagonal matrix. This result can be consider as the SVD of an incomplete matrix using matrix-v ariate t regularization. The details are skipped because of the limit space. 3.4 Variational Mean Prediction model. We e xpand the model by adding matrix variate  X  ,  X  and  X  with distrib ution as Eq. (4). Since the marginal distrib ution, Eq. (5), is the same as the prior of T , we can derive the original model by marginalizing out  X  ,  X  and  X  . However, instead of integrating out  X  ,  X  and  X  , we use them as the parameters to approximate T  X  X  posterior distrib ution. Therefore, the estimation of the parameters is to minimize ov er  X  ,  X  and  X  . The first term in the RHS of Eq. (14) can be written as Due to the convexity of negative logarithm, the second term in the RHS of Eq. (14) is bounded by prediction by means usually outperforms the prediction by modes.
 Let J be the sum of the right-hand-side of Eq. (15) and (16), which can be considered as the upper bound of Eq. (14) (ignoring constants). Here, we estimate the parameters by minimizing J . Because A and B involve the inverse of quadratic term of  X  , it is awkward to directly optimize  X  ,  X  ,  X  . optimization method in Section 3.2 to find optimal U , V and S . After estimation U , V and S , by Theorem 1, we can compute T = M = USV &gt; . The details are skipped because of the limit space. Maximum Margin Matrix Factorization (MMMF) [9] is not in the frame work of stocha stic matrix analysis, but there are some similarities between MMMF and our mode estimation in Section 3.3. Using trace norm on the matrix as regularization, MMMF ov ercomes the ov er-fitting problem in factorizing matrix with missing values. From the regularization viewpoint, the prediction by mode of MVTM uses log-determinants as the regularization term in Eq. (12). The log-determinants en-courage sparsity predicti ve models.
 Stochastic Relational Models (SRMs) [12] extend MTGPs by estimating the covariance matrices for each side. The covariance functions are required to be estimated from observ ation. By maxi-mizing marginalized likelihood, the estimated S and R reflect the information of the dependenc y structure. Then the relationship can be predicted with S and R . During estimating S and R , inverse-Wishart priors with parameter  X  and  X  are imposed to S and R respecti vely. MVTM differs from SRM in integrating out the hyper-parameters or maximizing out. As MacKay suggests [8],  X  X ne should integrate ov er as many v ariables as possible X .
 Robust Probabilistic Projections (RPP)[1] uses Student-t distrib ution to extends PPCA by scaling each feature vector by an independent random variable. Written in a matrix format, RPP is where IG is inverse Gamma distrib ution. Though RPP unties the scale factors between feature vec-tors, which could make the estimation more robust, it does not integrate out the covariance matrix, which we did in MVTM. Moreo ver inherited from PPCA, RPP implicitly uses independence as-sumption of feature vectors. Also RPP results different models depending on which side we assume to be independent, therefore it is not suitable for matrix prediction. Synthetic data: We generate a 30  X  20 matrix (Fig-ure 2(a)), then add noise with  X  2 = 0 . 1 (Figure 2(b)). The root mean squared noise is 0 . 32 . We select 70% elements as the observ ed data and the rest elements are for predic-tion. We apply MMMF [9], PPCA[11], MTGP[13], SRM [12], our MVTM prediction-by-means and prediction-by-modes methods. The number of dimensions for low rank approximation is 10 . We also apply MCMC method to infer the matrix. The reconstruction matrix and root mean squared errors of prediction on the unobserv ed el-ements (comparing to the original matrix) are shown in Figure 2(c)-2(g), respecti vely. MTGP has the similar re-sult as PPCA, we do not show the result.
 MVTM is in favor of sparse predicti ve models. To v erify this, we depict the singular values of the MMMF method and two MVTM prediction methods in Figure 3. There are only two singular RMSE 1 . 425 1 . 387 1 . 186 1 . 165 1 . 162 1 . 151 Table 1: RMSE (root mean squred error) and MAE (mean absolute error) of experiments on Each-movie data. All standard errors are 0 . 001 or less. values of the MVTM prediction-by-means method are non-zeros. The singular values of the mode estimation decrease faster than the MMMF ones at beginning, but decrease slower after a threshold. This confirms that the log-determinants automatically determine the intrinsic rank of the matrices. Eachmo vie data: We test our algorithms on Eachmo vie from [2]. The dataset contains 74 , 424 The random selection was carried out 10 times independently . We compare our approach with other three approaches: 1) USER MEAN predicting rating by the sample mean of the same user X  ratings; 2) MOVIE MEAN, predicting rating by the sample mean of users X  ratings of the same movie; 3) MMMF[9]; 4) PPCA[11]. We do not have a scalable implementation for other approaches compared in the previous experiment. The number of dimensions is 10 . The results are shown in Table 1. Two MVTM prediction methods outperform the other methods. In this paper we introduce matrix-v ariate t models for matrix prediction. The entire matrix is mod-eled as a sample drawn from a matrix-v ariate t distrib ution. An MVTM does not require the inde-pendence assumption ov er elements. The implicit model selection of the MVTM encourages sparse models with lower ranks. To minimize the log-lik elihood with log-determinant terms, we propose an optimization method by sequentially minimizing its convex quadratic upper bound. The experiments show that the approach is accurate, efficient and scalable.

