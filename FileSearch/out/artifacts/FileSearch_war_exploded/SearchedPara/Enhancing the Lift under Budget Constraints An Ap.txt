 A lift curve, with the true positive rate on the y-axis and the customer pull (or contact) rate on the x-axis, is often used to depict the model performance in many data mining applications, especially in the area of customer relations hip management (CRM). Typically, these applications concern only the model accuracy at a relatively small pull or con-tact/intervention rate of the whole customer base, which is predetermined by a budget constraint for the project, e.g., how many customers can be contacted every month. In this paper, we address the important problem of enhancing the lift (true positive rate) at a specified pull rate. We propose two distinct algorithms, which are applicable to different scenarios. In particular, when the binary class label of the training set is extracted from a continuous variable, we can optimize a training objective which takes into account the specified pull rate rather than the class prior, based on the often ignored continuous variable. In those cases where onl y the binary class label is available during training, we pro-pose a constrained optimization algorithm to maximize the true positive rate related to a specific decision threshold a t which the specified pull rate is achieved. We applied both algorithms to our projects of predicting defection (declin e in account value) of mutual fund accounts for two major U.S. mutual fund companies and achieved substantial enhance-ment of the lift at the specified pull rate.
 H.4 [ Database Management ]: Database Applications -Data Mining; I.2.6 [ Artificial Intelligence ]: Learning; I.5.2 [ Pattern Recognition ]: Design Methodology -classifier design and evaluation Algorithms lift curve, ROC curve, true positive rate, pull rate, neural networks, mutual fund redemption Recently there has been a great deal of discussion on the Receiver Operating Characteristic or ROC curve [3] in ma-chine learning and data mining, e.g., [4], [9], [11], [8]. Th e ROC curve depicts the performance of a classifier by plotting the true positive rate against the false positive rate. Assu m-ing that a classifier produces a continuous output, then the output must be thresholded to label each sample as positive or negative. Thus, for each setting of the decision threshol d, a true positive and a false positive rate is obtained. By vary -ing the decision threshold over the range of the output, the ROC curve is produced. For many real-world classification problems, the ROC curve is believed to be a better perfor-mance metric than the typical correct classification rate [1 0]. The area under the ROC curve (AUC) is equivalent to the Wilcoxon-Mann-Whitney statistic, and is a general, robust measure of classifier performance [4].

A tightly related performance metric is the lift curve, which is rarely addressed in the academia but is widely used in real-world data mining applications, especially in the a rea of customer relationship management (CRM) [1]. Let us consider a project of predicting defection (decline in acco unt value) of mutual fund accounts. The mutual fund company would like to pull out a list of the most likely defectors and contact them to retain the potential defectors. Assuming that the model (a classifier) produces a continuous output and that a higher output corresponds to a larger probability of defection, for each customer pull (or contact) rate r , the customers with a model output in the highest r  X  100% will be labeled as positive and be included in the list. We can then produce a lift curve by varying the pull rate r , with the true positive rate on the y-axis and the customer pull rate on the x-axis, to visualize the model performance. An example of a lift curve can be found in Figure 1, where the diagonal line is for random sampling. The difference be-tween the true positive rate and r is the lift at pull rate r , which is equal to the true positive rate achieved by random sampling. The larger the lift, the more bowed the lift curve toward the upper left corner and the better the classifier X  X  ability to discriminate between the two classes.

This characteristic appears similar to the ROC curve; in fact, as derived in the Appendix, the area under the lift Figure 1: A lift curve with the theoretic limit, which is the straight line determined by the class prior p . curve (AUL) and the AUC have the following relationship: where p is the class prior (positive sample rate). For random sampling, both AUC and AUL are 0.5. However, note that when AUC is 1, i.e., for the perfect classification accuracy, the AUL is 1  X  p 2 . In Figure 1, we see that this corresponds to the theoretic limit line, which is determined by the prior p . Unlike the ROC curve, the shape of a lift curve depends on the class prior, since the x-axis is the pull rate which takes into account both positive and negative samples. Therefore , lift curves for data sets with dramatically different class p ri-ors cannot be directly compared.

According to Eq. 1, for a fixed prior p , optimizing the overall lift curve, measured by the AUL, is equivalent to op-timizing the AUC. It is demonstrated that error rate min-imization can be dissociated from the AUC maximization, and several approaches have been proposed to directly op-timize the AUC [11], [2]. One can also empirically search a prior or sample weights over the training set to find a better AUC [10]. However, here we tackle the important problem of enhancing the lift curve at a specific pull rate, predetermined by a budget constraint. When we look at specific points on the curves, lift and ROC curves are appli-cable to different scenarios in practice. In the CRM area, the ROC curve is well suited for some applications, e.g., for an incoming call center. The customer service represen-tatives will initiate some retention strategy for a custome r who calls in and whose defection score is above a certain threshold. This threshold can be established according to a specified false positive rate predetermined by some cost-profit analysis. Then, the focus is on the point on the ROC curve that corresponds to the specific false positive rate.
However, the lift curve is much more applicable to an application for a CRM campaign, which proactively makes outgoing calls (or other contacts) to customers. For these applications, there is typically a budget constraint which de-termines, among other things, the capacity of the customer service team or how many customers can be contacted, e.g., each month. The constraint is expressed as a customer pull (or contact) rate, and only the true positive rate or lift at the specified pull rate is important to the project. We would like to maximize the true positive rate tp for the pull rate r , which corresponds to a certain point on the lift curve. The relationship between a false positive rate fp and the pull rate r is in the form Eq. 2 shows that the false positive rate depends on both the pull rate and the true positive rate, which is unknown and is to be optimized. Thus, the pull rate predetermined by a budget constraint does not correspond to a specific point on the ROC curve before the model is trained. The ROC curve is ill-positioned to address this constraint of a certain pu ll rate.

Mozer et al. propose several approaches to prod a specific point on the ROC curve [8]. These approaches are shown to achieve a similar, small improvement at the specific true positive or true negative rates over the two data sets. It ap-pears that the constrained optimization approach in [8] can be straightforwardly extended to maximize the true positiv e rate subject to the constraint of a specific pull rate. In this approach, the sigmoid function is used to approximate the step function so that the true positive rate and the constraint (true neg-ative rate) can be differentiable. However, as noted in [11], the sigmoid function does not work well in providing a dif-ferentiable approximation to the step function. For a rel-atively small  X  , e.g.,  X  &lt; 2,  X  ( x ) softens I ( x ) too much when  X  1  X  x  X  1. We have found that the constrained optimization, using the sigmoid function in the objective, always achieves a worse true positive rate than minimizing the conventional mean squared error function for our data sets. A larger  X  makes  X  ( x ) closer to I ( x ), but it brings in numerical problems during optimization due to steep gra-dients. In Section 2.1, we propose a new constrained opti-mization algorithm which avoids using the sigmoid function as an approximation to the step function.

In some cases, the binary class label is extracted from a continuous variable according to a predetermined threshol d. For instance, we could label the mutual fund accounts which had a net redemption amount of 35% or more of the account balance in a specific time window as defectors or positives and other accounts as negatives. Here the class label is based on the continuous variable of the net redemption rate. Typically, the continuous variable is then ignored during training. In Section 2.2, we propose an approach to take advantage of the information from the continuous variable and to focus the training on the specific pull rate rather than the class prior. We then apply the two algorithms to our projects of predicting mutual fund account defection fo r two major U.S. mutual fund companies in Section 3.
Denote { x 0 , x 1 , . . . , x m positive samples, and { y 0 , y 1 , . . . , y n puts for n negative samples. We assume that the classi-fier produces high outputs for positive classifications and low outputs for negative classifications. The proposed algo -rithms can be applied to any parametric classifier, for which one can optimize the differentiable objective function with respect to the parameters using gradient based methods. 1 In this paper, we apply the proposed algorithms to a typical multilayer perceptron (MLP) network with softmax outputs, and with a single hidden layer and direct connection between the input and output layers. Our goal is to enhance the true positive rate (or lift) at the specified pull rate r .
Assume that the specified pull rate r can be achieved at a decision threshold  X  (0 &lt;  X  &lt; 1), i.e., the customers in the pull are those with an output larger than  X  . In order to maximize the true positive rate, we would like to push as many positive samples as possible above  X  , while also pushing as many negative samples as possible below  X  . We achieve this via minimizing the following objective: where and Here, p &gt; 1 and 0 &lt;  X   X  1. When S is zeroed, all the positive samples are above  X  +  X  and all the negative samples are below  X   X   X  . Also, note that, when x i &gt; =  X  +  X  , the i th positive sample stops contributing to the objective and subsequently the gradients. This is also true for a negative sample when y j &lt; =  X   X   X  . This mechanism makes the optimization focus on moving more positive samples x i to satisfy x i &gt;  X  (and more negative samples y j to satisfy y &lt;  X  ), rather than maximizing the difference between x and  X  (or y j and  X  ). 2 This is a key difference between our approach and approximating the true positive rate via the sigmoid function in [8]. Note that a positive margin  X  is needed for better generalization performance, which needs to be experimentally determined.

However, this optimization must be subject to the con-straint of the pull rate r , which is realized by the decision threshold  X  . Rather than trying to use a differentiable ap-proximation to r , we approximate a related ratio r 1 following differentiable function: In contrast, in [8], the true negative rate is approximated i n
We use the limited memory BFGS method in [7].
The similar mechanism explains the performance improve-ment and the ability to avoid overfitting in [11].  X  (  X   X  y j ) close to 1, this formulation provides a poor approx-imation to the true negative rate. In Eq. 8, both the numer-ator and denominator are functions of f ( u, v ) and g ( u, v ). If the optimization moves most samples close to the range between  X  +  X  and  X   X   X  , Eq. 8 will provide a better approx-quite close approximation to the constraint via Eq. 8. Now we convert the constrained optimization problem into an unconstrained problem by the following Lagrangian: During the training iterations,  X  is gradually decreased until convergence of the constraint ( C  X  r 1 be optimized with the model parameters, but we have found that fixing  X  at 0.5 achieves almost the same results over our data sets.
In many applications, the binary class label is extracted from a continuous variable according to a predetermined threshold. For instance, we use the (continuous) net re-demption rate to label the mutual fund accounts as defec-tors or stayers. Another example is churn prediction in the telecommunications industry [12], where churn can be de-fined as the percentage of active services dropped to a pre-determined threshold. Typically, the continuous variable is ignored during training once it has been used to generate the training labels. However, this continuous variable pro -vides useful information for training, especially when the specified pull rate is different from the class prior. 3 Naively, one may be tempted to train a regression model rather than a classifier, trying to take full advantage of the underlying continuous variable. However, regression is a much more difficult problem than binary classification and it outputs more but less accurate information than what we need. We will see shortly that a regression model based on the under-lying continuous variable provides much worse prediction accuracy. One might also try another intuitive approach: labeling the samples according to the pull rate rather than the predetermined threshold, i.e., for the training set, la bel-ing all the samples with a value of the underlying variable in the top r  X  100% as positives and others as negatives. Again, we will see that this simple approach does not work well either.

Our proposed approach is related to the simple approach above, but does not treat all the samples in the top r  X  100% as equal. Denote the underlying continuous variable as  X  , and, in this section only, X = { x 0 , x 1 , . . . , x m classifier outputs for the samples with the value of  X  in the top r  X  100%, and Y = { y 0 , y 1 , . . . , y n outputs for other samples. In order to optimize the pull, we minimize the following objective:
The class prior is quite small for many applications, e.g., a defection or churn rate of 1%. In general, we assume that the pull rate is larger than the prior, but the approach can also apply when the pull rate is smaller than the prior. where
R ( x i , y j ) = (  X  ij  X  ( x i  X  y j )) with q &gt; 1. Here,  X  ij is a monotonic ascending function of  X   X   X  j . Let X &gt; Y mean any sample in X has an output larger than any one in Y . Denote P as the set of positive samples, then P  X  X , since in general r &gt; p . When U in Eq. 10 is zeroed, X &gt; Y , and P &gt; Y . Thus, the pull is optimized. In contrast to the conventional classificatio n based on the prior, which tries to make P &gt; Y and P &gt; X  X  P , the new algorithm requires only P &gt; Y , which might make the optimization easier. This approach is similar to the AUC optimization algorithm in [11], where  X  ij is a fixed margin for all the pairs of { x i , y j } and the objective function is based on the prior, i.e., the original positive and negati ve samples.
We apply the two algorithms to our projects of predicting defection of mutual fund accounts for two major U.S. mu-tual fund companies. The definition of defection in the first project is based on three conditions related to gross sales, redemptions, and net sales, but, for the second project, de-fection is defined according to a single underlying variable  X  the net redemption amount. We therefore apply the con-strained optimization to the first project, and the pull opti -mization to the second project. We first review the domain related to mutual fund redemption in the next section.
The entire 15 trillion dollar mutual fund industry is based on the simple idea of investors pooling their money at an investment company that then buys stocks, bonds or money market contracts with these pooled resources. By pooling resources into a central location, mutual funds offer invest ors the promise of reasonable returns without the complexity of managing their own investment portfolios as would be required if investors bought and sold the individual securi ties contained in their mutual fund. At the end of January, 2005, American investors had placed some 8.0 trillion dollars in one or more of the 8,126 U.S. mutual funds [5]. Worldwide, the mutual fund industry houses 15 trillion dollars  X  about 8 trillion from U.S. investors and another 7 trillion from foreign investors. Today, the US mutual fund industry holds about 18% of all households X  financial assets and about 22% of all outstanding U.S. corporate stock [6].

One of the reasons mutual funds are such an attractive investment vehicle is their scale economies  X  by pooling as-sets over millions of individual investors, mutual funds ca n maintain much lower transaction costs than if investors wer e acting on their own. Within the mutual fund industry, this notion of lower costs through economies of scale is encap-sulated in a fund X  X  expense ratio, which expresses the cost of maintaining a fund (i.e., fund manager fees, fees to bro-kers and other sales agents as well as the expenses involved in the back office tasks such as order entry, bookkeeping, statement production and mailing and issuing checks when investors redeem their assets) as a proportion of the funds liquid assets. Investors clearly favor funds with low expen se ratios: in 2003, 66% of new money invested in mutual funds went to funds with expense ratios less than 1%. Clearly, fund companies as well as fund investors have great incen-tive to keep expense ratios low  X  the fund company because low expense ratios create more assets under management (AUM) and therefore more net profit, and the individual in-vestors because their rate of return depends on the expense ratio.

One of the greatest variable costs fund companies attempt to manage is the large transactional and bookkeeping costs associated with investors liquidating their holdings in a p ar-ticular mutual fund  X  that is, redeeming their assets. At the end of 2003, the industry wide redemption rate stood at 24.2%, implying that the investor base completely turns ove r in 4 (1/0.242) years! To illustrate the magnitude of redemp-tions in the mutual fund industry, the Investment Company Institute, estimated that in 2003 1.086 trillion new dollar s flowed into equity funds but, over the exact same measure-ment interval, 934 million (86%) flowed back out [6]. The costs associated with keeping track of this flowing river of money, adding and deleting client information to databases , filing required tax forms with federal, state and local taxin g authorities as well as simply cutting checks to redeeming clients is an enormous drain on any funds X  expense ratio, not mentioning the revenue drop of fund companies because of the decreased AUM due to redemption.

Of course, some mutual fund redemptions occur for rea-sons beyond the mutual fund company X  X  control  X  buying homes, paying college tuition bills or paying income taxes cannot be avoided forever and so mutual funds are some-times redeemed to meet these expenses. Investors initiatin g redemptions for these reasons might be called uncontrollab le defectors. Some redemptions, however, happen because in-vestors think they can get better service or greater returns in a different mutual fund or different investment product. These are controllable defections and usually amount to money being moved from one mutual fund company to an-other, thereby effectively doubling the expense since all of the accounting and customer service fees accrue at both the company the money flows out of and again at the company the money flows into.

In recent years, more and more mutual fund companies have recognized the importance of early identification of in -vestors at risk of redeeming their assets (or defectors), so that proactive client service and educational programs cou ld be initiated to  X  X lug X  the outflow of assets. Using carefully controlled experimental designs, many fund companies have realized ROIs of 4x to 15x on their investment in data mining driven intervention projects. Because of the very structur e of the mutual fund industry, it is inevitable that the cost savings embedded in this ROI flow backward to investors. Both individual investors and fund companies alike stand to benefit by even marginal reductions in the rate of redemp-tion.

Typically, designated client service representatives at t he fund companies proactively make outgoing calls or other contacts to intervene with the at risk investors, who are in the list pulled out by the model every month. The pull rate or contact rate is predetermined by the budget constraint for the project, and the true positive rate at this specified pull rate is the focus for model training and evaluation.
The raw data for modeling is extracted from several data sources: The data is a mixture of continuous and categorical vari-ables, and consists of many time series, e.g., 12 months of historical transactions and account balances. To summa-rize the time series, t 0 , ..., t K , we use the following weighted average where K = 11 in our projects. For each time series, we nor-mally choose three different  X  values e.g., 1, 0.6, and 1/0.6. Thus, each time series is represented by three input feature s w (1), w (0 . 6), and w (1 / 0 . 6). In general the three average val-ues are still able to maintain the general trend of the time series. At the same time, the weighted average smoothes the noise in the time series and reduces the number of input features in the model. For categorical variables, we either use the binary coding or the class probability conditioned o n the categorical value, e.g., the U.S. state codes, to repres ent the raw data [12]. Missing values are simply imputed by the mean or the mode.

In order to provide early identification of defectors, there is typically a three or four month gap between the end of the independent variable (IV) window and the beginning of the dependent variable (DV) window. The DV window is generally one month and can be two months depending on the mutual fund company X  X  business rules. For example, at the end of February 2005, we would like to predict which accounts will defect in July 2005, so that the mutual fund company can act on the predicted potential defectors in the period from March to June. For this prediction, we use a model trained over a training set with the DV window of February 2005 and with the IV window from September 2003 to September 2004.

For the first data set, 409 raw data fields were extracted from the several data sources. In the end, 132 data fea-tures were selected based on the Wilcoxon-Mann-Whitney statistic [12]. 4 The defection definition for this data set is based on gross sales decline, redemption increase, and net sales decrease in comparison to self history and peers. Ther e is no single underlying variable to determine the class la-bel. For this data set, we compare an MLP model trained by the constrained optimization algorithm in Section 2.1 with an MLP model trained using the conventional mean squared error (MSE) function. Both MLP networks have
The Wilcoxon-Mann-Whitney (WMW) statistic is calcu-lated for each individual feature. Those features with a WMW statistic value larger than an empirically determined threshold, e.g., 0.51, are selected. Figure 2: Lift curves for predicting defection for a U.S. mutual fund company. The dotted line is the lift curve of the model trained by the constrained optimization algorithm, and the dashed line is for the model trained by MSE minimization. 5 hidden units. Among the 299,542 samples, the defection rate is 12.5%. The mutual fund company would like to con-tact 15% of the customer base for each month X  X  retention campaign. We therefore try to enhance the lift at the pull rate of r = 15%. During the optimization of Eq. 9,  X  is fixed at 0.5, and  X  is initialized at 100 and then updated by  X  t +1 = 0 . 75  X  t , where t is the index for iterations. With p = 1 . 01 and  X  = 0 . 3, the optimization converged at a pull rate of 13.8% over the training set, i.e., 13.8% of the traini ng samples had an output value larger than  X  , which is quite close to the target pull rate 15%. The lift curves in Figure 2 are based on a 50/50 split for training and test of the data set. We can see that, beginning from the region around the pull rate of 10%, the lift curve of the constrained optimiza-tion is substantially better than the lift curve of minimizi ng the MSE. 5
The second data set consists of 367,180 samples. We used 104 data features in the final model after feature selection based on the Wilcoxon-Mann-Whitney statistic and the time series representation based on the original 1,882 data field s. Defection is defined as those accounts with a net redemption amount of at least 35% of the account balance in a two month period, so we can apply the algorithm in Section 2.2 for optimizing the pull. The prior (defection rate) is only 0.8%, and we would like to enhance the lift at the pull rate of 5%. Though there are other choices for  X  ij in Eq. 11, we simply let  X  ij be
Interestingly, we see that the lift curve is overall improve d since the pull rate of 10% in this example. However, the algorithm only tries to maximize the true positive rate at the specific pull rate, and the lift curve is not necessarily t o be better overall. Figure 3: Lift curves for predicting defection for a U.S. mutual fund company. The dotted line is the lift curve for optimizing the pull at 5% pull rate, and the dashed line is for the model trained by MSE minimization. The short dotted line is for the model trained by labels simply determined by the pull rate, and the dot-dashed line is the for the regression model.
 We chose q = 4, since this resulted in the largest lift over the training set at the pull rate of 5%. Note that we choose the free parameters based on the training set performance for both algorithms since we did not observe obvious overfitting for either algorithm over our data sets. In Figure 3, we can see that the lift curve of the new algorithm begins to outperform other lift curves at around 5% pull rate. All the MLP models in Figure 3 have 5 hidden units. In addition to the lift curve based on MSE minimization, there are two other lift curves in Figure 3: one obtained by the regression model for the net redemption rate and the other one is for the classifier trained by labels simply determined by the 5% pull rate. Both these lift curves are worse than the lift curv e of the conventional MSE minimization, with the regression model being the worst.
We have discussed the relationship between the lift curve and the ROC curve, each of which is more applicable in different scenarios. When a budget constraint exists in the form of a predetermined pull rate, it is better to work with the lift curve. We propose two distinct algorithms to en-hance the lift at a specific pull rate determined by a budget constraint. The objective functions in both algorithms are differentiable, so gradient based optimization methods can be used to train the model, e.g., an MLP network. We have applied both algorithms to our projects of predicting mutua l fund account defection, and achieved substantially improv ed lift curves.

An interesting direction in the future is to explore the problem of the so called valuable false positives. As in the second project described in Section 3.2, the binary class la -bel is based on the net redemption rate. The true positives are those accounts which have a net redemption rate of at least 35% and are pulled out in the list. The accounts with a lower but still significant net redemption rate, e.g., at 25% are regarded as false positives. However, these false pos-itives are also valuable to the mutual fund company, and these are the so called valuable false positives. It is possi ble to extend the work of optimizing the pull to consider the valuable false positives  X  maximize the true positive rate i n the pull while try to improve the average net redemption rate over the accounts in the pull. Initial experimental re-sults have shown very promising improvement in terms of the average redemption rate in the pull.
The authors thank Mike Sarrafian at @RISK, Inc. for help with the data preparation and Robert Hull at @RISK, Inc. for helpful discussions. [1] A. Berson, S. Smith, and K. Thearling. Building Data [2] C. Cortes and M. Mohri. AUC optimization vs. error [3] D. M. Green and J. A. Swets. Signal Detection Theory [4] D. J. Hand. Construction and assessment of [5] Investment Company Institute. Trends in Mutual [6] Investment Company Institute. 2004 Mutual Fund [7] D. C. Liu and J. Nocedal. On the limited memory [8] M. C. Mozer, R. Dodier, M. Colagrosso, C.
 [9] F. Provost and T. Fawcett. Robust classification for [10] F. Provost, T. Fawcett, and R. Kohavi. The case [11] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. [12] L. Yan, R. Wolniewicz, and R. Dodier. Customer Note that the ROC and lift curves of a finite set of samples are based on a step function in the form Denote { x 0 , x 1 , . . . , x m classifier outputs for m positive samples, and { y 0 , y 1 as the classifier outputs for n negative samples. Then, the class prior p = m m + n . Note that the true positive rate does not change until the decision threshold reaches the next pos -itive sample. We derive the relationship between the AUL and AUC by expressing the AUL as Note that and Thus, we get the AUL as n m + n ( where X is equal to the AUC [11], and 1 2( m + n ) is due to the stair-like effect of the finite number of samples. Typically, we can assume that 1 2( m + n ) is zero for large values of m and n , and we get
