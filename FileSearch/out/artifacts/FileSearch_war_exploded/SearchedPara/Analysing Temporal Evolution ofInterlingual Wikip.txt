 Wikipedia articles representing an entity or a topic in differ-ent language editions evolve independently within the scope of the language-specific user communities. This can lead to different points of views reflected in the articles, as well as complementary and inconsistent information. An anal-ysis of how the information is propagated across the Wiki-pedia language editions can provide important insights in the article evolution along the temporal and cultural dimen-sions and support quality control. To facilitate such analy-sis, we present MultiWiki  X  a novel web-based user interface that provides an overview of the similarities and differences across the article pairs originating from different language editions on a timeline. MultiWiki enables users to observe the changes in the interlingual article similarity over time and to perform a detailed visual comparison of the article snapshots at a particular time point.
Wikipedia is a rich interlingual information source that of-ten reflects cultural differences: Wikipedia articles describ-ing real-world entities, topics, events and concepts evolve independently in different language editions, as there is no sophisticated support for multilingual collaboration when writing articles. Moreover, there is a social impact on mul-tilingual article creation, as different communities of Wiki-pedia editors vary in their perception of the topics they are describing. As a result, there is a distributed evolution of Wikipedia articles that leads to semantic differences repre-senting linguistic points of view on particular topics [3], as well as complementary or sometimes contradictory informa-tion between articles.

The temporal evolution of Wikipedia articles plays an im-portant role when analysing the interlingual development of articles: For example, multilingual users actively transfer information from one language edition to others [4] and arti-cles may be translated to complement missing information. Likewise, information on events impacting both language editions at a time could originate from one of the language editions and be adapted from the other article with some delay.

Our methods aim at supporting Wikipedia editors and readers in better understanding of how such changes prop-agate across the language editions. To this extent, we mea-sure the similarity of the interlingual article snapshots at different time points and visualise them on a timeline.
Figure 1 gives an example of such a timeline generated by our tool, MultiWiki, for the English/German article pair  X  X odex Aureus of St. Emmeram X , which visualises the fol-lowing process: The English article was created in October 2003, nearly five years before the German one and consisted of a very few sentences for a long time. Then, in 2008, the German article was created and became immediately much longer than the English one. Hence, the timeline shows a very small similarity within the first two years after the cre-ation of the German article. Then, parts of the German texts were adapted to enlarge the English article, which lead to a significant increase of their interlingual similarity. Fi-nally, the texts evolved independently from each other and their similarity slightly decreased.

For each particular pair of snapshots derived from the timeline, our interface also provides a detailed comparison. This comparison clearly goes beyond existing tools (e.g. [1], [3]), in particular through visualising a detailed comparison of the similarities and differences of the article texts.
MultiWiki presented in this demonstration is a web-based tool 1 including the following functionalities:
These functions enable MultiWiki to: 1) Present an overview of the evolution of the interlingual article similarity over time; and 2) Enable users to perform a detailed article com-parison at a certain time point.
The demo is publicly available at: http://multiwiki.l3s. uni-hannover.de/demo.html.
MultiWiki provides users with an overview of how the relation between two articles that describe the same topic in different languages changes over time. To this extent, MultiWiki automatically generates a timeline that visualises the evolution of the semantic similarity of the articles over time and the corresponding number of edits for both articles.
In order to visualise this timeline and to enable a more fine-grained analysis of an article pair at a particular time point, we compute a semantic similarity score Sim ( A 1 ,A for two article snapshots A 1 and A 2 from different Wiki-pedia language editions. This score is composed of several similarity functions Sim f ( A 1 ,A 2 )  X  [0 , 1] that are applied on different features f  X  F .

We differentiate between the text-based features ( F and features using meta information like images and links ( F meta ). The textual similarity Sim text between two article snapshots A 1 and A 2 is computed as follows, where w f de-notes the weight assigned to one of the similarity functions: Sim meta , the similarity of the article snapshots computed using meta information, is defined analogously. We consider different feature categories, such as images, Wikipedia an-notations (i.e. references to other Wikipedia articles in the text), external links and editors to be equally important. Therefore, we equally distribute the weights across these feature categories. Tables 1 and 2 provide an overview of the MultiWiki features and their weights.
 The overall similarity Sim ( A 1 ,A 2 )  X  [0 , 1] of a snapshot Table 1: Similarity Measures based on Meta Fea-tures pair is the weighted sum of Sim text and Sim meta , where we set  X  = 0 . 5 to balance the influence of both factor types: Sim ( A 1 ,A 2 ) =  X   X  Sim text ( A 1 ,A 2 )+(1  X   X  )  X  Sim
In the following, we describe the features, the similarity functions based on them and how we present the results to the user: Our interface does not only show the numeric similarity scores, but also visualises the similarities based on particular features as illustrated in Figures 2 and 4. When comparing two Wikipedia articles, one of the main visual impressions is given by the images placed in them. Therefore, we compute the fraction of images used in both articles. In the interface, we oppose them in a table like the one shown in Figure 2(a).
 Motivated by the findings in [4], MultiWiki aligns external links mentioned in the footnotes of the articles and their hosts. As illustrated in Figure 2(b), the host names of the external links are shown to the user ranked by their overlap frequency. Those at the top are frequently mentioned in both articles and are therefore good indicators for the topical overlap of the articles.
 Two articles are similar if they refer to the same entities, concepts and topics [3]. To extract this kind of annota-tions, we rely on two sources: (1) Wikipedia links manually added to articles by Wikipedia editors; and (2) Wikipedia links automatically created by applying an entity annota-tion tool (DBpedia Spotlight). While the user-defined links are precise, but rather sparse and without repetitions, the automatic annotation raises the recall of the Wikipedia ref-erences. These references are aligned across languages by using interlingual article links provided by Wikipedia. Wikipedia articles are thoroughly based on the input of the Wikipedia editors. Some multilingual editors tend to edit ar-ticles describing the same entity in different languages, such that similar content is spread across languages [4]. MultiWiki computes the overlap of the editors that contributed to the articles under comparison. Furthermore, the linguistic point of view (as defined in [3]) emphasises the cultural differ-ences between language communities. Therefore, we deter-mine the countries where anonymous editors come from and compute the similarity of the country distribution per arti-cle. As this location similarity Sim loc ought to measure the similarity of the distribution, but should not be biased by differences in the number of anonymous editors, it is com-puted by Equation 2 (where L is the set of locations and each article A i is assigned a set of editors e  X  E i ): Before computing the overlap, the number of editors is matched by
In the MultiWiki interface, two world maps like the one presented in Figure 2(c) are showing the editors X  origins for a pair of article snapshots.
 MultiWiki provides a fine-grained comparison of the article texts by aligning semantically similar text passages in an article pair as illustrated in Figure 4.
 This alignment is facilitated by an bottom-up approach: At first, sentences with overlapping information are aligned using the following features: (1) Cosine similarity of the vec-tors representing text passages using terms (automatically translated to English); (2) Similarity of the Wikipedia en-tities metioned in the sentences; (3) Time similarity using temporal expressions automatically extracted from the sen-tences. Consequently, sentence pairs whose similarity score exceeds a pre-determined threshold value are merged in a bottom-up manner: As long as the similarity of an aligned text passage pair increases, the text passage is expanded by adding neighboured sentences from one of the articles or by merging two text passage pairs in a close neighbourhood. Given the aligned text passages, they are presented to the user by showing both articles side by side and connecting them as illustrated in Figure 4. With this visualisation ap-proach, the user immediately obtaines an overview of the similarities and differences in the articles.
 Regarding the textual similarity score of an article pair Sim text ( A 1 ,A 2 ), three measures are derived from the arti-cle texts: 1) Text passage coverage is the percentage of text aligned as part of text passage pairs; 2) Text length similar-ity compares the length of the articles; and 3) Text overlap similarity is the Jaccard similarity of the English (machine-translated) texts.
In order to facilitate the comparison of articles based on the proposed features and to analyse their temporal evolu-tion, each article pair runs through a preprocessing pipeline. In a first step, we need to inspect the revision history in both languages to create a set of article snapshots pairs that ful-fils the following condition: Both snapshots in an article pair must have been on-line at the same time. This ensures that dissimilarities between the articles are not based on tempo-ral shifts. Besides, the selected article pairs should be evenly distributed over time to provide a better overview.

For each article snapshot, we collect meta information, extract the sentences and annotate them with the features presented in Section 2 using state-of-the-art methods. The pipeline for extraction and annotation is depicted in Figure 3. At first, we fetch the texts of each article and collect its contributing editors from the revision history. For each of the unregistered, anonymous editors, the IP address is pro-vided, which makes it possible to determine their country. To allow for the text passage alignment, the text is split into sentences; then the features needed for the sentence align-ment are collected. The results of the preprocessing pipeline are stored in a database. Additionally, the complete set of interlingual Wikipedia links is stored, such that the final comparison of the article pair including the computation of similarity values and the text passage alignment can be per-formed at run time.
To facilitate the demonstration of our methods, we ex-tracted a set of 79 randomly selected article pairs to be inves-tigated using MultiWiki. For each article pair, we collected eight snapshot pairs on average. The majority of 54 arti-cle pairs is German/English, 14 are Dutch/English and the remaining 11 pairs are Portuguese/English. As we extract multiple snapshots of each article to construct the timelines, a total of 637 snapshot pairs has been extracted and an-notated. Among these article pairs, there is the politician  X  X awrence Eagleburger X , the German film  X  X er Stern von Afrika X  (movie) and the  X  X eneral Post Office X .
The multilingual Wikipedia has been a research target for different disciplines. One area of interest in this context is the study of differences in the language points of view in Wi-kipedia [3]. In [4], Rogers conducts an intensive case study where he compares the highly controversial articles on the Srebrenica massacre in several Wikipedia language editions. In his work, all of the investigations like image alignment and a comparison of the table of contents are made manu-ally. To simplify such tasks in future, some of the features mentioned in [4] have been implemented in MultiWiki.
Two of the few existing tools to support cross-lingual an-alytics in Wikipedia are Manypedia [3] that provides an au-tomatic translation to English, article statistics and overlap of Wikipedia links, and Omnipedia [1], which can be used to compare the given Wikipedia links for up to 25 language editions simultaneously. Another tool that helps to explore the temporal development of a single article is Contropedia [2] that focusses on the interaction of Wikipedia editors. Un-like existing tools, MultiWiki excibits unique features such as temporal analysis of interlingual article similarity and de-tailed textual comparison of article snapshots.
In this paper we presented MultiWiki  X  a novel user in-terface to conduct a detailed visual analysis of the similar-ities and the differences across the Wikipedia articles on the same topic written in different languages. MultiWiki provides means to explore how information is propagated across the language editions by observing how the similarity of an article pair evolves over time. Moreover, it enables a detailed visual comparison of the article snapshots based on users, media elements, entities, and links as well as a detailed analysis of textual similarities.
