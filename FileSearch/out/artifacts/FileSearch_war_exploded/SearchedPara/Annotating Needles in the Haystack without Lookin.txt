 Business-to-consumer (B2C) emails are usually generated by filling structured user data (e.g. purchase, event) into tem-plates. Extracting structured data from B2C emails allows users to track important information on various devices.
However, it also poses several challenges, due to the re-quirement of short response time for massive data volume, the diversity and complexity of templates, and the privacy and legal constraints. Most notably, email data is legally protected content, which means no one except the receiver can review the messages or derived information.

In this paper we first introduce a system which can extract structured information automatically without requiring hu-man review of any personal content. Then we focus on how to annotate product names from the extracted texts, which is one of the most difficult problems in the system. Nei-ther general learning methods, such as binary classifiers, nor more specific structure learning methods, such as Condition-al Random Field (CRF), can solve this problem well.

To accomplish this task, we propose a hybrid approach, which basically trains a CRF model using the labels pre-dicted by binary classifiers (weak learners). However, the performance of weak learners can be low, therefore we use Expectation Maximization (EM) algorithm on CRF to re-move the noise and improve the accuracy, without the need to label and inspect specific emails. In our experiments, the EM-CRF model can significantly improve the product name annotations over the weak learners and plain CRFs.
 Structured information extraction, Business intelligence Email is arguably one of the most successful applications on the Internet. In the early days email was primarily used for short textual user-to-user communication. Today, this role has been largely overtaken by chat and social network plat-forms. Now email increasingly serves as a repository of trans-actional information such as receipts from many business-to-consumer (B2C) interactions. Email messages have several  X  Work done while all the authors were at Google.
 properties that make them appealing for such communica-tion: the communication is asynchronous  X  it does not re-quire both parties to be present at the same time; it is vir-tually infallible; email provides persistent storage; finally it is mostly private, requiring authentication for access.
While email is a very suitable communication medium for such information exchange, it was originally designed for PC screens with manageable amount of messages. However, nowadays more and more people are checking emails from mobile devices with smaller screens. It will be much more convenient and efficient for users to track important informa-tion without having to read every email on mobile devices. Actually it is a key feature of Google Now, just as those displayed in Figure 1.

Most B2C emails are generated by filling a template with values from databases. We call it a templatized email. For example, retailers make receipt emails by populating order details (order number, items and prices, etc.) into a prede-fined template, and shipment details (tracking number, de-livery date, etc.) into another template. Usually users only look for those details, not the templates or static contents. In other words, users only want to see the structured data from databases, which is embedded in the templates. In this paper we will propose a system to extract those data from emails, also known as  X  X rapper X  [ 12] or  X  X arser X  [ 19 ] in the literature.

A simple but accurate way is to manually create a parser for each template. However, due to the privacy constraints, it will rely on the vendors to provide the templates, or hire people to craft the extraction rules using donated emails of this template. However, both approaches are not scalable and are vulnerable to changes of the template.

Another more desirable approach is to automatically ex-tract the structured data from those templatized emails: construct the template from similar documents, extract the data, and annotate the semantic types (i.e., price, shipping address, delivery date, etc.) of those data entries. Eventual-ly, the extracted structure data can be rendered in a different UI and served to the users, as what Google Now does. We will introduce such a system in section 3. Privacy. By law and by policy commercial email providers are held to a very high privacy standard. Users can assume rightfully that their messages are not read by other humans. Most major Internet companies have established protocols to ensure such guarantees automatically. This makes it impos-sible to generate broad training data of annotated emails, or to visually inspect the results of extractors applied to emails. In other words, unlike traditional information extraction sce-narios, we have no access to both the input and output of the extractors, except a very small amount of donated emails. Every design and implementation shall respect and protect user privacy. That is why it is hard for us to get more sam-ples to analyze, find heuristics and train good models over the data we cannot see.
 Diversity. Different websites have very different templates, the same site can have multiple templates (order confirma-tion, cancellation, etc.), and even the same template may yield different variants for personalized experience. In gen-eral, we are generating millions of templates from billions of emails. Each template has its own contents and character-istics, but we only have some donated emails from a small number of templates to train models, which in turn could yield very biased models with poor performance when apply to new templates. For example, a wrapper or model trained from Google Play receipts may not work well on Newegg.com receipts, but the problem is that we do not have donated training samples from Newegg, nor allow to view any per-sonal emails from Newegg.
 Complexity. In early days, many email templates only have one or a few simple tables, but now the HTML codes used in email become much more complex and nested for better visual presentation. In addition, a template consists of various semantic types. For instance, a purchase receipt may contain customer ID, order number, tracking number and URL, delivery date, shipping address, product name, total price, and so on, while an event email can have a totally different set of types.
 Scalability. We are dealing with extremely large data, and have to process it in a very short time since people expect emails to arrive instantly. The daily volume of emails are a number of times larger than the web pages indexed per day by well known search engines, and it grows fast. Therefore, efficiency and scalability are the key issues of the system.
In summary, rigid user privacy constraints, diversity, com-plexity and lack of data are new challenges to wrapper tech-niques proposed previously for scalable email systems.
In this paper we address the problem of extracting per-sonal structured information in the presence of reviewing re-strictions and variations in emails. We take advantage of the repetitive structure of emails to induce templates. For the content that is not part of the template, i.e., the text regions changing in every email, we need annotate the semantic type so that it can be properly rendered to the user. Some types are easy to annotate, such as date, address, price, etc. We can pre-annotate them using some existing annotators. This paper focuses on non-trivial types without mature annota-tors, particularly the product name in email receipts, which was one of the most difficult problems in the system. Specifi-cally, after we extract a text without any pre-annotated type, we need to predict if it is a product name or not. We can also apply the same solution to other non-trivial types.
Due to the diversity and lack of training data on all tem-plates, general supervised learning models, such as binary classifiers, have poor performance for this task, although they can be trained with limited data. On the other hand, structure learning methods, such as Conditional Random Field (CRF), are more specific and accurate for inducing structures in templates of sufficient training samples, but it usually requires training labels of every template. Please note, here the elements of the structure learned by CRF are semantic types, not the HTML nodes or text regions. When we apply CRF on a templatized email, it can annotate the types of each node or region 1 , such that we can use it to pre-dict the type of any extracted text. If we train a CRF model from some templates and then apply to others templates, its predictions still could be poor, again due to diversity of the data and complexity of the model.

To solve this dilemma, we propose a hybrid method, which takes advantages of both the generality of classifiers and specificity of structure learners. The former can generate sufficient training labels, although it has low quality, and then we rely on the latter to remove the noise and discover high accurate structures, by applying an Expectation Maxi-mization (EM) algorithm. In our experiments, the EM-CRF model can significantly improve the product name annota-tions over the weak learners and simple CRFs. In sum, our main contributions are: Information extraction on the Web. Information ex-traction is a well-studied problem. In particular, since most commercial emails contain HTML, it is reasonable to as-sume that tools developed for Web pages could conceivably be extended to apply to emails, too. In fact, we will take advantage of this strategy in our model. [7, 15 ] present heuristic rules to extract data from Web pages using characteristics of HTML files. [ 8] uses HTML tag strings to find useful patterns for extraction. In [30 , 44 ], the data records from the Web pages are detected by visual features such as gaps between blocks, and then tagged based on the pre-detected tree structure in the HTML. In [12 , 13 ], different extraction rules are incorporated in an automatic fashion. The above work heavily relies on the induced We-b page templates and lack of the advantages of leveraging the other annotated data fields to adaptively improve the extraction/annotation performance, which can be problem-atic when the templates are mismatched. Therefore, learn-ing based methods are proposed. In [46 ], the authors infer a hierarchical CRF model to simultaneously detect the da-ta records and label the attributes. [ 45 ] exploits additional information about page element alignment by using a 2D-CRFs model. A more integrated model which dynamically learns the hierarchical structure of the Web page and labels the attributes is proposed in [47 ]. A prerequisite of these works is that the Web pages in the training data should be
Region means the text of a particular node in the DOM tree [18 ] of the email HTML. It is the unit for labeling here. fully labeled to train the CRFs models. This is impractical in our scenario where emails are not human accessible. Email. Email is always among the most sensitive data on the Internet due to users X  privacy concerns. Thus data avail-ability is one of the main constraints for any of research or product work on emails [26]. Most work on emails content mining is concerned with anti-spam [4 , 9], where the task is to perform binary classification to figure out whether an email is a spam or not [43 , 20]. Moreover, classification [26 , 24 ] and clustering [29 , 27 ] techniques are explored for email message categorization into the user X  X  predefined hierarchi-cal folders. This task has some unique challenges [ 6], such as the varying of users X  email filing habits, and the strong imbalance of different email folders. In previous works on email content mining, the email data used is always in the bag-of-words form [ 26 ], even if there are some sections (e.g. from , to , subject and body ). This is quite different from our email data, where the HTML structure and tags can be heav-ily utilized to improve performance and dynamically include content (such as up-to-date advertisements). For machine generate emails, templating and threading are also studied to help re-organize the email list presenting [1 ]. Such work is different with our problem because it does not need to recognize the type of each text field (or region). Besides the email content mining, there are some works on email social network analysis and mining [ 3, 14 ] to infer email priority [42 ], to detect spam [41 ], and to analyze the social hierarchy [38 ] inherent in the data.
 Semi-supervised Learning. To supplement expensive or even unavailable labeled data researchers have started de-vising semi-supervised learning algorithms which take ad-vantage of additional unlabeled data. See e.g. [48 ] for an extensive summary and review. Usually semi-supervised al-gorithms take advantage of a reasonable hypothesis based on which the unlabeled data could be utilized to improve the learning model [ 49 ]. In the context of NLP, such a hypoth-esis can be modeled e.g. via generalized expectation criteria [31 ] which assumes that conditional class probabilities satisfy moment constraints; regularization via posterior constraints [17 ]; or by using extrinsic objectives [ 19 ]. Optimization pro-ceeds e.g. via Lagrangian relaxation and dual decomposition [39 , 40 ].

In our work we define a hypothesis class using structured extraction via a CRF and employ automatically generated (low-accuracy) annotations as (inconsistent) training data. In other words, we learn constraints between adjacent labels as a mechanism for extracting information about the struc-ture of the documents. Moreover, we cannot assess the quali-ty of the results directly since, due to privacy constraints, we are not allowed to view the extractions. This is what makes it highly challenging to apply moment constraints directly, since this would require knowledge about the commercial content of the emails in question.

Note that our work also links to information extraction with weak supervision, which was originally proposed for biomedical entity recognition [ 11 ] and then applied in other scenarios such as entity recognition from multi-lingual corpo-ra [ 25 ] and search queries [ 34 ], and entity relation extraction [32 , 21 ]. The  X  X eak X  supervision, in previous work, normally comes from direct text matches with some knowledge bases. However, as pointed out in [37 , 21 ], when the target text is very diverse and not aligned with the knowledge bases, su-pervision helps little. In our scenario with emails as input, the text is quite different and most of the entities such as product names and addresses have multiple variants. Thus it provides little help from the direct match of the entity names. Our approach can be viewed as a form of weak super-vision with a novel notion of weak signals (i.e. low-accuracy annotations) coupled with domain adaptation.
This section introduces the information extraction system, or wrapper, we developed for large scale email systems.
Some regions in a templatized email are static and do not change for different users or orders, which we call  X  X ixed re-gions X . Other regions vary in every document, such as Order Number , Product name. We call them  X  X ransient regions X . Usually only transient regions contain user relevant data, and the template is made from fixed regions. We need to separate transient regions from fixed ones and annotate the semantic type of each transient region.

Figure 2 illustrates the components of our system. Basi-cally, the system has the following major components. Clustering. The very first step is to split emails by senders, then cluster similar emails which may be generated from a common template. Emails from the same sender are not nec-essarily from the same template, for instance some retailers may use one email address to send both order confirmation and shipment notification emails. It is also possible that mul-tiple senders share the same template, which can be solved by merging clusters of different senders.

To preserve user privacy and avoid templatizing consumer-to-consumer (C2C) emails, we only induce templates from large clusters which contain many receivers and similar e-mails. Besides, it is easier to distinguish transient regions and fixed regions using lots of similar emails from the same cluster.
 Templatization. We induce a template from emails of each cluster. First we segment each email into regions. The major difference between HTML and text emails is how we segment and locate the regions. Each HTML page has a DOM tree [18 ] and we can regard a text node as a region and use XPath to locate a node in the tree, while for plain text emails we need construct a finite-state machine (FSM) to represent the structure. Moreover, HTML pages may contain tables or hyperlinks, which can be used to get more features. The processes are similar for HTML and text emails. Without loss of generality, we only consider HTML emails below. We declare regions with high document frequency as fixed. The rest is transient. Eventually a template consists of a dictionary of values in fixed regions (e.g.  X  X our order of X ,  X  X hank you! X ) and the location (XPath) of transient regions. We also pre-annotate easy types, such as Price , Address , Date and store the mapping from XPath to its pre-annotated semantic type in the template, because usually the same n-ode among templatized emails has a consistent type. For example, the cell of third row and fourth column of the sec-ond table is always Price . In case it is inconsistent, we store all the possible types with their probability.
 Extraction. The previous steps are done offline, while ex-traction is performed online. That is, when a non-spam B2C email is received, we find its cluster and template, segment the email to regions, match the regions in the template, de-cide if it is a fixed region or transient, and finally get its type by the annotation module. The outcome is a list of (type, value) tuples, the structured data we need. Annotation. If a transient region only has one pre-annotated type, we assign it this type. For regions with multiple can-didate types, we either use the most likely type, or let the annotator to decide which one to use based on the text val-ue, potentially using the prior distribution of types, or apply some heuristics according to the surrounding texts (context). Usually only a small portion of transient regions in an email have pre-annotated types. The others are Unknown .

For purchase emails, we currently only have one annota-tor to predict whether the value of an unknown regions is Product . However, it is a non-trivial task. Different prod-ucts may have very similar names, and the same product could have quite different names as well, because the retail-ers can choose any form to present the products to users. Some product names are very short, such as  X 9 X  (a movie) or  X  X i X  (a song). It is very common to include some product specifications in the name, or intentionally add some terms for  X  X earch engine optimization X . In addition, many emails include recommendations or ads, which also contain produc-tion names. As the growing of products available online, it is almost impossible to maintain a database of product names.
The rest of the paper focuses on how to annotate product name in transient regions of unknown type.
The low accuracy estimators that we have at our disposal are all binary. That is, for a given position they estimate e.g. the probability of it being a number, or a product name, or a date. In other words, for each position i for document x we have the probability indicating the probability of the label y i , as inferred from a weak, low-accuracy heuristic p weak , being equal to the true label y  X  i . Note that there is no need that these probabilities are properly normalized, i.e. typically we will have P y 1, as another form of normalization will be given in ( 10 ). We simply require that the probabilities are bounded, i.e.  X  ij  X  [0 , 1].

To convert this information into an actionable statistical model we follow the lines of [23 ]. That is, we treat the above problem as one of observing the correct label (denoted as t = TRUE) with probability  X  ij for every position i , as specified by the low-accuracy estimator. In this case, the probability of inferring the correct labels for x j is given by p (correct | x j , X  ) = X Here p ( y 1 ,...y n | x j , X  ) denotes the CRF modeling a non-trivial joint probability over annotations. Moreover, we as-sume that the correct label distribution factorizes, hence the Q i  X  ij term to capture the joint probability of the inferred labels ( y 1 ,...,y n ) being correct. The model of Figure 3 cap-tures the basic idea.

In the special case of unstructured estimation this reduces to the model of [23 ]. Moreover, in the case where  X  ij  X  X  0 , 1 } this reduces to the setting where we simply sum over a sub-set of possible label combinations. Unfortunately, in all the above settings p (correct | x, X  ) is not log-concave in p ( y | x, X  ). This complicates matters in terms of inference and we will need to resort to DC programming [22 ], often also referred to loosely as Expectation Maximization in this context, for op-timization. Before going into specifics let us briefly describe the statistical model.
The primary benefit of using a CRF is that we may exploit structural correlation between adjacent labels [ 28 ]. This is achieved by expressing the entire chain of labels as a con-ditional undirected graphical model by multiplying adjacent clique potentials. In other words, we posit that the condi-tional label distribution is given by an exponential family model where  X  ( x j ,y ) is the feature function and the parameter  X  acts as the coefficients of the features. Here g (  X  | x the so-called conditional log-partition function ensuring that p ( y | x j , X  ) is properly normalized as a distribution over y . It is well known that g (  X  | x j ) is a convex function in  X  . Com-puting g (  X  | x j ) and its derivatives can be accomplished by dynamic programming. For this purpose we exploit that  X   X  g (  X  | x j ) = X Since the sufficient statistics  X  ( x j ,y ) decomposes into terms on maximal cliques ( ... X  ( y i ,x j ) , X  ( y i ,y i +1 ,x ficient to have access to p ( y i | x j , X  ) and p ( y i ,y deal with the chain CRF [28 ]. Both terms can be efficiently computed using dynamic programming for E y i | x j , X  [  X  ( y backward algorithm suffices since we are dealing with a chain model. For more sophisticated structural evaluation model-s we would need to resort to a matching strategy satisfying the conditions of the Generalized Distributive Law [ 2] on the (log,+) semiring.
Compared with standard CRF models, the key challenge in our scenario is that we do not have access to the correc-t labels y  X  directly but rather only via  X  ij as obtained by rather much weaker models. Hence, instead of dealing with the log-likelihood log p ( y | x j , X  ) from ( 3), we are dealing with log P y [ Q i  X  ij ] p ( y | x j , X  ) from (2 ), which is a nonconvex ob-jective function. More specifically, in the case of a CRF the objective decomposes via As can be seen, the first term is convex and the second is con-cave. Hence, for the purpose of maximizing the log-likelihood model to perform prediction on new documents.
 Algorithm 1 CRF Inference with Side Labels (EM-CRF) Require: Document set { x j } Require: Initial distributions q j ( y ), e.g. q j ( y ) = const .
Initialize CRFs parameters  X  , e.g.  X  = 0. while not converged do end while return  X  we can lower-bound it by linearizing the first term via a Tay-lor approximation. This yields  X  c + D  X , X   X  log X = c + D  X , X where the distribution q j ( y ) is given by q ( y ) = Comparing with (3), the likelihood calculation in (9 ) takes the weighted average of  X  ( x j ,y ) across the candidate labels y w.r.t. q j ( y ). In other words, we re-weight the conditional la-bel estimates according to the outcomes of the low-accuracy annotators and the CRF model prediction using the current weight  X  . Subsequently terms are renormalized.

Optimization proceeds by alternating between maximiza-tion of the lower bound of the log posterior over  X  using the current estimate of label distribution q j ( y ) and by recomput-ing a new approximation q j ( y ) using the current estimate of CRF-weights  X  . Note that by construction the lower bound is tight at the point of expansion. This follows directly from the fact that Taylor expansions are exact at the point of ex-pansion. To train the CRF in the M-step, we generate a set of candidate labels for each sequence and weight each of them using q j ( y ), and then use a standard convex solver to maximize ( 7). We add an L 2 penalty on the weights  X  of the CRF for regularization as is common in structured estima-tion. Algorithm 1 summarizes the inference procedure.
The key challenge in the experimental setup is to demon-strate the efficacy of the algorithm without the need for ex-plicitly labeled training or test data and without the need to inspect the data, e.g. by means of editors. Yet, at the same time we want to have more directly quantifiable quantities than, say, predictive log-likelihoods. This makes assessment of the approach rather difficult.

The assumption is that while the templates might differ, we can at the very least assume that within a given template, the structure is sufficiently similar to apply a given CRF model. That is, we assume that each template comes with its own CRF model. In production, the data flow is as follows: 1. Human labeled region data from text unrelated to us-2. In addition to the manually labeled auxiliary data we 3. For each new template (i.e. the templates from other 4. For each new email in the template we use the corre-Figure 4 describes the data flow in such an environment. Note that training and test set are entirely disjoint. That is, emails required for testing the EM-CRF model are not used in the training of the EM-CRF.

In the above description, we assumed that the HTML tem-plate structure is fully given, that is, the template is entirely static with the only changes being relevant fields in ques-tion (e.g. purchase emails from a given sender). Section 6.2 provides results on the performance of the EM-CRF model in this context. Secondly, whenever the HTML structure is variable, with a similar method from [ 1], we can induce vari-able and static contents using standard automatic methods based on text frequencies across emails in the same template.
Given an email in HTML, we need to transform it into a representation amenable to a CRF. This requires two stages  X  the actual segmentation and the annotation of content with low-accuracy classifiers, as illustrated in Figure 5.
Step 1. We begin by segment emails to regions using the system we described in section 3. The sequence of the text regions follows their order in the DOM tree of the HTML file. Some text regions are fixed, as part of the template, and some are transient, which may already have semantic types from pre-annotators. Moreover, some text regions may be highly relevant and specific to a receipt although they share the same DOM tree node with surrounding template text. For example, the order number 9261297642094757559542 as shown in step 1 of Figure 5. In such cases, the text regions will be further segmented (see step 2 of Figure 5).
 Step 2. We align these text regions to build the linear CRFs data. The label of each fixed region of the template is set as Fixed , while the other regions will be given by the low-accuracy annotator (e.g. Product , Other ) and pre-annotated types (e.g. Price , Email Address , etc.)
Compared with a more traditional word-level CRF anno-tator, we allow for the segments to contain several words. As such a possible problem is that the text features may not match across documents. In practice this turns out to be less of a problem than anticipated. This is due to two reasons: firstly, the template text regions are almost always repeti-tive; secondly, even for a new non-template node text, its label can be initially induced by the low-accuracy annotator or the manually crafted rules.
The low-accuracy annotators are essentially binary classi-fiers which generate a conditional class probability. There are 32 high-level features of the following categories: Content Based Number of words, number of digits, having Context Based Minimum and average distance to regions Search Based If we send this text as a query to a search Knowledge Based Find the knowledge graph entities in Annotation Based How much this text look like a price,
We tried using N-Gram features, but it did not work well because first it largely increases the dimensionality, and sec-ond the feature distribution from one domain can be very different from another domain. Feature selection or reduc-tion does not help either.

In total, we have 66,494 labeled regions generated from 2,310 user donated emails. Among these labeled region-s, there are 2,740 Product regions and 45,637 non-product ( Other ) regions. As noted before, some of these regions are pre-annotated as Price , Date , Time , Email Address , Ad-dress , etc. These are highly accurate for easy fields and we regard them as ground truth throughout the experiments. We only focus on the harder task of detecting product name in the emails. We use this data to train the low-accuracy an-notator. In total, we compare 7 different binary classifiers, as illustrated in Table 1.
 LogRegL2 Logistic regression with ` 2 penalization [ 20] LogRegL1 Logistic regression with ` 1 penalization [ 35] CART Classification and Regression Trees [ 33] MARS Multivariate Adaptive Regression Splines [16 ] GBM Generalized Boosted Regression Models [ 36 ] RandFor Random Forests [ 5] SVM Support Vector Machines [10 ] Model selection parameters inherent in the above algorithms are adjusted using cross validation in an automatic fashion. Table 1: Low-accuracy annotator performance. The estima-tors are trained on dataset that is not used anywhere else in the rest of the experiments. LogRegL2 0.701 0.329 0.448 0.938 9.51 LogRegL1 0.692 0.399 0.507 0.943 11.26 RandFor 0.872 0.664 0.754 0.974 17.02 LogRegL2 , LogRegL1 and SVM are linear models, the others are all nonlinear. We observe that RandFor provides the best prediction performance while having high computational ef-ficiency. This is not too surprising given that it approximates a nonlinear Pitman estimator in the version space of trees. Consequently we use Random Forests as our low-accuracy region annotator in our work. Based on the low-accuracy annotation we next infer the EM-CRF model as discussed in Section 4. More specifical-ly, the low-accuracy annotator is used to obtain an initial estimate q j ( y ) of a region being a product. This allows us to tag the emails for new (or unseen) templates. These are then used to train the EM-CRF model for each template. We proceed by alternating between computing a convex up-per bound on the negative log-posterior of the model, i.e. the negative log-likelihood and the Gaussian log-prior, and by invoking an off-the-shelf CRF inference algorithm using the probability estimates q j ( y ) for a weighted set of labels.
We perform 4-fold cross validation to test our model. For each test template we sample 75% of its emails and remove their labels to simulate regular unlabeled data. We apply a hand-tuned region annotator to detect specific regions such as Price, Email Address , and Order Number . For the re-gions labeled as Product or Other , we apply the weak learn-er to generate a probability of this region being labeled as Product . After that, we train an EM-CRF model for this template using the weighted (and noisy) labeled emails. Fi-nally, for each template we test the EM-CRF model on the remaining 25% labeled emails.
To illustrate the benefit of the EM-CRF approach over a plain CRF model we also trained a CRF model directly us-ing the low-accuracy annotator X  X  predictions. In this case we used the maximum likelihood annotation of the region-s rather than the label probabilities. It is to be expected that this approach will still benefit from the regularity prop-erties of the document. For instance, if in a template the Product region is always followed by a Quantity region and then a Price region, one would expect that the potential  X   X  ( y i ,y i +1 ) , X  yy  X  capturing adjacent labels would model this correlation. We call this model CRF-Max (since it used the maximum likelihood estimation of the low-accuracy an-notator).

A second very natural baseline is to use the Weak Learning ( WL ) directly, i.e. to output just the prediction of the low-accuracy estimator. We expect this to perform the worst.
As has been noted previously, we focus the evaluation on the accuracy of tagging Product regions, which is the most difficult one. We use precision, recall and the F1 measure to illustrate overall accuracy.
We first focus on analyzing the performance of our ap-proach when the template structure is well known. By tem-plate structure we mean which regions in the DOM tree are fixed for all emails in the template and which regions are specific to a given email instance from that template (e.g. recipient name , address and product (s) in the purchase). We use this setup to conduct a detailed analysis of our pro-posed approach. Large scale experiments with variable struc-ture are reported in Section 6.5 .

We used 4 frequent templates of user donated emails, and for any given template we manually engineer a template pars-er to annotate data with almost perfect precision as fixed or variable. This is a costly exercise. It is not scalable since an engineer needs to analyze HTML code to accomplish this task. Moreover, it requires us to continue investing resources whenever the template changes.
As can be seen, even the frequent templates only consist of a rather small number of labeled emails.
Figure 6 provides a comparison of F1, precision, and re-call scores for all three algorithms (WL, CRF-Max and EM-CRF). To render the results comparable we tuned all models for maximum F1 score performance. Particularly, for three out of these four templates, WL X  X  achieved precision is lower than recall, which seems to be inconsistent with the RandFor figures in Table 1. This is just because the figures in Table 1 are calculated on the da-ta across all the templates while the performance would be different for each individual template.

Besides these three algorithms compared in Figure 6, we also checked the performance of a CRF trained on the da-ta across all other templates. The F1 performance on all four tested templates is almost 0, caused by the structure inconsistency brought from the huge difference across tem-plates. This supports our motivation of training a CRF per template. Another observation is EM-CRF can still boost from WL although WL X  X  precision is lower than 0.5 (F1 is still higher than 0.5). This is because T4 emails contain-s many (3.85) products on average, which help CRFs learn from abundant repeated structures.

Figure 7 illustrates the distribution of the F1 score across a range of hyperparameter values. Note that the variance of the EM-CRF model is lower than that of its alternatives. Not only is the model more accurate, it also provides a more reliable performance in large scale experiments where we do not have access to a development set for each template.
Figure 6 illustrates precision and recall when the hyper-parameters have been tuned for the best F1 score for all models. Again, we may observe improved performance of CRF-Max and EM-CRF over WL. Compared to EM-CRF, the CRF-Max model occasionally exhibits higher precision but lower recall. This is because CRF-Max is trained direct-ly on the labels predicted by the low-accuracy estimator. For Figure 7: Distribution of F1 performance scores on four tem-plates over a range of hyperparameters. the Product regions, which are correctly labeled by WL, the CRF-Max will train good parameters to predict them. On the other hand, the Product regions which are incorrectly labeled as Other , CRF-Max will be relatively easily induced to annotate these regions as Other . On the contrary, for EM-CRF, when WL provides the wrong prediction on Product regions, it just labels it as Product with a less-than-half prob-ability. However, this probability will not be ignored during the EM-CRF training. EM-CRF will evaluate the posterior probability of when this region is labeled as Product , and usually increases the probability of this region being labeled as Product if it finds there is higher structural consistency.
Note that by construction the CRF-Max estimate is what the EM-CRF algorithm obtains in its first iteration with only max-likelihood label sequences. That is, EM-CRF creates a continuum between the decidedly suboptimal annotations of the low-accuracy annotators and the better CRF estimates to a fully self-consistent estimate. Precision and Recall of the low-accuracy estimator.
 Since EM-CRF is built on data labeled by the low-accuracy WL annotator, it is important to analyze under which con-ditions the EM-CRF results can improve. To conduct this study we simulated a weak learner with performance that spans the possible range of precision and recall. This can be achieved by oversampling the weight of positive produc-t instances when training the low-accuracy annotators. We then compare the performance difference between EM-CRF and WL to the precision and recall of WL. The results on two large templates (2 and 4) are shown in Figure 8. Figure 8: Improvement in F1 score of EM-CRF over WL as a function of precision and recall for templates 2 (left) and 4 (right). Some precision-recall regions are missing since the associated conditions cannot be satisfied.

As can be seen, the results of both templates are quali-tatively similar. That is, improvements are highest for WL whenever the recall is sufficiently high. This is quite pos-sibly due to the fact that we use conditional independence assumptions on the weak learners, i.e. their estimates en-ter as products of probabilities Q i  X  ij . Hence, poor recall immediately leads to a strong bias against the presence of a given attribute. A more refined model to capture correlation between the weak learners would probably ameliorate these issues. By and large, for over 50% recall improvements are pervasive.
 Number of candidates in the E-Step. In (10 ) the pos-terior probability of each possible label combination y for the current document x j needs be calculated. A potential problem here is that when there are many uncertainties over the labeling of regions in one email, as there could be expo-nentially large number of possible label combinations (2 N which much reduces the efficiency of training. In our so-lution, we pick the top K candidate sequence labels with largest posterior probability in the step of recalculating dis-tribution q j ( y ). This reduces the time of the costly M-step (7) significantly.

This raises the question as to how much the hyperparame-ter K influences the EM-CRF performance? We train mod-els with K ranging from 1 to 500 and evaluate the EM-CRF performance on each template for each K , as shown in Figure 9. As can be seen, the F1 measure overall improves, albeit it does not change dramatically with varying K . This suggests that small values of K are perfectly acceptable. We finally set K = 100.
 Regularization of CRF weights. We tune the L 2 regu-larization penalty during the training of the CRF given the current belief on each label combination q j ( y ). That is, we add  X  k  X  k 2 to the negative log-likelihood in ( 7). Figure 10 Figure 9: F1 as a function of the number of candidate se-quences in the E-step. As can be seen, it is highly robust to sparse approximations. Figure 10: F1 as a function of the L2 regularization param-eters. More regularization improves accuracy. show the accuracy as a function of the regularization parame-ter for  X   X  [10  X  3 , 10]. As expected, increasing regularization improves generalization up to some point, since it restrict-s the model class. Beyond that, accuracy decreases again due to underfitting. Empirically, we set L2 regularization as 10  X  2 for the large scale experiments below.
In this section we demonstrate the behavior of our method by a larger scale evaluation study on 200 templates. The number of emails in each template ranges from 10 to 2500 emails.

We used simple frequency counting with exact textual match as simple template extraction method. Those fixed regions are labeled as Fixed during our CRF analysis, how-ever, their textual context is used to as feature for the CRF based models. We use the low-accuracy WL estimator from Section 5.3 which was trained over a separate dataset as our weak learner. The training method proceeds as discussed earlier over each template separately. Once we learn a struc-tural model for each template, we apply this model to predict product regions in new and unseen emails under the same template. We compare the performance of the three meth-ods: WL, CRF-Max and EM-CRF. Those unseen emails are donated with user consent and as such we hand-labeled them strictly for evaluation purposes. During training of the CRF-based models, no labels are needed and as such we do not perform any manual tuning of the hyperparameters and we rather fix them, across all templates, to default values ac-quired in the previous section. The training of EM-CRF is efficient because in practice we find the performance get-s convergence within 10 EM iterations. The average real runtime on a single machine is 1.6s for the large templates studied in this section. Figure 11: F1 performance as a function of the number of unlabeled emails in a given template.

We first compare the performance of the three methods as a function of the number of emails in each template. As show in Figure 11 , both EM-CRF and CRF-Max provide a higher overall performance than WL, which verifies the ef-fectiveness of structural information extraction on large-scale data. Furthermore, as the template email number increases, the improvement over WL becomes more significant. This is reasonable since more emails help CRF models learn the template structure pattern better. Moreover, EM-CRF re-sults in higher improvement for templates with large number of emails ( &gt; 1000 emails) while its performance is similar to the CRF-Max model for templates with small number of e-mails. Thus one can use CRF-Max for cold start situations (new templates) and then switch to using EM-CRF for large templates (with over 1000 emails). We further focus on the performance of the largest 20 templates and give a detailed break-down of the performance in Figure 12 . The perfor-mance break-down over templates with small number of e-mails is similar to the one shown in Figure 6 and is omitted due to space constraints.
In this paper, we addressed the challenging problem of in-formation extraction from commercial emails. While super-vised information extraction itself is a relatively well-studied area, information extraction from emails presents distinc-t privacy challenges that prevent us from even looking at the emails to either annotate fields for training or tune the hyper-parameters of the learning method.

We tackled this problem using a fully automatic approach that requires almost no manual tuning and is unsupervised in nature. The approaches presented in this paper (EM-CRF and CRF-Max) make use of low-accuracy annotators trained using weak features on a separate dataset. Our meth-ods leverage those weak signals to learn, in an unsupervised fashion, structural patterns specific to each template and then use those patterns to extract information from future emails in the same template. We provided a thorough eval-uation of our approach over large scale emails and showed that our proposed approaches result in significant perfor-mance improvement. Moreover, we analyzed the model and data conditions which could lead large improvement.

In the future we plan to investigate joint approaches for template extraction and structural learning as well as explor-ing the efficacy of transfer learning approaches of structural patterns across different email templates. Acknowledgements.

We sincerely thank Andrei Broder for helpful advices and support for the project. Also, we thank the team and col-laborators for the excellent work.
