 In resent years, blog is becoming an increasingly popular form of communication on the World Wide Web. The blogosphere is a rich information source of public voice, and is useful in extracting and mining public opinions towards some objects or events. Different from other kinds of online textual information, the main characteristics[1] of a blog are: 1) Information provided is often opinion-oriented; 2) Containing numbers of documents that cover a wide range of topics. The need to find appropriate retrieval techniques to track the way bloggers react to products, persons and events raises some challenging problems in the field of information retrieval[2]. Blog opinion retrieval is a task to save the challenge and serve the growing interest in IR. 
In this paper, blog opinion retrieval is defined as a task to search blogs with a recurring interest and opinion towards a given topic. Similar to traditional retrieval system, blog opinion retrieval has two basic tasks: 1) search the relevant documents to a user X  X  query, and 2) ranking these documents according to the level of relevance. However, blog opinion retrieval has several special characteristics to be taken into subscribe as an interesting feed about the topic (i.e. users may add the interesting feed to their RSS readers). This requires the retr ieval unit to be the entire blog containing a number of posts, but not a single post document. Since a blog contains both relevant posts and non-relevant posts to a topic, the overall relevance of a blog must be measured in a proper way. Besides, the blog opinion retrieval goes beyond topic relevance and integrates the opinion relevance in the evaluation of the retrieved blogs. This requires the system to determine whether a blog expresses opinions or facts. TREC 2009 Blog Track 1 highlights its interest in blog retrieval, and introduces the Faceted Blog Distillation Task. This task takes into account a number of attributes of facets such as opinion, personality and in-depth facets. This paper mainly focuses on the blog opinion retrieval in previous works: two-stage approach based on classification and mixture of language models approach. The two-stage approach is often used in previous TREC Blog Track. There are two basic components in this approach[3]: the retrieval component and the opinion classification component. The former carries out basic relevance retrieval for each query whereas the latter classifies each blog into two categories, namely, opi nionated category and factual category. SVM and the maximum entropy classifiers are used in many cases. Mixture of language models approach[4, 5] assumes that a blog is generated by sampling words from a mixture model involving a background language model, a topic language model, and an opinion language model. 
In this paper, we present our approach based on the topic-opinion mixture model. It is similar to the above mentioned mixture of language model approach. However, their approaches assume the content of opinion model is the same for all topics, or require models to be trained for every topic by annotated data, or manually input subjective keywords. In our approach, we assume the text opinion expression is dependent on the topic. We first make use of pseudo feedback documents from wiki corpus to construct the topic relevance mode l, and then some words are automatically selected from a subjective/objective lexicon by the semantic association extent with the topic. Then we combine these words with original query to re-retrieve and get the opinion feedback documents. An opinion relevance model is constructed by these feedback documents. Finally, a topic-opinion mixture model is combined from topic relevance model and opinion relevance model. This model contains topic features and their associated opinion features. So it is effective to evaluate the level of topic relevance and opinion relevance of a blog. 
We conduct experiments in this paper on TREC blogs08 datasets, with each blog post being considered as a web page. Moreover, the opinion lexicon (subjective or objective lexicon) used is domain-independent. Hence our proposed approach is applicable to all opinion retrieval tasks on any text resource contained information about topic and opinion, such as product reviews. 
The rest of the paper is organized as follows. In Section 2, we briefly introduce the related works in the field. The problem is defined in Section 3. The whole approach is described in Section 4. The experiments and result analysis are presented in Section 5. Finally we conclude the paper and discuss the future work in Section 6. There are many related works in the TREC Blog Track. First introduced in TREC 2006, the blog track explores the information seeking behavior in the blogosphere. In task . At the first stage, documents are ranked using modern and effective document ranking functions such as BM25[6], language models (LM) and divergence from randomness (DFR) models[7]. A relevance score is allocated to each document. At whether a document is opinionated or factual, and an opinionated score is assigned for the document. Next the retrieved documents are re-ranked according to the combined score of the relevance score and the opinion score. Most solutions use a linear combination of relevance score and opinion score, whereas a quadratic combination solution[13] is proposed and achieve a significant improvement. 
For the blog distillation task, there are three main solutions: expert finding, pseudo-cluster selection and federated search model. Expert finding solution[7, 14] regards the blog distillation task as an association finding task, between topics and bloggers. blogger model and posting model are proposed for modeling blog distillation[15]. The blogger model represents the blog as a as a multinomial probability distribution over the vocabulary terms. It then computes probability of a query given a blogger. While in the posting model, each post is computed by query likelihood scoring method followed by combining the score for each post. Pseudo-cluster selection solution[16] topic-dependent pseudo-cluster. Federated search model solution[17] ranks blogs by the estimated number of relevant documents. Pseudo-cluster selection and federated search model solutions use small document model which treats posts of a blog individually. In expert finding solution, large document model which treats all posts of a blog as a whole can achieve a better performance than the small document model. All solutions use language model as the basic retrieval method. 
In TREC 2009 Blog Track, the opinion finding task and the blog distillation task facets. This paper mainly focuses on the opinion facet. We use a mixture of topic and opinion language models to solve the problem of blog opinion retrieval. A mixture of language models is commonly used in IR application. The basic idea[18] is to infer language models corresponding to unobserved features in the corpus, with the hope that the features learned represent topic and opinion. An example of these works is from Koji and Victor[5], in which sentiment relevance models and topic relevance models are combined based on Generative Models. Mei ant others[4] first introduced Topic-sentiment Mixture model (TSM), which can reveal the latent topical facets in a opinions. Their TSM model is a special case of CPLSA model[19], which mixes themes with different views. TSM attempts to learn a general opinion model to all topics, based on the assumption that the opinion model is independent to the topic model. However, in reality, there is a correlation between opinion model and topic model. For example, in topic  X  X ii exercise X , the words represent opinion such as  X  X agical X ,  X  X isgust X ,  X  X illy X  have a higher probability of occurrence; while in topic  X  X esterns movies and novels X , the opinionated words such as  X  X lawless X ,  X  X ddities X ,  X  X ropitiously X  are more likely to appear. Our approach assumes each topic has its own opinion relevance model. The opinion relevance model can be estimated by pseudo-relevance feedback, and then combined with topic relevance model which is estimated by wiki pseudo-relevance feedback. The aim of opinion blog retrieval task is to  X  X ind opinionated or factual blogs that are principally devoted to a given topic 2 over the timespan of the blog X . Inspired by TREC 2009 Blog Track, we define the opinion blog retrieval task as follows: 
Given a topic T , find blogs related to T , rank them by topic relevance and opinion relevance. The system should provide three blog ranking results according to opinionated relevance, factual relevance and topic relevance as the baseline respectively. The retrieval unit is a blog containing a number of blog posts which can be viewed as web documents. 
The previous solution to blog opinion retrieval problem adopted a two-stage the opinion relevance; 2) Using different classification techniques to compute the opinion relevance of all retrieved blogs, followed by re-ranking them. In the following section, we introduce our approach based on the topic-opinion mixture model to address the blog opinion retrieval task. 4.1 Blog Representation and Query Generation Following the works of [17, 20], we choose Global Representation Model to represent blog. This model treats a blog as a virtual document which is composed of all posts of the blog. Because this model considers all posts over the timespan of the blog, it can factually approach to rank, Global Representation Model, which combines many posts into a large document, can avoid the problem of sparsity of words as much as possible. 
In our approach, title, description and narrative fields of a topic are used for query string generation. First, we filter out unnecessary punctuation marks in the above fields. All verbs are replaced by their infinitives and all nouns by their singular forms. After this, we extract the keywords to build the bag of words. The basic Indri 3 query Q is defined as: w w 2 ...w n are the keywords in the bag. We use the following Indri query template to generate query string for a given topic: description and narrative field of the topic. 4.2 Basic Retrieval Model Using the language model approach in IR has shown its effectiveness and simplicity. The general language model approach[21] is decomposed into three components: 1) query model Q ; 2) document model D ; 3) matching strategy between query model and document model. In our approach, we choose KL-divergence to measure the distance between Q and D , and rank blogs by the following formula: Because the constant cons ( Q ) does not affect the ranking results, we do not compute it in our system. Thus, the main task is to estimate Q and D . For blog retrieval in the paper, the document model D is a multinomial distribution whose parameters are represented by unigram language models. We assume that blog documents are generated by D , which can be estimated by the following formula: count of w occurs in d , and  X  is a Dirichlet smoothing parameter. We use  X  =2000 in this paper, which is optimal in most cases[22]. 
In traditional approach[21], Q will be updated by feedback documents model that can be obtained by the relevant documents judged by users, or top documents from Topic-opinion Mixture model TO , and interpolate it with the original query model Q to obtain the updated query model Q X  , and then assign a score to blog D by Formula (1). The updated query model Q X  is: where  X  controls the influence of topic-opinion mixture model TO . In Section 4.3, we describe how to estimate topic-opinion mixture model TO . 4.3 Topic-Opinion Mixture Model The topic-opinion mixture model TO in Formula (3) is the language model which reflects the information need for both topic and opinion; hence a mixture of language models is used to estimate TO . In our solution, we define two language models, namely, topic relevance model T and opinion relevance model O . The topic-opinion mixture model TO is a linear combination of the two language models: where  X  is used to control influence of opinion relevance model O . 
In general, the topic relevance model T in Formula (4) can be obtained by pseudo-relevance feedback method (PRF). PRF assumes the k top-retrieved documents are relevant to the original query and extracts highly discriminative words from those documents to update the original query model. We use divergence minimization algorithm[21] to estimate T . The divergence minimization algorithm assumes that the topic relevance model is very close to each language model of feedback documents, and uses KL-divergence as the distance between two language models. In order to obtain the feedback documents with high relevance, we index the Wikipedia corpus 4 and treat the k top-retrieved wiki pages as the relevance feedback documents. Given a Wikipedia corpus. So the dist ance can be represented as: Where Wiki is the Wikipedia corpus language model,  X   X  [0, 1) is the factor that controls the weight of Wikipedia corpus language model. Following [21], p ( w | T ) can be computed as follows: According to Formula (6), wo rds that are common in the feedback documents, but not common in the entire Wiki corpus will be assigned a higher probability. In our system, k =25,  X  =0.5, the feedback terms count is set to be 100. 
Next we must estimate the opinion relevance model O in Formula (4). O reflects the users X  information need for opinion. Some bloggers provide opinionated content for their interested topics, while others report factual information. So we need to estimate two O , one for opinionated information and the other for factual information. Previous works show that the opinion always has an association with topic. Different topics may have a different opinion expression. But training different models on annotated data for different topic is usually unpractical. 
The basic procedure of our approach has two steps. The first step is to expand original query with some subjective words or objective words, and then use the expanded query to obtain the top k ranked results as pseudo-feedback documents. The second step is to make use of pseudo-relevance feedback method to estimate O . For lexicon and an objective lexicon. The subjective lexicon contains 8821 words that are used in OpinionFinder[23]. The words in objective lexicon are selected from SentiWordNet[24]. Similar to [25], we us e the Pointwise Mutual Information (PMI) to measure the semantic association between subjective/objective word w and the query string Q of a given topic: where | C | is the total number of documents in corpus. We make use of blog collection which contain subjective/objective word w and query string Q respectively. hits ( #uw 15( w Q )) is the count of retrieved documents containing w and Q simultaneously in an unordered window of 15 terms. The reason why we use a fixed size window instead of a sentence is that: it is time-consuming and unpractical to split all text into sentences, and the inaccuracy can be ignored when large corpus is used. To avoid division by zero, 0.01 is added to the number of hits. Finally we choose the top 30 subjective/objective words according to t he PMI value, and use them to expand original query . T he feedback documents can be used to build opinion relevance model O by Formula (6). 5.1 Experiment Setup 5.1.1 Data Sets We use TREC Blogs08 collection as required by TREC 2009 Blog Track to evaluate our approach. The summary statistics of this collection is shown in Table 1. We actually use the permalinks and homepages in our approach. Blog feeds collection is not used. It is because the text in the feed pages usually contains a few sentences of each post and therefore cannot reflect the topic or opinion well. The permalinks and homepages are encoded by HTML. We use Indri to index them respectively. The Krovetz stemmer and a list with 450 stop words are used to pre-process. 5.1.2 Evaluation There are 13 opinion topics provided by TREC 2009 Blog Track (see Table 2). The evaluation metrics used are standard IR me asures[26], such as mean average precision (MAP), R-Precision (R-prec), and precision at top 10 results (p@10). The relevance and opinion judgments adopt the TREC 2009 Blog Track standards: not judged (-1), not relevant (0), relevant (1), relevant and opinionated (2) and relevant and factual (3). All results are assessed by th e evaluation tool provided by TREC. There are four approaches in our experi ments for comparative studies: (1) Our Topic-opinion Mixture Model (TOM) (2) MEClassifier. It is a traditional approach based on classifier. We trained a maximum entropy classifier on Movie Review Data. The classifier takes blog text vector as input, and outputs opinionated or factual label and an associated score, which is combined with original relevance score. Blogs is then re-ranked by the combined score. (3) SingleModel. It combines all topic models with the same opinion model. This approach is introduced in [4], which treats the the topic relevance score while ranking the opinionated and the actual blogs. 5.2 Experimental Results 5.2.1 Overview of Experimental Results Result comparisons of each approach are presented in Table 3 and Fig.1. The results show that all approaches outperform the baseline. Comparing with other approach, our approach achieves the best retrieval performances except for R-prec and P@10 of factual blog retrieval in Table 3. This demonstrates that our proposed approach is effective especially for opinionated blog retrieval. 
Fig. 2 (a) and (b) show the performance improvements over baseline on each topic in terms of MAP and R-prec. The average improvements on all topics for opinionated blogs retrieval are 48.87% and 26.39% in terms of MAP and R-prec. The average improvements for factual blogs retrieval are 22.69% and 8.82% in terms of MAP and R-prec. We note that there is a slight improvement over baseline in factual blog retrieval. The explanation is that, ranking by topic and factual relevance does not have much difference from ranking only by topic relevance. Only topic 1134 and 1150 get decreased performance. In terms of MAP, there are 5 topics which have no improvement over baseline for factual blogs retrieval, comparing with 2 topics for opinion blogs retrieval. In terms of R-prec, there are 7 topics which have no improvement over baseline for factual blogs retrieval, comparing with 5 topics for opinion blogs retrieval. This proves that our approach is more effective for opinionated blogs retrieval than factual blogs retrieval. 5.2.2 Analysis of Parameters of Topic-Opinion Mixture Model In our approach, the parameter  X  of the topic-opinion mixture model controls influence of and opinion relevance in topic-opinion mixture model. In order to analyze the effect of  X  , we note that parameter  X  in Formula (3) may affect the final performance. The difference can be observed in Fig. 3 (a), in which we show the changing performances by changing  X  from 0 to 1, with a step up size of 0.1. In this experiment, we set  X  =0, thus, TO actually becomes the topic relevance model T . Therefore the experiment actually evaluates the effects of feedback documents from Wiki corpus. We notice that using feedback model from wiki documents can generally improve the performance. But when it is too large approaching 1, the performance is extremely bad and is even worse than the performance without using feedback model. We choose  X  =0.5, which is a value that can usually achieve better performance than other values. 
Fig. 3 (b) shows how MAP, R-prec varies accordingly with  X  , when  X  is fixed at 0.5. Note that performance at  X  =0 is actually the baseline performance. Overall, when the  X  value increases, the overall performance improves. But when  X  is too large, the overall performance deteriorates sharply. Be more specific, when  X  =0.5 the opinionated blog retrieval achieves its best performance; when  X  =0.3 the factual blog retrieval achieves its best performance. Th is is because the topic relevance model helps to focus on the topic, while the opinion relevance model can supplement subjective or objective words for the purpose of opinion retrieval. When  X  is too large, there will be many opinionated or factual blogs with no topic relevance. 5.2.3 Analysis of Samples from Topic-Opinion Mixture Model Table 4 presents sample probabilities using topic-opinion mixture model. Samples are divided into the two topics:  X  X azz music X  and  X  X o child left behind X . The  X  X opic model X  columns contain the topic words. These words may come from the subtopic of the corresponding topic, such as  X  X usician X  ,  X  X and X ,  X  X frica X ,  X  X ducate X ,  X  X und X , etc. So they can be treated as supplement for the original query. The  X  X pinionated model X  columns contain subjective words related to the corresponding topic. As we have discussed above, the opinionated relevance model varies significantly with topics. For instance, for  X  X azz music X  topic, the subjectiv e words  X  X imitless X ,  X  X ntertaining X  have relatively higher probability of occurrence; whereas for  X  X o child left behind X  topic, the associated subjective words are  X  X illing X ,  X  X upportive X , etc. In the  X  X actual model X  columns, the words are found to be neutral, without any semantic orientation. Some words appear in many topics, such as  X  X omment X ,  X  X tate X , etc. This reflects that the factual relevance model has low association with topics. In this paper, we present an approach to the task of blog opinion retrieval. This approach uses topic-opinion mixture model to solve the problem of ranking blog not only by topic relevance but also by opinion relevance. Comparing with previous work, this model can effectively learn opinion relevance model without training on annotated data. In addition, the opinion relevance models vary with topics so that the model X  X  effectiveness to different topics is ensured. We evaluate our model on TREC Blogs08 collection, and the experimental results show that the topic-opinion mixture model approach achieves a better performance than other approaches for most of the opinion topics in TREC 2009 Blog Track. 
In general, performance of the blog opinion retrieval is worse than traditional text retrieval. There is still a huge potential space for further research to improve the the knowledge behind topic and opinion from the perspective of time dimension of blogs. Another interesting future research direction is to use the mixture language etc. Acknowledgments. We would like to express our gratitude to Computer Software Lab of Beijing Institute of Technology for providing us experiment condition for our participation in TREC 09. This work is supported by the grant from Chinese National Natural Science Foundation (No: 60705022). 
