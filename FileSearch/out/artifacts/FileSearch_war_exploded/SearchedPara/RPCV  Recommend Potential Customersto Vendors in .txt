 With the rapid development of location-acquisition and mobile communication technologies, a number of location-based social network services have emerged in recent years (e.g., Foursquare, BrightKite, Gowalla and so on), which result in a new concept of online social media named location-based social network (LBSN). LBSN allows users to share their locations and find out local points of interest, which bridges the gap between the physical and digital worlds. Foursquare, as a representative LBSN, has achieved one billion users X  check-ins within two years since its foundation. The average amount of check-ins made by users per day was about three million in Foursquare, and this number is still growing. Such rapid growth of LBSN has brought the convenience to collect user data, which consists of the spatial, social and rating aspects. These real user data enables a deeper understanding of users X  preferences and behaviors. centered recommendations in LBSN, such as user recommendations [ 1 ], activity recommendations [ 2 ] and social media recommendations [ 3 ]. However, increas-ing demands encourage researchers to study on vendor-centered recommenda-tions, which can help vendors grow their business by recommending potential customers. Besides the user preference, vendor-centered recommendations need to consider more users X  real-time requirements and spatial location relations than user-centered recommendations. For example, a user makes a check-in at a restaurant after he has a meal with his friends. There is a great possibility that they will do some entertainment activities after the meal. This is a good time point for recommendation service providers to push useful information which meats the user X  X  real-time needs. As we know, users X  demands may be changed over time, and outdated information is worthless for them. Therefore if the ser-vice provider can catch users X  real-time requirements at a right time point, it will improve their recommendation quality, and can help vendors to do mar-keting better. It is important to consider spatial relations while recommending customers to local vendors. Figure 1 gives an example to illustrate the impor-tance of spatial locations. Whereby, A and B are two customers, V1 and V2 are two vendors, A is the top-1 customer of V1 and V2. If we want to recommend one customer to V1 and V2, traditional works that use similar approaches like top-k query will recommend customer A to both of them. In reality, customer A treats V2 as his top-1 vendor. There is a great possibility that he will choose V2 instead of V1. As we know, recommending service is not free, and vendors should pay for each recommendation. Obviously, top-k query is not a good solu-tion, since it does not consider the spatial relations among vendors. Therefore, to save vendors X  cost and improve the quality of recommendations, it is neces-sary to make better use of spatial relations among vendors. In conclusion, to recommend potential customers to vendors should fulfill two essential require-ments: (1) Users X  requirements and (2) Vendors X  profits. The former one requires to find users X  true preferences, which guarantees the relevance of a vendor to an individual user. The latter one encourages the service providers to maximize the profit of a vendor when the vendor has a fixed budget.
 In this paper, we propose a framework that can Recommend Potential Cus-tomers to Vendors in LBSN, named RPCV. It aims at selecting relevant poten-tial customers for vendors in real-time, and considers both of the two essential requirements. Instead of considering vendors separately, we propose a reverse spatial-preference kRanks algorithm, which considers the influence of other ven-dors on customers. What X  X  more, this algorithm effectively combines spatial rela-tions with user preference and can catch users X  real-time requirements. By this algorithm, we can find k customers whose ranks for a given vendor are highest among all customers. The contributions of this paper are summarized below:  X  We propose a recommendation framework that can recommend potential customers to vendors and work in a real-time environment.  X  We propose a reverse spatial-preference kRanks algorithm, which effectively combines spatial relations with user preference, and can also catch users X  real-time requirements.  X  We evaluate our work in two real datasets from Foursquare and BrightKite. Experiments show that our strategy has a higher precision than others. The rest of this paper is organized as follows. We first review related work in Section 2 . Then, Section 3 presents the system framework of our RPCV. Sections 4 and 5 introduce our novel user preference model and reverse spatial-preference kRanks approach. Section 6 analyzes experimental results. Finally, we conclude this paper in Section 7 . Recommendations in LBSN. Due to the rapid development of location-based services, real traces of user locations and activities have been collected and used in several researches [ 4  X  6 ]. The location dimension bridges the gap between the virtual online social network and physical world, giving rise to new challenges and opportunities in recommending systems. Besides location, the temporal, spatial, and social aspects are also available in LBSN. Therefore, more and more researchers try to make efforts to mine users X  mobile behaviors in LBSN. In [ 7 ], Huiji et al. proposed to model temporal effects of human mobile behavior in LBSN, and strong temporal cyclic patterns have been observed in user move-strong heterogeneity across users with different characteristic geographic scales of interactions across ties. While Ye et al. [ 10 ] investigated the geographical influence [ 11 ] and social influence [ 12 ] for location recommendation, they dis-covered that user preference plays a more important role in contributing to the recommendation than social and geographical influences do.
 Ranking Query. In general, the ranking query returns top k tuples with max-imal (minimal) ranking scores by employing a user-defined scoring function. A general linear model is one of the most widely adopted models among existing scoring function. However, the top-k query under linear model is mainly focused on the perspective of users, which aims at finding a set of products to match their preferences. However, vendors would prefer to know who would be inter-ested in them, which are totally opposite. In [ 13 ], reverse top-k query is used to return an unordered result set of users, and these users are all treating the given vendors as one of their top-k vendors. Nevertheless, it can not work in our research, since it can not guarantee 100% coverage of any given query. In this section, we illustrate the framework architecture of RPCV shown in Figure 2. In order to avoid missing users X  real-time requirements, we designed it in a burst mode and triggered by users X  check-in behaviors. When the start event is triggered, our RPCV will start from its reverse spatial-preference kRanks mod-ule. It begins to recommend a specific number of potential customers to prelim-inary defined vendors. As presented in the figure, the reverse spatial-preference kRanks module requests user preference from a user preference module. The main task of user preference module is to compute user preference with our user preference model. Our user preference model handles this task by leveraging social, historical, rating and spatial data. The details of the two modules will be explained in Section 4 and 5 . Finally, the framework outputs a series of potential users for preliminary defined vendors.
 In reality, users prefer more relevant information with respect to their preferences [ 14 ]. Therefore, in this section, we introduce a novel model to build user pref-erence, which is an indispensable part of our reverse spatial-preference kRanks approach. The preference of user u i to a vendor v j can be described by differ-ent profiles. In this paper, we use a two-dimension vector w preference. The first dimension of this vector is the degree of a user preferring the vendor. This preference can be computed as a preference score S leveraging users X  social relations and historical behaviors. The second dimension is the sensibility of the spatial distance, which is computed by a spatial score. The spatial score can be measured by different metrics. A common approach for the spatial score computation is based on the distance between the check-in loca-tions and users X  home. Then, we can find out the user X  X  sensibility of the spatial distance, denoted as S sd u i ( v j ). Finally, the vector w be used to represent the preference of the user u i for the vendor v normalize S p u i ( v j )and S sd u i ( v j ) to make their summation to be 1. 4.1 Analyzing Social and Historical Behaviors Previous works find users X  friends may influence their behaviors [ 8 , 15 ]. To inspect our guess, we capture about 2M users and 1M venues across US from foursquare and compared the number of common check-ins between two friends and two strangers. As shown in Table 1(a) , on average, a pair of friends share about 13.527 check-ins, while a pair of strangers share only 4.831 check-ins. This indicates that friends have strong influence to a user X  X  check-in behaviors.
 When mining user preference, users X  historical behaviors are important fac-tors that cannot be ignored. While capturing a user X  X  historical behaviors, two important properties must be considered. The first one is that a user tends to go a few places many times and many places a few times. This means the history approximately follows a power-law distribution. Another property is that the historical behaviors have short-term effect. This means the previous check-ins have different strengths to the latest check-in. As shown in Table 1(b) , there are many common features between language processing and LBSN mining. Besides, the check-in data and the document have similar structure. Therefore, we prefer to use a state-of-the-art language processing tech called hierarchical Pitman-Yor process (HPY) [ 16 ] to capture users X  historical behaviors.In addition, the HPY is a hierarchical extension of Pitman-Yor process [ 17 ].
 we leverage them to model user preference in this paper. We will combine the two behaviors together to evaluate user preference, using Equation S  X S P i ( v j ) represents the historical score. The parameter  X  is used to adjust the relative importance of the parts. 4.2 Social Score Computation The opinions data about how much a user u i likes a vendor v from similarities, which can be inferred from user X  X  ratings and check-in location histories in LBSN. In this paper, we use a simple but effective computation app-roach by leveraging users X  ratings. Table 2(a) shows an example about the close-ness between users while Table 2(b) shows the normalized rating score s (with a value between zero and one) of a vendor v j given by a user u know, different friends have different social effects on a user. So in this paper, we use a weight cw i,k to represent the closeness u k towards u of the user u i .Weuse f ( u i ) to represent the friends of the user u can be evaluated from many metrics, such as the number of common friends, the number of common check-ins and so on. We constrain the total weight of the closenesses to be one. Thus, the friends X  recommending score of the user u on a vendor v j can be computed by the equation as follows.
 4.3 Hierarchical Pitman-Yor Process As mentioned above, the historical score is generated by HPY and the HPY. In this subsection, we will explain how HPY works. The HPY process assumes that the earlier a word is mentioned, the less importance the word has. It is an n-gram model that captures the short-term effect without losing the power-law property in distribution. In HPY, G u denotes the probability of the next check-in while given a history context u : In ( 2 ), d | u |  X  [0 , 1) is a discount parameter to control the power-law property,  X  is the strength parameter,  X  ( u ) is the suffix of u and G next check-in in the history context u . And the PY is a Pitman-Yor process. All of these parameters are under context u which consisting of all but the earliest check-ins. G  X  ( u ) is then computed with parameters d |  X  This process is repeated until we get the empty historical context The m locations can be represented by the location space L ,and m = base distribution G 0 is a uniform distribution providing by a prior probability. It satisfies G 0 ( l )=1 /m , where G 0 ( l ) is the probability of a location l check-in.
 Where N ul is the number of check-ins at l following the historical context u and n u = l N ul  X  t u = l t ul is the sum of all t ul , which is a latent variable satisfying: In this section, we will explain our reverse spatial-preference kRanks algorithm. It effectively combines spatial relations with user preference. Its tree-based prun-ing approach improves its efficiency and makes it applicable in a real-time envi-ronment. It guarantees that we do not lose the chance to catch users X  real-time requirements. 5.1 Basic Concepts In our work, we want to know who will be interested in a vendor. This is totally opposite to top-k query. Reverse top-k query seems to meet our requirements, but it cannot ensure 100% coverage for any given vendor and the size of the result set sometimes is larger than k. However, it is necessary to recommend a specific number of customers to vendors. Therefore, we propose a reverse spatial-preference kRanks algorithm, which can effectively combine spatial relations with user preference and return a ranked result set of k customers for any given ven-dors. For any given vendor, we use an attribute vector v = &lt;r,z&gt; to represent it, where r is the average ratings given by all users and z is the z-value calcu-lated by its location. The z-value here is generated by the well-known Z-order approach [ 18 ]. With the help of Z-order approach, we can estimate the dis-tance between a user and a vendor through the difference value of their z-value quickly. What X  X  more, the Z-order makes it possible to take the spatial location information into the vendor X  X  attribute vector, which can help avoid rebuilding the R-tree of our vendors. The details of R-tree will be explained later. In this paper, a score function is defined as f ( w, v )= d i =1 w ( production of the user X  X  preference vector w and the vendors attribute vector function is f ( w, v )=(0 . 3  X  4 . 2+0 . 7  X  (65  X  23)).
 Definition 1 ( rank(u,q) ). Given a vendor point vector set D , a specific user u , and a query point vector q , the rank of q for u is rank ( u, q )= is the cardinality of S ,and S is a subset of D .And  X  p i f ( u.w, p i ) &lt;f ( u.w, q ) ;For  X  p j  X  ( D  X  S ) , we have f ( u.w, p Definition 2 ( reverse spatial-preference kRanks query ). Given a vendor point vector set D ,auserset U , a positive integer k (the size of the result set), and a query point vector q , reverse spatial-preference kRanks query returns a set SU , SU  X  U, | SU | = k and  X  u i  X  SU,  X  u j  X  ( U  X  rank ( u j .w, q ) For any given user u in U and any given point p in D , we compute rank ( u.w, q ) one by one, and keep k weights with the smallest rank ( u.w, q ) for query point q. The complexity is O ( m  X  n ) where m is the number of customers and n is the number of vendors. Note that this is used as a baseline to compare with our tree-based pruning approach. 5.2 Tree-Based pruning approach The baseline method above evaluates every customer and vendor pair. As we mentioned that its time complexity is O ( m  X  n ). Fortunately, we can use an R-tree to avoid some parts of computations, i.e., building an R-tree to index all vendors by their attribute vectors. In the R-tree, we use r denote a minimal bounding rectangle (MBR), and then use r.L and r.U to denote the bottom left and top right points of r respectively.
 Definition 3 ( Dominance ). We say a point p 1 dominates a point p as p 1  X  p 2 ), if and only if the following two conditions hold: (1) (2)  X  j, p j 1 &lt;p j 2 According to the definition 3 ,wehave f ( u.w, p 1 ) &lt;f ( u.w, p since  X  i, w ( i )  X  0. Therefore, there are two facts we can obtain. Given a query point q , a specific user u i , and an MBR r in R-tree, if f ( u then  X  p  X  r ,wehave f ( u i .w, q ) &lt;f ( u i .w, p ). And if f ( u  X  p  X  r ,wehave f ( u i .w, p ) &lt;f ( u i .w, q ).
 (TPA). We index all vendors by an R-tree R offline. During processing, it com-putes ranking score by traversing R-tree. According to the two facts, the nodes satisfying f ( u i .w, q ) &lt;f ( u i .w, r.L )or f ( u i Algorithm 1. Tree-based pruning approach ( R, U, q, k ) safely. Otherwise, if the node is not a leaf node, it will be appended to the queue Q for further processing. The queue Q keeps the tracks of all un-pruned leaf nodes. And the global variable minRank is used to describe the kth maximal entry in array A . That is, at least k customers treat q as one of his top favorite objects till now. Finally, the algorithm returns k smallest entries in A . TPA prunes computations from the perspective of data points and reduces time complexity to O ( m r  X  n ), where m r = | R | ,n = | D | 6.1 Experimental Settings In this subsection, we introduce the experimental settings. All codes are written in JAVA, and run on a single machine with Intel CPU/2.8GHZ and 8GB memory. Data Set. Our experiments are based on two real datasets from Foursquare and Brightkite. Both of them allow users to make check-ins at physical locations through mobile phones and let their online friends know where they are. All the information about the two datasets is listed in Table 3 .
 Evaluation Metrics. In this paper, we use the average precision as our eval-uation metric. We compare our approach with top-k query and reverse top-k query. Actually, this is a strict evaluation measurement, as a user may still like a vendor even if he did not visit it. In addition, there is a probability that the user could forget to make a check-in when he visits the vendor. Therefore, our framework is actually more effective than the experimental results shown later. Besides, we compare the time consumption of our tree-based pruning approach with a baseline method. 6.2 Experiment Results Reverse Spatial-preference KRanks Effectiveness. Reverse spatial-preference kRanks (short for RSPKR) is the core of our RPCV. It is responsible to deal with the input query and output potential customers for a querying ven-dor. Thus, we first evaluated the effectiveness of our reverse spatial-preference kRanks approach. We use the real check-ins of users recommended to the query-ing vendor as the ground truth, and compare RSPKR with top-k query (i.e. return top-k preferred customers, denoted as TopK) and reverse top-k query (i.e. return a set of unordered customers who treat the given vendor as their top-k vendors, denoted as RTopK), in terms of their precisions. The perfor-mance of three approaches on the two datasets are shown in Figure 3(a) and 3(b) respectively. The X-axis of both figures represents the number of recom-mending customers, and the Y-axis of both figures represents the precision value. other two approaches. The TopK is the worst, since it does not consider the opinion of a user towards other vendors. RTopK is better than TopK, because it chooses the customers who treat the querying vendor as their top-k vendors. However, the size of its return customers may be larger or smaller than k .For some unpopular vendors, RTopK even returns none customers. As mentioned in the previous section, the results of RTopK are unordered. Thus, while the size of the results is larger than k , we should choose the top k customers for the querying vendor, but we do not know the rank of these customers. These reasons cause that RTopK is less effective than our RSPKR. The experimental results show that it is helpful to consider spatial relations among vendors. Efficiency Comparison . Our reverse spatial-preference kRanks uses tree-based pruning approach to accelerate the query processing. Therefore, we compare the tree-based pruning approach (TPA) with baseline method mention before, in terms of different numbers of customers and different numbers of vendors respectively. The comparisons of time consumption are shown in Figure 4(a) and 4(b) . In both figures, the unit of their Y-axis is seconds. Note that Figure 4(a) shows the performance changes while the number of customers increases from 100K to 500K and the number of vendors is 20K. Figure 4(b) shows the performance changes under the number of vendors increases from 10K to 50K and the number of customers is 400K. Figure 4(a) and 4(b) show that the processing time of both methods increases with both the increment of the number customers and vendors. From this two figure, we can also see that our tree-based pruning approach is far more efficient than the baseline method under the two different scenarios. Comparing these two figures, we can see that the computation time grows significantly quicker with the increment of the number of vendors, comparing with the time under the increment of the number of customers. This is because the computation time of each customer grows when the number of vendors increases. In this paper, we present RPCV, a recommending framework that aims at rec-ommending potential customers to vendors in a real-time environment. With the help of our reverse spatial-preference kRanks approach, we effectively com-bines spatial relations with user preference. The experimental studies on two real datasets demonstrate that our framework outperforms existing strategies. An interesting direction for future work is to consider temporal and/or semantic features.

