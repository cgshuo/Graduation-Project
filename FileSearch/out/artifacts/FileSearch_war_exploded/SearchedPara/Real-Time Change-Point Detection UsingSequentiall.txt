 1.1 Motivation We are concerned with the issue of detect ing change points in time series. Here a change-point is the time point at which the statistical nature of time series suddenly changes. Hence the detection of that point may lead to the discovery of a novel event. The issue of change-po int detection has recently received vast attentions in the area of data mining ([1],[9],[2],etc.).This is because it can be applied to a wide variety of important data mining problems such as the de-tection of failures of computer devices fr om computer performance data such as CPU loads, the detection of malicious ex ecutables from computer access logs.
We require that the change-point detection be conducted in real-time. This requirement is crucial in real environm ents as in security monitoring, system monitoring, etc. Hence we wish to design a real-time change-point detection al-gorithm s.t. every time a datum is input, it gives a score measuring to what extent it is likely to be a change-point. Further it is desired that such an algo-rithm detects change-points as early a s possible with least false alarms.
We attempt to design a change-point detection algorithm on the basis of data compression. The basic idea is that a change point may be considered as a time point when the data is no longer compressed using the same nature as the one which have ever been observed. An important notion of sequentially normal-ized maximum likelihood (SNML) coding has been developed in the scenario of sequential source coding [4],[6],[5]. It has turned out to attain the shortest code-length among possible coding methods. Hence, from the information-theoretic view point, it is intuitively reasonable that the time point when the SNML code-length suddenly changes can be thought of as a change point. However, SNML coding has never been applied to the issue of change-point detection. Further in the case where data sources are non-stationary, SNML should be extended so the data compression is adaptive to the time-varying nature of the sources. 1.2 Purpose and Significances of This Paper The purpose of this paper is twofolds. One is to propose a new method of real-time change point detection using the sequentially discounting normalized maxi-mum likelihood coding(SDNML) . SDNML is a variant of SNML, which we newly develop in this paper. It is obtained by extending SNML so that out-of-date statistics is gradually discounted as time goes on, and eventually the coding can be adaptive to the time-varying nature of data sources. In our method, we basically employ the two-stage learning framework proposed in [9] for real-time change-point detection. In it there are two-stages for learning; one is the stage for learning a probabilistic model from an original data sequence and giving a score for each time on the basis of the learned model, and the other is the stage for learning another probabilistic model from a score sequence obtained by smooth-ing scores calculated at the first stage and giving a change-point score at each time. In this framework we use SDNML code-length as a change-point score. Note that in [9], the predictive code-length was used as a change-point score instead of SDNML code-length. Since the SDNML coding is optimal as shown in [6],[5], we expect that our method will lead to a better strategy than the one proposed in [9]. The theoretical background behind this intuition is Rissanen X  X  minimum description length (MDL) principle [4], which asserts that the shorter code-length leads to the better estimation of an underlying statistical model.
The other purpose is to empirically demonstrate the significant superiority of our method over existing methods in te rms of detection accu racy and computa-tional efficiency. We demonstrate that using both artificial data and real data. As for artificial data demonstration, we evaluate the performance of our method for two types of change-points; continuous change points and discontinuous ones. As for real data demonstration, we apply our method into real security issues called malware detection . We empirically demonstrate that our method is able to detect unseen security incidents or their symptoms at significantly early stages. Through this demonstration we develop a new me thod for discovering unseen malware by means of change-point detection from web server logs. 1.3 Related Works There exist several earlier works on change-point detection. A standard approach to this issue has been to employ the hypothesis testing method [3], [8], i.e., testing whether the probabilistic models before and after the change-point are identical or not. Guralnik and Srivastava proposed a hypothesis-testing based event detec-tion [2]. In it a piecewise segmented function was used to fit the time-dependent data and a change-point was detected by finding the point such that the total errors of local model fittings of segment s to the data before and after that point is minimized. However, it is basically computationally expensive to find such a point since the local model fitting task is required as many times as the number of points between the successive points every time a datum is input.
As for real-time change-point detection, Takeuchi and Yamanishi [9] (see also [11]) have proposed ChangeFinder, in which the two-stage learning framework has been employed. It has been reported in [9] that ChangeFinder outperforms the hypothesis testing-based method both in detection accuracy and compu-tational efficiency. In the two-stage learning framework the choice of scoring function is crucial. In ChangeFinder the score is calculated as the predictive code-length, which will be replaced with the SDNML code-length in this paper.
The technology of change-point detection has been applied to a variety of application domains (failure detection, marketing, security, etc.). The security has been recognized as one of most important application areas among them since it has critical issues of how to d etect cyber-threat caused by malicious hackers. Although various classification-based pattern matching methods have been applied to security issues [10],[12], to the best of our knowledge, there is few works that gives a clear relation of security issues to change-point detection.
The rest of this paper is organized as follo ws: Section 2 introduces the notion of the SDNML. Section 3 describes our prop osed method. Section 4 gives empirical evaluation of the proposed method for artificial data sets. Section 5 shows an application of our method to security. Section 6 yields concluding remarks. This section introduces the SDNML coding. Suppose that we observe a discrete-time series, which we denote as, { x t : t =1 , 2 ,  X  X  X } .Wedenote x t = x 1  X  X  X  x t . probability density functions where  X  denotes the k -dimensional parameter vec-x we consider the following minimax problem: This is known as the conditional minimax criterion [5], which is a conditional variant of Shatarkov X  X  minimax risk [7]. The solution to this yields the distribu-tion having the shortest code-length relative to the model class F .Itisknown from [4] that the solution of the minimum in (1) is achieved by the sequentially normalized maximum likelihood (SNML) density function defined as: We call the quantity  X  log p SNML ( x t | x t  X  1 )the SNML code-length .Itisknown from [5],[6] that the cumulative SNML code-length, which is the sum of SNML code-length over the sequence, is opti mal in the sense that it asymptotically achieves the shortest code-length. According to Rissanen X  X  MDL principle [4], the SNML leads to the best statistical model for explaining data.
 We employ here the AR model as a probabilistic model and introduce SD-NML(sequentially discounting normalized maximum likelihood) coding for this model by extending SNML so that the effect of past data can gradually be dis-counted as time goes on. The function of  X  X iscounting X  is important in real situations where the data source is non-stationary and the coding should be adaptive to it.

Let X X  R be 1-dimensional and let x t  X  X  for each t . We define the k th order auto-regression (AR) model as follows:
Let r (0 &lt;r&lt; 1) be the discounting coefficient .Let m be the the least sample counting maximum likelihood estimate of the parameter A t =( A (1) t ,  X  X  X  ,A ( k ) t ) T from x t i.e., estimate can be thought of as a modified variant of maximum likelihood estimate so that the weighted likelihood is maximum where the weight of the j th past data is given r (1  X  r ) t  X  j . Hence the larger the discounting coefficient r is, the exponentially smaller the effect of past data becomes.
 likelihood estimate of the variance from x t by
Below we give a method of sequential computation of  X  A t and  X   X  t so that they Let us recursively define  X  V t and M t as follows: Then we obtain the following iterative relation for the parameter estimation: Setting r =1 / ( t  X  m ) yields the iteration developed by Rissanen et.al. [5] and Roos et.al. [6]. We employ (4) for parameter estimation. Define s t by We define a SDNML density function by normalizing the discounting maximum likelihood, which is given by where the normalizing factor K t ( x t  X  1 ) is calculated as follows: The SDNML code-length for x t is calculated as follows:  X  We may employ the SDNML code-length (8) as the scoring function in the context of change-point detection. The main features of our proposed method are summarized as follows: 1) Two-stage learning framework with SDNML code-length: We basically employ 2) Efficiently computing the estimates of parameters: Although the Yule-Walker Below we give details of our version of the two-stage learning framework. Two-stage Learning Based Change-point Detection: We observe a discrete-time series, which we denote as, { x t : t =1 , 2 ,  X  X  X } .The following steps are executed every time x t is input.

Step 1 (First Learning Stage). We employ the AR model as in (2) to learn Step 2 (First Scoring Stage). Ascorefor x t is calculated in terms of the
Step 3 (Smoothing). We construct another time series { y t } on the basis of
Step 4 (Second Learning Stage). We sequentially learn again SDNML den-
Step 5 (Second Scoring Stage). We calculate the SDNML code-length for In [9],[11], the score is calculated as the negative logarithm of the plug-in density the discounting learning algorithm from x t  X  1 . In our method, it is replaced by the SDNML code-length.

In updating each parameter estimate, there is only one iteration every time a datum is input. The computation time for our method is O ( k 2 n ) while that for the original two-stage learning-based method: ChangeFinder is O ( k 3 n ). 4.1 Methods to Be Compared We evaluated the proposed method in comparison with existing algorithms: ChangeFinder in [9], and the hypothesis testing method.

Guralnik and Srivastava [2] proposed an algorithm for hypothesis testing-based change-point detection, which w e denote as HT. In it the square loss function was used as an error measure. It was extended in [9] to the one using the predictive code-length as an error m easure. Below we briefly sketch the basic idea of HT using the predictive code-length. Let x t u = x u  X  X  X  x t . Let us define the cumulative predictive code-length, which we denote as where  X  ( x i  X  1 u ) is the maximum likelihood estimator of  X  from x i  X  1 u .InHT,if there exists a change point v ( u&lt;v&lt;t )in x t u , the total amount of predictive code-length will be reduced by fitting differe nt statistical models before and after
On the basis of the principle as above, we can detect change points in an incremental manner. Let t a be the last data point detected as a change point and t b be the latest data point. Every time a datum is input, we examine whether the following inequality holds or not: where  X  is a predetermined threshold. If it holds, we recognize the time point giving the minimum in the left hand side as a change point. Once a change point is detected, which we denote as t cp , then the detection process restarts by letting t cp be the final detected change point. This pr ocedure continues recursively. The computation time is O ( n 2 )where n is the data size. 4.2 Discontinuous Change-Point Detection In our experimental setting, we formally define two-types of change-points. One is a discontinuous type of change points and the other is a continuous type.
Letting p B and p A be the probability density functions for data generation before and after the change point t , respectively. We define the dissimilarity between p B and p A in terms of the Kullback-Leibler divergence defined as follows:
First we consider the case where change points are discontinuous in the sense that the value of  X  ( t ) discontinuously changes at a change point t .
As for the data-generat ion model we employed the following AR model: where A 1 =0 . 6 ,A 2 =  X  0 . 5 , and  X   X  X  (  X , 1). We generated 1,000 records and set change-points so that the jump of the mean value  X  occurred at x  X  100 ( x = 1 , 2 ,  X  X  X  ). Let the amount of jump of mean at the k th change-point be D k .We set D k =10  X  k . The dissimilarity at the i th change point is given by The amount of jump in this model is discrete. Hence we call the change points in this case discontinuous change points. Figure 1(a) shows the data set including discontinuous change points. Note that the change points tend to be more diffi-cult to be identified as i increases since they are mor e affected by noise. Hence it is non-trivial to detect all of them regardless they are discontinuous.
In the applications of our method and ChangeFinder, we set k = 4 (the degree of AR model), r =0 . 01 (discounting parameter), and T = 3 (smoothing parameter). Through the paper all of the parameters are systematically chosen so that they are best fit for a fixed percentage (say, 5%) of training data.
Below we give a measure of performance for change-point detection. By setting a threshold of scores, an alarm was made i f the score value exceeds the threshold. Letting t  X  be the true change-point, we define the benefit ofthetimepoint t when an alarm is made as follows: The benefit measures how early the true ch ange-point is detected. It takes the maximum value 1 when the true change-point is detected at that point, and is zero when | t  X  t  X  | exceeds 20. The false discovery rate (FDR) is the ratio of the number of false positive alarms over the number of total alarms. Considering the trade-off between benefit and FDR, we used the benefit-FDR curve as proposed in [1] for the performance comparison . It is a concept similar to ROC curve.
Figure 1(b) shows the results of the benefit-FDR curves for our method and existing methods. The horizontal axis shows FDR while the vertical axis shows the average benefit where the average was taken over all of the change points. SDNML is our method, CF is ChangeFinder, the conventional two-stage learning based method. HT is the hypothesis-testing based method in which the fourth-degree AR model is used for model fitting and the score is measured in terms of the logarithmic loss. We observe from Figure 1(b) that SDNML performs better than HT and CF. The AUC (Area Under Curve) for SDNML was about 12 % larger than that for CF.

Figure 2 shows the computation time (sec) of SDNML in comparison with CF for this data set. We see that SDNML is significantly more efficient than CF. 4.3 Continuous Change-Point Detection Next we consider the case where change points are continuous in the sense that the value of dissimilarity  X  continuously changes at each of the points. We consider the following data generation model x t = v ( t )+  X  where  X   X  X  (0 , 1) and v ( t )=0for0  X  t  X  100, and v ( t )= c ( t  X  100)( t  X  99) / 2for t&gt; 100.
Letting the dissimilarity at time t be  X  ( t ), then it is calculated as: For a given c&gt; 0,  X  ( t )=0for0  X  t  X  100, and  X  ( t )= c 2 ( t  X  100) 2 / 2for t&gt; 100.
This shows that the dissimilarity of change points is continuous with respect to t . We call such change points continuous change points. They are more difficult to be identified than discontinuous ones.
 We generated 6 times 200 records according to the model as above. Figure 3(a) shows an example of such data sets. We evaluated the detection accuracies for CF,HT, and SDNML for this data set. Parameter values for all of the methods are systematically chosen as with the discontinuous case. Figure 3(b) shows the results of the benefit-FDR curves for CF and SDNML where the average-benefit was computed as the average of the benefits taken over the 6-times randomized data generation. Note that HT was much worse than CF, and was omitted from the Figure3(b). We observe from Figure 3(b) that SD-NML performs significantly better than CF. The AUC for SDNML is about 46 % larger than that for CF.

Through the empirical evaluation using artificial data sets including contin-uous and discontinuous change-points, we observe that our method performs significantly better than the existing methods both in detection accuracy and computational efficiency.

The superiority of SDNML over CF may be justified from the view of the minimum description length (MDL) principle. Indeed, SDNML is designed as the optimal strategy that sequentially attains the least code-length while CF using the predictive code produces longer code -lengths than SDNML. It is theoretically guaranteed from the theory of the MDL principle that the shorter the code-length for data sequence is, the better model is learned from data. Hence the better strategy in the light of the MDL principle yields a better strategy for statistical modeling, eventually leads to a better strategy for change-point detection. This insight was demonstrated experimentally.
 The reason why SDNML and CF are significantly better than HT is that SDNML and CF are more adaptive to non-stationary data sources than HT. Indeed, SDNML and CF have the function of sequential discounting learning while HT has no such a function. It was also demonstrated experimentally.
It is interesting to see that the difference between SDNML and CF becomes much larger in detecting continuous change points rather than discontinuous ones. This is due to the fact that the statistical modeling is more critical for the cases where the change-points ar e more difficult to be detected. We show an application of our method to malware detection. Malware is a generic term indicating unwanted software (e.g., viruses, backdoors, spywares, torojans, worms etc.). Most of conventional methods against malware are signature-based ones such as anti-virus software. Here signature is a short string characterizing malware X  X  features. In the signature-based methods, pattern matching of any given input data with signatures is conducted to detect malware. Hence unseen malware or those whose signatures are difficult to describe may not be detected by the signature-based methods. Furthermore it is desired that the symptom of malware is detected earlie r than its malicious action actually occurs. We expect that change-point detectio n from access log data is one of promising technologies for detecting such mal ware at early stages.

We are concerned with the issue of detecting backdoor ,whichisoneoftyp-ical malware. In our experiment we used access logs, each of which consists of a number of attributes, including time stamp, IP address, URL, server name, kinds of action, etc. All of the data were collected at a server. URL means the URL accessed by a user. We used only three attributes from among them; time stamp, IP address, URL . We constructed two kinds of time series. One is a time series of IP address counts , where a datum was generated every 1 minutes and its value is the maximum number of identical IPs which occurred within past 15 minutes. The other is a time series of URL counts , where a datum was generated every 1 minutes and its value was the maximum number of identical URLs which occurred within past 15 minutes.

In the data set there are a number of bursts of logs including the message 500ServerError , which are considered as actions related to backdoors. From the view of security analysts, they can be thought of as a symptom of them. Hence we are interested in how early our method is able to detect such bursts without any knowledge of the message 500ServerError .

We applied our method to the two time series as above. The original data set consisted of 5538 records, and the length of the time series obtained after the pre-processing as above was 536. In the original data set, there were included three bursts of logs including the message 500ServerEroor . Figure 4(a) shows graphs of a time series of IP address counts, SDNML s core curve, and CF s core curve. Figure 4(b) shows graphs of URL counts data, SDNML score curve, and CF score curve.
Table 1 summarizes the performance of SDNML and CF for the two time series (IP counting data and URL counting data) in terms of alert time and the total number of alarms. In the row of ServerError Time, for each burst of messages 500ServerError , the starting time point and ending time point of the burst are shown. In the table  X - X  indicates the fact that the burst associated with the message: 500ServerError was not detected.

We observe from Table 1 that our method was able to detect all of the bursts associated with the message: 500ServerError , while CF overlooked some of them. It was confirmed by security analys ts that all of the detected bursts were related to backdoor, and were considered as symptoms of backdoor. Further there were no logs related to backdoor other than the bursts of the message: 500ServerError . It implies that our method was able to detect backdoor at early stages when its symptoms appeared. This demonstrates the validity of our method in the scenario of malware detection. We have proposed a new method of real-time change point detection, in which we employ the sequentially discounting normalized maximum likelihood (SDNML) coding as a scoring function within the two-stage learning framework. The intu-ition behind the design of this method is that SDNML coding, which sequentially attains the shortest code-length, would improve the accuracy of change-point detection. This is because according to the theory of the minimum description length principle, the shorter code-length leads to the better statistical model-ing. This paper has empirically demonstrated the validity of our method using artificial data sets and real data sets. It has turned out that our method is able to detect change-points with significantly higher accuracy and efficiency than the existing real-time change-point detection method and the hypothesis-testing based method. Specifically, through the application of our method to malware detection, we have shown that real-time change-point detection is a promising approach to the detection of symptoms of malware at early stages.
 This research was supported by Microsoft Corporation (Microsoft Research CORE Project) and NTT Corporation.

