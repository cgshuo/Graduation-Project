
Semi-supervised classification methods aim to exploit labelled and unlabelled examples to train a predictive model. Most of these approaches make assumptions on the distribution of classes. This article first proposes a new semi-supervised discretization method which adopts very low informative prior on data. This method dis-cretizes the numerical domain of a continuous input vari-able, while keeping the information relative to the predic-tion of classes. Then, an in-depth comparison of this semi-supervised method with the original supervised MODL approach is presented. We demonstrate that the semi-supervised approach is asymptotically equivalent to the su-pervised approach, improved with a post-optimization of the intervals bounds location.
Data mining can be defined as the non trivial process of identifying valid, novel, potentially useful, ultimately un-derstandable patterns in data [10]. Even though the model-ing phase is the core of the process, the quality of the results rely heavily on data preparation which usually takes around 80% of the total time [17]. An interesting method for data preparation is to discretize the input variables.
Discretization methods aim to induce a list of intervals which splits the numerical domain of a continuous input variable, while keeping the information relative to the out-put variable [6] [12] [8] [14] [15]. A na  X   X ve Bayes classifier can exploit a discretization of its input space [3] as the inter-vals set which is used to estimate conditional probabilities of classes given the data. Discretization methods are useful for data mining, to explore, prepare and model data.
The objective of semi-supervised learning is to exploit unlabelled data to improve a predictive models. This arti-cle focuses on semi-supervised classification, a well known problem in the literature. Most of semi-supervised ap-train the model. The uncertainty of predictions is evalu-ated in order to label only the most confident examples [18].  X 
The Co-training approach involves two predictive mod-els which are independently trained on disjoint sub-feature sets. This heuristic uses the predictions of both models to label two examples at every iteration. Each model labels one example and  X  X eaches X  the other classi-fier with its prediction [2] [16].  X 
The Covariate shift approach estimates the distributions of labelled and unlabelled examples [21]. The covariate shift formulation [20] weight s labelled examples accord-ing to the disagreement between these distributions. This approach incorporates this disagreement into the training algorithm of a supervised model.  X 
Generative model based approaches estimate the distri-bution of classes, under hypothesis on data. These meth-ods make the assumption that the distributions of classes belong to a known parametric family. Then training data is exploited in order to fit parameters values [11].
Semi-supervised learning without making hypothesis on data distribution is a great challenge. Therefore, most of semi-supervised approaches make assumptions on the dis-tribution of classes.

For instance, generative model based approaches aim to estimate P ( x, y )= P ( y ) P ( x | y ) the joint distribution of data and classes (with data denoted by x  X  X and classes denoted by y  X  Y ). The distribution P ( x, y ) is assumed tor  X  of finite size corresponds to the modeling parame-ters of P ( x, y ) . The joint distribution can be rewritten as P ( x, y )  X  = P ( y )  X  P ( x | y )  X  .Theterm P ( y )  X  is defined by a prior knowledge on the distribution of classes. P ( x | y is identified in a given family of distributions, thanks to the vector  X  .

Let U be the set of unlabelled examples and L the set of labelled examples. The set L contains couples ( x, y ) , with a scalar value and y  X  [1 ,J ] a discrete class value. The set U contains scalar values without labels. Semi-supervised generative model based approaches aim to find the parame-ters  X  which maximize P ( x, y )  X  onthedataset D = U  X  L The quantity to be maximized is p ( L, U |  X  ) , the probabil-ity of data given the parameters  X  . The Maximum Likeli-hood Estimation (MLE) is widely employed to maximize p (
L, U |  X  ) (with ( x i ,y i )  X  L and x i  X  U ): choice of the bounds of the intervals. The third term corre-sponds to the choice of the output distribution in each inter-val and the last term represents the conditional likelihood of the data given the model. Therefore  X  X omplex X  models with large numbers of intervals are penalized. This discretization method for classification provides the most probable dis-cretization given the data sample. Extensive comparative experiments showed high performances [3]. tion method which is based on previous work described above. The same modeling hypothesis as [3] are adopted.
A prior distribution P ( M ) which exploits the hierarchy of the model parameters is first proposed. This prior distribu-tion is uniform at each stage of this hierarchy. Then, we define P ( D | M ) the conditional likelihood of data given the model. This leads to an exact analytical criterion for the posterior probability P ( M | D ) .
 Discretization models:
Let M be a family of semi-supervised discretization models denoted M ( I, { N i } , { N ij } ) . These models consider unla-belled and labelled examples together, and N is the total number of examples in the data set. The models parameters are defined as follows: I is the number of intervals; { N the number of examples in each interval; { N ij } the number of examples of each class in each interval. 3.1 Prior distribution of the models. This prior exploits the hierarchy of the pa-rameters. The number of intervals is first chosen, then the bounds of the intervals and finally the output frequencies are chosen. The joint distribution P ( I, { N i } , { N be written as follows: tributed between 1 and N . Thus we get: equiprobable for a given number of intervals. Computing the probability of one set of intervals turns into the combi-natorial evaluation of the number of possible intervals sets,
Let us consider a very simple and intuitive problem to explain Equation 5. An interval i can be compared with a  X  X ag X  containing N i 1  X  X lack balls X  and N i 2  X  X hite balls X . Given the parameters N i 1 =6 and N i 2 =20 , what is the probability to simultaneously draw N l i 1 =2 black balls and i 2 =3 white balls? Let draws, and 6 2  X  20 3 the number of draws which are com-posed of 2 black balls and 3 white balls. Assuming that all draws are equiprobable, the probability to simultaneously draw 2 black balls and 3 white balls is given by:
The second term P ( D | M,  X   X  ) of Equation 4 is estimated considering a uniform prior over all possible permutations of { N l ij } examples of each class among N l i . The indepen-dence assumption between the intervals gives: P ( D | M, L  X  )= Finally, the likelihood of the model is:
In every interval, the number of unlabelled examples is previous expression can be rewritten: 3.3 Evaluation criterion
The best semi-supervised discretization model is found by maximizing the probability P ( M | D ) . A Bayesian eval-uation criterion is obtained exploiting Equations 3 and 6. The maximum a posteriori model, denoted  X  M map  X , is de-fined by: and L =  X  . For each interval N u i = N i and for each class ij = N ij . Therefore, the term P ( D | M ) is equal to 1 for any model. The conditional likelihood (Equation 6) can be rearranged as follows : distribution P ( M | D )= P ( M ) , in which case the model M map includes a single interval. Both criteria give the same discretization, as long as supervised approach is not able to cut the numerical domain of the input variable in this case. C semi sup can be rewritten as: log( N )+log the supervised approaches consists in the prior distribu-tion P ( M ) . In semi-supervised approach, the space of discretization models is bigger than in the supervised ap-proach. Unlabelled examples represent additional possible locations for the intervals bounds. Therefore, the model-ing cost of the prior distribution is more important for the semi-supervised criterion. When the number of unlabelled examples increases, the criterion C semi sup prefers models with less intervals.
 ment. Let us consider a binary classification problem. All examples belonging to the class  X  0  X  X  respectively  X  1  X  X  are located at x =0 [ respectively x =1 ]. During the experi-ment, N the number of examples increases. The number of labelled examples is always the same in both classes. For every value of N ,weevaluate N l min the minimal number of labelled examples which induces a M map with two intervals (and not a single interval).
 teria. For the criterion C sup , the minimal number of labelled examples necessary to split data does not depend on N .In this case, N l min =6 for every value of N . A different be-haviour is observed for C semi sup . Figure 1 quantifies the influence of N on the selection of the model M map .When sults are demonstrated: an interpretation of the likelihood in terms of entropy; and an analytical expression of the op-timal N ij . Taking into account these empirical and theo-retical results, we demonstrate that the semi-supervised ap-proach is asymptotically equivalent to the supervised ap-proach, associated with a post-optimization of the bounds location.
The semi-supervised and the supervised discretization approaches are based on the ranks statistics. Therefore, the location of the bounds between intervals of the optimal model are defined in a discrete space, thanks to the number of examples in every interval. The discretization bias aims to define the bounds location in the numerical domain of the continuous input variable. 5.1.1 How to position a bound between two training The parameters { N i } [ respectively { N l i } ] given by the op-timization of C semi sup [ respectively C sup ] are not sufficient to define continuous bounds location. Indeed, there is an in-finity of possible locations between two training examples. A prior is adopted in [3] which considers the best bound location as the median of the distribution of the true bound locations, denoted P tb . This median minim izes the general-ization Means Square Error, for any P tb . The objective is to place a bound between two examples without information about the distribution P tb . In this case P tb is assumed to be uniform, and a bound is placed midway between the two concerned examples. 5.1.2 How to position a bound in an unlabelled area? The optimization of the semi-supervised criterion C semi sup does not indicate the best bounds location, when the pa-rameters { N l i } are constant. This phenomenon is observed on a toy example below. Considering an area of the in-put space X where no example is labelled, all possible bounds locations have the same cost according to the cri-terion C semi sup . Therefore, the semi-supervised approach is not able to determine bounds location in such an unla-belled area. The same prior as [3] which aims minimizing the generalization Means Square Error is adopted, in order to define continuous bounds location. The unlabelled ex-amples are supposed to be drawn from the distribution P tb In this case, the median of P tb is estimated exploiting the unlabelled examples. The intervals bounds are placed in the middle of unlabelled areas.

Finally, the supervised and the semi-supervised ap-proaches are not able to position a continuous bound be-tween two labelled examples. In both cases, the same prior
Figure 3. Bound X  X  quantity of information vs. bound X  X  location 5.2 A post-optimisation of the supervised
This section demonstrates th at the semi-supervised ap-proach is asymptotically equivalent to the supervised ap-proach improved with a post-optimization on the bounds location. This post-optimization consists in exploiting un-labelled examples in order to position the intervals bounds in the middle of unlabelled areas. 5.2.1 Equivalent prior distribution The discretization bias established in Section 5.1 modifies our a priori knowledge about the distribution P ( M ) .From now, the bounds are forced to be placed in the middle of unlabelled areas. The number of possible locations for each bound is substantially reduced. The criterion C semi sup con-siders N  X  1 possible locations for each bound. Exploiting the discretization bias of Section 5.1, only N l  X  1 possible locations are considered. In these conditions, the prior dis-tribution P ( M ) (see Equation 3) can be easily rewritten as in the supervised approach (see Equation 2). 5.2.2 Asymptotically equivalent likelihood
Lemma A: The conditional likelihood of the data given the model can be expressed using the entropy (denoted H M )ofthesets U , L and D , given the model
M :  X  Supervised case  X  Semi-supervised case minimize the criterion C semi sup (denoted { N ij } )cor-respond to the proportion of labels observed in each interval  X  : Proof : This proof handles the case of a single interval model. Since data distribution is assumed to be independent between the intervals, this proof can be independently repeated on I in-tervals. We consider a binary c lassification problem. Let the function f ( N i 1 ,N i 2 ) denote the criterion C semi sup all parameters fixed except N i 1 and N i 2 . We aim to find an analytical expression of the minimum of the function f (
The terms N l i 1 and N l i 2 are constant, and N i 2 = N f can be rewritten as a single parameter function:
And:
Consequently: f (
N i 1 ) decreases if: f (
A toy problem is exploited to evaluate the behavior of the post-optimized method (see Section 5.2). This problem consists in estimating a step function from data. The artifi-cial dataset is constituted by examples which belong to the class  X 1 X  on left-hand part of Figure 4 and to the class  X 2 X  on the right-hand part. The objective of this experiment is to find the step location with less labelled examples as pos-sible.

The values of the variable (horizontal axis) which char-acterizes the 100 examples x i are drawn according to the expression x i = e  X  ,  X  varying between 0 and 10 with a step of 0.1. The step location is placed at x = 220 :47ex-amples belong to the class 1 and 53 to the class 2. The train set and the test set are both constituted by 100 examples.
We compare two discretization methods: the supervised method (see Section 2) and the supervised method with a post-optimisation of bounds location (see Section 5.2). For both methods, the M map is exploited to discretize the in-put variable. Then this var iable is placed on the input of a naive Bayes classifier. The predictive model is evaluated using the area under the ROC curve (AUC) [9]. The num-ber of labelled examples is the only free parameter and al-lows comparisons between both methods, examples to be labelled are drawn randomly. The experiment of this sec-tion is realized considering discretization models with one or two intervals, that is consistent with theoretical proofs demonstrated above.

Figure 5 plots the average AUC versus the number of la-belled examples. For each value of the number of labelled examples the experiment has been realized 10 times. Points reprensent the mean AUC and natches the variance of the results. Considering less than 6 labelled examples, both dis-cretisation methods give a M map with a single interval. In this cas, the AUC is equal to 0 . 5 . From 6 labelled exam-ples, the M map includes two intervals for both discretiza-
Our approach gives an important result: the intervals bounds must be placed in the middle of unlabelled ar-eas to minimize the mean square error. The main con-tribution of this article is to demonstrate that unlabelled examples provide useful information, even with a mini-mum of assumptions on the data distribution. We also proposed a post-optimization which allows the supervised MODL approach to be equivalent to our semi-supervised discretization method. This post-optimization makes an intuitive bridge between both approaches, and can be ex-ploited to efficiently implement the semi-supervised dis-cretization method.

In practice, the use of [3] to carry out a semi-supervised discretization offers advantages. First, the supervised ap-proach is faster than the semi-supervised one, due to the less important number of possible bounds X  locations which are considered. Second, the supervised approach gives best M map with most intervals, due to the less important mod-eling cost of the prior distribution. We plan to incorporate this semi-supervised preprocessing step in datamining algo-rithms, such as decision trees or naive Bayes classifier.
An efficient search algorithm which optimizes the eval-uation criterion to find the optimal discretization model is necessary to exploit our semi-supervised approach on real data set. The optimization algorithm used in [3] performs a post-optimization on the result of a standard greedy bottom-up heuristic which is based on hill-climbing search in the neighborhood of a discretization. The time complexity of this algorithm is O ( JN log N ) . Our  X  X emi-supervised X  and  X  X ost-optimized supervised X  approaches will be imple-mented using the same efficient algorithm. Empirical re-sults support the conclusions though both approaches have to be compared more in depth on large number of real world data sets in future work.
 Acknowledgement : Thank to Oliver Bernier for his wise ad-
