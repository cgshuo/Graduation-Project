 Macquarie University, Australia applications. Computing power has increased since the first such systems were developed, and this domain-specific information. 1. Introduction
There has been an interest in representing knowledge and automatically processing it from the time of the first generation of computers. This interest has increased from the end of the 1980s to become an urgent necessity. Decisive factors in this increase of interest are an unprecedented growth in the amount of digital information available, an explosion of growth in the use of computers for communications, and the increasing number of users that have access to all this information.
 itate the localization, retrieval, and manipulation of these enormous quantities of data. Question Answering (QA) is one of these research fields.
 a computer) answers arbitrary questions formulated in natural language. QA systems are especially useful in situations in which a user needs to know a very specific piece of information and does not have the time X  X r just does not want X  X o read all the available documentation related to the search topic in order to solve the problem at hand. artificial intelligence (AI) and information retrieval (IR).
 using the knowledge encoded in databases as an information source. Obviously, these systems can only provide answers concerning the information previously encoded in application domain represented in the database structure allows the use of advanced techniques such as theorem proving and deep reasoning in order to address complex information needs.

IR, initiated by the Question Answering track of TREC 1 in 1999 (Voorhees 2001). Since then, increasingly powerful systems have participated in TREC and other evaluation fora such as CLEF 2 (Vallin et al. 2005) and NTCIR 3 (Kando 2005). From this perspective, large collections of documents. The tasks set in these conferences have molded a specific kind of question answering that is easy to evaluate and that focuses on the use of fast and shallow methods that are generally independent of the application domain. In other words, current research focuses on text-based, open-domain question answering. trum connecting what we might label as structured knowledge-based and free text-based question answering. Whereas structured knowledge-based QA systems are well adapted to applications managing complex queries in a very structured information environment, the kind of research developed in TREC, CLEF, and NTCIR is probably better suited to broad-purpose generic applications dealing with simple factual ques-tions such as World Wide Web X  X ased question answering.
 important real applications that handle complex questions by combining domain-specific information typically expressed in different sources (structured, semistructured, unstructured, etc.) using reasoning techniques. Examples of such applications are:
Interfaces to machine-readable technical manuals: Many software applications are
Front-ends to knowledge sources: Many disciplines and areas of human activity have
Help desk systems in large organizations: Help desk staff in large organizations need 42 the results are too specific and not open to generalization. This may have been the case with early work in natural language processing (NLP), which focused on restricted domains simply because of limitations in computing power and in theoretical cov-erage. This is not the case nowadays. The availability of comprehensive and reliable resources in complex domains enables interesting and fruitful research to be carried out in restricted-domain natural language processing.
 problems related to the incorporation of domain-specific information into current state-of-the-art QA technology with the hope of achieving deep reasoning capabili-too-long-term vision, we are convinced that research in restricted domains will drive the convergence between structured knowledge-based and free text-based question answering.
 domains. In the process we will highlight the advantages of developing systems based with an emphasis on restricted domains, and focusing mainly on early work. Sec-tion 3 presents desirable characteristics of restricted domains for the development of
NLP research in general, and question answering in particular. Section 4 comments on some of the main factors that distinguish question answering in an open domain from question answering in a restricted domain. Section 5 focuses on the use of domain-specific resources for question answering. Section 6 outlines current restricted-domain question answering methods. Section 7 notes the main aspects to consider when building a restricted-domain question answering system. Section 8 introduces conclusions. 2. Early Work Two examples of early question-answering systems are BASEBALL and LUNAR. BASE-
BALL answered questions about baseball games played in the American league over one season (Green et al. 1961), and LUNAR answered questions about the analysis of rock samples from the Apollo moon missions (Woods 1997). Both systems were very successful in their chosen domains. In particular, LUNAR was demonstrated at posed by geologists without prior instructions with regard to the allowable phrasing (Hirschman and Gaizauskas 2001). Both LUNAR and BASEBALL are examples of what have been described as natural language interfaces to databases , that is, their source of information was a database that contained the relevant information about the topic.
The user X  X  question was converted into a database query, and the database output was given as the answer. The very specific nature of the domains enabled the construction of appropriately comprehensive databases, and a domain-specific question analysis that enabled a mapping from the meaning of the user X  X  question onto the corresponding database query.
 question answering, but there were many other such systems. Simmons X  X  (1965) survey described a variety of early QA systems. Most of these focused on restricted domains by developing a database of knowledge and providing a natural language interface. Still, many of these early systems (including LUNAR and BASEBALL) were no more than  X  X oy systems X  that focused on very limited domains. Those early systems that used a corpus of text as the inherent information source typically processed small volumes of text and would rely on a human to disambiguate the corpus sentences or convert them to a simplified version of English.
 oretical bases for computational linguistics. This research prompted the development of
QA systems on domains that were more complex than those of the earlier systems. The main goal of this research was to use QA as an application framework within which projects such as the Berkeley Unix Consultant (Wilensky et al. 1994).
 ing system to develop a help system that combined research in planning, reasoning, natural language processing, and knowledge representation. The user X  X  question was analyzed and a meaning representation corresponding to the question was encoded in a knowledge representation formalism. Then, UC hypothesized the actual information needs of the user by consulting the user model and applying goal analysis. The answer certainly impressive. However, no transcripts of real-world dialogues were provided and therefore it cannot be determined whether the methods and theories developed in UC were robust enough for practical use.
 of the time, question answering focused on restricted domains. A turning point was reached in 1999, with the introduction of the QA track in the TREC (Voorhees 1999). The popularity of the QA track in TREC has enabled research on QA from an IR perspective. to the task of finding the text that contains the answer to the question and extracting the answer. Text documents are viewed as a source of unstructured information that techniques.
 methods, allowing what has been called open-domain question-answering . This ap-proach is largely used in current QA systems. It is beyond the scope of this article to survey the techniques and systems used in open-domain QA; the interested reader is referred to the proceedings of TREC, which are available on-line. sequent sections we will review current approaches to question answering in restricted domains. But before that, let us analyze what a restricted domain is. 3. Characteristics of Restricted Domains
The nature of a particular restricted domain affects the kinds of questions asked and answers that can be expected. Consequently, different restricted domains benefit from different QA techniques. Some domains are particularly appropriate for the develop-ment of question answering systems. Minock (2005) lists three desiderata for a restricted 44 domain within the context of World Wide Web X  X ased question answering X  X hat is, question answering that relies on documents taken from the World Wide Web as the main source for finding answers. According to Minock, a restricted domain must meet the following desiderata: 1. It should be circumscribed. 2. It should be complex. 3. It should be practical.

The same desiderata apply, with some modifications, to restricted domains on question answering that is not World Wide Web X  X ased. 3.1 Circumscription
Minock X  X  original description of a circumscribed domain is motivated by the user X  X  need to know what to expect of the World Wide Web X  X ased QA system at hand and to know what questions are appropriate to the domain at hand. An example of a domain that would fare low in this desideratum is that of current events, because the user might domain according to this desideratum would be a science domain such as astronomy or chemistry.
 use within a corporation, however, users do not face the problem of wondering what questions are appropriate. Rather, a more important motivation for a circumscribed domain is the need for clearly defined knowledge sources. The range of techniques used in a restricted domain should not need to use extensive knowledge from outside the chosen domain. Rather, a domain that has authoritative and comprehensive resources is to be preferred. Examples of resources include actual databases containing the required information.
 scribed it is, the more possible it is to obtain such comprehensive databases. For more complex domains, useful resources are terminology databases and domain ontologies.
An added value is the existence of well-accepted terminology and ontology standards. 3.2 Complexity
A domain should be complex enough to warrant the use of a QA system. This may seem an obvious statement, but it is important to bear in mind that, in a desire to find a domain that is fully circumscribed, one might attempt to develop a QA system in a domain where a simple list of facts or a FAQ would be sufficient to satisfy the user X  X  need for information. There is no need for a QA system in such domains.
 icant area. Such domains are to be left to those who are more interested in capitalizing on current research advances to develop practical applications, rather than extending current research boundaries. In general, the more complex a domain is, the more inter-esting it becomes for the researcher and the more useful it presumably is to the user. that of a circumscribed domain, because these two desiderata are in conflict. At some higher probability of requiring resources belonging to other domains; in other words, the domain becomes less circumscribed. 3.3 Practicality Practicality is an important desideratum to consider when developing a QA system.
The domain should be of use to a relatively large group of people. Otherwise one risks wasting effort on a system that nobody would use, such as for an artificially constructed toy domain. The choice of domain affects the kind of users to target. Therefore, for each domain it is important to determine the kinds of questions asked in the specific domain (question style and terminology used are two important factors to consider), the sort of information that is most commonly requested, and the level of detail expected in the answers. 4. Open-Domain versus Restricted-Domain Question Answering
There are various factors that determine the best techniques to use in restricted-domain question answering, and whether techniques used in open-domain question answering briefly introduce some of these factors. 4.1 The Size of the Data
A well-known method used in open-domain QA is derived from redundancy-based techniques. These techniques were first discussed by Brill et al. (2001), who observed to a specific question can be found with data-intensive methods that do not require a complex language model. Thus, if the question is Who killed Abraham Lincoln? ,itiseasier to find the answer in John Wilkes Booth killed Abraham Lincoln than in John Wilkes Booth ended Abraham Lincoln X  X  life . Redundancy-based techniques are likely to have a weaker impact in restricted-domain QA, especially in the case of domains with relatively small corpora.
 necessary, to find the answer. The haystack of a restricted domain is relatively small, but it also has fewer needles.
 complex NLP techniques to the complete corpus off-line. Nowadays it is possible to parse the entire corpus used in the QA track of TREC and to extract all its named entities.
It is therefore feasible to parse and extract the named entities of corpora of restricted domains. 4.2 Domain Context
The actual domain provides a specific context to the question-answering process. Con-sequently the set of senses available to words is typically a subset of all the available senses. The impact of word-sense disambiguation is possibly reduced in RDQA, though 46 therefore word-sense disambiguation still plays a role. We are not aware of any studies on the impact of word-sense disambiguation on restricted domains and certainly this area is worth exploring.
 those asked in an open domain. Users of a restricted domain, and especially users who are experts in the domain, will use specific terminology and will pose rather technical questions that require very specific answers. Questions asked by such users are much more complex than those of casual users of open-domain QA systems. This is certainly convincingly. The challenges related to solving those questions are certainly worth the effort in pursuing research in RDQA. 4.3 Resources
An important difference between open-domain and restricted-domain QA is the ex-istence of specific resources for restricted domains that can be used. In the following sections we will comment on these resources. 5. Use of Domain-Specific Resources users X  information needs with the specificity and depth required.
 to the complexity of the domain and the particular needs of the domain users. Hence, and terms to high-level ontologies where all the domain knowledge is unambiguously represented.
 scription of concepts in the domain of discourse, together with their attributes, roles, restrictions, and other defining features (Noy and McGuinness 2001). The relations between the concepts are also expressed formally. The two most common relations shown in an ontology are subclass ( X  X s a subtype of X ) and instance ( X  X s an instance of X ), but other relations can be included, such as meronymy ( X  X art of X ) and, in the case of WordNet (Fellbaum 1998), entailment.
 representations as ontological resources .
 have available ontological resources that can be used to quick-start QA research and development. These resources are typically developed for the domain users to help them categorize the domain knowledge and agree on notational standards, and to help them retrieve information using conventional information retrieval applications. 5.1 Open-Domain Ontologies
There are ontologies that are designed without a specific domain in mind. These are referred here as open-domain ontologies. A widely used open-domain ontology is
WordNet (Fellbaum 1998). WordNet contains a large list of open-class words grouped into synonym sets (the  X  X ynsets X ). A range of synset relations is encoded, such as hyper-nymy/hyponymy, meronymy, and entailment. WordNet also includes word relations, such as antonymy. A departure from ontologies like Cyc (Lenat and Guha 1990) is that
WordNet does not include formal definitions of the features of the objects. Still, for the purposes of this article, WordNet is an ontology. This view is supported by its use in many systems, including open-domain question answering systems (Moldovan and Novischi 2002).
 stricted domains. This is so because the information is unlikely to be well balanced with respect to the chosen domain. For example, parts of open-domain ontologies are too coarse-grained for specific restricted domains, whereas other parts are too fine-grained.
And worse, open-domain ontologies may contain information that is not appropriate for specific restricted domains.
 nical domains, abound in terms that are specific to the domain and largely unknown in other domains. Open-domain ontologies typically do not include these specific terms. In some domains, however, these terms may be used widely. Consequently, open-domain ontologies will need to be complemented with terminology lists or local ontologies.

Open-domain ontologies are too fine-grained. Open-domain ontologies that map words to concepts, as is the case with WordNet, face the problem of polysemous words, that is, words with multiple meanings. However, those ambiguous words are usually unam-biguous in restricted domains. Take the noun file . WordNet 1.7.1 lists four meanings, shown in Table 1. Of the four meanings, only the first one ( X  X  set of related records kept together X ) is relevant within domains related to software development. Open-domain ontologies therefore risk overloading the system with concepts that are rarely, if ever, used within the chosen restricted domain.
 most damaging property of open-domain ontologies is that they may contain informa-overload some terms commonly used outside their domain. For example, the usual meaning of the verb print is to render something into printed matter. However, within the domain of computer programming, the verb print usually means to display on the computer monitor. Consequently, a system that uses an open-domain ontology would possibly misinterpret the meaning of print in the question Which C++ instruc-48 tion prints words onto the screen? This sense of print is not available in WordNet therefore it is not possible to apply word-sense disambiguation techniques to find the appropriate sense. 5.2 Uses of Ontological Resources
Ontological resources define a common vocabulary for accessing information in a do-main and this makes it easier to manage domain information as regards the following (Noy and McGuinness 2001):
Among theses concerns, enabling the separation of domain knowledge and operational knowledge is probably the most valuable characteristic for QA purposes. This fact al-lows the separation of the process of representing the concepts expressed in a document from the use of the relations between concepts for deduction or reasoning processes.
On the other hand, formalisms, theories, and algorithms either designed for domain document representation or reasoning may be made independent from the chosen domain ontology and can also be applied to different domains, thus enhancing system portability between domains.
 by means of an internal unambiguous knowledge representation. Both questions and knowledge are represented using specific knowledge models based on ontological en-ment, which is useful in determining whether a given sentence answers a particular question. 6. The State of the Art in RDQA
Current work on QA in restricted domains tends to exploit the characteristics of the done largely by determining the types of information needs in the chosen domain, by studying the format of questions asked, and by leveraging the ontological information available in the domain.
 streamline the process to find specific information. An example of such a domain is that of medicine. It is important for a doctor to quickly diagnose the illness of a patient, and to determine if a patient is developing a new variation of an illness that has occurred before. Given the importance of finding the correct diagnosis and treatment, the domain of medicine has developed trusted resources that can be used for question answering in this domain. Zweigenbaum (2003) provides examples of resources for terminology and corpora of authoritative material.
 ing a database with PICO (Population, Intervention, Comparison, and Outcome) ele-ments from medical abstracts obtained from MEDLINE. PICO structures are the frames used for evidence-based medicine. Sang, Bouma, and de Rijke (2005a) describe several strategies for populating a database with medical information related to diseases, symp-toms, and treatments, which is automatically extracted from medical texts. This struc-tured information is used for answering medical-related questions. Niu and Hirst (2004) describe a method for identifying semantic classes and the relations between them in medical texts. This approach is able to build an ontology for the domain automatically. on a well-known hierarchical evidence taxonomy (Ely et al. 2002). Rinaldi, Dowdall, developed for assisting questions on UNIX technical manuals (Moll  X  a et al. 2000) to the Genomics domain.
 systems. WEBCOOP is a logic-based system that integrates knowledge representation and advanced reasoning procedures to generate responses to natural queries. This system has been developed for the tourism domain.
 limitation the restrictions imposed by the underlying knowledge representation models.
Thus, in the following subsections we will focus on the efforts that are being employed from both historical trends in QA research (structured knowledge X  X ased and free-text X  50 based perspectives) to provide systems with deep reasoning capabilities supported by ontological domain information. We introduce several works that aim at combining the use of various ontologies and we also describe current attempts to separate the process-ing of domain-dependent information from generic domain-independent information with the goal of increasing portability across domains. 6.1 Ontologies and Structured Knowledge X  X ased QA
As noted earlier, the first QA systems focused on the development of natural language interfaces to databases (NLIDBs). This is a natural approach to follow in circumscribed domains that are not very complex. The idea is to produce a structured information resource containing comprehensive information on the contents of the domain. This information resource is produced before any question is asked and is queried over when the user asks a question.
 of this article to survey this important area of research. Rather, we refer the reader to
Androutsopoulos, Ritchie, and Thanisch (1995). Work in NLIDBs assumes an existing database that is queried over. If the database does not exist, it is created by using meth-ods based on information-extraction technology. The aim is to extract all the information that might be used as an answer. A clear candidate is the use of named entities, but the restricted domains (Weischedel, Xu, and Licuanan 2004).
 answering, including some dealing with questions unanticipated at the time of system construction. These include the AP Chemistry question-answering system (Barker et al. 1988), the two systems developed for DARPA X  X  High Performance Knowledge Base (HPKB) project (Cohen et al. 1988), and the two systems developed for DARPA X  X  Rapid
Knowledge Formation (RKF) project (Schrag et al. 2002). 6.2 Ontologies and Free-Text X  X ased QA
In this approach, users pose questions in natural language to knowledge bases made up of documents also written in natural language. In this case ontologies are used to define a language in which questions and documents can be represented and exploited to obtain the required answers. The translation from natural language to the internal representation is automatic; this presupposes fully unambiguous representations that are currently beyond our capabilities.
 in the different parts of the question answering system. For instance, the ontology is the initial query, in the reasoning processes carried out over the classes and subclasses from the ontology, and in the similarity algorithms employed for answer retrieval and extraction.
 ing where both questions and source texts are parsed into underspecified semantic expressions where names of the semantic atoms and predicates are defined in an in-terlingual ontology. Answer retrieval is done using subsumption and unification, and queries are expanded using ontological rules. 6.3 Integrating Heterogeneous Sources of Information semistructured information (such as text with some XML markup) or even unstruc-tured information (i.e., plain text). This has been proposed for World Wide Web X  X ased question answering (Lin 2002), given the availability of pockets of information stored in databases on the World Wide Web. The idea is to analyze the question and find the bases or it is not possible to determine the appropriate database query, then standard question-answering techniques are applied using the World Wide Web as a resource. keeping a set of relevant databases and a corpus of documents to query over in case the question is not covered in the databases.
 heterogeneous sources:
Interface: The resources in each domain will have their own formats and interfaces,
Selection: The QA system needs to determine the actual resource within which to look
Given that the actual domain-specific resources range from simple word lists to struc-tured databases, interfacing to them is by no means simple. Two approaches are envis-aged (Lin 2002):
Wrap: Provide an application program interface (API) to the individual databases. The
A step beyond portable QA systems is to build a meta-domain QA system. A meta-domain QA system specializes in several restricted domains by acting as a knowledge broker to specialized domain modules. An example of such a system is START (Katz 1997), which currently is a World Wide Web X  X ased QA system that uses a wide range of structured data available on the Internet.
 questions in natural language to knowledge bases of facts extracted from a federation of Web sites and organized in topic map repositories. This approach uses an ontology-based methodology to search, create, maintain, and adapt semantically structured
World Wide Web content according to the vision of the Semantic Web in a domain related to university World Wide Web sites. 52 in a database with domain-related documents through an ontology that describes aca-demic life. AQUA tries to answer a question using its knowledge base. If a query cannot be satisfied via the database, it tries to find an answer on domain-related World Wide Web pages.
 works in the medical domain; it tries to combine authoritative medical knowledge with information about patients. The information needed by physicians is of two sorts. pressure over the past three days, or the substances to which Ms. Y is allergic. Second, there is what can be defined as medical knowledge, that is, the information found in textbooks, journal articles, clinical studies, and so on. The final objective of this work 2 minutes? 6.4PortingtoOtherDomains
Developing a system in a specific domain could be time-consuming. It is natural to think of ways to reuse technologies (or even code) in QA systems from other domains or from open-domain QA systems. A topic that is intimately related is that of portability to other domains.
 portability in mind. These are generic systems that can be localized to specific domains.
For example, JAVELIN (Nyberg et al. 2005) is an open-domain QA system that can be extended to focus on restricted domains. Special care was taken to leverage ontologies specific to the chosen domain by developing a Java API. The specific ontological in-formation extracted is the type hierarchy and sets of synonyms (AKA, or  X  X lso known as X  extraction). Another example that demonstrates efforts in adapting an open-domain
QA system to a specialized geographical environment can be seen in the work by Ferr  X  es and Rodr  X   X guez (2006).
 tured knowledge sources. This approach applies deep linguistic analysis to the question characteristics. This representation is domain-independent and provides a natural in-terface to the underlying knowledge databases. This approach has been implemented as a prototype for two application domains: the domain of Nobel prize winners and the domain of language technology.
 main. Nyberg et al. (2005) provides a case study that describes the problems in adapting an existing open-domain QA system to be able to deal with knowledge from existing domain ontologies. 7. Building a Restricted-Domain QA System: Main Considerations
It is difficult to imagine a general methodology for the development of an RDQA system. On the one hand, current systems are overly influenced by the specific characteristics and requirements of the domains, from the different types of questions to be answered to the heterogeneity of the knowledge available for the domain. On the other hand, the known methodological proposals (Minock 2005) are so general that they could be used to design any kind of information system.
 to be taken into consideration when designing a QA system for a specific domain. These selection of the appropriate technology required by the QA system. They can be listed as follows:
Domain query system analysis: Knowing in detail all the different ways users ask for
Domain knowledge selection: The amount and type of authoritative knowledge
Domain knowledge acquisition and representation: Using the domain knowledge
System interface design: In order to obtain a natural mode of communication between 54
Technological requirements selection: The abilities we expect from an RDQA system 8. Introduction to the Articles in this Special Section
Demner-Fushman and Lin X  X  article ( Answering clinical questions with knowledge-based and statistical techniques ) extends previous work by the authors (Demner-Fushman and information needs within the framework of evidence-based medicine (EBM) whereby a doctor needs to gather the current best evidence, namely, high-quality patient-centered clinical research. The data source used by the system is the set of MEDLINE domain, the input questions are formulated as PICO-based frames representing the major elements of a query in EBM: Problem/Population, Intervention, Comparison, elements in the MEDLINE abstracts and their matching with the input query frame.
In the process the system uses the Unified Medical Language System (UMLS), an extensive ontology specialized on this domain. This system is a clear example of the adaptation of the task of question answering to a specific and highly practical domain using specialized resources in order to satisfy information needs formulated as complex, structured questions.
 cialized domain where the users are domain experts are typically complex in nature. The solution proposed in this article is to facilitate question formulation by means of
Conceptual Authoring, whereby the user edits a formal representation of the query and receives feedback from an automatically generated natural language representation of that query. The article describes this method within the context of a QA system for a database of electronic health records. An analysis of the question model in this domain presents a concept of complex query formulation that can potentially be ported to other specialized domains. 9. Conclusions domains and we have argued for developing research in this area. To conclude we would like to comment on two reasons for developing question answering in restricted domains:
Development of vertical systems: Restricted domains allow the development of sys-
Applicability to current needs: General and broad scope systems are not effective in
A major difference between open-domain question answering and restricted-domain question answering is the existence of domain-dependent information that can be used to improve the accuracy of the system. Much of the focus of this article has been on forms of tapping information from these resources.
 than others. A domain must be circumscribed enough so that a comprehensive on-tological resource can be built for the domain. A domain must be complex enough biomedicine) that meet all these properties are naturally more popular for researchers and developers. Consequently they have some of the best ontological information and QA systems.
 tions and offers the opportunity to carry out complex analysis of the text sources and the questions. Restricted domains also provide comprehensive ontologies and domain 56 answers. The challenges and opportunities are there for us to take.
 References 58 Appendix A: List of QA Systems in Restricted Domains
The following list is by no means exhaustive. Our purpose in presenting this list is to show the breadth of current research and applications in RDQA. We welcome updates and additions to the list, which will be maintained at http://www.ics.mq.edu.au/  X  diego/answerfinder/rdqa/. 1. Generic systems 2. Collaborative learning for engineering education 60 3. Services provided by a large company 4. Salmon fish biology 5. Biography information 6. Tourism 7. Weather forecasts 8. Technical domains 9. Genomics 10. Financial 11. Medical domain 12. Geographic domain 13. Nobel prizes 14. Language technology 15. Opinion texts 16. Reading comprehension texts 17. Role-playing games
