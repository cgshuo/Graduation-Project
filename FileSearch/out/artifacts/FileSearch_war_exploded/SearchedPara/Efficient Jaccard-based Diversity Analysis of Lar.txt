 We propose two efficient algorithms for exploring topic diversity in large document corpora such as user generated content on the so-cial web, bibliographic data, or other web repositories. Analyzing diversity is useful for obtaining insights into knowledge evolution, trends, periodicities, and topic heterogeneity of such collections. Calculating diversity statistics requires averaging over the similar-ity of all object pairs, which, for large corpora, is prohibitive from a computational point of view. Our proposed algorithms overcome the quadratic complexity of the average pair-wise similarity com-putation, and allow for constant time (depending on dataset prop-erties) or linear time approximation with probabilistic guarantees. Our theoretical findings are verified on synthetic and real-world data sets. As applications, we show examples of diversity-based studies on large samples from corpora such as the social photo shar-ing site Flickr, the DBLP bibliography, and US Census data. H.3.0 [ Information Storage and Retrieval ]: General diversity, efficiency, min-wise hashing, random sampling
Diversity has been studied in different disciplines and contexts for decades. The diversity of a population can reveal certain cul-tural properties of a country [18, 11], e.g. with respect to religion, ethnic groups, or political orientations. In the area of ecology, bio-diversity is used as a measure of the health of biological systems [15]. Recently, diversity also drew the attention of scientists in the database and information retrieval communities. For instance, Vee et al. [29] use the sum of similarities of all object pairs to measure diversities of relational records, while Ziegler et al. [30] employ a similar measure for diversifying items in a recommender sys-tem. In the area of search result diversification [12, 30], inter-object similarity is used to obtain a subset of the most dissimilar results, providing an overview over the result space. However, due to the quadratic computational complexity, the mentioned approaches are applied on relatively small sets, limited to the number of life forms in a biosystem, or top-k objects selected in the context of search result diversification. In contrast, in this paper, we focus on an-alyzing diversity on Web collections and in other large-scale text corpora as a whole .

Motivation: Increasing amounts of data are published on the In-ternet on a daily basis, not least due to popular social web environ-ments such as YouTube, Flickr, and the blogosphere. This results in a broad spectrum of topics, communities and knowledge, which is constantly changing over time. An increase of content diver-sity over time indicates that a community is broadening its area of interest; negative peaks in diversity can additionally reveal a tem-porary focus on specific events. Analyzing diversity is promising for understanding the dynamics of information needs and interests of the users generating the data. In a recommender system context, diversity and its temporal evaluation exhibits an additional crite-rion for suggesting to users interest groups or communities (e.g. rather broad vs. more specialized ones). Additionally, our methods could be used to efficiently analyze the correlation between diver-sity indexes for the documents retrieved for a set of queries and the performance of an IR system, allowing for quicker, deeper, and broader analyses. Furthermore, high diversity in document reposi-tories can be employed as indicator that more structure is required, and trigger manual or automatic processes for introducing topic hi-erarchies or clusters (cf. Section 6.3). In our studies we show an example analysis depicting the temporal development of the diver-sity of photo annotations in Flickr over time, revealing interesting insights about trends and periodicities in that social content shar-ing environment (Figure 1 in Section 6). In addition we conduct an analysis of scientific communities on data extracted from the DBLP bibliography, and furthermore, study diversity in clustered corpora such as US Census data and newsfeeds. Our goal is to enable a fast analysis of the variation of topic diversities according to different aspects such as time, location and communities.

Computational Problem: There are a number of well-known indexes measuring diversity in ecology such as Simpson X  X  diver-sity [27] and the Shannon index [14]. For applying the concept of diversity to text data , existing works use the sum of all document pair similarities or variations based on pair-wise distances as diver-sity metrics [24, 12, 30, 29]. These diversity indexes are based on the computation of pairwise comparisons. Thus, a common prob-lem is their computational complexity: O n 2 comparisons are necessary for sets of n objects. While this is still feasible in sce-narios with small amounts of data as for top-k candidates in query result diversification, it becomes prohibitive when computing topic diversity for large data sets.
Contribution: I n order to solve the computational problem (the main contribution of this paper), we propose two novel algorithms which make use of random sampling and Min-wise independent hashing paradigms. More specifically, we propose two fast approx-imation algorithms for computing the average pair-wise Jaccard similarity of n sets with probabilistic accuracy guarantees, coined as SampleDJ and TrackDJ . We discovered that specific properties of the Jaccard coefficient as underlying measure for the pair-wise similarities required in diversity indexes can make the computation feasible, even for huge amounts of data. Although there exist a va-riety of alternative metrics, Jaccard is still one of the most popular measures in IR due to its simplicity and high applicability [19, 3], and provides intuitive and interesting results in our example studies. SampleDJ, which is based on random sampling, solves the problem in
O 1 RDJ 2 t ime independent of the data set size, where RDJ is the diversity index value to be estimated. TrackDJ, which is based on Min-wise independent hashing [7, 4, 5, 6] solves the problem in O ( n ) time regardless of the input data distribution. Experiments on real-world as well as synthetic data confirm our analytical results. Furthermore, we show the applicability of our methods in example studies on various data collections.

Outline: The rest of this paper is organized as follows: In Sec-tion 2, we describe related work in the areas of diversity mea-surement, diversification of search results, sampling, and Min-wise hashing. Section 3 introduces the diversity index used throughout this paper. In our main Section 4, we describe algorithms for ef-ficiently computing the diversity index values, and prove accuracy and efficiency properties. We verify our theoretical findings using real and synthetic data in Section 5. As application examples, we show results of various corpora studies in Section 6. Finally, we conclude and point out directions for future work in Section 7.
Diversity measurement: Diversity indexes were proposed in ecology [27, 14] decades ago; they assume that objects are clas-sified into groups. For example, Simpson X  X  diversity index [27], a well-known diversity index in ecology is defined as follows: D = P i and each individual in the population belongs to one of Z groups. Note that Simpson X  X  index can just be employed in the special case where objects belong to one of a discrete set of categories. Re-cently, new diversity indexes were proposed in various areas focus-ing on different applications. For example, Stirling [28, 25] pro-posed a general diversity index trying to measure diversities in dif-ferent areas in science, technology and society. The general Stirling distance between object i and j ; p i , p j are the relative occurrences of object i and j in the whole data set. The diversity measure used in this paper for text collections can be interpreted as a special case of the Stirling index. None of the mentioned works deals with the efficiency problem of computing diversity measures for whole data collections, which is the main focus of this paper.

Diversity in search or query result diversification: There is a plethora of work on diversifying query or search results. Search engines, recommender systems and databases have the need to re-turn diverse results to users in order to include answers for differ-ent user needs in the result set. This is especially important if the query is ambiguous. Vee et al. [29] use the sum of similarities of all object pairs to measure diversities of relational records, while Ziegler et al. [30] apply a similar measure for diversifying items in a recommender system. Gollapudi and Sharma [12] make use of inter-object similarity in their axiomatic search result diversifi-cation approach. In their recent work [21] Minack et al. deal with efficiently diversifying search results for large data streams; note that obtaining a diverse top-k list from a large dataset corresponds to an entirely different problem setting than the one studied in this paper. In general, work on search result diversification is about diversifying small top-k sets of query results. In contrast, in this paper we tackle the efficiency problem of computing diversity in-dexes for whole data collections.

Sampling is a technique that finds a wide range of applica-tions, such as auditing of large databases and query optimization in DBMS [22]. A more theoretical example related to our work is the application of random sampling to estimate the average value (or sum) of a set of numbers, for which it is known to be difficult to bound the relative error without having prior knowledge about the input data [9]. More research on sampling can be found in the survey of Babcock et al. [2] and in [22]. We are the first to use random sampling as an underlying technique to solve the problem of efficiently computing diversity indexes.

Min-wise independent hashing is a technique originally pro-posed for finding near duplicate documents [6]. It can be consid-ered as a variation of Locality Sensitive Hashing (LSH) [13, 10]. LSH was used for indexing high dimensional data points. Similar to Min-wise independent hashing, LSH also has the property that two objects with a smaller distance are more likely to have a hash collision. The difference is that the distance/similarity is measured by the L p norm (e.g. Euclidean or Hamming distance of vectors). For cosine similarities of vectors, there exist also hash functions with the LSH property [8]. Different from the aforementioned ap-plications, we are the first to use Min-wise independent hashing as a building block for efficient diversity index estimation.
To the best of our knowledge, there exist no other methods for efficiently computing the diversity of whole corpora.
There exists a plethora of methods for computing pair-wise sim-ilarities (e.g. cosine similarity, Jaccard coefficient, Okapi BM25, inverted distances, etc.). For diversity computation in this paper, we employ the Jaccard coefficient, which is one of the most popu-lar measures in IR due to its simplicity and high applicability [19, 3]. We will see that specific properties of this coefficient can make the computation of diversity values feasible even for large data sets.
Given two term sets O i and O j (e.g. sets of tags for two photos in Flickr), their Jaccard similarity JS( O i , O j ) is defined as follows: W e define our topic diversity index as Refined Diversity Jaccard-Index , which is in fact the average Jaccard similarity of all object pairs.

D EFINITION 1 (R EFINED DJ-I NDEX ). Given a collection of objects O 1 , . . . , O n , where each object is a set of elements (e.g. terms), the refined DJ-Index measuring the diversity of the collec-tion is defined as follows: where 1  X  i &lt; j  X  n .
 In this paper, we use the expression Refined DJ-Index, or RDJ index for short, to emphasize that self-similar pairs are not included in the diversity computation. It is easy to see that the RDJ-index can be considered as a special case of the Stirling index described in Section 2 where  X  and  X  are set to 1 , and both p i and p self-similar pairs are included. Note that smaller RDJ values mean larger diversities. For better visualization in plots we do not use 1-RDJ to measure diversity because RDJ values are usually quite small, and 1-RDJ is often close to 1.
H aving defined the RDJ-index for measuring diversity, the goal of this section is to compute this statistic for a given text corpus.
P ROBLEM 1 (RDJ-I NDEX C OMPUTATION ). Given a collec-tion of objects O 1 , . . . , O n , where each object is a set of elements (e.g. terms), the objective is to compute the RDJ-index value effi-ciently.
The straightforward solution for computing RDJ directly accord-ing to Definition 1 is 1) to compare all object pairs and compute the size of intersection and union of each pair, and then 2) to sum up the similarities of all pairs and to divide by the number of object pairs. We call this algorithm All-Pair . Clearly, All-Pair takes O n time, and is inefficient for data collections with a large number of objects. Although some heuristics may improve the efficiency of All-Pair, the time complexity will still be O n 2 since in the worst case all pairs will have to be compared to obtain the exact value. Note that All-Pair can be easily parallelized with O n 2 /m com-parisons where m is the number of machines, which, however, is still not feasible for large datasets. In the following, we study ap-proximate but more efficient techniques to estimate the value of the RDJ diversity index.
To increase the time efficiency of the RJD computation, we con-sider approximation algorithms that are usually faster but provide estimated results, which are subject to errors. Our goal is to bound these errors within a tolerable range. In the following, we define error measures for the estimation quality of approximation algo-rithms.

D EFINITION 2 (A BSOLUTE E RROR ). Let  X  D be an estimate of a statistic D , the absolute error is defined as follows:
D EFINITION 3 (R ELATIVE E RROR ). Let  X  D be an estimate of a statistic D , the relative error is defined as:
L ike many other indexes, diversity indexes are mainly used for comparisons. A single index value alone usually cannot reveal much insight to users, and the relative error is more appropriate than the absolute error for measuring the accuracy of index value estimates. For the absolute error, it becomes hard for users to spec-ify a meaningful accuracy requirement in form of an error bound unless they approximately know the value of the indexes to be esti-mated. Therefore, for both approximation algorithms described in the next subsections, we will focus our theoretical analysis on the relative error. A natural solution to reduce the computational cost is sampling. One approach is to take a random sample of the input data set, i.e., to sample r objects uniformly at random (without replacement) from a collection of n objects, compute the sum of similarities of all object pairs in the sample, and scale the diversity index of the sample. Another approach is to take r objects uniformly at ran-dom but with replacement (see also [22] for a general discussion of sampling with replacement). In our context, we sample from all possible pairs , compute the similarities of those r pairs and scale the result according to r and n as the final estimate. The advantage of this approach is that each pair is taken independently of other
Algorithm 1: S ampleDJ: An approximation algorithm estimating di-
Input : A collection of objects O 1 , . . . , O n , each object is a set
Output : Estimates of RDJ-Index of the given collection begin pairs, which makes the sampling analysis easier. We focus on t his approach in this paper and name it SampleDJ .

The details are shown in Algorithm 1. The input to the algorithm is a collection of objects with each object consisting of a set of term IDs. In the Line 2 the values of r 1 and r 2 are initialized depend-ing on the desired accuracy confidence; here, r 1 is the number of trials in each of the r 2 experiments. The final result is computed as the median RDJ value obtained from the r 2 independent exper-iments ( r 2 being determined by user requirement  X  ); r 1 with each iteration of the algorithm while r 2 remains constant. In the Line 4 and 5 the similarity sum of all sampled pairs is com-puted. Line 6 keeps track of the number of trials. Line 7 computes the current RDJ estimate. Line 8 and the  X  X ntil X  statement serve to determine if the RDJ estimate is accurate enough.

Note that window size W is independent of data set sizes, and merely corresponds to regular accuracy checks in the algorithm; the number of windows is determined automatically , and changes according to the data properties. Therefore, no tuning of W is re-quired. In our experiments we used the same value for W (10,000) for all of the datasets. For practical reasons, there is also a  X  X oler-able running time X  parameter T because SampleDJ can take more running time than the straightforward method in the worst case, and this time is not predictable. For example, if all object pairs have zero similarity, SampleDJ would proceed forever without a stopping condition based on T . The algorithm stops when the es-timated result is accurate enough or the running time exceeds the user-specified time limit. We name the former case as  X  X ail X  and the latter as  X  X ucceed X . Based on our analysis described in the next paragraph, the accuracy is determined by the absolute error bound  X  , which can be determined based on the number of trials r that  X  and  X  are the user requirements for the accuracy of the diver-sity index computation, and r 2 is determined by user input  X  .
Since SampleDJ is an approximation algorithm, it is of high practical importance to have accuracy guarantees. The next state-ment specifies the time and space complexity of the SampleDJ al-gorithm.

C LAIM 1 (C OMPLEXITY OF S AMPLE DJ). If Algorithm 1 suc-ceeds, the estimate [ RDJ is guaranteed to have a relative error at most  X  with probability at least 1  X   X  . That is, where RDJ is the true value of [ RDJ . The time and space costs to where U is the maximum set size of all objects.

P ROOF . We first prove the accuracy of SampleDJ. Let p , . . . , p N be all possible object pairs, where N = n ( n  X  1) X be a random variable indicating the Jaccard similarity of a pair drawn uniformly at random from p 1 , . . . , p N . That is, X = s ( i = 1 , . . . , N ) with Pr[ X = s i ] = 1 N , where s i similarity of p i . Then E [ X ] = 1 N P N i = 1 s i = RDJ , and
If there are r 1 identically and independently distributed random variables following the same distribution as X , the mean of the r variables is also expected to be equal to RDJ and the variance Inequality, we have w here absolute error bound  X  =  X   X  RDJ . Let the probability ment log 2 1  X  t imes independently and taking the median, the upper bound of the probability Pr h [ RDJ  X  RDJ &gt;  X  RDJ i is raised to
N ext, we show the time and space complexities. To guarantee the relative error at most  X  with probability 1  X   X  , it is sufficient to guarantee the absolute error at most  X  since [ RDJ  X   X   X  RDJ , guarantees the relative error with probability 1  X   X  according to the accuracy analysis. Thus, the time complexity is O U log 2 As for the space complexity, the main costs come from storing the input, which is O ( nU ) .

Note that the running time of SampleDJ is independent of n , b ut dependent on RDJ , the value to be estimated. Thus, Sam-pleDJ can be very efficient for large data sets if RDJ is reasonably large. However, for smaller values of RDJ , the running time can be higher. Note further that, similar to All-Pair, SampleDJ can be easily parallelized; this is because the pairwise similarity computa-tions, which correspond to the main computational overhead, and part of the aggregation steps involved can be run independently on different machines.
Although SampleDJ can be very efficient in some cases, its per-formance is sensitive to the data distribution, and it can be very slow in the worst case. Apart from that, without prior knowledge of the input data, it is difficult to predict the running time. In this section we present TrackDJ, another approximation technique returning an accurate estimate for the DJ-Index in O ( n ) time regardless of the input data distribution, where n is the number of objects (term sets) in the data set. We first briefly sketch the underlying concept of Min-wise hashing and its application in our scenario.
Broder et al. proposed a powerful technique called Min-wise in-dependent hashing (Min-hash) [7, 4, 5, 6]. An interesting property of this technique is that the hashing collision probability of two ob-jects is exactly equal to their Jaccard similarity. The basic idea of Min-hash mapping a term set is as follows: Min-hash picks a per-mutation  X  uniformly at random from all possible permutations of the term vocabulary. Given a set of terms O , Min-hash applies  X  on O and takes the term that has the minimum rank after the per-mutation as the Min-hash value.
 3 objects O 1 ( A, B, C ) , O 2 ( B, C, D ) and O 3 ( C, E ) where A, B, C, D, E are distinct terms. Assume TrackDJ uses two min-hash functions h 1 and h 2 where the two permutations are: from ( A, B, C, D, E ) to  X  1 = ( E, B, A, C, D ) and  X  2 = ( A, C, B, D, E ) . Under these permutations, the terms with minimum ranks are as follows:
Given the Min-wise hashing property that more similar objects are more likely to have a hash collision, TrackDJ counts the number of collisions of all object pairs and estimates the diversity index. This is done by finding the self-join sizes 2 of all min-hash values. The self-join size of a set of items is in fact the similarity sum of all object pairs where the similarity function returns only 1 or 0 depending on whether the pair of objects match or not. In summary, the key idea of TrackDJ is that if there are more similar pairs, the self-join size of the min-hash values will be higher due to the Min-wise hashing property; instead of comparing all object pairs, the self-join size of a set of items can be computed in linear time.
Using the above Min-wise Hashing example, the self-join sizes of min-hash values under h 1 and h 2 are both 5 . Accordingly, TrackDJ returns 5  X  3 3(3  X  1 ) as the RDJ-Index estimate where the 5 in the numerator is the average of the two self-join sizes, and the 3 in the denominator is the number of objects. In our example, the es-timate is exactly the true RDJ-Index value. Although this may not always be the case in practice, the expected value of the estimate is equal to the true value, which we will prove below. Typically, TrackDJ needs to use a larger number of min-hash functions to re-duce the variance.
 TrackDJ maps each object (e.g. a term set) to a min-hash value. The algorithm uses the fact that two objects have a higher prob-ability to have a min-hash collision if they have a higher Jaccard similarity; the total number of collisions of all possible object pairs Algorithm 2: T rackDJ: Estimating the RDJ-Index in Linear Time
Input : A collection of objects O 1 , . . . , O n , each object is a set
Output : an estimate of RDJ-Index of the given collection begin directly approximates the sum of their pair-wise similariti es. Thus, by computing the self-join size of all min-hash values (i.e. the total number of collisions of all pairs), TrackDJ estimates the RDJ-Index value.

The detailed approximation method is shown in Algorithm 2. In addition to the input data set and accuracy and confidence require-ments  X  and 1  X   X  , the user needs to specify the maximum term set size among the n objects. Line 1 sets the number of independent trials and experiments. For each of the L 2 iterations there are L trials. L 1 and L 2 are computed based on the accuracy and confi-dence requirements defined by the user. Note that for TrackDJ the number of required iterations are known in advance; thus no checks of error bounds are necessary at later stages. Details can be found in the algorithm analysis part below.

Line 2 and 3 initialize a buffer storing the L 2 self-join sizes. Line 4 and 5 initialize counters, which are used later to store the number of occurrences of each ID. In each of the L 2 iterations, there is a data stream with L 1  X  n objects. Line 6 generates the L 1 hash functions. Line 7 increments the corresponding counter based on the min-hash value of object O i . Line 8 and line 9 compute the accumulated self-join size so far. Note that by maintaining a linked list of non-zero counters, TrackDJ does not need to check all D counters which can significantly improve the efficiency if D is large. Line 10 resets non-zero counters of IdCounts[] . Line 11 computes the median, and Line 12 returns the final result; it computes the average self-join sizes over L 1 iterations and removes the contribution from self-similar pairs.
Similar to SampleDJ, TrackDJ is a randomized algorithm which approximates the RDJ-Index. In the following, we prove complex-ity and accuracy guarantees for TrackDJ.

C LAIM 2. The refined DJ-Index estimate from TrackDJ, [ RDJ , is expected to be equal to the true value RDJ . The variance of i s at most w here U is the maximum set size of all objects in the input object collection, and K is the number of min-hash functions used.
P ROOF . We first analyze the case with only one hash function; the case with K hash functions corresponds to repeating the same experiment K times independently, which we will discuss at the end of the proof.

Let X ij be a random variable indicating if a pair of objects O and O j are mapped to the same min-hash value, i.e. X ij = 1 if h ( O i ) = h ( O j ) and 0 otherwise. Also, let Y = P i 6 = j X ij . (Note that X ij = X ji .) Thus, [ RDJ = Let s ij = JS( O i , O j ) , then Pr[ X ij = 1] = s ij , and E [ X s . Thus,
Due to the definition of Jaccard similarity (sets overlap size di-vided by sets union size), if s ij &gt; 0 we have If TrackDJ uses K min-hash functions independently, then
With this statement, we can derive the time and space complexi -ties of TrackDJ.

C LAIM 3 (C OMPLEXITY OF T RACK DJ). To estimate the re-fined DJ-Index and guarantee a small relative error (at most  X  ) with a high probability (at least 1  X   X  ), TrackDJ requires O log(1 / X  )  X  2 n U time and O (log( nU ) nU ) memory bits, where n is the number of objects in the input data set and U is the maximum set size among all objects. P R OOF . Knowing the variance from Claim 2, by Chebyshev X  X  Inequality we can observe that K in TrackDJ should be set to O t o bound the relative error to  X  with a constant probability (e.g. ) . To increase the success probability, we can repeat the pro-cess described before 2 log (1 / X  ) times independently and report the median of the outputs. In this way, the success probability can be boosted to 1  X  1 2 l og(1 / X  ) . Therefore, TrackDJ has a run-ning time of O log(1 / X  )  X  2 n U . The space costs come from stor-ing the input and ID counters are as follows: TrackDJ needs to store O ( nU ) counters of all term IDs, which is equal to the space requirement of the input. Each frequency counter in the buffer needs O (log( nU ) bits, resulting in the overall space complexity of O (log( nU ) nU ) .

Note that TrackDJ can be easily parallelized with a complexit y of O ( n/m ) . This can be done by partitioning the data into m parts for m machines, computing self-join sizes separately for the sub-sets using TrackDJ, and aggregating the result on a central machine accordingly.
We evaluated the algorithms described in this paper using both synthetic and real world datasets 3 . In this section, we first elaborate on data sets used. We then compare the three algorithms, All-Pair, SampleDJ and TrackDJ, under different efficiency aspects includ-ing accuracy, time and space costs, and parameters. Note that there exist no other methods for efficiently computing the diversity of large document corpora we could compare with. Our real-world data sets were obtained from Flickr 4 and DBLP. DBLP [17] is a Computer Science Bibliography database contain-ing more than 1.2 million bibliographic records. The data records in DBLP are mostly contributed by human editors and are well-structured. From DBLP, we extracted 1,256,089 paper titles based on the publication year and venue. We only considered conference and journal papers and removed books and other article types. Each paper title was considered as one object for our diversity analysis. For reasons of completeness and cleanness we focused on DBLP paper titles to mine topic diversities of computer science papers.
Finally, we gathered tag assignments for 134 Mio Flickr pho-tos uniformly over the time period from 01 Jan 2005 until 05 Sept 2010. From this set we selected a subset of 25 Mio photos where each of photo contained at least 3 English tags (though a dictionary check), and performed stemming.
We created additional synthetic data sets in order to study the performance of different algorithms on data sets with various RDJ-index values. To this end, we generated groups of objects with the property that 1) all objects within a group had the same number of terms and were pair-wise similar with the same similarity, and 2) objects in different groups had always similarity 0 . By adjusting the number of groups with different sizes (i.e. the number of objects in each group), we constructed multiple data sets with different RDJ-index values. More specifically, we constructed the data sets as follows: 1) We set U , the number of term IDs in each object to 10 . 2) In each group, we generated a set of common IDs shared by all objects in the group. All other IDs in the group were distinct; in this way, by controlling the common ID numbers, we set the pair-wise similarity of all pairs in each group to around 0.5. 3) By varying the number of groups G and group size Gs , we created multiple synthetic data sets with n = G  X  Gs = 524 , 288 objects each.
To implement the straightforward All Pair algorithm, we used an array of size n to store the input file, with each array element be-ing, in turn, an array containing the term IDs of an object. To com-pute the RDJ-Index values, All-Pair iterates over all possible object pairs, and computes the Jaccard similarity of each pair by linearly scanning the two sets of sorted term IDs and counting the number of common terms and the total number of terms. To implement SampleDJ , we used the system-provided lrand48() function to generate random numbers within the range 1 and n . We set W , the number of consecutive trials to 10000. For TrackDJ , we used linear hashing to implement Min-Wise independent hashing as suggested by Broder et al. [7]. We used the same settings for error bound and confidence as for SampleDJ.
In this set of experiments, we compared the performances of the 3 algorithms All-Pair, SampleDJ and TrackDJ on real-word and synthetic data.
The three metrics used to measure the performance of the al-gorithms were running time, space (memory) requirements, and accuracy. In terms of memory, the primary costs of All-Pair and SampleDJ were almost the same: namely, storing all term IDs, re-quiring e.g. about 33MB for the DBLP title IDs. TrackDJ requires more space for storing the frequency counters. Depending on the data sets, this cost can be as large as the input data set in the worst case. For the DBLP data set, it is less than 1/10 of the input data. Because the space cost is relatively clear and corresponds directly to the input data set size, we focused on running time and accu-racy in our experiments. The preliminary experiments with the synthetic data on the effect different parameters were conducted on a machine with 2x Xeon5320 1.86GHz processors and 16GB of memory running CentOS 5.3. For experiments on the real world data set, we used one separate core on a more powerful machine with 8x Quad-Core AMD Opteron 2.7GHz processors and 256GB of memory running the same OS. Programs were coded in C and compiled using gcc 4.40.
Experiments for the approximation algorithms were performed with an error bound  X  of 0.1 and a confidence value of 1  X   X  = 0.95. Table 1 shows the running time and error values (along with the ex-act RDJ values computed through All-Pair). Experimental results are consistent with our theoretical findings described in Section 4.
For the naive All-Pair solution, we observe that running times are rather small for dataset sizes of 1,000 and 10,000 but, due to its quadratic behavior, quickly become infeasible for larger sets.
Our SampleDJ approach shows the best running time behavior of the three tested algorithms. Running times stay in the order of magnitude of minutes, and are almost constant with respect to the input size. The shorter running times for relatively small data sizes are an artifact of the hardware, and can be explained by L1 and L2 caching as for small datasets a larger part of possible object pairs can be kept in the caches; for larger sizes we observed a constant running time (approx. 5 min for the Flickr dataset), consiste nt with our theoretical findings in Section 4.3. Also consistent with our the-oretical findings, TrackDJ shows linear behavior and outperforms All-Pair for datasets of size n larger than 1 million. Note that for the approximation algorithms TrackDJ and SampleDJ the actual er-ror is clearly below the defined error bound (in most cases less than 0.001 for  X  = 0.1) For the given datasets, SampleDJ shows much better performance than TrackDJ; however, in the next paragraph we will see that TrackDJ can be more efficient for data distribu-tions with very high diversity.
We have seen that SampleDJ always provides accurate estimates within short running time. This is because the RDJ value is still rel-atively large. However, Table 2a shows SampleDJ degrades indeed in O ( 1 RDJ 2 ) r ate for varying RDJ values on our synthetic data as shown in our theoretical analysis. In comparison, All-Pair and TrackDJ are not sensitive to the RDJ values; TrackDJ outperforms SampleDJ if RDJ values are small.
 In another set of experiments, we used the first 1000 lines of the DBLP data to test the effect of the relative error bound  X  on running time and accuracies of SampleDJ and TrackDJ. We set  X  to a fixed vale of 0 . 001 and varied  X  . Table 2b confirms that the running time of both SampleDJ and TrackDJ are indeed O ( 1  X  2 ) . Ideally, the er-rors of both solutions should strictly decrease when the error bound decreases, but in fact this is not the case in our experiments and the error of both solutions fluctuate sometimes. We believe this is be-cause the real error is already quite small and close to the optimal. Note that even the best possible pseudo random number generator and min-wise hashing implementation are approximations to the theoretical ideals. Figure 1: F lickr photo tags similarity over the time period 2005-2010,
The main characteristics of the tested algorithms can be summa-rized as follows:
Note, that all three approaches can be parallelized (cf. Section 4).
We now show the results of sample studies on a number of real world datasets. Note, that low RDJ values correspond to high di-versity.
We also studied the temporal development of tag annotation di-versity in the social photo sharing site Flickr over the time period from 01 Jan 2005 until 05 Sept 2010 (see Section 5.1 for a descrip-tion of the Flickr sample).

Our first observation from Figure 1 is a year wise increase in annotation diversity reflected by the decrease of the RDJ values. A possible explanation for the increasing topic diversity is that the user community has broadened over the years with Flickr becoming more and more popular for people of different ages, origins, and backgrounds.

Secondly, exploring diversity on a more fine-grained, monthly level reveals additional interesting patterns and periodicities. In or-der to obtain representative tags for the most interesting parts of the curve, we computed Mutual Information (MI) [19] for each tag, which measures how much a joint distribution of terms and categories deviates from a hypothetical distribution in which terms and categories (time period for a peak and the rest of the year in our case) are independent of each other. Note that the number of photos captured for this figure remains rather constant over time, amount-ing to approx. 10,000 images per day. The RDJ value curve starts at its minimum at the beginning of each year (January) and remains at the lowest level till the end of March, reflecting high topic diversity. Photos in this time period are mainly described by tags for a rather broad range of topics like winter , snow , vacation , or house . In sum-mer, the curve starts to increase steadily, and reaches its maximum in mid-July before it decreases steadily until the end of September, with the most representative tags in this time period being grad-uation , wedding and beach . In October the RDJ value increases sharply, reaching a peak by the end of that month. Our term anal-ysis reveals that this is due to the popular holidays halloween and thanksgiving . Finally, the RDJ curve reaches its maximum at the end of December where Christmas is the dominating topic. To study diversity in the DBLP dataset, we classified Computer Science (CS) paper titles into groups based on publication year and publication venue. We intended to explore how topic diver-sities of Computer Science papers change with time and research area. We picked well-known publication venues to represent 4 re-search areas: Databases (DB), Artificial Intelligence (AI), Comput-ing Theory and Computer Networks. The venues representing the areas are as follows: DB: SIGMOD , VLDB , AI: AAAI , IJCAI , The-ory: STOC , FOCS , and Computer Networking: SIGCOMM , INFO-COM . Figure 2 shows how topic diversity changes with time. The figures indicate that the topic diversities of CS papers increased gradually over time with the exception of Network papers within the past 5 years. Also, curiosity driven papers (Theory, AI) seem to have higher topic diversities than application driven ones (DB, Networking).
Cluster analysis or  X  X lustering X  refers to the division of a set of objects into subsets (called clusters) so that objects in the same cluster are more similar and objects in different clusters are less similar. In many contexts unsupervised machine learning tech-niques like hierarchical, partitional or spectral clustering are em-ployed to achieve this goal. Intuitively, the higher the number of clusters in a particular data set, the higher its diversity. In this sec-tion we want to verify if this property is reflected by the RDJ index. To this end, we analyzed three real world data sets: 1. RCV1: The  X  X euters Corpus Volume 1 X  (RCV1) is a corpus 2. Flickr Groups: The second dataset consists of tagged pho-3. US Census 1990: In demographics clustering is defined as Table 3 provides an overview over the topics in the datasets and the number of instances per topic. For each dataset we selected the top n = 7 largest clusters. We computed sets of all n k possible cluster combinations for k = 1 , . . . , n clusters. In order to obtain balanced cluster sizes, we restricted the number of instances, s , per combination to the size of the smallest cluster, and randomly se-lected s k i nstances from each cluster in the sample. For the RCV1, Flickr and UCI Census datasets we obtained 31,328, 71,158 and 107,142 instances, respectively. Finally, for each number of clus-ters k we computed the average RDJ index value across all cluster combinations.

Figure 3 shows the RDJ index vs. the number k of clusters con-tained in the sample sets. The key observation is that the RDJ value indeed decreases with the number of clusters. This shows that topic diversity in the sample sets is mirrored by the Jaccard-based RDJ index. Despite of the large structural and conceptual differences between the distinct corpora and the large differences between the absolute RDJ values, the decreasing pattern observed is remarkably similar across corpora.

A comparison of diversity values in different corpora and for specific clusters reveals further interesting insights (cf. Table 3). Generally, the diversity in the Flickr data set is highest (correspond-ing to lower RDJ values) as the tags used for diversity computa-tion can be defined by users and are not restricted. The Reuters data set contains more restricted vocabulary, and is less diverse. Finally, attributes in the UCI Dataset are well defined, the num-ber of possible terms per instance is small (68), and the  X  X ocab-ulary X  limited, which results in high RDJ values. We also stud-ied the correspondence of RDJ diversity values to different topics. For example in Table 3a the first five categories including  X  X ndus-trial X  ( RDJ=4.31 ) or  X  X arkets X  ( 4.79 ) are more general and there-fore more diverse (an exception being  X  X overnment/Social X  with ( RDJ=5.73 )).  X  X omestic Politics X  ( 5.21 ) and  X  X ar, Civil War X  ( 5.81 ) are sub-categories that are more specific and less diverse. The Flickr groups  X  X isual Arts X  ( 0.61 ) and  X  X bsolutely beautiful X  ( 0.51 ) are more general than  X  X ighthouse Lovers X  ( 4.56 ) and  X  X ir-craft Photos X  ( 1.99 ). Finally, for the census data, we observe that the group  X  X /a Less Than 3 Yrs. Old X  ( 84.55 ), which mainly rep-resents babies, has the lowest diversity.

The RDJ index clearly corresponds to the number of clusters in a data set and could be used in efficient heuristics for determining the number of clusters in large data sets which is required as a param-eter in many clustering techniques such as k-means [1], k-medoids or the expectation-maximization algorithm for clustering. In our future work we plan to investigate in depth how exactly different diversity indexes might help to estimate parameters for clustering in large datasets.
Contributions: Two novel, efficient algorithms for estimating the diversity of whole corpora with probabilistic guarantees, and illus-trative example studies on different datasets. To the best of our knowledge, there exist no other methods for efficiently computing the diversity of whole corpora.
Simplicity of the diversity measure: W e would like to point out that nearly all recent diversity measures used in the context of query result diversification and cited in the paper are actually based on  X  X imple X  pairwise similarity or distance computations. We consider  X  X implicity X  as an asset since simple ideas have a higher chance to be applied in practice. For instance, one of the reasons why relational databases are so popular is that the relational model is simple.

TrackDJ vs. SampleDJ: Although our SampleDJ algorithm out-performs TrackDJ for our specific datasets, it becomes superior for datasets with smaller RDJ value. In this paper we have presented a strong theoretical result, which has the potential to be applied in additional contexts:  X  X verage pair-wise similarity can be computed in one pass with probabilistic guarantees. X 
Tuning parameters: The parameters of the algorithms are basi-cally the user-defined epsilon and delta which we comprehensively study in our experiments. As described in Section 4, window size W for SampleDJ is independent of data set sizes; the number of windows is determined automatically , and changes according to the data properties. Therefore, no tuning of W is required.
Vocabulary size: Guarantees for error bounds and running times for both SampleDJ and TrackDJ do not require any assumptions about the overall vocabulary size of the corpus.

Parallelization: We elaborate on parallelization for the three con-sidered algorithms (cf. Section 4 with an additional backward ref-erence made in the summary of Section 5). All of the algorithms can run approx. k times faster on k machines.

Main memory consumption: TrackDJ allows for computing di-versity in one pass, thus each term-set needs to be read just once, making the algorithm feasible even in case the main memory size is limited. SampleDJ requires only a fraction of the comparisons of the All-Pairs algorithm, and thus allocates only a negligible amount of main memory. In case hard-drive access is necessary, SampleDJ would further save a considerable number of I/O processes com-pared to the baseline approach.

Future work: We aim at adapting our algorithms to other similar-ity measures like Euclidean distance and cosine similarity by using LSH and its variants. In addition, for other multimedia types such as videos or photos a study of diversity based on visual properties (e.g. color distributions or shapes) may reveal further insights about social content sharing environments such as Flickr or YouTube.
This work is partly funded by the European Commission under the grant agreement 270239 (ARCOMEM) and 287704 (CUBRIK) as well as by the NTH School for IT Ecosystems. We would like to thank Dr. Davood Rafiei for helpful and insightful discussions at the initial stage of the work. [1] Data clustering: 50 years beyond k-means. Pattern [2] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. [3] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information [4] A. Z. Broder. Min-wise independent permutations: Theory [5] A. Z. Broder. On the resemblance and containment of [6] A. Z. Broder. Identifying and filtering near-duplicate [7] A. Z. Broder, M. Charikar, A. Frieze, and M. Mitzenmacher. [8] M. Charikar. Similarity estimation techniques from rounding [9] P. Dagum, R. Karp, M. Luby, and S. Ross. An optimal [10] M. Datar, N. Immorlica, P. Indyk, and V. S. Mirrokni. [11] J. D. Fearon. Ethnic and cultural diversity by country*. [12] S. Gollapudi and A. Sharma. An axiomatic approach for [13] P. Indyk and R. Motwani. Approximate nearest neighbors: [14] C. C. Krebs. Ecological Methodology . HarperCollins, 1989. [15] C. L X v X que and J.-C. Mounolou. Biodiversity . John Wiley &amp; [16] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A new [17] M. Ley. The dblp computer science bibliography. http: [18] S. Lieberson. Measuring population diversity. American [19] C. D. Manning, P. Raghavan, and H. Sch X tze. Introduction to [20] C. Meek, B. Thiesson, and D. Heckerman. The [21] E. Minack, W. Siberski, and W. Nejdl. Incremental [22] Olken. Random sampling from databases. In Ph.D. Diss. [23] O. Papapetrou, W. Siberski, and N. Fuhr. Text clustering for [24] D. Rafiei, K. Bharat, and A. Shukla. Diversifying web search [25] I. Rafols and M. Meyer. Diversity and network coherence as [26] N. Sahoo, J. Callan, R. Krishnan, G. Duncan, and [27] E. H. Simpson. Measurement of diversity. Nature , 163, 1949. [28] A. Stirling. A general framework for analysing diversity in [29] E. Vee, U. Srivastava, J. Shanmugasundaram, P. Bhat, and [30] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and G. Lausen.
