 Automated summarization systems which enable user to quickly digest the important information conveyed by either a single or a cluster of docu-ments are indispensible for managing the rapidly growing amount of textual information and mul-timedia content (Mani and Maybury, 1999). On the other hand, due to the maturity of text sum-marization, the research paradigm has been ex-tended to speech summarization over the years (Furui et al., 2004; McKeown et al., 2005). Speech summarization is expected to distill im-portant information a nd remove redundant and incorrect information caused by recognition er-rors from spoken documents, enabling user to efficiently review spoken documents and under-stand the associated topics quickly. It would also be useful for improving the efficiency of a num-ber of potential applica tions like retrieval and mining of large volumes of spoken documents. 
A summary can be either abstractive or extrac-tive. In abstractive summarization, a fluent and concise abstract that reflects the key concepts of a document is generated, whereas in extractive summarization, the summary is usually formed by selecting salient sentences from the original document (Mani and Maybury, 1999). The for-mer requires highly sophisticated natural lan-guage processing techniques, including semantic representation and inference, as well as natural language generation, while this would make ab-stractive approaches difficult to replicate or ex-tend from constrained domains to more general domains. In addition to being extractive or ab-stractive, a summary may also be generated by considering several other aspects like being ge-neric or query-oriented summarization, single-document or multi-document summarization, and so forth. The readers may refer to (Mani and Maybury, 1999) for a comprehensive overview of automatic text summarization. In this paper, we focus exclusively on generic, single-document extractive summarization which forms the building block for many other summarization tasks. 
Aside from traditional ad-hoc extractive sum-marization methods (Mani and Maybury, 1999), machine-learning approaches with either super-vised or unsupervised learning strategies have gained much attention and been applied with empirical success to many summarization tasks (Kupiec et al., 1999; Lin et al., 2009). For super-vised learning strategies, the summarization task is usually cast as a two-class (summary and non-summary) sentence-classification problem: A sentence with a set of indicative features is input to the classifier (or summarizer) and a decision is then returned from it on the basis of these fea-tures. In general, they usually require a training set, comprised of several documents and their corresponding handcrafted summaries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and per-sonnel. The other potential problem is the so-called  X  bag-of-sentences  X  assumption implicitly made by most of these summarizers. That is, sen-tences are classified independently of each other, without leveraging the de pendence relationships among the sentences or the global structure of the document (Shen et al., 2007). 
Another line of thought attempts to conduct document summarization using unsupervised machine-learning appro aches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the perfor-mance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. 
Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to inherit their individual merits to overcome their inherent limitations. In this paper, we present a probabilistic summariza-tion framework stemming from Bayes decision theory (Berger, 1985) fo r speech summarization. This framework can not only naturally integrate the above-mentioned two modeling paradigms but also provide a flexible yet systematic way to render the redundancy and coherence relation-ships among sentences and between sentences and the whole document, respectively. Moreover, we also illustrate how the proposed framework can unify several existing summarization models. 
The remainder of this paper is structured as follows. We start by reviewing related work on extractive summarization. In Section 3 we for-mulate the extractive summarization task as a risk minimization problem, followed by a de-tailed elucidation of the proposed methods in Section 4. Then, the experimental setup and a series of experiments and associated discussions are presented in Sections 5 and 6, respectively. Finally, Section 7 concludes our presentation and discusses avenues for future work. Speech summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence i S is characterized by set of T indicative features  X  X  X  and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), ac oustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector i X of i S is taken as the input to the classifier. If the output (classification) score belongs to the positive class, 
S will be selected as part of the summary; oth-erwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be sum-marized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning me-thods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. 
Although such supervised summarizers are ef-fective, most of them (except CRF) usually im-plicitly assume that sentences are independent of each other (the so-called  X  bag-of-sentences  X  as-sumption) and classify each sentence individual-ly without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary ex-emplars are required for training the summarizers; however, such summarizers tend to limit their generalization capability and might not be readi-ly applicable for new tasks or domains. 2.2 Unsupervised summarizers The related work conducted along this direction usually relies on some heuristic rules or statistic-al evidences between each sentence and the doc-ument, avoiding the need of manually labeled training data. For example, the vector space model (VSM) approach represents each sentence of a document and the document itself in vector space (Gong and Liu, 2001), and computes the relevance score between each sentence and the document (e.g., the cosine measure of the simi-larity between two vectors). Then, the sentences with the highest relevance scores are included in the summary. A natural extension is to represent each document or each sentence vector in a latent semantic space (Gong and Liu, 2001), instead of simply using the literal term information as that done by VSM. 
On the other hand, the graph-based methods, such as TextRank (Mihalcea and Tarau, 2005) and LexRank (Erkan and Radev, 2004), concep-tualize the document to be summarized as a net-work of sentences, where each node represents a sentence and the associated weight of each link represents the lexical or topical similarity rela-tionship between a pair of nodes. Document summarization thus relies on the global structural information conveyed by such conceptualized network, rather than merely considering the local features of each node (sentence). 
However, due to the lack of document-summary reference pairs, the performance of the unsupervised summarizers is usually worse than that of the supervised summarizers. Moreover, most of the unsupervised summarizers are con-structed solely on the b asis of the lexical infor-mation without considering other sources of in-formation cues like discourse features, acoustic features, and so forth. Extractive summarization can be viewed as a decision making process in which the summariz-er attempts to select a representative subset of sentences or paragraphs from the original docu-ments. Among the several analytical methods that can be employed for the decision process, the Bayes decision theory, which quantifies the tradeoff between various decisions and the po-tential cost that accompanies each decision, is perhaps the most suited one that can be used to guide the summarizer in choosing a course of action in the face of some uncertainties underly-ing the decision process (Berger, 1985). Stated formally, a decision problem may consist of four basic elements: 1) an observation O from a ran-dom variable O , 2) a set of possible decisions (or actions)  X   X  a , 3) the state of nature  X   X   X  , and 4) a loss function  X   X   X  , cost associated with a chosen decision that  X  is the true state of nature. The expected risk (or conditional risk) associated with taking decision where  X   X   X  |O p is the posterior probability of the state of nature being  X  given the observation O Bayes decision theory states that the optimum decision can be made by contemplating each ac-tion the expected risk is minimum: 
The notion of minimizing the Bayes risk has gained much attention and been applied with success to many natural language processing (NLP) tasks, such as automatic speech recogni-tion (Goel and Byrne, 2000), statistical machine translation (Kumar and Byrne, 2004) and statis-tical information retrieval (Zhai and Lafferty, 2006). Following the same spirit, we formulate the extractive summarization task as a Bayes risk minimization problem. Without loss of generality, let us denote  X   X   X  as one of possible selection strategies (or state of nature) which comprises a set of indicators used to address the importance of each sentence summarized. A feasible selection strategy can be fairly arbitrary according to the underlying prin-ciple. For example, it could be a set of binary indicators denoting whether a sentence should be selected as part of summary or not. On the con-trary, it may also be a ranked list used to address the significance of each individual sentence. Moreover, we refer to the k -th action choosing the k -th selection strategy observation O as the document D to be summa-rized. As a result, the expected risk of a certain selection strategy Consequently, the ultimate goal of extractive summarization could be stated as the search of the best selection strategy from the space of all possible selection strategies that minimizes the expected risk defined as follows: 
Although we have described a general formu-lation for the extractive summarization problem on the grounds of the Ba yes decision theory, we consider hereafter a special case of it where the selection strategy is represented by a binary deci-sion vector, of which each element corresponds to a specific sentence i S in the document D and designates whether it should be selected as part of the summary or not, as the first such attempt. More concretely, we assume that the summary sentences of a given document can be iteratively chosen (i.e., one at each iteration) from the doc-ument until the aggregated summary reaches a predefined target summarization ratio. It turns out that the binary vector for each possible action will have just one elemen t equal to 1 and all oth-ers equal to zero (or the so-called  X  one-of-n  X  coding). For ease of notation, we denote the bi-nary vector by i S when the i -th element has a value of 1. Therefore, the risk minimization framework can be reduced to where D ~ denotes the remaining sentences that have not been selected into the summary yet (i.e., the  X  residual  X  document); erior probability of a sentence cording to the Bayes X  rule, we can further ex-press where ability, i.e., the likelihood of D ~ being generated by important; and the evidence probability of D ~ , which can be approximated by 
By substituting (6) and (7) into (5), we obtain the following final selection strategy for extrac-tive summarization: 
A remarkable feature of this framework lies in that a sentence to be considered as part of the summary is actually evaluated by three different fundamental factors: (1) prior probability that addresses the importance of sentence generative probability that captures the degree of relevance of (3) es the relationship between sentence other sentence framework can be regarded as a generalization of several existing summarization methods. A de-tailed account on the construction of these three component models in the framework will be giv-en in the following section. 4 Proposed Methods There are many ways to construct the above mentioned three component models, i.e., the sen-tence generative model prior model In what follows, we will shed light on one possi-ble attempt that can accomplish this goal elegant-ly. 4.1 Sentence generative model In order to estimate the sentence generative probability, we explore the language modeling (LM) approach, which has been introduced to a wide spectrum of IR task s and demonstrated with good empirical success, to predict the sentence generative probability. In the LM approach, each sentence in a document can be simply regarded as a probabilistic genera tive model consisting of a unigram distribution (the so-called  X  bag-of-words  X  assumption) for generating the document (Chen et al., 2009): where term (or word) w occurs in D ~ , reflecting that w will contribute more in the calculation of that the sentence model mated on the basis of the frequency of index term w occurring in the sentence maximum likelihood (ML) criterion. In a sense, (9) belongs to a kind of literal term matching strategy (Chen, 2009) and may suffer the prob-lem of unreliable model estimation owing partic-ularly to only a few sampled index terms present in the sentence (Zhai, 2008). To mitigate this potential defect, a unigram probability estimated from a general collection, which models the gen-eral distribution of words in the target language, is often used to smooth the sentence model. In-terested readers may refer to (Zhai, 2008; Chen et al., 2009) for a thorough discussion on various ways to construct the sentence generative model. 4.2 Sentence prior model The sentence prior probability garded as the likelihood of a sentence being im-portant without seeing the whole document. It could be assumed uniformly distributed over sen-tences or estimated from a wide variety of factors, such as the lexical info rmation, the structural information or the inherent prosodic properties of a spoken sentence. 
A straightforward way is to assume that the sentence prior probability to the posterior probability of a sentence ing included in the su mmary class when observ-ing a set of indicative features from such factors or other sentence importance measures (Kupiec et al., 1999). These features can be integrated in a systematic way into the proposed framework by taking the advantage of the learning capability of the supervised ma-chine-learning methods. Specifically, the prior probability that a sentence j S with features ed by the summary class S and the non-summary class S , respectively; the prior proba-bility  X  X  S P and research. To estimate several popular supervised classifiers (or summa-rizers), like BC or SVM, can be leveraged for this purpose. 4.3 Loss function The loss function introduced in the proposed summarization framework is to measure the rela-tionship between any pair of sentences. Intuitive-ly, when a given sentence is more dissimilar from most of the other sentences, it may incur higher loss as it is taken as the representative sentence (or summary sentence) to represent the main theme embedded in the other ones. Conse-quently, the loss function can be built on the no-tion of the similarity measure. In this research, we adopt the cosine measure (Gong and Liu, 2001) to fulfill this goal. We first represent each sentence specifies the weighted statistic i t z , , e.g., the product of the term frequency (TF) and inverse document frequency (IDF) scores, associated with an index term t w in sentence cosine similarity between any given two sen-tences The loss function is thus defined by 
Once the sentence generative model the sentence prior model tion summary sentences can be selected iteratively by (8) according to a predef ined target summariza-tion ratio. However, as can be seen from (8), a new summary sentence is selected without con-sidering the redundant information that is also contained in the already selected summary sen-tences. To alleviate this problem, the concept of maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), which performs sentence selection iteratively by striking the balance be-tween topic relevance and coverage, can be in-corporated into the loss function: where Summ represents the set of sentences that have already been included into the summary and the novelty factor  X  is used to trade off be-tween relevance and redundancy. 4.4 Relation to other summarization models In this subsection, we briefly illustrate the rela-tionship between our proposed summarization framework and a few existing summarization approaches. We start by considering a special case where a 0-1 loss function is used in (8), namely, the loss function will take value 0 if the two sentences are identical, and 1 otherwise. Then, (8) can be alternatively represented by which actually provides a natural integration of the supervised and unsupervised summarizers (Lin et al., 2009), as mentioned previously. 
If we further assume the prior probability 
S P is uniformly distributed, the important (or summary) sentence selection problem has now been reduced to the problem of measuring the document-likelihood between the document and the sentence. Alone a similar vein, the important sentences of a docu-ment can be selected (or ranked) solely based on the prior probability of an equal document-likelihood 5 Experimental setup 5.1 Data The summarization dataset used in this research is a widely used broadcast news corpus collected by the Academia Sinica and the Public Televi-sion Service Foundation of Taiwan between No-vember 2001 and April 2003 (Wang et al., 2005). Each story contains the speech of one studio anchor, as well as severa l field reporters and in-terviewees. A subset of 205 broadcast news doc-uments compiled between November 2001 and August 2002 was reserved for the summarization experiments. 
Three subjects were asked to create summaries of the 205 spoken documents for the summariza-tion experiments as refere nces (the gold standard) for evaluation. The summaries were generated by ranking the sentences in the reference transcript of a spoken document by importance without assigning a score to each sentence. The average Chinese character error rate (CER) obtained for the 205 spoken documents was about 35%. 
Since broadcast news stories often follow a relatively regular structure as compared to other speech materials like conversations, the position-al information would play an important (domi-nant) role in extractive summarization of broad-cast news stories; we, hence, chose 20 docu-ments for which the generation of reference summaries is less correlated with the positional information (or the position of sentences) as the held-out test set to evaluate the general perfor-mance of the proposed summarization frame-work, and 100 documents as the development set. 5.2 Performance evaluation For the assessment of summarization perfor-mance, we adopted the widely used ROUGE measure (Lin, 2004) because of its higher corre-lation with human judgments. It evaluates the quality of the summarization by counting the number of overlapping units, such as N -grams, longest common subsequences or skip-bigram, between the automatic summary and a set of ref-erence summaries. Three variants of the ROGUE measure were used to quantify the utility of the proposed method. They are, respectively, the ROUGE-1 (unigram) measure, the ROUGE-2 (bigram) measure and the ROUGE-L (longest common subsequence) measure (Lin, 2004). The summarization ratio, defined as the ratio of the number of words in the automatic (or manual) summary to that in the re ference transcript of a spoken document, was set to 10% in this re-search. Since increasing the summary length tends to increase the chance of getting higher scores in the recall rate of the various ROUGE measures and might not always select the right number of informative words in the automatic summary as compared to the reference summary, all the experimental results reported hereafter are obtained by calculating the F-scores of these ROUGE measures, respectively (Lin, 2004). Ta-ble 1 shows the levels of agreement (the Kappa statistic and ROUGE measures) between the three subjects for important sentence ranking. They seem to reflect the fact that people may not always agree with each other in selecting the im-portant sentences for representing a given docu-ment. 5.3 Features for supervised summarizers We take BC as the representative supervised summarizer to study in this paper. The input to BC consists of a set of 28 indicative features used to characterize a spoken sentence, including the structural features, the lexical features, the acoustic features and the relevance feature. For each kind of acoustic features, the minimum, maximum, mean, difference value and mean dif-ference value of a spoken sentence are extracted. The difference value is defined as the difference between the minimum and maximum values of the spoken sentence, while the mean difference value is defined as the mean difference between a sentence and its previous sentence. Finally, the relevance feature (VSM score) is use to measure the degree of relevance for a sentence to the whole document (Gong and Liu, 2001). These features are outlined in Table 2, where each of them was further normalized to zero mean and unit variance. 6 Experimental results and discussions 6.1 Baseline experiments In the first set of experiments, we evaluate the baseline performance of the LM and BC summa-rizers (cf. Sections 4.1 and 4.2), respectively. The corresponding results are detailed in Table 3, where the values in the parentheses are the asso-ciated 95% confidence intervals. It is also worth mentioning that TD denotes the summarization results obtained based on manual transcripts of the spoken documents while SD denotes the re-sults using the speech recognition transcripts which may contain speech recognition errors and sentence boundary detection errors. In this re-search, sentence boundaries were determined by speech pauses. For the TD case, the acoustic fea-tures were obtained by aligning the manual tran-scripts to their spoken documents counterpart by performing word-level forced alignment. 
Furthermore, the ROGUE measures, in es-sence, are evaluated by counting the number of overlapping units between the automatic sum-mary and the reference summary; the corres-ponding evaluation results, therefore, would be severely affected by speech recognition errors when applying the various ROUGE measures to quantify the performan ce of speech summariza-tion. In order to get rid of the cofounding effect of this factor, it is assumed that the selected summary sentences can also be presented in speech form (besides text form) such that users can directly listen to the audio segments of the summary sentences to bypass the problem caused by speech recognition errors. Consequently, we can align the ASR transcripts of the summary sentences to their respective audio segments to obtain the correct (manual) transcripts for the summarization performance evaluation (i.e., for the SD case). 
Observing Table 3 we notice two particulari-ties. First, there are significant performance gaps between summarization using the manual tran-scripts and the erroneous speech recognition transcripts. The relative performance degrada-tions are about 15%, 34% and 23%, respectively, for ROUGE-1, ROUGE2 and ROUGE-L meas-ures. One possible explanation is that the errone-ous speech recognition transcripts of spoken sen-tences would probably carry wrong information and thus deviate somewhat from representing the true theme of the spoken document. Second, the supervised summarizer (i.e., BC) outperforms the unsupervised summarizer (i.e., LM). The better performance of BC can be further explained by two reasons. One is that BC is trained with the handcrafted document-summary sentence labels in the development set while LM is instead con-ducted in a purely unsupervised manner. Another is that BC utilizes a rich set of features to charac-terize a given spoken sentence while LM is con-structed solely on the basis of the lexical (uni-gram) information. 6.2 Experiments on the proposed methods We then turn our attention to investigate the utili-ty of several methods deduced from our pro-posed summarization framework. We first con-sider the case when a 0-1 loss function is used (cf. (13)), which just show a simple combination of BC and LM. As can be seen from the first row of Table 4, such a combination can give about 4% to 5% absolute improvements as compared to the results of BC illustrated in Table 3. It in some sense confirms the feasibility of combining the supervised and unsupe rvised summarizers. Moreover, we consider the use of the loss func-tions defined in (11) (denoted by SIM) and (12) (denoted by MMR), and the corresponding re-sults are shown in the second and the third rows of Table 4, respectively. It can be found that MMR delivers higher summarization perfor-mance than SIM (especially for the SD case), which in turn verifies the merit of incorporating the MMR concept into the proposed framework for extractive summarization. If we further com-pare the results achieved by MMR with those of BC and LM as shown in Table 3, we can find significant improvements both for the TD and SD cases. By and large, for the TD case, the pro-posed summarization method offers relative per-formance improvements of about 19%, 23% and 19%, respectively, in the ROUGE-1, ROUGE-2 and ROUGE-L measures as compared to the BC baseline; while the relative improvements are 29%, 46% and 31%, respectively, in the same measurements for the SD case. On the other hand, the performance gap between the TD and SD cases are reduced to a good extent by using the proposed summarization framework. 
In the next set of experiments, we simply as-sume the sentence prior probability fined in (8) is uniformly distributed, namely, we do not use any supervised information cue but use the lexical information only. The importance of a given sentence is thus considered from two angles: 1) the relationship between a sentence and the whole document, and 2) the relationship between the sentence and the other individual sentences. The corresponding results are illu-strated in the lower part of Table 4 (denoted by Uniform). We can see that the additional consid-eration of the sentence-sentence relationship ap-pears to be beneficial as compared to that only considering the document-sentence relevance information (cf. the second row of Table 3). It also gives competitive results as compared to the performance of BC (cf. the first row of Table 3) for the SD case. 6.3 Comparison with conventional summa-In the final set of experiments, we compare our proposed summarization methods with a few existing summarization methods that have been widely used in various summarization tasks, in-cluding LEAD, VSM, LexRank and CRF; the corresponding results are shown in Table 5. It should be noted that the LEAD-based method simply extracts the first few sentences in a doc-ument as the summary. To our surprise, CRF does not provide superior results as compared to the other summarization methods. One possible explanation is that the structural evidence of the spoken documents in the test set is not strong enough for CRF to show its advantage of model-ing the local structural information among sen-tences. On the other hand, LexRank gives a very promising performance in spite that it only uti-lizes lexical information in an unsupervised manner. This somewhat reflects the importance of capturing the global relationship for the sen-tences in the spoken document to be summarized. As compared to the results shown in the  X  X C X  part of Table 4, we can see that our proposed methods significantly outperform all the conven-tional summarization methods compared in this paper, especially for the SD case. 7 Conclusions and future work We have proposed a risk minimization frame-work for extractive speech summarization, which enjoys several advantages. We have also pre-sented a simple yet effective implementation that selects the summary sentences in an iterative manner. Experimental results demonstrate that the methods deduced from such a framework can yield substantial impr ovements over several popular summarization methods compared in this paper. We list below some possible future exten-sions: 1) integrating differe nt selection strategies, e.g., the listwise strategy that defines the loss function on all the sentences associated with a document to be summarized, into this framework, 2) exploring different modeling approaches for this framework, 3) investigating discriminative training criteria for training the component mod-els in this framework, and 4) extending and ap-plying the proposed framework to multi-document summarization tasks. 
