 In this paper we discuss a method to incorporate diver-sity into a personalised ranking objective, in the context of ranking-based recommendation using implicit feedback. The goal is to provide a ranking of items that respects user preferences while also tending to rank diverse items closely together. A prediction formula is learned as the product of user and item feature vectors, in order to minimise the mean squared error objective used previously in the RankALS and RankSGD methods, but modified to weight the difference in ratings between two items by the dissimilarity of those items. We report on preliminary experiments with this mod-ified objective, in which the minimisation is carried out using stochastic gradient descent. We show that rankings based on the output of the minimisation succeed in producing rec-ommendation lists with greater diversity, with just a small loss in relevance of the recommendation, as measured by the error rate.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Diversity; Implicit Ratings
A large amount of research on recommender system al-gorithms has been driven by the task of predicting ratings for unrated items, given a database of items that have been explicitly rated by users in the past. Matrix factorisation models have proven very successful in minimising the root mean squared prediction error and fast algorithms have been developed to fit these models. However, there is growing interest within the recommender system community in pro-ducing recommendation algorithms that optimise for differ-ent quality measures in other contexts. One context of par-ticular interest is that of producing personalised rankings of items given a database of implicit feedback [2, 4, 5, 3, 6]. For instance, in a music recommendation scenario, im-plicit positive feedback is gathered in terms of the number of times that a track or an artist has been listened to by a user. In this case, the absence of a rating can be interpreted as negative feedback that should be incorporated into the recommendation algorithm. Of particular interest to the work presented here are the methods of [3, 6], in which a matrix factorisation model is learned by the minimisation of a ranking objective.

Ranking based on relevance only can result in recommen-dation sets that have low diversity  X  many of the highly relevant items can be very similar to each other. This has led to interest in diversifying recommendation lists while maintaining high relevance [10, 8, 7]. This paper focuses on this problem. Differently to past work that has focused on diversifying nearest-neighbour algorithms [8, 9] or on select-ing diverse subsets of items from a set of relevant items [10], here we examine whether a diversification criterion can be incorporated into a ranking-based objective. Using a ma-trix factorisation model, user-and item-feature vectors are learned by minimising this objective to produce predicted ratings, that when used to rank the items in the database, result in recommendation sets that are highly diverse, while remaining highly relevant. We present preliminary results that evaluate our ranking with diversity model on the Net-flix dataset.
Adopting the notation of [6], let U and I be the number of users and items, respectively, in the database and write U and I for the sets of users and items. We use u  X  X  to index users and i, j  X  X  to index items. Implicit ratings are denoted as r ui and the matrix of ratings is denoted as R  X  R U  X  I . Predictions are denoted as  X  r ui . T denotes the set of ( u, i ) indices of R where positive feedback is provided. If ( u, i ) /  X  X  then an implicit negative feedback rating of r ui = 0 is assumed. U i = { u | ( u, i )  X  X } is the set of users who have given positive feedback on item i .

Our ranking with diversity strategy is based on the objec-tive function proposed originally in [3] and further developed in [6]: f R ( X ) = where  X  are the parameters of the prediction model and c ui and s j are parameters of the objective function. The key is to find a good ranking by learning the rating difference of two items for a given user u . The parameters c ui select user-item pairs with positive feedback and are taken as c ui =1if ( u, i )  X  X  and c ui = 0 otherwise. The parameters s j repre-sent the importance of item j in the objective function. The original KDD 2011 challenge [1] for which the objective was designed, required that items that receive positive feedback from a given user should be distinguished from generally popular items. For this task, an importance weighting of s  X  X U j | is appropriate.

A matrix factorisation formulation is chosen for the pre-diction model such that  X  r ui = p T u q i ,where p is an F -dimensional user feature vector associated with user u , q is an F -dimensional item feature vector associated with item i and F is the number of features. Hence  X  = ( p u , q i )The computational challenge of minimising f R ( X ) is that the ob-jective contains T  X  I terms. Originally in [3] a stochastic gradient descent algorithm (SGD), in which the items j of the third summation in (1) are sampled at random, was proposed. This is referred to as the RankSGD algorithm in [6], where an efficient alternating least squares (ALS) algo-rithm, RankALS , that avoids sampling is proposed. Our focus in not on such computational issues, but rather on exploring whether the ranking objective can be modified to take ac-count of item diversity. In the experiments presented later in this paper, we use RankSGD , although RankALS could also be applied. Assume that we have an I  X  I diversity or distance matrix D= { d ij } X  R I  X  I expressing how dissimilar item i is to item j . This matrix may be obtained from any source; it may, for example, represent a content-based dissimilarity of the items. We assume that the dissimilarity is derived from a positive definite, normalised similarity matrix, S = { s ij with s ii =1,using d ij =
We wish to form an I -dimensional ranking vector q based on this dissimilarity matrix. Let  X  i denote the item whose rank is i whereitemsarerankedaccordingto q i.e. q  X  i  X  q j . Consider an objective that attempts to choose q so that the squared difference of the difference between two compo-nents i and j of the ranking vector and the dissimilarity d is minimised: This objective may be minimised by gradient descent, using:  X  ( f 1 )= where  X  q is the mean of q . We conduct an experiment in which we form a similarity matrix S = XX T for a random vector X with I = 100. We derive the dissimilarity matrix D and minimise f 1 ( q ). The resulting q is used to sort the items and a set of N = 10 items is selected in order, starting Figure 1: The ILD of a list of N =10 items, con-sisting of items {  X  i ,..., X  i + N  X  1 } , plotted against the from each item in turn. The intra-list distance (ILD) [10, 8] of the resulting sets is plotted in Figure 1 and compared against sets selected by starting with the same item but greedily maximising the ILD. We note that choosing items from either end of the ordering produced by q results in sets with high ILD.
Of course, if diversity were the only criterion of interest, then we could simply choose sets that maximise the ILD. However, we also want to maximise the relevance of the resulting set. Given ranking vector r , chosen on the basis of relevance, we can ask if we can find a new ranking vector q which respects the given ranking in r but otherwise ranks items according to their diversity. To do so, consider the objective Again, computing the gradient, we obtain (assuming sym-metric D) Setting the gradient to zero, we obtain
Using the same dissimilarity matrix as the previous exper-iment with I = 100, we now construct a random relevance vector r with each component assigned a number between 1 and 5, with uniform probability. In Figure 2 we show the ILD and the average relevance of sets of N =10itemscho-sen in order from the ranking derived from q as computed by (3). We see that, while the ordering of q respects the or-der of r (the average relevance is monotonically decreasing), it also results in sets of high diversity as measured by the ILD. Figure 2: The vector q keeps the same rank order as r when the ratings differ but sets chosen in the rank order of q also have high ILD.
 Inputs:Learning Rate:  X  Num.of features: F 1. forall ( u, i )  X  X  do 2. draw an item j not rated by u , with 5. e  X  s j [( X  r ui  X   X  r uj )  X  d ij ( r ui  X  r uj )] 6. c = p u 7. p u = p u  X   X e ( q i  X  q j ) 8. q i = q i  X   X e c 9. q j = q j +  X e c 10.end Figure 3: The RankSGD algorithm used to minimize the ranking with diversity objective.
In the previous section, we assumed that the relevance vector was pre-computed and then modified it to take ac-count of diversity. Now we ask if it is possible to optimise for relevance and diversity simultaneously. To do so, we propose the following modification to the ranking objective function (1), to obtain a ranking with diversity objective for implicit feedback systems: f
RD ( X ) = The RankALS or RankSGD algorithms of [6] and [3] respec-tively, can be used to minimise this objective to obtain rat-ing estimates  X  r ui = p T u q , that are used to rank items to be recommended to each user u . In our experiments, we have employed the RankSGD algorithm with pseudocode shown in Figure 3.
We carry out preliminary evaluation of the ranking with diversity objective on the Netflix dataset. Although this is Figure 4: The Distribution of ILD values for N =10 randomly selected items from Netflix not an implicit rating dataset, it has previously been used for evaluation of RankALS and RankSGD in [6], so it is pos-sible to compare the results we obtain with these previous results. The Netflix training set consists of 100,480,507 rat-ings ranging from 1 to 5 from 480,189 users on 17,770 items. Following [6], we defined the implicit rating matrix by as-signing 1 to user-items pairs with rating values of 5 and 0 to all other user-item pairs. We trained using the Netflix train-ing set with the probe set removed (containing 22,783,659 implicit ratings) and we tested on the probe set (containing 384,573 implicit ratings).
To evaluate the performance of the ranking in terms of relevance, we use the errorrate metric as proposed in Track 2 of the 2011 KDD cup [1]. To apply this metric, for each user u , the test set consists of two sets of items I + u containing items for which u has given positive and negative feedback. I  X  u is created by drawing |I + u | items randomly with probability proportional to |U i | .Theitemsin I + u are ranked using the predicted rating and the errorrate is the proportion of the top |I + u | ratings that are not from A lower errorrate implies better performance. To evaluate the diversity of the recommended sets, we use the ILD of the top N items, obtained by ranking all I X  X  + u items using the predicted ratings. We evaluate using N = 10.
In the presented evaluation, we use a distance matrix D based on item profile distance. In particular, we obtain the similarity matrix S as the normalised dot product of item profiles: where E is a diagonal matrix with diagonal elements e i = this leads to generally low similarity values (and consequently very high pairwise distances). To obtain a greater spread of diversity values, the similarity values are filtered through the sigmoidal function tanh(  X s ), where we take  X  = 20. The resulting distribution of ILD values of sets of N =10 items selected uniformly at random from the 17,770 items in Netflix is shown in Figure 4.
In [6] it is stated that an item importance weighting pro-portional to the item popularity is appropriate when the errorrate measure is being optimised. Hence, we take s j = Figure 5: The Distribution of ILD values for N =10 items selected by ranking with diversity f RD ( X ) Figure 6: The Distribution of ILD values for N =10 randomly selected by ranking with f R ( X ) |U j | / max |U j | . We compare the RandSGD algorithm run to convergence with  X  =0 . 008 to minimise the ranking objec-tive f R ( X ) with the same algorithm used to minimise the ranking with diversity objective f RD ( X ). The results are summarised in Table 1. The distribution of ILD values ob-tained from the ranking with diversity objective is shown in Figure 5 and the distribution obtained from optimising f ( X ) is shown in Figure 6. It is clear that ranking with diversity obtains much more diverse recommendation sets at some cost to performance in terms of relevance. As the raw ILD values are dependent on the distance matrix, it is informative to look at the results in terms of percentiles of the distributions. For instance, the 80 th percentile of the distribution of ILD values of randomly selected sets, cor-responds to the 79 th percentile of the ILD values obtained when only relevance is considered. However, it is only the 36 th percentile of the distribution of ILD values obtained by ranking with diversity. Ranking with diversity is highly biased towards highly diverse recommendations.

Preliminary results with the ranking with diversity ob-jective are encouraging and further evaluations on other datasets will follow. Other formulations for incorporating diversity within ranking objectives will be considered in fu-ture work.
This publication has emanated from research conducted with the financial support of Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289 [1] G. Dror, N. Koenigstein, Y. Koren, and M. Weimer. [2] Y. Hu, Y. Koren, and C. Volinsky. Collaborative [3] M. Jahrer and A. T  X  oscher. Collaborative filtering [4] I. Pil  X  aszy, D. Zibriczky, and D. Tikk. Fast als-based [5] S. Rendle, C. Freudenthaler, Z. Gantner, and [6] G. Tak  X acs and D. Tikk. Alternating least squares for [7] S. Vargas and P. Castells. Rank and relevance in [8] M. Zhang and N. Hurley. Avoiding monotony: [9] M. Zhang and N. Hurley. Niche product retrieval in [10] C. Ziegler, S. M. McNee, J. A. Konstan, and
