 ABSTRACT An important issue in visualizing categorical data is how to order categorical values. The focus of this paper is on constructing such orderings efficiently without compromising their visual quality. 1. INTRODUCTION 
Visual representation has become increasingly important for the analysis and exploration of large collections of mul-tidimensional data [14, 5, 1], because visual perception is remarkably good at identifying spatial relationships. The goal is to present the information in such a way that re-veals interesting trends present in the data. Many domains contain categorical attributes, for example, host names in system management data or city names in census data. The lack of a natural ordering of categorical values makes it diffi-cult to use standard visual techniques such as scatter plots or parallel coordinate plots: there are exponentially many ways in which the values can be totally ordered (and thus mapped to the axes in the visual space), and each ordering provides a different visual quality. To illustrate the importance of having a proper ordering, consider a dataset [12] contain-ing over 10,000 events of 20 types, generated by 160 hosts in a three-day period. Figure 1 shows two different scat-ter plots with the x-axis denoting the time of an event and the y-axis representing the host that generated the event. The ordering on the y-axis in Figure la) is a random per-mutation of host names, while the ordering in Figure lb) was constructed algorithmically. Although the plots illus-trate the same dataset, they provide qualitatively different visualizations (see Section 4). 
Although the problem has been studied before [12, 11, 2], efficiency and accuracy issues have not been adequately ad-dressed due to the inherent complexity of the problem. First, a natural discrete formulation is NP-hard; hence finding the personal or classroom use is granted without lee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish X  to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. KDD 01 San Francisco CA LISA Copyright ACM 2001 1-58113-391-x/01/08...$5.00 ing over 10,000 events of 20 different types generated 160 hosts in a three-day period. exact solution in most likely infeasible. Second, an effective visualization must use geometric (visual) proximity to cap-ture the relationships between data objects, so that similar objects are placed near each other in the ordering. Any al-gorithm that explicitly computes this underlying similarity matrix, inevitably has quadratic complexity, and thus scales poorly X  
In order to avoid the inherent intractability of previous for-mulations, we relax the discreteness constraint and consider the corresponding continuous optimization problem solvable exactly using the spectral method [9]. Such continuous re-laxations have been successfully used in various contexts, e.g. graph partitioning [10], sparse matrix reordering [3], cluster-ing [7]. Finding the spectral information, however, is rather expensive (superlinear). To reduce the complexity, we use a multi.level approach. The data is modeled as a graph. First, the original graph is approximated by a sequence of increas-ingly coarser graphs. Then the coarsest instance is ordered using the spectral algorithm. Finally, the ordering is propa-gated back by interpolating through the sequence of interme-diate graphs. Real data is usually highly over-determined, i.e. contains multiple values with almost identical similarity structures. The multilevel approach emerges very naturally in this context: the coarsening hides all unimportant, re-dundant details about the graph, while preserving only the most crucial connectivity information. Moreover, the spec-tral method is particularly good at capturing global proper-ties of graphs. On a finer level, however, it is often worse tices, and, as a result, is not particularly good at capturing when the size and the complexity of the dataset is large. of projecting high-dimeusional data onto a low-dimensional space that itself can be used as a visual representation of the data. However, there is a fundamental difference between the objective of ordering and the goal of projection methods 240 where f3 denotes the sequence intersection (sequences are treated as multi-sets). In our example, "yl (G, H) = 4/5, while ~fl(F, G) = 2/5 and ~/2(F, H) = 1/3. 
We are also interested in the inter-attribute similarity func-tion 7tJ : Dt x Dj -~ [(3, 1], which captures the similarity of y E D~, we define For example, the similarity of host F and event type a is ")'12(F, a) ----1/3. 
We associate the dataset with its underlying pairwise sim-ilarity graph, where the vertices represent the values to be ordered. Notice that the vertices may represent the values of different attributes. We call such graphs heterogeneous. The weight of an edge corresponds to the similarity of its end-points; if both end-points represent the values of the same attribute (e.g. both are hosts), then the intra-attribute simi-laxity is used; otherwise, we use the inter-attribute similarity. This representation allows to visually explore the relations between different values not only within the same attribute, but also across the attributes. Section 2.3 discusses how to use the heterogeneous representation to order the values of multiple categorical collections simultaneously. 
Given a categorical attribute A with domain D and the inter-attribute similarity function 7 : D x D ~ [0, 1], the goal of the linear ordering problem is to find a permutation of D such that Clearly, the above formulation encourages similar values to be in close positions in the permutation. 
Most real datasets have multiple categorical attributes. It is important to order these categorical sets in such a way that not only is each ordering good, but the orderings are also good in respect to each other~ i.e., the orderings have to be consistent with each other, so that they can be used together in constructing effective visualizations (for example, in parallel coordinate plots). In order to extend the ordering algorithm to multiple categorical attributes, we propose to create a "heterogeneous" linear ordering that represents a mapping of all (or a subset of) attributes onto a single line. We use our example to make this notion clear. Instead of ordering host names and event types independently, we map their values to the set of objects {or = F, 02 = G,03 = H, 04 = a, 05 = b, oo = c}. Now the problem simply reduces to the problem of ordering a single set of values. Once the ordering has been constructed, it can be mapped back to the original values in an obvious way. For example, to obtain the ordering of host names one would simply filter out the ordering of objects corresponding to host names, i.e. the ordering of 01, 02, o3. Notice that since we defined both inter-attribute and intra-attribute notions of similarity, the similarity between objects is well defined. 
This allows us to focus on the single-attribute case. Hence, in what follows, we may assume that we have a set of objects defined on pairs of objects from 8. Two points a, b E S are said to be e-close if 7(a, b) ~_ 1 -e. 
As we discussed in the introduction, the discrete formu-lation (1) is NP-hard; hence the solution is not likely to be obtained efficiently. To avoid the combinatorial complexity, we allow the coordinates (the values of ~r) in Equation (1) to be real. This yields a continuous optimization problem of finding a real placement vector x = [xl .... ,xn] (where x~ is the placement of the i-th point) minimizing the weighted sum of squared distances between the points, x=argmxm~ E "/(i,j)(xi-xj) 2, such that Ex~ = 1. A normalization constraint is needed in order to avoid a triv-ial solution when all the points axe mapped to zero. Clearly, the above formulation encourages related points to be near each other on the line, while pushes dissimilar points apart. Hall [9] showed that the solution of the above problem is just the second eigenvector of the weighted Laplacian ma-trix associated with the similarity graph of the data. Even though mapping the solution of the continous problem to the closest discrete point does not necessarily yield the opti-mal discrete solution, it provides a good approximation [3]). However, finding the eigenvectors is rather expensive. More-over, even before computing the eigenvectors, the algorithm has to compute the underlying similarity matrix of the data, which is infeasible for large datasets. 
The efficiency of our algorithm is based on the following key ideas. The first is to reduce the size of the dataset by coalescing (not necessarily disjoint) subsets of similar points. This serves two purposes. First, the spectral algorithm has be run on a much smaller set of points, which significantly reduces the complexity. Second, by absorbing groups of sim-ilar points, we guarantee that these points will be in close positions in the final ordering X  The second idea is to avoid the quadratic complexity of explicitly computing all pair-wise similarities by constructing an implicit representation that approximates the underlying similarity matrix. An im-portant observation is that only a linear number of similar-ities (instead of quadratic) have to be computed in order to coarsen and order the dataset. In other words, in order to obtain a high-quality ordering of points, we do not actually have to compute most pairwise similarities. We also show that a sample of size independent of the size of the dataset is sufficient to approximate the adjacencies of most points, allowing to answer neighborhood queries in constant time. The algorithm proceeds in three phases: First, the original dataset is coarsened. Once the dataset is sufficiently small, it is ordered using the spectral algorithm. Notice that this requires the original spectral algorithm to be extended to multi-vertices, which can be done by incorporating vertex weights into the normalization constraint. Finally, the re-sulting ordering of the reduced dataset is uncearsened and refined. repeat cC 1 ln(2c/6e) times: 
Figure 2: A new canopy construction 
In this example, the size of each canopy is at most 4, i.e. 
Now we are no longer guaranteed tllat each point appears 
NOW instead of sampling 
Once the coarse graph is constructed, the spectral ordering 
Two datasets are used to test the effectiveness of our al-
Figure 5 shows the adjacency matrices of this dataset. If 
Our second dataset contains events collected from a pro-
We have presented an efficient multMevel algorithm for or-visualization g~ exploration environment. In IEEE Symposium on information visualization, 1995. clustering of dimensions for an enhanced visualization of multidimensional data. In IEEE Symposium on Information Visualization, pages 52-60, 1998. algorithm for envelope reduction of sparse matrices. 
Numerical linear algebra with applications, 2(4):317-334, 1995. [4] G. S. Davidson, B. Hendrickson, D. K. Johnson, C. E. Meyers, and B. N. Wylie. Knowledge mining with VxInsight: Discovery through interaction. Journal of 
Intelligent Information Systems, 11:259-279, 1998. [5] M. Derthick, J. A. Kolojejchick, and S. F. Roth. An interactive visualization environment for data exploration. 
In Proceedings of knowledge discovery in databases, 1997. [6] S. Diamond. http://www.spss.com/software/diamond. [7] P. Drineas) R. Kannan, A. Frieze, S. Vempala, and V. Vinay. Clustering in large graphs and matrices. In Proceedings of the lOth A CM-SIAM Symposium on 
Discrete Algorithms, 1999. [8] C. Faloutsos and K.-I. D. Lin. Fastmap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets. In Proceedings of the 1995 A CM SIGMOD International Conference on Management of 
Data, pages 163-174, 1995. [9] K. M. Hall. An r-dimensional quadratic placement algorithm. Management Science, 17(3):219-229, 1970. partitioning algorithm for mapping parallel computations. 
SIAM Journal on Scientific Computing, 16(2):452-469, 1995. categorical attributes to better visualize multidimensional data. Technical Report YO1%8-1999-0237, IBM, 1999. improve visualization. In Proceedings of the IEEE 
Symposium on Information Visualization, 1999. of high-dimensional data sets with application to reference matching. In KDD, pages 169-178, 2000. multivariate data. In Proceedings of Visualization, 1994. 
