 The noisy-or and noisy-and-not conditional probability distributions are frequently studied in cog-nitive science for modeling causal reasoning [1], [2],[3] and are also used as probabilistic models for artificial intelligence [4]. It has been shown, for example, that human judgments of the power of causal cues in experiments involving two cues [1] can be interpreted in terms of maximum likelihood estimation and model selection using these types of models [3].
 But the noisy-or and noisy-and-not distributions are limited in the sense that they can only represent a restricted set of all possible conditional distributions. This restriction is sometimes an advantage because there may not be sufficient data to determine the full conditional distribution. Nevertheless it would be better to have a representation that can expand to represent the full conditional distribution, if sufficient data is available, but can be reduced to simpler forms (e.g. standard noisy-or) if there is only limited data.
 This motivates us to define the noisy-logical distribution. This is defined in terms of noisy-or X  X  and noisy-and-not X  X  of causal features which are conjunctions of the basic input variables (inspired by the use of conjunctive features in [2] and the extensions in [5]). By restricting the choice of causal features we can obtain the standard noisy-or and noisy-and-not models. We prove that the noisy-logical distribution is complete in the sense that it can represent any conditional distribution provided we use all the causal features. Overall, it gives a distribution whose complexity can be adjusted by restricting the number of causal features.
 To illustrate the noisy-logical distribution we apply it to modeling some recent human experiments on causal reasoning in complex environments [6]. We show that noisy-logical distributions involv-ing causal factors are able to account for human performance. By contrast, an alternative linear model gives predictions which are the opposite of the observed trends in human causal judgments. Section (2) presents the noisy-logical distribution for the case with two input causes (the case com-monly studied in causal reasoning). In section (3) we specify the full noisy-logical distribution and we prove its completeness in section (4). Section (5) illustrates the noisy-logical distribution by showing that it accounts for recent experimental findings in causal reasoning. In this section we study the simple case when the binary output effect E depends only on two binary-valued causes C 1 , C 2 . This covers most of the work reported in the cognitive science literature for C 1  X  X  0 , 1 } , C 2  X  X  0 , 1 } .
 To define the noisy-logical distribution over two variables P ( E = 1 | C 1 , C 2 ) , we introduce three C ,  X  3 ( ~ C ) = C 1  X  C 2 , where  X  denotes logical-and operation(i.e. C 1  X  C 2 = 1 if C 1 = C 2 = 1 and C 1  X  C 2 = 0 otherwise).  X  3 ( which we write in form  X  E,f ( E combination of three logic operations AND, OR, NOT . This induces the noisy-logical distribution P nl ( E | The noisy-logical distribution is characterized by the parameters  X  0 , ...,  X  3 and the choice of the corresponding causal features  X  0 , ...,  X  3 , as shown in Figure (1).
 The noisy-logical distribution includes the commonly known distributions, noisy-or and noisy-and-not, as special cases. To obtain the noisy-or, we set E = E 1  X  E 2 (i.e. E 1  X  E 2 = 0 if E 1 = E 2 = 0 and E 1  X  E 2 = 1 otherwise). A simple calculation shows that the noisy-logical distribution reduces to the noisy-or P nor ( E | C 1 , C 2 ;  X  1 ,  X  2 ) [4], [1]: P nl ( E = 1 | C 1 , C 2 ;  X  1 ,  X  2 ) = To obtain the noisy-and-not, we set E = E 1  X   X  E 2 (i.e. E 1  X   X  E 2 = 1 if E 1 = 1 , E 2 = 0 and E 1  X   X  E 2 = 0 otherwise). The noisy-logical distribution reduces to the noisy-and-not P ations AND-NOT, OR. The parameters of the distribution are given by  X  0 ,  X  1 ,  X  2 ,  X  3 . The proof of this claim will be given for the general case in the next section. To get some insight, we consider the special case where we only know the values P ( E | C 1 = 1 , C 2 = 0) and P ( E | C 1 = 1 , C 2 = 1) . This situation is studied in cognitive science where C 1 is considered to be a background cause which always takes value 1 , see [1] [3]. In this case, the only causal features are considered,  X  Result . The noisy-or and the noisy-and-not models, given by equations (1,2) are sufficient to fit any P ( E = 1 | C 1 = 1 , C 2 = 0) and use P ( E = 1 | 1 , 1) to denote P ( E = 1 | C 1 = 1 , C 2 = 1) .) The noisy-or and noisy-and-not fit the cases when P ( E = 1 | 1 , 1)  X  P ( E = 1 | 1 , 0) and P ( E = preventative cause).
 Proof. We can fit both the noisy-or and noisy-and-not models to P ( E | 1 , 0) by setting  X  1 = P ( E = 1 | 1 , 1) = P ( E = 1 | 1 , 0) . Hence we must fit a noisy-or and a noisy-and-not model to cases (i) model by setting  X  2 = 0 . We next consider representing probability distributions of form P ( E | ~ C ) , where E  X  { 0 , 1 } and ~ the values of P ( E = 1 | ~ C ) for all possible 2 N values of ~ C .
 of C 1 and C 2 , and so on. The feature  X ( ~ C ) = C a  X  C b  X  ...  X  C g will take value 1 if C a = C b = ... = C g = 1 and value 0 otherwise.
 0 , ..., 2 N  X  1 } .
 i = 0 , ..., 2 N  X  1 } . This can be thought of as a circuit diagram. In particular, we define E = (where  X  E means logical negation). This gives the general noisy-logical distribution , as shown in Figure (2).
 distribution. This is the main theoretical result of this paper. Figure 2: Circuit diagram in the case with N causes. All conditional distributions can be represented in this form if we use all possible 2 N causal features  X  , choose the correct parameters  X  , and select the correct logical combinations  X  .
 Result We can represent any conditional distribution P ( E | ~ C ) defined on binary variables in terms of a noisy logical distribution given by equation (3).
 Proof. The proof is constructive. We show that any distribution P ( E | ~ C ) can be expressed as a noisy-logical distribution.
 This ordering can be obtained by setting ~ C 0 = (0 , ..., 0) , then selecting the terms with a single non-zero), then with three conjunctions, and so on.
 The strategy is to use induction to build a noisy-logical distribution which agrees with P ( E | ~ C ) three cases to consider which are analogous to the cases considered in the section with two causes. we obtain: 1 | ~ that  X  M +1  X  [0 , 1] ).
 Then we obtain: 1 | ~
C i ) for i &lt; M + 1 (because  X  M +1 ( ~ C i ) = 0 ,  X  i &lt; M + 1 ). To determine the value of  X 
M +1 we must solve P ( E = 1 | 1 | ~ C M +1 ) } /P ( E M = 1 | ~ C M +1 ;  X  0 , ...,  X  M ) (the conditions ensure that  X  M +1  X  [0 , 1] ). Case 3. If P ( E = 1 | ~ C M +1 ) = P ( E M = 1 | ~ C M +1 ;  X  0 , ...,  X  M ) , then we do nothing. We illustrate noisy-logical distributions by applying them to model two recent cognitive science experiments by Liljeholm and Cheng which involve causal reasoning in complex environments [6]. In these experiments, the participants are asked questions about the causal structure of the data. But the participants are not given enough data to determine the full distribution (i.e. not enough to determine the causal structure with certainty). Instead the experimental design forces them to choose between two different causal structures.
 We formulate this as a model selection problem [3]. Formally, we specify distributions P ( D | ~ X , Graph ) for generating the data D from a causal model specified by Graph and parameter-ized by ~ X  . These distributions will be of simple noisy-logical form. We set the prior distributions P ( ~ X  | Graph ) on the parameter values to be the uniform distribution. The evidence for the causal model is given by: Graph 2 , called the causal support [3] and use this to predict the performance of the participants. This gives good fits to the experimental results.
 As an alternative theoretical model, we consider the possibility that the participants use the same causal structures, specified by Graph 1 and Graph 2 , but use a linear model to combine cues. Formally, this corresponds to a model P ( E = 1 | C 1 , ..., C N ) =  X  1 C 1 + ... +  X  N C N (with  X  i  X  0 ,  X  i = 1 , ..., N and  X  1 + ... +  X  N  X  1 ). This model corresponds [1, 3] to the classic Rescorla-Wagner learning model [8]. It cannot be expressed in simple noisy-logical form. Our simulations show that this model does not account for human participant performance . We note that previous attempts to model experiments with multiple causes and conjunctions by Novick and Cheng [2] can be interpreted as performing maximum likelihood estimation of the pa-rameters of noisy-logical distributions (their paper helped inspire our work). Those experiments, however, were simpler than those described here and model selection was not used. The extensive literatures on two cases [1, 3] can also be interpreted in terms of noisy-logical models. 5.1 Experiment I: Multiple Causes In Experiment 1 of [6], the cover story involves a set of allergy patients who either did or did not have a headache, and either had or had not received allergy medicines A and B . The experimental participants were informed that two independent studies had been conducted in different labs us-ing different patient groups. In the first study, patients were administered medicine A , whereas in the second study patients were administered both medicines A and B . A simultaneous presenta-tion format [7] was used to display the specific contingency conditions used in both studies to the experimental subjects. The participants were then asked whether medicine B caused the headache. able E indicates whether a headache has occurred ( E = 1 ) or not ( E = 0 ). B 1 = 1 and B 2 = 1 no-tate background causes for the two studies (which are always present). C 1 and C 2 indicate whether medicine A and B are present respectively (e.g. C 1 = 1 if A is present, C 1 = 0 otherwise). The data D shown to the subjects can be expressed as D = ( D 1 , D 2 ) where D 1 is the contingency table P ( E = 1 | B 1 = 1 , C 1 = 0 , C 2 = 0) , P d ( E = 1 | B 1 = 1 , C 1 = 1 , C 2 = 0) for the first study 1 , C 2 = 1) for the second study.
 The experimental design forces the participants to choose between the two causal models shown on the left of figure (3). These causal models differ by whether C 2 (i.e. medicine B ) tions in form P ( D i | ~ X  i , Graph ) = tributions.
 For Experiment 1 there are two conditions [6], see table (1). In the first power-constant condition [6], the data is consistent with the causal structure for Graph 1 (i.e. C 2 has no effect) using noisy-or distributions. In the second  X  P-constant condition [6], the data is consistent with the causal structure for Graph 1 but with noisy-or replaced by the linear distributions (e.g. P ( E = 1 | C 1 , ..., C n ) =  X  C 1 + ... +  X  n C n ) ).
 (1) P d ( E = 1 | B 1 = 1 , C 1 = 0 , C 2 = 0) , P d ( E = 1 | B 1 = 1 , C 1 = 1 , C 2 = 0) 16/24, 22/24 (2) P d ( E = 1 | B 1 = 1 , C 1 = 0 , C 2 = 0) , P d ( E = 1 | B 1 = 1 , C 1 = 1 , C 2 = 0) 0/24, 6/24 5.2 Experiment I: Results We compare Liljeholm and Cheng X  X  experimental results with our theoretical simulations. These comparisons are shown on the right-hand-side of figure (3). The left panel shows the proportion of participants who decide that medicine B causes a headache for the two conditions. The right panel shows the predictions of our model (labeled  X  X oisy-logical X ) together with predictions of a model that replaces the noisy-logical distributions by a linear model (labeled  X  X inear X ). The simu-lations show that the noisy-logical model correctly predicts that participants (on average) judge that medicine B has no effect in the first experimental condition, but B does have an effect in the second condition. By contrast, the linear model makes the opposite (wrong) prediction. In summary, model selection comparing two noisy-logical models gives a good prediction of participant performance. Figure 3: Causal model and results for Experiment I. Left panel: two alternative causal models for the two studies. Right panel: the experimental results (proportion of patients who think medicine B causes headaches)) for the Power-constant and  X  P-constant conditions [6]. Far right, the causal support for the noisy-logic and linear models. 5.3 Experiment II: Causal Interaction Liljeholm and Cheng [6] also investigated causal interactions. The experimental design was identical to that used in Experiment 1, except that participants were presented with three studies in which only one medicine ( A ) was tested. Participants were asked to judge whether medicine A interacts with background causes that vary across the three studies. We define the background causes as B 1 , B 2 , B 3 for the three studies, and C 1 for medicine A . This experiment was also run under two different conditions, see table (2). The first power-constant condition [6] was consistent with a noisy-logical model, but the second power-varying condition [6] was not.
 The experimental design caused participants to choose between two causal models shown on the All the distributions are noisy-or on the unary causal features (e.g. B, C 1 ), but the nature of the conjunctive cause B  X  C 1 is unknown (i.e. not specified by the experimental design). Hence our theory considers the possibilities that it is a noisy-or (e.g. can produce headaches) or noisy-and-not (e.g. can prevent headaches), see graph 2 of Figure (4). 5.4 Results of Experiment II Figure (4) shows human and model performance for the two experimental conditions. Our noisy-logical model is in agreement with human performance  X  i.e. there is no interaction between causes in the power-constant condition, but there is interaction in the power-varying condition. By contrast, the linear model predicts interaction in both conditions and hence fails to model human performance. Figure 4: Causal model and results for Experiment II. Left panel: two alternative causal models (one involving conjunctions) for the three studies . Right panel: the proportion of participants who think that there is an interaction (conjunction) between medicine A and the background for the power-constant and power-varying conditions [6]. Far right, the causal support for the noisy-logical and linear models. the set of causal factors. If all the causal factors are allowed, then the distribution can represent distributions such as the noisy-or and noisy-and-not.
 We illustrated the noisy-logical distribution by modeling experimental findings on causal reasoning. Our results showed that this distribution fitted the experimental data and, in particular, accounted for the major trends (unlike the linear model). This is consistent with the success of noisy-or and noisy-and-not models for accounting for experiments involving two causes [1], [2],[3]. This suggests that humans may make use of noisy-logical representations for causal reasoning.
 One attraction of the noisy-logical representation is that it helps clarify the relationship between logic and probabilities. Standard logical relationships between causes and effects arise in the limit as the  X  i take values 0 or 1 . We can, for example, bias the data towards a logical form by using a prior on the ~ X  . This may be useful, for example, when modeling human cognition  X  evidence suggests that humans first learn logical relationships and, only later, move to probabilities. In summary, the noisy-logical distribution is a novel way to represent conditional probability distri-butions defined on binary variables. We hope this class of distributions will be useful for modeling cognitive phenomena and for applications to artificial intelligence.
 We thank Mimi Liljeholm, Patricia Cheng, Adnan Darwiche, Keith Holyoak, Iasonas Kokkinos, and YingNian Wu for helpful discussions. Mimi and Patricia kindly gave us access to their experimental data. We acknowledge funding support from the W.M. Keck foundation and from NSF 0413214. [1] P. W. Cheng. From covariation to causation: A causal power theory. Psychological Review, [2] L.R. Novick and P.W. Cheng. Assessing interactive causal influence. Psychological Review, [3] T. L. Griffiths, and J. B. Tenenbaum. Structure and strength in causal induction. Cognitive [4] J. Pearl, Probabilistic Reasoning in Intelligent Systems. Morgan-Kauffman, 1988. [5] C.N. Glymour. The Mind X  X  Arrow: Bayes Nets and Graphical Causal Models in Psychology. [6] M. Liljeholm and P. W. Cheng. When is a Cause the  X  X ame X ? Coherent Generalization across [7] M. J. Buehner, P. W. Cheng, and D. Clifford. From covariation to causation: A test of the [8] R. A. Rescorla, and A. R. Wagner. A theory of Pavlovian conditioning: Variations in the effec-
