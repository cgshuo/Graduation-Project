 member of I is a literal called an item, and any set of these literals is called an itemset. into n mutually exclusive groups. The concept of an itemset can be extended to a contrast-set as follows: 
Definition 1. Let Al,Aa,. . . ,Ak be a set of k variable8 called attributes. Each Ai can take on values from the set {K/;:1, I&amp;, . . . , I&amp;}. Then a contrast-set is a conjunction of attribute-value pairs defined on groups Gi, G2, . . . , G,. 
We define the support of a contrast-set with respect to a group G as follows: 
Definition 2. The support of a contrast-set with respect to a group G is the percentage of examples in G where the contrast-set is true. 
Our goal is to find all contrast-sets whose support differs meaningfully across groups. Formally, we want to find those contrast-sets (cset) where: 3ij P(cset = True 1 Gi) # P(cset = True 1 Gj) (1) and mindev is a user defined threshold. We call contrast-sets where Equation 1 is statistically valid significant, and contrast-sets where Equation 2 is met large. If both requirements are met, then we call it a deviation. 
We treat the problem of mining contra&amp;-sets as a tree search problem. The root node is an empty contrast-set, and we generate children of a node by specializing the set by adding one more term. We use a canonical ordering of attributes to avoid visiting the same node twice [9]. Children are formed by appending terms that follow all existing terms in a given ordering. 
For example, consider an artificial domain with two attributes, A1 = {Vll,Vl2} and A2 = {V21,V22}, each with two possible values. Figure 2 shows the resulting search tree and enumerates every possible subset of values for A1 and AZ. Nodes 3 and 4 have no children because A2 comes after Al in our ordering. 
We search this tree in a breadth-first, levelwise manner, Given all nodes at a level, we scan the database and count their support for each group and then examine each node to determine if it is significant Figure 2: Example of the search tree for two Attributes 
A1 = {VII, F/12} and Aa = {I&amp;, I&amp;}. and large, if it should be pruned, and if children should be generated. Figure 3 outlines the STUCCO (Search and Testing for Understandable Consistent Contrasts) algorithm. Section 3.1 explains the significance testing used. Section 3.2 describes pruning. 
After finding all significant contrast-sets in the data, we then process the result8 and select a subset to show to the user. We display the low order result8 first, which are simpler, and then show only the higher order results that are surprising and significantly different. This is described in Section 3.3. 
Figure 3: STUCCO: Search and Testing for Under-standable Consistent Contrasts 
We can check if a contrast-set is significant by testing the null hypothesis that contrast-set support is equal across all groups or, alternatively, contrast-set support 
The support counts from each group is a form of frequency data which can be analyzed in contingency tables. We form a 2 x c contingency table where the row variable represents the truth of the contrast-set, and the column variable indicates the group membership. 
For example, consider the top admitted students at UC1 as measured by SAT Verbal scores (SATV &gt; 700) and their school of admission (Arts, Biology, Engineering, Information and Computer Science, and Social Ecology) : 
If SATV and UC1 School are independent variables, then we would expect the proportion of students with high SATV scores to be roughly equal across all groups. 
Clearly, the proportions are not equal and vary from a high of 10.7% for ICS to a low of 2.6% for Social Ecology. 
We need to determine if the differences in proportions represent a true relation between the variables or if it can be attributed to random causes. 
The standard test for independence of variables in contingency tables is the chi-square test. It works by computing the statistic x2: where Ojj is the observed frequency count in cell ij, and Eij IS the expected frequency count in cell ij given independence of the row and column variables and is calculated as follows: Eij = Cj Oij CiOij/N with 
N being the total number of observations. We then compare the result to the distribution of x2 when the null hypothesis is true. 
To determine if the differences in proportions are significant, we first pick a test o level. The choice of 
Q sets the maximum probability of rejecting the null hypothesis when it is true. For a single test, cr is commonly set to 0.05. We then calculate that x2 = 35.4 with 4 degrees of freedom and has a p-value of 3.8e-7. 
Since the p-value is less than the 0.05 cutoff, we can infer that the null hypothesis is likely false. 
With a single test, Q sets the maximum probability of falsely rejecting the null hypothesis. However, with multiple tests, the probability of false rejection can be highly inflated. This is especially true in data mining, where often thousands, or millions, of hypotheses are tested. For example, if the null hypothesis is always true and we made 1000 tests each at o = 0.05, we would obtain on average 50  X  X ignificant X  differences. Falsely rejecting the null hypothesis, i.e., concluding that there is a difference when none exists, is known as a Type I error or false positive. 
Type I error can be controlled for a family of tests by using a more stringent CY cutoff for the individual tests. 
We can relate the oi levels used for each individual test to a global cr (the expected error rate) by using the Bonferroni inequality: given any set of events el,e2 ,..., en, the probability of their union (ei V e2 V probabilities. Applied to hypothesis testing, we let ei be the rejection of the ith hypothesis hi. Then we reject hi if pi 5 (Y; where ci oi 5 o. Usually oi = o/n, where n is the total number of tests. 
This method controls the error rate per family (PFE), which is th e expected number of false rejections (PFE 5 a), for any combination of true or false hypotheses and holds even with dependent tests [lo]. 
There are two problems with applying this: (1) If we are reporting results incrementally after we mine each level, we do not know how many tests we will make in total. Thus, n is unknown. (2) We use the same cutoff for testing a conjunction of size 1 as size 10. This is undesirable because as CY~ gets smaller, we lose power and are less able to detect a difference if it exists. This is an unavoidable tradeoff, as power is related to Type I error. Since lower order conjuncts are more general, we would like more power on those tests. Because the Bonferroni method holds as long as Ci oi 5 Q, we can use different oi for tests at different levels of the search tree as follows: where CY~ is the cutoff for level 1, and 191 is the number of candidates at level 1. This apportions l/2 of the total on. The minimum requirement ensures that the test (Y levels always become more stringent. We prune a node on the search tree when all specializa-tions of that node can never be a significant and large contrast-set. This is similar to subset-infrequency prun-ing used by Apriori [2] and Max-Miner [3]. Nodes are pruned based on: (1) minimum deviation size, (2) ex-pected cell frequencies, and (3) x2 bounds. 
Minimum Deviation Size: The deviation size of a contrast-set is the maximum difference between the support of any two groups. We require that this difference is greater than the threshold mindev. This can only occur in the children of a node if the support for at least one group is greater than mindev. 
Expected Cell Frequencies: The expected cell frequencies in the top row of the contingency table can only decrease as we specialize the contrast-set. This is important because the validity of the chi-square test depends on approximating the distribution of the x2 statistic with the chi-square distribution. When the test is invalid, we prune the node because we cannot make valid inferences. The approximation is made under the assumption that the expected cell frequencies are not  X  X oo small. X  Typically, expected values of 5 are considered satisfactory [7]. x2 Bounds: We find an upper bound on the x2 statistic for any child of a node and use this to prune candidates when it is no longer possible for specializations to meet the x2 cutoff implied by (YI. 
The x2 contribution from each cell is a function of the observed and expected cell counts where Eij = xi 0i.j cj Oij/N. Notice that the column sum and N are fixed; therefore let f = Cj Oij/N. We can also break the row sum up into two components: 0, the observed value in cell ij, and R = zik,kfj Oik, the sum of the remainder of the row. Thus Eij = f(0 + R) , and the x2 contribution from cell ij is: Then the following theorem applies to the x2 statistic: 
Theorem. If 0 is bounded by [Onairar O,,,] and R by [Gin 9 Gas], then the following is an upper bound on the x2 statistic obtainable in any specialization: 
Proof. We find a maximum value for x2 by maximizing the contribution from each cell. xf;(O, R) is a function of two variables where the feasible region is rectangular and in Quadrant I. The partial derivatives  X  X fj(O,R) aX?j(OzR) the?? the observed count). Also the lim&amp;+e+,R+e+ = 0. 
Since xt is clearly positive, and there are no relative maxima in the feasible region, then the function max-imum must occur on a boundary point. Furthermore, the maximum must occur at a corner, since our feasible region is rectangular.0 
As we mine contrast-sets, we only present those sets which are surprising given what we have already shown. 
For example, consider that we know P(sex=male 1 PhD) under independence of sex and occupation we expect 0.14 = 0.113. Similarly, we expect the probability of being a male-manager is 0.173 for Bachelor holders. 
The actual proportions for male managers are 0.109 (Ph.D.) and 0.190 (Bachelor), which are very close to our expected results, and thus are not surprising. So although male-managers is a deviation, we do not show it to the user. 
This example was simple and only involved two vari-ables which we assumed were independent. However, we can use this general approach for larger and more complicated sets of variables; i.e., we find the maximum likelihood estimates for a conjunction of variables based on its subsets by using iterative proportional fitting [7]. 4 Evaluation We evaluated STUCCO on two datasets: the Adult Census data from the UC1 Repository of Machine Learning Databases [4] (originally from the US Census 
Bureau), and UC1 Admissions Data. We will first present pruning results, and then we will show practical results with examples of mined deviations. 
The Adult Census data has 48842 records and 14 variables such as age, working class, education, sex, hours worked, salary, etc. The UC1 Admissions data describes applicants to the University of California at 
Irvine. There are 6 years of data from 1993-98 with about 17000 applicants per year. The data contains 17 variables such as ethnicity, school, sex, home location, first language, GPA, SAT scores, etc. For both databases, continuous attributes were discretized into approximately equal sized intervals. 
We compared two pruning strategies: (1) using the minimum deviation size only -this is equivalent to extending Apriori subset infrequency pruning to handle multiple groups, and (2) using all pruning methods: minimum deviation size, expected cell frequencies, and x2 bounds. The last two pruning methods can only be used with contrast-sets as they require frequency counts from all groups in the data. 
Figure 4 shows the number of candidates counted at each level for two different data sets (mindev = 0.05). In both cases the additional pruning methods (expected cell frequencies and x2 bounds) significantly reduced the number of candidates that were evaluated. 
In (b) deviation size pruning ran out of memory. Figure 4: Effectiveness of pruning strategies: (a) 
Bachelor vs. Ph.D. degree recipients, (b) comparison of UC1 Schools for 1998. 
For the Adult Census data we asked,  X  X hat are the differences between people with Ph.D. and Bachelor de-grees? X  (mindev = l%, cr = 0.05). Table la summarizes the number of candidates, deviations (significant and large contrast-sets), and surprising sets found at each level. Table lb shows several mined contrast-sets. 
We found over 10000 deviations; however, most were not surprising given their subsets. Thus we reduced the number of returned sets to only 164. In contrast, other mining systems tend to return far more results. Apriori returned over 75000 rules on this dataset. 
On the UC1 Admissions Data we asked,  X  X ow has the applicant pool changed from 1993-1998? X  (mindev = 5%, a = 0.05). F igure 5 shows a subset of the results. The spike in part (a) is probably caused by a change in 
California state law which (beginning in 1998) barred the UC system from considering ethnicity in admissions. 
Chakrabarti, Sarawagi, and Dom [5] tackle the related problem of finding surprising temporal patterns in market basket data. They use a Minimum Description 
Length approach where surprising patterns are those with long encoding costs. Our work is fundamentally different. We find differences between two or more probability distributions, whereas they find changes in a single distribution as it varies through time. 
Explora [8] searches for subgroup8 of cases with un-usual distributions with respect to a target variable (T) and the parent population: i.e., it finds a subpopulation 
G, c G such that P(T 1 G,) # P(T 1 Gp). In contrast, junctions of variables Ti such that P(Ti A T2 A . . .T, 1 
GI) # P( T,ATzA...Tn 1 G2). 
We introduced the problem of detecting differences across several contrasting groups as that of finding all contrast-sets, conjunctions of attributes and values, that have meaningfully different support levels. This allows us to answer queries of the form,  X  X ow are 
History and Computer Science students different? X  or,  X  X hat has changed from 1993 through 1998? X  
We combined statistical hypothesis testing with search to develop the STUCCO algorithm for mining contrast-sets. It has (1) admissible pruning rules, (2) guaranteed control over false positives, and (3) compact summarization of results. Acknowledgments This research was funded in part by the National Science Foundation grant IRI-9713990. We thank Nira Brand and Wagner Truppel for their comments. 
