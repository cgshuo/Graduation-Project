 1. Introduction and related work
As search engines and search algorithms have grown more sophisticated in recent years, people have become increasingly 1997, Edelson, Pea, &amp; Gomez 1996; Karasavvidis 2002 ), and organizational learning literatures ( Granovetter 1973, Allen, 1997, Burt 1992; Cross &amp; Sproull 2004 ) have documented how people also serve as valuable information resources. Cross and Sproull (2004) noted that in the workplace, 38 of the 40 managers interviewed  X  X  X elied heavily on other people when seeking information, despite a high-quality computer-based knowledge repository X  (p. 6). In particular, weak ties ( Granovet-ter 1973 ), who tend to bridge across organizational and geographic boundaries, are known to supply new information, di-verse ideas, and novel perspectives ( Burt 1992; Granovetter 1982). dale et al., 1997). Both Morris (2008), and Evans and Chi (2008) discuss the prevalence and importance of social interactions during web search. As many as half of searchers may turn to others for advice, brainstorming opportunities, or search tips mation and seeking feedback. Additionally, it has been shown that peer support provides the greatest benefit when users are ended goals ( Marchionini, 2006 ). This type of exploratory searching can be hard to support from a system X  X  perspective due to the occasional gulf between users X  concepts and keywords and the jargon of the problem domain. Human-to-human com-the fact that social inputs may serve as cognitive aids during search.

Today X  X  web search tools provide relatively poor support for explicit social interactions during search tasks. SearchTo-more searchers have a common goal. Yet information seekers with personal (non-collaborative) search goals may still en-gage in momentary collaborative efforts by emailing or calling friends for help. Can we also design integrated social search social inputs, and collaboration in web-based information seeking.

We can draw some assumptions about these benefits by turning to the organizational learning literature, where Borgatti and Cross have proposed a formal model of information seeking in social contexts (2003). Their work suggests that people will seek the help of others who have domain expertise, who are accessible (or available to provide information in a timely man-mulation, problem framing) to searchers. While we might expect that this model applies in digital environments, neither the and colleagues will provide online searchers with both informational and cognitive (reformulation, framing) benefits.
Our goal with this work is primarily exploratory. We hope to document the ways that searchers exploit their social envi-ronments during exploratory search tasks X  X ut by observing social events that extend beyond web-based interactions. We cio X  X ognitive benefits apply during online sensemaking and problem solving. In what specific ways do social resources aug-ment the search process? To look at this, we selectively recruited users with large and active social networks. We instructed them during one search task to use only social sources (Google, Yahoo!, MSN were not allowed). From this, we observed that questioning a social network and separately engaging in one-on-one answering sessions may help users think through prob-lems. Long-term, we hope that this and future work can offer suggestions for the design of search tools that incorporate so-cial support for users in situationally-appropriate ways. 2. Method
We used a talk-aloud protocol and video capture techniques to explore how eight users performed two search tasks re-lated to US energy policy. Below we describe our study design and data analysis procedures. 2.1. Subject selection
Our call for participation went out formally on Craigslist and Stanford University (SU) Post, and informally through Twit-their typical use of computers, the Internet, social networking, and web search. Because our goal was to discover effective social strategies for searching, we selected only eight individuals from this pool who were both highly social and skilled at web search X  X alling in the upper quartile of reported social networking activities and search behaviors from the set of 30 candidates.
 2.2. Participants
Subjects (5 female, 3 male) came from a range of backgrounds and experiences ( Table 1 ). All were between 21 and 40 years old, well-educated, and fairly liberal in their political leanings. Although the search tasks we selected could have been politically polarizing, politics did not come up as a major issue or impediment to reasoning during the study. 2.2.1. Social network characteristics
While subjects were selected for being highly social, the nature of their social behaviors varied widely. Subjects X  primary social networks were Twitter ( N = 5), LinkedIn ( N = 2), and Facebook ( N = 2) (one subject nominated both Twitter and Link-edIn equally); and self-reported network size ranged from 55 to 1000 (mean: 416; standard deviation: 323). 2.2.2. Social network diversity
In addition to network size, we estimated network diversity (or access to knowledge resources) though a position gener-varying prestige, and for each occupation has users report whether it is held by a member of their social network (family, friend, or acquaintance). (Prestige scores were previously standardized to ISEI socioeconomic index measures ( Ganzeboom et al., 1992 )). We modified our instrument slightly from the one reported in Van der Gaag et al. (2008) and Marlow (2005) to include  X  X  X nvironmental consultant X  and  X  X  X il/gas industry worker, X  as these occupations were relevant to the domain of en-ergy policy. A sum of the ISEI occupational prestige scores in a user X  X  network became her diversity measure (range: 341 X  1295; mean: 920; standard deviation: 283). This shows that, as with network size, there was a wide range of knowledge resources in users X  networks. This measure was not used in the subject selection process, but was included in subsequent correlational analyses. 2.3. Task questions
Our specific task questions were chosen for several reasons. We wanted to observe the search process for exploratory que-unfamiliar and also  X  X  X oogle-hard. X  We determined that a question was  X  X  X oogle-hard X  if, even after several attempts in ma-jor search engines, very few result listings had high information scent. We also wanted questions that had no single correct answer, but instead required a good deal of information foraging (learning) and subsequent sensemaking (synthesis) X  X  nice complement to their  X  X  X oogle-hard X  nature.

Finally, we wanted to preserve a sense of real-life relevancy. Since US gas prices were rapidly increasing at the time of the study (mid-2008), we thought that issues related to energy policies may be suitable task questions. These are not meant to be canonical social search queries X  X hey were selected as  X  X  X oogle-hard X  questions within the domain of energy policy X  X ut consequently, we believed they would generate interesting (social) explorations. 55 MPH : If we lowered the US national speed limit to 55 miles per hour (MPH) (89 km/h), how many fewer barrels of oil would the US consume every year? Pyrolysis : What role does pyrolytic oil (or pyrolysis) play in the debate over carbon emissions?
In fact, there was surprisingly little information about either of these topics available through Google (or in Wikipedia) at the time of our study. Thus, we told participants that we cared more about their exploration processes than whether they discovered the  X  X  X ight X  answer. 2.4. Procedure
All participants engaged in two search blocks without time restrictions X  X irst in the Social and then the Non-Social (NS) Condition. Task questions were counterbalanced between these conditions. After each search block, we inter-viewed subjects about their strategies and behaviors. Total session time (both blocks) varied between 37 and 120 min.

To best simulate subjects X  natural working environments, we ran most users in their homes or workplaces; two preferred to come to our laboratory. Participants used their personal laptops, mobile phones, and regular suite of online tools for the session. Only one person additionally used pen-and-paper. All on-screen actions were recorded with screencast software (either Silverback [Mac] or Camtasia [Windows]). A Flip video camera or MacBook computer was instrumented to capture off-screen actions from the subject X  X  desk and workspace. This track was used to corroborate events from on-screen actions and to view mobile phone interactions. 2.4.1. The Social Condition
In the Social Condition, participants were allowed to use only social resources to search for information. Friends, col-leagues, social networking sites, question X  X nswer sites, and blogs were permitted, but traditional search engines (Google,
Yahoo!, MSN) and Wikipedia were not. 1 We asked that any recruited collaborators abide by the same restrictions as partici-pants. Although this was impossible to enforce, when subjects first began interacting with their partners, we requested that they communicate the Social Condition X  X  restrictions and, at the same time, obtain verbal consent from their collaborators to be remote participants in the study. 2.4.2. The Non-Social Condition
The Non-Social Condition was more similar to a traditional search session. It permitted the use of non-social resources (e.g., search engines, information databases) X  X ncluding Wikipedia X  X nd disallowed the use of the social resources men-tioned above. 2.4.3. Talk-aloud protocol We collected verbal protocols from participants during each search block per standard talk-aloud techniques ( Ericsson &amp;
Simon, 1980 ). We first provided instructions on the talk-aloud method and conducted a warm-up task; during the actual search blocks, we only interrupted subjects to remind them of the procedure if they became silent for an extended period. 2.4.4. Interview and retrospective probing
At the completion of each search block, we conducted a semi-structured interview with retrospective probing, consisting served to elicit information about the people, technology, tools, or idiosyncratic behaviors we observed during the search tasks, but for which we did not interrupt. We asked subjects about their relationships with each person they contacted in the Social Condition; we discussed the history and typical usage of the tools they recruited; and we tried to understand the expected practices and cultural norms surrounding the technologies used. 2.5. Data analysis
All videos were transcribed and manually reviewed. We initially coded for the types of activities users performed: whether they were describing their processes, having social interludes with friends, actively seeking information that ad-dressed their queries, navigating interface elements, etc.; and whether their problem solving was conducted individually or in collaboration with others. This fine-grained demarcation of problem spaces revealed higher-level patterns that proved more worthwhile for our analyses [see Behavioral Patterns in the results section]. 2.6. Scoring performance
Task performance was scored and included in analyses in multiple ways. For each task question, we identified thirteen  X  X  X acts X  central to the understanding of each question (for a selection of facts, see Table 2 ). We selected these based on the advice of field experts as well as the description of important findings from government and academic reports on oil sav-ings and car speed ( United States Government Accountability Office. Energy efficiency: Potential fuel savings generated by a national speed limit would be influenced by many other factors. Washington: Government Printing Office, 2008 ) and pyro-lysis ( Lehmann, 2007 ). 2.6.1. Total facts discovered
Some of our analyses included the total number of facts discovered as a dependent variable. Of course, participants uncovered lots of information while searching; here we only tally  X  X  X acts X  from the thirteen we deemed relevant. 2.6.2. Learning scores
Other analyses took into account comprehension of each fact through a 3-point depth of processing scale ( Table 3 ), mod-ported information from a website) received one point. Facts that were paraphrased or reworded received two points. Facts that were later evaluated in comparison to other information or otherwise synthesized received three points. Ultimately sub-each of the 13 relevant facts they discovered. For example, ss02 received a Learning Score of 6 in the Social Condition from receiving depth of processing scores of 3 on two important facts. 3. Results
Our results focus on the process of social exploration and social reasoning that we observed. Since social search is still poorly supported by web technologies, we do not intend to do a full comparison of performance between the Social and
NS Conditions. Instead, we focus on the outcomes of various social strategies in the Social Condition. 3.1. Performance results
Before turning to these social strategies, we briefly consider the performance differences between tasks and experimental conditions. Our two task questions resulted in different success rates, with Pyrolysis Learning Scores higher during NS than
This suggests that certain queries are better suited for social search than others. The 55 MPH question may have elements of common sense that friends are able to reflect on from personal experiences, whereas the pyrolysis question may be too tech-nical or esoteric for casual colleagues X  X r even energy and environmental experts X  X o have specific knowledge about.
Similarly, we saw performance differences between conditions; namely Learning Scores were higher during NS blocks traditional web search still has advantages over social searching on its own X  X fter all, search algorithms have been contin-for success, going beyond what we would have observed in our experimental sessions.

These results prompted us to consider what factors might correlate with Learning Scores. There were time differences between tasks: participants in the Non-Social Condition spent between 6 and 20 min searching (average: 10 min); in the So-cial Condition, they spent between 12 and 36 min (average: 19 min). Surprisingly time spent searching did not correlate with performance outcomes in either condition. Additionally, none of the pre-test survey responses appeared to influence perfor-mance, and subjects X  performance across conditions was not correlated. 3.2. Behavioral patterns
Just as individual performance varied, so too did information seeking strategies. Six general categories of behavior emerged from our analysis: Targeted Asking, Network Asking, Searching, Checking for Replies, Thinking, and Other . Targeted Asking, Network Asking , and Searching were employed as primary social tactics in the Social Condition. In Targeted chronously) or over instant messaging (IM) or telephone conversations. Network Asking involved posting a question in a pub-question X  X nswer sites (Ask MetaFilter and Aardvark 3 ).

Of course, Searching occurred in both Social and NS Conditions. When users were restricted to only social resources, they condition, they readily exploited Google, Yahoo!, and Wikipedia search functionality.

Checking for Replies was common in the Social Condition for users who engaged in either Targeted or Network Asking. One response X  [ss06]. Thinking was observed in talk-aloud segments where users were contemplating an answer or synthesizing information they had discovered. Episodes where subjects were overtly socializing with friends or chatting with the researchers were coded as Other . This suite of strategies is reflected in the color coding of behaviors on ss03 X  X  timeline ( Fig. 1 ). An elaboration of his process mapped to behaviors on the timeline is presented below.

At the start of the task, ss03 goes immediately into a social networking site, Ask MetaFilter. This network, while familiar, had not been visited in about a year, but it was considered to be the  X  X  X o-to X  site for question X  X nswering. He begins by searching for previously posted question X  X nswer pairs on MetaFilter [beige coding]. After gathering reasonable back-ground on the domain, he composes his query. Posting the question was actually somewhat involved [see long blue phases]: He reframes and rephrases his query several times before finally posting it.

In the process of asking his question on MetaFilter, ss03 realizes that the question contains sub-parts that could be out-sourced to other communities. He then posts one sub-question to Twitter and another to Aardvark. Next, after searching his mental address book and iPhone contact list for friends he can solicit for help, he texts a few candidates with his ques-tion, then moves into Google Chat (an IM client). He soon begins IMing with another friend [green bands] whose status indicator had signaled his availability.

Interspersed with these activities, ss03 occasionally checks for replies to his network questions [yellow], chats with the researchers [red], and searches for information (briefly) on Yahoo! Answers [the beige bands towards the end]. By the end of the session, he has accumulated several facts that are relevant to answering the question and concludes by synthesiz-ing everything he has learned into a final answer [gray phases towards the end].

This demonstrates how a suite of tactics might be employed in a single search session. Of course, some people did not in a social database. As a result, participants X  use and combination of social strategies were highly diverse. 3.2.1.  X  X  X o-to  X  sources
There were some qualitative similarities across approaches: Participants who had  X  X  X o-to X  sources in mind always turned to them first. Often these  X  X  X o-to X  sources were particular people. For example, ss08  X  X  X tarted with David, [her] know-it-all friend, X  and without hesitation sent him an email request. Subject ss02 also initially turned to a friend, Sarah, who was in-volved in  X  X  X ustainable studies and environmental work, X  a domain likely considered to be relevant for our energy policy questions. This speculation is supported by a later comment that he was looking for people who  X  X  X ay actually know the answer to this X  [ss02]. This user was so committed to getting a hold of Sarah, he first emailed her but followed up by phone five minutes later.
 works that [he is] a part of X  through the service Ping.fm. Since these participants have large and active social networks and already as  X  X  X o-to X  sources.
 3.2.2. Social relationships and social decisions
Subjects X  relationships with sources also affected their information seeking decisions. Several participants commented that they sought  X  X  X nowledge mavens X  or domain experts in related fields. When such target candidates existed, they were the  X  X  X o-to X  sources initially solicited for help. However, one-on-one interactions occurred throughout the search sessions.
When friends were recruited at later points in the process, it was more likely because they were presently available or will-ing to engage in problem solving. This general finding agrees with Borgatti and Cross (2003), and Cross and Sproull (2004) , that information seeking in social contexts is not only about finding the nearest domain expert.

Many factors influence who searchers turn to for help. We are calling these social decisions after the set of social factors out in the formal model of social information seeking by Borgatti and Cross (2003) . These include perceptions of: 1. A person X  X  knowledge and authority  X  X  I trust what she says  X  [ss06] 2. Their accessibility  X  X  I know he X  X  online and I know he X  X  at home  X  [ss01] 3. The social costs or obligations that ogy used to communicate (in the present and historically). For example, ss08 chose David not only because he was a  X  X  X now-it-all friend, X  but also because:  X  X  X e have an engagement over email where we can do this kind of thing. X  Subject ss01 reached out to Alex because she had  X  X  X een IMing with [him] recently. X  Another [ss07] used her Facebook buddy list to find someone to ask:  X  X  X  can see who X  X  online right away ... who X  X  even on here? X  developing supporting tools. While our study cannot address the reasons for turning to social resources in the course of nat-ural search tasks, it does begin to illuminate some of the cognitive consequences of social interactions in search. 3.3. Outcomes of social strategies
We observed several common benefits from seeking information from targeted friends and wider networks. 3.3.1. Informational benefits of social resources
First, friends provided information (facts) to our users. Both Targeted and Network Asking had a relatively high rate of return for 20 X 30 min sessions. Although responses came at a time delay, subjects received between 1 and 6 replies from suggesting that friends can, in fact, play an important role in supplying information.

Initially, we expected that certain social tactics would emerge as superior to the others, as each of the three strategies (Targeted Asking, Network Asking, and Searching) has different merits. Targeting individuals can be useful if they are knowl-edgeable and available to respond. Querying a network distributes a question over a wide (diverse) audience, theoretically increasing the likelihood of reaching an individual with the appropriate knowledge and availability. Searching, of course, could provide ample information (with large databases), but is limited to the content already present in the database.
However, no individual tactic was superior to others; instead, combining these social tactics consistently led to significant 0.73; p &lt; 0.05) ( Table 5 ). In other words, people who employed more strategies uncovered and synthesized more task-rele-vant information. Additionally, the number of social tactics used correlated with task performance better than any other measure we collected, including number of friends on the primary social networking site, social network diversity (as mea-sured by the position generator ), and background knowledge and interest in energy policy. This suggests that the potential availability of and access to knowledge within a network may not determine the search outcome X  X sers must know how to manipulate their social environments. Targeted and Network Asking are types of social manipulations, and those who adeptly exploited their available social resources outperformed those who did not (regardless of other network factors).
At the same time, it is possible that Targeted and Network Asking are manipulations of the same social environment, but in complementary ways (e.g., Network Asking could be used to identify people for subsequent Targeted Asking).
These approaches could be partnered in theory, but in practice, most participants used each social tactic as distinct strategies. For example, ss08 first emailed her friend David, then searched over Yahoo! Answers, and finally asked a question on Twitter. Her trajectory through the search space was fluid and natural, but her efforts were chunked into three distinct phases. 3.3.2. Cognitive benefits of social resources
Yet friends can provide more than just facts and information X  X hey can also act as problem solving aids ( Cross &amp; Sproull, and Network Asking led users to become cognitive engaged with task material, but in different question X  X nswering phases. 3.3.3. Question composition prompts thinking in Network Asking
When interacting with social networking sites, several subjects realized cognitive benefits during the first phase of social search X  X he questioning phase. Three out of five users who employed Network Asking engaged in episodes of deliberate thinking and contemplation while they were composing their query. Their talk-aloud verbalizations revealed this [ss03]:  X  X  X kay, what can I ask as a quick thing that somebody might actually reply to? X  He later paused after the first draft of his query (for the 55 MPH question):
So that X  X  a big open question. We still do not know how many barrels we use per year; we do know how many gallons are in a barrel, so we need to know ... [pause]. The problem is X  X he number of barrels per year kinda helps, but it X  X  not the full answer, cause I do not know how much of that is ... consumed by cars.
 do I really want to be asking? X  [ss05]. These episodes of thinking around query composition were not prevalent during Tar-geted Asking, which is somewhat surprising since the communication modes of email and IM offer similar technological affordances (small text box, asynchronous exchanges) but in private channels. Perhaps posting a public and archival question prompts people to more seriously consider the nature of their query? If this is the case, social networking sites may, curi-ously, provide benefits to the framing and formulation of search questions. 3.3.4. Private replies prompt thinking during Targeted Asking
In contrast, Targeted Asking offered cognitive support primarily in the answering phase of social search. For the five sub-jects who engaged in Targeted asking, all paused to synthesize information after receiving private replies (from both syn-chronous or asynchronous exchanges). One subject [ss02] commented after the phone call with Sarah:
She started by saying [pyrolysis] is probably a way to convert from one liquid or substance to another. Well, breaking down the word, the first part of the word means fire or inflammable ... so maybe it X  X  a medium in which ... you convert the substance from one thing to another, and it reduces or eliminates the carbon emissions.

Similarly, ss08 evaluated two conflicting answers about fuel economy and vehicle speed (15 X 25% savings versus no savings):
David is really knowledgeable and he says it is 15 X 25% savings ... But I also believe [Derek], who X  X  an electrical engineer and thinks in terms of mechanics X  X robably I would average the two. I could assign a higher weight to David X  X  response, in which case I would bear on the higher side of what he suggested, but if I were not weighing his answer, I would say 15%.

This behavior can also be seen in the color coded activities in subjects X  timelines ( Fig. 2 ) where the green and gray bands because some of the green blocks mark when users asked questions of their friends. Thinking and contemplation were ob-in complementary ways to public or semi-public networks. 3.3.5. Quality of friends X  responses
A possible reason for these differences may lie in the quality of the responses received. Replies from social networking that helped advance understanding of the search question. For example, one Twitter reply suggested that there would be A third, via Facebook, commented about pyrolytic oil:  X  X  X sn X  X  that something I rub on my [body]? Are you still in San Francisco? X 
In the days following the study, we contacted the friends who helped our participants in order to assess the motivations behind their responses. There were twelve individuals who provided public replies through social networking sites X  X ight answered our follow-up prompt, reporting that they were mostly looking to start a conversation rather than provide a sub-stantive reply.
 I was curious to know why she thought the way she did and more importantly to start a small conversation [R7]. Seemed rhetorical and random, so I thought I X  X  reply for fun [R8].
 My reply was more snark than anything else [R3].

In contrast, replies from targeted friends were content-rich . Ss08 X  X  friend, David, replied that a 55 MPH limit would result provided details about the complexity of the problem:  X  X  X here X  X  no one national speed limit, there are two: 55 miles per hour in general, 65 miles per hour for certain roads. X 
As before, we followed up with these private respondents to learn more about their motives. The three who replied (out of conversational aspect of the exchange. Perhaps as a result, our subjects had the incentive and the material for serious reflection. 3.3.6. Searching in social and non-social contexts
Because our goal in this study was to understand social exploration and reasoning during search, we devoted the majority ing was observed in the Social Condition over social databases (e.g., Twitter, Yahoo! Answers, etc.) and as the entire search strategy in the NS Condition.

In many ways, searching across social sources looked very similar to searching on Google and Yahoo!. The search tools were comparable (e.g., single line search box) and global strategies were the same (e.g., submitting our entire task question as a multi-string query). Participants even found many of the same information resources when searching in both conditions.
However, there were qualitative differences in searching outcomes between conditions in the ratio of search queries to thinking episodes . We considered the number of searches executed as the search query count X  X earching with Google or Ya-hoo! [NS Condition] or searching a social database [Social Condition]. Thinking episodes were tallied from our Thinking dition. Put another way, searching in social sources resulted in less deliberation per search (mean ratio of thinking/search: 0.29) than using search engines and other non-social tools (mean ratio of thinking/search: 0.53).

These differences can be explained in part by looking at the quantity and quality of the search results. Social sources do not have the scale and scope of traditional search engines, and thus may be limited by providing fewer hits. This was re-flected in our data: participants identified fewer task-relevant pages per search when using social databases (mean: 0.67 pages/search) than when using traditional search engines (mean: 1.55 pages/search).

However, pages perceived by the user as relevant resulted in roughly the same amount of thoughtful deliberation regard-pages was approximately equal across conditions (0.27 in the Social Condition; 0.31 in the NS Condition). This suggests that subjects are able to make accurate judgments on social material, dismissing irrelevant content but paying attention to important facts. If this is the case, the act of searching may not be measurably different in social versus non-social con-texts X  X earchers may simply need to expend more effort finding relevant material in limited social databases. 4. Discussion
In our study we observed several interesting patterns and noted that different types of social engagements (e.g., public versus private) may provide complementary cognitive benefits. While further study is needed to isolate the exact reasons why these benefits occur, we can discuss a few of the possibilities for our findings. 4.1. Combining social strategies
Regarding our observation that combining social tactics led to better task performance, we might wonder why all users did not exploit the suite of social options.

One possibility is that early successes become barriers to subsequent discoveries. Several subjects who found (relevant) information early in their process seemed less likely to search in another channel at a later point. When ss02 spoke with
Sarah, their conversation was short, succinct, and produced reasonable information about pyrolysis; but the facts were incomplete, and he did not extend his problem solving when the conversation ended. Similarly, ss07 only spoke briefly with a friend on Facebook, but after getting reliable information from him, she ended her information seeking process. (Both re-ceived mediocre Learning Scores.) Why might targeting friends for help X  X nd getting good information from them X  X roduce weaker outcomes than exploring multiple social channels? Is one possible shortcoming of  X  X  X xpert X  (social) opinions that people place too much trust on their data? Bandura (1989) suggests that  X  X  X ufficing outcomes can ... operate as barriers to alternatives, even though better ones [may] exist. X  ( Schwartz, 1982 in Bandura, 1989 ). If such factors affect search as well, system designers could try to increase social presence on a site or reveal alternative social channels to information seekers.
 A second possibility is that different social strategies may be optimal for different search phases and information needs.
For example, searching in large databases may provide an overview of the problem space ( scope ), but personalized responses how scope and depth should be paired in a search task. But the nature of exploratory queries suggests that getting the scope and breadth of a domain (i.e., through searching) may be more useful in framing open-ended queries early in the search pro-cess, while drilling down to details (i.e., through customized replies) becomes more useful as the problem space becomes more familiar.

It may be noteworthy that none of the social tactics we observed involved pushing information to the user: Our subjects X  strategies involved explicitly seeking information from social communities. This lack of pushed data (e.g., recommendations, facilities despite a long and rich history with social recommendation and collaborative filtering techniques ( Glance, 2001; Goldberg, Nichols, Oki, &amp; Terry, 1992; Konstan et al., 1997; Smyth, 2007). Google X  X   X  X  X id you mean X  feature and Yahoo! X  X 
Search Assist provide guidance only relative to common usage patterns (averages), rarely providing insights into an extended search space. In contrast, MrTaggy ( http://mrtaggy.com ) X  X  new social search tool X  X resents concepts related to a user X  X  search query by aggregating keyword tags from social bookmarks, providing scope to users exploring novel or com-plex domains ( Kammerer, Nairn, Pirolli, &amp; Chi, 2009 ). Future work could compare how user strategies and outcomes differ when receiving implicit social metadata versus performing active question X  X nswering X  Chi X  X  (2009) distinction between so-cial feedback and social answering . 4.2. Social resources as cognitive aids
It is interesting that Network and Targeted Asking tactics were associated with different cognitive gains during the ques-tioning and answering phases of search, respectively. Of the many possible reasons for these differences, some may be due to the nature of the tools and the audiences reached. 4.2.1. Network asking
Social networking sites have a different set of affordances and cultural norms than private messaging channels like email, instant messenger, or X  X t the other extreme X  X ace-to-face communication. This set of constraints may have led users to reformulate their problem before asking it on a social networking site. 1. One constraint lies in the lack of knowledge about other participants in their network. Even on sites like Facebook, with bidirectional, presumably real-life friendships, the audience can grow quite large such that each member X  X  individual presence is not immediately observable. Perhaps without current knowledge of this audience, our subjects had to care-fully craft their information request. 2. Another constraint relates to the asynchronous nature of online communication. In synchronous channels (i.e., face-to-ural back-and-forth is often lacking in the asynchronous interactions on social networking sites. Instead, there may be tunity, not something they could incrementally build upon with collaborators.Furthermore, questions, comments, and discussions around a topic become archival material in many public forums. The fact that our subjects X  queries were being publicly recorded may have also prompted their early consideration of our task questions. participation, but with short messaging formats. Twitter restricts posts to 140-characters or less. Facebook and Ping.fm do not have explicit limits, but interface designs and cultural practices likely encourage succinct posts: the  X  X  X tatus update X  box is (visually) small and users tend to be pithy in their updates and comments. These short messaging practices prob-ably also led our subjects to think about their task problems early on. One subject [ss05] outwardly commented that our instead, she interpreted and then paraphrased the critical parts of the question, customizing it for a short message format.
The process of reworking the question in this way led to insights about what the question was really asking and how to think about it differently. 4.2.2. Targeted asking
Private messaging channels have an alternative set of affordances that likely contributed to the deeper processing of pri-vate replies, as opposed to the deeper formulation of early queries. The near-synchronous, personalized nature of one-on-one responses may underlie these observed cognitive benefits. 1. In contrast to addressing wider networks, targeted messaging usually occurs between people who are (minimally) acquaintances ( Cross et al., 2001 ). This relationship history contributes to a working knowledge of friends X  background and interests. Thus, if the question is asked of the right source, there may be little need to paraphrase or reformulate the initial inquiry; the question will be either familiar or unfamiliar to the friend. As a result, our subjects may have had little motivation to think deeply about their task question in the initial formulation of privately-posed questions. 2. However, the synchronous nature of the communication channel may be critical for deep thinking. The majority of our subjects X  targeted interactions occurred via telephone or IM where they received and responded to information in near-to-real-time. Indeed, only after a series of exchanges did users [ss01, ss02, ss03, ss07] achieve the highest depth of processing scores on discussed facts. Curiously, these communication channels would be categorized as moderate social presence media  X  X emote, synchronous exchanges X  X y Robert and Dennis (2005) . They proposed a paradox of media rich-ness, suggesting that low social presence channels (email, fax and voicemail) may actually offer the best opportunities for cognitively processing complex information. We might add that moderate social presence channels may offer similar affordances. 3. Finally, there are different cultural norms to observe in private (versus public) communication channels. When asked a specific question, friends may feel obliged to provide a serious answer. In doing so, they likely customize their response to the seeker X  X  perspective (background and knowledge). The content, therefore, becomes much more personalized and relevant than information shared via social networking sites.

Additionally, our subjects may have felt loyalty to friends who were noticeably engaged. If answering a question obvi-ously demanded their time and energy X  X ultiple messages were sent or the exchange lasted a long time X  X sers may be sub-sequently obliged to think carefully about their replies. Such collaborative involvement may have led to our observations of deeper engagement with privately-shared material. 4.3. Limitations
Our results should be qualified by the limitations inherent in our experimental design. First, we collected data from only eight users, each of whom had markedly different interaction styles and task behaviors. Our analysis is based on their 16 search sessions. Second, self-motivated searches are known to have different behavioral profiles than externally-prompted ones ( Evans &amp; Chi, 2008; Russell &amp; Grimes, 2007).

Third, we instructed subjects to focus on the search process rather than try to achieve a certain answer or result. These that their social resources may be limited. Not directing subjects to a specific goal state, however, meant that fine-grained post-test measures were inappropriate; instead we constructed performance measures to capture the exploration process, including depth of processing of search material.

Fourth, our task questions were drawn from only one domain (energy policy), and participants used  X  X  X eneral-purpose X  social sources to answer them. We may expect to see different social strategies in communities of shared practices or among colleagues with shared interests (e.g., technical forums, domain-specific social networking sites).

Finally, our analysis was restricted to single session search blocks. Exploratory searches X  X haracterized by open-ended queries and frequently requiring multiple iterations X  X ay extend across sessions and involve multiple sources, making them ronments were as naturalistic as possible, hoping that this would minimally reveal their authentic behaviors and approaches to our task problems. We did not set time restrictions in any session, and allowed participants to signal the natural conclu-sion of their own search episodes. It is noteworthy that search sessions X  X n both the Social and Non-Social conditions X  X ere rather long and involved, lasting anywhere from 6 X 36 min. Altogether this suggests that we may have captured more than just the early stages of exploratory search with our study X  X  design. 4.4. Design implications
It is unsurprising that different communication channels serve individual cognition in different ways. The design chal-lenge is to create working platforms that integrate the benefits of social communications with those of traditional web search facilities. Our study has begun to illuminate the benefits of engaging social resources during search: Both during the questioning and answering phases of search, other individuals are useful not only for providing information, but also for triggering new insights to problems. Of course, search engines have an enormous advantage over social strategies on their own because of their vast databases and quick retrieval algorithms. However, social inputs may naturally augment search platforms in cases where the information need is not well served by traditional methods.

Some queries are just better suited for social answering. These may be cases of  X  X  X ocabulary problems X  ( Furnas et al., 1987 ) where users lack the right search terminology (due to mis-framing, having alternative perspectives, or from navigating a novel domain). Similarly,  X  X  X ow to X  questions often require tacit knowledge from prior experiences; and subjective ques-tions (e.g., dining or lodging recommendations) are addressed through contextual knowledge and personal opinions. Not only may these queries benefit from social inputs, the best results may come from a trustworthy friend over a stranger. A recent report by the PEW Internet and American Life Project (2008) corroborates this sentiment X  X heir results show that community networks are preferred for certain types of information needs (such as choosing a new bank or dealing with a spiritual crisis) ( Wells &amp; Rainie, 2008 ).

This presents two challenges for bringing social and collaborative resources to search engines: how to identify the set of queries that benefit from social inputs and how to incorporate social networking and social answering facilities.
First, how do we distinguish the set of queries that will benefit from social inputs? User intent has always been difficult to discern; by classifying queries that are  X  X  X ocial X  or collaborative in nature, we will begin to have a framework for iden-tifying those use cases in practice. Another approach may be to observe users in action, taking cues from a series of behav-iors within a single search session. Users suffering from vocabulary problems may exhibit certain types of behaviors X  using long multi-string queries, searching with a  X  X  X ow to X  phrase, frequently reformulating search terms in short period of time, or seeking help from the  X  X  X id you mean X  (Google) or  X  X  X earch Assist X  (Yahoo!) options. Developing methods for use cases.

The second challenge is how to effectively integrate social networking, direct messaging, and social recommendations with current search facilities. One suggestion is to begin with traditional search. The great value in search engines is that they can efficiently provide scope on a problem domain, quickly revealing whether the answer is buried deep or not. If it becomes apparent that search results do not immediately address the user X  X  needs (signaled by the behavioral cues above), a search engine could then take explicit actions to suggest alternative approaches. For example, high-level concepts derived from tags and other social metadata could be displayed in a sidebar on the page X  X s MrTaggy does ( Kammerer et al., 2009 ).
This would aid users in navigating a search space by concepts and categories, not just by keywords. Or, available domain experts from the community (or filtered by the user X  X  address book) could be suggested as social resources: Instant messag-ing). Finally, the site could encourage users to tap their social networks, broadcasting their question to a large personal network (i.e., Network Asking).

Whileourstudyfoundcognitivebenefitstoposingquestionstolargenetworks,havingone-on-oneconversationswithpeers serve as a query broadcasting mechanism. Next, expertise-matching algorithms could route questions to certain individuals in the network X  X ither self-identified experts or experts of convenience (who are presently available). This combined social strategy may increase the likelihood of a relevant response by (1) reducing noise (well-matched targets will provide well-more bystanders are present). Although this is a style of asynchronous, remote collaboration, our results suggest that there goals. 5. Conclusion
Our study provides some early insights to the behaviors and practices surrounding question X  X nswering in social environ-ments. Let us briefly summarize: We identified three social tactics for information gathering (Targeted Asking, Network Asking, and Searching). These tactics used in combination led to better search outcomes (based on Learning Scores).
 Query composition on social networking sites resulted in reformulation and framing of the task problem.

Processing (targeted) friends X  answers led to greater synthesis of task-relevant material, through episodes of thinking and contemplation.

Facile manipulation of social environments (through the three social tactics) correlated better with task performance than factors like social network size, network diversity, or background knowledge.
 Yet, Learning Scores were still higher under tradition web searching than social searching alone.

This begs the question: Do your friends make you smarter? Our results would suggest yes : other people serve as cognitive aids during search and sensemaking tasks. Social resources may be essential for answering a certain class of queries and, in partnership with powerful search engines, could greatly assist users on their quest for information.

The evidence from our study alone is not enough to determine which of the underlying factors are most important for designing integrated social search systems. Future studies should look more closely at question X  X nswering behaviors and outcomes across different social environments. As a research community, we must develop a more sophisticated under-standing of how social searches of various types compare to traditional web search. We have several models of social infor-mation seeking ( Borgatti &amp; Cross, 2003; Evans &amp; Chi, 2008; Pirolli, 2009 ) and collaborative information seeking ioral observations to understand how these phenomena play out in digital environments: How do personal goals influence social decisions? How do social capital, social presence, and tie strength affect information seeking? Will different online communities be more amenable to question X  X nswering? How do collaborative filtering and social recommendations com-plement explicit social information seeking practices? We hope that our study provides some initial contributions to a more holistic understanding of question X  X nswering and social search.
 Acknowledgments We extend a great thanks our willing participants and our collaborators in the Augmented Social Cognition group at PARC.
We thank the reviewers of our manuscript for their critical comments. And we are grateful for the guidance from our energy policy experts: Gabriele Cente, Johannes Lehmann, and Lew Fulton. This work was supported in part by Office of Naval Re-search Contract No. N00014-08-C-0029 to Peter Pirolli.
 References
