 Classic data analysis techniques are generally designed for variables with single values only. However, when it comes to the age of big data, the data complexity has gone beyond the classic data framework. The values of variables may appear in aggregate form to represent a certain homogeneous behaviours of objects instead, which is referred to as symbolic data. Symbolic data analysis (SDA) approach is of particular interest for huge data set of high complexity when the units are not individual records but some second-order objects.
 data, where the variable values are sets of stochastic measurements and each set is an instance of a stochastic process. The second order objects in stochastic pattern-based symbolic data may include the behaviour of some customer of interest in aggregated credit card purchases, the parameter variation patterns of an emitter. In any case, the observed variability for the second-order objects is of utmost interest.
 sidered as a multi-valued variable and represented as intervals [ 13 ], crystal item provided with an associated measure or distribution, such as frequencies, proba-bilities or weights. However, in practical applications, the situation is even more complicated such that the measurement sets are instances of stochastic patterns whose distributions are heavily overlapping and some measurements may be missing. Therefore, the intervals and item sets become inappropriate. For exam-ple, to monitor the physical status of patients, the set of heart rate measurements of individual patients are recorded which follow different stochastic patterns for different individuals. The same goes for radar emitter parameter analysis where the parameter measurement sets from different emitter types comply with the type-specific stochastic patterns.
 Figure 1 illustrates a running example of a stochastic pattern-based symbolic data consisted of five objects from two classes. Each object has two attributes ( A 1and A 2) and one class label ( c 1 or c 2 ). The objects in the classic data possess a single mean value for each attribute while they have a set of stochastic numeric measurements in the symbolic data instead. The underlying stochastic patterns of attribute A 1 are denoted as P 11 and P 12 respectively. Obviously, the two classes are unable to be discriminated in the classic data but finely distinguishable with the two stochastic patterns.
 In this work, we bring forward an incremental hierarchical clustering algo-rithm for stochastic pattern-based symbolic data ( IHCPSD ) and make the fol-lowing contributions: (1) We have proposed a novel  X  -Jaccard index for evalua-tion of similarity between a pair of stochastic measurement sets which is robust to overlapping distribution and missing measurements; (2) We have put forward a flexible and effective cluster candidate set model for hierarchical clustering which is well adapted for incremental learning as well; (3) Extensive experi-ments on both synthetic and real-life data sets have validated the effectiveness of our IHCPSD method.
 The rest of paper is organized as follows. We review related work in Sect. 2 . Our IHCPSD method is presented in Sect. 3 . In Sect. 4 , we present the experi-mental results. And the conclusion is made in Sect. 5 . Symbolic data analysis has gone through a considerable development since it was first introduced by E. Diday in the 1980s [ 1 ]. The pioneering SDA projects,  X  X ym-bolic Objects Data Analysis System X  SODAS and  X  X nalysis System of Symbolic Official data X  ASSO were devoted for a systematic development of symbolic data analysis methodologies. Meanwhile, the first book on SDA,  X  X nalysis of Sym-bolic Data X  [ 2 ] was formally published. Though it has been recognized that the values of a symbolic variable could be a symbolic stochastic process as well, not much effort has been made yet [ 3 ].
 There has been a considerable greater effort in developing methods for interval-valued symbolic data rather than for other types. The benchmark SDA methods, such as the univariate and bivariate descriptive statistics [ 4 ], factor-Only a few ones have been adapted for histogram-valued data [ 9 , 10 ]. In this section, we formally propose our IHCPSD method which is composed of three major components, pattern similarity evaluation, pattern discovery via hierarchical clustering and incremental pattern-based data transformation. The input of IHCPSD is the original symbolic data while the output is the set of discovered stochastic patterns and the pattern-based transformed data. Table 1 summarizes the notations in IHCPSD . 3.1 Pattern Similarity Evaluation The Jaccard index is a benchmark statistic for comparing the similarity and diversity of sample sets. However, the traditional Jaccard index only applies for sample sets composed of discrete items or equal-length vectors. This certainly is not our case of stochastic pattern-based symbolic data where the units are consisted of numeric measurements of unequal sizes. To evaluate the pattern similarity between a pair of numeric measurement sets of a certain attribute, S i and S j ,weproposethe  X  -Jaccard index based on a specified approximation threshold  X  and a symmetric distance function dist (). For each measurement S ip  X  S i , we find the closest unmatched measurement S  X  S measurement sets S i and S j , we define their matched set , denoted as M atchSet ( S , S j ), as the set of matched pairs with the shortest distances within  X  distance away. Specific ally, the first matched pair is the one with the shortest distance below threshold  X  , the second pair is the one with the shortest distance among the pairs composed of the remaining unmatched measurements below threshold  X  and so on.
 Definition 1 (Match Set). Suppose S i = { S ip } p and S j of stochastic numeric measurements, given the approximation threshold  X  and and S j is the set of matched pairs with the shortest distances below threshold  X  , M atchSet ( S i , S j )= { &lt;S ip 1 , S jq 1 &gt; , &lt;S k  X  such that dist ( S ip , S jq )  X   X  .
 The  X  -Jaccard index is further defined upon the matched set as below: Definition 2 (  X  -Jaccard index). Suppose S i = { S ip } and S two sets of numeric measurements,  X  is the specified approximation thresh-old, the measurement distance function is dist ( S ip , S M atchSet ( S i , S j ) is the match set between S i and S between sets S i and S j is calculated as The  X  -Jaccard index varies between zero and one. Assume the approximation threshold  X  is 0.1, for the running example in Fig. 1 ,the  X  -Jaccard index between the measurement sets of attribute A 1fromobject o 1 and o index between object o 1 and o 4 is 0.2. 3.2 Pattern Discovery via Hierarchical Clustering Based on the  X  -Jaccard index, we discover the stochastic patterns by agglom-erative hierarchical clustering of cluster candidates. Each cluster candidate is modelled with a cluster candidate set . The cluster candidate sets are initial-ized with the individual measurement sets and then merged iteratively until the threshold . During the above agglomerative hierarchical clustering, the measure-ments, measurement weights, member set and support of the cluster candidate sets would be updated all along the way. The final stochastic patterns would be discovered from the final cluster candidate sets which meet the minimum weight threshold minw and the minimum support threshold minsup .
 index that a pair of cluster candidate sets must obtain for agglomerative merg-ing. The minimum weight threshold minw specifies the minimum weight that the measurements must obtain to be remain in the cluster candidate set. The mini-mum support threshold minsup specifies the number of measurement sets that the cluster candidate must cover to be identified as a final stochastic pattern.  X  Cluster Candidate Model {
C i 1 , C i 2 , ..., C i | C i | ) whose measurement weights are denoted as W w indicates the probability that the corresponding measurement has a match in the current cluster candidate. The measurement weights of a cluster candidate i all satisfy threshold minw , w ik  X  minw ,1  X  k  X | C i | cluster candidate i , MemSet i , is the set of measurement sets that it has merged. The stochastic patterns could be safely discovered as long as the weights of the measurements with missing values satisfy threshold minw .  X  Cluster Candidate Initialization MemSet i = { S i } . Meanwhile, the associated measurement weights and support are all initialized as ones, w i 1 = w i 2 = ... = w i | C i C are denoted in brackets, MemSet 1 = { S 1 } and Sup 1 =1.  X  Hierarchical Clustering didates are calculated as the one minus the largest  X  -Jaccard index between measurement sets in their member sets.
 During the hierarchical clustering, the pair of cluster candidates &lt;C with the largest  X   X  Jaccard index above threshold would be merged into a new cluster candidate set C i with the associated measurement weights W support Sup i and member set MemSet i iteratively.
 set M atchSet ( C i , C j ) between the pair of cluster candidate sets C inferred. Then, for each matched pair &lt;C ip k , C jq k 1  X  k  X | M atchSet ( C w i r would be generated according to Eqs. 3 and 4 respectively: On the other hand, for each unmatched measurement within C M atchSet ( C i , C j ), either C ip in cluster candidate C didate C j , the corresponding measurement and associated weight in the new cluster candidate i would be generated as shown in Eqs. 5 and 6 : Meanwhile, the support and member set of the new cluster candidate i would be calculated as well as shown in Eqs. 7 and 8 : Whenever the weight of a measurement is below threshold minw , the mea-surement will be removed from the cluster candidate set. The hierarchical clus-tering process proceeds iteratively until none existing cluster candidate pairs satisfies threshold . Finally, the set of measurements in cluster candidate sets that satisfy threshold minsup would be identified as a stochastic pattern.  X  Example For the running example in Fig. 1 , given approximation threshold  X  =0 . 1, similarity threshold =0 . 5, minimum weight threshold minw =0 . 5 and the minimum support threshold minsup = 2, the agglomerative hierarchical clus-tering proceeds as shown in Fig. 2 . There are initially five cluster candidates 1 X 5 represented by cluster candidate sets C 1 , C 2 , ..., and C dates 1 and 2 merge into a new cluster candidate 1 . So do cluster candidates 4 and 5 which merge into cluster candidate 4 . Later, cluster candidates 1 and 3 merge into 1 . The final two stochastic patterns above threshold minsup are C = { 10 . 75(0 . 67) , 30(1) , 79 . 67(1) , 97 . 5(0 . 67) which are rather close to the underlying true patterns.
 3.3 Incremental Pattern-Based Data Transformation Our IHCPSD method adapts well for incremental pattern-based data transfor-mation on the symbolic data stream. We store the latest symbolic data in G data blocks of equal size BlockSize , denoted as D 1 , D 2 , ..., and D blocks would be discarded. Given the specified approximation threshold  X  ,the similarity threshold , the minimum weight threshold minw and the minimum support threshold minsup , we discover the set of stochastic patterns from each data block D g for each attribute, 1  X  g  X  G respectively, denoted as  X  global merging would be conducted. As long as any two stochastic patterns from different data blocks satisfy the similarity threshold , we merge them iteratively just as we do in the hierarchical clustering. The set of final stochastic patterns after merging is denoted as  X  .
 from each class to construct the latest symbolic training data Train . The class discriminating power of each discovered stochastic pattern in  X  is then evaluated by the chi-square test on Train and the top M discriminating stochastic patterns are selected for symbolic data transformation.
 sets of each object would be transformed into a  X  -Jaccard index. In this way, the original symbolic training data Train would be transformed into a data set composed of M new attributes and the classical machine learning approaches could be applied. We evaluated our IHCPSD method on a series of synthetic data sets and one real-life emitter parameter data. Experiments were conducted on a Dell PC running Microsoft Windows XP with a Pentium dual-core CPU of 2.6 GHz and a4GRAM.
 three, five and eight were embedded, where P 1 = { 30, 60, 90 140, 160 } and P 3 = { 90, 150, 180, 200, 220, 240, 260, 280 for each parameter value p comply with a normal distribution where sd = c  X  p and coefficient c varied between 0 . 01 and 0 . 3. To evaluate the robustness of IHCPSD to missing measurements, a missing probability mprob was specified as 20 %. We made use of a data generator with a random variable R for missing measurement simulation. The value of variable R is a random number following a uniform distribution in the range of [0, 1]. In case variable R is below mprob , the measurement would be missed, otherwise the measurement would be simulated according to the above normal distribution. The number of simulated symbolic data records was varied between 10 k and 100 k . pattern-based symbolic data records. Each record was consisted of an emitter id, a set of stochastic measurements of PRI (pulse repetition interval) parameter, a numeric RF (radio frequency) parameter value and a label of emitter type. The real-life data had three different types of airborne radar emitters, denoted as  X  X  X ,  X  X  X  and  X  X  X  respectively. 4.1 Evaluation of Pattern Discovery on Synthetic Data We evaluated the effectiveness of IHCPSD on the synthetic data sets. In the default setting, we fixed the approximation threshold  X  as 0.1, the similarity threshold as 0.5, the minimum weight threshold minw as 0.5, the minimum support threshold minsup as 0.1 of the data block size, the data block size BlockSize as 10 k and the number of data blocks G as ten.
 We evaluated the similarity between the discovered stochastic patterns and the underlying true patterns. We found that over 90 % discovered stochastic patterns achieved a  X  -Jaccard index larger than 0.8 with one of the three true patterns. This indicates that the discovered stochastic patterns comply with the underlying true parameter patterns fairly well. The boxplots of these discovered coherent stochastic patterns w.r.t. the corresponding true parameter patterns were given in Fig. 3 (a), (b) and (c). 4.2 Evaluation of Pattern Discovery on Real-Life Data There were three PRI modulation patterns, single, dual and pulse group in the real-life emitter parameter data. In the single PRI modulation, the PRI value across different time slots was unique while for the dual PRI modulation, two different PRI values were observed across the time slots. For the pulse group modulation, on the other hand, pulses were organized in groups, each pulse group with a fixed number of PRI values across different time slots. As can be seen, the PRI modulation patterns across time slots were typical stochastic patterns.
 We compared the discovered stochastic PRI patterns against the ground truth modulation patterns provided from domain experts. During experiments, we applied the default parameter setting as the synthetic data.
 In Fig. 4 , we report the top five stochastic PRI patterns discovered for emitter type  X  X  X , denoted as A 1 , A 2 , ..., A 5 respectively. The estimated PRI measure-ments in the discovered stochastic patterns were represented as solid points and the true PRI modulation pattern values in time slots as horizontal lines. As can be seen, A 1 , A 2 and A 3 were in association with the pulse group modulation, A was in association with the dual modulation, while A 5 was in association with the single modulation. Similar observation could be found for discovered stochastic PRI patterns for emitter type  X  X  X  and  X  X  X , as shown in Figs. 5 and 6 . tern mining methods were able to discriminate the delicate emitter parameter pat-terns. Due to the heavy overlapping between parameter patterns, the traditional discretization strategy and pre-clustering strategy for fuzzy region discovery sim-ply could not work. 4.3 Evaluation of Pattern-Based Transformation on Real-Life Data We compared the emitter identification accuracies of the benchmark Logistic Regression, Multilayer Perceptron, Naive Bayes, SVM, KNN, AdaBoostM1 and Decision Tree methods on the pattern-based transformed data against those on the classic data consisted of the mean values of parameter measurement sets. As can be seen from Table 2 , with our pattern-based transformation, the performance of these benchmark classification methods have been enhanced significantly. This is because we have made a good use of the underlying parameter pattern distrib-utions after the pattern-based symbolic data transformation.
 In this paper, we have proposed a novel incremental hierarchical clustering algo-rithm for stochastic pattern-based symbolic data ( IHCPSD ) to discover stochastic patterns from numeric set-valued symbolic data. To our knowledge, our IHCPSD method is the first one designed for stochastic pattern-based symbolic data. It X  X  robust to pattern overlapping and missing values and adaptable for incremen-tal learning. Experimental results on both synthetic and real-life data indicate that IHCPSD is effective in identifying delicate stochastic patterns and valuable for enhancing classification performance on symbolic data.

