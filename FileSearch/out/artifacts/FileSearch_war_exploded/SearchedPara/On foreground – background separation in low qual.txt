 ORIGINAL PAPER Utpal Garain  X  Thierry Paquet  X  Laurent Heutte Abstract This paper deals with effective separation of fore-ground and background in low quality document images suf-fering from various types of degradations including scan-ning noise, aging effects, uneven background, or foreground, etc. The proposed algorithm shows an excellent adaptability to tackle with these problems of uneven illumination and lo-cal changes or nonuniformity in background and foreground colors. The approach is primarily designed for (not restricted to) processing of color documents but it works well in the gray scale domain too. Test document set considers samples (in color as well as in gray scale) of old historical docu-ments including manuscripts of high importance. The data set used in this study consists of hundred images. These images are selected from different sources including image databases that had been scanned from working notebooks of famous writers who used to write with quill or pencil gener-ating very low contrast between foreground and background. Evaluation of foreground extraction method has been judged by computing the accuracy of extracting handwritten lines and words from the test images. This evaluation shows that the proposed method can extract lines and words with ac-curacies of about 84% and 93%, respectively. Apart from this quantitative method, a qualitative evaluation is also pre-sented to compare the proposed method with one popular technique for foreground/background separation in docu-ment images.
 Keywords Document image analysis  X  Historical documents  X  Color image  X  Binarization  X  Foreground segmentation 1 Introduction Binarization is considered as one of the important prepro-cessing steps in document image analysis (DIA) algorithms. This is so because compared to gray or color information the use of bilevel (foreground and background) information decreases the computational complexity and thereby enables the utilization of simplified analysis techniques. Therefore, in the field of document image analysis efficient binariza-tion has been a subject of intense research during last several years.
 application mainly in the gray-scale domain as research in document processing has so far by and large been restricted to binary or gray-scale area only. On the other hand, with the widespread development of input devices for color im-ages, documents like books, magazines, newspapers, per-sonal notebooks, historical documents, etc. are now often stored into computers so that color information is preserved on the digital data as it is. Therefore research dealing with color documents has also gained considerable attention in the recent past.
 and foreground  X  background separation induce a subtle dif-ference between them. Though binarization essentially does foreground  X  background separation in document images, but as far as color documents are concerned, we view that the later technique (i.e. foreground/background separation) refers to a more general aspect because color documents very often contains foreground elements (and may be back-ground too) in different colors. Therefore, apart from label-ing the image pixels as foreground or background, it seems to be more meaningful (and perhaps useful too in many DIA applications) if different labels (depending upon their color similarity) are maintained within different foreground (back-ground) entities.
 documents have not been well tested or extended for color documents. Instead, a very few studies that have been pro-posed for foreground extraction in color documents are quite different in nature from the traditional binarization methods and have been restricted to color domain only. In this sense, a gap is observed regarding the generality of the binariza-tion techniques concerning the application domain (gray or color) and a more general approach is therefore called for. fers regarding the type (printed or handwritten) of docu-ments being processed. Though printed documents, in gen-eral, show a well-contrasted background and foreground, such thing may not hold for many handwritten manuscripts. Furthermore, historical documents impose different types of degradations including aging effect, noise, uneven illumina-tion, etc. Many of the existing approaches working in the gray-scale domain have addressed some of these issues but several other difficult situations still remain unaddressed. For example, in many handwritten manuscripts of histori-cal/literary interest, text has been written with quill or pencil that sometimes does not generate very well-contrasted fore-ground. Moreover, stroke marks are very often spread over the page background. Effective binarization in such cases still remain a challenging task.
 issues and bridging the observed gaps within its capacity. Initially, it presents a general binarization techniques which is primarily aimed for (but not restricted to) color docu-ments and applicable to gray-scale as well. The algorithm is designed for binarization of varieties of documents starting from images of well-contrasted foreground and background to those suffered from many degradations like uneven illu-mination, noise, aging effect, etc. Moreover, the approach is applicable for printed as well as handwritten manuscripts. After binarization is achieved, the proposed technique at-tempts to locate different regions (based on color similarity) within the foreground part and give different labels to them and thereby helping other immediate DIA applications like page segmentation, text location, etc. 1.1 A brief survey of popular binarization and foreground X  X ackground separation techniques As mentioned earlier that binarization because of its impor-tance has been a subject of intense research interest during the last several years and summary of such techniques can be found in several papers like ones in [1 X 4]. These techniques have, so far, been applied for binarization of grey-scale im-ages but their potential for binarization of color documents has not been properly investigated.
 that most of them focus on one aspect of choosing thresh-old either globally or locally. The global threshold selection methods (e.g., [ 5 , 6 ]) assumes the gray-level histogram is bi-modal and then chooses a single threshold at valley point to label pixels into foreground or background classes. Experi-ments show that such a technique is simple and often effec-tive too but breaks down when illumination, background or noise characteristics are nonuniform. As a remedy to these problems, local or adaptive thresholding schemes have been proposed. In local thresholding, threshold values are deter-mined locally, e.g., pixel by pixel, or region by region. (i.e. pixel or region) based on local statistics [ 7 ]. For ex-ample, the approach proposed by Niblack [ 9 ] attempts to vary the threshold over the image based on the local mean and standard deviation computed in a small neighborhood of each pixel. O X  X orman X  X  method [ 10 ] chooses the thresh-old to optimize local connectivity whereas Tsai X  X  method [ 8 ] tries choose threshold to preserve local low-order moments. Liu and Srihari [ 11 ] used the global Otsu [ 5 ] algorithm to ob-tain candidate thresholds. Then, texture features were mea-sured from each thresholded image, based on which the best threshold was picked. Sauvola et al. classify page contents to background, pictures and text prior to apply different ap-proaches to define threshold for each pixel. Recently, Gatos et al. [ 12 ] proposed another adaptive binarization technique for gray-scale images of low quality historical documents where Niblack X  X  method [ 9 ] is initially applied to detect foreground parts but final binarization result is improved us-ing several postprocessing steps.
 traction techniques that have been proposed for color docu-ment images are broadly based on color clustering or color segmentation principle and in this sense, they are quite dif-ferent from traditional threshold selection algorithms. How-ever, despite the large number of proposed algorithms for color image segmentation [ 14 ] only a handful of them have found direct application for the document image processing. This is so because use of classical segmentation algorithm exhibit difficulties to tackle several document defects like stains, humidity marks, degradation of ink, paper, etc. Large size of color document images is another bottleneck for ef-ficient use of the traditional segmentation strategies. Rather, generic algorithms, in few cases, have been customized in several ways for efficient background  X  foreground separa-tion in color document images.
 centrates on extraction of text parts. For example, studies by Lopresti and Zhou [ 17 ], T. Perroud et al. [ 18 ], Wang and Kangas [ 20 ], Loo et al. [ 23 ] etc. deal with locating and ex-tracting text in color document images. These methods are by and large based on some color clustering approach (e.g., histogram-based color clustering [ 17 , 18 , 20 ], region grow-ing [ 23 ]) followed by several other processing steps to locate textual elements in a document image. Experiments have been conducted on images of printed documents [ 18 ], of In-ternet pages [ 17 , 23 ], scene images from digital camera [ 20 ], etc. Images are mostly well-contrasted and not very much suffered from image defects that are generally observed in historical documents.
 Leydier et al. [ 25 ] are focused on separating foreground and background in color document images. The approach pro-posed in [ 24 ] works in HSV color space and color map in a document is identified by a color quantization algorithm that quantizes image colors into six levels which are found to include all distinct foreground and background colors for a batch of archive documents on which the method has been tested. The method involves a manual registration of tem-plate color maps. A foreground color is identified through its matching with the template color maps by using a fuzzy color classification algorithm.
 foreground  X  background segmentation is achieved by a se-rialized k-means algorithm. However, the approach involves a manual intervention to set the number of logical classes and the color samples for each logical class to initialize the original centers of clusters in the k-means algorithm [ 29 ] which is applied on a sliding window (e.g. 6  X  6 ) so that the segmentation is neighbor-dependent. Three parameters have been used to take special measures to prevent class swap-ping (which is often done by an unsupervised clustering al-gorithm like k-means), to overcome local stains in the im-age, and to control the serialization of the algorithm. The algorithm has been tested with several ancient manuscript images and it observed that the parameters along with the window size which can have a heavy impact on the perfor-mance of the algorithm as well as on the computational time. ground  X  background separation though in the context of compression. The approach is based on a multiscale bicolor clustering algorithm by considering several grids of increas-ing resolution. Each successive grid delimits block whose size is a fraction of the size of the blocks of the previ-ous grid. The bicolor clustering algorithm is applied on the blocks of the first grid and a foreground/background color for each block in this grid is obtained. The blocks of the next grids are then processed and this process continues un-til convergence of the foreground and background colors. This technique works quite well for a large category of doc-uments in the gray as well as in color domain. However, it fails in cases where documents contain low contrasted fore-ground and background as observed in many handwritten manuscripts. Some demonstrations of such failure are illus-trated in Sect. 3 that presents our experimental results. ground extraction techniques. It no way attempts to present an exhaustive summary in this area. Rather, popular tech-niques are only referred, their relative strength, weaknesses and domain of application are precised. 1.2 Our approach To design a generic document image binarization that works in both gray and color domain and can still handle a variety of degradation in documents including historical ones (pages from old printed books, handwritten manuscripts, microfilm images, etc.), we propose a new method that initially uses a connected component labeling approach to capture the spa-tially connected similar color pixels. This helps to rapidly locate zones containing information of interest. Next, dom-inant background components are determined looking at their size (in terms of member pixels) and then the entire im-age is divided into number of rectangular blocks (essentially not disjoint and are of different sizes) one around each dom-inant background components. These blocks represent local uniformity of illumination, background, etc. and respective foreground parts are treated against these local uniformities. This provides the adaptive nature of the proposed algorithm.
 like structure as explained later in Sect. 2.4 . Blocks in a tree are hierarchically connected and parent-child relation is es-tablished based on their size and geometric layout (disjoint or overlapping). Blocks in a tree are subsequently processed in a top  X  down manner (i.e. from root to leaves). Compo-nents in each block undergo a bicolor clustering by tradi-tional k-means approach where initialization is done using clustering results obtained by processing its parent block. Processing of all blocks results in binarization of an input document image.
 foreground  X  background separation or binarization results gains from two other aspects: (i) components represent much larger entities than isolated pixels and each component con-sist of spatially connected pixels having similar or near-similar color values. This aspect improves the performance of k-means because it gets less confused to cluster a compo-nent compared to the case when it deals with isolated pixels, (ii) to implement k-means, cluster centers are not initialized blindly rather the initialization is done by true background and foreground color values obtained by using some con-textual information as described later in Sect. 2.5 .Suchan initialization technique results in a quick convergence of k-means with better clustering output.
 in case of color image, further go through an unsuper-vised color clustering to detect different color regions (or elements) within the foreground region. The remainder of the paper is organized as follows. Section 2 presents the proposed binarization technique while Sect. 3 outlines the approach for detecting individual color regions within the foreground part. Experimental results and observations are presented in Sect. 4 . Section 5 concludes the paper with some discussions on future scope of research in this area. 2 The proposed method Our proposed method consists of a chain of processing steps asshowninFig. 1 . Optional steps are marked with dou-ble ellipses and similarly optional output requirements are marked with double rectangles. The major steps are: (i) pre-processing, (ii) connected component labeling, (iii) detec-tion of dominant background components, (iv) segmentation of the entire image into hierarchically arranged rectangular blocks of different sizes, (v) bicolor clustering in each block, and (vi) foreground segmentation. Each of these steps are explained below with some illustrations. 2.1 Preprocessing step Preprocessing, in our approach, is treated as an optional step as it is required for certain types of images while others may directly be passed to the next stage. One of the preprocess-ing steps deals with color smoothing in the input image. In our application, a simple smoothing technique is involved and it is found to be efficient for a large class of documents. In this approach, each pixel color is reassigned to an aver-age color value found within a small region surrounding that pixel. Color of each pixel ( X ) is redefined as the mean color computed in a 3  X  3 window surrounding the pixel, X ( X be-ing at the center of the window). However, for applications dealing with specific documents, one may incorporate more sophisticated smoothing techniques or image enhancement techniques like one in [ 13 ]. For example, the binarization method proposed in [ 12 ] uses a low-pass Wiener filter for this purpose.
 document inside the document image. In many cases, doc-uments mostly the historical ones contain a dark outer re-gion surrounding the document and this often happens due to the requirement to scan such document against a dark back-ground. Figure 2 a shows one such document. Antonacopou-los and Karatzas [ 28 ] address this issue. They assume the real paper edges to be approximately straight and identifi-cation of outer edges starts by examining the edge pixels of the image for each of the four edges (top, bottom, left, and right). From each edge pixel the process moves inwards (row or column wise) and the difference in Lightness for each pair of adjacent pixels is recorded. A pixel is marked as a poten-tial paper edge one if the difference is found to be above a threshold value or the difference in Lightness between the current pixel and the average of the previous pixels exam-ined is above the threshold. A straight line is subsequently fitted on each of the four potential paper edges.
 tive technique that initially computes row and column wise run length of pixel colors. Only one color channel is used for color documents. Moreover, instead of 256 levels of a color (or gray values), a low resolution of 32 levels has been used to measure run length. Next, maximum run length is noted for each row and column and first order difference is calculated as follows. Let r i be the maximum run length noted for the i-th row and R be the number of pixel rows. First order difference is computed as,  X  i =| r i  X  r i + i = 0 ...( R Actual page borders (top and bottom) are found by locating two picks (top and bottom) in the histogram of  X  i . Similar operations are carried out column wise to find left and right page borders. Figure 2 b shows the located paper region (out-side is set to white) for the image in Fig. 2 a. This method though insensitive to small amount of skew (  X  5  X  as veri-fied experimentally) needs modification in case a document suffers from large amount of skew during scanning. 2.2 Connected component labeling (CCL) After preprocessing step, a connected component labeling (CCL) is executed on the entire image. But as the traditional CCL algorithm assumes the input image in binary mode and only considers spatial connectivity (e.g. 4-connectivity or 8-connectivity), we modified this algorithm so that it captures color information and spatial details at the same time. The modified algorithm is presented under Algorithm-I where push() and pop() represent the traditional push/pop op-erations associated with a stack data structure.
 turned by the Algorithm-I will differ in different color spaces and even within the same color space (even for gray scale image) results differ with different values of the threshold, A low threshold value generates large number of connected components (resulting in excessive oversegmentation), on the other hand, higher values of the threshold wrongly com-bines pixels not having enough color similarity.
 Algorithm-I for one example image (a small image is in-tentionally chosen for better understanding). Responses in four different color spaces namely, RGB, HSV, YCbCr, and CIE L*u*v* are presented and within the same color space results with various threshold (  X  ) values have been shown in Fig. 3 . The integer number given at the bottom-right corner of each image represents the number of connected compo-nents obtained for a particular threshold value within a cho-sen color space.
 answers for two important aspects: (i) which color space must be used to execute CCL? and (ii) how to choose the threshold value (  X  ) automatically? Gray-scale images con-cern only with the second aspect.
 concerned, we have experimented with four different color spaces namely, (i) RGB, (ii) HSV, (iii) YCbCr, and (iv) CIE L*u*v* (details about these color spaces can be found in [ 14 , 15 ]). This experiment was initially conducted on a set of 20 images. We have carried out experiments to check CCL results if the color spaces (for the same image) are forced to generate the same (or nearly the same) number of compo-nents (by controlling the threshold value, (  X  ) in each indi-vidual color space).
 segmentation i.e. generate more number of components than actual ones. However, among the four spaces, a single connected component (as perceived visually) in HSV is broken into less number of components and therefore, CCL under HSV generates less number of connected compo-nents for an image (images in Fig. 3 also well-represent this phenomenon). This characteristic becomes helpful in subsequent processing stages and increases computational efficiency. Based on these observations HSV is chosen as the color space in this present experiment. Hence, choice of HSV as the color space is completely empirical rather than based on any general theory. In fact, [ 14 ] presents several merits and demerits of different color spaces to show no one is in general superior to another.
 it in more than one color space and then producing the final results by comparing the results obtained in multiple color spaces. Otherwise, instead of using one color space at a time, more than one color space can be used to represent color of an image pixel increasing the feature dimensions used to compute  X  L and D k in CCL. This has been tried by some studies like [ 25 ] where a six-dimensional vector (RGB and HSV values together) is used to represent color feature of a pixel.
 varying nature of documents, in our approach, we prefer to select the threshold value (  X  ) by some automatic means rather setting it to a predefined value. The threshold is calculated from the input image by considering only the adjacent pair of pixels in row and column wise manner. The maximum color distance between such pixel pairs are recorded for each row and column and an average of these values serves as the threshold,  X  used in the Algorithm-I. A few examples of CCL results obtained at the automatically selected  X  are shown in Fig. 4 .

Algorithm-I : Connected component labeling (CCL) in Input: Color Image (I) and Output: Labeled image consists of z number of connected components, c 1 , c 2 ,..., c z . Initialization: All pixels are initially unlabelled. S: is the stack of pixel coordinates; L: is the label value and initialized to 1; for i = 1 to H (image height in pixels) for j = 1toW(imagewidthinpixels) end for; end for; 2.3 Identification of dominant background Let c 1 , c 2 ,..., c z be the z number of connected components found after execution of the Algorithm-I. Each component ( c i is the i -th component) is represented by the following tuple: i , S where i is the component label, S i is the size of c i in terms of number of member pixels, C i ( x , y ) is the center of inertia of c i . The term  X  X box X  represents bounding box of c i (i.e. the minimum upright rectangle surrounding c i ). Basically,  X  X box X  records the top-left and bottom-right coordinates of the corresponding bounding box. The next three values in ( 1 ), namely  X  h i ,  X  s i ,and  X  v i represent the mean hue, satu-ration and value for c i . The last entry i.e. { m i } is the list of member pixels belonging to the i -th component. In fact, this list is a collection of x and y coordinates of each m i .Obvi-ously, this list will have S i number of ( x , y ) entries one for each member pixel.
 size) values and mean of S i values is computed. Let be this mean. Some of background components (i.e. com-ponents representing backgrounds) are located at this stage by comparing their size against  X  S . The idea is to capture heavier or bigger (with respect to  X  S ) components which are assumed to represent background parts. This assump-tion is quite general because the foreground parts, at large, contains only about 5% (sometimes even less) of the entire image (this is very much true for printed pages as well for handwritten manuscripts).
 to their mean size values, it would be clear that very large (with respect to the mean size of the components) compo-nents basically represent multiple backgrounds parts which are either spatially disconnected or dissimilar in color. If the background of an image is uniform then only a few num-ber of background components are located but this num-ber increases if (color) non-uniformity of the background increases. The background components identified by this way captures the local uniformity of color or illumination. A foreground part, therefore, has to be identified with re-spect to its nearest background component instead of any global background reference. This process provides the re-quired adaptivity of the algorithm as demonstrated later. ponent if S i &gt; X  X  S ,where  X  is a scalar whose value is not directly a user-defined one. Rather, to minimize the heuristic nature of our proposed algorithm, value of  X   X   X  is determined dynamically. It is determined in a way so that the combined value of  X  X  S equals to certain percentage (in our experi-ment, it is set to 10%) of image area. Therefore, the value of  X   X   X  is calculated locally and depends on the particular input image X  X  height, width and the mean size of the components found in that image.
 equality condition represents dominant backgrounds in the image. Figure 5 b shows the dominant background com-ponents extracted for the image in Fig. 5 a. Execution of Algorithm-I for this image results in 16,439 connected com-ponents which shows a mean size of 182.69 pixels and only 12 components have been identified as background components. Identification of these background components shows the local non-uniformity in the background of the in-put image. Components representing foregrounds are much smaller in sizes; however, there are various background components which are small in size and remain unidentified at this stage.
 components and B represents this subset of l components. Let c b (where b  X  X  1 ... l ] ) be the biggest component and its color is taken as the reference color for background parts. Let B ref denote this reference background color. A refer-ence foreground color ( F ref ) is then searched from the rest of all other components as follows. For each component c i ( i = b ) its distance in color space is measured with re-spect to c b and the component ( c f ) showing the highest dis-tance is treated as reference foreground part. In other word, color ( c f )  X  color ( c b ) &gt; color ( c i )  X  color ( ( b or f ) .Thecolorof c f is assigned as F ref . Use of B ref F ref will be clear in subsequent sections. 2.4 Formation of rectangular blocks and their hierarchical arrangement After identifying the set B , the entire image is divided into several rectangular blocks. This is done by using the bound-ing box information (i.e. bbox information in ( 1 ) avail-able with each component). Hence, l blocks are identified for l background components. For example, Fig. 5 cshows the blocks formed by 12 dominant background components (shown in Fig. 5 b) for the image in Fig. 5 a. Next, these blocks are arranged in a hierarchical structure following a graph theoretic approach. Geometric layouts of the blocks and the area covered by each block are considered for such an arrangement which induces a tree structure. The parent  X  child relationship between two blocks in the tree are estab-lished following the Algorithm-II.
 tree and other blocks overlapping with (or contained in) the root block become the leaves and nonleaf nodes of the tree. From the Algorithm-II, it is to be noted that if a block ( G i ) is overlapped with (or contained in) more than one block then the parent of G i becomes the one that is larger than G i but the smallest among the blocks with which G i is overlapping (or contained in). Figure 6 demonstrates the tree that is formed with the blocks in Fig. 5 c. In this case, the largest block contains all the other blocks and therefore, only one tree is formed. But there may be cases where the largest block does not overlap or contain other blocks and disjoint sets of overlapping (contained in) blocks may result in. In such cases, each set of blocks generate a tree and final arrangement of blocks results in a forest (collection of trees) structure. However, in any case, the Algorithm-II defines a parent-child relationship, if exists between two blocks. Let G 1 , G 2 ,..., G l be the list of l -blocks corresponding to l background components.
 Sort the blocks in a descending order on the area covered by them. for i = 1to l  X  1 for j = i + 1to l end for; end for; 2.5 Bicolor clustering The blocks as described in the preceding section are ar-ranged in a hierarchical structure to implement a multi-scale bicolor clustering of the connected components obtained af-ter execution of CCL. In our approach, such a clustering has been achieved by traditional k-means algorithm [ 29 ] with slight modification for the initialization of the algorithm. For a tree of blocks, bicolor clustering algorithm is initially ap-plied on root block for which one cluster (assumed to repre-sent background) is initialized with B ref and another cluster is initialized with F ref obtained at the stage described under Sect. 2.3 .
 ner blocks (leaves and nonleaf nodes) of the tree, one cluster is initialized with the same color as that of the background component represented by the block (note that each node representing a block is originated by a background compo-nent identified at the stage described in Sect. 2.3 )butthe cluster representing foreground components is initialized by the foreground color found for the parent of the current node (i.e. block). This modification in initializing the bicolor clus-tering algorithm introduces a bias in the process to rapidly attract the components toward the true foreground and back-ground clusters.
 side a block is implemented to cluster the connected compo-nents contained by the block. The constituent components for a block is determined by looking at the C i ( x , y ) (see ( 1 )) of the components. Execution of bicolor cluster-ing in each block classify the block X  X  member components into background or foreground components. In fact, all com-ponents are tagged with a one-bit binary flag (this is done by adding one more binary field with attributes shown in ( 1 )) to indicate whether a component belongs to background or foreground part. Therefore, processing of all blocks (ar-ranged in a tree or forest) results in a binarized version of the input image. Figure 6 b shows this end result for the image in Fig. 5 a.
 background components may not cover the entire surface of the input image. In these cases, some connected com-ponents will remain unprocessed by the bicolor clustering executed on the tree (or forest) of blocks. Therefore, a final check is done to detect unclassified connected components. This is achieved by another round of execution of bicolor clustering involving the unprocessed components only and in this case, initialization of the algorithm is done by us-ing reference background ( B ref ) and foreground ( F ref ors obtained previously (as explained in Sect. 2.3 ). Figure 7 demonstrates this process. Figure 7 a shows the input image, Fig. 7 b presents the intermediate foreground extraction re-sult where some regions (painted in gray color) remained unprocessed as they were not covered by the blocks identi-fied as dominant background. Final run of bicolor clustering algorithm produces the ultimate binarized version as shown in Fig. 7 c. 2.6 Foreground segmentation The processes described in the preceding sections extract foreground parts from an input image. This can, in general, be viewed as binarization of the input document. However, on some occasions documents (mostly the color documents) contain foreground parts in different colors and therefore, separation of these element will probably help subsequent document analysis tasks. This section describes this process of segmenting foreground elements into different clusters each one representing foreground parts of similar color. ponents labeled as foreground components. Each of these q components are tagged with their mean color values as shown in ( 1 ). These components are subject to a color clustering to achieve foreground segmentation. Here the clustering is essentially an unsupervised one to avoid user interaction at this stage. The traditional Maximin clustering algorithm is slightly modified for this purpose. The follow-ing algorithm is a modification of the Maximin clustering algorithm to achieve the said task: Let c 1 , c 2 ,..., c q be the list of q -foreground components. 1. Compute d  X  = 2. Let ( c a , c b ) where a = b and 1  X  a , b  X  q be the pair 3. If D ( c a , c b )&gt; d  X  then choose z 1 = c a and z 4. Compute distance ( D ) between all other samples ( c i 5. If d k &gt; d  X  then N c = N c + 1; z N c = c k ;gotostep4. a second cluster, our approach described in Algorithm-III seeks whether a second cluster exists (step 3 of the algo-rithm) using a threshold ( d  X  ) computed dynamically (in step 1) from the image in hand. Some of the foreground segmen-tation results are shown in the next section presenting exper-imental details. 2.7 Analysis of the Algorithm Time and space complexity of the proposed algorithm can be analyzed in the following manner. Let n  X  m be the size of an input image in pixels and loading of this image needs a space of an order of ( n 2 ) (considering n  X  m  X  n 2 ). Execu-tion of the pre-processing step (Sect. 2.1 ) does not demand any viable extra space but involves a time complexity of ( n 2 ) . Execution of connected component labeling (CCL) of Sect. 2.2 imposes a time complexity of ( n 2 ) . Storing of the labeled image needs an extra space of ( n 2 ) .However, one can avoid the use of this extra space by maintaining a la-bel tag with each pixel in the original image itself. Moreover, implementation of CCL needs an extra space for stacking of pixels and this adds a linear space complexity of ( n ) . of CCL. It is to be noted that z n 2 . Storing of these z -components requires a space of ( z ) andsorting(based on their size value) of components involves a time com-plexity of ( z log z ) . This sorting is required to identify dominant background components as described in Sect. 2.3 . Let l background components are identified (induces a time complexity of ( l ) ) generating l number of blocks to be arranged in a tree (or forest ) structure(Sect. 2.4 ). Such a data structure needs an extra space of ( l ) and arrange-ment of l blocks into a tree (or forest ) requires a time com-plexity of ( l 2 ) (see Algorithm-II). Note that complexity of Algorithm-II can be reduced to ( l log l ) but considering the minor gain in overall complexity, this modification was not explored in our current experiment.
 blocks. Let a block, G i contain o i connected components and t i be the number of iterations needed for the convergence of k-means in block G i . Note that l i = 1 o i = z . Hence, pro-cessing (Sect. 2.5 ) of each block G i involves a time com-plexity of p i ( o i ) . Time complexity to process all blocks is therefore, l i = 1 [ p i ( o i ) ] which roughly equals to p where p = l i = 1 p i and ( o i )  X  ( z ) (though  X  i , o Additional space complexity to implement bicolor cluster-ing is quite low as just two cluster centers are maintained for each block resulting in a low constant (linear) space require-ment.
 (Sect. 2.6 ) induces a time complexity of ( q 2 ) for the first two steps (Algorithm-III). The rest of the steps in this algo-rithm are executed in ( q ) time. Moreover, the algorithm is single-pass in nature. Like k-means the Algorithm-III also does not impose much space complexity as only space (addi-tional) requirement is to keep information about N c clusters found among the q foreground components. Table 2 sum-marizes the time and space complexity involved by the dif-ferent steps of the proposed algorithm. The method shows a total complexity expressed as, 3 ( n 2 ) + ( z log z ) + ( ( l 2 ) + p [ ( z ) ] + ( q 2 ) + ( q ) which is of the order of ( n 2 ) which comes as the dominating term in the preceding expression. Similarly, space complexity is also ( n 2 ) . 3 Test data, experimental results and discussions As the real challenge lies in dealing with low quality doc-uments showing different degradations due to uneven illu-mination, aging, scanning, etc., creation of test data puts emphasis on processing of documents of this sort includ-ing historical documents mostly handwritten manuscripts of famous personalities. Both printed as well as handwritten manuscripts in color and gray-scale are considered. For the current experiment, documents dominant in text (printed or handwritten) are only taken into consideration.
 divided into three parts among which first two consider color documents while other deals with gray-scale documents. Most of the images are scanned at 300 dpi (a few are at 150 dpi) and images are quite large in size (average size is about 3M pixels) as often encountered in reality.
 ing (or learning is real sense) component, there was no need of using a training data in the experiment. However, the method makes use of one user-defined threshold value, i.e. the combined value of  X   X  X   X  in Sect. 2.3 (please note another parameter  X   X   X  used in Algorithm 1 is determined dynami-cally). Therefore, 20 images are initially used to (i) empir-ically choose the right value for  X   X  X   X  (in this experiment, the combined value of  X  X  S equals to 10% of the total image area) and (ii) choose a color space (HSV in this experiment) convenient for the present purpose. In strict sense, this set of 20 images is not called a training set, as the algorithm has not been trained on this set. However, these images are excluded from the final test set.
 parts. Under Part-I of the test set, 20 test documents are taken from the  X  Ancient books, and Historical Documents  X  category of  X  DjVu Zone Digital Library . X  1 Selection of these documents enable us to compare our results with those by DjVu technique [ 27 ]. Most documents under this group are century old, some are more than 200 years.
 which are in color scanned from working notebooks of several famous writers of 19th and 20th century. Samples include images from the notebooks of Gustave Flaubert (1821 X 1880), James Joyce (1882 X 1941), etc. Many of these manuscripts had been written with quill or lead pencil (not ink) and pencil marks are frequently spread over the background. Because of the very low contrast between foreground and background parts, efficient extraction of foreground marks seems quite difficult for these documents. Part-III of the dataset considers 20 gray-scale documents which are mostly scanned images of century old handwritten manuscripts, microfilm images, etc. Out of these 20 docu-ments, 10 are taken from manuscript of  X  Madame Bovary  X  2 and others are taken from the database of correspondences received by Emile Zola (1840 X 1902). These correspondeces are recorded on microfilms which has been scanned into images using Canon MS 800 Microfilm scanner. 3 taken from Part-I of the test dataset. Figure 8 bandc(and similarly Fig. 8 e and f) compares the foreground extraction results obtained by DjVu [ 30 ] and our proposed technique. These documents are taken from DjVu document database where DjVu achieves good extraction results but our results are also comparable to that DjVu as checked visually. A quantitative evaluation is presented later part of this section. low contrast between foreground and background parts in many of these documents, DjVu very often fails to prop-erly extract the foreground parts, whereas our proposed method, in major cases successfully locate the foreground elements. Figure 9 presents a few examples where our tech-nique outperforms DjVu results. Test results on Part-III doc-uments which are in gray-scale show that the proposed ap-proach is equally effective for gray-scale images. Some re-sults are presented in Fig. 10 where Fig. 10 d shows result on old handwritten manuscript scanned at gray-scale image (Fig. 10 c) and Fig. 10 f shows result on a microfilm image (Fig. 10 e).
 amination of foreground extracted from the test images reveals that one of the three phenomena takes place: a foreground part (visually perceived) is (i) extracted cor-ground part at all in the corresponding image. Therefore, an ideal method for evaluation of foreground extraction results should consider all these three aspects. However, several nontrivial problems make designing of such an ideal eval-uation method extremely difficult. Basic question is what would be the unit for measuring extraction efficiency. For example, measuring efficiency at the pixel level is difficult as no groundtruth (i.e. whether a pixel belongs to foreground or background) is available for the test images.
 ture, accuracy could have been measured at the stroke level. But designing a consistent evaluation technique working at the stroke level is equally difficult due to lack of a proper definition of stroke in the handwritten data being dealt in the present study (images shown in different figures of this correspondence well represent this fact). Therefore, quan-tification of accuracy of extraction is finally done at two dif-ferent levels: lines and words. Evaluation of extraction re-sults is done by manually computing the number of lines and words in each original image ( I o ) and in the corresponding extracted foreground ( I e ). Next, extraction efficiency ( the line level, and w : at the word level) is measured as: = No. of lines (correctly extracted) in I e very clear in some original images and therefore, the counts (mainly the word counts) are based on manual perception only. Errors in extractions are classified into two categories namely, (i) partially extracted and (ii) completely missed. A line is partially extracted if some of its constituent words are missed, whereas extraction of a word is partial if some con-stituent strokes are missed. Table 3 presents the evaluation results for the combined set of 80 test documents. Evalua-tion results for DjVu technique is presented for a compara-tive evaluation. Table 4 presents evaluation results in details for 10 samples (handwritten manuscripts of famous writers and are considered as historical documents of special im-portance) that show the marked improvement achieved by our proposed method over the DjVu technique in extracting foreground parts.
 ination of extraction/binarization results reveals that though the proposed approach successfully works for most of the images, in a few cases, it fails to locate all the visible fore-ground parts of an input image. Figure 10 f demonstrates such a problem for processing of the image (which is a mi-crofilm image) in Fig. 10 e. Several strokes are broken in the extracted foreground. It is analyzed that such problems oc-cur more in handwritten manuscripts than in printed docu-ments and it is mainly due to (i) very weak stroke marks, (ii) very low contrast between a foreground stroke and its cor-responding background, and (iii) spreading of ink or pencil marks over the background.
 seeping of ink from the reverse page side imposes another problem. It is observed that when a document having show-through effect is subject to foreground extraction, marks present due to show-through effect are sometimes identified as foreground. Figure 11 showssuchanexample where original image is suffered with bleed-through effect and extracted foreground contains several bleed-through strokes. However, in such cases bleed-through marks are quite prominent and look similar (as visually perceived) to the true foreground parts and therefore, identifying them as foreground parts should not be judged as any weakness of the proposed algorithm which primarily deals with fore-ground extraction/binarization. Rather, some specialized technique similar to ones proposed in [ 13 , 31 , 32 ] can be used to tackle the problems related to bleed-through effect. We treat this part as an future extension of the present study. ages where the background contains a grid like structure, some portions of the grid is also inconsistently labeled as foreground along with the actual foreground parts. Figure 12 shows such an example. Original image and extraction result are shown in Fig. 12 a and b, respectively. In this case, color similarity among the grid marks and the handwritten parts is so close that they are not separated even after foreground segmentation.
 is studied for color images to segment the foreground parts into regions based on similar colors. Performance of segmentation results is judged by checking how many color maps are properly located against the actual number of maps (marked manually) in the foreground part of an input image. Experiments show our proposed algorithm (i.e. the Algorithm-III) rarely misses any color map present in the foreground parts but on a few occasions, more than one color maps are generated for a single (as perceived visually) color map. Figure 13 shows an example of foreground segmentation where Fig. 13 a shows a document with three visible color zones: (i) background (ii) handwriting text and (iii) red strokes. Figure 13 b shows result after foreground extraction and 13(c) exhibits that two different color maps are identified within the foreground parts.
 Sect. 2.7 , time and space complexity of the proposed method is discussed. The absolute run time required by the method is also analyzed. Programs (written in Matlab and C) when executed on a server (having two processors of 1.5 GHz clock speed, primary memory of 1 GB and shared by about 30 people) take on an average 8.17 s to produce the back-ground/foreground separation result for images of an aver-age size of 2000  X  1500 pixels. This time does not include the time for reading the image into memory. This is done by Matlab tool and it takes around 10 to 15 s on a desktop (P-IV, 1.7 GHz) machine with 256 MB RAM. The average time units taken by intermediate steps are like these: (i) pre-processing steps: 1.25 secs; (ii) connected component label-ing: 2.75 s, (iii) arrangement and processing of blocks: 3.5 s, (iv) foreground segmentation: 0.67 s. This analysis further shows the computational efficiency of the technique as com-pared to many other existing adaptive binarization methods which are often computationally quite expensive. For exam-ple, method described in [ 25 ] takes about 500 s to process a image of size 3000  X  2000 pixels on a latest high-end PC. 4 Conclusions In this paper, an efficient approach is presented for back-ground/foreground separation in document images with an emphasis on processing of low-quality color documents for which a few studies have been reported so far. Algorithm is tested on varieties of documents staring from gray-scale to color, printed and handwritten manuscripts, documents with well-contrasted text as well as those suffering from degra-dations like uneven illumination, aging, etc. which quite of-ten observed in historical documents. Test documents con-tain several samples scanned from handwritten manuscripts of famous writers. These manuscripts are written with quill, pencil, etc. and generate low contrast between background and foreground. Results show enormous adaptability of the proposed approach with the uneven illumination or local changes in the background and foreground color.
 tion, compression of documents where the foreground and background layers are separated to achieve better compres-sion, locating text in documents, image enhancement in dig-ital preservation of ancient documents etc. However, the al-gorithm has so far been tested on text dominant documents only. Behavior of this algorithm for documents containing in nontextual elements like graphics, half-tones, etc. is consid-ered as future extension of the present work.
 needs benchmarking and groundtruthing of foreground and background pixels in sample documents. This needs use of extensive manual intervention and hence, finding an efficient way (may be semiautomatic in nature) of achieving it could be treated as another future direction of the current study. Design of several other processing steps for initial enhance-ment of the input image, bleed-through removal, improve-ment in foreground segmentation results, etc. needs further research.
 References
