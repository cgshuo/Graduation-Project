 We consider the problem of finding neighboring class sets. 
Objects of each instance of a neighboring class set are grouped using their Euclidean distances from each other. Recently, location-based services axe growing along with mobile com-puting infrastructure such as cellular phones and PDAs. 
Therefore, we expect to see the development of spatial databases that contains very large number of access records including location information. The most typical type would be a database of point objects. Records of the objects may con-sist of "requested service name," "number of packet trans-mitted" in addition to x and y coordinate values indicating where the request came from. The algorithm presented here efficiently finds sets of "service names" that were frequently close to each other in the spatial database. For example, it may find a frequent neighboring class set, where "ticket" and "timetable" are frequently requested close to each other. 
By recognizing this, location-based service providers can promote a "ticket" service for customers who access the "timetable." Recently, location-based services are growing along with mobile computing infrastructure such as cellular phones and 
PDAs. Consequently, we expect to work with spatial databases that contain a very large number of access records involving location information. Recent progress in computing facil-ities makes it possible to integrate geographic information systems (GIS) and large databases that contain spatial in-formation. Efficient data management and retrieval in such integrated 
GISs have already been investigated [5]. There are several research projects that focused on spatial data mining, i.e., mining knowledge or frequent patterns in spatial contexts from huge spatial databases [9, 8, 4, 7, 6, 12, 3]. In this pa-per, we consider a spatial data mining problem of finding fre-quent neighboring class sets. The members of a neighboring requires prior specific permission and/or a fee. KDD 01 San Francisco CA USA Copyright ACM 2001 1-58113-391-x/01/08...$5.00 Table 1: Access Reeords of Mobile Services 
ID Position Service .. #Packets xxx (14975,27020) Weather .. 2 xxx (16723,24301) Timetable .. 1 xxx (15521,26441) Ticket .. 4 xxx (14373,26752) Timetable .. 1 class set are grouped according to their Euclidean distances from each other. Especially for emerging location-based ser-vices, such frequent neighboring class sets yield important insights for providing attractive location-sensitive advertise-ments, portals, promotions, and so forth. 
Table 1 shows one of the most typical spatial databases con-taining point objects. The database contains access records of mobile services of a certain carrier or a location ser-vice provider. Each record in the database consists of at-tributes "Service," indicating the name of requested ser-vice, "#Packets," the number of packets transmitted in the request, and "Position," the x and y coordinate values in-dicating where the request came from. 
We consider the problem of finding class sets, which are sets of services in the database that are frequently issued close to each other. Assume that the points in Table 1 are distributed on the map in Figure 1. In the figure, the ac-cess records of Timetable, Ticket, and Weather services are shown as circles, triangles, and squares, respectively. Note that a circle (Timetable) lies close to a triangle (Ticket) four times. Similarly, a circle lies close to a square (Weather) three times and a triangle lies close to a square two times. Moreover, all three kinds of points lie close to each other two times. We call such class sets (sets of Service) neighboring class sets, where the objects form a close group with each other. 
If the number of instances of a neighboring class set is larger than a specified value, called the minimum support value, we call the class set a frequent neighboring class set. In this paper, we present an efficient algorithm for finding frequent neighboring class sets from a large spatial database. 
For example, we may find a pattern where Ticket and Timetable are requested close to each other as a frequent neighboring class set. By recognizing this, a location service provider can offer a Ticket service to customers who access the Timetable by displaying a link to Ticket services on their mobile de-vice. 
This paper assumes a database that contains x and y co-ordinate values like Table 1. We also assume that each point has some features like Service in the table. We classify each point by using such features. Therefore, we can assume that each point can have its own class label. 
Figure 2 shows an example of a valid instance of a neigh-boring class set. Let D be a user specified distance to judge whether the distance between two points is or is not close. The Euclidean distance d between any two points in a valid instance must be smaller than D. We denote dist(pi,pj) as the Euclidean distance between two points, pi and pj. In addition, let N be the user specified minimum support value. A frequent neighboring class set has more than N valid instances. 
We describe a neighboring class set that consists of k classes and has n support (the number of valid instances) where cl (i = 1,..., k) are classes of the set. 
The frequent neighboring class sets in the Figure 1 can be found, if we set the minimum support value N = 2 and the distance D as the diameter of the circles on the map. 
We call neighboring class sets that consist of k different classes k-neighboring class sets. Neighboring class sets that 
Figure 2: Valid Instance of Neighboring Class Set consist of only one class, k = 1, axe 1-neighboring class sets. Each instance of a 1-neighboring class set contains only one point and, therefore, we cannot measure any distance. We define a 1-neighboring class set that has more than N (minimum support) points as a frequent 1-neighboring class set. For k &gt; 2, we define a class set that has more than N valid instances as a frequent k-neighboring class set. 
Assume that we have point records that belong to one of three classes, circles, squares, and triangles. An in-stance of the 2-neighboring class set, {circles, squares}, is a pair of an instance of {circles} and an instance of {squares}. We make instances of {circles, squares} so that each pair is the closest pair of a circle and a square, that is, the circle in a pair is the closest circle from the square in the pair and vice versa. Figure 3, left, shows how we group an instance of 2-neighboring class set. 
In the Figure, {"4", "1"} and {"5", "2"} axe valid in-stances of {circles, squares}. Similarly, {"4", "8"} is a valid instance of {circles, triangles}. And, {"2", "8"} is a valid instance of {squares, triangles}. As in the Fig-ure, any point object must belong to only one instance of a k-neighboring class set. (But a point of an instance of a k-neighboring class set may belong to an instance of an-other k-neighboring class set.) Notice that {"5", "3"} is not a valid instance of {circles, squares}. Even though the distance between the two point is less than D, object "5" is already belongs to an instance of {circles, squares}, {"5", 
For each instance of a k-neighboring class set such that k &gt; 2, we compute the center, whose coordinate value is coordinate values of the j-th point in the instance. We use the center to represent the position of the instance of the k-neighboring class set. We can construct a (k+l)-neighboring class set from a k-neighboring class set by adding another class into the k-neighboring class set. We make an instance of the (k+ 1)-neighboring class set by grouping an instance of the k-neighboring class set and the closest point of the other class. We choose the closest point from the center of each in-stance, denoted by "+" as shown in the Figure 3, right. The closest triangle from the center of {"4", "1"} is "8". There-fore, {"4", "1", "8"} is an instance of {circles, squares, triangles}. Though "8" is also the closest triangle from the center of {"5", "2"}, the center of {"4", "i"} is closer. 
Note that instances of k-neighboring class sets for k &gt; 2 may be different depending on the order of classes as they axe grouped. We will discuss this later in this paper. 
Let C~ be a neighboring class set that contains k different 7 ({e, A,I}, nk) ({e, A, @}, nk' ) ({e, &amp;,l,@}, nk.l) 
Figure 4: A Priori Generation of Valid Instances classes. Let sup(C~) be support of Ck. Figure 4 shows an example of a valid instance of Ck+x. The figure illustrates that a neighboring class set that consists of four classes and nk+~ support value, If the instance of the 4-neighboring class set Ck+l is valid, every three-point combination chosen from the instance (the 4 points) is also valid. For example, the two subsets, an in-stance of C~ = ({circles, triangles, squares}, nk) and an instance of C~ = ({circles, triangles, diamonds}, n'k ) axe also valid. Therefore, it is obvious that nk &gt; nk+t and 
Based on the observation, if a k-neighboring class set is not frequent, (k + 1)-neighboring class sets that contain all the k classes must not be frequent. 
We specify the distance value D and the minimum sup-port value N. Then we compute the frequent 1-neighboring class set by using N. We can easily compute all frequent 1-neighboring class sets by scanning the database once. From all frequent 1-neighboring class sets, we generate k-ne!ghboring rithm presented in [1]. We use following Alg. 3.1, Apriori-Gen for Neighboring Class Sets, for finding all frequent (k + 1)-neighboring class sets from all frequent k-neighboring class sets. We assume that we can order all classes and we can order all class sets. In each iteration of the algorithm, each instance I has two variables, "corresponding additional point, cp(I)," and "dis-tance value between the center of I and the cp(I), dcp(I)." 
ALG. 3.1. Apriori-Gen for Neighboring Class Sets [2] For each valid instance of Ck[i] E Sk, [3] Construct a Voronoi diagram of Gi. [4] ForO=i+l;j&lt;m;j++ ) [6] Initialize sup(Ck+l[i, j]) = 0. [7] For each instance Ii of C~[i], [8] For each valid instance Ij of Ck LJ]: [9] Find the nearest center, g* E Gi from pj. [10] For each point, pii (ii = 1, ...,k), in I.~, [11] If all points in I* satisfy the inequality, do: [12] If dcp(I*) &gt; dist(g*,pj), do: [13] lf cp(I.~) == null, sup(Ck+l[i,j]) + +. [141 cp(I.~) = pj. [15] dcp(I*) = gist(g*, pj). [16] If sup(Ck+l[i,j]) &gt; N, make valid instances [17] Add C~+1[i, j] into Sk+t. 
In Alg. 3.1, we made an instance of a (k + 1)-neighboring class set by grouping an instance of a k-neighboring class set and the closest point of another class. Instances of k-neighboring class set for k &gt; 2 may different depending on the order of the class as added into the class set. Therefore, the support value of a k-neighboring class set for k &gt; 2 may be slightly different. In general data mining applications, it is much more important to know what are the frequent neighboring class sets than to know what is the exact sup-port value of each neighboring class set. Therefore, the ef-ficient approximate algorithm is adequate for our purposes here. 
In Alg. 3.1 Step [9], we use a Voronoi diagram for finding the nearest point from a set of points. A Voronoi diagram is an efficient data structure for this purpose [2]. Assume that we have a set of n points, P = {pl, ...,p~}, in a plane, then the Voronoi diagram of P, Vor(P), is the subdivision of the plane into n regions, called "Voronoi regions," one for each point, called a "Voronoi point." 
Let pi E P be a Voronoi point of Vor(P) and Reg(pi) be the corresponding Voronoi region. The Voronoi diagram has the following property. A point q lies in the region Reg(pi) 
We can find the nearest point p* E P from a point q efficiently by using this property of the Voronoi diagram 
Vor(P). Alg. 3.2, often called point location, is one such algorithm. 
ALG. 3.2. Point Location in Voronoi Diagram 1 [1] Choose an arbitrary starting point pi G P. [3] Collect Voronoi regions, ~, that is adjacent to Reg(pi). [4]For each Voronoi region Reg(pj) G ~: [5] Ifdist(pi,q) &lt; dm~,~, do: [6] dm~ = dist(pj, q). [7] p~ = p~. [8] Go to Step [3]. [9] Return pi as p*. 
Though the worst case time complexity of Alg. 3.2 is O(n), the expected running time is approximately constant if we can start the algorithm from a Voronoi point that lies close to p* in Step [1]. 
In many GIS systems or spatial database systems, a qua-ternary tree like Figure 5 is often used for indexing a two dimensional plane. We used a quaternary tree for indexing sets of centers of valid instances of each frequent neighbor-ing class set. As the root note of the tree, we use a large rectangle that covers all the points in a database. Then, we divide the rectangle into four equal-sized subrectangles. We continue this division procedure for each rectangle, recur-sively. We set the depth of the quaternary tree so that the average number of points of a class in each leaf node is close to one, because this empirically performs well as measured by time and space efficiency. Since the width and depth of each leaf node of the tree is fixed when we execute Alg. 3.2.. we can find a leaf node for each point in a constant time. 
For each k-neighboring class set, we assign a representa-tive center point to each leaf node as a label of the node. A label of a leaf node is chosen arbitrary from all center points that belong the node. We also assign a label to all other nodes of the tree. A label for an ancestor node is chosen from the labels of its child nodes. If there is no center point 1In order to simplify the explanation, we omitted some ex-ceptional conditions, for example, the condition when q lies on the border of the Voronoi regions. in a leaf node, we label the node null. Figure 6 shows an example of labeling of a quaternary tree. 
In Step [1] of Alg. 3.2, we search for the nearest point label is null, we use the non-null label of its closest ancestor node. If the nearest point that is found by Alg. 3.2 is differ-ent from the corresponding label, we update the label to the nearest point adaptively. This quaternary tree indexing of Voronoi points and the heuristics for labeling of the nodes in the tree significantly improves the expected running time of Alg. 3.2. As a result, the expected running time for finding the nearest instance of a frequent neighboring class set will be approximately constant. 
In Alg. 3.1 Step [3], we construct Voronoi diagrams for each frequent k-neighboring class set. Algorithms for con-structing Voronoi diagrams have been investigated inten-sively. The problem is proved to be 12(nlogn) where n is the number of Voronoi points [2]. There is a known algo-rithm whose worst time complexity is O(nlog n), which is the optimal complexity. 
Ohya et al invented an efficient algorithm whose average time complexity is O(n), though the worst time complex-ity is O(n 2) [10, 11]. In general, data mining applications prefer to an algorithm whose average running time is fast. Therefore, we used this efficient method. 
We first construct an initial (intermediate) Voronoi dia-gram, Vor(P3) that consists of three points among n Voronoi points. We incrementally update the intermediate Voronoi diagram by adding new Voronoi point one by one until all the Voronoi points are added. Figure 7 illustrates the incre-mental update procedure to construct the Voronoi diagram Vor(P,~+l) having rn + 1 points from the Voronoi diagram Vor(Pm) having m points. If new point p,~+l is added, we search the nearest Voronoi point p* in the intermediate dia-gram. Then, we draw a perpendicular bisector of p,~+l and p* in Reg(p*). Similarly, we draw a perpendicular bisector Figure 7: Incremental Construction of a Voronoi Di-agram in regions that are adjacent to Reg(p*). 
A method presented in [10, 11] uses a quaternary tree bucketing procedure to decide the order of Voronoi points to add in the incremental Voronoi diagram construction. The quaternary tree is also used to find the nearest Voronoi point in the intermediate diagram. 
We implemented the proposed algorithm and performed several experiments to evaluate the performance. All exper-iments were clone on an IBM IntelliStation which consists of a Pentium II processor running at 450 MHz with 512 KB of L2 cache and 128 MB of real memory. 
The number of combinations to be examined by Alg. 3.1 is affected by how we eliminate candidate neighboring class sets. Therefore, the overall performance of our algorithm is heavily affected by the input parameters, i.e., the distance D and the minimum support value N, and the contents of the database. 
In order to assess overall performance, we examine the running time of one iteration of Alg. 3.1 while changing the support value of neighboring class sets, sup(Ck[i]) sup(Ck~]). Since the effect of the k value is negligible in the performance of one iteration, we set k = 1 in these ex-periments. 
We generated sets of synthetic C1 [i] points and C1 [j] points with several number of records. All records have an attribute for identification, a class label, and two coordinate values in the two-dimensional plane. We divided the execution time of the iteration into two parts: Voronoi and Examination. Voronoi is the time taken for constructing Voronoi diagrams by using the incremental method. Examination is the time for examining the valid instances of the new neighboring class set. Total is the total time taken for one iteration of Alg. 3.1. 
Each graph of Figure 8, shows the relationships between the execution time for a fixed number of Sup(Ck~]) ious numbers of Sup(Ck[i]). There are three lines in each graph, showing the execution times for Voronoi, Examina-tion phases and Total times. There is a gap in the execution time of the Voronoi in each graph. This gap comes from a change of the depth of the quaternary tree. We adjusted the depth of the tree so that the average number of points in each leaf is close to one. Therefore, we changed the depth accord-ing to Sup(C~[i]). When Sup(CA[i]) = 2048, we adaptively changed the depth of the trees. Notice that all the execution times of the Examination in Figure 8 are almost constant. 
Each graph in Figure 9, on the other hand, shows the relationships between the execution time for a fixed num-ber of Sup(C~[i]) and various numbers of Sup(Ck[j]). cause Sup(C~[i]) is fixed in all of the experiments, the exe-cution times of the Voronoi are almost constant. The exe-cution times of the Examination have linear dependence on 
We apply our algorithm for the NTT Townpage Database (a kind of telephone directory of commercial facilities like the Yellow Pages in the US), which was provided by NTT Busi-ness Information Service, Inc. We collected data on 138,858 commercial facilities in Kanagawa prefecture, Japan. Each facility is categorized into one of 431 classes, for example, train stations, post offices, schools, cafes, and so on. We used the categories as class values. Each facility also has an address. We identified the x and y coordinate values of each record from its address and made a database of point records. 
We found the following frequent neighboring class sets from the point database. (The most frequent set for each k-neighboring class sets for k = 2, 3, 4, 5.) ({Snack Bar, Beauty Salon}, 1791) ({Diner, Tavern, Snack Bar}, 717) 
We used distance D = 50m and minimum support N = 100 for finding the class sets. Note that the commerciM fa-cilities of the database tend to lie in urban areas. Moreover, the distance of 50m is relatively large compared with the population density in the urban areas of Kanagawa Prefec-ture, Japan. Therefore, we found many, about 2000, fre-quent neighboring class sets. We intentionally set these pa-rameters to examine the workablity of our algorithm for real spatial databases. It took around 3 to 4 minutes per run, in-cluding data I/O, for these large tests. But if we use smaller D or larger N values, it terminates within a minute in most cases. 
We have developed an algorithm for finding important spatial pattern called frequent neighboring class sets from spatial databases. The neighboring class sets are not just clusters that can be found by conventional clustering algo-rithms because each instance (cluster) of a set is guaranteed to have one object of each class in the set. Frequent neigh-boring class sets can be utilized for many applications such as location-based services, development planning, and area marketing. 
Current problems that we have to consider for the neigh-boring class sets function are as follows: The author would like to thank Harunobu Kubo, Akihiro Inokuchi of IBM Tokyo Res. Lab. and Takeshi Kanda of Univ. of Tokyo for their help for implementing the system. [1] R. Agrawal and R. Sril~nt. Fast algorithms for mining [2] M. de Berg, M. van Kreveld, M. Overmars, and [3] M. Ester, H.-P. Kriegel, J. Sander, M. Wimmer, and [4] M. Ester, H.-P. Kriegel, and X. Xu. Knowledge [5] R. H. Giiting. An introduction to spatial database [6] J. Han, K. Koperski, and N. Stefanovic. GeoMiner: A [7] E. M. Knorr and R. T. Ng. Finding aggregate [8] K. Koperski and J. Han. Discovery of spatial [9] R. T. Ng and J. Han. Efficient and effective clustering [10] T. Ohya, M. Iri, and K. Murota. A fast voronoi [11] T. Ohya, M. Iri, and K. Murota. Improvements of the [12] W. Wang, J. Yang, and R. R. Muntz. STING: A 
