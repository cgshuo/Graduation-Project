 Categories and Subject Descriptors: H.2.8 Database management: Database applications [Data mining] General Terms: Measurement, Experimentation Keywords: data mining, high dimensional data, subspace clustering, projected clustering, evaluation
For knowledge discovery in databases, fair and compara-ble evaluation of detected patterns is of major importance. For a thorough evaluation of mining techniques, it is essen-tial to have objective methods that measure the quality of data mining results. In contrast to the subjective quality as-sessment by domain experts, these measures should provide an objective and comparable evaluation. This evaluation is important for quality assessment of novel methods vs. com-peting approaches but also for knowledge extraction based http://dme.rwth-aachen.de/OpenSubspace/E4SC/ on the detected patterns. Evaluation completes the knowl-edge discovery process by providing more insights than a mere listing of patterns.

In this work we focus on evaluation measures for subspace clustering techniques [17, 9]. In general, subspace clustering or projected clustering aim at the detection of clusters in arbitrary subspace projections. While traditional cluster-ing searches for clusters based on object similarity using all available attributes (full space), subspace clustering consid-ers object similarity in any subset of the given attributes (subspaces). Several subspace clustering approaches have been proposed. They all show high quality results, espe-cially on high dimensional data where traditional clustering approaches fail to detect clusters. Surveys [17, 9] or empir-ical studies [15, 13] provide some comparisons of subspace clustering approaches. However, all of these publications fo-cus on the subspace clustering techniques and not on the specific characteristics of evaluation in this research area.
So far only few measures were developed specifically for subspace clustering. Instead, researchers borrowed measures from other areas, as information retrieval or classification without discussing their applicability and characteristics for subspace clustering. Thus, some measures may not be ap-propriate for subspace cluster evaluation. Furthermore, the differing use of measures leads to incomparable results. As illustrated in Fig. 1, comparing the hidden clusters (ground truth) and the detected clusters with two of these measures might yield contradicting results. Even for a single measure, users do not know how to interpret the results because they are not aware of its characteristics. The variety of evalua-tion measures used, usually reflect different aspects of the clustering results and hardly any of them allows a holistic evaluation. Overall, this situation leads to unfair compar-isons of subspace clustering results.

In this paper we bridge the gap between individual eval-uation measures. Besides evaluation challenges inherited by traditional clustering, we highlight specific core require-ments for a systematic evaluation of subspace clustering re-sults. Based on a given ground truth, traditional clustering measures evaluate the purity of clusters and the detection of all clustered objects. For subspace clustering we have further challenges: First, a high quality subspace clustering should also detect the correct subspaces in which objects are grouped. Second, subspace clusters might be reported redundantly in several subspaces. Last, objects may be part of multiple valid clusters.

As key contributions of this paper, we take a systematic approach to characterize the main quality requirements for Fig. 1: Enhanced evaluation by insights into charac-teristics of evaluation measures [conflicting evalua-tion (top), meaningful interpretation (bottom)] subspace clustering . We formalize all of these properties and we provide an analysis of evaluation measures used in re-cent publications [12, 18, 5, 11, 6, 14, 15, 13]. In addition, we propose an enhanced evaluation measure which meets these requirements. Based on our systematic comparison, we provide a recommendation of measures to be used in future evaluations. In conjunction with the derived char-acteristics in this paper, these measures can be used not only for evaluation but also for further knowledge extrac-tion. Knowing about the characteristics of the measures, evaluation provides a reasoning about why poor results are observed (Fig. 1 (bottom)). This knowledge can be helpful for better parametrization or for improvement of the data mining algorithm itself.
Evaluation of clustering as unsupervised learning is chal-lenging since the X  X orrect X  X esult is usually unknown. Several evaluation types have been proposed.
 Evaluation Types. Evaluation based on domain experts is one possible type, used in application oriented evalua-tions. Here domain experts are consulted to manually eval-uate each cluster. This evaluation provides more insight into the detected clusters but it is subjective and does not yield comparable results on benchmark data. Furthermore, it can only be applied for very small result sets. As a sec-ond evaluation type, internal evaluation measures are de-fined based on properties of the cluster definition e.g. the compactness of clusters (cf. k-means [10]). Such measures only reflect the relative adherence to the underlying cluster definition. They are thus typically used for those cluster-ing paradigms trying to optimize a task specific objective function. For most clustering paradigms including subspace clustering such a general objective function is not defined, and thus, no internal measure is meaningful for all methods. Clustering methods adhering to different cluster definitions cannot be fairly evaluated w.r.t. a single internal measure. As a third type, external evaluation measures are used (e.g. for k-means [20]). They assume a ground truth, as provided by synthetic data or labeled data. External measures com-pare the detected clusters with this given ground truth, pro-viding an objective quality assessment, independent of the cluster definition. In this work, we focus on external evalua-tion measures for subspace clustering. Before discussing the novel requirements induced by subspace clustering in Sec. 2, we review the general idea of external evaluation measures. The  X  X ll and Only X  Quality Criterion. External eval-uation measures compare a given ground truth (ideal clus-tering) with the detected result set of found clusters. Intu-itively, a measure should provide high quality values for a clustering that detects all hidden clusters, but also detects only the hidden clusters. This all and only property applies to several aspects in the evaluation of subspace clusters. We distinguish between the cluster level (single cluster) and the clustering level (overall set of clusters): First, on the cluster level, each found cluster should contain all and only objects of a single hidden cluster. Furthermore, each found subspace cluster should be detected in all and only the dimensions of the hidden subspace cluster. And second, on the clustering level, the overall set of detected clusters should contain all and only the hidden clusters.
 Evaluation characteristics. We first introduce some basic notions for subspace cluster evaluation, before presenting the quality requirements that each measure should fulfill. An external measure evaluates the subspace clustering result that contains a set of subspace clusters, each representing a group of objects in a subset of the dimensions.
 Definition 1. Subspace clustering result Given a set of dimensions Dim and a database DB ,asub-space cluster C =( O,S ) is a set of objects O  X  DB along with a set of relevant dimensions S  X  Dim .Asubspace clustering result Res is a set of subspace clusters Res = {
C 1 ,...,C k } with C i being a subspace cluster.
 In Fig. 2 two exemplary subspace clusterings are illustrated. The x-axis denotes the dimensions and the y-axis the objects of the database. Each subspace cluster covers a specific set of objects and dimensions.
REMHFWV
External evaluation measures determine the quality of a clustering w.r.t. a ground truth. This ground truth repre-sents a gold standard that should be recovered by the sub-space clustering algorithms to the greatest extent. Definition 2. Ground truth The ground truth Ground is a subspace clustering represent-ing the perfect result.
 In Fig. 2 we assume the ground truth to be given by Ground = { C a ,C b ,...,C f } and the other clustering to be determined by a clustering algorithm. As indicated in Fig. 2, an object can belong to several subspace clusters. Also the relevant dimensions of clusters can overlap. Hence an object can be part of several clusters in a single dimension in the ground truth or in the clustering result, e.g. the ones of C and C 5 . Thus, a mandatory requirement for each measure is to handle overlapping subspace clusters. We denote this criterion as overlap applicable .

An evaluation measure for subspace clustering can for-mally be defined by: Definition 3. Evaluation measure Given a set of dimensions Dim ,adatabase DB ,andthe ground truth Ground of this data set; an evaluation measure is defined by where Clus = { ( O,S ) | O  X  DB,S  X  Dim } is the set of all possible subspace clusters. The quality of a clustering Res w.r.t. the ground truth is: M ( Ground, Res ) .
 In general, an external measure can be used as a similarity measure between two arbitrary clusterings. W.l.o.g., in our work all measures are normalized between 0 and 1, where 1 indicates the perfect quality, e.g. M ( Ground, Ground )=1 holds. Any errors in the result should be reflected in the value of M and hence an optimal value should only be achieved for identical clusterings. As depicted in Fig. 2, the clusters themselves can differ, i.e. the hidden clusters are not exactly recovered ( C b vs. C 2 ); but also the overall set of clusters can differ, i.e. the clusterings disagree ( C c ). Over-all, we discuss specific characteristics on the cluster level and on the clustering level. We start with the cluster level. Object awareness. As in traditional clustering, we want to identify the correct object groupings of the hidden clusters. The found clusters should not mix several hidden clusters or obfuscate a hidden cluster by other objects, since the purity of a cluster is crucial. The cluster C 2 in Fig. 2 has perfect purity w.r.t. C b regarding the objects, while the cluster C mixes several hidden clusters and noise objects. Moreover, for a correct object grouping, it is also important to identify as many objects as possible of the hidden cluster, not just a few as the cluster C 1 w.r.t. C a . Overall, for a good detection it is mandatory to group all and only the objects of the hidden cluster. If this is not fulfilled by the clustering result Res a measure M should determine a lower quality. We denote this property of a measure as object awareness . Subspace awareness. For subspace clusters the set of rele-vant dimensions constitutes a major part of its information content. It is therefore important to identify the correct object group and at the same time the correct relevant di-mensions. It is an indication of poor quality to find the hidden object group but in a totally different subspace. Con-sequently, we want to identify all and only the relevant di-mensions of a subspace cluster of the ground truth. In Fig. 2 the cluster C 2 does not reflect the relevant dimensions of C perfectly. A measure fulfills the subspace awareness criterion if it punishes false or missing relevant dimensions. Redundancy awareness. Both previous criteria are rel-evant for determining the quality of single subspace clus-ters. The following criteria will consider the clustering level. In subspace clustering, we analyze subspace projections of the data. For any subspace cluster definition fulfilling the anti-monotonicity criterion, all exponentially many subspace projections of a valid cluster are valid as well. A set of clusters sharing nearly all objects and relevant dimensions, however, induce redundancy and therefore obscure the true clustering result. A measure should punish clustering re-sults that identify one ground truth cluster several times. Beside the true hidden cluster C f / C 4 ,inFig.2severalre-dundant clusters are generated ( C 5 , C 6 , C 7 ). In traditional clustering, redundancy does not occur due to full space clus-tering. In subspace clustering, however, several approaches suffer from this phenomenon [3, 16, 8]. Evaluation measures for subspace clustering have to take into account, that a re-dundancy polluted clustering is not the perfect clustering. Adding further clusters not represented by the ground truth must lead to lower quality. In extreme words: Simply gener-ating all possible clusters must not yield the perfect quality. A measure accounting for this criterion is redundancy aware . Identification awareness. Respectively, it is not optimal to miss some clusters of the ground truth. In Fig. 2 the clus-ter C c is not identified at all; a measure should not deter-mine perfect quality. For subspace clustering, this property is a challenge, which cannot be trivially adapted from tradi-tional clustering. While in traditional clustering each object belongs to just one cluster, in subspace clustering objects can belong to several clusters due to their relevant dimen-sions. Missing clusters in traditional clustering can simply be identified by a non coverage of some objects. However, in subspace clustering all objects could be covered by the result, even if not all clusters are identified. This problem appears, e.g. in partitioning approaches that only detect dis-joint subspace clusters [1, 2, 19, 21]. Overall, to be identifi-cation aware , a measure has to decrease the quality for every missing cluster of the ground truth.

Summarized, we introduce 4 criteria that evaluation mea-sures for subspace clustering have to fulfill: object, subspace, redundancy, and identification awareness.
In this section we examine existing evaluation measures with regard to the 4 criteria. Only if a measure responds to all 4 respective clustering variations, substantial conclusions can be drawn out of its quality assessment. For measures that ignore at least one criterion, a low quality value still indicates a bad clustering solution. A high quality value, contrarily, does not necessarily indicate a good clustering result. Clearly, a measure where neither low nor high qual-ity values allow any conclusions is inappropriate. This is the case for those, that do not handle mandatory require-ments of subspace clustering like overlap applicability. An example is the Entropy measure [5, 15]. For a ground truth with overlapping clusters, the entropy will always indicate a quality below optimal, even if we compare the ground truth against itself. An optimal clustering that equals the ground truth should, however, always have optimal quality results.
In the following Sec. 3.1 we only consider those measures, that are overlap applicable. To the best of our knowledge, we include all evaluation measures in our comparison that are used in recent subspace clustering publications. For these we will examine the sensitivity w.r.t. our 4 criteria. As a result, we will get that none of the existing measures deals fairly with all criteria. We, therefore, propose a novel, simple quality measure for subspace clustering in Sec. 3.2.
For our analysis we assume Res to be the set of found clusters and Ground to be the ground truth. The objects of acluster C are denoted with O ( C ) and the set of relevant dimensions of C with S ( C )respectively. Onemethodfortheevaluationofclusteringresultsisthe F1-measure. F1 formalizes the requirement that clusters in Res should represent the clusters in Ground . That is, a cluster C r  X  Res should on the one hand have many objects in common with one of the hidden clusters C g  X  Ground , but on the other hand it should contain as few objects as possible that are not in this particular hidden cluster. These two constraints can be formalized by the terms precision and recall and represent the all and only constraint of object awareness. recall ( C r ,C g )= The F1-measure evaluates the matching of two clusters as the harmonic mean of precision and recall.
 Note that the relevant subspaces do not occur in the formal definition of F1, which is therefore not aware of subspaces. However, it is widely used in subspace clustering evaluation [12, 11, 13, 6, 14, 15]. For the overall matching of two clusterings P and Q the F1 measure is defined as: Optimal quality is denoted by a value of 1, whereas 0 in-dicates the lowest quality. It is crucial that the function of F 1
Clus is not symmetric ( F 1 Clus ( P,Q ) = F 1 Clus ( Q, P )), even though it has not been discussed in the literature yet. The sum only iterates over clusters in P andthusclustersin Q are only considered if they match at least one cluster in P best. Clusters in Q besides these matches have no influence on the evaluation result at all. The measure is used as in [4], where Res is the clustering that is considered only partially for the quality evaluation. Thus, this definition is not redundancy aware, since it is not capable of detecting the presence of false clusters. That is, for all clusterings Res  X  Ground the quality result will always be optimal M
F 1  X  R ( Ground, Res ) = 1. Thus, only the obtained recall w.r.t. the clusters in Ground is assessed; hence the naming  X  F 1-Recall X  ( F 1-R ).

In [12, 11, 13] results are evaluated by the counterpart definition In this case, the ground truth has only limited influence on the quality assessment of F1. Therefore, the presented def-inition of F1 is not identification aware, as all clusterings Res  X  Ground will always have the perfect quality outcome of M F 1  X  P ( Ground, Res ) = 1. Since only the obtained pre-cision w.r.t. the clusters in Ground is assessed, we chose the naming  X  F 1-Precision X  ( F 1-P ).

In [6, 14, 15] a third definition was introduced, where clusters in Res are merged if their best matching cluster in Ground is identical. The size of the resulting clustering Res is thus adjusted to the size of Ground . For each cluster C  X  Ground we get a new cluster C  X  Res ,suchthat: O ( C ):= A solution Res is evaluated based on the ground truth and the novel result Res : Due to the merging of found clusters this measure does not detect whether found clusters split hidden clusters and is thus not object aware.
Another quality assessment is realized by the Accuracy measure [14, 7, 15]. The basic idea is to predict the hidden clusters based on the found clusters. The more accurate the hidden clusters are predicted, the better the ground truth is generalized by the identified clusters. For prediction, the method of classification is used. As the training data, bitvec-tors are given that represent the membership of the objects in the hidden clusters C i  X  Res . That is, each object o in-duces a bitvector of length k = | Res | where the i th entry is 1 if o  X  C i . Based on these training data a decision tree classifier is built and the accuracy is determined (usually C4.5 with 10-fold cross validation).

Since classification accuracy depends on the training data, we can infer that impure clusters affect the quality of the result; the training data contains errors w.r.t. the ground truth. However, as a classifier tries to countervail these ef-fects the object awareness of the measure is questionable: Even if an object was assigned to some wrong clusters, the classifier could be able to predict the correct hidden clusters for the object. Thus, the measure indicates high quality, even in the presence of errors in the clustering result. Obvi-ously, this measure is also not subspace aware, because only the object sets are used for training. If a cluster is com-pletely missed, the classifier cannot assign the objects to this cluster. Thus, the identification awareness is fulfilled.
In [18] the first measures have been introduced that fulfill the subspace awareness criterion. The basic idea is to repre-sent a cluster ( O,S ) as a single set T instead of a tuple. For this, each object o i  X  O is not stored as the full-dimensional feature but for each dimension d  X  S an object o i,d is con-structed. We denote these objects as micro-objects. Thus, a subspace cluster can be represented by its set of micro-objects An x -dimensional cluster with y objects is represented by x  X  y micro-objects. Based on this representation, the RNIA (relative non-intersecting area) measure assesses whether the micro-objects of the ground truth are all and only covered by the clustering result. Formally, the union U of the micro-objects of both clusterings is determined and their intersec-tion I is subtracted. The assumption is, that for a good clustering result U and I are nearly identical. Overall, with U = U ( Ground )  X  U ( Res ), I = U ( Ground )  X  U ( Res ), and U ( P )= C  X  P t ( C ) . To handle overlapping clusters, [18] presents a method to adapt the union and intersection. We use this version in our experiments and we plot the value 1 . 0  X  RNIA so that perfect quality corresponds to 1 . 0.
Obviously, the RNIA measure is subspace aware. The redundancy and identification awareness are also fulfilled, because errors w.r.t. these criteria have an influence on the union and intersection respectively. The drawback of RNIA is its lack of object awareness. The purity or recall of sin-gle clusters is not considered at all. RNIA simply checks whether a micro-object of the ground truth is also contained in Res and vice versa. If U ( Ground )= U ( Res ) holds, RNIA returns perfect quality; independent of how the single clus-ters behave. Splits or impurities of clusters remain unde-tected.
The disadvantages of the RNIA measure were addressed by the CE (clustering error) measure [18]. The basic idea is to find a 1:1 mapping between the hidden and found clus-ters. Each cluster C g of the ground truth is assigned to at most one cluster C r of the result, and vice versa. For each mapped pair ( C g ,C r ) the cardinality of their intersecting micro-objects is determined. Overall, those 1:1 mappings are chosen that result in the highest total sum over all car-dinalities. This sum is denoted as D max . By replacing the intersection I within RNIA by D max we formally get the CE measure: We plot the values of 1 . 0  X  CE such that perfect quality equals to 1. CE fulfills the same quality criteria as RNIA. The object awareness is still not completely fulfilled. On the one hand, the 1:1 mapping penalizes clusters which split up in several smaller ones because the coverage of the cluster decreases. On the other hand, the impurity of clusters is still not considered; the intersection between two clusters is not influenced by additional, wrong objects. Thus, the object awareness is not adequately implemented.
The previously reviewed techniques have major drawbacks in at least one of the 4 awareness criteria. The gathered in-sights on subspace clustering allow us to define an external evaluation measure, that addresses all 4 criteria, for a holis-tic evaluation of subspace clusterings.

The terms of precision and recall assure the awareness of objects with full contentment. Thus, they build the basis of our new E4SC measure. By transforming subspace clusters to micro-object clusters, the object awareness is extended to dimensions. The definitions of recall and precision become: recall SC ( C r ,C g )= The harmonic mean of precision and recall now represents the all and only constraint for cluster objects as well as for relevant dimensions. On the cluster level this measure meets all requirements for subspace cluster evaluation.
 F 1 SC ( C r ,C g )= 2 The extension F 1 Clus SC ( P,Q ) of this definition for the clus-tering level leads to This formula exhibits a non-symmetry that we utilize for enhanced quality assessment. The non-symmetry of F 1 Clus implicates a precision and recall relation itself  X  though on the cluster ing level. F 1 Clus SC ( Ground,Res ) evaluates how well all of the hidden clusters were found; it can be denoted as the recall of the clustering .Contrarily, F 1 Clus SC ( Res, Ground ) evaluates how well each of the found clusters represents one of the hidden clusters; thus, it can be seen as precision of the clustering . The combination of these derived precision and recall values by a harmonic mean represents the all and only constraint on the clustering level.

The novel measure of E4SC successfully adopts the idea of F1 for subspace clustering. The central idea of preci-sion and recall has been transferred to the level of subspace clusters and by means of recurring averaging has also up-graded F1 to the level of clustering . E4SC stands out due to the complete consideration of all 4 criteria. Object aware-ness is realized by using precision and recall on cluster level. A maximal quality result thus reports pure and complete clusters in Res compared to Ground . Asdimensionsare treated as micro-objects, same holds for subspace aware-ness. Through the harmonic mean of F 1 Clus SC ( P,Q )and F 1
SC ( Q, P ), E4SC is able to consider lower quality due to redundant or missing identification of clusters. The re-call F 1 Clus SC ( Ground, Res ) of the clustering decreases if one cluster in Ground is not or insufficiently found by Res . The precision F 1 Clus SC ( Res, Ground ) is low if clusters in Res are unrelated to the clusters in Ground . An optimal qual-ity result thus also reports a pure and complete clustering Res with regard to Ground . The maximal quality value of M
E 4 SC ( Ground, Res ) = 1 indicates an optimal clustering w.r.t. all characteristics of subspace clustering.
Note that E4SC fulfills the following useful properties: symmetry, non-negativity and identity of indiscernibles. The symmetry property M E 4 SC ( P,Q )= M E 4 SC ( Q, P ) for all clusterings Q and P is valid by design. Since precision and recall values lie within the range [0 , 1], the harmonic mean does so too. Thus, E4SC fulfills the non-negativity and even stronger for all clusterings P and Q we get M E 4 SC ( P,Q ) [0 , 1]. At last, we prove the identity of indiscernibles, i.e. P = Q  X  M E 4 SC ( P,Q ) = 1. This property is especially important since the perfect quality is only achieved if the two clusterings are identical. Any error in the clustering re-sult, e.g. splits, redundancy, or inclusion of noise, leads to a decrease of the E4SC value.
 Proof:  X  : It holds that recall SC ( C, C ) = 1 and analo-gously precision SC ( C, C )=1since t ( C )  X  t ( C )= t ( C ) and therefore also F 1 SC ( C, C )=1. If P = Q we have  X 
C i  X  P  X  C j  X  Q : C i = C j and since F 1 SC ( C r ,C g ) we get Thus, F 1 Clus SC ( P,P ) = 1 and hence M E 4 SC ( P,P )=1.  X  : Assuming P = Q . W.l.o.g. there exists C  X  P and C/  X  Q . It holds that  X  C j  X  Q : F 1 SC ( C, C j ) &lt; 1 since either C  X  Q would hold. Thus and hence the harmonic mean M E 4 SC ( P,Q ) &lt; 1for P = Q .
In our experiments, we highlight the characteristics of the evaluation measures w.r.t. errors in the clustering result. While all measures provide perfect quality for a perfect clus-tering, they show different behaviors on clustering errors. Given a ground truth Ground of hidden subspace clusters and a clustering result Res of found subspace clusters, we compare the measures X  performance. In order to understand all properties of the measures under consideration, we first study them for different evaluation scenarios with synthetic data, where we are able to vary the degree of each error separately as illustrated in Fig. 3 (right). To study different characteristics, we emphasize a different error in each evalu-ation scenario. Each scenario is motivated by general errors produced by different clustering approaches. The thereby gained insights subsequently allow us to discuss some evalua-tions of real cluster algorithms on real world datasets. These experiments will reveal the dependency of the assessment of the vanquishing algorithm on the evaluation measure. Fig. 3: Traditional workflow to evaluate algorithms (left) &amp; novel workflow to evaluate measures (right) Evaluation Setup. We created a benchmark database with 5000 objects and 30 dimensions. Objects are grouped in 9 subspace clusters, each with 9 dimensions and covering 500 objects. The ground truth for this synthetic data is given. In traditional evaluation to compare different algorithms , one uses each algorithm to obtain a clustering result and this result is compared with the ground truth by using a specific measure (cf. Fig. 3 (left)). In our work, however, we want to compare the characteristics of different measures . Thus, instead of using an arbitrary algorithm on the data, we systematically insert specific errors into the ground truth to obtain an (imperfect) clustering result. This insertion of errors corresponds to an algorithm that is not able to detect the perfect clustering on the data. However, we are now able to analyze each type of error separately leading to a more insightful analysis. Based on this clustering result, the different measures can be executed and their properties can be evaluated (cf. Fig. 3 (right)).

We created different clustering results based on our bench-mark data, i.e. we insert different types of errors. Obviously, the perfect clustering result is simply the list of hidden sub-space clusters ( Res = Ground ). This is the ideal baseline for all evaluation measures. However, we construct more re-alistic scenarios to analyze the sensitivity of the measures. For the first experiment, we split the hidden clusters into multiple found clusters regarding their objects, i.e. for each hidden cluster we partition its objects into x parts of equal size, thus getting x smaller clusters. For grid-based subspace clustering approaches [3, 16, 19, 21], this might happen due to discretization of the search space. Thus, we get a cluster-ing result Res that does not perfectly represent the ground truth. It is of major importance that evaluation measures are aware of such phenomena and show significantly lower quality if hidden clusters are split up. For the following ex-periments, we give short descriptions of the evaluation setup in the respective paragraph. Object Awareness. Most measures compare the set of hid-den objects with the found objects. Though, there are ma-jor differences in their sensitivity to splits of clusters .As depicted in Fig. 4, the measures RNIA and F1-Merge do not detect these errors and provide constantly perfect val-ues. The merge operation of F1-Merge is a clear drawback as a split of clusters does not affect the overall quality. A similar argument holds for RNIA because this measure only assesses the coverage of the hidden clusters but not whether the objects belong to the correct clusters. The Accuracy measure can still identify a reasonable generalization for the data with the split parts; thus, the quality decreases only slightly.

Next, we perform a certain number of merge operations between the hidden clusters. This is a realistic scenario where clustering algorithms fail to separate two similar clus-ters, resulting in a bad purity of clusters. As depicted in Fig. 5, almost all measures detect this bad clustering and show decreasing values with increasing amount of merges. Only the RNIA measure is not affected by merged clusters due to the reason described above. Next, we consider ob-ject awareness for results produced by projected clustering methods [1, 2, 19, 21]; they partition the data . However, as we have overlapping hidden clusters, a partitioning of the data cannot be the perfect clustering result. The result-ing quality values range from 0.735 (RNIA, CE) to 0.847 (F1 measures, E4SC). Thus, all measures show lower qual-ityvaluesaseachobjectisassignedtoexactlyonecluster and not multiple ones.

Overall, the first experiments have shown that most mea-sures are aware of the most basic properties of clustering quality. Missing objects due to partitioning, affects the qual-ity of all measures. Splitting or merging clusters, affects all but the RNIA measure due to the simple coverage method. Subspace Awareness. In the following experiments we consider errors in both, the detected object set and the di-mension set, for each subspace cluster. We remove/include objects and dimensions respectively with a certain percent-age. As depicted in Fig. 6, the perfect result is at the center of each figure (0% additionally included objects, 9 dimen-sions). For the x-axis  X  X etected objects X   X  p %meansthat p % of the objects were excluded from the found clusters and + p % refers to the amount of included objects. For the y-axis we added or removed dimensions compared to the perfect re-sult respectively. We show four different measures (results of F1-R &amp; F1-Merge are similar to the one of F1-P; the result of RNIA corresponds to the one of CE).

Obviously, F1-P and Accuracy, as measures without sub-space awareness, are only affected by changes in the ob-ject set; however, they react differently. While F1-P still returns good qualities when adding many objects, the Ac-curacy measure is more sensitive and exposes the area of perfect quality more distinctly. Our novel E4SC measure and CE are affected also by changes in the dimension set. Beside this subspace awareness of CE and E4SC, we observe interesting characteristics. While in the area of perfect clus-tering both changes in the object and dimension set affect the overall quality to the same degree (nearly rectangular ar-eas), this effect is not observed for extreme cases where e.g. most of the objects have been removed. For such extreme cases either the object set or the dimension set is dominating (rounded areas). Furthermore, the CE measure reacts more sensitive in this experiment, i.e. the quality values decrease faster than for E4SC. This property is especially observed in the first quadrant, where objects and dimensions are added.
Overall this experiment demonstrates the lack of sub-space awareness in F1-P, F1-R, and F1-Merge. Their use in subspace clustering is meaningless or at least question-able. E4SC and CE simultaneously handle subspaces and object groups.
 Set of detected clusters. While in the previous experi-ments we have analyzed different effects on the content of clusters, in the following we consider typical clustering er-rors such as completely missing clusters or detecting similar clusters multiple times.

In our first experiment, depicted in Fig. 7, we remove one cluster from the resulting clustering each time. We gen-erated 9 hidden clusters, each with a different number of objects. By sorting the clusters based on their object size, such that to the left of the x-axis the smallest cluster is re-moved and to the right the largest one, we show the effect of the cluster size . We observe that CE, RNIA, and Accuracy are affected more by the exclusion of large clusters than by exclusion of small ones. These measures are biased w.r.t. the cluster size. All other measures are nearly not affected by the size of clusters; they are unbiased w.r.t. the size. A special case is F1-P, that shows perfect quality although clusters have not been detected. As F1-P maps each found cluster to one hidden cluster, it is not affected by missing clusters (cf. Sec. 3).

Next, we exclude not only one cluster but accumulate the removal of several clusters , starting by excluding the largest cluster until only one cluster remains in the found cluster-ing. As depicted in Fig. 8, all measures except for F1-P show decreasing quality values. However, the slopes vary greatly. CE, RNIA and Accuracy show steep decrease in the first (large) clusters because removing large clusters is more crit-ical for these measures. F1-R and F1-Merge measures show almost linear decrease; removing one additional cluster re-sults in constant drop of the quality. Our E4SC measure, however, decreases more quickly with each additionally ex-cluded cluster. That is, excluding two clusters is more than twice as bad as the removal of a single cluster; although we get in Fig. 7 a constant curve.

Both, missing a cluster but also detecting similar clusters in redundant projections, should lead to lower quality values. In the following experiment, we additionally add redundant clusters in lower dimensional projections as observed in sev-eral subspace clustering approaches [3, 16, 8]. The x-axis in Fig. 9 indicates the amount of redundant clusters. Start-ing by adding only the redundant 8 dimensional projections (of the original 9d clusters), we add more and more lower-dimensional ones. As illustrated, only CE, RNIA and E4SC are affected by redundancy; quality decreases while redun-dancy increases. However, CE &amp; RNIA show a significant drop to almost zero quality already for redundancy in 6 to 8 dimensional clusters; we get no discriminable quality val-ues after this point. Our E4SC measure shows continuously decreasing quality, down to the 1 dimensional redundant clusters, but remains in high quality ranges. CE and E4SC detect bad clusterings due to redundancy best.

Overall, these experiments have shown that F1-P, F1-R, and F1-Merge do not meaningfully assess the quality of re-dundancy polluted clusterings. Furthermore, F1-P is not able to detect a miss of clusters. For the criteria of redun-dancy and identification awareness the measures CE, RNIA and E4SC are preferable.
 Sensitivity of measures. We created further evaluation scenarios to show the sensitivity of each measure. First, we created a clustering result where a certain fraction of the clustered objects is removed. This miss of objects is assessed as low quality by all measures in Fig. 10 as the leftmost values indicate. Afterwards, we progressively re-add objects to the clusters; however, not from the correct but different clusters. Thus, we increase the impurity of the clustering results . Most measures accurately show decreasing quality for impure clusterings in Fig. 10. CE and Accuracy, however, are almost not affected by this scenario. Because the largest part of the hidden cluster is still detected, adding incorrect objects does not influence their quality values. Even worse, the RNIA measure increases in quality since we cover more objects of the hidden clusters. Thus, these three measures are not sensitive to the impurity of clusterings.

Next, we simulate the effect of algorithms that are not able to detect outliers , i.e. algorithms enforcing an assignment of each object to a cluster. Thus, beside the hidden clusters we generate for the clustering result one single cluster that con-tains all noise objects . Most of the measures are influenced by this as the leftmost entries in Fig. 11 indicate. In the fol-lowing, we relocate more and more objects from the noise-cluster to the hidden clusters. This phenomenon is typically observed in algorithms mixing up noise objects with the de-tected clusters. Clearly, the quality of the clustering should decrease because the true clusters are now polluted by noisy objects. However, CE and RNIA are not affected by noise as the hidden clusters are still covered and the purity is in-cidental. All other approaches show decreasing quality.
In the following experiment, we split each hidden cluster notinequallylargeparts but in one half of the cluster and an increasing fraction of further parts. While the large part seems to be the most valuable representation of the hidden cluster, the other parts hinder more and more the interpre-tation of the overall result set. As depicted in Fig. 12, most measures are not affected by this scenario because the ma-jor part of the hidden cluster is still found. F1-Merge and RNIA even show highest quality, ignoring the splits at all. Only F1-P and E4SC are aware of a decreasing quality.
Overall, for the core quality criteria we have shown that measures as F1-P, F1-R, F1-Merge, and Accuracy are not aware of subspace properties and fail in the very core of subspace cluster evaluation. Nevertheless, these measures are the most widely used ones in subspace clustering works. They are of interest where only object sets are relevant or given for the evaluation. Enhanced measures such as CE, RNIA, and E4SC consider also correct detection of sub-spaces. However, we have seen major differences in their evaluation. The RNIA measure is not affected by splits or merges of clusters. The CE measure shows high sensitivity to redundancy, while E4SC is sensitive to impure clusters, noise and split of clusters. In Fig. 13 we provide an overview of the measures and their characteristics.
 Real world data and algorithms. The previous experi-ments aimed at an objective analysis of all error types sep-arately. Enabled by a systematic transformation of a pre-sumed set of ground truth clusters for synthetic data, an unaffected consideration for each error type was possible. The following consideration of real world data and clustering results of real algorithms will now provide the opportunity not only to prove but also to apply the newly won insights into the measures. For these real world experiments we used the publicly available clustering results of [15] and applied the discussed measures on them. Notice that the ground truth of real world data usually consists of a partitioning of
Fig. 13: Characteristics of evaluation measures the dataset and provides no subspace information with the partitions. Each table in Fig. 14 and 15 shows the qual-ity values of different subspace clustering algorithms for one dataset [15]. For each measure we depicted the maximal and minimal values obtained for various parameter settings [15]. To fastly grasp the main tendency of the results we colored the quality values (gets darker with increasing quality). We only discuss Fig. 14 but similar observations can be drawn out for the other data sets in Fig. 15. As a first observation, each measure yields different quality values for the same al-gorithms. Consequentially, each measure assesses a different algorithm as vanquisher. This is hard to understand if one is not aware of the underlying characteristics of evaluation measures. Thus, further interpretation requires information about the measures X  sensitivity as presented in this work. (size: 768; dim: 8) Fig. 14: Results for the measures on diabetes data
The coloring of the results reveals the rare differentiation of Accuracy, CE, and F1 since results only differ slightly and do not allow contrasty comparisons of different approaches. This effect is mainly due to the insensitivity of the measures to a variety of errors or, in the case of CE, the excessive punishment of redundancy and its size-bias. Only RNIA and E4SC show discriminative results between the approaches.
The evaluation results in Fig. 14 point out the importance of redundancy awareness. On average, the measures F1 and Accuracy, which are insensitive to redundancy, assign higher quality values to the resulting clusterings than CE, RNIA and E4SC. The worth of redundancy awareness becomes even more evident as we see that mainly the partitioning approaches DOC, MINECLUS, PROCLUS and P3C, whose results are not redundant by definition, have high values for CE, RNIA and E4SC. Only with these measures the benefit of non-partitioning subspace clustering approaches that suc-cessfully try to avoid redundancy, like INSCY and STATPC, is traceable as they yield better quality values than other ap-proaches without redundancy model.

Overall, we see that our awareness criteria and the thor-ough evaluation on synthetic data helps to interpret quality assessment on real world data based on different measures. We also see that only measures fulfilling the majority of our 4 criteria are able to carry out significant quality assertions. The more error cases a measure is sensitive to (cf. Fig. 13), the higher is the quality assessment, and thus, the better the contrast of low and high quality ratings.
A fair and comparable quality assessment based on objec-tive evaluation measures is a key component for knowledge discovery in databases. In this work, we provide an analy-sis of evaluation measures for the research area of subspace clustering. We show that novel criteria for a meaningful eval-uation of subspace clustering algorithms are needed. Thus, we introduce four major criteria each measure has to fulfill: object, subspace, redundancy and identification awareness. Based on these categories, an analysis of existing measures identifies their drawbacks for applicability. Thus, we develop a novel evaluation measure that fulfills our general quality criteria. In an empirical study we highlight the characteris-tics for each measure in typical clustering scenarios.
As a conclusion, we recommend to use CE and E4SC mea-sures in future evaluations as both highlight main subspace clustering properties. In combination with other measures such as RNIA they also bring out the reasons for bad clus-tering quality as depicted in Figure 10 where we observe a significant increase in RNIA while CE remains constant and E4SC decreases. This divergence in clustering evaluation measures indicates assignment of incorrect objects to the detected clusters. With such knowledge about the charac-teristics of measures, improvements of the clustering result and the algorithms itself can be fostered.

Our work lays the foundation for a fair evaluation of algo-rithms in the area of subspace clustering. Beside the analy-sis of measures, however, it is necessary to provide a set of benchmark data that is annotated with the hidden cluster-ing structure. This is one challenge for future studies.
Acknowledgment. This work has been partly funded by the German Federal Ministry of Economics and Technology under project funding reference number 01MQ09014 and the UMIC Research Centre, RWTH Aachen University, Germany. [1] C. Aggarwal, J. Wolf, P. Yu, C. Procopiuc, and [2] C. Aggarwal and P. Yu. Finding generalized projected [3] R. Agrawal, J. Gehrke, D. Gunopulos, and [4] E. Amig  X o, J. Gonzalo, J. Artiles, and F. Verdejo. A [5] I. Assent, R. Krieger, E. M  X  uller, and T. Seidl. DUSC:
Shape (size: 160; dim: 17) Liver  X 
Dis. (size: 345; dim: 6)
Glass (size: 214; dim: 9) (size: 198; dim: 33) [6] I. Assent, R. Krieger, E. M  X  uller, and T. Seidl. INSCY: [7] B. Bringmann and A. Zimmermann. The chosen few: [8] K. Kailing, H.-P. Kriegel, and P. Kr  X  oger.
 [9] H.-P. Kriegel, P. Kr  X  oger,andA.Zimek.Clustering [10] Y. Liu, Z. Li, H. Xiong, X. Gao, and J. Wu.
 [11] G. Moise and J. Sander. Finding non-redundant, [12] G. Moise, J. Sander, and M. Ester. P3C: A robust [13] G. Moise, A. Zimek, P. Kr  X  oger, H.-P. Kriegel, and [14] E. M  X  uller, I. Assent, S. G  X  unnemann, R. Krieger, and [15] E. M  X  uller, S. G  X  unnemann, I. Assent, and T. Seidl. [16] H. Nagesh, S. Goil, and A. Choudhary. Adaptive grids [17] L. Parsons, E. Haque, and H. Liu. Subspace clustering [18] A. Patrikainen and M. Meila. Comparing subspace [19] C. Procopiuc, M. Jones, P. Agarwal, and T. Murali. A [20] J. Wu, H. Xiong, and J. Chen. Adapting the right [21] M. L. Yiu and N. Mamoulis. Frequent-pattern based
