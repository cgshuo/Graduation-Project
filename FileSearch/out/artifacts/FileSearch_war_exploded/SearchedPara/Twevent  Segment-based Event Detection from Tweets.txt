 Event detection from tweets is an important task to understand the current events / topics attracting a large number of common users. However, the unique characteristics of tweets ( e.g., short and noisy content, diverse and fast changing topics, and large data volume) make event detection a challenging task. Most existing techniques proposed for well written documents ( e.g., news articles) cannot be directly adopted. In this paper, we propose a segment-based event detection system fortweets, called Twevent . Twevent rstde-tects bursty tweet segments as event segments and then clusters the event segments into events considering both their frequency dis-tribution and content similarity. More specically, each tweet is split into non-overlapping segments ( i.e., phrases possibly refer to named entities or semantically meaningful information units). The bursty segments are identied within a xed time window based on their frequency patterns, and each bursty segment is described by the set of tweets containing the segment published within that time window. The similarity between a pair of bursty segments is computed using their associated tweets. After clustering bursty segments into candidate events, Wikipedia is exploited to identify the realistic events and to derive the most newsworthy segments to describe the identied events. We evaluate Twevent and com-pare it with the state-of-the-art method using 4.3 million tweets published by Singapore-based users in June 2010. In our experi-ments, Twevent outperforms the state-of-the-art method by a large margin in terms of both precision and recall. More importantly, the events detected by Twevent can be easily interpreted with little background knowledge because of the newsworthy segments. We also show that Twevent is e ffi cient and scalable, leading to a desir-able solution for event detection from tweets.
 H.3.3[ INFORMATION STORAGE AND RETRIEVAL ]:Infor-mation Search and Retrieval X  Clustering; Information ltering Event detection, Twitter, Microblogging, Tweet segmentation
Twitter, as a social networking service and microblogging ser-vice, has gained great success in recent years. Twitter users not only share and communicate with friends and family, but also to the general public. The unique gene of the latter enables Twitter users to access and contribute  X  the latest stories, ideas, opinions, Twitter has become one of the top-10 most visited website on the
In Twitter, each user becomes an individual news media that not only absorbs / assembles information (such as breaking news), but also publishes / propagates opinions, sentiments, and stories of themselves [9,20]. The message unit, called a tweet , is limited to maximum 140 characters in length. Such a concise unit enables information updates at extremely low-cost and in realtime, mak-ing Twitter a timely fresh information resource [3]. Consequently, the intensive interaction between users in realtime enables timely event detection by monitoring tweet updates and many prominent events are timely spotlighted by Twitter users. For example, a record number of tweet updates per second was set within a 30-sec period after the 2010 FIFA World Cup match between Japan and Cameroon on June 14, 2010. Three days later, the record was broken right after the Lakers X  victory in the 2010 NBA Finals on ported that earthquake detection based on Twitter is faster than the detection based on traditional medi a [19]. Moreover, event detec-tion from tweetswould help us gain timelyunderstanding of users X  opinion / sentiment with respect to the detected events, making it possible for company / organization to take a fast response to any emerging crisis. Event detection from Twitter stream would also contribute to the study of mass communication by analyzing the types of events general users are mostly interested in [22] as well as the reactions by users at di ff erent geographical regions [15].
Event detection from Twitter stream is challenging for at least three reasons: short and noisy content, diverse and fast changing topics, and large data volume. The task of event detection has been intensively studied in the past mostly on formal texts, e.g., news articles, blog posts, or academic papers [4 X 6,8]. However, tweets are signicantly di ff erent from well written texts because of the shortness and informal writing style. According to the principle of least e ff ort [26], people are used to communicate information with the least context, especially in the situation where a short message with free style is allowed. This makes tweets contain a lot of mis-spellingsandinformalabbreviations [17]. Becauseofthenoiseand shortness, direct adoption of most existing approaches developed for formal texts ( e.g., clustering bursty features with co-occurrence measure [5,6]) is doomed to fail on Twitter streams.

Tweets cover very diverse topics and about half of the tweets are not event-related according to a study by PearAnalytics [12]. They manually categorized 2 , 000 tweets into six categories: news (3.6%), spam (3.75%), self-promotion (5.85%), pointless babble (40.55%), conversational (37.55%) and pass-along value (8.7%). Thenumbersindicatethepercentageofthetweetsineachcategory. Based on their analysis, about 50% ( i.e., spam, self-promotion, pointless babble) of tweets are not related to events. Similar ob-servations are also made in our pilot study of the tweets data used in our experiments. However, a large number of features would be expected being bursty from tweets of pointless babble category. Obviously, none of these bursty features would help in detecting any event, but would mislead the event detection algorithm and also incur unnecessary computational cost. The situation would be further exaggerated with the fast changing topics in tweets. For example, many users would discuss about a football match during the match or within a few hours right after the match but not for a few days.
To address the above challenges, we present Twevent , a novel segment-based event detection system for tweets. One novel fea-ture of Twevent is to use the notion of tweet segment instead of unigram to detect and describe events. A tweet segment is one or more consecutive words (or phrase) in a tweet message. We ob-servethat tweet segmentscontained inalargenumber oftweetsare likely to be named entities ( e.g., Steve Jobs ) or some semantically meaningful unit ( e.g., Argentina vs Nigeria ). Therefore,a tweetseg-ment often contains much more specic information than any of the unigrams contained in the segment. The use of tweet segment instead of unigrams therefore gr eatly reduces the noise in the event detection process and also makes the event detected much easier to beinterpreted. Forexample, Twevent detectedaneventwiththefol-lowing ve segments [south korea, greece, korea vs greece, korea won, korea] on12June 2010; theevent isself-explanative. Another novel feature of Twevent is the utilization of external knowledge base in guiding the event detection process. In the following, we brief the main steps in Twevent for event detection from tweets.
Given tweets published in a Twitter stream, Twevent rstly seg-ments each individual tweet intoasequence of consecutive phrases ( i.e., segments). Then bursty segments are identied by modeling thefrequency ofasegment asaGaussian distributionbased on pre-denedxedtime-window( e.g., adayoranhour). Todetectevents attracting a larger number of use rs, we also utilize user frequency (oruser support) ofthe tweetsegments toidentifythe event-related bursty segments, called event segments. Afterthat, we apply an ef-cientclusteringalgorithmtogroup event-related segmentsascan-didateevents,whichrequiresonlyasinglepassthrougheachpairof event segments. To compute the similarity between a pair of event segments,weconsiderthefrequency distributionandthecontentof the tweets containing each of the tweet segments published within the time-window. The result of event segment clustering is a set of candidate events detected in that time window. The knowledge encoded in Wikipedia is then harnessed to help us gure out the realisticevents detected fromthetrivialonesand toderive themost representative segments for describing the realistic events. As the result, each event detected by Twevent is represented by a ranking list of segments including many named entities for easy interpreta-tion.

Twevent holds several features toaddress the challenges of event detection from tweets. Tweet segmentation employed in Twevent identies informative phrases which reduces noise in further pro-cessing. The use of user frequency in bursty event segment ex-traction makes Twevent robust to the negative impact of the tweets of Spam and Self-Promotion . The external knowledge base o Twevent the ability to resist the adverse impact of diverse and dy-namic topics of tweets, such as tweets of Pointless Babble ,and derive interpretable event descriptions. Lastly, Twevent is e and scalable by utilizing only the frequency of segments for bursty segment extraction and non-iterative clustering algorithm.
We evaluated Twevent with more than 4.3 million tweets pub-lished by Singapore-based users over a one month period. In our experiments, Twevent achieves much better performance compared to the state-of-the-art method [21] in terms of both precision and recall. More specically, Twevent achieves a precision of 86 and arecallof 75 distinctevents detected fromthe one-month data. Our experimental results also demonstrate the e ff ectiveness of us-ing tweet segments compared to the same detection process using unigrams. To illustrate that the events detected by Twevent often contain named entities or convey concise information, we list the most newsworthy segments detected by Twevent in Table 2 as part of the experimental results.

The rest of the paper is organized as follows. Section 2 surveys related work. Section 3 describes Twevent and its components in detail. Section 4 presents the experimental results. We conclude this paper in Section 5.
Event detection has a long history, which can be traced back detect and track events from news stream. Two main approaches have been studied in the literature: document-pivot and feature-pivot approaches. The former aims to cluster documents related to thesameeventsandthenextractevent-based featuresfromthedoc-ument clusters [1,2,23 X 25]. The latter aims to rstly identify the representative features of thehidden events from thestream, which are assumed to have bursty frequency patterns along time. Then events are detected by clustering these representative features [8]. Because the proposed Twevent is a feature-pivot method, in our lit-erature survey, wetherefore mainlyfocus on feature-pivot methods for event detection from formal texts.
Kleinberg [8] proposed to detect events by analyzing frequency patterns along time. An innite-state automation is used to model the changes of word frequency, and the state transitions are con-sidered as events. Fung et al. [5] proposed to identify bursty fea-tures as representatives for the events hidden in text stream. The frequency of each feature ( i.e., unigram word) is modeled with a binomial distribution. The bursty feature extraction is then based on the perspective of statistics. The events are then detected by maximizing the co-occurrences among documents and the consis-tence of the frequency distributions for all bursty features within an event. The timestamp for an event is calculated based on the bursty periods of the bursty features related to that event. The au-thors further presented an event-based search framework in [4] to retrievegroupsofdocumentssuchthatthedocumentsineachgroup are about the same event. In their result, the events are organized in a time-based hierarchy. In this event-based framework, a set of related bursty features with similar frequency distributions are re-trieved rstly. Then, document s related to the bur sty features are extracted and clustered into a hierarchy of events. Instead of using frequency directly, He et al. [6] proposed to use Discrete Fourier Transformation (DFT) to extract bursty features. They build a sig-nal for each feature using document frequency -inverse document frequency ( df  X  idf )scheme along timedomain. Then, DFT trans-forms the signal in time domain to frequency domain, i.e., aspike in frequency domain indicates a corresponding high frequency sig-nal source. Similarto [5], they group bursty features into events by considering both features X  co-occurrence and their distributions in time domain. To estimate the timestamp of the events, they model a df  X  idf signal with a Gaussian mixture.

Unlike formal texts that are formally written and published in moderaterate,tweetsareshort,informallywritten,andpublishedat an enormous amount. Thus, bursty feature extraction solely based on statistics would result in a huge number of bursty features, par-ticulary when unigram feature representation is used. Similarly, the application of DFTwould be dread and prohibited. Further, co-occurrence measuresusedin[5,6]maynotworkwellinthecontext of twitter due to sparsity.
Recently, event detection on twitter stream becomes a hot re-search topic. Michael and Nick [11] presented a trend detection system over twitter stream. They rstly identify the bursty terms based on queueing theory. Then bursty terms are grouped into the events based on their co-occurrences. For a detected trend, PCA, SVD and entity extraction techniques are then applied to derive contextual informationforthetrenddescription. Petrovi  X  c etal. [13] trackedeventsontwitterstreambyapplyinglocalitysensitivehash-ing (LSH). LSH is applied to each tweet to measure the similarity to existing tweets. The tweets similar to each other are grouped as events. Swit and Tsuyoshi [14] proposed an approach for break-ing news detection and tracking by clustering the similar tweets together. The approach only focuses on the tweets with a spe-cic hashtag #breakingnews. The similarity between two tweets of breaking news is measured by using a variant of tf  X  idf scheme where the named entities detected by a Named Entity Recognizer (NER) are further boosted. Popescu et al. [16] proposed a method for entity-based event detection on twitter streams. A set of tweets containing the predened target entity are processed and machine learning techniques are used to predict whether the tweets consti-tute an event regarding the entity. Very recently, Li et al. [18] proposed to detect crime and disaster related Events (CDE) from tweets. Conventional text mining techniques are applied to extract the meta information ( e.g., geo-location names, temporal phrase, and keywords) for event interpretation. To summarize, most exist-ing approaches for detecting events from tweets are applicable to certain types of tweets ( e.g., having a specic hashtag, containing a predened entity, or related to crime and disaster). The other so-lutions including [11] and [13] involvecomplicated processing and lead to heavy computational cost.

Themostrelatedworktoours,istheapproachproposedbyWeng and Lee, named EDCoW [21]. There are three steps in their ap-proach. Firstly wavelettransformation and autocorrelation areap-plied to measure the bursty energy of each word. The words with outstanding high energies are retained as event features. Then they measure the similarity between each pair of event features by us-ing cross correlation . At last, modularity-based graph partitioning is used to detect the events, each of which contains a set of words with high cross correlation . However, several issues get in the way of the practical application for their approach. Wavelet transfor-mation and auto correlation for each word of the twitter stream would require a huge amount of computation, making it not a scal-able choice. Moreover, utilizing only cross correlation for similar-ity measure would lead to the resulted event consisting of several distinct events which happened at the same period by coincidence ( e.g., twofootball matches hold at the sametimeduring FIFA2010 World Cup). Thirdly, the detected events with unigram features are di ffi cult for human interpretation. In Twevent , we segment each tweet into possible semantic phrases, making the detected events easy to interpret. During the detection process, we do not employ computational costly Wavelet transformation and auto correlation for tweet segments. Instead, only the tweet frequency and user fre-quency are needed for bursty tweet segment detection. To distin-guish events that happened at the same period, Twevent computes content similarityforapairoftweetsegments. Eachtweetsegment is described by the content of the tweets containing the segment. Although pair-wisesimilaritycomputation iscomputational costly, it is only applied to a relatively small set of bursty tweet segments detected within one time window.
In this section, we present a feature-pivot event detection frame-work. Illustrated in Figure 1, our framework consists of three main components: tweetsegmentation , eventsegmentdetection ,and event segment clustering . After receiving a tweet from a Tweet stream, tweetsegmentationcomponentsplitsthetweetintonon-overlapping segments. A tweet segment can be either a unigram or multi-gram ( e.g., [mtv movie awards] , [steve jobs] ), and each segment may or may not represent a semantic unit. The resultant tweet segments obtained from a tweet, together with the content and timestamp of the tweet, are indexed in the segment index. The event segment detection component detects abnormal bursty segments by consid-ering tweets frequency distribution and user frequency of the seg-ments. The event segments about the same event are then grouped togethertoformtheeventbytheeventclusteringcomponent. Inthe restofthissection, wedescribe eachcomponent indetailfollowing the order of their usage in our framework.
The notion of tweet segment was rstly proposed in our recent work [10] for named entity recognition, not related to event detec-tion. In the following, we brief the techniques for tweet segmenta-tion.

Given a tweet d  X  X  , the problem of tweet segmentation is to split d into m non-overlapping and consecutive segments, d s s 2 ... s m , where a segment s i is either a word (or unigram) or a phrase (or multi-gram). We formulate tweet segmentation problem as an optimization problem with the following objective function, where C is the function measures the stickiness of a segment or a tweet.
Ahigh stickiness score of segment s indicates that further split-ting segment s would break the correct word collocation .Inother words, segment s cannot be further split at any internal position if it has a high stickiness score. We dene stickiness function by us-ing the generalized Symmetric Conditional Probability (SCP) for n -grams with n  X  2, supported by statistical information derived
SCP is dened to measure the "cohesiveness" of a segment s w as shown in the following equation, where Pr(  X  ) denotes the prior probability derived from Microsoft Web N-Gram service. In this equation, the logarithm value is taken to avoid underow. Note that, SCP ( s ) = 2log Pr ( w )ifsegment s is of unit length ( i.e., | s | = 1or n = 1).

Based on SCP ( s ), we dene the stickiness score of segment s by considering thehigh quality semantic resources inWikipedia. That is, segments which frequently appear as anchor texts in Wikipedia are further favored. The stickiness function is then dened as: where Q ( s )istheprobabilitythat s appears as theanchor text in the Wikipedia articles that contain s ,and S (  X  ) is the sigmoid function. Thefunction L denedinEquation4isusedtogivemoderatepref-erence forlonger segments. Withthisstickiness function, thetweet segmentation dened in Equation 1 can be nished e ffi ciently in linear time with dynamic programming.
One salient characteristic of emerging events in text streams is that there is a signicant coverage of topics related to an event withinacertaintimeperiod. Accordingly,givenacollectionofseg-ments of the tweets published within a xed time window, bursty segments in terms of frequency would be potentially related to some hot events talked and shared by Twitter users. However, con-sidering the dynamic nature and the large volume of tweets pub-lishedeveryday, e ffi cientlydetectingburstysegmentsisnon-trivial.
Let N t denotethenumberoftweetspublishedwithintime-window t from Twitter stream, f s , t be the number of tweets containing s published within t , i.e., the tweet frequency of segment s in time-window t . The probability of observing frequency f s , t in t can be modeled by a binomial distribution [5].
 where p s isthe expected probability of tweets thatcontain segment s inarandomtimewindow. Giventhat N t isverylargeinthecaseof Twitterstream,itisreasonabletoapproximate P ( f s , t )withGaussian distribution: Thus, given segment s , the expected number of tweets containing s would be E [ s | t ] = N t p s . The more the additional tweets contain-ing s with respect to E [ s | t ], the more bursty the segment is. On the other hand, segment s with frequency f s , t &lt; = E [ s ered as a non-bursty segment and willnot be considered forfurther processing. Hence, we dene bursty segment as follows.

Denition 1. [Bursty Segment] Asegment s is a bursty seg-ment in time window t if its tweet frequency f s , t &gt; Next we transfer the frequency of a bursty segment into range of (0 , 1] indicating its bursty probability .

We consider a bursty segment s to be extremely bursty and as-sign P b ( s , t ) = 1 if its tweet frequency f s , t  X  E [ s  X  [ s | t ] = tion 6. Fora burstysegment whose tweet frequency f s , t fallswithin compute its bursty probability.
 where S (  X  ) is the sigmoid function, and a constant 10 is introduced in the equation because the sigmoid function S ( x ) smooths reason-able well for x in the range of [  X  10 , 10].

Withtheabovestatisticalmethod,weareabletodetectthebursty segments and assign each a bursty probability. However, Twitter is signicantly di ff erent from most text streams ( e.g., news stream andblog stream)thathavebeenextensively studiedintheliterature for bursty feature / event detection, because of its informal writing style and topic diversity. Therefore, a large number of tweet seg-ments would be detected to be bursty segments. A simple statistics in our study shows that the number of distinct bursty segments is about 75% of the number of distinct tweets in a randomly chosen time window. Among the bursty segments detected, many contain misspelling words and informal abbreviations. These noisy bursty segments would not only incur unnecessary computational cost but alsohurt theevent detectionaccuracy inthefurtherprocessing. We therefore source for the wisdom of the crowds to lter the bursty segments.

Instead of solely relying on the tweet frequency of a segment, we believe that a bursty segment has a higher chance to be related to an event if there are more users post tweets containing the seg-ment. Hence, we dene user frequency u s , t of a segment s ,which isthenumber ofuserswho post tweetscontaining s during thetime period t .

With the two factors, bursty probability and user frequency, the most simple approach to detect the event-relatedness of a bursty segment is to take the product of the two factors. However, this simple approach would make the top-ranked segments dominated by the ones used by most users, such as "i X  X " , "i X  X l" ,and "guys" .To some extent, bursty segments with higher user frequencies are cor-related with some events. However, considering the limited length oftweets,theburstysegmentswithhigheruserfrequenciesmaynot besemanticallymeaningful and areoftenambiguous. Forinstance, "nigeria" , "argentina" and "argentina vs nigeria" are all related to a single event: a 2010 world cup match between nigeria and ar-gentian . However, the bursty segment "argentina vs nigeria" has a relatively much lower user frequency due to the principle of the least e ff ort [26]. In contrast, comparing "argentina vs nigeria" with either "nigeria" or "argentina" , the segment "argentina vs nigeria" would convey much more information about the event. Based on this observation, we assign each bursty segment s a weight w by using a logarithm function. The above weight scheme would keep the more bursty segments of the higher user frequency being ranked higher and the more bursty segments of the moderate user frequency being ranked relatively higher than the others.

By ranking the bursty segments by their weights w b ( s , thenretainthetop-K burstysegmentsaspotentialevent-relatedseg-ments (orsimplyevent segments) forfurtherprocessing. Thevalue of K is non-trivial because a small K would result in a very low recall of events detected, and a large K may bring in more noise, leading to much higher computational cost as well as lower preci-sion on the detected events. In practical, the optimal K value de-pends on the size of the time window, and requires some expertise knowledge ( e.g., , users from di ff erent regions may be interested in di ff erent topics [15]). In this work, we apply a heuristic strategy to lter out the bursty segments by setting K to
Denition 2. [Event Segment] Aburstysegment s isapotential event-related segment (or simply event segment) in time window t if it is ranked among top-K bursty segments by w b ( s , ing order, where K =
Given a set of event segments detected from the previous step, we now cluster them into groups, each of which corresponds to a possible realistic event. Some event segments that cannot be clus-tered into groups are considered noise or non-event-related. These non-event-related segments are dropped from further processing.
Accordingly, weneedtoderiveasimilaritymeasureforeachpair of event segments. Various similarity measures have been used in the past to cluster bursty feat ures detected in formal texts, mainly based on co-occurrences of bursty features [5,6]. However, sim-ilarity measure based on co-occurrence would not work well on tweets because they are much shorter in number of words com-pared to formal documents. Moreover, the topics in tweets are ex-tremely dynamic and fast changing. Considering these two factors, we propose to measure similarity between two event segments by the content of their associated tweets and their temporal frequency patterns.

Foreachtimewindow t ,wefurtherdividethetimeperiodevenly into M sub-time-window: t = t 1 ... t M . The tweet frequency of an event segment s in sub-window t m is denoted by f t ( s T ( s , m ) be the set of tweets that each contains segment s and is published within sub-window t m . We dene the similarity between apairofsegments s a and s b within time window t as follows: sim t ( s a , s b ) = where sim ( T 1 , T 2 )measuresthesimilaritybetweentwosetsoftweets T and T 2 ,and w t ( s , m ) weighs the importance of sub-window t segment s . To compute sim ( T 1 , T 2 ), we concatenate all tweets in T (resp. T 2 ) to form a pseudo document, and use cosine similarity with tf  X  idf scheme. The importance ofsub-window t m tosegment s is the normalized frequency distribution over M sub-windows:
Equation 9 illustrates that two event segments are similar if they have both similar tweet content and consistent frequency patterns along the time sub-windows. Either dissimilar tweet content or in-consistent frequency patterns leads to low similarity. More specif-ically, dissimilar tweet content suggests that two event segments refer to two distinct events. Inconsistent frequency pattern may suggest that the two event segments refer to two similar events but happened at di ff erent time points ( e.g., two football matches at the same day).

To be shown in our experiments (Section 4.3) content similarity isnecessary to distinguish segments ofdi ff erentevents having very similar tweet frequency distributions. Note that, because of the specic information conveyed by tweet segment, we believe that the content similarity of using all tweets containing the tweet seg-mentismoremeaningful thanthatusingunigram. Forexample, the tweetscontainingsegment steve jobs willbeverydi ff erentfromthe tweets containing either steve or the tweets containing jobs only.
Giventhesimilaritymeasure inEquation9,clustering eventseg-ments into possible events become straightforward and many ex-isting clustering algorithms can be directly applied. We apply an variantofJarvis-Patrickalgorithm[7]foreventsegmentclustering.
Given a graph of objects with edges indicating the similarity be-tween any two objects, Jarvis-Patric k clustering algorithm parti-tions the graph by measuring the number of common neighbors among the k -nearest neighbors of the two objects. The partition-ing involves two parameters: k and . Two objects are put into the same cluster if: 1) they arein each others X  k -nearest neighbors, and 2) they share at least common nearest neighbors among the k -nearest neighbors. Note that, Jarvis-Patrick requires a single scan of all pairs of objects for clustering, which o ff ers great scalability for Twitter stream-based event detection.

Considering the unique properties of short length and informal writing style of tweets, two event segments referring to the same eventmaynotsharealargenumberofcommon k -nearestneighbors to each other. Nevertheless, an event segment referring to a realis-tic event would likely appear in another event segment X  X  k -nearest neighbors, and vice versa, given that the two event segments refer-ring to the same event. We therefore relax the clustering criterion by considering only the rst requirement: two event segments ap-pearing in each others X  k-nearest neighbors are put into the same cluster . With this relaxation, given a complete graph of event seg-ments,theclusteringbecomestoretainanyedgebetweentwoevent segments s a and s b if and only if they appear in each other X  X  k -nearest neighbors. The resultant connected components are con-sidered as candidate events . If an event segment is in isolation and not grouped into any cluster, it is considered not event related and dropped from further processing. The clustering of event segments therefore requires only one parameter k and we set k = 3inour experiments.
Cambridge Dictionaries Online denes an event as  X  X nything ever, weobserve thatmany candidate events detected through clus-tering event segments are not realistic events. For instance, the segments "friday night" , "friday" , "weekends" , "trip" and "enjoy" are returnedasapossibleeventbytheaboveproceduresatsomeFriday ( e.g., Jun 18, 2010 covered in our dataset). More detailed human investigation shows that the tweets of this candidate event are from people who were talking about the plan or schedule for the coming weekend. Apparently, this kind of events can not be considered as realistic events. This calls for a mechanism to evaluate the  X  X mpor-tant and unusual X  aspect of a candidate event obtained from event segment clustering.

We observe that many events involve well-known entities ( e.g., person names, locations, festivals) and many of these entities are documented in Wikipedia. Recall that each segment is produced in Section 3.1 with the preference t owards Wikipedia entities (see Equation3). WethereforeagainutilizeWikipediatoapproximately evaluate X  X mportantandunusual X  X spectofacandidateevent. More specically, we dene newsworthiness measures for event segment and candidate event respectively.

Denition 3. [ Segment Newsworthiness ] The newsworthiness  X  ( s )ofasegment s is where isany sub-phrase of s ,and Q ( )isthepriorprobabilitythat appears as anchor text in Wikipedia articles that contain . The exponential function is used in the equation since it is an in-creasing function with an increasing rst derivative in the range of [0 , 1]. That is, a segment with a larger Q ( ) would gain a relatively higher newsworthiness value. Next, we dene the newsworthiness of a candidate event as follows.

Denition 4. [ Event Newsworthiness ]Thenewsworthiness  X  ( e ) of an event e containing a set of event segments e s = { s where E e is a set of edges that are retained during applying Jarvis-Patrick clustering, and sim ( g ) is the similarity of edge g which is calculated by using Equation 9.
 Observe that newsworthiness of a candidate event considers both the newsworthiness of its member event segments ( i.e., the rst component) and the topology of the connected component formed by its member event segments ( i.e., the second component). The latter is equivalent to measure the density of the connected compo-nentintheclusteringresult. Therefore, acandidate eventreceivesa high newsworthiness scoreifsomephrases initsmember segments are commonly used as anchor text in Wikipedia (indicating well known entities) and the member segments are well connected with strong cohesive topology.

Weobserveinourexperiments,mosttop-rankedcandidateevents by newsworthiness are likely related to realistic events. On the other hand, noisy events likely have much lower newsworthiness scores. Thatis,thedistributionofnewsworthinessscoreshasapos-itive skewness. Let  X  x be the highest newsworthiness score among all candidate events detected ina given time-window. Based on the above observation, we consider a candidate event e to be a realistic event ifthe ratio between  X  x and  X  ( e ) issmaller than a threshold in better precision of the detected events but poorer recall, and vice versa. We investigate the impact of  X  empirically in Section4.
After ltering away noisy ev ents, we represent each detected event with its member event segments sorted by newsworthiness scores. The top-ranked segments are used to describe the event. In this work, the top-5 segments are used to describe the event.
The e ffi ciency of Twevent is a non-trivial factor from a practical perspective. Recall that Twevent contains three main components: tweet segmentation, event segment detection, and event segment clustering, shown in Figure 1. We next discuss the computational cost for each component.

The running time of tweet segmentation is linear to the length of a tweet (in number of the words). As segmentation of one tweet is independent of segmentation of other tweets, parallel computing techniques can be easily utilized in this component. More impor-tantly,tweetsegmentationcanbeconsideredasapartofpreprocess because all segments are stored in an index for further processing.
Event segment detection only requires one scan of segments X  tweet frequency and user frequency. The time complexity is lin-ear to the number of segments in each time window.

Mostcomputationtimeisconsumed bycalculatingthesimilarity between two event segments, and event segment clustering. How-ever, the pair-wised event segment similarityis computed for a rel-atively small set ( e.g., K = numberoftweetspublishedwithinatimewindow. Thatis,thetime complexity is O ( K 2 ). The Jarvis-Patrick clustering algorithm used for event segment clustering requires one scan of all pairs of event segments within a time window. Given the relative small number of detected events in each time window, the running time for the candidate event ltering is negligible.
 Weconducted our experiments onaworkstation witha2.40GHz Xeon quad-core CPU and 24GB of RAM. Without considering the timetakenfortweetsegmentation 8 , Twevent takesabout18seconds to detect events from average 143 K tweets published in one day ( i.e., the time window).
In this section, we report our extensive experiments on evaluat-ing Twevent . We show that Twevent outperforms the state-of-the-art approach with both better precision and recall. We show that newsworthy segments make the detected events much easier to be interpreted by users. Further, we evaluate the usefulness of the no-tion of tweet segment against unigram, the e ff ect of the parameters in Twevent . Wikipedia Data. The Wikipedia data used in tweet segmenta-tion (Section 3.1) and newsworthiness measure (Section 3.3.3) are based on the Wikipedia dump released on 30 Jan, 2010. It con-tains 3 , 246 , 821 articles and 266 , 625 , 017 hyperlinks. In total, there are 4 , 342 , 732 distinct entities appeared as anchor texts in the Wikipedia dump.
 Twitter Stream. A collection of tweets published by Singapore-based users (based on the location specied in user prole) in June 2010 isused to simulate aTwitterstream. Thisdataset was builtby Weng and Lee for evaluating the EDCoW event detection method in[21]. Thereare atotalof4 , 331 , 937 tweetspublished by 19 unique users in the dataset. A number of realistic events happened inthedatacollection period,such as FIFA World Cup 2010 , WWDC 2010 ,and MTV Movie Awards 2010 .

Figure2(a)showstheaveragenumberoftweetspublishedwithin each hourofaday. Most tweetsarepublished within6AMto6PM, with relatively more tweets published in the afternoon. Parameter Setting. There are several parameters that could a crosoft Web N-Gram Web service. Table 1: Detection results of Twevent , Twevent u ,and EDCoW . Method No. events detected Precision Recall DERate EDCoW 21 76 . 2% 13 23.1% Twevent 101 86.1% 75 16.0 %
Twevent u 146 75 . 3% 78 41.0% the performance of Twevent . Thesize ofthetime-window t and the number of sub-time-windows M are the two basic parameters for Twevent . In our evaluation, we x t to be a day and set M That is, each sub-time-window is 2 hours.

Recallthatweretainonly top K = segments, where N t is the number of tweets published in the time window t ; For Jarvis-Patrick clustering, we set k = 3 for the num-berofnearestneighborsinthegraph; Todistinguishrealisticevents from noise, we set threshold on the ratio of newsworthiness our experiments, we observe that parameter  X  a ff ects the event de-tection accuracy of Twevent more signicantly than the other two parameters K and k . We therefore evaluate the impact of varying and x K = Evaluation Metric. The dataset does not come with ground truth labels on all realistic events within the data collection period. Be-cause it is infeasible to manually label the over 4 million tweets in the dataset, we choose to manually evaluate the detected events returned by Twevent .Weuse precision and recall to evaluate the accuracy of the events detected.

We follow the denition of Precision used in [21], which is de-ned as the fraction of the detected events that are related to a realistic event. However, recall was not dened in [21] because of the lack of the ground truth labels in the dataset. In our pa-per, we choose to report Recall as the number of distinct realistic eventsdetected fromthedatasetondailybasis. Notethat,iftwode-tected events are both related to the same realistic event within the same time window ( i.e., one day), then both are considered correct in terms of precision, but only one realistic event is considered in counting recall. Due to this reason, we also dene Duplicate Event Rate (or simply DERate ) to denote the percentage of events that have been duplicately detected among all realistic events detected.
We rst report statistics on the tweet segments returned by the tweet segmentation component. After removal of stop-words and wordswithnon-Englishcharacters,thereare662 , 088distinctwords or unigrams retained in the data. Tweet segmentation is then ap-plied to each tweet. A total of 1 , 275 , 809 distinct segments are obtained after segmentation.

Observe from Figure 2(b), the tweet frequency of a segment fol-lows a power-law distribution. On average, each segment is con-tained in19 tweets. InFigure2(c), wereport thedistributionofun-igram and multi-gram segments. The gure shows that about 50% of the segments are 2-grams; segments with more than 3 grams are very rare. We observe that 2-gram segments cover a large propor-tional of named entities, such as "lady gaga" and "justin bieber" ,or location name like "orchard road" . Moreover, many 3-grams seg-ments are very informative, like "mtv movie awards" and "penalty shoot out" . More examples are given in Table 2. We compare Twevent with two methods: EDCoW and Twevent u . The latter is a variant of Twevent without using tweet segment but using unigram intheevent detection process,withthesameparam-etersettingsas Twevent exceptthesettingforthreshold  X  .Inthisset Figure 3: Comparison of frequency distributions for the two events: Twilight and Park Yong-ha of experiments, we set  X  = 4for Twevent and  X  = 3for Twevent The impact of varying  X  will be reported inSection 4.4.
Recallthatwemeasurethesegment X  X newsworthinessusingDef-inition 3. Based on this denition, a unigram is likely to have zero newsworthinessscore. Thus,wechangethenewsworthinessdeni-tion for unigram to be  X  ( w ) = e Q ( w ) for a unigram w . The modied denition strongly favors informative unigrams, leading to better representations for the detected events. Next, we report the event detection accuracy of the three methods.
 Event detection accuracy . Table 1 reports the number of events detected, theprecisionandrecall,ofthethreemethodsrespectively. The results of EDCoW are reproduced from [21] 9 . Shown in the table, our proposed method Twevent yields the best precision of 86.1% which is signicantly larger than the precisions achieved by EDCoW and Twevent u . Observe that our method Twevent de-tects 101 events with a recall of 75 realistic events. On the same dataset, EDCoW detects 21 events in total with 13 realistic events. Twevent u yields a slighter worse precision than EDCoW (75.3% vs 76.2%) but detects the largest number of realistic events. In terms of DERate, Twevent achieves the lowest rate despite that our method detects much more events than EDCoW (101 vs 21). On the other hand, we observe that Twevent u delivers the worst DER-ate, more than double of Twevent (41% vs 16.0%). That is, the un-igrams about the same event are clustered into two or more events. Because a tweet segment usually conveys very specic informa-tion, thetweetscontaining thetweetsegment areallabout thesame topic ( e.g., the event). Two tweet segments about the same event are therefore have higher chance to be clustered together.
From the list of events detected, we observe that an event is re-detected mainly because users discuss the event from di ff spectives, or one event is a sub-event of another. We use the two events e 22 and e 20 detected on 12 Jun 2012 as an example for illus-tration. Listed in Table 2, e 22 , detected with segments [usa, eng-land, eng, vs] , refers to the football match between England and USA in 2010 World Cup; e 20 with [steven gerrard, captain, score, scored, gerrard] refers to the caption of England, Steve Gerrard, scored a goal in this match. Because both events refer to the same match, we count them as one realistic event in our recall. Event interpretation . We argue that the notion of tweet segment not only benets betterprecision inevent detection, but alsomakes the detected events much easier to be interpreted. In above dis-cussion, we show that person name [steven gerrard] is detected as an event segment in the result. We now give more examples by listing all the events detected by Twevent between June 07 to Figure 4: Twevent and Twevent u against di ff erent  X  values wide range of events that happened in June, 2010, including Apple WWDC 2010 , MTV Movie Awards 2010 ,and FIFA World Cup 2010 , among others.

FromTable 2, we make two observations. First,many event seg-ments are multi-gram segments such as various types of named entities [steve jobs] , [mtv movie awards] , [katy perry] ,and [karate kid] , and segments conveying concrete information like [argentina vs nigeria] and [season %nale] . These segments make the events much easier to be interpreted than some unigram keywords. For comparison, we also list the keywords of all the 8 events detected by EDCoW , reproduced from [21], and the keywords of all the 40 events detected by Twevent u during the 6-day period in Tables 3 Table 3: Events detected by EDCoW in June 07  X  June 12, 2010 (reproduced from [21], following their event id.)
Day e ID Event keywords and 4, respectively. We can see that the keywords detected by ED-CoW is relatively hard to interpret than the two methods Twevent and Twevent u . Compare the latter two methods, we argue that Twevent detects more semantically meaningful keywords / phrases than Twevent u . Forinstance, weusethersttwo eventsdetected by both methods as example. Although both methods detect similar keywords for the WWDC 2010 event, [steve jobs, imovie, wwdc, iphone, wi%] is more easy to interpret than [wwdc, keynote, live, jobs, steve] . Similarly, Twevent detects [mtv movie awards, mtv, new moon, twilight, awards] while Twevent u outputs [mtv, moon, twilight, movie, awards] ; the phrase [mtv movie awards] makes the event much more easy to interpret. Second, the detected events by Twevent cover a wide range of events, such as Korea music bands , Apple WWDC 2010 , MTV Movie Awards 2010 , release of musicvideosand movies, andfootball matchesof World Cup 2010 . That is, Twevent does not favor certain types of events than others. Among the 22 events listed in Table 2, only 1 event has no cor-responding real-life events leading to a precision of 95 . 6-day period.
 Case study . We use a case study to illustrate the importance of using content inevent detection fromtweets. Figure3plots therel-ativefrequency oftweetspublished onJune 30, 2010 relatedtotwo events. The rst event with segments [harry potter, twilight, hours, trailer] is about the movie The Twilight Saga: Eclipse ,whichwas released on June 30, 2010. The trailer of the Movie Harry Potter and the Deathly Hallows Part 1 was shown before The Twilight Saga: Eclipse . The second event, with segments [park yong ha, rip, peace, hope, park] refers to the suicide case of Korean actor Park Yong-ha on June 30, 2010. Observe from Figure 3, the two events have very similar tweet frequency distribution over the 24 hours of the day. The tweet frequency of an event is dened as the relative frequency of the tweets published in an hour that contain any event segment oftheevent. Weargue that itishard todistinguish thetwo eventswithout using content similaritybetween theevent segments (see Section 3.3).
Day e ID [Event Segments] : Event Description 7 8 9 10 . The song Never Say Never by Justin Bieber serves as the theme . 12 . Park Ji-Sung, the caption of South Korea, scored a goal against
While event segments are clustered into candidate events, the ratio threshold  X  denes the boundary between the realistic events and the noisy events. We next analyze the e ff ect of  X  value on the performance of Twevent and Twevent u .

Figure 4(a) plots the precision and DERate of the two methods when changing  X  from 2 to 10. We make the two main observa-tions. First,forbothmethods,precisiondegradesalongtheincrease of  X  as more events are considered as realistic events. Neverthe-less, the rate of degradation for Twevent is much smaller than that of Twevent u . Observe that Twevent maintains very good precision above 80% even when  X  = 10, which is better than the best preci-sion achieved by Twevent u with all  X  values. Second, increasing of  X  leading to increase in DERate. Shown in Figure 4(a), the DER-ate of Twevent is about half of Twevent u for most  X  values and stop increasing when  X  &gt; 6. In summary, the use oftweetsegmentation in event detection contribute to much higher precision and much lower duplicate event detection rate.

Figure 4(b) reports the number of events detected and the recall values along the change of  X  values for the two methods. For both methods, increase  X  leads to better recall. Observe that, although Twevent u alwaysachievesbetterrecallthan Twevent ,thedi ff between therecall values donot change much along theincrease of  X  . However,incrementof  X  leadstosharpincreaseofthenumberof events detected for Twevent u . But due to thepoorer precision along theincreaseof  X  , the number of realistic events detected does not increase at the same pace as the number of detected events.
Twitter,asanewtype ofsocialmedia,hasexperienced anexplo-sive growth in terms of both users and information volume in re-cent years. The characteristics of tweets propose severe challenges to many tasks including event detection. In this paper, we present a novel event detection system for Twitter stream, called Twevent , to tackle the adverse impacts of tweets: short and noisy content, diverse and dynamic topics, and large data volume. One of the key concept in Twevent is to use tweet segment instead of unigram for identifying the bursty features and then distinguishing the realistic events from thenoisy ones. Twevent demonstrates outstanding per-formance in our experiments: e ff ectiveness, informativeness, and e ffi ciency. As a part of our future work, we will investigate the ef-fectivenessofutilizingmorefeaturesfromtweets( e.g., retweetrate and hashtags) in Twevent . Another important task is to investigate thee ff ectiveness of Twevent whennone ofthesegments ofan event is covered by Wikipedia. This work was partially supported by MOE AcRF Tier-1 Grant RG13 / 10, Singapore. We thank Jianshu Weng from HP Labs Sin-gapore for providing us the dataset used in [21]. Table 4: Events detected by Twevent u in June 07  X  June 12, 2010
Day e ID Event keywords [1] J. Allan, R. Papka, and V. Lavrenko. On-line new event [2] T. Brants, F. Chen, and A. Farahat. A system for new event [3] A. Dong, R. Zhang, P. Kolari, J. Bai, F. Diaz, Y. Chang, [4] G. P. C. Fung, J. X. Yu, H. Liu, and P. S. Yu. Time-dependent [5] G. P. C. Fung, J. X. Yu, P. S. Yu, and H. Lu. Parameter free [6] Q. He, K. Chang, and E.-P. Lim. Analyzing feature [7] R. A. Jarvis and E. A. Patrick. Clustering using a similarity [8] J. Kleinberg. Bursty and hierarchical structure in streams. In [9] H. Kwak, C. Lee, H. Park, and S. Moon. What is twitter,a [10] C. Li, J. Weng, Q. He, Y. Yao, A. Datta, A. Sun, and B.-S. [11] M. Mathioudakis and N. Koudas. Twittermonitor: trend [12] PearAnalytics. Twitter study, August 2009. Available online [13] S. Petrovi  X  c, M. Osborne, and V. Lavrenko. Streaming rst [14] S. Phuvipadawat and T. Murata. Breaking news detection [15] B. Poblete, R. Garcia, M. Mendoza, and A. Jaimes. Do all [16] A.-M. Popescu, M. Pennacchiotti, and D. Paranjpe. [17] A. Ritter, S. Clark, Mausam, and O. Etzioni. Named entity [18] L. Rui, L. Kin, K. Ravi, and C. Kevin. Tedas: a twitter based [19] T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes [20] J. Teevan, D. Ramage, and M. R. Morris. #twittersearch: a [21] J. Weng and B.-S.Lee. Event detection intwitter. In ICWSM , [22] S. Wu, J. M. Hofman, W. A. Mason, and D. J. Watts. Who [23] Y. Yang, T. Ault, T. Pierce, and C. W. Lattimer. Improving [24] Y. Yang, J. G. Carbonell, R. D. Brown, T. Pierce, B. T. [25] Y. Yang, T. Pierce, and J. Carbonell. A study of retrospective [26] G. K. Zipf. Human Behavior and the Principle of Least
