 Non-negative Matrix Factorization (NMF)[ 3], which has already been successfully applied to document clustering. However, experiments on short texts, such as micro-blogs, Q&amp;A documents and news titles, suggest unsatisfactory performance of NMF. One of the possible reasons is that compared with documents, microblogs are in gen-noisy data can be challenging. blog. Some researchers[4] introduce semi-supervised priors and explore the effects on additional semantics. 
In this paper, however, we take advantage of term correlation to enrich the seman-is calculated. And then, a non-negative matrix factorization embedded with word-microblog dataset demonstrate the superior performance of the proposed method. 
The outline of this paper is as follows: Section 2 presents details of our approach. The experiments and results are given in Section 3. We conclude our paper in Section 4. 2.1 Generation of Prior Knowledge Generally speaking, estimating the relation between terms takes advantage of co-if they frequently co-occur in the same document. A term can then be represented by posed a coupled term-term relation model for document representation, which consid-ers both the intra-relation and inter-relation between a pair of terms. 
Likewise, in this paper, we consider both the co-occurrence and dependency of terms to capture the underlying relationship between terms. The co-occurrence of two terms can be quantified by using positive point mutual information (PPMI) while the dependency of terms can be formalized by their interaction with all the link terms. as: corpus term is represented by a term co-occurrence vector, We then apply the common vector-terms. link term t k can be defined as: tion with all the link terms as: When w ( i,j ) is beyond a certain predefined threshold, these two words are considered considered to be in two different clusters. must-link document pairs are encoded as a symmetric matrix A whose diagonal entries all equal to one and the cannot-link pairs as another matrix B . 2.2 Algorithm Description In the proposed model, we perform the corresponding NMF algorithm[6]. Introducing orthogonality constraint leads to rigorous clustering interpretation. The simultaneous row/column clustering can be solved by optimizing The Frobenius norm is often used to measure the error between the original T matrix X and its low rank approximation FSG . Algorithm 1 . The overall procedure of our approach Input  X  Word-Microblog matrix X, number of word clusters k 1 , number of microblog clusters k 2 , must-link document pairs A ml and cannot-link document pairs B cl . 1. Initialize F , S and G with non-negative values  X  2. Construct must-link matrix A and cannot-link matrix B ; 3. Iterate for each k 1 and k 2 until convergence The correctness and convergence of our algorithm has already been proved [6]. 3.1 Dataset and Performance Metrics performance of our algorithm, we use three popular measures for clustering [9]: puri-ty, adjusted random index (ARI), and normalized mutual information (NMI). 3.2 Experimental Results The experiments include two parts: 1) Overall evaluation of our model by comparing with that of other algorithms; 2) Experiments Using Pair-wise Relations. Experiments Using Prior Knowledge We denote our method utilizing prior knowledge as TNMF-CP (Tri-Factor Nonnega-to as IT-Co-clustering[10], Tri-Factor Nonnegative Matrix Factorization (TNMF_E) Factorization (TNMF_I) denotes the NMF with the generalized I-divergence. All these above methods do not make use of knowledge in the word space. In this expe-result with the best performance with the corresponding threshold. the real number of all the document clusters. Figure 1 shows the experimental results on our dataset using purity, ARI and NMI as the performance measure. All the expe-rimental results are obtained by averaging 20 runs. Figure 1 shows the experimental comparisons. We can see that our method TNMF-CP can greatly enhance the clustering results by benefitting from the prior knowledge. means that our model is able to generate significantly better results by quickly learn-ing from these pair-wise constraints. Effect of Pair-Wise Constraints In order to illustrate the impact of prior constraints on the performance of clustering, data sets. Figure 2 shows the performance. In this figure, purity, ARI, and NMI scores are used to depict the performance of our proposed approach, varying along with the value of parameter  X  (from 0.1 to 0.9 with increment 0.1) for each dataset. criteria is robust across a wide range of mixing proportions. All these demonstrate that the inter-relation has great impact on the performance of microblog clustering. Besides, we observe that the best performance with the different value of  X  on different evalua-requires higher clustering accuracy. In summary, the experimental results match favor-ably with our hypotheses and encouraged us to further explore the reasons. In this paper, we explore the performance of a term correlation based semi-supervised background knowledge source, both intra and inter relations among terms are ex-are introduced into NMF framework. Our evaluations demonstrated the effectiveness of the proposed method for clustering short texts. Nevertheless, microblogs (and pos-or explored. Future work aims at finding proper ways of adding different priors. Acknowledgement. This work is supported by the National Natural Science Foundation of China (No., 61363058, 61163039), Research Foundation of Education Department of Gansu Province (No. 2013A-016). 
