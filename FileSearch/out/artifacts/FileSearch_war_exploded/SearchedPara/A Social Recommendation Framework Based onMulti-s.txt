 This paper addresses the issue of social recommendation based on collaborative filtering (CF) algorithms. Social re c-ommendation emphasizes utilizing various attributes info r-mation and relations in social networks to assist recom-mender systems. Although recommendation techniques have obtained distinct developments over the decades, traditio nal CF algorithms still have these following two limitations: ( 1) relational dependency within predictions, an important fa c-tor especially when the data is sparse, is not being uti-lized effectively; and (2) straightforward methods for com-bining features like linear integration suffer from high com -puting complexity in learning the weights by enumerating the whole value space, making it difficult to combine var-ious information into an unified approach. In this paper, we propose a novel model, Multi-scale Continuous Condi-tional Random Fields (MCCRF), as a framework to solve above problems for social recommendations. In MCCRF, relational dependency within predictions is modeled by the Markov property, thus predictions are generated simultane -ously and can help each other. This strategy has never been employed previously. Besides, diverse information and rel a-tions in social network can be modeled by state and edge feature functions in MCCRF, whose weights can be opti-mized globally. Thus both problems can be solved under this framework. In addition, We propose to utilize Markov chain Monte Carlo (MCMC) estimation methods to solve the difficulties in training and inference processes of MCCRF. Experimental results conducted on two real world data have demonstrated that our approach outperforms traditional CF algorithms. Additional experiments also show the improve-ments from the two factors of relational dependency and feature combination, respectively.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Algorithms, Experimentation Collaborative Filtering, Multi-scale Continuous Conditi onal Random Fields, Markov Chain Monte Carlo, Social Recom-mendation
Recommender system is to suggest relevant items (news, books, movies, images, etc.) attracting particular users, which plays an important role on the Web nowadays since it satisfies both commercial companies and users in daily lives . Traditionally, CF algorithms are used in these systems, as-signing each user-item pair a score indicating the user X  X  ra t-ing on the item, based on which a ranking list of items is generated to the user as suggestions. Classical CF meth-ods are divided into memory-based methods [4, 12, 14, 20, 30, 34] and model-based methods [7, 13, 32, 33]. Recently, social relations have been considered in many applications , and in this paper, we address the issue of social recommen-dation. Different from traditional recommender systems, in social recommendation, multiple information and various r e-lational dependencies in social networks should be utilize d to improve recommendation results. Traditional CF algo-rithms, however, suffer from the following two weaknesses. To illustrate the problem, we use an example showed in Figure 1. In this example, there are four users, denoted by u and seven items, denoted by i m . r lm is rating record by u to i m . (e.g., scale from 1 to 5, higher value means better satisfaction). The CF algorithms predict values of unrated user-item pairs, denoted as y lm (without loss of generality, not all y lm are shown in the figure), and suggest top ranked items as recommendations.
 Lack of relational dependency within predictions. In traditional methods, predictions are only relationally de-pendent on the rated records, while predictions among each other are independent. For example, in Figure 1, suppose u 3 and u 4 are similar users based on observed ratings, and then y 33 can be predicted by referring to r 43 , because it is the same item and the two users have high similarity. In the same way, suppose i 3 and i 5 are observed to have high similarity, and then y 45 can be predicted by referring to r because they are similar items by the same user. For sim-plicity, we suppose no high similarity exists between other items/users pairs, and we do not consider any other rela-tions. In this case, based on traditional CF algorithms, y cannot be predicted accurately. Because there are no rated items by u 3 which is similar to i 5 and there is no rating on i whose host is similar to u 3 . Thus no relevant information can be referred to. But if we consider relational dependency within predictions, things are different. As u 3 and u 4 are similar, y 35 and y 45 should be close; as i 3 and i 5 are simi-lar, y 35 and y 33 should be close. So if relational dependency within predictions is utilized, the information of r 43 can be passed to y 35 through relational dependency of y 33 , y 45 y 35 . In this case, predictions should be generated simultane-ously by utilizing the dependency, which let predictions he lp each other, improving the accuracy. In social recommenda-tions, the data is sparse [30], thus a number of predictions lack of information to refer to, leading to low accuracy. Ef-fectively utilizing relational dependency is indeed impor tant. Previous work, however, did not utilize such information su f-ficiently. Wang et al.[34] proposed a heuristic method to find r 43 . It has two limitations: (1) It is difficult to measure the similarity between r 43 and y 35 ; and (2) It cannot guarantee the nearness of y 35 and y 33 (or y 35 and y 45 ). Ma et al.[20] proposed to firstly predict y 33 and y 45 , and then to predict y 35 . The problem is that mistakes can propagate from top level to bottom level, which influences the accuracy.
Being difficult to integrate various features in so-cial network into an unified approach. In social rec-ommendation, various attributes information and relation s have been demonstrated to be effective features. For ex-ample, in attribute information, Melville et al.[22] utili zed content information (genres, directors, etc.) to boost CF algorithms in movie recommender systems; Nakamoto et al.[23] and Sen et al.[31] employed tag information to im-prove the accuracy. In relations information, trust relati ons are utilized effectively in some recent works [1, 3, 9, 21, 24] . These attribute and relation features should be combined to assist predictions in social recommendation. But in tradi-tional CF algorithms, it is hard to combine these features into an unified model. Melville et al.[22] has to convert trad i-tional CF to a classification problem in order to add content features, in which ratings are not predicted. Some of pre-vious work utilized linear integration techniques to smoot h feature weights [20]. Consequently, the computing complex -ity for enumerating values in all spaces to obtain a fitting weight-vector is large when the number of features increase s. Thus a framework to globally optimize the weights of mul-tiple effective features should be explored.

Continuous Conditional Random Fields (CCRF) [26] is a desirable approach by going through literatures on solving similar problems mentioned above. CCRF is a recently pro-posed new model which defines a conditional distribution on predictions of items conditioned on observations. Rela-tional dependency within predictions is modeled in feature functions. CCRF has outstanding advantages comparing to other methods: (1) relational dependency within predic-tions can be modeled by the Markov property, which is the most general assumption in probabilistic graphical models and has been proven effective in many applications [16]; and (2) feature function weights are globally optimized in CCRF model, which makes it easy to combine various of features. Thus all the two problems aforementioned can be solved based on this approach. Therefore, it is natural to lead us to employ CCRF in social recommendation problems. How-ever, single-scale of CCRF in [26] cannot be directly em-ployed to model different users in recommendations, which will be discussed in detail in Section 3. Therefore in this pa -per, we extend CCRF model from single-scale to multi-scale in theory, in which each scale corresponds to predictions of a particular user, and apply this new model in social recom-mendations as a framework to solve the two problems dis-cussed above, which to the best of our knowledge is the first attempt to employ CCRF in recommender systems. The main contributions of this paper include: 1. We formulate the problem of social recommendations 2. We propose a gradient-based optimization algorithm
The rest of this paper is organized as follows: In Section 2, we introduce the related work. In Section 3, we formu-late the problem of social recommendations and present our MCCRF framework. Algorithms are discussed in Section 4 and experimental results together with analysis are given i n Section 5. Finally, we summarize this paper in Section 6.
Traditionally, there are two categories of CF methods: memory-based and model-based. The basic idea of memory-based methods (also called neighborhood-based) is that rat -ing predictions for a user depends on other similar users X  rated values on the same item or on the current user X  X  pre-vious rated values on other similar items. So approaches are naturally divided into user-based [4, 12, 14] and item-based [5, 18, 30], together with combined approaches [20, 34]. The key point of these methods is the selection of sim-ilarity calculation. Typical examples include Pearson Cor -relation Coefficient (PCC) [27] and Vector Similarity (VS) [4]. Alternatively, model-based methods [7, 13, 32, 33] are from a probabilistic perspective, which builds a probabili stic model to calculate the expectation of a user X  X  rating on an item. A classical way is to utilize probabilistic latent cla ss [13]. In this approach, latent space exists between users and items, which can be explained as the users X  interests or styles. Different latent classes have different distributio ns on the rating of items, and different users have different distri -butions on the latent classes. Expectations are calculated as predictions. Some work also combined memory-based and model-based methods into an unified model [25, 36]. Other recent algorithms of CF include [28, 29, 37, 38], etc. The dif -ference of our method from traditional CF methods is that relational dependency within predictions is not utilized s uf-ficiently in most of previous work, but MCCRF models this information using Markov property.

In parallel with the development of CF algorithms is the exploration of effective features in recommendation. At the beginning, only rating information is utilized [4, 5, 12, 13 , 30, 33]. However, the data is usually sparse, making it difficult to obtain high accuracy in some cases. Yet some work tried to utilize more features to boost CF algorithms. As men-tioned before, the features are divided into attribute feat ures and relational features. Attribute features are descripti ons of a single item or a single user, which can be item con-tent (e.g., director, genre in movie recommendations ) [22] , tags [23, 31], etc. Relational features, on the other hand, are relationships among item or users, such as user trust in-formation [1, 9, 21, 24]. In previous work, these additional features are combined separately, because under tradition al framework of algorithms, it suffers from computing com-plexity to linearly combine large number of features. But in our approach, since the weights of features are optimized globally, we combine various features into a unified model.
Conditional Random Fields (CRF) is first proposed as a state-of-the-art probabilistic model for segment and labe ling sequences data [10, 16]. This model can describe relational dependency in undirected probabilistic graphs, solving th e label bias problem. Due to effectiveness in many applica-tions, the theory is widely developed such as Multi-scale CRF [11], Constrained CRF [15, 35], etc. A more detailed tutorial can be found in [8]. Qin et al.[26] first extended con -ditional random fields from discrete label spaces to contin-uous label spaces, and applied this CCRF model in  X  X lobal ranking X  tasks. Compared with traditional learning to rank methods relying only on local features of single objects, th is method can also model relational dependency among objects to improve ranking. In this paper, we extend this model from single-scale label space to multi-scale label space an d apply the new model in social recommendations. We also propose a MCMC-based algorithm to solve the difficulties in training and inference processes.
Let X denote observations which can be existing rat-ing records, trust information, similarities between diffe rent users/items, profile information of users, etc. Let vector Y denote predictions with y lm denoting the prediction of item i m by user u l .
 Figure 2: Probabilistic graph of single-scale CCRF
We call X  X ocal recommendation X  X r X  X raditional recommen-dation X , if the problem is formulated as Further more, we call  X  X lobal recommendation X  or  X  X ocial recommendation X , if the problem is formulated as where y  X  l,  X  m denotes all other predictions except y l,m
The major difference of these two formulations is that pre-dictions in social recommendation are dependent on each other conditioned on observations and thus predictions on different items should be generated simultaneously; while in traditional recommendation, predictions are independe nt. In other words, traditional recommendation is a special cas e of social recommendation when relational dependency withi n predictions is removed.
Single-scale CCRF is proposed by Qin et al.[26], applied in the issue of  X  X lobal ranking X . In this model, a joint con-ditional probability distribution of a probabilistic grap h is defined conditioned on observations. In this section, we ex-plain the model in the application of recommender systems. Please notice single-scale CCRF can only model predictions of a single user and we discuss how to handle multiple users in the next sub-section.

The detailed definition of single-scale CCRF is as fol-lows. Figure 2 gives the probabilistic graph. Let nodes X ( x 1 , x 2 , ..., x 5 ) denote observations and nodes Y ( y denote predictions ( y m for item i m ). The edge connecting y m and y n indicates that relational dependency exits be-tween them in the model. We define the set of nodes con-nected to y m by actual line as the  X  X eighbor X  of y m , de-noted as neighbor ( y m ). Since X denotes observations and all values of Y are conditioned on it, we use dotted line to approximately express the relational dependency among X and Y . The joint conditional probability density function of predictions Y conditioned on observations X is defined as where H ( y m , X ) is a local state feature functions vector de-fined on a local value y m , and G ( y m , y n , X ) is a relational edge feature functions vector defined on the relational de-pendent values of y m and y n .  X  and  X  are function weights vectors to be learned from the training dataset. Z sgl ( X ) is a normalization factor defined as The goal for social recommendation is to find a vector of predictions Y for this user, which can maximize the joint conditional probabilistic distribution of p ( Y | X ). The feature functions are defined in the quadratic form as: In the equations, t 1 is state feature function index ranging from 1 to T 1 and t 2 is edge feature function index ranging from 1 to T 2 . Here, x m,t 1 is observed features on item i which can be the average rating of i m ; M m,n,t 2 is a relational feature measure which can be the similarity between item i and item i n . If we use these two features as an example, it is not difficult to conclude that p ( Y | X ) will be high if predic-tions Y fit the following conditions: (1) predictions on item i m is close to the average rating of item i m ; and (2) similar items receive similar ratings predictions. Therefore, rel a-tional dependency within predictions for a particular user is described in single-scale CCRF model.
Single-scale CCRF cannot model multiple users, because there is only single value for each item, though conditioned relational dependency within predictions is modeled on dif -ferent items. In this case, all users will be treated the same , which is not reasonable. Besides, what we need to do is not only distinguishing prediction strategies of different use rs, but also modeling the relational dependency within them. In social recommendation, various relationships (trust in for-mation, similarity information, etc) among users are neede d to be modeled. Therefore, in this paper, we extend CCRF from single-scale to multi-scale to form a novel model and apply it as a framework in social recommendations to solve aforementioned limitation.

Figure 3 gives the probabilistic graph of MCCRF. In this graph, label space of Y has been extended from single-scale to multi-scale with y l,m denoting prediction on item i m user u l . Different scales of Y are drawn in different layers which denote predictions of multiple users. For example, ( y 11 , y 12 , y 13 , y 14 , y 15 ) is the rating predictions for user u tual line to denote the relational dependency of prediction s Y in the model. In MCCRF, relational dependency exists not only within predictions of the same user (layer), but also within predictions among different users (layers). For example, the prediction of y 13 , has dependent relationship neighbor ( y 13 ) (the five dependent nodes) is defined in MC-CRF.

In this model, the joint conditional probability density function is defined as where l and j denote different users; m and n denote dif-ferent items. H ( y l,m , X ) is a local state feature functions vector defined on local value y l,m ; G ( y l,m , y j,n , X ) is a re-lational edge feature functions vector defined on relationa l dependent values within the same layer; R ( y l,m , y j,m relational edge feature functions vector defined on relatio nal dependent values across different layers. {  X ,  X ,  X  } is feature function weights vectors to be learned from training data. Z mul ( X ) is the normalization factor defined as The task for social recommendations under this framework is to find the predictions Y that can maximize the joint probabilistic distributions p ( Y | X ). Feature functions are still defined in the quadratic form as: Here, x l,m,t 1 is observed features of i m or u l , which can be the average rating of u l ; M m,n,t 2 is a measure of relational feature in the same layer which can be the similarity of i and i n ; U l,j,t 3 is a measure of relational feature across differ-ent layers which can be the trust relation of u l and u j the value of U l,j,t 3 is 1 of u l trust u j and is 0 of not). Under this definition of features as an example, it is not difficult to conclude that p ( Y | X ) will be high if Y fits the follow-ing conditions: (1) predictions of a user are close to averag e rating of the user; (2) predictions on similar items for the same user are close; and (3) predictions of trusted users on the same item are close. Therefore all kinds of relational dependency within predictions have been modeled. The feature selection in our work is experiment-based. In CRF, features are divided into state features and edge fea-tures. Following are the features combined in our model. We will also show the effectiveness of each feature in exper-imental section.

State Features (The three kinds of state features are only provided in MovieLens dataset): 1. Average rating of an item within users of similar oc-2. Average rating of an item within users of similar age 3. Average rating of the same genre.

Edge Features (Trust is only contained in Epinions dataset and the other two are in both datasets): 1. Trust information among users: if one user trusts an-2. Similarity of users (please refer to [20] for definition): if 3. Similarity of items (please refer to [20] for definition):
In this section, we introduce the details of learning and inference processes of MCCRF.
Parameters learning is to obtain parameter {  X ,  X ,  X  } which can maximize the log-likelihood from training data D = ( x k , y k ) is a training data sample, the setup of which will be explained in the experimental section. In this paper, Gradi -ent Ascent is chosen as optimization method. For simple de-notation, we use vector  X  to denote feature function weights {  X ,  X ,  X  } , and use vector F ( y k , x k ) to denote the value of feature function vectors { H, G, R } given y k and x k . Then, the log-likelihood can be written in As discussed in [26], to make the integration Z calculable, we must have  X  &gt; 0. Thus it is substituted in algorithm by another variable in order to employ Gradient Ascent opti-mization method. Let  X  = e  X  0 , where e  X  0 is set by e  X  0 Thus The gradient of the objective function is
To calculate the expectation term is expensive. In this pa-per, we propose an approximate estimation method based on Markov chain Monte Carlo. Particularly, we employ Gibbs sampling technique as our method. The main idea is to first sample a sequence of variables y following the distribution of current p ( y | x ) (this distribution is defined in Eq. (1) and is decided by current  X  ). Then, the feature function values of the sequence data y are averaged as the expectation of feature function value denoted as where S is the length of the sequence.

One of the key points for Gibbs sampling is to calculate p ( y l,m | y  X  l,  X  m , X ) in sampling the sequence, where y denotes all other predictions except y l,m . In our case, Under the definition of p ( y | x ) in Eq. (1), it is not difficult to conclude that p ( y l,m | y  X  l,  X  m , X ) is a Gaussian distribu-tion, the mean and variance of which can be calculated by current y  X  l,  X  m , x and  X  . Thus the Gibbs sampling methods is feasible in this estimation case by using existing Gaus-sian distribution sampling methods (in this paper, we use DistLib 1 ) as tools. Due to space limitation, please refer to [2, 19] for more details about the theory of Gibbs sampling. The detailed learning algorithm is shown in Algorithm 1.
Inference is to search predictions that can maximize the joint probability density function conditioned on observa -tions, which is formulated as On this problem of MCCRF, exact estimation is hard to calculate, thus we still consider approximate methods. Gen -erally speaking, Gibbs sampling can be directly used to esti -mate the optimal solution, however, as discussed in [2], thi s http://statdistlib.sourceforge.net Algorithm 1 Learning Algorithm for MCCRF Input : Training data D = { ( x k , y k ) } N k =0 , U : number of updating iterations S : number of sampling iterations Algorithm : for i = 0 to N -1 do end for
Gibbs sampling initialization for i = 0 to U -1 do end for Output : Parameter  X  of MCCRF model. method is inefficient because random samples can rarely ap-proach the optimal solution unless p ( y | x ) has large proba-bility mass around the solution. Thus, in this paper, we employ Simulated Annealing. Using this strategy, the joint conditioned probability function of acceptable sampling d ata sequence can be controlled by the temperature schema as where T ( i ) is the temperature at time i . When tempera-ture falls, probability mass around the optimal solution wi ll increase, making the sampling process approach to the so-lution faster. More details about simulated annealing in MCMC are shown in [2, 6, 19].

Utilizing MCMC technique as inference method has an-other advantage: it is easy to add constraints in the infer-ence process to improve the prediction results. In social recommendations, users usually have rating history on some items, and these ratings can serve as constraints in the in-ference to assist predictions. In our proposed framework, the constraints can be added into the model by fixing the rated scores in the inference process when sampling. Refer-ring to [10, 15, 17], such process will not destroy the Markov property of the Conditional Random Fields model, and the inference result will be the best one in candidates that can fit the constraints. The detailed algorithm for inference of MCCRF is shown in Algorithm 2.
Our experiments are conducted on two real world datasets from MovieLens and Epinions. We aim at verifying the fol-lowing issues: 1. How about the overall performance of our proposed Algorithm 2 Inference Algorithm for MCCRF Input : Testing Data T : time control sequence S : number of sampling iterations  X  : function weights vector Algorithm : Load features,  X  , constraints Fix predictions of relevant user-item pairs Initialize predictions
Gibbs sampling initialization for T = T 0 to T min according to T i do end for Output : Predictions of MCCRF. 2. How does the relational dependency in predictions af-3. How do the features we combined from previous work 4. How about the computing complexity of MCCRF?
To Issue 1, we compare our approach with traditional and state-of-the-art CF algorithms in Section 5.4; to Issues 2 and 3, additional experiments are conducted to show the effectiveness of relational dependency and combination of various features in Section 5.5 and Section 5.6. We give analysis of Issue 4 in Section 5.7. Experiments setup is in-troduced in Section 5.1, Section 5.2 and Section 5.3. In the pre-processing, clustering algorithms are employed, and t he impact of cluster size is analyzed in Section 5.8. In this paper, we choose two datasets, MovieLens 2 and Epinions 3 in our experiments for social recommendation. MovieLens is a famous dataset in CF tasks. In this dataset, there are 1 , 682 movies and 943 users. Ratings are given on the scale of 1 to 5, with higher value indicating better sat-isfaction. There are totally 100 , 000 rating records in this user-item matrix. The density is For a single user, there are at least 20 ratings. Some of the statistical results are shown in Table 1. Besides rating inf or-mation, the dataset also provides other content informatio n. For a movie item, content information includes released dat e, http://www.cs.umn.edu/Research/GroupLens http://www.epinions.com/ genre, etc; and for a user, age, gender, occupation are pro-vided. In our approach, genre, occupation, age and gender are combined as content features.

Epinions dataset comes from a consumer review site Epin-ion.com. In this system, users can give reviews (scale from 1 to 5) to products, being used for future customers as refer-ence and for companies to receive feedbacks or to recommend items. Different from traditional benchmark datasets, Epin -ions dataset has social trust information among users besid es basic rating records. A user can build a trust/distrust list of other users for personalized products ranking as well as indicating users X  reputations in the whole social network. Thus it is a good dataset for social recommendation. The whole dataset contains 40 , 163 users who rated a total num-ber of 139 , 529 different items at least once, writing 664 , 824 reviews. The density is There are totally 487 , 183 trust information records in our dataset. The density of trust relationship is Other statistics are summarized in Table 2.

In both datasets, we randomly group users into four groups, with three groups as training, and the rest as testing. To observe the performances when active users have different number of ratings as history, experiments are conducted by selecting 5, 10 and 15 as rating history for each active user respectively in MovieLens and 2, 5, and 10 in Epinions. We name them Given2, Given5, Given10, and Given15.
In this section, we introduce how we build probabilistic graphs on the two datasets. A probabilistic graph repre-sents a data sample ( x k , y k ) in dataset D = ( x k , y MovieLens, since it is small in size, all users and items can be contained in one probabilistic graph. For Epinions, the size is large. For this problem in memory-based CF, Xue et al.[36] proposed a cluster-based method as a solution. By clustering users into small groups, non-similar users are r e-moved in predicting a particular user X  X  evaluations. Thus not only the scalable problem is solved, the accuracy can also be improved. In this paper, we employ similar ideas in our approach. Both users and items are clustered into sub-groups, and a probabilistic graph is built on one group of users and one group of items. Referring to [36], we employ K-means algorithm as our clustering algorithm. K is the number of clusters, which is manually defined. In this al-gorithm, we first randomly select K nodes (users/items) as centroid. All other nodes are assigned into a cluster whose centroid is closest to current node. During iteration pro-cesses, the centroid of each cluster is re-calculated based on current nodes in the cluster, and then other nodes are re-assigned to adapt the new centroid configuration. In each iteration, the node which has the smallest average distance to other nodes are selected as centroid. Similar to [36], we employ PCC to measure the distance between two nodes. For users, it is defined as Sim ( a, u ) = where a and u denote two users. I ( a ) and I ( u ) are the items they have rated. r a,i is the rating of item i by user a . r is the average rating of user a . For items, the definition is similar. Due to space limitation, please refer [20] for the details of the definition. In Section 5.8, we will give analys is on the impact of cluster size K in this task. We use Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) as our evaluation metrics. MAE is defined as where  X  R u,i is the predicted ratings of item i by user u , R is the ground truth, and N is the total number of testing predictions. RMSE is defined as In both metrics, lower value indicates higher accuracy.
To compare our approach with traditional methods, we choose two algorithms (one memory-based and one model-based) as baselines. In memory-based methods, user-based PCC [4] and item-based PCC [30] are widely used. In our baseline, following the idea in [20] which improves the ac-curacy, we linearly combine these two methods, denoted as EPCC. For model-based methods, generative models are re-spective. Specifically, Aspect Model (AM) [13] is chosen as baseline. Since our approach belongs to memory-based methods, we choose two state-of-the-art memory-based meth -ods, Similarity Fusion (Fusion) [34] and EMDP [20], for com-parison. As stated before, these methods tried to solve sim-ilar problems with our approach, but our model have more advantages for solving the error propagation problem.
Table 3 and Table 4 shows the overall performance of different methods on MovieLens and Epinions, respectively. Lower MAE and RMSE values indicate better accuracy. On both datasets, we can conclude that MCCRF outperforms traditional and state-of-the-art algorithms. We summariz e the improvements from two factors: relational dependency within predictions and combination of various features.
Figure 4: Dependency effectiveness on MovieLens
Figure 5: Dependency effectiveness on Epinions
To evaluate the effectiveness of relational dependency in predictions, we conduct experiments with only basic featur es (CRF-B) of user/item similarities. This means we use the same information comparing with previous work, and the main difference of our approach is that we add relational de-pendency in predictions. The two state-of-the-art memory-based methods, Fusion method and EMDP method, are cho-sen for comparisons. Figure 4 and Figure 5 show the exper-imental results on the two datasets.

From these two figures we can conclude that relational de-pendency within predictions can improve recommendation results. This is because predictions of user-item pairs can help each other without error propagation. As the data is very sparse in real recommendation systems, utilizing rela -tions in social network sufficiently can improve the accuracy .
To evaluate the effectiveness of various features, we con-duct experiments by adding features separately to basic fea -Figure 7: Result samples of different iteration times tures of user/item similarity. In MovieLens, we conduct experiments by adding occupation features (CRF-BO), age and gender features (CRF-BA), and genre features (CRF-BG). We compare the results with only basic features (CRF-B) and all features (CRF-All). In Epinions, we compare models with (CRF-T) and without (CRF-B) trust informa-tion. Figure 6 shows the results in the two datasets (left two: MovieLens, right two: Epinions).
 We can observe that each feature we combined (CRF-BO, CRF-BA, CRF-BG, CRF-T) can improve the prediction ac-curacy comparing to CRF-B. The combination of all features (CRF-ALL, CRF-T) can outperform models with single ad-ditional feature.
The main computation in our model lies in the sampling process in both training and inferencing. The number of sampling times is the key factor. It is determined by the number of sampling iterations at each temperature and the temperature control schema. Figure 7 shows the results of different iterations in the initialized temperature on tw o datasets (left: MovieLens; right: Epinions). We can observ e after four iterations, the change is not obvious. Figure 8 shows the results in different temperatures (left two: Movie -Lens; right two: Epinions). According to these results, we set iteration number be 4 and temperature schema from 1 . 0 to 0 . 2 with interval of 0 . 2. Suppose there are m items and n users, the sampling times is O ( m  X  n ). Another computation comes from the the updating process of Gaussian distribu-Figure 9: Results on different cluster sizes in Epin-ions (x-axis: userSize*itemSize) tions of user-item pairs. This is decided by the neighbor size of current user-item pair. The neighbor size s can be controlled by adjusting the threshold mentioned in Section 3.4. The updating times for each sample of user-item pair is O ( s ).

In our experiments, the testing hardware environment is on two Windows workstations with four dual-core 2.5GHz CPU and 8GB physical memory each. The approximate total time for inference in Epinions dataset is 9 hours.
As discussed before, we employ clustering techniques as pre-processing. We conduct experiments on different set-tings to see the impact of cluster size. Figure 9 shows the experimental results. The accuracy increases first and then falls down. This is because at the beginning, there are not enough reference resources. But as the size of a cluster en-larges, non-relevant users/items are included, which influ -ences the accuracy. In our experiments, items are clustered into 50 groups and users are clustered into 20 groups.
In this paper, we have investigated the problem of so-cial recommendation based on CF. Different from traditional recommender systems, various information should be consid -ered in social recommendations. According to limitations o f traditional CF algorithms, we extend single-scale CCRF in theory and propose a new model MCCRF as a framework for social recommendation. We also propose MCMC-based methods for training and inference of the model. Experi-mental results on real world datasets, MovieLens and Epin-ions, have demonstrated: (1) Markov property in MCCRF is an effective technique to model the relational dependency within predictions. In sparse data, utilizing this kind of dependency can improve recommendation results. (2) Com-bination of various features into the model can enhance the ability of prediction, which is also the original intention of social recommendations.
The work described in this paper is supported by grants from the Research Grant Council of the Hong Kong Spe-cial Administrative Region, China (Project No.: CUHK 4128/08E and CUHK 4158/08E). This work is also affiliated with the Microsoft-CUHK Joint Laboratory for Human-centri c Computing and Interface Technologies. [1] R. Andersen, C. Borgs, J. Chayes, U. Feige, [2] C. Andrieu, N. De Freitas, A. Doucet, and M. Jordan. [3] P. Bedi, H. Kaur, and S. Marwaha. Trust based
