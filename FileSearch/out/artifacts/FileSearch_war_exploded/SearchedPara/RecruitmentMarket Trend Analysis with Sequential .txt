 Recruitment market analysis provides valuable understand-ing of industry-speci c economic growth and plays an im-portant role for both employers and job seekers. With the rapid development of online recruitment services, massive recruitment data have been accumulated and enable a new paradigm for recruitment market analysis. However, tradi-tional methods for recruitment market analysis largely rely on the knowledge of domain experts and classic statistical models, which are usually too general to model large-scale dynamic recruitment data, and have difficulties to capture the ne-grained market trends. To this end, in this paper, we propose a new research paradigm for recruitment market analysis by leveraging unsupervised learning techniques for automatically discovering recruitment market trends based on large-scale recruitment data. Speci cally, we develop a novel sequential latent variable model, named MTLVM, which is designed for capturing the sequential dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian gen-erative framework. In particular, to capture the variabil-ity of recruitment topics over time, we design hierarchical dirichlet processes for MTLVM. These processes allow to dynamically generate the evolving recruitment topics. Fi-nally, we implement a prototype system to empirically eval-uate our approach based on real-world recruitment data in China. Indeed, by visualizing the results from MTLVM, we can successfully reveal many interesting ndings, such as the popularity of LBS related jobs reached the peak in the 2nd half of 2014, and decreased in 2015.
 Trend Analysis, Recruitment Market, Latent Variable Model
The scarcity of skilled talents has stimulated the global recruitment industry in the past few years. An article from Corre sponding Author.
 Forbes reported that, US corporations spend nearly $ 72 billion each year on a variety of recruiting services, and the worldwide number is likely three times bigger [4]. Along this line, a growing challenge is to provide an effective trend analysis of recruitment market, such as forecasting recruit-ment demand and predicting market status. Both employers and job seekers can bene t from the study of recruitment market trends. Moreover, at the macro level, this analysis can also provide valuable understanding of industry-speci c economic growth for business analysts.

With the rapid development of online recruitment ser-vices, such as Linkedin [7], Dice [3], and Lagou [6], mas-sive recruitment posting data have been accumulated. For example, as of the end of 2015, there are more than 1.3 million job positions from 100K+ companies across more than 20 Internet-related industries, such as mobile Internet, online-to-offline (O2O), and cloud computing, available at Lagou [6]-a Chinese tech hiring service website. These huge data enable a new paradigm for studying recruitment mar-ket trends in a holistic and ne-grained manner.
Recruitment market analysis is a classic topic in human capital economics, where recruitment market is either treated as a factor of macro economic phenomenons or the analysis is focused on advising people to make the best job decisions in a general economic framework [26, 27, 29]. However, previ-ous studies rely largely on the knowledge of domain experts and classic statistical models, and thus usually too general to capture the high variability of recruitment market (e.g., the evolution of recruitment topics). Also, these studies have limited efforts on understanding the ne-grained mar-ket trends, such as forecasting the recruitment situation for a speci c company in the next few months. Therefore, it is very appealing to design a new research paradigm for recruit-ment market analysis through large-scale analysis on mas-sive recruitment data. Along this line, there are some major challenges. First, how to model the intrinsically sequential dependency of recruitment states (e.g., Hiring Freeze) form-ing the market trend? Second, how to model the semantic relationship between the market trend and job postings from different companies? Finally, how to model the variability of recruitment postings for a long time period?
To tackle these challenges, we propose an unsupervised learning approach for recruitment market trend analysis, which can automatically discern the underlying trend of recruitment market. First, we develop a novel sequential market trend latent variable model (MTLVM), which is de-signed for capturing the temporal dependencies of recruit-ment states of companies and is able to automatically learn Fi gure 1: The trend of the number of job postings related to different skill requirements over two years, which indicates the demands of recruitment market. the latent recruitment topics and demands from recruitment data within a Bayesian generative framework. To be more speci c, we assume that the current recruitment state of a speci c company is in uenced by its state in previous epoch, and it will impel the company to review appropriate recruit-ment demands (e.g., R&amp;D recruitment). Then, different re-cruitment demands will generate different recruitment top-ics (e.g., experienced algorithm engineer), which will nally generate the recruitment postings. In particular, to capture the variability of recruitment topics over time, we design a hierarchical dirichlet processes for MTLVM, which can dy-namically generate recruitment topics. Finally, we imple-ment an intelligent prototype system to empirically evalu-ate our approach based on a real-world recruitment data set collected from China for the time period from 2014 to 2015. Indeed, by visualizing the results from MTLVM, we can successfully observe many interesting discoveries, such as the popularity of LBS related jobs reaches the peak in the 2nd half of 2014, and decreases in 2015 . Generally, the con-tributions of this paper can be summarized as follows.
In this section, we rst introduce some preliminaries of recruitment market modeling, and then formally present the overview of our model MTLVM.
Recent years have witnessed the rapid development of on-line recruitment services, which have already become the Figure 2: The word cloud representation of job post-ings related to \Mobile Software Engineer" with re-spect to different epochs in our data set, where the size of each keyword is proportional to its frequency. most important venue of talent seeking, especially for high-tech companies. Therefore, the job posting data from these services can help researchers better understand the trend of recruitment market from the perspectives of not only an individual company but also the whole industry.

Intuitively, different job postings can indicate different re-cruitment demands of companies, such as R&amp;D related positions, which usually change over different epochs. For example, Figure 1 demonstrates the trend of the number of job postings related to different skill requirements dur-ing January 2014 to November 2015 based on our real-world data set. We can observe that skill \Information Retrieval" becomes less popular, compared with other skills, such as \Data Mining", and\Machine Learning". Meanwhile,\Spark", an emerging technique for big data processing, has attracted more and more attention during these years. Indeed, such evolution of recruitment demands is inherently determined by the change of latent recruitment states of companies at different epochs, which have strong sequential dependency. For example, Alibaba, one of the largest E-Commerce com-panies in China, hugely enlarged the recruitment in 2014, which is followed by the recruitment state \Hiring Freeze" in 2015. As a result, its recruitment demands related to E-Commerce largely shrank in 2015. To capture the change of recruitment states, and model the semantic relationship between recruitment demand and state, our model MTLVM follows the Beysian latent variable model with rst-order Markov assumption, where current state is only determined by the state at previous epoch.

Indeed, by further analyzing the descriptions of job post-ings, we observe that the detail of similar recruitment de-mands (e.g., Recruiting Mobile Software Engineer) will be in uenced by the corresponding recruitment states. Thus the corresponding demands usually have high variability, and generate different recruitment topics . For example, Figure 2 shows the word cloud representation 1 of job post-ings related to \Mobile Software Engineer" with respect to
A ll the words are originally in Chinese, and are automati-cally translated by a commercial translation tool [1]. Fi gure 3: The graphical representation of MTLVM. different epochs. We can observe that, \Mobile Game De-velopment" is a hot topic in the second half of 2014, while \Android based Web Technology" becomes popular in the rst half 2015. To model the semantic relationships among recruitment states, recruitment demands, and recruitment topics, our model, MTLVM, follows the idea of Hierarchical Dirichlet Processes, an in nity version of topic modeling, to model the job postings. Therefore the topic number can be automatically determined.
Formally, we regard the m -th job posting of company e at epoch t as a bag of words e;t;m = f e;t;m;n g n , where e;t;m;n is the basic observation in job postings (e.g., key-words in job description), and j e;t;m j = N e;t;m . For model-ing the trend of recruitment market, we rst divide all job postings into different data units f e;t g e;t with respect to companies and timestamps, which contain job postings of company e at epoch t .

As introduced above, we assume that the current recruit-ment state of a speci c company is in uenced by its state in previous epoch, and it will impel the company to review appropriate recruitment demands. Then, different recruit-ment demands will generate different recruitment topics, which will nally generate the recruitment postings. There-fore, we de ne a parameter c e;t to represent the recruit-ment state of company e at epoch t , where the number of unique recruitment states is C . Speci cally, at the rst epoch, the corresponding c e; 1 for all companies is sampled from a uniform distribution. For the following epochs, if company e releases some job postings at previous epoch t 1, namely that e;t 1 exists, its current recruitment state c e;t is sampled from a multinomial distribution deter-mined by previous state c e;t 1 . Otherwise, c e;t is drawn from the overall recruitment state at epoch t 1, i.e., P ( c e;t  X  average P ( c e  X  ;t 1 ) of company e  X  who has market state c at epoch t 1. In addition, we name the chains consisting of neighbouring e;t 1 that belong to the same company as a data chain. Therefore, if a company only occasionally re-leases jobs, it may have more than one data chain according to our formulation.

Furthermore, we de ne the generative process of job post-ing e;t;m 2 e;t of company e at epoch t as follows. First, a recruitment demand D e;t;m is generated from the latent fac-tor G c which is sampled from a Dirichlet Process and deter-mined by the current recruitment state c e;t . Then, we sam-ple a recruitment topic  X  e;t;m;n from the demand D e;t;m each observation e;t;m;n . Finally, each observation e;t;m;n is generated from a multinomial distribution determined by corresponding topic  X  e;t;m;n . Speci cally, Figure 3 shows the graphical representation of MTLVM.
In this section, we will introduce the technical details of our model MTLVM. And we illustrate the important math-ematical notations in Table 1.
According to the introduction in Section 2, we can sum-marize the parameterizations of MTLVM as follows,
Following the above parameterizations, we can get the joint probability distribution of and c as where is a set of hyper-parameters, including , H , 0 , , 2 , and c 0 . Speci cally, c 0 is a default initial recruitment state and c 0 is xed to (1 =C;:::; 1 =C ). Indeed, the above equation can be divided into two parts, i.e., P ( c e;t j that follows a multinomial distribution Multi( c e;t 1 ), and P ( e;t j ;c e;t ) that follows Dirichlet Processes, respectively. Speci cally, P ( e;t j ;c e;t ) can be computed by Therefore, the objective of learning MTLVM is to nd a set of optimal parameters in P ( c e;t j c e;t 1 ; ), P ( D e;t;m imize the probability of Equation 1. In this paper, we pro-pose a two-step framework to learn our model by a Gibbs Sampling method.

In the rst step, we introduce how to optimize the transi-tion matrix , which is constituted of P ( c e;t j c e;t 1 P ( e;t j ;c e;t ). Depending on equation 1, we could get the conditional distribution of c e;t Since P ( e;t j c e;t = c; ) is given, the only challenge is to calculate P ( c e;t = c j c e;t ; ). Here we follow the inference in [16] and give it directly.
 where q e;t ( c ) means the number of recruitment states c ap-pearing except c e;t , and q e;t ( c c e;t 1 ;c appearing except c e;t .

In the second step, we introduce how to compute the pa-rameters related to Dirichlet Process in Equation 2. Indeed, this task can be regarded as an analog of the Chinese Restau-rant Process (CRP) [8], and the metaphor can be explained as follows. We have C cuisine styles (i.e., recruitment state) and a franchise (i.e., company) with M e;t restaurants (i.e., job postings). Everyday, the franchise will change its cuisine style according to the cuisine styles on last day. In Particu-lar, the menus of different restaurants may be different, even if they share the same cuisine style. At each table of each restaurant, the dish (i.e., topic) is determined by the rst customer (i.e., the basic observation in job postings) sitting there, and it is shared among all customers who sit at that table. When a new customer enters the restaurant, she can Fi gure 4: A screenshot of our system for recruitment market analysis. sit at an occupied table or a new table. If she chooses a new table, she can order a new dish from the menu. According to the above metaphor of CRP, we can easily obtained a Gibbs sampling scheme for posterior sampling given [28]. The detailed de nition and inference can be found in Appendix.
After learning stage, MTLVM can be used for predicting the future trend of recruitment market, e.g., recruitment states, demands, topics, and basic observations. Speci cally, given a company e , we can estimate its current recruitment state c e;t by where is the transition matrix, and Therefore, the probability of recruitment state at the next epoch c e;t +1 can be obtained by P ( c e;t +1 ) = Multi( Furthermore, the recruitment topics can be obtained in the same way introduced in Section 3.1. Thus, the probability of a basic observation e;t +1 ;k (e.g., keywords in job de-scription) from company e appearing at epoch t + 1 can be computed by where P ( e;t +1 ;k j c e;t +1 ) can be obtained by Equation 2. In this section, we will study the performance of our model MTLVM on a huge data set collected from a major online recruitment website in China.

Furthermore, we have developed a web-based prototype system to empirically evaluate our model. This system can visualize the results of our model, provide in-depth analysis of recruitment market analysis, and help people understand the high variability of recruitment market. Figure 4 shows a screenshot of this prototype system. In this system, we sh ow the trend analysis of the entire recruitment market and the detail evolution of recruitment state of companies. All of following visualization results in this section can be obtained by this prototype system.
 Table 2: The statistics of our real-world data set.
The data set used in our experiments is collected from a major online recruitment website in China and contains 934,761 job postings from 68,302 companies released from January 2014 to November 2015. Specially, Figure 5(a) to 5(d) demonstrate some statistics of our data set. As men-tioned above, \data unit" in Figure 5(c) means a job posting set e;t released by company e at epoch t and \data chain" means chains consisting of neighbouring e;t 1 that belong to the same company. From these statistics we can observe that most of companies only randomly release very few job postings, and therefore cannot represent the trend of recruit-ment market. To avoid such bias, we only conserve compa-nies which have released more than 100 job postings. Table 2 shows the detailed statistics of our raw data set and the l-tered data set. By the above pre-process, we ltered about 72% original data; and the number of companies declined by 98.6%. However, the average number of job postings per company increases from 13.7 to 258, and the average length of chain also increases from 1.65 to 5.16, which make it more reasonable for training MTLVM.

In particular, in each job posting, the keywords in job description (e.g., job responsibility, skill requirements) are treated as basic observations, and all stop words are re-moved to guarantee the modeling performance. Note that, our model is trained with original Chinese words, and all experimental results were translated into English by a com-mercial translation tool [1] for facilitating demonstration.
In the following subsections, we will comprehensively study the performance of MTLVM in term of trend analysis (e.g., learning recruitment states and recruitment topics). Spe-cially, following [28], we set a symmetric Dirichlet distribu-tion with parameters of 0.5 for the prior H over topic distri-butions. For simplicity, 0 , 1 , and 2 are set to 1 directly, and another hyperparameter is also be set to 1 empirically.
How to quantitatively evaluate the performance of latent variable models is always an open problem. Although per-plexity and held-out likelihood are common measures for evaluating prediction results, they cannot demonstrate how coherent and meaningful the latent factors (e.g., recruitment states and topics) are.

Therefore, in this paper, we follow the measures intro-duced in [31], which is inspired by [30, 13], for evaluating MTLVM. Speci cally, we picked up top 10 keywords for each learned recruitment topic and asked 4 senior experts of hu-man resource to evaluate its value. These experts are rst Fi gure 6: The trend of popularity of recruitment states discovered by our model over time. required to judge whether this topic is valuable . If a topic is valuable , they need continue to judge how many words are relevant in the top 10 keyword list. Based on these manu-ally labeled results, the metrics Validity Measure (VM) and Coherence Measure (CM) are de ned as V M = # of valid topics
Besides, to evaluate how the number of recruitment states affects the performance, we train MTLVM with different set-tings of state number, i.e., C = 5 ; 10 ; 20 respectively. Fur-thermore, we select widely used topic model Latent Dirichlet Allocation (LDA) [12] as baseline. After convergence, the numbers of topic in all our models, i.e., K , are automati-cally determined as about 100. Therefore, we set K as 100 for LDA.

Table 3 shows the average results of VM and CM. We can observe that in terms of VM, both of MTLVM (C=20) and MTLVM (C=10) outperform LDA a lot, and MTLVM (C=20) has the best performance. In terms of CM, the performance of MTLVM (C=10) is the best, while that of MTLVM (C=20) is worse than LDA. It may be because that too many states will make the model relatively sparse, and thus will make relevant words scattered in different topics. In particular, the performance of MTLVM (C=5) is the worst, which may be because that few states cannot accurately describe the market trend well. Overall, since MTLVM (C=10) has the most balanced results, we set state number C = 10 in all of following experiments.
Here, we will empirically evaluate the learned recruitment states from several aspects.

Figure 6 shows the trend of popularity of recruitment states discovered by MTLVM over time. It is obvious that these states change over time dramatically. Speci cally, state #3 keeps a relative high popularity over the long pe-riod, while popularity of #6 is always low. Meanwhile, the popularity of state #9 is rising dramatically since February length.
 Fi gure 7: The transition matrix of recruitment states, where the i;j element means the transition probability from i -th state to j -th state, and deeper color means higher probability. 2015. Several other states, such as state #2, #7, and #10, represent totally opposite trends. Furthermore, Figure 7 shows the transition matrix of recruitment states, where the element of i -th row and j -th column represents the tran-sition probability from state i to state j . We can observe that, all states have the highest transition probabilities to themselves, which is due to the momentum of recruitment market. Also, the color of 3-th, and 9-th columns is rela-tively deeper, which indicates the importance of states #3, and #9. All of above results show that our model MTLVM has the ability to capture the high variability of recruitment market by discovering these latent recruitment states.
Here, we will test whether the recruitment states discov-ered by our model are comprehensible. To solve this prob-lem, we select 4 representative recruitment states according to above analysis and show their top 4 topics in gure 8 by word cloud representations, where the larger words have higher generative probabilities. Meanwhile, Table 4 shows the corresponding generative probabilities of these topics.
We can nd that the topic about \programming" always has very high probability in every state. In particular, the top #1 topics in state #1, state #3, and state #9 are the same. That means the demands for R&amp;D related posi-tions are always exuberant, since the high-probability words, \linux" and \mysql", directly indicate the fundamental skill requirements of R&amp;D. Actually, the salary of software en-gineer has kept rising for a long time, which can support this discovery of our model. These states also show that the work about games and front-end are also very popular, which is consistent with our real-world observations. Next, we further inspect states illustrated in gure 8. Table 4: The probabilities of top recruitment top-ics of selected recruitment states (e.g., #1, #3, #4, #9). The corresponding word cloud representations of these topics are shown in gure 8. of these recruitment topics are shown in table 4.
Here, we evaluate our model by checking the trend of sev-eral representative companies from a few important elds, such as Baidu is a famous high-tech company and Alibaba is the largest E-Commerce company in China. We visualize the evolution of the recruitment states of these companies in gure 9.

From gure 9, we can rst observe that state #3 is a very common state among most of companies. It is consistent with the analysis from topics of this state. Besides, we nd that state #4, which is relevant to LBS, appears relatively frequently among Baidu, Sogou, and Tencent in 2014. Ac-tually, all of these companies provide map service in China, especially Baidu. Baidu Map is the most popular naviga-tion tool in China and many O2O companies use LBS API provided by Baidu to improve their services. So Baidu has remarkable strengths in LBS and has paid much attention to it indeed. Furthermore, Tencent, as one of the largest IT companies in China, its business is very scattered and covers many elds, such as game, social network, media, and enter-tainment. This kind of business strategy is directly re ected in Figure 9, where the recruitment state of Tencent changes frequently. Meanwhile, Baidu, Alibaba and Sogou (another search engine) prefer state #9, which is relevant to big data (e.g., large-scale machine learning and data mining), in 2015. Considering that their core business (search engine and E-commerce) has several data-related practical applications (advertising and recommender system), the preference is also reasonable. In addition, we happened to nd an in-teresting company, Zuora, whose state is almost state #9. Actually, Zuora is an enterprise software company that aim to automate billing, commerce, and nance operations with a subscription business model. Such business model is nat-urally related to big data processing and thus has need for senior data-related talents.

Furthermore, we can observe that state #5, which is re-lated to O2O, appears in company Tuniu, Qunar, and Feiniu frequently. Indeed, all of these companies aim to connect offline merchants and online customers, which is high con-sistent with O2O. Both of Tuniu and Qunar aim to provide one-stop travel booking service, such as hotel, ticket, car rental, and so on. And Feiniu is a B2C E-commerce wesite which is invested by a large retail corporation. The goal of it s establishment is to fuse traditional offline service channel with online sale channel.
Here, we will evaluate the proposed model by predicting basic observations in future.

As introduced in Section 3, we make prediction by calcu-lating the probability of basic observations with equation 7. So in this experiment, we will compare the likelihood of over-all observations in test set to prove the performance of our model. The test set is built up by the following approach. We extract the recruitment postings in November 2015, the companies of which had also released some jobs in October 2015. It means all of companies in test set have recruitment states in the previous time span. In the end, the test set contains 350 companies and 4002 recruitment postings. Be-sides, all of recruitment postings between January 2014 and October 2015 are treated as train data.
 We select two model as baselines. One is dynamic Topic Model (DTM) [11]. DTM is a classic topic model for analyz-ing evolution of topics. It assumes topics evolve smoothly with respect to time and thus chains topics in adjacent epochs by state space models. Its performance was proved by predicting the next year of Science given all the articles from the previous years in [11]. It is obvious that DTM can-not be used for prediction directly, but due to its assump-tion, the topics extracted by it can model future data better than static topic models in some cases. In this experiment, we follow this method to prove the assumption of DTM is not very solid in our problem and indicate the necessity of our model. The code of DTM was got from [2]. The number of topics is set to 100 and all of other parameters are set to default values.

In addition, we developed a simple sequence approach, called Byesian multivariate Hidden Markov Model (B-mHMM), as the other baseline. Compared with MTLVM, this baseline associates states with words directly. The joint probability distribution of B-mHMM is as follows where the rst term is the same to equation 1. And as shown in second term, we assume that given the recruitment state, all of observations e;t;m;n are conditionally independent in B-mHMM and P ( e;t;m;n j c e;t ; ) = Multi ( c e;t ). By this baseline, we aim to prove the latent hierarchical structure of our model are meaningful for modeling recruitment markets. Because of the similarity of B-mHMM and MTLVM, The details and inference of B-mHMM follow those of MTLVM and are omitted here.

Table 5 shows the log likelihood of prediction with respect to different models. The larger number means better perfor-mance. Both of B-mHMM and MTLVM outperform DTM largely. It indicates it is reasonable to employ latent recruit-ment states to model the trend of recruitment markets. And the performance of MTLVM is also better than that of B-mHMM. All of these clearly validate the effectiveness of the proposed model.
Generally, the related works of this paper can be grouped into two categories, namely recruitment market analysis, and sequential latent variable model.
 Table 5: The prediction performance of MTLVM and baseline methods in terms of log likelihood.
Traditionally, recruitment market analysis can be regarded as a classic topic in human capital economics, which attracts generations of researchers to contribute ever since Adam Smith. From the Macro perspective, labor is always a crucial element in studying gross economy growth, money market, exchange market and the equilibrium [26], ever since Solow proposed his growth model. Therefore, economists usually study topics about, for example, the demographic structure and participation rate of labor, the relation between in ation and unemployment rate, and how labor contributes in gross productivity or expenditures, etc [27]. In another Micro per-spective, which is more relevant to our paper, all studies are set off from a basic market cleaning framework [29], where all employees choose their best balance between leisure and work, while all employers hire with budget constrain, and consequently the wage is derived as the marginal labor cost. Later researches improve our understandings by releasing constraints [19] (e.g., acknowledging the market with seg-mentations/barriers and as non-cleaning), or by detailed in-vestigations (e.g., forming better utility functions of employ-ees, and studying the actions of employees with game the-ory). Recently, several researchers in computer science try to employ data mining technology to solve these problems, such as offer categorization [24], job skill analysis [22].
However, previous research in economics efforts relies largely on the knowledge of domain experts or classic statistical models, and thus are usually too general to capture the high variability of recruitment market, and neglect the ne-grained market trend. On the other hand, the recent re-search in computer science still focuses on those traditional human resource problems. Therefore, in this paper we pro-pose a new research paradigm for recruitment market anal-ysis by leveraging unsupervised learning approach.
Indeed, our novel sequential latent variable model MTLVM can be regarded as a combination of both Hidden Markov Model (HMM) and Hierarchical Dirichlet Processes (HDP) within a Bayesian generative framework, which can intrin-sically capture the sequential dependency and variability of latent variable (e.g., recruitment states and topics).
Specially, HMM based sequential latent variable models have been successfully applied to problems in a variety of elds, such as signal processing and speech recognition [25, 21], biometrics [15], genetics [14, 23], economics [18], and mobile Internet mining [20, 9, 33]. For much of their history, HMMs have been implemented by using recursive algorithms developed for parameter estimation [10], which are viewed as\black boxes"by many statisticians. In recent years, some researchers proposed to use Bayesian methods to simulate HMM parameters from the posterior distribution, which can representing different states. provide more scalable and stable process of parameter esti-mation for HMM [16, 17]. Compared with the traditional maximum-likelihood estimation (MLE) based HMM learn-ing solution, the Bayesian methods can directly maximize the probability of the hidden variables given the observed data by integrating over all possible parameter values rather than searching for an optimal set of parameter values. To this end, the model proposed in this paper also follows a Bayesian generative framework.

Latent Dirichlet Allocation (LDA) [12] based latent vari-able models, have become one of the most powerful tools for mining textual data. However, most topic models [11, 31, 32] need a prede ned parameter to indicate the number of topics, and thus fail to capture the variability of topics. To this end, the Hierarchical Dirichlet Processes (HDP) [28] is proposed as an in nity version of topic model, which can automatically learn the number of topics. Therefore, in this paper we propose to ingrate HDP into our MTLVM for cap-turing the variability of latent recruitment topics.
In this paper, we provided a large-scale data driven analy-sis of recruitment market trends. Speci cally, we developed a novel sequential latent variable model, named MTLVM, which is designed for capturing the temporal dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian gen-erative framework. Moreover, to capture the variability of recruitment topics over time, we designed hierarchical dirich-let processes for MTLVM. These processes allow to dynam-ically generate recruitment topics. Finally, we implemented a prototype system to empirically evaluate our approach based on large-scale real-world recruitment data. The re-sults showed that our approach could effectively discover recruitment market trends and provide guidances for both job recruiters and job seekers. Here, we will describe an analog of Chinese Restaurant Process (CRP) for P ( e;t j ;c e;t ) and corresponding infer-ence in detail. Speci cally, we rst de ne f e;t;m;z g z as vari-ables sampled from G c e;t for each job posting and j e;t;m Z is the index of e;t;m;z for  X  e;t;m;n . In other words, we have  X  number of f  X  e;t;m;n g n linked with e;t;m;z . According to CRP, we can integrate out the D e;t;m and get the condi-tional distribution of  X  e;t;m;n as follows. where is a probability measure concentrated at .
If a new is sampled, it indicates the second term on the right-hand side of equation 9 is chosen. Then we need to add Z e;t;m by 1, sample a new by equation 10, and allocate  X  e;t;m;n to it. If the sampled value is an existed  X  , we just need allocate  X  e;t;m;n to it.

Second, we de ne f c;s g s as variables sampled from G 0 for each recruitment state and j c j = S c . Each e;t;m;z the number of f e;t;m;z g e;t;m , which is linked with c;s c e;t = c . Similarly, we can integrate out G c and get the conditional distribution of e;t;m;z as follows. The sampling process is similar to  X  .
 Third, we let f k g k denote the variables sampled from H and j j is K . Each c;s is linked with a k and k c;s is the index of k for c;s , i.e., c;s = k c;s . And we also let o k denote the number of f c;s g c;s . Now we can write the conditional distribution of c;s directly as
Next, we will describe a Gibbs sampling method yielded from above. Speci cally, we follow the inference method in [28] and sample z , s , k and , rather than dealing with  X  , and directly.

Sampling z , s , and k . Relying on equation 9, we can easily compute the conditional distribution of z e;t;m;n by given all of other variables. And the prior probability that z is i e;t;m;z . Its prior probability for a new is proportional to 2 . The process of sampling s and k is similar to that of sampling z .

Sampling . Given z , s , and k , f k g k are mutually inde-pendent. So the conditional distribution for each k is only related with all of that linked with it. It follows where h ( k ) is the density of measure H at parameter k . [1] Baidu translation. http://fanyi.baidu.com/. [2] Code of dynamic topic model. [3] Dice. http://www.dice.com/. [4] Forbes article. http://suo.im/gxxz0. [5] Internet plus. [6] Lagou. http://www.lagou.com/. [7] Linkedin. http://www.linkedin.com/. [8] D. J. Aldous. Exchangeability and related topics . [9] T. Bao, H. Cao, E. Chen, J. Tian, and H. Xiong. An [10] L. E. Baum, T. Petrie, G. Soules, and N. Weiss. A [11] D. M. Blei and J. D. Lafferty. Dynamic topic models. [12] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [13] J. Chang, S. Gerrish, C. Wang, J. L. Boyd-Graber, [14] G. A. Churchill. Stochastic models for heterogeneous [15] D. R. Fredkin and J. A. Rice. Bayesian restoration of [16] S. Goldwater and T. Griffiths. A fully bayesian [17] S. Guha, L. Yi, and D. Neuberg. Bayesian hidden [18] J. D. Hamilton. A new approach to the economic [19] T. Hayashi and T. Sakai. Nash implementation of [20] B. Huai, E. Chen, H. Zhu, H. Xiong, T. Bao, Q. Liu, [21] B.-H. Juang and L. R. Rabiner. Hidden markov [22] C. Litecky, A. J. Igou, and A. Aken. Skills in the [23] J. S. Liu, A. F. Neuwald, and C. E. Lawrence. [24] E. Malherbe, M. Cataldi, and A. Ballatore. Bringing [25] L. R. Rabiner. A tutorial on hidden markov models [26] D. Romer and C. Chow. Advanced Macroeconomic [27] C. Shapiro and J. E. Stiglitz. Equilibrium [28] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. [29] H. R. Varian and J. Repcheck. Intermediate [30] P. Xie and E. P. Xing. Integrating document [31] H. Zhang, G. Kim, and E. P. Xing. Dynamic topic [32] C. Zhu, H. Zhu, Y. Ge, E. Chen, Q. Liu, T. Xu, and [33] H. Zhu, C. Liu, Y. Ge, H. Xiong, and E. Chen.
