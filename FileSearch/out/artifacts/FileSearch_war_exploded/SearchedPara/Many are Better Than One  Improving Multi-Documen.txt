 Given a collection of documents, various multi-document summarization methods have been proposed to generate a short summary. However, few studies have been reported on aggregating different summarization methods to possi-bly generate better summarization results. We propose a weighted consensus summarization method to combine the results from single summarization systems. Experimental results on DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization sys-tems, and our proposed weighted consensus summarization method outperforms other combination methods.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval.
 General Terms: Algorithms, Experimentation.
 Keywords: Weighted consensus, summarization.
Various multi-document summarization methods base on different strategies and usually produce diverse outputs. A natural question arises: can we perform ensemble or con-sensus summarization by combining different summarization methods to improve summarization performance? In gen-eral, the terms of  X  X onsensus methods X  or  X  X nsemble meth-ods X  are commonly reserved for the aggregation of a number of different (input) systems. Previous research has shown that ensemble methods, by combining multiple input sys-tems, are a popular way to overcome instability and increase performance in many machine learning tasks, such as clas-sification, clustering and ranking. The success of ensemble methods in other learning tasks provides the main motiva-tion for applying ensemble methods in summarization. To the best of our knowledge, so far there are only limited at-tempts on using ensemble methods in multi-document sum-marization.

As a good ensemble requires the diversity of the individual members, here we study several widely used multi-document summarization systems based on a variety of strategies, and evaluate different baseline combination methods for obtain-ing a consensus summarizer t o improve the summarization performance. Motivated from [5], we also propose a novel weighted consensus scheme to aggregate the results from Note that For fixing r  X  , the optimization problem becomes
This is a quadratic function optimization problem with linear constraints with K variables. This is a problem of just about tens of variables (i.e., weights for each input sum-marization system) and thus can be computed quickly. It can also be solved by simply projecting vector  X   X  1 2  X  d onto (
K  X  1)-simplex. With step 1 and 2, we iteratively update w and r  X  until convergence. Then we sort r  X  in ascending order to get the consensus ranking.
In the experiments, we use four typical multi-document summarization methods as indi vidual summarizers and com-pare our WCS method with other eight aggregation meth-ods. The four individual summarization methods are: (a) Centroid [7], (b) LexPageRank [1], (c) LSA [2], and (d) NMF [4]. And the baseline aggregation methods are: (1) average score (Ave Score), which normalizes and averages the raw scores from different summarization systems; (2) average rank (Ave Rank), which averages individual rank-ings; (3) median aggregation (Med Rank); (4) Round Robin (RR); (5) Borda Count (BC); (6) correlation-based weight-ing (CW), which weights individual systems by their average Kendall X  X  Tau correlation between the ranking list they gen-erated and all the other lists; (7) ULTRA [3], which aims to find a consensus ranking with the minimum average Spear-man X  X  distance [8] to all the individual ranking lists; (8) graph-based combination (Graph), the basic idea of which is similar to the work proposed in [9], however, we use co-sine similarity so that we can compare this method with other combination methods fairly. We conduct experiments on DUC benchmark data for generic multi-document sum-marization and use ROUGE [6] toolkit (version 1.5.5) to measure the summarization performance.
Table 1 show Rouge-1, Rouge-2, and Rouge-SU scores of different individual and combination methods using DUC2004 data sets (intuitively, the higher the scores, the better the performance). From the resu lts, we observe that (1) Most of the combination summarization systems outperform all the individual systems except the round robin combination. The results demonstrate that in general consensus methods can improve the summarization performance. (2) Weighted combinations (e.g., CW, ULTRA, and WCS) outperform average combination methods which treat each individual system equally. (3) Our WCS method outperforms other weighted combination methods because WCS optimizes the weighted distance between the consensus sentence ranking to individual rankings and updates the weights and con-sensus ranking iteratively, which is closer to the nature of consensus summarization than other approximation based weighted methods.

