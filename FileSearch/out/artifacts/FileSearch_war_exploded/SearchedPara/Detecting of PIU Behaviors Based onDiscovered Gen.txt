 Since Internet has widely spread over the world, using computer to surfing Inter-net has been a basic part of our daily life. It is reported that the global consumer PC penetration per capita was 6 percent in 2006 and this number will reach 17 percent until 2015 [1]. Unfortunately, some heavy users suffer from extreme de-pendency on Internet, which affects their work, study and living severely. This phenomenon is named as Internet Addiction Disorder (IAD) by Goldberg early in 1996 [2] or Pathologica Internet Use (PIU) by Young [3]. With the popularity of Social Network Service in recent yea rs, PIU or IAD phenomenon become more serious due to the exploration of Internet users in exponential scale. Here, only taking social game as an example, in August 2010, 21 percent of female users of social games on America X  X  Facebook c laimed to be addicted whereas on 21 percent of male users asserted this [1]. Therefore, it is significant to detect PC user X  X  PIU Behaviors (PIU-B) from their daily computer-med iated interaction events to prevent them from addition.

In previous researches, a common approach to diagnosing PIU or IAD is based on diagnostic questionnaire made by medical or psychology specialists such as Young X  X  20 items questionnaire [4] and Beard X  X  5 criteria [5]. However, to our best knowledge, no existing work discusses how to diagnose PIU according to computer-mediated interaction information. In this light, by referring to the con-cepts of generator [6] and equivalence class [7] and the mining idea of discovering generators together with EPs in an effici ent way [8], two PIU-B detecting algo-rithms are proposed in this paper. One is Gen-based ( Gen erator-based) strategy and the other is EP-based( E merging P attern-based) strategy. The solutions of two strategies for detecting PIU-B are divided into two phases: building sample classifier(s) and contrasting a test behavior sequence with classifier(s) to judge whether it is a PIU-B or not. Gen-based method contrasts a test behavior sam-ple with the mined PIU classifier consisting of PIU generators to detect PIU-B, while EP-based approach contrasts a test behavior sample with two discovered sample sets, PIU and NPIU ( N on-PIU ) classifiers corresponding to their re-spective EPs, to decide whether it i s an instance of PIU-B or NPIU-B ( N PIU B ehaviors). The main contributions of this paper are summarized as follows. 1. Since behavior generator set is the lower bound of a behavior equivalence 2. Since EPs can highlight the difference characteristics between two data sets, 3. For dealing with excessive fragmentation of complex event X  X  occurrence time 4. To the best knowledge of us, this is the first paper to address how to detect
The rest of this paper is organized as fo llows. Section 2 intr oduces some pre-liminaries such as simple events, complex events, equivalence class, emerging patterns and generators. The details of two PIU-B detecting algorithms are discussedinSection3.InSection4,exper imental results and evaluation are de-scribed. Section 5 gives some related work, while Section 6 concludes the paper. Before introducing two PIU-B detecting algorithms, some basic concepts such as simple events, complex events, emergin g patterns, event equivalence class and event generators will be given in this section. 2.1 Simple Events Events are real-world occurrences that unfold over space and time. In other words, an event is something notable that happens, owning a lasting time, occurs in a specific place, and typically will involve certain change of state. The formal definition about simple event and association rules to infer complex events are described in the following.
 Definition 1. Let E( type s , t s , p s , S s ) represent a simple event, where parame-ter type s , t s ,and p s represent type, time and place that a simple event oc-curs respectively. And S s is an attribute set of different simple events, i.e., S s =( S 1 , S 2 ,..., S n ), where S i (1  X  i  X  n) is the i th attribute in S s .
Since all simple computer-mediated i nteractive events occur in a common place, parameter p s canbeomittedinthispaper.Incomputer-mediatedin-teractions, a simple event X  X  S s has an unique attribute depending on type s . Therefore, both type s and different values of S s  X  X  unique attribute can act as can be simplified into the form E ( Type s , t s ), where parameter Type s not only reflects an event type but also gives its measurable value. Further, in order to facilitate discussing, we will use abbreviation E to replace E ( Type s , t s )inthe following unless otherwise specified.

We focus on 8 aspects of simple events r elating to computer-mediated inter-actions, which are 1) CPU utilization, 2) capacity of memory occupied, 3) the number of clicking mouse X  X  left buttons, 4) the number of clicking mouse X  X  right buttons, 5) the amount of moving pixel of mouse, 6) the number of pressing keyboards, 7) network flow and 8) a front running process of monitored ap-plications. In fact, since there are lots of applications in real computer world, it is unrealistic to monitor all applications. Therefore, for simplifying, only 7 typical processes are selected, denoted by F p (1  X  p  X  7), which are IE explorer, Google explorer, War3 (a real time strategy game), Trading Card Game Online (a board game), Windows Media Player, QQ (an instant message software) and MSN. The different values of Type s are listed in Table 1. Based on the 8 aspects mentioned above, there are totally 8 t ypes of simple events need to monitor, which are listed in the following. 1. Once A is over 50%, an instance of E , e ( A , t ), is captured and created. 2. Once B is over 60%, an instance of E , e ( B , t ), is captured and created. 3. Once C 1 is over 30, an instance of E , e ( C 1 , t ), is captured and created. 4. Once C 2 is over 10, an instance of E , e ( C 2 , t ), is captured and created. 5. Once C 3 is over 1600, an instance of E , e ( C 3 , t ), is captured and created. 6. Once D is over 100, an instance of E , e ( D , t ), is captured and created. 7. Once EF is over 40 MB, an instance of E , e ( EF , t ), is captured and created. 8. Once F p is running, one of instances of E , e ( F p , t ), is captured and created. 2.2 Complex Events Let cE ( type c , t c , p c , S c ) represent a complex event, where each parameter X  X  sub-script c distinguishes complex events from si mple events. Above all, parameter p c can be omitted due to the same reason as that of simple events. Second, similar with simple event X  X  characteristic of unique attribute, it is enough for complex events to let S c only record their lasting time. Thus, based on two points just dur ), where the first two parameters rep resent the type and time that a com-plex event occurs and the last parameter dur represents event X  X  duration time. In addition, substitute Type c for type c in order to keep coincident with the type expression of simple events. As a result, cE ( type c , t c , dur ) is written into cE ( Type c , t c , dur ). The different values and meanings of parameter Type c are listed in Table 2.

The association rules for identifying complex events are represented in a dis-junctive normal form. Let R denote association rules set, then R =( r 1  X  r 2  X  ...  X  r Formula (1). The left-hand side of the rule is called t he rule antecedent or precondition. It contains a disjunctive normal of the conjunction of simple event tests, which is shown in Formula (2).
 where 1  X  ( m , h , g )  X  8. Parameter m , g , h represent the number of simple events in a different conjunction normal. The right-hand side of the rule is called the rule consequent. If the precondition of r v is satisfied, then r v is said to be triggered, event. Association rules to deduce complex events are shown in Table 4. It is obvious that there are 7 association rules, which results in 1  X  v  X  7. For example, if e ( A , t ), e ( B , t )and e ( EF , t ) are monitored simultaneously at time t ,rule r 1 will be triggered. As a result, ce ( WVOn , t , dur ) will be generated. In other words, we can induce that the computer user is watching video online at time t with dur =null because t is a time point. In order to obtain the duration time of ce ( Type v c , t , dur ), an approach to obtaining complex event X  X  lasting time will be exploited, which is introduced in next paragraph in detail.

During computing the lasting time of complex event, an interesting phe-nomenon is observed. Many complex eve nts with a same event type are treated as different events just because their occurring time or lasting time is different. In fact, if time is limited to a reasonable r ange, these events have no obvious dis-tinction. For example, given two complex events,  X  X urfing the Internet starting at 8:00 a.m. for 47 minutes X  and  X  X urfing the Internet at 9:00 a.m. for 52 min-utes X , it is obvious that both of them have little semantic difference in real life, as they all happen in morning and the duration difference is not too much. How-ever, two independent complex events are generated in event processing. This phenomenon results in the number of frequent complex events is too much, here, which is called Excessive Fragmentation of Time (EFT). For avoiding this issue, complex events can be merged together based on some coarse time granularity. Premise is this reduction has no negat ive effect on the precision of emerging pattern mining.

Considering the time semantic nature of real life, it is reasonable to partition a day with 24 hours into 5 time intervals, i.e. , (6:00 a.m. -11:00 a.m.), (11:00 a.m. -2:00 p.m.), (2:00 p.m. -6:00 p.m.), (6:00 p.m. -11:00 p.m.) and (11:00 p.m. -6:00 a.m.) in this paper, and each of them represents  X  X orning X ,  X  X oon X ,  X  X fternoon X ,  X  X vening X  and  X  X efore dawn X  respectively. For avoiding EFT effects on both t c and dur , two solution strategies, i.e. , Occurrence Time Mapping Strategy (OTMS) and Duration Rounding Strategy (DRS), are proposed in this paper. The basic idea of OTMS is to merge some complex events into a group, where one to one mapping relationship between groups and 5 time intervals need to satisfy. For emphasizing the semantic meaning of occurrence time, parameter t c is replaced with T c . The basic idea of DRS is to let duration is the multiple times of integer 10, here, time unit is minute, and if not, round it. Both OTMS and DRS all decrease the number of complex ev ents dramatically. Finally, complex event X  X  abstract form cE ( Type c , t c , dur ) is represented as CE ( Type c , T , Dur ). Table 3 lists 5 values of T in detail. In addition, in order to facilitate discussing, we will use abbreviation CE and Ce , to replace CE ( Type c , T , Dur ) and its instance respectively, in the following unless otherwise specified. 2.3 Equivalence Class and Generators of Complex Events A CE dataset is a set of CE transactions. A CE transaction is a non-empty set of CEs . The key idea of PIU-Miner is to mine a concise representation of equivalence classes of frequent CE set from a transactional CE database D . Formally, an equivalence class of CEs is defined as follows.
 Definition 2. Let EC CE represent an equivalence class of CEs . EC CE is a set of CEs that always occur together in some CE transactions of D . That is,  X  X,Y  X  EC CE ,  X  f D (X)= f D (Y), where f D (Z)= { R  X  D | Z  X  R } .
 Definition 3. The support of an CE itemset P CE in a dataset D , denoted by sup( P CE , D ), is the percentage of CE transactions in D that contain P CE . Definition 4. Let X be a CE itemset of a CE dataset D. The equivalence class of X in D is denoted [ X ] D . The maximal CE itemset and the minimal itemsets of [ X ] D are called the closed pattern and the generators of this CE equivalence class respectively. Generator of [ X ] D is represented as G. The closed patterns and generators of D are all the closed patterns and generators of their equivalence classes.
 Property 1. Let C CE be the closed pattern of an equivalence class EC CE and G
CE be a generator of EC CE .Thenall CE itemset X satisfying G CE are also in this equivalence class.
 Corollary 1. An equivalence class EC CE can be uniquely and concisely repre-sented by a closed pattern C CE and a set G CE of generators, in the form of EC CE =[ G CE , C CE ], where [ G CE , C CE ]= { X | X  g  X  G CE ,g  X  X  X  C CE } . Corollary 2. The entire equivalence class can be concisely bounded as EC CE =[ G CE , C CE ] ,where G CE is the set of generators of EC CE , C CE is the closed pattern, and [ G CE , C CE ]= { X | X  g  X  G CE ,g  X  X  X  C CE } .

In order to facilitating discuss, generator G CE is abbreviated to G in the following unless otherwise specified. 2.4 Emerging Patterns Assuming that we are given ordered pair of data sets D and D , sup D ( X )and sup D ( X ) are their support respectively, some definitions are described as follows. Definition 5. The growth rate of an itemset X from D to D is defined as Definition 6. Given  X &gt; 1 as a GrowthRate threshold, an itemset X is called a  X  emerging pattern from D to D if GrowthRate D  X  D (X)  X   X  .

A  X  emerging pattern is sometimes called  X  EP or simply EP when  X  is un-derstood. An EP from D to D is sometimes described as  X  X n EP in(or of) D  X , represented by sup D ( X )simply,when D is understood. Definition 7. A jumping Emerging Pattern (JEP) from D to D is defined as an emerging pattern from D to D with the growth rate  X  .

Similarly, an JEP from D to D is sometimes called  X  X n JEP in(or of) D  X  when D is understood.
 Definition 8. If Gr D (X)  X   X  , sup D (X)  X  MinSup and { X  Y  X  X | Gr(Y) &lt;sup D (X) or sup D (Y) &lt; MinSup } , then X is called an essential emerging pattern (eEP). Since the mining of frequent behavior generators is a prerequisite to exploit two PIU-B detecting algorithms, we firstly describe the discovery of frequent behavior generators in Section 3.1. And then, Section 3.2 and 3.3 give the detailed illus-tration about two algorithms. Here, each algorithm includes two phases: building sample classifier(s) and contrasting a test behavior sequence with classifier(s) to judge whether it is a PIU-B or not. 3.1 Discovering Frequent Generators of PIU-B Based on Generators are the lower bound of equivalence class, in other words, a set of gen-erators is the shortest ex pression to represent an EC .Giventhat D is a formalized database of complex events, F l is a set of behavior items, D a is a condition database corresponding to some behavior item a i in F l , Minsup is a predefined support threshold of frequent behavior generators need to discover, l is a frequent generator variable, FG is a frequent behavior generators set and TempFG is it X  X  temporary set. The procedure that how to discover frequent be-havior generators, i.e. , Generator Mining algorithm, is illustrated in Algorithm 1. The main processing steps are described in the following.
 Algorithm 1. Generator Mining Algorithm 1. Scan each item of D to generate item set F and record the number of each 2. Build a FP-tree [8] aiming at the item set. 3. Visit the item with minimum support value in D and create D X  X  condition 4. Aiming at each item from the condition database and all power sets assem-3.2 Generator-Based Algorithm for Detecting PIU-B A computer-mediated interactive behavi or can be represented as a set consisting of many frequent behavior generators. But not all these generators have the characteristics of PIU-B. As a result, the basic idea of Gen-based algorithm is to select some special generators repr esenting PIU from frequent behavior generators.

Firstly, rank all frequent generator s based on their scores to select PIU-B generators. Experts in PIU domain are involved in detecting work, scoring each one in generator set and rank the useful ones. According to knowledge and experiences, a formula for scoring every generator is given in Formula 4. Just like mentioned in Section 2.2, in Formula (3), Type c represents the type of frequent CE , T represents a CE  X  X  time interval projected by OTMS and Dur is CE  X  X  lasting time. The weights of Type c and T are listed in Table 2 and 3 respectively. Parameter k points out the number of CEs included in a generator G .After scoring all the generators, the generator set whose score less than threshold r s will be pruned. The remaining ones are the final generators to represent PIU optimally. In other words, a PIU-B classifier is created based on these PIU generators.

Secondly, next is to validate a test sample to see if it belongs to a PIU-B classifier by the sum of two PIU parameters, one is it X  X  generator overlap rate and the other is it X  X  duration time overlap rate. The former is denoted as f(G) and the latter is represented by f(dur) . In other words, if the sum of two overlap rates great than and equal to a given threshold, a behavior set is classified into PIU class, otherwise, it belongs to NPIU class. The larger the value of duration time overlap rate is, the higher probability of the behavior set belonging to a PIU class is. As a result, aiming at the CE m ( type m , t m , dur m )and CE n ( type n , t , dur n ), if t m = t n , t m = t n ,and dur m  X  dur n ,then CE m and CE n are thought to be a same event.
Here, assume FG 1 is a set of frequent generators coming from a testing data set, FG 2 is that from a PIU sample set. The calculation of f(G) and f(dur) are given in Formula(5) and (6). The numerat or in Formula5 is the intersection set of FG 1 and FG 2 , i.e. , the number of common generators and the denominator is the number of generators in the testing set. The ratio of two values is the percentage of PIU generators occu rred in all testing generators, i.e. , generator overlap rate. Before calculating f(G) , we must justify whether a behavior item ce m maps a contrast item in a set of PIU generators, G j . For example, assume that G i is a generator from FG 1 and G j is a generator from FG 2 ,forjustifying whether a ce m belongs to a contrast item, what need to do is to see if the ce m has the same Type and t as those of the contrast item, and whether the dur of ce m is greater than and equals to that of the contrast item. If so, then based on Formula(5), calculate generator overlap rate. In Formula(6), the numerator is the sum of duration time of PIU-B generators, and the denominator is that of testing generators. The ratio of two values is the overlap rate of PIU duration time. 3.3 EP-Based Algorithm for Detecting PIU-B In first phase, EP-based algorithm classifies EPs, i.e. , generators satisfying the threshold requirement of growth rate, to build PIU and NPIU classifiers by select-ing their corresponding JEPs and eEPs. JEP X  X  computation is exploited by set-difference operation and eEP X  X  computation is implemented by set-intersection operation. After getting JEPs and eEPs, set-union operation is done to obtain fi-nal EPs of PIU and NPIU. In second phase, EP-based algorithm contrasts a test behavior sample with two classifiers respectively by calculating two individual scores and then judges which classifier belonging to based on the group decided by maximum score. The processing steps of EP-based algorithm are listed as follows. 1. Computation of JEP. JEP is the EPs whose growth rate is  X  ,whichcan 2. Computation of eEP. eEP is the EPs whose growth rate is greater than 3. Computation of EP. We implement set-union operation to obtain EPs. 4. Computation of score. After obtaining JEP and eEP, we calculate scores In Formula(7), D i and D j are sample database, where i and j are class labels. Here, there are only two sample database, one is PIU and the other is NPIU. The former is represented by D 1 and the latter is denoted as D 2 . Parameters X and Y represent generators of EPs in D 1 and D 2 respectively. RS is an positive object set which imposes positive effect on samples and WS is negative object set which brings negative effect on samples. Gr ( X,D j | i ,D i | j )representsX X  X growth rate from a data set to the other. For example, Gr ( X,D 2 ,D 1 )representsX X  X  growth rate from D 2 to D 1 , while Gr ( X,D 1 ,D 2 ) represents X X  X  growth rate from D 1 to D 2 . MaxGr RS is the maximum growth rate threshold of object data set. MinGr WS is the minimum growth rate threshold of non-object data set. C is complex event set need to classify. Sup c ( X ) is the support of X in C and Sup c ( Y ) is the support of Y in C .

Ifatestdataset C is taken as a RS , i.e. , a set of target class, we can depend on the first part of Formula(7) to determi ne classifying score. Otherwise, if C is thought to be a WS , i.e. , a set of non-target class, the the second part of Formula(7) is used to obtain score. In Formula(7), the first part of it describes the contributions of JEPs and eEPs to classify C , in particularly, parameter MaxGr emphasizes the special role of JEPs in calculating score. At the same time, the EPs in a non-target class also produce some effect on C  X  X  belonging to the target class. In other words, EPs in D 2 , i.e. , Y , have some effect on identifying whether C belongs to D 1 . For example, if C contains Y , the probability of C the contribution of Y to score is small, thus, Y can be omitted. But, when the value of Gr ( Y , D 2 , D 1 ) satisfies a predefined threshold and is small, it will play important role in validating C belongs to D 1 . In addition, considering the difference between eEP and JEP , the second part of Formula(7) is given. In a word, Formula(7) is a synthetical repre sentation after much consideration. For testing efficiency and effectivenes s of two PIU-B detecting algorithms, we gather real interactional behavior data from 20 masters in our lab by running event collector with trigger 24 hours a day in each student X  X  computer. Among 20 students, we select 5 persons who have high PIU probability such as watching video online, playing board game, and Browsing Web Site by questionnaires as PIU sample objects and collected their d aily computer interactions about 10 weeks as PIU sample samples. One third of 15 students are treated as normal NPIU samples. Two third of 15 students are treated as the testing data set and are feeded into two algorithms to j ustify whether an object has latent PIU behavior. In addition, considering scalability of two algorithms, synthetic data about 100 weeks are generated in a hybrid way based on some typical PIU-B generators. All the experiments are done with Intel Core i3 processor (2.53 GHz CPU with 4GB RAM) and operating system is Windows 7 professional edition. 4.1 Efficiency Aiming at real and synthetic data, effic iency test of two PIU-B detecting algo-rithms, i.e. , running time and occupied memory space are measured. Experi-mental results are shown from Fig.1(a) to Fig.1(d) respectively.
Firstly, from the viewpoint of running time, Fig.1(a) and .1(b) show that two algorithms time increases as data scale( i.e. , the number of test days) increases, since the much data quantity is, the much the time consumes. Also, Fig.1(a) shows that Gen-based algorithm spends less time than EP-based algorithm since the latter includes more processing steps. But this advantage will be weakened as data scale enlarges. Especially, just like showing by crossing point where two lines intersected in Fig.1(b), whe n data volume exceeds approximate 30 days, EP-based algorithm is superior to Gen-based algorithm, i.e. , EP-based algorithm runs faster than Gen-based algorithm. This phenomenon is obvious in Fig.1(b) where the runtime X  X  rising extent of EP-based algorithm is much slower than that of Gen-based algorithm. The reason lies in, with the persistent increment of data scale, the number of generators will reach to an unpredictable quantity, while the number of EPs will be kept in a stable range. In other words, ineffective generators will be filtered out due to threshold limitation of growth rate and characteristics of emerging pattern. As such, EP-based algorithm only need much less time than that of Gen-based algorithm.

Secondly, from the viewpoint of occupied memory space, both algorithms need more space with the increment of d ata scale. The reason is the much data quantity is, the much space consumes. In addition, EP-based algorithm need much more space than Gen-based algorithm due to dependence of generators for EPs discovery. 4.2 Effectiveness Two algorithms effectiveness such as precision, false positive and false negative rates are tested in this paper. We discuss all possible affects that each of them imposes on two algorithms in the following . Besides these, how growth rate effects the EP-based algorithm X  X  eff ectiveness is also addressed.

Firstly, from the viewpoint of precision rate, Fig.2(a) and Fig.2(b) show that both real data and synthetic data achieve high precision rate. In Fig.2(a), the average of EP-based algorithm X  X  precision rate is 89.1% and that of Gen-based algorithm is 79.8%. In Fig.2(b), the average of EP-based algorithm X  X  precision rate is 89.5% and that of Gen-based algorithm is 87.5%. These results show that data quantity of a test set is proportional to accurate rate of detecting results. In addition, EP-based algorithm X  X  precision is superior to Gen-based algorithm no matter whether real data or synthetic data. The reason is that EP-based algorithm need to contrast with two sample sets and it X  X  judgement principles is objective, fair and reasonable due to many factors to be considered. But Gen-based algorithm only depends on the contrast with one sample set and it X  X  decision rules are more subjective s ince most of them come from specialists opinions.

Secondly, standing on the viewpoints of error rate, from Fig.2(c) to Fig.2(f), real data and synthetic data are in low level. Here, error rate includes false pos-itive rate and false negative rate. For real data, as shown in Fig.2(c), average false positive of EP-based algorithm is 9.8%, while that of Gen-based algorithm is 16.4%. Also, as shown in Fig.2(d), the false negative rate of EP-based algorithm is 12.4% and that of Gen-based algorithm is 25.4%. For synthetic data, as shown in Fig.2(e), average false positive of EP-based algorithm is 9.5%, while that of Gen-based algorithm is 17.6%. At the same time, as shown in Fig.2(f), the false negative rate of EP-based algorithm is 7.8% and that of Gen-based algorithm is 8.6%. Based on these, one conclusion is that error rate of EP-based algorithm is lower than that of Gen-based algorithm. The reason lies in, compared with Gen-based algorithm, EP-based algorithm X  X  classifier not only has concise expression form, but also includes the attribute characteristics with strong distinction abil-ity. In addition, the other conclusion is error rates of two algorithms will descend as data scale increases since the much the data quantity is, the lower the error rate is.
Finally, on the side of EP X  X  growth rate, we discuss how it affect the EP-based algorithm X  X  effectiveness. In Fig.2(g) and 2(h), axes X and Y represent growth rate and the number of EPs(written by #EPs) respectively. It is seen that the number of EPs will decrease as the gro wth rate increases until down to the number of JEPs. Just mentioned in Section3.3, the number of EPs equals to an accumulation sum of the amount of JEPs and eEPs. While the number of JEPs is not influenced by growth rate due to its infinite growth rate. Therefore, in fact, the number of EPs is only associated with the amount of eEPs. When the number of EPs equals to the number of JEPs, the corresponding growth rate becomes a critical value, which means once growth rate exceeds this point, the number of EPs keeps invariable and equals to the number of JEPs all along. In this case, the classifier with only JEPs has the strongest distinguishing effectiveness. Main work associated with this paper h as been introduced in Section 1. In the sequel, we give a brief review about research achievements related with our work. Frequent Pattern Mining. Discovering frequent patterns from large database is meaningful and practical in association rule mining [9,10], correlation analysis [11], classification [12], emerging pattern [13] and other domains. Due to limited space, here, only some algorithms and ideas associated with emerging pattern are introduced. Li et al. [8] propose DPMiner to mine generators and equivalence classes. They construct a modified FP-tree which those frequent items with full support must be removed from the head table of FP-tree, thus both save running time and space in a great scale. Milton et al. [14] introduce fuzzy emerging patterns as an extension of emerging patte rns to deal with numerical attributes using fuzzy discretization. Khan et al. [15] present the dual support Apriori for temporal data algorithm to discover EP and JEP from time series data using a sliding window technique. It dose not rely on itemsets borders with a constrained search space, thus requires less memory, minimum computational cost and very low data set accesses. Yu et al. [16] bridge causal relevance and EP discriminability to facilitate EP mining and propose a new framework of mining EPs from high-dimensional data, thus enables to extract a minimal set of strongly predictive EPs from an explosive number of candidate patterns. Sequential pattern mining. Sequential pattern mining was first introduced by Agrawal and Strikant [17] used in data mining research field. SPADE [18], PrefixSpan [19] and SPAM [20] are quite popular ones. All these search strate-gies can be divided into two types [21] -breadth-first search, such as GSP and SPADE, generating many candidate patterns, and depth-first search, such as PrefixSpan and SPAM, iteratively partitioning the original data set. While most of previously developed closed pattern mining algorithms are inherently costly in both runtime and space usage when the support threshold is low or the patterns become long, Wang et al . [22] presented an efficient algorithm for mining fre-quent closed sequences, BIDE, without c andidate main tenance. In recent years, the studying domain of sequential pattern mining has been extended. Since ex-isting work of studying the problem of frequent sequence generator mining is rare, Gao et al . [23] present a novel algorithm, i.e. , FEAT, to perform this work. Internet addiction disorder. Internet addiction was first introduced by Young [24], but the illustrate of term addiction is various between scholars and has greatly developed. In paper [2], Young defined Internet addiction as impulse-control disorder by using Pathological Gambling as a model. The behavior was first named as Pathological Compulsive Internet Usage (PCIU) and later changed to Pathological Internet Use (PIU), divided into 5 types -information overload, net compulsions, cyber-relationship addiction, cyber-sexual addiction and game addiction [25]. Be absorbed in Internet so addictively as to unable to control, this phenomenon is called PIU or IAD. PIU is a negative production of Internet popularizing and need to avoid. Aiming at this issue, two novel PIU-B detecting algorithms, Gen-based and EP-based approaches are proposed in this paper. The basic idea of the former is to mine generators only due to it X  X  simplest representation of behavior equivalence classes. Based on mined frequent behavior generators, a PIU-B sample set, i.e. , a PIU classifier, is created, which can be used to detect PC users PIU-B. Taking growth rate betw een two data sets into account, the focus of EP-based algorithm is to discover EPs that highlight different characteristics between two data sets. Based on the EPs from generators satisfying the threshold requirement of growth r ate, two sample sets, i.e. , PIU and NPIU classifiers, are built simultaneously so as to diagnose PIU-B and NPIU-B meanwhile. Extensive experimental results show that both t wo methods are efficient and effective. Since the initial launch in August 2009, Sina Weibo, a Twitter-like microblogging service, has grown rapidly to become a major and influential site for millions of Internet users in China to disseminate news and urgent information, promote new productions, and express opinions and comments on controversial issues [4, 6]. However, unlike Twitter which attracts much attentions from the research community due to its popularity in United States and Europe, few studies have been done to characterize tweeting behaviors of Sina Weibo users.

In this paper, we present a first systematic study to infer the tweeting activities of Sina Weibo via a simple yet effective algorithm, which explores continuous public status streams and user status streams via Weibo open platform APIs. Through analyzing sampled tweets captured from public status streams and all complete tweets of two independent groups of Weibo users  X  a subset of users from the global Weibo user population and a subset of users from a local Weibo community, we first estimate the sampling rate of public status streams, and subsequently derive the overall Weibo tweeting activities using this sampling rate and the total tweets in sampled public status streams. In our experiments, we find that the sampling rates independently calculated from two groups are almost the same. In addition, the diurnal pattern of estimated tweeting activities well approximates the data in the public statistics released by Sina Weibo. Weibo provides real-time and sampled status streams of its all users via the public timeline API, which returns a maximum of 200 latest randomly-selected tweets, which are also referred to as statuses or weibos. The real-time status streams, although a sample of all Weibo statuses, contain a rich set of valuable information on user tweeting behaviors and information cascading patterns over Weibo online social network. We collect public status streams from June 14, 2013 to July 2, 2013. During the 19-day data collection period, we have collected a total of over 91 million statuses.

In addition to providing sampled status streams of all users, Weibo also sup-ports an API call that returns all status es (or tweets) of a given user. However, due to the sheer size of Sina Weibo population, it is impractical to collect all statuses of all Weibo users. Sampling is a widely used technique to analyze and process vast amount of data in online social networks [1 X 3, 5], thus we adopt simple sampling approaches to collect complete tweeting activities of two inde-pendent groups of Weibo users  X  a subset of users from the global Weibo user population and a subset of users from a local Weibo community. For simplicity, we use global cluster and local cluster to refer to users in these two groups, re-spectively. For each user in the global cluster and local cluster, we launch Weibo user timeline API calls to harvest its user status streams, i.e., complete tweet-ing activities of the user during the same time period as public status streams. Before inferring the overall tweeting volumes of Sina Weibo, we first need to estimate the sampling rate used for public status streams. As Weibo randomly selects the latest tweets as a result for public status streams, the probability of any tweet being selected is the same, say p . Thus, our objective is to find an accurate inference of p based on data collected from Weibo. If the total number of sampled tweets during a given time period t is n ( t ), then the estimated total number of tweeting activities, N ( t ), is derived as N ( t )= n ( t ) p .
To calculate the sampling rate of public status streams, we develop a simple and intuitive approach by using the sampled tweets captured in the public status streams for global cluster and local cluster and their complete tweets obtained via separate user status timeline API calls. Figures 1[a][b] illustrate strong linear correlations between the numbe r of sampled tweets captured in public status streams and the number of complete tweets by users in the global cluster and local cluster during the first week of ou r data collection period, respectively. The clear linear relationships serve as a strong indication of the sampling rates for both clusters. Note that these two cl usters are independently selected, thus consistent sampling rates are expected for any robust inference algorithm.
Let i denote the user i in a cluster with m user, and S i and T i represent the total number of tweets captured in the public status streams and the total number of complete tweets for the user i . To quantitatively calculate the over-all sampling rates for each cluster, we use the following equation to infer the in public status streams over the total number of actual tweets posted by these users. Using public status streams and the total complete tweets, the sampling rates are calculated as 0 . 2051 and 0 . 2018, for global cluster and local cluster, re-spectively. The consistent sampling rates across two independent groups indicate the robustness of our simple yet effective approach of estimating the sampling rate of public status streams. The average sampling rate for the combined two clusters is 0 . 2063, which we use throughout the remainder of this paper. The availability of the estimated sampling rate allows to infer the total number of tweets posted by all Weibo users. For each time interval, we infer the overall Sina Weibo tweeting activities as the number of tweets captured in public status streams over the sampling rate 0 . 2063.
Figure 2[a] illustrates the inferred number of actual tweets during a 24-hour time window. In this time window, we estimate that the total number of tweets posted by Weibo users is 23 , 924 , 607. Ideally, the validation of the estimation on inferred tweeting volumes of Weibo users is to use the public release data from the official Weibo announcements. A s Weibo does not release such data, we find one public graph released in an o fficial Weibo presentation, shown in Figure 2[b], which presents the average number of tweets posted by Weibo users from mobile devices during one-day cycle over March 2012. Although this public figure does not come with any real statistics, its shape and trend substantially match our estimation. This observation confirms that our proposed approach is a promising and reasonably accurate technique to estimate the tweeting activities of Sina Weibo or other microblogging services such as Twitter. This paper develops a simple yet effectiv e inference algorithm to estimate the tweeting activities of Weibo users over time based on public status streams and complete user status streams of two independent groups. To the best of our knowledge, this paper presents the fi rst effort to systematically infer Weibo tweeting volumes over time. We are currently in the process of analyzing the unstructured contents of tweeting messages posted by Weibo users for gaining an in-depth understanding of Weibo users X  behaviors, interests and intents. Acknowledgement. This research was financially supported by NFSC project (Grant No: 61103027), 973 project (No: 2011CB302305) and Shenzhen Gov Projects (JCYJ20130331144541058 and JCYJ20130331144416448), NSF grant CNS-1218212 and an ASU SRCA grant.

