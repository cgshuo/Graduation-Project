 Previous research has shown that features based on term proximity are important for effective retrieval. However, they incur substantial costs in terms of larger inverted in-dexes and slower query execution times as compared to term-based features. This paper explores whether term proximity features based on approximate term positions are as effective as those based on exact term positions. We introduce the novel notion of approximate positional indexes based on di-viding documents into coarse-grained buckets and recording term positions with respect to those buckets. We propose different approaches to defining the buckets and compactly encoding bucket ids. In the context of linear ranking func-tions, experimental results show that features based on ap-proximate term positions are able to achieve effectiveness comparable to exact term positions, but with smaller in-dexes and faster query evaluation.

In information retrieval, efficiency (speed) and effective-ness (quality) are often in tension, since good relevance sig-nals are frequently expensive to compute during ranking. For example, term proximity features are good predictors of relevance but are costly to compute compared to term-based features. This paper proposes to reduce the cost of computing term proximity features by introducing approx-imate positional indexes , a novel method of encoding term positions in the payload of postings lists.

There are two aspects of cost associated with term prox-imity features. The first is index size: in order for a rank-ing model to support term proximity features, term posi-tions must be encoded in postings payloads. The second is the speed of computing term proximity features at retrieval time. For example, to determine if two query terms occur within w terms of each other during ranking, term positions must be decoded and checked. This is computationally ex-pensive compared to term-based features.

The central hypothesis explored in this paper is the follow-ing: are term proximity features based on approximate term positions as effective as those based on exact term positions? The answer turns out to be yes, in that a fuzzy notion of term proximity yields ranking functions, trained in a learn-ing to rank framework, that are comparable in effectiveness to similar models that use exact term proximity features. The basic insight is that instead of recording exact term positions, we divide documents into coarse-grained buckets and record in which bucket the term occurs. We explore dif-ferent approaches to defining and compressing the buckets. Our best variant algorithm yields substantial reductions in both index size and query evaluation time.
It is widely recognized that term proximity features con-tribute to improvements in retrieval effectiveness over term-based features (i.e.,  X  X ag of words X ) alone. Early studies date back to the 1980s [4], and there has been no shortage of studies on the topic since then [3, 9, 1]. More recently, Markov random fields [7] provide a theoretically-motivated framework for understanding and reasoning about term de-pendencies using undirected graphical models.

Of course, to support term proximity features, it is nec-essary to store term position information in the postings. Existing compression techniques for encoding positional in-formation [10] can be considered lossless, and they achieve different tradeoffs between compression rate and decoding speed. Our work tackles an orthogonal issue related to rep-resenting term positions, where we can take advantage of previous work on compression.

One common approach to faster query evaluation is index pruning [2]. Experiments have shown that it is possible to discard postings that are unlikely to contribute much to a document X  X  score, thus yielding a smaller index X  X ranslating into faster ranking. Index pruning differs from our work in that we retain all postings, but encode positional informa-tion in a more compact (but lossy) manner.
Our work uses linear feature-based ranking functions [7] of the form S ( Q,D ) = P j  X  j f j ( Q,D ), where Q is a query, D is a document, f j ( Q,D ) is a feature function, and  X  the weight assigned to feature j . More specifically, this work uses a particular instantiation of the Markov random field model known as the sequential dependence (SD) model [7]: where f T is defined over query unigrams, and f O and f are defined over query bigrams. The latter two are term proximity features: f O corresponds to phrase matches and f
U corresponds to query term co-occurrence within a partic-ular span. The  X   X  X  are parameters that need to be learned. The original formulation of the SD model defines features in terms of language modeling query likelihoods with Dirichlet smoothing [7]. Here, we adopt an alternative formulation based on BM25 scores [8]. In practice, we have discovered that BM25 scores are slightly more effective, but the differ-ences are not statistically significant in most cases.
The central hypothesis we explore in this paper is whether term proximity features based on approximate term posi-tions are as effective as those based on exact term positions. Our basic idea is that instead of storing exact term positions in the index, we divide each document into coarser-grained buckets and record the id (i.e., the sequential number) of the bucket in which the term occurs.
 We explored two different approaches to defining buckets: Variable-Width Buckets. We can divide each document into a fixed number of buckets b , where each bucket repre-sents a span of term positions within that document. Under this scheme, buckets in different documents will have dif-ferent widths, which means that long documents receive a coarser-grained treatment than short documents.
 Fixed-Width Buckets. As an alternative, we can fix the bucket size w and let the number of buckets in a document vary with the document length. This in effect selects a single level of granularity at which to model term positions in the entire collection.
 We explored two different approaches for coding bucket ids: Integer Coding. We treat bucket ids as an array of inte-gers and use standard gap-based compression techniques to code them (using  X  codes [10]).
 Bit-Array Coding. Bucket positions are coded in a bit-array. That is, the k th bit of the bit-array is set to one if the k th bucket contains the term, or zero otherwise. This scheme works well if the number of buckets is equal to a machine word in the variable-width bucket scheme. Furthermore, as an optimization, checking for term proximity (e.g., if two terms are found in the same bucket) translates into efficient bitwise operations.
 Note that in both cases, we only code the presence or absence of terms in a bucket, but not the number of terms that occur in that bucket. In other words, the approximate positions do not capture term frequency.
To parallel the f O and f U term proximity features in the sequential dependence model, we introduce the three fol-lowing approximate proximity operators. Each operator is defined over an adjacent pair of query terms (i.e., a query bigram), just as the original features are: These features share the same functional form (i.e., weighted using BM25) as their exact positional counterparts. To esti-mate the parameters of our linear models, we employ greedy feature selection X  X  simple but effective learning to rank ap-proach that directly optimizes for the retrieval metric of in-terest (e.g., MAP) described by Metzler [6].
We implemented the approximate positional indexes de-scribed above with Ivory [5]. Inverted indexes adopt a stan-dard compression scheme: document id gaps are compressed with Golomb codes and term frequencies are coded with  X  codes. For baselines, we created an index with no positional information and an index with exact term positional infor-mation. In the latter index, term positions are converted into gap differences and compressed with  X  codes.

Indexes were constructed using Hadoop, and retrieval ex-periments were performed on a server with dual Intel Xeon quad-core processors (E5620 2.4GHz), 64GB RAM, and six 2TB 7.2K RPM SATA drives in RAID-6 configuration (run-ning Red Hat Linux). All experiments used a single thread and performed retrieval on a single, monolithic index (i.e., no document partitioning), returning 1000 hits per query.
For evaluation, we used two TREC web collections: Gov2 (topics 701 X 850) and the first English segment of ClueWeb09 (topics 1 X 50). In each case, queries were split sequentially into training and test sets of equal size. All parameters were estimated on the training set and all results reported on the test sets. Retrieval effectiveness is measured in terms of mean average precision (MAP) and precision at 10 (P@10). A one-side paired t -test (with p = 0 . 05) was used to deter-mine the statistical significance of differences in the metrics.
We used the following baselines as points of compari-son: classic BM25 ; BM25-sd , the basic sequential depen-dence model with BM25 scores and default parameters; and BM25-sd -t , a variant of BM25-sd for which the model pa-rameters were trained on a per-collection basis. This al-lowed the model to adapt to collection-specific characteris-tics, rather than using the same default parameters for all collections as is done with BM25-sd . Our BM25 runs used Figure 1: Percentage reduction in index size with respect to exact positional indexes. Non-positional indexes (left-most bars) provide upper bounds. the non-positional indexes since they do not require any po-sitional information for ranking documents, while the other two baselines used the exact positional indexes, which were needed to compute the exact term proximity features.
In our experiments, we used nine variants of approximate positional indexes that have different bucket types: variable-width buckets with number of buckets b = 8 , 16 , 32 , 64 X  X ach denoted as Var( b ) X  X nd fixed-width buckets with bucket size w = 10 , 20 , 30 , 40 , 50 X  X ach denoted as Fixed( w ).
We now describe our experimental analysis of approximate positional indexes and proximity features in terms of index size, retrieval effectiveness, and query evaluation speed.
Figure 1 compares the sizes of the approximate positional indexes with respect to exact positional indexes. Bars plot space savings, so higher is better. For reference, the left-most bars show the space savings of non-positional indexes (i.e., discarding positional information altogether), which ranges between 76% to 82%. This serves as an upper bound.
The two collections exhibit similar patterns. As expected, we notice that as the number of buckets per document ( b ) increases in the variable-width models or as the bucket size ( w ) deceases in the fixed-width models, the index size in-creases (and thus the space savings decrease). In some cases, the bit-array coding indexes are actually bigger than exact positional indexes.

The figures also show a clear advantage to the integer coding scheme in terms of index size (space savings range from 29% to 66%) compared with the bit-array scheme. Table 1: Retrieval effectiveness. Bold values indi-cate stat. sig. over BM25; star-annotated and un-derlined values indicate n.s. compared to BM25-sd and BM25-sd -t , respectively.
Table 1 presents retrieval effectiveness in terms of MAP and P@10 for the test collections. We annotated the ef-fectiveness values to indicate results of significance testing between the approximate positional models and the base-lines: bold values indicate statistically-significant improve-ments over BM25, and star-annotated and underlined val-ues indicate no statistically-significant difference compared with BM25-sd and BM25-sd -t , respectively.
 MAP results reported in the table indicate that, in the Gov2 collection, all approximate positional models exhibit significant improvements over BM25. Moreover, all of the fixed-width models have no statistically-significant differ-ences with BM25-sd -t . While the MAP results are generally in favor of our approximate models for Gov2, the Clue results are more mixed. The table shows that the baselines aren X  X  very different from each other, and this might explain the lack of significant improvement of our approximate models over BM25.

Although the P@10 results indicate that our approximate models are not significantly better than BM25, the models are also not statistically different from the other baselines either. This suggests that term proximity features are better at enhancing precision at lower ranks, since they consistently improve MAP.

Considering the absolute MAP and P@10 scores in addi-tion to the results of the statistical significance tests, we see that the fixed-width models are consistently better than the variable-width models. We hypothesize that variable-width models introduce a great deal of variance (or noise) into the proximity features (such as SameBucket ) because win-dow sizes vary greatly depending on the document length (i.e., very short for short documents, very long for long documents) X  X r more accurately, on the variance of doc-ument lengths within a collection. If all documents have the same length (i.e., zero variance), then Var( b ) would behave exactly the same as Fixed( avgdl / w ). However, as the vari-ance increases, the definition of proximity features becomes less  X  X onsistent X , which ultimately yields noisy feature values and thus less effective results. Figure 2: Average normalized query execution time of baselines and different approximations.

The results of the fixed-width models show that, as the width of the bucket decreases, the effectiveness improves. This is expected since smaller buckets yield more accurate approximate positional information. Overall, the fixed-width models Fixed(10) and Fixed(20) are the best among all the approximate positional models.
Figure 2 shows the average (over three trials) query ex-ecution time (QET) for each collection across a variety of approximate positional indexing strategies. The QET fig-ures are normalized with respect to baseline BM25, which uses the non-positional indexes, and thus the bars show how much slower (in relative terms) the other conditions are.
Comparing integer and bit-array coding, we notice that the latter is generally faster but not substantially. BM25-sd -t is comparable to BM25-sd on Gov2. For Clue, the learned BM25-sd -t model uses fewer features than BM25-sd , simply as an artifact of the greedy feature selection algorithm, and as a result it is substantially slower.

Rather than exhaustively explain all the results, we fo-cus on the Fixed(10) and Fixed(20) models, which yielded consistently strong effectiveness (from the previous section). For Gov2, we observe a substantial reduction in QET with the Fixed(20) model (  X  57%) compared to both variants of the sd models. In the Fixed(10) model, the greedy feature selection algorithm uses more features, and thus is substan-tially slower. The results for Clue show that both Fixed(10) and Fixed(20) are significantly faster (  X  57%) than BM25-sd and exhibit comparable efficiency (  X  5%) to BM25-sd -t .
Overall, the Fixed(20) model not only exhibits effective-ness that is comparable to the BM25-sd model, but also strong efficiency characteristics X  X  substantial reduction in index size and query execution time. This particular setting nicely balances a small index footprint, good effectiveness, and fast query execution.
Term proximity features are useful for a variety of search tasks, especially those that deal with large collections such as web search. However, full positional indexes can consume a large amount of space and positionally-aware retrieval mod-els that utilize such indexes are considerably slower than their non-positional counterparts. To help minimize the time and space costs of positional indexes, we proposed a novel indexing strategy called approximate positional in-dexes and a corresponding retrieval model. These indexes break documents into fixed or variable width buckets and encode which buckets a term occurs in, either using integer or bit-array coding.

Our experimental results, carried out over two TREC web collections, show that our proposed methods are able to achieve comparable effectiveness to term-proximity models based on full positional indexes, but with smaller indexes and faster query execution times. Therefore, the proposed methodology provides system designers with a viable  X  X id-dle ground X  in the efficiency-effectiveness tradeoff space to better balance quality, time, and space. This work has been supported by NSF awards IIS-0836560, IIS-0916043, and CCF-1018625. Any opinions expressed are the authors X . The second author is grateful to Esther and Kiri for their loving support and dedicates this work to Joshua and Jacob. [1] S. B  X  uttcher, C. Clarke, and B. Lushman. Term [2] D. Carmel, D. Cohen, R. Fagin, E. Farchi, [3] W. Croft, H. Turtle, and D. Lewis. The use of phrases [4] J. Fagan. Experiments in automatic phrase indexing [5] J. Lin, D. Metzler, T. Elsayed, and L. Wang. Of Ivory [6] D. Metzler. Automatic feature selection in the Markov [7] D. Metzler and W. Croft. A Markov random field [8] S. Robertson, S. Walker, M. Hancock-Beaulieu, [9] M. Srikanth and R. Srihari. Biterm language models [10] I. Witten, A. Moffat, and T. Bell. Managing
