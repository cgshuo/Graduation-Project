 The input to an algorithm that learns a binary classi er normally consists of two sets of examples, where one set consists of positiv e examples of the concept to be learned, and the other set consists of negativ e examples. However, it is often the case that the available training data are an incomplete set of positiv e examples, and a set of unlab eled examples, some of whic h are positiv e and some of whic h are negativ e. The problem solv ed in this pap er is how to learn a standard binary classi er given a non traditional training set of this nature.

Under the assumption that the lab eled examples are se-lected randomly from the positiv e examples, we sho w that a classi er trained on positiv e and unlab eled examples pre-dicts probabilities that di er by only a constan t factor from the true conditional probabilities of being positiv e. We sho w how to use this result in two di eren t ways to learn a classi-er from a non traditional training set. We then apply these two new metho ds to solv e a real-w orld problem: iden tifying protein records that should be included in an incomplete specialized molecular biology database. Our exp erimen ts in this domain sho w that mo dels trained using the new meth-ods perform better than the curren t state-of-the-art biased SVM metho d for learning from positiv e and unlab eled ex-amples.
 H.2.8 [ Database managemen t ]: Database applications| data mining.
 Algorithms, theory .
 Sup ervised learning, unlab eled examples, text mining, bioin-formatics.

The input to an algorithm that learns a binary classi er consists normally of two sets of examples. One set is positiv e examples x suc h that the lab el y = 1, and the other set is negativ e examples x suc h that y = 0. However, supp ose the available input consists of just an incomplete set of positiv e examples, and a set of unlab eled examples, some of whic h are positiv e and some of whic h are negativ e. The problem we solv e in this pap er is how to learn a traditional binary classi er given a non traditional training set of this nature.
Learning a classi er from positiv e and unlab eled data, as opp osed to from positiv e and negativ e data, is a problem of great imp ortance. Most researc h on training classi ers, in data mining and in mac hine learning assumes the availabilit y of explicit negativ e examples. However, in man y real-w orld domains, the concept of a negativ e example is not natu-ral. For example, over 1000 specialized databases exist in molecular biology [7]. Eac h of these de nes a set of posi-tive examples, namely the set of genes or proteins included in the database. In eac h case, it would be useful to learn a classi er that can recognize additional genes or proteins that should be included. But in eac h case, the database does not con tain any explicit set of examples that should not be in-cluded, and it is unnatural to ask a human exp ert to iden tify suc h a set. Consider the database that we are asso ciated with, whic h is called TCDB [15]. This database con tains information about over 4000 proteins that are involved in signaling across cellular mem branes. If we ask a biologist for examples of proteins that are not involved in this pro-cess, the only answ er is \all other proteins." To mak e this answ er operational, we could tak e all proteins men tioned in a comprehensiv e unsp ecialized database suc h as SwissProt [1]. But these proteins are unlab eled examples, not negativ e examples, because some of them are proteins that should be in TCDB. Our goal is precisely to disco ver these proteins.
This pap er is organized as follo ws. First, Section 2 for-malizes the scenario of learning from positiv e and unlab eled examples, presen ts a cen tral result concerning this scenario, and explains how to use it to mak e learning from positiv e and unlab eled examples essen tially equiv alen t to learning from positiv e and negativ e examples. Next, Section 3 deriv es how to use the same cen tral result to assign weigh ts to unlab eled examples in a principled way, as a second metho d of learn-ing using unlab eled examples. Then, Section 4 describ es a syn thetic example that illustrates the results of Section 2. Section 5 explains the design and ndings of an exp erimen t sho wing that our two new metho ds perform better than the best previously suggested metho d for learning from positiv e and unlab eled data. Finally , Section 6 summarizes previ-ous work in the same area, and Section 7 summarizes our ndings. Let x be an example and let y 2 f 0 ; 1 g be a binary lab el. Let s = 1 if the example x is lab eled, and let s = 0 if x is unlab eled. Only positiv e examples are lab eled, so y = 1 is certain when s = 1, but when s = 0, then either y = 1 or y = 0 may be true.

Formally , we view x , y , and s as random variables. There is some xed unkno wn overall distribution p ( x; y; s ) over triples h x; y; s i . A non traditional training set is a sample dra wn from this distribution that consists of unlab eled ex-amples h x; s = 0 i and lab eled examples h x; s = 1 i . The fact that only positiv e examples are lab eled can be stated formally as the equation In words, the probabilit y that an example x app ears in the lab eled set is zero if y = 0.

There is a subtle but imp ortan t di erence between the sce-nario considered here, and the scenario considered in [21]. The scenario here is that the training data are dra wn ran-domly from p ( x; y; s ), but for eac h tuple h x; y; s i that is dra wn, only h x; s i is recorded. The scenario of [21] is that two training sets are dra wn indep enden tly from p ( x; y; s ). From the rst set all x suc h that s = 1 are recorded; these are called \cases" or \presences." From the second set all x are recorded; these are called the bac kground sample, or con taminated con trols, or pseudo-absences.

The single-training-set scenario considered here pro vides strictly more information than the case-con trol scenario. Ob-viously , both scenarios allo w p ( x ) to be estimated. However, the rst scenario also allo ws the constan t p ( s = 1) to be es-timated in an obvious way, while the case-con trol scenario does not. This di erence turns out to be crucial: it is pos-sible to estimate p ( y = 1) only in the rst scenario.
The goal is to learn a function f ( x ) suc h that f ( x ) = p ( y = 1 j x ) as closely as possible. We call suc h a function f a traditional probabilistic classi er. Without some as-sumption about whic h positiv e examples are lab eled, it is imp ossible to mak e progress towards this goal. Our basic assumption is the same as in previous researc h: that the lab eled positiv e examples are chosen completely randomly from all positiv e examples. What this means is that if y = 1, the probabilit y that a positiv e example is lab eled is the same constan t regardless of x . We call this assumption the \se-lected completely at random" assumption. Stated formally , the assumption is that Here, c = p ( s = 1 j y = 1) is the constan t probabilit y that a positiv e example is lab eled. This \selected completely at random" assumption is analogous to the \missing completely at random" assumption that is often made when learning from data with missing values [10, 17, 18]. Another way of stating the assumption is that s and x are conditionally indep enden t given y .

So, a training set is a random sample from a distribution p ( x; y; s ) that satis es Equations (1) and (2). Suc h a train-ing set consists of two subsets, called the \lab eled" ( s = 1) and \unlab eled" ( s = 0) sets. Supp ose we pro vide these two sets as inputs to a standard training algorithm. This algo-rithm will yield a function g ( x ) suc h that g ( x ) = p ( s = 1 j x ) appro ximately . We call g ( x ) a non traditional classi er. Our cen tral result is the follo wing lemma that sho ws how to ob-tain a traditional classi er f ( x ) from g ( x ).
 Lemma 1: Supp ose the \selected completely at random" assumption holds. Then p ( y = 1 j x ) = p ( s = 1 j x ) =c where c = p ( s = 1 j y = 1).
 Pro of: Remem ber that the assumption is p ( s = 1 j y = 1 ; x ) = p ( s = 1 j y = 1). Now consider p ( s = 1 j x ). We have that The result follo ws by dividing eac h side by p ( s = 1 j y = 1).
Although the pro of above is simple, the result has not been published before, and it is not obvious. The reason perhaps that the result is novel is that although the learning scenario has been discussed in man y previous pap ers, including [3, 5, 11, 26, 6], and these pap ers do mak e the \selected completely at random" assumption either explicitly or implicitly , the scenario has not previously been formalized using a random variable s to represen t the fact of an example being selected.
Sev eral consequences of the lemma are worth noting. First, f is an increasing function of g . This means that if the clas-si er f is only used to rank examples x according to the chance that they belong to class y = 1, then the classi er g can be used directly instead of f .

Second, f = g=p ( s = 1 j y = 1) is a well-de ned probabilit y f 1 only if g p ( s = 1 j y = 1). What this says is that g &gt; p ( s = 1 j y = 1) is imp ossible. This is reasonable because the \positiv e" (lab eled) and \negativ e" (unlab eled) training sets for g are samples from overlapping regions in x space. Hence it is imp ossible for any example x to belong to the \positiv e" class for g with a high degree of certain ty.
The value of the constan t c = p ( s = 1 j y = 1) can be estimated using a trained classi er g and a validation set of examples. Let V be suc h a validation set that is dra wn from the overall distribution p ( x; y; s ) in the same manner as the non traditional training set. Let P be the subset of examples in V that are lab eled (and hence positiv e). The estimator of p ( s = 1 j y = 1) is the average value of g ( x ) for x in P . Formally the estimator is e 1 = 1 n P x 2 P g ( x ) where n is the cardinalit y of P .

We shall sho w that e 1 = p ( s = 1 j y = 1) = c if it is the case that g ( x ) = p ( s = 1 j x ) for all x . To do this, all we need to sho w is that g ( x ) = c for x 2 P . We can sho w this as follo ws: A second estimator of c is e 2 = P x 2 P g ( x ) = P x 2 V This estimator is almost equiv alen t to e 1 , because where m is the cardinalit y of V .

A third estimator of c is e 3 = max x 2 V g ( x ). This estima-tor is based on the fact that g ( x ) c for all x .
Whic h of these three estimators is best? The rst estima-tor is exactly correct if g ( x ) = p ( s = 1 j x ) precisely for all x , but of course this condition nev er holds in practice. We can have g ( x ) 6 = p ( s = 1 j x ) for two reasons: because g is learned from a random nite training set, and/or because the family of mo dels from whic h g ( x ) is selected does not include the true mo del. For example, if the distributions of x given y = 0 and x given y = 1 are Gaussian with di eren t covariances, as in Section 4 below, then logistic regression can mo del p ( y = 1 j x ) and p ( s = 1 j x ) appro ximately , but not exactly . In the terminology of statistics, logistic regression is mis-sp eci ed in this case.

In practice, when g ( x ) 6 = p ( s = 1 j x ), the rst estimator is still the best one to use. Compared to the third estimator, it will have much lower variance because it is based on av-eraging over m examples instead of on just one example. It will have sligh tly lower variance than the second estimator because the latter is exp osed to additional variance via its denominator. Note that in principle any single example from P is sucien t to determine c , but that in practice averaging over all mem bers of P is preferable.
There is an alternativ e way of using Lemma 1. Let the p ( x; y; s ) is the overall distribution. To mak e notation more concise, write this as E [ h ]. We want an estimator of E [ h ] based on a non traditional training set of examples of the form h x; s i .

Clearly p ( y = 1 j x; s = 1) = 1. Less obviously , p ( y = 1 j x; s = 0) = p ( s = 0 j x; y = 1) p ( y = 1 j x ) By de nition
E [ h ] = Z The plugin estimate of E [ h ] is then the empirical average 1 m where and m is the cardinalit y of the training set. What this says is that eac h lab eled example is treated as a positiv e example with unit weigh t, while eac h unlab eled example is treated as a com bination of a positiv e example with weigh t p ( y = 1 j x; s = 0) and a negativ e example with complemen-tary weigh t 1 p ( y = 1 j x; s = 0). The probabilit y p ( s = 1 j x ) is estimated as g ( x ) where g is the non traditional classi er explained in the previous section.

There are two ways in whic h the result above on estimat-ing E [ h ] can be used to mo dify a learning algorithm in order to mak e it work with positiv e and unlab eled training data. The rst metho d is to express the learning algorithm so that it uses the training set only via the computation of averages, and then to use the result above to estimate eac h of these averages. The second metho d is to mo dify the learning al-gorithm so that training examples have individual weigh ts. Then, positiv e examples are given unit weigh t and unlab eled examples are duplicated; one cop y of eac h unlab eled example is made positiv e with weigh t p ( y = 1 j x; s = 0) and the other cop y is made negativ e with weigh t 1 p ( y = 1 j x; s = 0). This second metho d is the one used in exp erimen ts below. As a special case of the result above, consider h ( x; y ) = y . We obtain
E [ y ] = p ( y = 1) where n is the cardinalit y of the lab eled training set, and the sum is over the unlab eled training set. This result solv es an open problem iden ti ed in [26], namely how to estimate p ( y = 1) given only the type of non traditional training set considered here and the \selected completely at random" as-sumption.

There is an alternativ e way to estimate p ( y = 1). By de nition so The obvious estimator of p ( s = 1 ^ y = 1) is n=m , whic h yields the estimator for p ( y = 1). Note that both this estimator and (4) are greater than n=m , as is exp ected for p ( y = 1).

The exp ectation E [ y ] = p ( y = 1) is the prev alence of y among all x , both lab eled and unlab eled. The reason-ing above sho ws how to estimate this prev alence assum-x densit y. ing the single-training-set scenario. In the case-con trol sce-nario, where lab eled training examples are obtained sepa-rately from unlab eled training examples, it can be pro ved that p ( y = 1) cannot be iden ti ed [21].

The argumen ts of this section and the preceding one are deriv ations about probabilities, so they are only applicable to the outputs of an actual classi er if that classi er pro-duces correct probabilities as its output. A classi er that pro duces appro ximately correct probabilities is called well-calibrated. Some learning metho ds, in particular logistic re-gression, do give well-calibrated classi ers, even in the pres-ence of mis-sp eci cation and nite training sets. However, man y other metho ds, in particular naiv e Bayes, decision trees, and supp ort vector mac hines (SVMs), do not. For-tunately , the outputs of these other metho ds can typically be postpro cessed into calibrated probabilities.

The two most common postpro cessing metho ds for cali-bration are isotonic regression [25], and tting a one-dimen-sional logistic regression function [14]. We apply the latter metho d, whic h is often called Platt scaling, to SVM classi-ers in Section 5 below.
To illustrate the metho d prop osed in Section 2 above, we generate 500 positiv e data points and 1000 negativ e data points, eac h from a two-dimensional Gaussian as sho wn in Figure 1. We then train two classi ers: one using all the data, and one using 20% of the positiv e data as lab eled pos-itiv e examples, versus all other data as negativ e examples.
Figure 1 sho ws the ideal trained classi er as a large el-lipse. Eac h point on this ellipse has predicted probabilit y 0.5 of belonging to the positiv e class. The transformed non-traditional classi er is the small ellipse; the transformation follo wing Lemma 1 uses the estimate e 1 of p ( s = 1 j y = 1). Based on a validation set of just 20 lab eled examples, this estimated value is e 1 = 0 : 1928, whic h is very close to the true value 0.2. Although the two ellipses are visually di er-ent, they corresp ond closely in the area where both positiv e and negativ e data points have high densit y, so they represen t similar classi ers for this application.

Giv en a data point h x 1 ; x 2 i , both classi ers use the repre-tours p ( y = 1 j x ) = 0 : 5 to be quadratic sections, as they are in Figure 1. Expanding the input represen tation in this way is similar to using a nonlinear kernel with a supp ort vec-tor mac hine. Because the pro duct x 1 x 2 is not part of the input represen tation, the ellipses are constrained to be axis-parallel. Logistic regression with this input represen tation is therefore mis-sp eci ed, i.e. not capable of represen ting ex-actly the distributions p ( y = 1 j x ) and p ( s = 1 j x ). Analogous mis-sp eci cation is likely to occur in real-w orld domains.
One common real-w orld application of learning from pos-itiv e and unlab eled data is in documen t classi cation. Here we describ e exp erimen ts that use documen ts that are records from the SwissProt database.

We call the set of positiv e examples P . This set consists of 2453 records obtained from a specialized database named TCDB [15]. The set of unlab eled examples U consists of 4906 records selected randomly from SwissProt excluding its intersection with TCDB, so U and P are disjoin t. Domain kno wledge suggests that perhaps about 10% of the records in U are actually positiv e.

This dataset is useful for evaluating metho ds for learn-ing from positiv e and unlab eled examples because in pre-vious work we did in fact man ually iden tify the subset of actual positiv e examples inside U ; call this subset Q . The pro cedure used to iden tify Q , whic h has 348 mem bers, is explained in [2]. Let N = U n Q so the cardinalit y of N is 4558. The three sets of records N , P , and Q are available at www.cs.ucsd.edu/users/elkan/posonly .

The P and U datasets were obtained separately , and U is a sample from the whole population, as opp osed to P [ U . Hence this exp erimen t is an example of the case-con trol scenario explained in Section 2, not of the single-training-set scenario. However, we can still apply the metho ds suggested in that section and evaluate their success. When applied in practice, P [ U will be all of SwissProt, so the scenario will be the single-training-set one.

Our exp erimen ts compare four approac hes: (i) standard learning from P [ Q versus N , (ii) learning from P ver-sus U with adjustmen t of output probabilities, (iii) learning from P and U after double weigh ting of U , and (iv) the bi-ased SVM metho d from [11] explained in Section 6 below. Approac h (i) is the baseline, that is the ideal: learning a standard classi er from fully lab eled positiv e and negativ e training sets. We exp ect its accuracy to be the highest; we hop e that approac hes (ii) and (iii) can achiev e almost as good accuracy . Approac h (iv) is the most successful metho d describ ed in previous researc h. To mak e comparisons fair, all four metho ds are based on soft-margin SVMs with linear kernels.

Eac h of the four metho ds yields a classi er that assigns numerical scores to test examples, so for eac h metho d we can plot its receiv er operating characteristic (ROC) curv e. Eac h metho d also has a natural threshold that can be used to con vert numerical scores into yes/no predictions for test examples. For metho ds (i) and (iii) this natural threshold is 0.5, since these metho ds yield scores that are well-calibrated probabilities. For metho d (iv) the natural threshold is zero, since this metho d is an SVM. For metho d (ii) the natural threshold is 0 : 5 c where c = p ( s = 1 j y = 1). As in Section 4 above, we use the estimator e 1 for c .

For eac h of the four metho ds, we do cross-v alidation with ten folds, and obtain a com bined confusion matrix from the ten testing subsets. With one confusion matrix for eac h approac h, we compute its recall and precision. All these num bers are exp ected to be somewhere around 95%. Cross-validation pro ceeds as follo ws. Partition P , Q , and N ran-domly into ten subsets eac h of size as equal as possible. For example Q will have eigh t subsets of size 35 and two of size 34. For eac h of the ten trials, reserv e one subset of P , Q , and N for testing. Use the other nine subsets of eac h for training. In every trial, eac h approac h gives one nal classi-er. In trial num ber i , this classi er is applied to the testing subsets P i , Q i , and N i , yielding a confusion matrix of the follo wing form: The com bined confusion matrix rep orted for eac h approac h has entries a = P 10 i =1 a i etc. In this matrix a is the num ber of true positiv es, b is the num ber of false negativ es, c is the num ber of false positiv es, and d is the num ber of true negativ es. Finally , precision is de ned as p = a= ( a + c ) and recall as r = a= ( a + b ).

The basic learning algorithm for eac h metho d is an SVM with a linear kernel as implemen ted in libSVM [9]. For ap-proac h (ii) we use Platt scaling to get probabilit y estimates whic h are then adjusted using Lemma 1. For approac h (iii) we run libSVM twice. The rst run uses Platt scaling to get probabilit y estimates, whic h are then con verted into weigh ts follo wing Equation (3) at the end of Section 3. Next, these weigh ts are used for the second run. Although the ocial version of libSVM allo ws examples to be weigh ted, it re-quires all examples in one class to have the same weigh t. We use the mo di ed version of libSVM by Ming-W ei Chang and Hsuan-Tien Lin, available at www.csie.ntu.edu.tw/-cjlin/libsvmtools/#15 , that allo ws di eren t weigh ts for di eren t examples.

For approac h (iv) we run libSVM man y times using vary-ing weigh ts for the negativ e and unlab eled examples. The details of this metho d are summarized in Section 6 below and are the same as in the pap er that prop osed the metho d orig-inally [11]. With this approac h di eren t weigh ts for di eren t examples are not needed, but a validation set to choose the best settings is needed. Giv en that the training set in eac h trial consists of 90% of the data, a reasonable choice is to use 70% of the data for training and 20% for validation in eac h trial. After the best settings are chosen in eac h trial, libSVM is rerun using all 90% for training, for that trial. Note that di eren t settings may be chosen in eac h of the ten trials.
 The results of running these exp erimen ts are sho wn in Table 5. Accuracies and F1 scores are calculated by thresh-olding trained mo dels as describ ed above, while areas under the ROC curv e do not dep end on a speci c threshold. \Rel-ativ e time" is the num ber of times an SVM must be trained for one fold of cross-v alidation.

As exp ected, training on P [ Q versus N , metho d (i), per-forms the best, measured both by F1 and by area under the better, only the imp ortan t part of the ROC space is sho wn. ROC curv e. However, this is the ideal metho d that requires kno wledge of all true lab els. Our two metho ds that use only positiv e and unlab eled examples, (ii) and (iii), perform bet-ter than the curren t state-of-the-art, whic h is metho d (iv). Although metho ds (ii) and (iv) yield almost the same area under the ROC curv e, Figure 2 sho ws that the ROC curv e for metho d (ii) is better in the region that is imp ortan t from an application persp ectiv e. Metho d (iv) is the slowest by far because it requires exhaustiv e searc h for good algorithm settings. Since metho ds (ii) and (iii) are mathematically well-principled, no searc h for algorithm settings is needed.
The new metho ds (ii) and (iii) do require estimating c = p ( s = 1 j y = 1). We do this with the e 1 estimator describ ed in Section 2. Because of cross-v alidation, a di eren t estimate e is computed for eac h fold. All these estimates are within 0.15% of the best estimate we can mak e using kno wledge of the true lab els, whic h is p ( s = 1 j y = 1) = j P j j P [ Q j
Consider the ROC curv es in Figure 2; note that only part of the ROC space is sho wn in this gure. Eac h of the four curv es is the result of one of the four metho ds. The points highligh ted on the curv es sho w the false positiv e/true posi-tive trade-o at the thresholds describ ed above. While the di erences in the ROC curv es may seem small visually , they represen t a substan tial practical di erence. Supp ose that a human exp ert will tolerate 100 negativ e records. This is represen ted by the blac k line in Figure 2. Then the exp ert will miss 9.6% of positiv e records using the biased SVM, but only 7.6% using the rew eigh ting metho d, whic h is a 21% re-duction in error rate, and a di erence of 55 positiv e records in this case.
Sev eral dozen pap ers have been published on the topic of learning a classi er from only positiv e and unlab eled training examples. Tw o general approac hes have been prop osed pre-viously . The more common approac h is (i) to use heuristics to iden tify unlab eled examples that are likely to be negativ e, and then (ii) to apply a standard learning metho d to these examples and the positiv e examples; steps (i) and (ii) may be iterated. Papers using this general approac h include [24, 20, 23], and the idea has been redisco vered indep enden tly a few times, most recen tly in [22, Section 2.4]. The approac h is sometimes extended to iden tify also additional positiv e ex-amples in the unlab eled set [6]. The less common approac h is to assign weigh ts someho w to the unlab eled examples, and then to train a classi er with the unlab eled examples interpreted as weigh ted negativ e examples. This approac h is used for example by [8, 12].

The rst approac h can be view ed as a special case of the second approac h, where eac h weigh t is either 0 or 1. The second approac h is similar to the metho d we suggest in Sec-tion 3 above, with three imp ortan t di erences. First, we view eac h unlab eled example as being both a weigh ted neg-ativ e example and a weigh ted positiv e example. Second, we pro vide a principled way of choosing weigh ts, unlik e previ-ous pap ers. Third, we assign di eren t weigh ts to di eren t unlab eled examples, whereas previous work assigns the same weigh t to every unlab eled example.

A good pap er that evaluates both traditional approac hes, using soft-margin SVMs as the underlying classi ers, is [11]. The nding of that pap er is that the approac h of heuris-tically iden tifying likely negativ e examples is inferior. The weigh ting approac h that is sup erior solv es the follo wing SVM optimization problem: sub ject to y i ( w x + b ) 1 z i and z i 0 for all i: Here P is the set of lab eled positiv e training examples and U is the set of unlab eled training examples. For eac h example i the hinge loss is z i . In order to mak e losses on P be penalized more hea vily than losses on U , C P &gt; C U . No direct metho d is suggested for setting the constan ts C P and C U . Instead, a validation set is used to select empirically the best values of C
P and C U from the ranges C U = 0 : 01 ; 0 : 03 ; 0 : 05 ; : : : ; 0 : 61 and C P =C U = 10 ; 20 ; 30 ; : : : ; 200. This metho d, called bi-ased SVM, is the curren t state-of-the-art for learning from only positiv e and unlab eled documen ts. Our results in the previous section sho w that the two metho ds we prop ose are both sup erior.

The assumption on whic h the results of this pap er dep end is that the positiv e examples in the set P are selected com-pletely at random. This assumption was rst made explicit by [3] and has been used in sev eral pap ers since, including [5]. Most algorithms based on this assumption need p ( y = 1) to be an additional input piece of information; a recen t pa-per emphasizes the imp ortance of p ( y = 1) for learning from positiv e and unlab eled data [4]. In Section 3 above, we sho w how to estimate p ( y = 1) empirically .

The most similar previous work to ours is [26]. Their approac h also mak es the \selected completely at random" assumption and also learns a classi er directly from the pos-itiv e and unlab eled sets, then transforms its output follo w-ing a lemma that they pro ve. Tw o imp ortan t di erences are that they assume the outputs of classi ers are binary as op-posed to being estimated probabilities, and they do not sug-gest a metho d to estimate p ( s = 1 j y = 1) or p ( y = 1). Hence the algorithm they prop ose for practical use uses a validation set to searc h for a weigh ting factor, like the weigh ting meth-ods of [8, 12], and like the biased SVM approac h [11]. Our prop osed metho ds are orders of magnitude faster because correct weigh ting factors are computed directly .

The task of learning from positiv e and unlab eled examples can also be addressed by ignoring the unlab eled examples, and learning only from the lab eled positiv e examples. In-tuitiv ely, this type of approac h is inferior because it ignores useful information that is presen t in the unlab eled exam-ples. There are two main approac hes of this type. The rst approac h is to do probabilit y densit y estimation, but this is well-kno wn to be a very dicult task for high-dimensional data. The second approac h is to use a so-called one-class SVM [16, 19]. The aim of these metho ds is to mo del a re-gion that con tains most of the available positiv e examples. Unfortunately , the outcome of these metho ds is sensitiv e to the values chosen for tuning parameters, and no good way is kno wn to set these values [13]. Moreo ver, the biased SVM metho d has been rep orted to do better exp erimen tally [11].
The cen tral con tribution of this pap er is Lemma 1, whic h sho ws that if positiv e training examples are lab eled at ran-dom, then the conditional probabilities pro duced by a mo del trained on the lab eled and unlab eled examples di er by only a constan t factor from the conditional probabilities pro duced by a mo del trained on fully lab eled positiv e and negativ e ex-amples.

Follo wing up on Lemma 1, we sho w how to use it in two di eren t ways to learn a classi er using only positiv e and unlab eled training data. We apply both metho ds to an im-portan t biomedical classi cation task whose purp ose is to nd new data instances that are relev ant to a real-w orld molecular biology database. Exp erimen tally , both metho ds lead to classi ers that are both hundreds of times faster and more accurate than the curren t state-of-the-art SVM-based metho d. These ndings hold for four di eren t de nitions of accuracy: area under the ROC curv e, F1 score or error rate using natural thresholds for yes/no classi cation, and recall at a xed false positiv e rate that mak es sense for a human exp ert in the application domain. This researc h is funded by NIH gran t GM077402. Tingfan Wu pro vided valuable advice on using libSVM. [1] B. Boeckmann, A. Bairo ch, R. Apweiler, M. Blatter, [2] S. Das, M. H. Saier, and C. Elk an. Finding transp ort [3] F. Denis. PAC learning from positiv e statistical [4] F. Denis, R. Gilleron, and F. Letouzey . Learning from [5] F. Denis, R. Gilleron, and M. Tommasi. Text [6] G. P. C. Fung, J. X. Yu, H. Lu, and P. S. Yu. Text [7] M. Galp erin. The Molecular Biology Database [8] W. S. Lee and B. Liu. Learning with positiv e and [9] H.-T. Lin, C.-J. Lin, and R. C. Weng. A note on [10] R. J. A. Little and D. B. Rubin. Statistic al Analysis [11] B. Liu, Y. Dai, X. Li, W. S. Lee, and P. S. Yu. [12] Z. Liu, W. Shi, D. Li, and Q. Qin. Partially sup ervised [13] L. M. Manevitz and M. Yousef. One-class SVMs for [14] J. C. Platt. Probabilities for SV mac hines. In A. J. [15] M. H. Saier, C. V. Tran, and R. D. Barab ote. TCDB: [16] B. Sch  X  olkopf, J. C. Platt, J. Sha we-T aylor, A. J. [17] A. Smith and C. Elk an. A Bayesian net work [18] A. Smith and C. Elk an. Making generativ e classi ers [19] D. M. J. Tax and R. P. W. Duin. Supp ort vector data [20] C. Wang, C. Ding, R. F. Meraz, and S. R. Holbro ok. [21] G. Ward, T. Hastie, S. Barry , J. Elith, and J. R. [22] F. Wu and D. S. Weld. Autonomously seman tifying [23] H. Yu. Single-class classi cation with mapping [24] H. Yu, J. Han, and K. C.-C. Chang. PEBL: Web page [25] B. Zadrozn y and C. Elk an. Transforming classi er [26] D. Zhang and W. S. Lee. A simple probabilistic
