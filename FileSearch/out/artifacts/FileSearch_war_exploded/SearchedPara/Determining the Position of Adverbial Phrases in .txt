 The job of a surface realizer is to transform an input semantic/syntactic form into a sequence of words. This task includes word choice, and word and con-stituent ordering. In English, the positions of re-quired elements of a sentence, verb phrase or noun phrase are relatively fixed. However, many sen-tences also include adverbials whose position is not fixed (Figure 1). There may be several appropriate positions for an adverbial in a particular context, but other positions give output that is non-idiomatic or disfluent, ambiguous, or incoherent.

Some computational research has included mod-els for adjunct ordering (e.g. (Ringger et al., 2004; Marciniak and Strube, 2004; Elhadad et al., 2001)). However, this is the first computational study to look specifically at adverbials. Adverbial positioning has long been studied in linguistics (e.g. (Keyser, 1968; Allen and Cruttenden, 1974; Ernst, 1984; Haider, 2000)). Most linguistic research focuses on whether adverbial placement is functional or semantic in na-ture. However, Costa (2004) takes a more flexi-ble feature-based approach that uses: lexical fea-tures (e.g. phonological shape, ambiguity of mean-ing, categorical status); syntactic features (e.g. pos-sible adjunction sites, directionality of adjunction, domain of modification); and information structure features (e.g. focus, contrast). We decided to evalu-ate Costa X  X  approach computationally, using features automatically extracted from an annotated corpus.
In this paper, we compare three approaches to ad-verbial positioning: a simple baseline approach us-ing lexical and syntactic features, and one-and two-stage classification-based approaches using lexical, syntactic, semantic and sentence-level features. We apply these approaches in a hybrid surface realizer that uses a probabilistic grammar to produce real-ization alternatives, and a second-stage classifier to select among alternatives. We find that: (a) One-and two-stage classification-based approaches can achieve almost 86% accuracy in determining the ab-solute position of adverbials; (b) A classifier trained with only syntactic features gives performance close to that of a classifier trained with all features; and (c) A surface realizer using a two-stage classifier for ad-verbial positioning can get improvements of at least 10% in simple string accuracy over a baseline real-izer for sentences containing adverbials.

As well as being useful for surface realization, a model of adverbial ordering can be used in machine translation (e.g. (Ogura et al., 1997)), language learning software (e.g. (Leacock, 2007; Burstein et al., 2004)), and automatic summarization (e.g. (El-hadad et al., 2001; Clarke and Lapata, 2007; Mad-nani et al., 2007)). From the sentences in the Wall Street Journal (WSJ) and Switchboard (SWBD) sections of the Penn Treebank III (Marcus et al., 1999), we extracted all NP, PP and ADVP phrases labeled with the adver-bial tags -BNF, -DIR, -EXT, -LOC, -MNR, -PRP, -TMP or -ADV. These phrases mostly modify S con-stituents (including RRC, S, SBAR, SBARQ, SINV, SQ), VP constituents, or NP constituents (includ-ing NP and WHNP), but also modify other adjuncts (PP, ADJP or ADVP) and other phrase types (FRAG, INTJ, LST, NAC, PRT, QP, TOP, UCP, X).

For each adverbial, we automatically extracted lexical, syntactic, semantic and discourse features. We included features similar to those in (Costa, 2004) and from our own previous research on prepo-sitional phrase ordering (Zhong and Stent, 2008). Due to the size of our data set, we could only use features that can be extracted automatically, so some features were approximated. We dropped adverbials for which we could not get features, such as empty adverbials. Tables 1 and 2 summarize the resulting data. A list of the features we used in our classifi-cation experiment appears in Table 3. We withheld 10% of this data for our realization experiment. Our goal is to determine the position of an adverbial with respect to its siblings in the phrase of which it is a part. An adverbial may have non-adverbial sib-lings, whose position is typically fixed. It may also have other adverbial siblings. In the sentence in Fig-ure 1, at your bank has one adverbial and two non-adverbial siblings. If this adverbial were placed at positions VP:0 or VP:1 the resulting sentence would be disfluent but meaningful; placed at position VP:2 the resulting sentence is fluent, meaningful and id-iomatic. (In this sentence, both orderings of the two adverbials at position VP:2 are valid.) 3.1 Approaches We experimented with three approaches to adverbial positioning.
 Baseline Our baseline approach has two stages. In the first stage the position of each adverbial with respect to its non-adverbial siblings is determined: each adverbial is assigned the most likely position given its lexical head and category (PP, NN, ADVP). In the second stage, the relative ordering of adjacent adverbials is determined in a pairwise fashion (cf. (Marciniak and Strube, 2004)): the ordering of a pair of adverbials is assigned to be the most frequent in the training data, given the lexical head, adverbial phrase type, and category of each adverbial. One-stage For our one-stage classification-based approach, we determine the position of all adver-bials in a phrase at one step. There is one feature vector for each phrase containing at least one adver-bial. It contains features for all non-adverbial sib-lings in realization order, and then for each adverbial sibling in alphabetical order by lexical head. The la-bel is the order of the siblings. For example, for the S-modifying adverbial in Figure 1, the label would be 2 0 1, where 0 =  X  X he X , 1 =  X  X ashed X  and 2 =  X  X hen X . If there are n siblings, then there are n ! possible labels for each feature vector, so the perfor-mance of this classifier by chance would be .167 if each adverbial has on average three siblings. Two-stage For our two-stage classification-based approach, we first determine the position of each ad-verbial in a phrase in relation to its non-adverbial siblings, and then the relative positions of adjacent adverbials. For the first stage we use a classifier. There is one feature vector for each adverbial. It contains features for all non-adverbial siblings in re-alization order, then for each adverbial sibling in al-phabetical order by lexical head, and finally for the target adverbial itself. The label is the position of the target adverbial with respect to the non-adverbial siblings. For our example sentence in Figure 1, the label for  X  X hen X  would be 0; for  X  X t the bank X  would be 2, and for  X  X n Tuesday X  would be 2. If there are n non-adverbial siblings, then there are n + 1 possible labels for each feature vector, so the performance of this classifier by chance would be .25 if each adver-bial has on average three non-adverbial siblings.
For the second stage we use the same second stage as the baseline approach. 3.2 Method We use 10-fold cross-validation to compute perfor-mance of each approach. For the classifiers, we used the J4 decision tree classifier provided by Weka 1 We compute correctness for each approach as the percentage of adverbials for which the approach out-puts the same position as that found in the original human-produced phrase. (In some cases, multiple positions for the adverbial would be equally accept-able, but we cannot evaluate this automatically.) 3.3 Results Our classification results are shown in Table 4. The one-and two-stage approaches both significantly outperform baseline. Also, the two-stage approach outperforms the one-stage approach for WSJ.

The decision trees using all features are quite large. We tried dropping feature sets to see if we could get smaller trees without large drops in per-formance. We found that for all data sets, the models containing only syntactic features perform only about 1% worse for one-stage classification and only about 3% worse for two-stage classification, while in most cases giving much smaller trees (1015 [WSJ] and 972 [SWBD] nodes for the one-stage ap-proach; 1008 [WSJ] and 877 [SWBD] for the two-stage approach). This is somewhat surprising given Costa X  X  arguments about the need for lexical and dis-course features; it may be due to errors introduced by approximating discourse features automatically, as well as to data sparsity in the lexical features.
There are only small performance differences be-tween the classifiers for speech and those for text. To investigate how a model of adverbial position-ing may improve an NLP application, we incorpo-rated our best-performing models into a surface re-alizer. We automatically extracted a probabilistic lexicalized tree-adjoining grammar from the whole WSJ and SWBD corpora minus our held-out data, using the method described in (Zhong and Stent, 2005). We automatically re-realized all adverbial-containing sentences in our held-out data (10%), af-ter first automatically constructing input using the method described in (Zhong and Stent, 2005).
We compute realization performance using sim-ple string accuracy (SSA) 2 . Realization performance is reported in Table 4. Both classification-based ap-proaches outperform baseline, with the two-stage approach performing best for WSJ with either met-ric (for SWBD, the classification-based approaches perform similarly). In this paper, we tested classification-based ap-proaches to adverbial positioning. We showed that we can achieve good results using syntactic features alone, with small improvements from adding lexi-cal, semantic and sentence-level features. We also showed that use of a model for adverbial position-ing leads to improved surface realization. In future work, we plan a human evaluation of our results to see if more features could lead to performance gains. This research was partially supported by the NSF under grant no. 0325188.
