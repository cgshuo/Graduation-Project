 To benchmark and rate a data store, one must repeat exper-iments that impose a different amount of load on the data store. Workloads that modify the benchmark database may require the same database to be loaded repeatedly. This may constitute a significant portion of the time to rate a data store. This paper presents several agile data loading techniques to expedite the rating process. These techniques include generating the disk image of the database once and re-using it, restoring the updated data items to their orig-inal value, maintaining in-memory state of the database across different experiments to avoid repeated loading of the database all together, and a hybrid of the third technique in combination with the other two. These techniques are gen-eral purpose and apply to a variety of cloud benchmarks. We investigate their implementation and evaluation in the context of one, the BG benchmark. Obtained results show a factor of two to twelve speedup in the rating process. As an example, when evaluating MongoDB with a million mem-ber BG database, we show these techniques expedite BG X  X  rating from 4 months (123 days) of continuous running to less than 11 days for the first rating experiment. Subsequent ratings of MongoDB with different workloads using the same database is much faster, in the order of hours.
 I.1.3 [ Computing Methodologies ]: Languages and Sys-tems X  Evaluation Strategies ; H.3.4 [ Information Systems Applications ]: Systems and Software X  Performance eval-uation(efficiency and effectiveness) Experimentation, Measurement Cloud benchmarks, Data stores, Data loading, Rating Cloud benchmarks such as YCSB [9], YCSB++ [17] and BG [3] are used to evaluate data stores. A data store is an object repository with a specific data model such as key-value, relational and other data models. See [8] for a survey. With realistic workloads and large data set sizes, the time to load the data store prior to the rating experiment may con-stitute a significant portion of the execution time [20, 21]. As an example, the time to load a modest sized BG database consisting of 10,000 members with 100 friends and 100 re-sources per member is 2 minutes with MongoDB. With an industrial strength relational database management system (RDBMS) using the same hardware platform, this time in-creases to 7 minutes. With MySQL, this time is 15 minutes.
To quantify the processing capability (throughput) of a data store with a workload, one repeats experiments that impose a different amount of load on the data store. With YCSB, YCSB++, and BG, the number of threads ( T ) con-trols the amount of imposed load. A higher value of T means the benchmark is generating a higher load. With those workloads that change the state of the database (its quired to destroy and reconstruct the database at the begin-ning of each experiment to obtain meaningful results. For example, Workload D of YCSB inserts new records into a data store, increasing the database size. Use of this work-load across different experiments with a different number of threads causes each experiment to impose its workload on a larger database size. If the data store becomes slower as a function of the database size then the observed trends can-not be attributed to the different amount of offered load ( T ) solely. Instead, they must be attributed to both a changing database size (difficult to quantify) and the offered load. To avoid this ambiguity, one must recreate the same database at the beginning of each experiment. This repeated loading of the same database may constitute a significant portion of the rating process, motivating this study of agile data load techniques to expedite the rating mechanism. some users having a larger number of friends compared to the others. Use of this kind of a workload across different back to back experiments results in each experiment to im-pose its workload on a different data set. store, the underlying storage space of the data store may change from the initial state in such a way that performance of an experiment may differ greatly from a previously exe-cuted experiment. Table 1: A BG workload consisting of a mix of social net working actions.
 These techniques are as follows. The first technique, named Database Image Loading, DBIL , relies on the capability of a data store to create a disk image of the database. DBIL uses this image repeatedly across different experiments. The sec-ond technique, named RepairDB , restores the database to its original state prior to the start of an experiment. Our proposed implementation of RepairDB is agnostic to a data store and does not require a database recovery technique. Depending on the percentage of writes and the data store characteristics, RepairDB may be slower than DBIL.
The third technique, named LoadFree , does not load the database in between experiments. Instead, it requires the benchmarking framework to maintain the state of the database in its memory across different experiments. In order to use LoadFree, the workload and its target data store must sat-isfy several conditions. One requirement is for the workload to be symmetric: It must issue write actions that negate one another in the long run. An example symmetric workload with BG issues Thaw Friendship (TF) action as frequently as Invite Friend (IF) and Accept Friend Request (AFR). The TF action negates the other two actions across repeated ex-periments. This prevents both an increased database size and the possible depletion of the benchmark database from friendship relationships to thaw. See Section 5 for other conditions that govern the use of LoadFree.

In scenarios where LoadFree cannot be used for the entire rating of a data store, it might be possible to use LoadFree in several experiments and restore the database using either DBIL or RepairDB. The benchmarking framework may use this hybrid approach until it rates its target data store. Sec-tion 6 shows the hybrid approaches provide a factor of five to twelve speedup in rating a data store.

The primary contribution of this paper is several agile data loading techniques for use with the cloud benchmarks. We describe an implementation of each with BG.

Related work: The overhead of loading a benchmark database is a recognized topic by practitioners dating back to Wiscon-sin Benchmark [6, 10] and 007 [7, 20, 21], and by YCSB [9] and YCSB++ [17] more recently. YCSB++ [17] describes a bulk loading technique that utilizes the high throughput tool of a data store to directly process its generated data and store it in an on-disk format native to the data store. This is similar to our DBIL technique. DBIL is different in two ways. First, DBIL does not require a data store to provide such a tool. Instead, it assumes the data store pro-vides a tool that creates the disk image of the benchmark database once its loaded onto the data store for the very first time. This image is used in subsequent experiments. Second, DBIL accommodates complex schemas similar to BG X  X  schema. Both RepairDB and LoadFree are novel and apply to data stores that do not support either the high throughput tool of YCSB++ or the disk image generation tool of DBIL. They may be adapted and applied to other benchmarking frameworks that rate a data store similar to BG.

The rest of the paper is organized as follows. Section 2 provides an overview of the rating framework. Subsequently, Section 3 through 5 use this framework to detail the 3 tech-niques in turn. We evaluate these techniques in Section 6. Brief conclusion and future research direction are presented in Section 7.
This section provides an overview of BG X  X  framework to rate a data store. This framework is general purpose and can be used in combination with both YCSB and YCSB++. This description concludes this section.

BG [3] rates a data store for processing interactive so-cial networking actions. It computes either a Social Action Rating (SoAR) or a Socialites rating of a data store given a pre-specified service level agreement (SLA). An example SLA may require 95% of actions that constitute a work-load to be performed faster than 100 msec with no more than 0.1% unpredictable data for 20 minutes. SoAR is the highest throughput of a data store that satisfies this SLA. Socialites is the highest number of threads that satisfies this SLA.

Table 1 shows the eleven social actions and their frequency of occurrence for a workload used in this paper. These sim-ple actions either read or write a small amount of data from a BG database. This database starts with M members, each with  X  friends and  X  resources. The write actions of a workload may modify the friendship relationship between members, post comments on resources, or both.

BG scales to a large number of nodes using a shared-nothing architecture to rate the fastest data stores. It does so by logically dividing a social network into N unique com-munities and assigning each to a different BGClient process. After the first loading of the database, our decentralized implementation [3, 4] enables each BGClient to either use LoadFree by maintaining an in-memory state of its unique assigned community or use DBIL/RepairDB to restore the database to its original state prior to each rating experiment. In addition, it enables each BGClient to either create or gen-erate a workload for its unique community independently. A coordinator, BGCoord, issues commands to BGClients to ei-ther create BG X  X  schema, construct a database and load it, or generate a workload for the data store. A BGListener on each node facilitates communication between BGCoord and its spawned BGClient. One may host multiple BGListeners on different ports on a node. A configuration file informs the BGCoord of the different BGListeners and their ports. (It is possible to extend BGClient with the functionality provided by BGListener to eliminate the BGListener all together, see Section 7.)
BGCoord conducts several experiments, each with a fixed number of threads T , to compute the SoAR and Socialites rating of a data store. With the SoAR rating, BGCoord uses heuristic search to control the value of T . In [3], we provide details and show the number of conducted experi-ment s is a function of the true SoAR rating of the data store. When this value is in the order of a few thousands, BGCoord value is in the order of one hundred million, BGCoord may conduct between 50 to 60 unique experiments. The next 3 sections describe three different approaches to expedite the rating process.
 To adapt this framework for use with both YCSB and YCSB++, one may relax BG X  X  SLA by specifying a high tolerable response time, e.g. max integer. This is because both YCSB and YCSB++ lack the concept of SLA. In ad-dition, extra software is required to communicate the ob-and their respective BGListener. This enables BGCoord to gather the throughput observed by each client to compute the overall throughput observed from a data store.
Various data stores provide specialized interfaces to create a  X  X isk image X  of the database [16]. Ideally, the data store should provide a high-throughput external tool [17] that the benchmarking framework employs to generate the disk im-age. Our target data stores (MongoDB, MySQL, an indus-a tool. Hence, our proposed technique first populates the data store with benchmark database and then generates its disk image. This produces one or more files (in one or more folders) stored in a file system. A new experiment starts by shutting down the data store, copying the files as the database for the data store, and restarting the data store. This technique is termed Database Image Loading, DBIL . In our experiments, it improved the load time of MongoDB with 1 million members with 100 friends and 100 resources per member by more than a factor of 400.

With DBIL, the load time depends on how quickly the system copies the files pertaining to the database. One may expedite this process using multiple disks, a RAID disk sub-system, a RAM disk or even flash memory. We defer this analysis to future work. Instead, in the following, we assume a single disk and focus on software changes to implement DBIL using BG.

Our implementation of DBIL utilizes a disk image when it is available. Otherwise, it first creates the database using it creates the disk image of the database for future use. Its implementation details are specific to a data store. Below, we present the general framework. For illustration purposes, we describe how this framework is instantiated in the context of MongoDB. At the time of this writing, an implementa-tion of the general framework is available with MongoDB, MySQL and SQL-X.

We implemented DBIL by extending BGCoord and intro-ducing a new slave component that runs on each server node looks up their observed throughput when the heuristic search attempts to repeat an experiment with the same T value. of this system. ship. With YCSB, this method is insert. (shard) hosting an instance of the data store. (The BGClient and BGListener are left unchanged.) The new component is named DBImageLoader and communicates with BGCoord using sockets. It performs operating system specific actions such as copy a file, and shutdown and start the data store instance running on the local node.

When BGCoord loads a data store, it is aware of the nodes employed by the data store. It contacts the DBImageLoader of each node with the parameters specified by the load con-figuration file such as the number of members ( M ), number of friends per member(  X  ), number of BGClients ( N ), num-ber of threads used to create the image ( T Load ), etc. The DBImageLoader uses the values specified by the parameters to construct a folder name containing the different folders and files that correspond to a shard. It looks up this folder in a pre-specified path. If the folder exists, DBImageLoader recognizes its content as the disk image of the target store and proceeds to shutdown the local instance of the data store, copy the contents of the specified folder into the ap-propriate directory of the data store, and restarts the data store instance. With a sharded data store, the order in which the data store instances are populated and started may be important. It is the responsibility of the programmer to specify the correct order by implementing the  X  X ultiShard-Load X  method of BGCoord. This method issues a sequence of actions to the DBImageLoader of each server to copy the appropriate disk images for each server and start the data store server.

As an example, a sharded MongoDB instance consists of one or more Configuration Servers, and several Mongos and Mongod instances [15]. The Configuration Servers main-tain the metadata (sharding and replication information) used by the Mongos instances to route queries and perform write operations. It is important to start the Configura-tion Servers prior to Mongos instances. Next, the shards (Mongod instances) are attached to the data store cluster. The programmer specifies this sequence of actions by imple-menting  X  X ultiShardStart X  and  X  X ultiShardStop X  methods of BGCoord.
Repair Database, RepairDB , marks the start of an exper-iment ( T Start ) and, at the end of the experiment, it em-ploys the point-in-time recovery [14, 13] mechanism of the data store to restore the state of the database to its state at T
Start . This enables the rating mechanism to conduct the next experiment as though the previous benchmark database was destroyed and a new one was created. It is appropriate for use with workloads consisting of infrequent write actions. It expedites the rating process as long as the time to restore the database is faster than destroying and re-creating the same database.

In our experiments (see Section 6), RepairDB was consis-tently slower than DBIL. Hence, RepairDB is appropriate for use with those data stores that do not provide a DBIL feature (or with those experiments where RepairDB is faster than DBIL).

With those data stores that do not provide a point-in-time recovery mechanism, the benchmarking framework may implement RepairDB. Below, we focus on BG and describe two alternative implementations of RepairDB. Subsequently, we extend the discussion to YCSB and YCSB++. Table 2: Factor of improvement in load times with Re pairDB when compared with re-creating the entire database, target data store is MongoDB, M =100K,  X  =100.

The write actions of BG impact the friendship relation-ships between the members and post comments on resources. BG generates log records for these actions in order to de-phase at the end of an experiment. One may implement point-in-time recovery by using these log records (during validation phase) to restore the state of the database to the beginning of the experiment.

Alternatively, BG may simply drop existing friendships and posted comments and recreate friendships. When com-pared with creating the entire database, this eliminates re-constructing members and their resources at the beginning of each experiment. The amount of improvement is a func-tion of the number of friendships per member as the time to recreate friendship starts to dominate the database load time. Table 2 shows RepairDB improves the load time of member. This speedup is higher with fewer friends per mem-ber as RepairDB is rendered faster.

BG X  X  implementation of RepairDB must consider two im-portant details. First, it must prevent race conditions be-tween multiple BGClients. For example, with an SQL solu-tion, one may implement RepairDB by requiring BGClients to drop tables. With multiple BGClients, one succeeds while others encounter exceptions. Moreover, if one BGClient cre-ates friendships prior to another BGClient dropping tables then the resulting database will be wrong. We prevent un-desirable race conditions by requiring BGCoord to invoke only one BGClient to destroy the existing friendships and comments.

Second, RepairDB X  X  creation of friendships must consider the number ( N ) of BGClients used to create the self con-tained communities. Within each BGClient, the number of threads ( T load ) used to generate friendships simultaneously is also important. To address this, we implement BGCoord to maintain the original values of N and T load and to re-use them across the different experiments.

Extensions of YCSB and YCSB++ to implement RepairDB is trivial as they consist of one table. This implementation may use either the point-in-time recovery mechanism of a data store or generate log records similar to BG.
With Load Free, the rating framework uses the same database across different experiments as long as the correctness of each experiment is preserved. Below, we define correctness. Subsequently, we describe extensions of the framework of Section 2 to implement LoadFree.
Correctness of an experiment is defined by the following three criteria. First, the mix of actions performed by an experiment must match the mix specified by its workload. In particular, it is unacceptable for an issued action to be-come a no operation due to repeated use of the benchmark database. For example, with both YCSB and YCSB++, a delete operation must reference a record that exists in the database. It is unacceptable for an experiment to delete a record that we deleted in a previous experiment. A similar example with BG is when a database is created with 100 friends per member and the target workload issues Thaw Friendship (TW) more frequently than creating friendships (combination of Invite Friend and Accept Friend Request). This may cause BG to run out of the available friendships across several experiments using LoadFree. Once each mem-ber has zero friends, BG stops issuing TW actions as there exist no friendships to be thawed. This may introduce noise by causing the performance results obtained in one experi-ment to deviate from their true value. To prevent this, the workload should be symmetric such that the write actions negate one another. Moreover, the benchmarking framework must maintain sufficient state across different experiments to issue operations for the correct records.

Second, repeated use of the benchmark database should not cause the actions issued by an experiment to fail. As an example, workloads D and E of YCSB insert a record with a primary key in the database. It is unacceptable for the inserts to fail because a row with the same key exists. This is caused by repeated use of the benchmark database. Such failures pollute the response times observed from a data store as they do not perform the useful work (insert a record) intended by YCSB. To use LoadFree, the unique-ness of the primary key must be preserved across different experiments using the same database. One way to realize this is to require the core classes of YCSB to maintain suffi-cient state information across different experiments to insert unique records in each experiment.

Third, the database of one experiment should not impact the performance metrics computed by a subsequent exper-iment. In Section 1, we gave an example with YCSB and the database size impacting the observed performance. As another example, consider BG and its metric to quantify the amount of unpredictable reads. This metric pertains to read actions that observe either stale, inconsistent, or wrong data. For example, the design of a cache augmented data store may incur dirty reads [12] or suffer from race condi-tions that leave the cache and the database in an inconsis-tent state [11], a data store may employ an eventual con-sistency [19, 18] technique that produces either stale or in-consistent data for some time [17], and others. Once unpre-dictable data is observed, the in-memory state of database maintained by BG is no longer consistent with the state of the database maintained by the data store. This prevents BG from accurately quantifying the amount of stale data in a subsequent experiment. Hence, once unpredictable data is observed in one experiment, BG may not use LoadFree in a subsequent experiment. It must employ either DBIL or RepairDB to recreate the database prior to conducting additional experiments.

LoadFree is very effective in expediting the rating pro-cess (see Section 6) as it eliminates the load time between experiments. One may violate the above three aforemen-tioned criterion and still be able to use LoadFree for a BG wor kload. For example, a workload might be asymmetric by issuing Post Comment on a Resource (PCR) but not issuing Delete Comment from a Resource (DCR). Even though the workload is asymmetric and causes the size of the database to grow, if the data store does not slow down with a grow-ing number of comments (due to use of index structures), one might be able to use LoadFree, see Section 7. In the following, we detail BG X  X  implementation of LoadFree.
To implement LoadFree, we extend each BGClient to ex-ecute either in one time or repeated mode. With the for-mer, BGListener (see Section 2) starts the BGClient and the BGClient terminates once it has either executed for a number of requests [9, 17]. With the latter, once BGListener starts the BGClient, the BGClient does not terminate and maintains the state of its in-memory data structures that describe the state of the database. The BGListener relays commands issued by the BGCoord to the BGClient using sockets.
 commands to a BGClient (via BGListener): reset and shut-down. BGCoord issues the reset command when it detects a violation of the three aforementioned criteria for using Load-Free. The shutdown command is issued once BGCoord has completed the rating of a data store and has no additional experiments to run using the current database.

In between experiments identified by EOE commands is-sued by BGCoord, BGClient maintains the state of its in-memory data structures. These structures maintain the pending and confirmed friendship relationships between mem-bers along with the comments posted on resources owned by members. When an experiment completes, the state of these data structures is used to populate the data structures cor-responding to the initial database state for the next exper-iment. BGClient maintains both initial and final database state to issue valid actions (e.g., Member A should not ex-tend a friendship invitation to Member B if they are already friends) and quantify the amount of unpredictable data at the end of each experiment, see [3] for details.
This section quantifies the speedup observed with the pro-posed 3 techniques using the workload in Table 1. In ad-dition, we consider two hybrids: 1) LoadFree with DBIL and 2) LoadFree with RepairDB. These capture scenarios schema, load database and create index, Execute One Ex-periment (EOE), construct friendship and drop updates. The EOE command is accompanied by the number of threads and causes BG to conduct an experiment to mea-sure the throughput of the data store for its specified work-load (by BGCoord). The last two commands implement RepairDB. where one applies LoadFree for some of the experiments and reloads the database in between. In the following, we report on the observed speedup relative to not using the proposed techniques. Due to lack of space, we refer the interested reader to [2] for the analytical models used to compute the reported results and their discussion.

Table 3 shows the observed speedup for rating of Mon-goDB using three BG databases with different number of members. LoadFree provides the highest speedup followed by DBIL and RepairDB. The hybrid techniques follow the same trend with DBIL outperforming RepairDB. These re-sults suggest the following: Using the proposed techniques, we must enhance the performance of other components of BG to expedite its overall rating duration. (It is impossible to do better than a zero load time of LoadFree.) A strong candidate is the duration of each experiment conducted by BG. Another is to reduce the number of conducted experi-ments by enhancing BG X  X  heuristic search technique.
Reported trends with MongoDB hold true with both MySQL ble 4. While rating of SQL-X observes speedups comparable to MongoDB, MySQL observes a higher speedup because its database load time is significantly slower than the other two. This enables BG X  X  rating of MySQL to observe the highest speedups when compared with the na  X   X ve technique.
With social networking companies continuing to introduce novel data stores to meet their requirements for interac-tive social networking actions (e.g., Cassandra and TAO [1] by Facebook and Voldemort by LinkedIn), it is important to have effective benchmarks to empower the designers of these systems to evaluate the performance tradeoffs asso-ciated with their solutions. (See [5] for an example use of BG.) Cloud benchmarking frameworks are ideal for this pur-pose. In order to be effective, they must rate a data store quickly. This paper presented several data load techniques to speedup the rating duration for workloads that require re-peated loading of the benchmark database. One technique, DBIL, requires a data store to provide specialized interfaces to export the disk image of the database and to import it subsequently. In the absence of such interfaces, one may em-ploy RepairDB that is agnostic to the underlying data store. LoadFree eliminates loading of data in between experiments all together. However, certain conditions must hold true for its use, see Section 5 for details. One may use LoadFree in combination with the other two techniques.

Our future research directions are as follows. First, we are developing a methodology to enable use of a hybrid tech-nique (e.g., LoadFree+DBIL) with asymmetric workloads. The ideal methodology detects when LoadFree should not of this system. be employed by an experiment and switches to DBIL to ensure the integrity of the rating produced by the bench-marking framework. Second, we are analyzing an alternative implementation of RepairDB to improve its performance. It employs log records with additional metadata to undo write actions performed during an experiment and revert the database to its initial state. Third, based on our analysis of the observed speedup using Amdahl X  X  law (see discussions of Table 3), we are improving the other components of the rating framework to expedite its performance. Fourth, we are analyzing other techniques such as the bulk data loading technique of YCSB++ [17] that utilizes the high through-put tool of a data store to generate an on-disk format of the benchmark database native to the data store. This analysis includes intermediate formats such as a comma separated CSV file or batching of insertion statements when creating the benchmark database. Finally, we are investigating alter-native software architectures in order to reduce the number of components that constitute the rating framework with-out sacrificing its ease of use. An immediate candidate is to incorporate the functionality of the BGListener in the BGClient, eliminating the BGListener all together.
We thank the anonymous reviewers of CIKM 2013 for their insights and valuable comments. [1] Z. Amsden, N. Bronson, G. C. III, P. Chakka, [2] S. Barahmand and S. Ghandeharizadeh. Expedited [3] S. Barahmand and S. Ghandeharizadeh. BG: A [4] S. Barahmand and S. Ghandeharizadeh. D-Zipfian: A [5] S. Barahmand, S. Ghandeharizadeh, and J. Yap. A [6] D. Bitton, D. J. DeWitt, and C. Turbyfill.
 [7] M. J. Carey, D. J. DeWitt, and J. F. Naughton. The [8] R. Cattell. Scalable SQL and NoSQL Data Stores. [9] B. F. Cooper, A. Silberstein, E. Tam, [10] D. DeWitt, S. Ghandeharizadeh, D. Schneider, [11] S. Ghandeharizadeh and J. Yap. Gumball: A Race [12] P. Gupta, N. Zeldovich, and S. Madden. A [13] D. Lomet and F. Li. Improving Transaction-Time [14] D. Lomet, Z. Vagena, and R. Barga. Recovery from [15] MongoDB. Sharded Cluster Administration, [16] MongoDB. Using Filesystem Snapshots to Backup and [17] S. Patil, M. Polte, K. Ren, W. Tantisiriroj, L. Xiao, [18] M. Stonebraker. Errors in Database Systems, Eventual [19] W. Vogels. Eventually Consistent. Communications of [20] J. Wiener and J. Naughton. Bulk Loading into an [21] J. Wiener and J. Naughton. OODB Bulk Loading
