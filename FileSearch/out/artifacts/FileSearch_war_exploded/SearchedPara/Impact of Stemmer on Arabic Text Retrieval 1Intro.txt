 Nowadays, h u ndreds of millions of people en g a g es in information retrieval every day derived from information retrieval , X  X nformation retrieval (IR) is findin g material tion need from within lar g e collections ( u s u ally stored on comp u ters) X . Any Informa-res u lt, the retrieval effectiveness, and the speed of s u ccessf u l retrieval [2, 3]. effort was spent. B u t, this work and efforts still not s u fficient with what has been done more than 20 co u ntries. Arabic is also the lan gu a g e of the Holy Q u ran, the holy book across the g lobe [4, 5]. When s u bjected to morpholo g ical analysis, Arabic words are disambi gu ate the word  X  X erm  X  senses [7]. q u ery [8]. The term stemmin g refers to a conflation approach that attempts to find a com-proach, one stem for a g ro u p of words that are relevant in terms of havin g a related form from words, there are fo u r different approaches to Arabic, these approaches of stemmin g stemmers for Arabic lan gu a g e in information retrieval u sin g the standard information retrieval eval u ation as disc u ssed later in section 4.2. Hence, the idea of comparin g the three different Arabic stemmers is to shed the li g ht on its effect in increase the infor-mation retrieval effectiveness for Arabic doc u ments. 
The remainder of this paper is or g anized as follows. Section 2 reviews previo u s and an examination of performance meas u res. Section 5 presents the experimental and f u t u re work. The stemmin g of Arabic doc u ments was performed man u ally prior to the Text Re-trieval Conference (TREC) and only applied on small corpora. Later, many research-amo u nt of Arabic stemmin g al g orithms. Despite stemmin g errors, it has been empiri-lan gu a g es in terms of its syntax, morpholo g y, and semantics. Since the morpholo g ical nat u re of the Arabic lan gu a g e is complex, there is a wide of body of research on this (AIR). root-based[12] or stem-based [1], [13], [14]. In Arabic, the root is the ori g inal form of the word before any transformation process [5].However, a stem is a morpheme or a set of concatenated morphemes that can accep t an affix [15], A wide body of research searchers has been employed Khoja's stemmer, li g ht stemmer, N-g ram stemmin g , statistical stemmers, root-extraction stemmer and Lemmatization stemmer called the Ed u cated Text Stemmer (ETS), to improve performance of Arabic IR (Table 2 ill u -strate s u mmery of some u sed stemmers techniq u es). 3 X  and u ses pattern matchin g to extract the roots. However, the al g orithm s u ffers from problems especially with names and no u ns, on the other hand, there have been several proposed Arabic stem-based (li g ht) al g orithms [10, 17-20].The most widely u sed Arabic li g ht stemmer is li g ht10 developed by [18, 20]. Li g ht stemmin g does not deal with patterns or infixes; it is simply a process of strippin g off prefixes and/or s u ffixes. letter and a root letter. Altho ug h li g ht stemmers prod u ce fewer errors than a gg ressive root-based stemmers, a gg ressive stemmers red u ce the size of the corp u s si g nificantly. Both Arabic root-based and stem-based al g orithms s u ffer from stemmin g errors. The main ca u se of this problem is the stemmer  X  s lack of knowled g e of the word  X  s lexical cate g ory (e. g ., no u n, verb, and preposition). 10,000 independent roots [26], it is time cons u min g and not s u fficient to u se a dictio-nary to recover wron g ly stemmed words. The N-g ram stemmin g techniq u e is ineffec-tive for Arabic text processin g [21-23];The stem-based n-g rams g enerally o u tper-formed the word-based n-g rams. however, Khoja  X  s root-extraction stemmer [16] and alon g with statistical stemmers  X  wo u ld be able to handle all instances of co-occ u rrence in Arabic text retrieval. morpholo g ical stemmers, which deal with the root of each word. Additionally, [27] context-sensitive morpholo g y, on monolin gu al AIR. F u rthermore, comparative analy-sis of context-sensitive morpholo g y and non-context-sensitive morpholo g y fo u nd that the former is more effective in AIR than the latter; moreover, [24] state that employ-root; if not, it ret u rns the ori g inal word witho u t modifyin g it. tactic str u ct u re, Arabic morpholo g y in IR is aimed at findin g words with identical or relevant meanin g s. F u rthermore, it has been identified that by means of indexin g Arabic text, the efficiency of retrievin g words or stems can be s u bstantially increased li g ht13 improvin g recall si g nificantly when u sin g relevance feedback over the TREC and Arabic Gi g aWord collections. 
Lemmatization is an advanced stemmin g process that involves the u sa g e of voca-to their stem, base, or root, g enerally from a written word form. Recently, [9] a new Arabic lemmatizer has been developed that has a hi g h ran g e of acc u racy; it u ses syn-tactical knowled g e to make stemmin g decisions. [9] proposes an Arabic advance stemmer called the Ed u cated Text Stemmer (ETS), which u ses the [16] and [20] root-based stemmers. The Khoja method u ses a root-base stemmer that removes s u ffixes, infixes, and prefixes (as mentioned above in Table 3) b u t also u ses pattern matchin g The ETS lemmatizer tackles the Arabic word lexically, which is a drawback com-pared to other types of Arabic stemmers [9]. It u ses a new and lon g list of affixes and short list of stopwords to distin gu ish between no u n and verb. ETS consist of two main mon threshold. In g eneral, the ETS is comp u tationally expensive, its initial al g orithm distin gu ish between verb and no u n. handle the problem of the broken pl u ral, which other stemmers are u nable to do effec-tively. They propose a set of r u les for detectin g broken pl u ral patterns and transform-in g these to their sin gu lar forms. Their method also u ses a corp u s to see whether the end of the process, if the res u ltin g word appears in the corp u s, then this word is con-million tokens and is able to achieve hi g h acc u racy; however, it has not tested on an AIR system.The lemmatizers proposed by [20, 29] have not been tested a g ainst stan-dard benchmarks or compared with each other. F u rthermore, they u se different r u les indicate that, as stated earlier, a stemmer sho u ld tackle the word morpholo g ically and be caref u l for the set of affixes to be removed from that word. 
These stemmin g limitations can ca u se problems in applications that have strict acc u racy by avoidin g over-stemmin g , u nder-stemmin g , and miss-stemmin g errors (as the impact of three different Arabic stemmers on doc u ment retrieval compared to raw data retrieval witho u t stemmin g . feat u res wei g htin g will apply on dataset  X  X oc u ments X  and q u ery, then the cosine simi-larity will be u sed to rank doc u ments relevant to q u ery. 3.1 Preprocessing P re-processin g phase is the first phase in each retrieval system. This phase, very im-portant phase considerin g in doc u ment representation. Its concern to preprocess of the other operations performed like, normalization, stopwords removal, and stemmin g . 3. 1.1 Normalization and Tokenization malization u sed by [20]:  X 
Remove p u nct u ation, non-letters, diacritics (primarily weak vowels). Some entries contained weak vowels, removal made everythin g consistent.  X 
Replace  X  ,  X  , and  X  with  X   X 
Replace final  X  with  X   X  Replace final  X  with  X  . Tokenization is the process of split text into token. In this research after normalization bo u ndaries. 3. 1.2 Stopwords Removal words does not g ive any hint val u e to the content of their doc u ments. The early elimi-nation of stopwords d u rin g indexin g will speed u p the system processin g and g eneral-Khoja for ISRI, [31] stopwords list for Li g ht10, and for ETS its stopwords list. 3. 1.3 Stemmers 3.1.3.1 I S RI part of the word, after al g orithm startin g with normalization of word and with affixes removal. 3. 1.3.2 ET S r u le base stemmer with lar g e n u mber of patterns and affixes. This stemmer u se differ-words are identified u sin g no u n and verb dictionaries as a look u p table. At the end the li g ht stemmin g applied on no u ns and Khoja root-based stemmer applied on verbs. 3.1.3.3 Light10 Li g ht10 Arabic stemmer does not deal with patterns or infixes; it is simply the process of strippin g off prefixes and/or s u ffixes, as shown in Table 5. Li g ht10 stem-mer is u sed in stemmin g process and we followed the same steps by Larkey  X  s [20]:  X 
Remove  X   X   X  ( X  X nd X ) if the remainder of the word is 3 or more characters lon g .  X 
Remove any definite article (e. g . prefix) that leaves two or more characters.  X  fo u nd at the end of the word, if this leaves two or more characters. The  X  X refixes X  are act u ally definite articles and a conj u nction. The li g ht stemmers do not remove any strin g s that wo u ld be considered Arabic prefixes. 3.2 Querying and IR Model Q u ery processed same as doc u ment in preprocessin g phase. IR model for rankin g and findin g similarity when searchin g doc u ments. We u se Vector Space (VS) model, VS is simple for implementin g term wei g htin g rankin g and relevance feedback [30]. Co-( t  X   X   X   X  ) is determined by: the terms associated with their wei g ht in the doc u ment correspond to a specific non-closed in [0, 1]. In addition, the cosine similarity is independent of doc u ment len g th; identical. lan gu a g e independent. The BOW method does not depend on word meanin g and per-In this method, 1 represents the presence of the term in the doc u ment and 0 represents its absence. (Term Freq u ency (TF) x Inverse Doc u ment Freq u ency (IDF)) ( TF x I D F ) ment. In the case of an inverse proportion, d is assi g ned as the n u mber of doc u ments in which the term occ u rs: doc u ment i and df is n u mber of term appeared in all doc u ments. The st u dy eval u ates these stemmers u sin g the standard recall and precision meas u res as the basis for comparison, In addition, we compare between three stemmers based on similarity. It answers the followin g q u estions : a. What is the effect of the stemmer on Arabic retrieval? b. How sensitive is retrieval to the u se of stemmer? c. Which stemmers have hi g h similarity? to determine which one achieves the optimal performance for Arabic lan gu a g e retrieval. 4.1 Data Set This research u sed the Arabic Newswire a corp u s was created by[33]. It is composed 2,337 compressed Arabic text data files, with 383,872 doc u ments containin g 76 mil-lion tokens over approximately 666,094 u niq u e words. The q u ery set associated with the LDC corp u s was created for TREC 2001[32]. There were 25 topics with relevance experiment. 4.2 Performance Evaluation (searcher) knowled g e of the search topics. The followin g IR meas u res are u sed:  X 
P recision: The proportion of relevant doc u ments to all doc u ments retrieved.  X  relevant doc u ments.  X 
Mean Avera g e P recision (MA P ): The avera g e of precision after each relevant doc-u ment is retrieved, MA P is calc u lated after set of q u eries are exec u ted. relevance of a g iven rank, and p ( ) precision at a g iven c u t-off rank. 4.3 Experiment Process The data and the q u ery set for the experiments were processed as followin g : a. The 383,872 files in the data set were converted from UTF-8 format to Win-b. Title and description for each of the 25 q u eries were extracted from the ori g inal c. The corp u s and q u eries were Normalized and Tokenization as we mentioned in d. Stop words list are removed. e. Stemmin g u sin g the three Arabic stemmers. f. Eval u ation u sin g standard TFIDF wei g htin g schema, cosine similarity, precision This st u dy involved three sets of experiments. First experiment is to retrieve the most related doc u ments based on 25 q u eries for three stemmers and compare between them based on MA P acc u racy, the second experiment is cond u cted to eval u ate the avera g e 25 q u eries with the top first 50 retrieved for three stemmers, the last experiments is to from AIR. achieve by u sin g li g ht 10 stemmer, on the other side the ISRI stemmer is worst stem-mer for AIR, where the rank of stemmers as followin g : li g ht 10, ETS,ISRI, RAW. In addition we show the compression rate after stemmers on the n u mber of terms ex-g et 0.57% of the data set, on the other hand the worst compression is RAW stemmer with 0.37% of the percenta g e data set. Second experiment as shown in fi g 1, to meas-stemmer with 0.33%, based on fi g 1 shows conver g ence between three stemmers on avera g e of top 50 retrieved namely; li g ht 10, ETS and ISRI, on the other side the raw mers based on first retrieved for each 25 q u eries, as shown in fi g 2, li g ht 10 ISRI and ETS stemmers are comparable to each other for the first retrieved, and three stemmers g et better than raw data stemmer. In this research, we investi g ated the effect of fo u r stemmers (Li g ht 10, ETS, ISRI and raw stemmer) and impact on improvin g Arabic monolin gu al IR. Based on o u r expe-res u lt, b u t comparin g the raw data witho u t stemmer g ot the worst performance for the ISRI stemmers. mers beca u se q u eries, the q u ery is very short comparin g with the doc u ments retrieved and stemmers have challen g e to detect the correct retrieved based on short q u ery, also first, we s ugg est to apply Arabic Doc u ment Cl u sterin g to show the effect of stemmers on lon g q u ery instead of short q u ery, where the Doc u ment Cl u sterin g need to choose show the effect stemmers. Second, we s ugg estion to u se Word Sense Disambi gu ation s ugg estion to u se q u ery expansion techniq u e(s) to increase effect of retrieved. Acknowledgment. We wo u ld like to thank lin gu istic Data Consorti u m (LDC) for providin g u s with LDC2001T55 Arabic Newswire P art 1 at no-cost, as one of the 
