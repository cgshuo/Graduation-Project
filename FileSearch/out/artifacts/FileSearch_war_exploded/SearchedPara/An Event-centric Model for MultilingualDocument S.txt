 Document similarity measures play an important role in many document retrieval and exploration tasks. Over the past decades, several models and techniques have been de-veloped to determine a ranked list of documents similar to a given query document. Interestingly, the proposed ap-proaches typically rely on extensions to the vector space model and are rarely suited for multilingual corpora.
In this paper, we present a novel document similarity mea-sure that is based on events extracted from documents. An event is solely described by nearby occurrences of temporal and geographic expressions in a document X  X  text. Thus, a document is modeled as a set of events that can be compared and ranked using temporal and geographic hierarchies. A key feature of our model is that it is term-and language-independent as temporal and geographic expressions men-tioned in texts are normalized to a standard format. This also allows to determine similar documents across languages, an important feature in the context of document exploration. Our approach proves to be quite effective, including the dis-covery of new similarities, as our experiments using different (multilingual) corpora demonstrate.
 I.5 [ Pattern Recognition ]: Clustering X  Similarity mea-sures ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Language models, Text analysis Algorithms, Languages
When are two documents similar? This is the question es-sential to tasks such as document classification, clustering, or topic detection and tracking. To address this often subjec-tive and application specific question, over the past decades several approaches for modeling the similarity of text docu-ments have been developed (see, e.g., [12]). Respective ap-proaches range from extensions to the vector space model, such as latent semantic analysis [6], to techniques that em-ploy explicit knowledge representation schemes such as on-tologies to estimate semantic relatedness (e.g., [9]). In gen-eral, documents can be similar according to the words they contain, their structure, the topic they address, or the se-mantic concepts that have been associated with the docu-ments. This plethora of different similarity aspects clearly does not lead to a single, universally applicable document similarity measure. Instead, different measures may lead to new insights into document similarity that cannot be cap-tured by just one single approach.

In this paper, we present a novel similarity approach that isbasedonanevent-centricdocumentmodel. Looselyspeak-ing, an event is something that happens at a specific place and time. Our claim is that for many categories of docu-ments, events are essential to describe a topic or theme. This holds, among others, for historical works or biographies, an aspect we will elaborate on later in this paper. Our approach is based on a simple characterization of an event: it is solely described by nearby occurrences of a temporal expression and a geographic expression in a document X  X  text. We thus do not rely on complex statistical NLP-based techniques or rich ontology-based frameworks for extracting event descrip-tions from documents. In particular, the proposed model leads to a small footprint for documents as only sets of events extracted from documents need to be managed and used for the proposed document similarity measure.

There are two key aspects to temporal and geographic ex-pressions describing events. First, both can be normalized in an explicit way. No matter what original expressions are used in the documents, they can be normalized to the same value represented in a standard date notation (for a tempo-ral expression) or as a coordinate (for a geographic/location expression). Grounding our event-centric model on such types of information makes the model term-and language-independent. The model therefore allows to compare doc-uments written in different languages. Second, with both temporal and location information simple concept hierar-chies are associated that specify a containment relationship. For example, the granularity of temporal information (as part of an event) can be of type day, like  X 2011-01-14 X , or type month, like in  X 2011-01 X , with the former being con-tained in the latter. Similarly, different granularities can be associated with geographic information, such as city, county, country, etc. Exploiting the different levels of granularity for event specifications provides for an interesting technique to compare events extracted from documents. Thus, two documents may still be similar in terms of the events they contain even though the documents do not describe exactly the same events. Exploring event-based similarities among documents may also lead to new information that was not explicit before. For example, even though two documents talk about completely different topics, they both may men-tion the same event. This new information then can be used to investigate and establish new cross-document references.
In summary, the paper X  X  main contributions are as follows:
The remainder of the paper is structured as follows. After a review of related work, we detail the extraction and repre-sentation of event information in documents in Section 3. In Section 4, we outline a similarity measure for pairs of events and extend this approach in Section 5 to compare event sets extracted from documents. In Section 6, we present a comprehensive evaluation of the proposed approach using different (multilingual) corpora. We conclude our paper in Section 7.
There are many approaches to the computation of docu-ment similarity in different IR related tasks such as docu-ment classification and clustering. In standard information retrieval, documents are typically represented as vectors, as are the queries [2, 14]. These vectors consisting of weights, such as tf-idf, for all terms in the documents are then used to calculate the similarity between a query and a document or two documents. There are numerous approaches to improve this standard similarity measure, e.g., by using (probabilis-tic) latent semantic analysis to analyze conceptual contents [4, 6]. Chim and Deng use phrase-based document similar-ity for clustering and show that feature vectors of phrase terms can be seen as expanded feature vectors for single-word terms [5]. Because of the large footprint of the vector space model for documents, the MapReduce framework was recently applied to large corpora for calculating document similarity [8].

An interesting empirical evaluation of models for text doc-ument similarity was conducted by Lee et al. [12]. They conclude that many automatic models have very good pre-cision, but poor recall. That is, they detect only a subset of highly semantically similar document pairs. This obser-vation is a motivation for our approach, because we do not want to replace existing similarity measures, but we do want to provide a measure for non-standard document similarity to identify new information, that is, event-based similarity relationships between documents.

An area related to our approach is topic clustering and in particular topic detection and tracking (TDT) where items of a document stream (e.g., a news stream) are analyzed. The goals of these approaches are to detect new unreported news events, and to track topics by assigning documents to already detected events [1]. There is a lot of research dealing with TDT for which the identification of events is necessary. Often, the similarity measures use information of named entity recognition, for example, locations, temporal expressions, or person and organization names mentioned in the documents [13, 27]. In contrast to our work, however, TDT systems try to identify a main event that can be as-sociated with documents. Our goal, on the other hand, is to identify as many events in documents as possible, and to use the identified events for calculating document similarity.
Similar to our approach of applying concept hierarchies to temporal and geographic information, Lakkaraju et al. [11] use general concept trees to classify documents according to a taxonomy. Our concept hierarchies, however, are very small (less than 20 concepts in total) and specific to (stan-dard) temporal and geographic aspects. There is also re-lated research on similarities for event identification in so-cial media [3]. In this work, however, they study general types of events and are not specifically concerned with tem-poral and geographic information. Some work combining geographic and temporal information extracted from docu-ments for search and exploration tasks has been studied in [15, 20] but without focusing on document similarity.
As already pointed out, our model for document similar-ity is based on a combination of geographic and temporal information to identify events. We need to clarify that we do not consider events in the same way as it is done in lin-guistics, e.g., in TimeML, the standard markup language for temporal annotations [24]. Instead, we consider something to be an event if it is described by a temporal and a geo-graphic expression. In the area of cross-language informa-tion retrieval, similarities are calculated on multilingual cor-pora. These calculations are usually based on translations while our approach uses normalized, language-independent information. There is only very few work on multilingual, translation-independent document similarity. One approach that makes use of a multilingual thesaurus for computing similarities has been proposed by Steinberger et al. in [18].
In contrast to most other works where a single temporal value (the document timestamp) and no geographic value are associated with a document, we use all geographic and temporal information mentioned in documents to form events. Therefore, we need to extract and normalize all geographic and temporal expressions using a geo-tagger and a temporal tagger. These named entity recognition and normalization tasks are outlined in the following Sections 3.1 and 3.2. In addition, we describe how the granularities of geographic and temporal expressions can be used for comparing expres-sions of different granularities. In Section 3.3, we combine geographic and temporal information into so-called docu-ment event profiles, which form the basis for our analysis of event-based document similarity.
Temporal expressions can be grouped into four types, as done in the standard meta language for temporal annota-tions, TimeML [21]: date , time , duration ,and set .Inthis paper, we only consider expressions of type date , although our method is suitable to support other types as well. Dates are anchored in a timeline, and a date X  X  position in a time-line is referred to as its normalized value. It is important to note that the normalized value of a temporal expression, called chronon , is independent of the language used in the according document. Thus, this representation is perfectly suited for multilingual analysis tasks.

Normalization is done assuming a discrete representation of time, based on the Gregorian Calendar. Temporal ex-pressions can be of different granularities, such as day, week, month, year, or decade. For the representation of these gran-ularities, we assume different timelines, e.g., T day for days and T month for months. For example,  X  X arch 19, 1999 X  can be anchored in T day while  X  X ay 2010 X  can be anchored in T month . Timelines can be ordered into a hierarchy, which is a crucial point for our analysis of event-based similarities between documents. A hierarchy of temporal information granularities is given in Figure 1(a). Although there are other possible timelines (finer ones like hours or coarser ones like centuries), we use the following timelines for our hier-be performed from a value of a finer granularity to a coarser granularity, since months consist of days, years consist of months, and decades consist of years. The mapping from one timeline to the next coarser one is defined as one temporal mapping step  X  t . For example,  X  t ( X 1999-03-19 X ) = X 1999-03 X  and  X  t (  X  t ( X 1999-03-19 X )) =  X 1999 X .

For the extraction and normalization of temporal expres-sions in documents, so-called temporal taggers are employed. Examples include GUTime, which is part of the Tarsqi toolkit [23], or HeidelTime [19], which was the best performing sys-tem for identifying and normalizing English temporal ex-pressions in the TempEval 2010 challenge [24]. Using such temporal taggers, the following information about temporal expressions is extracted and used for further analysis: the offset (start and end position) of the expression in the doc-ument, the type (date, time, etc.), and chronon (normalized value). In Section 6, we give more details about the specific document processing pipeline employed in our approach.
In the same way temporal expressions like dates refer to a point in time, geographic expressions refer to locations. We assume that with each geographic expression a geometry can be associated, which is represented as a latitude/longitude value pair. For the extraction and normalization of geo-graphic expressions in documents, named entity recognition (NER) tools for locations can be used. Such geo-taggers usually use gazetteers and context information for the dis-ambiguation of location names. Examples of such tools are MetaCarta [16] and Yahoo Placemaker [26]. Note that nor-malized location information is language-independent in the same way as temporal information.

Usually, geo-taggers only assign point geometry informa-tion to a location, regardless of the actual geographic extent of the location. Nevertheless, containment information, e.g., that a city is in a state or country, is often associated with an extracted expression. For example, the normalized con-(a) Temporal hierarchy. Figure 1: Concept hierarchies for geographic and temporal information. tainment information about  X  X ew York City X , which can be referred to by expressions such as  X  X ew York, NY, US X ,  X  X ew York X ,  X  X YC X , or  X  X ig Apple X , is  X  X ew York, NY, US X . This containment relationship is very important for geographic information and can be used directly and formalized in the following way: If a location g i is contained in a location g the relationship is denoted g i  X  G g j . For example, the fact that a city g 1 iscontainedinacountry g 2 can be expressed as g 1  X  G g 2 .

Similar to the hierarchy of timelines for temporal expres-sions, the hierarchy of locations is crucial for our similarity measure. A general overview of the hierarchy of geographic information is depicted in Figure 1(b). Although there are many other levels (finer ones like addresses or coarser ones like continents), we use the following granularities for our hierarchy: city, state, and country. The mapping from one granularity to the next coarser one is defined as one geo-graphic mapping step  X  g . For example,  X  g ( X  X an Diego, CA, USA X ) = X  X A, USA X .
As mentioned in Section 1, events in our scenario are co-occurrences of geographic and temporal expressions in a doc-ument. While there are several ways to form events from such expressions found in documents, we consider a pair of a geographic and a temporal expression to form an event if the two expressions occur in the same sentence. This method is much more precise than forming events from the cross-product of all pairs of geographic and temporal expressions in a document, which results in many false positives. Also, our method is much more efficient than a complete linguis-tic analysis of the documents, which is infeasible for large corpora.

We summarize the information about the geographic and the temporal dimension of all events in a given document d in a document event profile , denoted dep ( d ). The idea behind document profiles is to describe the information textually mentioned in a document in a concise manner and to make it accessible for further analysis. More precisely, a document event profile dep ( d ) contains a set of pairs ( t i ,c i ( g ,v i ,p ( g ) i ) with (1) t i and g i being the temporal and geographic expressions occurring at the sentence level, (2) c and v i being their normalized temporal (chronon) and ge-ographic values, and (3) p ( t ) i and p ( g ) i being the offset of both expressions in document d . Instead of just recording the latitude/longitude information, we include the normal-ized containment information as the normalized geographic value v i , since our similarity measure exploits this informa-tion. Note that events can be of different geographic gran-ularities and timelines. Nevertheless, they can be compared using geographic and temporal mappings  X  t and  X  g ,which were described in the previous paragraphs.

To summarize, in our approach, a document is solely de-scribed by an event profile. Compared to a vector space representation, our event-centric document model leads to a small amount of information that is used to compute the document similarity based on events. This computation and underlying similarity measure will be discussed next.
In this section, we introduce the fundamental step for calculating event-centric document similarity, which is the comparison of two arbitrary events. Specifically, we first de-scribe the problem setting for computing the similarity of twoeventsbyspecifyingtherequirementsforsuchasim-ilarity function in Section 4.1. In Section 4.2, we develop the similarity function and verify that all requirements are fulfilled. The similarity of pairs of events is then used in our new approach for calculating event-based document similar-ities, which will be detailed in Section 5.
For comparing any two events, we use the normalized val-ues of their temporal and geographic information as de-scribedinSection3. Thus,aneventisdescribedbya chronon c and a normalized geographic value v .Wecall c and v the dimensions of an event e = c, v .Bothdimen-sions can be mapped to coarser granularities using the tem-poral and geographic mapping steps  X  t and  X  g introduced in Sections 3.1 and 3.2, respectively.

In order to define the requirements for the similarity func-tion for events, denoted sim e , we first list all possible sim-ilarity cases that can occur. In the listed cases, we do not distinguish the number of granularity mapping steps that have to be applied for one dimension, but use c  X  for c and v for v being mapped to any coarser granularity. Given two events e 1 = c 1 ,v 1 and e 2 = c 2 ,v 2 , the following similari-ties can occur: 1. Values of both dimensions of the events are identical. 2. The values of one dimension have to be mapped to a 3. The values of both dimensions have to be mapped to 4. It is not possible to map the values of one dimension 5. It is not possible to map the values of both dimensions
Using the listed set of possible cases, we now detail the requirements for the similarity function sim e .Forthis,we state requirements followed by their detailed description. R1: The more similar e 1 and e 2 , the higher sim e . The more similar two events e 1 and e 2 are, the higher should be their similarity sim e ( e 1 ,e 2 ), with sim e ( e 1 ,e imal if both events are identical. In (1.1), the events are identical and thus should have the highest possible similar-ity value.

R2: The fewer values of the same dimension need to be In the second group, either at least one of the chronons has to be mapped to a coarser timeline (2.1 and 2.2) or at least one normalized geographic value has to be mapped to a coarser granularity (2.3 and 2.4). If only one value has to be mapped (2.1 and 2.3), the similarity score should be higher than if both values have to be mapped (2.2 and 2.4). This reflects the fact that the former ones can be correct (al-though described in an imprecise way) while the latter ones cannot be correct. For example, the sentences he visits NYC in May 2010 and he visits NYC on May 4, 2010 can talk about the same event. In contrast, the sentences he visits NYC in May 2010 and he visits NYC in April 2010 cannot talk about the same event. Nevertheless, there still is a sim-ilarity between e 1 and e 2 in the latter example, since both events happened at the same location and temporally close to each other (both in 2010). Consequently, sim e should be higher for (2.1) and (2.3) and penalize (2.2) and (2.4).
The same cases occur in the third group: If only one value of each dimension has to be mapped (3.1, 3.2), the similar-ity score should be higher than if both values of the same dimension are involved (3.3, 3.4, and 3.5).
 R3: If mapping leads to no equality, sim e should be 0. In the fourth group, either the chronons or the normalized geographic expressions cannot be mapped to a coarser gran-ularity to achieve equality. In the fifth group both types of normalized values cannot be mapped sufficiently. Note that whether such cases can occur depends on the used hierar-chies for geographic and temporal mappings (cf. Figure 1). For example, if  X  X arth X  is used as the top level of the geo-graphic hierarchy, then every geographic expression can be mapped to the top of the hierarchy. However, if  X  X ountry X  is at the top level, then, e.g., cities located in different coun-tries cannot be mapped to a coarser granularity to achieve equality. Thus, if no sufficient mapping can be found, the assigned similarity score sim e is 0, even though there may be a temporal or geographic similarity when using a differ-ent hierarchy. Instead, such unmatched events influence the aggregated similarity score when comparing two documents, as detailed in Section 5.
 R4: The fewer mapping steps are needed, the higher sim e . The similarity score additionally depends on the differences of granularity between either c and c  X  or v and v  X  .The granularities are defined in Sections 3.1 and 3.2, and are represented by the timelines for temporal information and by the containment hierarchy for geographic expressions. The larger the differences, the less precise the information. R5: The finer the granularities, the higher sim e . So far, the original granularities of the values, i.e., before they are mapped to coarser granularities, are not taken into account. For example, if there are two events e 1 = (2006), (Germany) and e 2 = (2006-07-09), (Berlin,Germany) ,then score should be sensitive to the original granularities of the events in the documents. An event that is mentioned more fine-grained in the document should be weighted higher than a coarser one, i.e., sim e ( e 1 ,e 1 ) &lt;sim e ( e 2 ,e
Having defined the requirements for a similarity measure for pairs of events, we now formalize a function sim e ( e that fulfills these requirements. As stated above, sim e ( e &gt; 0 only holds if equality of two events e 1 = c 1 ,v 1 e = c 2 ,v 2 can be achieved, namely by applying a certain number of mapping steps to the geographic and temporal dimensions of the events. We define  X  =  X  t +  X  g as the number of mapping steps that are needed to achieve equal-ity for events e 1 and e 2 in both dimensions. Specifically,  X  the sum of the number of temporal mapping steps that need to be applied to c 1 and c 2 , respectively, in order to achieve equality in the temporal dimension.  X  g is the correspond-ing sum of the number of mapping steps applied to v 1 and v 2 in the geographic dimension. That is,  X   X  X  0 ,..., 2 k with k being the total number of possible geographic and temporal mapping steps. Furthermore, we define  X  to be the maximum of the number of values per dimension that are involved in the mapping, thus  X   X  X  0 , 1 , 2 } .Wetenta-tively define the event-centric similarity sim e ( e 1 ,e calculated in the following way:
While  X  is used to moderately decrease sim e ( e 1 ,e 2 ),  X  in-creases the denominator exponentially, thus penalizing the similarity score stronger than  X  . Thisismotivatedbyre-quirement R2 that e 1 and e 2 can refer to the same event if  X  = 1, but cannot if  X  =2 X  X omatterhowlarge  X  is.

Equation 1 fulfills requirements R1 through R4 as will be shown below. However, it does not yet support R5 (the finer the original granularities, the higher sim e ). Thus, we additionally consider a parameter  X  poss , which is the num-ber of mapping steps (both temporal and geographic) that arestillpossiblefor e 1 and e 2 after both events have been mapped to be of equal granularity in both dimensions. That is, for example, if e 1 and e 2 were mapped to both represent ( c =2006-06 ,v =Germany) ,then  X  poss =2,asnofurther mapping step is possible for v and two more mapping steps are possible for c (year and decade). By weighting sim e with  X  poss + 1, R5 is supported by our similarity function. Adding 1 to  X  poss is necessary as the similarity of the coars-est granularity would be 0 otherwise.
Equation 2 fulfills all requirements R1 through R5, and can thus be used for calculating the similarity of two events. To exemplarily verify this, we calculate the similarity scores between four events (Table 1) and show that all five require-ments are met. For better readability, we demonstrate this example using only the granularities day, month, and year for the temporal dimension, and city and country for the geographic dimension.

Although R1 (the more similar e 1 and e 2 , the higher sim is a subjective formulation, there are some examples in Ta-ble 1 for which this formulation is obvious, e.g., e 4 is more similar to e 3 than to e 1 . This example shows that sim e calculated correctly with respect to R1, since sim e ( e 3 Table 1: Events (left) and similarity scores between them calculated using Equation 2 (right). sim e ( e 1 ,e 4 ). R4 (the fewer mapping steps are needed, the higher sim e )isconsideredby sim e since, e.g., sim e ( e (one mapping step is needed) is higher than sim e ( e 1 ,e (three mapping steps are needed). The fact that R2 is taken into account can be shown directly using Equation 2. If zero, one, or two values of the same dimension need to be mapped, then  X  equals 0, 1, or 2, respectively. For  X  =0, the denominator of Equation 2 equals 1. If  X &gt; 0, then  X &gt; 0 and thus, (1 +  X  ) &lt; (1 +  X  ) 2 , i.e., R2 is fulfilled since sim e (  X  =1) &gt;sim e (  X  = 2). The consideration of R5 (the finer the granularities, the higher sim e ) is already achieved by the modification from Equation 1 to Equation 2. Finally, if no equality can be achieved with any number of mappings, Equation 2 is defined as sim e ( e 1 ,e 2 ) = 0, i.e., R4 is fulfilled.
Defining the similarity of just two events is already not trivial and many requirements need to be satisfied by the similarity function, as discussed in the previous section. How-ever, aggregating the similarity of two sets of events in a meaningful way is even more challenging. Therefore, before defining how to calculate a respective aggregation, we first give the problem statement and define some requirements for this aggregation in Section 5.1. Then, an event-based document similarity model satisfying these requirements is incrementally developed in Section 5.2.
Informally, the problem of computing the event-centric document similarity can be stated as follows: Given two doc-uments d 1 and d 2 represented through their document event profiles dep ( d 1 )and dep ( d 2 ), with each profile describing a multiset of events. Using the profiles, compute the event-centric document similarity sim e ( d 1 ,d 2 ) in a concise and meaningful way.

To be able to specify a suitable similarity function, we first formalize some requirements for the aggregation of event similarities that need to be fulfilled: A1: themorematchingeventsarein d 1 and d 2 , the higher A2: the more non-matching events are in d 1 and d 2 ,the A3: if only one document contains additional events, this
In addition, all the requirements formulated for event sim-ilarities apply here, too. That is, requirements R1 to R5 described in Section 4.1 can be summarized as: A4: the more similar the events in d 1 and d 2 , the higher
Given a document, the objective now is to determine a ranked list of most similar documents using the information given by their document event profiles. The simplest way to calculate this similarity is to view all events as terms. For every document, these terms then form a vector so that the similarity between two documents can be calculated by com-paring their vectors with, e.g., the cosine similarity function. This simple approach satisfies A1. However, other require-ments are not fulfilled, in particular A4 is not taken into account. Therefore, we base our model on the similarity function between events introduced in Section 4.2 (Equa-tion 2). For this, we use the following methods:
To satisfy A1 and A3, we furthermore utilize
For realizing these methods, the vector approach is not applicable since not only exact matches are considered but matches between events after granularity mapping. There-fore, instead of comparing vectors, we perform event align-ment by building the cross-product of the document event profiles to compare all event pairs. If two events are not equal, they will be mapped to coarser granularities until equality is reached or no further mapping is possible. The similarity score for every pair is calculated according to sim e ( e 1 ,e 2 ) (cf. Equation 2) and aggregated to sim
However, requirement A2 is not fulfilled so far. Therefore, we have to normalize sim e ( d 1 ,d 2 ) according to the number of events in the documents. For two documents d 1 and d 2 containing n and m events, respectively, using the sum n + m violates A3. Thus, we use min ( n, m ) for normalization and sim e ( d 1 ,d 2 ) is thus calculated as follows:
This equation together with the methods M, W, and N represents our full document similarity model (FM). To an-alyze the influence of the different methods, we use three further models in our evaluation: a model without granu-larity mapping (FM-M), a model without granularity map-ping and granularity weighting (FM-MW), and additionally a model without normalization (FM-MWN).

To calculate sim e ( d 1 ,d 2 ) efficiently, we map and materi-alize the events to all coarser granularities before comparing pairs of events. This way, the mapping does not have to be done every time an event is compared with another one. An example showing how the granularities are used for the calculation is given in Table 2. At the top of Table 2(a) and 2(b), the original events of document d 1 and document d 2 given. Below them, the original events and their mappings are grouped by  X  poss since two events with different  X  poss values cannot be equal, and thus do not have to be com-pared. Note that for better clarity, we only use day, month and year, and city and country as temporal and geographic concepts in the hierarchies, respectively. In Table 2(c), we show the steps for comparing some events.
 Algorithm 1 CalculateSimE( dep 1 ,dep 2)
The pseudocode for computing the similarity of two doc-uments represented by their event profiles dep 1and dep 2is shown in Algorithm 1. In line 2, all values of  X  poss are listed in descending sort order, with 3 being the highest value in our example. In lines 3 and 4, the possible mappings of all events in the document event profiles of d 1 and d 2 are pre-calculated. This results in the mappings grouped by  X  poss as shown in Table 2(a) and 2(b). Using the ids of the events, the cross-product is calculated in lines 5 to 7 and stored in the hash set todo . Then, the real calculation starts with iterating over the sorted  X  poss and the events contained in the mappings of the respective  X  poss . If two events match (line 11), all ids of the events are combined by iterating over the events X  ids (lines 12-13). In the example (Table 2), four event pairs are compared for  X  poss = 3 with one matching pair (a,f). Once  X  poss = 0, one event pair is left contain-ing several ids for each document. However, not all event pairs are still in todo , i.e., their similarity might already have been calculated (e.g., for a,f). If the id pair is still in todo (line 14), the pair is removed from the hash set (line 15) and the event similarity score is added to the total score sim (line 16). The method get sim calculates the similarity between two events according to Equation 2 (Section 4.2). Method get sim accesses values  X  t and  X  g of events through their ids, e.g., c.t represents the value of  X  t for event c .For better efficiency, the results can directly be stored in a hash map, since they are limited to the combinations of id 1 .t , id 1 .g , id 2 .t , id 2 .g ,and poss . Finally, if the todo hash set is empty (lines 17-18) or if all  X  poss are processed (line 19), the similarity score is normalized by dividing sim by the minimum of the lengths of dep 1and dep 2 and returned. In the example, the aggregated similarity score is divided by 3, i.e., the number of events extracted from document d 2.
In summary, using the above approach, a document sim-ilarity measure can effectively be computed solely based on document event profiles. Several optimizations can be applied to this computation (e.g., binning of events based on some granularity such as year and then only computing cross-products for same-year bins). Due to space constraints and to allow for a concise representation of our approach, these optimizations are not discussed in this paper. In the next section, we demonstrate that this new event-based sim-ilarity measure for documents is meaningful and also applies to multilingual corpora. contained in d 1 (Table (a)) and d 2 (Table (b)) are grouped by  X 
In this section, we first discuss the evaluation objectives and scenarios followed by a description of the corpora used for evaluation and our document processing pipeline. Then, we present the evaluation results and compare event-centric document similarity to a simple term-based similarity mea-sure, namely tf-idf combined with cosine similarity.
Manual Evaluation. Evaluating event-centric similar-ity is a challenging task since no adequate gold standard is available. We cannot use standard similarity evaluation corpora as our goal is not to identify documents as similar that talk about the same topic in general, but only docu-ments that contain similar events. Although there are eval-uation corpora for related tasks such as topic detection and tracking (TDT), these are not suitable due to the different goals of TDT and our similarity model. While TDT systems associate a main event with documents and cluster incom-ing news articles according to these events, we take into account all events extracted from documents to calculate event-centric similarity scores. Thus, a straightforward way to evaluate our model is to use a corpus, calculate the simi-larities between all documents and manually check whether two documents are similar or not. However, this scenario is very labor-intensive and can only be done for a small subset of documents. The results of such a manual evaluation are presented in Section 6.6.

Cross-language Evaluation. Another way to evalu-ate our model is based on a multilingual corpus containing cross-language links between related documents from dif-ferent languages. Intuitively, documents written in different languages having the same content (e.g., about the same per-son) can be assumed to be similar in an event-centric way. For example, the English and the German version of a biog-raphy can obviously be regarded as similar with respect to the mentioned events (e.g., birth, death, travels)  X  no matter whether or not the two documents are (partial) translations of each other. Using a multilingual corpus containing cross-language links, we can evaluate how often cross-language linked documents are the top-k most similar documents for each other. Note that the cross-language links are only used for evaluation purposes, and not considered for calculating the similarities. This evaluation scenario allows for a large-scale evaluation, and the results are described in Section 6.4.
We created two corpora for our evaluation. The smaller corpus contains the English Wikipedia featured articles [25] and the corresponding German articles linked to the En-glish ones through cross-language links. This corpus con-tains 3,124 English and 1,825 German articles. Note that the German articles are not necessarily featured. The rea-sons for choosing the Wikipedia featured articles are that (i) they are determined by the editors to be of high quality, and (ii) they are grouped into 30 categories and 13 biography subcategories. The latter fact allows for a detailed analysis which documents contain many events and for which topics our similarity model is particularly suitable. Table 3 shows some numbers for the categories. Topics such as history, warfare, or biographies tend to contain many events on aver-age. We expect to achieve better results for them compared to categories containing only few events, such as computing or physics. The differing numbers for English and German can be explained by the different length of the documents. Featured articles tend to be very long.

As a second test set, we built a larger corpus to evaluate our model with more documents taken into account. We used the publicly available Wikipedia XML Corpus [7], con-taining Wikipedia articles as XML files. We selected the main collections of English and German articles consisting of 659,388 and 305,099 articles, respectively, and created a subset of all document pairs for which the English and the German article are available, resulting in 94,348 pairs. Table 3: Statistics of the featured articles corpus grouped by category. In parentheses are the num-bers of documents with no/less than 3 events.
 Table 4: Statistics of both corpora with e  X  x being the number of documents with at least x events.

Some details on both corpora, which will be of interest in the result sections, are given in Table 4. The large dif-ferences in the number of average events per document can mainly be explained by the different lengths of the docu-ments. The featured articles tend to be much longer than other articles. In addition, the Wiki XML corpus contains several very short documents with just a couple of sentences. For both corpora, we only use the main parts of the arti-cles, i.e., reference sections are ignored. These sections of-ten contain bibliographic information including publication date and place, which are not relevant for the article itself.
For the evaluation, we built a UIMA-based text mining pipeline [22]. We developed collection readers to access both corpora. Linguistic preprocessing, i.e., sentence splitting, to-kenization, and part of speech tagging is done using compo-nents of the DKPro repository [10] and the Tree Tagger [17]. As temporal tagger, we chose HeidelTime [19] due to its best performance in the TempEval-2 challenge [24] for the extraction and normalization of temporal expressions from English documents. For identifying locations, we run Yahoo Placemaker [26] since it returns detailed containment infor-mation about extracted locations, which is crucial in terms of using the geographic hierarchy. While Yahoo Placemaker directly handles English and German documents, we had to develop a rule set for the temporal tagger to process Ger-man documents. Finally, we identify events by extracting co-occurrences based on the annotations of the temporal tag-ger, the geo-tagger and the sentence splitter. By applying our document processing pipeline, we obtain all the needed information to create document event profiles and thus to perform our event-centric document similarity analysis.
The hypothesis for the cross-language evaluation is that two documents linked by a cross-language link are similar in an event-centric way. Although we do not expect the linked documents to be the most similar ones for each other in all cases, we assume that they are among the most sim-ilar ones. We compare the four models introduced in Sec-tion 5.2, i.e., our full model (FM) to the model without granularity mapping (FM-M), to the model without gran-ularity mapping and weighting (FM-MW), and to the one additionally without normalization according to the number of events (FM-MWN). For every document, its similarity to each other document in the corpus is calculated. Obviously, if one document does not contain any events, no similarity score can be calculated for this document. In such cases, the score is set to zero. In addition, the similarity score can be zero if no similarity between the events of two documents is identified after the mapping process. For all models, given one document, we determine if its cross-language linked doc-ument belongs to the x most similar ones. We set x to 1, 3, 5, 10, 50 and 100. In addition, we set x to 10% of all compared documents.

Figure 2 shows the results for the Wikipedia featured ar-ticles corpus (2(a)) and for the Wiki XML corpus (2(b)). For both corpora, we show results for document pairs where both documents contain at least 1 event (bars) and at least 3 events (points). In addition, we group the results for the Wikipedia featured articles by the category of the documents (2(c)) using only the full model.
 For the featured articles corpus, using the simplest model FM-MWN already results in 26% (29%) precision that a cross-language linked document is the most similar one if both documents contain at least 1 (3) events. This indicates that, in general, events can be helpful for identifying simi-lar documents. Adding the event-occurrences normalization, weighting of different granularities, and the mapping of fine grained events to coarser granularities significantly improves the results in all cases. The full model achieves a precision of 36%, 54%, 62%, and 69% (top 1, 3, 5, and 10, respec-tively) for document pairs containing at least 3 events. A further advantage of the full model is that due to the map-ping of the events to coarser granularities, more similarities can be calculated. While the full model identifies similarities for cross-language linked document pairs in 86% and 94% of the cases, the other three models identify only 67% and 76% for pairs containing at least 1 and 3 events, respectively.
In Figure 2(b), the results for the Wiki XML corpus are given. Note that due to the much larger number of docu-ments in the corpus, the chance for a cross-language linked document to be within the x most similar documents de-creases. In addition, there may be more documents in the corpus being very similar in an event-centric way. This ex-plains the lower precision results for the Wiki XML corpus compared to the smaller corpus. Nevertheless, using the full model (FM) for documents with at least three events, in 15% (28%, 34%, 51%, 62%, 68% , 86%) of the cases cross-language linked documents are within the top x most similar documents, with x being 1, 3, 5, 10, 50, 100, and 10%, re-spectively. In addition, the results show that the full model outperforms the other models significantly. Especially the mapping of events to coarser granularities provides a sub-stantial feature to discover new similarities.

Figure 2(c) shows the results grouped by the categories of the documents. Categories rich in events clearly outper-form categories containing just few events (cf. Table 3), with biographies performing best with 69% (77%) for the cross-language linked documents being within the top 5 (top 10) most similar documents for each other.
Although there are several advanced approaches to calcu-late document similarities as pointed out in Section 2, most of them are extensions to the vector space model and thus term-based. In comparison, our model is based on the doc-ument event profiles described in Section 3.3. Hence, we expect to find other kinds of documents to be similar com-pared to term-based models. Therefore, for comparison with term-based models, we do not have to use highly sophis-ticated methods such as latent semantic analysis, but can choose a simple model as representative for all term-based approaches. For this, we select the tf-idf measure combined with the cosine similarity denoted sim t .

To evaluate the differences between sim e and sim t ,we analyze pairs of documents ( d 1 , d 2 ) according to their rank for both similarity scores. This results in four categories: c1. ( d 1 , d 2 ) is similar for both scores c2. ( d 1 , d 2 ) is similar for sim e , but not for sim t c3. ( d 1 , d 2 ) is similar for sim t , but not for sim e c4. ( d 1 , d 2 ) is not similar for either scores
This evaluation is performed using the Wikipedia featured articles corpus. We use the top-n ranked documents for sim e ,with n  X  X  1 , 3 , 5 , 10 } , i.e., rank e ( d 1 ,d culate the ratio of documents that are similar using sim t 1000 } . As Figure 3 indicates, about 48% (56%) of the top-5 (top-10) ranked documents using sim e are within the top-10 ranked documents using sim t ,andthebestrankeddoc-ument is the same for both measures in about 15% of the cases. This indicates that using sim e leads to the discov-ery of new similarity relationships, which are hidden in the geographic and temporal information in documents. These cannot be discovered using standard similarity measures.
To demonstrate that the identification of similarities with both measures is still valuable, we give examples for pairs of documents for the categories (c1) to (c3). As the reference document d 1 for which similar documents are analyzed, we use the featured article  X 7 World Trade Center X . A docu-ment d 2 for which rank t ( d 1 ,d 2 ) &lt; 10 and rank e rank t ( d 1 ,d 2 ), i.e., category (c3), is  X  X ower of London X . Ob-viously, both documents do not talk about same events, but are similar with respect to the content, namely the Figure 3: Ratio of documents that are ranked top n according to sim t for different rank e values. topic of both documents is a tall building, its construc-tion and design. A document for which rank t ( d 1 ,d 2 ) &lt; 10 and rank e ( d 1 ,d 2 ) &lt; 10, is  X  X merican Airlines Flight 11 X . Both documents are similar with respect to the topic of the terror attack and thus talk about same events, too. Finally, the article  X  X an Thorpe X  is said to be similar in terms of mentioned events, i.e., rank e ( d 1 ,d 2 ) &lt; 10 (with rank t rank e ). This surprising result is valid, as the arti-cle states that Ian Thorpe was present at the World Trade Center on the morning of 11 September 2001, having stopped there on his jog, before returning to his hotel after forgetting his camera .

For further validation of the utility of sim e ,weperforma manual evaluation, which is described next.
The objective of the manual evaluation is to validate the precision of the event-centric similarity model. For this, we use the Wikipedia featured articles corpus and randomly select 40 articles from the categories history, warfare, and biographies as source documents. These categories are es-pecially suitable for event-centric document similarity as the cross-language evaluation showed since their documents con-tain many events (c.f. Table 3). We select the five most similar documents for each source document and evaluate whether they contain exactly the same events, belong to the same category, have a similar main topic, and are written in the same language.

The precision at 1, 3, and 5 for a document to be similar is 65%, 70%, and 64%, respectively. As expected, the results are independent of the language since 53% of the similar documents are not in the language of the source document. Although there were many documents belonging to the same category (69%) and having a similar main topic (78%), there were several examples showing that sim e identifies similar-ities across topics as well.

An error analysis showed that documents were wrongly identified to be similar mainly in the following cases: (i) one of the documents contains person names that were wrongly tagged as locations by the geo-tagger, and (ii) the source document contains no fine-grained events. While the first reason can be faced by using a high confidence value of the geo-tagger, the second one indicates that documents con-taining only coarse grained events are less suitable for our similarity model than documents with fine-grained events.
In this paper, we presented a novel model for the event-centric computation of document similarity. The model uses normalized event information, that is, pairs of temporal and geographic expressions extracted from documents to deter-mine document similarity solely on the basis of events. Using this approach, it is possible to identify documents as being similar if they contain similar events although they might be different in other aspects, e.g., the main topic of the docu-ments. In particular, because of the normalization of tempo-ral and geographic expressions, including their containment relationships based on concept hierarchies, our model is ap-plicable to multilingual corpora, an important feature not supported by other document similarity models.

We are currently extending our framework to include more languages, with a focus on Spanish and French, and to ex-tend our corpora for evaluations correspondingly. We are also investigating structural aspects in terms of the order in which events are mentioned in a document. Such an or-der is obvious, for example, for the biography of a person written in two languages but might also lead to other inter-esting new information for other categories of documents. Finally, we are extending the types of events we consider by non-trivial events, such as names of holidays and their normalized temporal values. [1] J. Allan (Ed.). Topic Detection and Tracking: [2] R. A. Baeza-Yates and B. Ribeiro-Neto. Modern [3] H. Becker, M. Naaman, and L. Gravano. Learning [4] T. Brants and R. Stolle. Finding Similar Documents [5] H. Chim and X. Deng. Efficient Phrase-based [6] S. Deerwester, S. Dumais, G. Furnas, T. Landauer, [7] L. Denoyer and P. Gallinari. The Wikipedia XML [8] T.Elsayed,J.Lin,andD.W.Oard.Pairwise [9] E. Gabrilovich and S. Markovitch. Computing [10] I. Gurevych, M. M  X  uhlh  X  auser, C. M  X  uller, J. Steimle, [11] P. Lakkaraju, S. Gauch, and M. Speretta. Document [12] M. D. Lee, B. Pincombe, and M. Welsh. An Empirical [13] J. Makkonen, H. Ahonen-Myka, and M. Salmenkivi. [14] C. D. Manning, P. Raghavan, and H. Sch  X  utze. [15] B. Martins, H. Manguinhas, and J. Borbinha.
 [16] MetaCarta Inc. http://www.metacarta.com/ . [17] H. Schmid. Probabilistic Part-of-Speech Tagging Using [18] R. Steinberger, B. Pouliquen, and J. Hagman. [19] J. Str  X  otgen and M. Gertz. HeidelTime: High Quality [20] J. Str  X  otgen, M. Gertz, and P. Popov. Extraction and [21] TimeML. http://www.timeml.org/ . [22] UIMA. http://uima.apache.org . [23] M. Verhagen and J. Pustejovsky. Temporal Processing [24] M. Verhagen, R. Sauri, T. Caselli, and J. Pustejovsky. [25] Wikipedia Featured Articles. http://en.wikipedia. [26] Yahoo Placemaker. [27] K. Zhang, J. Zi, and L. G. Wu. New Event Detection
