 1. Introduction
Meteorological conditions have a significant impact on the operability of power transmission lines, the integrity of the trans-mission infrastructure, and the ch aracteristics of transmission net-works ( Crocombette, 2007 ). Weather phenomena that can cause transmission line failures and outages include extreme winds, lightning and ice loads. A study by the International Council on
Large Electric Systems (CIGRE) showed that ice accretion on power lines, winds or a combination of both, cause 87% of the total damage costs in 5 years starting from 1991 worldwide ( Kiessling et al., 2003 ). Although icing events are not common, they cost an annual average of $313,000,000 in the US alone. The extreme icing storm that hit Canada in January 1998 caused damage of $1.44 billion  X  the largest insured loss in Canadian history. Millions of people were left without power, and there were 25 fatalities ( Changnon and Creech, 2003 ; Lecomte et al., 1998 ). As another example, in December 2002 an ice storm hitting eastern United States left more than 65% of
Duke Power X  X  2.2 million customers without power for days. The post-storm recovery required 12,500 support personnel ( DeGaetano et al., 2008 ).

Prediction of icing events and their severity could help the electric power companies and communities at risk to get prepared and take appropriate preventati ve measures. The icing forecasts could also help utilities to better plan for recovery by appropriate staffing and dispatch of repair crews ( DeGaetano et al., 2008 ). Hence, a system that can forecast ice accretion would practically decrease the costs associated with icing events. As a result, there is an increasing interest in the develo pment of Ice Accretion Forecasting Systems (IAFS).

There have been many models of ice accretion developed over the last 50 years ( Makkonen and Lozowski, 2005 ). There are two major categories of accretion models: physical/mathematical models and experimental models ( McComber et al., 1995 , 1999 ). A mathematical model describes icing based on the associated physical processes of ice accretion ( Myers and Charpin, 2004 ; Poots, 1996 ). These models usually rely on para-meters that are difficult to measure such as liquid water content and droplet size distribution ( McComber et al., 1999 ). On the other side, experimental approaches describe the accretion pro-cess based on observed weather features and experimental data ( Jones, 1998 ; Makkonen, 1984 ).

Most icing models estimate the amount of ice based on observa-tions, assuming that freezing rain is falling ( Jones, 1998 ). Thus, to forecast the ice load on power lines, an IAFS must first predict the occurrence of freezing rain. Next, when freezing precipitation is forecast, an icing model can be engaged to estimate the expected amount of ice accretion ( Arnold, 2009 ; DeGaetano et al., 2008 ; Musilek et al., 2009 ). There has been several precipitation type (p-type) prediction algorithms developed. The Ramer algorithm ( Ramer, 1993 ) has demonstrated a good accuracy for the use in icing research ( Graham and Evans, 2008 ; Musilek et al., 2009 ). More recently, some modern machine learning techniques have been applied in this area ( Kuligowski and Barros, 1998 ; Wandishin et al., 2005 ).

DeGaetano et al. (2008) modified the Ramer algorithm to better resolve the surface conditions in weather forecasts. Subse-quently, the authors applied an icing model to predict the amount of accreted ice. Musilek et al. (2009) improved the p-type algorithm and the accuracy of ice accretion forecasts by allowing the accretion model to be gradually engaged, to account for mixed precipitation. Finally, Pytlak et al. (2010) proposed a more com-plex engagement function and developed a genetic algorithm to optimize its parameters. This modification further improved the performance of the forecasting system. All these ice accretion forecasting systems rely on a simple model of ice accretion ( Jones, 1998 ). However, this paper argues that making the ice accretion forecasts dependent on using an intermediate explicit icing model, may not be the best possible solution. Considering the availability of valuable historical data sets of icing events, we suggest that modern prediction models can be applied to learn an effective IAFS directly, without the use of the accretion model.
Learning models, and more specifically neural networks, have been previously applied in ice accretion studies. Larouche et al. (2000) and McComber et al. (1999) used neural networks to estimate the amount of ice accretion on transmission lines.
Maralbashi-Zamini (2007) applied recurrent neural networks to predict the type of ice, and to estimate its rate of accretion on a transmission line. Our work differs in several significant ways.
First, those earlier studies used weather observations to learn the icing model, rather than predictions in the form of hindcasts or forecasts. In other words, those studies focused on the task of now-casting which assumes the availability of weather observa-tions throughout the power transmission grid. An accretion model would then provide estimates of ice accreted at limited number of locations, for real-time monitoring applications. Sec-ond, all three studies use observations recorded at the same icing test site operated by Hydro Quebec on Mont Be  X  lair in Quebec,
Canada. However, to investigate the prediction power and gen-eralization performance of IAFS based on modern learning meth-ods requires testing on more spatially and temporally scattered data sets. Finally, all three studies used data collected by a specialized instrument called Icing Rate Meter ( Maralbashi-
Zamini, 2007 ). However, in a forecasting scenario, such measure-ments would not be available.

This work uses the outputs from a Numerical Weather Predic-tion (NWP) model to predict ice accretion, rather than estimating the amount of ice from indirect measurements. This approach provides a number of advantages, including the availability of weather information for virtually any location or area, and the possibility to predict meteorological variables with horizon up to 84 h. In addition, the data set used for this experimental study is more comprehensive as it covers eight different icing events, and contains sensor data from 20 different locations. This study also considers inclusion of additional features, and shows that the use of elevation data can improve the accuracy of the accretion forecasts. We apply the technique of Support Vector Machines (SVM) to develop two new forecasting models. The first model follows the standard approach of using the icing model. In this system, the historical data set is used to learn the subsystem which controls the engagement level of the icing model. The second model investigates the alternative approach of learning the entire forecasting system using the available data set, without an explicit icing model.

A number of experiments were performed to compare the two new models against several previously proposed systems. Additional experiments were used to gage the ability of these systems to generalize, i.e. predict new icing events. The results show that the use of SVM regression substantially improves the ice accretion forecast accuracy. The second SV M-based model, which does not rely on an icing model, considerably and statistically significantly outperforms the other systems.

The remainder of this paper is organized as follows. Section 2 formally defines the ice accretion prediction problem and explains the major common methods in more detail. The SVM regression algorithm and the two proposed systems are elabo-rated in Section 3 . The experimental data set and setup, along with the comparative results and analysis, are provided in Section 4 . Finally, the concluding remarks and future research directions are discussed in Section 5 . 2. Ice accretion forecasting
The major components of most ice accretion forecasting systems ( DeGaetano et al., 2008 ; Musilek et al., 2009 ; Pytlak et al., 2010 ) are weather prediction, precipitation-type prediction, and icing model, as shown in Fig. 1 . In order to predict the amount of ice accreted on a conductor, such systems first predict expected weather attributes in a temporal and spatial domain of interest.
This task is performed by an NWP model, using publicly available weather reanalysis (NCEP NARR, 2011 ) or forecast ( NCEP NAM, 2011 ) data. Although such data could be used directly, the inclusion of the NWP model has a number of advantages. First, meteorological data can be downscaled to a particular location (i.e. a power transmission corridor) incorporating local geogra-phy, even though the reanalysis and forecast data is available on a horizontal grid with resolution of 32 km and 12 km, respectively.
Given that most freezing rain events are local, the coarse resolu-tion is not sufficient to capture and localize them. Second, NWP models can disaggregate individual meteorological variables in time. The reanalysis and forecast data are usually spaced 3 X 6 h apart, while NWP system can provide weather predictions at scales equal to the simulation time step, e.g. a few seconds.
Finally, when using the forecast data, NWP models allow weather prognoses with time horizons up to 84 h ( Hosek et al., 2011 ), with the same spatial and temporal resolutions.

The Weather Research and Forecasting (WRF) model ( Skamarock et al., 2008 ) is the usual choice of weather prediction system. By supporting many physics options, this advanced NWP system can forecast precipitation and provide the weather attri-butes required for p-type prediction and the icing model. All necessary attributes are obtained either directly, or by using post-processing calculations applied to the NWP output.

The first step is predicting the expected weather attributes for the location and time period of interest. The next step uses the p-type algorithm to determine the type of precipitation predicted by the NWP model, if any. There has been a number of p-type algorithms developed over the years ( Baldwin et al., 1994 ; Ramer, 1993 ). Many ice accretion forecasting systems use the Ramer algorithm or its modifications, as it is known to be statistically strongest ( Graham and Evans, 2008 ). This algorithm uses the vertical profile of wet bulb temperature, pressure, and relative humidity to determine whether the precipitation is rain, snow, ice pellets, freezing rain, or freezing mix.

Previous ice accretion forecasting systems improved the p-type prediction step performed by the Ramer algorithm as follows. (a) DeGaetano et al. (2008) considered the conditions near the (b) Musilek et al. (2009) developed a gradual engagement func-(c) Pytlak et al. (2010) proposed a more complex engagement
In the final step, the icing model estimates the amount of ice, once the occurrence and character of freezing precipitation have been determined in the preceding step. The icing model calculates the amount of ice forming on the conductor from the forecast meteorological conditions during the icing event. There have been a number of ice accretion models proposed in the literature including the Makkonen model ( Makkonen, 1998 ), and the Simple Model (SM) ( Jones, 1998 ). Many other models are summarized in Yip and Mitten (1991) . The SM has been widely applied in icing research ( DeGaetano et al., 2008 ; Hosek et al., 2011 ; Musilek et al., 2009 ; Pytlak et al., 2010 ), because of its accuracy and computational simplicity ( Jones, 1998 ; Pytlak et al., 2010 ).

To calculate the equivalent radial thickness of ice accreted on a conductor, R SM , the SM applies the following sum over each hour j for the duration of the event ( N hours) R where r i  X  900 kg m 3 and r w  X  1000 kg m 3 are, respectively, the densities of ice and water, P j is the precipitation rate (mm h is the liquid water content (kg m 3 ), and U j is the component of wind velocity normal to the line (m s 1 ). The liquid water content is calculated based on the precipitation rate ( Best, 1950 )as W j  X  6 : 7 10 5 P j 0 : 846  X  6  X 
The SM accumulates the increments of ice accretion over the duration of the storm and does not involve any dynamic terms. The engagement function G is trained using the hourly ASOS sensor measurements, rather than the total amount of ice accreted on a power conductor. These sensors are effectively static as they are periodically reset by melting accumulated ice ( NOAA, 1998 ).
Fig. 2 shows how the three ice accretion forecasting systems described above apply the icing model to the NWP forecasts to estimate the amount of ice accreted on power lines. In the system described by DeGaetano et al. R SM is the final output. However, in systems developed by Musilek et al. and Pytlak et al. this value is scaled by the factor G (cf. the dashed box in Fig. 2 ), so the final output, ^ R eq , is determined as follows: ^ R eq  X  G R SM  X  7  X 
These recent systems apply advanced techniques, such as fuzzy sets and genetic algorithms, to achieve a higher accuracy of ice accretion forecasts. However, they rely on explicit ice accretion models to perform the final step of the forecasting task. In other words, the structure of the forecasting system is fixed, and only some parameters of the icing model are adjusted to better reflect the relation between forecast weather conditions and experienced ice loads. As a result, the accuracy of these systems depends on the performance of the icing model. One of the SVM-based systems, introduced in the following section, removes this restriction by directly learning a regression function. Such function can perform the ice accretion forecasting task without an explicit accretion model. 3. Learning SVM regression models of ice accretion
Similar to any other learning and prediction problems, the problem of ice accretion forecasting can be formulated in terms of a set of features and their respective target values. These features and targets, available in a number of instances, form a historical data set that can be applied to learn an effective prediction model for future use. In our case, the instances represent different locations and different points in time. The intended future use of the model is prediction of accretion from weather attributes. There are several weather attributes commonly used in IAFS.
Some are used for the p-type prediction, and some for modeling of ice accretion. In general, the historical data set, describing past ice storms, can be denoted as follows:
D  X  x i  X  X  f i 1 , f i 2 , ... , f i N  X  , R i eq no where N is the number of features, and l is the number of instances in the data set D . Each instance i contains the forecast weather attributes, f i j , and a measured target value R ( N  X  1)-tuple corresponds to a specific time and location (not explicitly shown in Eq. (8)).

There are many methods that can be used for this task of learning a continuous function from data (regression). Among them, a rather new class of algorithms called Support Vector
Machines (SVMs) has recently received a lot of attention as SVMs can efficiently find accurate models of data and so have been very effective in many applications. Because their approach is typically very tolerant to noise, these SVM-produced models are usually very robust. Moreover, Support Vector Regression (SVR) requires the user to see many fewer parameters and design alternatives, compared to other approaches such as neural networks. This translates to lower risk of over-fitting, and less human interven-tion in the learning process. SVR requires solving quadratic programs, which are convex optimization problems with unique optimal solution, which can be found efficiently using numerical methods ( Smola and Sch  X  olkopf, 2004 ). This is often regarded as a great advantage, compared to the more common methods of neural networks that can get stuck in local optima.

The two ice accretion systems developed in this paper apply n -SVR algorithm on the historical data set of icing events, to learn forecasting models. Before describing the details of the two systems, we first elaborate on their main component  X  the n -SVR algorithm. 3.1. m -SVR
Support vector machines are a class of learning algorithms based on the statistical learning theory developed by Vapnik (1995) . SVMs were initially designed for pattern classification.
They attempt to find sparse solutions, so that predictions for new instances depend only on a subset of the training data points, called the support vectors . The SVM formulation allows the use of kernel techniques ( Smola, 1998 ) to find certain non-linear models with high efficiency and ease.

The e -SVR algorithm is the basic version of the support vector regression method. This method attempts to find a function f ( x ) that has at most e deviation from the targets in the training set, while having as simple form as possible. That is, this algorithm searches for a linear function f of the form f  X  x  X  X  w , x hi  X  b  X  9  X  of the input instances, w A R N is a vector of weights defining the function, and b A R is an offset parameter. The expression denotes the dot product, where w , x  X  P i w i x i . In addition, there used to extend the sparseness property of SVM classification to regression ( Vapnik, 1995 , 1998 )
Er  X  f  X  x  X  y  X  X  0if f  X  x  X  y o e , f  X  x  X  y e otherwise  X  10  X 
To find the best fitting linear function, SVR uses the following minimization procedure ( Smola and Sch  X  olkopf, 2004 ): minimize w , b 1 2 : w 2 :  X  C 1 l where C is a constant to adjust the trade-off between accuracy and simplicity. Considering the value of x and x n as new e -insensitive error measures, this objective can be written as minimize w , b 1 2 : w 2 :  X  C 1 l subject to constraints : w , x hi  X  b  X  X  y i r e  X  x i ,  X  13  X  y w , x hi  X  b  X  X  r e  X  x n i , x i , x n i Z 0  X  14  X  Vapnik (1995) solved this problem by dual optimization using
Lagrange multipliers. Based on the definition of function f in (9), the regression result would be linear. However, one can imple-ment certain non-linear functions by using the kernel technique.
We apply this technique to learn a non-linear mapping between the meteorological attributes and the thickness of accreted ice in the forecast model. Another issue is the requirement of providing an a priori value for the parameter e . At the same time, the intended use of the algorithm dictates that the estimations are as accurate as possible. Sch  X  olkopf et al. (2000) suggest incorporating this parameter in the optimization objective minimize w , e 1 2 : w 2 :  X  C ne  X  1 l for some n Z 0, subject to the same constraints as above and e
Details of computing the dual form and the optimal w and b can be found in Smola and Sch  X  olkopf (2004) .

The most important advantage of n -SVR algorithm is that the user does not have to specify a value for the parameter e . Instead s/he provides the parameter n , which allows an effective control of the number of support vectors and the outlier sensitivity. By using this parameter, a maximum n fraction of l training points will fall outside the e -tube, while a minimum n fraction of them are support vectors within the tube or on its edge ( Sch  X  olkopf et al., 2000 ). Chang and Lin (2002) provide a comprehensive comparison between e -SVR and n -SVR algorithms.

To generalize the method to non-linear estimations, we can map the feature space of the input vectors into a very high dimensional new space via a non-linear map ^ (.) ( Smola, 1998 ).
Since the dual form uses only the dot products of the input vectors, we need only consider the kernel function kx , y  X  X  X  ^ x  X  X  ^  X  y  X   X  X   X  16  X  and no need to deal explicitly with the ^ -mapping itself ( Sch  X  olkopf et al., 1998 ). The usual choice for the kernel function in problems with low dimensionality (like our problem) is the
Gaussian kernel ( Sch  X  olkopf et al., 1999 ; Smola, 1998 ) kx , y  X  X  X  exp  X  x y 2 = 2 s 2  X  ,  X  17  X  where s 4 0 is a tunable parameter. SVR experiments in this study were implemented using package  X  X  X 1071 X  X  ( Dimitriadou et al., 2005 ; Karatzoglou et al., 2006 ). 3.2. FactorSVR: learning the engagement function
The first system, FactorSVR, uses the SVM regression algorithm in connection with the icing model. Hence, like the two previous
IAFS ( Musilek et al., 2009 ; Pytlak et al., 2010 ), FactorSVR only optimizes the scaling factor that multiplies the output of the icing model. This regression model attempts to find the best engage-ment function for the set of available features. This resembles ( Pytlak et al., 2010 ), but differs by replacing Eq. (4) with
G  X  fx  X  X  ,  X  18  X  where f ( x ) is obtained by applying n -SVR algorithm on the training data set. Thus, the training set must be in the form { x where x i is the input vector of NWP outputs, and G i is the corresponding target  X  the scaling factor for the i th case
G  X  where R i eq is the measured amount of ice, and R i SM is the estimate provided by the icing model (5). Thus, in the training phase, the
SVM regression model will learn the optimal function f ( x ); in the testing/operation phase, the system will predict ^
R eq  X  f  X  x i  X  R i SM  X  20  X  similar to relation (7).

The components of this first SVM-based ice accretion forecast-ing system correspond to Fig. 2 , except that the dashed compo-nent is determined by the n -SVR algorithm. 3.3. IceSVR: learning an ice accretion predictor
The second system, IceSVR, does not involve any explicit icing model. Instead, it applies the regression method directly on the data set of icing events. Thus, instead of using the R i SM system learns an appropriate function to directly predict the amount of ice for given weather conditions ^
R eq  X  fx i  X  X   X  21  X 
The final IAFS is depicted in Fig. 3 : the n -SVR algorithm is applied directly to the icing data set (8). 4. Experimental results and analysis
We tested the proposed systems using a data set of eight different icing events. Basic properties of these events are listed in Table 1 and in Section 4.3 . The storm of 3 X 5 December 2002 was the most severe event, causing significant damage to power lines and leaving many residents of the central and eastern US without electricity ( Jones et al., 2004 ). The remaining four events, although less severe, also caused notable damage and power outages ( Pytlak et al., 2010 ). The observations of ice amounts were made by 20 different Automated Surface Observation System (ASOS) stations scattered in southern and eastern US ( Fig. 4 ).

The first column of Table 1 shows the total amount of ice measured by all stations for each of the five events. The second column indicates the number of stations (locations) affected by the event. The last column shows the total number of icing observations per station, aggregated on a half-hour basis. To perform the ice accretion forecast, weather attributes were forecast for the locations where observations were available. For this purpose, the WRF v3 simulations were run in three nested grids with resolutions of 10.8 km, 3.6 km and 1.2 km. The outer-most domain covered an area of about 15,595 km 2 with a 38 38 grid. Pytlak et al. (2010) provides details of the configuration of the WRF runs. After the WRF predictions were made, four significant weather attributes were used for ice accretion fore-casts: wet bulb temperature, wind speed, precipitation rate, and fraction of frozen precipitation. The half-hourly predictions were then assigned to the locations and time intervals corresponding to the available ASOS observations. 4.1. Single-storm learning and cross-validation
To compare the performance of the two new systems to the previous approaches, we first applied each to the most significant storm of 3 X 5 December, 2002. During this event, an observer at each ASOS station measured the ground truth (i.e. the total accumulated amount of ice) by full-time backup and augmenta-tion ( Jones et al., 2004 ). Table 2 provides the ground truth, and 5-fold cross-validation forecast errors associated with various IAFS. Each forecasting method was applied to each half-hour WRF outputs. Subsequently, the predicted amounts of ice were aggregated for each station through the whole event to obtain the final amount of ice accretion. Minus predictions of ice were set to zero in the system.

The appropriate values for the parameters in the SVR algo-rithm were found experimentally, using 5-fold cross-validation. For each training set, comprising of four folds, the SVR parameters were tuned using yet another 5-fold cross-validation on this training set only. Using the best set of parameters, the fifth fold (not participating in the training process) was used for testing.
This process was repeated to run the tuning and test on all five folds. The right set of parameters depends on the target value distribution ( Cherkassky and Yunqian, 2004 ). As the distribution was different for the two data sets used to train FactorSVR and
IceSVR, the parameters were tuned separately. The resulting values were around C  X  5, n  X  0.7 for FactorSVR, and C  X  10,  X  0.2 for IceSVR. Both systems used a Gaussian kernel function with g  X  1, corresponding to 1/2 s 2  X  1 in formula (20). Results of this initial set of experiments are shown in Table 2 .
The row labeled  X  X  X AE X  X  contains the sum of absolute errors ( AE ) for all stations, obtained as P i predict i truth i , while the  X  X  RMSE  X  X  row shows the root mean squared error. The results show that
FactorSVR notably improves the ice forecasting accuracy in terms of AE . While the IAFS ( Musilek et al., 2009 ) and the IAFS-GA ( Pytlak et al., 2010 ) systems have an AE of about 23.5 mm, the FactorSVR algorithm achieves a better AE of 16.75 mm ( p o 0.05).
All claims of statistical significance involved paired t -tests in the experiments. Similar observations can be made in terms of the other measures listed in Table 2 .

As an extension to the basic SVR models, we also considered adding the location  X  X  X levation X  X  feature to the data sets, to evaluate its effect on the prediction accuracy. With this additional feature included, the accuracy of the system improved to 11.75 mm for FactorSVR (  X  elev). The direct prediction method, IceSVR, performed even better. Using the elevation feature,
IceSVR (  X  elev), AE dropped to 10.55 mm. This result is signifi-cantly better ( p o 0.05) than the best previously achieved AE of 23.5 mm.

Fig. 5 compares the performance of various forecasting sys-tems with respect to the measured amounts of ice, R eq , for all 20 stations. The ice amount predictions made by FactorSVR are much closer to the measurements than the GA method. The IceSVR system further improves prediction accuracy, and has fewer cases of ice under-prediction.

As the IAFS is to be used to predict hazards, low AE is very important. In addition, from the perspective of hazard forecasting, under-prediction is less desirable than over-prediction. The total amount of under-prediction is reported, for all systems, in
Table 2 ; see bottom row, labeled  X  X  P E ; E o 0  X  X . The table also contains two additional error indices, to provide a more complete view of the performance of the compared systems. The total error,
E , is the difference between the total amount of ice predicted by a particular system and the sum of corresponding measurements, i.e.

P that it can cancel out over-and under-predictions at different locations, possibly hundreds of kilometers apart. The mean absolute error (MAE), provides a direct measure of the average error per location. It is derived from the absolute error, i.e. AE / n . Table 2 shows that the new, SVR-based systems have better prediction performance according to all error indices but total error, E . This is caused by canceling out positive and negative errors, as explained above.

The root mean squared error (RMSE), follows a quadratic relationship with respect to the error, thus placing a much higher weight on large errors important for a hazard-forecasting system.
RMSE improved to 0.86 mm for IceSVR, compared to 1.45 mm for the IAFS-GA. The total under-predicted amount of ice (considering over-predictions as zero), over all 20 stations, was 3 mm for
IceSVR, compared to 12 mm for IAFS-GA. These results show that the SVR-based methods are suitable for the hazard-prediction applications in the electric power industry and similar fields. 4.2. Multiple-storm learning and cross-validation
To further examine the performance of the proposed SVM regression-based IAFS, four additional icing events were added to the data set. The best previously achieved results, obtained by the
IAFS-GA system using 10-fold cross-validation on the same data set, are reported in Table 3 , which also contains the error measures of FactorSVR and IceSVR systems. The same in-fold tuning process applied in the first experiment ( Section 4.1 ) was used. This tuning method provides an evaluation that is more reliable than a single run global tuning (followed by 10-fold cross-validation) used in the previous studies.

As in the single-storm case, the AE of each individual events and overall are improved by using the SVM regression models ( Fig. 6 ).
The FactorSVR system has the overall AE of 45.57 mm, compared to 80.76 mm of IAFS-GA system. The IceSVR (  X  elev) system achieves an overall AE of 38.46 mm. The grand-total error, P E , for IAFS-GA is very small, similar to the IceSVR (  X  elev). However, as can be seen in the first column of Table 3 , IAFS-GA system over-predicts the December 2002 storm by 21.98 mm ( Fig. 7 ). This high over-prediction compensates the under-predictions for the other storms, leading to the small value of P E . The other two measures reported in this table do not suffer this shortcoming, and confirm the high prediction accuracy of the SVR-based methods. The IceSVR(  X  elev) system achieved the total absolute error of 18.45 mm, and the sum of under-predictions of  X 10.17 mm. In comparison, the IAFS-GA achieved values of 56.82 mm and 29.26 mm, respectively. In terms of RMSE , IceSVR achieved value of 0.60, compared to 1.38 for
IAFS-GA ( p o 0.005). 4.3. Independent testing
To evaluate the generalization capability of the SVR-based forecasting systems, three additional icing events data were set aside and used for testing. For the experiments described in this section, the IceSVR system was used with parameters obtained using procedure outlined in Section 4.2 . FactorSVR results are not considered, as this system performed worse than IceSVR. The error measures of the IAFS-GA and IceSVR systems are reported in Table 5 . The IceSVR has lower overall AE , and lower E for two of the three events (2003 and 2007). The total under-prediction ( P
E ; E o 0) and sum of absolute errors over storms ( P 9 E slightly worse for the IceSVR than the IAFS-GA system. On the other hand, the IceSVR has a lower RMSE over all stations and storms. In summary, the generalization capability of IceSVR appears to be comparable to that of IAFS-GA.

A more detailed examination of Table 5 provides a hint about possible reason for the relatively poor generalization performance of IceSVR system: the event of December 15, 2005, has all error measures higher than IAFS-GA, while the other two events show the opposite trend. In general, the accuracy of any IAFS depends on the accuracy of weather forecasts that are used as the inputs to the ice accretion modeling subsystem. The accuracy of the WRF predictions for all eight icing events is shown in Table 4 . Only two most important attributes are considered: wind speed and pre-cipitation rate. The precipitation rate for the event of December 15, 2005, was predicted with a notably higher accuracy compared to the other two events. As all learning methods, SVR is driven by training data, and learns to compensate for any biases consis-tently present therein. Further examination of the table shows that the event of February 1, 2008 was predicted by WRF with the worst accuracy. By omitting this storm from the training set, and using only remaining four, IceSVR system achieved better gen-eralization when applied to the three new storms, as shown in
Table 5 . This system, referred to as IceSVR4, has parameters tuned to values C  X  8, n  X  0.2, and g  X  1, compared to C  X  13, n  X  0.1, and  X  1.2 for the original IceSVR.

Although not reported in Table 5 , FactorSVR system performed better than IAFS-GA in both generalization and cross-validation experiments. This is likely due to the engagement function not having a fixed structure as opposed to the function used in the GA system which has a predetermined fraction form. Further-more, IceSVR system outperformed FactorSVR in all experiments.
A possible explanation is that the performance of FactorSVR system depends on the fixed icing model. While such model may work well with directly measured weather data as input, this is not guaranteed with NWP hindcasts or forecasts. In contrast, IceSVR does not use any explicit accretion model and thus does not have this limitation. In addition, a detailed exam-ination of the training data revealed many cases where the output of the icing model was zero, while the ASOS measurements showed nonzero amounts of accretion. In such cases, no multi-plicative engagement factor can compensate for the zero output of the model. This allows IceSVR to achieve a superior prediction performance. 5. Conclusions and future work
This paper introduces two ice accretion forecasting systems based on the Support Vector Regression learning algorithm. The first system is based on an explicit ice accretion model, while the second system applies the SVR algorithm directly. Both systems were trained, verified, and tested using an extensive data set containing eight different icing events which took place over a period of 7 years, in an area of thousands of squared kilometers.
The results show that the forecasting performance of the SVR-based systems is superior to other state-of-the-art forecasting systems. The IceSVR system, which directly learns a regression model of ice accretion without an explicit physical model, achieves significantly better forecast performance in comparison to FactorSVR and other systems described in recent literature.
Furthermore, the proposed inclusion of elevation as an exogenous feature was found to further improve forecast accuracy. Based on a number of experiments, the IceSVR (  X  elev) system can be considered a good choice for development of an operational ice accretion forecasting system for use in power industry. This statement is supported by low total error, and the low sum of under-predictions, which is significant because of the hazard-prediction nature of the application.

Currently, the SVR algorithm is not bounded and may predict negative amounts of ice. It would be more reasonable to constrain the SVR learning process to non-negative functions. This task will be part of our future research. Another limitation of this study is that the algorithms are trained and tested using data sets containing only positives, i.e. specific icing events. Further model training and assessment should consider more general data sets, including both positive and negative cases, i.e. periods with and without freezing rain. Finally, the current study could be extended to consider dynamics of ice accretion ( Makkonen, 1984 ; Fu et al., 2006 ). Most empirical models consider the accretion process to be static, which is appropriate for icing events of short to medium duration (up to 30 h)  X  such as our current study. However, the accretion rate can decrease signifi-cantly over long ice storms, which can lead to overprediction of the total amount of accreted ice by our model. Although this is not critical for a hazard prediction system, correct modeling of long icing events may require the use of different learning algorithms designed to handle time series data.
 References
