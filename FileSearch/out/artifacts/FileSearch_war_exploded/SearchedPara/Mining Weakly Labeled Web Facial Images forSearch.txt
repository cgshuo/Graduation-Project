 In this paper, we investigate a search-based face annotation frame-work by mining weakly labeled facial images that are freely avail-able on the internet. A key component of such a search-based an-notation paradigm is to build a database of facial images with ac-curate labels. This is however challenging since facial images on the WWW are often noisy and incomplete. To improve the label quality of raw web facial images, we propose an effective Unsuper-vised Label Refinement (ULR) approach for refining the labels of web facial images by exploring machine learning techniques. We develop effective optimization algorithms to solve the large-scale learning tasks efficiently, and conduct an extensive empirical study on a web facial image database with 400 persons and 40,000 web facial images. Encouraging results showed that the proposed ULR technique can significantly boost the performance of the promising search-based face annotation scheme.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval; I.2.6 [ Artificial Intelligence ]: Learning Algorithms, Experimentation web facial images, auto face annotation, unsupervised learning
Due to the popularity of various digital cameras and the rapid growth of Internet-based photo sharing, recent years have witnessed an explosion of the number of photos captured and stored by con-sumers. A large collection of photo images which are usually un-labeled raises a great challenge for end users to browse and search. One possible solution is to tag images manually, which is however time-consuming and often costly for large photo collections.
Instead of annotating images manually, another more salient tech-nique to overcome this challenge is automated image annotation [ 7], which aims to automatically assign an image some metadata typi-cally in the form of captions or keywords to describe the semantic concepts/objects in the image. Despite being studied extensive-ly [ 4, 7, 8], existing techniques for generic image annotation re-m ain far from practical and satisfactory in real-world applications. Unlike the existing generic image annotation, in this paper, we ad-dress a specific sub-topic, i.e., auto face annotation , which aims to detect human faces from a photo image and to annotate the human names to the facial image.

Auto face annotation can be beneficial to many real-world ap-plications. For example, with auto face annotation techniques, on-line photo-sharing sites (e.g., Facebook) can automatically anno-tate users X  uploaded photos to facilitate online photo search and management. Besides, face annotation can also be applied in news video domain to detect important persons appeared in the videos to facilitate news video retrieval and summarization tasks [ 17 ].
C onventional face annotation methods usually adapt existing face recognition techniques by training multi-class face classification models from a collection of human-labeled facial images using su-pervised machine learning techniques [ 2, 25 ]. We refer to such k ind of conventional techniques as  X  X odel-based face annotation". Such approach is however limited in several aspects. First, it is usually time-consuming and expensive to collect a large amount of human-labeled training facial images. Second, it is usually difficult to generalize the models when new training data or new persons are added, in which an intensive re-training process is usually required. Last but not least, the annotation/recognition performance often s-cales poorly when the number of persons/classes is very large.
To address the above limitations, in this paper, we investigate a promising search-based framework for auto face annotation, which aims to exploit large amount of weakly labeled facial images that are freely available on the World Wide Web (WWW). Unlike the conventional model-based approaches, the proposed framework is data-driven and model-free, which annotates a novel facial image by a retrieval-based annotation process [ 22 ]. In particular, given a n ovel facial image for annotation, we first retrieve a set of k most similar facial images from a weakly labeled facial image database, and then label the novel facial image by performing voting on the labels associated with the top k similar facial images.
A key challenge in the above search-based face annotation frame-work is that labels with web facial images are usually noisy and sometimes may be incomplete due to the nature of image upload-ing and tagging by WWW users. This is critical as the label quality of the database can considerably affect the final annotation perfor-mance of the search-based face annotation process. To overcome this challenge, in this paper, we propose a novel unsupervised la-bel refinement scheme by studying machine learning techniques to enhance the labels purely from the weakly-labeled data without hu-man manual efforts. As a summary, the main contributions in th is paper include the following:
The rest of this paper is organized as follows. Section 2 reviews the related work. Section 3 gives an overview of the proposed search-based face annotation framework. Section 4 presents the proposed unsupervised label refinement scheme by learning from weakly labeled data. Section 5 discusses our experiments for per-formance evaluation, and Section 6 concludes this paper. Our work is related to several groups of research.

The first group is on the topics of face detection, verification and recognition. Face detection, verification and recognition are classi-cal research problems in computer vision and pattern recognition, which have been extensively studied for many years [ 1, 28 ]. Re-s earchers have developed a variety of face databases for the bench-mark of face detection and recognition techniques, such as the well-known FERET database [ 15 ]. The traditional studies are often lim-i ted for the high-quality databases collected in well-controlled envi-ronments. Recent years have observed some emerging benchmark studies of unconstrained face detection and verification techniques on facial images that are collected from the web, such as the LFW benchmark studies [ 11 , 3]. A comprehensive survey on face detec-t ion and recognition topics can be found in [ 28 , 10 ].
T he second group of related work is on the topic of face anno-tation. In general, face annotation can be viewed as an extended face detection and recognition problem. Some studies in literature have attempted to adapt existing face recognition techniques for face annotation tasks by formulating the problem as a supervised face classification task [ 2, 26 , 25 , 17 ]. For example, the work in [ 2] a dapted the Fisher X  X  linear discriminant analysis method for face annotation, the study in [ 26 ] employed a Bayesian method for face a nnotation, and the work in [ 25 ] adopted the Support Vector Ma-c hines (SVM) to train and predict the probabilities of human names towards transcript matching faces in the videos. Besides the super-vised learning approaches, some existing work also attempts to ap-ply semi-supervised learning for face annotation. For example, the work in [ 31 ] proposed a transductive kernel Fisher discriminan-t for face annotation, which employs both labeled and unlabeled data to train classification models for the annotation tasks. Our work differs from the above existing studies in that our method is model-free by adopting the emerging search-based annotation paradigm for auto face annotation, which is fully data-driven by mining weakly labeled web facial images.

The third group of related work is on the topics of auto image annotation [ 12 , 9, 21 ] and some recent emerging studies on search-b ased image annotation [ 22 , 23 , 24 ]. Conventional image annota-t ion approaches have been studied extensively, which usually apply some existing object recognition techniques to train classification models from human-labeled training images [ 7, 8, 4]. Recently, t here is a surge of interests for exploring web image repositories for auto image annotation and object recognition problems using the retrieval-based annotation paradigm [ 22 ]. For example, Rus-s ell et al. [ 16 ] developed a large collection of web images with g round truth labels to facilitate object recognition research. Wang et al. [ 22 ] proposed a fast retrieval-based approach for image an-n otation by studying some efficient hashing technique. Torralba et al. [ 20 ] suggested efficient image search and scene matching tech-n iques for exploring a large-scale web image repository. These s-tudies usually concerned more on efficient indexing and searching techniques, while our work focuses on improving the label quality by machine learning techniques.

The final group of closely related work is about mining web fa-cial images, which aims to leverage noisy web facial images for face recognition [ 2, 13 , 27 ]. For example, Berg et al. [ 2] crawled a large number of news pictures and captions from the WWW, and proposed a modified k-means clustering approach for clean-ing up noisy web facial images. Recently, Le et al. [ 13 ] proposed a t wo-step re-ranking scheme to purify text-based retrieval results for some special names. Zhao et al. [ 27 ] proposed a consistency learn-i ng method to train face models for famous people by mining the text-image co-occurrence on the web as a weak signal of relevance towards supervised face learning task from a large and noisy train-ing set. Unlike the above existing works that were not designed to optimize the search-based face annotation paradigm, our novel unsupervised label refinement scheme is proposed to optimize the label quality for the search-based face annotation task. Finally, we note that our learning methodology for solving the unsupervised la-bel refinement task is partially inspired by some existing studies in machine learning, including graph-based semi-supervised learning and multi-label learning techniques [ 32 , 19 , 5].
Figure 1 illustrates the system flow of the proposed search-based face annotation scheme, which consists of the following steps: (1) facial images data collection, (2) face detection and facial feature extraction, (3) high-dimensional facial feature indexing, (4) learn-ing with weakly labeled data, (5) similar face retrieval, (6) face an-notation by majority voting from similar faces with their improved labels. The first four steps are conducted before the test phase of a face annotation task, while the last two steps are conducted during the test phase of a face annotation task, which thus should be done very efficiently. We describe each step briefly as follows. The first step is the collection of facial image data as shown in Figure 1(a), in which we crawled facial images from the WWW by web search engines (e.g., Google) based on a name list that stores the names of persons to be collected. This crawling process pro-duces a collection of facial images, each of them is associated with some human name. Given the nature of web images, these facial images are often noisy, which do not always correspond to the right human name. Thus, we call such kind of web facial images with noisy names as weakly labeled facial image data.

The second step is to pre-process web facial images to extract face-related information, including face region detection and align-ment, face region extraction, and facial feature representation. For facial region detection and alignment, we adopt the unsupervised face alignment technique in [ 30 ]. For facial feature representation, w e extract the GIST features [ 18 ] to represent the extracted faces. A s a result, each face can be represented as a d -dimensional vector.
The third step of the framework is to index the extracted features of the faces by applying some efficient high-dimensional indexing technique to facilitate the task of similar face retrieval in the subse-quent step. In our approach, we adopt the Locality-Sensitive Hash-and use their associated names for voting towards auto annotation. ing (LSH) [ 6], a popular and effective high-dimensional indexing t echnique for approximate nearest neighbor search.

Besides the indexing step, another key step of our framework is to engage an unsupervised learning scheme to enhance label quality of the weakly labeled facial images. This process is critical to the entire search-based annotation framework since the label quality considerably affects the final annotation performance.

All the above are the processing steps before annotating a query facial image. Next we describe the process of face annotation dur-ing the test phase. In particular, given a query facial image for an-notation, we first conduct a similar face retrieval process to search for a subset of most similar faces (typically top k similar face ex-amples) from the previously indexed facial database. With the set of top k similar face examples retrieved from the database, the next step is to annotate the facial image with a label (or a subset of la-bels) by employing a majority voting approach that combines the set of labels associated with these top k similar face examples.
In this paper, we pay our main attention on the key step of the above framework, i.e., the unsupervised learning process to refine labels of the weakly labeled facial images.
In this section, we present a novel Unsupervised Label Refine-ment (ULR) scheme to refine the labels of web facial image data by learning with weakly labeled data. In the following, we first in-troduce some preliminaries and notations followed by the problem formulation and the proposed algorithms.
We denote by X  X  R n  X  d the extracted facial image features, where n and d represent the number of facial images and the num-ber of feature dimensions, respectively. Further we denote by  X  = { n 1 , n 2 , . . . , n m } the list of human names for annotation, where m is the total number of human names. We also denote by Y  X  [0 , 1] n  X  m the initial raw label matrix to describe the weak label information, in which the i -th row Y i  X  represents the label vector of the i -th facial image x i  X  R d . In our application, Y is often noisy and incomplete. In particular, for each weak label value Y Y ij 6 = 0 indicates that the i -th facial image x i has the label name n , while Y ij = 0 indicates that the relationship between i -th fa-cial image x i and j -th name is unknown. Note that we usually have k Y i  X  k 0 = 1 since each facial image in our database was uniquely collected by a single query.

Following the terminology of graph-based learning methodolo-gy, we build a sparse graph by computing a weight matrix W = [ W ij ]  X  R n  X  n , where W ij represents the similarity between x and x j defined as follows: where n K ( x j ) denotes the K  X  n nearest neighbor list of the data point x j based on Euclidean distance.
The goal of the Unsupervised Label Refinement (ULR) task is to learn a refined label matrix F  X   X  R n  X  m to improve the initial raw label matrix Y . This is challenging since we have nothing else but the raw label matrix Y and the data examples X themselves. To attack this challenge, we propose a graph-based learning solution based on a key assumption of  X  X abel smoothness", i.e., the more similar the visual contents of two facial images, the more likely they share the same labels. The label smoothness principle can be formally formulated as an optimization problem of minimizing the following loss function E s ( F, W ) : where kk F denotes the Frobenius norm, W is a weight matrix of a sparse graph built from the n facial images, L = D  X  W denotes the Laplacian matrix where D is a diagonal matrix with diagonal elements as D ii = P n j =1 W ij , and tr denotes a trace function.
Directly optimizing the above loss function is problematic as it will yield a trivial solution. To tackle this challenge, we notice that the initial raw label matrix usually, though being noisy, still con-tains some correct and useful label information. Thus, when we optimize to search for the new label matrix F , we shall avoid the solution F being deviated too much from the raw label matrix Y . To this end, we formulate the following optimization task for the unsupervised label refinement problem by including a regular iza-tion term E p ( F, Y ) to reflect this concern: where  X  is a regularization parameter and F  X  0 enforces F is nonnegative. Next we discuss how to define an appropriate function for E p ( F, Y ) .

One possible choice of E p ( F, Y ) is to simply set E p ( F, Y ) = k F  X  Y k 2 F . This is however not appropriate as Y is often very sparse, i.e., many elements of Y are zeros due to the incomplete nature of Y . Thus, the above choice is problematic since it may simply force many elements of F to zeros without considering the label smoothness. A more appropriate choice of the regularization should be applied only to those nonzero elements of Y . To this end, we propose the following choice of E p ( F, Y ) : where S is a  X  X ign" matrix S = [ sign ( Y ij )] where sign ( x ) = 1 if x &gt; 0 and 0 otherwise, and  X  denotes the Hadamard product (i.e., the entrywise product) between two matrices.

Finally, we notice that the solution of the optimization in (3) is generally dense, which is again not desired since the true label matrix is often sparse. To take the sparsity into consideration, we introduce a sparsity regularizer E e ( F ) by following the  X  X xclusive lasso" technique [ 29 ]: where we introduce an  X  1 norm to combine the label weights for the same person with respect to different names, and an  X  combine the label weights of different persons together. Combin-ing this regularizer and the previous formulation, we have the final formulation as follows: where  X   X  0 and  X   X  0 are two regularization parameters. The above formulation combines all the terms in the objective function, which we refer it to as  X  X oft-Regularization Formulation" or  X  X RF" for short.

Another way to introduce the sparsity is to formulate the op-timization by including some convex sparsity constraints, which leads to the following formulation: where  X   X  0 and  X  &gt; 1 . We refer to this formulation as  X  X onvex-Constraint Formulation" or  X  X CF" for short.

It is not difficult to see that the above two formulations are con-vex, which thus can be solved with global optima by applying con-vex optimization techniques. Next, we discuss efficient algorithms to solve the above optimization tasks.
The above optimization tasks belong to convex optimization or more exactly quadratic programming (QP) problems. It seems to be possible to solve them directly by applying generic QP solver-s. However, this would be computationally highly intensive since matrix F can be potentially very large, e.g., for a large 400 -person database of totally 40,000 facial images in our experiment, F is a 40000  X  400 matrix that consists of 16 million variables, which is almost infeasible to be solved by any existing generic QP solver.
We firstly adopt an efficient algorithm to solve the problem in E-q. 6, then propose a coordinate descent based approach to improve t he scalability. By vectorizing matrix F  X  R n  X  m into a colum-n vector  X  f = vec ( F )  X  R ( n m )  X  1 , we can reformulate g ( F ) as follows: g ( F ) = tr ( F  X  LF ) +  X  k ( F  X  Y )  X  S k 2 F +  X  k F 1 k where  X  denotes the Hadamard product,  X  denotes the Kronecker I m  X  L  X  , V = ( 1  X   X  I n ) , R = diag (  X  s ) , Q = U +  X R +  X V c =  X  2  X R  X   X  y , h =  X   X  y  X  R  X  y and I k is an identity matrix with dimension k  X  k .

The above optimization is clearly a QP problem. To solve it efficiently, we adopt an accelerated multi-step gradient algorithm, which converges at O ( 1 k 2 ) , k i s the iteration step.
First of all, we reformulate the QP problem as follows: x  X  = arg min We then define a linear approximation function p t ( x , z ) for the above function q at point z : where t is the Lipshitz constant of  X  q . In order to achieve the opti-mal solution x  X  , we will update two sequences { x ( k ) recursively. Commonly at each iteration k , the variance z named as search point and used for constructed combination of the two previous approximate solutions x ( k  X  1) and x ( k  X  2) proximation x ( k ) is achieved by the following optimization: After ignoring terms that do not depend on x , the former optimiza-tion problem Eq. 14 could be equally presented as: m in where g = 2 Q z ( k ) + c . The closed-form solution is given below: Finally, Algorithm 1 summarizes the optimization progress. Algorithm 1: M ulti-step Gradient Algorithm for ULR
O utput : x  X   X  R n m 1 begin 2  X  0 = 1 ; k = 1 ; z (0) = x (0) = x (  X  1) = 0 ; 3 repeat 4 C ase SRF : Achieve x ( k ) with Eq. 14 ; 5 C ase CCF : Achieve x ( k ) with Eq. 19 ; 8 k = k + 1 ; 9 until CONVERGENCE ;
To further improve the scalability, we propose a coordinate d e-scent approach to solving the optimization iteratively. This can take advantages of the power of parallel computation when solving very large-scale problems.

For the proposed coordinate descent approach, at each iteration, we optimize only one label vector F i  X  by leaving the others { F i } intact. Specifically, at the ( t + 1) -th iteration, we define the fol-lowing optimization problem for updating F ( t +1) i  X  with F where the objective function  X  is defined as follows: where  X  L i  X   X  R 1  X  ( n  X  1) is the i -th row of Laplacian matrix L removing the i -th element L ii ,  X  F  X  R ( n  X  1)  X  m is a sub-matrix of F by removing its i -th row F i  X  , z = f  X  Y  X  i  X  , R = diag ( S T = 1 1  X  ,  X  Q = L ii I M +  X R +  X T ,  X  c = 2(  X  L i  X   X 
The Eq. 17 is also a smooth QP problem, but much smaller than t he original Eq. 10 . Similarly, it could be solved efficiently by Al-g orithm 1. The pseudo-code of the coordinate descent algorithm is s ummarized in Algorithm 2.
 Algorithm 2: C oordinate Descent Algorithm for ULR Input : X  X  R n  X  d , Y  X  [ 0 , 1] n  X  m
Output : F  X   X  R n  X  m 1 begin 2 t = 0 and F ( t ) = Y ; 3 repeat 4 for i = 1 to n do 5 C ase SRF: Achieve F ( t +1) i  X  with Eq. 17 ; 6 C ase CCF: Achieve F ( t +1) i  X  with Eq. 25 ; 7 t = t + 1 ; 8 until CONVERGENCE ;
F or the convex-constraint formulation, by doing vectorization, we can reformulate Eq. 8 into the following: m in where Q  X  = U +  X R ,  X   X  1 , and all the other symbols are the same as Eq. 10 . We also apply the multi-step gradient scheme to s olve Eq. 18 , however the constraint for the sub-problem is slightly d ifferent from Eq. 15 , which is defined:
We can split the vector x into a series of sub-vectors  X  x [ x Eq. 19 could be reformulated as: The above optimization can be decoupled for each sub-vector  X  x and solved separately in linear time by following the Euclidean pro-jection algorithm proposed in [ 14 ]. Specifically, we can obtain the o ptimal solution  X  x i X  for  X  x i with the following problem: where  X  x i X  has a linear relationship with the optimal Lagrangian variable  X   X  , which is introduced by the inequlaity constrain k  X  x  X  : where sign ( ) is the aforementioned sign function. Suppose S = { j |  X  v i j  X  0 } , the optimal  X   X  could be obtained: where  X   X  is the unique root of function f (  X  ) : f (  X  ) is continuous and monotonically decreasing in (  X  X  X  ,  X  ) . The root  X   X  can be obtained by the bisection search algorithm in lin-ear time. An improved searching scheme was also proposed in [ 14 ] u sing the characteristic of function f (  X  ) .

Similar to the soft-regularization formulation, we can also adopt the coordinate descent scheme to further improve the scalability. In particular, we define a new update function  X   X  similar to the aforementioned formula in Eq. 17 : where  X   X  ( f | F, i ) = f  X   X  Q  X  f +  X  c  X  f and all symbols are the same as Eq. 17 except  X  Q  X  = L i i I M +  X R . Eq. 25 is a special case of t he optimization problem in Eq. 18 , and can be solved efficiently b y the same algorithm. Finally, the pseudo codes of the algorithm for the convex-constraint formulation are similar to the previous, as shown in Algorithm 1 and Algorithm 2.
In this section, we conducted extensive experiments to evalu-ate the performance of the proposed ULR technique for automated face annotation. In the following, we first introduce our experimen-tal testbed, then discuss the comparison schemes and experimental setup, and finally present our experimental results.
To build our testbed, we first collected a name list consisting of 400 popular actor and actress names downloaded from the IMD-b website http://www.imdb.com . We collected those names w ith the billboard:  X  X ost Popular People Born In yyyy " of IMD-b , where yyyy is the born year, e.g., the webpage 1 presents all t he actor and actresses who were born in 1975 in the popularity or-der. Our name list covers the actors and actresses who were born between 1950 and 1990. We submitted each name from the list as a query to search for related web images by Google image search en-gine. The top 200 retrieved web images are crawled automatically. After that we use the OpenCV toolbox to detect the faces and adopt F igure 2: Two example sets of weakly labeled facial images where wrongly labeled images were highlighted by red boxes: (a) a good case of most images correctly labeled, and (b) a bad case of half of them wrongly labeled. the DLK algorithm [ 30 ] to align facial images into the same well-d efined position. The no-face-detected web images were ignored. As a result, we collected over 40 , 000 facial images in our database. We refer to this database as the  X  X etrieval database", which will be used for facial image retrieval during the auto face annotation pro-cess. Figure 2 shows two examples in our database.

W e also built a  X  X est dataset" by randomly choosing 80 names from our name list. We submitted each selected name as a query to Google and crawled about 100 images from top 200 to 400 search results. Note that we did not consider the top 200 retrieved images since they had already appeared in the retrieval dataset. This aim-s to examine the generalization performance of our technique for unseen facial images. Since these facial images are often noisy, to obtain ground truth labels for the test dataset, we request our staff to manually examine the facial images and remove the irrelevant fa-cial images for each name. As a result, the test database consists of about 1000 facial images with over 10 faces per person on average. We run all the experiments on a PC with an Intel(R) Xeon(R) CPU (W3520), 12 G memory and MATLAB 2010(b). To handle a very large-scale optimization task of 16-million unknown variables, we adopted the Parallel Toolbox in Matlab to exploit the parallel computation power.
In our experiments, we implemented all the proposed algorithms for solving the ULR task. We finally adopted the soft-regularization formulation of the proposed ULR technique in our evaluation since it is empirically faster than the convex-constraint formulation ac-cording to our implementations. To better examine the efficacy of our technique, we also implemented some baseline annotation method and existing algorithms for comparisons. Specifically, the compared methods in our experiments include the following:
For a fair comparison to the above approaches, we adopted the same GIST features to represent the facial images. To evaluate their annotation performances, we adopted the hit rate at top t annotated results as the performance metric, which measures the likelihood of having the true label among the top t annotated names. For each query facial image, we retrieved a set of top K similar facial images from the database set, and return a set of top T names for annotation by performing a majority voting on the labels associated with the set of top K images.

Further, we discuss parameter settings. For the ULR implemen-tation, we constructed the sparse graph W by setting the number of nearest neighbors to 5 for all cases. In addition, for the two key regularization parameters  X  and  X  in the proposed ULR algorithm, we set their values via cross validation. In particular, we randomly divided the test dataset into two equally-sized parts, in which one part was used as validation to find the optimal parameters by grid search, and the other part was used for testing the performance. This procedure was repeated 10 times, and their average perfor-mances were reported in our experiments.
Table 1 and Figure 3 show the average annotation performance ( hit rates) at different T values, in which both mean and standard deviation were reported. Several observations can be drawn from the results.
 Figure 3: Evaluation of auto face annotation performance in t erms of hit rates at top T annotated names.

First of all, it is clear that ULR which employs unsupervised learning to refine labels consistently performs better than the ORI baseline using the original weak label, the existing CL algorithm and MKM algorithm. For example, by comparing the hit rate at the first annotated name, ORI, CL and MKM achieved 54 . 8% , 63 . 4% and 57 . 8% respectively, while ULR can significantly boost the hit rate to 71 . 5% . For the hit rate at top 10 annotated names, the result of ORI, CL and MKM are 91 . 4% and 92 . 8% and 94 . 3% respective-ly, while ULR can achive a better hit rate 96 . 8% . The promising result validates the effectiveness of the proposed ULR technique for improving search-based face annotation. Second, when T is small, the hit rate gap, i.e., the hit rate difference between ORI and ULR is more significant, which verifies that the proposed ULR algorithm could efficiently refine the noisy data. Finally, we observed that the annotation performance increases slowly when T &gt; 5 . In practice, we usually focused on the a small T value since users typically would not be interested in a long list of annotated names. Table 1: Evaluation of auto face annotation performance in t erms of hit rates at top T annotated names.

ORI 0.548 0.661 0.766 0.837 0.872
MKM 0.578 0.717 0.797 0.856 0.882
ULR 0.715 0.809 0.859 0.892 0.916
ORI 0.892 0.898 0.907 0.912 0.914
MKM 0.902 0.910 0.918 0.930 0.943
ULR 0.927 0.936 0.946 0.958 0.968
This experiment aims to examine the annotation performance un-der varied values of K and T respectively for top-K retrieved im-ages and top-T annotated names. To ease our discussion, we only show the results of the ULR algorithm. The performance differ-ences between the ULR algorithm and the baseline algorithm as well as the CL algorithm are mostly similar to the observations in the previous experiment. The face annotation performance of var-ied K and T values are illustrated in Figure 4 and Table 2 where b oth mean and standard deviation results were reported. Figure 4: Annotation performance of varied K a nd T values. Some observations can be drawn from the experimental results. First of all, when fixing K , we found that increasing T value gen-erally leads to better hit rate results. This is not surprising since generating more annotation results certainly gets a better chance to hit the relevant name. Second, when fixing T , we found that the impact of the K value to the annotation performance fairly de-pends on the specific T value. In particular, when T is small (e.g., T = 1 ), increasing the K value leads to the decline of the annota-tion performance; but when T is large (e.g., T &gt; 5 ), increasing the K value often boosts the performance of top-T annotation results. Such results can be explained as follows. When T is very small, e.g., T = 1 , we prefer a small K value such that only the most relevant images will be retrieved, which thus could lead to more precise results at top-1 annotated results. However, when T is very large, we prefer a relatively large K value since it can potentially retrieve more relevant images and thus can improve the hit rate at top-T annotated results.
 Table 2: Annotation performance of varied K and T values.
K=05 0.747 0.827 0.868 0.882 0.894
K=10 0.735 0.831 0.870 0.886 0.906
K=20 0.725 0.828 0.877 0.900 0.920
K=40 0.715 0.809 0.859 0.892 0.916
K=05 0.894 0.895 0.895 0.896 0.896
K=10 0.911 0.919 0.924 0.927 0.928
K=20 0.935 0.945 0.950 0.952 0.956
K=40 0.927 0.936 0.946 0.958 0.968
This experiment aims to further examine how the annotation per-formance is affected by the number of facial images per person in building the facial image database. Unlike the previous experiment with top 100 retrieval facial images per person in the database, we created three variants of varied-size databases, which consist of top 50 , 75 , and 100 retrieval facial images per person, respectively. We denote these three databases as P 050 , P 075 , and P 100 , respectively.
Figure 5 shows the experiment results of average annotation per-f ormance. We can draw some observations. First of all, it is clear that the larger the number of facial images per person collected in our database, the better the average annotation performance can be achieved. Second, similar to the previous observations, ULR con-sistently boosts the annotation performance for all the databases, and achieves the best performance by beating the other competitors for all the cases. Finally, we noticed that enlarging the number of facial images per person in general leads to the increases of com-putational costs, including time and space costs for indexing and retrieval as well as the ULR learning costs.
There are two key parameters  X  and  X  in the ULR algorithm. In the previous experiments, we found the best values by cross vali-dation. In this experiment, we further examine their sensitivity to the annotation performance. Figure 6 shows an evaluation of anno-t ation performance by a grid search on varied values of parameter  X   X  [0 . 1 , 0 . 6] and  X   X  [0 , 0 . 7] in one of cross validation experi-ments. The value of each vertex on the color mesh represents the hit rate gap between ULR and ORI. Figure 6: Evaluation of parameter sensitivity with respect t o  X  and  X  for T = 1 . The values of the vertex on the color mesh illustrate the hit rate gap between ORI and ULR.

Some observations can be drawn from the results. First, we found that for all  X  and  X  values, the proposed ULR scheme al-ways has a positive improvement over ORI with original labels. Second, we found that the best  X  and  X  values are about 0 . 3 and 0 . 1 , respectively. Further, we noticed that it is not difficult to find such good  X  and  X  values to get comparable results. Typically, ULR attains fairly good results when choosing  X   X  [0 . 2 , 0 . 4] and  X   X  [0 . 01 , 0 . 4] . These results show that ULR is quite robust to the parameters and could always enhance the annotation performance.
This section aims to conduct extensive evaluations on the run-ning time cost by the four proposed algorithms. To distinguish the previous four algorithms clearly, in the following subsections, we will refer to the four algorithms by the following abbreviations:
We first compare two algorithms: SRF-MGA and CCF-MGA, which adopt the same gradient-based optimization scheme for two different formulations, as shown in Algorithm 1. We adopted an ar-t ificial dataset with varied numbers of classes m = 20, 40, 60, 80, 100 where each class corresponds to a unique Gaussian distribu-tion. We set the number of examples generated from each class as P = 100 , and the total number of examples n = 2000, 4000, 6000, 8000, 10000. The goal of the ULR optimization is to optimize the refined label matrix F  X  R n  X  m , which has the total number of un-known variables V = 40000, 160000, 360000, 640000, 1000000, respectively for each of the above cases. For the iteration number, we set it to 50 for both algorithms.

We randomly generated the artificial datasets and run the algo-rithms over these random datasets. This procedure was repeated five times. Table 3 show the average running time cost, where the fi rst two columns are the means and their standard deviations ob-tained by both SRF-MGA and CCF-MGA algorithms, respectively. Figure 7 (a) further illustrates these results. Some observations ca n be drawn from these results as follows. F igure 7: The running time of the proposed four algorith-m (SRF-MGA, CCF-MGA, SRF-CDA, CCF-CDA). The group size P is 100 . The x -axis presents the number of variables V , The y -axis is the running time(seconds).

First of all, it is clear that increasing the number of variables leads to the increase of the running time cost for both algorithms. Second, by comparing the two algorithms based on two different formulations, we found that the time cost growth rate of SRF-MGA is always slower than that of CCF-MGA, which indicates that SRF-MGA runs always more efficiently than CCF-MGA.

To further compare the difference of their growth rates, we try to fit the running time costs T w.r.t the number of variables V by a function T = a  X  V b , where a, b  X  R are two parameters. By fit-ting the functions using the data shown in Figure 7(a), we obtained a = 9 . 04 E  X  7 and b = 1 . 45 for SRF-MGA, and a = 3 . 70 E  X  8 and b = 1 . 74 for CCF-MGA.

We compare running time cost of RF-CDA and CCF-CDA by adopting the similar settings as the previous experiment. For the iteration number, we set the outer-loop iteration number for CDA Table 3: Average running time (seconds) of the proposed algo-r ithms, where the 2nd rows show the standard deviations. 40000 4.80 6.76 76.63 136.50 160000 29.04 49.05 197.92 330.30 360000 95.43 178.45 399.11 607.20 640000 228.44 494.29 670.23 950.40 1000000 428.46 1076.04 1022.70 1457.40 to 3 0 and fix the inner iteration number w.r.t. their subproblems to 30 . The average running time cost and their standard deviations are illustrated in the last two columns of Table 3 and Figure 7(b).
F irstly, the SRF-based algorithm SRF-CDA spent less time cost than the CCF-based algorithm CCF-CDA. Second, unlike the pre-vious results of the MGA based algorithms, we found that the run-ning time cost grows almost linearly w.r.t the number of variables for both CDA based algorithms. More specifically, by fitting the time cost function T = a  X  V b w.r.t. the number of variables V , we have a = 3 . 93 E  X  3 and b = 0 . 90 for SRF-CDA, and a = 1 . 50 E  X  2 and b = 0 . 83 for CCF-CDA, which show that the time cost growth rates of both algorithms are empirically sublinear. This encouraging result indicates that both CDA based algorithms are efficient and scalable for large-scale datasets.
This experiment is to evaluate running time cost of the CDA-based algorithms (SRF-CDA and CCF-CDA) on our 400-person weakly labeled real web facial image dataset. For this real dataset, we have 400 persons and about 100 images for each person, which leads to 40000 images and 16-million unknown variables in our optimization task. We skipped the evaluation of MGA-based algo-rithms (SRF-MGA and CCF-MGA) since they are computationally too intensive for this large-scale experiment.

We randomly chose P = { 50 , 75 , 100 } images from each per-son to build three databases of different sizes. We refer to these databases as P 050 , P 075 and P 100 , respectively. We set the out-er iteration number to 10 for both algorithms, and fixed the inner iteration number for their subproblems to 30 . First, we employed the CDA-based algorithms (SRF-CDA and CCF-CDA ) directly on those three databases, then we adopted the  X  Parallel Computing Toolbox " in Matlab to speed up the loop structure. We simply used the command  X  matlabpool 4 " to estimate 4 local labs for the paral-lel computing task. The final results are presented in Table 4.
T wo observations can be drawn from the above results. First, the same as the previous results, SRF-CDA is faster than CCF-CDA on the real database. Secondly, after applying the  X  Parallel Computing Toolbox ", the running time is significantly reduced, which saved roughly two-third of the total time cost.
This experiment is to evaluate the convergence rates of the four different optimization algorithms. In particular, we consider a toy dataset with m = 100 , P = 100 , n = 10000 . Figure 8 show the e valuations on the objective functions of the four different algo-rithms. For each algorithm, the average running time per iteration was also displayed on each of the figures. Some observations can be drawn from the results.
 Table 4: The running time cost (seconds) of SRF-CDA and CCF-CDA algorithms on 400-person retrieval database. The top two rows show the running time cost of algorithms with-out parallel computing. The last two rows show the results us-ing X  Parallel Computing Toolbox " in Matlab.
 Sequential P050 P075 P100 SRF-CDA 2726.1  X  2 7.9 4078.0  X  2 6.3 5506.0  X  2 2.7 CCF-CDA 2999.6  X  3 3.4 4519.6  X  3 4.7 6131.3  X  3 1.8 Parallel P050 P075 P100 SRF-CDA 1072.3  X  1 6.6 1556.0  X  1 3.2 2022.6  X  1 3.3 CCF-CDA 1184.1  X  1 8.6 1805.9  X  2 1.5 2337.2  X  1 1.3 First of all, it is clear that all the algorithms converge quic kly. In particular, the two MGA-based algorithms almost converged af-ter 10 iterations, which is slightly slower than the two CDA-based algorithms that almost converged after 8 iterations. Second, with the same formulation, we can see that the final objective values ob-tained by two different solvers are very close, which validates the correctness of the proposed algorithms. Finally, in terms of time cost per iteration, we found that the algorithms based the SRF for-mulation are faster than the algorithms based on the CCF formu-lations. More details about the running time cost comparison are given in the subsequent section.
 Figure 8: The objective function values of the four different o ptimization algorithms at each iteration on the toy data with m = 100 , P = 100 and n = 10000 . The average running time per iteration was also displayed on each of the figures.
Despite the encouraging results, our work is limited in some as-pects. First, in our experiments, we assume each name corresponds to a unique single person, i.e., we do not consider the duplicate name case. This is however possible in reality. Second, we assume the top retrieved web facial images are related to a query human name. This is clearly true for popular human beings, such as movie stars and famous politicians. However, when the query facial image is not a popular person, there may not exist many relevant facial im-ages on the WWW, which is a limitation of all existing data-driven annotation techniques. Third, comparing with the whole WWW, our current facial image database is still not large, though the es-sential optimization task in our problem is huge. In our future work, we plan to collect a large database, and develop more efficient al-gorithms to resolve the optimization task.
T his paper investigated a promising search-based face annotation framework for mining weakly labeled facial images freely available on the WWW. To enhance the quality of the noisy and incomplete labels of the web facial images, we proposed a novel Unsupervised Label Refinement (ULR) technique by learning to refine the class labels from the weakly-labeled data. To make the proposed tech-nique feasible for large-scale problems, we presented efficient and scalable optimization algorithms, which successfully solved a ULR optimization task on a real-world web facial image dataset with 400 persons and 40000 facial images by a single PC. From an extensive set of experiments, we found that the proposed technique achieved promising results with about 96% average hit rate of top-10 an-notated names over a challenging test set with various web facial images captured in a wild. Our results also indicated that the pro-posed ULR technique significantly surpassed the other competitors, including the baseline with the original labels and other regular so-lutions in literature. For the future work, we will further speed up the current solution for very large-scale applications and investigate other machine learning techniques to improve the label refinement task.
 This work was supported by the Singapore National Research Foun-dation Interactive Digital Media R&amp;D Program, under research grant NRF2008IDM-IDM004-006. [1] P. N. Belhumeur, J. P. Hespanha, and D. J. Kriegman. [2] T. L. Berg, A. C. Berg, J. Edwards, M. Maire, R. White, [3] Z. Cao, Q. Yin, X. Tang, and J. Sun. Face recognition with [4] G. Carneiro, A. B. Chan, P. Moreno, and N. Vasconcelos. [5] O. Chapelle, B. Sch X lkopf, and A. Zien, editors.
 [6] W. Dong, Z. Wang, W. Josephson, M. Charikar, and K. Li. [7] P. Duygulu, K. Barnard, J. de Freitas, and D. A. Forsyth. [8] J. Fan, Y. Gao, and H. Luo. Multi-level annotation of natural [9] J. Fan, Y. Gao, H. Luo, and G. Xu. Automatic image [10] E. Hjelm X s and B. K. Low. Face detection: A survey. [11] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. [12] J. Jeon, V. Lavrenko, and R. Manmatha. Automatic image [13] D.-D. Le and S. Satoh. Unsupervised face annotation by [14] J. Liu and J. Ye. Efficient euclidean projections in linear time. [15] P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss. The feret [16] B. C. Russell, A. Torralba, K. P. Murphy, and W. T. Freeman. [17] S. Satoh, Y. Nakamura, and T. Kanade. Name-it: Naming [18] C. Siagian and L. Itti. Rapid biologically-inspired scene [19] Y.-Y. Sun, Y. Zhang, and Z.-H. Zhou. Multi-label learning [20] A. Torralba, Y. Weiss, and R. Fergus. Small codes and large [21] C. Wang, L. Zhang, and H.-J. Zhang. Learning to reduce the [22] X.-J. Wang, L. Zhang, F. Jing, and W.-Y. Ma. Annosearch: [23] L. Wu, S. C. H. Hoi, R. Jin, J. Zhu, and N. Yu. Distance [24] P. Wu, S. C. H. Hoi, P. Zhao, and Y. He. Mining social [25] J. Yang and A. G. Hauptmann. Naming every individual in [26] L. Zhang, L. Chen, M. Li, and H. Zhang. Automated [27] M. Zhao, J. Yagnik, H. Adam, and D. Bau. Large scale [28] W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld. Face [29] Y. Zhou, R. Jin, and S. C.-H. Hoi. Exclusive lasso for [30] J. Zhu, S. C. H. Hoi, and L. V. Gool. Unsupervised face [31] J. Zhu, S. C. H. Hoi, and M. R. Lyu. Face annotation using [32] X. Zhu, Z. Ghahramani, and J. D. Lafferty. Semi-supervised
