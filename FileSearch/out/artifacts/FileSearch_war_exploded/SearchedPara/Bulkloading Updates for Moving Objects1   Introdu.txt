 The rapid advances in wireless communications and electronic technologies en-able a wide range of emerging location-aware applications in mobile environ-ments, such as traffic monitoring and intelligent transportation systems. Moving objects with positioning devices move continuously and their location informa-tion is reported to the server for further processing. Efficiently tracking the changing positions of moving objects can substantially improve the quality of these applications.

Spatial indexes like R-tree provide a basis for indexing moving objects. The key challenge is to handle the frequent updates because the sampled location values are dynamically changing and need to be updated frequently. The high demand for updates is motivated by most location-aware applications. Several indexing technologies have been proposed for moving objects [12, 6, 9, 16, 4, 2, 17]. One way is to accelerate the location steps of the old and new entries in leaf nodes, and reduces the number of disk accesses to internal nodes in traverse of the index structure [6, 9, 16, 17]. Another way is to model the objects X  movement as a function of time to support the future trajectory queries [12, 4]. Only when the function parameters change, is an update issued, which reduces the number of location updates. Most of the existing work regards the update as an individual process for each object, and separate updates are issued respectively in update-intensive environments. With a large number of moving objects, this one-by-one manner causes a high volume of update path traverses and duplicate disk accesses to same nodes by different objects.

In this paper, we propose the bulkloading updates (BLU) for moving objects, which efficiently utilize the spatial correlation between different updates and achieve significantly lower update cost. We first present a framework of BLU, in which there is no need to modify any existing disk-based update or query algorithm. Thus BLU can be applied to the existing moving object indexes as a flexible component. Based on it, we propose three bulkloading schemes with different spatial biases. Each of them ut ilizes its spatial bias to group objects with near positions. Within the same group, shared update paths are prefetched into the buffer and multiple disk accesses to the same node can be combined into one. In this way, BLU avoids I/O overhead for objects with the same group. We also propose a novel MBR-driven flushing algorithm. It organizes the flushing order in an MBR-driven manner and improves the buffer hit ratio. We conduct the theoretical analysis and experimental evaluation. As shown in the analysis, one distinguishing feature of BLU is that its query performance is lossless, that is, it does not affect the query I/O cost of the index it is applied to. Both the analysis and experimental results demonstrate that BLU has the good update performance.

The rest of the paper is organized as follows. Section 2 reviews the related work. Section 3 presents the bulkloading updates (BLU) in detail. Section 4 conducts the experimental evaluation and we conclude the paper in Section 5. The bulkloading technique [5, 7, 15] is usually used for the construction phase of an index structure and can improve the overall performance with fairly static data. However, for dynamic data, especially frequently updated data like moving objects, the effect of bulkloading for the initial index construction is trivial. Several group updates for spatial indexes [1, 10] have been proposed and little work is favorable to moving object applications. Recently [8] proposes a lazy group update method for moving objects. With a disk-based insertion buffer for each internal node in R-tree, it improves the update throughput and also incurs additional I/O overhead in query evaluation.

Moving object indexing problems are generally categorized into three kinds: (1) Indexing the historical trajectories of objects [11, 13]. (2) Indexing the cur-rent positions of objects [6, 9, 16, 2, 17]. (3) Indexing the near future positions of objects [12, 4]. Among category (2) and (3), how to support frequent updates as well as efficient query processing is the key challenge to the existing index technologies.

To support frequent updates, several indexing methods have been proposed recently. Different from the traditional deletion-insertion way, Lazy R-tree [6] updates the index only when an object moves out of the corresponding MBR. Q+Rtree [16] differentiates fast-moving objects and quasi-static objects, and con-structs a hybrid tree structure consist ing both an R*-tree and a Quadtree. The Frequently Updated R-tree (FUR-tree) [9] incorporates the localized bottom-up strategies into R-tree. It locates the leaf node via a secondary object-ID index, and a bottom-up search is issued from the leaf node to find the new entry to be inserted. [4] proposes a B + -tree based structure B x -tree for indexing current and near future positions of moving objects. [2] proposes the change tolerant in-dexing for high update environments. The MBR is defined based on the changes to data values and thus can reduce the number of updates that cross MBR boundaries. [17] presents an R-tree variant that avoids disk accesses for purg-ing old entries during an update process. Most of the existing work regards the update as an individual process, and a large number of separate updates are issued respectively in update-intensive environments. In this paper, we propose the bulkloading update (BLU) and apply it to FUR-tree [9], a typical moving object index that has been widely used. Meanwhile, the proposed technique is also applicable to other moving object index structures. 3.1 Motivation The basic idea behind BLU is to group the objects with close positions and com-bine their individual updates into a common process. An example is illustrated in Figure 1. The location updates for object o 1and o 2 are issued in FUR-tree. Both of them are deleted in leaf node A and respectively inserted into leaf node B and C in a bottom-up way. We assume an LRU buffer of four disk pages. In the traditional way where a separate update for each object is issued one by one, there is no correlation between the update for o 1 and the one for o 2. Figure 1(b) shows the buffer states and disk page swapping occurs frequently between two individual update phases. It incurs 8 disk accesses totally (here we do not account the I/O cost for accessing the secondary object-ID index). Now we con-sider the bulkloading way. o 1and o 2 are clustered together and then a common update process is issued. Two objects almost share the same update path in FUR-tree. As shown in Figure 1(c), it incurs only 5 disk accesses. In fact the update path ADE has been prefetched into the buffer before the update for o 2. 3.2 A Framework of Bulkloading Updates We first present a framework of bulkloading updates for moving objects, as shown in Figure 2. It consists of two phases loading and flushing . An in-memory loading pool is maintained for buffering the incoming location information. When a new tuple ( oid, pos ) comes at each time step, it is first put into the loading pool according to a certain criteria. When the loading pool has not enough memory to accommodate the new incoming tuples, the flushing phase is issued. The location values in the loading pool are group by group flushed into the disk-based index. Then an ordinary update operation is performed for each object in a group. Two points should pointed out here. 1. In this framework, there is no need to modify any disk-based update (inser-tion/deletion) algorithm in the existing moving object indexes. Therefore BLU can be applied to the current moving objet databases as a flexible component. 2. When a new ad hoc query comes, BLU first checks whether the loading pool is empty. If not, it flushes the remaining values in the loading pool and then performs the query evaluation, as shown in Figure 2. In this way, only one active copy of each object X  X  location in formation is kept at the same time, and no additional overhead is incurred to keep the data values consistent between the loading pool and the disk index. Similarly, there is no need to modify any disk-based query algorithm and BLU remains adaptive in dynamic environments.
Within the above framework, two problems become critical to the perfor-mance of BLU: thegroupingcriteria and the flushing algorithm . According to the grouping criteria, we propose three bulkloading schemes in Section 3.3, and the flushing algorithm will be investigated in Section 3.4.
 3.3 Bulkloading Scheme For a given group of objects with approximate positions, their updates in the disk index might share the same path from the old entry to the new entry, like the path ADE in Figure 1. With the concept of the shared path, we use the relative cost ratio  X  to measure the effect of BLU, where l s is the shared path length, n s is the number of objects whose update path contains the shared path, n is the total number of objects in this group, and l i is the length of object i  X  X  update path excluding the shared path. The path length is referred to the number of nodes accessed on it. For example, in Figure 1 l s =3, n s =2and  X  = 3+2 6+2 = 5 8 . In the BLU schemes, we expect both l and n s to be large so that the nodes on the shared path repeatedly accessed by multiple objects can be prefetched into the buffer and efficiently combined into one disk access. We first introduce the concept of bulkloading bias, which forms the basis of bulkloading schemes.
 Definition 1. (Bulkloading Bias) The bulkloading bias is defined as the spa-tial unit based on which the moving objects are grouped. The objects are called neighbors if their positions are within the same spatial unit.
 According to the bulkloading bias, the loading pool is partitioned into a set of buckets, each of which forms a group and accommodates the continuously incoming tuples. A hash-based bucket function h is used to determine which bucket a new tuple ( oid , pos ) should be put into. The processing logic of BLU is described in Algorithm 1. We present three bulkloading schemes of different spatial biases, each of which has its own bucket function.
 MBR Biased Scheme(MBS) In this scheme, the bulkloading bias is the MBR (Minimum Bounding Rectangle) in R-tree based indexes. Note that we distinguish two kinds of positions, the old position and the new position. The former is reported at last time step and currently stored in the index structure. The latter comes from the new tuple ( oid , pos ) and will be processed. For each object, its old and new positions respectively correspond to the old and new MBRs the position lies in. We employ the old MBR in MBS since the new MBR of an object is unknown before traverse of the index structure. In this way, objects whose old positions are located in the same MBR are grouped in the same bucket. In R-trees, the leaf node and the leaf MBR have a one-to-one relationship. Two objects reside in the same MBR if and only if their corresponding entries are within the same leaf node. Thus the leaf node serves as a tag of the MBR and becomes the key of the bucket function. Especially in FUR-tree, the leaf node N can be directly located via the secondary object-ID index before a bottom-up search is issued. The new tuple ( oid, pos ) is then put into the bucket h ( N ) in the loading pool. Grid Biased Scheme(GBS) Different from MBS that objects with near old positions are grouped together, we take into consideration the grouping effect of new positions in GBS. Although the new MBR of each object is not known in the loading phase, we use the grid partition as approximation. The space is uniformly divided into k  X  k grids of same size. For a new position pos ( x , y ), it is easily to obtain the grid cell that pos lies in. With row-major ordering, the grid cell id gid is ( y/yunit )  X  k + x/xunit ,where yunit and xunit are the grid cell side length of y-axis and x-axis respectively. The new tuple ( oid, pos ) is put into the bucket h ( gid ) in the loading pool.

It should be noted that GBS is approximate grouping while MBS is precise grouping. In MBS, it is concerned with the old positions and objects keep con-sistent between the buckets and the old MBRs. In GBS, it considers the new positions and the grid is just the spatial approximation to the new MBR. Ob-jects in the same grid might be in the same new MBR and there are also chances that they reside in different MBRs. In other words, MBS is a look-back scheme and GBS is a look-ahead scheme.
 Hybrid Biased Scheme(HBS) Based on MBS and GBS, we propose the hybrid biased scheme (HBS). We combine the grouping effect of both MBS and GBS in a unified way. The key of the bucket function is ( N, gid ), where N istheleafnodelocatedinMBSand gid isthegridcellidcalculatedinGBS.Thusobjectsareclusteredinamore compact way. Only those whose old positions are located in the same MBR and new positions are approximately neighboring can be grouped in the same bucket and then a common disk-based update is issued. In fact, the concern in HBS is a trajectory between two time steps rather than a single position. The shared update path is expected to be longer in HBS while the number of objects in each bucket might be less.

Figure 3 illustrates three bulkloading schemes. The objects o 1, o 2, o 3move from the old positions to the new positions respectively. In MBS, two groups are formed h ( MBR 1) = { o 1 ,o 2 } and h ( MBR 2) = { o 3 } .InGBS, h ( g 1) = { o 1 } and h ( g 2) = { o 2 ,o 3 } . In HBS, three groups are formed because of the finer granularity, h ( t 1) = { o 1 } , h ( t 2) = { o 2 } ,and h ( t 3) = { o 3 } . 3.4 MBR-Driven Flushing Algorithm When the loading pool can not accommodate new tuples, the data values in the buckets are flushed into the disk index. The flushing algorithm considers in what order the buckets are collected . The buckets reflect the spatial location of the objects in it, and different flushing orders lead to different buffering effects as well as disk I/O cost. Intuitively, the spatial units preserving proximity should be close in the flushing order. We propose an MBR-driven flushing algorithm. A stack-like MBR Table (MT) with LRU replacement is used to maintain the leaf nodes recently accessed. The size of MT is a parameter that can be dynamically adjusted.

The flushing algorithm for the MBR biased scheme is described in Algorithm 2. Note that N and N are referred to the leaf node ID rather than the actual page. When a leaf node is pinnned into the buffer by previous updates, its ID is pushed into MT. In this way, MT records the leaf nodes that have been accessed and still reside in the buffer. The subsequent buckets driven by the leaf node (MBR) popped from MT can directly access the in-buffer nodes without I/O overhead. Even some of consecutive buckets share a common update path, which has been prefetched into the buffer. It should be noted that the shared path here is subtly different from that in Section 3.3. We distinguish them as in-bucket shared path and between-bucket shared path respectively. The former means that the update path is prefetched into the buffer and shared by objects within the same bucket, as described in Section 3.3. The between-bucket shared path here means that it is commonly accessed by objects belonging to different buckets, which is the immediate effect of the flushing algorithm.
 The flushing algorithm for the grid biased scheme is different from that for MBS in two points: (1) The key of the bucket function h is the grid id gid instead of the leaf node id N . (2) To find which grid to be driven by the MBR popped from MT, we map the MBR to the grid space and select the grids whose region overlap with the MBR as the next one in the flushing order. Since the grid partition is uniform, the mapping calculation is simple. For example, in Figure 3, when MBR1 is popped from MT, the grids that MBR1 intersects are selected and their corresponding buckets will be next collected for flushing. The MBR-driven order is distinguished from other space-filling curves like row-major order or Hilbert curve, since it utilizes the dynamic spatial correlation based on buffer hit, instead of a predefined visiting order. As for the hybrid biased scheme, the above MBR-driven flushing algorithm either for MBS or for GBS can be employed. 3.5 Cost Analysis We first introduce a theorem to show the query performance of BLU. Let T be the original index structure and BLU-T be the corresponding index with the proposed bulkloading updates.
 Lemma 1. Let o 1 and o 2 be two objects to be updated. For an R-tree based index, the same average query I/O cost.
 Theorem 1. The query performance of BLU is lossless, that is, the query I/O cost of BLU-T is not more than that of T.
 Proof. Let T 0 be the index before the update, n be the total number of ob-jects, C q ( T ,n )and C q ( BLU-T , n ) be the query I/O cost of T and BLU-T .An update is an index structure change denoted as a binary tuple, that is, ( T 0 , T )and( T 0 , BLU-T ) respectively. For all the objects, there is an update se-BLU-T ). We prove that C q ( BLU-T , n ) is not larger than C q ( T ,n ) by induc-tion of n .(1)When n = 1, there is only one object and the conclusion exists. ries of bubble swapping for the first sequence so that o n swaps with its left neighbor and o i n swaps with its right neighbor repeatedly until it turns a new tion, C q ( BLU-T , n  X  1) is not larger than C q ( T ,n  X  1). Therefore the same for the n -length sequence and we have the conclusion when n&gt; 1.
 From Theorem 1, we see that BLU keeps the good query performance of the existing R-tree variants. Different from some of the previous approaches, which sacrifice the query performance for the update performance, BLU does not need to make a compromise between them. In fact, since objects with close positions are updated together, BLU-T keeps a more compact index structure than T and even might slightly improve the query performance.
 Update Cost. We first analyze the update I/O cost of the bottom-up approach. For simplicity, we use the form cost(read or write, the accessed object) in the following analysis. If the new entry remains in the old leaf node, the cost = 1(R, secondary index) + 2(R/W, leaf node) = 3. If the new entry is inserted into some sibling of the old leaf node, the cost = 2(R/W, secondary index) + 2(R/W, leaf node) + 2(R/W, sibling node) = 6. Otherwise, a bottom-up search is issued and the nodes on the top-down path are accessed to locate the new entry. The cost = 2(R/W, secondary index) + 2(R/W, old leaf node) + ( h  X  1)(R, internal nodes on the top-down path) + 2(R/W, new leaf node) = 5 + h ,where h is the height of the top-down path in the search. Let p 1 , p 2 and p 3 be the probability that a new entry is located in the old leaf node, in the sibling node, and in the new leaf node respectively. The cost of a bottom-up update is 3 p 1 +6 p 2 +(5+ h ) p 3 .Fora group of m objects in a bucket, the total cost is 3 m p 1 +6 m p 2 +(
For the bulkloading update of MBR biased scheme, the objects in a bucket reside in the same old MBR and multiple node accesses can be combined into one. Let l s be the length of the shared update path as described in Section 3.3. For m objects in a bucket, we analyze the I/O cost in the above three cases. In case 1, the cost = m  X  1(R, secondary index) + 2(R/W, leaf node) = m +2. In case 2, the cost = m  X  (2(R/W, secondary index) + 2(R/W, sibling node)) + 2(R/W, leaf node) = 4 m +2.Incase3,thecost= m  X  (2(R/W, secondary index) + 2(R/W, new leaf node)) + 2(R/W, old leaf node) + =4 m +2+ From the above equation we see that the longer shared update path, the more cost reduced. Note that here we only consider the in-bucket shared path and do not take into account the effect of the between-bucket shared update path as described in Section 3.4.
 Memory Requirement. The additional memory requirement in BLU is the size of the loading pool S lp , which is the maximum number of accommodated tuples. Given a fixed available memory of size S total , how to allocate S total to S lp and the buffer size S buf is an interesting problem, and we will investigate it in the experiments. 4.1 Experimental Setup We compare the following four approaches: FUR-tree [9], BLU-based FUR-tree with MBR biased scheme (BLU-MBS), BLU-based FUR-tree with grid biased scheme (BLU-GBS), and BLU-based FUR-tree with hybrid biased scheme (BLU-HBS). All the experiments are conducted on Pentium IV 2.0GHz with 512 MB RAM running Windows Server 2003. The size of disk page is set to 4KB. We use synthetic datasets generated by GSTD [14]. All the objects are uniformly distributed in a unit-square space and can move arbitrarily with a maximum moving distance of 0.2. The default number of objects is 100K. The performance metric is the number of disk accesses. Since BLU does not affect the query I/O cost according to Theorem 1, in the following experiments we focus on the update performance and do not report the results of query performance.

For a fair comparison, we allocate the same memory size (10% of dataset size) to all the approaches. For FUR-tree, the buffer size is set to the whole available memory size. For BLU, the same memory size is allocated to the buffer and the loading pool respectively, and the allocation ratio  X  = S lp S an LRU buffer with the write-through strategy. The setting of k in BLU-GBS (grid cell number per dimension) depends on the size of loading pool S lp .Let N lp be the number of tuples the loading pool can accommodate, we set k to 4.2 Results and Discussion We conduct a set of experiments to investigate the effect of maximum moving distance, memory size, number of objects and allocation ratio respectively.
We first vary the maximum moving distance of objects from 0.01 to 0.15 and investigate its effect on the update performance. Figure 4(a) gives the update I/O cost for all the approaches. With the increase in objects X  moving distance, the update cost rises up slightly. This is due to the fact that in FUR-tree more objects move far from old leaf nodes to new leaf nodes. The larger moving distance indicates the longer bottom-up and top-down update path, which further results in more accesses to index nodes. BLU-based F UR-trees outperform that without BLU. The bulkloading manner enables objects with similar positions to issue updates together, and reduces the additional disk access to common update paths. Figure 4(a) also shows that MBR biased scheme has the lower cost than grid biased scheme. This reveals a look-back bulkloading scheme performs better than a look-ahead one. An interesting result is that BLU-MBS and BLU-HBS almost have the same I/O cost. This is because the MBR bias puts more effects on the performance and the hybrid scheme prefers to it. Meanwhile HBS employs the same MBR-driven flushing algorithm with MBS, and the flushing unit of both of them is MBR instead of Grid. In this way, BLU-HBS can be regarded as a finer-granularity version of BLU-MBS.

We then study the effect of memory size by varying it from 0% to 15% of dataset size. For BLU, the allocated memory serves as the loading pool besides buffer space. As shown in Figure 4(b), when no memory is allocated, all the approaches have the same I/O cost because of each direct disk access to index nodes without buffering. When memory size is increased to 5% of dataset size, there is a great drop in the update cost. Update performance continues to im-prove with the increasing memory size, as can be expected. From Figure 4(b) we see that the enlargement of memory size has a strong impact on the performance of BLU due to variety of the loading pool size.

Figure 4(c) gives the update performance with different number of objects from 100K to 1M. BLU keeps the update cost steady with the increasing number of objects. Still BLU-MBS and BLU-HBS have the lowest I/O cost. It should be noted that although the dataset size is increasing, it does not affect the tuple load of the loading pool in each flushing phase due to a fixed loading volume.
In Figure 4(d) we investigate the effect of the allocation ratio. We set the allocation ratio  X  , that is, the percentage of loading pool size to buffer size, to 1 / 4, 2 / 3, 3 / 2, and 4 / 1 respectively. The variety indicates more memory size allocated to the loading pool. BLU improves its update performance when  X  changes from 1 / 4to3 / 2. This is because the larger loading pool can accommodate more tuples, and thus the shared update path can be longer and accessed by more objects, as discussed in Section 3.5. When  X  varies from 3 / 2to4 / 1, the update cost does not change too much, which means the performance turns stable and does not fluctuate in this interval. Figure 4(d) also shows that under different allocation ratios BLU-MBS and BLU-HBS still have the similar performance and performs better than BLU-GBS. In actual applications, MBS or HBS is a good choice. We propose an efficient method, the bulkloading updates (BLU), for moving object databases. It is adaptive to the existing moving object indexes and can be applied to commercial systems as a flexible component. Both the theoretical analysis and experimental results demon strate that BLU significantly improves the update performance while keeping the good query performance all the same. In future work, we would like to extend BLU to other types of index structures, and accelerate the update process in various update-intensive environments.
