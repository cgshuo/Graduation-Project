 joris.mooij@tuebingen.mpg.de Graphical models are used in many different fields. A fundamental problem in the application of graphical models is that exact inference is NP-hard [1]. In recent years, much research has focused on approximate inference techniques, such as sampling methods and deterministic approximation methods, e.g., Belief Propagation (BP) [2]. Although the approximations obtained by these meth-ods can be very accurate, there are only few useful guarantees on the error of the approximation, and often it is not known (without comparing with the intractable exact solution) how accurate an approximate result is. Thus it is desirable to calculate, in addition to the approximate results, tight bounds on the approximation error.
 There exist various methods to bound the BP error [3, 4, 5, 6], which can be used, in conjunction with the results of BP, to calculate bounds on the exact marginals. Furthermore, upper bounds on the partition sum, e.g., [7, 8], can be combined with lower bounds on the partition sum, such as the well-known mean field bound or higher-order lower bounds [9], to obtain bounds on marginals. Finally, a method called Bound Propagation [10] directly calculates bounds on marginals. However, most of these bounds (with the exception of [3, 10]) have only been formulated for the special case of pairwise interactions, which limits their applicability, excluding for example the interesting class of Bayesian networks.
 In this contribution we describe a novel bound on exact single-variable marginals in factor graphs which is not limited to pairwise interactions. The original motivation for this work was to better understand and quantify the BP error. This has led to bounds which are at the same time bounds for the exact single-variable marginals as well as for the BP beliefs. A particularly nice feature of our bounds is that their computational cost is relatively low, provided that the number of possible values of each variable in the factor graph is small. On the other hand, the computational complexity is exponential in the number of possible values of the variables, which limits application to factor graphs in which each variable has a low number of possible values. On these factor graphs however, our bound can significantly outperform existing methods, either in terms of accuracy or in terms of computation time (or both). We illustrate this on two toy problems and on real-world problems arising in medical diagnosis.
 The basic idea underlying our method is that we recursively propagate bounds over a particular sub-tree of the factor graph. The propagation rules are similar to those of Belief Propagation; however, instead of propagating messages, we propagate convex sets of messages. This can be done in such a way that the final  X  X eliefs X  at the root node of the subtree are convex sets which contain the exact marginal of the root node (and, by construction, also its BP belief). In the next section, we describe our method in more detail. Due to space constraints, we have omitted the proofs and other techni-cal details; these are provided in a technical report [11], which also reports additional experimental results and presents an extension that uses self-avoiding-walk trees instead of subtrees (inspired by [6]). 2.1 Preliminaries Factorizing probability distributions. Let V := { 1 ,...,N } and consider N discrete random X We consider a probability distribution over x = ( x 1 ,...,x N )  X  X  V that can be written as a product of factors (  X  I ) I  X  X  : For each factor index I  X  F , there is an associated subset N I  X  V of variable indices and the factor  X  I is a nonnegative function  X  I : X N I  X  [0 ,  X  ) . For a Bayesian network, the factors are (conditional) probability tables. In case of Markov random fields, the factors are often called poten-tials. In general, the normalizing constant ( X  X artition sum X ) Z is not known and exact computation number of variables N . Similarly, computing marginal distributions P ( x A ) for subsets of variables A  X  X  is intractable in general. In this article, we focus on the task of obtaining rigorous bounds on single-variable marginals P ( x i ) = P x Factor graphs. We can represent the structure of the probability distribution (1) using a factor and edges e  X  E , with an edge { i,I } between i  X  V and I  X  F if and only if the factor  X  I depends on x i (i.e., if i  X  N I ). We will represent factor nodes visually as rectangles and variable of a factor node I is precisely N I ; similarly, we denote the set of neighbors of a variable node i by N i := { I  X  X  : i  X  N I } . We will assume throughout this article that the factor graph corresponding to (1) is connected.
 Convexity. We denote the set of extreme points of a convex set X  X  R d by ext ( X ) . For a subset Y  X  R d , the convex hull of Y is defined as the smallest convex set X  X  R d with Y  X  X ; we denote the convex hull of Y as conv ( Y ) .
 element of M A can be identified with a finite measure on X A ; therefore we will call the elements of M A  X  X easures on A  X . We write M  X  A := M A \{ 0 } .
 Operations on measures. Adding two measures  X  ,  X   X  X  A results in the measure  X  +  X  in M A . For A,B  X  V , we can multiply a measure on M A with a measure on M B to obtain a measure on M A  X  B ; a special case is multiplication with a scalar. Note that there is a natural embedding of M
A in M B for A  X  B  X  V obtained by multiplying a measure  X   X  M A by 1 B \ A  X  M B \ A , the constant function with value 1 on X B \ A . Another important operation is the partial summation: given A  X  B  X  X  and  X   X  X  B , define P x  X  over all x a  X  X  A , i.e., P x Operations on sets of measures. We will define operations on sets of measures by applying the operation on elements of these sets and taking the set of the resulting measures; e.g., if we have two subsets  X  A  X  X  A and  X  B  X  X  B for A,B  X  X  , we define the product of the sets  X  A and  X  B to be Completely factorized measures. For A  X  V , we will define Q A to be the set of completely factorized measures on A , i.e., Q A := Q a  X  A M { a } . Note that M A is the convex hull of Q A . Indeed, we can write each measure  X   X  M A as a convex combination of measures in Q A which are zero everywhere except at one particular value of their argument. We denote Q  X  A := Q A \{ 0 } . Normalized (probability) measures. We denote with P A the set of probability measures on A , i.e., P A = {  X   X  M A : P x convex; the simplex P A has precisely #( X A ) extreme points, each of which corresponds to putting all probability mass on one of the possible values of x A . We define the normalization operator N which normalizes measures, i.e., for  X   X  X   X  A we define N  X  := 1 Z  X  with Z = P x Boxes. Let a,b  X  R d such that a  X   X  b  X  for all components  X  = 1 ,...,d . Then we de-fine the box with lower bound a and upper bound b by B ( a,b ) := { x  X  R d : a  X   X  x  X   X  b  X  for all  X  = 1 ,...,d } . Note that a box is convex; indeed, its extreme points are the  X  X orners X  of which there are 2 d .
 Smallest bounding boxes. Let X  X  R d be bounded. The smallest bounding box of X is defined as B ( X ) := B ( a,b ) where the lower bound a is given by the pointwise infimum of X and the upper bound b is given by the pointwise supremum of X , that is a  X  := inf { x  X  : x  X  X } and b  X  := sup { x  X  : x  X  X } for all  X  = 1 ,...,d . Note that B ( X ) = B (conv ( X )) . Therefore, if X is convex, the smallest bounding box for X depends only on the extreme points ext ( X ) , i.e., B ( X ) = B (ext ( X )) ; this bounding box can be easily calculated if the number of extreme points is not too large. 2.2 The basic tools To calculate marginals of subsets of variables in some factor graph, several operations performed on measures are relevant: normalization, taking products of measures, and summing over subsets of variables. Here we study the interplay between convexity and these operations. This will turn out to be useful later on, because our bounds make use of convex sets of measures that are propagated over the factor graph.
 The interplay between convexity and normalization, taking products and partial summation is de-scribed by the following lemma.
 Lemma 1 Let A  X  X  and let  X   X  X   X  A . Then: The next lemma concerns the interplay between convexity and taking products; it says that if we take the product of convex sets of measures on different spaces, the resulting set is contained in the convex hull of the product of the extreme points of the convex sets.
 Lemma 2 Let ( A t ) t =1 ,...,T be disjoint subsets of V . For each t = 1 ,...,T , let  X  t  X  M A t be convex with a finite number of extreme points. Then conv Q T t =1  X  t = conv Q T t =1 ext  X  t . The third lemma says that the product of several boxes on the same subset A of variables can be easily calculated: the product of the boxes is again a box, with as lower (upper) bound the product of the lower (upper) bounds of the boxes.
 Lemma 3 Let A  X  V and for each t = 1 ,...,T , let  X  t ,  X  t  X  M A such that  X  t  X   X  t . Then Q We are now ready to state the basic lemma. It basically says that one can bound the marginal of a variable by replacing a factor depending on some other variables by a product of single-variable of the bound on P ( x i ) based on (b):  X  X hat can we say about the range of P ( x i ) when the factors corresponding to the nodes marked with question marks are arbitrary? X ; (d) Subtree of the factor graph; (e) Propagating convex sets of measures (boxes or simplices) on the subtree (d), leading to a bound B i on the marginal probability of x i in G . factors and bounding the result. This can be exploited to simplify the computational complexity of bounding the marginal. An example of its use will be given in the next subsection.
 Lemma 4 Let A,B,C  X  X  be mutually disjoint subsets of variables. Let  X   X  X  A  X  B  X  C such that for each x C  X  X  C , P x Proof. Note that M  X  C is the convex hull of Q  X  C and apply Lemma 1.
 The positivity condition is a technical condition, which in our experience is fulfilled for many prac-tically relevant factor graphs. 2.3 A simple example Before proceeding to our main result, we first illustrate for a simple case how the basic lemma can be employed to obtain computationally tractable bounds on marginals. We derive a bound for the marginal of the variable x i in the factor graph in Figure 1(a). We start by cloning the variable x j , i.e., adding a new variable x j 0 that is constrained to take the same value as x j . In terms of the factor graph, we add a variable node j 0 and a factor node  X  , connected to variable nodes j and j 0 , satisfies: with A = { i } , B = { k } , C = { j,j 0 } and  X  =  X  J  X  K  X  L yields: Applying the distributive law, we obtain (see also Figure 1(c)): which we relax to Now it may seem that this smallest bounding box would be difficult to compute. Fortunately, we only need to compute the extreme points of these sets because of convexity. Since smallest bounding boxes only depend on extreme points, we conclude that which can be calculated efficiently if the number of possible values of each variable is small. 2.4 The main result The example in the previous subsection can be generalized as follows. First, one chooses a particular subtree of the factor graph, rooted in the variable for which one wants to calculate a bound on its marginal. Then, one propagates messages (which are either bounding boxes or simplices) over this subtree, from the leaf nodes towards the root node. The update equations resemble those of Belief Propagation. The resulting  X  X elief X  at the root node is a box that bounds the exact marginal of the root node. The choice of the subtree is arbitrary; different choices lead to different bounds in general. We now describe this  X  X ox propagation X  algorithm in more detail.
 Definition 5 Let ( V , F , E ) be a factor graph. We call the bipartite graph ( V,F,E ) a subtree of ( V , F , E ) with root i if i  X  V  X  V , F  X  F , E  X  E such that ( V,F,E ) is a tree with root i and for all { j,J } X  E , j  X  V and J  X  F (i.e., there are no  X  X oose edges X ). 1 We denote the parent of j  X  V according to ( V,F,E ) by par( j ) and similarly, we denote the parent of J  X  F by par( J ) . An illustration of a possible subtree of the factor graph in Figure 1(a) is the one shown in Figure 1(d). The bound that we will obtain using this subtree corresponds to the example described in the previous subsection.
 In the following, we will use the topology of the original factor graph ( V , F , E ) whenever we refer to neighbors of variables or factors. Each edge of the subtree will carry one message, oriented such that it  X  X lows X  towards the root node. In addition, we define messages entering the subtree for all  X  X issing X  edges in the subtree (see also Figure 1(e)). Because of the bipartite character of the factor graph, we can distinguish two types of messages: messages B J  X  j  X  M j sent to a variable j  X  V from a neighboring factor J  X  N j , and messages B j  X  J  X  M j sent to a factor J  X  F from a neighboring variable j  X  N J . The messages entering the subtree are all defined to be simplices; more precisely, we define the incoming messages We propagate messages towards the root i of the tree using the following update rules (note the similarity with the BP update rules). The message sent from a variable j  X  V to its parent J = par( j )  X  F is defined as where the product of the boxes can be calculated using Lemma 3. The message sent from a factor J  X  F to its parent k = par( J )  X  V is defined as where the second equality follows from Lemmas 1 and 2. The final  X  X elief X  B i at the root node i is calculated by We can now formulate our main result, which gives a rigorous bound on the exact single-variable marginal of the root node: Theorem 6 Let ( V , F , E ) be a factor graph with corresponding probability distribution (1). Let i  X  V and ( V,F,E ) be a subtree of ( V , F , E ) with root i  X  V . Apply the  X  X ox propagation X  Proof sketch The first step consists in extending the subtree such that each factor node has the right number of neighboring variables by cloning the missing variables. The second step consists of applying the basic lemma where the set C consists of all the variable nodes of the subtree which have connecting edges in E \ E , together with all the cloned variable nodes. Then we apply the distributive law, which can be done because the extended subtree has no cycles. Finally, we relax the bound by adding additional normalizations and smallest bounding boxes at each factor node in the subtree. It should now be clear that the  X  X ox propagation X  algorithm described above precisely calculates the smallest bounding box at the root node i that corresponds to this procedure. [12], the bounds on the (exact) marginals that we just derived are at the same time bounds on the approximate Belief Propagation marginals (beliefs): Corollary 7 In the situation described in Theorem 6, the final bounding box B i also bounds the (approximate) Belief Propagation marginal of the root node i , i.e., P BP ( x i )  X  X  i . 2.5 Related work We briefly discuss the relationship of our bound to previous work. More details are provided in [11]. The bound in [6] is related to the bound we present here; however, the bound in [6] differs from ours in that it (i) goes deeper into the computation tree by propagating bounds over self-avoiding-walk (SAW) trees instead of mere subtrees, (ii) uses a different parameterization of the propagated bounds and a different update rule, and (iii), it is only formulated for the special case of factors depending on two variables, while it is not entirely obvious how to extend the result to more general factor graphs.
 Another method to obtain bounds on exact marginals is  X  X ound Propagation X  [10]. The idea un-difference. For a variable i  X  V , we define the sets  X  i := S N i (consisting of all variables that ap-pear in some factor in which i participates) and  X  X  :=  X  i \{ i } (the Markov blanket of i ). Whereas our method uses a cavity approach, using as basis equation Propagation is P ( x i ) = P x case, the computational complexity of Bound Propagation is exponential in the size of the Markov model, eventually yielding a new (tighter) bound on P ( x  X  X  ) . Although the iteration can result in rather tight bounds, the main disadvantage of Bound Propagation is its computational cost: it is exponential in the Markov blanket and often many iterations are needed for the bounds to become tight. Figure 2: Comparisons of various methods on different factor graphs: P ROMEDAS (left), a large grid with strong interactions (middle) and a small grid with medium-strength interactions (right). In this section, we present only few empirical results due to space constraints. More details and additional experimental results are given in [11]. We have compared different methods for calculat-ing bounds on single-variable marginals; for each method and each variable, we calculated the gap (tightness) of the bound, which we defined as the `  X  distance between the upper and lower bound of the bounding box. We have investigated three different types of factor graphs; the results are shown in Figure 2. The factor graphs used for our experiments are provided as supplementary material to the electronic version of this article at books.nips.cc . We also plan to release the source code of several methods as part of a new release of the approximate inference library libDAI [13]. For our method, we chose the subtrees in a breadth-first manner.
 First, we applied our bound on simulated P ROMEDAS patient cases [14]. These factor graphs have binary variables and singleton, pairwise and triple interactions (containing zeros). We generated nine different random instances. For each instance, we calculated bounds for each  X  X inding X  variable in that instance using our method ( X  X  OX P ROP  X ) and the method in [10]. Note that the tightness of both bounds varies widely depending on the instance and on the variable of interest. Our bound was tighter than the bound from [10] for all but one out of 1270 variables. Furthermore, whereas [10] had only finished on 7 out of 9 instances after running for 75000 s (after which we decided to abort the calculation on the remaining two instances), our method only needed 51 s to calculate all nine instances.
 We also compared our method with the method described in [6] on a large grid of 100  X  100 binary (  X  1 -valued) variables with strong interactions. Note that this is an intractable problem for exact inference methods. The single-variable factors were chosen as exp(  X  i x i ) with  X  i  X  N (0 , 1) , the SAW tree to 10 5 nodes. Note that our method yields the tightest bound for almost all variables. Finally, we compared our method with several other methods referred to in Section 1 on a small  X  methods would need several days to handle a large grid. In this case, the method by [6] yields the tightest bounds, followed by [10], and our method gets a third place. Note that many methods return completely uninformative bounds in this case. We have described a novel bound on exact single-variable marginals, which is at the same time a bound on the (approximate) Belief Propagation marginals. Contrary to many other existing bounds, it is formulated for the general case of factor graphs with discrete variables and factors depending on an arbitrary number of variables. The bound is calculated by propagating convex sets of measures over a subtree of the factor graph, with update equations resembling those of BP. For variables with a limited number of possible values, the bounds can be computed efficiently. We have compared our bounds with existing methods and conclude that our method belongs to the best methods, but that it is difficult to say in general which method will yield the tightest bounds for a given variable in a specific factor graph. Our method could be further improved by optimizing over the choice of the subtree.
 Although our bounds are a step forward in quantifying the error of Belief Propagation, the actual error made by BP is often at least one order of magnitude lower than the tightness of these bounds. This is due to the fact that (loopy) BP cycles information through loops in the factor graph; this cycling apparently often improves the results. The interesting and still unanswered question is why it makes sense to cycle information in this way and whether this error reduction effect can be quan-tified.
 Acknowledgments References
