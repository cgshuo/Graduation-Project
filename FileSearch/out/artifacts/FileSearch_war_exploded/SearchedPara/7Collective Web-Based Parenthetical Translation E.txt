 In multilingual language processing tasks, bilingual lexicons are of great importance to many applications, such as machine translation, computer-assisted translation, and cross-language information retrieval (CLIR). However, most existing bilingual datasets are (i) not adequate for their intended uses, (ii) not up-to-date, or (iii) apply only to limited domains. Because it is very difficult and expensive to create a large-scale bilingual dataset by hand, many researchers have tried extracting bilingual lexicon entries from the Web. One line of research is to collect parallel bilingual web corpora, for example, pairs of web pages that are mutual translations, and to automatically acquire lexical data from them [Chen and Zong 2008]. Sometimes comparable, rather than strictly parallel, corpora are used (e.g., Wikipedia) [Kim et al. 2011].
The other line is mining bilingual segments of web pages whose content is written in two languages. Non-English web sites often give English translations for English terms or names that appear therein X  X ometimes in parentheses, and sometimes col-lected in a table. This translation data can be mined by pattern-based extraction. For example, Cao et al. [2007] and Lin et al. [2008] proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages X  X specially those whose primary language is Chinese, Japanese, or Korean X  often annotate terms with their English translations inside a pair of parentheses, for example, (Zuckerberg). Expressions satisfying this pattern are referred to as parenthetical translations. A parenthetical translation is composed of a preparenthet-ical non-English named entity (NE) followed by a left bracket, followed by an English NE, and then followed by a right bracket. We refer to the task of extracting the NE from a parenthetical translation segment as PTE, parenthetical translation extraction. The main problem when extracting translations for parenthetical English NEs (PNEs) is determining the left boundary of the preparenthetical non-English NE. In Chinese, Japanese, or Korean, this task becomes even more challenging because these languages do not use explicit delimiters (spaces) between words in a sentence.

Previous approaches to PTE ignore the fact that one can determine the left boundary of a preparenthetical NE (PPNE) by referring to other instances. Take the following two incomplete segments, for example: ... , (international maritime bureau) ... (international maritime bureau)
It is possible to detect the left boundary of  X   X  in the second sentence by referring to the first sentence, where there is a delimiting comma.

In this article, we propose a collective approach to PTE based on Markov Logic [Domingos and Lowd 2009]. Collective classification is the task of inferring labels for a set of objects using not just their attributes but also the relations among them. One is of class u and has relation R to object y , y is likely to also be of class u ). The main advantage of employing Markov logic in our model is that it makes it easy to incorporate relational information and jointly infer all labels at once. Collective extraction using Markov logic has become popular recently; several approaches [Riedel et al. 2009; Poon and Vanderwende 2010; Dai et al. 2011] employing Markov logic on collective extraction tasks have achieved comparable performance with state-of-the-art machine-learning methods.

We employ the word alignment algorithm of Lin et al. [2008] as a baseline feature. In addition to this feature, we have designed three new local features, including strongest character-word prefix link, punctuation marks, and co-occurrence prefix; and three new collective features, including constraint, neighbor, and cross-segment (see Section 3.2 for feature details). All these features are represented by first-order formulae. We use Markov logic networks (MLNs) to perform collective inference. Like the approach of Lin et al. [2008], our proposed collective approach does not require any additional resources (i.e., pronunciation or bilingual dictionaries). Moreover, all of our features are generated by an unsupervised process. In this section, we briefly review automatic extraction of bilingual translations and parenthetical translation extraction related to our research. Automatically extracting bilingual translation pairs is an important task for CLIR and machine-translation systems because most online bilingual dictionaries lack domain-specific words or named entities. Further, new entities are generated every day, but because bilingual dictionaries cannot be updated quickly enough, coverage is often limited. Most dictionaries cover the names of famous politicians but not the names of entertainers, which are often the most frequent search keywords on the web.
There are two main types of approaches proposed for automatic extraction of bilin-gual translation pairs: corpus-based and Web-based. In corpus-based methods, pairs are extracted from parallel or comparable corpora. A parallel corpus is a collection of texts, each of which is translated into one or more other languages. A comparable corpus is one that selects similar texts in more than one language or variety. Diab and Finch [2000] propose a translation model of statistical word-level mapping for comparable corpora. Their approach is based on the assumption that, if two words are similar in distributional profiles, the distribution profile of their corresponding translations should also be similar. Shao and Ng [2004] proposed a method to extract Chinese-English translation pairs from comparable corpora by combining context and transliteration information. Lee et al. [2006] used a statistical transliteration model for extracting NEs and their translations from parallel corpora. All these approaches suffer from the aforementioned shortcomings of bilingual corpora, namely, limited cov-erage and difficulty to keep up-to-date.

To overcome these limitations, Web-based methods were proposed. Nagata et al. [2001] extracted English translations for given Japanese technical terms by searching mixed Japanese X  X nglish web pages. Their method scores each translation candidate c by combining the character distance between the given source term and c as well as the number of their co-occurrences. Lu et al. [2002] proposed a novel approach to constructing a multilingual dictionary by using anchor texts (two different languages referring to the same web page) and their linking structure on the web. Zhou et al. [2006] proposed a pattern-matched translation approach to analyze mixed-language web pages. They first manually constructed five patterns by observing the co-occurrence of the NE and its translation in the web pages. They then submitted the NE to a search engine and retrieved the first 500 snippets from the search results. Last, the five patterns were used to extract the translation from the snippets.

In this article, we focus on extracting translation pairs from parenthetical transla-tions. The syntax of a named entity immediately followed by a translation enclosed in parentheses is frequently used, regular, and language independent, which makes it the ideal candidate for translation pair extraction. A parenthetical translation (PT) is a bilingual translation pair found in a natural lan-guage sentence in which a given word is followed by its translation enclosed in paren-theses. Usually, the article/text language term comes first, with the foreign language translation in brackets. Figures 1 and 2 are examples of parenthetical translations from Google 1 snippets. Identifying parenthetical translations in natural language and extracting them is referred to as parenthetical translation mining (PTM). The end goal of PTM systems is often the construction of a large-scale, web-based bilingual dictionary.

Several approaches to PTM have been explored in previous research. Kwok et al. [2005] presented a method that collects a set of parenthetical translation candidates by sending a requested English keyword to monolingual search engines, and used a frequency-based method to extract corresponding Chinese transliterations from the collected snippets.

Cao et al. [2007] proposed an approach to mining a bilingual dictionary from monolin-gual Chinese web pages. It contains two phases: candidate extraction and translation selection. In the first stage, bilingual translation pair segments are extracted from Chi-nese web pages based on a set of predefined templates, one of which is parenthetical translation. In the translation selection stage, multiple possible segmentations for the preparenthetical Chinese term are taken into account, and a discriminative learning method is used to determine the correct translation pair. The parenthetical translation template achieved satisfactory precision on extracting bilingual translation pairs in the experiment by Cao et al. [2007].

Instead of separating the PTM task into multiple stages, Lin et al. [2008] proposed an unsupervised word-alignment method for PTM. They used a modified version of one of the simplest word-alignment algorithms, Competitive Linking [Melamed 2000]. The algorithm assumes that there is a score associated with each possible bilingual transla-tion pair in a given text. It sorts the bilingual pairs in descending order of their scores, selecting pairs based on the resultant order. A bilingual pair of words is linked if nei-ther of the two words were previously linked to any other words. Lin et al. [2008] made a small change to the Competitive Linking algorithm to allow consecutive sequences of words on one side to be linked to the same word on the other side. Specifically, given have no previous linkages, the version by Lin et al. [2008] requires only that at least one of them be unlinked and that (supposing e i is unlinked and f j is linked to e k )none of the words between e i and e k be linked to any word other than f j .

Lin et al. [2008] used the  X  2 statistic [Gale and Church 1991] as the link score: where a is the number of segments containing both e i and f j ; a + b is the number of segments containing e i ; a + c is the number of segments containing f j ;and d is the number of segments containing neither e i nor f j . In the segment  X  (Aalborg), X  for example, the number of segments containing both  X   X  and  X  X alborg X  is 2, the number of segments containing  X  X alborg X  is 2, the number of segments containing  X   X  is 439, and the number of segments containing neither  X   X  nor  X  X alborg X  is 35,129. Therefore, a = 2, b = 0, c = 437, and d = 35,129. The  X  2 of  X   X  X s
The  X  2 score ranges from 0 to 1. If a link score is below the user-defined threshold, it is treated as 0. The approach by Lin et al. [2008] does not require any additional resources, such as pronunciation or bilingual dictionaries, and outperforms the approach by Cao et al. [2007] because its source of translation candidates are not limited by predefined templates. In this section, we present our MLN-based collective parenthetical translation extrac-tion approach.

Unlike the PTM works discussed in Section 2.2, the PTE task focuses only on iden-tifying Chinese NEs that occur before parenthetical English NEs. We illustrate two main machine-learning-based approaches: the individual approach and our collective approach. We use ME as the underlying model for the individual approach because ME and MLN are both log-linear models. MLN supports collective PTE by allowing formulae referring to more than one instance, whereas ME makes a prediction for each instance independently of the other instances. Given a sentence containing one PT, we extract a segment starting from the head of the sentence to the end of the closing bracket of the PT. For the sentence  X  (Tokyo University) X  for example. If the sentence contains multiple PTs, we extract multiple segments. The first PT segment is extracted as described earlier, with subse-quent PT segments starting from the closing bracket of the previous one. Thus, for the sentence  X  (Tokyo University) (Osaka University) , X  we would extract these two segments:  X  (Tokyo University) X  and  X  Chinese NE (PPNE) from the rest of the segment by predicting the first character of PPNE. Every preparenthetical Chinese character is referred to by its position relative to the left parenthesis. In the previous two example segments, the correct start points are  X   X (the4 th character) and  X   X  (the 4 th character). The PTE task is formulated as a position prediction task. Given a segment s , we need to identify the leftmost character of the PPNE. We use the predicate PPNE ( i , s , l )to describe that the i th character from the left bracket in the segment s has the PPNE label For example,  X  (Aquino) X  is labeled as  X  / O / O / O / O / O / B / I / I (Aquino). X  3.2.1. Markov Logic Network (MLN). In first-order logic (FOL), formulae are constructed using four types of symbols: constants, variables, functions, and predicates. Constants represent objects in a domain of discourse (e.g., people: Anne, John, etc., or database entries). Variables (e.g., x , y ) range over the objects. Predicates represent the relations among objects (e.g., correlates ), or attributes of objects (e.g., hasTitle ). Variables and constants may be typed. An atom is a predicate symbol applied to a list of arguments, which may be variables or constants (e.g., hasTitle ( John , x ) ). A ground atom is an atom all of whose arguments are constants (e.g., hasTitle ( John , Mr. ) ). A world is an assignment of truth values to all possible ground atoms. A KB is a partial specification of a world; each atom in it is true, false, or (implicitly) unknown.

A Markov network represents the joint distribution of a set of variables X = ( X where each fact or f k is a nonnegative function of a subset of the variables x k ,and Z is a normalization constant. As long as P ( X = x ) &gt; 0 for all x , the distribution can be equivalently represented as a log-linear model: where the features g i ( x ) are arbitrary functions of (a subset of) the variables X  state. An MLN L is a set of pairs ( F i ,w i ), where F i is a formula in FOL and w i is a real number representing a weight. Together with a finite set of constants C , it defines a Markov network M L , C , where M L , C contains one node for each possible grounding of each predicate appearing in L . The value of the node is 1 if the ground predicate is true, and 0 otherwise. The probability distribution over possible worlds x is given by: where Z is the partition function, F is the set of all first-order formulae in the MLN, G i is the set of groundings of the i -th first-order formula, and g j ( x ) = 1ifthe j -th ground formula in G i is true and g j ( x ) = 0 otherwise. General algorithms for inference and learning in Markov logic are discussed in Richardson and Domingos [2006].
In the following subsections, we introduce the construction of our MLN model. We designed noncollective and collective sets of formulae to calculate the probability of PPNE ( i , s , l ).
 We implemented the character X  X ord affix link feature following the approach by Lin et al. [2008]. Suppose that there are m Chinese characters before the left bracket and the number of words in the PNE is n , we use the Competitive Linking algorithm [Melamed 2000] to align the m Chinese characters and n English words. For each English word e i and Chinese character f j pair, the  X  2 statistic (shown in Equation (1)) is used to score the link between e i and f j . After all m  X  n Chinese X  X nglish pairs are scored, pairs with scores lower than the threshold (0.005 in this article) are discarded. We then define the HasLink predicate to model this linkage. For each input segment s , if the link score of the i -th character and any word of the PNE is greater than the threshold, and at least one of them does not link to any other word, then the predicate HasLink ( i , s ) is true; otherwise, it is false.

We also designed Formula 1 based on the hypothesis that, if the i th character is strongly linked to the PNE, then it should be within a PPNE. That is, it should be will receive different weights during the training process.
 Formula 1 : Character X  X ord Affix Link (Baseline)
In a similar manner to the approach by Lin et al. [2008], syllable-level regularities are also considered in our MLN. The link score of a character X  X ord pair ( e i , f j )isthe suffix). We use the first and the last three ASCII characters of a word as its prefix and suffix, respectively.

The prefix link score is the link score for a Chinese character in the preparenthetical text and the n -character prefix of a word in the PNE. We set n to 2 because using a 2-character prefix results in the best accuracy on the development set. For example, in the segment  X  ... , (Apollo) ... , X  the CW prefix link scores for [ ,Ap], [ ,Ap], ... ,[ , Ap] are calculated. These scores are calculated using Equation (1). According to our observations of parenthetical translations, the leftmost character of the PPNE frequently has a high link score with the prefix of a word in the PNE. This tendency is higher when the PPNE is a transliteration of the PNE.

We have also observed that the Chinese character with the highest prefix link score is the most likely to be the leftmost character of the PPNE. For example, in the segment  X  ... (Apollonius) ... , X  [ , Ap] has the highest prefix pair link score.
 Formula 2 is designed to identify the character with the highest link score.
For example, in the segment  X  ... (Apollonius) ... , X  [ , Ap] has the highest prefix pair link score. Formula 2 is designed to identify the character with the highest link score.
 Formula 2 : Strongest Character X  X ord Prefix Link In these formulations, the predicate PfxLink is the preparenthetical Chinese character with the highest link score. PfxLink ( i , s ) is true if and only if the i th character of the s th segment was selected as the PfxLink character. Formula 2 describes the logical relationship between PfxLink and PPNE .

According to our observations, the positions of punctuation marks (i.e., commas, peri-ods, and so forth) can often be used to clearly determine the start of the preparenthetical Chinese NE, such as in the segment,  X  , (International Maritime Bureau) ...  X  We can use clearly delimited PPNEs such as this one to help identify the PPNE start points in other sentences that contain the same PNE X  X or example,  X 
For punctuation features, we defined Formula 3. The formula describes the logical relationship between the selected start point RightAfterPM and PPNE . The predicate to the right bracket in another training-set sentence and the character before this iden-tical part is a punctuation mark. Since the identical substrings contain the PNE, these two PT segments share the same PNE. Take the input sentence s : X  set sentence t : X  , (International Maritime Bureau) ... , X  in which a comma appears before  X  , X  then RightAfterPM (5 , s ) is true. Usually, characters such as  X  , X  whose RightAfterPM value is true, are inside the PPNE.
 Formula 3 : Punctuation
The co-occurrence prefix feature describes matching between preparenthetical Chi-nese characters and parenthetical English words, or even prefixes X  X or example, in  X  = Markov X  pair also appears in many other phrase instances. An example of prefix co-occurrence would be the  X  = Alb X  found in the names  X  (Albanel) X  and  X  (Albania). X  In cases in which Chinese character sequences co-occur with English words/prefixes regularly, we can exploit this information to identify the PPNE X  X  leading characters.

Since we cannot rely on dictionaries or word segmentation tools to identify Chinese co-occurrence candidates such as  X   X  mentioned earlier, we consider the prefix n characters that appear more than once to be co-occurrence candidates. We first compile all individual words found in PNEs in the training set into a list. For each word w , we retrieve all training segments containing w and extract the prefix 2, 3, and 4 characters from each of these segments. We then calculate these prefix terms X  frequency. For example, for the word Markov, we find that there are two training-set segments containing Markov:  X  (Markov chain) X  and  X  (Markov network). X   X  , X   X  , X  and  X   X  are extracted from the former segment while  X  , X   X  appear more than once, thus they are added to a dictionary ( PDict ).

For the co-occurrence prefix feature, we defined Formula 4. We search the preparen-thetical part of each segment s for terms contained in PDict . The predicate CoPfx ( i , s )is true if and only if i is in the leftmost position for all matched terms X  leading characters. In Formula 4, the formula describes the logical relationship between the selected start points ( CoPfx )and PPNE .
 Formula 4 : Co-occurrence Prefix 3.2.3. Collective Formulae. There are two kinds of collective information used in our approach. The first kind captures the interactions within a parenthetical phrase pair. The other type of the information is the one shared across different parenthetical pairs. Among the four types of collective formulae (CL1 X  X L4), CL1 and CL2 belong to the first type. Both can be addressed by CRF with proper feature engineering. CL3 and CL4, on the other hand, cannot be captured by the CRF model. We describe them in detail next.

In general, a segment s cannot have more than one starting translation character; we use a hard constraint to ensure that only one position can be labeled as B for each segment. We call this formula the Constraint Collective Formula: Formula CL1 : Constraint Collective Formula Formula CL1 means that, for all distinct positions in the same segment, no more than one position can be labeled as B .

The i th character X  X  PPNE label is closely related to its neighbor characters. For instance, represent this property, and we called it the Neighbor Collective Formula, as described here: Formula CL2 : Neighbor Collective Formula In Formula CL2, the predicate HasChar ( i , c , s ) means that the i th character has the Chinese character c in the segment s . The CL2 means that, for any neighbor characters i th and i  X  1 th position, their PPNE labels l and l  X  will be collective inference.
Here, cross-segments are different segments that share the same PNE. According to our observations, cross-segments usually contain the same Chinese PPNE. Suppose that two segments s and s  X  share the same PNE. If the PPNE in s starts from the i th position, then the PPNE in s  X  usually starts at the i th position, too. For example,  X  PPNE in these two segments both start from  X  . X  Accordingly, we use a formula called the Cross-segment Collective Formula to collectively infer labels in cross-segments: Formula CL3 : Cross-Segment Collective Formula In Formula CL3, the predicate SharePNE ( s , s  X ) means that the segments s and s  X  share the same PNE. Formula CL3 means that, if the segment s and the segment s  X  share the PNE and the i th characters are the same, then they will have the same PPNE label l on the i th characters.

In Chinese, an English-named entity may have multiple translations due to near-homophones of Chinese characters. For example,  X  X quino X  has multiple translations, such as  X   X  X nd X   X . We design a cross near-homophone collective formula to take these variations into account. Suppose that two segments s and t share the same PNE. We calculate the phonetic similarity between the postfix of their Hanyu pinyin pronunciations with a modified ALINE algorithm [Wang et al. 2013], which assigns a similarity score to pairs of phonetically transcribed words on the basis of the decomposition of phonemes into elementary phonetic features. The phonetic fea-tures are assigned salience weights that express their relative importance. Feature values are encoded as floating-point numbers in the range [0,1]. The numerical val-ues reflect the distances between vocal organs during speech production. The overall similarity score is the sum of individual similarity scores between pairs of phonemes in an optimal alignment of two words, which is computed by a dynamic programming algorithm.

Then, we illustrate the procedure of calculating the pronunciation similarity of s and t . First, we extract the postfixes of the Chinese part with a length of 2 to 8 because we have observed that 99% of all PPNEs appear in postfixes within a length of 8 in our dataset. We remove the tone marks from pinyin, and segment the pinyin sequences into single letters. For each of s  X  X  postfix p , we calculate the pronunciation similarity between p and each of t  X  X  postfix whose length ranges from | p | X  2to | p |+ 2. For example, if p  X  X  length is 5, we calculate the similarity of p with t  X  X  postfix ranging from 3 to 7. Finally, we extract s  X  X  postfix and that of t with the highest similarity. We use t  X  X  postfix starting from the j th character have the highest similarity among all pairs of postfixes. For example, suppose that s =  X  (Aquino) X  and t =  X  tong a ji nuo X  and  X   X  is converted into its pinyin  X  X n qia nuo jie dai a kui nuo. X  For s  X  X  postfix  X  X  ji nuo, X  we calculate the edit distances between it and t  X  X  postfix  X  X ie dai a kui nuo, X   X  X ai a kui nuo, X   X  X  kui nuo, X  X nd  X  X ui nuo. X  In this case, the segment  X  X  kui nuo X  has the shortest distance from  X  X  ji nuo. X  Thus, i is the position of  X   X  X n s ( i = 5) and j is the position of  X   X  X n t ( j = 6). We use a formula called  X  X ross Near-Homophone Collective X  to collectively infer labels in cross-segments with Near-Homophone link: Formula CL4 : Cross Near-Homophone Collective Formula To evaluate our MLN for collective PTE, we used Chinese X  X nglish named entity (e.g., person names, location names, organization names, and the like) lists from the LDC 2 and CNA 3 to construct our experimental dataset. We first collected 344,873 segments with parenthetical translations from Google search result snippets by using the named entity lists. Then, we constructed an experimental dataset of 71,132 segments by re-moving duplicate segments. This dataset, called Web71T , contains 32,916 unique par-enthetical translation pairs. We designed three experiments. Experiment 1 measures the contribution of each for-mula in our MLN system. Experiment 2 measures and compares the extraction perfor-mance of our proposed collective MLN model and the individual MLN model. Experi-ment 3 measures and compares the extraction performance of our proposed collective MLN model and another baseline, the conditional random fields (CRF) model. We use the1-best MIRA online-learning method [Crammer and Singer 2003] for learning weights and employ cutting plane inference with integer linear programming [Riedel 2008] as its base solver for inference at test time as well as during the MIRA online-learning process. In order to evaluate our performance under an unbiased circum-stance, we apply a two-sample paired t -test, which is defined as follows: The null hypothesis, which states that there is no difference between the two configurations A and B , is given as where  X  A is the true mean F-score of configuration A and  X  B is the mean of the configuration B , while the alternative hypothesis is
A two-sample paired t -test is applied since we assume that the samples are inde-pendent. As the number of samples is large and the samples X  standard deviations are known, the following two-sample t -test can be administered:
If the resulting t -score is equal to or less than 1.67 with a degree of freedom of 29 and a statistical significance level of 95%, the null hypothesis is accepted; otherwise, it is rejected. To retrieve the average F-scores and their deviations required for the from the 71,132 segments. Each training set and test set contains 32,916 segments. We trained the model on g i and tested it on d i . Afterwards, we summed the scores for all 30 test sets and calculated the averages for performance comparison. We use F-measure to measure our collective PTE X  X  performance. The results are given as F-scores, defined as F = 2 PR / ( P + R ), where P denotes the precision and R denotes the recall. The formulae for calculating precision and recall are as follows: Table I shows the result of Experiment 1. The result of Formulae 1 + 2 + CL1 + CL2 combination shows, by adding our designed Strongest Character X  X ord Prefix Link formula (Formula 2) with Formula 1, the recall rates are improved by over 23%, which results in an improvment of over 18% on F-measure. This shows that a new word often consists of transliteration words. In contrast with the previous combination, the combination of Formulae 1 + 3 + CL1 + CL2 and combination of Formulae 1 + 4 + CL1 + CL2 slightly improve the F-measure by 2.65% and 4.65%, respectively. In the seventh configuration, we used all the formulae mentioned in Section 3.2.2 and achieved the F-measure of 74.17% ( p value = 1.00074e-40, compared to the baseline). In the last configuration, after adding the near-homophone collective, the F-measure can be further improved to 76.19% ( p value = 3.19064e-43, compared to the baseline). We have also implemented the MLN-based individual PTE system and evaluated it using the same experimental procedure. The results are shown in Table II. We can see that, in every configuration, the collective system outperforms the individual one, indicating that removing collective formulae causes performance drop. Employing all local formulate (Formulae 1 X 4) also results in the best performance in the individual system. The best collective system outperforms the best individual system by an F-measure of 8.2%. The best collective system requires 49ms to inference on a PT segment, on average. Since constructing a bilingual NE lexicon is usually a batch job, we believe this time is acceptable. Table III shows the performance of the CRF-based PTE system. We convert Formulae 1 to 4 to CRF features, denoted as Feature set 1 to 4. We can see that the best CRF-based system achieves an F-measure of 70.29%, which is still lower than the best collective MLN-based system by 5.9% ( p value = 3.20e-10). Sometimes NEs appear after a character that has a similar pronunciation. For example,  X  . X  The first  X   X  refers to Korea, while the second  X   X  is part of the bank name  X   X (Hana Bank). Since our method relies on the links between English prefixes and Chinese characters, such PTs can confuse our system.
 In some cases, the Chinese transliteration is not based on the English pronunciation, especially with geographical or personal names. For example, an alternate Chinese transliteration for  X  X lorence, X   X   X (fei1 leng3 cui4) is transliterated directly from the Italian  X  X irenze. X  If the pronunciations are too different, errors inevitably occur. In this article, we have presented a collective approach that employs Markov logic to model multiple constraints for the parenthetical translation extraction (PTE) task. The main difficulty in PTE is detecting the left boundary of the preparenthetical NE. Since many Asian languages are not delimited by spaces, it is hard to determine what should be counted as a term. To solve this problem, we designed several first-order formulae for observed features used in our MLN, including word alignment, punctuation marks, and co-occurrence prefix. Moreover, our model does not require any additional resources (i.e. pronunciation dictionaries or bilingual dictionaries), and all of our features are generated automatically, saving considerable human effort. Our dataset was compiled from Google search-result snippets containing parenthetical translations.
The contribution of this article is threefold. First, we have proposed a new PTE method using Markov logic, which allows us to model several observed features of the PTE task and solve it using an MLN. Second, we have designed multiple effective features that can be concisely represented by simple first-order logic formulae in an MLN. Finally, our model yields significant improvements compared to the current state-of-the-art PTE approaches.

