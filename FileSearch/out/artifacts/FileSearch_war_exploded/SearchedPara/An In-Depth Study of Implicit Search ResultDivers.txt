 Hai-Tao Yu 1( Accurately and efficiently providing desired information to users is still difficult. A key problem is that users often submit short queries that are ambiguous and/or underspecified. As a remedy, one possible solution is to apply search result diversification (SRD) characterized as finding the optimally ranked list of documents which maximizes the overall relevance to multiple possible intents, while minimizing the redundancy among the returned documents. Depending on whether the subtopics underlying a query are known beforehand , the problem of SRD can be differentiated into implicit SRD and explicit SRD .Inthiswork,we do not investigate supervised methods for SRD, but we focus instead on implicit methods , for which the possible subtopics underlying a query are unknown . Despite the success achieved by the state-of-the-art methods, the key under-lying drawback is that: the commonly used greedy strategy works well on the premise that the preceding choices are optimal or close to the optimal solution. However, in most cases, this strategy fails to guarantee the optimal solution. Moreover, the factors, such as the initial runs and the number of input doc-uments, are not well investigated in most of the previous studies on implicit SRD.
 implicit SRD is proposed. Based on this formulation, the exactly optimal solution can be obtained and validated. We then compare the effectiveness of the proposed method ILP4ID with the state-of-the-art algorithms using the standard TREC diversity collections. The experimental results prove that ILP4ID can achieve improved performance over the baseline methods.
 Sect. 3 , the method ILP4ID based on ILP is proposed. A series of experiments are then conducted and discussed in Sect. 4 . Finally, we conclude the paper in Sect. 5 . In this section, we first give a brief survey of the typical approaches for SRD. For a detailed review, please refer to the work [ 3 ]. We begin by introducing some notations used throughout this paper. For a given query q , D = represents the top-m documents of an initial retrieval run. r ( q, d relevance score of a document d i w.r.t. q . The similarity between two documents d and d j is denoted as s ( d i ,d j ).
 the greedy best first strategy . At each round, it involves examining each document that has not been selected, computing a gain using a specific heuristic criterion, and selecting the one with the maximum gain. To remove the need of manually tuning the trade-off parameter  X  , Sanner et al. [ 2 ] propose to perform implicit SRD through the greedy optimization of Exp -1-call @ k , where a latent subtopic model is used in the sequential selection process.
 where R ( S )= d  X  S r ( d ) denotes the overall relevance. obtaining S  X  , they initialize S with the k most relevant documents, and then iteratively refine S by swapping a document in S with another one in D At each round, interchanges are made only when the current solution can be improved. Finally, the selected documents are ordered according to the contri-bution to Eq. 1 .
 paper implicit SRD as an ILP problem. Moreover, the effects of different ini-tial runs and the number of used documents on the diversification models are explored. This study is complementary to the work by Yu and Ren [ 5 ], where explicit subtopics are required. We formulate implicit SRD as a process of selecting and ranking k exemplar doc-uments from the top-m documents. We expect to maximize not only the overall relevance of the k exemplar documents w.r.t. a query, but also the representa-tiveness of the exemplar documents w.r.t. the non-selected documents. The ILP formulation of selecting k exemplar documents is given as: In particular, the binary square matrix x =[ x ij ] m  X  m indicates whether document d i is selected, and x ij : i = ment d i chooses document d j as its exemplar. Restriction by Eq. 4 guarantees that k documents are selected. Restriction by Eq. 5 means that each document must have one representative exemplar. The constraint given by Eq. 6 enforces that if there is one document d i selecting d j as its exemplar, then d exemplar documents. D ( x )= m i =1 m j =1: j = i x ij  X  s ( d view of the fact that there are k numbers (each number is in [0 , 1]) in the rel-evance part R ( x ), and m -k numbers (each number is in [0 , 1]) in the diversity part
D ( x ). The coefficients m -k and k are added in order to avoid possible skewness issues, especially when m k . Finally, the two parts are combined through the parameter  X  .
 Although solving arbitrary ILPs is an NP-hard problem, modern ILP solvers can find the optimal solution for moderately large optimization problems in reasonable time. We use the free solver GLPK in this study. Once the k exemplar documents are selected, they are further ranked in a decreasing order of their respective contributions to objective function given by Eq. 2 . We denote the proposed approach as ILP4ID , namely, a novel Integer Linear Programming method for implicit SRD .
 documents, and D \ S as the complementary set of non-selected documents, the calculation of max d  X  S { s ( d, d ) } can be then interpreted as selecting the most representative exemplar d  X  S for d  X  D \ S .Thus D ( S ) is equivalent to Therefore, DFP is a special case of ILP4ID when the coefficients m -k and k are not used. Since ILP4ID is able to obtain the exact solution w.r.t. the formulated objective function, and DFP relies on an approximate algorithm, thus ILP4ID can be regarded as the theoretical upper-bound of DFP .
 ILP4ID since the study [ 6 ] has shown that they can be rewritten as different variants of DFP . However, ILP4ID is not the upper-bound of MMR , MPT and QPRP . This is because the space of feasible solutions for ILP4ID and DFP relying on a two-step diversification is different from the one for MMR or MPT or QPRP , which generates the ranked list of documents in a greedy manner. 4.1 Experimental Setup The four test collections released in the diversity tasks of TREC Web Track from 2009 to 2012 are adopted (50 queries per each year). Queries numbered 95 and 100 are discarded due to the lack of judgment data. The evaluation metrics we adopt are nERR-IA and  X  -nDCG, where nERR-IA is used as the main measure as in TREC Web Track. The metric scores are computed using the top-20 ranked documents and the officially released script ndeval with the default settings. The ClueWeb09-T09B is indexed via the Terrier 4.0 platform. The language model with Dirichlet smoothing (denoted as DLM )and BM25 are deployed to generate the initial run.
 introduced in Sect. 2 are used as baseline methods. In particular, for 1-call @ k ,we follow the setting as [ 2 ]. For MPT , the relevance variance between two documents is approximated by the variance with respect to their term occurrences. For DFP , the iteration threshold is set to 1000. For MMR , MPT , DFP and the proposed model ILP4ID , we calculate the similarity between a pair of documents based on the Jensen-Shannon Divergence. The relevance values returned by DLM and BM25 are then normalized to the range [0 , 1] using the MinMax normalization. 4.2 Experimental Evaluation Optimization Effectiveness. We first validate the superiority of ILP4ID over DFP in solving the formulated objective function. In particular, we set  X  =0 (for  X  = 0, the results can be compared analogously), both DFP and ILP4ID work the same, namely selecting k exemplar documents. For a specific topic, we compute the representativeness (denoted as D ) of the subset S of k exemplar documents, which is defined as D ( x ) in Sect. 3 . The higher the representative-ness is, the more effective the adopted algorithm is. Finally, for each topic, we compute the difference between D ILP 4 ID and D DF P . As an illustration, we use the top-100 documents of the initial retrieval by BM25 . Figure 1 shows the per-formance of DFP and ILP4ID in finding the best k exemplars, where the x-axis represents the 198 topics, and the y-axis represents the representativeness dif-From Fig. 1 , we see that D ILP 4 ID  X  X  DF P  X  0 for all topics. Because ILP4ID always returns the exact solution for each topic, while DFP can not guarantee to find the optimal solution due to the adopted approximation algorithm. Since the process of selecting exemplar documents plays a fundamental role for implicit SRD, the effectiveness of DFP is therefore impacted, which is shown in the next section.
 Implicit SRD Performance. We use 10-fold cross-validation to tune the trade-off parameters, namely b for MPT and  X  for MMR , DFP and ILP4ID . Particularly,  X  is tuned in the range [0 , 1] with a step of 0 . 1. For b , the range is [  X  10 , 10] with a step of 1. The metric nERRIA@20 is used to determine the best result. Table 1 shows how MMR , MPT , DFP ,1-call @ k and ILP4ID vary when we change the initial runs (i.e., BM25 and DLM ) and the number of input docu-ments (i.e., top-m documents of the initial run, where m on the Wilcoxon signed-rank test with p&lt; 0 . 05, the superscripts statistically significant difference to the best result of each setting, respectively. At first glance, we see that BM25 substantially outperforms DLM .More-over, given the better initial run by BM25 , all the models tend to show better performance than that based on the initial run with DLM .
 A closer look at the results (columns 2 X 4) shows that MPT and 1-call @ k exhibit poor performance, which even does not enhance the naive-baseline results with BM 25. For MMR , DF P and ILP 4 ID , they show a positive effect of deploy-ing a diversification model. Moreover, the proposed model ILP4ID outperforms all the other models in terms of both nERR-IA@20 and  X  -nDCG@20 across different cutoff-values of used documents. When using the top-100 documents, the improvements in terms of nERR-IA@20 over BM 25, MMR , MPT , DFP and 1-call @ k are 20 . 76 %, 15 . 03 %, 59 . 05 %, 5 . 18 % and 69 . 67 %, respectively. Given a poor initial run with DLM (columns 6 X 8), for MMR ,  X  = 0 (i.e., using top-50 or top-100 documents) indicates that at each step MMR selects a document merely based on its similarity with the previously selected docu-ments. When using only the top-30 documents, all models (except MMR ) out-perform DLM that does not take into account the feature of diversification. The improvements of MPT , DF P ,1-call @ k and ILP 4 ID over DLM in terms of nERR-IA@20 are 10 . 28 %, 36 . 4%, 17 . 36 % and 32 . 02 %, respectively. However, when we increase the number of used documents of the initial retrieval, MPT shows a slightly improved performance when using the top-50 documents, but the other models consistently show decreased performance. For MMR , the results are even worse than DLM . These consistent variations imply that there are many noisy documents within the extended set of documents.
 namely an unreliably-estimated document (with big variance) should be ranked at lower positions.
 1-call @ k requires no need to fine-tune the trade-off parameter  X  , the experi-mental results show that 1-call @ k is not as competitive as the methods like MPT , DF P and ILP 4 ID , especially when more documents are used. The rea-son is that: for 1-call @ k , both relevant and non-relevant documents of the input are used to train a latent subtopic model, thus it greatly suffers from the noisy information. Both MMR and MPT rely on the best first strategy, the advantage of which is that it is simple and computationally efficient. However, at a particu-lar round, the document with the maximum gain via a specific heuristic criterion may cause error propagation. For example, for MMR , a long and highly relevant document may also include some noisy information. Once noisy information is included, the diversity score of a document measured by its maximum similarity w.r.t. the previously selected documents would not be precise enough. This well explains why MMR and MPT commonly show an impacted performance with the increase of the number of used documents. DFP can alleviate the afore-said problem based on the swapping process. Namely, it iteratively refines S by swapping a document in S with another unselected document whenever the current solution can be improved. However, DFP is based on the hill climbing algorithm. A potential problem is that hill climbing may not necessarily find the global maximum, but may instead converge to a local maximum. ILP4ID casts the implicit SRD task as an ILP problem. Thanks to this, ILP4ID is able to simultaneously consider all the candidate documents and globally identify the optimal subset. The aforementioned issues are then avoided, allowing ILP4ID to be more robust to the noisy documents.
 To summarize, ILP4ID substantially outperforms the baseline methods in most reference comparisons. Furthermore, the factors like different initial runs and the number of input documents greatly affect the performance of a diversi-fication model. In this paper, we present a novel method based on ILP to solve the problem of implicit SRD, which can achieve substantially improved performance when com-pared to state-of-the-art baseline methods. This also demonstrates the impact of optimization strategy on the performance of implicit SRD. In the future, besides examining the efficiency, we plan to investigate the potential effects of factors, such as query types and the ways of computing document similarity, on the per-formance of diversification models, in order to effectively solve the problem of implicit SRD.

