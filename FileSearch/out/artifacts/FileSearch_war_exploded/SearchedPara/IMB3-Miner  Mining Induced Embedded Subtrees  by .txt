
Henry Tan 1 , Tharam S. Dillon 1 , Fedja Hadzic 1 , Elizabeth Chang 2 , and Ling Feng 3 Research in both theory and applications of data mining is expanding driven by a need to consider more complex structures, relationships and semantics expressed in the data [2,3,4,6,8,9,12,15,17]. As the complexity of the structures to be discovered increases, more informative patterns could be extracted [15]. A tree is a special type of graph that has attracted a considerable amount of interest [3,8,9,11,12,17]. Tree mining has gained interest in areas such as Bioinformatics, XML mining, Web min-ing, etc. In general, most of the formally represented information in these domains is of a tree structured form and XML is commonly used. Tan et. al. [8] suggested that XML association rule mining can be recast as mining frequent subtrees in a database of XML documents. Wang and Liu [13] developed an algorithm to mine frequently occurring induced subtrees in XML documents. Feng et. al. [4] extend the notion of associated items to XML fragments to present associations among trees. 
The two known types of subtrees are induced and embedded [3,8,9,17]. An In-duced subtree preserves the parent-child relationships of each node in the original tree whereas an embedded subtree preserves not only the parent-child relationships but also the ancestor-descendant relationships over several levels. Induced subtrees are a subset of embedded subtrees and the complexity of mining embedded subtrees is higher than mining induced subtrees [3,9,17]. 
In this study, we are mainly concerned with mining frequent embedded subtrees from a database of rooted ordered labeled subtrees. Our primary objectives are as follows: (1) to develop an efficient and scal able technique (2) to provide a method to control and limit the inherent complexity present in mining frequent embedded sub-trees. To achieve the first objective, we utilize a novel tree representation called Em-bedding List (EL) , and employ an optimal enumeration strategy called Tree Model Guided (TMG) . The second objective can be attained by restricting the maximum level of embedding that can occur in each embedded subtree. The level of embedding is defined as the length of a path between two nodes that form an ancestor-descendant relationship. Intuitively, when the level of embedding inherent in the database of trees is high, numerous numbers of embedded subtrees exist. Thus, when it is too costly to mine all frequent embedded subtrees, one can restrict the level of embedding gradu-ally up to 1, from which all the obtained frequent subtrees are induced subtrees. The two known enumeration strategies are enumeration by extension and join [3]. Recently, Zaki [17] adapted the join enumeration strategy for mining frequent em-bedded rooted ordered subtrees. An idea of utilizing a tree model for efficient enu-meration appeared in [14]. The approach us es the XML schema to guide the candidate generation so that all candidates generated are valid because they conform to the schema. The concept of schema guided candida te generation is generalized into tree model guided (TMG) candidate generation for mining embedded rooted ordered la-beled subtrees [8,10]. TMG can be applied to any data with clearly defined semantics that have tree like structures. It ensures that only valid candidates which conform to the actual tree structure of the data are generated. The enumeration strategy used by TMG is a specialization of the right most path extension approach [2,8,9,10]. It is different from the one that is proposed in FREQT [2] as TMG enumerates embedded subtrees and FREQT enumerates only induced subtrees. The right most path exten-sion method is reported to be complete and all valid candidates are enumerated at most once (non-redundant) [2,8,9]. This is in contrast to the incomplete method TreeFinder [11] that uses an Inductive Logic Programming approach to mine unor-dered, embedded subtrees. The extension approach utilized in the TMG generates fewer candidates as opposed to the join approach [8,9]. 
In section 2 the problem decomposition is given. Section 3 describes the details of the algorithm. We empirically evaluate the performance of the algorithms and study their properties in section 4, and the paper is concluded in section 5. A tree can be denoted as T(r,V,L,E), where (1) r  X  V is the root node; (2) V is the set of vertices or nodes; (3) L is the set of labels of vertices, for any vertex v  X  V, L(v) is the label of v; and (4) E is the set of edges in the tree. Parent of node v, parent(v) , is defined as the predecessor of node v. There is only one parent for each v in the tree. A node v can have one or more children, children(v), which are defined as its succes-descendant of p. The number of children of a node is commonly termed as fan-out / degree of the node, degree(v) . A node without any child is a leaf node; otherwise, it is an internal node. If for each internal node, all the children are ordered, then the tree is an ordered tree . The height of a node is the length of the path from a node to its furthest leaf. The rightmost path of T is defined as the path connecting the rightmost leaf with the root node. The size of a tree is determined by the number of nodes in the tree. Uniform tree T(n,r) is a tree with height equal to n and all of its internal nodes have degree r . All trees considered in this paper are rooted ordered labeled. Induced Subtree. A tree T X (r X , V X , L X , E X ) is an ordered induced subtree of a tree T (r, V, L, E) iff (1) V X   X  V, (2) E X   X  E, (3) L X   X  L and L X (v)=L(v), (4)  X  v X   X  V X ,  X  v  X  V and v X  is not the root node parent(v X )=parent(v), (5) the left-to-right ordering among the siblings in T X  should be preserved. Induced subtree T X  of T can be obtained by repeat-edly removing leaf nodes or the root node if its removal doesn X  X  create a forest in T. Embedded Subtree. A tree T X (r X , V X , L X , E X ) is an ordered embedded subtree of a tree generalizes property (4) such that  X  v X   X  V X ,  X  v  X  V and v X  is not the root node ances-tor(v X ) = ancestor (v). Level of Embedding (  X  ). If T X (r X , V X , L X , E X ) is an embedded subtree of T, the level of embedding (  X  ) is defined as the length of a path between two nodes p and q, where p  X  V X  and q  X  V X , and p and q form an ancestor-descendant relationship from p to q. We could define induced subtree T as an embedded subtree with maximum  X  that can occur in T equals to 1, since the level of embedding of two nodes that form parent-child relationship equals to 1. 
For instance in fig 2 the level of embedding,  X  , between node at position 0 and node at position 5 in tree T is 3, whereas between node 0 and node 2, 3, and 4 is equal to 2. According to our definition of induced and embedded subtree previously, S1 is an example of an induced subtree and S2, S3, and S4 are examples of embedded sub-trees. Transaction based vs o ccurrence match support. We say that an embedded subtree rences of t in k , a function g(t,k) denotes the number of occurrences of t in transaction k. For transaction based support, t p k=1 when there exists at least one occurrence of t in k, i.e. g(t,k)  X  1 . In other words, it only checks for existence of an item in a transac-tion. For occurrence match support , t p k corresponds to the number of all occur-T , the support of embedded subtree t in T db is defined as: Transaction based support has been used in [3,12,17]. However occurrence match support has been less utilized and discussed. In this study we are in particular inter-ested in exploring the application and th e challenge of using occurrence match sup-port. Occurrence match support takes repetition of items in a transaction into account whilst transaction based support only checks for existence of items in a transaction. There has not been any general consensus which support definition is used for which application. However, it is intuitive to say that whenever repetition of items in each transaction is to be accounted for and order is important, occurrence match support would be more applicable. Generally, transaction based support is very applicable for relational data. label is shown as a single-quoted symbol inside the circle whereas its pre-order posi-tion is shown as indexes at the left/right side of the circle. From fig. 1,  X  (T1) : X  X  c / b e  X  (T1) : X  X  c / b e X . We refer to a group of subtrees with the same encoding L as candi-date subtree C L . A subtree with k number of nodes is denoted as k-subtree . Through-out the paper, the  X + X  operator is used to conceptualize an operation of appending two or more tree encodings. However, this operator should be contrasted with the conven-tional string append operator, as in tree string encoding the backtrack symbols needs to be computed accordingly. Mining (induced|embedded) frequent subtrees. Let T db be a tree database consist-mining from T db with given minimum support (  X  ), is to find all the candidate (in-duced|embedded) subtrees that occur at least  X  times in T db . Based on the downward-closure lemma [1], every sub-pattern of a frequent pattern is also frequent. In rela-tional data, given a frequent itemset all its subsets are also frequent. A question how-ever arises of whether the same principle applies to tree structured data when the occurrence match support definition is used. To show that the same principle doesn X  X  apply, we need to find a counter-example. pseudo-frequent candidate subtree . In the light of the downward closure lemma these candidate subtrees are infrequent because on e or more of its subtrees are infrequent. Lemma 2. The antimonotone property of frequent patterns suggests that the fre-quency of a superpattern is less than or equal to the frequency of a subpattern. If pseudo-frequent candidate subtrees exist then the antimonotone property does not hold for frequent subtree mining. From fig. 1, suppose that the minimum support  X  is set to 2. Consider a candidate hand, when an induced subtree is consid ered, there are only 2 occurrences of C L that duced and embedded types. By extending C L with node 8 we obtain C L X  where subtree because we can find a subtree of C L X  whose encoding  X  X  b e X  at position (0, 7, 8) is infrequent. This holds for both induced and embedded subtrees. In other words, lemma 1 holds whenever occurrence match support is used. Subsequently, since pseudo-frequent candidate subtrees exist, according to lemma 2, the antimonotone property does not hold for frequent subtree mining when occurrence match support is used. Hence, when mining induced and embedded subtrees, there can be frequent subtrees with one or more of its subsets infrequent. This is different to flat relational data where there are only 1-to-1 relationships between items in each transaction. Tree structured data has a hierarchical structure where 1-to-many relationships can occur. This multiplication between one node to its many children/descendants makes the antimonotone property not hold for tree structured data. This makes full (k-1) pruning should be performed at each iteration when generating k-subtrees from a (k-1)-subtree when occurrence match support is used to avoid generating pseudo-frequent subtrees. Database scanning. The process of frequent subtree mining is initiated by scanning a tree database, T db , and generating a global pre-order sequence D in memory ( diction-ary ). The dictionary consists of each node in T db following the pre-order traversal indexing. For each node its position, label, right-most leaf position (scope), and parent position are stored. An item in the dictionary D at position i is referred to as D[i] . The notion of position of an item refers to its index position in the dictionary. When gen-erating the dictionary, we compute all the frequent 1-subtrees, F 1 . After the dictionary is constructed our approach does not require further database scanning. Constructing Embedding List (EL). For each frequent internal node in F 1 , a list is generated which stores its descendant nodes X  hyperlinks [12] in pre-order traversal ordering such that the embedding relationships between nodes are preserved. The For a given internal node at position i , such ordering reflects the enumeration se-list as embedded list (EL) . We use notation i-EL to refer to an embedded list of node at position i . The position of an item in EL is referred to as slot. Thus, i-EL[n] refers to the item in the list at slot n . Whereas |i-EL| refers to the size of the embedded list of node at position i . Fig 3 illustrates an example of the EL representation of tree T (fig . 1). In fig 3, 0-EL for example refers to the list: 0:[1,2,3,4,5,6,7,8] , where 0-EL[0] =1 and 0-EL[6] =7. Occurrence Coordinate (OC). When generating k-subtree candidates from (k-1)-subtree, we consider only frequent (k-1)-subtrees for extension. Each occurrence of k-subtree in T db is encoded as occurrence coordinate r:[e 1 ,...e k-1 ]; r refers to k-subtree ( T2 ) with encoding  X  X  b e X  is encoded as 0:[6,7] ; 4-subtrees T1 with encoding  X  X  c / b e X  are encoded as 0:[5,6,7] , and so on. Each OC of a subtree describes an instance of each occurrence of the subtree in T db . Hence, each candidate instance has an OC associated with it. TMG enumeration formulation. TMG is a specialization of right most path exten-sion method which has been reported to be complete and all valid candidates are enumerated at most once (non-redundant) [2,8,9,10]. To enumerate all embedded k-subtrees from a (k-1)-subtree, TMG enumeration approach extends one node at the path as an extension point. One important property of EL is that the positions of nodes are stored in pre-order manner. Hence, given a (k-1)-subtree with known tail slot, the subsequent slots in EL will form the scope of extension from i to j. All embedded k-subtree are generated by attaching a node at position i to j to the (k-1)-subtree. Sup-pose l(i) denotes a labeling function of node at position i . Given frequent (k-1)-EL|-1 . Thus its occurrence coordinate becomes r:[m,...,n,j] and its encoding becomes node, at each extension a check is performed if the level of embedding is less or equal extension point is less than  X  , the extension is performed. From fig 4, suppose that  X  is set to 1, when we extend a subtree with OC 0:[0,3,4] with node at position 6, 7, and 9 ( 0:[5], 0:[6], 0:[8]) , the level of embedding between nodes at position 6, 7, and 9 to their extension point equals to 1 (  X   X  ), and thus should not be pruned. However when between node at position 8 and 10 to their extension points is&gt;2 (  X   X  ), and thus should be pruned. Pruning. When using occurrence match support there can be pseudo-frequent candi-date subtrees generated when generating k-subtrees from (k-1)-subtrees. To make sure that all generated subtrees do not contain infrequent subtrees, full (k-1) pruning must be performed. The rationale of this has been discussed in [9,17]. From this point on-numbers of (k-1)-subtrees need to be generated from the currently expanding k-duced subtree, we only need to generate l numbers of (k-1)-subtrees where l &lt;(k-1) and l equal to the number of leaf nodes in k-subtrees. When the removal of root node of k-subtree doesn X  X  generate a forest [8,9,17] then an additional (k-1)-subtree is gen-erated by taking the root node off from the expanding k-subtree. The expanding k-subtree is pruned when at least one (k-1)-subtree is infrequent, otherwise it is added to the frequent k-subtree set. This ensures that the method generates no pseudo-frequent subtrees. While full pruning is easily done in a breadth first search (BFS) based method, it is a challenge for a depth first search (DFS) based approach such as VTre-eMiner (VTM). As a consequence, VTM performs opportunistic pruning [17]. Doing full pruning is quite time consuming and expensive. Further, to accelerate full prun-ing, a caching technique is used by checking whether a candidate is already in the frequent k-subtree. If a (k-1)-subtree candidate is already in the frequent k-subtree set, it is known that all its (k-1)-subtrees are frequent, and hence only one comparison is made. Vertical Occurrence List. To determine if a subtree is frequent, we count the occur-rences of that subtree and check if it is greater or equal to the specified minimum support  X  . We say that a candidate subtree with encoding L has a frequency n if there are n instances of subtrees in the database with the same encoding L . Each occurrence of a subtree is stored as an occurrence c oordinate, as previously described in [9]. Computing the frequency of a subtree can be easily determined from the size of the list that stores each occurrence of a subtree. We call such a list as vertical occurrence list (VOL). VOL(L) denotes the vertical occurrence list of a subtree with encoding L . The frequency of a subtree with encoding L is denoted as |VOL(L)| . When transaction based support is used the occurrence of each subtree is grouped by its transaction IDs and the support count corresponds to the number of unique transactions in the VOL. We compare IMB3-Miner (IMB3), FREQT (FT) for mining induced subtrees and MB3-Miner (MB3), X3-Miner (X3), VTreeMiner (VTM) and PatternMatcher (PM) for mining embedded subtrees. We created a synthetic database of trees with varying: max. size (s), max. height (h), max. fan-out (f), and number of transactions (|T r |). Notation XXX X  X , XXX-C, and XXX X  X  are used to denote execution time (including data preprocessing, variables declaration, et c), number of candidate subtrees |C|, and the number of frequent candidate subtrees |F| obtained from the XXX approach re-spectively. Additionally, IMB3-(NP)-dx notation is used where x refers to the level of embedding  X  and (NP) is optionally used to indicate that full pruning is not per-formed. The minimum support  X  is denoted as (sxx), where xx is the minimum fre-quency. Occurrence match support was used for all algorithms; Experiments were run on 3Ghz (Intel-CPU), 2Gb RAM, Mandrake 10.2 Linux machine and used GNU g++ (3.4.3) for compilation. Scalability (s:10,h:3,f:3). |T r | was varied to 100K, 500K &amp; 1000K, with  X  set to 25, 125 and 250, respectively. We can see that all algorithms are well scalable (fig 6a). MB3 outperforms VTM &amp; PM for mining embedded subtrees and IMB3 outperforms FT for mining induced subtrees. For |T r |:1000K at  X  :250, it can be seen that VTM and PM generate more candidates (VTM-C &amp; PM-C) by using the join approach (fig 6b). Those extra candidates are invalid, i.e. they do not conform to the tree model. Pseudo-frequent (s:9,h:2,f:5,|T r |:1). We created a dataset that corresponds to the tree T in fig 1 to illustrate the importance of full pruning when occurrence match support is used. We set  X  to 2 and compare the number of frequent subtrees generated by various algorithms. From fig 8 we can see that the number of frequent subtrees de-tected by VTM (DFS) is larger in comparison to PM, MB3 and X3 (BFS). The differ-ence comes from the fact that the three BFS based algorithms perform full pruning whereas DFS based approach such as VTM relies on opportunistic pruning which does not prune pseudo-frequent candidate subtrees. Fig 7 shows that FT &amp; IMB3-NP generate more frequent induced subtrees in comparison to IMB3. This is because they don X  X  perform full pruning, and as such generate extra pseudo-frequent subtrees. Deep Tree (s:28,h:17,f:3,|T r |:10,000) &amp; Wide Tree (s:428,h:3,f:50,|T r |:6,000). For deep trees (273,090 nodes), when comparing the algorithms for mining frequent em-bedded subtrees, MB3 has the best performance (fig 9a). VTM aborts when  X  &lt;150 where the number of frequent subtrees increases significantly when  X  is decreased (fig 9b). At  X  :150, VTM generates a superfluous 688x more frequent subtrees compared to MB3 and PM. In regards to mining frequent induced subtrees, fig 8a shows that IMB3 has a slight better time performance than FT. At s80, FT starts to generate pseudo-frequent candidates. For wide tree (1,303,424 nodes), the DFS based approach like VTM outperforms MB3 as expected (fig 9c). However, VTM fails to finish the task when  X  &lt;7. We omit IMB3 &amp; FT because the support threshold at which they produce interesting results is too low for embedded subtrees algorithms. In general, the DFS and BFS based approaches suffer from, deep and wide trees respectively. CSLogs (s:214,h:28,f:21). The dataset was used by Zaki in [17]. When used for oc-currence match support, the tested algorithms had problems in returning frequent subtrees. Hence, the dataset was trimmed. At |T r |:32,241, interesting results started to appear. VTM aborts when  X  &lt;200 due to numerous numbers of candidates generated. The usefulness of constraining the level of embedding is demonstrated in fig. 10b &amp; 10c. From fig 10b, we can see that the number of frequent subtrees generated by FT &amp; IMB3-NP is identical. Both FT &amp; IMB3-NP generate pseudo-frequent subtrees as they do not perform full pruning. Because of this, the number of frequent induced subtrees detected by FT &amp; IMB3-NP can unexpectedly exceed the number of frequent embedded subtrees found by MB3 &amp; PM (fig 10b, s80). 
Fig 10a shows that both IMB3-NP &amp; IMB3 outperform FT. A large time increase for FT and IMB3-NP is observed at  X  : 200 as a large number of pseudo-frequent sub-trees are generated (fig 10b). We also compare the results from VTM, PM &amp; MB3 to the result obtained when the level of embedding is restricted to 6 (IMB3-d6) (fig 10c). By restricting the embedding level, we ex pect to decrease the execution time without missing many frequent subtrees. The complete set of frequent subtrees was detected at  X  X  200, while only less than 2% were missed with  X  &lt;200. Overall, MB3 and its vari-ants have the best performance. Overall Discussion. All MB3 and its variants demonstrate high performance and scalability which comes from the efficient use of the EL representation and the opti-mal TMG approach that ensures only valid candidates are generated. The join ap-proach utilized in VTM &amp; PM could generate many invalid subtrees which degrades the performance. MB3 performs expensive full pruning, whereas VTM utilizes less expensive opportunistic pruning but suffers from the trade-off that it generates many pseudo-frequent candidate subtrees. This can cause memory blow up and serious performance problem (fig 8a &amp; 10). In the context of association mining, regardless of which approach is used, for a given dataset with minimum support  X  , the discov-ered frequent patterns should be identical and consistent. Assuming pseudo-frequent subtrees are infrequent, techniques that don X  X  perform full pruning would have limited applicability to association rule mining. When representing subtrees, FT [5] uses string labels VTM, PM, and MB3 (and its variants) use integer labels. When a hashtable is used for candidate frequency counting, hashing integer labels is reported to be faster than hashing string labels especially for long patterns [10] As we can see, IMB3 &amp; IMB3-NP always outperform FT. When experimenting with the level of embedding constraint (fig 10c), we have found that restricting the level of embedding percentage of frequent subtrees while providing a good estimate could be found by restricting the level of embedding. In this study we have provided some detailed discussions about various theoretical and performance issues of the different approaches. We proposed an efficient ap-proach to tackle the complexity of mining embedded subtrees by utilizing a novel Embedding List representation, Tree Model Guided enumeration, and introducing Level of Embedding constraint. High performance and scalability of the proposed approach was demonstrated in our experiments by contrasting it with the state of the art algorithms Tree-Miner and FREQT. Specifically, we studied the problem of em-bedded subtrees rather than just induced subtrees. Further, we studied the notion of using occurrence match support instead of the simpler transaction based support. We use both synthetic and real datasets in the experimental studies. A special thanks to Prof. M. J. Zaki [17] for providing us the TreeMiner source code and discussing the results obtained from it with us. 
