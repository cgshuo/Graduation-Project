 Classical recommender systems provide users with a list of recommendations where each recommendation consists of a single item, e.g., a book or DVD. However, several applica-tions can benefit from a system capable of recommending packages of items, in the form of sets. Sample applications include travel planning with a limited budget (price or time) and twitter users wanting to select worthwhile tweeters to follow given that they can deal with only a bounded number of tweets. In these contexts, there is a need for a system that can recommend top-k packages for the user to choose from.
Motivated by these applications, we consider composite recommendations , where each recomme ndation comprises a set of items. Each item has both a value (rating) and a cost associated with it, and the user specifies a maximum total cost (budget) for any recommended set of items. Our com-posite recommender system has access to one or more com-ponent recommender systems focusing on different domains, as well as to information sources which can provide the cost associated with each item. Because the problem of generat-ing the top recommendation (package) is NP-complete, we devise several approximation algorithms for generating top-k packages as recommendations. We analyze their efficiency as well as approximation quality. Finally, using two real and two synthetic data sets, we subject our algorithms to thor-ough experimentation and empirical analysis. Our findings attest to the efficiency and quality of our approximation al-gorithms for top-k packages compared to exact algorithms. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Filtering Algorithms, Theory Recommendation Algorithms, Optimization, Top-k Query Processing
Recommender systems (RecSys) have become popular and have become an essential driver of many applications in-cluding web services [2]. However, classical RecSys provide recommendations consisting of single items, e.g., books or DVDs. Several applications can benefit from a system ca-pable of recommending packages of items, in the form of sets. For example, in trip planning, a user is interested in suggestions for places to visit, or points of interest (POI). There may be a cost to visiting each place (time, price, etc.). Optionally, there may be a notion of compatibility among items in a set, modeled in the form of constraints: e.g.,  X  X o more than 3 museums in a package X ,  X  X ot more than two parks X ,  X  X he total distance covered in visiting all POIs in a package should be  X  10 km. X  etc. The user may have a limited budget and is interested in suggestions of compat-ible sets of POIs such that the cost of each set is under budget and its value (as judged from ratings) is as high as possible. In these applications, there is a natural need for top-k recommendation packages for the user to choose from. Some so-called  X  X hird generation X  travel planning web sites, such as NileGuide 1 and YourTour 2 , are starting to provide certain of these features, although in a limited form.
As another application, in social networks like twitter, one of the important challenges is helping users with rec-ommendations for tweeters to follow, based on the topics of their interest 3 . Tweeters are ranked based on how influen-tial they are [20] and currently any new user is presented with a list of influential tweeters on each topic from which they manually choose tweeters they would like to follow 3 To automate tweeter recommendation, a tweeter X  X  influence score can be treated as their value and the frequency with which they tweet as their cost. Compatibility may corre-spond to the constraint that a given set of topics should be covered. Since a user can only deal with a bounded number of tweets in a day, given a user X  X  topics of interest, it would be useful to select compatible sets of tweeters to follow such that their total influence score is maximized and the total cost is below a budget. Onc e again, it would be beneficial to give the user choice by presenting them with the top-k sets of recommended tweeters to follow. We also note that some newly founded startups like Followformation 4 are be-ginning to provide services on recommending to users the top-k influential tweeters in a specific domain.
Motivated by these applications, we consider composite recommendations , where each recomme ndation comprises a set of items. Each item has both a value (rating or score) and a cost associated with it, and the user specifies a maxi-mum total cost (budget) for any recommended set of items. Our composite recommender system consists of one or more recommender systems focusing on different domains. These component RecSys serve (i.e., recommend) top items in non-increasing order of their value (explicit or predicted ratings). In addition, our composite system also has access to infor-mation sources (which could be databases or web services) which provide the cost associated with each item.
In our setting, the problem of generating the top recom-mendation (package) is NP-complete as it models the Knap-sack problem [10]. Because of this and the fact that we expect the component recommender systems to provide rat-ings for large numbers of items and access to these ratings can be relatively expensive, 5 we devise approximation algo-rithms for generating top-k packages as recommendations.
Other researchers have considered complex or composite recommendations. CARD [4] and FlexRecs [12] are com-prehensive frameworks in which users can specify their rec-ommendation preferences using relational query languages extended with additional features or operators. In contrast, we are concerned with developing efficient algorithms for combining recommendations from RecSys that provide only ratings for items. Closer to our work is [3] which is concerned with finding packages of entities, such as holiday packages, where the entities are associated in some way. However, their packages are of fixed size, whereas we allow packages of variable size. CourseRank [16, 17] is a system for pro-viding course recommendations to students, based on the ratings given to courses by past students and subject to the constraints of degree requirements. While we do not capture all CourseRank constraints, in our framework we have item costs and user budgets X  X ssential features of the application areas we consider for deployment of our system X  X hich are not captured by CourseRank. Similarly, item costs and user budgets are not considered for team formation in [13].
In this paper, for space limitations, we restrict attention to the problem of recommending packages when there is just one component RecSys and no compatibility constraint is imposed. The problem remains intractable and still war-rants approximation algorithms. We discuss in Sec. 5 how to extend our algorithms when multiple component RecSys and compatibility constraints are present.

The roadmap of the paper is as follows. After discussing related work in more detail (Sec. 2), we present the archi-tecture of our system and give a precise definition of the problem we study (Sec. 3). We then describe the approx-imation algorithms we have developed for returning top-k composite recommendations (Sec. 4). We first present a 2-approximation algorithm that is instance optimal [6] with an optimality ratio of one. This means that any other 2-approximation algorithm, that can only access items in non-increasing order of their value, must access at least as many items as our algorithm. However, this algorithm makes re-peated calls to a routine for solving exactly the problem of finding the top-rated package under budget, from those items that have been accessed from the component RecSys so far. Because this is an NP-complete problem, we then
Especially when the ratings need to be predicted. develop a greedy algorithm for returning top-k composite recommendations. This algorithm is also guaranteed to re-turn a 2-approximation, but is no longer guaranteed to be instance optimal. It is interesting to note that the average value of packages returned by our approximation algorithms is higher than that returned by the exact algorithm. This is because an exact algorithm will add low-value items to a recommendation in order to maximize value. However, from a user X  X  perspective the recommendations returned by the approximation algorithms may sometimes be preferable.
In Sec. 6 we subject our algorithms to thorough empirical analysis using two real data sets  X  TripAdvisor and Movie-Lens  X  and two synthetic data sets. We first investigate the quality of the recommendations produced by our approxima-tion algorithms. Our findings confirm that our algorithms always produce recommendations that are 2-approximations, with many of them being close to optimal. We then com-pare the efficiency of our instance optimal and greedy ap-proximation algorithms with that of an exact algorithm in terms of running time and number of items accessed. Our results indicate that our greedy algorithm is always signifi-cantly faster than the other two algorithms, while the greedy and instance optimal algorithms usually access substantially fewer items than the exact algorithm. Finally, we discuss fu-ture work and conclude the paper in Sec. 7. To the best of our knowledge, this is the first time instance optimality is established in the context of approximation algorithms.
Closest to our work is [3], where they are interested in finding top-k tuples of entities. Examples of entities in-clude cities, hotels and airlines, while packages are tuples of entities. Instead of querying recommender systems, they query documents using keywords in order to determine en-tity scores. A package in their framework is of fixed size, e.g., one city, one hotel and one airline, with fixed associ-ations among the entities essentially indicating all possible valid packages. Instead, we allow for packages (composite recommendations) of variable size, subject to a budget con-straint. Associations between entities can be easily captured in our framework using the notion of compatibility of sets.
Other closely related work is [5] where a novel framework is proposed to automatically generate travel itineraries from online user-generated data like picture uploads and formu-late the problem of recommending travel itineraries of high quality where the travel time is under a given time budget. However, in this work, the value of each POI is determined by the number of times it is mentioned by users, whereas in our work, item value is a personalized score which comes from an underlying recommender system and accessing these items is constrained to be in value-sorted order. Unlike [5], we optimize item accesses, establish instance optimality, and provide algorithms for generating top-k packages.
CARD [4] is a framework for providing top-k recommen-dations of composite products or services. Fine-grained con-trol over specifying user requirements as well as how atomic costs are combined is provided by an SQL-like language ex-tended with features for decision support. Each composite recommendation is of fixed size, making the problem sim-pler; thus CARD returns exact not approximate solutions.
Similarly, FlexRecs [12] is a sophisticated system for defin-ing complex recommendations from relational data. Recom-mendation requirements are specified by relational algebra expressions enhanced with extend , recommend and blend op-erators. As with [3, 4], recommendations are of fixed size and thus solutions are exact.

In our setting of access to component RecSys (but with a restricted notion of binary boolean compatibility), the prob-lem of finding the top-k fixed-size packages is simpler than that of finding packages of variable size; it can be solved efficiently using Rank Join [7].

CourseRank [17] is a project motivated by a course plan-ning application for students, where constraints are of the form  X  X ake k i from S i , X  where k i is a non-negative integer and S i is a set of courses. Similar to our work, each course in this system is associated with a score which is calculated using an underlying recommendation engine. Given a num-ber of constraints of the form above (and others), the system finds a minimal set of courses that satisfies the requirements and has the highest score.

Later work [16] extends CourseRank with prerequisite con-straints, and proposes several approximation algorithms that return high-quality course recommendations which satisfy all the prerequisites. As in our work, such recommendations need not be of fixed size. However, [16, 17] do not consider the cost of items (cf. courses) which can be important for applications like trip planning and twitter.

The problem of team formation is studied in [13]. Here each person has a set of skills and pairs of people have a collaboration cost associated wi th them (lower cost indicates better collaboration). Given a task requiring a set of skills, the problem is to find a set of people whose skills cover those required and who have a low aggregated collaboration cost. The notion of compatibility in our framework can model their collaboration cost. Similar to CourseRank, the people (items) themselves are not rated. A further difference with our approach is that we wish to maximize the aggregate item (cf. people) ratings subject to item and compatibility costs, rather than minimize compatibility cost.

Although we do not include in our system complex con-straints such as those in [13, 16, 17], for applications where complex constraints exist, we can leverage existing work to post-process each composite recommendation generated by our algorithms to ensure that the constraints are satisfied.
Finally, motivated by online shopping applications, [18] studies the problem of recommending  X  X atellite items X  re-lated to a given  X  X entral item X  subject to a cost budget. The resulting notion of packages is quite restricted compared to our framework, and item values are not taken into account.
In a traditional RecSys, users rate items based on their personal experience, and these ratings are used by the sys-tem to predict ratings for items not rated by an active user. The predicted ratings can be used to give the user a ranked recommendation (item) list.

As shown in Figure 1, our composite recommendation sys-tem is composed of one or more component RecSys and has access to external sources that provide the cost of a given item. An external source can be a local database or a web service. E.g., Amazon.com can be consulted for book prices. In terms of computation, we abstract each RecSys as a sys-tem which serves items in non-increasing order of their value (rating or score) upon request. In addition, the system in-cludes a compatibility checker module, which checks whether a package satisfies compatibility constraints, if any. We as-sume the compatibility checker consults necessary informa-tion sources in order to verify compatibility.

The user interacts with the system by specifying a cost budget, an integer k , and optionally compatibility constraints on packages. The system finds the top-k packages of items with the highest total value such that each package has a total cost under budget and is compatible.

Given a set N of items and U of users, an active user u  X  U ,anditem t  X  N ,wedenoteby v u ( t )the value of item t for user u . Wedenotethevalueas v ( t ) when the active user is understood. A RecSys predicts v ( t )whenitis not available, by using the active user X  X  past behavior and possibly that of other similar users. For t  X  N ,wedenote by c ( t )the cost of item t . Given a set of items R  X  N we define c ( R )= X  t  X  R c ( t )and v ( R )= X  t  X  R v ( t a cost budget B ,asetofitems P  X  N is called feasible if c (
P )  X  B . In this paper, for space limitations, we focus on the following problem (with extensions discussed in Sec. 5): Definition 1 (Top-k Composite Recommendations). Given an instance I of a composite recommendation sys-tem consisting of one component RecSys and an external information source, a cost budget B and an integer k , find the top-k packages P 1 , ..., P k such that each P i is feasible and among all feasible packages P 1 , ..., P k have the k est total values, i.e., v ( P )  X  v ( P i ) for all feasible packages P  X  X  P 1 , ..., P k } .

When k = 1, the top-k composite recommendation prob-lem (CompRec) can be viewed as a variation of the classical 0/1 knapsack problem [10] with the restriction that items can be accessed only in non-increasing order of their value. Without loss of generality, we assume all items have cost smaller than the cost budget B .

Note that ratings of items from the component RecSys are retrieved using sorted access, while the cost of a given item is obtained via random access. Let c s and c r be the costs associated with these accesses. Then the total access cost of processing n items is n  X  ( c s + c r ). Notice that c s and be large compared to the cost of in-memory operations: for both accesses information needs to be transmitted through the Internet, and for the sorted access, v ( t ) may need to be computed. So, well known algorithms for knapsack which need to access all items [10] may not be realistic. Thus, an efficient algorithm for top-k CompRec should minimize the total access cost, i.e., it should minimize the number of items accessed and yet ensure the top-k packages are obtained.
It can be shown that if we have no background knowledge about the cost distribution of items, in the worst case, we must access all items to find top-k packages. In order to facilitate the pruning of item accesses, we thus assume some background information about item costs is precomputed and maintained at the composite RecSys. The background cost information, which we denote generically by BG ,can be a histogram collected from the external cost source or something as simple as a minimum item cost c min .This information can be materialized in our system and be re-freshed regularly by re-querying the cost source.
Our composite recommendation problem can be consid-ered as a special case of a resource-limited knapsack prob-lem where in addition to quality guarantee, the number of items to be accessed should also be minimized. So standard algorithms for knapsack, e.g., exact algorithms [10] and ap-proximation algorithms [8, 19] may not be efficient as they always need to access the entire dataset. The only known variation of knapsack which deals with resource limitation is the Online Knapsack Problem [15]. However, for this prob-lem, no access constraints are considered, only competitive-ness in terms of quality is studied. And furthermore, no information about items can be inferred, which makes the problem significantly harder and difficult to approximate.
In this section, we develop several approximation algo-rithms for top-1 CompRec, after which we extend them to handle top-k CompRec.
As identified in Section 3.2, top-1 CompRec is a variation of the 0/1 knapsack problem where the underlying items can be accessed only in non-increasing order of their value (rat-ing). Because of the huge potential size of the sets of items and the high cost of retrieving item information from the source, it is crucial for an algorithm to find high-quality so-lutions while minimizing the number of items accessed .Fur-thermore, as the 0/1 knapsack problem is NP-Complete [10], we need to develop efficient approximation algorithms.
Given an instance I of top-1 CompRec, let BG denote the known background cost information and S = { t 1 , ..., t n the set of items which have been accessed or seen so far.
Let  X  v be the value of the first accessed item, because items are accessed in the non-increasing order of their value, n  X  is a trivial upperbound on the value that can be achieved by any knapsack solution for S .
 For each i  X  X  1 , ..., n } and v  X  X  1 , ..., n  X   X  v } ,let note a subset of { t 1 , ..., t i } whose total value is exactly and whose total cost is minimized. Let C ( i, v )bethecost of
SS i,v ( C ( i, v )=  X  if the corresponding SS i,v doesn X  X  ex-ist), then it is well known from previous work [19, 10] that a pseudo-polynomial algorithm can be utilized to get the op-timal knapsack solution for S by first calculating all C ( using the following recursive function and then choosing the maximum value achievable by any subset SS n,v of which the total cost is bounded by budget B , i.e., max { v | C ( n, v B } .
 C ( i +1 ,v )= (1) j
Let the background cost information be BG = c min ,which is the minimum cost of all items, let v min =min t  X  S v ( the minimum value of all accessed items, and let OP T be the true optimal solution to the underlying top-1 CompRec Instance I . We can get an upperbound V  X  on the value v (
OP T ) of the optimal solution using the following algo-rithm MaxValBound. (Proofs of all lemmas and theorems can be found in [1].)
Algorithm 1: MaxValBound( S , C , B , BG ) 1 2for v  X  X  1 , ..., n  X   X  v } do 3if C ( n, v ) &lt;B 5return V  X 
Lemma 1. Given S , C , B , BG ,thevalue V  X  returned by MaxValBound is an upperbound on v ( OP T ) .And V  X  is tight in that there exists a possible unseen item configuration for which V  X  is achievable by using a subset of accessed items and feasible unseen items 6 .

Given the upper bound V  X  on the optimal solution, we next propose a 2-approximation algorithm for top-1 Com-pRec which is guaranteed to be instance optimal (see be-low). The algorithm, InsOpt-CR, is shown as Algorithm 2. One item is retrieved from the source at each iteration of the algorithm (lines 3 X 4). After accessing this new item, we can use the pseudo-polynomial algorithm to find an optimal solution R o over the accessed itemset S (line 5). We calcu-late the upper bound value V  X  of the optimal solution using MaxValBound. If v ( R o )  X  1 2  X  V  X  , the algorithm terminates; if not, it continues to access the next item (lines 7 X 8). The following example shows how InsOpt-CR works.

Algorithm 2: InsOpt-CR( N , B , BG ) 1
S  X  An empty buffer 2 while TRUE do 3 t  X  N .getNext() 4 S .Insert( t ) 5 ( R o , C )  X  OptimalKP( S , B ) 6 V  X  = MaxValBound( S , C , B , BG ) 7if v ( R o )  X  1 2  X  V  X  8return R o
Example 1. Let I = { t 1 ,t 2 ,...,t n } be a top-1 Com-pRec instance, where v ( t 1 )= v ( t 2 ) = 101 , c ( t 1 100 ,for i =3 ,..., 101 , v ( t i )= c ( t i )=1 ,andfor i 102 ,...,n , v ( t i )=1 and c ( t i )=0 . 5 .Let B = 199 . Clearly, BG = c min =0 . 5 . After accessing the first 101 items, S { t 1 ,...,t 101 } , R o = { t 1 } X  X  t 3 ,...,t 101 } , v ( R o cause c min =0 . 5 and v min =1 , we can calculate V  X  = 398 and InsOpt-CR will stop since v ( R o )  X  1 2  X  V  X  . Given a top-1 CompRec instance I with optimal solution OP T ,because V  X   X  v ( OP T ), if v ( R o )  X  1 of OPT.
An unseen item t is feasible iff. v ( t )  X  v min and c (
To analyze the optimality of our proposed algorithm, we utilize the notion of instance optimality proposed in [6].
Definition 2. Instance Optimality: Let A be a class of algorithms, and let I be a class of problem instances. Given a non-negative cost measure cost ( A , I ) of running al-gorithm A over I , an algorithm A  X  X  is instance optimal over A and I if for every A  X  X  and every I  X  X  we have cost ( A, I )  X  c  X  cost ( A ,I )+ c , for constants c and stant c is called the optimality ratio .

To prove the instance optimality of InsOpt-CR, we first show the following.

Lemma 2. Given any top-1 CompRec instance I and any 2-approximation algorithm A with background cost informa-tion BG and the same access constraints as InsOpt-CR, A must read at least as many items as InsOpt-CR.

Theorem 1. Let I be the class of all top-1 CompRec in-stances, and A be the class of all possible 2-approximation al-gorithms that are constrained to access items in non-increas-ing order of their value. Given the same background cost information BG , InsOpt-CR is instance optimal over A and I with an optimality ratio of one.
In addition to the best composite recommendation, it is often useful to provide the user with the top-k composite rec-ommendations, where k is a small constant. In this section, we extend the algorithm proposed in Section 4.1.1 to one that returns the top-k composite recommendations. Simi-lar to the top-1 case, due to the hardness of the underlying problem, we seek an efficient approximation algorithm which can give us high quality recommendations.

Givenaninstance I of top-k CompRec, assume R I is the set of all feasible composite recommendations , i.e., R I { R | R  X  N  X  c ( R )  X  B } ). Following Fagin et al. [6] and Kimelfeld et al. [11], we define an  X  -approximation of the top-k composite recommendations to be any set R k of min( k , |R I | ) composite recommendations, such that, for all R  X  X  k and R  X  X  I \R k , v ( R )  X  1
To produce top-k composite recommendations, we will ap-ply Lawler X  X  procedure to InsOpt-CR. Lawler X  X  procedure [14] is a general technique for enumerating optimal top-k answers to an optimization problem, which relies on an efficient al-gorithm to find the optimal solution to the problem.
Let InsOpt-CR-Topk be the InsOpt-CR algorithm modi-fied using Lawler X  X  procedure. All we need to change is that instead of returning the 2-approximation solution found in Algorithm 2 (line 8), we enumerate at this point all possible 2-approximation solutions using Lawler X  X  procedure. If the number of 2-approximation solutions is at least k ,thenwe can report the top-k packages found; otherwise, we continue accessing the next item.

In InsOpt-CR, the enumeration of all possible 2-approxim-ation solutions is straightforward. Since we know the upper bound V  X  , we can simply utilize Lawler X  X  procedure to enu-merate candidate packages which are under cost budget and have aggregated value of at least half of V  X  .

Lemma 3. Given any instance I of top-k CompRec and any 2-approximation algorithm A with the same background cost information BG and access constraints as InsOpt-CR-Topk, A must read as many items as InsOpt-CR-Topk.
Theorem 2. Let I be the class of all top-k CompRec in-stances, and A be the class of all possible 2-approximation algorithms that are constrained to access items in the non-increasing order of their value. Given the same background cost information BG , InsOpt-CR-Topk is instance optimal over A and I with an optimality ratio of one.
Although the instance optimal algorithms presented above guarantee to return top-k packages that are 2-approximations of the optimal packages, they rely on an exact algorithm for the knapsack problem which may lead to high computational cost. To remedy this, we propose more efficient algorithms next. Instead of using an exact algorithm to get the best package for the currently accessed set of items S ,weusea simple greedy heuristic to form a high quality package R G from S andthentestwhether R G is globally a high quality package.
 Compared with InsOpt-CR, our greedy solution Greedy-CR for top-1 CompRec needs to replace OptimalKP in InsO-pt-CR with GreedyKP, which uses greedy heuristics [10] to find a high quality itemset in polynomial time 7 ,andto change R o to the greedy solution R G . Furthermore, instead of using tight upperbound calculated by MaxValBound, we need to use an untight heuristic upperbound which is calcu-lated by the following algorithm MaxHeuristicValBound.
Algorithm 3: MaxHeuristicValBound( S , B , BG ) 1 2 Sort S = { t 1 ,...,t n } by value/cost ratio 3 4
R m = { t 1 ,...,t m } 5if m == n 6 V  X  = v ( R m )+  X   X  ( B  X  c ( R m )) 7else 9return V  X 
It follows from known results about knapsack that, similar to InsOpt-CR, Greedy-CR will always generate a correct 2-approximation to the optimal solution.

However, unlike InsOpt-CR, Greedy-CR is not instance optimal among all 2-approximation algorithms with the same constraints, as the following example shows.

Example 2. Let I = { t 1 ,t 2 ,...,t n } be a top-1 CompRec instance, where v ( t 1 )= v ( t 2 ) = 101 , c ( t 1 )= c for i =3 ,..., 101 , v ( t i )= c ( t i )=1 ,andfor i = 102 v ( t i )=1 and c ( t i )=0 . 5 .Let B = 199 , BG = c min =0 . 5 and approximation ratio  X  =2 . From Example 1, we know that after accessing the first 101 items, S = { t 1 ,...,t v (
R o ) = 200 , V  X  = 398 and InsOpt-CR will stop. However, at this moment R G = { t 1 } ,and v ( R G ) = 101 &lt; 1 2 So Greedy-CR will continue accessing new items and it can be easily verified that Greedy-CR needs to access another 98 items before it stops.
Note that any approximation algorithm for knapsack [10] can be plugged in here while correctness of the resulting algorithm and the instance optimality result won X  X  change.
We note that, in practice, cases such as the above may occur rarely. In fact, in our experimental results (Sec. 6) we observed that, on a range of datasets, Greedy-CR exhibited a very low running time while achieving similar access costs and overall result quality when compared to InsOpt-CR.
Similar to Section 4.1.2, we can easily extend Greedy-CR to Greedy-CR-Topk by using Lawler X  X  procedure [14] to enu-merate all possible high quality packages after one such pack-age is identified. However, unlike InsOpt-CR-Topk which guarantees instance optimality, here we simply use Lawler X  X  procedure to enumerate all candidate packages using the greedy algorithm instead of the exact algorithm. Similar to [11], we show in the following theorem that for top-k Com-pRec, if an  X  -approximation algorithm is utilized in Lawler X  X  procedure instead of the exact algorithm which finds the optimal solution, we get an  X  -approximation to the top-k composite recommendations.

Theorem 3. Given an instance I of top-k CompRec, any  X  -approximation algorithm A for top-1 CompRec can be uti-lizedwithLawler X  X proceduretogenerateaset R k of com-posite recommendations which is an  X  -approximation to the optimal set of top-k composite recommendations.

So the quality of the packages generated by the resulting enumeration process can be guaranteed. In this enumeration process, given a candidate package, we use the greedy algo-rithm to get the next candidate package for each sub-search space in Lawler X  X  procedure, and if all of them are not guar-anteed to be 2-approximations, the enumeration will stop. However, similar to Greedy-CR, it is obvious that Greedy-CR-Topk is not instance optimal. We note that, in practice, the difference between the results generated by InsOpt-CR-Topk and Greedy-CR-Topk (in terms of the aggregate values of packages generated) may be very small.
As mentioned in Sec. 3, our framework includes the notion of a package satisfying compatibility constraints. E.g., for trip planning, the user may require the returned package to contain no more than 3 museums.

To capture these constraints in our algorithms, we can define a Boolean compatibility function C over the packages under consideration. Given a package P , C ( P )= true iff all constraints on items in p are satisfied. We can add a call to C in InsOpt-CR-Topk and Greedy-CR-Topk after each candidate package has been found. If the package fails the compatibility check, we just discard it and search for the next candidate package. In terms of access cost, it can be easily verified that the modified InsOpt-CR-Topk algorithm is still instance optimal.

It is worth noting that the Boolean compatibility func-tion defined here allows for greater generality than the con-straints studied in previous work such as [3, 17]. However, depending on the application needs, for scenarios where only one specific type of constraint is considered, e.g., having one item from each of 3 predefined categories, more efficient al-gorithms like Rank Join [7] can be leveraged.

Furthermore, although in the previous algorithms we as-sume there is only one component recommender system, it is straightforward to combine recommendation lists from sev-eral component recommender systems by creating on-the-fly a  X  X irtual recommendation list X , e.g., select at each iteration the item which has the maximum value/rating across all recommender systems. The details will appear in the full version of the paper where efficient algorithms are given for special cases of compatibility constraints as well as compat-ibility constraints based on continuous functions.
In this section, we study the performance of our proposed algorithms based on both real and synthetic datasets.
The goal of our experiments were: (i) evaluate the rel-ative quality of Inst-Opt-CR and Greedy-CR compared to the optimal algorithm, in terms of both the total and aver-age values of the top-k packages returned, and (ii) evaluate the relative efficiency of the algorithms with respect to the number of items accessed and the actual run time. All ex-periments were done on a Xeon 2.5GHz Quad Core Windows Server 2003 machine with 16GB RAM and a 128GB SCSI hard disk. All code is in Java using JDK/JRE 1.6.
We use four datasets in our experiments. The first dataset is from MovieLens 8 . We use the 10 million rating MovieLens dataset which contains 1 million ratings for 3900 movies by 6040 users. In our experiments , we used the running time of movies, obtained from IMDB 9 , as cost and we assume users are interested in packages of movies where the total running time is under a given budget.

TripAdvisor 10 is a well-known website where users can share and explore travel information. For our experiments, we crawled user rating information from places of interest (POIs) in the 10 most popular cities in the US. We exclude POIs which have one or no reviews, and the dataset contains 23658 ratings for 1393 POIs by 14562 users, so it is very sparse. 11 We associate with each POI in the dataset, a cost which is based on log(number of reviews) and scaled to the range of 1 to 50. The intuition of this cost function is that the more popular a POI is (in terms of number of reviews), themorelikelyitistobecrowdedorthemorelikelyitis for the tickets to be expensive. In practice, we may also use some existing work like [5] to mine from online user-generated itineraries other cost measures, e.g., average time users spent at each POI, average cost of visiting each POI, etc.

For the MovieLens and TripAdvisor datasets, we use a simple memory-based collaborative filtering algorithm [2] to generate predicted ratings for each user. The ratings are scaled and rounded to integers ranging from 1 to 50.
For the MovieLens dataset, we randomly selected 20 users from the 23594 user pool, and the budget for e ach user was fixed at 500 minutes 13 . For the TripAdvisor dataset, be-cause of the sparsity of the underlying user rating matrix, we selected the 10 most active users as our sample for testing the algorithms, and set the user cost budget to 50. http://www.movielens.org http://www.imdb.com http://www.tripadvisor.com
Pruning more aggressively rendered it too small.
Our algorithms don X  X  depend on a specific recommendation algorithm; in practice, our framework assumes ratings come from existing recommender systems.
For all datasets, we tested our algorithms under various cost budgets with very similar results, so other budgets are omitted for lack of space.
We also tested our algorithms on synthetic correlated and uncorrelated datasets. For both datasets, item ratings are randomly chosen from 1 to 50. For the uncorrelated dataset, item costs are also randomly chosen from 1 to 50, but for the correlated dataset, the cost of item t is randomly chosen number of items is 1000, and t he cost budget is set to 50. For all datasets, we assume the background cost information BG is simply the global minimum item cost.
For each dataset, Table 1 shows the quality of the top-5 composite recommendations returned by the optimal and approximation algorithms. We use as measures of quality the aggregated value of each package (SUM column) and the average item value of each package (AVG column).
It can be verified from Table 1 that our approximation al-gorithms do indeed return top-k composite packages whose value is guaranteed to be a 2-approximation of the optimal. Furthermore, from the average item value column, it is clear that our proposed approximation algorithms often recom-mend packages with high average value, whereas the opti-mal algorithm often tries to fill the package with small cost and small value items. So by sacrificing some of these lower quality items, the proposed approximation algorithms may manage to find high quality packages much more efficiently.
To better study the overall quality of returned packages, we also adopt a modified Normalized Discounted Cumulative Gain (NDCG) [9] to measure the quality of the top-k com-posite packages returned by the approximation algorithms against the optimal algorithm. Let R o = { P o 1 ,...,P o the top-k packages returned by the optimal algorithm, and R a = { P a 1 ,...,P a k } be the top-k packages returned by the approximation algorithm. The modified NDCG score is a weighted sum of aggregated package value difference at each position of the returned top-k list, and is defined as: The ideal value for the modified NDCG score is 0, where the top-k packages returned have exactly the same value as the optimal top-k packages. The worst possible value for the modified NDCG score is package returned has an aggregated value of 0. In Figure 2, we show for the 4 datasets the NDCG score of the top-k packages ( k ranging over 1 to 10) returned by the instance optimal algorithm and the greedy algorithm. It is clear that, while having a substantial run time advantage, the greedy algorithm can achieve a very similar overall top-k package quality compared to the instance optimal algorithm. We also note that both approximation algorithms have a very small NDCG score.
The running times of our algorithms on the 4 datasets are shown in Figure 3 (a)-(d), while access costs are shown in Figure 3 (e)-(h). For MovieLens, TripAdvisor and the uncor-related dataset, it can be seen that on average the greedy al-gorithm Greedy-CR-Topk has excellent performance in terms of both running time and access cost. The instance optimal algorithm InsOpt-CR-Topk also has low access cost, but its running time grows very quickly with k since it needs to solve exactly many instances of knapsack, restricted to the accessed items.

As can be seen in Figure 3 (h), the only dataset where both the greedy and instance optimal algorithms have a high ac-cess cost is the correlated dataset (but notice that the greedy algorithm still has good running time). The reason for this is that, for the correlated dataset, the global minimum cost corresponds only to items which also have the least value. Thus the information it provides on the unseen items is very coarse. In practice, one solution to this might be to obtain more precise background cost information.
Motivated by applications in trip planning and in finding the most effective tweeters to follow, we studied the prob-lem of recommending packages consisting of sets of items. Our composite recommender system has one or more com-ponent RecSys, which serve item recommendations in non-increasing order of their value. We proposed the problem of generating top-k package recommendations that are com-patible and are under a cost budget, where a cost is in-curred by visiting each recommended item and the budget and compatibility constraints are user specified. We focused on the case where there are no compatibility constraints and there is only one component RecSys. The problem is NP-complete since it is a variant of the Knapsack problem with the restriction that items need to be accessed in value-sorted order. So we developed two 2-approximation algorithms that are designed to minimize the number of items accessed. The first of these, InsOpt-CR-Topk, is instance optimal in a strong sense: every 2-approximation algorithm for the prob-lem must access at least as many items as this algorithm. The second of these, Greedy-CR-Topk, is not guaranteed to be instance optimal, but is much faster. We experimentally evaluated the performance of the algorithms and showed that in terms of the quality of the top-k packages returned both algorithms are close to each other and deliver high quality packages; in terms of the number of items accessed Greedy-CR-Topk is very close to InsOpt-CR-Topk, but in terms of running time, Greedy-CR-Topk is much faster. Part of this work was done during Peter Wood X  X  visit to UBC in January, 2010. This research was supported by a grant from NSERC (Canada).
