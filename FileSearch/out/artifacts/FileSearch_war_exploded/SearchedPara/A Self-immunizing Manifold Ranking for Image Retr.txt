 With the ubiquitous use of digital images in a large number of practical applications, Content-Based Image Retrieval (CBIR) has drawn substantial research attention in many computer communities during the past two decades [2]. A main challenge in CBIR is the so-called semantic gap, i.e. the low-level visual features are not sufficient to characterize the high-level semantics of images. Relevant feedback has been shown with CBIR system. During the past years, a wide variety of relevant feedback tech-niques have been proposed, most of which belong to the family of supervised learning [14, 2]. 
One critical research topic related to relevance feedback is to learn with few labeled training examples, as few users are patient to label a lot of images during the interac-tion. To this end, semi-supervised learning [1] has been applied to relevance feedback [3, 4, 8, 9, and 13]. A popular semi-supervised learning method used in CBIR is the underlying geometrical structure of the given image database. Previous studies have shown that MR is one of the most promising and successful semi-supervised learning techniques for relevance feedback [3, 7, 10 and 11]. 
However, it has been found that the performance of semi-supervised learning may be even worse than the supervised learning when  X  X nreliable X  unlabeled data is ex-ploited [ 5 ]. Taking MR as an example, it assumes that a labeled example and its (un-labeled) nearby neighbors trend to have similar properties, and thus their ranking scores should be approximate, but this assumption may not be true in CBIR due to the semantic gap. To verify the efficacy of this assumption, we conducted an empirical study on a set of 10,000 images, each consecutively-numbered 100 images in which belong to the same semantic category. Given the image set, a k NN graph is constructed and corres-ponding adjacency matrix is shown by Figure 1a. Ideally, for each image i , we expect floor 100 100 , i  X   X   X  () floor 100 100 100 i  X +  X   X  (e.g., if an image id is 1588, its  X  X rusted X  interval should be [1501, 1600]), since the images within this interval belong to the same class as illustrated in Figure 1b, where () floor  X  denotes the integer op-diagonal of the adjacency matrix, which means most neighbor points are inside their trusted interval. But there are still many nonzero elements far away from the principal strated by Figure 1c), and, in this case, the performance of MR may degenerate. Moreover, the performance of MR is sensitive to the scale parameter used for calculating examples [11], which is a common issue in graph-based semi-supervised learning. 
To address the above problems, this paper presents a S elf-i mmunizing ma nifold unlabeled images  X  X afely X  and tune the scale parameter adaptively. Concretely, we first propose a new graph structure named elastic k NN graph and corresponding constructing algorithm. In this structure, the creditable relationship between each labeled image and its nearby neighbors can be dynamically adjusted by monitoring the change of retrieval performance. Also, a local scaling solution is employed by Simar to tune the scale pa-rameter for Laplacian matrix calculation, which is beneficial to the data distribution with multi-scales, e.g. image database. Our empirical study shows encouraging results in comparison to some existing semi-supervise d learning algorithms widely used in CBIR. 
The remainder of this paper is organized as follows. Section 2 elaborates the pro-posed Simar approach. Section 3 shows experimental evaluations. Finally, section 4 concludes this paper. local scaling method to facilitate the setting of parameters. 2.1 Preliminaries Let image by a d -dimensional feature vector. To discover the geometrical structure of the define nn  X   X  W  X  as corresponding adjacency matrix with element ij w saving the using a Gaussian kernel if xx or of the k nearest neighbors of x , and tance) between i x and j x . Finally, we define a label vector as record the user X  X  judgment in relevance feedback loops, in which an element 1 i y = if y = otherwise. f:  X  X  X  that assigns each image solving the following optimization problem: where 0  X  &gt; is the regularization parameter and D is a diagonal matrix with 
D= w  X  . The first term is a smoothness constraint that makes the nearby images optimal f by the following closed form symmetrical normalization of W . In large scale problems, we prefer to use the iteration scheme: 
During each round of iteration, each data point receives information from its process is repeated until convergence. 
As illustrated by Eq. (3) and (4), one of the key issues is to design an appropriate S , and more precisely to design W , which depends on two key parameters: the number of the nearest neighbors k used for constructing k NN graph and the scale parameter  X  used by Gaussian kernel. We will discuss how to tune the parameters in the following subsections. 2.2 Constructing an Elastic k NN Graph MR scheme. As mentioned, the k NN graph is a popularly used structure, but it is prone to exploit  X  X nreliable X  unlabeled images, as ill ustrated by Figure 1. To  X  X afely X  exploit unlabeled images, we expect that the cons tructed graph could dynamically update the k purpose, for each image reduce the likelihood of exploiting the  X  X nreliable X  neighbors. At worst, no unlabeled images are considered and our Simar approach will degenerate to a supervised ranking method. In this way, we can guarantee that our semi-supervised ranking method will never worse than a supervised one. 
Given the labeled image set, a challenge is to probe whether most of their (unla-beled) nearby neighbors are inside the corresponding  X  X rusted X  intervals, since the images are not indexed by semantic in real-world applications. Considering this, Simar unlabeled images used by current ranker is evaluated by monitoring the changes in its retrieval performance. Concretely, the retrieval performance is measured by using the on image retrievals. If the current precision cur Precision is greater than the previous 
Precision Precision &lt; , then it means that the  X  X eliability X  of the unlabeled images considerations, we adaptively tune the parameter k according to to  X  X afely X  exploit the unlabeled images. 
Note that the Precision mentioned here is calculated with the number of relevant images that appear in a fixed number of retrievals. Suggested by Luxberg [6], the initial connectivity purpose. 2.3 Local Scaling As mentioned before, the performance of MR is sensitive to the scale parameter  X  . Some However, the performance of this approach is heavily depended on the testing data and the range of values to be tested still has to be set manually. What is worse, there may not be a single value of  X  that works well for all data points when the input data with different address this shortcoming from a local scaling view, i.e. calculating a local scale parameter for each image, instead of selecting a single scale parameter for all images. 
Inspired by the self-tuning spectrum clustering technique [12], the scale parameter provides an intuitive way for selecting possible  X  . Let i  X  and j  X  denote the local  X  X een X  by i x can be defined as Hence, the square distance 2 d between two images can be generalized as: and the weight of the edge between a pair of images, i.e. Eq. (1), can be rewritten as: purpose, the selection of the local scale i  X  can be done by studying the local statistics of the neighborhood of i x . Considering the efficiency, we use the distance from i x to where () floor log kn = that gave good result in our experiment. 2.4 Implementation Issues For the real-time response purpose, previous work suggested using a sparse represen-tation for the affine matrix W and calculating it off-line [3]. However, different from conventional MR, Simar requires updating matrix W on-line because elastic k NN graph is considered. Our idea is to calculate an initial affine matrix with a large k value off-line, and then add or remove elements into/from the matrix according to the changes of k values on-line. In the way, we can update matrix W with low computa-tional cost. The key steps are summarized as follows. Step 1 (off-line) : Starting with a large where each element ij g denotes the identity of the j -th nearest neighbor of image i x . Based on G , the initial affinity matrix 0 W is calculated by Eq. 7. can be gained by: Step 3 (on-line) : After the second round of feedback, the affinity matrix cur W used tailed updating rules can be described as: 
Another issue is with respect to the out-of-sample search. If the query image is not in the database, we first connect the query with its corresponding neighbor. Then, we calculate the edge weights by Eq. 7 and add one row and one column to 0 W , with each element equal to the corresponding edge weight. All the other operations will be performed similarly using the enlarged matrix 0 W and G . In this section, we show several experimental results and comparisons to evaluate the periments are implemented in MATLAB 2008 and run on a PC with Intel Core (TM) Duo 2.93 GHZ processor and 2GB RAM. 3.1 Experimental Setup Experiments are performed on a set of 10,000 images picked from the Corel database. These images belong to 100 semantic classes, each of which has 100 images. 
Three different features are used to represent the images, including a 64-dimensional color histogram, an 18-dimensional wavelet-based texture and a 5-dimensional edge vector. 
We use PR-graph and P@TopN to evaluate the effectiveness of image retrieval methods. PR-graph depicts the relationship between precision and recall of a specific value, i.e. MAP (mean average precision). However, PR-graph can hardly reflect the changes of retrieval performance caused by feedbacks directly. P@TopN emphasizes between precision and round of feedback at top N retrieval results. Thus it can com-pensate for the deficiency of PR-graph. 3.2 Comparison Methods To examine the efficacy of the proposed Simar approach, several existing semi-supervised learning solutions for relevance feedback in CBIR are compared in our regular MR algorithm to learn a ranking function. The setting of parameters is consis-independent rankers using different distance metrics, and then each ranker labels for the other ranker its two most confident images from unlabeled data for the purpose SVMs using a similar procedure of boosting algorithm. In particular, both labeled and unlabeled images are exploited in the boosting procedure. The SVM is implemented using LIBSVM toolbox. Furthermore, in order to study whether the elastic k NN graph is useful, a degenerated variant of Simar, termed SimarDeg, is evaluated in the comparison. (4) SimarDeg is almost the same as Simar except that the former use the fixed k NN graph ( () floor log kn = ), instead of the elastic k NN graph, to calculate the Laplacian matrix. 3.3 Performance Evaluation To evaluate the average performance, we conducted every experiment on a set of 200 random queries sampled from our image dataset. At the beginning of retrieval, the database images are ranked according to th eir Euclidean distances to the query image methods are then applied to rerank the database images. For each compared method, after obtaining a query, several rounds of feedback were performed, and in each round the user labeled ten images as the feedback. At first, the performance of Simar, MR, Co-training and SemiBoost are compared. The PR-graph at the 1 st , 2 nd , and 3 rd round of feedback are shown in Figure 2, and the corresponding MAP statistic is tabulated in Table 1, where the best performance has been boldfaced. The precision curve at top 20, top 60, and top 100 retrieval results are presented in Figure 3. Several observations can be drawn from the experimental results. First, by comparing the two MR approaches, the performance of Simar is much better than conventional MR. Note that the main difference between them is that Simair calculates the Laplacian matrix using an adaptive scale parameter while conventional MR does this using a fixed scale parameter, which verifies the usefulness of our local scaling solution. Furthermore, in most cases, Simar outperforms Co-training and Se-miBoost, especially at the first round of fee dback, which is meaningful to the real world applications because it is not practical to require the user to provide many rounds of feedback and therefore the retrieval performance at the 1 st round of feedback is the most important. Finally, it is impressive that at all rounds of feedback, the MAP of Simar is semi-supervised ranking methods when the parameters are tuned appropriately. 
In order to study whether the elastic k NN graph employed in our approach is bene-ficial or not, Simar is compared with its degenerated variant SimarDeg. Figure 4 and Figure 5 print the MAP and the P@Top20 of the two algorithms at 1 st to 5 th round of feedback, respectively. As can been seen, the performance of Simar and SimarDeg are probability of exploiting the  X  X nreliable X  unlabeled images (the nearby neighbors of the labeled images) would be low, and thus the impact of the elastic k NN graph is trivial. By gradually adding the user X  X  feedbacks, the elastic k NN graph is increasingly helpful to Simar. In this paper, we presented a novel MR approach for relevance feedback in CBIR, which addressed the two main drawbacks of regular MR algorithm. In particular, we scale parameter used for calculating Laplacian matrix. We conducted extensive expe-riments to evaluate the performance of our techniques for relevance feedback in CBIR, from which the promising results showed the advantages of the proposed approach in comparison to several existing methods. In the future work, we will take more visual features into consideration and evaluate our method on other databases. Acknowledgements . This work was supported in part by the Fundamental Research Funds for the Central Universities (#2012JBM038 and #2012JBM035), the Natural Science Foundation of China (#61170232, #60973067 and #61175053), and the State Key Laboratory Research Funds #RS2012K011 . 
