 C  X  esar Antonio Fuentes Montesinos  X  CESARF @ STUDENT .  X  ETH Z  X  urich, Z  X  urich, Switzerland  X  The University of Tokyo, Tokyo, Japan * Liverpool John Moores University, Liverpool, United Kingdom Object detection is one of the fundamental challenges in computer vision. Target objects in real-world images not only exhibit high variance in appearance, but also differ in various views, scales, illumination conditions, and back-ground clutter. While object recognition algorithms have undergone rapid progress, for many practical tasks, a high-quality fully automatic detection system is still beyond our reach. A major problem for automatic object detection is the lack of sufficient training examples, as manual anno-tations are usually time-consuming and expensive, some-times even impossible until the task is revealed. For exam-ple, consider a biodiversity monitoring task as in Fig. 1(a). In order to obtain accurate and timely data on the orangutan distribution in the surveyed area, ecologists launch micro UAVs,  X  X onservation drones X , to take high-quality pho-tographs of orangutan habitat from above treetops. Fre-quently going through thousands of those photos to look for orangutan nests is an extremely tedious task for experts. On the other hand, an automatic detection system (e.g., the rightmost figure in Fig. 1(a)) tends to produce many false positive detections in the high-clutter background, given limited training samples obtained from the drone missions. A natural step towards a sustainable and efficient system is to incorporate human supervision during the detection process. In such settings, the automatic system and the human expert collaborate in order to obtain the best performance: first, the system proposes candidate objects to the expert for verification, and then the expert provides feedback in order to guide the system to generate better detections. To make the best use of the scarce labeling resources, one needs to decide when to invoke the expert, or, in other words, in which order to query the candidates, such that the best possible performance could be achieved in exchange for the minimum amount of user supervision. Similar problems (i.e., minimizing the number of user in-teractions) have been studied extensively as active learning problems in many other contexts, such as text classifica-tion (Tong &amp; Koller, 2002), image recognition (Luo et al., 2004). However, comparing with the classical settings, the active detection problem studied in this paper is different in the following aspects: 1. In the classical active learning setting, the learner 2. In our setting, the system only queries objects which 3. The queries proposed by an active detector are part of Rather than developing novel object recognition algo-rithms, in this paper, we focus our attention on the study of techniques for intelligently interacting with users. In particular, we propose a general framework for active detection problems, which brings together the quality of manual annotation and the scalability and speed of automatic detection, regardless of what base detectors have been employed. We show how one can, from a given base detector, derive a natural sequential decision problem. Fur-ther, its objective function satisfies adaptive submodularity (Golovin &amp; Krause, 2011), a natural diminishing returns condition, quantifying how user labels explain the evidence obtained from the base detector. This insight allows us to use highly efficient greedy algorithms, with strong theoret-ical guarantees. To demonstrate the effectiveness of active detection, we carry out experiments on three different detection tasks using different base object detectors (see Fig. 1), and show that active detection does have substantial advantages over its passive counterpart. In addition, for the orangutan nest detection task, our algorithm significantly outperforms a natural baseline based on existing active learning techniques. To the best of our knowledge, our ap-proach is the first to rigorously address the active detection problem from both empirical and theoretical perspectives. In summary, our contributions are as follows:  X  We propose a general framework for the active detec- X  prove theoretical performance guarantees for the pro- X  show that different base detectors can be integrated  X  demonstrate the effectiveness of our approach on three Multiple object detection via submodular optimization Sliding-window based algorithms (Felzenszwalb et al., 2010) and patch based (e.g., Hough transform based) algo-rithms are two of the most widespread approaches for mul-tiple object detection. These approaches produce responses with peaks at candidate object locations (see Fig. 1). When dealing with overlapping hypotheses, common ob-ject detection methods use non-maximum suppression or mode-seeking to locate and distinguish peaks. Such post-processing requires tuning of many parameters and is often fragile, especially when objects are located spatially close to each other. Recently, Barinova et al. (2012) proposes a new probabilistic framework for multiple object detection, with an objective function satisfying submodularity, which can be solved efficiently with a greedy algorithm for sub-modular maximization (Nemhauser et al., 1978). Hereby, submodularity captures diminishing returns in the detector response at nearby object locations. Our work is inspired by this framework. In contrast to their approach, however, we consider the active detection setting, where detection is interleaved with expert feedback.
 Learning object detectors with human in the loop Active learning has been used successfully to reduce labeling cost in classification (Joshi et al., 2012). However, it is more challenging for object detection problems. These approaches start off with few annotated images and then look at a pool of unlabeled examples, and find the ones which would most improve the performance of the classi-fier once their label has been obtained. Such a procedure has been shown to significantly reduce the number of required labels (Abramson &amp; Freund, 2004; Kapoor et al., 2007; Bietti, 2012), and even work well in large scale (Vi-jayanarasimhan &amp; Grauman, 2011) and in a distributed pattern (Vijayanarasimhan et al., 2010). However, in these works, active learning has only been applied at training time to produce a good base detector. To re-iterate, we consider the complementary setting, of taking any given base detector, and applying it in an active manner at test time, i.e., interleaving automatic detection with expert feedback. Moreover, many existing algorithms require retraining the model from scratch on new labels, whereas we choose to gradually update the base detector on new observations, which potentially could be much cheaper. Human feedback has been used in different levels: e.g., image-level (Vijayanarasimhan &amp; Grauman, 2008), object and attribute levels (Kovashka et al., 2011; Shrivastava et al., 2012), and part-level annotations (Wah et al., 2011). Parkash &amp; Parikh (2012) consider attribute feedback (at training time), but on negative labels, the human expert also tries to communicate an explanation for why the learner X  X  belief is wrong, and the learner can then propagate the feed-back to many unlabeled images. Our work is similar in that we also treat positive and negative feedbacks differently, but we only require object level feedback (at test time) to update the prediction model.
 Object recognition with test-time feedback Branson et al. (2010) and Wah et al. (2011) study fine-grained classification problems, where the goal is to recognize bird species, with the help from an expert answering actively selected questions pertaining to visual attributes of the bird. Similarly, Branson et al. (2011) focus on interactive labeling, where users can adjust incorrect labels (e.g., the expert can drag misplaced parts to correct locations). In these works, they consider posing multiple queries on part attributes for each test image, and allow symmetric updates for both positive and negative labels. In contrast, we focus on a different problem setting: active detection of multiple object instances (with asymmetric updates upon different labels), where user only provides a single  X  X es X  or  X  X o X  feedback on each proposed candidate. Motivating Example: Hough-transform based method Hough-transform based detection algorithms work by transforming the input image into a new representation in a domain called the Hough space (Hough, 1959; Ballard, 1981). Each point in the Hough space corresponds to a hy-pothesis of existence of an object instance with some par-ticular configuration. The Hough image is built by aggre-gating the contributions of the individual voting elements, taken from the image or some appropriate sets of features of it. The detections will then be identified as peaks in the Hough image, with the height of the peak as an indicator of the confidence in the detection. As an example, to de-tect lines in an image, one can search through the peaks in the 2-d Hough space (with each axis corresponding to one parameter of the line function), and find a subset of line parameters that have the highest accumulated votes. Simi-larly, to detect natural objects, one needs to create individ-ual voting elements that vote for a certain configuration of the whole object. See Fig. 1(b) for an illustration. More generally: Votes and Hypotheses Suppose we are given a finite set H of hypotheses h 1 ,...,h n , where each hypothesis h i  X  H represents a possible configuration of the target object at location x i . We use Y 1 ,...,Y n  X  O = { +1 ,  X  1 } to denote the (initially unknown) labels of the hypotheses, such that Y i = +1 if hypothesis h i is true (i.e., there exists an object at x i ), and Y i =  X  1 otherwise. We use Y H = { Y 1 ,...,Y n } to refer to the collection of all variables. Whenever a hypothesis h i is selected, the corre-sponding variable Y i is revealed as y i . Similarly, if we se-lect a set of hypotheses A , the corresponding observations are represented as y A  X  2 H X O .
 We further assume a finite set of evidence V . Each item v  X  V corresponds to a voting element that can cast votes for a set of hypotheses. A base object detector proposes a voting scheme that connects the hypotheses set H and the evidence set V . The interaction between hypotheses and voting elements can be formally represented as a bipartite graph G ( V , H , E ) ; each edge ( v,h )  X  E is assigned with a score (e.g., confidence, probability estimation given by the base object detector) with which v votes for hypothesis h . We will give concrete examples in Section 5.
 Active Detection as a Sequential Decision Problem We consider a sequential strategy, where the detector proposes a hypothesis h i  X  H , and receives a label y i from the ex-pert. Whenever a label is revealed, we update the under-lying bipartite graph, which represents the current state of the base detector. In particular, we perform the updates by only reducing the weights associated with the voting ele-ments (i.e., covering the edges in G ), as observations will keep explaining the votes proposed by the base detector. Our goal, therefore, is to propose a strategy that can cover the entire set of edges as soon as possible. We begin with the case where the votes generated by the base detector only have binary values, and then generalize to the setting with real-valued votes. In Section 4.3, we provide an efficient greedy solution to the active detection problem, and present our main results. 4.1. Binary Votes Setting We first study a simple case, where the voting elements can only cast binary votes (i.e., 0/1) for the presence of an object with configuration/location x encoded by some hypotheses h  X  X  .
 Suppose the active learner proposes a hypothetical detec-tion h + , and receives a positive label from an external ex-pert. Since a voting element has equal confidence for all its supporting hypotheses, the true hypothesis then fully ex-plains the voting elements v  X  X  that voted for h + , thereby  X  X overing X  all votes associated with those voting elements. We refer to the amount of edges covered by selecting h + with positive feedback as the positive coverage of h + . The perhaps more interesting case is when the active detec-tor makes a false prediction. Let the negative coverage be the reduction of edge weights in G incurred by a false detec-tion h  X   X  X  . The construction of negative coverage is akin to that of positive coverage, but with one substantial differ-ence: while in the positive case we cover the edges which are neighbors of the edges that directly vote for h + (i.e., stemming from the same voting elements), in the negative case we will reduce the weight of all edges that are similar to the ones pointing to the false hypothesis h  X  . Concretely, we assume that the votes generated by the base detector are associated with some features, and thus can be clustered ac-cordingly. The clustering associated with the base detector is denoted by means of a function c : V X H X  Z + , which maps an edge ( v,h )  X  E to its cluster index. A false de-tection thereby  X  X xplains away X  (covers) similar votes that share the same clusters with the potentially false vote(s). See Fig. 2 for an illustration.
 Formally, the fraction of an edge ( v,h )  X  X  covered due to negative observations, could be modeled as a monotone in-creasing function g : E  X  2 H X O  X  [0 , 1] . In particular, we express the coverage as a function q of how frequent sim-ilar edges have been observed to vote for false hypotheses: g ( v,h, y A ) = q ( n neg ( v,h, y A )) , where n neg ( v,h, y of false hypotheses that are being voted for by any edge in the same cluster as ( v,h ) . In general, we want such a function to be concave within range [0,1], i.e., the edge should be largely covered even when n neg is small, and reach full coverage when n neg approaches infinity. An extreme choice would be q ( n ) = min( n, 1) : the edge is fully covered as soon as it is in the same cluster of a vote for a negative hypothesis. A less aggressive choice of the concave function, which we adopt in our experiments, is: The negative discount factor  X  controls the speed with which the weights will be discounted. If  X  = 0 , all the edges in the cluster c will be fully discounted once one of them votes for a negative hypothesis; if  X  = 1 , the edges will never be discounted.
 Now we are ready to construct the coverage function f (1) 2
H X O  X  R  X  0 for any edge ( v,h )  X  X  , in the binary votes setting. Given a set of hypotheses A X  X  , and correspond-ing observations y A  X  H  X  O , the amount by which a given edge ( v,h ) is covered is defined as f 4.2. The General Case with Real-valued Votes The previous approach is limited in that it only allows us to describe the support given by a voting element to a hypoth-esis as a binary relation. In practical settings, we would like to take the strength of confidence into account, i.e., each edge ( v,h ) is associated with a weight w vh  X  R  X  0 For this more general scenario, we need to redefine  X  X over-age X , by allowing edges to be partially covered. Following the previous example, when an edge ( v,h ) is covered due to positive observation, it will also cover its neighbors in a magnitude that is at most its weight w vh . Since we do not allow negative weights, if a neighbor edge ( v,h 0 ) has a weight w vh 0 &lt; w vh , then it is fully covered. Thus, an edge ( v,h ) covers another edge ( v,h 0 ) in a magnitude given by Taking negative coverage into account, the coverage func-tion for an edge is defined as: f v,h ( y A ) = g ( v,h, y A )  X  w vh + min n max We can interpret the first term on the RHS as the fraction of weight covered due to negative observations, and the second therm as the fraction of remaining weight (i.e., af-ter negative discount) covered due to positive observations. Note that w vh 0 does not have a discount factor, since we know that the edge ( v,h 0 ) represents the vote for a positive hypothesis, and thus it should be fully covered.
 Connection with the binary votes setting. We can see that the coverage function with binary votes (Eq. 4.2) is a special case of the general coverage function (Eq. 4.3), when all non-zero weights are set to 1: Assume the edge ( v,h ) exists, i.e., w vh = 1 . If the maximum among the weights w vh 0 of the first term is 0, then the first term van-ishes and we are left with g ( v,h, y A ) . Note that all the w vh 0 being 0 is equivalent to the second case of Equa-tion 4.2. The only alternative is if max ( h 0 , +1)  X  y 1 . Since 1  X  g  X  1 , we have f v,h ( y A ) = (1  X  g ) + g = 1 . The objective function. Finally, we can define the ob-jective function F : 2 H X O  X  R  X  0 for the active detec-tion problem, by summing up weights covered from all the edges in E : The goal of active detection, therefore, is to adaptively se-lect a minimum subset of hypotheses, such that the edges in the underlying bipartite graph can be fully covered. 4.3. Active Detection: A Greedy Solution In this section, we show that the active detection problem defined in the previous section is an adaptive submodular optimization problem, and thus can be efficiently solved using a greedy algorithm. First, we show that the objective function (Eq. 4.4) satisfies submodularity: Lemma 1. F is monotone submodular.
 Formally, a function f : 2 H X O  X  R  X  0 is submodular, if for all ( h,y h )  X  H  X O and y A  X  y B  X  H  X O , it holds that f ( { ( h,y h ) } X  y A )  X  f ( y A )  X  f ( { ( h,y y )  X  f ( y B ) . In other words, adding a label helps more if we have observed few labels so far. The key idea of the proof is that we can decompose a voting element into many voting elements, each casts equal votes to its favorable hy-potheses. Then we just need to prove F in the new evidence space to be submodular, which is straightforward. We defer the proof details to the supplementary material.
 In active detection, since we have no access to the label of a hypothesis in advance, we are not able to select hypothesis-label pairs for each iteration. Instead, we consider the conditional expected marginal gain of a hypothesis h (considering any possible label):  X 
F ( h | y A ) = E y H [ F ( y A  X  X  ( h,y h ) } )  X  F ( y A Function F together with prior distribution P ( Y H ) is called adaptive submodular (Golovin &amp; Krause, 2011), if, whenever y A  X  y B  X  H X O , and P ( Y H ) &gt; 0 , we have  X  F ( h | y A ) &gt;  X  F ( h | y B ) . Adaptive submodularity Algorithm 1 The active detection algorithm
Input: Bipartite graph G ( V , H , E ) , prior P ( Y H ) , dis-count factor  X  , # of detections N Output: Detections (with associated labels) y A
A X  X  X  , y A  X  X  X  for i = 1 to N do end for characterizes a natural diminishing returns property: the gain of a new item, in expectation over its unknown label, can never increase as we gather more information.
 Lemma 2. F is adaptive submodular w.r.t. P ( Y 1 ,...,Y n as long as Y 1 ,...,Y n are independent.
 Proof. With a factorial distribution over the outcomes, the adaptive submodularity of F follows immediately from Lm. 1 and Thm. 6.1 of Golovin &amp; Krause (2011). With the objective function defined in Section 4.2, we can associate the following greedy algorithm: It starts with the empty set, and at each iteration adds to the current set A the hypothesis h which maximizes the marginal improvement (Eq. 4.5). Once the label of h is observed, we update the bipartite graph G with the remaining edges that have not yet been explained by the current observations y A . Al-gorithm 1 provides the details of the greedy algorithm. A major benefit of adaptive submodularity is that we can use a technique called lazy evaluations to dramatically speed up the selection process (Golovin &amp; Krause, 2011). A further benefit is the following performance guarantee, which we obtain following the analysis in Golovin &amp; Krause (2011). Corollary 3. Suppose F : 2 H X O  X  R  X  0 is defined as Equation 4.4. Fix any value Q &gt; 0 and  X  &gt; 0 , and let OPT wc be worst-case cost of an optimal policy that achieves a maximum coverage value of Q for any realiza-tion of the variables Y H . Let C greedy be the cost of Al-gorithm 1 using a factorial prior on variables Y 1 ,...,Y until it achieves expected value Q  X   X  . Then, Moreover, it holds that under the algorithm X  X  prior: P ( f ( y A )  X  Q )  X  1  X   X  .
 Note that the above result provides guarantees even for worst-case realization of Y H (i.e., without assumptions on P ( Y H ) ), as long as our algorithm uses any factorial prior. Further note that if we choose, in the extreme case,  X  = min Y H P ( Y H ) , we actually guarantee that the algo-rithm achieves full coverage ( f ( y A )  X  Q ) for all realiza-tions of Y H . If we do not have a strong prior, we can obtain the strongest guarantees if we choose a distribution  X  X s uni-form as possible X  (i.e., maximizes min Y H P ( Y H ) ), while still guaranteeing adaptive submodularity. In this section, we empirically evaluate our active detec-tion approach on three (substantially different) data sets: an orangutan nest detection task for biodiversity monitoring, a pedestrian tracking task in a video sequence, and a standard object detection task for the PASCAL VOC Challenge. For each data set we employ different base detector that is most tailored for the task. Our emphasis is on comparing the active detection algorithm with classical passive detection algorithms (and active detection baseline, if applicable), as well as empirically quantifying the improvement by the ac-tive detection framework over the base detectors.
 Orangutan Nest Detection on UAV-recorded Forest Im-ages The first application is an interactive orangutan nests detection system for biodiversity monitoring. To es-timate the distribution of critically endangered Sumatran orangutans ( Pongo abelii ), ecologists deploy conservation drones above orangutan habitat in surveyed areas, so that they can obtain timely and high-quality photographs of orangutan nests high in the tree canopies (Koh &amp; Wich, 2012). Our test set contains 37 full-resolution ( 4000  X  3000 pixels) images from two separate drone missions launched in September 2012, in Sumatra, Indonesia. Each of the tar-get images contains at least one orangutan nest, and there are a total number of 45 nests in the data set, with a mini-mum size of 19  X  19 pixels. Selected examples of the nest and non-nest image patches are shown in Fig. 3.
 As we can see from the examples, the positive class has high intra-class variation. For efficiency considerations, we reduce the resolution of the original images by half. We then extract all 45 examples of orangutan nests of size 9  X  9 pixels, as well as 148 background image patches, as the labeled set. Each training example is represented as a 9-d vector which consists of statistics (mean, maximum and minimum) of three color channels in a patch. Based on these features, we train a linear discriminant classifier (LDA) in order to classify orangutan nests vs. background. The base detector we employ is a sliding-window based system. As we do not have sufficient (positive) training data, we use all the labeled images other than those in the current test image as training set. At runtime, each image patch located by the current sliding window (of size 9  X  9 ) is evaluated with a pre-trained classifier, and used as a voting element that casts equal votes to its surrounding area (i.e., 9  X  9 pixels). The confidence of votes from theses voting windows are determined by their distances to the classi-fier X  X  decision boundary; positive windows that are further away from the decision boundary have higher confidence when voting for a nest hypothesis.
 To cluster similar voting elements, we apply k -means algo-rithm on the set of voting windows. Moreover, as negative detections often occur adjacently (e.g., branches are usually connected), we also use a local clustering algorithm (i.e., segmenting nearby regions), to avoid overwhelming false detections. The precision-recall curve for active detection is demonstrated by the red line in Fig. 4(a).
 Our first baseline is the  X  X assive X  version of Alg. 1, where the algorithm assumes all detections to be  X  X rue X , and thus only performs positive updates. The only difference be-tween Alg. 1 and the passive baseline is that for active detection, we actively update the order of the sequence, while for the passive baseline we do not (note that the pas-sive approach also needs expert to verify the detections, only that it happens after all detections are made). We can see from Fig. 4(a) that, at 80% recall, active detec-tion (  X  = 0 . 5 ) obtains almost twice the precision (0.27 vs. 0.15) as the passive approach. As another baseline, we compare with an active learning heuristic, where the base classifier is retrained after each query. More specifi-cally, at each iteration, the baseline active detector gener-ates a response image by applying the new classifier, and removes the surrounding areas of previous candidates by non-maximal suppression. The next candidate is then lo-cated through mode-seeking. As shown in Fig. 4(a), al-though the active baseline (blue curve) comes with no guar-antees, it still outperforms the passive approach due to extra feedbacks, but generally performs worse than Alg. 1. Pedestrian Detection on TUD-crossing Image Sequence Hough-based approaches offer seamless integration with the active detection framework. To demonstrate how user supervision can help such systems, we apply Alg. 1 to the TUD-crossing sequence, based on the Hough Forest detec-tor proposed in Gall &amp; Lempitsky (2009). We use a dis-count factor  X  = 0 . 01 to penalize votes that are  X  X imilar X  with any of the incorrect votes. Here votes are considered  X  X imilar X  if they are (1) from similar image patches (i.e., sharing the same leaf in Hough forest), and (2) pointing to locations that have the same offset to the voting elements. We also use  X  X ocal clusters X  to update the bipartite graph when observing a false hypothesis, similar as the case for nest detection: edges that share the same voting element are considered within the same local cluster, and thus will be discounted if any of them points to a false hypothesis. Since the background clutter does not change much across frames, for active detection we choose to share the cluster updates through the entire video sequence, rather than dis-card the information acquired from user feedback and start from scratch (i.e., reset the negative count for each clus-ter) for each new frame. As baseline, we compare active detection with the state-of-the-art passive detection results on this data set, which is given by Barinova et al. (2012). We find that training a Hough forest detector is very expen-sive (e.g., it takes &gt; 1 hour to train a forest with 15 trees), making it highly inefficient to frequently retrain the model. Therefore, we skip the active baseline for this task. For evaluation of both algorithms, we apply the Hungarian algorithm (Kuhn, 1955) to match the set of detections with the ground truth annotations, based on the Jaccard simi-larity (  X  40% are considered as false detections) between bounding boxes 1 . We test the candidate algorithms on 41 frames of the TUD-crossing sequence (by sampling every 5th frame of the full video sequence) in the single scale sce-nario, and show the results in Fig. 4(b). The curves are gen-erated by varying the stopping threshold on the marginal gain of new hypotheses. We limited the maximum number of detections to be 10 for both systems (given there are at most 8 objects per frame) in order to have a fair compari-son. As can be seen, with user supervision, our framework considerably outperforms the baseline detection algorithm. Object detection on PASCAL VOC Data Set The third data set differs from the previous two in the sense that it contains object classes that exhibit much richer structural features (e.g., the  X  X erson X  class includes examples of a high variability of poses and shapes). The state-of-the-art results for this dataset are obtained by the sliding-window based, multi-scale, deformable parts model (MDPM) of Felzenszwalb et al. (2010). To convey the idea that our framework can incorporate different base detectors, we build our bipartite graph upon an earlier release ( voc-release3 ) of their system, as it already incorporates most of the important innovations of the MDPM, without extra ex-pensive components (e.g., grammar models as in Girshick et al. (2011)) that are designed specifically for certain tasks. In MDPM, each category is modeled by a  X  X oot X  filter that describes the shape of the object, and a fixed number of part filters that describe important sub-areas of the object at a higher resolution. For multi-scale detection, we keep a feature pyramid that consists image cells (of size 8  X  8 , rep-resented by a 31-d HOG descriptor (Dalal &amp; Triggs, 2005)) from a pile of rescaled versions of the image. A hypothesis z is then characterized by a triplet ( x,y,s ) corresponding to the location and scale of an object, and is scored jointly by both root filter and associated parts filters.
 To build a bipartite graph, we assume that voting elements correspond to image patches (i.e., cells in the feature pyra-mid), and will cast equal votes for a hypothesis h given that they are inside its associated window. The total sum of votes h receives from the voting cells amount to the score given by the underlying MDPM. To handle the de-formable parts, we further assume two types of hypothe-ses:  X  X oot hypotheses X  that represent the existence of an object, and  X  X art hypotheses X  as intermediate nodes in the bipartite graph, that can be voted by (part) cells. Each hy-pothesis node in the bipartite graph will eventually receive (direct) votes from the root cells, as well as (indirect) votes from the part cells, that are weighted by the deformation coefficient (Felzenszwalb et al., 2010) of the part window. Edge similarity is measured based on two sets of features: the filter type of the window associated with h , and the HOG descriptor of the voting cell v . To construct clusters, we first group the windows by filter type, and then employ a hierarchical clustering method to retrieve similar edges (i.e., small cosine distance between HOG descriptors). Fig. 4(c) shows our results on the Person category of the VOC2008 data set (4133 test images). Each detector makes 16 detections per image. Unlike the nest detection task, re-training a deformable parts model after each detection is a prohibitive task (it would have taken weeks to retrain  X  66K MDPMs). Without a better choice for active baselines, we show how human feedbacks can be used to improve the base detector. The red curve shows the performance of our active detector (AUC 0.566), which only uses root fil-ters, yet it already outperforms the baseline system (Felzen-szwalb et al. (2010), AUC 0.516) that utilizes both root and parts filters. Note that in principle we can incorporate feedback of part filters as well. We also find that the pas-sive approach under our framework (i.e.,  X  X ctive detection X  assuming all detections are true) also considerably out-performs the baseline (AUC 0.544). One possible reason is that, when identifying multiple objects, our framework does not suffer from problems caused by the non-maximum suppression approach, and thus has better recall. In this paper, we propose an active detection framework that enables turning existing base detectors into automatic systems for intelligently interacting with users. Our ap-proach reduces active object detection to a sequential edge covering optimization problem. We show that the objective function satisfies adaptive submodularity, allowing us to use efficient greedy algorithms, with strong theoretical per-formance guarantees. We demonstrate the effectiveness of the active detection algorithm on three different real-world object detection tasks, and show that active detection not only works for various base detectors, but also provides substantial advantages over its passive counterpart. Acknowledgments. This research was supported in part by Abramson, Y. and Freund, Y. Active learning for visual object recognition. Technical report, UCSD, 2004.
 Ballard, D.H. Generalizing the hough transform to detect arbitrary shapes. Pattern recognition , 1981.
 Barinova, O., Lempitsky, V., and Kholi, P. On detection of multiple object instances using hough transforms. PAMI , 2012.
 Bietti, A. Active learning for object detection on satellite images. Technical report, Caltech, 2012.
 Branson, S., Wah, C., Schroff, F., Babenko, B., Welinder,
P., Perona, P., and Belongie, S. Visual recognition with humans in the loop. In ECCV , pp. 438 X 451, 2010.
 Branson, S., Perona, P., and Belongie, S. Strong supervi-sion from weak annotation: Interactive training of de-formable part models. In ICCV , pp. 1832 X 1839, 2011. Dalal, N. and Triggs, B. Histograms of oriented gradients for human detection. In CVPR , 2005.
 Felzenszwalb, P.F., Girshick, R.B., McAllester, D., and Ra-manan, D. Object detection with discriminatively trained part-based models. PAMI , 2010.
 Gall, J. and Lempitsky, V. S. Class-specific hough forests for object detection. In CVPR , 2009.
 Girshick, R., Felzenszwalb, P., and McAllester, D. Object detection with grammar models. IEEE TPAMI , 2011.
 Golovin, D. and Krause, A. Adaptive submodularity: The-ory and applications in active learning and stochastic op-timization. JAIR , 2011.
 Hough, P.V.C. Machine Analysis of Bubble Chamber Pic-tures. In International Conference on High Energy Ac-celerators and Instrumentation , 1959.
 Joshi, A.J., Porikli, F., and Papanikolopoulos, N.P. Scal-able active learning for multiclass image classification. PAMI , 2012.
 Kapoor, A., Grauman, K., Urtasun, R., and Darrell, T. Ac-tive learning with gaussian processes for object catego-rization. In ICCV , 2007.
 Koh, L.P. and Wich, S.A. Dawn of drone ecology: low-cost autonomous aerial vehicles for conservation. Trop Conserv Sci , 2012.
 Kovashka, A., Vijayanarasimhan, S., and Grauman, K.
Actively selecting annotations among objects and at-tributes. ICCV , 0:1403 X 1410, 2011.
 Kuhn, Harold W. The hungarian method for the assignment problem. Naval Research Logistics Quarterly , 2:83 X 97, 1955.
 Luo, T., Kramer, K., Goldgof, D.B., Hall, L.O., Samson,
S., Remsen, A., and Hopkins, T. Active learning to rec-ognize multiple types of plankton. In ICPR , 2004. Nemhauser, G.L., Wolsey, L.A., and Fisher, M.L. An anal-ysis of approximations for maximizing submodular set functions X  X . Mathematical Programming , 1978.
 Parkash, A. and Parikh, D. Attributes for classifier feed-back. In ECCV , pp. 354 X 368, 2012.
 Shrivastava, A., Singh, S., and Gupta, A. Constrained semi-supervised learning using attributes and comparative at-tributes. In ECCV , pp. 369 X 383, 2012.
 Tong, S. and Koller, D. Support vector machine active learning with applications to text classification. JMLR , 2002.
 Vijayanarasimhan, S. and Grauman, K. Multi-level active prediction of useful image annotations for recognition. In NIPS , pp. 1705 X 1712, 2008.
 Vijayanarasimhan, S. and Grauman, K. Large-scale live active learning: Training object detectors with crawled data and crowds. In CVPR , 2011.
 Vijayanarasimhan, S., Jain, P., and Grauman, K. Far-sighted active learning on a budget for image and video recognition. In CVPR , pp. 3035 X 3042, 2010.
 Wah, C., Branson, S., Perona, P., and Belongie, S. Mul-ticlass recognition and part localization with humans in
