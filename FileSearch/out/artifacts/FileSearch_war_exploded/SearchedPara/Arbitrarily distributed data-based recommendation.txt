 1. Introduction Recommender systems have recently become so essential and versatile component of e-business applications [1] . and a target item (denoted as q ), they provide a prediction to a for q (denoted as p speaking, CF process consists of the following three main steps [3] :
With millions of customers and products, a typical web-based recommender system running conventional memory-based off-line computations (model construction) and online computations (prediction estimation).
Truthful and trustworthy recommendations cannot be estimated from insufficient data. Similarities between entities computed from inadequate data might not be accurate or dependable. Similarly, neighborhoods formed on such similarities to own enough data for better referrals. In CF applications, since the size of item space is very large, user sparse. Furthermore, newly established vendors might suffer from inadequate data. This phenomenon causes sparsity and improve sparsity, coverage, and accuracy.
 Data collected for CF purposes can be arbitrarily distributed between two e-commerce companies, even competing ones. preserving scheme to estimate item-based predictions on arbitrarily distributed data (ADD) between two vendors while confidentiality.
 data owners might decide to work in partnership. Through collaboration, data owners are able to offer services based on more data and they can offer additional services in various data mining applications [7] . Additionally, companies, holding insufficient data for some data mining tasks, can provide services responding more accurately and dependably important to provide them some measures for preserving their secrecy so that they can decide to work in pairs [8] .The studies technically show that the parties can realize many knowledge discovery tasks in partnership through their data [ 9  X  11 ]. Vendors do not share secret data with each other, because they do not want to give up competitive knowledge advantages or violate anti-trust law.
 and discuss our empirical outcomes. Finally, we conclude the study and give future directions in Section 8 . 2. Background explain the problem that we look for solutions. 2.1. Item-based collaborative fi ltering algorithm found that the adjusted cosine similarity, given in Eq. (1) , performs the best: in which sim i,j is the similarity weight between items i and j , U is the set of users, R for similar items, as follows: in which a j represents a rating of a for item j . 2.2. Arbitrarily distributed data (ADD)
Data collected for CF purposes might be horizontally or vertically distributed between two different companies [9] .In horizontal or vertical cases [9] .
 each party are distinct sets. 2.3. Privacy de fi nition and constraints value allows parties inferring information, which conflicts the main privacy constraint. scheme should not allow any of the cooperating parties behave against the main and the auxiliary privacy constraints. 2.4. Problem de fi nition should provide equilibrium among them. 3. Related work the discovered association rules mined and propose solutions for reliable representations for association rules. achieve both security and completeness with good efficiency.
 models (HMMs) between two parties while preserving model owners' confidentiality. association rules over HDD.

Jagannathan and Wright [9] introduce the concept of so called arbitrarily distributed data (ADD). The authors present a a privacy-preserving BIRCH algorithm based on ADD. They also introduce secure protocols for distance metrics and give a procedure for using these metrics in securely computing clusters over ADD. Han and Ng [29] propose a privacy-preserving
SVM classifier scheme working on ADD. Their accuracy results are comparable to that of ordinary SVM classifier based on distance-based outlier detection protocol over ADD ensuring about information leakage. as a specific combination of HPD and VPD configurations.
 generation algorithm, we utilize the item-based algorithm enabling pre-computing of item all related works we presented about CF over split data, our data partitioning model is novel. 4. Providing private predictions on distributed data data masking processes, two parties collaborate securely to estimate final prediction value p pre-constructed models in online phase.
 The user  X  item matrix D might be arbitrarily distributed between A and B , as shown in Fig. 1 , where D by Sarwar et al. [4] . Given two items, i and j , the similarity ( w where i  X  denotes the dot-product of the two vectors; and i  X  use z -scores rather than ratings, as follows: where remember that p aq is the prediction for an active user a on a target item q , v standard deviation of a 's ratings, J is the set of q 's neighbors, w z-score of a 's rating on item j . Given a 's rating on item j ( v from a .
 computations in such a way so that they do not reveal their data to each other.
 direction, we implicitly assume that  X  disclosing user and/or item IDs is not a privacy violation. 4.1. Off-line phase In order to protect their data, the parties first mask their private data sets, namely D based on perturbed data. The parties can disguise their data, as follows: iii. Next, each party j uniformly randomly selects  X  j percent of their empty cells. iv. A and B finally fill such cells with fake ratings ( v
There are various factors that might help the parties determine distribution, number of commonly filled cells by both vendors increases with increasing fake ratings affects the originality of the true data. Besides the value of follows: iii. Personalized ratings: Use the most probable values estimated from available data using a prediction algorithm as v be estimated without violating data owners' privacy based on filled databases, as follows: 4.1.1. Private Mean Estimation Protocol
Given x u ratings provided by a user u , their arithmetic average v be written, as follows: where x u shows the number of ratings including the fake ones for user u , and x including the fake ones held by A and B , respectively. The parties can estimate v the masked databases in a distributive manner, as follows: i. A and B compute partial sum and count values based on their masked databases for all users. iii. Next, A and B estimate user mean ratings for even and odd indexed users, respectively.
Although it is not easy to perform computations in a distributive manner without sharing any information, the parties sum of the ratings and the rated items for such users during this protocol. 4.1.2. Private Vector Length Estimation Protocol is an example of distributive measure like mean, it can be estimated in a distributive manner, as follows: in which x u is the set of users who provide ratings including the fake ones for item j , similarly, x lengths for all items, j =1, 2, ... , m , based on masked databases in a distributive manner, as follows: iii. Next, A and B estimate vector lengths for even and odd indexed users, respectively. 4.1.3. Private Adjusted Cosine Estimation Protocol (PACEP) explained previously. Then, Eq. (3) can be written, as follows: which is basically a scalar dot-product between two vectors including normalized ratings and v arbitrarily distributed, X  X  i  X  follows: X explain how the parties can estimate X A  X  Y B in a private manner:  X  B divides Y B into f random vectors, where Y B =  X  i =1 f  X 
B encrypts each value in each random vector with KB using a homomorphic encryption scheme, where KB is B 's public key.  X 
B then sends encrypted values to A .  X 
A similarly divides X A into g random vectors, where X A =  X  operation to be conducted based on the encrypted data without decrypting them. We employ an efficient homomorphic encryption scheme proposed by Paillier [38] .  X   X 
A then permutes all encrypted values using a permutation function f  X 
B decrypts them and adds them up.  X 
In order to estimate X B  X  Y A , they follow the same steps by switching the roles.  X  weights are kept by A ; and for the others, they are kept by B . 4.1.4. Model construction neighbors of each item. For each item, they can select those items satisfying a pre-determined threshold ( et al. [4] perform some experimentation to determine the optimum values of some parameters including the neighborhood those items, for which they have the similarity weights, satisfying the are held by B . 4.2. Online phase: recommendation estimation in a distributive manner using Eq. (4) , as follows: company. The parties then follow the following steps:  X 
A finds v a and  X  a values; and computes z aj values.  X  available data off-line. A follows the similar steps as done while masking D  X 
A then removes those items' z-scores from a 's vector, which are q 's neighbors and held by itself.  X  together with the query.  X  B divides w qj values into random pieces w qjB ; computes E encryption property, where homomorphic encryption allows multiplication operation to be conducted on an encrypted value and a plain value without decrypting the encrypted value.  X 
B then permutes them using a permutation function f B ; and sends them A together with  X  A decrypts them and finds  X  j  X  J
In the following, we analyze our proposed scheme in terms of performance, privacy, and accuracy. 5. Performance analysis additional online costs and then explain off-line costs.

To evaluate computational complexity of CF schemes, online phase is much more vital than off-line phase because the encryption, computation costs increase. Suppose that A is the chief company. It performs m number of z-scores sent to B . It also performs m aB w ajB homomorphic encryption, the number of exponentiations conducted by B increases by w producing a single prediction. Without privacy concerns and communication overheads, item-based scheme on distributed dominant supplementary costs are due to homomorphic encryption and decryption. If we assume that there are 20 commonly weight is divided into five random pieces, on average, there are 20/2 encryptions and 5 X 10=50 decryptions. We used the benchmarks given above and determined that an encryption and decryption take 80 ms. Thus, due to cryptographic computing machines because note that we use a computer, which is Intel Core2Duo, 2.4 GHz with 4 GB RAM. Similarly, with also utilize parallel computation techniques to improve online time.
 communications is two only. In our scheme, number of communications and amount of data to be transferred between a and the chief company do not increase due to privacy measures. However, in our scheme, the chief company must communicate query to the collaborating company, while it receives some encrypted values. Thus, since they perform two additional communications, online number of communications increases by two times. Without privacy concerns, when two parties want amount of data to be transferred is about (6 X  m a +10) bytes. In our scheme, the chief party fills m company is about ( m a + m f )/2 X 16+( m a + m f )/2 X 2+2=9 X ( m values because remember that B divides similarity weights into w (6 X  m a +10) bytes to (9 X ( m a + m f )+16 X  w ajB +18) bytes.
Storage costs should also be analyzed. Storage overheads due to our privacy-preserving scheme are, as follows: Besides original user  X  item matrices, the parties need to keep filled and normalized user privacy-preserving measures, like computation and communication overheads, extra storage costs are also expected. parties offer CF services to their customers using the existing model while updating in process. 6. Privacy analysis the correct  X  j is 1/  X  j ; and the probability of guessing the correct out the number of truly rated items ( m r ) from received count values, as follows: m for each user is 1 out of C m m ities. Also note that C X Y  X  C X X  X  Y  X  X 1 = 100  X  j X ! through homomorphic encryption, permutation, and random division at the same time. Paillier [38] shows that homomorphic their order is 1 out of h !, where value of h depends on f , g , a can be inferred.
 method allows data owners provide recommendations while preserving their privacy during both off-line online phases. 7. Coverage and accuracy analysis: experiments on accuracy, we performed several experiments using real data sets. construction (training), while the remaining votes were used for testing.

We utilize two well-known accuracy metrics: mean absolute error (MAE) and normalized mean absolute error (NMAE). MAE can be formulized, as follows: where t is the number of ratings in the test set, and r i respectively. NMAE can be obtained by normalizing the MAE, as follows: how collaboration affects coverage, we utilized the following metric, where r res and r test stand for the number of predictions returned and the number of test ratings.
In order to demonstrate whether the improvements are statistically significant or they occurred by chance, we applied that the improvements are statistically significant and they did not happen by chance. 7.1. Effects of supplementary ratings
Due to the nature of data partitioning and our proposed privacy-preserving scheme, some cells in user have rating sets R A and R B , respectively, having values for disjoint cells. Let each rating set R of  X  , where j is A or B . Thus, the size of each rating set is R rating sets F A and F B , respectively. We can estimate the number of fake ratings for each party j , as follows, where the range (0,  X  j ): where  X  (  X  j ) represents the expected value of  X  j , which equals the probability of being filled twice or being already filled cell ( P the probability of having cells with double ratings ( P o ly to represent users' true preferences.

Fig. 3 . As seen from Fig. 3 , P o values increase with increasing cells with any ratings have double votes.

We also conducted trials to demonstrate how amount of such cells affect accuracy without privacy concerns. We used both user, item, or overall mean votes, user distribution, and personalized ratings estimated from available data. We set Votes). We then computed recommendations on integrated data, where some cells might have double ratings (Double Votes). We demonstrated the MAEs for both data sets in Table 1 .
 We have two exceptions. When user or item mean votes are used as fake ratings, allowing double votes improves accuracy. follows: First, as seen from Fig. 3 , percentage of the overlapped ratings is about 14% when we set z-score normalization) smoothes the effects of different protocols used for data masking. 7.2. Accuracy and coverage improvements due to collaboration more likely to offer predictions for more items and provide high quality referrals. To verify how ADD-based CF improves preciseness and coverage, we performed experiments. We ran our trials 100 times in which we utilized uniformly randomly n values only for MLM in Table 3 .
 n and m values. We displayed coverage values as percent in Tables 2 and 3 .
 predictions but also query response rate.
 data, we conducted another set of experiments using MLP only, where we used entire data set. We defined X data held by the party j ; and 1-X j percent of the data held by the other party. We varied X accuracy changes with varying amount of unevenly partitioned data. Note that when X (bigger than 50), the outcomes become closer to the results on combined data because the results for X from collaboration when X j is smaller than 90 for small  X  7.3. Methods for determining fake ratings  X 
MLP and MLM, respectively. Since we proposed three major methods (non-personalized ratings, ratings distribution, and computing overall averages for both data sets, we displayed the MAE values in Table 4 .
Since the overall mean method is the only scheme, which provides enhanced outcomes for both data sets, we chose it to determine fake votes. 7.4. Level of perturbation
Number of unrated cells to be filled is determined according to determining fake votes. We used data sets with sizes 943 X 1682 and 1000 X 3591 for MLP and MLM, respectively. We ran data After calculating overall averages, we displayed the MAE values in Table 5 for both data sets.
As seen from Table 5 , accuracy slightly changes with varying better with increasing  X  values from 0 to 25, while it becomes worse for larger
For MLM, we have similar findings. Filling some of the unrated cells enhances accuracy. With increasing 100, accuracy slightly becomes worse. However, compared to the base result, the quality of the recommendations enhances faintly. Number of filled cells also affects overall performance because amount of data involved in the recommendation generation processes increases. Thus, we selected 12.5 as the optimum value of to mask the train data. Since we obtained the similar outcomes, we did not show them. According to our experiments, overall averages of the MAEs and displayed them for both data sets in Table 6 .

As seen from Table 6 , the quality of the referrals becomes worse with increasing with increasing  X  values. For MLP, accuracy losses due to inserted fake ratings are about less than 1% when
Since the best outcomes are obtained when  X  is 3.125, we selected it as the optimum value of data sets. 7.5. Overall performance both data sets, respectively.
 goals, privacy-preserving measures might make accuracy worse. However, such losses should be small enough so that the results for MLM when n is larger than 250. It means that the improvements due to cooperation overweigh the downfalls on changing n values, enhancements with varying m values are more notable. For MLM, amount of improvements decreases with improvements using the t -tests. Each of the improvements in Table 7 satisfies the t -test for are 20.84 and 16.39 for MLP and MLM, respectively, where n is 500. Hence, our scheme significantly ensures the accuracy and for MLM with m being 1600, respectively.

In order to show how overall performance changes for larger values of and m values only using both data sets. We followed the same methodology and set worse when n is bigger than or equal to 500. Compared to the results for smaller users is usually very large in the data sets constructed for CF purposes, and utilizing larger damage quality of the data, data owners should select smaller in Section 6 .
 We finally compared our results with other prediction methods. For this purpose, we used NMAE measure. As seen from reduction methods. NMAE value achieved by that method is 0.1838. Bogdanova and Georgieva [5] utilize error-correcting dependencies for CF and improve CF's performance. Their approach's performance in terms of NMAE is 0.1776. Lemire and
Maclachlan propose a scheme based on average rating differential, which achieves the NMAE value of 0.1880. Compared to other approaches, our scheme provides promising and comparable results while preserving confidentiality. 8. Concluding remarks and future work
We proposed a privacy-preserving scheme to offer recommendations on ADD between two parties. Our method can be scheme can be used to provide accurate recommendations efficiently while preserving privacy. neural network learning, and decision tree tasks based on ADD have been proposed [ 9,11,28 association rule mining, and regression analysis on ADD while preserving confidentiality is still an open question. Acknowledgments This work was supported by grant 108E221 from TUBITAK.

References
