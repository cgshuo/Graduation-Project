 In the last decades, the use of IT systems for supporting business activities has notably increased, thus opening to the possibility of monitoring business processes and performing on top of them a number of useful analysis. This has brought to a large diffusion of tools that offer business analysts the possibility to observe the current process execution, identify deviations from the model, perform individual and aggregated analysis on current and past executions, thus supporting process model re-design and improvement.
 Unfortunately, a number of difficulties may arise when exploiting information system data for monitoring and analysis purposes. Among these, data may bring only partial information in terms of which process activities have been executed and what data or artefacts they produced, due to e.g., manual activities that are scarcely monitorable and hence not present in within the information system data ( non-observable activities ). led the latter problem. Only recently, the problem of dealing with incomplete information about process executions has been faced by few works [ 1 , 2 ]. How-ever, either the proposed approach relies on statistical models, as in [ 1 ]orit relies on a specific encoding of a particular business process language, with lim-ited expressiveness (e.g., it cannot deal with cycles), as in [ 2 ]. incomplete business process execution traces, proposing an approach that, lever-aging on the model, aims at recovering missing information about process exe-cutions using action languages. In order to address the problem we exploit the similarity between processes and automated planning [ 3 ], where activities in a process correspond to actions in planning. A (complete) process execution cor-responds to a sequence of activities which, starting from the initial condition, leads to the output condition satisfying the constraints imposed by the workflow. Analogously, a total plan is a sequence of actions which, starting from the initial state, leads to the specified goal.
 to construct a planning problem s.t. each solution corresponds to a complete process execution and vice versa. In this way, by analysing all the possible plans we can infer properties of the original workflow specification (e.g. the number of valid cases, unused branches, etc.), including all the possible completions of the trace. The advantage of using automated planning techniques is that we can exploit the underlying logic language to ensure that generated plans conform to the observed traces without resorting to an ad hoc algorithm for the specific completion problem. In the literature different languages have been proposed to represent planning problems and in our work we use the language on the Answer Set Programming engine DLV K (see [ 4 ]). This language, in the spirit of the well known C (see [ 5 ]), is expressive enough for our purposes and the integration within an ASP system enables a flexible and concise representation of the problem. On the other hand, the main ideas behind the encoding are general enough to be adapted to most of the expressive planning languages. they are composed of blocks, where every split has a corresponding join, matching its type, and of loops with a single entry and exit points [ 6 ]. This assumption rules out pathological patterns that are notoriously hard to characterise (e.g. involving nested OR joins); but they provide coverage for a wide range of interesting use cases [ 7 ]. We aim at understanding how to reconstruct information of incomplete process execution traces, given the knowledge about the process model (which we assume to be correct and complete). The input to our problem consists of: (i) an instance-independent component, the process model, which in this paper is described using the YAWL language 1 [ 6 ]; and (ii) an instance-specific component, that is, the input trace.
 Hereafter we assume familiarity with YAWL, a work-flow language inspired by Petri Nets, whose main con-structs are reported in Figure 1 .
 As a simple explanatory example of the problem we want to solve, consider the YAWL process in Figure 2 .
 The process takes inspiration from the procedure for the generation of the Italian fiscal code: the registration mod-ule is created ( CRM ), the personal details of the sub-ject are added ( AP D ) and, before assigning the fiscal code, either the passport/stay permit information ( APPD ) or the parents X  data (
AP ARD ) are added to the module. In the latter case, according to whether the child is foreigner ( f oreigner ) or not (! f oreigner ), either the nationality code or the birth APSS code ( AAC ) is added to the module. Once data have been added ( AP DC ), the fiscal code is generated ( GF C ) and checked ( fiscal code is correct ( FCOk ), administrative offices ( be notified (in parallel), otherwise (! FCOk ), the error reported ( fiscal code generation procedure iterated until successful. Specifically, for the user notification, according to whether the request is marked as a request for a child or not, either the parents ( NP ) or the requester ( the notification the request module is finally registered ( We assume that a run-time monitoring system is able to trace the execution of this process, by logging only the observable activities marked in Fig. 2 with a small gears icon and the data observed by the system. An example of such a logged information (partial trace) is reported in ( 1 ). It lists 4 executions of observable activities and the corresponding observed data (enclosed in curly brackets): trace, we would like to know whether it is possible (and how) to reconstruct the complete trace. For instance, by knowing the process control flow in Fig. 2 and the fact that RRM was executed, we can infer that the workflow has been exe-cuted from the start until RRM . Thus, taking into account the YAWL semantics, this means that: (i) all the sequential and  X  X arallel X  activities AP DC , GF C , CFC , N , NU , NUC and NA have been executed; and (ii) exactly one among the mutually exclusive activities (a) APPD and AP ARDC ,(b) AN C or AAC , and (c) NP or NR , have been executed. Moreover, by knowing from ( 1 ) that RE has been executed twice, it is possible to understand that the cycle has been iterated two times (and hence CFC have been executed three times). Similarly, by observing that has been executed, it is possible to understand that the execution also passed through AP ARDC and not through APPD . As a result a possible extension of the trace in ( 1 )is: as we cannot understand which of the alternatives among AN C NP or NR , have been executed. Data, both used for enriching the model and observed in the trace, provides a further source of useful knowledge which can help to discriminate about the missing activities. For example, by observing in the trace the value of the variable f oreigner just after the branching activity AP ARD , it is possible to understand that the branch executed by the considered execution trace is the one passing through AN C . Finally, it could happen that some further knowledge is available about data in a workflow, e.g., what are the activities in charge of manipulating those data. For instance, in this example, we could have further knowledge about the variable child : we could be aware that child is a field of the registration module that is only set by the activity AP ARD (to true )and APPD (to false ) 2 . This knowledge makes it possible to understand that the  X  child  X  branch, i.e., the branch passing through the parent notification ( NP ) should have been executed, thus reconstructing a complete trace, e.g., incomplete trace is relatively easy, this is not the case for real world examples. In the next sections we show how to encode general problems in order to be able to automatically reconstruct a partial trace (if the incomplete information of the partial trace is compliant) or alternatively, to assess the non-compliance of the incomplete information of the partial trace). The output that we expect is hence either (a) the notification that the partial trace is inconsistent with the process model, or (b) a set of traces that complete the input partial trace (partially or in full). IA (complete) process execution can be seen as a sequence of activities which, starting from the initial condition, leads to the output condition satisfying the constraints imposed by the workflow. Similarly, a total plan is a sequence of specified goal.
 By exploiting this similarity, given a workflow (that we assume to be correct and complete, as its actions) and an observed trace, we provide an algorithm to construct a planning problem such that each solution of the planning problem corresponds to a complete process execution and vice versa. In this way, we can (i) either assess the non-compliance of the incomplete information of the partial trace w.r.t. the workflow specification (if no compliant plan is found) or (ii) by analysing all the possible plans we can infer properties of the original workflow specification.
 Our encoding includes two stages: firstly the given workflow is encoded into an equivalent planning problem; then further constraints are added to the gen-erated problem to ensure that the only admissible plans are those conforming to the observed traces.
 The key of the bisimulation of the workflow processes using an action lan-guage lays in the fact that the semantics of YAWL is provided in terms of petri nets transition systems, where states are defined in terms of conditions connected to activities. Conditions may contain one or more tokens and the execution of activities causes transition between states by moving tokens from incoming to outgoing conditions according to their type (AND/OR/XOR join or split); e.g. in Figure 3a the execution of activity N , with an AND split, moves tokens from the input condition to both the output conditions. In a nutshell, the general idea of the bisimulation is to represent the position of tokens by means of states and execution of activities by (possibly non-deterministic) transitions between states (see Figure 3b ). accumulates in a single condition; therefore we do not need to keep track of the number of tokens in each condition but we just need to track the presence of a token by means of an appropriate mechanism (that of propositional fluents introduced below).
 action language, that is fluents and actions . The formers represent the state of the system which may change by means of actions. Causality statements describe the possible evolution of the states and preconditions associated to actions describe which action can be executed according to the present state. The conditions in the workflow are represented by means of fluents and appropriate causality statements describe the transition by  X  X imulating X  the semantics of activities. The possibility of representing partial knowledge and non-determinism in K , introduced in the next section, enables the precise modelling of complex workflow structures like OR-splits and loops.
 which, together with causality and pre-condition statements involving observable activities, rule out unwanted plans. We introduce our encoding in two different steps; firstly we provide a general algorithm that, given a block structured workflow, generates a planning problem that bisimulates the valid cases. Secondly, we show that given an observed trace we can modify the planning problem in order to exclude plans that are not conforming to the observations. Later we show that additional information about data used by the process can be easily incorporated into the framework, providing additional insight into the observed processes.
 nique. For the complete encoding and formal proofs the reader is referred to [ 8 ]. 4.1 Overview of Action Language K A planning problem in K is specified using a Datalog-like language where flu-ents and actions are represented by literals (not necessarily ground). A problem specification includes the list of fluents, actions, initial state and goal conditions; moreover a set of statements specifies the dynamics of the planning domain using causation rules and executability conditions. The semantics of ily from ASP paradigm. In fact, the system enables the reasoning with partial knowledge and provides both weak and strong negation.
 where f is either a classical literal over a fluent or false (representing absurdity), the b i  X  X  are classical literals (atoms or strongly negated atoms, indicated using -) over fluents and background predicates and the a j  X  X  are positive action atoms or classical literals over fluent and background predicates. Informally, the rule states that f is true in the new state reached by executing (simultaneously) some actions, provided that a 1 ,...,a m are known to hold while known to hold in the previous state (some of the a j might be actions executed on it), and b 1 ,...,b k are known to hold while b k +1 ,...,b in the new state.
 An executability condition is a statement of the form where a is an action atom and b 1 ,...,b are classical literals (known as pre-conditions in the statement). Informally, such a condition says that the action is eligible for execution in a state, if b 1 ,...,b k are known to hold while are not known to hold in that state.
 Terms in both kind of statements could include variables (starting with cap-ital letter) and the statements must be safe in the usual Datalog meaning w.r.t. the first fluent or action of the statements. Additionally, to express commonly used patterns. These are internally expanded using the above two statements together with strong and weak negation. For example a fluent can be declared inertial , expressing the fact that its truth value does not change unless explicitly modified by an action, or it could be stated that after an action there should be total knowledge concerning a given fluent. For more details the reader should refer to [ 4 ]. 4.2 Encoding of the Workflow The main elements of a YAWL workflow are activities and conditions: the lat-ter represent the current status by means of those where tokens are present, while the former  X  X ctivate X  according to the state of input conditions and move tokens in output conditions. To each activity X in the workflow is associated an action with the identifier x in the plan, moreover each condition is associated to a unique identifier. In our example this unique identifier is represented by the concatenation of the connected actions. For example, nu np represents the condition connecting the activities NU and NP in the workflow in Fig. 2 . States are represented by the inertial fluent enabled(  X  ) ranging over the set of conditions in the workflow. The fact of the fluent being true corresponds to the presence of a token in the corresponding condition. In this way we can establish a one to one correspondence between planning and workflow states. In the examples below implicit conditions are named using the starting and ending activities. Work-flow contains two special conditions called start and end respectively. These are encoded as the initial state and goal specification: The encoding is based on the activities of the workflow: each activity with input and output conditions translates to a set of K statements in a modu-lar fashion. The kind of join determines the executability of the corresponding action according to the input conditions over the enabled( enabled(  X  ) fluents associated to the output conditions are manipulated according to the kind of split by means of a set of causation rules.
 ing parallelism and decision respectively. Parallelism makes sure that all the alternative branches are processed by activating all the output conditions and waiting for all the input conditions before enabling the closing activity: All tokens in input conditions are  X  X onsumed X  by the activities and this is cap-tured by using strong negation; e.g. for RRM : Decision patterns (XOR) select only one condition, and the corresponding join expects just one of the input conditions to be activated: flow; i.e. it is sufficient to consider input and output conditions associated to the activity. On the other hand, YAWL semantics for the OR join sanctions that the corresponding activity is executable iff there is a token in at least one of the input conditions and no tokens can reach empty input conditions later on. This specification is clearly non-local and requires the inspection of the status of conditions not directly connected with the action. However, the restriction to block structured workflows enables us to restrict the actual dependency only to conditions enclosed between the  X  X pening X  OR split corresponding to the join. By looking at the network we could determine which conditions might inject tokens into each one of the input conditions; therefore we can prevent the exe-cutability of the action unless there are no  X  X ctive X  conditions that might bring a token into any of the empty inputs. To this end we introduce the fluent delayed( which identifies such  X  X aiting X  conditions: The information concerning reachability is encoded into the predicate reachable(  X  ,  X  ) which can be pre-computed during the encoding. Given these predicates, the encoding of the OR join for an action S with input conditions c ,...,c n correspond to an executability condition of the form: for each of the input conditions. 4.3 Encoding of Traces Activities are divided in observable and non-observable. Traces are sequences of observed activities and generated plans should conform to these sequences in the sense that observable activities should appear in the plan only if they are in the traces and in the exact order.
 In order to generate plans in which observable activities appear in the cor-rect order, we introduce a set of fluents (indicated as trace fluents) to  X  X nhibit X  observable action activation unless it is in the right sequence. The action can be executed only if its corresponding trace fluent is satisfied; moreover trace fluents are set to true in the same order as the observed trace. An additional fluent indicating the end of the trace and included among the goal guarantees that all observed activities are included in the plan.
 Trace fluents are in the form observed(  X  ,  X  ) where the first argument is the name of the activity and the second one an integer representing the order in the sequence ( observed(end, k +1 ) is the fluent indicating the end of a trace of length k ). E.g. a trace APARD , RRM for the example corresponds to the sequence of fluents The additional integer argument is necessary to account for multiple activations of the same activity in the trace; e.g. if RE has been observed twice there would be a fragment observed(re, n ),observed(re, n +1 ) in the sequence of trace fluents. To ensure that observable activities are included in plans only if required, all the pre-conditions of the executability conditions for observable actions are augmented with the corresponding trace fluents: Once an action from the trace is included in the candidate plan, the action must not be repeated and the following activity could be considered; i.e. the corresponding trace fluents should be toggled: Finally the initial status and goal should be modified in order to enable the first observable action and ensure the completion of the whole trace: With the additional constraints related to the observed trace, the planner will select only plans that conform to the observation among all the possible ones induced by the workflow specification. 4.4 Encoding Information About Data Although data within YAWL plays a crucial role in analysing process executions, to the best of our knowledge there is no formalisation suitable for automatising reasoning with workflows (see [ 9 ]).
 As specified in YAWL, the conditions in which tokens are moved after the execution of (X)OR splits depend on the evaluation of the so called branching tests associated to the edges. 4 In order to provide an effective automated rea-soning support for workflows manipulating data we considered common usage in use cases [ 10 ] and introduced a restricted form of data which enables the analysis of a wide range of workflows. The first restriction is that we focus on boolean variables, that is, with true or false value; and the second is that we restrict branching tests to literals; i.e. a variable or its negation. disparate sources; we distinguish two kind of variables according to how their value is established: endogenous and exogenous . The latter ones indicate vari-ables whose value is determined by the environment in which the process actors interact (e.g. a query to a web service) or by events not directly represented within the workflow (e.g. an user action). For example, in Fig. 2 , the variable foreigner is not  X  X ontrolled X  within the workflow but depends on the context in which the process is executed. Endogenous variables, on the contrary, are those which are completely characterised by the workflow description; i.e. for these variables we know which activities manipulate their value. For example, CFC in Fig. 2 sets the flag FCOk which signals whether code is not valid, and the value of this flag is used to control the loop in the workflow.
 processes but rather in being able to further restrict the set of execution traces to those conform to the observations about the data. E.g. the execution of a specific activity might be incompatible with a branch because of the value of a variable, and our system should be able to take this into account.
 Endogenous variables. This kind of variables have a natural encoding within the action language by considering each variable a different inertial fluent which can be modified by actions. Branching tests involving these variables should be added to the causation rules defining the activation of the corresponding condition. fore the encoding should include the causation rule  X  caused child after apard.  X . Similarly, branching depending on these variables affects the enabling of the corre-sponding conditions. For example, the condition connecting NU and NP depends on the truth value of child as well: advancing of the corresponding trace fluent, the value of the variable should be verified. This is encoded in the planning problem by adding the observed variable to the pre-conditions of the following trace fluent. For example, if in the trace RRM observes the value true for child , then the corresponding trace fluent should be  X  X dvanced X  only if that value has been set by an action: Exogenous variables The behaviour of these variables is different because the process does not control but only accesses their value. In fact, in general, is not even possible to assume that their value would be constant through the complete run of the process. In terms of planning, this means that they cannot be characterised as inertial because their value might change without an explicit causation rule (e.g. external temperature below freezing). However, knowledge about their value might be exploited in specific context and this information could arise from two different sources: traces and branching tests.
 In the trace shown in Equation ( 1 ), the value of exogenous variable foreigner is observed to be TRUE by the first activity ( APARD ); therefore we know its value right after the execution of the corresponding activity. This can be encoded into the following causation rules involving the fluent: The addition of the trace fluent is necessary to guarantee that the value is associated to the corresponding observation and not just each time the action is included in the plan (this is relevant for loops). Additional information about the nature of these variables can be used to further refine the encoding. E.g. knowing that the value of the variable would not change during the execution of the process would enable its declaration as inertial and this knowledge could be used in other parts of the workflow.
 In general, exogenous variables which are part of a branching test cannot be used to select the right branch as shown in the case of endogenous variables. The reason being the fact that their value cannot be assumed. However, from the non-deterministic selection of a specific condition by means of the search for a valid plan the current value of a variable could be induced. Consider again the variable foreigner from the example in the case that its value would not have been observed in the trace, i.e., there is no information concerning which branch has been really taken). The planner would select non-deterministically between the two fluents apard anc and apard aac (see Fig. 2 ). From the selection of the first one we can assume that the value of variable foreigner must be TRUE. Indeed in any process execution in which that branching has been selected, the value of that variable had to be TRUE. This constraint can be imposed also for the encoding in the planning problem by adding the causation rule: The problem of finding a (optimistic) plan for a K program is PSPACE-complete [ 11 ] and this result dominates the complexity of our algorithm. In fact, the proposed encoding generates a K program whose size is polynomially bound w.r.t. the size of the input problem (workflow and trace). Despite the upper-bound complexity, we are interested in investigating whether the approach is able to reconstruct incomplete traces in real scenarios and what kind of information is worth exploiting for the encoding.
 RQ1 Is the ASP-based solver able to cope with the planning problems obtained RQ2 Is encoding information about data worth to be used by the solver to cope Experimental Setting. The process investigated in the experiment is the Ital-ian procedure for the registration of births. The process, which involves several actors such as the public health service (APSS), the municipality, and the cen-tral national registry (SAIA), is reported (in the YAWL notation) in Figure 4 It contains 38 activities (6 of which observable), 5 XOR blocks and 1 OR block, and it is enriched with data (specifically, 5 endogenous and 2 exogenous vari-ables). Specifically, after that the activities devoted to prepare the procedure (  X  ) have been executed, the execution flow can take two alternative paths: the municipality path (path  X  ) or the hospital one (path  X  ), according to whether the parents decide to register the newborn first at the municipality and then the registration is passed to the hospital ( &lt;  X , X , X  &gt; ) or, first at the hospital and then the registration is passed to the municipality ( &lt;  X , X , X  &gt; (  X  ) allows the flow, once executed one of the two paths, to go back and execute the other one. Moreover, the  X  path also exhibits a mutually exclusive branch, such that, the subpath  X  1 is executed if  X  is executed as first path, while the subpath  X  2 is taken if the path  X  is executed as second path.
 choice between the execution of  X  1 or  X  2 are realized through conditions imposed on data. Hence, based on the observable activities, the model enriched with data and conditions on data ( DM ) allows for only two possible compliant cases: &lt;  X , X , X  not taken into account (i.e., the only control flow model M is considered), either  X   X  allows for the repetition of  X  and  X  . Although a potentially infinite number of different executions can be generated from M , in order to answer the research questions, we only focus on all the different incomplete traces (based on the set of the available observable activities) such that each observable activity appears at most once in the trace. The following 7 incomplete traces have been examined: Among these traces, only t 5 and t 7 are compliant with DM .Twodifferent encodings have been investigated: (i) the one that considers only the information about the control flow (the M -based encoding) and the one relying on both control flow and data (the DM -based encoding). They contain about 35 actions and 142 (causation and executable) rules. For each incomplete trace we evaluated (both for the M and DM -encoding) the number of possible solutions (if any), as well as the time required for returning at least one solution of minimum size. The experimentation has been performed on a pc running Windows 8 with 8GB RAM and a 2.4 GHZ Intel-core i7.
 Experiment Results Table 1 reports for each incomplete trace, its size (i.e., the number of observable activities that it contains), the length of the plan (i.e., the size of the complete traces reconstructed by the planner), two metrics related to the planner exploration of the search space (i.e., the number of choice points and the recursion level), the number of alternative solutions (i.e., of the possible complete traces of minimum length) and the time required for reconstructing the missing information with and without using the information about data. Results in the table show that the planner with the DM encoding has correctly returned a complete trace only for t 5 and t 7 , while it has classified the other traces as non-compliant. Indeed, the information about data, has a twofold advantage ( RQ2 ):  X  By constraining the execution flow through the information in the model and in the partial trace, it filters out non-compliant solutions. This also comes out by looking at the number of solutions of minimum length returned with the M and DM -encoding for t 5 and t 7 : it is lowered down from 2 ( c 13 )to1(  X  By reducing the search space, it reduces the time required for the explo-ration. The time required for reconstructing the complete trace with the DM -encoding is almost a quarter of the one needed with the M -encoding. By inspecting the time required by the planner to find a compliant plan, i.e., to find at least a possible complete trace of minimum size, results show that it depends on both the process model and the incomplete trace. For instance, the time required with the M -encoding seems to vary according to the plan length and, for plans of the same length, on the base of the type of path followed by the trace. Although the time required with the M -encoding can be high (e.g., see c ), overall, the time required with the DM -encoding to find at least one possible complete trace, is of the order of a couple of minutes, which is still acceptable for a real case study ( RQ1 ). Moreover, by inspecting the data, we found that for more complex (and hence time-consuming) cases, like c 10 (which can even take 10 minutes for getting a solution), the observability of a single extra activity drastically reduces the time required for the planning. For instance, observing 6 activities rather than only 5 in trace t 5 would allow us to halve the time needed for providing a solution (from 497429 ms to 244603 ms). This seems to suggest that a critical factor in terms of approach scalability is the ratio (and the type) of observable activities. The problem of incomplete traces has been faced in a number of works in the field of process mining, where it still represents one of the challenges [ 12 ]. Several works [ 13  X  15 ] have addressed the problem of aligning event logs and procedural models, without [ 13 ] and with [ 14 ] data, or declarative models [ 15 ]. All these works explore the search space of the set of possible moves to find the best one for aligning the log to the model. In our case, however, both goal and preconditions are different since we assume that the model is correct. Moreover, differently from [ 14 ], data are not used for weighting a cost function, by looking at their values, but rather their existence is exploited to drive the reconstruction of the complete trace.
 the control flow has been deeply investigated by the artefact-centric approaches, in which processes are guided by the evolution of business data objects, i.e., artefacts [ 16 ]. The Guard-Stage-Milestone (GSM) approach [ 17 ] is an example of these approaches. It relies on a declarative description of the artefact life cycles, through a hierarchical structure of stages (sets of clusters of activities equipped with guards, controlling the stage activation, and milestones, determining when the stage goal is achieved). Although, similarly to these approaches, we also focus on the interaction between data and workflows, we are not interested to the data lifecycle, but rather we aim at exploiting data in order to further restrict the set of plans compliant with the available partial observations.
 The reconstruction of flows of activities of a model given a partial set of information on it can be related to several fields of research in which the dynam-ics of a system are perceived only to a limited extent and hence it is needed to reconstruct missing information. Most of those approaches share the com-mon conceptual view that a model is taken as a reference to construct a set of possible model-compliant  X  X orlds X  out of a set of observations that convey limited data. We can divide the existing proposals in two groups: quantitative and qualitative approaches. The former rely on the availability of a probabilistic model of execution and knowledge. For example, in a very recent work about the reconstruction of partial execution traces [ 1 ], the authors exploit stochas-tic Petri nets and Bayesian Networks to recover missing information (activities and their durations). The latter stand on the idea of describing  X  X ossible out-comes X  regardless of likelihood; hence, knowledge about the world will consist of equally likely  X  X lternative worlds X  given the available observations in time. Among these approaches, the same issue of reconstructing missing information has been tackled in [ 2 ] by reformulating it in terms of a Satisfiability Modulo Theory (SAT) problem. In this work, the problem is reformulated as a planning problem (specifically in the form of an action language).
 Other works focused on the use of planning techniques in the context of workflows [ 18 , 19 ], though with a different purpose (e.g. for verifying workflow constraints, for accomplishing business process reengineering). Planning tech-niques have also been applied for the construction and adaptation of autonomous process models [ 20  X  22 ]. For example in [ 21 ] YAWL is customized with Planlets , YAWL nets where tasks are annotated with pre-conditions, desired effects and post-conditions, to enable automatic adaptivity of dynamic processes at run-time. The same problem is addressed using continuous planning, in [ 22 ], where workflow tasks are translated into plan actions and task states into causes and effects, constraining the action execution similarly to the approach presented here. However, to the best of our knowledge, planning approaches have not yet been applied to specifically face the problem of incomplete execution traces. The paper aims at supporting business analysis activities by tackling the lim-itations due to the partiality of information often characterising the business activity monitoring. To this purpose, a novel reasoning method for reconstruct-ing incomplete execution traces, that relies on the formulation of the issue in terms of a planning problem, is presented.
 Although preliminary experiments with significantly more complex workflows than the one used in the paper show that the approach can cope with real workflows, we plan to perform an exhaustive empirical evaluation to understand whether the planner can scale up to workflows deployed in practice. Another aspect to investigate is the different kind of data used in workflows and their interaction with the observed traces in order to discriminate relevant plans by augmenting the workflow with annotations. To this end we plan to consider the recent work on data-centric approaches to business processes (e.g. [ 16 ]) to characterise the data involved in process specification. Another line of research we have not yet considered is the analysis of the compatible completed traces. Since there could be several possible completions for an observed trace, it would be interesting to investigate how these can be aggregated and probabilistically ranked.

