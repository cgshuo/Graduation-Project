 Behavioral targeting (BT) is a widely used technique for on-line advertising. It leverages information collected on an in-dividual X  X  web-browsing behavior, such as page views, search queries and ad clicks, to select the ads most relevant to user to display. With the proliferation of social networks, it is possible to relate the behavior of individuals and their so-cial connections. Although the similarity among connected individuals are well established ( i.e. , homophily), it is still not clear whether and how we can leverage the activities of one X  X  friends for behavioral targeting; whether forecasts de-rived from such social information are more accurate than standard behavioral targeting models. In this paper, we strive to answer these questions by evaluating the predictive power of social data across 60 consumer domains on a large online network of over 180 million users in a period of two and a half months. To our best knowledge, this is the most comprehensive study of social data in the context of behav-ioral targeting on such an unprecedented scale. Our analysis offers interesting insights into the value of social data for de-veloping the next generation of targeting services. H.2.8 [ DATABASE MANAGEMENT ]: Database ap-plications X  Data mining ;J.4[ SOCIAL AND BEHAV-IORAL SCIENCES ]: Economics Algorithms, Experimentation advertising, social targeting, behavioral targeting, social-network analysis, large-scale data mining
Behavioral targeting (BT) [4, 5, 25] is an online marketing service that infers the specific interests of consumers based on their online activities. By understanding factors such as the frequency of content consumed, the recency of user en-gagement, and interactions on the site, BT can aggregate large, yet granular audience to whom advertisers can de-liver the most relevant messages. Industry research shows that behaviorally targeted ad spending will reach $4.4 bil-lion by the end of 2012, nearly 25% of US display ad spend-ing [10]. Almost all major online publishers such as Yahoo!, Microsoft and Google have enthusiastically embraced this business model.

Today, the advertising inventory of BT often comes in the form of some kind of demand-driven taxonomy, e.g. , Fi-nance/Loans and Life Stages/Parenting and Children .For each category of interest, BT system builds a model that can derive a response score for each individual from his past online activities ( e.g. , page views, search queries). The score indicates the likelihood that this user will respond to an ad in that category. The response can be ad clicks or conver-sions ( e.g. , product purchases and account sign-ups).
Should the user appear online during a targeting time win-dow, the ad-serving system will qualify this user (to show ads in that category to the user) if her score is above a cer-tain threshold. The threshold is predetermined by domain experts in such a way that both a desired level of response (measured by the cumulative click-through-rate) and reach (measured by the volume of targeted ad impressions served or the number of qualified users) can be achieved. The rev-enue generated by BT is a function of both response and reach .

With the proliferation of social media and social-networking sites, it is now possible to relate the behavior of individuals and their social contacts. In fact, a few startup companies have begun to target consumers based on who they are con-nected to  X  generating a lot of buzz around a new advertis-ing model called social targeting . If information from social networks can drive more accurate and effective advertising, it is desirable to devote more effort to developing new tar-geting technologies that combine both behavioral data and social signals. However, before we jump on this bandwagon of social targeting , it is important to answer the following fundamental questions:
In this paper, we strive to answer the above questions by evaluating the predictive power of social data on a large on-line network of over 180 million users in a period of two and a half months. We develop a wide array of supervised and un-supervised machine-learning approaches to incorporate so-cial signals to standard BT models. We conduct extensive experiments to assess the effectiveness of these methods on users with different levels of online activities, and across over 60 consumer domains including Technology , Retail , Enter-tainment , Finance , Travel , Life Stages , Automotive ,etc.
As the behavioral and social data are intrinsically in large scale ( e.g. , tens of terabytes of da ta and hundred s of billions events in two months), we parallel all the machine-learning algorithms using Hadoop MapReduce framework. Specifi-cally, we have designed and implemented a highly scalable end-to-end solution to conduct large-scale data analysis us-ing Hadoop. Our solution handles the generation of behav-ioral and social features, model training, scoring, network propagation, and model evaluation in a very efficient and scalable fashion.

To the best of our knowledge, this is the most comprehen-sive large-scale social-network data analysis in the context of BT. Our study based on real-world applications offers in-teresting insights into the value of social data for developing the next generation of targeting products. Our findings of-fer a solid and quantitative guideline for both publishers and advertisers in decision making about social targeting versus behavioral targeting. Our algorithm implementations also serve as the building blocks for future researches in this do-main.

Organization of the material: Section 2 reviews re-lated work. Section 3 describes our behavioral and social data. Section 4 introduces BT baseline model and evalua-tion metrics. In Section 5 we develop a wide array of super-vised and unsupervised approaches to evaluate the value of social data for BT. In Section 6 we briefly discuss how these different approaches are implemented on Hadoop using a unified framework. We conclude the paper in Section 7.
Friends are similar along a variety of dimensions is a long-observed empirical regularity, which sociologists called the homophily [16]. The study of this pattern is a recurring theme with increasing interests owing to the boom of online social networking services. Researchers from Microsoft [20] found that people who chat with each other using instant messaging are more likely to share similar personal charac-teristics ( e.g. , age, location) and interests ( e.g. ,searchtop-ics). Engineers from Facebook [12] developed techniques to infer users X  undeclared profiles ( e.g. , age, gender, profession) from their friends so that advertisers can precisely target more consumers. Scientists from academia also developed models to evaluate the quality of algorithms that derive one X  X  interests from their social contacts [17, 24]. However, most existing work is limited to the inference of  X  X tatic X  profiles such as age, gender, education. Understanding the role of homophily with respect to one X  X  online behavior, and partic-ularly in the context of behavioral targeting has been largely ignored.
 The most relevant work to ours is by Bagherjeiran and Parekh [1]. The authors observed that online friends tend to see and click on similar display ads. They developed an ensemble classifier to combine both behavioral and social features to boost the probability that a user will click on an ad. We also evaluated this approach in our experiment (to be described later). We observed that the computational cost of this approach is prohibitively high, which makes it not very much practical in large-scale production systems. Further, our work differs from [1] in that we systematically studied a wide array of supervised and unsupervised data mining strategies to incorporate social data into traditional behavioral targeting. To our best knowledge, our work is the most comprehensive study of the value of social data in the context of behavioral targeting at an unparalleled scale. Another seemingly relevant work is by Provost et al. [18]. The authors proposed to construct a quasi-social network that connects people who visit the same user-generated micro-content sites. Given a set of valued seed customers from ad-vertisers, Provost et al. identified more users on the quasi-network who are in close proximity to the seed users for brand advertising. The  X  X roximity X  between two users is based on the similarity of the contents they have viewed. The idea, though called  X  X ocial targeting X , is closely related to traditional behavioral targeting because the network is derived from users X  browsing activity ( i.e. , page views).
There is another large body of work in the literature on network influence modeling , which is one of the fundamen-tals to viral marketing [13]. Although Watts [23] challenged the existing influence hypothesis and claimed that the so-called influencers in social networks were just accidental, viral marketing recently received increasing attention. Hill et al. [11] found that consumers who were linked to prior adopters adopt a telecommunication service at a rate 3-5 times higher than the control group. Bhatt et al. [3] also in-vestigated how we might use network information to predict product adoptions. They observed strong signals of peer pressure, but very little evidences of influence from highly connected users. Furthermore, they found that the prop-agation of the adoption remains mostly local to the initial adopters and their close friends, echoing the discovery made by Bakshy et al. [2] that most information cascade in social networks are very shallow. We note that influence analysis is primarily interested in how information spreads over the network, whereas our focus is to understand the value of so-cial data, and how we can leverage social data for behavioral targeting.
The analysis and experiments in this paper are conducted on vast amounts of behavioral and social-network data from a large IT company in a period of two and a half month. In this section, we describe the data and its properties.
Behavioral data: Behavioral data serves as the back-bone of our study. It contains individuals X  web-browsing behavior such as the pages they have visited or the searches they have made, all aggregated at the BT category level, e.g. , 10 page views in category  X  X etail X  at time t . For eval-uation, we split the data into training and test sets. Fig-ure 3 illustrates the generation of both training and test data. The training data is collected from a 10-week period of time (2010/08/23 X 2010/10/31), where the last 4 weeks (2010/10/4 X 2010/10/31) are used to generate the targets ( i.e. , clicking on an ad or not). For each user u on each day t n +1 in the 4-week target window, we set the target to1if u clickedonanadintheBTcategorybeingmod-eled, or 0 if u saw the ad but did not click on it. Next, we create the corresponding behavioral features from this user X  X  activities in the preceding 6 weeks (details in Sec-tion 4.1). The test data is generated from a 7-week period of time (09/20/2010 X 2010/11/07), where the last 1 week (2010/11/01 X 2010/11/07) is used to form the targets. This process produces 13 billion training and test examples and approximately 7terabyte data.

Social data: Our social graph is constructed from users in an Instant Messaging (IM) network operated by a large IT company. We remove singleton users and establish an edge between all pairs of users who mutually authenticate each other as buddies. The resulting network has over 390 million nodes and 5 billion edges .Intersectingthebe-havioral data (training and test, respectively) with this com-munication network results in approximately 180 million users, for whom we have a record of both their own behaviors as well any behaviors of their friends.

Remarks: We conduct our research in a privacy-friendly fashion. Specifically, we do not use any demographic or ge-ographic information. The behavioral data is aggregated at category level, e.g. ,10 page views in category  X  X ravel/Cruise X  at time t . We do not use any granular user activities. Figure 3: Generating training and test behavioral data.
It is a long-observed empirical regularity that friends are similar on a variety of aspects  X  a pattern sociologists called homophily .AsMcPherson et al. write in their seminal re-view [16],  X  X omophily limits people X  X  social worlds in a way that has powerful implications for the information they re-ceive, the attitude they form, and the interactions they ex-perience. X  In other words, where there is homophily ,onecan in principle predict an individual X  X  behavior based on the information from his or her social contacts. Thus, to assess the value of social data for behavioral targeting, we first at-tempt to answer the following question: Can we observe the presence of homophily in our social data, and in particular, along certain dimensions related to behavioral targeting? We answer this question by studying BT qualifications and ad clicks .
 BT qualifications: Recall that a user is qualified for a BT category if her BT score derived from the corresponding model is above the serving threshold. The plot in Figure 1 shows that it is possible to infer one X  X  BT qualifications from that of her friends. For almost all the 60 major BT categories we studied, users with more friends who are qualified for a certain category are more likely to be qualified for the same category. For example, among all consumers with 5 friends qualified for Retail , 21% are also qualified for Retail ,6times higher than consumers with no friends qualified for Retail .
Ad clicks: Since a majority of online publishers adopt the pay-per-click model for their BT products, i.e. ,advertisers pay publishers when their ads are clicked, we also study the homophily of ad clicks using our data. Specifically, we com-pute the likelihood that a user will click on the display ads in a BT category as a function of having friends who have done the same within the last few days. The results are il-lustrated in Figure 2. Similar to the trend we observed for BT qualifications ,socialdataareingeneralinformativefor predicting ad clicks as well, though the effect varies consid-erably across different categories. For 42 of the 60 categories shown in the plot, users whose friends clicked on the ads be-fore have markedly higher rates of clicking themselves, with increases ranging from 0.3% to over 977.0%.

Remarks: Goel and Goldstein [9] also investigated so-cial homophily using data from off-line sales, sign-ups for an online service, and clicks on ten online banner ads. Our findings echo the observations made by them.
In this section, we briefly introduce BT baseline model and evaluation metrics.
The baseline model [5] takes users X  browsing habits as in-put, and builds a classifier to predict the likelihood that a user is going to click on an ad in a certain BT category. The actual data-mining algorithm to learn the classifier is often not crucial. In fact, it is generally intractable to use algo-rithms of time complexity higher than linear in solving large-scale machine learning problems of industrial relevance [4]. Our previous experience shows that linear classifiers such as logistic regression, linear regression and support vector machines do not differ significantly in terms of prediction performance. In this paper, we use a customized version of LIBLINEAR [7] to train all models on Hadoop MapReduce platform.

On the other hand, how to construct features for train-ing and scoring has a huge impact on large-scale production systems. As online users constantly change their behaviors by browsing different web pages and searching different sub-jects, it is generally impractical to continuously create new features and score hundreds o f millions of users from scratch  X  after all, online systems often need to make ad serving de-cisions in near real time (in the order of millisecond). Next we introduce a simple linear-time method that can incremen-tally update behavioral features, allowing linear classifiers to incrementally update scores as well.

For each type of user activities a  X  X  page view , search query , ad click , ... } in the BT category being modeled, the baseline model computes two types of input features:
As the feature window moves from [ t 0 ,t n ]to[ t 0 ,t n is easy to update features without having to re-process all the prior events:
The target of the model is a binary variable indicating aclickonanadinthecategorybeingmodeled( y =1), or not ( y = 0). Although it is possible to use conversions such as product purchases as the target, in this paper we mainly focus on pay-per-click model, where advertisers pay the hosting service when the ad is clicked.
We build a BT model for each category c and measure its performance by two metrics: 1) the cumulative CTR of a collection of targeted users whose scores are above a certain serving threshold (or at a certain reach level); and 2) the area under the ROC curve [8].

The cumulative CTR at a certain serving threshold is de-noted by CTR reach c and illustrated in Figure 4. It is calcu-lated as the total ad clicks received from users whose scores are above the threshold, divided by total ad impressions served to these users. To eliminate the potential variance across different models, we normalize CTR reach c by the cor-responding population CTR where the threshold is set to the minimum (rightmost value on x-axis). We denote this normalized metric by CTR Lift reach c :
CTR lift provides a sneak peek of the model performance at certain reach levels. To have a global picture, we use the area under the ROC curve, denoted by AUC c ,toexaminea Figure 4: CTR vs. Reach curve. BT scores (sorted model X  X  discrimination power over the entire score distribu-tion. The higher the AUC value, the better the model.
Since we build models for 60 major BT categories in one batch, and ads in different categories receive distinctive serv-ing demands, we report average AUC c and CTR Lift reach c weighted by ad impressions served in each category. where v c is the ad impressions in category c .Weightingby ad impressions allows us to pay more attention to revenue-bearing categories which usually have a large amount of con-tracted impressions to deliver.
In this section, we develop various supervised and unsu-pervised methods to incorporate social signals into tradi-tional BT. We evaluate the efficacy of these methods through extensive experiments on large-scale real-production data across 60 major consumer domains. Our results offer very interesting insights into the value of social data, allowing us to answer the questions raised before: How can we leverage one X  X  friends activities for behavioral targeting? Are fore-casts derived from such social features more accurate than standard behavioral targeting models?
Our preliminary study in Section 3.2 shows that connected users share similar behavioral patterns such as BT qualifi-cations and ad clicks. Motivated by this finding, we propose to train BT models with additional social features extracted from the network. Specifically, we develop two types of so-cial features: neighborhood features and community features .
Neighborhood features: These features provide simple statistics of one X  X  social circle. The first set of neighborhood features includes: 1) the number of friends; 2) the number and percentage of active friends, where active means that the user has certain online activities ( e.g. browsing pages, Figure 5: Distribution of the sizes of the connected com-Figure 6: Example of creating community features. clicking ads) in the feature time window; and 3) the number and percentage of ad clickers in one X  X  neighborhood (recall that a user is likely to click the ad if her friends also clicked onthead).Wedenotethesefeaturesby Neighbors1 .

Note that ad clicks are extremely rare events  X  the pop-ulation CTRs on Automotive and Travel display ads are only about 0.15% and 0.08%, respectively according to a DoubleClick report in 2009 [6]. Thus, the volume of users that can benefit from friends X  ad-clicking behavior are quite small. On the other hand, views of web pages and ads represent the most dominant patterns of online activities. Hence, we construct the second set of neighborhood fea-tures on top of Neighbors1 by introducing the number and percentage of friends with page views and ad views in the same category being modeled. We denote these features by Neighbors2 and Neighbors1  X  Neighbors2 .Theabso-lute values of these features may vary drastically in practice (approximately follow a power-law distribution), we apply a logarithmic transformation to scale all quantities to a rea-sonable range.

Community features: The second approach is to ex-tract latent traits based on network structure. One typical example is the online community where members inside the group have more inter-connections than with others outside. Recently, Tang and Liu [21, 22] utilized community mem-bership as features to solve a network-based classification problem. The algorithm first identifies communities from the network, and then treats community memberships as la-tent features for classical supervised learning. They showed that this approach outperforms other collective-classification methods [19], especially in noisy social-media networks.
However, finding communities in a large-scale social net-work with 390 million nodes and 5 billion edges is not a trivial task. It is necessary to first understand the over-all network structure before delving into any specific algo-rithms. Figure 5 illustrates the distribution of the connected components in our network. There are more than 9 million connected components, among which the largest component alone covers 94 . 21% of nodes  X  a very typical power-law dis-tribution. Standard community-detection algorithms such as matrix factorization and statistical inference, if not well tuned, are very likely to end up finding these connected com-ponents instead of real  X  X atent features X .

To tackle this challenge, we develop a simple notion of community as a user and her 1-hop neighborhood .Recall again that users with clickers in the neighborhood are more likely to click on ads, we only keep communities that are centered at an ad clicker. We treat each such community as a feature; if a user belongs to that community, the cor-responding feature value is 1, and 0 otherwise. We further normalize each user X  X  membership features so that they sum up to 1. We denote this type of feature by Community . Figure 6 illustrates an example of creating such features.
Another way of combining social and behavioral data is to build an ensemble classifier, which merges the outputs of behavioral model with social model to improve predic-tions. Mathematically, the output of an ensemble model S e is calculated as where  X   X  [0 , 1] is a weighting parameter.

A constant weight, say  X  =0 . 5, often leads to a poor per-formance based on our experience. In practice,  X  is learned through a third classifier that takes both S behavioral and S social as inputs and the original targets as outputs. Bagher-jeiran and Parekh [1] discussed this approach for online ad-vertising in ICDM 2008 workshop. However, we would like point out that the computational cost of this approach is prohibitively high because it needs to train three models: behavioral model, social model, and the ensemble classifier, and score each user multiple times. Thus, this method does not scale very well to large production systems.
We build a bunch of new BT models using the aforemen-tioned social features and ensemble approach. We evaluate these models with respect to the baseline in terms of both AUC and CTR Lift reach (see Section 4.2 for definitions). For illustration purpose, we report the relative improvement of these metrics as follows:
The reach takes a value of 5% , 10% ,..., 50%, meaning that ad serving thresholds are chosen for each model that top 5% , 10% ,... users are qualified for ad serving. Results I: The experimental results are summarized in Table 1. A positive value in the cell means that the new model is performing better than the baseline, whereas a neg-ative value indicates that the new model is worse. Line 1 is the baseline model compared with itself, therefore all en-tries are 0s. Line 2 is a random targeting model that ran-domly assigns scores to users, so its AUC random =0 . 5and CTR Lift reach random = 0% at all reach levels. Line 3 X 5 are mod-els built from social features alone. From Line 1 X 5 we have two interesting observations: Line 6 X 8 are models built from hybrid features that combine both behavioral and social data. We can observe that these models have higher AUC and CTR than baseline, though the improvement seems only marginal (we will elaborate more on this shortly). It is also worth noting that ensemble clas-sifier surprisingly underperforms the BT baseline, possibly due to overfiting in the training phase. Considering its com-putational cost as well, we exclude it from the subsequent analysis.
The experimental results in Table 1 show that models built from the combination of social and individual behav-ioral features outperform the baseline. But the actual gains on Line 6 X 9 seem rather marginal (less than 1% of  X  AUC aged over 60 BT categories, we conducted further analysis to examine the performance improvement of each individual category. In particular, we chose BT + Neighbors1 method to study as it is one of the best performing methods. The category-level results are shown in Figure 7. We can see that the improvement is highly skewed, some category has as large as 11% boost and some others only less than 1%. So our next questions are: why could this happen? When does social features help most?
To answer these questions, we further partition our users into the following three groups: It is clear that the magnitude of behavioral signals vary sig-nificantly among these three types of users: Type-0 is the weakest, followed by Type-1, and Type-2 is the strongest.
In the following experiments, we choose the best perform-ing models BT + Neighbors1 , BT + Neighbors2 and BT + Community , and evaluate their performance against each type of users, in an attempt to answer the questions we raised in this section.
 Results II: The experimental results are illustrated in Figure 8. We can observe that
So how does these findings help us answer the questions raised at the beginning of this section? We further inves-tigated categories with large performance improvement and found that they often have more Type-0 and Type-1 users. This is the case when social features are playing important roles. In addition, the findings also help us understand the pattern we observed in Line 6-8 of Table 1, that is, the performance improvement increases as the reach level in-creases. We found that when the reach is small, only those users with high BT scores are qualified, and most of them are among Type-2 users. Hence, we do not see much gain of performance. As the reach increases, more and more Type-0 and Type-1 users are qualified and targeted with ads, con-sequently, the value of social features starts to manifest.
In this section, we employ network-propagation methods [15, 26, 14, 27] to infer users X  BT scores directly from their friends X . The motivation behind this approach is again the homophily property we observed in Section 3.2  X  users in close proximity share similar behavioral patterns. One ad-vantage of this approach is that we may only need to score a small set of active users and use them as the seeds of the Figure 8: Performance improvement with respect to propagation, thus reducing the storage and computational cost of creating a large set of BT features for classification models. We test this idea using three network-propagation schemesasfollows.
Scheme 1. Let s ( t ) ( u ) denote the score of user u after the t -th iteration, N ( u ) be the set of users who are friends with u , d ( v ) be the out-degree of user v (the number of friends of v ), | G | be the total number of users in the social network, and 0 &lt; X &lt; 1 a dumping factor. The first propagation is defined recursively as follows: Scheme 1 is essentially the PageRank algorithm [15]. PageR-ank is used to measure the quality of a web page based on the structure of the hyperlink graph. A page that receives  X  X n-dorsements X  X rom many other good quality pages in the form of hyperlinks tends to be of good quality too. The station-ary state of this propagation depends on graph structure, but not on initial scores.

Scheme 2. Let s (0) ( u ) denote the initial BT score of user u according to the standard BT models, and 0 &lt; X &lt; 1 a weighting parameter. The second propagation is defined recursively as follows: Scheme 2 has its roots in semi-supervised learning [27]. The basic assumption there is consistency : data points close to each other, or on the same cluster or manifold are likely to have the same class labels. The propagation allows every data point to iteratively spread its label information (BT scores in our scenario) to its neighbors until a global state is achieved. During each iteration, each point receives the information from its neighbors, and also retains its initial in-formation. The stationary state of this propagation depends on graph structure as well as the initial scores.
Scheme 3. The third propagation is defined recursively as follows: s t ) ( u )=(1  X   X  ) Scheme 3 is a variation of PageRank with the exception that a user X  X  score computed in the previous iteration is carried over to the next iteration in computing her new score  X  a sort of self-reinforcement . This propagation is used in [26] to search experts on an author-citation network.
Our study of supervised models in Section 5.1 have shown that 1) social features appreciably improve the prediction ac-curacy for users without much behavioral information (Type-0 and Type-1 users); indicating that these types of users ben-efit most from their active neighbors; and 2) social features are not quite informative for users with lots of activities (Type-2 user); meaning that for this type of users, baseline model is sufficiently trustworthy. Hence, to evaluate the ef-fectiveness of network-propagation approaches, we hide BT scores (computed from BT baseline model) of Type-0 and Type-1 users (their scores are set to zeros), and initiate prop-agation from Type-2 users. After each round of propagation, we compute  X  AUC on Type-0 and Type-1 users respectively to evaluate the performance.
 Results III: The experimental results are summarized in Figure 9. Unfortunately, we find that propagation in general does NOT increase prediction accuracy of baseline models on either Type-0 or Type-1 users. Since ad click is rare, it often requires vast amounts of data to train a classification model in order to optimize CTRs. Consequently, unsuper-vised approaches such as network propagation may not be able to capture this weak signal.

Nevertheless, we still have some interesting observations to point out. First, Type-0 users benefit from the first round of propagation with  X  AUC of 0 . 55% while Type-1 users do not; indicating again that when users do not have any be-havior data, social information can provide valuable signals. Second,  X  AUC decays as propagation continues (hold true when the number of iterations 3); showing that infor-mation from remote friends are noisy and not much useful. Third, the decay of  X  AUC from propagation Scheme 3 is slower than other two approaches; implying that the self-reinforcement strategy adopted by Scheme 3 may protect users X  scores from being significantly skewed by their neigh-bors. Figure 9: Performance of three network-propagation
Remarks: It is also possible to initiate propagation from past clickers who often have high BT scores. However, since CTRs are low and the degrees of most nodes are small, rel-atively few users are connected to any clickers at all. Thus, even though neighbors of clickers have relatively high CTRs, including them in an even moderately-sized set of individu-als results in negligible improvement.
Another contribution we have made is that we designed and implemented a highly scalable end-to-end solution to conduct large-scale data analysis using Hadoop MapReduce framework. Our solution handles the generation of behav-ioral and social features, model training, scoring, network propagation, and model evaluation in a very efficient fash-ion. Due to space constraints, we only present a sketch of two major components: social-feature generation and net-work propagation . Although they serve different purposes with different specs, we can implement them on Hadoop us-ing a unified framework as follows: Thepseudo-codefor social-feature generation and network propagation are presented in Algorithms 1 and 2.

Algorithm 1: Social-feature Generation
In Algorithm 1, a user passes her behavioral informa-tion to other users she is connected to (Line 4 X 9). Note that if we want to create Community features, only ad clickers will pass information to neighbors (Line 7 X 9). In the reducer, each user aggregates all information received from friends (Line 12 X 15) and invokes CreateNeighborhood-Feature and CreateCommunityFeature functions to construct Neighborhood and Community features, respectively (Line 16 X 19). The ou tputs of the reducer serve as inputs to the model training and the scoring components.

Algorithm 2: Network Propagation
In Algorithm 2, the mapper computes for each user the scores need to be distributed to her neighbors (Line 4 X 6). In the reducer, each user sums up all score contributions from her neighbors and computes updated BT score (Line 12 X 16). Since it is impossible to maintain a global graph structure in memory, we need to pass along the graph from one iteration to the next. This is accomplished by emitting the adjacency list of each user keyed by the user id (Line 3), and this structure is written back out to disk in the reducer (Line 17). The outputs of the reducer have the same data structure as the inputs to the mapper, which can be used for the next round of MapReduce iteration.
In this paper, We developed a wide-array of supervised and unsupervised methods to leverage social data for BT. We conducted extensive experiments to assess the effective-ness of these methods on a large network of 180 million users, and across 60 consumer domains. To our best knowledge, this is the most comprehensive study of the value of social data for advertising. To conclude, we summarize our major findings here. 1) Social data alone do carry informative signals that can be utilized to compliment standard BT models. However, its value for targeting must be stated carefully as it is not always a silver bullet . In our study, categories with a strong homophily effect are more likely to benefit from social data, but the degree of improvement depends on the amount of be-havioral information the targeted users have, and how strong the baseline is. 2) Among all the methods we have investigated, append-ing social features directly to standard BT features seems to be the most effective and scalable way to go.

Finally, we want to point out that this study explores only one aspect of utilizing social-network data for advertis-ing. We mainly treat it as an additional information source, and try to understand its value in the context of BT. How-ever, social networks can be employed in other forms such as improving user engagement with products, and identifying influencers to promote word-of-mouth marketing. All these problems merit further systematic and quantitative study. [1] A. Bagherjeiran and R. Parekh. Combining behavioral [2] E.Bakshy,J.M.Hofman,W.A.Mason,andD.J.
 [3] R. Bhatt, V. Chaoji, and R. Parekh. Predicting [4] Y. Chen, D. Pavlov, and J. F. Canny. Large-scale [5] C.Y.Chung,J.M.Koran,L.-J.Lin,andH.Yin.
 [6] DoubleClick. 2009 year-in-review benchmarks: A [7] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, [8] T. Fawcett. An introduction to ROC analysis. Pattern [9] S. Goel and D. G. Goldstein. Birds of a feather shop [10] D. Hallerman. Behavioral targeting: Marketing trends. [11] S. Hill, F. Provost, and C. Volinsky. Network-based [12] T. Kendall and D. Zhou. Leveraging information in a [13] J.Leskovec,L.Adamic,andB.Huberman.The [14] S. A. Macskassy and F. Provost. Classification in [15] C. D. Manning, P. Raghavan, and H. Sch  X  utze. [16] M. McPherson, L. Smith-Lovin, and J. M. Cook. [17] A. Mislove, B. Viswanath, K. P. Gummadi, and [18] F. Provost, B. Dalessandro, R. Hook, X. Zhang, and [19] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, [20] P. Singla and M. Richardson. Yes, there is a [21] L. Tang and H. Liu. Relational learning via latent [22] L. Tang and H. Liu. Leveraging social media networks [23] D. Watts. Challenging the influentials hypothesis. [24] Z. Wen and C.-Y. Lin. On the quality of inferring [25] J. Yan, N. Liu, G. Wang, W. Zhang, Y. Jiang, and [26] J. Zhang, J. Tang, and J. Li. Expert finding in a social [27] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and
