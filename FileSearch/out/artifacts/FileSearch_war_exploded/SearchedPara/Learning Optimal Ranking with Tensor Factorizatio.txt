 Tag recommendation is the task of predicting a personalized list of tags for a user given an item. This is important for many websites with tagging capabilities like last.fm or de-licious. In this paper, we propose a method for tag recom-mendation based on tensor factorization (TF). In contrast to other TF methods like higher order singular value decom-position (HOSVD), our method RTF ( X  X anking with tensor factorization X ) directly optimizes the factorization model for the best personalized ranking. RTF handles missing values and learns from pairwise ranking constraints. Our optimiza-tion criterion for TF is motivated by a detailed analysis of the problem and of interpretation schemes for the observed data in tagging systems. In all, RTF directly optimizes for the actual problem using a correct interpretation of the data. We provide a gradient descent algorithm to solve our op-timization problem. We also provide an improved learning and prediction method with runtime complexity analysis for RTF. The prediction runtime of RTF is independent of the number of observations and only depends on the factoriza-tion dimensions. Besides the theoretical analysis, we empir-ically show that our method outperforms other state-of-the-art tag recommendation methods like FolkRank, PageRank and HOSVD both in quality and prediction runtime.
 I.2.6 [ Artificial Intelligence ]: Learning X  Parameter learn-ing Algorithms, Experimentation, Measurement, Performance Tensor factorization, ranking, tag recommendation
Tagging, in general, allows users to describe an item (e.g. website, song, friend, . . . ) with a list of words ( X  X ags X ). Tags can be used e.g. for organizing, browsing and searching. Tagging is a popular feature of many websites like last.fm, delicious, facebook, flickr 1 . With tag recommendation a website can simplify the tagging process for a user by recom-mending tags that the user might want to give for an item. item, it is important to personalize the recommended tags for an individual user. That means the tag recommender should infer from the already given tags, which tags a cer-tain user is likely to give for a specific item. For predicting a personalized list of tags for an item, the tag recommender should use the tagging behaviour of the past of this and other users as well as the tags for this and other items. Interest-ing about tagging data is that it forms a ternary relation between users, items and tags. This makes it different from typical recommender systems where the relation is usually binary between users and items. Exploiting all information of the ternary relation is a key challenge in tag recommen-dation. A second major challenge for tag recommendation is the data interpretation as usually only positive feedback is present in a tagging system.

In this paper we present a tag recommender that is based on a tensor factorization (TF) model and thus can exploit directly the ternary relationship in tagging data [14]. We will show that other learning methods for tensor factorization proposed by now  X  like HOSVD [7] or other least square methods [8]  X  are not optimal for learning a TF model for tag recommendation. We will discuss this in detail and propose a new optimization criterion and learning algorithm that directly optimizes a TF model for optimal ranking.
In all our contributions are as follows: 1. We present a new interpretation scheme for tagging 2. We propose RTF, an optimization criterion and learn-3. Finally, we show empirically that our proposed method http://www.last.fm/ , http://delicious.com/ , http:// www.facebook.com/ and http://www.flickr.com/ + + + +
User 1 User 2 User 3 item item item
Personalized Tag Recommenders. The literature con-cerning the problem of personalized tag recommendation is still young, but has nevertheless attracted significant atten-tion recently. In [5] a comprehensive evaluation and com-parison of several state-of-the-art tag recommendation algo-rithms in three different real world datasets is provided. The best results reported in terms of precision and recall, were given by the FolkRank algorithm [3], an adaptation of the well known PageRank. Even though FolkRank showed to provide high quality recommendations, due to its very slow prediction runtime it is not applicable for large real-world scenarios. We will show that our method RTF outperforms FolkRank both in quality and prediction runtime.

Non-personalized Tag Recommenders. A non-per-sonalized tag recommender predicts the same list of tags for the same item  X  i.e. it is independent of the user. There is several work on non-personalized tag recommenders, e.g. [2, 13, 12]. In [13], for example, an algorithm based on a Pois-son Mixture Model is introduced. Although the algorithm is able to make predictions nearly in linear time, it is not per-sonalized since the training data is composed from (words, documents, tags) triples containing no user specific infor-mation. Another difference to our work and the work pre-sented before, is that their method is content aware. In [12] the problem of tag recommendations is casted as a multi-label ranking problem for document classification and a fast recommendation algorithm based on gaussian processes is proposed. The algorithm provides linear time to train, pro-portional to the number of training samples, and constant time to predict per test case. Again differently from us, this approach is non-personalized since a given test document would be classified with the same set of tags independently of the users. Our evaluation (see section 5.4.3) indicates that if user information is present, our proposed personal-ized tag recommender outperforms any non-personalized tag recommender.

Tensor Factorization. While the idea of computing low rank approximations for tensors has already been used for many purposes [7, 11, 6], it has just recently been applied for the problem of personalized tag recommendations [14]. In this approach, HOSVD [7] is applied for computing a low rank approximation of the original tensor, through which tag recommendations are generated yielding promising re-sults. Nevertheless all these TF approaches like HOSVD or other least-square methods [8] do not lead to optimal factor-izations for the task of tag recommendation as we will show in this paper both theoretically and empirically.
The task of tag recommendation is to provide a user with a personalized ranked list of tags for a specific item. An ex-ample is a bookmark website where after the user has added a new bookmark, the system recommends him a personal-ized list of ranked tags/ keywords for this bookmark. The list of recommended bookmarks can be learned from the tag-ging behaviour of the past of this user for other bookmarks and the tagging behaviour of other users for both this and other bookmarks.
Let U be the set of all users, I the set of all items/ re-sources and T the set of all tags. The tagging information of the past, i.e. all individual tags the users have given to resources, is denoted by S  X  U  X  I  X  T . E.g. ( u,i,t )  X  S would mean that user u has tagged an item i with the tag t . The ternary relation S can be viewed as a three dimensional tag cube (see figure 1), where the dimensions are the users, items and tags. The posts P S denotes the set of all distinct user/ item combinations in S : From the ternary relation S one can induce a tensor Y with training data. There are several ways how to interpret S and create Y . We will present two methods in section 3.2.
The task of tag recommendation is to predict which tags a user u is most likely to use for tagging an item i . That means a tag recommender has to predict the numerical values  X  y of the tensor  X  Y indicating how much the user likes a tag for an item. Instead of predicting single elements of  X  Y , in general the system should provide the user a personalized list of the best N tags for the item. Given a predictor the list Top of the N highest scoring items for a given user u and an item i can be calculated by: Where the superscript N denotes the number of tags to re-turn. Figure 2: 0/1 interpretation: Positive examples are encoded as 1 and the rest as 0 . For any learning algorithm good training data is crucial. In typical learning tasks, the set of positive and negative ex-amples is clearly given. In contrast to this in many recom-mender problems, like in tag recommendation, only positive examples are present. In tag recommendation the positive examples are the elements of S . But it is unclear how the rest of this relation ( U  X  I  X  T ) \ S should be interpreted.
A common interpretation scheme  X  we call it the 0/1 scheme  X  is to encode positive feedback as 1 and interprete the remaining data as 0 (see figure 2). The training data Y 0 / 1 is then defined as: This interpretation is e.g. used for training tag recommenders using a HOSVD model [14].

The 0/1 interpretation has three severe drawbacks. 1. The semantics are obviously incorrect. Imagine a user 2. Also from a sparsity point of view the 0/1 scheme leads 3. As one is interested in ranked lists, trying to fit to Figure 3: Post-based ranking interpretation: Non observed data inside given posts are negative exam-ples. All other entries are missing values. No nu-meric value is assigned to the classes, instead only a ranking is implied.
In this paper we present another interpretation scheme, that we call the post-based ranking interpretation . Our scheme addresses all of the three problems of the  X 0/1 scheme X . With this interpretation we distinguish between positive and neg-ative examples and missing values. The idea is that posi-tive and negative examples are only generated from observed posts. All other entries  X  e.g. all tags for an item that a user has not tagged yet  X  are assumed to be missing values (see examples for a given post: From this we can define for the values of Y pairwise ranking constraints:
From a semantical point of view this scheme makes more sense as the user/ item combinations that have no tags are the ones that the recommender system will have to predict in the future. With our interpretation we treat this kind of data as missing values and do not use it as training data like in the  X 0/1 scheme X  2 . Also inside a given post the negative values are not fitted to 0, instead we only require that the positive examples have a higher value than the negative ones. This addresses the first two drawbacks of the  X 0/1 scheme X . The third drawback is tackled by our scheme by allowing free values for y and only posing pairwise ranking constraints (see eq. 2). In all, a model for  X  X ost-based ranking interpretation X  should be optimized to satisfy as many ranking constraints as possible. Please note that optimizing for the ranking constraints between positive and negative values is related to optimizing the ranking statistic AUC (area under the ROC-curve) as we will see in the next section. First we describe tensor factorization models in general. Then we present in detail how a tensor factorization model can be learned for optimizing the ranking statistic AUC (area under the ROC-curve). We discuss the RTF model and compare it to HOSVD and Folkrank.
Please note that the  X 0/1 scheme X  poses more constraints on y u,i,t as fitting to 0/1 is required and there are constraints on tags of non-observed posts. T Figure 4: Tensor factorization: The tensor  X  Y is con-structed by multiplying three features matrices  X  U ,  X  I and  X  T to a small core tensor  X  C .
With tensor factorization, Y is estimated by three low rank matrices and one tensor (see figure 4). For each of the low rank matrices tries to represent an entity with a small number of parameters. We call the matrices feature matrices and the tensor core tensor . The model parameters of a TF model can be seen as latent variables.

The prediction is made by multiplying the three feature matrices to the core tensor: Where the core tensor  X  C and the feature matrices  X  U ,  X   X  T are the model parameters that have to be learned and  X  x is the tensor product to multiply a matrix on dimension x with a tensor. The model parameters have the following sizes: Where k U , k I and k T are the dimensions of the low-rank ap-proximation. That means that  X  Y in the formula (3) results in a tensor with dimensions | U | X | I | X | T | . We denote the model parameters by the quadruple  X   X  := (  X  C,  X  U,  X  I,
Given the feature matrices and the core tensor, the pre-diction  X  y u,i,t can be made as follows: Given  X  y u,i,t a personalized ranked list of tags for user u and item i can be created with formula (1).

Throughout the paper, indices over the feature dimension of a feature matrix are marked with a tilde (e.g. elements of a feature matrix are marked with a hat (e.g.  X  t ).
After we have presented the model equation (4), we now show how to learn the model parameters  X  C ,  X  U ,  X  First we discuss the optimization criterion and afterwards we derive an algorithm for the optimization task.
For finding the  X  X est X  model parameters an optimization criterion has to be defined. Usually tensor factorization models (like HOSVD) are learned by minimizing an element-wise loss on the elements of  X  Y  X  e.g. by optimizing the square loss: For this minimization task, one can use standard HOSVD or square-loss implementations like [6, 8], because the data Y is assumed to be dense. Such an optimization uses the  X 0/1 interpretation scheme X  (see section 3.2). As we have argued before this scheme misinterprets the semantics of the data as it does not handle missing values, suffers from sparsity in terms of domination of zero values and does not optimize for ranking quality.

Instead we propose another optimization criterion that uses the  X  X ost-based ranking interpretation X  and maximizes the ranking statistic AUC (area under the ROC-curve). The quality measure AUC (or Mann-Whitney statistic) for a given post of user u for item i is defined as:
AUC(  X   X ,u,i ) := where H  X  is the Heaviside function: The overall optimization task with respect to the ranking statistic AUC and the observed data is then: With this optimization (i) missing values are taken into ac-count because the maximization is only done on the observed posts P S and (ii) the model is optimized for ranking. In all, this criterion takes into account all obeservations of section 3.2.
The optimization criterion presented so far will lead to the best value given the training data. With high feature dimensions (i.e. high k U , k I , k T ) an arbitrary small error on the training data can be achieved. In general we are not interested in a low error for the already observed data but in a low error over unseen data. Minimizing the training error for models with a large number of parameters will lead to overfitting, i.e. a small training error but a large error over new/ unseen data. A common way to prevent this is to regularize the optimization criterion. Regularization is Adding a regularization objective to the optimization task in formula (7) leads to the following objective: argmax Where  X  C and  X  are the regularization parameters for the core tensor and the feature matrices respectively. || X || 2 the Frobenius norm.
Next we present an algorithm to solve the optimization problem of formula (8). Obviously, optimizing (8) directly is infeasible. Instead we use gradient descent to minimize the objective function. As the AUC is not differentiable because of the Heaviside function, we replace H like in [1] by the s-shaped logistic function s : The overall algorithm can be found in figure 5. This al-gorithm uses a stochastic update approach, that means for each post ( u,i )  X  P S the model parameters are updated.
For using gradient descent, AUC has to be differentiated with respect to all model parameters. First of all, the deriva-tive of AUC given a post ( u,i )  X  P S can be simplified for all model parameters x : with:  X  y Hence, the derivative of the core tensor features is: For the feature matrices U and I the derivatives are as fol-lows:  X  AUC  X  AUC  X   X  For the tags the updates depend on whether a tag t is posi-tive or negative:
Higher order singular value decomposition (HOSVD) [7] is another method for learning a tensor factorization model. HOSVD targets to create an optimal reconstruction of a ten-sor Y using the model equation (3). Even though HOSVD 1: procedure LearnRTF ( S, X , X , X  C ) 2: initialize  X   X  := (  X  C ,  X  U ,  X  I ,  X  T ) 3: repeat 4: for ( u,i )  X  P S do 5: for (  X  u,  X  i,  X  t )  X  k u  X  k i  X  k t do 7: end for 8: for  X  u  X  1 ,...,k u do 10: end for 11: for  X  i  X  1 ,...,k i do 13: end for 14: for t  X  1 ,..., | T | do 15: for  X  t  X  1 ,...,k t do 17: end for 18: end for 19: end for 20: until stopping criterion met 21: return  X   X  22: end procedure Figure 5: Learning RTF models by gradient descent with learning rate  X  and regularization  X  and  X  C . is a good method for the task of reconstruction tensors, for the task of personalized ranking HOSVD has three major drawbacks to RTF: 1. HOSVD cannot deal with missing values. For tag rec-2. HOSVD optimizes for minimal element-wise error. But 3. HOSVD has no regularization. For machine learn-There are also other related tensor factorization methods similar to HOSVD like iterative least-square error minimiza-tion [8], that also suffer from the same problems discussed above. In all HOSVD for tag recommendation tries to op-timize the  X 0/1 interpretation scheme X  (see section 3.2). Be-sides this theoretical analysis, in our evaluation we will show that RTF largely outperforms HOSVD.
One of the benefits from a factorization model like RTF or HOSVD is that after a model is built, predictions only rely on the model. This leads to faster prediction runtime than with models like FolkRank. In the following, we look into the runtime of RTF models in detail and show how to speed them up.
Formula (1) shows the general way to predict a top-n list of tags for a specific user u and item i . For predicting  X  y of users U and items I . with a factorization model, formula (4) is used. The runtime complexity for equation (4) is O ( k U  X  k I  X  k T ) and thus the trivial upper bound of the runtime for predicting a top-n list be improved largely by reordering the sums in formula (4): When making a top-n prediction for user u and item i in-stead of computing (4) for each tag, an intermediate re-sult  X  t u,i  X  t can be computed first in O ( k U  X  k top-n prediction can then be made using this intermedi-ate result and the total runtime of predicting top-n is then O ( | T | X  k T + k U  X  k I  X  k T ). Thus the runtime for prediction with a factorization model is independent of the number of users, items and observations S . It only depends on the dimensions of the factorization and the number of tags.
The complexity of learning a RTF model (see figure 5) is of iterations. This is because the runtime is dominated by the update of tag features. Also here by rearranging the sums for the gradients and storing intermediate results, one can achieve a better runtime. We suggest to calculate the intermediate vector v  X  t which then can be used in the gradient for  X  U ,  X  I and  X  C : This vector can be calculated in O ( | T + | X | T  X  | X  k T this definitions, the gradients can be simplified to: So in total, the runtime for these updates is in O ( | T + k T + k U  X  k I  X  k T ).

Similarly, the updates for T can be simplified by calculat-ing the intermediate vector q  X  t in O ( k T  X  k U  X  k I Now the updates for the tag feature matrices can be calcu-lated in a total runtime of O ( k T  X | T | 2 + k U  X  k I  X  k the formulas: In all, learning an RTF model can be implemented in O ( iter  X  | P
S | X  ( k T  X | T | 2 + k U  X  k I  X  k T )).
We compare the runtime complexity of our RTF method to the state-of-the-art tag recommendation method FolkRank [4]. J  X  aschke et al. [5] have proven that the runtime com-plexity for top-n predictions with FolkRank is O ( iter  X  ( | S | + ations. That means for predicting a personalized top-n list, FolkRank has to pass several times the whole database of observations. When we compare this to RTF with complex-a much better runtime complexity as they only depend on the small dimensions of the factorization and on the number of tags. The only advantage of FolkRank over RTF w.r.t. runtime is that it does not have a training phase. But as training is usually done offline, this does not affect the appli-cability of RTF for fast large-scale tag recommendation. In our evaluation chapter we will give an empirical comparison of the prediction runtime of FolkRank and RTF.
We investigate the performance of RTF both in predic-tion quality and runtime compared to the other state-of-the-art tag recommendation algorithms HOSVD, FolkRank and PageRank. We evaluate our RTF method on the BibSonomy and Last.fm dataset from [4]. As in [4, 5, 14] we use a p-core for BibSonomy the 5-core and for last.fm the 10-core. The dataset characteristics of the p-cores are:
The p-core of S is the largest subset of S with the property that every user, every item and every tag has to occur in at least p posts.
We use the common evaluation protocol for tag-recom-mender of predicting posts [5]. For each user in the dataset we remove all triples S test he has given for one item  X  i.e. we remove one post for each user. The remaining observed user-item-tag triples are the training set S train := S \ S Then we learn the models on S train and predict top-N lists for each of the removed posts P S test . We measure the recall and precision of the top-1, top-2 to top-10 lists of each post and report for each top-N level (1 to 10) the F1-measures of the average recall and precision:
Prec( S test ,N ) := avg Recall( S test ,N ) := avg We choose F1-Measure on top-n lists as the main quality measure so that the results can be directly compared to related work like [5]. Additionally, we also report the related measure AUC for the RTF models. All experiments are repeated 10 times and we report the mean of the runs. For each run, we use exactly the same train/ test splits as in [5].
We run RTF with ( k u ,k i ,k t )  X  dimensions. The corresponding model is called  X  X TF 8 X ,  X  X TF 16 X , and so on. The other hyperparameters are: learning rate  X  = 0 . 5 for BibSonomy and  X  = 0 . 1 for Last.fm; regularization  X  =  X  c = 10  X  5 for BibSonomy and  X  =  X  c = 10  X  6 for Last.fm; iterations iter = 500 for BibSonomy and iter = 600 for Last.fm. The model parameters  X   X  are initialized with small random values drawn from the normal distribution N (0 , 0 . 1).

For FolkRank and PageRank we report the values obtained by [5] as we use the same datasets and splits. For HOSVD we have a dimensionality of ( k u ,k i ,k t ) = (60 , 105 , 225) for BibSonomy and ( k u ,k (875 , 556 , 614) for Last.fm. As with FolkRank and Page-Rank, all hyperparameters were optimized on one split and then used for all the other splits.

For the runtime comparison for prediction we used a C++ implementation of Folkrank and an Object-Pascal imple-mentation of RTF.
Both the datasets and the implementations of all algo-rithms of our experiments are publicly available for research purposes. The BibSonomy dataset we used is available from the University of Kassel [4]. We will provide our Last.fm dataset upon request by email. FolkRank and PageRank is provided by the University of Kassel within the Nepomuk project 4 . The HOSVD of our experiments [6] is available as Mathlab package 5 . Our RTF implementation is available upon request by email. http://dev.nepomuk.semanticdesktop.org/download/ http://csmr.ca.sandia.gov/~tgkolda/TensorToolbox/ Figure 9: Runtime comparison for predicting one ranked list of tags for the small BibSonomy and the larger Last.fm dataset. FolkRank is compared to RTF with an increasing number of dimensions. On small datasets FolkRank X  X  runtime is feasible but on larger datasets it gets impractical. In contrast to this RTF only depends on the factorization dimen-sions and not on the size of the dataset. In the following, we discuss the results of our evaluation. Figure 7 shows a qualitative comparison of the state-of-the-art models FolkRank, HOSVD and PageRank to our model class RTF. There you can see that RTF models with a suf-ficient number of dimensions (e.g. 64) outperform all other models in quality. In figure 8 you can see the increasing AUC quality of RTF models with an increasing number of dimen-sions. Finally figure 9 compares the prediction runtime of FolkRank to the runtime of RTF models. When comparing the prediction quality of RTF and FolkRank (figure 7) one can see that high dimensional RTF models outperform FolkRank on both datasets in quality. On BibSonomy RTF with 64/ 128 dimensions achieves com-parable results whereas on the larger Last.fm dataset already 32 dimensions clearly outperform FolkRank in quality.
An empirical runtime comparison for predicting a ranked can see, the runtime of the RTF model is dominated by the dimension of the factorization and is independent of the size of the dataset. The runtime on the BibSonomy dataset and the 20 times larger Last.fm dataset are almost the same  X  e.g. for RTF64 10.4 ms for BibSonomy and 12.4 ms for Last.fm. With smaller factorization, the number of tags has a larger influence on the runtime  X  e.g. for RTF16 it is 0.3 ms vs. 1.1 ms. For the very large factorization of RTF128 and the very small dataset of BibSonomy, the runtime of RTF is worse than that of Folkrank (82.1 ms vs 19.1 ms). The reason is that the runtime of FolkRank depends on the size of the dataset  X  i.e. the observations S  X  and on the very small BibSonomy dataset that leads to a reasonable runtime but already for the larger Last.fm dataset the runtime of FolkRank is not feasible any more for real-time predictions. All these empirical results match the theoretical complexity analysis we presented in section 4.4.3.

Another major advantage of RTF is that the tradeoff be-tween quality and speed can be chosen by controlling the number of dimensions. That means depending on the ap-plication one can chose if runtime is more important than quality and thus reduce the number of dimensions. With FolkRank you cannot control this tradeoff.

The only drawback of RTF to FolkRank is that it needs a training phase. But training is usually done offline and for online updating a factorization model there are very promis-ing results for the related model class of regularized matrix factorization [9].
The prediction quality of RTF is clearly superior to the one of HOSVD (figure 7). On BibSonomy even with a very small number of 8 dimensions, RTF achieves almost similar results as HOSVD with a dimensionality of (60 , 105 , 225) and (875 , 556 , 614) respectivly. Increasing the dimensions of RTF to 16 dimensions already largely outperforms HOSVD in quality. Note that for Last.fm this means that for HOSVD there are 298 , 711 , 000 parameters to learn in the core tensor  X  whereas for RTF8 there are only 512 and for RTF16 only 4 , 096 parameters. The empirical qualitative results match our discussion about the data interpretation in section 3.2.
Even though RTF and HOSVD have the same predic-tion method and thus prediction complexity, in practice RTF models are much faster in prediction than compara-ble HOSVD models, because RTF models need much less dimensions than HOSVD for achieving better quality.
A final problem with HOSVD is that we found it to be very sensitive for the number of dimensions and that they have to be chosen carefully. Also HOSVD is sensitive to the relations between the user, item and tag dimensions  X  e.g. choosing the same dimension for all three dimensions leads to poor results. In contrast to this, for RTF we can choose the same number of dimensions for user, item and tags. Furthermore for RTF, by increasing the number of dimensions we get better results. We expect this behaviour due to the regularization of RTF models.
In a last experiment, we compare the prediction quality of personalized tag recommenders to the best possible non-personalized tag recommender, i.e. the theoretical upper bound for n on-p ersonalized tag recommender np max (see fig-ure 7). The weighting method for np max is: Please note that in practice  X  y np max cannot be applied as S bound for non-personalized recommenders because it creates the best non-personalized top-n list for the test set S test ery other method for non-personalized tag recommendation like [2, 13, 12] is guaranteed to have a lower (or in the best case the same) quality on S test . As you can see in figure 7, personalized tag recommenders like FolkRank, RTF32 and RTF64 outperform np max the theoretical upper bound for non-personalized tag recommendation 6 . That means, in ap-plications, where there is personalized information present, personalized tag recommender are supposed to outperform non-personalized tag recommender.
In this paper, we have presented a new optimization cri-terion for tensor factorization for the task of ranking with missing values. Our optimization is motivated theoretically by a proper interpretation of observed and non-observed
Evaluating np max on the small BibSonomy dataset makes no sense because in the test sets S test of BibSonomy are rarely two posts with the same item. increased from 8 to 128 and 64 respectively. data. It can handle both missing values and pairwise rank-ranking instead of optimizing for minimal element-wise error like in other tensor factorization algorithms (e.g. HOSVD). For our proposed optimization task, we have presented an optimization algorithm based on gradient descent. In our evaluation we have shown that this algorithm largely out-performs HOSVD in quality  X  even with much less factor-ization dimensions which leads to higher prediction speed than HOSVD. Furthermore we have shown that our method is also able to outperform other state-of-the-art tag recom-mendation algorithms like FolkRank and PageRank in qual-ity and largely in prediction runtime.

In future work, we want to study the isolated effect of each single improvement over HOSVD, namely data inter-pretation, regularization and AUC optimization.
 This work is partially co-funded through the European Com-mission FP7 project MyMedia (www.mymediaproject.org) under the grant agreement no. 215006. Leandro Balby Marinho is supported by the Brazilian National Council for Scientific and Technological Research (CNPq). [1] A. Herschtal and B. Raskutti. Optimising area under [2] P. Heymann, D. Ramage, and H. Garcia-Molina.
 [3] A. Hotho, R. J  X  aschke, C. Schmitz, and G. Stumme. [4] R. J  X  aschke, L. Marinho, A. Hotho, [5] R. J  X  aschke, L. Marinho, A. Hotho, [6] T. G. Kolda and J. Sun. Scalable tensor [7] L. D. Lathauwer, B. D. Moor, and J. Vandewalle. A [8] L. D. Lathauwer, B. D. Moor, and J. Vandewalle. On [9] S. Rendle and L. Schmidt-Thieme. Online-updating [10] J. D. M. Rennie and N. Srebro. Fast maximum margin [11] A. Shashua and T. Hazan. Non-negative tensor [12] Y. Song, L. Zhang, and C. L. Giles. A sparse gaussian [13] Y. Song, Z. Zhuang, H. Li, Q. Zhao, J. Li, W.-C. Lee, [14] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos.
