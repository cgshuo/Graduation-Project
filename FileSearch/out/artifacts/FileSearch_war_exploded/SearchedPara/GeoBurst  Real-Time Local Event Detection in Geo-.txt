 The real-time discovery of local events ( e.g. , protests, crimes, dis-asters) is of great importance to various applications, such as crime monitoring, disaster alarming, and activity recommendation. While this task was nearly impossible years ago due to the lack of timely and reliable data sources, the recent explosive growth in geo-tagged tweet data brings new opportunities to it. That said, how to extract quality local events from geo-tagged tweet streams in real time re-mains largely unsolved so far.

We propose G EO B URST , a method that enables effective and real-time local event detection from geo-tagged tweet streams. With a novel authority measure that captures the geo-topic correlations among tweets, G EO B URST first identifies several pivots in the query window. Such pivots serve as representative tweets for potential local events and naturally attract similar tweets to form candidate events. To select truly interesting local events from the candidate list, G EO B URST further summarizes continuous tweet streams and compares the candidates against historical activities to obtain spa-tiotemporally bursty ones. Finally, G EO B URST also features an updating module that finds new pivots with little time cost when the query window shifts. As such, G EO B URST is capable of mon-itoring continuous streams in real time. We used crowdsourcing to evaluate G EO B URST on two real-life data sets that contain millions of geo-tagged tweets. The results demonstrate that G EO B nificantly outperforms state-of-the-art methods in precision, and is orders of magnitude faster.
 Twitter; tweet; local event; event detection; social media
A local event ( e.g. , protest, crime, disaster, sport game) is an un-usual activity bursted in a local area and within specific duration while engaging a considerable number of participants. The real-time detection of local events was nearly impossible years ago due to the lack of timely and reliable data sources, yet the recent ex-plosive growth in geo-tagged tweet data brings new opportunities to it. With the ubiquitous connectivity of wireless networks and the wide proliferation of mobile devices, more than 10 million geo-tagged tweets are created in the Twitterverse every day [1]. Each geo-tagged tweet, which contains a text message, a timestamp, and a geo-location, provides a unified 3W ( what, when , and where ) view of the user X  X  activity. Even though the geo-tagged tweets ac-count for only about 2% of the entire tweet stream [16], their sheer size, multi-faceted information, and real-time nature make them an invaluable source for detecting local events. For example, when the tragic 2011 Tohoku Earthquake hit Japan on March 11th 2011, thousands of related geo-tagged tweets were created instantly; and when the Baltimore Riot took place in April 2015, many people posted geo-tagged tweets to broadcast it right on the spot.
We aim to achieve real-time local event detection from geo-tagged tweet streams. This task is important as it can underpin various ap-plications. Take disaster alarming as an example. By detecting emergent disasters ( e.g. , earthquakes, fires) in real time, we can send alarms to the populace at the very first moment when these disasters outbreak. Such alarms can be much faster than tradi-tional news media [9, 24, 30], and thus allow for timely response that avoids huge life and economic losses. As another example, the detected local events can be easily filtered by a few keywords for activity recommendation. Consider a user who is interested in sport games, movies, and music festivals. With proper filtering keywords, the detector can continuously feed the user with such activities in the city. As such, she can easily learn about what is happening around and decide what to do.

Despite its practical importance, real-time local event detection in the geo-tagged tweet stream is nontrivial because it introduces several unique challenges: (1) Integrating diverse types of data. The geo-tagged tweet stream involves three different data types: location, time, and text. Considering the totally different represen-tations of those data types and the complicated correlations among them, how to effectively integrate them for local event detection is challenging. (2) Extracting interpretable events from overwhelm-ing noise. Existing studies have revealed that about 40% tweets are just pointless babbles [2], and even those event-related tweets are mostly short and noisy. As truly interesting local events are buried in massive irrelevant tweets, it is nontrivial to accurately identify them and describe in an interpretable way. (3) On-line and real-time detection. When a local event outbreaks, it is key to report the event instantly to allow for timely actions. As massive geo-tagged tweets stream in, the detector should work in an on-line and real-time manner instead of a batch-wise and inefficient one.
A number of studies [6, 12, 13, 28, 17, 5] have investigated event detection in Twitter. Although these techniques have demonstrated inspiring results in detecting global events, they are inapplicable to detecting local events. Unlike global events that are bursty in the entire stream, local events are  X  X ursty X  in a small geographical region and involve a limited number of tweets. Such local bursts cannot be readily captured by global event detection methods. Re-cently, a few methods tailored for local event detection [15, 10, 7, 3] have been introduced. The state-of-the-art method E VEN [3] extracts the keywords that are both temporally bursty and spa-tially localized, and then clusters those keywords into events based on spatial distributions. Unfortunately, the quality of the result events is limited because it does not model the semantic correla-tions between keywords. Furthermore, E VEN T WEET cannot detect local events in real time, because it partitions the stream into fixed-width time windows and the detection is triggered only when the current window is saturated.

We propose G EO B URST , an effective and real-time local event detector. Our key insight is that, a local event usually leads to a con-siderable number of geo-tagged tweets around the occurring place ( e.g. , many participants of a protest may post tweets on the spot). As such tweets are geographically close and semantically coherent, we call them a geo-topic cluster and consider it as a potential lo-cal event. Nevertheless, not necessarily does every geo-topic clus-ter correspond to a local event because (1) the activity could be just routine in that region instead of an unusual event, e.g. , many shopping-related tweets are posted on the 5th Avenue in New York every day; and (2) the activity may be geographically scattered in-stead of localized, e.g. , a popular TV show may result in several geo-topic clusters in different regions. Hence, we should also care-fully measure the spatiotemporal burstiness of each geo-topic clus-ter to identify true local events.

Motivated by the above, the first step of G EO B URST finds all geo-topic clusters in the query window as candidate events. Specif-ically, we compute a tweet X  X  geo-topic authority by combining the geographical and semantic contributions from its similar tweets, where the geographical side is measured using a kernel function, and the semantic side is captured using random walk on a keyword co-occurrence graph. We then design an authority ascent process to identify all pivot tweets, which are essentially authority maxima in the geo-topic space. Such pivot tweets naturally attract similar tweets to form geo-topic clusters.

The second step of G EO B URST ranks all the candidates based on spatiotemporal burstiness. For this purpose, we continuously summarize the stream and store the summaries in a space-efficient structure called activity timeline. The stored summaries, which de-scribe the typical activities in different regions, serve as background knowledge to measure the spatiotemporal burstiness of geo-topic clusters and select out local events.
 Besides extracting local events from an ad-hoc query window, G
EO B URST also features an updating module that enables contin-uous monitoring of the stream. As new geo-tagged tweets stream in, G EO B URST can shift the query window and update the results in real time. The updating incurs little time cost because authority computation, which is the most time-consuming operation in the framework, can be completed by subtracting the contributions of outdated tweets and emphasizing the contributions of new ones.
To summarize, we make the following contributions: 1. We design G EO B URST for local event detection in the geo-2. With the additive property of the authority score, we design 3. We perform extensive experiments on millions of geo-tagged Global Event Detection. Global event detection aims at extracting events that are bursty and unusual in the entire tweet stream. Ex-isting approaches to this end can be classified into two categories: document-based and feature-based .

Document-based approaches consider each document as a basic unit and group similar documents to form events. Allan et al. [6] perform single-pass clustering of the stream, and use a similarity threshold to determine whether a new document should form a new topic or be merged into an existing one. Aggarwal et al. [5] also detect events by continuously clustering the tweet stream, but their similarity measure considers both tweet content relevance and user proximity. Sankaranarayanan et al. [25] train a Na X ve Bayes filter to identify news-related tweets, and cluster them based on TF-IDF similarity. They also enrich each piece of news with location infor-mation by extracting geo-entities.

Feature-based approaches [12, 13, 21, 28, 17] identify a set of bursty features ( e.g. , keywords) from the stream and cluster them into events. Fung et al. [12] model feature occurrences with bino-mial distribution to extract bursty features. He et al. [13] construct the time series for each feature and perform Fourier Transform to identify bursts. Weng et al. [28] use wavelet transform and auto-correlation to measure word energy and extract high-energy words. Li et al. [17] segment each tweet into meaningful phrases and ex-tract bursty phrases based on frequency, which are clustered into candidate events and further filtered using Wikipedia.

The above methods are all designed for detecting global events that are bursty in the entire stream. As aforementioned, a local event is usually bursty in a small geographical region instead of the entire stream. Hence, directly applying these methods to the geo-tagged tweet stream would miss many local events.

There has also been work [24, 22, 19] on detecting specific types of events. Sakaki et al. [24] investigate real-time earthquake detec-tion. A classifier is trained to judge whether an incoming tweet is related to earthquake or not, and an alarm is released when the num-ber of earthquake-related tweets is large. Li et al. [19] detect crime and disaster events (CDE) with a self-adaptive crawler that dynam-ically retrieves CDE-related tweets. Different from those studies, we aim to detect all kinds of local events from the stream. Local Event Detection. Foley et al. [11] use distant supervision to extract local events from Web pages, but the proposed method can only extract local events that are well advertised in advance on the Web. Watanabe et al. [27] and Quezada et al. [23] study location-aware events in the social media, but their major focus is on geo-locating tweets/events, whereas we aim to automatically extract local events from raw geo-tagged tweets.

Krumm et al. [15] propose the detection of spatiotemporal spikes in the tweet stream as local events. Nevertheless, their approach can only detect events for pre-defined rigid time windows ( e.g. , 3-6 pm, 6-9 pm), because it discretizes time and compares the number of tweets in the same bin across different days. It supports neither ad-hoc query windows nor real-time detection.
 Chen et al. [7] extract events from geo-tagged Flickr photos. By converting the spatiotemporal distribution of each tag into a 3-dimensional signal, they perform wavelet transform to extract spa-tiotemporally bursty tags, and clusters those tags into events based on co-occurrence as well as spatiotemporal distributions. Such a method, however, can only detect local events in batch manner. The most relevant work to our task is by Abdelhaq et al. [3]. They propose E VEN T WEET , which detects local event in a time window with four steps: (1) examine several previous windows to extract bursty words; (2) compute the spatial entropy of each bursty word and select localized words; (3) cluster localized words based on spatial distribution; and (4) rank the clusters based on features such as burstiness and spatial coverage. Unfortunately, E
VEN T WEET suffers from two drawbacks. First, the clustering of localized keywords is merely based on spatial distribution without considering tweet content. It results in irrelevant keywords in the same cluster, and cannot distinguish different events that occur at the same location. Second, although E VEN T WEET is an online method, it is incapable of detecting local events in real time, as the detection is triggered only when the current window is saturated.
In this section, we formulate the real-time local event detection problem, and then explore several of its characteristics, which mo-tivate the design of G EO B URST .
 Problem description. Let D = ( d 1 ,d 2 ,...,d n ,... ) be a continu-ous stream of geo-tagged tweets that arrive in chronological order. Each tweet d is a tuple  X  t d ,l d ,E d  X  , where t d is its post time, l its geo-location, and E d is a bag of keywords. For each tweet, we use an off-the-shelf tool 1 to extract entities and noun phrases as its keywords. Note that such preprocessing does not affect the gener-ality of our method, and one can also represent each tweet message as a bag of uni-grams for simplicity.

Consider a query time window Q = [ t s ,t e ] where t s and t the start and end timestamps satisfying t d 1  X  t s &lt; t local event detection problem consists of two sub-tasks: (1) extract from D all the local events that occur during Q ; and (2) monitor the continuous stream D and update the local event list in real time as Q shifts continuously.
 G
EO B URST overview. In practice, a local event often results in a considerable number of relevant tweets around its occurring loca-tion. Take Figure 1 as an example. Suppose a protest occurs on the 5th Avenue in New York, many participants may post tweets on the spot to express their attitude, with keywords such as  X  X rotest X  and  X  X ights X . We call such a set of tweets a geo-topic cluster as they are geographically close and semantically coherent.
Nevertheless, not necessarily does every geo-topic cluster cor-respond to a local event even if the cluster has a large size. First, https://github.com/aritter/twitter_nlp the activity can be just routine in that region. Continue with the example in Figure 1. On almost every day, we can observe many shopping-related tweets on the 5th Avenue. Although such tweets also form a geo-topic cluster, they do not reflect any unusual activ-ities. Second, the cluster may correspond to a global event instead of a local one. For instance, when a popular TV show like  X  X ame of Thrones X  goes online, we can observe geo-topic clusters dis-cussing about it in different regions. Such geo-topic clusters do not correspond to local events as well. We thus define a local event as a geo-topic cluster that shows clear spatiotemporal burstiness .
Based on the above observations, we first detect all geo-topic clusters in the query window and regard them as candidates  X  this step ensures high coverage of the underlying local events. The dis-covery of geo-topic clusters, however, poses several challenges: how to combine the geographical and semantic similarities in a reasonable way? how to capture the correlations between differ-ent keywords? and how to generate quality clusters without know-ing the suitable number of clusters in advance? To address these challenges, we perform a novel pivot seeking process to identify the centers of geo-topic clusters. Our key insight is that: the spot where the event occurs acts as a pivot that produces relevant tweets around it; the closer we are to the pivot, the more likely we observe relevant tweets. Therefore, we define a geo-topic authority score for each tweet, where the geographical influence among tweets is captured by a kernel function, and the semantic influence by a ran-dom walk on a keyword co-occurrence graph. With this authority measure, we develop an authority ascent procedure to retrieve au-thority maxima as pivots; and each pivot naturally attracts similar tweets to form a quality geo-topic cluster. After discovering the candidate events, we rank them by spatiotemporal burstiness. To this end, we continuously cluster the stream to obtain summaries of regional activities at different timestamps, and store the sum-maries in a space-efficient structure called activity timeline. The stored summaries serve as background knowledge that enables us to measure the spatiotemporal burstiness of any candidate.
G EO B URST also includes a module that updates the result list in real time as the query window shifts. It will be shown shortly that, the authority score satisfies an additive property. Hence, instead of finding new pivots from scratch when the query window shifts, we can identify them by simply updating the authority scores and then performing fast authority ascent.

We summarize the framework of G EO B URST in Figure 2. As shown, G EO B URST offers two detection modes. The first is the batch mode, which uses the candidate generator and the ranker to detect local events in a fixed query window. The second is the online mode, at the core of which is an updater that updates pivots in real time as the query window shifts. Meanwhile, the ranker is underpinned by the activity timeline structure, which continuously summarizes the stream to obtain background knowledge.

In this section, we describe the batch mode of G EO B URST aforementioned, given a query window Q, the batch mode detects local events in Q by first generating geo-topic clusters as candidate events, and then ranking the candidates by spatiotemporal bursti-ness. In the sequel, we present the details of these two steps in Sections 4.1 and 4.2, respectively.
Let D Q be the set of tweets falling in Q . The task of candidate generation is to divide D Q into several geo-topic clusters, such that the tweets in each cluster are geographically close and semanti-cally coherent. As motivated in Section 3, our idea is to view the occurring spot of an event as a pivot and assign each tweet to its corresponding pivot. Below, we introduce a novel geo-topic au-thority score to define pivot , and then develop an authority ascent procedure for pivot seeking. Geographical impact. Given two tweets d and d 0 , we measure the geographical impact of d 0 to d as where K (  X  ) is a kernel function, k l d  X  l d 0 k is the geographical distance between d and d 0 , and h is the kernel bandwidth. While various kernel functions can be used, we choose the Epanechnikov kernel here due to its simplicity and optimality in terms of bias-variance tradeoff [8]. With the Epanechnikov kernel, G ( d becomes
G ( d 0  X  d ) = c (1  X  X  l d  X  l d 0 k where c is a scaling constant of the Epanechnikov kernel. Semantic impact. As each tweet message is represented by a bag of keywords, a very straightforward idea for measuring semantic impact is to compute the vector similarity between two tweet mes-sages. Nevertheless, the effectiveness of vector similarity is lim-ited, not only because tweets are short in nature, but also that the dimensions (keywords) are correlated instead of independent. To overcome these drawbacks, we propose a random-walk-based ap-proach to capture semantic impact more effectively.
 keyword co-occurrence graph for D Q is an undirected graph G = ( V,E ) where: (1) V is the set of all keywords in D Q ; and (2) E is the set of edges between keywords, and the weight of an edge ( e ,e j ) is the number of tweets in which e i and e j co-occur. The keyword co-occurrence graph can be easily built from D With such a graph, we employ random walk with restart (RWR) to define keyword similarity, as it uses the holistic graph structure to capture node correlations. Consider a surfer who starts RWR from the keyword x 0 = u . Suppose the surfer is at keyword x at step t , she returns to u with probability  X  (0 &lt;  X  &lt; 1) and continues surfing with probability 1  X   X  . If continuing, she ran-domly moves to i  X  X  neighbor j with probability P ij , where P is the transition matrix of the graph. The stationary distribution of such a process defines the RWR scores from u to all the keywords in V , and the score from u to keyword v , denoted as r u  X  v probability that the surfer resides on v .

Now, given two tweets d and d 0 , we start RWR from the key-words of d 0 , and define the semantic impact of d 0 to d as the av-erage probability that the random walk resides on d [20, 29]. For-mally, let E d = { e 1 ,e 2 ,...,e m } be the keyword set of d , and E 0 = { e 0 1 ,e 0 2 ,...,e 0 n } the keyword set of d 0 , then the semantic impact from d 0 to d is Geo-topic authority. Based on geographical and semantic im-pacts, we measure the geo-topic authority of a tweet as follows.
D EFINITION 2 (N EIGHBOR ). Given a tweet d , we say d 0 is a neighbor of d if d 0 satisfies G ( d 0  X  d ) &gt; 0 and S ( d where 0 &lt;  X  &lt; 1 is a pre-specified threshold.
 D EFINITION 3 (A UTHORITY ). Given a tweet d  X  D Q , let N ( d ) be the set of d  X  X  neighbors in D Q . The authority of d is
Given a tweet d , d 0 is a neighbor of d if it resembles d both geographically and semantically. The set of all neighbors in D form d  X  X  neighborhood and contribute to d  X  X  authority. We could interpret Equation 2 as follows: an amount of G ( d 0  X  d ) energy is distributed from d 0 to d through random walk on the graph, G ( d d )  X  S ( d 0  X  d ) is the amount that successfully reaches d ; and d  X  X  authority is the total amount of energy that d receives from its neighbors.
 Pivot. With Definition 3, we define a pivot as an authority maxi-mum.

D EFINITION 4 (P IVOT ). Given a tweet d  X  D Q and its neigh-borhood N ( d ) , d is a pivot if A ( d ) = max
Consider a local event that occurs at location l . If d is a tweet discussing about that event at l , then d is likely to be surrounded by relevant tweets to become the pivot for that event. The notion of neighborhood plays an important role in Definition 4: it ensures the supporting tweets are both geographically close and semantically relevant. This property leads to different pivots that can distinguish different-semantics events happening at the same location, as well as same-semantics events happening at different locations.
Now our task is to find all pivots in D Q and assign each tweet to its corresponding pivot. We develop an authority ascent procedure for this purpose. As shown in Figure 3, starting from a tweet d as the initial center, we perform step-by-step center shifting. As-suming the center at step t is tweet d t , we find d t  X  X  neighborhood N ( d t ) , and the local pivot l ( d t )  X  the tweet having the largest authority in N ( d t ) . Then we regard l ( d t ) as our new center, i.e. , d t +1 = l ( d t ) . As we continue such an authority ascent process, the center is guaranteed to converge to an authority maximum. It is because every shift operation increases the authority of the current center, and the authority is upper bounded (there are only a finite number of tweets in D Q ).
 Candidate Event Generation. Algorithm 1 depicts the process of finding the pivot for every tweet in D Q . As shown, we first compute the neighborhood for each tweet d  X  D Q (lines 1-2). Subsequently, we compute the authority of each tweet (lines 3-4), and obtain its local pivot (lines 5-6). So long as the local pivots are obtained, we perform authority ascent to identify the pivot each tweet belongs to. Finally, the tweets having the same pivot are grouped into one geo-topic cluster and returned as a candidate event. Algorithm 1: Pivot seeking.

Input : The tweet set D Q , the kernel bandwidth h , the
Output : The pivot for each tweet in D Q . // Neighborhood computation. foreach d  X  D Q do 2 N ( d )  X  X  d 0 | d 0  X  D Q ,G ( d 0  X  d ) &gt; 0 ,S ( d // Authority computation. foreach d  X  D Q do 4 A ( d )  X  d  X  X  authority score computed from N ( d ) ; // Find local pivot for each tweet. foreach d  X  D Q do 6 l ( d )  X  arg max // Authority ascent. foreach d  X  D Q do 8 Perform authority ascent to find the pivot for d ; Fast RWR score computation. In Algorithm 1, while it is easy to compute geographical impact based on tweet location, the chal-lenge is how to compute semantic impact efficiently. A na X ve idea is to obtain the RWR score between any two keywords, but such an idea is not efficient as the keyword co-occurrence graph can be large. To address this challenge, we leverage the locality of RWR: given a keyword q , we observe that only a limited number of key-words falling in q  X  X  vicinity have large values, while most keywords have extremely small RWR scores. We thus introduce the concept of keyword vicinity , which keeps only large enough RWR scores by exploring a small neighborhood around q . Below, we demonstrate how to fast compute the keyword vicinity based on the Decompo-sition Theorem [14].

T HEOREM 1. For a keyword u , let O u be the set of u  X  X  out-neighbors in G . Given a keyword q , the RWR from u to q satisfies
Theorem 1 says that, the RWR from u to q can be derived by lin-early combining the RWR scores of u  X  X  out-neighbors, with extra emphasis on q itself. With this theorem, we use a local computation algorithm [20] to obtain q  X  X  vicinity. Starting from an initial vicin-ity, we gradually expand the vicinity and propagate RWR scores among the keywords falling inside. The RWR approximation be-comes tighter and tigher as the vicinity expansion continues, and terminates when an error bound (0 &lt;  X  ) is guaranteed. Algorithm 2 depicts the detailed vicinity computation process. To compute q  X  X  vicinity, we maintain two quantities for any keyword u : (1) s ( u ) is the current RWR score from u to q ; and (2) p ( u ) is the score that needs to be propagated. We use a priority queue to keep p ( u ) for all the keywords. Every time we pop the keyword Algorithm 2: Approximate RWR score computation.

Input : The keyword co-occurrence graph G , a keyword q , the
Output : q  X  X  vicinity V q . s ( q )  X   X ,p ( q )  X   X ,V q  X   X  ;
Q  X  a priority queue that keeps p ( u ) for the keywords in G ; while Q.peek()  X   X  do 4 u  X  Q.pop(); 5 for v  X  I ( u ) do 6  X  s ( v ) = (1  X   X  ) p vu p ( u ) ; 7 s ( v )  X  s ( v ) +  X  s ( v ) ; 8 V q [ v ]  X  s ( v ) ; 9 Q.update( v , p ( v ) +  X  s ( v ) ); 10 p ( u )  X  0 ; return V q ; u that has the largest to-propagate score, and update the score and to-propagate score for each in-neighbor of u . After that, we set p ( u ) to zero to avoid redundant propagation. The algorithm termi-nates when the max element in the priority queue is less than  X  , and returns all the keywords that have non-zero RWR scores as q  X  X  vicinity. Any keyword u not in q  X  X  vicinity must satisfy r
T HEOREM 2. Let  X  r u  X  q be the approximate RWR score com-puted by Algorithm 2, then  X  r u  X  q satisfies | r u  X  q The time complexity of Algorithm 2 is O ( D q / X  log 1 / (  X  )) , where D q = P
P ROOF . See [20] for details.
Up to now, we have obtained a set of geo-topic clusters in the query window as candidate events. Nevertheless, as discussed in Section 3, not necessarily does every candidate correspond to a lo-cal event because it can be either routine in that region or a global event. In this subsection, we describe G EO B URST  X  X  ranking mod-ule, at the core of which is the activity timeline structure to facili-tate ranking candidates by spatiotemporal burstiness. In what fol-lows, we describe activity timeline construction in Section 4.2.1, and present the ranking function in Section 4.2.2.
The activity timeline aims at summarizing the stream to unveil typical activities in different regions during different time periods. For this purpose, we design a structure called tweet cluster (TC), and extend CluStream [4], an effective stream clustering algorithm.
Let S be a set of tweets that are geographically close, its TC maintains the following statistics: 1) n = | S | : the number of tweets. 2) m l = P d  X  S l d : the sum vector of locations. 3) m l 2 = P d  X  S l d  X  l d : the squared sum vector of locations. 4) m t = P d  X  S t d : the sum of timestamps. 5) m t 2 = P d  X  S t 2 d : the squared sum of timestamps. 6) m e = P d  X  S E d : the sum dictionary of keywords.

The TC essentially provides a where-when-what summary for S : (1) where: with n , m l , and m l 2 , one can easily compute the mean location and spatial variance for S ; (2) when: with n , m one can easily compute the mean time and temporal variance for S ; and (3) what: m e keeps the number of occurrences for each key-word. As we shall see shortly, those fields enable us to estimate the number of keyword occurrences at any location. Moreover, TC sat-isfies the additive property, i.e. , the fields can be easily incremented if a new tweet is absorbed. Based on this property, we adapt CluS-tream to continuously clusters the stream into a set of TCs. When a new tweet d arrives, it finds the TC m that is geographically clos-est to d . If d is within m  X  X  boundary (computed from n , m m l 2 , see [4] for details), it absorbs d into m and updates its fields; otherwise it creates a new TC for d . Meanwhile, we employ two strategies [26] to limit the maximum number of TCs: (1) deleting the TCs that are too old and contain few tweets; and (2) merg-ing closest TC pairs until the number of remaining TCs is small enough.

The activity timeline is a sequence of clustering snapshots pro-duced by CluStream at different timestamps. As storing the snap-shot of every timestamp is unrealistic, we use the pyramid time frame (PTF) structure [4] to achieve both good space efficiency and high coverage of the stream history. The PTF structure im-poses finer granularity for recent snapshots and coarser granular-ity for old ones. It involves two integer parameters: b &gt; 1 and l &gt; 0 . Given a tweet stream D , assume the start timestamp is 0 and the most recent timestamp is T . PTF creates d log b 0 , 1 ,...... log b T . Each layer i stores the snapshots for the times-tamps that can be divided by b i . If a timestamp matches multiple layers, it is stored in the highest possible layer to avoid redundancy. Further, every layer has a capacity of b l + 1 so that only the latest b + 1 snapshots are stored. As such, the total number of snapshots in PTF is no larger than ( b l + 1) d log b ( T ) e .

E XAMPLE 1. Suppose the start timestamp of the stream is 0 and the most recent timestamp is 25. Then the maximum layer in the corresponding PTF is b log 2 25 c = 4 , and the capacity of each layer is 5. The snapshots stored in different layers are: Layer 0 : 25 23 21 19 17; Layer 1 : 22 18 14 10 6; Layer 2 : 20 12 4; Layer 3 : 24 8;
Layer 4 : 16.
The snapshots stored in the activity timeline serve as background knowledge for ranking candidate events. To derive the ranking score of candidate C , we quantify the spatiotemporal burstiness of each keyword in C , and then aggregate the burstiness of all the keywords as C  X  X  final ranking score.
 Temporal burstiness. First, we measure how temporally bursty a keyword k  X  C is at the pivot location l C , by vertically comparing C against the historical activities at l C . As shown in Figure 4, we retrieve the snapshots in a reference time window R that right precedes the query window Q . Each pair of consecutive snapshots in R corresponds to a historical activity , defined as follows. two snapshots at timestamp t s 1 and t s 2 ( t s 1 &lt; t activity during the time interval [ t s 1 ,t s 2 ] is the set of TCs obtained by subtracting s 1 from s 2 .

Let us use an example in Figure 4 to illustrate how we acquire historical activities in the reference window R . As shown, the snapshots s 1 ,s 2 ,s 3 ,s 4 fall in R . For each pair of consecutive snapshots, i.e. , [ s 1 ,s 2 ] , [ s 2 ,s 3 ] , [ s 3 ,s 4 traction to obtain the historical activity during the respective time interval. For instance, for the snapshot pair [ s 1 ,s s from s 2 and obtain the historical activity, represented as a set of TCs: { m 1 ,m 2 ,m 4 ,m 6 ,m 7 ,m 8 } . Note that the subtraction of two snapshots can be easily done by matching TC ids and subtract-ing the fields. Figure 4: Retrieving historical activities from activity timeline.
Using each historical activity, we can employ kernel density es-timation to infer the expected number of occurrences of keyword k at location l C . Consider the query time window Q = [ t the historical activity in [ t 0 s ,t 0 e ] . Denote the set of TCs in [ t as { m 1 ,m 2 ,...,m n } . We estimate the number of occurrences of keyword k at location l C as: where N m i ( k ) is the number of k  X  X  occurrences in m i mean location of m i , and h is the kernel bandwidth. As R contains multiple historical activities, and each can generate an estimation of keyword k  X  X  occurrences at location l C , we obtain a set of esti-mations, denoted as  X  t = {  X  N 1 ( k ) ,  X  N 2 ( k ) ,..., use z-score to quantify k  X  X  temporal burstiness at l C : where N ( k ) is k  X  X  actual number of occurrences in C , and  X   X  t are the mean and standard deviation of  X  t .
 Spatial burstiness. To measure spatial burstiness, we horizontally compare all the candidates in Q . The rationale is that, among the spatially scattered candidates, a keyword k in candidate C is spa-tially bursty if k  X  X  proportion in C is significantly higher than in other candidates. Given n candidate events C 1 ,C 2 ,...,C denote the keyword probability distribution of candidate C  X  s = { P 1 ( k ) ,P 2 ( k ) ,...,P n ( k ) } , we compute the spatial bursti-ness of keyword k in candidate C i as: where  X   X  s and  X   X  s are the mean and standard deviation of  X  Ranking function. For each keyword k in a candidate C , we have used vertical comparison against the historical activities to mea-sure its temporal burstiness, and horizontal comparison with the other candidates to measure its spatial burstiness. As the final step, we compute the ranking score of candidate C by aggregating the burstiness of all the keywords in C : where  X  (0 &lt;  X  &lt; 1) is a factor balancing the spatial and temporal burstiness; and w C ( k ) is the TF-IDF weight of keyword k .
In this section, we present the online mode of G EO B URST sider a query window Q , let Q 0 be the new query window after Q shifts. Instead of finding local events in Q 0 from scratch, the online mode leverages the results in Q and updates the event list with little cost. The updated event list is guaranteed to be the same as directly running batch-mode detection on Q 0 .

In G EO B URST  X  X  two steps, the candidate generation step has a dominating time cost. At the core of the online mode is thus an updating module that finds new pivots in the new window Q little overhead. Let D Q be the tweets falling in Q and D tweets in Q 0 . We denote by R Q the tweets removed from D R
Q = D Q  X  D 0 Q ; and by I Q the tweets inserted into D Q I
Q = D 0 Q  X  D Q . In the sequel, we design a strategy that finds pivots in D 0 Q by just processing R Q and I Q .

Recall that, the pivot seeking process first computes the local pivot for each tweet and then performs authority ascent via a path of local pivots. So long as the local pivot information is correctly maintained for each tweet, the authority ascent can be fast com-pleted. The key to avoiding finding pivots from scratch is that, as D
Q is changed to D 0 Q , only a number of tweets have their local pivots changed. We call them mutated tweets and identify them by analyzing the influence of R Q and I Q .

D EFINITION 6 (M UTATED T WEET ). A tweet d  X  D 0 Q is a mutated tweet if d  X  X  local pivot in D 0 Q is different from its local pivot in D Q .

For any tweet, it can become a mutated tweet only if at least one of its neighbors has authority change. Therefore, we take a reverse search strategy to find mutated tweets. We first identify in D
Q all the tweets whose authorities have changed. Then for each authority-changed tweet t , we retrieve the tweets that regard t as its neighbor, and update their local pivots. Hence, the key becomes how to find authority-changed tweets. In what follows, we handle R Q and I Q to this end.
 Handling deletions. The deletion of a tweet d  X  R Q can cause authority change in two ways. First, for the tweets having d as a neighbor in D Q , their authorities decrease. Second, the keyword co-occurrence graph may evolve because of deleting d . As a result, the vicinities of certain keywords need to be recomputed and the authorities of corresponding tweets may change. The first case can be easily handled due to the additive property of authority. When d is deleted, we simply retrieve the tweets having d as a neighbor in D Q . For each of those tweets, we subtract d  X  X  contribution from the authority score. For the second case, the key is to identify the keywords that need vicinity recomputation. Let us look at an ex-ample in Figure 5. If d contains two keywords e 1 and e 2 d would decrease the weight of the edge [ e 1 ,e 2 ] . For any other keywords having e 1 or e 2 in their old vicinities ( e 3 and e example), we mark them as to-recompute keywords. However, we defer the computation of their vicinities until I Q is handled to iden-tify the complete set of to-recompute keywords. Figure 5: Updating the keyword co-occurrence graph and key-word vicinities.
 Handling insertions. A new tweet d  X  I Q can also cause authority changes in two ways: (1) increasing the authority of the tweets that regard d as a neighbor; and (2) making the keyword co-occurrence graph evolve. Here, we need to first deal with the second case to en-sure authority computation in the first case is based on the updated keyword vicinities. Similarly, we identify the keywords whose at-taching edges have weight change, and mark other keywords that include such keywords in their vicinities. After all the to-recompute keywords are identified, we call Algorithm 2 to obtain their new vicinities. Once the keyword vicinities are updated, we retrieve the affected tweet pairs and update the corresponding authority scores. For the second case, now that the keyword vicinities have already been updated, for the inserted tweet d , we simply find which other tweets having d as their neighbor, and then add d  X  X  contribution to their authorities.
We evaluate the empirical performance of G EO B URST section. All the algorithms were implemented in JAVA and the ex-periments were conducted on a computer with Intel Core i7 2.4Ghz CPU and 8GB memory. Data Set. Our experiments are based on two real-life data sets, both of which are crawled using Twitter Streaming API 2014.08.01  X  2014.11.30. The first data set, referred to as NY, consists of 9.5 million geo-tagged tweets in New York. After re-moving the tweets having no entities or noun phrases, we obtain 2.4 million tweets. The second data set, referred to as LA, con-sists of 9.9 million geo-tagged tweets in Los Angeles, and there are 2.8 million tweets that have entities and/or noun phrases. The rea-son we choose these two cities is because they have quite different population distributions  X  the populace of New York is relatively concentrated in Manhattan and Brooklyn, while the populace of Los Angeles is spread out in many different districts.
 Compared methods. For comparison, we implemented two exist-ing local event detection methods. The first is E VEN T WEET which extracts bursty and localized keywords as features, and then clusters those features based on their spatial distributions. The sec-ond is W AVELET [7], which uses wavelet transform to identify spa-tiotemporally bursty keywords and then clusters them by consider-ing both co-occurrence and spatiotemporal distribution.
 Parameters. There are four major parameters in G EO B URST the kernel bandwidth h ; (2) the restart probability  X  ; (3) the RWR similarity threshold  X  ; and (4) the ranking parameter  X  for balanc-ing spatial and temporal burstiness. Unless stated explicitly, we set h = 0 . 01 , X  = 0 . 2 , X  = 0 . 02 , and  X  = 0 . 5 . E partitions the whole space into N  X  N small grids. We find N is E VEN T WEET  X  X  most sensitive parameter, and set N = 50 after tuning. For W AVELET , the most sensitive parameters are the granu-larities for constructing the spatiotemporal signal. After tuning, we set the space partitioning granularity to  X  x = 0 . 1 , X  y the time granularity to  X  t = 3 hours.
To evaluate effectiveness, we randomly generate 80 query time windows that are non-overlapping during 2014.08.01  X  2014.11.30. Among them, there are 20 3-hour windows, 20 4-hour ones, 20 5-hour ones, and 20 6-hour ones. As all the three methods require a reference window, we use a 5-day reference window right preced-ing each query. For every query, we run the three methods to re-trieve top-5 local events on the two data sets, and upload the results https://dev.twitter.com/streaming/overview to CrowdFlower 3 , a popular crowdsourcing platform, for evalua-tion. For G EO B URST , we ran both its batch mode and online mode to detect local events in the query window, and found these two modes produce exactly the same results. Thus, we only upload the results produced by the online mode and report its effectiveness.
On CrowdFlower, we represent each event with 5 most represen-tative tweets as well as 10 representative keywords, and ask three CrowdFlower workers to judge whether the event is indeed a lo-cal event or not. To ensure the quality of the workers, we label 10 queries for groundtruth judgments on each data set, such that only the workers who can achieve no less than 80% accuracy on the groundtruth can submit their answers. Finally, we use majority voting to aggregate the workers X  answers.

The representative tweets and keywords are selected as follows: (1) For G EO B URST , each event is a cluster of tweets, we select the 5 tweets having the largest authority scores, and the 10 keywords having the largest TF-IDF weights. (2) E VEN T WEET represents each event as a group of keywords. We select top-10 keywords in each event. Then we regard the group of keywords as a query to retrieve the top-5 most similar tweets in the query window using the BM25 retrieval model. (3) W AVELET represents an event with both keywords and matching tweets. We simply select the top-5 tweets and the top-10 keywords.
After gathering judgments from CrowdFlower, we compute the precision for each method. Figure 6 shows the precisions of the three methods on NY and LA when K and query interval vary. One may notice that the overall precision is not high for all the three methods. This phenomenon is reasonable because the query time windows are generated randomly. There are chances that some query windows fall in a time period ( e.g. , early morning) during which no local events happened in the city.
 Figure 6: Precision comparison of G EO B URST , E VEN T WEET
Comparing the three methods, we find that G EO B URST signifi-cantly outperforms E VEN T WEET and W AVELET on both data sets. The huge improvements indicate the superiority of G EO B URST two-step scheme: (1) the candidate generation step ensures a good coverage of all potential local events; and (2) the ranking step effec-http://www.crowdflower.com/ tively identifies true local events by carefully measuring spatiotem-poral burstiness.

We also observe that the precisions of the three methods all in-crease with the query interval. It is because a larger query interval is more likely to cover a time period in which certain local events have taken place.
Now we perform a case study on NY to compare the local events detected by the three methods. We choose the query window to be 7  X  10pm on November 7th 2014 and show the top-3 local events detected by different methods in Figure 7. For each event, we show the messages of the top-3 tweets, highlight the representative key-words, and plot the locations of the member tweets.

Examining the results of G EO B URST , one can see the generated geo-topic clusters are of high quality: the tweets in each cluster are both geographically compact and semantically coherent. Inter-estingly, G EO B URST can group the tweets that discuss about the topic using different keywords ( e.g. ,  X  X hai Restaurant X  and  X  X sian Dishes X ). This is because the RWR measure effectively captures the subtle semantic correlations between keywords. Another inter-esting observation is that, the pivot tweet of each cluster is highly interpretable. This is because such high-quality tweets mention most important keywords about the topic and locate closely to the occurring spot, thereby receiving high authority scores. For the given query, the top two clusters produced by G EO correspond to two local events: (1) the New York Festival of Light, which is held under the Manhattan Bridge; and (2) the basketball game between two NBA teams  X  Brooklyn Nets and New York Knicks. The third cluster is a group of tweets discussing about dinner instead of any interesting local events. Nevertheless, our investigation into its z-score reveals that there is a huge score gap (16.23 versus 0.73) between the second cluster and the third one. This suggests that one can easily use a z-score threshold to rule out non-event clusters in practice.

E VEN T WEET also successfully detects the basketball game be-tween Nets and Knicks. Nevertheless, the interpretability of the re-sult event is not satisfactory, because it just groups bursty keywords based on their spatial distributions. As a result, the keywords in the same cluster may not be semantically coherent. One may notice that there exist geographically faraway tweets in the same cluster. This is because E VEN T WEET is a feature-based method that uses only keywords to represent an event. As the matching tweets are re-trieved based on keyword similarity, it is possible that some tweets are geographically faraway even if they use the same keywords.
For W AVELET , it also reports the basketball game event, but misses the event of New York Festival of Light. The result clus-ters are of high quality as W AVELET considers both keyword co-occurrence information and spatiotemporal distribution during the clustering process. Nevertheless, the major drawback of W is that it tends to miss many local events in the query window. Us-ing wavelet transform for bursty keyword identification, W is more suitable for extracting influential local events on a tweet collection that spans a long time period, rather than real-time local event detection in an ad-hoc query window.
To study the efficiency of the three methods, we generate 200 random queries with different lengths. For every query, we run each method for 10 times and report the average running time.
In the first set of experiments, we compare the running time of G EO B URST against E VEN T WEET and W AVELET . We run G EO in both batch mode and online mode. Given a query window Q , the batch mode performs candidate generation and ranking in Q ; the online mode considers a window Q 0 that precedes Q by 10 min-utes, and finds local events in Q by updating the results in Q
Figure 8 shows the running time of the three methods on NY and LA. We observe that G EO B URST is much more efficient than E
VEN T WEET and W AVELET even when in the batch mode. This phenomenon is explained by two facts. First, in the candidate gen-eration step, the approximate RWR computation strategy can effec-tively speed up the pivot seeking process. Second, in the ranking step, G EO B URST just uses a number of historical activities to com-pute z-scores, which is very efficient (we found that the running time of the ranking step accounts for less than 1% of G EO total running time). Meanwhile, the online mode is even much faster than the batch mode. This is expected as the online mode does not need to find pivots from scratch in the time-consuming candidate generation step, but just needs to process the updated tweets and can achieve excellent efficiency.

The major overhead of E VEN T WEET and W AVELET is due to their space partitioning strategy. Specifically, E VEN T to compute spatial entropy to select localized keywords and per-form clustering based on keyword spatial distributions; W needs to perform wavelet transform on the spatiotemporal signal and compute the spatiotemporal KL-divergence between keywords. One may propose to partition the space at a coarser granularity to improve the running time of the two methods, but that comes with the price of being much less effective. Note that the running time of Figure 8: Running time v.s. # tweets in the query window. W
AVELET remains almost unchanged when the number of tweets increases. The reason is W AVELET finds events in an augmented window that includes both reference and query tweets. As our queries are at the same scale of several hours, we fixed the length of the reference window to 5 days. Accordingly, the running time of W
AVELET is not affected much by the length of the query interval.
In Figure 9, we report the scalability of G EO B URST mode when the number of updates varies: To this end, we choose a 3-hour query window Q . Then we use a window Q 0 that precedes Q by 1, 2, ... , 8, 9, 10 minutes, re-spectively, and update the results in Q 0 . One can observe that the running time of the online mode shows good scalability with the number of updates. For example, when there are as many as 212 updates, the online mode takes just 0.282 second to finish on the NY data set. Such performance suggests that, G EO B URST  X  X  online mode is capable of continuously monitoring the stream and realiz-ing real-time detection.
We proceed to study the throughput of G EO B URST for construct-ing the activity timeline. We apply G EO B URST to construct activ-ity timeline on NY and LA and periodically record the number of tweets processed so far and the running time. As shown in Fig-ure 10, G EO B URST finished constructing activity timeline for 2.4 million tweets in 341.35 seconds on NY, and 2.8 million tweets in 330.82 seconds on LA, and it scales well with the number of tweets.
We studied the problem of real-time local event detection in the geo-tagged tweet stream. We proposed the G EO B URST detector. To the best of our knowledge, G EO B URST is the first method that is capable of extracting highly interpretable local events in real time. G
EO B URST first generates candidate events based on a novel pivot seeking process, and then leverages the continuous summarization of the stream as background knowledge to rank the candidates. Our extensive experiments have demonstrated that G EO B URST highly effective and efficient. The usage of G EO B URST is not lim-ited to Twitter. Rather, any geo-textual social media stream ( e.g. , Instagram photo tags, Facebook posts) can use G EO B URST tract interesting local events as well. For future work, it is inter-esting to extend G EO B URST for handling the tweets that mention geo-entities but do not include exact GPS coordinates. We plan to pursue this direction by augmenting G EO B URST with existing geo-locating techniques [18, 27].
This work was sponsored in part by the U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, NSFC (Grant No. 61572488), and Grant 1U54GM114838 awarded by NIGMS through funds pro-vided by the trans-NIH Big Data to Knowledge (BD2K) initia-tive (www.bd2k.nih.gov), and MIAS, a DHS-IDS Center for Mul-timodal Information Access and Synthesis at UIUC. The views and conclusions contained in this document are those of the author(s) and should not be interpreted as representing the official policies of the U.S. Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.
