 Effective diagnosis of Alzheimer X  X  disease (AD) is of pri-mary importance in biomedical research. Recent studies have demonstrated that neuroimaging parameters are sensi-tive and consistent measures of AD. In addition, genetic and demographic information have also been successfully used for detecting the onset and progression of AD. The research so far has mainly focused on studying one type of data source only. It is expected that the integration of heterogeneous data (neuroim ages, demographic, and genetic measures) will improve the prediction accuracy and enhance knowledge discovery from the data, such as the detection of biomarkers. In this paper, we propose to integrate hetero-geneous data for AD prediction based on a kernel method. We further extend the kernel framework for selecting fea-tures (biomarkers) from heterogeneous data sources. The proposed method is applied to a collection of MRI data from 59 normal healthy controls and 59 AD patients. The MRI data are pre-processed using tensor factorization. In this study, we treat the complementary voxel-based data and re-gion of interest (ROI) data from MRI as two data sources, and attempt to integrate the complementary information by the proposed method. Experimental results show that the integration of multiple data sources leads to a considerable improvement in the prediction accuracy. Results also show that the proposed algorithm identifies biomarkers that play more significant roles than others in AD diagnosis. H.2.8 [ Database Management ]: Database Applications -Data Mining; J.3 [ Life and Medical Sciences ]: Health, Medical information systems Algorithms Copyright 2008 ACM 978-1-60558-193-4/08/08 ... $ 5.00. Neuroimaging, tensor factoriz ation, heterogeneous data source fusion, multiple kernel learning, biomarker detection
Currently, approximately 5 million people in the US -about 10% of the population over 60 are afflicted by Alzheimer X  X  disease (AD), the most common form of dementia. The di-rect cost to care the patients by family members or health care professional is estimated to be over $100 billion per year. As the population ages over the next several decades, it is expected that the AD cases and the associated costs will go up dramatically. Recognizing the urgent need to slow down or completely prevent from the occurrence of a health care crisis in US and worldwide, AD researchers have intensified their efforts to investigate ways to delay, cure, or prevent the onset and progression of AD. Objective and quantitative criteria, so called, biomarkers, are essential to evaluate the effectiveness of a potential treatment or pre-vention strategy. Thus, research on exploring biomarkers in the form of a test of cerebrospinal fluid (CSF) or blood, or images from brain scans has attracted great attention.
Recent studies have demonstrated that imaging parame-ters from brain scans are more sensitive and consistent mea-sures of disease progression th an cognitive assessment [32]. Some studies have shown that imaging measures correlate with cognitive test performance in Mild Cognitive Impair-ment (MCI) 1 and AD -an initial step in the validation of markers that accurately predict the course of the disease. Evidently, neuroimaging research offers great potential to identify the sensitive and specific biomarkers that can iden-tify individuals early in the course of dementing illness. This opens up opportunities to implement treatments in the early stages of disease when intervention may be most beneficial.
The volumetric T1 weighted MRI is a high-resolution struc-tural imaging technique that allows for the visualization of brain anatomy with a high degree of contrast between brain tissue types. It can be used to measure specific structures (e.g., hippocampus, entorhinal cortex, amygdale, etc.), a region of interest (ROI) approach, and detect the volume changes of the structures for AD vs. Normal [21]. Recently,
Mild Cognitive Impairment (MCI) is a transition stage be-tween the cognitive changes of normal aging and the more serious problems related to dementia. structural MRI images have been used to quantify reduc-tions of whole brain volume in sequentially acquired scans [8]. Promising methodological developments in the analysis of structural MRI data also include the use of probabilistic brain maps [3] to compute regional alterations in gray mat-ter, white matter, CSF, and whole brain, and to examine cross-sectional difference or longitudinal changes on voxel-by-voxel basis, an approach referred to as the voxel-based morphometry (VBM) [36]. Another neuroimaging technique is the so called positron emission tomography (PET). With different radioactive tracers, PET provides information on various physiological, biochemical and/or metabolic processes. In addition, other types of data, e.g., demographic informa-tion, such as age, gender, education, genetic makeup (such as the possession of the allele of Apolipoprotein e4), etc, have also been shown to be associated with AD.

While promising, the research so far has mainly focused on studying only one type of neuroimaging, e.g., MRI, fMRI (functional MRI), or FDG-PET using either region of in-terest or voxel-based approach [2, 8, 9, 24, 35, 44]. It is expected that combining different types of neuroimag-ing will help the prediction. However, even for the same neuroimaging data, different features constructed by differ-ent approaches (region of interest versus voxel-based ap-proaches) might complement each other. Integrating ROI and voxel-based information from the same type of neu-roimaging data and incorporating demographic information is expected to improve the prediction.

In this paper, we propose a kernel method to fuse hetero-geneous data (different types of features from single MRI data, together with demographic and genetic information) for accurately classifying subjects and discovering useful knowl-edge on biomarkers. More specifically, our main contribu-tions to the AD research are summarized as follows: To the best of our knowledge, our uses of (1) tensor factor-ization for extracting features from AD-related neuroimages; (2) multiple kernel learning fo r integrating AD-related mul-tiple data sources; and (3) feature selection from multiple data sources are novel contributions to the AD research.
We evaluated the proposed method using data acquired under the support of ADNI 2 from 59 normal control (NC) and 59 AD patients. The data includes 118 MRI images rep-resented as a three-dimensional array of size 181  X  217  X  (in the standard Talairach space and with 1 cubic mm voxel size), as well as demographic information such as age, gen-der, and genetic information based on Apolipoprotein E e4 (APOE4). SPM5 3 was used together with the optimized voxel-based-morphometry to generate the modulated gray matter map in the customized template space 4 .Experi-mental results show that multiple kernel learning achieves a considerable improvement in the prediction accuracy in comparison with classification based on each data source in-dividually. Results also show that the proposed algorithm is able to identify a number of brain regions that are known to be affected by AD.

The rest of the paper is organized as follows. Tensor fac-torization for feature extraction from MRI data is presented in Section 2. We introduce multiple kernel learning for het-erogeneous data fusion in Section 3. Biomarker detection from multiple data sources is discussed in Section 4. Exper-imental results are presented in Section 5. Finally, Section 6 concludes this paper with discussions and future work.
As high resolution 3D data, volumetric MRI data have a huge number of voxels at the time they were acquired from each subject. In our VBM pre-processing, we kept the voxel size in the template space to be in 1 cubic mm resulting in the image dimension of 181  X  217  X  181. Dimensionality reduction, which extracts a small number of features by re-moving the irrelevant, redundant, and noisy information, is crucial for the analysis of such data. Some neuroimag-ing studies use sub-sampling or a region of interest (ROI) based approach such as the Automated Anatomical Label-ing (AAL) [40] to reduce the data dimensionality. Although the within-ROI variation is ignored, AAL ROI summarizes the information from multiple brain regions with much re-duced dimension and these reg ions are representative over the whole brain volume. These techniques, however, may not be able to account for the information variation within each region of interest. Additionally, a traditional dimen-sionality reduction technique called Principle Component Analysis (PCA) [16] has been used widely in many appli-cations [34, 39], including a well-known adaptation in the http://www.loni.ucla.edu/Research/Databases/ http://www.fil.ion.ucl.ac.uk/spm/
Gene Alexander X  X  group processed the MRI images used in this study. More details on these data can be found in Section 5.1. neuroimaing field, often referred to as the scaled sub-profile modeling (SSM) [1]. PCA adopts the vector representation for images by concatenating all voxels within a pre-defined brain volume into a single vector. One inherent problem with this approach is that some information on spatial re-lationships (such as the corre lation among different slices of the 3D image) is not explicitly accounted for. One effective way to overcome these limitations is to treat a collection of three-dimensional images as a tensor and apply tensor factorization [19, 25, 26].
A tensor , also known as multidimensional matrix [45], is a higher order generalization of a vector (first order tensor) and a matrix (second order tensor). An N th-order tensor is An N th-order tensor A is of rank-one if it can be expressed as the outer product of N vectors: where x n  X  I n , for all 1  X  n  X  N .

A generalization of the product of two matrices is the product of a tensor and a matrix. The mode-n product whose element is denoted as q j n i n ,where1  X  j n  X  J n 1  X  i n  X  I n , is a tensor, denoted as whose entries are given by ( tensors A and B is defined as: The Frobenius norm of a tensor A is then defined as
The mode-n vectors of A are the I n -dimensional vectors obtained from A by varying index i n while keeping the other indices fixed. They form the column vectors of matrix A the tensor A .The n -th rank of A , denoted as rank n ( A defined as the dimension of the vector space spanned by the mode-n vectors: rank n ( A )=rank( A ( n ) ). factorization of A is formulated as finding a lower-rank ten-for all n , such that the following least-squares cost function is minimized: More specifically,  X  A canbeexpressedasfollows: where U ( n )  X  I n  X  R n has orthonormal columns for n = 1 ,  X  X  X  ,N .When R n is much smaller than I n for all n ,the core tensor C and the basis matrices { U ( n ) } N n =1 give a com-pact representation of the original tensor A , resulting in data compression.
 Given the basis matrices { U ( n ) } N n =1 , the core tensor be readily computed as C = A X  1 ( U (1) ) T  X  X  X  X  N ( U ( N Thus, the optimization problem focuses on the computation of the basis matrices only. An iterative approach can be applied for the computation [25, 43]. Each iterative step optimizes only one of the basis matrices, while keeping the other N  X  1 basis matrices fixed.

The iterative algorithm above may be computationally expensive and the solution depends on the initialization. In this paper, we apply an approximation algorithm called N -mode SVD [41], which has been applied successfully in com-puter vision and computer graphics [41, 42]. Define D n as an I n  X  I n matrix whose ( u, v )-th entry (1  X  u, v  X  I given by: of the N th-order tensor A X  I 1  X  I 2  X  X  X  X  X  I N . It follows that D n is a symmetric and positive semi-definite matrix. Let D n = U n  X  n U T n be the SVD of D n . Denote U matrix, which consists of the first R n columns of U n .The approximation of the original tensor A is given by
Since the size of the tensor A considered in this paper can easily exceed the memory capacity of a single machine, we develop an out-of-core algorithm by partitioning a tensor into smaller blocks as in [43]. Different neuroimaging features (voxel-based tensor and ROI-based AAL features from the same data source) may capture different but complementary characteristics of the data. For example, the voxel-based tensor features focus more on the global information, while AAL features focus on representative multiple ROI (local) information, though potential information overlaps exist between these two types of data (generated from the same MRI data set). A joint analysis of these data can potentially exploit their comple-mentary information and improve the prediction. Such pre-diction can be further improved by incorporating additional non-imaging data sources, such as demographic information.
Multiple Kernel Learning (MKL) provides a general frame-work for learning from multiple data sources [23]. MKL works by first constructing a kernel from each of the data sources and then combining these kernels based on a cer-tain criterion for improved classification performance. In addition to the SVM-based formulation in [23], we apply a discriminant analysis -based formulation.
Kernel methods work by embedding the input data into some high-dimensional feature space and they are generally formulated as convex optimization problems [37, 38]. The key fact underlying the success of kernel methods is that the embedding into feature space can be determined uniquely by specifying a kernel function that computes the dot product between data points in the feature space implicitly. In other words, the kernel function implicitly defines the nonlinear mapping to the feature space and expensive computations in the high-dimensional feature space can be avoided by eval-uating the kernel function in the original attribute space. Thus one of the central issues in kernel methods is the se-lection of kernels.

We call K : X X X X  R a kernel function [37], where X is the input space, if it satisfies the finitely positive semi-definite property: for any x 1 ,  X  X  X  ,x m  X  X  ,the Gram ma-trix G  X  m  X  m , defined by G ij = K ( x i ,x j ) is symmetric and positive semidefinite. Any kernel function K implicitly maps the input set X to a high-dimensional (possibly in-finite) Hilbert space H K equipped with the inner product (  X  ,  X  ) H In binary classifications, t he algorithms learn a classifier f : X X  X  X  1 , +1 } whose decision boundary between the two classes is affine in the feature space: f ( x )=sgn( w T  X  b ), where w  X  K is the vector of feature weights, b  X  is the intercept, and sgn ( u )=+1,if u&gt; 0, and  X  1otherwise.
Assume that we are given p kernel matrices G 1 ,  X  X  X  ,G p In MKL, the optimal kernel matrix G  X  lies in the set G defined as where r i =trace( G i ). In the following, we assume that all kernel matrices have been centered. This is equivalent to centering the data as the pre-processing step.

For binary-class problems, we are given { x + 1 ,  X  X  X  ,x and { x  X  1 ,  X  X  X  ,x  X  m  X  } , the collections of data points from the positive and negative (AD and normal) classes, respectively. The total number of data points is m = m + + m  X  .Fora given kernel function K , the basic idea of kernel discrim-inant analysis with regularization, called RKDA [47] is to find a direction w in the feature space H K onto which the projections of the two sets {  X  K ( x + i ) } m + i =1 and are well separated. Define the centroids of the two classes in the feature space as follows: In RKDA, the separation between the two classes is mea-sured by the ratio of the variance ( w T (  X  + K  X   X   X  K )) the classes to the variance w T  X  K w within the classes, where  X 
K =  X  K ( X ) P X  K ( X ) T /m is the covariance matrix of the data in the feature space and  X  K ( X ) is the data matrix in the feature space. Specifically, RKDA in the binary-class case maximizes the following objective function: where  X &gt; 0 is a regularization parameter.

It can be shown [47] that for a given set of p centered ker-nel matrices G 1 ,  X  X  X  ,G p , the optimal kernel matrix G can be found by solving the following Semidefinite Program (SDP): where  X  =[  X  1 ,  X  X  X  , X  p ] T , r =[trace( G 1 ) ,  X  X  X  , trace( G and The problem can be further formulated as a quadratically constraint quadratic programming (QCQP) problem [48], which is more efficient to solve than SDP.
Recall from the introduction that identifying biomarkers which are sensitive to AD onset or progression [31] is ex-tremely important in AD study. Feature selection is com-monly used for selecting a small subset of features for build-ing a comprehensible learning model with good generaliza-tion performance [13, 29, 30]. Such a small subset of features can then be used as  X  X iomarkers X . We propose to apply fea-ture selection from multiple d ata sources, including the AAL data and the voxel-based tensor data, both from the same single MRI modality, as well as various types of demographic information.
Given a data set with d features { F 1 ,F 2 , ..., F d } ,thetask of a feature selection algorithm is to remove as many irrel-evant (and redundant) features as it can and find a feature reduced data, a learning algorithm can achieve similar or better performance. Feature selection has been used widely in many applications including text mining [11, 17], image processing [12], and bioinformatics [6, 14, 27, 28]. Tradi-tional feature selection algorithms work on a single data source only. The challenge is how to develop effective fea-ture selection algorithms from multiple data sources, called  X  X ulti-source feature selection X .
Assume that among the p data sources {D i } p i =1 of m in-stances (subjects), D t (1  X  t  X  p ) is the target for feature (biomarker) selection. In our study, p = 5 data sources are involved. In feature selection from multiple data sources, we aim to remove irrelevant (and redundant) features accord-ing to the global pattern extracted from all p data sources. Clearly this is different from s tandard feature selection. To the best of our knowledge, feature selection from multiple data sources has not been well-addressed in the literature.
We propose to use multiple kernel learning for feature se-lection from multiple data sou rces. Specifically, multiple kernel learning is applied for information fusion from multi-ple data sources for pattern extraction. The combined kernel matrix extracts the pattern of the data in the form of pair-wise similarities, which can then be used as the input for a generic feature selection algorithm. We plan to study two feature selection algorithms, SPEC [50] and ReliefF [20], as both algorithms use the pairwise similarities (or distances) and the feature vectors as their input.
 SPEC is a framework for both supervised and unsupervised feature weighting [50]. Given a data set D , the similarities among instances can be captured by a set of pairwise in-stance similarities and its induced graph . SPEC treats features as functions defined on D and selects features in terms of the smoothness on the manifold formed by the ob-served data instances. The smoothness of a feature f i is evaluated by comparing the feature with the spectrums of L , the normalized Laplacian matrix of : InEq.(12),(  X  i , X  i ) i =1 ,... ,m denotes the spectrum (or eigen) decomposition of the normalized Laplacian matrix L .  X  (  X  is an increasing function which is used to modify the eigen-values of L and has an effect of removing noise [49].  X  ( a predefined smoothness measure function, which compares the feature with the spectrums of L . In [15, 50], a robust smoothness measure function is defined as: According to spectral clustering theories [33], the eigenval-ues of L measure the separability of the components of the graph and the eigenvectors are the corresponding soft clus-ter indicators. We compare the normalized feature vector  X  f with the eigenvectors of L (measured by  X  j  X  X  defined in Eq. (14)). The intuition behind Eq. (13) is that the better aligns to the leading eigenvectors of L , the better the feature f can separate the data as a function defined on D .Note that in Eq. (13), we ignore the first eigenvector of L .The reason is that the trivial eigenvector  X  1 only carries density information around instances and does not determine sep-arability. In the application, the set of pairwise instance similarities can be obtained from the learned kernel matrix from the last section.
 ReliefF is a well-known supervised feature selection algo-rithm derived as an extension of Relief [18]. It determines the relevance of a feature according to its contribution to the hypothesis margin [4] of the observed data. In ReliefF, the relevance of a feature f i is defined as: r ( f i )= 1 where x t,i denotes the value of instance x t on feature f NH ( x )and NM ( x ) denote the nearest points to x in the data with the same and different label respectively, and  X  is a distance measurement. In this application, the neighbor-hoods of instances can be determined by the learned kernel matrix from the last section.
We evaluate the effectiveness of the proposed methods on a collection of 118 samples consisting of 59 normal healthy controls and 59 AD patients.
Five feature (data) sources are used in this study, in-cluding tensor and AAL features from MRI images, two types of demographic information related to AD: age and gender, and genetic information based on Apolipoprotein Ee4(APOE4) 5 . It is well known that Apolipoprotein E e4 (APOE4) is a risk factor for AD. Compared to APOE4 non-carriers whose onset age for AD of 84 and risk of 20%, people with one/two copy/copies of APOE4 get the dis-ease at younger age (onset age of 75/68) and increased risk (47%/91%). We derive linear kernels for tensor and AAL features. A Gaussian kernel with an appropriate parameter value is used for the age feature. A simple binary kernel ma-trix is constructed based on gender feature: if two samples share a common gender, their corresponding kernel matrix entry is 1, otherwise it is set to 0. We use ApoE Genotyp-ing Allele 1 and Allele 2 to divide the samples into three groups: APOE4 non-carriers, heterozygotes, and homozy-gote groups. A kernel matrix similar to the one for the gender feature is then constructed.
We apply tensor factorization based on N -mode SVD for extracting features from the 118 MRI images. The whole collection of images can be represented as a 4th order tensor I 4 = 118. The fourth dimension of the 4th order tensor, which corresponds to the 118 subjects, is fixed (i.e., R 4 I 4 = 118), while the other three dimensions ( I 1 , I 2 ,and I ) which correspond to the size of a single 3D image are reduced to R 1 , R 2 ,and R 3 , respectively. Following Eq. (8), the approximation tensor  X  A is given as
I i  X  R i is the basis matrix along the i -th dimension. The j -th slice of  X  A along the fourth dimension is of size R R 2  X  R 3 , which is the compressed representation for the j -th image.

We use the Tensor Toolbox in [5] as the building block for our implementation. The factorization performance is measured in terms of compression ratio and information loss [10, 46]. The information loss (IL) is given by and the compression ratio (CR) is given by where m = I 4 = 118 is the total number of samples.
For simplicity, we set the reduced dimensionalities, i.e, R R ,and R 3 to a common value in our experiment. The result is summarized in Table 1. We can observe that we achieve a compression ratio of about 263 when the size of each image is reduced to 30  X  30  X  30, while the majority (96%) of the information from the original data is kept. This significantly
Human apolipoprotein E (apoE) is a 34-kDa protein con-taining 299 amino acid residues. There are three major iso-forms of human apoE (namely apoE2, apoE3, and apoE4), which are the products of three alleles (e2, e3, and e4) at a single gene locus on chromosome 19q13.2. Table 1: Performance of tensor factorization on 118 MRI images.
 reduces the memory and disk space, which is critical when analyzing and transmitting large volume neuroimaging.
To visually evaluate the compression performance, we ran-domly pick one image from the data set. We compare the original and reconstructed images (reduced dimension is 20 20  X  20) using four slices in three different views (sagittal, coronal, and axial), as shown in Figure 1. We can observe from the figure that the reconstructed slices are visually very similar to the original ones, even with a compression ratio as high as 889. In the following experiment, we set R 1 = R 2 = R 3 = 20, resulting in a 8000-dimensional repre-sentation for each MRI image, as using a larger dimension-ality doesn X  X  improve the performance much.
In this experiment, we evaluate the multiple kernel learn-ing algorithm for integrating five data sources denoted as tensor, AAL, age, gender, and APOE4. The study is per-formed by repeated random splitting of the data into train-ing and test sets of ratio of 2 : 1. To reduce the variability, the splitting is repeated 20 times and the results are aver-aged.

Table 2 presents the prediction performance of various algorithms (RKDA and SVM 6 using each of the five data sources by itself and the combination of them based on MKL) in terms of sensitivity and specificity. We can ob-serve from the table that multiple kernel learning based ap-proaches (using the combination of all five data sources), outperform all other methods based on a single data source in terms of both sensitivity and specificity. For example, RKDA-based MKL achieves a sensitivity about 0.950, which is significantly higher than RKDA based on any single data source. We can obtain the same observation in the case of SVM. This implies that different data sources contain com-plementary information and the integration of them leads to a significant improvement for AD prediction.
In this experiment, we evaluate the proposed algorithm for selecting features based o n learning from multiple data sources. All five data sources are used to learn the kernel Gram matrix and AAL is used as the target data source with 116 brain regions as the feature set. We also report the feature selection result using AAL data source only for comparison.

Table 3 presents the top 20 regions (features) obtained by two feature selection algor ithms: SPEC and ReliefF us-ing G 2 (the kernel matrix constructed from the AAL data source only) and G  X  (combined kernel matrix from all five data sources based on RKDA). It is important to note that
We used the LIBSVM implementation in [7] and the SVM-based MKL in [23] with the regularization parameter esti-mated through 5-fold cross-validation.
 Table 2: Performance of MKL based on RKDA and SVM in comparison with RKDA and SVM based on each of the five data sources alone. Prediction in terms of sensitivity and specificity.
 the comparison is based on the assumption that we use pre-existing AD domain knowledge from our collaborators at Banner Alzheimer X  X  Institute at Phoenix as the gold stan-dard. It is clear from Table 3 that both SPEC+ G  X  and ReliefF+ G  X  based on MKL perform significantly better than their counterparts SPEC+ G 2 and ReliefF+ G 2 based on a single data source. For example, among the top 20 re-gions from SPEC+ G  X  , 16 of them are confirmed to be AD-related, while there are only 11 AD-related regions from SPEC+ G 2 . Figure 2 highlights the top 12 regions detected by SPEC+ G  X  .

Our multiple kernel learning procedure not only provides adequate distinction of AD and normal subjects as shown in Table 2, but also identifies regions that play more signifi-cant roles than others in such classification (as shown in Ta-ble 3). These brain regions, interestingly enough, included left/right parahippocampla, hippocampus, amygdala, L/R Fusiform, various temporal regions, lingual, and occipital. It is worth noting that our MKL procedure was blind to the prior knowledge of brain regions associated with AD. Never-theless, the regions that are known to be affected by AD are those that have contributed the most in our MKL analysis. This further confirms the promise of MKL for data fusion for the AD study.
In this paper, we have proposed a kernel method for inte-grating heterogeneous data for AD prediction. We further extend the kernel framework for selecting features (biomark-ers) from heterogeneous data sources. Our experiments show the integration of multiple data sources leads to a consider-able improvement in the prediction accuracy. Results also show that the proposed multi-s ource feature selection algo-rithm identifies biomarkers (brain regions) that play more significant roles than others in AD diagnosis.

The tensor factorization used in this paper assumes no prior knowledge on the importance of entries from a given tensor. A uniform weight is applied to all entries. In our AD study, certain collections of entries in the brain are known to be more important. It is thus desirable to put higher weights to these voxels. We plan to examine weighted tensor factor-Figure 1: Original and reconstructed images (reduced dimension is 20 constructed from the AAL data source alone) and G (combined kernel matrix from all five data sources ization in the future. In this study, we have focused on MRI data. While MRI provides anatomical/structural in-formation about the disease, the complementary PET tech-nique with the positron-emitting radiotracer FDG allows re-searchers to examine the glucose hypometabolic pattern in AD patients in comparison with normals by measuring the cerebral metabolic rate for glucose (CMRgl). We expect that the fusion of MRI data (structural neuroimaging data) with PET data (functional neuroimaging data) as well as demographic data will further improve the prediction accu-racy, and provide a more sensitive measure of longitudinal changes as well as a more powerful indication of any poten-tial treatment/drug evaluations.
 This research is supported in part by funds from the Arizona State University and the National Science Foundation (NSF) under Grant No. IIS-0612069. Figure 2: Top 12 regions (highlighted) detected by SPEC+ G
