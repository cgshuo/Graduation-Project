 In recent years, natural language processing techniques have been used more and more in IR. Among other syntactic and semantic parsing are effective methods for the design of complex applica-tions like for example question answering and sentiment analy-sis. Unfortunately, extracting feature representations suitable for machine learning algorithms from linguistic structures is typically difficult. In this paper, we describe one of the most advanced piece of technology for automatic engineering of syntactic and se-mantic patterns. This method merges together convolution depen-dency tree kernels with lexical similarities. It can efficiently and effectively measure the similarity between dependency structures, whose lexical nodes are in part or completely different. Its use in powerful algorithm such as Support Vector Machines (SVMs) allows for fast design of accurate automatic systems. We report some experiments on question classification, which show an un-precedented result, e.g., 41% of error reduction of the former state-of-the-art, along with the analysis of the nice properties of the ap-proach.
 Categories and Subject Descriptors: H.3.3 [ Information Sys-tems ]: Information Search and Retrieval -Selection process; Re-trieval models; Information filtering.
 General Terms: Algorithms.
 Keywords: Kernel Methods, Natural Language Processing, Ques-tion Answering, Support Vector Machines, Syntactic Semantic Struc-tures.
Recent years have shown that syntactic and semantic structures are becoming essential for solving complex IR tasks, e.g., in ques-tion answering [17, 15, 2, 16] and opinion mining [9, 10, 11].
Tree kernels are a valid approach to avoid the difficulty of man-ually designing effective features from linguistic structures [14]. Indeed, they can directly define a similarity between data points in terms of all possible substructures in an implicit vector space. However, when the availability of training data is scarce, lexical It should be also noted that the most important property of SPTK is its generalization ability, which of course is extremely useful in scarce training data condition.

In the reminder of this paper, Section 2 illustrates our repre-sentation of questions by means of syntactic structures. Section 3 presents the experimental evaluation for QC and Section 4 derives the conclusions.
Thanks to structural kernel similarity, a question classification (QC) task can be easily modeled by representing questions, i.e., the classification objects, with their parse trees. Several syntactic representations exist, we report the most interesting and effective structures that we proposed in [7]. Given the following sentence: (s1) What is the width of a football field? the representation tree according to a phrase structure paradigm, i.e. constituency tree (CT), is in Fig. 1. We apply lemmatization to the lexicals to improve generalization and, at the same time, we add a generalized PoS-tag, i.e. noun (n::), verb (v::), adjective (::a), deter-miner (::d) and so on, to them. This is useful to measure similarity between lexicals belonging to the same grammatical category.
Our conversion of dependency structures in dependency trees is done in two steps:
Most importantly, SPTK (using LSA similarity): This suggests that patterns formed by sequences of similar lexicals need to be selected according to their syntactic structures to pro-duce accurate results. Indeed, when syntax is missing such as for the unstructured lexical sequences of LPST, the accuracy does not highly improve.

To better understand the role of lexical similarity in syntactic structures, in the next section, we will outline the advantages of SPTK over the other models by analyzing classification errors.
Table 2 shows four questions of the test set (labelled form 1 to 4) along with: the flags +/-asserting the presence or not of an error, the classification model, the true label of the question and the one given by the classifiers.

The first question is not correctly classified by BOW, which as-signed ENTITY category. Indeed, from a bag-of-words perspective ENTITY and LOCATION are equally probable for Question 1, e.g., the question What is the French cognac produced in province? uses the same words but asks for an entity. However, it is enough to add some syntactic cues to solve the above ambiguity. For example, the previous question would generate a dependency between What and is whereas Question 1 generates a dependency between What and French province . These syntactic features are contained in both tree representation paradigms. As a consequence, all the syntactic-based models correctly classify this example.

The second question is mistaken by all models but SPTK. The explanation is that without knowing that ruler is a person, it is not possible to infer the expected category of the answer. Indeed, if ruler had been a synonym of army or region the expected answer type would have been ENTITY. SPTK can disambiguate between ENTITY and HUMAN by exploiting the similarity with the train-ing question What Mexican leader was shot dead in 1923 ? . This shows some structural similarity, which is reinforced by the lexical similarity between French and Mexican , between ruler and leader , and between defeat and shot .

A similar rationale applies to the third question: without know-ing that peninsula indicates a geographic location the most proba-ble category could be ENTITY. In contrast, SPTK can provide the correct answer by measuring the structural similarity of Question 3 with the training question: What island group is Guadalcanal a part of ? along with the lexical similarity between peninsula and island and between Spain and Guadalcanal .

The last question is correctly classified only using the depen-dency structure. The BOW model is too influenced by words such as least, amount and per . The costituency structure fails as well, probably because it does not contain structures encoding lexical trigrams like what-state-have , which instead are subtrees of LCT. Finally, the errors of SPTK refer to questions like What did Jesse Jackson organize? , where the classifier selected ENTITY instead of HUMAN category, or What is the melting point of copper ? where ENTITY is selected instead of the correct NUMBER. These are clear examples where specific background knowledge is needed to provide the correct answer.

To understand the role of syntactic/semantic kernels, it is inter-esting to study their impact on the SVM generalization. For this purpose, Fig. 5 reports the learning curve of BOW, of STK and PTK applied to CT and of PTK and SPTK applied to LCT. We note that:
The benefits in terms of accuracy of SPTK are clear thus it is important to demonstrate that it can be efficiently applied to large datasets. For this purpose, we plotted the average running time of each computation of PTK and SPTK applied to the different struc-tures. We divided the examples from QC based on the number of nodes in each example. Fig. 6 shows the elapsed time in function of the number of nodes for different tree representations. We note that: (i) LCT-PTK is very fast as we used the fast algorithm de-signed in [14]; (ii) LCT-SPTK is also very fast as it uses the same algorithm of PTK but, as it tends to match many more tree frag-ments, its complexity increases. However, the equation of the curve fit, shown in the figure, suggests that the trend is sub-quadratic, i.e., x 1 . 7 . This efficiency is due to the tree structure, which imposes hi-erarchical matching of subtrees. (iii) Only when SPTK is applied to LPST, which has no structure, it matches all possible similar sub-sequences of nodes. This increases its computational complexity, which results in an order higher than 2 .
This paper has investigated the properties of a novel tree ker-nel, namely SPTK, which can encode generalized syntactic patterns from dependency or constituency structures. The main characteris-tic of SPTK is its ability to measure the similarity between syntac-tic structures, which are partially similar and whose lexical nodes can be different but related, e.g., Mexican and Spain. This allows SVMs to exploit large feature spaces, automatically generated from dependency substructures.

We have tested SPTK on the question classification (QC) task by also comparing with previous state-of-the-art models. The results show that SPTK with SVMs achieves an unprecedented result for QC, i.e., 94.8% of accuracy.

The error analysis has revealed that syntactic structures are needed to disambiguate the lexical semantics of questions. However, they may be either too general if lexicals are not part of them or too sparse if they are based on several lexicals. Therefore, SPTK, gen-eralizing the latter, provides a compromise that improves accuracy and generalization ability of SVMs.

Finally, we have also investigated the computational complexity of SPTK by empirically showing that it can easily scale to large datasets. Such result enables many promising future research di-rections: the most important being the use of SPTK for many IR tasks with many different similarities. It is also interesting to note that SPTK can be applied to trees completely different from syntac-tic parses, e.g., XML trees, on which a general semantic similarity can be defined between nodes.

