 With the increasing in number and size of databases dedi-cated to the storage of visual content, the need for effective retrieval systems has become crucial. The proposed method makes a significant contribution to meet this need through a technique in which sets of clusters are fused together to create an unique and more significant set of clusters. The im-ages are represented by some features and then are grouped by these features, that are considered one by one. A proba-bility matrix is then built and explored by the breadth first search algorithm with the aim of select an unique set of clusters. Experimental results, obtained using two different datasets, show the effectiveness of the proposed technique. Furthermore, the proposed approach overcomes the draw-back of tuning a set of parameters that fuse the similarity measurement obtained by each feature to get an overall sim-ilarity between two images.
 I.5.3 [ Pattern Recognition ]: Clustering X  algorithms Algorithms, Performance, Experimentation.
 Image clustering, BFS, CBIR, clustering fusion.
Due to the huge amount of digital informations the meth-ods to retrieve information are become very important and this has increased the research efforts in this area. Nowa-days, the digital information is not only textual ( e.g. , docu-ments) but it can be also visual ( e.g. , images, videos), both of them have the same importance from the users point of view. In this scenario, the methods to compute the similar-ity between two images and to retrieve visual informations in a database are needed. In content-based image retrieval (CBIR) systems the query by example strategy is often em-ployed. Furthermore, due to the size of the database, the users has often the need to groups in clusters the images that the systems consider similar to the query image. There are several ways to achieve this result but the main problem, faced by all these methods, is how to compare two images [2, 10, 8, 6]. Actually, the most effort is to understand the image semantic content [4, 7, 11] and compare the images using their content. Otherwise, the similarity between two images can be obtained by using the low level features, such as color, textures, edges, object shape and so on. Since these features are heterogeneous, they could be represented and compared in different ways, to get an overall similarity mea-sure between two images is not a trivial task. Indeed, the importance given to each feature is tuned by coefficients that normally are found empirically. Obviously this technique shows an high cost in terms of time machine and therefore has a further room for improvement. On the other hand, machine learning techniques could be used to find the opti-mal value of the coefficients. Instead, the proposed method has the advantage that it does not need any coefficients to get an overall metric. Roughly speaking, the system pro-cesses the query image extracting its low level features and producing a ranking for each feature. The first images of these rankings are considering relevant with respect to the query and are put in a set. Considering the feature one by one, these images are grouped in sets of clusters. Obviously, the number of the sets of clusters is equal to the number of features. These sets of clusters are fused by building the probability matrix and it is thresholded to obtain a binary matrix that can be seen as the representation of a graph. The final set of clusters, that is shown to the users, is deter-mined through the research of connected sub-graphs in this matrix via the well-known breadth first search (BFS) algo-rithm. The proposed approach is scalable to the number of considered features. Indeed, it is possible to increase easily the number of features used and hopefully improving the performances of the system. The results show a significant improvement compared with the technique used in [2]. Due to the fact that this is a very novel approach no other com-parisons are allowed, indeed at the best of our knowledge, the problem is not exhaustively addressed in literature. The paper is organized as follows. In section 2 the used method to represent an image is explained. The clustering algorithm and the clustering fusion technique are described in section 3. The experimental results are shown in section 4. Finally, the conclusions are drawn in section 5.
Any image is represented by using the low level features vectors. In particular the features used are the textures, the color and the edges.
The textures are analyzed using the Laguerre Gauss func-tions [3]. These functions belong to the class of Circular Harmonic Functions (CHFs). The functions identified by the indexes n = 1 and k = 0, and n = 3 and k = 0, at three different resolutions are used. Since the Laguerre Gauss functions are complex, the marginal density of the real part and the imaginary part are separately approxi-mated by using the Generalized Gaussian Density (GGD). The GGD can be completely described by two parameters:  X , X  . Then, the textures are represented by a vector made up of 24 elements. The similarity between two textures vec-tors are computed by using the Kullback-Leibler distance [5, 3], as follows where g and f denote two different images and i denotes the i th GGD. The described textures analysis is separately performed on the R, G, B, and Y components. Then, for each component, we have a vector made up of 24 elements.
The representation of the color feature is performed by using the chromatic components of the YUV color space, [9]. The U e V components are represented by the mean value, the second and the third centered moment, obtaining a vector made up of 6 elements. The similarity measurement between two color vectors is computed by the Euclidean Dis-tance, as follows where CV f i denotes the i th element of the color vector com-puted on the image f .
The edges feature is represented by using the phase his-togram of the edge points. The first operation is the selec-tion of the most important edge points. These edge points are selected combining two maps by the AND operator. The first map is computed by using the Laplace operator, the sec-ond one by using the Laguerre Gauss function n = 1 and k = 0, at the high resolution. Once the most important edge points are selected, their phase is estimated by computing the phase of the Laguerre Gauss coefficients. The phase his-togram is computed considering the range [0 , X  ] quantized in 36 steps of 5 degrees each one. As for the color vectors, the similarity measurement is computed by the Euclidean Distance, as follows where PH f i is the i th element of the phase histogram com-puted on the image f .
Each image is then represented by six vectors that have different meaning and different methods to perform the com-parison. Generally, the overall similarity between two im-ages is computed as follows where D i denotes the similarity computed by using the i th feature,  X  i is a weight that tunes the importance given to the i th feature and I is the number of the features. In the classical approach it is necessary to find the correct values of  X  i to get the best performances, and this is a not triv-ial task. For this reason in the next section we propose a novel approach to fuse the results obtained by the use of the features in independent way.
The content-based image retrieval systems are typically based on a query image, and the images in the dataset are ranked according to the similarity with it. The final ranking provided to the users depend on the query, on the similarity measurement and on the dataset. Indeed, when the query is not properly chosen to represent what the users are looking for, they are not satisfy by the ranking. Since the query is only an example, it could happen that the images not ranked in the first positions may be important from the users point of view, especially when the dataset is very large and hetero-geneous. Finally, the similarity measurement is important to define if two images are similar or not. In this scenario a clustering algorithm, that groups relevant images into clus-ters, allows a better analysis of the results provided by the systems. The aim of this work is to fuse the results obtained by the clustering algorithm in which the similarity between two images is measured by using independently each feature. In [2] an overall metric were defined as shown in equation 4. As said in the previous section, this approach need to find the correct value of the weights  X  i . These values depend on the metric used for each feature and on the images belonging to the dataset. To overcame this drawback we first apply the clustering algorithm considering the feature one by one, and then we fuse the results to obtain the final set of clusters.
In this work we use the clustering algorithm proposed in [2]. The algorithm can be summarized in three steps: 1. The images in the dataset are ranked according to the 2. The images belonging to the set S are ranked accord-3. The operations performed in the previous step are re-Since the second and the third steps are performed for each feature, we get six sets of clusters ( i.e. , six is the number of the features) that need to be fused to create an unique set of clusters to show to the users.
The aim of the clustering fusion is to create an unique set of clusters from the six sets of clusters, obtained as it is explained in the previous section. The clustering fusion technique proposed in this work is made up of two steps. In the first step the results obtained by the clustering algo-rithm are analyzed and the probability matrix is built. Let p ( r,c ) be the generic value of the probability matrix P in the position r,c . The generic element p ( r,c ) of the matrix represents the probability that the r th image is put with the c th image. The six sets of clusters are analyzed one by one and the matrix P is updated. Indeed, the value of p ( r,c ) is increased each time that the r th image and the c th image belong to the same cluster, [10]. If p ( r,c ) = k , where k de-notes the number of the used features, the r th image and the c th image are put in the same cluster by considering every feature. An example of the probability matrix is shown in figure 1. By doing so we fuse the results obtained by con-sidering the features one by one without using the equation 4, then avoiding to find the optimal values of  X  i . Once the probability matrix is built, it is thresholded to get a binary matrix, as shown in figure 2. This matrix can be seen as the representation of a graph and then can be analyzed by using the breadth first search algorithm. In this context the images with an high probability ( i.e. , higher than the chosen Figure 2: Thresholded version of the probability ma-trix shown in figure 1.
 Figure 3: Examples of the images in the Vision Tex-ture dataset. value of minimum probability p min ) to be put in the same cluster are linked. The BFS algorithm is used to find the connected images that are the final clusters. Indeed, starting from the first image the BFS algorithm explores the matrix to find all the images connected with it. These images make up the first final cluster and the connections related to these images are removed. This operations are repeated until all the connections on the matrix are removed.
The performances of the proposed technique are evaluated by using two different datasets. The first one is the Vision Texture [1] that is made up of 640 images divided in 40 classes, see figure 3. This dataset is used to allow a compar-ison with the results shown in [2]. The performances of the system are evaluated also by using a more complex dataset that was not used in [2]. It is a subset of the Corel dataset, made up of 9 classes with 16 elements each one, see figure 4. The experimental results are shown in table 1 and table 2. It is important to define that an impure cluster is a cluster containing at least one outsider, and an outsider is an image put in a wrong cluster. In table 1 the results obtained by the proposed method are compared with the results shown in [2] that use an overall metric to compare the images, see equa-tion 4. In our method we have to set only the value of p used to obtain a binary matrix from the probability matrix P . Since the features used are six, we set p min equal to 5 and 6. Comparing the first and the second column of table 1 we can see that the average number of the outsiders in each cluster decreases in our method. Furthermore, we get the same average percentage of impure clusters but with an higher average number of clusters created, always very sim-ilar to the true average number of clusters ( i.e. , the number Figure 4: Examples of the classes belonging to the subset of Corel dataset used.
 Table 1: Experimental results obtained by using the dataset shown in figure 3.
 percentage of 6.17% 6.14% 1.16% impure clusters in each cluster clusters created
True average of classes that are represented at least by one image in the set S ). In the third column the performances improve but the ratio between the number of created clusters and the true number of cluster increases. Finally, the performances of the method are evaluated by using the dataset shown in figure 4, see table 2. Although, the dataset is more com-plicated the performances are quite good. It is important to notice that using our method no parameter need to be tuned.
In this work a novel technique to fuse clusters of images based on the BFS is presented. A set of relevant images is selected and its elements are grouped in clusters using the features one by one. These sets of clusters are fused together to obtain the final set of clusters. This leads to a completely unsupervised system that does not require the tuning of any parameter. The experimental results obtained are good for both of the used datasets. Indeed, the number of outsiders is always less than 2 for each cluster and the percentage of impure clusters created decreases as the number of features used increases. Furthermore, it is easily possible to add or to remove heterogeneous features ( e.g. , GPS data and textual annotation if available, EXIF data and so on) used to represent the images. [1] Mit, vision and modeling group. vision texture. In Table 2: Experimental results obtained by using the dataset shown in figure 4. [2] L. Costantini, L. Capodiferro, M. Carli, and A. Neri. [3] L. Costantini, P. Sit`a, L. Capodiferro, and A. Neri. [4] I. J. Cox, M. Miller, T. P. Minka, T. Papathoman, [5] M. N. Do and M. Vetterli. Wavelet-based texture [6] H. Flickner, W. Sawhney, J. Niblack, Q. Ashley, [7] Y. Herdiyeni, S. Nurdiati, and I. Daud. Image [8] S. Wei, Y. Zhao, Z. Zhu, and N. Liu. Multimodal [9] A. Yanagawa, W. Hsu, and S.-F. Chang. Brief [10] J. Zhang, J. Gao, M. Zhou, and J. Wang. Improving [11] T. Zhang and Y. Fu. An image semantic retrieval
