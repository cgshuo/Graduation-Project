 Different from traditional information retrieval, both content and structure are critical to the success of Web information retrieval. In recent years, many relevance propagation techniques have been proposed to propagate content information between web pages through web structure to improve the performance of web search. In this paper, we first propose a generic relevance propagation framework, and then provide a comparison study on the effectiveness and efficiency of various representative propagation models that can be derived from this generic framework. We come to many conclusions that are useful for selecting a propagation model in real-world search applications, including 1) sitemap-based propagation models outperform hyperlink-based models in sense of both effectiveness and efficiency, and 2) sitemap-based term propagation is easier to be integrated into real-world search engines because of its parallel offline implementation and acceptable complexity. Some other more detailed study results are also reported in the paper. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval; H.5.4 [ Information Interfaces and Presentation ]: Hypertext/Hypermedia Algorithms, Experimentation, Theory. Relevance Propagation, Hyperlink Based Score Propagation, Hyperlink Based Term Propagation, Sitemap Based Score Propagation, Sitemap Based Term Propagation Different from traditional information retrieval (IR), the Web contains both content and link structures that have provided many new dimensions for exploring better IR techniques. In the early days, people analyze web content and structure independently. Typical approaches such as [10][11][14] use TF-IDF [3] of the query term in the page to compute a relevance score, and use hyperlinks to compute a query-independent importance score (e.g. PageRank [19]). And then these two scores are combined to rank the retrieved documents. Such a methodology has brought the first major improvement in Web IR [6]. In recent years, some new methodologies that explore the inter-relationship between content and link structures have been introduced and produced some exciting results. Roughly speaking, these methods can be divided into two categories: one is to enhance link analysis with the assistance of content information [2][5][13][17]; the other is relevance propagation, which propagates content information with the assistance of Web structure [6][18][22][23]. For the first category, HITS [17] and topic-sensitive PageRank [13] are the representatives. HITS first constructs a query specific sub-graph, and then computes the authority and hub scores on this sub-graph to rank the documents. Topic-sensitive PageRank calculates a set of PageRank vectors, each element of which is biased to one of the predefined topics. Generally speaking, these methods conduct link analysis on a sub-graph which is sampled from the whole Web graph by considering the content of the web pages. For the second category, many relevance propagation methods were proposed to refine the content of web pages by propagating content-based attributes through web structure. For example, [6][18] propagate anchor text from one page to another to expand the feature set of web pages. [22] propagates the relevance score of a page to another page through the hyperlink between them. [23] propagates query term frequency from child pages to parent pages in the sitemap tree. Experiments on TREC benchmark showed that both methods in [22][23] can improve the retrieval accuracy. * Comparatively speaking, the first category has been a long-studied research topic, and many works have been done on detailed [1][4][8][9][13][15][17]. However, the second category, although attracted much attention in recent years, has not yet been studied comprehensively. In this paper, we explore more on the second category and study how effective and efficient the relevance propagation methods are and whether they are practical for real-world Web search applications. We will give a comprehensive study of relevance propagation technologies for Web information retrieval. Firstly, we extend the existing works [22][23] to come out a generic framework, and then show that the various existing propagation models can actually be derived from it. Secondly, we conduct both theoretical and experimental evaluations over these models to answer the following questions: 1) Do these relevance propagation methods improve web search 2) Which method is more effective and efficient? 3) Which method is more feasible to be applied in real-world Based on the experiments on two different benchmarks (TREC .Gov2002 collection and MSN.com) and some theoretic analysis, we found that relevance propagation through parent-child relationship in the sitemap tree is more effective than through hyperlinks, and term propagation is more feasible for real-world implementation than relevance score propagation. These conclusions are very meaningful and informative for model selection in real-world search engines. The organization of this paper is as follow. In Section 2, we review some existing relevance propagation methods. In Section 3, we discuss the generic relevance propagation framework and propagation methods. Then we study the effectiveness and efficiency of relevance propagation models in Section 4. Conclusions are given in Section 5. As mentioned in the introduction, many relevance propagation methods have been proposed to enhance relevance weighting [6][18][22][23]. In this section, we will briefly review two latest and representative works. Shakery, et al [22] found that two factors are important to relevance weighting: the relevance score of a web page and the relevance scores of the pages that have links to/from that page. Motivated by this observation, they propagate the relevance score of a page to its neighbors in the link graph. They define a so-called hyper relevance score for each page as a function of three variables: its self-relevance score, a weighted sum of the hyper relevance scores of all the pages that point to it (denoted by in-link pages), and a weighted sum of the hyper relevance scores of all the pages that it points to (denoted by out-link pages). Based on these definitions, they proposed a relevance score propagation model as below: iteration, s ( p ) is the original relevance score of page p ,  X  are weighting functions for in-link and out-link pages respectively. Note that h 0 ( p )= s ( p ). For practical implementation, they derive three simplified cases, which are shown in Table 1. As can be seen, the hyper relevance scores are computed iteratively. When the iteration process converges, the final hyper relevance scores will be used for relevance ranking. Experiments [22] show that the above score propagation models generally perform better than without propagation. 1~2% improvements are observed on the Web Track of TREC 2002. However, the amount of improvement is sensitive to the document collection and the tuning of parameters [22]. Table 1. Three cases of the relevance score propagation model Special case Model formulation weighted in-link weighted out-link uniform out-link Different from [22], [23] proposes a sitemap-based feature propagation method. They first construct a sitemap for each website based on URL analysis, and then propagate query term frequency along the parent-child relationship in the sitemap tree as follow: page p before and after propagation, q is the child page of p ,  X  is a weight which controls the contribution of the child pages to their parent. As can be seen, [23] actually propagates term frequency based on sitemap, and so we rename it as sitemap-based term propagation. After the propagation of term frequency, any relevance weighting algorithm can be adopted on the refined features to rank web pages. Their experiments with a variation of BM2500 model got one of the best results on the Web Track of TREC 2004 [11], which shows that the sitemap-based term propagation method could significantly boost the retrieval performance. Although the aforementioned two works were developed independently and seem not correlated to each other, however, as shown in the next section, they can actually be considered as two special cases of one generic propagation framework. This encourages us to further study whether we can derive some other models from this generic framework, and which of them is more effective and efficient for real-world applications. We will provide some detailed comparisons and evaluation of different propagation models in the following sections. In this section, we will generalize the two propagation models introduced in the previous section to a generic framework. For this purpose, we will first extend the sitemap-based term propagation model [23] to an iterative version. At the first glance, the two relevance propagation methods defined in (1) and (5) seem very different: the final hyper relevance score in (1) is calculated iteratively, while only one-step computation is needed in (5). However, with a little modification, (5) could also be extended to an iterative version: with only one step of iteration. So far, (6) has been very similar to (2)(3) and (4): the right hand is composed of the original relevance of page p , and the relevance iteratively propagated from other pages. The only difference is the coefficient of linear combination. To bridge the gap, (6) can be further modified as follows: In fact, the above modification is necessary because the coefficients in (6) will make the iterative computation un-converged (i.e., after each iteration, the information is doubled because (1 ) (1 ) 2  X  X  ++ X = ). On the other hand, the following discussions, we will directly call (7) by the iterative version of sitemap-based term propagation model. As shown in the previous section, the formulations of the relevance score propagation model (2)(3)(4) and the sitemap-based term propagation model (7) are quite similar. This encourages us to propose a generic relevance propagation framework on top of them: where c 0 ( p ) represents the original relevance of page p , c and N p represents the pages in the neighborhood of page p . There could be many choices of function g . Similar to the propagation methods in [22] [23], we adopt linear combination for simplicity. It is easy to find that in the score propagation model (1), h corresponds to c i ( p ), s ( p ) corresponds to c the pages which point to or are pointed to by p . That is, the relevance is represented by score, and the structure is hyperlink graph. In this regard, we rename the relevance score propagation models by hyperlink-based score propagation model (or HS model). Similarly, in the iterative sitemap-based term propagation model, f t i ( p ) and f t 0 ( p ) correspond to c and N p represents the child pages of p in the sitemap tree. That is, the relevance is represented by term frequency and the structure is the sitemap tree. This is consistent with its name, sitemap-based term propagation model (or ST model in brief). Table 2 shows the relationship between the two existing models and the generic framework. Hyperlink Hyperlink based score propagation [22] ? 
Sitemap ? Sitemap based term propagation [23] From Table 2, one can easily think of two new models for relevance propagation (corresponding to the two question marks): hyperlink-based term propagation model (or HT model) and sitemap-based score propagation model (or SS model). Similar to the ST model, the HT model needs to propagate the frequency of query term in a web page before adopting relevance weighting algorithms to rank the documents. While similar to the HS model, the HT model also has three special cases: 
Special case Model formulation weighted in-link weighted out-link uniform out-link Symmetrically, similar to the HS model, the SS model first computes a relevance score for each page, and then propagates it to calculate hyper relevance score. And similar to the ST model (7), sitemap tree is used for the propagation: In summary, we proposed a generic relevance propagation framework and derived four propagation models as its special cases. In the following, we will evaluate each of them in terms of effectiveness, efficiency and the potential application in real world search engines. In this section, experiments were conducted to evaluate the performance and efficiency of relevance propagation models. We first introduce the experimental settings and some implementation issues, and then present experimental results and discussions. To avoid the corpus bias, two different data collections were used in our experiments. One is the  X .GOV X  corpus, which is crawled from the .gov domain in early 2002. This corpus has been used as the data collection of Web Track since TREC 2002. There are totally 1,053,110 pages with 11,164,829 hyperlinks in it. The other data set is the  X  X SN X  corpus, which is crawled from msn.com. This corpus has 2,218,428 pages with 29,163,922 hyperlinks. When conducting the experiments on the  X .GOV X  corpus, we used the topic distillation task in the Web Track of TREC 2003 and 2004 as our query sets (with 50 and 75 queries respectively). For simplicity, we denote these two query sets by TD2003 and TD2004. The ground truths of these tasks are provided by the TREC committee. When doing experiments on the  X  X SN X  corpus, we use a self-defined query set with 100 queries in total. The ground truths are labeled by human beings 1 . As the baseline, we adopted BM2500 [20] as the relevance weighting function in our experiments: frequency of the term T within the web page, qtf is the frequency of the term T within the topic from which Q was derived, and  X  is the Robertson/Sparck Jones weight [21] of T in Q . K is calculated by where dl and avdl denote the page length and the average page length. In our experiments, we set k 1 = 2.5 , k 3 = 1000 , b = 0.8. According to the Web Track of TREC, we returned 1000 search results by each model for evaluation. And we used mean average precision (MAP) and precision at 10 (P@10) as evaluation criterions [3][10]. Following [22], the hyperlink-based propagations are not applied on all the web pages. Instead, for each query, we construct a working set. The flowchart of the working set construction is shown in Figure 1(a). For a query, we first retrieve the relevant set which contains all the pages that have at least one query term. Then we rank all the pages in the relevant set with BM2500, and choose 1000 pages with highest relevance scores as the core set. Then, we find the set of pages that point to the core set (denoted core set (denoted by the cited set). After that, we construct the working set as (16), which is illustrated by the gray part in Figure 1(b). Our implementation of the SS and ST models is similar to [23]. corpus based on URL analysis 2 . Then for each query, we rank all the relevant documents with BM2500 and select top 10000 pages as the working set to conduct the propagation. Besides, another important implementation issue about the sitemap-based propagation models is that they can actually be implemented in a non-iterative manner, although they are defined and ST models. If we carry out the propagation from the leaf node to the root of the sitemap tree in a bottom-up manner, we can avoid iterative computation but come up with the same propagation result. Let X  X  see an example in Figure 2. This is a website with only 4 pages. Table 4 shows the propagation results according to the iterative version of the SS model (where  X  =1- X  , and s relevance score of page p i before propagation). From this table we can see that it takes 2 iterations to converge because the scores after the 2nd and the 3rd iterations are the same. Iteration p 1 p 2 p 3 p 4 Now let us consider a non-iterative implementation of the SS model. This time, we first update the score of page p h ( p 4 ) =  X  s 4 ; after that, we update p 2 and p 3 and h 1 ( p 3 ) =  X  s 3 ; for the last step we update p h pages in each step, the resulting scores are the same as those produced by the iterative implementation. With such a bottom-up strategy, we need to propagate the relevance score (or term frequency) of a page to its parent only once , which can greatly improve the efficiency of sitemap-based propagation models. Note that although we avoid iteration, the final scores we get are the converged results of (13) with many steps of iteration. With the preparations in subsection 4.1 and 4.2, we tested all the four propagation models and collected the retrieval performance for evaluation. Before presenting the results, we first give the abbreviations of these models in Table 5 for ease of reference. 
Hyperlink-based score 
Hyperlink-based term Figure 3 shows the performance of the four models (total 8 algorithms) on the  X .GOV X  corpus with the TD2003 query set. As can be seen, all models (with proper parameters) boosted the retrieval performance against the baseline (the baseline corresponds to  X  =1, which MAP is 0.124 and P@10 is 0.110). Among these models, SS got the best result; ST and HT-WI had similar performance and in the second position; HS-WI produced the worst performance and the other four algorithms performed similarly with only marginal improvement over the baseline. Figure 3. Performance on the  X .GOV X  corpus with TD2003 To gain more understanding of the performance comparison, we further list in Table 6 the best MAP and P@10 of each algorithm. From this table, we can find that the sitemap-based models outperformed the hyperlink-based models by much. For example, the best MAP of the SS model was 0.1719, which was not only 40% better than the baseline, but also won the best result reported in TREC 2003 by over 10%. Similarly, the best P@10 of the SS model was 0.148, which outperformed the baseline and the best result of TREC 2003 by 30% and 15% respectively. Comparatively speaking, almost none of the hyperlink-based models outperformed the best results reported in TREC 2003. Figure 4 shows the performance of the four models on the  X .GOV X  corpus with the TD2004 query set. We can draw very similar conclusions from this figure to those from Figure 3. A little difference is that HS-WI performed better with TD2004 than with TD2003. This time it was almost as good as the two sitemap-based models. Figure 4. Performance on the  X .GOV X  corpus with TD2004 Figure 5 shows the performance on the  X  X SN X  corpus. Again, we can come to similar conclusions to the above two experiments. The difference is that the ST model was much better than the SS model on this corpus, unlike what it performed on the  X .GOV X  corpus. Besides, HT-WI did not perform as well as on the  X .GOV X  corpus. Actually, these differences are understandable b ecause the  X  X SN X  corpus is quite different from the  X .GOV X  corpus: 1) This corpus was crawled from a commercial website but not from the governmental websites; 2) The query set for the  X  X SN X  corpus is very different from those for the  X .GOV X  corpus. The TD2003 and TD2004 query sets are for topic distillation; however, the queries for the  X  X SN X  corpus are for general purpose 3 . Although with these differences, the experimental results still tell us that relevance propagation can boost the performance, no matter over what kind of data sets and with what kind of query sets. Besides the peak of the performance curve, the robustness of an algorithm is also an important factor for its effectiveness. We list in Table 7 the range of  X  in which each algorithm got better result than the baseline. From this table we can see that the SS model was the most robust, which won the baseline with most values of  X  . The ST and HT-WI models were the second winners, which boosted the retrieval performance with about half of the possible  X  values. Comparatively, the remaining algorithms were not so robust, since they resulted in improvements only when  X  was closed to 1. To summarize the above experiments, we can draw the following conclusions: 1) In general, relevance propagation can boost the search 2) The sitemap-based models are more effective and robust than 3) The two sitemap-based models have similar performance. In the previous section, we investigate the effectiveness of the relevance propagation models. However, for real-world applications, efficiency is another important factor besides effectiveness. In this regard, we evaluate the efficiency of the four models in this section to see their potential of being used in search engines. Roughly speaking, typical architecture of a search engine has three components [3][6]: crawler, indexer, and searcher. If we want to integrate relevance propagation technologies into search engine, we should consider these three components. Clearly, we could only embed relevance propagation into the second or third component. Since the search engine indexes the Web offline, and implement the search operation online, we will discuss the efficiency of relevance propagation for the online case and offline case respectively. Due to the algorithm descriptions, all the relevance propagation models have two kinds of computations. The first one is to retrieve the relevant pages and rank them by relevance weighting functions. Actually this is also needed by existing search engines. The second is the additionally-introduced complexity, including working set construction, relevance propagation and so on. This will be the major concern when integrating these models into the search engines. In this regard, we will focus on the analysis of these additional computations in this section. According to the model formulation and the implementation issues, we can get the following estimations on the online complexity of the relevance propagation models. Note that the time complexity we estimate here is for one query. 1. Since the SS model needs to propagate the relevance score 2. For the ST model, we need to propagate the frequency of 3. For each step of iteration in the HS models, we need to 4. Similar to the analysis of the HS models, we can get the To verify the above theoretical analysis, we logged the time usage of the eight algorithms on a PC with 1.5GHz CPU and 2GB memory. To save space, here we only list the statistical data on the  X .GOV X  corpus with TD2004 in Table 8. The second column summarizes the theoretical time complexity. The third column shows the average size of the working set. As can be seen, the size of the working set for the HS and HT models is about 7 times the experimental settings). The average number of hyperlinks per page is 11 as shown in the fourth column, which is consistent with previous reports [3][16]. The fifth column shows the average iteration numbers. Note that the SS and ST models do not need any iteration, so we set t = 1. The sixth column shows the average number of query term per page. An interesting finding is that the pages in the working set of the ST model contain more terms than that of the HT model on average. This is reasonable because the working set of the ST model consists of the top 10000 most relevant pages, but the working set of the HT model is made up of the top 1000 most relevant pages and some other pages in the citing and cited sets (which might not be very relevant). So generally speaking, those pages in the working set of the ST model will be more relevant than those of the HT model. Therefore the average number of query terms per page of the ST model will be larger. The last column shows the average CPU time per query. 
Algorithm Time Complexity average w average l average By analyzing Table 8, we can come to the following conclusions 1) The sitemap-based models are more efficient than the 2) The score-level propagation models are faster than those 3) The numbers in Table 8 is quite in accordance with our Since a real search engines should handle hundreds of queries per propagation techniques online according to Table 8. So offline implementation is much more preferred if we want to apply them in real-world applications. Search engines usually build offline invert and forward indices to store the information of each term (including frequency, position and so on) in web pages [3][6]. Then it is easily understood that term-level propagation models can well match this mechanism and we only need to refine the offline index files. To illustrate it, let us take the ST model for example. Suppose the child pages of page p contain a particular word, and we need to propagate the occurrence frequency of this word to page p . If p already contains this particular word, we only need to modify its frequency; while if p does not contain the word, we need to add its ID to the forward index [6] of page p , and then update its term frequency. Comparatively, the score-level propagation models could hardly be integrated into search engines, because scores do not exist in the offline indices but are dependent on the online relevance ranking algorithm used in the search engine. Although term-level propagation has the potential to be integrated into search engines, whether they can finally survive will depend on their efficiencies. As we know, the update cycle of the indices propagation models can not fit the need of such frequent update, they still can not be used. To gain more understanding of this issue, we further conduct an efficiency analysis. Note that this time the working set will be the whole web page collections. For the ST model, since we need to propagate all the unique words in each page to its parent, the time complexity will be qnc , where q is the average number of unique words per page, and n is the total number of pages in the data corpus. According to [3][6], the average size of a web page is about 5~6K bytes. Therefore it is reasonable to assume that q  X  100. Furthermore, as we know, typical search engines currently indexes 5-8 billion pages. So we let n =8 X 10 9 . Based on Table 8, we know that it will cost about 8.3/3  X  2.8 ms to propagate one word on a graph with 10000 pages. Then accordingly, we can estimate that it will take about 2.8 X 8 X 10 9  X 100/10000 ms (or 62.2 hours, or 2.6 days ) to re-index the 8-billion pages. Obviously this is an acceptable time complexity. For the HT model, with similar analysis to the ST model, we know that its time complexity is h qtnlc . According to [3][16], the average number of hyperlinks per page is about 10 in real Web. we assume that the hyperlink number and iteration number in real Web are all equal to those in Table 8 (although we can expect that with larger working set, the convergence will be slower), we can estimate the lower-bound time usage for the HT model to re-index the 8-billion pages: (50/1.5) X 8 X 10 9  X 100/6800=3.9 X 10 9 1083 hours, or 45 days). Clearly, so long a time to build index is unacceptable for real search engine application and we must use parallel computation. However, as the propagation of HT happens computations into local tasks. Comparatively, since the ST model only propagates within websites, the computations can be more easily divided and conquered. Based on the above discussions and derivations, we can come to the following conclusions: 1) Score-level propagation is very difficult to implement offline; 3) The ST model is easy for parallel implementation while the In this paper, we conducted a comprehensive study on relevance propagation in Web information retrieval. In particular, a generic relevance propagation framework was proposed and shown that it can be used to derive many existing propagation models. Then we investigated the effectiveness and efficiency of those propagation models with both theoretical analysis and experimental verifications. The following conclusions are drawn from our study: 1) Generally speaking, relevance propagation can boost the 2) Sitemap-based propagation models outperform the 3) Score-level propagation and term-level propagation have 4) Term-level propagation models can be implemented offline. Overall, sitemap-based term propagation model is a good choice for search applications in terms of effectiveness, efficiency and offline parallel implementation. [1] Amento, B., Terveen, L., and Hill, W. Does "Authority" [2] Amitay, E., Carmel, D., Darlow, A., Lempel, R., and Soffer, [3] Baeza-Yates, R., Ribeiro-Neto, B. Modern Information [4] Bharat, K., and Henzinger, M. R. Improved Algorithms for [5] Bharat, K., and Mihaila, G. A. When Experts Agree: Using [6] Brin, S., and Page, L. The Anatomy of a Large Scale [7] Broder, A. A Taxonomy of Web Search. SIGIR Forum 36(2), [8] Chakrabarti, S. Integrating the Page Object Model with [9] Chakrabarti, S., Joshi, M., and Tawde, V. Enhanced Topic [10] Craswell, N., Hawking, D. Overview of the TREC 2003 Web [11] Craswell, N., Hawking, D. Overview of the TREC 2004 Web [12] Feng, G., Liu, T. Y., Zhang, X. D., Qin. T., Gao, B., Ma, W. [13] Haveliwala, T.H. Topic-Sensitive Pagerank. In Proc. of the [14] Hawking, D. Overview of the TREC-9 Web Track, in the 9th [15] Ingongngam, P., and Rungsawang, A. Report on the TREC [16] Kamvar, S. D., Haveliwala, T. H., Manning, C. D., Golub, G. [17] Kleinberg, J. Authoritative Sources in a Hyperlinked [18] Mcbryan, O. GENVL and WWWW: Tools for Taming the [19] Page, L., Brin, S., Motwani, R., and Winograd, T. The [20] Robertson, S. E. Overview of the Okapi Projects, Journal of [21] Robertson, S. E., and Sparck Jones, K. Relevance Weighting [22] Shakery, A., Zhai, C. X. Relevance Propagation for Topic [23] Song, R., Wen, J. R., Shi, S. M., Xin, G. M., Liu, T. Y., Qin, 
