 Recently, various domain-specific search engines emerge, wh-ich are restricted to specific topicalities or document for-mats, and vertical to the broad-based search. Simply ap-plying the ranking model trained for the broad-based search to the verticals cannot achieve a sound performance due to the domain differences, while building different ranking models for each domain is both laborious for labeling suf-ficient training samples and time-consuming for the train-ing process. In this paper, to address the above difficulties, we investigate two problems: (1) whether we can adapt the ranking model learned for existing Web page search or verti-cals, to the new domain, so that the amount of labeled data and the training cost is reduced, while the performance re-quirement is still satisfied; and (2) how to adapt the ranking model from auxiliary domains to a new target domain. We address the second problem from the regularization frame-work and an algorithm called ranking adaptation SVM is proposed. Our algorithm is flexible enough, which needs only the prediction from the existing ranking model, rather than the internal representation of the model or the data from auxiliary domains. The first problem is addressed by the proposed ranking adaptability measurement, which quantitatively estimates if an existing ranking model can be adapted to the new domain. Extensive experiments are per-formed over Letor benchmark dataset and two large scale datasets crawled from different domains through a com-mercial internet search engine, where the ranking model learned for one domain will be adapted to the other. The results demonstrate the applicabilities of the proposed rank-ing model adaptation algorithm and the ranking adaptability measurement.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models
This work was performed when Bo Geng was visiting Mi-crosoft Research Asia as a research intern.
 Algorithms, Theory, Experimentation.
 Information Retrieval, Support Vector Machines, Learning to Rank, Domain Adaptation.
Learning to rank is a kind of learning based information retrieval technique, specialized in learning a ranking model with some documents labeled wi th their relevancies to some queries, where the model is hopefully capable of ranking the documents for an arbitrary new query automatically. Based on various machine learning methods, existing learning to rank algorithms have already shown their promising perfor-mances in information retrieval, especially Web search, e.g., Ranking SVM [10, 12], RankBoost [8], RankNet [2], ListNet [4], LambdaRank [3], and etc.

However, as the emergence of domain-specific search en-gines, more attentions have moved from the broad-based search to specific verticals, for hunting information constraint to a certain domain. Different vertical search engines deal with different topicalities or document types. For example, a medical search engine should clearly be specialized in terms of its topical focus, whereas a music, image or video search engine would concern only the documents in particular for-mats.

Since currently the broad-based and vertical search en-gines are all based on text search techniques, the rank-ing model learned for broad-based can be utilized directly to ranking the documents for the verticals. However, the broad-based ranking model is built upon the data from mul-tiple domains, and therefore cannot generalize well for a par-ticular domain with special search intentions. Alternatively, each vertical can learn its own ranking model independently. However, it X  X  laborious to label sufficient training samples and time-consuming to train different models for each ver-tical, since the number of verticals is increasing drastically.
Based on our experimental results, the ranking model of the broad-based search can provide a reasonable, though not as perfect as the specifically trained, ranking model for verti-cal search applications. Thereafter, we can make a trade-off between the direct using of the broad-based model and the independent learning of a completely new ranking model, for each specific vertical. That is, the broad-based rank-ing model can be adapted, with the help of several labeled samples, for ranking the documents in the new verticals. Because the existing broad-based ranking model provides a lot of common information in ranking documents, only few training samples are needed to be labeled in the new do-main. From the probabilistic perspective, the broad-based ranking model provides a prior knowledge, so that only few new samples are sufficient for the target ranking model to achieve the same confidence. Hence, to reduce the cost for new verticals, how to adapt the auxiliary ranking models to the new target domain turns into a pivotal problem for building effective domain-specific ranking models.
Ranking adaptation is closely related to classifier adapta-tion, which has shown its effectiveness for several learning problems [1, 6, 7, 21, 15, 25, 27]. However, to the best of our knowledge, there are no prior works on the model adapta-tion for the ranking problem. Besides the general difficulties faced by the classifier adaptation, such as covariate shift (or namely sample selection bias) [21, 27] and concept drifting [15], ranking model adaptation is comparatively more chal-lenging. Unlike classifier adaptation, which mainly deals with binary targets, ranking adaptation desires to adapt the model which is used to predict the rankings for a collection of documents. Though the documents are normally labeled with several relevance levels, which seems to be able to be handled by multi-class classification or regression, it is still difficult to directly use classifier adaption for ranking. The reason lies in two-fold: (1) in ranking, the mainly concerned is about the preference of two documents or the ranking of a collection of documents, which is difficult to be modeled by classification or regression; (2) the relevance levels be-tween different domains are sometimes different and need to be aligned.

In this paper, we focus on the adaptation of ranking mod-els, instead of utilizing the labeled data from auxiliary do-mains directly, which may be inaccessible due to privacy issue or data missing. Moreover, Model adaptation is more desirable than data adaptation, because the learning com-plexity is now only correlated to the size of the target do-main training set, which should be much smaller than the size of auxiliary data. In this paper, we X  X e going to investi-gate two problems of ranking model adaptation: (1) whether we can adapt the ranking model learned for the existing broad-based search or some verticals, to a new domain, so that the amount of labeled data is reduced while the per-formance requirement is still guaranteed; and (2) how to adapt the ranking model effectively and efficiently. We ad-dress the second problem from the regularization framework and a ranking adaptation SVM algorithm is proposed. Our algorithm is a black-box ranking model adaptation, which needs only the predictions from the existing ranking model, rather than the internal representation of the model itself or the data from the auxiliary domains. With the black-box adaptation property, we achieved not only the flexibility but also the efficiency. The first problem is solved by the pro-posed ranking adaptability measure, which quantitatively es-timates whether an existing ranking model can be adapted to the new domain, and predicts the potential performance for the adaptation.

The rest of the paper is organized as follows. In Section 2, some related works are reminded. We formally present and analyze the proposed ranking adaptation algorithm in Section 3. Section 4 explores the ranking adaptability. The experimental results are shown and discussed in Section 5. Section 6 concludes the paper.
To create a ranking model that can rank the documents according to their relevance for a given query, various types of models have been proposed, some of which have even been successfully applied to Web search engines. Classical BM25 [20] and Language Models for Information Retrieval (LMIR) [16, 19] work quite stable for the broad-based search with few parameters needing adjusted. However, as the development of statistical learning methods, and more labeled data with complicated features being available, sophisticated ranking models become more desirable for achieving better ranking performance. Recently, a dozen of learning to rank algo-rithms based on machine learning techniques have been pro-posed. Some of them transform the ranking problem into a pairwise classification problem, which takes a pair of docu-ments as a sample, with the binary label taken as the sign of the relevance difference between the two documents, e.g., Ranking SVM [10, 12], RankBoost [8], RankNet [2] and etc. Some other methods focus on the structure of ranking list and the direct optimization of the objective evaluation mea-sures such as Mean Average Precision (MAP) and Normal-ized Discounted Cumulative Gain (NDCG). The methods include ListNet [4], SVM Map [26], AdaRank [23], Permu-Rank [24], LambdaRank [3] and etc. In this paper, instead of designing a new learning algorithm, we focus on the adap-tation of ranking models across different domains based on the existing learning to rank algorithms.

A lot of domain adaptation methods have also been pro-posed to adapt auxiliary data or classifiers to a new do-main. Daume and Marcu proposed a statistical formulation in terms of a mixture model to address the domain distri-bution differences between training and testing sets [7]. A boosting framework was also presented for the similar prob-lem [6]. For natural language processing, Blitzer and et al. [1] introduced a structural correspondence learning method which can mines the correspondences of features from dif-ferent domains. For multimedia application, Yang and et al. [25] proposed Adaptive SVM algorithm for the cross-domain video concept detection problem. However, those works are mainly designed for classification problems, while our work is focused on the domain adaptation problem for ranking in this paper. The most similar work is presented in [5], which aimed at utilizing the auxiliary data for the target rank-ing model learning, i.e., data adaptation instead of ranking model adaptation. In the following, we X  X l demonstrate that our proposed model adaptation algorithm is more advan-tageous than the data adaptation approach, from both the flexibility and efficiency perspectives.
We define the ranking adaptation problem formally as fol-lows: for the target domain, a query set Q = { q 1 ,q 2 ,...,q and a document set D = { d 1 ,d 2 ,...,d N } are given. For each query q i  X  Q , a list of documents d i = { d i 1 ,d i 2 ,...,d are returned and labeled with the relevance degrees y i = { y 1 ,y i 2 ,...,y i,n ( q i ) } corresponding to the query q man annotators. The relevance degree is usually a real value, so that different returned do cuments can be compared for sorting an ordered list, i.e., y ij  X  R . For each query doc-ument pair &lt;q i ,d ij &gt; ,an s -dimensional feature vector  X  ( q i ,d ij )  X  R s is extracted. n ( q i ) denotes the number of returned documents for query q i . The target of learning to rank is to estimate a ranking function f  X  R s  X  R so that the documents d canberankedforagivenquery q according to the value of the prediction f (  X  ( q, d )).

In the setting of the proposed ranking adaptation, both the number of queries m and the number of the returned documents n ( q i ) in the training set are assumed to be small. They are insufficient to learn an effective ranking model for the target domain. Moreover, an auxiliary ranking model f , which is well trained in another domain over the labeled data Q a and D a , is available. It is assumed that the auxil-iary ranking model f a contains a lot of prior knowledge to rank documents, so it can be used to act as the base model to be adapted to the new domain. Few training samples can be enough to adapt the ranking model since the prior knowledge is available.

Before the introduction of our proposed ranking adapta-tion algorithm, it X  X  important to review the formulation of Ranking Support Vector Machines (Ranking SVM), which is one of the most effective learning to rank algorithms, and is here employed as the basis of our proposed algorithm.
Similar to the conventional Support Vector Machines (SVM) for the classification problem [22], the motivation of Ranking SVM is to discover a one dimensional linear subspace, where the points can be ordered into the optimal ranking list under some criteria. Thus, the ranking function takes the form of the linear model f (  X  ( q, d )) = w T  X  ( q, d ), where the bias pa-rameter is ignored, because the final ranking list sorted by the prediction f is invariant to the bias. The optimization problem for Ranking SVM is defined as follows: where C is the trade-off parameter for balancing the large-margin regularization || f || 2 and the loss term i,j,k  X 
Because f is a linear model , we can represent f (  X  ( q i f (  X  ( q i ,d ik )) = f (  X  ( q i ,d ij )  X   X  ( q i ,d ik  X  ( q i ,d ik ) denoting the difference of the feature vectors be-tween the document pair d ij and d ik . If we further introduce the binary label sign( y ij  X  y ik ) for each pair of documents d ij and d ik , the above Ranking SVM problem can be viewed as a standard SVM for classifying document pairs into pos-itive or negative, i.e., whether the document d ij should be ranked above d ik or not.

Since the number of labeled samples for the new domain is small, if we train the model using only the samples in the new domain, it will suffer from the insufficient training sample problem, which is ill-posed and the solution may be easily overfitting to the labeled samples with low general-ization ability. Moreover, the current SVM solver requires super-quadratic computational cost for the training [18], as a consequence, it is quite time-consuming and nearly in-feasible to train models using the training data from both the auxiliary domain and the target domain. This problem is more severe for the ranking SVM since the training are based on pairs and so the problem size is quadratic to the sample size.

In the following, we will develop an algorithm to adapt the auxiliary model using the few training samples labeled in the new domain. By model adaption, both the effectiveness of the result ranking model and the efficiency of the training process are achieved.
It can be assumed that, if the auxiliary domain and the target domain are related, their respective ranking functions f and f a should have similar shapes in the function space R s  X  R . Under such an assumption, f a actually provides a prior knowledge for the distribution of f in its parame-ter space. The conventional regularization framework shows that the solution of an ill-posed problem can be approxi-mated from variational principle, which contains both the data and the prior assumption [9]. Consequently, we can adapt the regularization framework which utilizes the f a the prior information, so that the ill-posed problem in the target domain, where only few query document pairs are la-beled, can be solved elegantly. By modeling our assumption into the regularization term, the learning problem of Rank-ing Adaptation SVM (RA-SVM) can be formulated as:
The objective function (2) consists of the adaptation reg-ularization term || f  X  f a || 2 , which minimizes the distance between the target ranking function and the auxiliary one in the function space or the parameter space, to make them close; the large-margin regularization || f || 2 ;andtheloss term i,j,k  X  ijk . The parameter  X   X  [0 , 1] is a trade-off term to balance the contributions of large-margin regularization || f || 2 which makes the learned model numerically stable, and adaptation regularization || f  X  f a || 2 which makes the learned model similar to the auxiliary one. When  X  =0,Problem (2) degrades to the conventional Ranking SVM (1), in other words, RA-SVM is equivalent to directly learning Ranking SVM over the target domain, without the adaptation of f a The parameter C is the same as in Ranking SVM, for bal-ancing the contributions between the loss function and the regularization terms. It can be observed that when C =0 and  X  = 1, (2) actually discards the labeled samples in the target domain, and directly output a ranking function with f = f a . This is sometimes desirable, since if the labeled samples in the auxiliary domain are unavailable or unusable, f a is believed to be better than random guess for ranking the documents in the target domain, as long as the auxiliary domain and the target domain are related.
To optimize problem (2), we briefly denote x ijk =  X  ( q i  X  ( q i ,d ik ) and introduce the Lagrange multipliers to inte-grate the constraints of (2) into the objective function, which results into the primal problem:
Taking the derivatives of L P w.r.t. f , and setting it to zero, we can obtain the solution as:
Denoting  X  f ( x )= i,j,k  X  ijk x T ijk x ,whichcanbeviewed as the part of support vectors learned from the target do-main, we can derive from (4) that the final ranking function f , which we would like to achieve for the target domain, is a linear combination between the auxiliary function f a and the target part  X  f , and the parameter  X  controls the contribution of f a .

In addition to (4), the optimal solution of problem (2) should satisfy the Karush-Kuhn-Tucker (KKT) conditions, which are consisted of:
Substituting (4) and (5) back into (3), we can derive the dual problem formulation as:
The above problem is a standard Quadratic Programming (QP) problem, and any standard QP solvers, e.g. SMO [18], can be utilized to solve it.

Notice that we can firstly train a ranking model in the target domain, and then linearly combine it with the auxil-iary model, which shows the same solution as shown in (4). However, as the scarcity of labeled data, purely training a ranking model in the target domain will lead the model over-fitting to the training samples, and cannot effectively com-bine with auxiliary model for a satisfactory performance. RA-SVM differs in that it learns a joint ranking model by considering f a during the learning phase, as shown in (6). The overfitting problem can be overcomed by utilizing the prior information from the auxiliary model.
The proposed RA-SVM has several advantages, which makes our algorithm highly applicable and flexible when applied to the practical applications. We X  X l give the detailed discussions of the characteristics of RA-SVM in the following.
Our proposed RA-SVM can be extended to a more gen-eral setting, where ranking models learned from multiple domains are provided. Denoting the set of auxiliary rank-ing functions as F = { f a 1 ,f a 2 ,...,f a R } , the RA-SVM for the multiple domain adaptation setting can be formulated as: min s . t .f (  X  ( q i ,d ij ))  X  f (  X  ( q i ,d ik ))  X  1  X   X  for  X  i  X  X  1 , 2 ,...,M } , where  X  r is the parameter that controls the contribution of ranking model f a r obtained from the r th auxiliary domain, and we can further constrain R r =1  X  r =1withoutanyloss of generality. Similar to the analysis in the one domain adaptation setting, the solution for problem (7) is:
If we represent f a ( x )= R r =1  X  r f a r ( x ), the auxiliary rank-ing functions can be regarded as a single one, which lies in the convex hull of F . Thus, similar to the discussion of (4), the final ranking model is a linear combination of two parts, i.e., the convex combination of ranking functions from auxiliary domains f a , and the part from the target set  X  f = i,j,k  X  ijk x T ijk x , with the parameter  X  r controlling the contribution of the auxiliary model f a r , while  X  control-ling all the contributions from F globally.
Though the ranking adaptation can mostly provide bene-fits for learning a new model, it can be argued that when the data from auxiliary and target domains share little common knowledge, the auxiliary ranking model can provide little help or even negative influence, to the ranking of the doc-uments in the target domain. Consequently, it is impera-tive to develop a measure for quantitatively estimating the adaptability of the auxiliary model to the target domain. However, given a ranking model and a dataset collected for a particular target domain, it X  X  nontrivial to measure their correlations directly, because neither the distribution of the ranking model nor that of the labeled samples in the target domain is trivial to be estimated. Thus, we present several analyses on the properties of the auxiliary model, based on which the definition of the proposed ranking adaptability is presented.
We analyze the effects of auxiliary model through the loss constraint in the formulation of our RA-SVM. By substitut-ing (4) into (2), we can obtain that: where, as defined before, x ijk =  X  ( q i ,d ij )  X   X  ( q  X  f = i,j,k  X  ijk x T ijk x . Thus, in order to minimize the rank-ing error  X  ijk for the document pair d ij and d ik , we X  X e hoping to get a high prediction value on the left-hand side of the first inequation in (9). For a given auxiliary ranking func-tion f a , a comparatively large f a ( x ijk ) suggests that f correctly judge the order for the document pair d ij and d and vice versa. According to the constraints (9), if f a is ca-pable of predicting the order of the documents correctly, we can relax the contribution of the part of the ranking function learned in the target domain, i.e.,  X  f .Atanextremecase, if f a is able to predict all pairs of documents correctly in the target domain, namely it can give perfect ranking lists for all the labeled queries, we may derive that f a should be adapted to the target domain directly without any nec-essary modifications (except the adaptation for the  X  X arge margin X  requirement in the target domain). On the other hand, if f a cannot give a desirable ordering of the document pairs, we have to leverage  X  f with a high contribution to eliminate the side effects of f a , so that the ranking error over labeled samples is reduced. Consequently, the perfor-mance of f a over the labeled document pairs in the target domain takes great effects to the learning of RA-SVM for the ranking adaptation.
Based on the above analysis of f a ,weproposetodevelop the ranking adaptability measurement by investigating the correlation between two ranking lists of the labeled docu-ments in the target domain, i.e., the one predicted by f a and the ground-truth one labeled by human judges. Intu-itively, if the two ranking lists have high positive correlation, the auxiliary ranking model f a is coincided with the distri-bution of the corresponding labeled data, therefore we can conclude that it possesses high ranking adaptability towards the target domain, and vice versa. In this paper, we adopt the well-known Kendall X  X   X  [14] to calculate the correlation between the two ranking lists, based on which the definition of the proposed ranking adaptability is presented.
For a given query q i , we denote the rank list predicted by the ranking function f as y  X  i = { y  X  i 1 ,y  X  i 2 ,...,y and define a pair of documents ( d ij ,y ij )and( d ik ,y ( y y )( y ij  X  y ik ) &gt; 0] and the number of discordant pairs as N sign( x ) is the sign function with sign( x )=1if x&gt; 0, sign( x )=  X  1if x&lt; 0, and sign( x ) = 0 otherwise. Sup-pose q i has neither tied prediction (i.e., for  X  j  X  ky  X  nor tied relevance (i.e., for  X  j  X  ky ij = y ik ), then N we can define the rank correlation for function f over the query q i based on the Kendall X  X   X  as:
However, ties are quite common for general applications, especially in the Web search scenario. When ties do exist, we can handled them by adding 0.5 to N c i and 0.5 to N d y ij = y ik , and ignore the pairs with y more general definition for the correlation is:
Thus, it is obvious  X  i ( f )  X  [  X  1 , 1], where  X  i ( f ) = 1 corre-sponds to the positive correlation between y  X  i and y i ,  X   X  1 equals to the negative correlation, and  X  i ( f )=0means uncorrelated.

Based on (11), the proposed ranking adaptability of aux-iliary ranking model f a for the target domain, is defined as the mean of the Kendall X  X   X  correlation between the pre-dicted rank list and the perfect rank list, for all the labeled queries in the target domain, namely,
The proposed ranking adaptability measures the rank cor-relation between the ranking list sorted by auxiliary model prediction and the ground truth rankings, which in turn gives us an indication of whether the auxiliary ranking model Table 2: Ranking Adaptation Experiment Settings.
 can be leveraged for the adaptation to the target domain, and how much assistance it can provide. Based on the rank-ing adaptability , we can perform automatic model selection for determining which auxiliary models will be adapted. The effectiveness of the proposed ranking adaptability measure-ment will be demonstrated experimentally in Section 5.3.
In this section, we perform several experiments under two different settings, to demonstrate the effectiveness of the proposed RA-SVM algorithm and the ranking adaptability measurement.
We firstly conduct the experiments over the Letor bench-mark dataset [17],and adapt the ranking model learned from TD2003 dataset to the ranking of TD2004 dataset. Letor TD2003 and TD2004 datasets are gathered from the topic distillation task of TREC 2003 and TREC 2004, with 50 queries for TD2003 and 75 ones for TD2004. The docu-ments are collected by crawling from the .gov domain. For each query, about 1000 associated documents are returned, and labeled with a binary judgment, i.e., relevant or irrel-evant. The features of TD2003 and TD2004 include the low-level features such as term frequency, inverse document frequency, and document length, as well as high-level fea-tures such as BM25, LMIR, PageRank, and HITS, for totally 44 dimensional features. However, Letor is a comparatively small dataset, and each document is only labeled with a binary relevance degree, which cannot reflect the practical Web search scenarios with multiple relevance degrees.
Therefore, to give a more thorough analysis of our pro-posed RA-SVM, we collect more large scale datasets from a commercial internet search engine. Two datasets are sepa-rately gathered from different domains, i.e. the Web page search and the image search engines. There are totally 2625 queries for the Web page search domain, and 2053 queries for image. At most 50 documents for each query are crawled and labeled, resulting into 46.79 documents returned for each Web page search query and 48.91 images for each image query on average. Query-dependent features are extracted for all query-document pairs based on different document sources, e.g., the anchor text, the URL, the document title and the body. Some other features are also incorporated, such as the static rank, the junk page and so on. Totally 354 dimensional features are extracted. Note that current image search engine only utilize the textual features, and in this paper, we only consider adapting the Web page text based ranking model to image textual feature based rank-ing. We X  X l consider how to utilize image content feature in the future work. Each query-document pair is labeled with a relevance degree by the human judges. The range of the relevance degree for Web page search is from 0 (i.e.  X  X ads X ) to 4 (i.e.  X  X erfect match X ) with totally five degrees, while for image, they are labeled 0 (i.e.  X  X rrelevant X ), 1 (i.e.  X  X ele-vant X ) and 2 (i.e.  X  X ighly relevant X ) with three degrees. The documents labeled as  X  X etrimental X  are removed from both datasets. The detailed information of each dataset, includ-ing the number of queries, query document pairs, relevance degrees, and feature dimensions are shown in Table 1.
The performance evaluations of the ranking results are based on two measures, namely, mean average precision (MAP) and normalized discounted cumulative gain at different rank truncation levels (NDCG@n) [11], for a comprehensive anal-ysis of the performances of different algorithms. The MAP, one of the most frequently used measure to evaluate the aver-age performance of a ranking algorithm, denotes the mean of the average precision (AP) , where the AP computes the area under precision/recall curve with non-interpolated manner and prefers relevant samples with higher rank. Since AP is evaluated only for binary judgement, we define relevance level 0 as non-relevant and all the other relevance degrees as relevant for all the datasets. To measure the ranking perfor-mance for multiple degree relevance, NDCG is proposed as a cumulative, multilevel measure of ranking quality, which is usually truncated at a particular rank level [11]. For a given query q i , the NDCG is calculated as: where r ( j ) is the relevance degree of the j th document, N is the normalization coefficient to make the perfect order list with N i =1,and L is the ranking truncation level at which NDCG is computed. In this paper, we evaluate NDCG@n by setting the truncation level n as at most 20.
We build the auxiliary ranking model by training Rank-ing SVM with different paramete rs over some labeled queries randomly sampled from the auxiliary domain, namely Letor TD2003 dataset and Web page search dataset, and then se-lect the models that are best performed over the remained respectively. Figure 2: The MAP of TD2003 to TD2004 adapta-tion results, with 5 and 10 labeled queries in TD2004 respectively. data in the auxiliary domain. In the adaptation target do-main, where the performance of different algorithms are re-ported, we randomly select several queries as the pool of the labeled data for adaptation, several queries as the validation set to determine the parameter s of different algorithms, and the remaining queries as the test set for the performance evaluation. We varies the size of adaptation set gradually, so that we can see the influence of the size of labeled sam-ples to the performance of the adapted ranking model. For each size, we generate five different adaptation sets by ran-domly sampling from the labeled adaptation data pool that is selected before, and then perform each algorithm over the generated sets separately, resulting into five ranking models. The final performance reported in this paper is the average results of the five ranking models, validated over the same validation set and evaluated over the same test set. The details of two experiment settings are summarized in Table 2.
 In order to demonstrate the effectiveness of our proposed RA-SVM, we compare the performance of RA-SVM to the Ranking SVM models learned purely from the adaptation sets of the target domain without adaptation (Tar-Only), as well as the results of applying the auxiliary ranking model directly to the test set (Aux-Only). In addition, we also compare to the performance of linearly combine the Aux-Only model and the Tar-Only model (Lin-Comb), to show that RA-SVM is able to fully leverage the auxiliary model to learn a more robust target ranking model, than directly combining the two independent models.
The NDCG and MAP of utilizing 5 and 10 labeled queries, which are randomly selected from adaptation data pool, are shown in Fig.1 and Fig.2 respectively. For 5 labeled queries, the Aux-Only model performs better than the Tar-Only one, whose performance is suffered from the insufficient labeled queries in the target domain. Meanwhile, it can be observed that the Lin-Comb and RA-SVM outperform the above two methods significantly, since both the Aux-Only model and target domain X  X  data information are utilized. In addition, RA-SVM shows the best performance over all, es-pecially for the first several truncation levels. For 10 labeled adaptation queries, as the number of labeled queries in-creased,the Tar-Only comes to outperform Aux-Only model. However, Lin-Comb almost performs equally to the Tar-Only results. We argue that directly combining Aux-Only and Tar-Only cannot effectively utilize the information of both auxiliary model and target domain, because the two models are trained independently and combined intuitively. For Lin-Comb, the Tar-Only model may have overfitted to limited queries in the adaptation set, while the Aux-Only model cannot discover the domain-specific knowledge, and their combination is consequently limited for inducing a ro-bust ranking model. Finally, RA-SVM, by leveraging the auxiliary model to build the target domain X  X  model jointly in one step, leads to the best performance over all the meth-ods. To further demonstrate the effectiveness of the proposed RA-SVM algorithm, we perform several experiments by adapt-ing the ranking model trained from Web page search domain (b) labeled queries of image search dataset utilized respectively. Figure 4: The MAP of Web page search to image search adaptation results, with 10, 30, and 50 la-beled queries of image search dataset utilized re-spectively. to the image search domain. The performances with 10, 30, and 50 labeled queries are shown in Fig.3 and Fig.4 respec-tively. It can be observed that, at each adaptation size, RA-SVM consistently outperform other methods significantly at all truncation levels. Furthermore, we can derive that for the 10 queries setting, the performance of Aux-Only model is much better than Tar-only one, because of the insufficient labeled sample problem. On the contrary, for the 50 queries setting, Tar-only model performs better than Aux-Only one, due to the larger size of training set and the limited per-formance of the auxiliary model caused by the domain dif-ferences. For Lin-Comb, as we discussed for the TD2003 to TD2004 adaptation, simply combine two ranking mod-els, cannot obtain desirable results. RA-SVM, by leveraging both the auxiliary model and the few labeled data in the target domain jointly, shows the best performance for both measurements.

In order to show the relationship between the performance and the size of adaptation set, we varies the adaptation set from 10 to 50 gradually and test the performance of each algorithm. The results are shown in Fig.5. We observe that for a small number of labeled queries in the target set, the ranking model of Tar-Only cannot give satisfying results, due to the insufficient training sample problem. However, by adapting the auxiliary model, the performance of RA-SVM with only 10 labeled queries can be comparative to the results of Tar-only with 50 queries. On the other hand, the auxiliary model itself can only give a poor performance over the test set of the target domain, due to the domain dif-ferences between Web pages and image documents, as men-tioned before. However, with the help of only several labeled query document pairs in the target domain, the ranking per-formance can be substantially boosted. Finally, we find that the performance improvement does not degrade much as the increase of the adaptation set, which gives a proof that our algorithm is quite effective for maximally utilizing the aux-iliary ranking model, even for a comparatively large number of labeled queries available in the target domain.
In this subsection, we perform several experiments to prove the effectiveness of the proposed ranking adaptability ,and the applicability for auxiliary model selection.

Firstly, ten ranking models are learned over the training set of the auxiliary domain, i.e., the TD2003 and the Web page search domain respectively, with the same training set used for the experiments in section 5.2 and Table.2. We still adopt Ranking SVM to learn the ranking models as the candidate auxiliary models. The ten models are learned by varying the parameter C of Ranking SVM. Then, we apply each model respectively to the target domain for adaptation experiments, using our RA-SVM. Finally, according to (12), the ranking adaptabilities of all the models over the adap-tation sets from image search domain are calculated. The performances and the ranking adaptabilities to be reported are averaged over the five random splits of adaptation sets. To be concise, we only show the results on the adaptation set composed of five labeled queries for TD2004 dataset and ten labeled queries for image search dataset, while the results of other sizes of adaptation sets are similar.

The evaluation measures of NDCG@20 and MAP are plot-ted together with the ranking adaptabilities in Fig. 6. We can conclude that, for both TD2003 to TD2004 and Web page search to image search, the performances of the adapted ranking models are approximately coincided with the pro-posed ranking adaptability , i.e., the ranking models with high adaptability will achieve a better performance in the target domain if being adapted, and vice versa. As dis-cussed before, such a property can be utilized for automatic model selection of the auxiliary ranking models for adapta-tion, given some labeled queries in the target domain.
As various vertical search engines emerge and the amount of verticals increase dramatically, the global ranking model, which is trained over a dataset sourced from multiple do-mains, cannot give a sound performance for each specific do-main with special topicalities or document formats. Building one model for each vertical domain is both laborious for la-beling the data and time-consuming for learning the model. In this paper, we propose the ranking model adaptation, to adapt the well learned models from broad-based search or any other auxiliary domains to a new target domain. By model adaptation, only a small number of samples need to be labeled, and the computational cost for the training pro-cess is greatly reduced. Based on the regularization frame-work, a Ranking Adaptation SVM algorithm is proposed, which performs adaptation in a black-box way, i.e., only the relevance predication of the auxiliary ranking models is needed for the adaptation. Furthermore, we propose ranking adaptability , to quantitatively measure whether an auxiliary model can be adapted to a specific target domain and how much assistance it can provide. We performed several exper-iments over Letor benchmark datasets and two large scale datasets obtained from a commercial internet search engine, and adapted the ranking models learned from TD2003 to TD2004 dataset, as well as from Web page search to image search domain. The results demonstrate that the proposed RA-SVM and ranking adaptability are consistently effective. page to image MAP.
