 This paper aims at defining integrated metadata for ubiquitous multimedia informa-ous environments. Defining this integrated metadata starts from ensuring compatibil-ity with the current international multimedia metadata standards. In other words, it is necessary to ensure compatibility mainly with MPEG-7 Multimedia Description Scheme (MDS) [1] and TV Anytime metadata [2]. These two standards include the widest range of elements and attributes related to multimedia-related metadata that have emerged so far, so that they can be a useful basis for defining integrated meta-signing federated multimedia information system on the semantic web. 
For this purpose, MPEG-7 MDS and TV-Anytime metadata were compared and analyzed to identify commonness and differences between these two standards. Based on the results, metadata made up of a union of these two standards was created. Inves-tigating these two standards revealed that some definitions were expressed in different terms even though they have the same meaning. In this case, either ones were used or third terms were selected. In another case, an element or an attribute of a definition in standard, which was easily integrated. When two elements had an intersection with remnants were defined with the terms originally used in the standard. Roantree[3] describes a metadata management scheme for federated multimedia sys-tems. He adopted an object oriented common model for integrating metadata and proposed a high-level query interface for the ODMG schema repository. This scheme multimedia information retrieval systems. Most recent research [4][5][6][7][8] pro-poses ontology based approach for multimedia information systems. Specially, Tsina-raki et al.[7][8] proposes a framework which allows transforming OWL ontology to MPEG-7 and TV-Anytime. However, they have not showed an integrated metadata with which access MPEG-7 and TV-Anytime metadata. Tsinaraki et al. transforms OWL to MPEG-7 and OWL to TV-Anytime respectively. The approach of transform-ing OWL to each metadata is not flexible enough to support non-standard metadata. This paper proposes a universal metadata that will support non-standard multimedia metadata as well as the standard multimedia metadata. MPEG-7 MDS (ISO/IEC JTC1/SC29/WG11) is an international standard for multi-media contents, which enables efficient storage, retrieval and transmission of multi-media data by effectively expressing them . On the other hand, TV-AnyTime metadata was designed to fit the digital TV broadcasting environment. Therefore, most multi-media data deals with motion images. MPEG-7 MDS expresses much more informa-tion in XML schema format, in comparison to TV-AnyTime Metadata. 
Of these two standards, MPEG-7 MDS deals with all digital contents such as im-age information, audio, video, and 3D as well as motion images, unlike TV-AnyTime Fig. 1 shows the relationship between MPEG-7 MDS and TV-AnyTime. Most ele-ments of TV-AnyTime metadata correspond to some elements of MPEG-7 MDS. This chapter describes a part of a UMA(unified multimedia access) metadata that have been newly defined by integrating MPEG-7 and TV-AnyTime metadata. Even though we have derived a larger set of integrated metadata elements, we describe one of them to show the principle of metadata integration. The CreationType element of MDS is related with the BasicDescription element of TVA metadata as shown in Fig. 2 . The relationship between descendents of these two elements is summarized in Table 3. Since MPEG-7 and TV-AnyTime have a same name for  X  X itle X , UMA metadata accept this name for the meaning of  X  X itle X . How-ever, since these two standards have two different names for  X  X edia title X , we need to choose one word for  X  X edia title X . Here we take the element name of MPEG-7 for the new metadata. Similarly, several new element names are defined for the elements common to the two standards even though we describe only one element in this paper. This section describes the architecture of the web service based multimedia integra-tion system that we have implemented for experimenting the applicability of UMA metadata. Since the integration system is implemented using web services technology, it gives users more flexibility than previous multimedia integration systems. The integration system is composed of three layers: application layer, mediation layer, and resource layer. The web service API provided by the mediation layer and the resource layer are used for data transfer between layers. 5.1 Application Layer In Application Layer, a user or an upper module transfers query and receives the re-genre, ID, or keyword. Application Layer calls the web service API provided by Me-diation Layer. This API transfers the query to Mediation Layer in XML format using XML format. 5.2 Mediation Layer Mediation Layer is composed of Query Processor, Rule Manager, and Global Schema Manager. Query is transferred from Application Layer to Mediation Layer using the API methods. Since the mediator functions are implemented using web services, users can connect a mediator and wrappers using API. Users may compose this relation-ship using a graphical user interface. 5.3 Resource Layer Resource Layer is connected to Local DB through wrappers. This layer retrieves rele-vant data from Local DB. Resource Layer is composed of a wrapper manager and multiple wrappers. Since the major functions are provided with web services API, users can build their own wrapper with ease. 5.4 Experiment The proposed integration framework and metadata work well for retrieving multime-dia data in heterogeneous resources. However, it is slower retrieving multimedia data from homogeneous resources. The simulation is performed on one computer system and the simulation program calls wrappers N times. The result shows relative com-with MPEG-7 MDS only, from databases described with TV-AnyTime metadata and from databases described with MPEG-7 and TV-AnyTime. Retrieving data from MPEG-7 described databases takes longer than any other cases. Retrieving data from TV-AnyTime described databases takes shorter than retrieving data from MPEG-7 databases. The system shows better perform ance in retrieving data from databases with MPEG-7 and TV-Anytime description. This is illustrated in Fig. 3 . This paper introduced a new metadata for multimedia contents. In order to define and construct the new metadata, two standards, which are internationally recognized to have the most multimedia information, were compared to investigate their relation-ship. In order to prove the effectiveness, we have implemented a prototype system for integrating multimedia databases. We have tested UMA data by integrating databases tagged with five different standards and found that the mapping tool enables defining the relationship between UMA and the five standards semi-automatically. In addition, users can build their own wrappers and compose the relationship between wrappers and a mediator more easily than ever since the prototype system provides web service API. We have showed this efficiency by showing easily implemented prototype sys-tem in the previous section. In the future, this metadata for multimedia contents will be used in defining multimedia ontology language, like RDF or OWL [9][10], so that it can be used for context aware multimedia access. 
We are going to measure the response time by simulating concurrent access of multiple databases. This will show more realistic comparison of performance. 
