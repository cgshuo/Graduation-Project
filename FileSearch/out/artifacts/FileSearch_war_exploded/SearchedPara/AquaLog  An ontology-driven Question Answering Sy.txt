 AquaLog (Lopez, 2005) is a fully implemented ontology-driven Question Answering (QA) sys-tem 1 , which takes an ontology and a NL query as an input and returns answ ers drawn from semantic markup (viewed as a KB) compliant with the input ontology. In contrast with much existing work on ontology-driven QA, which tends to focus on the use of ontologies to support query expansion in information retrieval (Mc Guinness, 2004), AquaLog exploits the availability of semantic statements to provide precise answers to complex queries expressed in NL. 
AquaLog makes use of the GATE NLP plat-form, string distance metric, generic lexical re-sources, such as WordNet, as well as the structure of the input ontology, to make sense of the terms and relations expressed in the input query with re-spect to the target KB. Naturally, these terms and relations match the terminology familiar to the user rather than those used in the ontology. 
We say that AquaLog is portable because the configuration time required to customize the sys-tem for a particular ontology is negligible. We be-lieve that in the SW scenario it makes sense to provide a NL query interface portable with respect to ontologies , our AquaLog system allows to choose an ontology and then ask queries with re-spect to its universe of discourse. The reason for this is that the architecture of the system and the reasoning methods are domain-independent, rely-ing on an understanding of general-purpose knowl-edge representation languages, such as OWL 2 , and the use of generic lexical resources, such as WordNet. 
Moreover, AquaLog learning mechanism en-sures that, for a given ontology and a particular community jargon used by end users, its perform-ance improves over time, as the users can easily correct mistakes and allow AquaLog to learn novel associations between the NL relations used by us-ers and the ontology structure. Approach. AquaLog uses a sequential process model (see Fig. 1), in which NL input is first trans-lated into a set of intermediate representations  X  called Q uery Triples , by the Linguistic Compo-nent. The Linguistic Component uses the GATE infrastructure and resources (Cunningham, 2002) to obtain a set of syntactic annotations associated with the input query an d to classify the query. Once this is done, it becomes straight-forward for the Linguistic Component to automatically create the Query-Triples. Then, these query triples are further processed and interpreted by the R elation Sim ilarity Se rvice Co mponent (RSS), which uses lexical r esources and the o ntology to map the m to ontolo gy-co mpliant semantic markup o r triples. The Linguistic Co mponent X  X  task is to map the NL input quer y to the Query -Triple. GATE (Cunnin g-ham , 2002) infrastructure and resources (e.g. pr oc-essing resources like A NNIE) are part of the Linguistic Co mponent. set of sy ntactic annotations associ ated with the in-put query are returned. These annotations include inform ation about sentences, tokens, nouns and verbs. For exa mple, w e ge t voice and te nse for the verbs and categories for the nouns, such as deter-minant, singular/plural, conjunction, possessive, determ iner, p reposition, exis tential, wh-determ iner, etc. When d eveloping AquaLog we extended the set of annotations returned b y GATE, by identif y-ing term s, relations, question indicators (which/who/when. etc.) and patterns or t ypes of questions. This is achieved through the use of Jape grammars , which consist of a set of phases , that run sequentially, and each phase is defined as a set of pattern rul es, which allow us to recognize regu-lar expressi ons using prev ious annotations in docum ents. of the Jape grammars , although we can still onl y deal with a s ubset of NL, it is possible to extend this subset in a relatively easy way by updating the regular expressions in the Jape gram mars . This ensures the easy portability of the s ystem with re-spect to both ontol ogies and natural languages. Currently , the linguistic co mponent, t hroug h the Jape grammars , d ynam ically identifies around 14 different linguistic categor ies or intermediate rep-resentations, including: ba sic queries re quiring an affir mation/negation or a description as an answer; or the big set of queries constituted by a wh-question (such as the ones starting with: what, who, when, where, are there any , does any -bod y/anyone or how m any, and im perative co m-mands like list, give, tell , name, etc.), like  X  X re there any PhD students in dotkom ? X  w here the re-lation is im plicit or unknown or  X  X hich is the job title of John? X  where no information about the type of the expected answer is provided; etc. tion that needs to be achieved, but also the y gi ve an indication of the m ost likely comm on problems that the s ystem will need to deal with t o understand this particular NL quer y and in co nsequence it guides the process of cre ating the equivalent in-ter mediat e re presentation. Categories ar e the driv-ing force to generate an answer by com bining the triples in an appropriate way . For e xam ple, in  X  X ho are the academics i nvolved i n the semantic web? X  the triple will be of the form &lt;generic term , relation, seco nd term&gt;, i.e. &lt;academ ics, involved, semantic web&gt;. A quer y with a equivalent triple representatio n is  X  X hich technologies has KMi produced? X , where the triple will be &lt;technologies, has produced, KMi&gt;. However, a query like  X  X re there any PhD students in akt?  X  has another equivalent representation, where the rel ation is im -plicit or unk nown &lt;phd s tudents, ?, a kt&gt; . Other queries may provide littl e inform atio n about the type of the e xpected answ er, i.e.  X  X hat is the job title of John? X , or they can be just a generic en-quir y ab out someone or so mething, i. e.  X  X ho is Vanessa? X ,  X  X hat is an ont olog y? X  ting the representation co mpletely right as the in-terpretation i s co mplet ely domain in dependent. The role of the triple-b ased interm ediat e represen-tation is sim ply to provide an easy wa y to represent the NL query and to m anipulate the input for the RSS. Consider the request  X  X ist all the projects in the knowledge media institute about the semantic web X , where both  X  X n knowledge media institute X  and  X  X bout s emantic web  X  are modifiers (i.e. they modify the meaning of other sy ntact ic constitu-ents). The problem here is to identif y the constitu-ent to which each modifier has to be att ached. The RSS is responsible for r esolving this am biguit y throug h the use of the ontolog y, or b y interacting with the user. The linguis tic co mponent X  X  task is therefore to pass the a mbiguity problem to the RSS through the inter mediate r epresentation. two basic queries. In this case, the intermediate representation usually consists of two triples, one triple per relationship. There are different ways in which queries can be combined. Firstly, queries can be combined by using a  X  X nd X  or  X  X r X  conjunc-tion operator, as in  X  X hich projects are funded by epsrc and are about semantic web? X . This query will generate two Query-Triples: &lt;projects, funded , epsrc&gt; and &lt;projects, ? , semantic web&gt; and the subsequent answer will be a combination of both lists obtained after resolving each triple. Secondly, a query may be conditioned to a second query, as in  X  X hich researchers wrote publications related to social aspects? X  which generates the Query-Triples &lt;researchers, wrote , publications&gt; and &lt; which are , related , social aspects&gt;,where the second clause modifies one of the terms in the first triple. In this example, ambiguity cannot be solved by linguistic procedures; therefore the term to be modified by the second clause remains uncertain. This is the backbone of the QA system. The RSS component is invoked after the NL query has been transformed into a term-relation form and classi-fied into the appropriate category. Essentially the RSS tries to make sense of the input query by look-ing at the structure of the ontology, string metrics 3 , WordNet, and a domain-dependent lexicon ob-tained by the Learning Mechanism . deal with the various sources of ambiguity. Some sentences are structurally ambiguous and although general world knowledge does not resolve this am-biguity, within a specific domain it may happen that only one of the interpretations is possible. The key issue here is to determine some constraints derived from the domain knowledge and to apply them in order to resolve ambiguity. Whether the ambiguity cannot be resolved by domain knowl-edge the only reasonable course of action is to get the user to choose between the alternative readings. Moreover, since every item on the onto-triple is an entry point in the KB or ontology the user has the possibility to navigate through them. In fact, to ensure user acceptance of the system justifications are provided for every step of the user interaction. This scenario is similar to research in NL queries to databases (NLIDB). However, the SW provides a new and potentially important context in which results from this research area can be applied. There are linguistic problems common in most kinds of NL understanding systems, see (Androut-sopoulos, 1995) for an overview of the state of the art. In contrast with the latest generation of NLIDB systems (see (Popescu, 2003) for recent work) AquaLog uses an intermediate representation from the representation of the user X  X  query (NL front end) to the representation of an ontology compliant triple, from which an answer can be directly in-ferred. It takes advantage of the use of ontologies in a way that the entire process highly portable and it is easy to handle unknown vocabulary. For in-stance, in PRECISE (Popescu, 2003) the problem of finding a mapping from the tokenization to the database requires that all tokens must be distinct, questions with unknown words are not semanti-cally tractable and cannot be handled. In contrast with PRECISE, AquaLog interpret the user query by means of the ontology vocabulary and structure in order to make sense of unknown vocabulary which appears not to have any match. nature from AquaLog as they are open-domain systems. QA applications to text typically involve (Hirschman, 2001) identifying the semantic type of the entity sought by the question (a date, a per-son...); and determining ke y words or relations to be use in matching candidate answers. Moreover, as pointed by Srihari et al. (Srihari, 2004) Named Entity (NE) tagging is often necessary. The main differences between AquaLog and open-domains systems are: (1) it is not necessary to build hierar-chies or heuristic to recognize NE, as all the se-mantic information needed is in the ontology. (2) AquaLog has mechanisms to exploit the relation-ships to understand a query. Nevertheless, the RSS goal is to map the relationships in the Query-Triple into an ontology-compliant-triple. Both AquaLog and open-domain systems attempt to find syno-nyms plus their morphological variants. AquaLog also automatically classifies the question before hand, based on the kind of triple needed, while most of the open-domain QA systems classify questions according to their answer target. The triple contains information not only about the an-swer expected, but also about the relationships of the other terms in the qu ery . T o conc lude, other QA sy ste ms also follow a relational data model (triple-based), e.g. the START  X  X bje ct-property -value X  approach (Katz, 2002). For dem onstration purpos es AquaLog application is used with the AKT ontolog y in t he context of the acade mic domain in our depart ment (Lei, 2006), e.g., AquaLog translates t he query  X  X hat is the hom epage of Peter who has an interest on the se-mantic web?" into a conjunctio n of ontolo gy-compliant non-grou nd trip les: &lt;what is?, has-web-address, pete r-scott&gt; &amp; &lt;person? , ha s-res earch-interest, Semantic Web area&gt;. Consider the query  X  X hat is the ho mepage of Peter? X  on Fig. 2. Given that the sy stem is unable to disam biguate between Pe ter-Scott, Peter-Sharpe, etc, user feed back is require d. Also the user is call to disa mbiguate that  X  X o mepage X  is t he sa me that  X  X as-w eb-address X  as it is t he first ti me the sy ste m came across this term , no s ynonyms have been identified, and the ontolog y does not provide fur-ther way s to disam biguate. The sy stem will learn the mapping and context for future occasions. On Fig. 3 we are asking for the web address of Pe-ter, who has an interest in SW. In this case AquaLog does not need any assistanc e from th e user, given t hat onl y one o f the Peters has an inter-est in SW. Also the similarity relation between  X  X omepage X  and  X  X as-web-address  X  has been learned by the Learning Mechanis m. When the RSS co mes a cross a query like that it has to ac ces s to the ontology inform atio n to recreate the context and com plete the ontology triples. In that way , it realize s that  X  X ho has an interest on the Se mantic Web X  is a modifier of the ter m  X  X  eter X . 
