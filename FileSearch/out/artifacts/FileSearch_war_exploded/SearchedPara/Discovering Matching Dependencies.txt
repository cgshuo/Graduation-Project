 Matching dependencies ( MD s) are recently proposed for various data quality applications such as detecting the violation of integrity constraints and duplicate object identification. In this paper, we study the problem of discovering matching dependencies for a given database instance. First, we formally define the measures, sup-port and confidence, for evaluating the utility of MD s in the given database instance. Then, we study the discovery of MD s with cer-tain utility requirements of support and confidence. Exact algo-rithms are developed, together with pruning strategies to improve the time performance. Finally, our experimental evaluation demon-strates the efficiency of the proposed methods.
 Categories and Subject Descriptors: H.2.0 [Database Manage-ment]: General General Terms: Algorithms
To make dependencies adapt to this real-world scenario, i.e., to be tolerant of various representation formats, Fan [4] proposed a new concept of data dependencies, called matching dependencies (
MD s). Informally, a matching dependency targets on the fuzzy val-ues like text attributes and defines the dependency between two set of attributes according to their matching quality measured by some matching operators (see [1] for a survey), such as Euclidean dis-tance and cosine similarity . For example, considering the Contacts relation in Table 1, we may have a MD as which states that for any two tuples from Contacts , if they agree on attribute Street (the matching similarity, e.g. cosine similarity , on the attribute Street is greater than a threshold 0 . 8 ), then the corresponding City attribute should match as well (i.e. similarity on City is greater than the corresponding threshold 0 . 7 ).
MD s can be applied in many tasks [4]. For example, in data cleaning, we can use MD s to detect the inconsistent data, that is,  X  Funding for this work was provided by the Hong Kong RGC grant No. 611608 similarity thresholds for MD s, which can satisfy users X  utility re-quirements of support and confidence.
 Contributions. In this paper, given X  X  Y and a relation in-stance, we study the issues of discovering matching dependencies. Our main contributions are summarized as follows:
First, we propose the utility evaluation of matching dependen-cies . Specifically, the confidence and support evaluations of MD s are formally defined. To the best of our knowledge, this is the first paper to study the utility evaluation and discovery of MD s.
Second, we study the algorithms for discovering MD s. The MD s discovery problem is to find settings of matching similarity thresh-olds on attributes X and Y for MD s that can satisfy the required confidence and support. We first present an exact solution and then study pruning strategies by the minimum requirements of support.
Third, we report an extensive experimental evaluation. Proposed algorithms on discovering MD s are studied. Our pruning strategies can significantly improve the efficiency in discovering MD s. Related Work. The concept of matching dependencies ( MD s) is first proposed in [4] for specifying matching rules for the object identification (see [3] for a survey). The MD s can be regarded as a generalization of FD s, which are based on identical values having matching similarity equal to 1 . 0 exactly. Thus, FD s can be repre-sented by the syntax of MD s as well. For any two tuples, if their X values are identical (with similarity threshold 1 . 0 ), then a FD ( X  X  Y ) requires that their Y values are identical too, i.e., a MD dencies with matching similarities on attributes Y when given the exactly matched values on X , which can be treated as a special case of MD s. The reasoning mechanism for deducing MD s from a set of given MD s is studied in [5]. The MD s and their reasoning techniques can improve both the quality and efficiency of various record matching methods. In this section, we formally introduce the definitions of MD s. Then, we develop utility measures for evaluating MD s over a given database instance.

Traditional functional dependencies FD s and their extensions rely on the exact matching operator = to identify dependency relation-ships. However, in the real world application, it is not possible to use exact matching operator = to identify matching over fuzzy data values such as text values. For instance, Jason Smith and J . Smith of attribute Name may refer to the same real world entity. There-fore, instead of FD s on identical values, the matching dependencies MD s [4] are proposed based on the matching quality.

Consider a relation R ( A 1 , . . . , A M ) with M attributes. Follow-ing similar syntax of FD s, we define MD s as following: 1 D EFINITION 1. A matching dependency ( MD )  X  is a pair ( X  X  Y,  X  ) , where X  X  X  , Y  X  X  are two sets of attributes, and  X  is a threshold pattern of matching similarity thresholds on attributes in X  X  Y , e.g.,  X  [ A ] denotes the matching similarity threshold on attribute A .
 A MD  X  specifies a constraint on the set of attributes X to Y . Specifically, the constraint states that, for any two tuples t 1 and t in a relation instance r of R , if V A then V A matching similarity thresholds on the attributes of A i and A j re-spectively. In the above constraint, for each attribute A i  X  X  X  Y ,
The MD s syntax is described with two relation schema R 1 , R 2 for object identification in [4], which can also be represented in a single relation schema R as the FD s.
We now study the determination of matching similarity thresh-old pattern for MD s based on the statistical distribution, which is a new problem different from FD s. In fact, once the X  X  Y is given for a FD , it already implies the similarity threshold to be 1 . 0 , that Unlike FD s, we have various settings of matching similarity thresh-olds for MD s. Therefore, in this section, we discuss how to find the right similarity thresholds in order to discover the MD s satisfying the required support and confidence.
 Problem Statement. In order to discover a MD  X  with the mini-mum requirements of support  X  s and confidence  X  c , the following preliminary should be given first: (I) what is Y ? and (II) what is matching quality requirement  X  Y . These two preliminary ques-tions are usually addressed by specific applications. For example, if we would like to use discovered MD s to guide objet identification in the Contacts table, then Y = SIN . The  X  Y is often set to high similarity thresholds by applications to ensure high matching qual-ity on Y attributes. For example,  X  Y is set to 1 . 0 for Y = SIN in the object identification application. Note that without the prelim-inary  X  Y , the discovered MD s will be meaningless. For example, a MD with  X  Y = 0 can always satisfy any requirement of  X  c ,  X  s . Since all the statistical tuples can satisfy the thresholds  X  Y = 0 , the corresponding support and confidence will always be 1 . 0 .
D EFINITION 2. The threshold determination problem of MD s is: given the embedded attributes X and Y , the minimum require-ments of support and confidence  X  s ,  X  c , and the matching similar-ity threshold pattern  X  Y , to find all the MD s  X  ( X  X  Y,  X  ) with threshold pattern  X  X on attributes X having confidence (  X  )  X   X  c and support (  X  )  X   X  s , if exist; otherwise return infeasible .
The attributes X can be initially assigned to R\ Y if no sug-gestion is provided by specific applications, since our discovery process can automatically remove those attributes that are not re-quired in X for a MD  X  . Specifically, when a possible discovered threshold  X  [ A ] on attribute A is 0  X  dom ( A ) , it means that any matching similarity value of the attribute A  X  X can satisfy the threshold 0 and will not affect the MD  X  at all. In other words, the attribute A can be removed from X of the MD  X  .
 Exact Algorithm. Now, we present an algorithm to compute the similarity thresholds on attributes X for MD s having support and be the m X attributes in X . For simplicity, we use  X  to denote the m
X attributes of X . Since, each threshold  X  [ A i ] on attribute A i is all the possible candidates of threshold pattern  X  . Let C t be the set of all the possible threshold pattern candidates, having The total number of candidates is c = |C t | = | dom ( X ) | = d m , where d is the size of dom ( A i ) .

Let n be the number of statistical tuples in the input statistical distribution D . We consider two statistical values P j i ( X, Y ) and P ( X ) , which record P ( X  X  X , Y  X  Y ) and P ( X  X  X ) respectively for the candidate  X  j  X  X  t based on the information of The recursion is defined as follows, with i increasing from 1 to n Algorithm 2 Pruning by support EPS ( D , C t ) 1: for each candidate  X  j  X  X  t , j : 1  X  c do 2: P a 0 j = P b 0 j = 0 3: for each tuple s i  X  X  , i : 1  X  n do 4: compute P a i j, P j i ( X ) 5: if P a n j &lt;  X  s then 6: remove all the remaining candidates  X   X  dominated by  X  j 7: return  X  j with confidence and support satisfying  X  c ,  X  s In fact, we can use a DAG (directed acyclic graph), G , to represent candidate similarity patterns as vertices and dominant relationships among the similarity patterns as edges. Thus, the dominant order of candidate patterns can be obtained by a BFS traversal upon G . Experiment Setting. In the experimental evaluation, we use two real data sets. The Cora 2 data set, prepared by McCallum et al. [8], venue , etc. The CiteSeer 3 data set is selected with attributes in-We use the cosine similarity to evaluate the matching quality of the tuples in the original data. By applying the dom ( A ) mapping in Section 2, we can obtain statistical distributions with at most 186 , 031 statistical tuples in Cora , and 314 , 382 statistical tuples in CiteSeer . Our experimental evaluation is then conducted in sev-eral off-line pre-processed statistical distributions with various data sizes, i.e., statistical tuples n from 10 , 000 to 150 , 000 respectively.
We mainly observes the efficiency of proposed algorithms. Since our main task is to discover MD s under the required  X  s and  X  c , we study the runtime performance in various distributions with differ-ent  X  s and  X  c settings. The discovery algorithms determine the matching similarity settings of attributes for MD s. Suppose that users want to discover MD s on the following X  X  Y of two data sets respectively: i) the dependencies on with the preliminary requirement of minimum similarity 0 . 6 on venue ; ii) the dependencies on with preliminary 0 . 1 on subject , respectively.

A returned result is either infeasible, or a MD with threshold pat-tern on the given X  X  Y , for example, one of the result returned by real experiment on Cora is: with support (  X  ) = 0 . 020 and confidence (  X  ) = 0 . 562 both greater than the specified requirements of  X  s and  X  c respectively. Approach Evaluation. We evaluate the performance of pruning by support ( EPS ) compared with the original exact algorithm ( EA ). As shown in (a) and (b) in Figure 1 and 2, the EA , which verifies all the possible candidates, should have the same cost no matter how  X  and  X  c set. Therefore, the time cost of EA in (a) is exactly the same as that in (b) in all two data sets.

Moreover, the EPS achieves significantly lower time cost in all the statistical distributions, which is only about 1 / 10 of that of the . These results demonstrate that our EPS approach can prune http://www.cs.umass.edu/~mccallum/code-data.html http://citeseer.ist.psu.edu/
