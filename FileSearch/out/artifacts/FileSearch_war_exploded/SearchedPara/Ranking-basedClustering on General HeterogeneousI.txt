 Recently there is an increasing attention in heterogeneous information network analysis, which models networked data as networks including di erent types of objects and rela-tions. Many data mining tasks have been exploited in het-erogeneous networks, among which clustering and ranking are two basic tasks. These two tasks are usually done sep-arately, whereas recent researches show that they can mu-tually enhance each other. Unfortunately, these works are limited to heterogeneous networks with special structures (e.g. bipartite or star-schema network ). However, real data are more complex and irregular, so it is desirable to design a general method to manage objects and relations in het-erogeneous networks with arbitrary schema. In this paper, we study the ranking-based clustering problem in a general heterogeneous information network and propose a novel so-lution HeProjI. HeProjI projects a general heterogeneous network into a sequence of sub-networks and an informa-tion transfer mechanism is designed to keep the consistency among sub-networks. For each sub-network, a path-based random walk model is built to estimate the reachable proba-bility of objects which can be used for clustering and ranking analysis. Iteratively analyzing each sub-network leads to ef-fective ranking-based clustering. Extensive experiments on three real datasets illustrate that HeProjI can achieve bet-ter clustering and ranking performances compared to other well-established algorithms.
 H.2.8 [ Database Management ]: Database applications-Data Mining Theory heterogeneous information network; clustering; ranking
Recently there is a surge of research on Heterogeneous In-formation Network (HIN) in which objects are of di erent types and links among objects represent di erent relations. It is clear that this kind of networks is ubiquitous and forms a critical component of modern information infrastructure [5]. For example, in the case of bibliographic network (e.g., network schema of DBLP dataset shown in Fig. 1(c)), the object types include authors, papers, venues; and links be-tween objects correspond to di erent relations, such as write relation between authors and papers.

Many data mining tasks have been exploited in HIN, such as clustering [18], classi cation [7], and ranking [16]. The link-based clustering attracts more and more attention, which usually groups objects that are densely interconnected but sparely connected with the rest of the network [10]. Also with the booming of search engine, object ranking [2, 6] be-comes an important data mining task, which evaluates the importance of objects. Conventionally, clustering and rank-ing are two independent tasks and they are usually used separately. However, recent researches show that cluster-ing and ranking can mutually promote each other and their combination makes more sense in many applications [17, 19]. If we know the important objects in a cluster, we can under-stand this cluster better; and the ranking in a cluster pro-vides more subtle and meaningful information for clustering. Although it is a promising way to do clustering and rank-ing together, previous approaches are con ned to a simple HIN with special structure. For example, Sun et al. val-idated the mutual improvement of clustering and ranking in bipartite network [17] (an example shown in Fig. 1(a)) and star-schema network [19] (an example shown in Fig. 1(b)). Shi et al. [20] integrated clustering and ranking in the hybrid network including heterogeneous and homoge-neous relations. However, the data in real applications are Figure 1: Examples of heterogeneous information networks. The letters are the abbreviation of di er-ent types of objects (e.g., P : paper, A : author). The details can be seen in Sec. 5.1. usually more complex and irregular, which are beyond the widely used bipartite or star-schema network. For example, the bibliographic data (see an example in Fig. 1(c)) includes not only heterogeneous relations but also homogeneous re-lations (e.g., self loop on P ); the bioinformatics data [3] (see an example in Fig. 1(d)) have more complex structure, which includes multiple hub objects (e.g., C and G ). So it is desirable to design e ective ranking based clustering al-gorithm for these complex and irregular HIN data. Broadly speaking, for HIN with arbitrary schema, we need to design a general solution to manage the objects and their relations, which is the basic for mining useful patterns on it.
Obviously, it is more practical and useful to determine the underlying clusters and ranks on a general heterogeneous in-formation network, but they are seldom exploited until now. When we integrate ranking and clustering on a HIN with arbitrary schema, it faces the following challenges. 1) A general HIN has more complex structure. For a simple HIN with a bipartite or star-schema structure, it is relatively easy to manage heterogeneous objects and build models. How-ever, a general HIN may have arbitrary schema, beyond the bipartite or star-schema structure. Although an intuitive way is to decompose it into multiple simpler sub-networks, the issue is how we decompose the HIN without structural information loss and maintain the consistency among the decomposed sub-networks. 2) It is challenging to integrate the clustering and ranking in a complex heterogeneous net-work. We know that it is still a daunting task to separately do clustering and ranking on a general HIN. Therefore, it is more dicult to design an e ective mechanism to combine these two tasks on the HIN.

In this paper, we study the ranking-based clustering prob-lem on a general HIN and propose a novel algorithm He-ProjI to solve the He terogeneous network Proj ection and I ntegration of clustering and ranking tasks. In order to con-veniently manage objects and relations in a HIN with ar-bitrary schema, we design a network projection method to project the HIN into a sequence of sub-networks without structural information loss, where the sub-network may be a relatively simple bipartite or star-schema network. More-over, an information transfer mechanism is developed to maintain the consistency across sub-networks. For each sub-network, a path-based random walk method is proposed to generate the reachable probability of objects, which can be e ectively used to estimate the cluster membership proba-bility and the importance of objects. Through iteratively analyzing each sub-network, HeProjI can obtain the steady and consistent clustering and ranking results. We perform a number of experiments on three real datasets to validate the e ectiveness of HeProjI. The results show that HeP-rojI not only achieves better clustering and ranking accuracy compared to well-established algorithms, but also e ectively handles complex HIN which cannot be handled by previous methods.
Many data mining tasks have been exploited in hetero-geneous information networks. According to the organiza-tion methods of objects, contemporary work can be roughly classi ed the following three types. 1) HIN is decomposed to multiple homogeneous networks. Most network analysis focus on homogeneous networks [10, 12]. However, the infor-mation loss from the decomposition operation may induce the inconsistency and unbalance among networks. 2) Bipar-tite graph is widely used to organize two types of objects and the relations among them, such as conference-author [17] and author-document [21]. As an extended version, the K-partite graphs [8] are able to represent the multiple types of objects. However, they both ignore the homogeneous re-lation among objects of same type. 3) HIN is usually orga-nized as star-schema network [13, 19, 18] where a target type is central node and connected by several attribute types. Many data with the target-attribute relations can be repre-sented with this schema, such as bibliographic data [19] and movie data [13]. However, more real networked data may have multiple hub types and homogeneous relations, which cannot be represented with the star-schema network.
Recently, the clustering on heterogeneous network attracts much attentions. Some of spectral clustering-based methods con ne to bi-type relational data [17]. The spectral clus-tering methods are also developed for a general relational data which are modeled as K-partite graphs [8]. Sun et al. [18] presented a semi-supervised clustering algorithm to generate di erent cluster results with path selection ac-cording to user guidance. The ranking problem is also an important task in data mining, which evaluates the impor-tance of objects based on some ranking functions. Con-ventional ranking tasks are set in homogeneous networks, such as PageRank [2] and SimRank [6]. Recently, more and more researches began to pay attention to the rank problem in heterogeneous networks. For example, Sun et al. [16] proposed PathSim to evaluate the similarity of same-typed object pairs in HIN. Contemporary clustering and ranking are usually done independently.

In recent years, ranking-based clustering algorithms il-lustrate that ranking and clustering can mutually promote each other. RankClus [17] is proposed to generate clusters integrated with ranking, and theoretical and experimental analysis show that the quality of clustering and ranking are mutually enhanced. Furthermore, Sun et al. [19] studied the clustering of multi-typed heterogeneous networks with a star network schema and proposed NetClus to generate high-quality net-clusters. However, these two algorithms are con ned to the speci ed network schema, i.e., RankClus and NetClus only for the bipartite and star-schema networks, re-spectively. Recently, Shi et al. [20] proposed the ComClus to promote clustering and ranking performance on a kind of hybrid network including the heterogeneous and homoge-neous relations. In fact, ComClus is also con ned to star schema network with self loop. So these methods cannot be directly applied to a general HIN with arbitrary schema.
In this section, we give the problem de nition and some important concepts used in this paper.

Definition 1. General heterogeneous information net-work . Given a schema A = ( T ; R ) which consists of a set of entities type T = f T g and a set of relations R = f R a general information network is de ned as a graph G = (X,E) with an object type mapping function : X !T and link type mapping function : E !R . Each object jTj &gt; 1 or the types of relations jRj &gt; 1, the network is called heterogeneous information network ; otherwise, it is a homogeneous information network .

Fig. 1 shows the schema of several HIN examples. The bipartite network in Fig. 1(a) only includes two types of objects, and the widely used star-schema network [13, 19, 18] in Fig. 1(b) organizes objects in HIN with one target type and several attribute types. However, a general het-erogeneous information network may be more complex and irregular. It may not only include homogeneous or heteroge-neous relations, but also include multiple hub objects. Fig. 1(d) shows such a general HIN example. The object G has heterogeneous relations (e.g., G ! GO and G ! C ) as well as homogeneous relations (e.g., G ! G ). Moreover, the network is beyond the star-schema because of multiple hub objects (e.g., G and C ). It is clear that bipartite graph and star-schema network is the special case of a general HIN.
For a general HIN, it is dicult to manage objects and re-lations in the network. Although we can project it into sev-eral homogeneous networks through assigning meta paths as reference [4] did, it will loss much information among di erent-typed objects. We know that, as the special case of HIN, the bipartite and star-schema networks are relatively easy to manage objects and relations in the network. So a basic idea of handling a general HIN is to decompose it into simpler networks. Following this idea, we design a novel HIN projection method. Speci cally, we can select one type (called pivotal type) and its connected other types (called supportive type). These types and their relations consti-tute the schema of a projected sub-network of original HIN. Formally, it can be de ned as follows:
Definition 2. Projected sub-network . For a HIN with schema A = ( T ; R ) , its projected sub-network has the schema A  X  = ( T  X  ; R  X  ) where T  X  T , R  X  R , T  X  includes one piv-otal type (denoted as P) and other types connected with P (called supportive type , denoted as S = f S g ). R  X  includes the heterogeneous relations between P and S and homoge-neous relations among P (if existing).
 A projected sub-network can be denoted as P S . The X ( P ) is the object set of pivotal type, and X ( S ) represents the object set of supportive type S . For convenience, the projected sub-network is also called sub-network which can be represented with its pivotal type P . For example, Fig. 2(c) shows the projected sub-network G f C;T;GO g with type G object (the one in red) as the pivotal type, while types C;T and GO are the supportive types as they are object types connected to object type G . Similarly, Fig. 2(b) and (d) show the projected sub-networks with pivotal type objects GO and C , respectively.

It is clear that a HIN can be projected into a sequence of sub-networks through selecting di erent pivotal types. So we de ne the HIN projection concept as follows.
 Fi gure 2: An example of HIN projection. The pivotal type is marked with red color. The dot line represents the information transfer among sub-networks.

Definition 3. HIN projection . A HIN with t types of objects can be projected into an ordered set of t projected sub-networks by successively selecting one of the t types as pivotal type.

Fig. 2 shows a projection example of SLAP network, a bioinformatics dataset (details in Section 5.1). Through suc-cessively selecting the 6 object types ( GO;G;C and so on) as pivotal type, the SLAP network is projected into a sequence of 6 sub-networks. It is clear that the HIN projection has the following properties.

Property 1. HIN projection is a structure-information lossless network decomposition.
 According to Def. 3, all objects and relations in original HIN are in the projected sub-networks. That is to say, the HIN can be reconstructed from the set of projected sub-networks.

Property 2. Each projected sub-network in HIN projection should be a bipartite graph or a star-schema network (with self loop).

According to Def. 2, if there are two types of objects in the sub-network, it is a bipartite graph; otherwise it is a star-schema network. Note that, di erent from the conven-tional bipartite and star-schema network, the pivotal type in sub-networks may include the homogenous relation (i.e., self loop).
 Property 3. HIN projection is not unique for a general HIN.

A HIN has di erent projection sequences through select-ing di erent orders of pivotal types. For example, the SLAP network in Fig. 2 has the projection sequences: GO G C Si Sub T , T G GO C Si Sub and so on.
 In fact, a HIN with t types of objects has the t ! projection sequences in all.

Assume that J represents a type in type set f T g . The object set can be denoted as X = f X ( J ) g , and X ( J ) where X ( J ) p is the object p 2 X ( J ) (i.e., ( p )= J ). The re-lations among objects include two types (homogeneous and heterogeneous relations), which can be represented by the two types of matrices homogeneous and heterogeneous relation matrices , respectively. If type J has homogeneous relation (e.g., the self loop on P in Fig. 1(c)), the homoge-nous relation matrices can be written as H ( J ) , where H denotes the relation between X ( J ) p and X ( J ) q . If two types ( I and J ) have heterogeneous relation (e.g., P A in Fig. 1(c)), the heterogeneous relation matrices can be written as H ( I;J ) wh ere H ( I;J ) pq denotes the relation between X ( I ) p Correspondingly, we have homogeneous transition ma-trix M ( J ) and heterogeneous transition matrix M ( I;J ) It is clear that the transition matrix M ( I;J ) can be derived where D ( I;J ) is the diagonal matrix with the diagonal value equaling to the corresponding row sum of H ( I;J ) . Similarly, M is the transition probability matrix of the citation relation H ( P ) , and M ( A;P ) is the transition probability matrix of the A P relation H ( A;P ) . For given network structure, we can derive the homogeneous and heterogeneous transi-tion matrix. In the following section, we consider that the transition matrix are known.

Di erent from conventional clustering in homogeneous net-works, cluster in HIN should include di erent types of ob-jects, where these objects share the same semantic meaning. For example, in bibliographic data, a cluster about data min-ing area includes venues, authors, and papers in this eld. For each type objects X ( J ) , we de ne the membership ma-whose diagonal value represent the membership probability of X ( J ) p belonging to the cluster C k . Note that the sum of membership probability of X ( J ) p in K clusters is 1 (i.e.,  X  clustering on a general HIN as follows. Given a heteroge-neous network G =( X;E ) and the semantic cluster number K , our goal is to nd a clusters set f C k g K k =1 , where C clustering. That is, an object p in X ( J ) can belong to sev-eral clusters, and it is in a cluster C k with the probability B pp . Moreover, a cluster C k can contain all kinds of objects.
Through the HIN projection, it will become much easier to analyze the HIN through handling a set of simple projected sub-networks, since these sub-networks are bipartite or star schema networks. However, it may result in a troublesome business: how to maintain the consistency among di erent sub-networks. To solve it, we design an information trans-fer mechanism which inherits a portion of information from other sub-networks to current one. In order to integrate the clustering and ranking in a uniform framework, a model is required to exibly support these two tasks. Following this idea, we build a probabilistic model to estimate the proba-bility of supportive and pivotal objects in each sub-network. Moreover, the probability of objects can e ectively infer the clustering information and represent the importance of ob-jects.
Speci cally, we rst project the original HIN into a se-quence of sub-networks, and then randomly assign the piv-otal objects of the rst sub-network into K clusters (i.e., initialize f C k g K k =1 ). For each sub-network, a path-based random walk method is proposed to estimate the reachable probability of supportive objects in each cluster C k and then a generative model is used to obtain the probability of piv-otal objects. After that, an EM algorithm is employed to estimate the posterior probability of objects (i.e., the clus-Al gorithm 1 HeProjI: Detecting K clusters on HIN teri ng information f C k g K k =1 ). According to probability of objects, we can also calculate their ranking in each clus-ter. The above step is repeated until convergence. In the iterative process, the clustering and ranking can mutually promote each other until they reach a steady result. The basic framework of HeProjI is shown in Algorithm 1. In the following sections, we will present these operations in detail.
As we have noted that the built probabilistic model can not only support the clustering and ranking tasks but also maintains the consistency among sub-networks. So the de-sign of the model should obey the following two rules. 1) PageRank principle. In order to support the ranking task, the probability of objects should be able to re ect their ranks. In other words, the probability of objects should be positively correlated to the node degree. 2) Consistency principle. In order to maintain the consistency among sub-networks, an e ective mechanism should be designed to trans-fer appropriate information among sub-networks.

For the rst rule (i.e., PageRank principle), the random walk is an apparent solution. However, it is traditionally used in homogeneous networks [6, 2]. Although it is also used in bipartite graph [21], it is seldom applied in HIN. Sun et al. [19] employed it to estimate the probability of at-tribute objects in a star-schema network, while it is con ned to two types of objects. Heterogeneous objects and link se-mantics make it dicult to directly employ random walk in HIN. In a projected sub-network, there are di erent types of supportive objects and they are connected through pivotal objects. So the random walk among objects should follow the speci ed paths. That is, the random walkers among supportive objects would need to pass through the pivotal objects. As a consequence, we need to estimate the prob-ability of supportive and pivotal objects separately. The reachable probability of a supportive object can be calcu-lated as the sum of the probability of walkers from other supportive objects walking to it through the pivotal type. The probability of pivotal objects can be generated through its reachable supportive objects. Because the bipartite net-work only contains one supportive type, the probability of supportive object can be calculated by the sum of proba-bility of walkers from the same type of objects walking to Figure 3: Illustration of the probability estimation process for supportive and pivotal objects. The black dash-dot line represents the random-walk pro-cess among supportive objects and the blue dotted line represents the generative process of pivotal ob-jects. it through the pivotal type. Fig. 3 shows the probability estimation process. The reachable probability of type C can be calculated by random-walkers wandering from type GO and T to type C through type G in Fig. 3(a).

For the second rule (consistency principle), it is an in-tuitive idea to transfer information among sub-networks. However, what and how do we transfer? It is clear that the sub-networks are overlapped. If we transfer the infor-mation of any overlapping types, the model may be hard to control, since two sub-networks may have many overlapping types and one type may appear in many sub-networks. If we do clustering on each sub-network individually, it is dif-cult to map clusters among sub-networks. We know that the random walk among supportive objects all pass through pivotal objects. So we only need to transfer the information of pivotal type, and then the information can be propagated to other supportive objects by random walkers. In order to maintain the clustering consistency during the iteration, we let the pivotal objects in the current sub-network in-herit a portion of clustering information from previous sub-networks with a controlling parameter. The dot line in Fig. 2 shows two information inheritance examples. Speci cally, the information on object G calculated in Fig. 2(b) is passed on to the calculation of the pivotal object G in Fig. 2(c) which a ects the calculation of object C , while the infor-mation on object C is then passed on to the calculation of pivotal object C in Fig. 2(d). First, we estimate the probability of supportive objects. The path-based random walk process is formulated with matrix representation. We use M ( S I ;S J | P;C ) to represent the probability transition matrix from supportive type S I to type S J passing pivotal type P in the sub-network C . M where M ( S I ;P | C ) is the transition matrix from S I to P (i.e., M ( S I ;P ) ). Compared to conditional transition matrix M de ned below, M ( S I ;S J | P;C ) is also called the global transi-tion matrix, which is xed for the sub-network C . For exam-ple, in Fig. 3(a), the global transition matrix M ( T;GO | means the transition probability from type T to GO through G on the sub-network G f T;C;GO g . In the proposed model, the global probability of objects is important infor-mation to smooth the probability of pivotal objects (see Eq. 8 for more details).

When considering the clustering information, the transi-tion matrices among supportive objects should be adjusted according to clusters. The clustering information can be represented by the membership matrix of pivotal objects, so the conditional transition matrix from S I to S J through P in the cluster C k (i.e., M ( S I ;S J | P;C k ) ) can be de ned as follows: where B ( P | C k ) is the membership of pivotal objects on clus-ter C k .

The above transition matrices only consider the cluster-ing information in the current sub-network, which may cause the inconsistency among di erent sub-networks. For exam-ple, in the bibliographical data shown in Fig. 1(c), clus-tering on the sub-network P f A;V;T g may focus on re-search areas, while clustering on the sub-network A f P g may more concern about co-author relations. In order to keep the clustering consistency among sub-networks, we can inherit a portion of cluster information from previous sub-networks. Only the clustering information of pivotal type is inherited from previous networks and it is integrated with current clustering information of pivotal type. The reason why the simple mechanism work is that the pivotal objects, as hub node, can propagate the clustering information to all supportive objects. The transition matrices can be rede ned as: where B  X  ( P | C k ) is the inherited membership matrix when the type P serves as a supportive type in the sub-network whose pivotal type is S ; and the S;P is a learning rate parameter that controls the ratio of information inheritance from previous sub-network (pivotal type is S ) to current one (pivotal type is P ). The dot line in Fig. 2 illustrates the two examples of information inheritance. The new transi-tion matrix has the following advantages. 1) It transfers the clustering information among sub-networks, which keeps the consistency of sub-networks. 2) It helps to speed up the con-vergence, since the priori clustering information is adopted. For a bipartite network, the transition probability matrix can be denoted as M ( S I ;S I | P;C k ) , which has the same calcu-lation mechanism.

The conditional probability of supportive type S J on sub-network C and cluster C k are denoted as Pr ( X ( S J ) j the PageRank [2], the probability of one type of objects is decided by the reachable probability from other types of ob-jects through pivotal objects. So the conditional probability of supportive type S J can be de ned as follows. The calculation is an iterative process and Pr ( X ( S J ) j is initialized as the even value at the rst iteration. For a b ipartite network, random walkers start from type S J and end up with the same type through the pivotal type P . The probability of supportive type S J , Pr ( X ( S J ) j C k ned as Pr ( X ( S J ) j C k ) = Pr ( X ( S J ) j C k ) M
Then we estimate the probability of pivotal objects. We can consider the pivotal objects are generated by adjacent supportive objects, so a generative model can be adopted here. The probability of pivotal objects comes from two parts: heterogeneous and homogeneous relations (if the piv-otal type has self loop). For heterogeneous relations, the het-erogeneous probability of pivotal object p in the sub-network C (i.e., Pr ( X ( P ) p j C )) can be calculated as follows: where N ( p ) is the set of neighbors of object p in the sub-network. It means the pivotal object p is generated by the di erent types of adjacent supportive objects. Then, we consider the probability of pivotal object p in a cluster C ated from the adjacent supportive objects in the cluster C In addition, we add the global probability of pivotal object X p to smooth the probability: where the smooth parameter represents the portion of global probability. The smooth operation is an important component due to following reasons. 1) It prevents piv-otal objects from accumulating into minority clusters, which helps to improve the clustering accuracy. 2) It makes the probability change of pivotal objects more steady, which can improve the stability of HeProjI. The experiments in Sec. 5.7 also validate the importance of smooth operation.
For homogeneous relations (i.e., the pivotal object has self loop), we can calculate the cluster based homogeneous tran-sition probability for pivotal type as follows: M :p denotes the sum of transition probability of other pivotal objects reaching p in cluster C k , which represents the importance of object p to some extent.

When considering the homogeneous relations (if existing), the probability of pivotal object p is generated by the hetero-geneous and homogeneous relations, so it can be calculated as follows:
In order to determine the membership of objects, we need to estimate posterior probability of objects. In each sub-network, there are two kinds of objects (i.e., pivotal and supportive objects). Because pivotal objects are the hub of sub-network that integrate supportive objects and contain complete semantic information, we rst estimate the pos-terior probability of pivotal objects, and then the posterior probability of supportive objects is decided by that of piv-otal objects.

Now we consider how to estimate the posterior probability of pivotal objects P ( C k j X ( P ) ). According to the Bayesian size P ( C k ) is unknown, we need to estimate an appropriate P ( C k ) to balance the cluster size. We use the P ( C k maximizes the likelihood of generating pivotal objects in dif-ferent clusters. The likelihood of pivotal objects is de ned as:
An EM algorithm can be utilized for the latent P ( C k ) by maximizing the logL . We can derive the Eq. 12 and 13. Initially, we set the P ( C k ) with even values and then repeat the E step (i.e., Eq. 12) and M step (i.e., Eq. 13) to iteratively update the latent cluster probability until the P ( C k ) obtains convergence.

Next we estimate the posterior of supportive objects. The basic idea is that the posterior probability of supportive ob-jects comes from its pivotal neighborhoods. We de ne it as follow: where P ( C k j X ( S J ) q ) is the probabilities of supportive object X q belonging to cluster C k ; N ( q ) is the neighbor set of supportive object q . It means that the posterior probability of supportive object X ( S J ) q is the average value of its pivotal neighborhoods.
Since the probability model obeys the PageRank principle, we can regard the conditional probability of objects as their ranks.

Because the conditional probability P ( X ( J ) j C k ) in HeP-rojI is estimated by the random walk process, it may prefer to assign a higher probability to an object with a higher de-gree. However, in some applications, the link-number based measure is not proper. For example, advertisement webpage may have many poor value links (i.e., high degree but low rank).

If we know the additional information of objects, which can be used to measure the importance of objects, we can in-tegrate the information into the proposed method and then get the more reasonable rank. Based on the conditional probability of objects, we propose a general ranking method for objects as follows: where the AI ( X ( J ) ) is the Additional Importance measure (AI) of objects X ( J ) . For example, in bibliographic network, the importance of a paper is decided by its citations to a la rge extent, and the AI can be a measure that is propor-tion to citations. We can also propagate the AI information to adjacent objects by transition probability matrix. It is denoted as follows:
Time complexity of HeProjI is composed of two main parts: 1) analyzing each sub-network; 2) handling the pro-jection sequence. In each sub-network, the complexity of es-timating the distribution of supportive objects is O ( t 1 where j E j is the number of edges in this sub-network, j is the number of supportive nodes, and t 1 is the iteration number and K is the cluster number. The complexity of estimating the distribution of pivotal objects is O ( K j where j E p j is the number of edges of pivotal objects. Then the time complexity of calculating posterior probability for pivotal objects is O ( t 2 K j P j ) where t 2 is the iteration times, j
P j is the number of pivotal objects. Similarly, the pos-terior probability for supportive objects has the complex-ity O ( K j E j ). So the complexity for each sub-network is O ( t 3 K ( t 1 j E jj S j + j E p j + t 2 j P j + j E j )) where t tion number for clustering adjustment in this sub-network. Besides, HeProjI has a projection sequence which selecting di erent object as the pivotal type. And thus the whole time complexity is O ( t 4 j T j t 3 K ( t 1 j E j S + j E p j j
T j is the number of type and t 4 is the iteration of cluster-ing. Omitting tiny and constant items, the time complexity of HeProjI can be summarized by O ( c 1 j E j + c 2 j P j
In this section, we evaluate the e ectiveness of HeProjI, and compare it with several state-of-art methods on three real datasets.
In this paper, we use two real information networks: DBLP and SLAP. These two networks are summarized as follows and their schemas are shown in Fig. 1(c) and (d). 1. DBLP dataset . The dataset is about bibliographic information in computer science domain, which constructs a HIN with four types of objects (paper ( P ), author ( A ), venue ( V ), and term ( T )) and their relations. To evaluate the clustering accuracy, we randomly label 1031 papers and 1295 authors with their research areas. In experiments, we extract two di erent-scaled subsets of the DBLP which are called DBLP-S and DBLP-L, respectively.

DBLP-S : It is a small size dataset which includes three research areas: database (DB), data mining (DM), and in-formation retrieval (IR). There are 21 venues, 25020 papers, 10907 authors and 14940 terms extracted from paper title.
DBLP-L : It is a large dataset which includes 8 areas: computer network, information security, computer architec-ture, theory, software engineering &amp; programming language, arti cial intelligence &amp; pattern recognition, computer graph-ics, data mining &amp; information retrieval &amp; database. It has 280 venues (35 venues for each area), 275,649 papers, 238,673 authors and 295,123 terms. 2. SLAP dataset [3]. This dataset integrates several well-known bioinformatics datasets (e.g., PubChem, Drug-Bank, PPI) into a single framework using semantic web technologies for drug discovery. Here SLPA is a simple ver-sion which includes 6 types of objects (i.e., gene ( G ), gene-ontology ( GO ), chemical compound ( C ), tissue ( T ), side ef-fect ( Si ), substructure ( Sub )) and their relations. There are 323 genes, 38,116 compounds, 672 kinds of side e ect, 212 kinds of substructure, 170 tissues, 948 gene ontologies and 105,387 links among these objects. We have known a priori that these genes are aliated to 5 gene families, which are considered as the labels of genes. In this section, we study the clustering e ectiveness of HeProjI through comparing it with other well-established algorithms.

The rst experiment is done on DBLP dataset, since this dataset has a relatively simple structure and is suitable for comparison with previous algorithms. The representative algorithms are included in experiments, which are summa-rized as follows.

The clustering quality is measured by the fraction of ver-tices identi ed correctly, FVIC [10, 12], which evaluates the average matching degree by comparing each predicting clus-ter with the most matching real cluster. The larger the FVIC is the better the partition is. HeProjI, ComClus and NetClus can be applied to DBLP dataset directly. For Net-Clus, we do not consider the self loop of type P , since Net-Clus cannot solve it. Note that RankClus [17] is not included here, because it only solves the bipartite network. Moreover, for iTopicModel and NetPLSA, we make a homogeneity as-sumption of links so that it can be applied to this dataset. The smoothing parameter in HeProjI is xed at 0.9. All learning rate are xed at 0.3. In HeProjI, the projection sequence of is P A C T . The parameters in other al-gorithms are set with the suggested values in their literals. Table 1: Clustering accuracy for DBLP dataset F rom the results shown in Table 1, we can observe that HeProjI achieves the best accuracy and lower standard devi-ation on all objects. HeProjI \ S also has good performances. However, due to omitting the smoothing operation, it has worse performances and stability when compared to HeP-rojI. The performances of HeProjI \ I degrade greatly, since T able 2: Clustering accuracy for SLAP dataset it does not inherit clustering information from other sub-networks. In this condition, HeProjI \ I analyzes these sub-networks independently, so the inconsistency among sub-networks causes its bad performances. NetClus and Com-Clus both have respectable results. However, the absence of citation information among papers may lead to NetClus's worse performances when it is compared with ComClus. The iTopicModel and NetPLSA methods ignore the heterogene-ity of objects and relations, so their performances are bad.
For SLAP network, contemporary methods cannot solve it directly. In order to compare with other algorithms, we con-vert the SLAP network into a homogeneous network through ignoring the heterogeneity of objects. As a comparison al-gorithm, the classical spectral clustering algorithm, NCut [14], is run on the homogeneous network. The projection se-quence is GO G C T Sub Si . HeProjI uses the same parameters with the above experiments, except the learning 0 : 7 ; 0 : 7 ; 0 : 7]. The results are shown in Table 2. It is clear that HeProjI performs much better than NCut. We know that there are distinct di erences on di erent types of ob-jects and relations, e.g., 70 ; 672 links in G C relation and 2222 links in G GO relation. If we do not consider object types, as NCut does, the clusters may be serious unbalanced, which results in the bad performances of NCut.
To evalute the ranking e ectiveness of HeProjI, we make a ranking accuracy comparison between HeProjI and NetClus. We utilize the venues rank recommended by Microsoft Aca-demic Search [1] as the ground truth. In order to measure the quality of the ranking result, we employ the Distance criterion proposed in [11], which computes the di erences between two ranking lists of the same set of objects. The criterion not only measures the number of mismatches be-tween two lists but also gives a big penalty term to top mismatch objects in the lists. The smaller Distance means the better performance. (a ) Top 5 on
DBLP-S Figure 4: Ranking accuracy comparison on top venues (the smaller Distance , the better perfor-mance).

Three algorithms are tested on the DBLP dataset. In addition to NetClus, there are two versions of HeProjI (He-ProjI with/without AI). The citations of paper are used as the AI measure. We extract the top 5 and 10 venues in di er-ent research areas and then calculate the Distance measure for them. Additionally, we also compare the accuracy of the global rank on both HeProjI and NetClus. The comparison results are shown in Fig. 4. We can nd that two versions of HeProjI achieve better rank performances compared with NetClus in the most cases, since their Distance get lower values. Moreover, the HeProjI-AI performs better than He-ProjI. In DBLP dataset, the citation information of papers (i.e., AI) re ects the quality of the papers to a large extent. So integrating the AI in HeProjI helps to improve the rank accuracy of papers. Moreover, the citation information can also promote the ranking accuracy of venues through the P V relation (see Eq. 17). So HeProjI-AI achieves the best ranking performances. We compare the ranking e ectiveness of HeProjI and Net-Clus with a case study on DBLP dataset. We use the global rank to prove the ranking e ectiveness of the He-ProjI method. Table 3 shows the top 15 venues ranked by HeProjI and NetClus on DBLP-S. From these results, the ranks of venues generated by HeProjI-AI more conform to the intuition. Although it is hard to rank conferences across di erent areas, the order within each area is more or less established and the HeProjI-AI con rms with that order. For example, in the DB area, it is SIGMOD, VLDB and ICDE, while in the data mining area, it is KDD, ICDM, and PKDD. However, there are some out of order venues gener-ated by NetClus. For example, among the database confer-ences, SIGMOD is ranked after VLDB and ICDE. Because NetClus cannot combine additional AI information (i.e., the citations of papers) and tends to get the rank which is propo-tion to its link number, it has the tendency to rank a good venue publishing a smaller number of papers with a lower rank (e.g., PODS) and a venue publishing a larger number of papers with higher rank (e.g., DEXA). Besides, for HeProjI which does not consider AI information, the rank of venues is basically proportional to their links, since the probability of objects are generated by a random-walk based method. The experiments re ect that the HeProjI method can exi-bly and e ectively integrate heterogeneous informations and achieve more reasonable ranks.
Now, we study the convergence and stability of HeProjI on the DBLP dataset. The entropy is able to measure the unpredictability of a cluster as well as the convergence of algorithm. We can de ne the following entropy:
Fig. 5 shows the comparison of AvgEntropy of HeProjI and NetClus on di erent types of objects of DBLP-S. We can observe that the HeProjI achieves lower AvgEntropy on all conditions. We think the reason is that the HeProjI method rationally combines more information from all types of objects. It helps HeProjI to achieve steady solution. We recorded the running time of each sub-network in He-ProjI along with the iterations on DBLP-S and SLAP in the Figure 5: The change of AvgEntropy with iterations. Figure 6: The time of analyzing sub-networks in He-ProjI along with the iterations. The pivotal type represents the corresponding sub-networks. experiments of Sec. 5.2. The results are shown in Fig. 6. We can observe that the complex sub-networks (including more object types and more links) cost much more running time, such as the sub-network P f A;T;C g in Fig. 6(a) and G f T;GO;C g in Fig. 6(b). It is reasonable, since more links and nodes need to be handled in this condition. Moreover, the analysis time of each sub-network decreases along the iteration. We think the prior knowledge inherited from previous iterations on the sub-networks helps to fas-ten convergence. Although the iteration process in HeProjI results in its higher time complexity, the time used in each iteration drops down quickly in most cases.
There is a set of parameters in HeProjI: the learning rate vector (i.e., ) and the smoothing parameter . With the AvgEntropy and clustering accuracy for di erent types of objects, we discuss the e ect of di erent parameter settings on HeProjI.

The smoothing parameter is used to control the portion of global probability utilized by each cluster (see Eq. 8). We run HeProjI on DBLP-S with di erent . The results are shown in Fig. 7. Fig. 7(a) shows that HeProjI achieves better performances when is from 0.5 to 0.9. It implies that the appropriate global information is helpful for clus-Figure 7: Accuracy and AvgEntropy with di erent . Figure 8: Accuracy and AvgEntropy of HeProjI with di erent . tering. Too much ( is small) or no global information ( is 1) both will degrade the performances of HeProjI. Fig. 7(b) also illustrates that the appropriate global information (i.e., 2 [0 : 5 ; 0 : 9]) will bene t for the stability and convergence of algorithms.

The learning rates (i.e., ) are important parameters which control how much information learned from other sub-networks. We run HeProjI on DBLP-S to observe the e ect of on clustering accuracy and convergence. In this experiment, we xed the smooth parameter with 0.9. For convenience, we set the elements of vector with a uni ed value. From Fig. 8, we can observe that the algorithm accuracy rst increases and then decreases with the increment of . It illustrates that either excessive or little information from other sub-networks degrades the algorithm performances. We think it is proper to set the learning rate vector in the range of [0.3, 0.5]. Note that, we set the learning rate with a uni-form value for all parameters. However, the learning rate can be di erent for di erent sub-networks in real applica-tions. For exmaple, HeProjI achieves good performances on SLAP dataset when setting di erent learning rates for sub-networks (see Sec. 5.2). Figure 9: Clustering accuracy of objects with di er-ent projection sequences.
In this experiment, we discuss the impact of di erent pro-jection sequences (i.e., the order of analyzing sub-networks). The experiments are done on DBLP-S and SLAP datasets and the same parameters of HeProjI are set with that of Sec. 5.2. Under di erent projection sequences, the cluster-ing accuracy of objects are shown in Fig. 9.

On one hand, at rst glance, the di erences of cluster-ing accuracy are small under di erent projection sequences, which illustrates HeProjI is not very sensitive to the se-quence of analyzing sub-networks. On the other hand, we can also observe that HeProjI consistently has bad perfor-mances on all objects under some sequences, such as the se-quence T G GO C Si Sub in Fig. 9(b). We think the reason lies in the type T objects has a small number of links to other types of objects, so the successive sub-networks can inherit little useful information from it. Although the order of analyzing sub-networks does not have large impact on the performance of HeProjI, we still suggest that HeProjI selects the sub-network whose pivotal type with rich infor-mation (e.g., P type in DBLP) or clear semantic meanings (e.g., GO type in SLAP) rst.
This paper studied the ranking-based clustering problem in a general heterogeneous information network and pro-posed a novel algorithm HeProjI. For a general HIN with arbitrary schema, HeProjI projects it into a sequence of projected sub-networks and iteratively analyzes each sub-network. For each sub-network, a path-based random walk model is built to estimate the reachable probability of ob-jects which can e ectively be used for clustering and ranking analysis. The experiments show that HeProjI achieves bet-ter clustering and ranking result than other representative algorithms. This work is supported by the National Basic Research Program of China (2013CB329603), the National Science Foundation of China (Nos. 61375058, and 71231002), the Ministry of Education of China and China Mobile Research Fund (MCM20130351) and the Beijing Higher Education Young Elite Teacher Project. [1] http://academic.research.microsoft.com . [2] S. Brin and L. Page. The anatomy of a large-scale hyper textual web search engine. Comput. Netw. ISDN
Syst , 30(1-7):1757-1771, 1998. [3] B. Chen, Y. Ding, and D. Wild. Assessing drug target association using semantic linked data. PLoS Comput.
Biol. , 8(7): 1757-1771, 2012. [4] M. Grcar and N. Lavrac. A methodology for mining document-enriched heterogeneous information networks.
In Discovery Science , pages 107-121, 2011. [5] J. Han. Mining heterogeneous information networks: the next frontier. In KDD , page Keynote speech, 2012. [6] G. Jeh and J. Widom. Simrank: a measure of structural-context similarity. In KDD , pages 538-543, 2002. [7] M. Ji, J. Han, and M. Danilevsky. Ranking-based classi cation of heterogeneous information networks. In
KDD , pages 1298-1306, 2011. [8] B. Long, X. Wu, Z. Zhang, and P. S. Yu. Unsupervised learning on k-partite graphs. In KDD , pages 317-326, 2006. [9] Q. Mei, D. Cai, D. Zhang, and C. Zhai. Topic modeling with network regularization. In WWW , pages 101-110, 2008. [10] M.E.J. Newman and M. Girvan. Finding and evaluating community structure in networks. Physics
Review E , 69(026113):1757-1771, 2004. [11] Z. Nie, Y. Zhang, J. R. Wen, and W. Y. Ma.
 Object-level ranking: bringing order to web objects. In
WWW , pages 567-574, 2005. [12] C. Shi, Z. Yan, Y. Cai, and B. Wu. Multi-objective community detection in complex networks. Applied Soft
Computing , 12(2):850-859, 2012. [13] C. Shi, C. Zhou, X. Kong, P. S. Yu, G. Liu and W.
Bai. Heterecom: a semantic-based recommendation system in heterogeneous networks. In KDD , pages 1552-1555, 2012. [14] J. Shi and J. Malik. Normalized cuts and image segmentation. In CVPR , pages 731-737, 1997. [15] Y. Sun, J. Han, J. Gao, and Y. Yu. Itopicmodel: information network-integrated topic modeling. In
ICDM , pages 493-502, 2009. [16] Y. Sun, J. Han, X. F. Yan, P. S. Yu, and T. Wu.
PathSim: meta path-based top-K similarity search in heterogeneous information networks. In VLDB , pages 992-1003, 2011. [17] Y. Sun, J. Han, P. Zhao, Z. Yin, H. Cheng, and T.
Wu. Rankclus: integrating clustering with ranking for heterogeneous information network analysis. In EDBT , pages 565-576, 2009. [18] Y. Sun, B. Norick, J. Han, X. Yan, P. S. Yu, and X.
Yu. Integrating meta-path selection with user guided object clustering in heterogeneous information networks.
In KDD , pages 1348-1356, 2012. [19] Y. Sun, Y. Yu, and J. Han. Ranking-based clustering of heterogeneous information networks with star network schema. In KDD , pages 797-806, 2009. [20] R. Wang, C. Shi, P. S. Yu, and B. Wu. Integrating clustering and ranking on hybrid heterogeneous information network. In PAKDD , pages 583-594, 2013. [21] D. Zhou, S. Orshanskiy, H. Zha, and C. Giles.
Co-ranking authors and documents in a heterogeneous network. In ICDM , pages 739-744, 2007.
