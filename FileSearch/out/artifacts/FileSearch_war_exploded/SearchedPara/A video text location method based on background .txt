 ORIGINAL PAPER Xiufei Wang  X  Lei Huang  X  Changping Liu Abstract In this paper, we propose a simple yet powerful video text location scheme. Firstly, an edge-based back-ground classification is applied to the input video frames, which are subsequently classified into three categories: sim-ple, normal and complex. Then, for the three different types of video frames, different text location methods are adopted, respectively: for the simple background class, a stroke -based textlocationschemeisused;forthenormalbackgroundclass, a variant of morphology called conditional morphology is incorporated to remove the non-text noises; for the complex background situation, after location routine based on stroke analysis and conditional morphology, an SVM text detector is trained to reduce the false alarms. Experimental results show that our approach performs well in various videos with high speed and precision.
 Keywords Background classification  X  Video text location  X  Stroke extraction  X  Conditional morphology 1 Introduction With the proliferation of digital media, techniques for automated video storage and retrieval have gained special significance. Text in videos is a powerful source of high-level semantics. If these text occurrences could be detected, segmented and recognized automatically, they would pro-vide useful cues for applications such as keyword-based video search, automatic video logging and text-based video indexing. Text location, as the first step of text information extraction, which aims at extracting potential text regions in videos, is an essential step for the extraction of video text information. 1.1 State-of-the-art in text location A variety of approaches to text location have been proposed during the past decades. According to the text features uti-lized, these methods can be mainly categorized into two types: region based and texture based [ 9 , 11 ].
Region-based methods use the properties of color in the text region and its surroundings. They exploit the fact that there is very little variation of color within text, and this color is sufficiently distinct from text X  X  immediate background to the corner map of original video frame by the SUSAN oper-ator. The corners are then filtrated and merged by some rules to get the text locations. Similar to Hua X  X  method, Dubey [ 4 ] use the vertical Sobel edges, then the morphological technique and connected component analysis are applied to form the candidate text regions. As only low-level features are used in region-based methods, the merit and defect of these methods are both obvious: they show high speed and perform well under simple background, but are sensitive to noises.

Texture-based methods mainly use the unique textural properties that distinguish texts from backgrounds. The tech-niques based on Gabor filters, Wavelet, FFT, spatial variance, etc. can be used to extract the textural features, which are then trained to get a text detector using machine learning meth-ods such as SVM, AdaBoost, and MLP [ 3 , 10 , 12 , 18 , 19 ]. Exact text locations can be obtained by a sliding window scanning within the input image. For example, Shin [ 18 ] uses the gray-scale features in a special regions directly to get a SVM text detector, while a cascade structure of Ada-Boost [ 5 ] algorithm is introduced by Li [ 3 ] to design the text detector based on histogram features. The main problem with texture-based method is the high computation complexity in texture classification, which accounts for most of the pro-cessing time.

More recently, a coarse-to-fine text location scheme is pro-posed, which combines the region-based method and texture-based method [ 1 , 2 , 14 , 22 ]. Candidate text regions are first obtained by region-based method. Then, a text verification step is applied to check the candidate text regions using a tex-ture classifier, instead of the total image scanning by the text detector. Chen [ 1 , 2 ] first gets candidate text regions using edge detection and morphology methods. Then, a SVM text detector based on constant gradient variance features is used to remove false alarms. Compared with traditional texture-based methods, the computational complexity is reduced remarkably. However, as the text detector is only used for text verification but not localization, the results of this method are highly dependent on the performance of coarse loca-tion, which can vary a lot under complex background sit-uation. 1.2 Difficulties for text location Although there are so many text location algorithms by now, there is still a long way from the practical application. The reason is that video text location itself is a challenging job, which relies on the following factors: (1) The style, size and color of video texts vary from videos (2) The background of video texts is complex and volatile.
Although the background complexity affects the work of text location a lot, most of the existing methods mainly focus on the performance of the location algorithm, while seldom attention is paid to difficulties for the text location. Actually, the localization of texts under different background is quite different. Generally speaking, the detection of video texts embedded in simple background would be much easier than that in the complex situation.

An example of video texts under different background complexity is shown in Fig. 1 . The text regions in the two images are both highlighted by green rectangles. It can be seen that the background of Fig. 1 a is very simple while it is more complex in Fig. 1 b. To locate the texts in Fig. 1 a, simple methods such as global binarization would be effec-tive, while the process of Fig. 1 b would be more sophis-ticated. It is obvious that the texts in Fig. 1 b cannot be extracted correctly just by a global binarization method, which is effective to Fig. 1 a, and the sophisticated process for Fig. 1 b may probably be unnecessary for the situation of Fig. 1 a.

So, if we could obtain the background complexity of the input video images prior to the text location process, it would be very helpful for us to choose a more effective location method. Unfortunately, seldom attention is paid to this, and there is no standard method to measure the com-plexity of text background by now. Most researchers just make a simple estimation by perception, which is different from person to person [ 17 , 19 ]. And there are also no stan-dard public video text databases for the researchers to test their algorithms, which are not comparable, for the back-ground complexity of the images in the databases are totally different. 1.3 Proposed scheme The previous analysis inspires the motivation of this work. Different from the former methods, the background com-plexity of the input image is taken into consideration. A back-ground classification step is first applied to category the input video frames into three classes: simple, normal and complex according to the background complexity. Then, different text location methods are applied to the related background type, respectively. For the simple background class, a stroke-based textlocationschemeisused;forthenormalbackgroundclass, a variant of morphology called conditional morphology is incorporated to remove the non-text noises; for the complex background situation, after location routine based on stroke analysis and conditional morphology, an SVM text detector is trained to reduce the false alarms. The flow chart of our algorithm is showed in Fig. 2 .

There main decisions preceded the development of our new text location scheme. (1) The video texts in this paper refer to film captions, (2) Video texts should be either horizontal or vertical. (3) As the stroke-based method is utilized, our system is
The rest of the paper is organized as follows. Section 2 introduces the method to measure the complexity of text background. Section 3 presents the details of text location algorithm for each kind of background. The database we use in the paper, together with the performance evaluation method and experiment results, is described in Sect. 4 . Sec-tion 5 provides some concluding remarks. 2 Background classification 2.1 Background complexity evaluation Textsareformedbyaseriesofregulardistributededgepoints, and this property is frequently used in text location. However, edge points in the background can also be falsely detected as texts and cause much confusion. Generally speaking, the more edge points, the more complex the background is.
Given an input image I ,weuse BC to measure the back-ground complexity as BC = where E (  X  ) and S (  X  ) denote the edge number and area of the input region, respectively. The calculation of E (  X  ) will be illustrated in Sect. 2.2 . The actual meaning of BC is the edge density of the input video frame. The bigger BC is, the more complex the background is. The observation that complex background always shows with dense edges proves that the evaluation of background complexity by edge density makes sense. 2.2 Background classification According to the analysis in Sect. 2.1 , the text background complexity can be expressed by the image edge density as showed in Eq. 1 . For convenience, we classify the images of different background complexity into three classes: the simple, the normal and the complex.

Given an input image I , the exact background classifica-tion method is carried out as follows. (1) Edge detection. Get the edge map of the input image (2) Binarization. The binary edge map (denoted as BE m ) (3) BC calculation. Calculate the background complexity (4) Background classification. Classify the input video Some background classification results are showed in Fig. 3 . Images in Fig. 3 a, c and e are examples of the sim-ple, normal and complex background classes, and Fig. 3 b, d and f are the related binary edge map with the val-ues of BC showed below. It can be seen that the value of BC increases in accord with the background complex-ity. 3 Text location The background type of the input image provides a priori knowledge of the difficulty for text location, according to which effective text detection methods are selected. 3.1 The simple background type The location scheme adopted in the paper for the simple class is mainly based on the stroke extraction method. Details are illustrated as follows. 3.1.1 Stroke extraction Texts are constitute of regular strokes in different directions. Generally speaking, text strokes show the following charac-teristics: (1) Strokes always contrast sharply with the background; (2) The width of stroke should be more than 3 pixels and (3) The directions of stroke are mainly distributed in 0, 45,
Ye [ 21 ] propose a stroke extraction operator by the char-acteristics described previously to extract texts in the check. Here, we use the operator to extract stroke information of video texts. The stroke map of the original input image is positivestrokemapmarkedas PSM ,whiletheinverseisnega-tive stroke map marked as NSM . Because the stroke operator only responses to dark texts in bright background, we use both the PSM and NSM to detect bright and dark texts.
Given an video frame, the exact stroke extraction process utilized in the paper is described as follows: (1) Stroke extraction. Get PSM and NSM of the input image (2) Binarization. Get the binary image of PSM and NSM (3) Stroke map mergence. Get the final stroke map SM by SM ( p ) = max ( BPSM ( p ), NPSM ( p )) (7) where SM ( p ), BPSM ( p ) and NPSM ( p ) denote pixel p of SM , BPSM and NPSM , respectively. 3.1.2 Stroke density filtration There are still some stroke-like noises, which cannot be elim-inated by stroke extraction. However, it is observed that the stroke density of text regions is much denser than that of non-text regions. Thus, the stroke density filtration step can be applied to remove the noises.
 Let SN ( X ) be the stroke pixel number of region X as: SN ( X ) =
The stroke density of region X , named as SD ( X ) ,is obtained by: SD ( X ) = SN ( X )/ S ( X ) (9)
Notice that the S ( X ) in Eq. 9 is the same meaning as we explained in Sect. 2 .

The stroke density filtration is carried out by a total sliding window scan of the whole stroke map SM . For the scanned region X , it would remain only if the stroke density of X is greater than a threshold (0.2 in this paper), otherwise it would be removed. The size of the slide window is 15  X  15 with a step of 4 pixel in both horizontal and vertical directions in the paper. 3.1.3 Region decomposition Using stroke extraction and stroke density filtration, most of the text regions can be segmented out from the input image. However, as we adopt both NSM and PSM to detect dark and bright texts, text lines would be conglutinated if they are too close in vertical directions, because the interstices between text lines can also be regarded as strokes.

To overcome this problem, region decomposition method proposed by Hua [ 7 ] is adopted in the paper to decompose conglutinated text lines. Decomposed text boxes can be con-sidered as texts only when they satisfy the text box con-straints. In this paper, we regard that the width and height of a text box should be great than 10 pixels, and the stroke density of text regions should be larger than 0.2. The text box that do not satisfy the constraints is regarded as a false alarm. 3.1.4 Text mergence In order to form candidate text regions, text boxes or lines that are close to each other horizontally or vertically need to be merged. Let B i and B j be two text boxes, W i , H i W conditions for the text mergence are considered: (A) (B) (C) (1) If B i and B j are overlapped as Fig. 4 a, let B ij be the (2) If B i and B j are horizontally near to each other as (3) If B i and B j are near to each other vertically as Fig. 4 c,
Some experiment results are showed in Fig. 5 . Figure 5 a is the input video frame. Figure 5 b and c are PSM and NSM , and Fig. 5 d and e are their binary image, respectively. Figure 5 f is the mergence of Fig. 5 d and e. Figure 5 gisthe result of stroke density filtration, and Fig. 5 h is the final loca-tion result after region decomposition and text mergence. 3.2 The normal background type Texts in the normal background cannot be extracted precisely just by stroke-based method, for there are more non-text dis-turbances. To solve this problem, we introduce an improved method of morphology: conditional morphology. 3.2.1 Conditional morphology Morphology methods are widely used in text location algo-rithms to remove noises and enhance texts [ 1 , 6 , 12 , 22 ]. How-ever, traditional morphology methods can hardly reach our expectations, for the erosion operation can remove not only the noises but also texts, while the dilation method can enhance both texts and non-texts.

To overcome this problem, an improved method of mor-phology called conditional morphology, is proposed in the paper. The underlying intuition of this method is that the mor-phology methods should be carried out conditionally for text and non-text regions to suppress non-text noises and enhance texts. The stroke density defined in Sect. 3.1.2 is adopted as operation conditions in the paper.

Let  X  and  X  be the conditional thresholds for dilation and erosionoperations,respectively,andsymbol P bethemasked region of the input image by the morphology structuring ele-ment. If the stroke density of P is larger than  X  ,weregard it as texts and take dilation method to enhance it, while if the stroke density of P is smaller than  X  ,weregarditas (A) (B) disturbances and take erosion to suppress it. Let ConDilate (
P , X ) and ConErode ( P , X ) be the operation of condition dilation and erosion of region P . Conditional morphology utilized in the paper can be written as ConDilate ( P , X ) = ConErode ( P , X ) = where Q and R are structure elements of dilation and ero-sion, respectively, and SD ( P ) is the stroke density of region P .AsshowedinFig. 6 ,a10  X  3 dilation operator and a 7  X  4 erosion operator are used for the conditional morphology in this paper.

Comparison results of conditional morphology and the original morphology are showed in Fig. 7 . Figure 7 aisthe input image, and Fig. 7 b is its negative binary stroke map. Figure 7 c and e are direct erosion and dilation results with structure elements of both 3  X  3, while Fig. 7 d and f are the conditional erosion and dilation results with structure ele-ments of 6  X  4 and 8  X  6 , respectively.

Compared Fig. 7 c with Fig. 7 d, it can be found that direct erosion removes not only the non-text noises but also the texts while condition erosion remains most of the text infor-mation when noises are removed. Similar conclusion can be obtained by comparison of Fig. 7 e and f.

Therefore,byconditionalmorphology,textsareenhanced, and noises are restrained remarkably, which makes the next location process much easier. 3.2.2 Location scheme The location scheme for the images of normal background complexity is a combination of stroke-based method as illus-trated in Sect. 3.1 and the conditional morphology method. Details are presented in Table 1 . Experimental results showed in Sect. 4.3 prove that this method is quite effective for the images of normal background complexity. 3.3 The complex background type When the background is complex, both text and non-text regions have high stroke density. The conditional morphol-ogy operations for the suppression of non-text noises and enhancement of text regions may not work effectively. To overcome this problem, a SVM-based texture classifier is applied in this condition to refine the precise text lines form candidate text regions. Details of this method are illustrated in the following parts. 3.3.1 Feature extraction A novel texture feature for text location: block-partitioned gradient histogram feature and gray-scale contrast feature is proposed in this paper. This feature is inspired by the analysis of texts X  characteristic on the following two points: (1) Texts are made up of edge points toward different ori-(2) The distribution of these edge points in different part of
What X  X  different from the pixel-based feature is that the feature proposed is region based. The text region is first par-titioned into several sub-blocks as showed in Fig. 8 . For each sub-block, we select the gray-scale contrast( GSC ) feature and edge-orientation-histogram( EOH ) feature.
 The GSC is used to eliminate the background influence. Let R be the whole text block, and k be the partitioned sub-block as showed Fig. 8 . Here, 1  X  k  X  8. Let R m ( k ) and ( k ) be the mean contrast and variance contrast of region k , respectively. The gray-scale contrast feature is defined as
R ( k ) = ( k ) = where Mean (  X  ) and Va r (  X  ) are the mean and variance of the input region.

Texts are formed by regular distributed edge points, which display statistical regularity in different partitioned blocks. The EOH [ 8 ] feature is widely used in texture analysis. In this paper, we adopt it as text features for text location.
Given a candidate block, the feature extraction step is car-ried out first by a normalization of the input block to a fixed size, which is 16  X  16 in the paper. Then, the normalized block is partitioned into eight parts as Fig. 8 , and for each sub-block, GSC and EOH features are extracted. The feature dimension is 8  X  ( 2 + 8 ) = 80. 3.3.2 Text detector To get an effective text detector, the SVM is used in our work to train the extracted features. SVM is a machine learn-ing method proposed by V. Vapnik and has been widely used in classification problems for its good performance [ 16 , 20 ]. The core idea of SVM is to find an optimal separating hyper-plane, which maximizes the margin between the two classes. For the non-linear situation, the kernel functions are used to map the original data into higher dimension space, in which a linear separating hyper-plane can be found.

In short, given m labeled training samples: ( x i , y i ),... ( x trained SVM classifier is shown as f ( x ) = where  X  i and b are parameters got by SVM training, and x is the selected support vector by SVM. 3.3.3 Text refinement Different from the verification process in [ 1 , 2 , 16 ], the text detector obtained by the SVM training is used for text refine-ment in this paper to get a more precise location of texts in the candidate text regions, which are obtained by the location method proposed in Sect. 3.2 .
Let T c be a candidate text region with the width W and height H . The exact text refinement process by SVM text detector are as follows: (1) Slide window scan by SVM. T c is first scanned by an (2) Text rect filtration. As the slide step s is smaller than (3) Text mergence. The rest sub windows are merged to 4 Experiment and results 4.1 The database To validate our method, we grabbed 1753 video frames with texts from 76 videos included movies, TV, MTV and etc. The resolution ranges from 352  X  240 to 720  X  576.
 The basic information of the database is presented in Table 3 and Fig. 11 . The video frames grabbed from movies, TV and MTV account for 51 . 66 , 14 . 21 and 34 . 11% , respec-tively. Using the background classification method illustrated inSect. 2 ,imagesinthedatabasearecategorizedtothreeclas-ses. The number of images and text lines of different back-ground complexity is presented in Table 3 . Some samples in the database are showed in Fig. 10 . 4.2 Performance evaluation The most commonly used measurements for text location algorithm are the recall rate and precision. In this paper, to reflect the influence of edges on text location, we use the edge-based evaluation method to define the performance evaluation criterions. The motivation of edge-based perfor-mance evaluation can be illustrated by the example showed in Fig. 12 . The red box is the ground truth, and the green is the location result. It can be seen that neither of the two located boxes is precise, but the influence of the two boxes on the recognition step is different. For Fig. 12 a, although the located box is bigger than the ground truth, it would not affect the recognition for the background is clean and simple, while for Fig. 12 b, the situation is quite different because the located box brings too much non-text noises.

As showed in Fig. 13 , let symbol G be the ground truth of the texts in the image, and L be the located area by text location algorithms. M is the crossover region of G and L . The edge-based recall rate and precision is defined as Recall = Precision = Here, E (  X  ) is the same meaning as we defined in Sect. 2.1 . 4.3 Experiment result and analysis 4.3.1 Comparison experiments of edge-based method and stroke-based method on the simple background For the video text images of simple class background, we adopt the stroke-based method (illustrated in Sect. 3.1 )to get the text regions. Compared with the edge, the stroke is a powerful feature of double-edge, and is thus more expres-sive. To illustrate the advantage of our method, we replace the stroke extraction step of location method in Sect. 3.1 with canny edge detection, and the stroke map with the canny edge map, together enable an edge -based location method. Com-parison experiments of edge-based method and stroke-based method are carried out on the simple background images of the database. The results are presented in Table 4 , where STL refers to the stroke-based method utilized in the paper and ETL means the edge-based method we illustrate ear-lier.

The experimental results show that on the simple back-ground text images, the stroke-based method gets a higher recall rate (97 . 27%) and precision (93 . 01%) than the edge-based method. This is because the stroke is double-edge fea-ture and is more expressive than edge feature when applied in text location. 4.3.2 Comparison experiments on the images of the normal background complexity For the normal background type, a variant of traditional morphology method called conditional morphology is used to suppress the non-text noises. Compared with traditional morphology method, conditional morphology cannot only remove non-text noises but also enhance text regions. According to the definition of conditional morphology in Sect. 3.2 , there are two parameters: the dilation threshold  X  and erosion threshold  X  . To get the optimal parameters for text location, we did several groups of experiments. The results are showed in Figs. 14 and 15 . Nine groups experi-ments are showed in Fig. 14 for the selection of the dilation threshold  X  , and six in Fig. 15 for the erosion threshold In this paper,  X  = 0.5 and  X  = 0.2 according to the results in Figs. 14 and 15 .

Tovalidatetheadvantageofourmethod,wemakecompar-ison experiments of different location methods: STL, STL + M and STL + CM on the normal background text images. Here, STL + M refers to the text location method of tradi-tional morphology combined with stroke-based method, and STL + CM for the conditional morphology and stroke-based method. For the method STL + M, the conditional morphol-ogy operation in Table 1 is replaced by the traditional mor-phology method.
Experimental results are showed in Fig. 16 and Table 5 .It can be seen that when applying the stroke -based method on the images of normal background complexity, it just shows a precision of 83 . 43%. When the traditional morphology method is utilized, the precision increases by 0 . 38% with alossof0 . 18% in the recall rate, while using the condi-tional morphology method, the precision goes up to 89 . 08% with a little increase in the recall rate. This proves that conditional morphology method cannot only suppress the non-text noises but also enhance texts. The effect of condi-tional morphology and traditional morphology is showed in Fig. 7 .
 4.3.3 Comparison experiments of different text features on the complex background A new text feature called block-partitioned edge orientation histogram feature and gray-scale contrast feature is proposed for the complex background text images. Compared with tra-ditional point-based text features, our feature is region based, that is, the text is first partitioned by lines of different direc-tions, and the feature proposed in Sect. 3.3 is extracted and combined. We select several other commonly used texture features as comparisons to prove the advantage of the pro-posed feature. As presented in Table 6 , the gray-scale (GS) feature [ 10 , 18 ] and edge map (EM) feature [ 1 ] are used.
Experiment results in Table 6 present that our feature per-forms the best in both precision and recall rate. The GSC feature in our feature is used to eliminate the background influence, and the EOH feature is used to describe the texture distributions. The experiment results prove that the proposed feature is effective. 4.3.4 Experiments of background classification-based text location algorithm The main contribution of this paper is the frame work of back-ground classification-based text location method. The input video frames are first classified by background complex-ity. Then, different text location methods are applied to the related background type adaptively. In this way, texts in dif-ferent background type are extracted, respectively by proper location methods. We apply the text location algorithms men-tionedinthispaperonthetotaldatabase.Experimentalresults are presented in Table 7 , where Alg.1, Alg.2 and Alg.3 refer to the location method described in Sects. 3.1 , 3.2 and 3.3 , respectively. BCTL is the background classification-based text location method, which we want to propose.

It can be seen that the stroke-based location method (Alg.1) shows the best recall rate (96 . 62%) but the worst precision (70 . 63%). This is mainly because the stroke-based method extracts most of the strokes in which texts and noises are both included. This leads to a high recall rate, but as no effective de-noising methods are taken, the precision is very poor. It may work well on the simple background type images, but for the normal and complex type with more noises it shows bad performance. For Alg.3, it shows a much higher precision than the others due to the SVM classifier, while the sacrifice of recall rate and time cost is also obvi-ous. For the simple and normal background text images, there is no need to use the SVM classifier for the text can be easily located with less time. However, when we apply the background classification method into text location, dif-ferent background type text images can be located by the proper method by background complexity. As presented in Table 6 , the BCTL method performs well both in precision and in recall rate. It X  X  more reasonable for us to choose differ-ent text location methods for text images in different back-ground.
 Some text location results by our method are showed in Fig. 17 . 5 Conclusion A new text location frame is presented in this paper. The difference of the proposed method from the former is that a background classification step is first applied. Different text location methods are then adopted based on the background complexity. For the simple background class, a stroke-based textlocationschemeisused;forthenormalbackgroundclass, a variant of morphology called conditional morphology is incorporated to remove the non-text noises; for the com-plex background situation, after location routine based on stroke analysis and conditional morphology, an SVM text detector is trained to reduce the false alarms. Experiment results show that the SVM classifier obtained by training of the proposed feature improves location precision remark-ably.

Comparison experiment results prove that the text location scheme based on the background classification performs bet-ter than any of the algorithms mentioned in the paper applied solely to the database.
 References
