 Daniil Ryabko dani il@cs.rhul.a c.uk 0EX, UK Online pattern recognition (or classi cation) is, infor-mally , the follo wing task. There is a nite num ber of classes of some complex objects. A predictor is learn-ing to lab el objects according to the class they belong to (i.e. to classify), based only on some examples (la-belled objects). One of the typical practical examples is recognition of a hand-written text. In this case, an object is a hand-written letter and a lab el is the letter of an alphab et it denotes. Another example is recog-nising some illness in a patien t. An object here is the set of symptoms of a patien t, and the classes are those of normal and ill.
 The formal mo del of the task used most widely is de-scrib ed, for example, in Vapnik (1998), and can be brie y introduced as follo ws (we will later refer to it as \the i.i.d. mo del"). The objects x 2 X are dra wn inde-penden tly and iden tically distributed (i.i.d.) according to some unkno wn (but xed) probabilit y distribution P ( x ). The lab els y 2 Y are given for eac h object according to some (also unkno wn but xed) function ( x ) 1 . The space Y of lab els is assumed to be nite (often binary). The task is to construct the best pre-dictor for the lab els, based on the data observ ed, i.e. actually to \learn" ( x ).
 Initially , the problem of pattern recognition had been considered in so-called oine (or batch ) setting: a ( nite) set of examples is divided into two nite sub-sets, the training set and the testing set. A predictor is constructed based on the rst set and then is used to classify the objects from the second; the less er-rors it mak es on the testing set the better. In another setting, so-called online setting of pattern recognition problem, a predictor starts by classifying the rst ob-ject with zero kno wledge; then it is given the correct lab el and (ha ving \learned" this information) pro ceeds with classifying the second object, the correct second lab el is given, and so on. This setting is more nat-ural than the oine one in the practical applications dealing with constan tly changing or slowly gained data (see e.g. Bottou and LeCun (2003) for a study in whic h cases online metho ds outp erform oine metho ds). There is a plen ty of algorithms dev elop ed for solv-ing the pattern recognition task (see Devro ye, Gy X or and Lugosi (1996) for the most widely used metho ds). However, the i.i.d assumption, whic h is cen tral in the mo del, is too tigh t for man y applications. It turns out that it is also too tigh t for a wide range of metho ds dev elop ed under the assumptions of the mo del: they work nearly as well under weak er assump-tions.
 Consider the follo wing situation. Supp ose we are try-ing to recognise a hand-written text. Obviously , letters in the text are dep enden t (for example, we strongly ex-pect to meet \u" after \q"). Does it mean that we can not use pattern recognition metho ds dev elop ed within the i.i.d. mo del for the text recognition task? No, we can shue the letters of the text and then use those metho ds. But will the results of recognition change signi can tly if we do not shue the letters? It is intu-itiv ely clear that the answ er is negativ e; it is intuitiv ely clear if we are having in mind nearly any popular pat-tern recognition metho d. Moreo ver, in online tasks we cannot shue examples, and so the question is not idle.
 It turns out that the only needed assumption on the distribution of examples are the follo wing two. First, that the dep endence between obje cts is only that be-tween their labels ; in other words, the type of object-lab el dep endence does not change in time. In our ex-ample, an image of a letter whic h in the beginning of the text denotes, say, \a", to the end of the text will not be interpreted as, say, \e". Second, eac h lab el should not cease in occurrence, i.e. the rate of occur-rence of eac h lab el should keep above some positiv e threshold. In the above example, the rate of occur-rence of eac h letter should be, say, between 1% and 99% of all letters, with some feasible probabilit y (de-pending on the size of the text).
 These intuitiv e ideas lead us to the follo wing mo del (to whic h we refer as \the conditional mo del"). The la-bels y 2 Y are dra wn according to some unkno wn (but xed) distribution P ( y ), where P is a distribution over the set of all in nite sequences of lab els. There can be any type of dep endence between lab els; moreo ver, we can assume that we are dealing with any ( xed) com binatorial sequence of lab els. However, in this sequence the rate of occurrence of eac h lab el should keep above some positiv e threshold. For eac h lab el the corresp onding object x 2 X is generated according to some (unkno wn but xed) probabilit y distribution P ( x j y ). All the rest is as in the i.i.d. mo del. The main di erence from the i.i.d. mo del is in that in the conditional mo del we made the distribution of lab els primal; having done that we can relax the requiremen t of indep endence of objects to the condi-tional indep endence, and replace the i.i.d. assumption about the distribution of lab els with the only assump-tion that the rate of occurrence of eac h lab el does not tend to zero.
 The main criterion in estimating how well a predictor works is the probabilities of its errors. In this work we pro vide a tool for obtaining estimations of probabil-ity of an error of a predictor in the conditional mo del from an estimation of the probabilit y of an error in the i.i.d. mo del. The only assumption on a predictor under whic h the new estimations are of the same order is what we call toler anc e to data : in any large dataset there is no small subset whic h change signi can tly the probabilit y of an error. This prop erty should also hold with resp ect to perm utations. This assumption on a predictor should be valid in the i.i.d. mo del. Thus, the results achiev ed in the i.i.d. mo del can be extended to the conditional mo del; this concerns distribution{free results as well as distribution{sp eci c, results on the performance on nite samples (whic h are of the main concern in this work) as well as asymptotic results. The general theorems about extending results con-cerning performance of a predictor to the conditional mo del are illustrated with the example of predictors minimising empirical error. We use some results of Vapnik-Cherv onenkis theory to establish tolerance to data of suc h predictors and sho w what results about them the dev elop ed theory yields.
 The idea of relaxing the i.i.d assumption in the i.i.d. mo del is not new. Thus, in Morv ai, Yakowitz and Al-goet (1997) the authors study the task of predicting a stationary and ergo dic sequence objects, and also consider the generalisation of this task to the task of regression estimation (whic h itself is a more general varian t of pattern recognition). Under the assumption that the join t distribution of objects and lab els is sta-tionary and ergo dic, the authors manage to construct a weakly consisten t predictor. This is a reasonable result in the framew ork and for the (more general) task at hand, but it is not the kind of results whic h is usually an achiev able goal for pattern recognition metho ds, namely results on the performance of a predictor over a nite sample of data, and pointwise (almost surely) consisten t predictors. Another approac h is considered in Vovk (2002), where the authors construct a wide class of predictors for the case of exc hangeable exam-ples (i.e. the distribution generating examples is ex-changeable).In both approac hes the authors consider di eren t types of assumptions on the joint distribution of objects and lab els. Then they construct a predictor, as in Morv ai, Yakowitz and Algo et (1997), or a class of predictors, as in Vovk (2002), to work well under the assumptions made. Our approac h is di eren t in that we nd the conditions on the distribution of lab els and (another condition) on conditional distribution of ob-jects, under whic h a certain class of predictors whic h are already known to work well in the i.i.d. mo del, work as well. The traditional scenario for online pattern recognition is as follo ws.
 Consider a sequence of examples ( x 1 ;y 1 ) ; ( x 2 ;y 2 eac h example z i := ( x i ;y i ) consists of an obje ct x and a label y i := ( x i ) 2 Y , where X is a measurable space called an obje ct space , Y := f 0 ; 1 g is called a label space and : X ! Y is some deterministic function. For simplicit y we made the assumption that the space Y is binary , but all results easily extend to the case of any nite space Y . The notation Z := X Y is used for the measurable space of examples. Ob jects are dra wn according to some probabilit y distribution P on X 1 (and lab els are de ned by ).
 The notation P is used for distributions on X 1 while the sym bol P is reserv ed for distributions on X . In the latter case P 1 denotes the i.i.d. distribution on X 1 generated by P .
 The traditional assumption about the distribution P generating objects is that P = P 1 for some distribu-tion P on X , i.e. examples are i.i.d. This is what we call in this pap er the i.i.d. model .
 Here we replace this assumption with the follo wing two conditions.
 First , for any n 2 N where A is any measurable set (an event) in X , U n is -algebra generated by y n and U is any -algebra whic h con tains U n .
 In more intuitiv e notation, for any i ;:::;i k ;j 1 ;:::;j k 2 N
P ( x n 2 A j y n ;x i 1 ;y j 1 ;:::;x i (This condition looks very much like Mark ov condi-tion, with the help of whic h it can be understo od more easily . Mark ov condition requires that eac h object de-pends on the past only through its immediate prede-cessor. The condition 1 says that eac h object dep ends on the past only through its lab el.) Second , for any y 2 Y , for any n 1 ;n 2 2 N and for any event A in X
P ( x n 1 2 A j y n 1 = y ) = P ( x n 2 2 A j y n 2 = y ) : (2) (It is worth noting that (1) allo ws dep endence in n , otherwise the presen t condition is not needed.) For eac h y 2 Y and any n 2 N we will denote the distribution P ( x n j y n = y ) by P y (it does not dep end on n by (2)). As we want the function ( x ) whic h speci es the lab el for eac h object to be deterministic, we put an extra requiremen t on the distributions P y , y 2 Y , namely that there exist suc h sets X y X , y 2 Y suc h that X 0 \ X 1 = ? and P y ( X y ) = 1 for eac h y 2 Y . 2 Under the conditions (1) and (2) we say that ob-jects are conditional ly indep endent and identic ally dis-tribute d (conditionally i.i.d).
 Less formally , these conditions can be reform ulated as follo ws. Assume that we have some sequence ( y n ) n 2 N of lab els and two probabilit y distributions P 0 and P 1 on X . Eac h example x n 2 X is dra wn according to the distribution P y eac h other.
 A predictor is a measurable function ( x 1 ;y 1 ;:::;x n 1 ;y n 1 ;x n ) taking values in Y . Denote n := ( x 1 ;y 1 ;:::;x n 1 ;y n 1 ;x n ). The probabilit y of an error of a predictor on eac h step n is de ned as (Here P in the list of argumen ts of err n is understo od as a distribution conditional on z 1 ;:::;z n 1 .) We will often use a shorthand notation and an even shorter one P (err n ( ) &gt; " )) in place of We call a predictor ( nitely) universal ly consistent with the bounding function 5 : N R ! [0 ; 1] if for any distribution P on Z We say that a predictor is toler ant to data with bounding function : N R ! [0 ; 1] if for any distri-bution P on Z for any n 2 N , any " &gt; 0 and { n := end of the Section 5 for the discussion of the choice of the constan ts { n ). The probabilit y in this de nition is tak en over z 1 ;:::;z n .
 Tolerance to data means, in e ect, that in any typi-cal large portion of data there is no small portion that change drastically the probabilit y of an error. This prop erty should also hold with resp ect to perm uta-tions.
 Theorem 1. Supp ose that a distribution P is such that the obje cts are conditional ly i.i.d, i.e. P sat-is es (1) and (2). Fix some 2 (0 ; 1 = 2] , denote p ( n ) := 1 n # f i n : y i = 0 g and C n := P ( j p ( n ) j 1 ) for each n 2 N . For any predictor if is nitely universal ly consistent with some bounding function 5 ( n;" ) and universal ly toler ant to data with some bounding function ( n;" ) , then for any " &gt; 0 and any n &gt; e 4 2 .
 The pro of of this and the follo wing theorem can be found in App endix A.
 The theorem says that if we kno w with some con -dence C n that the rate of occurrence of eac h lab el is not less than some (small) , then having bounds on the error rate of a predictor in the i.i.d. mo del we can obtain bounds on its error rate in the conditional mo del.
 A predictor dev elop ed to work in the oine setting should be, loosely speaking, toleran t to perm utations of the training sample. The theorem sho ws under whic h conditions in the online mo del this prop erty of a predictor can be utilised.
 Theorem 1 pro vides a tool for obtaining distribution{ free bounds on probabilit y of an error in the condi-tional mo del given the bounds in the i.i.d. mo del. However, often for certain classes of distributions there exist much better bounds on the probabilit y of an error than for the univ ersal (distribution-free) case. Next we sho w how distribution{sp eci c results achiev ed in the i.i.d. mo del can be extended to the conditional mo del. Let P be some distribution on X 1 satisfying (1) and (2). We say that a distribution P on X agrees with P if the conditional distribution P ( x j y ) is equal to P y and P ( y ) 6 = 0 for eac h y 2 Y . Clearly , this de nes the distribution P up to the parameter p = P ( y = 1) 2 (0 ; 1). For a distribution P on X 1 we denote the family of distributions whic h agree with P For a distribution P on X 1 whic h satis es (1) and (2) we call a predictor ( nitely) consistent for the distri-bution P with the bounding function 5 : N R ! [0 ; 1] if (3) holds for any distribution P on X whic h agrees with P . Furthermore, we say that a predictor is tol-erant to data for a distribution P with bounding func-tion : N R ! [0 ; 1] if (4) holds for any distribution P on X whic h agrees with P .
 Theorem 2. Supp ose that a distribution P on X 1 satis es (1) and (2). Fix some 2 (0 ; 1 = 2] , denote p ( n ) := 1 n # f i n : y i = 0 g and C n := P ( j p ( n ) j 1 ) for any n 2 N . For any predictor if is nitely consistent for P with some bounding function 5 ( n;" ) and toler ant to data for P with some bounding function ( n;" ) , then for any " &gt; 0 , any n &gt; e 4 2 .
 Let us call a class of distributions P on X conditional ly close d if with any distribution P 2P the class P also includes any distribution P 0 suc h that P ( A j y = i ) = P ( A j y = i ) for any A X and eac h i 2 Y (i.e. P 01 agrees with P 1 ).
 As imp ortan t examples of conditionally closed classes of distributions we men tion the class of distributions whic h have densities, whic h have smo oth densities, dis-tributions whic h generate examples separable by a hy-perplane.
 Theorem 2 means that if we have some bounds on the error probabilities of a predictor for some condition-ally closed class of distributions P then we can obtain bounds on the error probabilities of for any distribu-tion P on X suc h that any (some) distribution on X whic h agrees with P is in P (ha ving bounds on toler-ance of to data for the distributions from P ). In fact, Theorem 1 is an immediate consequence of Theorem 2. Here we sho w how the dev elop ed concepts relate to the PAC (Probably Appro ximately Correct) theory (see, e.g. Vidy asagar (1997); Kearns and Vazirani (1994)); here we mainly follo w Vidy asagar (1997) in de nitions).
 For the purp ose of this section we x some condition-ally closed class P of distributions on Z .
 A predictor is called PAC for the class of distribu-tions P if for eac h " &gt; 0.
 Denote by P the set of distributions on Z 1 whic h satisfy (1) and (2), suc h that for eac h P 2 P there exist P 2 P suc h that P agrees with P . We call a predictor PAC in conditional model for the class of distributions P if for eac h " &gt; 0. For eac h 2 (0 ; 1 = 2], denote p ( n ) := # f i n : y i = 0 g and C n ( ) := sup P 2 P P ( j p ( n ) j 1 ) for eac h n 2 N .
 Theorem 2 implies the follo wing statemen t.
 Corollary 1. Supp ose that lim n !1 C n ( ) ! 1 for some 2 (0 ; 1 = 2] . Supp ose further, that a predictor is toler ant data for each P 2 P with some bounding function ( n;" ) , such that lim n !1 ( n;" ) = 0 for each " &gt; 0 . Then if is PAC for P then it is PAC in conditional model for P . In this section we use some results of Vapnik-Cherv onenkis theory to establish tolerance to data of certain popular classes of predictors and sho w how the asymptotic results (strong univ ersal consistency) can be obtained within the conditional mo del.
 The concepts of Vapnik-Cherv onenkis theory used here were dev elop ed in Vapnik and Cherv onenkis (1974a; 1974b; 1974c). See also Vapnik (1998) and Devro ye, Gy X or and Lugosi (1996) for detailed overviews. Here we mainly follo w Devro ye, Gy X or and Lugosi (1996) in notations.
 Let X = R d for some d 2 N and let C be a class functions of the form ' : X ! Y = f 0 ; 1 g , called decision functions . For a probabilit y distribution P on X we denote err( P;' ) := P ( ' ( x i ) 6 = y i ). The sym bol S ( C ;n ) denotes the n -th shatter coecien t of the class C . For a sample of examples ( z 1 ;:::;z n ) and a decision function ' 2C the empirical error functional err n ( ' ) is de ned as err n ( ' ) := P n i =1 I ' ( x z = ( x i ;y i )).
 Theorem 3. Let C be a class of decision functions and let be a predictor which for each n 2 N minimises err n over C on the observe d examples ( z 1 ;:::;z n ) . Then is universal ly toler ant to data with the bound-ing function Thus, if we have bounds on the VC dimension of some class of classi ers, we can readily obtain bounds on the performance of the empirical error minimising predic-tors for the conditional mo del given those for the i.i.d. mo del.
 For example, for bounds on the VC dimension of classes of neural net works see e.g. Baum and Haus-sler (1989) (also in Devro ye, Gy X or and Lugosi (1996), Theorem 30.6).
 Next we sho w that the asymptotic performance of an empirical risk minimising predictor in the conditional mo del can also be estimated with the help of the the-orems of the previous section.
 Lemma 1. Let P be some distribution on X 1 satis-fying (1) and (2). Assume that a sequenc e of classes C ( k ) of decision rules of the form X ! Y is such that which agrees with P . Then Corollary 2. Let be a classi er that minimises the empiric al error over the class C ( k ) , wher e C ( k ) is the class of neur al net classi ers with k nodes in the hidden layer and the threshold sigmoid, and k ! 1 so that k log n=n ! 0 as n !1 . Let P be any distribution on X 1 satisfying (1) and (2) such that P 1 1 . Then is strongly consistent for P , i.e. In the section 2 we have introduced \conditionally i.i.d." mo del for pattern recognition whic h generalises the commonly used i.i.d. mo del. A general tool is pre-sen ted whic h mak es it possible to extend the results achiev ed in the i.i.d. mo del to the conditional one. The rst question whic h arises is how much more gen-eral the conditional mo del is, and how useful is the generalisation. In resp onse to the rst part, observ e that in the i.i.d. mo del, lab els should be i.i.d, while in the conditional mo del lab els can be distributed arbi-trary , with the only restriction that the rate of occur-rence of eac h lab el does not tend zero. To compare, in the i.i.d mo del the rate of occurrence of eac h la-bel quic kly tends to a certain limit. The assumption that objects are i.i.d conditionally on lab els seems to capture the idea that this is only the object-lab el de-pendence that a predictor is required to learn, whic h itself does not put any restrictions on the dep endence between the examples.
 Another question is in what cases the bounds on the probabilit y of an error pro vided by the (general) the-orems 1 and 2 are of the same qualit y as those in the conditional mo del. Whic h means, are the bounds on tolerance to data of the same (or lower) order then the bounds on the probabilit y of an error in the i.i.d. mo del? To sho w that this is often the case, we consider empirical error minimising predictors in section 4. In the theory of structural error minimisation the probabilit y of an error is split into two parts: estima-tion error and appro ximation error (see, e.g. Devro ye, Gy X or and Lugosi (1996)). The estimation error is the di erence between the probabilit y of an error of the considered predictor and that of the minim um of probabilit y of an error among all decision rules in the class. The bounds on this probabilit y of an error are univ ersal and, in general, good, sub ject to the VC di-mension of the class of decision rules. The second part, the appr oximation error is the minim um of probabilit y of an error among all decision rules in the class. This variable is, in general, greater than the estimation er-ror and can tend to zero arbitrarily slow. We sho w that for predictors minimising empirical risk the con-stan ts bounding the tolerance to data are of the same order that the estimation error, i.e. small, sub ject to the VC dimension of the class.
 Still another question remains, can the same bounds on the probabilit y of an error in the conditional mo del be achiev ed without assumptions on tolerance to data? The follo wing negativ e example sho ws that the bounds on tolerance to data are necessary .
 Prop osition 1. Ther e exists a distribution P on X 1 satisfying (1) and (2) such that P ( j p n 1 = 2 j &gt; 3 =n ) = 0 for any n (i.e. C n = 1 for any &gt; 0 and n &gt; 3 ) and a predictor such that P 1 (err n &gt; 0) 2 1 n for any distribution P which agrees with P and P (err n = 1) = 1 for n &gt; 1 .
 Proof. Let X = Y = f 0 ; 1 g . We de ne the distribu-tions P y as P y ( x = y ) = 1, for eac h y 2 Y . The distri-bution P is de ned as follo ws: P y = P y for eac h y 2 Y and P j Y 1 is the Mark ov distribution with transition probabilit y matrix sequences of lab els ::: 01010101 ::: .
 We de ne the predictor as follo ws So, in the case when the distribution P is used to gen-erate the examples, is alw ays seeing either n 1 zeros and n ones, or n zeros and n ones whic h, consequen tly, will lead it to alw ays predict the wrong lab el. It re-mains to note that this is almost improbable in the case of an i.i.d. distribution.
 One more point whic h needs clari cation is the choice of the constan ts { n . We xed these constan ts for the sak e of simplicit y of notations, however, they can be made variable, as long as { n obeys the follo wing con-dition. almost surely for any p 2 (0 ; 1) and any probabilit y distribution P on X suc h that P ( y = 1) = p , where p n := 1 n # f i n : y i = 0 g . Increasing { n increases the function and decreases C 1 n The author would like to thank the review ers for use-ful commen ts and constructiv e criticism. I also thank Alex Gammerman and Vladimir Vovk for fruitful dis-cussions. I am grateful to Royal Hollo way, Univ er-sity of London for funding my Ph.D. study . This researc h was partially supp orted by EPSR C (gran t GR/R46670/01), BBSR C (gran t 111/BIO14428) and Royal Societ y (gran t ref: 15995).
 Theorem 1 is an immediate consequence of Theorem 2, so we pro ceed with the pro of of the latter. Proof of The orem 2. We de ne the conditional proba-bilities of errors of as follo ws err 0 n ( ) := P ( y n 6 = n j err 1 n ( ) := P ( y n 6 = n j (with the same notational con vention as used with the de nition of err n ( )).
 In words, for eac h y 2 Y = f 0 ; 1 g we de ne err y n as the probabilit y of all x 2 X , suc h that mak es an error on n 'th trial, given that y n = y and given (random vari-ables) x 1 ;y 1 ;:::;x n 1 ;y n 1 . We will also use more explicit notations for err y n ( ) specifying the distribu-tion or the input sequence of lab els, when the con text requires. Obviously , err n ( ) max y 2 Y err y n ( ). For any y := ( y 1 ;y 2 ;::: ) 2 Y 1 , denote y n := ( y 1 ;:::;y n ) and p n ( y ) := # f i n : y i = 0 g . Fix some n &gt; 1, some y 2 Y and suc h y 1 2 Y 1 that n p n ( y 1 ) n (1 ). We shell nd bounds on P err n &gt; " j y n = y 1 n . The follo wing fact will allo w us to pass from i.i.d. distributions to conditionally i.i.d. Observ e that for any p 2 [0 ; 1].
 for eac h y 2 Y , if underlying probabilit y distribution is P , p 1 . Denote p = p n ( y 1 ) =n . For any y 2 2 Y 1 suc h that j p n ( y 2 ) np j { n = 2 there exist suc h perm utations 1 ; 2 of the set f 1 ;:::;n g that y 1 y n { n ) we have, + P 1 p err y n ( x 0 1 ;y 2 1 ;:::;x 0 n ;y 2 n ) &gt; "= 3 ; where x 0 in the rst line is tak en over the space X n , in the second line over X n + { n and everywhere rest over X n . To bound the rst two terms, we observ e that for any y c 2 Y 1 suc h that j p m ( y c m = n + { n = 2, there exist perm utations 1 ; 2 of the set f 1 ;:::;n + { n = 2 g suc h that y c and i n . Hence, for j = 1 ; 2 and any perm utation of the set f 1 ;:::;n g we have if n &gt; 8.
 Thus, and, hence y 2 was chosen arbitrary among sequences y 2 Y 1 for whic h j p n ( y ) np j { n = 2, we conclude (here we used that n &gt; e 16 2 ). Finally , as y 1 was chosen arbitrary among sequences y 2 Y 1 suc h that n p n ( y 1 ) n (1 ) we have
P (err n &gt; " ) P (max whic h concludes the pro of.
 Proof of The orem 3. Fix some probabilit y distri-bution P on X and some n 2 N . Denote ' n := arg min ' 2C err n ( ' ) (so that n = ' n ). We also de-note by ' any suc h decision rule ' 2C that err n ( ' ) = max We need to sho w that P n ( j err( ' ) err( ' ) j &gt; " ) ( n;" ).
 Clearly , j err n ( ' ) err n ( ' ) j { n , as { n is the max-imal num ber of errors whic h can be made on the dif-ference of the two samples. Moreo ver, P n j err( ' ) err( ' ) j &gt; " Now the statemen t of the theorem follo ws from the fact that see Devro ye, Gy X or and Lugosi (1996), Theorem 12.6. Proof of Cor ollary 2. Applying Theorem 2 and using its notations we have By Theorem 12.6, Devro ye, Gy X or and Lugosi (1996) the rst term is bounded by and is summable if we use the bound see Theorem 30.6, Devro ye, Gy X or and Lugosi (1996). The second term is bounded by and so is summable by Corollary 30.1, Devro ye, Gy X or and Lugosi (1996), whic h says that for any distribution P on X and from Lemma 1. For the function ( n;" ) we have the bound pro vided by Theorem 3, whic h is also summable if we use the bound (6).
 Baum, E. and Haussler, D. (1989). What size net gives valid gener alisation? Neural Computation, 1:151-160.
 Bottou L., LeCun Y. (2003). Large Scale Online Learn-ing. Adv ances in Neural Information Pro cessing Sys-tems 16 ( proceedings of NIPS 2003 ) Devro ye L., Gy X or G., Lugosi G (1996). A probabilistic theory of pattern recognition . New York: Springer. Kearns M.J. and Vazirani U.V. (1994) An Intr oduction to Computational Learning The ory The MIT Press, Cam bridge, Massac husetts.
 Morv ai G., Yakowitz S. J., Algo et P. (1997). Weakly
Conver gent Nonp arametric Forecasting of Station-ary Time Series IEEE Transactions on Information Theory , Vol. 43, No. 2, pp. 483{498.
 Vapnik V. N. (1998), Statistic al Learning The ory New York etc.: John Wiley &amp; Sons, Inc.
 Vapnik, V. and Cherv onenkis, A. (1974) Ordered risk minimisation I. Automation and Remote Con trol, 35: 1226-1235.
 Vapnik, V. and Cherv onenkis, A. (1974). Ordered risk minimisation II. Automation and Remote Con trol, 35: 1403-1412.
 Vapnik, V. and Cherv onenkis, A. (1974) The ory of Pattern Recognition Nauk a, Mosco w. (in Russian); German translation: Theorie der Zeic henerk enn ung, Akademie Verlag, Berlin 1979.
 Vidy asagar M. (1997) A The ory of Learning and Gen-eralization New York: Springer.
 Vovk V.(2002). On-line Con dence Mac hines are well-calibrated Proceedings of the Forty Thir d Annual
Symp osium on Foundations of Computer Scienc e,
