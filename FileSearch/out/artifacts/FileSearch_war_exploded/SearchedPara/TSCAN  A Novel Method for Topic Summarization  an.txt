 A topic is defined as a seminal event or activity along with all directly related events and activ ities. It is represented as a chronological sequence of documents by different authors published on the Internet. In this paper, we define a task called topic anatomy, which summarizes and associates core parts of a topic graphically so that readers can understand the c ontent easily. The proposed topic anatomy model, called TSCAN, deri ves the major themes of a topic from the eigenvectors of a temporal block association matrix. Then, the significant events of the themes and their summaries are extracted by examining the constitution of the eigenvectors. Finally, the extracted events are associated through their temporal closeness and context similarity to form the evolution graph of the topic. Experiments based on the official TD T4 corpus demonstrate that the generated evolution graphs comprehe nsibly describe the storylines of topics. Moreover, in terms of content coverage and consistency, the produced summaries are superior to those of other summarization methods based on human composed reference summaries. H.2.8 [ Database Applications ]: Data mining, I.2.7 [ Natural Language Processing ]: Text analysis. Algorithms, Performance, De sign, Experimentation. Topic anatomy. topic summariza tion, temporal text mining. The explosive growth in the numbe r of documents available on the Internet has provided an abundant source of information as an alternative to traditional media. While current technologies can efficiently search for appropriate documents to satisfy keyword search requests, users still have difficulty assimilating needed knowledge from the overwhelmi ng number of documents. The situation is even worse if the needed knowledge is related to a temporal incident, about which many independent authors have published documents based on various perspectives that, considered together, detail the development of the incident. To promote research on detecting and tracking incidents from Internet documents, the Defense Advanced Research Projects Agency (DARPA) initiated the Topic Detection and Tracking (TDT) [1] project. The project defines a topic as  X  a seminal event or activity, along with all directly related events and activities.  X  Its goal is to automatically detect topics and track related documents from several document streams, such as on-line news feeds. The TDT project has attracted great deal of attention due to the importance and practicability of the problem. While an effective TDT system can detect topics and track all th eir related documents [3][5][19], users cannot fully comprehend a topic unless they read many of the tracked documents. Hence, there is an urgent need for effective summarization methods to extract the core parts of detected topics, as well as graphic representation me thods to depict the relationship of core parts. Applied togeth er the two techniques, called topic anatomy , can present essential information about a topic in a structured way. Topic anatomy is an emerging text mining research issue that involves three major tasks: theme generation , event segmentation and summarization , and evolution graph construction . Generally, the content of a topic is comprised of several simultaneous themes , each representing an episode of the topic [11]. The theme generation process tries to identify the themes of a topic from the related documents. Over the lifespan of a topic, the focus of the topic X  X  content may shift from one theme to another to reflect the topic X  X  development [11]. We define an event as a disjoint sub-episode of a theme. The event segmentation and summarization process extracts topic events and their summaries by analyzing the intension variation of themes over time. Semantically, events may be associated because they are temporally close or share similar contexts, e.g., they may refer to the same named entities. By connecting the associations, the c onstructed evolution graph reveals the storylines of the topic. In this paper, we present a topic anatomy system called TSCAN (Topic Summarization and Content ANatomy), which organizes and summarizes a temporal topic described by a set of documents. TSCAN models the documents of a topic as a symmetric block (which is a portion of a document) association matrix and treats each eigenvector of the matrix as a theme embedded in the topic. The eigenvectors are then examined to extract events and their summaries from each theme. Finally, a temporal similarity function is applied to generate the event dependencies, which are used to c onstruct the evolution graph of the topic. The results of experiments on the official TDT4 corpus demonstrate that the evolution graph construction process successfully extracts the themes, events, and event dependencies of the examined topics. Furthermore, compared to other text summarization methods, our summari es are highly representative and compare well with human composed summaries. Text summarization automatically creates a condensed version of one or more documents that capture s the gist of the documents. In this study, we focus on extraction-based generic text summarization [6]. As a document X  X  content ma y contain many themes, generic summarization methods concentr ate on extending the summary X  X  diversity to provide wide coverage of the content [7]. Gong and Liu [7] applied Singular Value Decomposition (SVD) [16] to the term-sentence association matrix of a document for extraction-based generic summarization. The authors regard the decomposed singular vectors as the themes of the document and compose diverse summaries by selecting informative sentences from important themes. Nomoto and Matsumoto [14] proposed the X -means algorithm, which groups the senten ces of a document into theme coherent clusters. The algorithm is a variation of the standard K -means algorithm that estimates the number of clusters, i.e., K , dynamically during the clustering process. For each cluster, the sentence with the most information is selected as the summary. In recent years, graph-based summari zation methods have generated a great deal of interest [6][20]. Fo r example, Zha [20] modeled the relationship between sentences and terms of a document as a bipartite graph. The model considers a sentence informative if it connects with many informative te rms, and vice versa. Zha proposes a reinforcement procedure that update s the informative scores of the terms and sentences iteratively. Finally, summaries are composed by selecting informative sentences . Erkan and Radev [6] represented a set of documents as a graph in which the nodes stand for sentences and content-similar sentences are associated with edges. The assumption is that a sentence is informative if it connects with many sentences; hence, by extension, the connected sentences are also informative. By deriving the informative scores of sentences from their connected sentences iteratively, the most informative sentence can be taken as the summary. Topic summarization differs from traditional text summarization because of its temporal properties. As topics are reported chronologically, comprehensive t opic summaries should describe the evolution (i.e., storylines) of the topics in addition to possessing informative sentences. Kleinberg [9] developed the techni que of topic evolution mining by constructing a hierarchical tree on a series of topic documents. He utilized a HMM-based two-state transition diagram to model the status of topics and suggested that a topic can be split into diverse themes, modeled as tree branches, whenever it receives bursty information. Nallapati et al. [12] formalized the problem of topic evolution mining as a text clustering task in which the identified clusters, i.e., the events of a topi c, are connected chronologically to form an evolution graph of the topic. In addition to graph construction, Mei and Zhai [11] modeled the activeness trend of identified themes. As the trend reveal s variations in the activeness of a theme over the lifespan of a topic, it helps users catch the rise and fall of the topic X  X  development. Yang and Shi [18] focused on the temporal properties of a topic, and showed that fine-grained evolution graphs can be obtained by using the temporal information about topics. A topic is a real world incident that consists of one or more themes, which are related to a finer incident, a description, or a dialogue of a certain issue. During the lifespan of a topic, one theme may attract more attention than the others, and is thus reported by more documents. We define an event as a significant theme development that continues for a period of tim e. Although the events of a theme are temporally disjoint, they are considered semantically dependent to express the development of the theme. Moreover, events in different themes may be associated due to their temporal closeness and context similarity. Naturally, all the events taken together form the storylines of the topic. Th e proposed method identifies themes and events from the topic documents, and connects associated events to form the topic evolution graph. In addition, the identified events are summarized to help readers better comprehend the storylines of the topic. Figure 1 illustrates the relationship between the themes, events, and event dependencies of a topic. A topic is explicitly represented by a collection of chronologically ordered documents. In this study, we assume that the documents are published in the same order as the reported events of the topic, and that there is no inconsistency be tween the contents of documents. Each document in TSCAN is deco mposed into a sequence of non-overlapping blocks . A block can be several consecutive sentences, or one or more paragraphs . We define a block as w consecutive sentences. Let T ={ t 1 , t 2 , ..., t m } be the set of stemmed vocabulary [4] without stopwords [4] of the topic. The topic can then be described by an m x n term-block association matrix B in which the columns { b , b 2 , ..., b n } represent the blocks ch ronologically decomposed from the topic documents. In other words, for any two blocks b b , if i &lt; j , then either the document containing b before the document containing b j , or b i appears before b same document. The ( i , j )-entry of B (denoted as b i,j term i in block j , computed by using th e well-known TF-IDF term weighting scheme [4]. The matrix A = B T B , called a block association matrix , is an n x n symmetric matrix in which the ( i , j )-entry (denoted as a product of columns i and j of the matrix B . As a column of B is the term vector of a block, A represents the inter-block association. Hence, entries with a large value imply a high correlation between the corresponding pair of blocks. A th eme of a topic is regarded as an aggregated semantic profile of a collection of blocks, and can be represented as a vector v of dimension n , where each entry denotes the degree of correlation of a block to the theme. Given a constitution of a vector v , v T Av computes the association of the theme to the topic X  X  content. The objective function shown in Eq. (1) of our theme generation process determines v  X  X  entry values so that the acquired theme is closely associated with the topic. max v T Av . (1) s.t. v T v = 1. (2) Without specifying any constraint on v , the objective function (1) becomes arbitrarily large w ith large entry values of v . Constraint (2) limits the search space within the se t of normalized vectors such that the following Lagrangian formula [17] can be used to solve Eqs. (1) and (2). To obtain the entry values of v , let  X  Z /  X  v =  X  Z /  X  X  = 0 as follows:  X  Z /  X  v = 2 Av  X  2  X  v = 0. (4)  X  Z /  X  X  = 1 -v T v = 0. (5) Eq. (4) implies that Av =  X  v . In other words, v is a normalized eigenvector of A and  X  is the corresponding eigenvalue. For any n x n square matrix, there can be at most n eigenvectors [16]. In terms of non-linear programming, Eq. (3) can ha ve more than one stationary point [17]. To acquire appropriate themes of the topic, the following theorem of symmetric matrices is employed. Theorem 1. For any nxn symmetric matrix A of rank r, there exists a diagonal matrix D and an orthonormal basis V for R A=VDV -1 , where V={v 1 ,v 2 ,...,v n } consists of the eigenvectors of A; and the diagonal entries of D satisfy d 1,1  X  d 2,2  X  ...  X  d =...= d n,n =0, which are eigenvalues corresponding to the respective columns of V.
 The proof of the theorem can be found in the section on diagonalization of symmetric matri ces of many linear algebra books [16]. Since V is an orthonormal basis of R n , its inverse is identical to represented as follows: A = VDV -1 = VDV T = [ v 1 ,..., v n ][ d 1,1 e 1 ,... d r,r e r , 0 e r+1 ,...,0 e = [ d 1,1 v 1 ,... d r,r v r , 0 v r+1 ,...,0 v n ][ v 1 ,..., v = d where e i denotes the standard vectors of R n [16]. In other words, the symmetric matrix A can be decomposed into the sum of n matrices eigenvectors of A as the themes of the topic. Then, the inter-block association approximated by the selected themes can be represented as follows: = [ v 1 , v 2 , ..., v L ][ d 1,1 e 1 ,..., d L,L e L ][ v = V L D L V L T , (7) where V L , called theme matrix , is an n x L matrix in which a column block association of a topic can be approximated by selecting a certain number of themes with significant eigenvalues. Note that, as the eigenvectors of A are orthogonal to each other, the produced themes tend to be unique and descriptive. A theme v j in V L is a normalized eigenvector of dimension n , where theme j . As topic blocks are indexed chronologically, a sequence of entries in v j with high values can be considered as a noteworthy event embedded in the theme, and valleys (i.e., a sequence of small values) in the entry sequence may be event boundaries. However, according to the definition of eigenvectors [16], the sign of entries in an eigenvector is invertible. Moreover, [8] shows that both the positive and negative entries of an eigenvector exhibit meaningful semantics for describing a certain concept embedded in a document corpus. Therefore, we adopt th e R-S endpoint detection algorithm [15], which examines the varia tion in the amplitude of an eigenvector, for event segmentation. Endpoint detection and event segmentation are similar in that they both try to find separation points between major segments of sequential data. To segment events, the endpoint detection al gorithm examines the amplitude variation of an eigenvector to find the endpoints that partition the theme into a set of significant events. In the R-S algorithm, every block in an eigenvector has an en ergy value, which is defined as follows: where eng ( i , j ) is the energy of a block i in a theme j , and H specifies the length of a sliding window us ed to smooth and aggregate the energy of a block with that of its neighborhood. Figure 2 shows the eigenvector of a theme and its energy contour. A peak in the energy contour (e.g., from indexes 150 to 163) indicates that the corresponding sequence of blocks is a significant development of the theme; therefore, it is identified as an event. To segment events from energy cont ours, we define a segmentation threshold as follows: thd where C is in the range [0,1], which is set as 0.2 in this study. Then, we linearly scan the energy contours for consecutive blocks whose energy values are above the thres hold. To reduce false alarms about event segmentation and refine the segmentation result, we adopt the two frequently used heuristics: 1) two close events are merged, and 2) small events are eliminated [ 15]. For each event, the block with the largest amplitude is selected as the event summary. Note that the summary block might not be the one with the largest energy value due to the averaging effect of the sliding window. Another interesting by-product of the above method is that the produced energy contour also describes the activeness trend of a theme. In the experiment section, we demonstrate that the changes in energy contours accurately reflect the evolution of a theme. A unique feature of our summarization approach is the introduction of the event segmentation process to extract the semantic construct  X  X vent X  before summari zation. Most existing generic summarization approaches [6][7][14][20] try to cover diverse themes in document summaries, but our method further describes the development of themes via summarized events to help users comprehend the storylines of a topic. An evolution graph connects themes and events to present the storylines of a topic. Let X ={ e 1 , e 2 , ..., e x } be the set of events in a topic. For each event e k , let e k .ev  X  [1, L ] denote the theme index of the event, and &lt; e k .bb , e k .eb &gt; be the event X  X  timestamp, where e and e k .eb are the indexes of the beginning and ending blocks, respectively; | e k |=1+ e k .eb  X  e k .bb is the temporal length of e topic evolution graph G = ( X , E ) is a directed acyclic graph, where X edges. An edge ( e i , e j ) specifies that event j is a consequent event of event i , which satisfies the constraint e j .bb &gt; e Automatic induction of event depe ndency is often difficult due to the lack of sufficient domain knowledge and effective knowledge induction mechanisms [12]. However, previous works [11][12] [18] have shown that, instead of domai n knowledge, word usage analysis can identify event dependency. Our approach follows this rationale and involves two procedures. Firs t, we sequentially link events segmented from the same theme to reflect the theme X  X  development. Then we use a temporal similarity function to capture the dependency of events from diffe rent themes. For two events, e e , belonging to different themes, where e j .bb &gt; e their temporal similarity ( TS ) by Eq. (10): TS ( e i , e j ) = TW ( e i , e j ) * cosine ( e i .cv , e where the cosine function returns the cosine similarity [4] between the centroid vectors of the events. The centroid vector, e event e k is defined as follows: . cv e (11) where b i is the term vector of block i . In short, e term vectors of the event blocks in accordance with their correlation to the event. The temporal weight ( TW ) function, defined in Eq. (12), then weights the cosine similarity based on the temporal difference between the events. If the temporal similarity is above a pre-defined threshold, we deem e j a consequence of e i and construct a link between them. The range of the proposed TW function is within (0,1]. As shown in Figure 3, TW considers the temporal re lationship between events e and e j and gives an appropriate tempor al weighting. In case 1 where e and e j do not overlap, TW penalizes the events with a large temporal distance. The penalty corresponds to Yang X  X  observation [19] that temporally close pieces of information are usually more relevant to one another than those far apart. In case 2, e i and e j do overlap and e contained in e i . TW penalizes events if their beginning timestamps are close to each other. This pena lty is based on the supposition that when two events happen almost simultaneously, they are probably the distractions of a certain prior event, rather than being dependent on one another. For instance, the outcome of a baseball tournament may give rise to concurrent events of celebrations and player trades. the increase in | e j |. This property, similar to case 2, prevents linking events with similar timestamps because they may be distractions of a prior event. In this section, we evaluate the performance of TSCAN. Traditionally, performance evaluations in information retrieval depend on annotated benchmarks. Ho wever, to the best of our knowledge, there are no official benchmarks and metrics for the study of topic anatomy. Therefore, in this section, we compare the performance of several summariza tion methods, as it is a common practice in summarization evaluation, and evaluate the topic evolution graphs generated by TS CAN to demonstrate the model X  X  capability. The experiments employed the official TDT4 corpus [1] where 26 news topics, each containing more than 20 documents, were selected for performance evaluations. The topics were labeled by NIST annotators and their elabor ate explications are regarded as reference summaries for summari zation evaluations. Although DUC (Document Understanding Conferences ) [2] also use TDT topics for summarization contests, the average size of the DUC topics is only 10 documents, which is too small to demonstrate the effect of the proposed method. In the pre-processing phase each topic document is partitioned into blocks of sentences by using a si mple script supplied by DUC. To reduce the impact of sentence partition errors, each block has 3 sentences to ensure that it contains a complete sentence. The parameter L is critical to the quality of detected themes. From Eq. (6), it is clear that the larger the number of themes selected, the better the approximation will be. For summarization comparisons, the evaluations are performed with L =1 to 10 to show the influence of themes on summarization performan ce. In addition, the parameter H and the temporal similarity threshold are set to 7 and 0.3, respectively. We compare the summarization performance of TSCAN with the following four summarization met hods: 1) The forward method, which generates summaries by extracting the initial blocks of a topic. 2) The backward method, which extracts summaries from the end blocks of a topic. This is frequen tly used as the baseline method in DUC contests [13]. 3) The SVD method [7], which composes summaries by extracting the blocks with the largest entry value in singular vectors. Note that the result of the SVD method is identical to that of the graph-based summarization method [6]. 4) The K -means method [14], which composes summaries by selecting the most salient blocks of the resulting K clusters. Generally, the performance of the K -means method depends on the quality of the initial clusters. In this experiment, to give the K -means method fair consideration, the best result from fifty randomly selected initial clusters is used for comparison. The summarization evaluation procedure is as follows. For each L , we first apply TSCAN to each topic to extract a set of blocks as the topic summary. To ensure that the comparison with the other methods is fair, we use the comp ared methods X  algorithms, and then produce summaries of the same size (in terms of the number of blocks) as those generated by TSCAN. The compression ratios for summaries of L produced by the compared methods are shown in Table 1. In sum, the compression ratios of the evaluated summaries are high and at least 90% of the topic X  X  contents are omitted. We use two metrics, summary-to-document content similarity (SDCS) and ROUGE [10], to ev aluate the above summarization methods. The SDCS metric compares the content coverage of a generated summary to the docum ents for summarization, while ROUGE considers the consistenc y between the content of a generated summary and that of a set of expert-composed reference summaries. Summary-to-document content similarity is defined as the average cosine similarity between an evaluated summary and topic documents, both of which are repres ented by TF-IDF term vectors. A high similarity score implies that the summary is representative of the topic and can effectively replace the original topic documents for various information retrieval tasks. Table 2 shows the micro average summary-to-document content similarity derived by the compared methods. Table 2. Micro average summary-to-document content similarity.
 As shown in Table 2, our method outperforms the compared methods, except the K -means method with large L values. The latter achieves a higher similarity score because its summary provides better coverage of the topic X  X  c ontents. Our method simply selects L most significant themes ( L &lt;&lt; r ) to represent a topic, whereas the K -means method partitions the all of the topic X  X  content into K clusters and extracts the most salient block from each cluster to represent the topic. As a result, summaries constructed by the K -means method provide better content coverage, and the similarity score increases as more clusters are used to partition the content. However, without an effective mechanism, such as the st ructure of themes and events, to leverage and organize the summarized results, large K values indicate that the summaries are unstructured, and therefore difficult for users to understand. Both the proposed method and the SVD method perform in between. Our method outperforms the SVD method, especially when the compression ratio is high. This is because our summary favors significant themes and events, which are representative of topic docum ents. The coverage provided by forward and backward methods is poor because their summaries only cover the beginning and end of topic documents, respectively. To improve their performance, lower compression ratios are required so that more topic information can be included in the summaries. ROUGE is a recall-oriented summary evaluation metric used mostly in DUC contests [13]. It measures summarization performance by calculating the number of overlapping n-grams between an evaluated summary and a set of reference summaries. ROUGE scores 1 when the evaluated su mmary is consistent with the reference summaries; and 0 when the evaluated summary is off topic. It has been shown that the results of the comparisons based on ROUGE-1 (unigram overlapping) and ROUGE-2 (bi-gram overlapping) are consistent with manual judgments [10]. Therefore, we use ROUGE-1 and ROUGE-2 to evaluate the consistency of manual summaries derived by the compared methods. Tables 3 and 4 show the micro average performances of ROUGE-1 and ROUGE-2, respectively. As ROUGE is a recall-oriented eval uation metric, the scores of all the compared methods increas e with the increases in L . In [13] the backward method is regarded as effective because its ROUGE performances have proved comparable to those of many elaborate summarization methods in a number of contests. However, in our evaluations, the backward method is inferior to the simple forward method. This is because the first few sentences of a news article usually detail the essential part of the story. Thus, the forward method is more effective and, in f act, it is nearly comparable to the sophisticated SVD method. The re sults show that the proposed method achieves the best ROUGE-1 and ROUGE-2 scores for all L . Moreover, the improvement it achie ves over the compared methods increases as the compression ratio increases (i.e., a decrease in L ). For example, when L =1, our method outperforms the compared methods by 27.3% to 62.6% for ROUGE-1 and by 41.7% to 125% for ROUGE-2. This is because our method selects representative sentences earlier than the compared methods when composing topic summaries. In resource-limited envi ronments, such as low network bandwidth or the small display pa nels of hand-held devices, this property helps users capture key information about a topic. The superior ROUGE performance of TSCAN is related to the manner of summary composition. The K -means method and the SVD method increase summary coverage by using clusters and singular vectors, respectively, whereas our method distinguishes between important events in themes to achieve both summary diversity and narrative tracing properties. The re sults of TSCAN are consistent with topic annotators X  reference summaries, which generally explain the major events of significant themes. As a result, TSCAN outperforms the compared methods in terms of the ROUGE evaluation metric. Two TDT4 topics, #40023  X  X resident Bush Bans Abortion Funding X  and #40004  X  X ussian Nuclear Submarine Kursk Sinks X  are selected as case studies of topic evolution graphs because their stories are well known and readers can understand them without specific knowledge or information about the cultural background. The topic  X  X resident Bush Bans Abortion Funding X  relates to the president X  X  decision on abortion in January, 2001. The topic contains 25 documents and 253 blocks. Figure 4 shows the constructed topic evolution graph, which consists of 5 themes (i.e., L =5), 13 identified events, and 14 edges. Each row of the graph shows the events of a theme. For each event, we show the indexes of its beginning, ending, and summary blocks as a trinary tuple. According to the summaries, Theme 1 relates to President Bush X  X  attitude toward abortion. Theme 2 represents the opinions of conservative groups on abortion. Theme 3 discusses the case of  X  X oe versus Wade, X  which led th e United States Supreme Court to legalize abortion in 1973. Theme 4 describes the interaction between President Bush and his cabinet. Finally, Theme 5 considers the impact of banning funding for abortion on medical research. Basically, these themes not only cover the storylines of the topic, but also include many interesting items of side information. For example, as the topic X  X  time period was just the president X  X  first week in office, the topic documents also include the interactions between him and the new cabinet. Surprisingly, the interactions were included in Theme 4. Furthermore, Theme 3 deals with the anniversary of the Supreme Cour t X  X  decision on Roe versus Wade, which was on the president X  X  first day in office. On the generated evolution graph and in the summaries, the topic was initiated by event e 8 when president-elect Bush revealed during a media interview that he might reverse some of President Clinton X  X  orders. Then, in event e 1 , President Bush announced that he would issue an executive order banning funding for abortion. Soon afterwards, in event e 2 , he signed a memorandum about blocking the the topic-related documents also mentioned his goals, and his interaction with the new cabinet. These incidents were extracted by events e 9 and e 10 . Coincidentally, the first day in office was also the anniversary of the Roe versus Wa de decision, which was identified by event e 7 and the opinions of pro-life groups were the focus in event e 5 . Next, in event e 4 Bush declared that support for stem cell research should be cut off because stem cells are taken from aborted fetuses. This declaration immediately attracted comments from conservative groups ( e 6 ) and medical researchers ( e reaffirmed that the government w ould not support research related to aborted fetuses ( e 11 ). Finally, in event e 12 , the media commented on the president X  X  first week in office, including his decision to ban abortion. They also mentioned th e difficulties and challenges that the president and his cabinet would face during his presidency. The energy contours shown in Figure 5 also reflect the trends of the themes. The contours of Themes 1 and 4 have several peaks distributed uniformly over the time period of the topic. Since  X  X ush X  X  attitude toward abortion X  and  X  X he interaction between Bush and his cabinet X  are the main themes of the topic, nearly all the topic X  X  documents are associated with a particular context. As a result, their energy distributi ons are uniform. Additionally, the peaks of Themes 3 and 5, which correspond to the time phases of the Roe versus Wade annivers ary and the debate on medical research, respectively, demonstrate that the energy contours of eigenvectors can describe the trends of themes. Finally, we examine the quality of links in the evolution graph. Generally, the links of events of the same theme state the storyline of the theme well. For example, the links of Theme 1 sequence the different phases of President Bush  X  X  attitude toward abortion from probability to certainty. Moreover, the links of different themes also explain the associations between events successfully. We label these kinds of links according to their ranking in terms of the TS values. As the criterion of link construction is based on the content similarity discounted with a (0,1] temporal weight, the linked events always have similar contexts and thus exhibit meaningful associations. For example, the set of links {1, 2, 3, 5, 6} clearly states that Bush X  X  decision in event e 4 caused disagreements between researchers ( e 13 ) and conservative groups ( e forced him to reaffirm his determination in e 11 . The style of links also demonstrates the utility of the proposed temporal weight function. As mentioned earlier, the temporal weight function prevents linking events that are separated by large temporal distances. Thus, the resulting evolution graph rarely has interlaced large-distance links, which makes the graph concise and traceable. Moreover, the function also disti nguishes parallel events, such as e and e 7 , both of which have similar cont ent with regard to Roe versus Wade, but neither one draws out the other. In sum, the proposed method successfully extracts meaningful events and summary sentences, and organizes their depe ndencies well so that users can easily comprehend the storylines of the topic. The second example is based on TDT4 40004  X  X ussian Nuclear Submarine Kursk Sinks X  which re ported the recovery of bodies from the sunken Russian submarine Kursk in October 2000. The topic is larger than the first exam ple and consists of 329 blocks in 56 related documents. Figures 6 and 7 show the constructed evolution graph and energy contours, respectively. According to the summaries, Theme 1 relates to the progress of body recovery. Theme 2 describes how rescue divers salvaged the sunken submarine. Theme 3 discu sses when and how the sailors died. Theme 4 is related to legislation that prevented Russians from using words from foreign languages when speaking Russian. Finally, Theme 5 discusses the causes of the explosion and sinking of the submarine. In fact, Theme 4 ha s nothing to do with the topic. However, the documents of Theme 4 mentioned that Russian President Vladimir Putin was the target of the legislative bill because he used inappropriate foreign words when speaking to the families of the sailors killed in the submarine disaster. This is probably the reason that TDT annot ators included the documents in the topic. Nevertheless, it is interesting to note that the proposed method can detect this incident and treats it as an isolated event (i.e., e ) in the evolution graph. Once again, the generated evolu tion graph and summaries explain the storylines of the topic clearly. According to the graph, the topic was initiated by a joint exercise of submarine rescue held in the South China Sea ( e 7 ). That exercise received a lot of attention because of the Russian submarine disaster and the fact that the Russian government was planning to launch a rescue operation a few days later. Then in events e 1 and e 8 , divers began cutting holes in the Kursk to recover bodies and start the salvage process. In the meantime, the Russian government tr ied to determine the cause of were killed instantly when the submarine sank ( e 12 ). In event e divers first found three bodies of the 118 sailors. Immediately sailor Kolesnikov who left a note indicating that at least 23 sailors survived for several hours after the explosion ( e 4 , e note led to a great deal of public criticism about the government X  X  slow reaction to the disaster and subsequent rescue operation. Even though officials still insisted that the sinking was caused by a collision with another submarine ( e 17 ), the note forced the officials to investigate other possibilities ( e 19 ). Meanwhile, the divers continued cutting holes in different compartments of the wreck to search for bodies ( e 5 , e 6 , e 9 , e 10 , and e 11 officials re-affirmed their determination to find the cause of the sinking and held a memorial service ( e 20 and e 21 ), even though they still speculated that it was caused by a collision with a NATO submarine ( e 22 ). As shown in Figure 7, the energy c ontours of Themes 1, 2, and 5 are distributed cyclically, as the events of the themes  X  X earch for bodies X ,  X  X ubmarine salvage X , and  X  X inking cause investigation X  were mentioned frequently throughout the topic. The energy peaks also indicate the important events of the topic. For example, the discovery of the note from the dying sailor is caught by the peak of e in Theme 3. In addition, the peaks of e 21 and e the holding of the sailors X  funerals and the drafting of the legislation, respectively. The links between events again describe the storylines of the topic well. For example, th e links of Theme 5 highlight the phases of the investigation into the disaster. They sequence the theme by first mentioning that ther e could be a number causes of the sinking, e.g., a collision with a fo reign submarine or ship, or a collision with a World War II mine . Then, the subsequent events indicate that a collision was the major cause. It is interesting to note the note discovery, rather than the investigation of the disaster. However, as the discovery of the note also raised hopes about learning the cause of the sinking, the investigation-related documents at that point mentione d the note many times. Thus, the theme generation process treated the note and the investigation as a single theme embedded in the inter-b lock association. The proposed TS function also extracts meaningf ul dependencies between events of different themes. For example, th e set of edges {2, 3, 4, 5, 6, 7} effectively illustrates the associations between body recovery, submarine salvage, and the investigation. Again, the TS function does not allow events separated by large temporal distances to be linked, so the resulting graph is concise and comprehensible. The case studies show that the evolu tion graph and summaries can help users understand the storylines of topics quickly. Topic anatomy has become an in creasingly important application because of the need to grasp the gist of information contained in a large number of topic documents. Most existing summarization works try to increase the diversity of the summary to cover all the important information in the summarized documents. However, when the documents to be summarized are related to an evolutionary topic, summarization methods should also consider the temporal properties of the topic in order to describe the development of storylines. In this paper, we have presented a topic anatomy system called TSCAN, which extracts themes, events, and event summaries from topic documents. Moreover, the summarized events are associated by their semantic and temporal relationships, and presented graphically to form the topic X  X  evolution graph. Experiments based on the TDT4 corpus show that TSCAN can produce highly representative summaries that correspond well to reference summaries composed by experts. In addition, case studies show that the constructed evolution graphs accurately depict the storylines of the topics to help readers comprehend the topic quickly. We assume that the documents are published in real-time and there is no inconsistency among the documents. The assumptions substantially reduce the difficulty of the topic evolution graph construction and summarizati on processes. Although the assumptions generally hold for news documents because they are written in a serious and accurate manner, it may be difficult to apply the proposed method to other uncons trained texts, such as blogs. Removing the constraints is an in teresting and challenging research issue that merits further investigation. This work was supported in part by NSC 96-2218-E-002-040 and NSC 96-3113-H-001-012. [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] http://www-nlpir.nist.gov/ projects/duc/index.html [3] Allan, J., Carbonell, J., Doddington, G., Yamron, J., and Yang, Y. 1998. [4] Baeza-Yates, R. and Ribeiro-Neto , B. 1999. Modern information [5] Chen, C. C., Chen, M. C., and Chen, M. S. 2005 LIPED: HMM-based [6] Erkan, G. and Radev, D.R. 2004. Le xRank: graph-based centrality as [7] Gong, Y. and Liu, X. 2001. Generic text summarization using relevance [8] Kleinberg, J. 1999. Authoritative sources in a hyperlinked environment. [9] Kleinberg, J. 2002. Bursty and hierarchical structure in streams. In [10] Lin, C.Y. and Hovy, E. 2003. Automatic evaluation of summaries using [11] Mei, Q. and Zhai, C.X. 2005. Discovering evolutionary theme patterns [12] Nallapati, R., Feng, A., Peng, F., a nd Allan, J. 2004. Event threading [13] Nenkova, A. 2005. Automatic text summarization of newswire: lessons [14] Nomoto, T. and Matsumoto, Y. 2001. A new approach to unsupervised [15] Rabiner, L.R. and Sambur, M.R. 1975. An algorithm for determining [16] Spence, L.E., Insel, A.J., and Friedbe rg, S.H. 2000. Elementary linear [17] Winston, W.L. 2004. Operati ons research. Thomson. [18] Yang, C.C. and Shi, X. 2006. Discove ring event evolution graphs from [19] Yang, Y., Pierce, T., and Carbonell, J. 1998. A study on retrospective [20] Zha, H. 2002. Generic summarization and keyphrase extraction using 
