 A query considered in isolation provides limited information about the searcher X  X  interest. Previous work has considered various types of user behavior, e.g., clicks and dwell time, to obtain a better un-derstanding of the user X  X  intent. We consider the searcher X  X  search and page view history. Using search logs from a commercial search engine, we (i) investigate the impact of features derived from user behavior on reranking a generic ranked list; (ii) optimally inte-grate the contributions of user behavior and candidate documents by learning their relative importance per query based on similar users. We use dwell time on clicked URLs when estimating the rel-evance of documents for a query, and perform Bayesian Probabilis-tic Matrix Factorization as smoothing to predict the relevance. Con-sidering user behavior achieves better rankings than non-personal-ized rankings. Aggregation of user behavior and query-document features with a user-dependent adaptive weight outperforms com-binations with a fixed uniform value.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Personalization; user behavior; document re-ranking
There is a growing interest in personalized search in order to better account for a searcher X  X  individual information need. This kind of personalization improves retrieval performance by tailor-ing, or re-ranking , the ranked results provided by a generic ranker for an individual user based on the models of her previous or cur-rent interests. Teevan et al. [7] find that retrieval performance can be improved as more data becomes available about the searcher X  X  interests. And White et al. [11] investigates the effectiveness of a task-based approach in predicting the searcher X  X  interests. They explore the value of modeling current task behavior, finding a sig-nificant opportunity in leveraging the on-task behavior to identify web pages to promote in the current ranking. They also explore the use of the on-task behaviors of particular user groups who are experts in the topic currently being searched, rather than all other users, yielding a promising gain in retrieval performance. Other re-cent work focuses on the role of domain expertise [3] and the use of long-term behaviors for personalized web search by modeling search interests from previous queries [9].

Understanding searchers X  information needs requires a thorough understanding of their interests expressed explicitly through search queries, implicitly through clicks on the search engine result page (SERP) or through post-SERP browsing behavior such as dwell time. When sufficient data of a given user is unavailable, the search behavior of other users may be beneficial. Teevan et al. [8] explores the similarity of queries and explicit relevance judgments across a small group. They find that some group members share documents that are relevant to a query because of a shared group focus, but that it is difficult to identify implicitly defined valuable groups.
We address the following personalized web document re-ranking task: re-rank the URLs of a SERP returned by the search engine according to the personal preferences of the users. That is, we aim to personalize search using the long-term (user history based) and short-term (session-based) user context. We use Bayesian Proba-bilistic Matrix Factorization (BPMF) to estimate the relevance of a URL for a query and to estimate the user X  X  preference for a URL. We begin with a probabilistic graphical model to model the rela-tionship between the searcher, the issued query and the document to be re-ranked. Then we estimate the probability through Bayesian networks using the aggregated dwell time and automatically assign a probability to each query-document and user-document pair us-ing BPMF. We combine users X  short-and long-term behaviors in a linear fashion, and adaptively aggregate user and document infor-mation depending on similar users.

We demonstrate the effectiveness of our approach to personal-ized document re-ranking based on a real world dataset that was made available as part of the Web Search Click Data workshop (at WSDM 2014). 1 We find that combining short-and long-term be-haviors of users achieves higher scoring rankings than non-personal-ized rankings and that aggregating user behavior and document fea-tures with a user-dependent adaptive weight outperforms combina-tions with a uniform fixed value.
The relationship between user , query and URLs (or documents ) to be re-ranked can be modeled by a graphical model as Fig. 1. The user submits a query, in response to which a list of 10 URLs are returned by a search engine. Our task is to re-rank the top 10 URLs. http://www . wsdm-conference . org/2014/ accepted-workshops/ . Figure 1: Probabilistic graphical model ( U : user, Q : query and D : document) We measure the relevance of a URL ( d ) to a query ( q ) submitted by a user ( u ) as a probability P ( d | q,u ) and use this probability as the final ranking score to output a ranking list of the top 10 URLs.
From Fig. 1, we calculate the joint probability p ( u,q,d ) : The relevance of d given q and u , p ( d | q,u ) , is To estimate p ( q,u | d ) , we use a linear mixture governed by a free parameter  X  : p ( q,u | d ) = (1  X   X  )  X  p ( q | d ) +  X   X  p ( u | d ) [4].
In the simplest case, p ( u ) and p ( d ) are assumed to be uniform, and hence, do not affect the document ranking, so that p ( d | q,u ) can be estimated by where p ( q | d ) = Q t because p ( u ) and p ( d ) are uniform.

As our task is to re-rank the top 10 documents, the contribution to each document from p ( q | u ) remains the same and will not change the ranking. Hence, we have: p ( d | q,u )  X  (1  X   X  )  X  Q t We estimate p ( d | u ) from the short-and long-term behaviors of the user u . Again, we use a linear combination p ( d | u ) = (1  X   X  )  X  achieve the final outcome. Therefore, our final re-ranking criteria is (5): The way in (5) we estimate p ( d | u ) short and p ( d | u ) in  X 2.2.
Many smoothing methods have been proposed in the setting of language models for IR. For our re-ranking task, it makes sense to use dwell time rather than term frequency for smoothing because the contents of query and document are unavailable.

We use Bayesian Probabilistic Matrix Factorization (BPMF) [5] to predict the relevance of a document for a query as well as the preference of a user for a document. Taking the former, for ex-ample, we first take the logarithm of the aggregated dwell time of known query-document pairs to dampen sharp peaks and then label the relevance of each pair as min( b lg( t + 10) c , 5) , where t is the aggregated dwell time, and b X c is the floor function. BPMF is then applied to the query-document matrix to assign a non-zero value to each element in the matrix. This completes our smoothing method. The original matrix query-document matrix is replaced by: where Q N  X  k and D M  X  k represent the query-and user-specific latent feature matrix, where N , M and k indicate the number of queries, documents and latent features, respectively.

The distribution of the values R  X  ij for query i and document j is computed by marginalizing over the model parameters and the hyperparameters: p ( R  X  ij | R,  X  0 ) = where  X  Q = {  X  Q ,  X  Q } and  X  D = {  X  D ,  X  D } are query and doc-ument hyperparameters, and the prior distributions over the query and document feature vectors are assumed to be Gaussian, and  X  0 = {  X  0 ,  X  0 ,W 0 } is a Wishart distribution hyperparameter with  X  0  X   X  0 scale matrix W 0 . BPMF introduces priors for the hyper-parameters, which allows the model complexity to be controlled based on the training data [6]. When the prior is Gaussian, the hy-perparameters can be updated by performing a single EM step [2], which scales linearly with the number of observations without sig-nificantly affecting the time to train the model.
For our task of re-reranking the top 10 URLs returned by the search engine, short-term behaviors, more specifically the clicks, may provide a strong signal of the user X  X  interest. We aggregate the contributions of all clicked URLs to compute the term p ( d | u ) mentioned before as: where D is the set of clicked URLs inside the current search ses-sion, and depends on the similarity between the clicked document d i document d to be re-ranked, while is a normalization factor. Further, D \{ d i } denotes the subset of D except d i and Dis ( d j ,d ) returns the Euclidean distance between d and d . Both documents are represented by the latent feature vectors returned by the BPMF process.

For the long-term behaviors of the user, we estimate the proba-bility p ( d | u ) long by accumulating all his dwell time on d from the historical logs.
Previous work [10] uses a fixed weight  X  in (5), i.e., the same for all users, when integrating the contributions from the user and a specific document. This choice shows good re-ranking results. However, we treat the weight differently as different users behave differently. We propose an adaptive weight solution to assign a specific weight  X  in (5) per user u , which depends on users that are similar to u .
 We first cluster the users in the training set using the k -Nearest Neighbors algorithm (KNN), and the users have been assigned the optimal  X  using a sweep from 0 to 1 with step-size 0 . 1 while maxi-mizing MAP. We set the number of clusters to k = 10 as our result performs the best with this setting. In the test phase, an unseen user u is assigned to the nearest cluster C and allocated a weight  X  as: where depends on the similarity between the user i in cluster C and the test user u while is a normalization factor, and  X  i is the weight for user users are represented by latent feature vectors returned by the BPMF.
We begin by describing the research questions that we aim to an-swer. We then report the results of experiments aimed at answering the questions and present the findings of an analysis of the results.
We are particularly interested in the contributions of two types of information obtained from user logs for personalized re-ranking: short-and long-term behaviors. We train our model and evaluate it by re-ranking the top 10 results from a web search engine. This original ranking is used as one of our baselines for comparisons. We address the following two research questions: 1. Does the combination of short-and long-term behaviors help 2. What are the optimal relative contributions for document re-Answers to these questions provide valuable insights about the rela-tive utility of the historical logs and can help inform decisions about when and how to use the historical logs for search personalization.
The primary source of data for this study consists of anonymized logs of users provided by the Personalized Web Search Challenge. The logs, collected for four weeks, contain a unique user identi-fier, a search session identifier, a query identifier, the specific query term identifier, the top 10 URLs returned by the search engine for that query, and the dwell time on clicked results. The information of users with more than 6 participations during the specific span is kept. Besides, we remove user records without short-term be-havior. Finally, BPMF is performed on the whole dataset and, we randomly split the dataset into five partitions, such that 80% is used as training data and the remaining 20% is used as test data for the latter experiments. Table 1 shows some statistics of the training dataset. Each query is different from the others between sessions; the numbers of search sessions and unique queries are the same.
Relevance labels are obtained automatically based on the aggre-gated dwell time units, with a graded relevance scale. We assign a grade 5 (highly relevant) to documents with clicks whose loga-rithmic dwell time is at least 5 or with the last result click in the session. We assign a grade 4, 3 and 2 (relevant, normal relevant and slightly relevant, respectively) to documents with clicks with https://www . kaggle . com/c/yandex-personalized-web-search-challenge .
 a logarithmic dwell time between 5 and 2. We assign grade 1 (ir-relevant) to documents with no clicks or clicks whose logarithmic dwell time is less than 1.

For evaluation purposes, with a graded relevance scale, we re-port our performance with NDCG@5 plus NDCG@10 as well as p@5 and MAP. The metrics for all queries are averaged to obtain a final measure across the top 10 results retrieved before re-ranking (for one baseline) and after re-ranking. Statistical significance of observed differences between the performance of two runs is tested using a two-tailed paired t-test and is denoted using N / cant differences for  X  = . 01 , or M / O for  X  = . 05 .
We begin by investigating the influence of short-and long-term behavior using a fixed value  X  = 0 . 5 . It is clear from Table 2 that the performance shows very minor differences when the weight  X  in (5) changes; it reaches a peak for  X  = 0 . 3 . Consequently, we choose  X  = 0 . 3 in later experiments.

To verify the effectiveness of personalization, we test our model with 5 runs, representing five different splits of the available data in training and test set, and choose  X  = 0 . 5 for the experiment (personalization is active whenever  X  &gt; 0 ). For  X  = 0 . 5 , doc-ument and user-based scoring receive equal weights. We plot the improvements over two baselines in Fig. 2. One baseline ranking is simply the ranked list produced by the search engine and another is produced when  X  = 0 (non-personalization). We report the im-provements of each run and the average as well. Our proposed method for re-ranking outperforms the two baselines on all met-rics and the differences are statistically significant at significance level  X  = . 01 . We can see that user information can effectively be used to boost the ranking performance when historical behaviors are available. Another interesting observation from Fig. 2 is that the relative improvements over the  X  = 0 setting are smaller than those over simply choosing the results from the input ranker.
Finally, we take a closer look at the effect of the free parameter  X  in (5) that governs the relative contribution of searcher informa-tion and document information to the overall performance of our re-ranker. We report our results by averaging the outcomes of 5 separate runs of adaptive  X  and each fixed weight in Table 3, respec-Table 3: Re-ranking performance for fixed values of  X  and an adaptive setting of  X  . Boldface marks the best result per col-umn; a statistically significant difference between the Adaptive  X  setting and the rankings produced with a fixed value of  X  or the baseline search engine (SE) ranking is marked. (Settings used:  X  = 0 . 3 .)
SE H .4451 H .2916 H .4017 H .5128  X  =0.1 H .4640 H .3081 H .4181 H .5462  X  =0.2 H .4648 H .3082 H .4184 H .5467  X  =0.3 H .4649 H .3082 H .4186 H .5467  X  =0.4 H .4649 H .3082 H .4189 H .5469  X  =0.5 H .4650 H .3082 H .4185 H .5469  X  =0.6 H .4658 O .3087 H .4203 H .5490  X  =0.7 H .4655 H .3084 H .4187 H .5475  X  =0.8 H .4656 O .3084 H .4189 H .5469  X  =0.9 H .4648 H .3082 H .4185 H .5465
Adaptive  X  .4976 .3160 .4463 .5698 tively. We also report the performance of the search engine (SE) as a baseline. A high value of  X  indicates that user information makes a big contribution to the overall performance. As shown in Table 3, the experiments with a big  X  ( &gt; 0 . 5 ) achieve better performance than those with a small  X  ( &lt; 0 . 5 ) except for  X  = 0 . 9 . The user components contributes more than the document itself under our personalized web search settings. With  X  adaptive, our model ef-fectively boosts ranking performance by improving 6.83%, 2.36%, 6.19%, and 3.79% for MAP, P@5, NDCG@5, and NDCG@10 re-spectively, over the best fixed value (  X  = 0 . 6 ). Additionally, it increases the MAP, P@5, NDCG@5, and NDCG@10 scores by 11.79%, 8.36%, 11.10%, and 11.12%, respectively, over the search engine ranking result. We conclude that adding user information and optimizing the weight  X  that controls the contribution of user information helps to improve the effectiveness of re-ranking.
Previous work on search personalization has exploited user be-haviors to model searcher interests. Relatively little was known about the relative contribution of document or user features for op-timal personalized re-ranking. In this paper we have investigated how the contributions of document and user can be combined. We have demonstrated that historic behavior yields benefits for person-alized re-ranking and that user information contributes more than the document itself for personalized re-ranking. This work makes an important step toward unifying prior work on personalization. Future work will further explore different features on how to best improve search performance through personalization.
 [1] P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, [2] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum [3] B. Huurnink, L. Hollink, W. van den Heuvel, and [4] O. Kurland and L. Lee. Corpus structure, language models, [5] R. Salakhutdinov and A. Mnih. Bayesian probabilistic [6] R. Salakhutdinov and A. Mnih. Probabilistic matrix [7] J. Teevan, S. T. Dumais, and E. Horvitz. Personalizing [8] J. Teevan, M. R. Morris, and S. Bush. Discovering and using [9] H. Wang, X. He, M.-W. Chang, Y. Song, R. W. White, and [10] R. W. White, P. N. Bennett, and S. T. Dumais. Predicting [11] R. W. White, W. Chu, A. Hassan, X. He, Y. Song, and
