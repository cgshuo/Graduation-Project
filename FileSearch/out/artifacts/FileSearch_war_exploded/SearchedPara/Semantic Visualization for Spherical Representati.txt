 Visualization of high-dimensional data such as text docu-ments is widely applicable. The traditional means is to find an appropriate embedding of the high-dimensional repre-sentation in a low-dimensional visualizable space. As topic modeling is a useful form of dimensionality reduction that preserves the semantics in documents, recent approaches aim for a visualization that is consistent with both the orig-inal word space, as well as the semantic topic space. In this paper, we address the semantic visualization problem. Given a corpus of documents, the objective is to simultane-ously learn the topic distributions as well as the visualization coordinates of documents. We propose to develop a semantic visualization model that approximates L 2  X  normalized data directly. The key is to associate each document with three representations: a coordinate in the visualization space, a multinomial distribution in the topic space, and a directional vector in a high-dimensional unit hypersphere in the word space. We join these representations in a unified generative model, and describe its parameter estimation through vari-ational inference. Comprehensive experiments on real-life text datasets show that the proposed method outperforms the existing baselines on objective evaluation metrics for vi-sualization quality and topic interpretability.
 H.4 [ Information Systems Applications ]: Miscellaneous; H.2.8 [ Database Applications ]: Data Mining semantic visualization; topic model; generative model; spher-ical space; spherical semantic embedding; dimensionality re-duction; L2-normalized vector;
Visualization is an important and widely applicable tool for exploratory analysis of high-dimensional data. There are various aspects to the study of visualization (e.g., inter-face, interactivity). Of special interest to data mining and machine learning is the dimensionality reduction aspect of visualization, i.e., finding a low-rank representation in two or three dimensions that preserves as much as possible the properties of the data. These low-rank representations are visualized on a scatterplot, a simple format to reveal the re-lationship structures among data points. The current state-of-the-art visualization approaches are formulated as finding coordinates whose distances in the visualization space  X  X e-flect X  the corresponding distances in the original space [12].
While a scatterplot is useful for identifying visualizable structures among data points, it has relatively limited ex-planatory power, because the reduced dimensions have no prescribed semantics. Another type of dimensionality reduc-tion that is focused more on interpretability is topic model-ing [17, 5], where the objective is to reduce each document X  X  original representation (e.g., word counts) into a probability distribution over Z (a user-defined quantity) topics. Each topic is associated with a distribution over words. Hence, the reduced dimensions (i.e., topics) have interpretable se-mantics, revealed by the most important words in each topic. However, topic model is not designed for visualization. In a 2D simplex, we can visualize topic distributions for only 3 topics, which is impractical, because Z is frequently much higher than that (though lower than the vocabulary size).
We are therefore interested in semantic visualization , de-fined as modeling visualization coordinates and topics in an integrated manner [19]. This integration has important benefits not available to either visualization or topic model on their own. On the one hand, it allows the infusion of the scatterplot visualization with topic modeling semantics. Each coordinate in the visualization space can now be as-sociated with both a topic distribution, as well as a list of the most important words. This complements structural ob-servations (e.g., clustering) with semantic explanations (the relevant topics and words). On the other hand, we envision that visualization may eventually serve as a user-friendly in-terface to explore and tune an underlying topic model, in a way that allows steering the topic model interactively.
In this paper, we propose a semantic visualization model for data with spherical representation . This refers to data whose instances can each be represented as a vector of unit length in a high-dimensional hypersphere [1], with dimen-sionality commensurate with the number of features. In other words, we are dealing with L 2 -normalized feature vec-tors as input. One important category of such data that we focus on in this work is text document. A document can be naturally represented as a normalized term vector, as done in the classical vector space model [32]. Stated more for-mally, the input to the problem is a corpus of documents D = { d 1 ,d 2 ,...,d N } , where every d n is represented by an L -normalized term vector  X  n . We seek to learn, for each d a probability distribution  X  n over Z topics ( semantic ), and a coordinate x n on a low-dimensional space ( visualization ). While we frame the discussion here in terms of documents and words, our technique is applicable to other data types for which both visualization and semantic interpretability are important, as long as they can be expressed in terms of spherical representation (i.e., L 2  X  normalized vectors).
Previous Approach. Jointly modeling topics and visu-alization coordinates is pioneered by PLSV [19] (reviewed briefly in Section 3). It is aimed at dyadic data , whereby every observation involves a couple ( d,w ) of word w  X  X  oc-currence in document d . The observations for a document can be summarized as an integer vector of word counts in
N | V | , where V is the vocabulary. Like its topic model-ing predecessors [17, 5], PLSV uses the word count vectors to maximize the likelihood of generating individual words based on the learned latent multinomial distribution over words { P( w | d n ) } w  X  V . Here, P( w | d n ) is obtained from top-ics X  word distribution P( w | z ) and document X  X  topic distri-bution P( z | d n ), i.e., P( w | d n ) = P Z z =1 P( w | z )P( z | d
The stated aim of most visualization approaches is to re-cover a low-dimensional manifold embedded within the high-dimensional space of the original data [22, 31, 16, 12]. Key to manifold learning is the capacity for approximating the similarities and differences among data instances [2]. In this respect, multinomial modeling of dyadic data has a couple of downsides [30]. For one thing, it primarily models word presences, but does not directly model word absences. The likelihood of a document is defined over only words present in the document. For another thing, it is also sensitive to document lengths. If one document were to contain two copies of each word in another document, the two documents would have different likelihoods, even though the word dis-tributions in the two documents are effectively identical.
Proposed Approach. Spherical representation could address the above-mentioned issues, leading towards better approximation of similarities among documents, and thus towards better manifold learning and visualization. In the spherical space, relationships between documents are mea-sured as cosine similarity  X  [0 , 1], which is the angular dis-tance between two directional unit vectors. Firstly, two doc-uments would have higher cosine similarity, not only if some words in common are present, but also if some other words in common are absent. Secondly, the normalization of all documents to unit vectors effectively neutralizes the impact of document lengths. Moreover, there is indicative evidence from the literature that a spherical approach will be promis-ing in terms of dimensionality reduction. For instance, the spherical topic model SAM [30] performs significantly better than the multinomial topic model LDA [5], when used as a dimensionality reduction technique.
 There are further advantages to spherical representation. For one thing, there is a greater degree of flexibility in ad-mitting different L 2 -normalized representations, e.g., term frequency tf or tf-idf or other feature vectors. For another thing, there is a greater degree of expressiveness , as an L normalized vector can have both positive and negative ele-ments, representing the degrees of word presences and ab-sences respectively. Inspired by [30], this expressiveness en-genders a change in the topic definition, from multinomial word distribution to a unit term vector. Given a topic, we no longer associate a word with a probability value, but rather with a real value that expresses the word X  X  presence or absence (the sign) and relative importance (the weight).
Contributions. Our problem formulation is novel be-cause to the best of our knowledge, we are the first to address semantic visualization for spherical representation ( first con-tribution ). We propose a generative model called SSE, which stands for Spherical Semantic Embedding . In Section 2.1, we develop the full generative process of SSE ( second contribu-tion ). To learn its parameters, we describe an estimation based on variational inference in Section 2.2 ( third contribu-tion ). In Section 3, we review related work in visualization and topic modeling. In Section 4, we validate SSE through experiments on publicly available real-life datasets, show-ing significant gains in visualization quality and topic inter-pretability ( fourth contribution ). We conclude in Section 5.
Document Representations. We associate each docu-ment with representations in three different spaces. Table 1 provides a list of notations for reference.
Of the three representations of d n , only  X  n is observed, while x n and  X  n are latent. A key step towards integrat-ing visualization and topic modeling is to define a mapping between the spaces to ensure a consistency among the repre-sentations. In defining the mapping, we associate each topic z with representations in both the visualization space  X  and the word space  X  z . The coordinate  X  z reveals where a topics is in the visualization space, allowing users to observe the relationships between documents and topics. The word vector  X  z reveals the topic semantics in terms of the relative importance of various words within  X  z .

Visualization Space to Topic Space. As both docu-ments and topics have coordinates in the visualization space,
N otation Des cription d n a specific document x n c oordinate of d n in the visualization space  X  n t opic distribution of d n  X  n,z p robability of topic z in document d n  X  n t he observed L 2 -normalized word vector of d n z a specific topic  X  z c oordinate of topic z in the visualization space  X  z L 2 -normalized word vector of topic z V t he vocabulary (the set of words in the lexicon) N t otal number of documents in the corpus Z t otal number of topics (user-defined) their relationship can be expressed in terms of distances || x n  X   X  z || . Intuitively, the closer is x n to a topic X  X   X  higher is  X  n,z or the probability of topic z for document d . One framework to relate variables based on distances is Radial Basis Function or RBF [7], which defines a function  X  ( || x n  X   X  z || ) in terms of how far a data point (e.g., x from a center (e.g.,  X  z ). The function  X  may take on various forms, e.g., Gaussian, multi-quadric, polyharmonic spline.
RBF network [3] is frequently used to build a function ap-proximation. We use an RBF network as a  X  X ernel X  for the mapping between coordinates and topic distributions. To express  X  n as a function of x n , we consider the normalized architecture of RBF network, with three layers. The input layer consists of one input node ( x n ). The hidden layer con-sists of Z number of normalized RBF activation functions. linear output layer consists of Z output nodes. Each output node y z ( x n ) corresponds to  X  n,z , which is a linear combina-tion of the RBF functions, as shown in Equation 1. Here, w z,z 0 is the weight of influence of the RBF function of z the  X  n,z , with the constraint P Z z 0 =1 w z,z 0 = 1.
While Equation 1 is the general form, to instantiate a specific mapping function, we need to determine both the assignment of w z,z 0 and the form of the function  X  . In this work, we will experiment with a special case (  X  is Gaussian and w z,z 0 = 1 when z = z 0 and 0 otherwise), which yields the function in Equation 2, where  X  refers to the collective set of  X  z  X  X . This specific function has appeared previously in the baseline [19] that we will compare to, and this design decision helps to establish parity for comparative purposes. In future work, we will explore other function instantiations.
Topic Space to Word Space. For d n , we also need to bridge  X  n to its word space representation  X  n . As introduced previously, each topic z also has a word space representation  X  . Because  X  n is essentially a topic distribution, we adopt a similar practice as in conventional topic model, which repre-sents a document X  X  word distribution as a weighted average (based on topic distribution) of the topics X  word distribu-tions. In our context, it means taking a weighted average of the topics X  spherical unit vectors  X  z  X  X , weighted by  X  followed by L 2 -normalization to return the mean vector to
To avoid overfitting, instead of equating  X  n to  X  n , we as-sume a probabilistic process where  X  n is drawn from a dis-tribution centered at  X  n . Because  X  n and  X  n are both direc-tional vectors, we turn to directional statistics [25]. In par-ticular, von Mises-Fisher (vMF) distribution [24] was previ-ously used to model documents [1, 30]. Equation 3 specifies the probability density function (p.d.f.) for a random unit vector  X  , given mean directional vector  X  , and concentra-tion parameter  X  . Note how the p.d.f. is parameterized by the cosine similarity  X  T  X  between the mean direction  X  and  X  , which is effectively the angular distance between the two unit vectors. The higher the  X  , the more concentrated the distribution is around  X  . The distribution is unimodal for  X  &gt; 0, and is uniform for  X  = 0. C D is the normaliza-tion constant, defined in Equation 4, where I r denotes the modified Bessel function of the first kind and order r .
We can then express  X  n as a draw from a vMF distribution with mean direction  X  n , i.e.,  X  n  X  vMF(  X  n , X  ).
Generative Process. We join the three representations into a generative model, with graphical representation as in Figure 1. The generative process of SSE is as follows: 1. Draw the corpus mean direction:  X   X  vMF( m, X  0 ) 2. For each topic z = 1 ,...,Z : 3. For each document d n , where n = 1 ,...,N :
In Step 1, we draw the corpus mean direction  X  . In Step 2, we draw, for each topic, a visualization coordinate  X  and a spherical direction  X  z . In Step 3, we draw, for each document, a visualization coordinate x n , which we use to compute topic distribution  X  n as a function of document and topics X  coordinates.  X  n together with different topics X   X   X  X  are used to compute the weighted average of topics X  directions, denoted  X  n . After normalizing  X  n to a unit-length vector, we draw  X  n from a vMF with mean  X  n . Though the observed  X  n is usually positive (e.g., tf-idf ), the latent  X  may contain negative elements, which reflect unlikely words. To estimate the parameters in SSE, we employ variational EM with maximum a posteriori (MAP) estimation. The un-known parameters are the coordinates for documents (collec-tively  X  = { x n } ) and for topics (collectively  X  = {  X  directional vectors for topics (collectively T = {  X  z } ) and the hyperparameters  X ,m . Given a corpus D , which are repre-sented as L 2  X  normalized term vectors V = {  X  n } N n =1 fer the posterior distribution P( T , X  |V , X ,  X  , X , X , X ,m, X  of the directional vectors for topics (collectively T = {  X  and the corpus mean direction  X  .

We approximate the posterior using the following varia-tional distribution: where q (  X  z ) = vMF(  X  z |  X   X , X  ), q (  X  z ) = vMF(  X  the variational parameters are  X   X ,  X  m . Given this variational likelihood with priors over the document and topic visual-ization coordinate x n , X  z , as follows:
In the E-step, we optimize the lower bound L (  X   X ,  X  m ) with respect to the variational parameters  X   X ,  X  m . In the M-step, the lower bound is optimized with respect to the parameters  X ,  X  , X ,m . We alternate E and M-steps until some appropri-ate convergence criterion is reached. We use gradient-based numerical optimization method such as the quasi-Newton method to update  X   X , X ,  X  , X  .

E-step. Let  X  n = E  X  n T  X  n where n  X  { 1 ...N } ranges over the documents. Taking the gradients of L (  X   X ,  X  m ) w.r.t  X   X  , we have: where A p ( c ) denotes the mean resultant length of a vMF distribution of dimension p with concentration c . Since E  X  n does not have a closed form, following [30] we ap-proximate it as:
We refer to E || P Z z =1  X  n,z  X   X  z || 2 as S n .  X  n will be approx-imated as: where
Taking the gradients of  X  n w.r.t  X   X  j , yields: where
The variational corpus mean  X  m has a closed form update rule:
M-step. In the M-step, taking gradients of L (  X   X ,  X  m ) w.r.t  X  , we have: where and
The corpus mean m has a closed form update rule as follows:
Taking the gradients of L (  X   X ,  X  m ) w.r.t x n , we have: where
Taking the gradients of L (  X   X ,  X  m ) w.r.t  X  z , we have: where
Visualization. The dimensionality reduction aspect of visualization is related to such techniques as PCA [20], ICA [11], and Fisher X  X  Linear Discriminant [14], which are fre-quently used for feature selection. However, they are not de-signed specifically for visualization, and are concerned more with the relationship between the dimensions (orthogonality or independence), rather than the relationship between in-stances. Moreover, due to linear projection, PCA and vari-ants do not capture intrinsic non-linearities well, such as when the data is embedded as a low-dimensional non-linear manifold [2] (frequently-made assumption in visualization).
Therefore, visualization is often formulated as manifold embedding , where the objective is to preserve the relation-ship among data instances in the low-dimensional represen-tation. In most cases, this relationship is expressed in terms of pairwise distance, such as in MDS [22], LLE [31], and Isomap [33]. Recent approaches employ probabilistic for-mulations, such as PE [18] and t-SNE [12], which we use as baselines. Yet, rather than distances, others seek to preserve the neighborhood information (e.g., SOM [21], GTM [4]).
The related work mentioned above has not incorporated the intermediate topic space. The problem of semantic vi-sualization is introduced by PLSV [19]. We briefly review PLSV, whose graphical model is shown in Figure 2. The gen-erative process of PLSV is as follows. For each topic z , we draw its word distribution  X  z from a Dirichlet with parame-ter  X  , as well as its coordinate  X  z from Normal distribution with mean 0 and variance  X   X  1 . In turn, for each document d , we draw its coordinate from Normal with mean 0 and variance  X   X  1 . To generate each of the M n words in d we draw a topic z based on Equation 2, and then draw a word from the selected topic X  X  word distribution  X  z key difference between SSE and PLSV is the representation of a document. Where SSE models the generation of an L 2 normalized vector, PLSV models the multinomial generation of words w . We compare to PLSV in Section 4.

We also describe a few other works in semantic visual-ization that are related, though not directly comparable. LDA-SOM [26] is a pipeline of LDA [5] followed by SOM [21], whose output is a topographic map not directly compa-rable to our scatterplot. Semafore [23] introduces manifold regularization to semantic visualization, which is orthogonal to the direction pursued in this paper (spherical representa-tion), as manifold regularization could be applicable to both multinomial as well as spherical representations. CCG [29] is a topic model based on a latent grid space. It seeks to im-prove topic models, and is not designed specifically for docu-ment visualization. For one thing, the grid cells are discrete (unlike PLSV or SSE with continuous visualization space). For another, each document is associated with multiple grid cells, and it is not clear how to visualize such documents.
While semantic visualization deals with visualizing the re-lationship of documents based on topic modeling, another orthogonal direction is to visualize the topics themselves, such as the prevalence of topics in a corpus [34, 15], or the dominant keywords in topics [9, 10]. These works tend to be on the HCI aspects, such as user interfaces [13], rather than on dimensionality reduction or statistical modeling.
Topic Model. Probabilistic topic modeling is popular-ized by PLSA [17], and eventually by LDA [5], which pro-vides a fully Bayesian generative model. These probabilistic models associate each document with a multinomial distri-bution over topics, and indirectly a multinomial distribution over words, effectively a simplex representation.

Recognizing the usefulness of L 2  X  normalized representa-tions, SAM [30] introduces a topic model, which associates each document with a multinomial distribution of topics, and a directional unit vector in a spherical word space. With SAM, SSE shares a similar modeling of topics in the spher-ical space. The key difference is that SAM models only topics, whereas SSE also needs to model visualization in ad-dition to topics. This requires a fundamental change in how a document X  X  topic distribution is derived. Unlike SAM, in SSE the topic distribution  X  n is not drawn from a Dirichlet. Instead, to reflect the visualization objective,  X  n is expressed as a function of visualization coordinates (see Equation 1).
We conduct comprehensive experiments to evaluate the effectiveness of SSE, in terms of the quality of its outputs (primarily visualization, but also topic model).
Datasets. We rely on three publicly-available 1 , real-life datasets [8]. 20 News consists of newsgroup documents (in English) belonging to twenty classes. Reuters 8 consists of newswire articles (in English) from eight classes. Cade 12 consists of web pages (in Brazilian Portuguese) classified into twelve classes. These datasets are chosen because they represent benchmark datasets for document clustering and classification tasks. Each document in the dataset has a known class label. Because the semantic visualization task is unsupervised, these labels are not required for learning. However, they represent an objective ground truth, which we would use to evaluate visualization quality. In addition, they cover diverse document types, and different languages.
Following the practice in [19], we create balanced datasets by randomly sampling 50 documents from each class, result-ing in, for each sample , 1000 documents for 20 News , 400 for Reuters 8, and 600 for Cade 12. These are of comparable sizes to those used in [19]. Moreover, because the algorithms are statistical, we draw five independent samples from each dataset, and run each sample five times. Hence, for each set-ting, the reported result is an average of 25 runs. Vocabulary sizes are similar among samples of the same dataset, with a maximum of 5455 for 20 News , 1972 for Reuters 8, 7622 for Cade 12. These are the dimensionalities of the word space.
L 2 -normalized Representation. SSE admits different options for the L 2 representation of a document. The option that is most well-recognized in the information retrieval lit-erature is tf-idf . We experimented with several alternatives, such as word count or term frequency ( tf ), and found tf-idf to give the best results. This echoes the finding in [30], which concluded that tf-idf was a better document representation than tf . Thus, we will use tf-idf in the experiments.
The comparative methods, and their attributes, are sum-marized in Table 2. SSE is our proposed method. A proper comparison is to another approach that jointly models visu-alization and topics, i.e., PLSV [19], which we use as the pri-mary baseline. For completeness, we include other baselines http://web.ist.utl.pt/acardoso/datasets/ S SE X X X X
PL SV X X X t -SNE X X PE (SAM) X X X PE (LDA) X X in visualization (t-SNE, PE). While not direct competitors, they allow us to highlight certain aspects of our model.
PLSV [19] is a semantic visualization method based on multinomial modeling for dyadic data. Therefore, it is the proper baseline to SSE, allowing us to investigate the effects of SSE X  X  modeling of spherical representation . For PLSV, we use the same settings as in the original paper [19] (  X  = 0 . 1 N and  X  = 0 . 1 Z , which we apply to SSE as well). We implement PLSV on our own (its authors have not made their implementation available), and verify that the results are similar to those reported in the original paper [19]. t-SNE [12] stands for t-distributed Stochastic Neighbor Embedding. It is one of the state-of-the-art approaches in visualizing high-dimensional data. Its input are feature vec-tors in the original dimensions, which in our context are the L -normalized tf-idf vectors. The idea behind t-SNE is to preserve the pairwise distances in the high dimensions in the visualization space. In addition to benchmarking against di-rect visualization, including t-SNE allows us to investigate the effects of topic model on visualization, by comparing SSE against an approach with the same input ( tf-idf vec-tors) and output (visualization), but which does not have an intermediate topic space. We use the R implementation of t-SNE with default settings and perplexity 40 as in [12].
PE [18] stands for Parameteric Embedding. It is also one of the state-of-the-art approaches in visualization, but is aimed at visualizing discrete probability distributions (e.g., class or topic distributions). PE cannot stand alone, as it needs to be coupled with a method that produces topic dis-tributions. Including PE allows us to investigate the effects of modeling visualization and topic model jointly , as op-posed to obtaining topic model separately before feeding it into PE. To produce the topic distributions, we experiment with two other topic models, as follows. PE (LDA) cou-ples PE with LDA [5], which operates in the simplex word space. For LDA, we use the implementation 3 by its first au-thor D. Blei. PE (SAM) couples PE with SAM [30], which operates in the spherical word space. For SAM, we use the implementation 4 by an author A. Waters with default set-tings (  X  0 = 10 , X  = 5000, which we apply to SSE as well). [19] showed that PE with PLSA [17] is inferior to PLSV.
For visualization, we will be comparing SSE against PLSV, t-SNE, PE (SAM) and PE (LDA). We also investigate the topic models, comparing SSE against PLSV, and the two topic models used with PE, i.e., SAM and LDA. As input, for models with spherical representation (see Table 2), we use tf-idf vector (as explained in Section 4.1). For the multi-nomial models, we use their regular inputs (word counts). http://cran.r-project.org/web/packages/tsne/ http://www.cs.princeton.edu/ blei/lda-c https://github.com/austinwaters/py-sam
Metric. The utility of a scatterplot visualization is in al-lowing the user to perceive similarities between documents through their distances in the visualization space. Our em-phasis is on the strength of the dimensionality reduction, rather than on the user interface aspect. Evaluating dimen-sionality reduction through user studies is hard on the eval-uator, may be overly subjective and not repeatable across evaluators. On the other hand, there exists established met-rics to measure dimensionality reduction objectively.
One such approach is to rely on the available class labels as ground truth. Intuitively, documents of the same class are more likely to be similar than documents from different classes. A good visualization will  X  X ncode X  this intuition, by placing documents of the same class nearby, and documents of different classes apart in the visualization space. Since dimensionality reduction means that the lower-dimensional representation still preserves the  X  X roperties X  of the data, we can measure how well a visualization output reflects this intuition, by employing each document X  X  visualization coor-dinates as a reduced  X  X eature vector X  in a classification task.
The choice of the classification method is not germane, because it is the feature vector that is being evaluated. In favor of simplicity, we employ kNN classification. For each document, we hide its class label, and predict a label by ma-jority voting among its k -nearest neighbors as determined by Euclidean distance on the visualization space. The accu-racy at k or accuracy ( k ) is the fraction of documents whose predicted label based on kNN matches the true label. The higher the accuracy, the better is a visualization at encoding the class information. 1 is the highest possible accuracy, and 0 the lowest. The same metric was also used in [19].
For relative comparison, we set k = 50, i.e., measuring accuracy (50), which is appropriate, as the datasets contain 50 documents from each class. Setting k &lt;&lt; 50 may not suf-ficiently penalize a visualization that splits documents of the same class into multiple small clusters in different localities.
Vary Number of Topics Z . We now compare the performance of various methods. In Figure 3, we plot the accuracy (50) as we vary the number of topics Z from 10 to 50. The three sub-plots (a), (b), and (c) correspond to the three datasets 20 News , Reuters 8, and Cade 12 respectively.
In terms of SSE X  X  performance as the number of topics varies: (#1) As the number of topics Z increases, initially there is an improvement in accuracy, most notably between Z = 10 and Z = 30. Thereafter, accuracies either remain flat or drop slightly as Z increases further. The best performance by SSE is 0.66 on 20 News (at Z = 30), 0.77 on Reuters 8 (at Z = 20), and 0.41 on Cade 12 (at Z = 30). (#2) SSE achieves a drastic reduction in dimensional-ity from thousands (vocabulary size) to two (visualization), while preserving the relationship between data points. The above accuracies as measured in the reduced dimensional-ity (visualization) approach closely the accuracies of kNN when using the full dimensionality (i.e., tf-idf input vectors), which are 0.73 on 20 News , 0.85 on Reuters 8, and 0 . 52 on Cade 12. This shows that SSE X  X  low-dimensional representa-tion has high approximation ratios of 90% for 20 News and Reuters 8 and 78% for Cade 12 in kNN accuracies, underlin-ing the quality of dimensionality reduction achieved. (#3) The varying accuracies across datasets indicate their relative difficulties, with 20 News in between Reuters 8 (the least difficult) and Cade 12 (the most difficult). In terms of SSE X  X  comparison to baselines: (#1) SSE has significantly higher accuracies than PLSV (the main baseline). In relative terms, SSE improves upon PLSV X  X  ac-curacy by 30 X 48% on 20 News , by 12 X 16% on Reuters 8, and by 22 X 36% on Cade 12. This indicates that spherical repre-sentation of word space helps to improve the visualization. (#2) SSE outperforms the visualization method t-SNE that also takes in tf-idf vectors as input. t-SNE X  X  accuracy is not affected by the number of topics. A direct visual-ization technique, t-SNE is competitive, outperforming the other baselines for 20 News and Cade 12. However, it per-forms worst for Reuters 8 (more on this later). SSE shows significantly higher accuracies than t-SNE in the majority of cases (except for very low number of topics Z = 10), with improvements up to 14% on 20 News , 54% on Reuters 8, and 14% on Cade 12. Since t-SNE shares the spherical rep-resentation of documents but does not model topics, the outperformance by SSE could be attributed in part to the approach of modeling topics with visualization. (#3) SSE also outperforms PE (SAM) by a large margin. Since SSE and SAM share a spherical representation of top-ics in the word space, this outperformance by SSE can be attributed to jointly modeling topics and visualization. This is further suported by how PLSV (which also jointly mod-els topics and visualization) outperforms PE (LDA), even as they share multinomial modeling of topic words.

Vary Number of Neighbors k . In Figure 4 we inves-tigate the effects of different neighborhood size k  X  X  at spe-cific settings of topics ( Z = 30 for 20 News , Z = 20 for Reuters 8, and Z = 30 for Cade 12). These are Z settings where SSE performs best, but similar observations can be drawn for other Z settings. The focus here is on the number of neighbors, rather than on the relative comparison against the baselines again, so we apply the same Z for all methods. (#1) As k increases from 10 to 50, the accuracy ( k ) tends to decrease. This is expected because a small k is very con-servative, where we are only concerned with the immediate neighbors, which tend to be very similar. As k increases, the neighborhood considered in the kNN is larger, with a higher chance of having neighbors of a different class. (#2) The gradients of the decrease vary among meth-ods. Most methods, such as SSE, are relatively stable. This stability across different k  X  X  is a good sign, indicating that documents of the same class are placed in the same general locality. The most affected is t-SNE, with the greatest dif-ference in accuracies between k = 10 and k = 50. The sharp difference indicates that t-SNE may splinter documents of the same class into several clusters in different localities, such that neighbors at low k are still of the same class, but neighbors at higher k are of different classes. This is indeed the case, as seen in the qualitative comparison (Section 4.5).
In summary , the experiments show that SSE overall produces a significant gain in visualization quality over the baselines, as measured in terms of its accuracy in kNN clas-sification with coordinates as features.
We also investigate whether the gain in visualization comes at the expense of the topic model. We compare SSE with baselines PLSV, LDA, and SAM in terms of topic model.
Metric. There are several evaluation methods for topic models proposed in the literature. One is perplexity [5], which measures the log-likelihood on unseen test data. Per-plexity is intrinsic , i.e., dependent on the specific probability model, and may be inappropriate when comparing models with drastically different probability models, e.g., PLSV or LDA that uses multinomial models, versus SSE or SAM that uses vMF distributions. We thus need an extrinsic evalua-tion that compares these models using external validation.
In our setting, interpretability is important, because the topic model serves to provide semantics to the visualization of the data at hand. To human subjects, interpretability is closely related to coherence [28], i.e., how much the top key-words in each topic are  X  X ssociated X  with each other. After an extensive study of evaluation methods for coherence, [28] identifies Pointwise Mutual Information (PMI) as the best measure, in terms of having the greatest correlation with human judgments. We therefore adopt PMI as a metric.
PMI is based on term cooccurrences. For a pair of words w i and w j , PMI is defined as log average the pairwise PMI X  X  among the top 10 words of that topic. For a topic model, we average PMI across the top-ics. Intuitively, PMI is higher (better), if each topic features words that are highly correlated with one another.

Key to PMI is the use of an external corpus to estimate p ( w i ,w j ) and p ( w i ). Following [27], we use Google Web 1T 5-gram Version 1 [6], a corpus of n-grams generated from 1 trillion word tokens. p ( w i ) is estimated from the frequencies of 1-grams. p ( w i ,w j ) is estimated from the frequencies of 5-grams, as recommended in [27]. We show the PMI for the English-based 20 News in Figure 5(a) and Reuters 8 in Fig-ure 5(b). Cade 12 is not included because we do not possess a large-scale n-gram corpus for Brazilian Portuguese.
Vary Number of Topics Z . From Figure 5, we draw the following observations on topic interpretability. (#1) SSE outperforms PLSV, and SAM outperforms LDA, in terms of PMI scores, across various topic settings, on 20 News and Reuters 8. It indicates that spherical models (SSE and SAM) produce topics that are more coherent and inter-pretable than multinomial models (PLSV and LDA). This is consistent with the conclusion reached in [30], which con-ducts an evaluation of coherence using human judges. This concurrence helps to show that our automatic evaluation on an external corpus is consistent with human judgments. (#2) SSE performs similarly to SAM, with slightly higher PMI scores on 20 News , but comparable scores on Reuters 8. This can be explained by their common modeling of topics in the spherical space. Since SSE also needs to deal with visualization constraints, it is notable that the gains in vi-sualization quality have not hurt, and have even sometimes helped the topic model. (#3) PLSV performs similarly to LDA on 20 News , but slightly worse on Reuters 8, which is not surprising since they both share a similar multinomial modeling of topics but PLSV also faces constraints to fit the visualization task.
In summary , the experiments show that by incorporat-ing spherical representation, SSE X  X  significant gain in visu-alization does not come at the expense of the topic model.
To gain a sense of the visualization quality, we show exam-ple visualization outputs for 20 News and Reuters 8. Cade 12 is not shown here due to space constraint. 20News. The visualizations for 20 News are shown in Figure 6 for Z = 30 (best viewed in color). Each document has a coordinate in the scatterplot. To aid identification, documents are drawn with a colored marker based on their class (see legend). Topics are drawn as black, hollow circles.
SSE X  X  visualization in Figure 6(a) shows better separation of different classes. For instance, there are distinct blue clus-ter and purple cluster on the right for rec.sport.hockey and rec.sport.baseball classes respectively, green and red clusters on the lower right for rec.motorcycles and rec.autos , etc. In-terestingly, not only are documents of the same class placed nearby, but related classes are also neighboring one another, with recreational classes rec.* on the lower right, computer classes comp.* on the lower left, science clases sci.* at the center and upper left, while classes related to politics and religion are on the upper right. Comparatively, PLSV in Figure 6(b) suffers from greater crowding at the mid-section, while t-SNE in Figure 6(c) from splintering of some classes into multiple clusters (e.g., pink square documents denot-ing talk.politics.mideast ). PE (LDA) in Figure 6(d) and PE (SAM) in in Figure 6(e) are weaker. The relative ranking in visualization quality largely mirrors the earlier finding on quantitative accuracy, with SSE being the best, followed by t-SNE, PLSV, and then the two PE approaches.

To show that the SSE X  X  visualization is backed by a good topic model, we show some topic words in Table 3. One property of spherical representation is that each topic may have both positive and negative words. We show the five most positive words, and the five most negative words. Only 10 topics out of 30 are shown due to space constraint. Look-ing at the positive words, we see that the topics cover some classes very well, such as hockey, motorcycle, car, windows, apple, christianity, religion, middle eastern politics, medicine, and space. Looking at the negative words, we see that the topics also define what classes they are not . Topic 0 is about hockey, and not baseball. Topic 1 is about motorcycles, and not cars. Topic 3 is about software, and not hardware. Reuters8. The visualizations for Reuters 8 are shown in Figure 7 for Z = 20. Generally, it is an easier dataset, and most methods perform better than for 20 News . Compar-atively, SSE still produces the clearest separation between classes, and similar observations apply as before. In par-ticular, the splintering issue with t-SNE is even clearer in Figure 7(c). For instance, the money-fx class is splintered into two navy-blue diamond clusters (lower left and upper right) separated by other classes. This helps to explain why t-SNE performs even worse (in relative terms) on Reuters 8 than on other datasets. hockey bike car window apple jesus god israel doctor space team dod engine software sale christ religion israeli patient launch cup motorcycle mile product monitor christian truth arab treatment moon playoff ride ford price computer god belief jew medicine flight nhl rider mustang user price sin existence jewish symptom nasa inning oort board slot burst wingate livesey algorithm jew driver bullpen sensor lady wiretap scsi sea corruption science key nice giant firearm 1983 ide 16-bit livesey theological armenia god motorcycle
In this work, we address the problem of semantic visu-alization that jointly models visualization and topics. Our model, Spherical Semantic Embedding or SSE is designed for data with spherical representation, i.e., L 2  X  normalized term vectors. Its generative model associates each document with a triplet of representations, namely: a coordinate in the Euclidean visualization space, a multinomial topic distribu-tion in the topic space, as well as a normalized term vector in the spherical word space. Comprehensive experiments on benchmark datasets show that SSE shows significantly improved performance when compared to existing state-of-the-art baselines in terms of visualization quality, as well as topic interpretability.
