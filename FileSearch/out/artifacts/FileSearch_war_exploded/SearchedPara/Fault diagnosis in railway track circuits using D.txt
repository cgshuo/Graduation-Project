 1. Introduction
Complex industrial systems need to be monitored continu-ously to detect dysfunctions and maintain a good quality of service. In the railway domain, the infrastructure is often inspected by instrumented vehicles in order to ensure a high level of safety and availability within a predictive maintenance framework. For some applications, signals recorded during inspection runs are manually analyzed by maintenance experts and technicians in order to identify anomalies. In this case, there which can reduce the time consumed by the analysis phase and improve the diagnosis performances. The aim of such systems is to detect the occurrence of a fault based on recorded measure-ments and then determine the exact nature and location of the fault. Maintainers are thus provided with an accurate and systematic analysis of recordings that allows them to schedule preventive maintenance appropriately.

Various approaches can be adopted in order to build an automatic FDI system, depending on the available knowledge of the system under study. In the so-called model-based approach, an accurate model of the system is typically assumed to be available. Several approaches have been proposed to exploit analytical redundancy, including parity space equations, state observers and process identification ( Gertler, 1998 ; Isermann, 2005 ; Korbicz, the pattern recognition approach to fault diagnosis uses only a set of historical data containing representative measurements ac-quired under various normal and abnormal conditions ( Rengas-pre-processing stage, referred to as feature extraction , maps data from the measurement space to a reduced feature space relevant to the FDI task. Machine learning techniques (such as decision trees, neural networks or support vector machines ( Duda et al., 2001 ; Bishop, 1995 ; Kittler, 1998 )) then capture the relationships between feature values and system states, based on learning data. To ensure good generalization, this approach requires some knowledge of the system to extract relevant features, as well as a large and exhaustive labelled database covering most of the situations that can be encountered in practice. A comparison between the model-based and pattern recognition approaches is given in Rengaswamy et al. (2002), and an approach to fault diagnosis based on trend analysis is presented in Maurya et al. (2007) .

This paper presents a method for FDI in railway track circuits based on a statistical pattern recognition approach. Track circuits generally use a scheduled maintenance regime: inspection is days) and inspection recordings are analyzed visually in order to detect major defects. Recent work on fault detection and diagnosis
The authors proposed a neuro-fuzzy system that makes it possible to detect and diagnose the most common track circuit failures in a laboratory test rig. The diagnosis system proposed here differs since it uses a train-based approach and it is dedicated to detect different kind of defects.

A track circuit is composed of a series of trimming capacitors connected between the two rails ( Berova; Hill and Carpenter, the fact that the presence of a fault in one subsystem (trimming capacitor) influences the inspection signal of other subsystems located downstream (between the defective capacitor and the represent the N trimming capacitors, and I i denotes the inspection inspection signals corresponding to all capacitors between S i and S . Consequently, the fault isolation task must take into account the spatial relationship between subsystems: an abnormal measurement from one subsystem may indicate a fault in that subsystem or in any of the subsystems located upstream of it.
The approach presented here uses machine learning (neural networks, decision trees) and information fusion techniques to capacitor is classified as fault-free or defective using a neural network or decision tree classifier and the local decisions are combined to make a final decision regarding the presence and location of a fault.

Training a neural network classifier involves minimizing the discrepancy between the neural network outputs and target outputs encoding class membership of training patterns. Conse-quently, an output coding scheme has to be chosen. Two such schemes will be tested and evaluated. In the first one, only the target output related to the defective subsystem is set to 1 (the others being set to 0). This scheme may be referred to as local coding . Alternatively, the target outputs of both the defective subsystem and the subsystems located downstream of it may et al., 1998 ). Each classifier thus provides information on the in any of the subsystems located upstream (distributed coding).

A large number of methods for classifier fusion have been proposed. For many applications, it has been shown that combining classifiers can yield performance improvements (Bi et al., 2004 ; Valente and Hermansky, 2007 ; Galina, 1994 ; Le et al., 2005 ). Depending on the information provided by the individual classifiers, three categories of fusion methods can be distinguished ( Kuncheva, 2004 ; Xu et al., 1992 ):
When each classifier produces a single class label output (crisp label), the two most representative approaches are majority voting Lam and Suen (1997) , and the behaviour X  X nowledge space (BKS) method ( Huang and Suen, 1995 ).

The second group of fusion methods is of the rank level decision type, i.e., the output of each classifier is a subset of possible labels ranked by plausibility. The fusion strategies applied on outputs of this type are based on class set reduction, class set reordering or a combination of both ( Ho et al., 1994 ).
The first approach aims at reducing the set of considered classes while the objective of the second one is to place the true class as close as possible to the top.

The third and largest group of fusion methods operates on classifiers that produce the so-called soft labels in the range [0,1]. These methods can be based on the Bayesian probability theory ( Le et al., 2005 ; Ruta and Gabrys, 2000 ), Possibility theory ( Pedrycz et al., 1998 ; Dubois and Prade, 1988 ; Zadeh, 1978 ) or the theory of belief functions, also referred to as the Dempster X  X hafer or evidence theory ( Den X ux et al., 1998 ;
Denoeux, 1997 ; Bloch, 1996 ; Jones et al., 2002 ; Yang and Wu, 2007 ). The method investigated here is based on the latter approach, which provides a flexible framework for handling uncertainty and managing the conflict between several classifiers.
 The rest of the paper is organized as follows. Section 2 describes the application under study and introduces the diagnosis problem in greater detail. The necessary notions of the Dempster X  X hafer theory are then recalled in Section 3. A system for fault detection and isolation in track circuits based on classifier fusion in the Dempster X  X hafer framework is then presented in Section 4.
Experimental results are finally reported in Section 5, and Section 6 concludes the paper. 2. Case study
The application considered in this paper concerns FDI in 2.1, and the problem addressed will be exposed in Section 2.2. An overview of the proposed FDI method will then be presented in
Section 2.3. 2.1. Track circuit principle
The track circuit is an essential component of the automatic modified signal The signalling system uses the occupation of track section to protect trains from coming into conflict. On French high speed lines, the track circuit is also a fundamental component of the track/vehicle transmission system. It uses a specific carrier frequency to transmit coded data to the train, for example the maximum authorized speed on a given section on the basis of safety constraints.

The railway track is divided into different sections. Each one of components:
A transmitter connected to one of the two section ends, which delivers a frequency modulated alternating current.
 The two rails that can be considered as a transmission line.
At the other end of the track section, a receiver that essentially consists of a trap circuit used to avoid the transmission of information to the neighbouring section.

Trimming capacitors connected between the two rails at constant spacing to compensate for the inductive behavior of the track. Electrical tuning is then performed to limit the attenuation of the transmitted current and improve the transmission level. The number of compensation points depends on the carrier frequency and the length of the track section.

The rails themselves are part of the track circuit, and a train is detected when its wheels and axles short-circuit the track. The presence of a train in a given section induces the loss of track circuit signal due to shorting by train wheels. The drop of the received signal below a preset threshold indicates that the section is occupied. In order to make the transmitted information specific to each track section and to minimize the influence of both longitudinal interference and transverse crosstalk, four frequen-(capacitor and inductance) on both the transmitter and the receiver. 2.2. Problem description
The different parts of the track circuit are subject to malfunc-tions (due to aging, atmospheric conditions or track maintenance operations) that must be detected as soon as possible in order to maintain the system at the required safety and availability levels. In the most extreme cases, such malfunctions can cause a significant attenuation of the transmitted signal which may induce signalling problems. The purpose of system diagnosis is to inform maintainers about track circuit failures, thus ensuring that the quality of transmitted information remains high.
A vehicle-based fault diagnosis system can be developed by equipping an inspection vehicle with a sensor in front of the first picked up by the sensor coils and recorded at each position of the train, while the track circuit is shunted by the inspection train itself ( Fig. 2 ).

This paper will focus on trimming capacitor faults that affect capacitor internal resistance. The deviation from the ideal behavior of the capacitor, mainly due to dielectric aging, is taken into account by introducing a serial resistance r that is null (or weak) when the capacitor is healthy and increases when it is defective. An electrical model has been developed that is able to perform realistic simulations of the system including a large variety of dysfunctions ( Berova; Hill and Carpenter, 1993 ; Debiolles et al., 2004 ). Fig. 3 shows examples of Icc signals simulated along a 1500m track circuit: one of them corresponds to an absence of fault, while the others correspond to a defective 9th capacitor. The aim of the fault detection and isolation system is to detect the operating mode of the track circuit by analyzing the measurement signal. 2.3. Overview of the diagnosis method
The proposed method is based on the following two observa-tions (see Fig. 3 ):
The inspection Icc signal has a specific pattern, which is a succession of arches also called catenary curves , each one Icc corresponding to a trimming capacitor; an arch can be approximated by a quadratic polynomial.

The presence of a fault in the system only affects the shape of the arches between the fault and the receiver leaving the signal upstream (between the transmitter and the fault) unchanged. The proposed method consists in extracting features from the
Elementary classifier outputs are then represented using the formalism of belief functions and combined. Finally, a decision regarding the presence and location of a fault is made. 3. Dempster X  X hafer theory
This section will provide a brief account of the fundamental notions of the Dempster X  X hafer theory of belief functions, also referred to as Evidence theory. This uncertain reasoning frame-work was initiated by Dempster (1968) and developed by Shafer (1976) . It can be seen as an extension of Bayesian probability theory. A particular interpretation of the Dempster X  X hafer theory has been proposed by Smets and Kennes (1994) , under the name of the transferable belief model (TBM). The TBM has a two-level structure composed of the following: a credal level where beliefs are entertained, and a pignistic level where decisions are made.
 In this section, we shall define only the concepts used in the diagnosis method introduced below. Further details can be found in Smets, (2002), Smets and Kennes (1994) , Smets and Kruse (1997) , Smets (1990) , and Rakar et al. (1999) . 3.1. Representation of beliefs: the credal level
Let Y denote the set of possible answers to a given problem, called the frame of discernment . Here, Y will be assumed to be finite: Y  X f y 1 ; y 2 ; ... ; y n g :  X  1  X 
A basic belief assignment (BBA) is a function m from 2 Y to [0,1] that assigns a  X  X  X ass of belief X  X  to each subset A of the frame of discernment Y , such that X m  X  A  X  X  1 :  X  2  X 
The basic belief mass m ( A ) represents a measure of the belief that cannot be committed to any strict subset of A . Every A D Y where + denotes the empty set, is said to be normal . The quantity m ( + ) can be interpreted as that part of belief that is committed to the assumption that none of the hypotheses in Y might be true (open-world assumption). When m ( Y )=1, m is called a vacuous
BBA: it represents total ignorance regarding the question under consideration.
 system under study, where y 1 is the normal state, and the other two states are faulty. Assume that we have some evidence that the system is in a faulty state (but we do not know which one), and we have a degree of confidence of 0.8 in this piece of evidence.
This information can be represented as the following BBA: m  X f y 2 ; y 3 g X  X  0 : 8 ; m  X  Y  X  X  0 : 2 : We note that the mass 0.8 is attached to { y 2 , y 3 } because the without pointing specifically to y 2 or y 3 . The remaining mass of 0.2 is not assigned to y 1 as no evidence points to that particular hypothesis. It remains uncommitted and attached to the whole frame of discernment. 3.2. Combination of several BBAs
To combine several BBAs defined on the same frame of discernment, Smets introduced the conjunctive rule of combina-1990 ). For this rule to be used, the different BBAs must be based upon independent pieces of evidence. Let m 1 and m 2 be two BBAs.
The BBA that results from their conjunctive combination, denoted by m 1 \ m 2 , is defined for all A D Y as m \ m 2  X  A  X  X  This rule is commutative and associative. When combining n following direct formula: m \ ... \ m n  X  A  X  X 
The mass m ( + ) assigned to the empty set may be interpreted as a measure of conflict between the two sources.

Example 2. Continuing Example 1, assume that we receive another independent piece of evidence telling us that the system is not in state y 2 , with confidence 0.6. This evidence may be represented by the following BBA: m  X f y 1 ; y 3 g X  X  0 : 6 ; m  X  Y  X  X  0 : 4 :
Combining m 1 and m 2 using (3) yields the BBA m=m 1 \ m 2 defined as follows:  X f y g X  X  0 : 8 0 : 6  X  0 : 48 ; m  X f y ; y 3 g X  X  0 : 8 0 : 4  X  0 : 32 ; m  X f y ; y 3 g X  X  0 : 2 0 : 6  X  0 : 12 ; m  X  Y  X  X  0 : 2 0 : 4  X  0 : 08 :
We observe that the masses still sum to one.
Icc (Ampere) 3.3. Discounting
The reliability of a source of information can be taken into account by discounting the original BBA m by a discount rate 1 a , where a is a coefficient between 0 and 1. The smaller the defined by Shafer (1976) and Smets (1993) : m  X  A  X  X  a m  X  A  X 8 A Y ; m  X  Y  X  X  1 a  X  1 m  X  Y  X  :  X  5  X 
In this way, part of the total mass of belief is transferred to Y , resulting in a less informative BBA. The coefficient a represents the degree of belief that the source is reliable ( Smets, 1993 ; and the belief function is unchanged. The closer a is to zero, the closer the resulting BBA is to the vacuous belief function ( m ( Y )=1), meaning that the information provided by the source is discarded. Several methods have been proposed to learn the 2008 ).
 Example 3. Assume that we are about to toss a coin, and we represent our belief regarding the outcome on the frame Y ={Head,Tails}. If the coin is fair, then our belief on Y can be represented by the following BBA: m  X f Head g X  X  0 : 5 ; m  X f Tails g X  X  0 : 5 :
Such a BBA, whose focal sets are singletons, is equivalent to a probability distribution and is called a Bayesian BBA. Assume now that we are not sure that the coin is fair, and we only have a degree of belief equal to 0.7 in this hypothesis. Then, the above BBA should be discounted by a rate 1 a =1 0.7=0.3. The discounted BBA is m  X f Head g X  X  0 : 7 0 : 5  X  0 : 35 ; m  X f Tails g X  X  0 : 7 0 : 5  X  0 : 35 ; m  X  Y  X  X  0 : 3 :
We observe that part of the mass has been transferred to the frame of discernment, which reflects partial ignorance of the probabilities. 3.4. Decision-making: the pignistic level
The TBM is based on a two-level structure: the credal level where beliefs are entertained and the pignistic 1 level where BBAs ar converted into probability distributions are used to make decisions according to the principle of maximal expected utility (Smets, 2002 ; Smets and Kennes, 1994 ).

When a decision has to be made, the BBAs are transformed into probabilities. For this purpose, we build a pignistic probability function BetP from the BBA m , using the pignistic transformation defined as ( Smets, 2002 ): Bet P  X  y  X  X  where j B j denotes the cardinality of B and it is assumed that m ( + ) o 1.

This definition is based on the idea that, in the absence of additional information, m ( B ) should be equally distributed between the components of B , for all B D Y . The pignistic probability is a classical probability measure that can be used for decision-making using standard Bayesian decision theory. A detailed discussion on this concept can be found in Smets (2002) . Example 4. Let us come back to the BBA m of Example 2. Its pignistic probability function is Bet P  X  y 1  X  X  0 : 12 2  X  0 : 08 3 C 0 : 09 ; Bet P  X  y 2  X  X  0 : 32 2  X  0 : 08 3 C 0 : 19 ; Bet P  X  y 3  X  X  0 : 48  X  0 : 32 2  X  0 : 12 2  X  0 : 08 3 C 0 : 73 : 4. The diagnostic system
The whole architecture of the proposed diagnosis system is As explained in Section 2, the objective of the application is to detect a fault in any of these capacitors, and to determine the represents the measurement data corresponding to capacitor S i . extracted from the Icc curve as displayed in Fig. 2 . The arrows S (for instance) influences the measurement data (i.e., the shape if catenary curves) related to all capacitors downstream.
As shown in Fig. 4 , the proposed system is composed of N local if capacitor S i is faulty, or if any of the upstream capacitors is faulty. These two approaches will be hereafter referred to as local these two approaches will be investigated below.

Each classifier D i receives feature values extracted from raw inspection data, and computes a probability p i . Depending on the coding chosen, this output is converted into a Dempster X  X hafer mass function m i . The N mass functions are then pooled into a combined mass function m using (3) X (4), and a decision regarding the presence and location of the fault is made based on pignistic probabilities (6).

In the rest of this section, we will first describe the feature and 4.2, respectively. The fusion process will then be described in Sections 4.3, and the final decision procedure will be presented in Section 4.4. Details regarding the training of classifiers will be presented with experimental results in Section 5. 4.1. Feature extraction
As explained in Section 2.2, the inspection data take the form of an Icc curve as shown in Fig. 3 . This constitutes the measurement space. The Icc curve is composed of arched curve segments. Each of these arches corresponds to a trimming capacitor. To obtain a compact representation of the data, each arch was approximated by a quadratic polynomial and the three (see Fig. 5 ). The whole Icc curve was thus described by a total of 3 N features.

As a fault in capacitor S i affects the inspection data down-stream, each classifier D i has to be provided with upstream and the i th trimming capacitor. The features spaces of the classifiers are thus nested. 4.2. Decision spaces of local classifiers
In this paper, we consider neural network or decision tree classifiers, whose outputs are interpreted as probabilities. As explained above, each local classifier D i can be trained either to between S 1 and S i . When neural networks are used as classifiers, the nature of the learning task will affect the coding of neural network outputs, as shown in Fig. 6 . Assume that a fault has occurred in capacitor S i (with i =3 in Fig. 6 ). Two cases will be considered:
If local coding is chosen (coding 1 in Fig. 6 ), the desired output for classifier D i is set to 1 and the desired outputs of all other classifiers are set to 0.
 outputs of classifiers D j with j Z i are set to 1 and the desired outputs of all other classifiers are set to 0.
 Distributed coding seems a priori to be more appropriate to account for the spatial relationship between subsystems. How-ever, both solutions will be studied and experimented in this paper. 4.3. Classifier fusion outputs have to be combined to reach a final decision regarding the presence and location of a defective capacitor. Here, the classifier outputs will are expressed in the Dempster X  X hafer framework and combined using Dempster X  X  rule (3) X (4).
As indicated in Section 3, to build a Dempster X  X hafer model we first need to define the frame of discernment. Here, it will be possible position of the fault. The virtual position N +1 corre-sponds to the absence of fault.

The conversion of classifier outputs into mass functions and coding, and then in the case of distributed coding. 4.3.1. Classifier fusion with local coding D N-1 S parametered signal in some capacitor S j with j a i or no fault. The output from the the singleton { i } and its complement Y \ { i }: m  X f i g X  X  p i ; m i  X  Y = f i g X  X  1 p i ;  X  9  X  where p i A [0,1] is the output of classifier D i .

The combination of the N BBAs m 1 , y , m N using the unnorma-lized Dempster X  X  rule (4) yields a BBA m with N +1 focal sets: the singletons and the empty set. This BBA has the following expression: m  X f i g X  X  p i m  X f N  X  1 g X  X  m  X   X   X  X  1
Let us now assume that we discount each classifier output by a Section 5, the discount rate can be determined as function of the then becomes m
Combining these N BBAs using the unnormalized Dempster X  X  rule now gives a BBA m defined as follows: m  X f i g X  X  a i p i m  X f N  X  1 g X  X  m  X  A  X  X  m  X  Y  X  X  the rest of the mass being assigned to the empty set. By convention, the products in the above expressions vanish when the indices of the coefficients are negative or 0. 4.3.2. Classifier fusion with distributed coding
Assume that distributed coding was used, and the output of classifier D i is equal to 0. This means that no fault was detected between S 1 and S i : consequently, there is either a fault between S D is equal to 1, it means that a fault was detected between S 1 and S . The information provided by classifier D i can therefore be represented by the following BBA: m  X  X  1 ; i  X  X  p i ; m i  X  X  i  X  1 ; N  X  1  X  X  1 p i ;  X  13  X  [1, i ] denotes the set of integers between 1 and i.
The combination of m 1 , y , m N using Dempster X  X  rule (4) yields the following BBA: m  X f i g X  X  m  X f N  X  1 g X  X  m  X   X   X  X  1
If, as before, we now discount each BBA representing the classifier becomes m  X  X  1 ; i  X  X  a i p i ; m i  X  X  i  X  1 ; N  X  1  X  X  a i  X  1 p i  X  ; m  X  Y  X  X  1 a i :  X  15  X 
Combining these BBAs using the unnormalized Dempster X  X  rule now yields m  X f 1 g X  X  a 1 p 1 m  X f 2 g X  X  a 2 p 2 a 1  X  1 p 1  X  m  X f i g X  X  a i p i a i 1  X  1 p i 1  X  m  X f N  X  1 g X  X  a N  X  1 p N  X  m  X  X  i ; j  X  X  a i 1  X  1 p i 1  X  a j p j m  X  Y  X  X  the rest of the mass being assigned to the empty set.
Example. Let us consider a hypothetical system composed of N= 3 subsystems. The frame of discernment is then Y = {1, 2, 3, 4}.
Without discounting, the different BBAs provided by the classi-fiers are given by
Classifier D1 : m 1  X f 1 g X  X  p 1 ;
Classifier D2 : m 2  X f 1 ; 2 g X  X  p 2 ;
Classifier D3 : m 3  X f 1 ; 2 ; 3 g X  X  p 3 ;
The combined BBA is then m  X f 1 g X  X  p 1 p 2 p 3 ; m  X f 2 g X  X  X  1 p 1  X  p 2 p 3 ; m  X f 3 g X  X  X  1 p 1  X  X  1 p 2  X  p 3 ; m  X f 4 g X  X  X  1 p 1  X  X  1 p 2  X  X  1 p 3  X  ; m  X  +  X  X  1
We can notice that if, e.g., p 1 = p 3 =1 and p 2 =0, there is a contradiction between classifiers 1 and 3. Then, applying the formulas, we obtain m  X f 1 g X  X  m  X f 2 g X  X  m  X f 3 g X  X  0 ; m  X f 4 g X  X  0 ; m  X  +  X  X  1 ; which means that there is total conflict between the three classifier outputs.
 With discounting, the BBAs given by the classifiers are
Classifier D1 : m 1  X f 1 g X  X  a 1 p 1 ;
ClassifierD2 : m 2  X f 1 ; 2 g X  X  a 2 p 2 ;
Classifier D3 : m 3  X f 1 ; 2 ; 3 g X  X  p 3 ;
The combined BBA is m  X f 1 g X  X  a 1 p 1 a 2 p 2 a 3 p 3  X  a 1 p 1  X  1 a 2  X  a 3 p 3 m  X f 2 ; 3 g X  X  a 1  X  1 p 1  X  X  1 a 2  X  a 3 p 3 ; m  X f 3 ; 4 g X  X  a 1  X  1 p 1  X  a 2  X  1 p 2  X  X  1 a 3  X  m  X f 1 ; 2 ; 3 g X  X  X  1 a 1  X  X  1 a 2  X  a 3 p 3 ; m  X f 2 ; 3 ; 4 g X  X  a 1  X  X  1 p 1  X  X  1 a 2  X  X  1 a 3  X  ; m  X  Y  X  X  X  1 a 1  X  X  1 a 2  X  X  1 a 3  X  ; the rest of the mass being assigned to the empty set. 4.4. Decision
To make the final decision, we compute the pignistic probability of each singleton using (6), and the estimated position ^ y of the fault is that with the highest pignistic probability: ^ y  X  argmax
By convention, ^ y  X  N  X  1 is interpreted as absence of fault. 5. Experimental results
In this section, the diagnosis system introduced in this paper is assessed using simulated data, and compared with a simple reference approach. The experimental settings will be described in Section 5.1 and the results will be reported and discussed in
Sections 5.2 and 5.3, respectively. 5.1. Experimental settings
To assess the performances of the method, we considered a track circuit of N =19 trimming capacitors and built a database containing 4256 simulated noised signals obtained for different values of the resistance of each capacitor. Among these signals, 608 were fault-free and 3648 had one defective capacitor with a resistance between r =1 O and r = N (removed capacitor). The data set was split randomly into three subsets (training, validation and test) and the performances were estimated on the test set containing 1064 signals. We have chosen to compare our approach to a basic method using one multilayer perceptron that
N +1 is used for fault-free case). In such way, we are able to quantify the benefits of our method that builds as many classifiers as trimming capacitors and uses an additional fusion stage to detect and localize a fault in the system.

The following methods were compared: 1. Regression using a multilayer perceptron ( Bishop, 1995 ) with one sigmoid hidden layer of 7 neurons and a linear output layer with one neuron. The inputs were the 19 3=57 was the location of the fault. The virtual location N+1 was used when the system was fault-free. This is considered as the reference method. This network was trained to minimize the mean square error between the estimated and the true fault positions on the whole training set. The number of hidden neurons was varied between 3 and 15; the best results on the validation set were obtained with 7 hidden neurons. 2. Fusion with neural networks and decision trees as local classifiers, with the two coding schemes described in Section 4.3, with and without discounting. Overall, this makes 8 different fusion-based methods. The neural network classifiers had one tan-sigmoid hidden layer and a sigmoid output layer with one neuron ( Fig. 7 ). Table 1 gives the number of hidden nodes used for each classifier, which was determined by minimizing the error criterion on the validation set. Each neural network was trained 100 times with random initializations. The decision tree generation algorithm was the CART method ( Breiman et al., 1984 ).
 When discounting was used, the discount rate 1 a i for classifier D i was defined from its mean square error (MSE i ) computed on the validation set as 1 a i  X  0 : 5 MSE i max
The worst classifier was thus discounted with rate 0.5, while a 5.2. Results The results of each method were analyzed as shown in Table 2 . We computed the following rates: correct detection (CD), false alarms (FA), nondetections (ND) and correct rejections (CR) on the whole data set including defective and fault-free signals. When a fault was detected, we distinguished between correct localizations (CL=CD+CR) and false localizations (FL), as it is possible for a fault to be correctly detected but incorrectly localized within the system.

If N 0 denotes the number of fault-free signals, N 1 the number of defective signals, and N X the number or cases in category X (where X is CD, CR, FL or FA), different performance measures can be computed as follows: t t  X 
The results are shown in Table 3 . Results obtained using decision tree classifiers (DT) are also reported to compare them to those of neural networks. The discount rates used to combine the classifier outputs were computed according to (18) and are reported in Fig. 8 . Except for neural network classifiers using with i , which means that classifiers are more heavily discounted as i increases, the learning task becoming more complex as we get closer to the receiver. 5.3. Discussion
We can see that, whatever the coding scheme, the fusion methods outperformed the reference regression approach and neural networks yielded better results than decision trees. Not only was the correct detection rate significantly improved, but at the same time the correct localization rate increased to over 90%. In addition, the fusion methods were responsible for only a small number of false alarms ( 2%) as compared with the regression method ( 59%). Indeed, the regression method attempts to simultaneously detect the fault and isolate it within the system. The output is an estimation of the fault position which varied between 1 and N +1 where N is the total number of subsystems and N +1 is the virtual position used for the fault-free system. In this particular case, if the estimated position is N +1 (fault-free system) rather than N (defective system, fault position= N ), this high for this method. However, it can be seen that all the methods lead to a small number of non-detections.

Local coding led to a higher nondetection rate than distributed coding. This can be explained by the unbalanced number of training instances from each class in the training database. When using local coding, each classifier learnt more 0s (no fault) than 1s.

Discounting brought only modest improvement, with a small increase of correct detection rates and a small decrease of false due to the good performances of all the local classifiers whose mean square error was low.

Inputs Output layer
For both learning methods (neural networks and decision trees), local coding induces higher correct localization rates than distributed coding. In order to analyze the magnitude of localization errors, Fig. 9 shows the histogram of the errors between the estimated and the true position of the fault in the case of fusion with distributed coding and no discounting. In 91.5% of the cases, the localization error was equal to 1, which is satisfactory in this application context. In addition, we estimated the histogram of the serial resistance of the defective capacitor when a fault was not well localized ( Fig. 10 ). For 79.2% of these signals, the capacitor fault was small with a resistance not exceeding 1.5 O .

Consequently, we can conclude that most faults were well detected by the proposed approach. Localization was also satisfactory even using distributed coding, because almost of the closest neighbour of the defective subsystem. Overall, the best results were obtained with the neural network method using distributed coding and discounting. 6. Limitation of the proposed approach and possible extensions
The pattern recognition approach presented here gives reliable results but it is only able to detect one defective subsystem (the another defective subsystem that could have a high level of severity. A model-based diagnosis approach based on an electrical transmission line model has been also developed to diagnose defects in the different subsystems is closely linked to accurate tuning of model parameters.

Further studies will be carried out to combine pattern recognition and model-based approaches in order to improve the effectiveness of the final results, especially in the case of multiple defects. The assessment of the severity of the defects is based maintenance context.  X   X  0 80 90 0 7. Conclusion
This article described an application of pattern recognition and information fusion techniques to fault detection and isolation in a railway track circuits. This device can be considered as a large-scale system that comprises several interconnected and spatially related subsystems. This means that a defective subsystem influences not only its own inspection data but also that of the systems located downstream of it.

The proposed method is based on a classifier fusion approach that builds as many local classifiers as subsystems. The local classifier outputs are then combined using the Dempster X  X hafer theory, which provides a convenient framework for handling imprecision and uncertainty in decision problems. Two learning strategies for local classifiers have been implemented, which consist in detecting the presence of a fault either on a subsystem or between a subsystem and the transmitter. Both neural networks and decision trees were investigated as local classifiers.
Experiments with simulated data have shown that correct detection rates over 99% and correct localization over 92% could be achieved using this approach, which represents a major improvement over the reference method that does not use classifier fusion. Additionally, we have shown that localization errors are small, and incorrectly localized faults generally correspond to a small resistance of the defective capacitor. Overall, the best results were obtained with neural network local classifiers and distributed coding. Although no result with real data could be presented because of lack of labelled signals, the results were judged conclusive enough by the end user to decide the implementation and dissemination of the method.

Further studies are being carried out to handle multiple faults and assess their severity, which may be useful in a predictive maintenance context. The functionality of the system will be extended to discriminate between benign faults, faults that need to be monitored and very serious faults that require immediate maintenance action.

Although the method has been developed in the context of railway track circuit diagnosis, we believe that it can be transferred to other application domains involving the diagnosis of large-scale systems composed or linearly organized subsys-tems, such as other infrastructure networks.
 Acknowledgements
This work was supported by the Infrastructure Department and the Engineering Department of the French National Railway Company (SNCF). The authors thank the anonymous referees for their helpful comments.
 References
