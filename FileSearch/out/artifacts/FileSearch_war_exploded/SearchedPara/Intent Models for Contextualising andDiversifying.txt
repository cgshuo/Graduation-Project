 The query suggestion or auto-completion mechanisms help users to type less while interacting with a search engine. A basic approach that ranks suggestions according to their frequency in query logs is suboptimal. Firstly, many can-didate queries with the same prefix can be removed as re-dundant. Secondly, the suggestions can also be personalised based on the user X  X  context. These two directions to improve the mechanisms X  quality can be in opposition: while the lat-ter aims to promote suggestions that address search intents that a user is likely to have, the former aims to diversify the suggestions to cover as many intents as possible. We in-troduce a contextualisation framework that utilises a short-term context using the user X  X  behaviour within the current search session, such as the previous query, the documents ex-amined, and the candidate query suggestions that the user has discarded. This short-term context is used to contex-tualise and diversify the ranking of query suggestions, by modelling the user X  X  information need as a mixture of intent-specific user models. The evaluation is performed offline on a set of approximately 1.0M test user sessions. Our results suggest that the proposed approach significantly improves query suggestions compared to the baseline approach. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage &amp; Retrieval]: Information Search &amp; Retrieval Keywords: query suggestions, contextualisation, diversity
Query suggestion is a mechanism that helps a search en-gine X  X  users to type less while submitting a query. Usually, such suggestions are represented as a list of queries, which are filtered by the prefix entered by the user. This list ap-pears as a user starts to enter a new query and changes as the user types new characters. Since up to 50% of queries in the query stream are preceded by other queries within
An extended version of this paper can be found at http://terrierteam.dcs.gla.ac.uk/publications/ kharitonov2013cikm-a.pdf the same session, the user X  X  earlier behaviour in the session can be a valuable source of contextual information [2], which can be used to provide the user with a better list of sugges-tions. To illustrate the utility of such kind of context, let us consider a user has just entered the query [apache], clicked on several pages devoted to Native Americans and skipped http://www.apache.org/ . It is natural to assume that the user X  X  next input [apache t] refers to [apache territory] and not to [apache tomcat]. Queries that have several possible interpretations ( intents ), such as [apache], are referred to as ambiguous [10].

Another possible direction to improve the query sugges-tion ranking is to diversify a list of proposed suggestions, i.e. to avoid unnecessarily redundant candidates. To illustrate, let us consider a prefix [apache t] and two possible candi-date sets: ([apache tomcat], [apache tomcat install], [apache tomcat download]) and ([apache tomcat], [apache tomcat install], [apache territory]). Despite the fact that [apache tomcat download] may be more frequent than [apache terri-tory], its utility in the presence of the two other candidates can be lower than that of [apache territory] and hence the latter set can be more useful to the users.

Often, the diversification and contextualisation approaches are studied independently (e.g., [7, 12]). However, if con-sidered independently, they are to some extent contrasting: while diversification implies a broad coverage of intents in order to satisfy as many users as possible, contextualisation aims to cover only the needs of a particular user. In some sense, both approaches constitute possible ways to deal with the lack or presence of the user X  X  intent preference infor-mation and a problem arises in how to combine them in a mathematically motivated manner.

In this paper, we describe a framework that is capable of providing a user whose intentions are clear with highly con-textualised queries and a user without context with diver-sified suggestions. We investigate how both the short-term search context and the query candidates diversification can be combined to provide a user with suggestions that are more useful with fewer typed characters. Our contributions in this paper can be summarised as follows:
The rest of this paper is organised as follows. After review-ing some related work in Section 2, we discuss our framework to perform a contextualised and diversified ranking of query suggestions in Section 3. Next, we describe our proposed ap-proach to model user behaviour (Section 4) and how it can be used to represent the user context (Section 5). The ex-perimental setup of our evaluation is described in Section 6. Finally, we report the results obtained in Section 7 and close the paper with some conclusions in Section 8. Three papers, Bar-Yossef et al. [2], Yan et al. [15], and Shokouhi [8] are the most closely related to our work. Bar-Yossef et al. proposed a method to contextualise query sug-gestions, which relies on representing suggestions and con-text (previous queries) as high-dimensional term-vectors. The ranking of suggestions is then based on the linear combina-tion of the query frequency and the similarity with the previ-ous context. Shokouhi [8] proposed a feature-based machine learning framework to personalise query suggestions. Shok-ouhi considered the long-term features (e.g. age, the user X  X  previous queries) as well as the short-term features (e.g. the user X  X  queries in the same session) and demonstrated that his approach outperforms the baseline that ranks suggestions according to their frequency. We note several key differences between our work and that of Bar-Yossef et al. [2] and Shok-ouhi [8]: the context we consider also includes those docu-ments that were clicked and skipped; our explicit modelling of user intents makes it possible to diversify the suggested queries while keeping them contextualised. In addition, in contrast to the work of Bar-Yossef et al. our method allows us to adjust the trade-off between query popularity and re-latedness with the context in a context-dependent manner.
After submitting a query, some search engines provide the users with query recommendations. An approach used by Yan et al. [15] to perform query recommendations in the presence of ambiguous queries differs from our work by ig-noring the search results the user skipped previously. In ad-dition, despite formulating the user needs in terms of query intents, the diversification of the recommendations was not discussed. Cao et al. [4] studied the related problem of con-textualising the query recommendations, but without con-sidering the user X  X  document examination behaviour as part of the context or addressing the explicit diversification. The method we use to extract latent user intents from the click and reformulation behaviour can be considered as an analog to the method introduced by Cao et al. [3]. However, they only mention the possibility to leverage that information in the query suggestion mechanism. Song et al. [11] proposed an approach to perform a diversified ranking of query rec-ommendations. The underlying idea behind their work is to promote queries with a high level of novelty with respect to the previously submitted query. Another algorithm to generate diversified query recommendations was introduced by Ma et al. [6]. The algorithm leverages a Markov random walk process on a query-URL bipartite graph to infer the most probable recommendation. The first difference with our work is that both approaches [6, 11] rely on the query candidate X  X  implicit similarity and dissimilarity without ex-plicitly modelling the possible user intentions. Secondly, the possibility of additional contextualisation of recommenda-tions by the user X  X  click behaviour is not considered.
Vallet et al. [14] introduced extensions to state-of-the-art diversification frameworks, such as IA-Select [1], to perform a diversified and personalised ranking of web results. Our work differs from that of Vallet et al. in the nature of the tackled task (query suggestions vs. results diversification) as well as the nature of the considered user behaviour (long-term vs. short-term).

As can be seen from the related work, little attention has been paid to the contextualisation of query suggestions by means of analysing the user X  X  document examination be-haviour, as well as to the problem of combining contextuali-sation and diversification. In the next section we introduce a novel framework that combines the user X  X  short-term query and document examination context and the diversification of the query suggestions in a unified manner, to improve the users X  satisfaction with the query suggestions.
Our approach to combine diversification and contextuali-sation is to reformulate the diversification problem as a spe-cial case of contextualisation. We use the underlying idea of IA-Select [1], where at each iteration, when a new document is selected to be added to the ranked list, the documents previously selected are assumed to have failed to satisfy the user X  X  needs. Similarly, we consider the set of queries already placed in the list of query suggestions to have failed to sat-isfy the user, and this set of queries forms the diversification part of the context. Apart from this, the user X  X  previous be-haviour (previously submitted query, documents clicked or skipped) constitutes the historical part of the context.
Informally, our framework to build diversified and contex-tualised suggestions can be recursively defined as follows. We consider the session of a user who submitted the query q , interacted with the search result page and submitted sev-eral characters of their next query. On the k + 1th step of building a query suggestions list, we already have selected k suggestion candidates: Q k = { q 1 1 ,...,q k 1 } . The task is to se-lect the next candidate q k +1 1 with the highest probability to guess the user X  X  target query, given their historical context H , and Q k as a diversification context. We denote the full context available at step k of the algorithm as T k := H  X  Q Then, the next query suggestion q k +1 1 is greedily selected with the highest probability to be submitted by the user given the current context T k , P ( q k 1 | T k ). After finding the suggestion candidate with the highest probability, it is in-cluded into Q k as q k +1 1 : Q k +1 := Q k  X  X  q k +1 1 } . We repeat the procedure until the required number of suggestions is selected.

As the above algorithm can encapsulate different forms of information, it constitutes a framework that can generate different query suggestion lists. In the remainder of this sec-tion, we describe a context-aware method to estimate the probability P (  X  q 1 | T k ) 1 for ranking candidate query sugges-tions given the current context T k .

Since we are considering the problem of ranking query suggestions after observing a part of the user X  X  session, it is natural to assume that the set of possible user intentions (search tasks) I coincides with a set of possible interpreta-tions of the previous query q 0 , i.e. I = I ( q 0 ). This allows us to deal with the small set of intentions associated with q instead of the potentially huge space of all possible search intents users may have. On the other hand, we lose the ability to diversify the candidate queries that are not repre-sented by the intents of q 0 , which may reduce the usefulness
For clarity, in the following we use the simpler notation  X  q instead of q k +1 1 for a candidate query suggestion identified at step k +1. The query the user actually submits is referred to as q 1 . of diversification. A previous search task can be completely unrelated to a new query q 1 if a user has satisfied his/her information need and is starting a new search task with the new query. Let us introduce an indicator variable c , which is equal to 1 if the user X  X  previous task is continued, and denote the probability of the continuation given the user X  X  context as P ( c = 1 | T k ).

We assume that before starting to submit the next query, the user can be in one of the | I | + 1 states: either the user is satisfied with the results and is not continuing their pre-vious search task (one state); or the user is dissatisfied with the results and continues the task ( | I | intent states). At each step, we update the full context T k and consequently our beliefs of the user X  X  state. After that, we find a sugges-tion candidate with the highest expected probability to be submitted by the user. To formalise this idea, we expand the expected probability of submitting  X  q 1 given the current context T k : The first term corresponds to the probability of the user submitting  X  q 1 and continuing the previous search task. The second term equals to the probability of submitting  X  q 1 starting a new search task. We assume that a user who is not going to continue their current search task issues a query  X  q with probability P g (  X  q 1 ), 2 which is close to the observed frequency of the query  X  q 1 in a query log. Taking that into account, we can drop the query X  X  dependency on the context in the second term, and as a consequence, we can re-write the previous expression as: P (  X  q 1 | T k ) = P g (  X  q 1 ) P ( c = 0 | T k ) + P (  X  q
Since the estimates for P g (  X  q 1 ) can be found directly by counting query occurrences in the query log, and are inde-pendent of the user X  X  context, we focus on estimating our be-lief that the user continues their task (i.e. P ( c = 1 | T the probability that the user submits  X  q 1 given he/she contin-ues the search task, P (  X  q 1 | T k ,c = 1). To estimate the latter probability, we assume that context T k influences these prob-abilities only by affecting the distribution of user intents. To leverage this assumption, we firstly factorise P (  X  q 1 | T over the possible intents I ( q 0 ):
P (  X  q 1 | T k ,c = 1) = X Under the above assumption, the probability of query  X  q independent from the user X  X  context given the user X  X  intent, thus we can drop the conditioning on the context from the first term:
P (  X  q 1 | T k ,c = 1) = X Using Bayes X  rule, P ( i | T k ,c = 1) can be estimated as follows:
As a next step, we obtain the following expression to es-timate the task continuation probability P ( c = 1 | T k ): P ( c = 1 | T k ) =
Except for P g (  X  q 1 ), all probabilities in Sections 3 and 4 are conditioned by q 0 -we omit q 0 to simplify the notation. The probability P ( c = 0 | T k ) can be similarly calculated.
Finally, P (  X  q 1 | T k ) can be estimated by combining Equa-tions (4), (5) and (6) and putting these into Equation (2). The obtained expression can be used for query ranking with various representations of the context T k . Only the prob-abilities of observing the context T k ( P ( T k | c = 0 ,i ) and P ( T k | c = 1 ,i )) depend on the context representation.
We have thus far defined our framework. In the next two sections, we discuss two possible instantiations of the framework and discuss how P ( c,i ), P (  X  q 1 | c = 1 ,i ), and the context representation parameters can be learned from a query log.
In this section, we introduce a generative approach to model the user behaviour. This model provides us with the means to represent different forms of the user context, as we will discuss in Section 5. This representation is further used in the above proposed query suggestion framework.

A part of the session, which starts with submitting a query and finishes with a query reformulation q 1 , is further referred to as an interaction . Let us consider a population of user in-teractions all starting with the query q 0 , O ( q 0 ). We assume that O ( q 0 ) is generated from a mixture of models, with each mixture component corresponding to an intent i from the family I ( q 0 ). With each interaction o  X  O ( q 0 ), we associate two latent variables: the intent i ( o ) the user had while sub-mitting q 0 and a binary variable c ( o ) which is equal to 1, if the next query q 1 belongs to the same search task as q 0 is equal to 0, if the user decided to switch to another task.
Each mixture component describes a model inspired by the Simplified DBN [5] click model and a unigram language model over possible query reformulations. Our model of user behaviour assumes that after submitting q 0 , a user with in-tent i  X  I ( q 0 ) examines results from top to bottom, one at a time. An examined document d attracts a user X  X  click with probability a d,i and satisfies the user after clicking with probability s d,i . If the user is satisfied with the last result clicked then the next submitted query q 1 is unrelated to the previous search task and its terms t  X  q 1 are distributed ac-cording to the background unigram language model of the whole query stream P lm g ( t ). If the user is not satisfied, then the user continues to examine documents until they find a satisfying document or after examining all the query results submits a new query with an intent-dependent term distri-bution P lm ( t | c = 1 ,i ).

In other words, the model assumes that a term t of q 1 is generated from a mixture of | I | + 1 components and a user X  X  satisfaction with the last clicked document determines which component will be used to generate it: a non-satisfied user submits a query with terms generated from P lm ( t | c = 1 ,i ) while a satisfied user generates the terms of the next query from the distribution P lm g ( t ). A user who cannot find a satisfying document examines all query results. Due to these intent-dependent click and language models, interac-tions with similar click/skip patterns or reformulations tend to be associated with the same component of the mixture.
The underlying graphical model is depicted in Figure 1 and, for a given document position j , it uses the random variables described in Table 1. Denoting the document on the j th position as d j , the model can be described by means of the following equations: Indeed, the above equations describe the following constraints on the model: The first document is always examined (7a); Documents are examined sequentially (7b); When an exam-ined document is attractive, the user will click it (7c); at-tractiveness and satisfaction are then document parameters, conditioned on intent (7d) &amp; (7e); An unclicked document cannot satisfy a user (7f); The examination of the ranked document list terminates when the user is satisfied, meaning that the search task is not continued and the user submits a new query (7g); If the user is not satisfied, then the ex-amination proceeds down the ranked list, as far as rank J (7h); If the user is not satisfied with the top J documents, then the user continues their search task with a new query (7i); A new query for a new search task of a satisfied user is drawn with the likelihood as given by the query log (7j); However, for the next query in a continuing search task, this probability is conditioned on the intent of the user (7k).
The maximum a posteriori (MAP) estimates of the model parameters  X  = ( a d,i ,s d,i ,P ( w | i )) as well as the P ( c,i ) dis-tribution are found from the available query log data by means of an Expectation-Maximisation (EM) procedure 3 : where P  X  ( o ) denotes the probability of an observed interac-tion o given the model parameters  X  . Following [5] and [16], we impose Beta and Dirichlet priors on the click ( a d,i , s and language model ( P lm , P lm g ) parameters, respectively. The probability P ( q 1 | c = 1 ,i ) is obtained by performing a single Expectation-like step over the interactions ending with q 1 .
More detailed description of this algorithm can be found in the extended version of this paper.
 Figure 1: Graphical model of the user behaviour. Grey circles correspond to observed variables.
 Recall that within our framework, we consider the context T k for a suggestion  X  q 1 at the k + 1th step to be defined as the unselected queries Q k and the historical context. In the following, we define two possible context representations for the historical part H of the context T k . The first represen-tation includes the previous query q 0 only, while the second includes not only the query, but also documents that the user has clicked or skipped during the session.

Query-only history Once the query-only historical con-text H is considered, our current belief in the user X  X  state is determined by the query-dependent intent probabilities P ( c,i ) and the diversification part of the context Q k we assume that the probability of the suggestion r  X  Q to be submitted by the user is independent from the con-text, given the user X  X  intent i , the probability that all k previously ranked suggestions have failed to guess the user X  X  target query given the user X  X  intent i is equal to:
P ( T k | c = 1 ,i ) = P ( Q k | c = 1 ,i ) = Y
On the other hand, if the user decided not to continue the task, then the assumption about the previously selected candidates leads to the following representation of the prob-ability of the context T k :
We expect the query-only context to be useful since the knowledge of the previous query should dramatically reduce the space of the user X  X  possible intentions.

Query, clicks and skips as history A more detailed search context includes not only the previous query, but also the clicked and skipped documents for that query. Taking the user intent model proposed in Section 4 into account and assuming that the diversification and historical contexts are independent given the user X  X  intent i and the search task continuation indicator c , the probability of context P ( T 0 ,i ) can be expressed as follows: Similarly, with P ( Q k | c = 0) and P ( Q k | c = 1 ,i ) being defined by Equa-tions (8) &amp; (9), respectively.

As in Section 4, d j denotes the document in the j th po-sition and K j is a binary variable representing that d j clicked. According to the user model described in Section 4, the probability of observing the historical part of the context is equal to: where J is the number of results on a search page. Putting Equations (10), (11), (12) &amp; (13) into Equation (6), we can find P (  X  q 1 | T k ) with the search context represented by the document X  X  clicks and skips. The values of P ( c,i ), a d,i and P ( r | c = 1 ,i ) are estimated from a session log using the EM procedure, as we discussed in Section 4.
Our empirical study has the following goals. Firstly, we in-vestigate if the proposed framework to perform a diversified and contextualised ranking leads to improvements over a ba-sic baseline algorithm that ranks query candidates according to their frequency. Secondly, we compare the performance of different possible combinations of historical and diversifica-tion contexts, so as to determine which part of the context, historical or diversification, leads to better improvements.
To address these goals, we experiment with the baseline ranking and four different variations of the proposed ranking framework: (a) Ranking contextualised by only the previous query entered by the user; (b) Ranking contextualised by the previous query and the documents clicked and skipped; (c) Ranking diversified and contextualised by the previous query; (d) Ranking diversified and contextualised by the pre-vious query and the clicked and skipped documents.

The case of contextualisation by the previous query only (a) (with T k = q 0 ) corresponds to ranking query candidates according to the probability of their generation from a mix-ture of the background query stream distribution P g (  X  q the distribution of query reformulations with the user X  X  task unchanged P (  X  q 1 | c = 1):
P (  X  q 1 | q 0 ) = P ( c = 0 | q 0 ) P g (  X  q 1 ) + P ( c = 1 | q
The mixing coefficients P ( c = 0 | q 0 ) and P ( c = 1 | q query-dependent and can be found by marginalising i from P ( c,i | q 0 ) known from the model learning step.

Dataset The dataset that we use in our evaluation ex-periments consists of training and test parts. The training part was generated from Yandex X  query log over a period from June, 1 to August, 28, 2012. The following two weeks were used to create the test set. We split the user actions into interactions (a part of session between two queries -as defined in Section 4) by five minutes of inactivity. A pro-duction query suggestions mechanism with near-duplicate queries removed was used to calculate P g ( q ) using the train-ing dataset. In order to avoid sparsity while learning the model parameters, we filter out all queries with less than 400 interactions observed during the training period. The test set contains only interactions starting with a query in the training set. Some descriptive statistics of the datasets can be found in Table 1.

Estimating The Model Parameters 4 All model pa-rameters -namely P ( c,i ), a d,i , s d,i and P ( q | c = 1 ,i ) are
More details can be found in the extended version of this paper.
 estimated from the training set using the Deterministic An-nealing modification of the EM algorithm [13], as initial ex-periments found this to obtain the highest performance. A hold-out subset of the training data is used to adjust the parameters of the Beta and Dirichlet priors. While learn-ing the language models of reformulations, the queries are lemmatised and stopwords are removed. We use a propri-etary entity-based web search intent-mining algorithm both to set the number of intents as well as to initialise the la-tent intent variables: an interaction is assigned to an intent which is the most likely connected with the last clicked doc-ument in the interaction. The number of intents for each query is set equal to the number of intents identified by the web search diversification algorithm. In order to speed up the learning process, we restrict each query to have no more than 5,000 associated interactions, uniformly sampling the required number of interactions for highly frequent queries. The optimisation is terminated either after performing 75 iterations or when the difference in log-likelihood between two consecutive iterations is less than 0 . 005.

Evaluation We use the same session log-based scenario as Bar-Yossef et al. [2], with two minor changes. Since build-ing the diversified ranking list is of quadratic computational complexity with respect to the number of suggestion can-didates, we perform diversification in two steps. At the first step, we use the corresponding non-diversified contex-tualised ranking to find 100 top scored candidates. Next, we perform the diversified re-ranking of these candidates. As a result of this scheme, weighting the scores by the number of candidates becomes less justified. Further, as the length of the query suggestion lists is usually no longer than 10, cut-off levels higher than 10 do not reflect the user X  X  actual experi-ence. For all these reasons, we report mean reciprocal rank (MRR) at cut-off level 10 in our experiments. Following [9], we use a prefix of length 3 to filter the query candidates.
Overall, to the best of our knowledge, our work is the first to evaluate the effects of diversification using a query log-based offline approach.
In this section, we report the evaluated quality of differ-ent combinations of contexts. Moreover, as longer queries are harder to predict given the first three characters, we ob-tain additional insights into the framework X  X  performance by varying the length of | q 1 | in the experiments. The results are presented in Table 3. We use the following abbrevia-tions: QCntx corresponds to the ranking with the previous query as a context; FCntx corresponds to the non-diversified ranking with the previous query, clicks and skips as a con-text; QCntxDiv and FCntxDiv correspond to the versions of QCntx and FCntx with the diversification context added.
Due to the proprietary nature of the system, we report only relative improvements over the baseline (e.g. +0 . 302 denotes a 30.2% relative improvement). All pairwise dif-ferences of these improvements (i.e., for any two cells on a single row with a non-zero difference reported) are statisti-cally significant according to the paired t-test ( p &lt; 0 . 005). of the query. | q 1 | is the length of the second query in words.
On analysing Table 3, we observe that contextualisation leads to a considerable improvement over a basic query sug-gestion approach that simply ranks candidates by their fre-quency. This agrees with the results reported in [2], however the values of the improvements are not directly comparable.
A noteworthy observation is that as the length of the sec-ond query in words grows, the improvement from the context increases. This seems reasonable, since the longer queries are harder to predict by the baseline approach given the three-character prefix. On the other hand, longer queries are related to the reformulation behaviour when a user is dissatisfied with the first query and tries to specify it using additional keywords. In this scenario, the user X  X  search task continues and hence contextualisation is beneficial.
For all considered subset of queries, adding the document examination context leads to further increases in the con-textualisation performance. Moreover, the relative improve-ment from the additional contextual information grows as the query length grows. We believe that a richer context allows the framework to derive the possibility of the task continuation and the user X  X  intent with higher confidences thus resulting in better results on sessions with reformula-tion behaviour.

In our experiments, the benefit of the diversification con-text is less marked than the benefit of the historical context (though statistically significant), especially when we have more evidence about the user intent (FCntx). This observa-tion makes sense, since diversification in its nature is loosely a method to address our uncertainty in the user X  X  search task, while contextualisation leverages information to pre-dict the task and rank suggestion candidates accordingly.
Overall, our results support the benefit of enriching the search context with the document examination behaviour as an approach to improve the user X  X  satisfaction with the query suggestion mechanism. Further adding the diversifica-tion context does not hurt performance and results in small, though statistically significant improvements in some cases.
To conclude, we find that our proposed framework is able to perform an effective contextualised ranking of query sug-gestions, by handling ambiguity in the user X  X  task.
In this paper, we presented a novel framework that per-forms a contextualised ranking of query suggestions, where the context encompasses the user X  X  previous query, the doc-uments previously clicked and skipped, and the query sug-gestions already examined. In contrast to the approaches, previously discussed in the literature, the proposed frame-work is capable to combine contextualisation and diversifi-cation in a uniform manner. In order to do so, the diversity requirement is represented as an intrinsic part of the user X  X  search context.

We experimented with two types of historical evidence for the search context: the first one contains the previous query only, while the second additionally contains the documents clicked and skipped during the user X  X  interaction for the pre-vious query. In order to infer the user X  X  intentions from their examination behaviour, we described an approach to model the user behaviour as a mixture of intent models. Our empir-ical study using a 3.5 month query log encapsulating about 20M interactions demonstrates that the proposed framework ranks query suggestions better than a baseline approach (ap-proximately a 30% relative improvement on the test set). Our results also show that enriching the search context with a finer-grained representation of user behaviour leads to fur-ther improvements in suggestion ranking quality. Indeed, the FCntxDiv ranking with the richest context considered (the user X  X  previous query, document examination history, and diversification context) exhibits the top performance on all the considered subsets of queries and attains a 100 . 3% relative improvement over the baseline in one of the exper-iments. As a possible direction of future work, the same approach can be used to contextualise and diversify web search results.
