 Much of the information on the Web is inherently structured, product pages of large online shopping sites such as Amazon.com being a typical example. Yet, un structured keyword queries are still the most common way to search for such structured informa-tion, which can introduce ambiguity and noise into the search results. This problem can be resolved by query segmentation , that is, transformation of unstruc tured keyword queries into structured queries. The resulting queries can be used to search product data-bases more accurately, and to improve result presentation and query suggestion. The main contribution of our work is a novel approach to query segmentation based on weakly supervised ma-chine learning, trained on the existing structured data (e.g., prod-uct tables) and the associated query and click logs. Extensive experiments over a large query a nd click log from a leading shop-ping engine demonstrate that ou r approach significantly outper-forms previously reported methods. H.3.3 [ Information Search and Retrieval ]: Information Storage and Retrieval  X  Search Process Performance, Design, Experimentation. Query segmentation, attribut e extraction, product search. A large fraction of the available data on the Web originally exists in structured databases, such as product catalogs. In contrast, un-structured keyword queries represent the most common way to search for information. Clearly , using unstructured queries to retrieve structured data represen ts a mismatch of retrieval para-digms, which is the central problem we are addressing in this paper. In short, the goal of our work is to use unsupervised ma-chine learning techniques to automatically learn to transform un-structured into structured queries. *Work done while visiting Emory University and Shopping.com The tension between structured and unstructured modes of representing and accessing information on the Web has sparked a lot of attention leading to many recent contributions in the area of information extraction. In particular, unsupervised techniques for fact extraction are an emerging field of critical importance. Shop-ping sites and specialized crawlers (e.g. those powering compari-son shopping sites) are often able to obtain information directly from the original product databases, and store product characteris-tics in a structured form. Similarly, the users searching these shopping sites (e.g., Shopping.com or Amazon.com) often have a particular product and characteri stics in mind. Hence, understand-ing the implied query structure c ould help better map the (impli-citly structured) query submitted by a user to the appropriate products stored in the (explicitly st ructured) database. In turn, this would improve the quality of the result ranking, query suggestion, and potentially results presentation. This paper focuses on the problem of detecting and labeling struc-tured attribute values in keyword search queries to enable struc-tured querying of product databases. For example, a keyword query  X  X ell inspiron 15 2gb X  could be converted to a structured form, such as { X  X ell X : BRAND ,  X  X nspiron X : FAMILY LINE ,  X 15 X : DISPLAY SIZE ,  X 2gb X : INSTALLED MEMORY } . This struc-tured query would more likely retrieve relevant results against a structured product database, compared to resorting to a keyword-based search only. To accomplish this segmentation we follow the machine learning-based approach to information ex traction and text segmentation. This approach is attractive since it allows the system to be re-trained as the underlying data changes. This requires obtaining a high-quality training set (TS) used for tuning the extraction sys-tem. The classical approach of manually labeling thousands or perhaps millions of queries is not feasible and to some degree futile because the labels can beco me obsolete as the queries and the product database contents change. Instead, we propose to gen-erate this training set automatically and robustly , using only user clicks and the existing structured product databases to guide the training process. That is, our idea, similar to [1], is to use the clicks on product records as indicators of a connection between the unstructured query text and the structured pr oduct description, and use this connection to construct labels fo r the query terms. However, un-like in the previous work we recognize that clicks are noisy (often users click on results by accident) and sparse (many tail records in the database are never clicked). Thus, the main contribution of this paper is development of a novel , robust and effective method of an unsupervised machine learni ng technique to train the query segmentation system. Our method requires no manual labeling for building a training set, which ca n be time consuming for a large number of domains. At the same time our method is able to cap-ture approximate matches between query terms and target attribute values, thus increasing the coverage of the TS. Finally, our approach allows for elegantly trading off between different performance characteristics through controlling the parameters of the automatic labeling process. Many semi-supervised or unsup ervised methods for sequence labeling have been proposed. A fe w dealt with search query seg-mentation (e.g., [1]). Several semi -supervised approaches to text segmentation, particularly to methods based on conditional ran-dom fields (CRFs) and Hidden Markov Models (HMMs) have been proposed. One common approach makes a typical assump-tion that in addition to a small am ount of labeled data there is a large amount of unlabeled data. In th is setting it is natural to apply self-training which combines a multi view and semi-supervised learning in different ways. It trains a model using the labeled data, and afterwards iteratively uses high-confidence predictions with the unlabeled data to e xpand the training set. Previous work has shown that the results were improved by add-ing a dictionary as a feature for HMM. A similar approach to CRF was presented and shown successful for text segmentation (e.g., in reference [5]). This semi-superv ised learning method aims to maximize the conditional log-likelihood of labeled data while minimizing the conditional entropy of the model predictions on unlabeled data. Previous approaches to context-aware sequential labeling have used Conditional Random Field (CRF) models [4] that allow modeling dependencies be tween states (e.g. attributes) and observations (e.g. tokens in a query). Moreover, previous works demonstrated that user product search queries do display statistically significant patterns that can help sequential labeling. Unfortunately, CRFs and other supe rvised models require signifi-cant amounts of human annotated data for the training to achieve production-level accuracy. This pr ocess can be expensive and not scalable, especially for a gene ral-domain setting where training a system for thousands of product /attribute domain categories is simply not feasible. Additionally, there is a fairly large amount of work on using additional resources for semi-or unsupervised information extraction in general. Click data together with data-bases was used in [1] for a semi -supervised CRF-based model. In our work we also use click data to decrease ambiguity. It was shown in [7] that clicked pages are important for uncovering the query intent. The unsupervised machine learning method for query segmentation was presented in reference [2]. The authors use click data and product database to reduce term ambiguity in segmentation process. This paper builds on that work and extends it significantly by improving the training set generation process and the training methodology, resulting in substantial accuracy improvements. We now present our novel weakly supervised machine learning method for query segmentation pr oblem, which is composed of two novel components: automatic query labe ling algorithm (AQ-LA), synthetic queries ge neration algorithm (SQGA) which are used for training the segmentation system (TSS) . AQLA: the goal of this component is to map unstructured query terms to product names and attribut es based on the click data. The click data comes from users intera cting naturally with a product search engine. The searchers run queries (e.g.  X  sony vaio  X ,  X  X ell inspiron 4gb  X , etc.) against a product search engine and click on product listings from the search re sults. Each click event is rec-orded to the clicks logs in the form of a ( query, product name) tuple . The products are stored in a database where each product consists of its name, textual desc ription, and structured attribute values. The AQLA uses clicks logs and product database as an input sources to derive a set of structured queries. The algorithm assigns a target attribute to each term in the query with a confi-dence estimation in range [0,1] corresponding to the certainty that a query term in fact corresponds to that attribute value. The me-thod will mark the word using a specific label  X  X nknown X  if it cannot detect any suitable target attributes for this term. This process follows the method previous ly described in reference [2] but the is enhanced by post-processing techniques to reduce the sparsity in the resulting training set, as described next. SQGA: the goal of this component is to substantially enhance the training set size and comprehensiv eness by automatically generat-extractors. First, SQGA computes the obser ved distribution of transition probabilities between attributes; th e transition probability distribu-tion is represented by a transition matrix (P), where: P( i , j ) = Pr(attribute jn =1+ |attribute in = The distribution is calculated based on the automatic labeled query set which is derived by AQLA. The clicked products have the following form: Clicked products = {product name, set of attributes description}. For example, the product  X  X ony vaio 1.33ghz 2gb 260gb 8in X  has the following set of attribute : {(attr: brand , attr_name: sony ), (attr: family line , attr_name: vaio ), (attr: processor speed , attr_name: 1.33 ghz ), (attr: in-Using the observed distribution of attribute value sequences in real queries, SQGA takes clicked products and generates a larger set of synthetic queries (SQ) using an attributes description and the distribution of transition probab ility to generate queries similar to real ones, but including queries for all products in the database, including the tail ones. To deal with rare terms, SQGA uses sim-ple additive smoothing. Training the Segmentation System: The CRF model (using the Mallet implementation) is used for the actual segmentation of new queries. The key idea is to use fo r training the system the union of automatically labeled queries (fr om AQLA) and the synthetically generated queries (from SQGA). Otherwise, the CRF training proceeds in the standard fashion. Detecting Target Attributes: The common challenge of the large database data is a duplicate det ection [6]. Our problem is some-what different: there are many nearly-duplicate a ttributes (e.g.  X  X elease-year X  and  X  release date X  ). We propose to detect such attribute duplicates by comparing the attribute values, using a bag-of-words representa tion we call an  X  X ttribute document X  : The  X  X ttribute document X  is represented by a set of words that appear as attribute values. For example, a  X  X rand_document X  con-tains all observed terms from all te xtual description of the attribute  X  X rand X  and their frequencies, which are derived across all clicked products, e.g. brand_document = (  X  dell X :14,  X  X eno-vo X :9,  X  X sus X :7 ). Attribute duplicate detection meas ures closeness between each pair of attributes by calculating a cosine similarity value between their dictionaries. Therefore, each term in the attribute document is weighted using a tf*idf metric, where tf is the count of times the term appeared inside the given attribute value, and idf is the in-verse of the count of different attributes where the term appeared. A threshold for the cosine similarity value was used to decide whether two attributes are dupl icates. The threshold was opti-mized empirically and set to 0.7 for all subsequent experiments. This process of duplicates de tection reduced the number of target attributes from 65 to 41 . Thus, it significantly reduced the target attribute space, increasing accura cy of segmentation without de-grading the user experience. Automatic Query Labeling: The AQLA uses the following input sources: 1. User clicks logs consist of click events e.g. ( QUERY = dell inspiron 14 black , CLICKED PRODUCT NAME = dell inspiron i1464-4382obk 1464 14 -inch laptop obsidian black ) , ( QUERY = sony vaio , CLICKED PRODUCT NAME = sony vaio 1.33ghz 2gb 260gb 8i). 2. Product database contains the names and attribute values of the products, with some values containing text. 3. Brand dictionary (BD) contains all brand names, brand syn-onyms and brand abbreviations and is built manually. E.g .  X  X p X  is an abbreviation for the brand  X  X ewlett Packard X ,  X  X ac X  is syn-onym for  X  X ackintosh X , etc. AQLA examines every click event ( query, product name) and quantifies the matching degree be tween each query term and a product attribute descriptions using a cosine similarity. Tf*idf-measure is used for weighting terms, but we used a modified con-ception of a  X  X ocument X . Our schema of the  X  X ocument X  is pre-sented as in formula (3). Every que ry term is referred to a particu-lar attribute in the final labeled query set. The derived pair is cha-racterized by the weight (cosine similarity) in range [0, 1]. AQLA assigns a zero weight to a query term which is labeled as  X  un-known  X . Thereafter we notice that the matched data is very sparse, meaning that a large number of queries contains terms which are defined as  X  unknown  X . This phenomenon happens because some product attribute descriptions do not contain a particular term. The described phenomenon significantly decreases the quality of de-rived labeled queries. Therefore we introduce a novel method to avoid such situations. This met hod constructs a dictionary for each attribute which includes terms and posterior probabilities. Posterior probabilities (post_pr) of belonging to a particular attribute dictionary are calculated for each query term during the automatic query labeling process. Then a dictionary of posterior probabilities for each attribute is derived in the following form: {attribute j  X  {(term i , post_pr i )} n i 1= } m j 1= (4). This dictionary is used for an updating algorithm (UA) which cleans up automatically labeled queries. Note that the value of posterior probability of belonging to a particular attribute is as-signed as an updated attribute weight for the term. The SQ are needed to extend a training TS for CRFs model. The distribution from formula (1) is supplemented with two special symbols: $begin and $end which are the beginning and the end of the query respectively. The SQGA uses this distribution and tex-tual descriptions of attributes to simulate the process of how a human being generates the product search query, generating a large synthetic training set SQ. Each (term, attribute) pair has a weight which equals a post_pr from formula (4). We consider this metric as a similarity value between term and attribute.
 CRF Model for Segmentation System: The training set for CRF learning is a union of automatically labeled queries and SQ. The system trains the CRFs model to segment the queries into attribute-value pairs. The set of target attributes was extended to label a sequence of terms like  X  Hewlett Packard  X  which are both  X  brand X  more precisely. We use the common approach of informa-tion extraction which introduces two types of attribute names: with suffixes  X  _BEGIN X  and  X  X CONTINUE X . Specifically, the CRF model is trained separately for each product sub-category because every product in our TS is already pre-classified into a distinct sub-category.
 Segmentation features: We introduce two types of features for the process of training the CRFs model: general features and dic-tionary features. General Features include :  X  Boolean features that represent a presence or an absence of: terms and ngram (unigram+bigram) ;  X  Regular expressions ( regexp ) features that match different types of the term such as numbers, words and mixed terms. Let us show an example of mixed terms: 4gb, 320gb and sd850 all match the regular expression:  X  X a-z]+[0-9]+ X  or  X  X 0-9]+[a-z]+ X  (in the pattern matching language):  X  Context information of the term that shows the preceding and the subsequent terms. Dictionary features:  X  Brand feature that shows if a particular term is a brand or not The system uses a brand catalog from the database for implemen-tation of this.  X  Dictionary for the attribute names. The system creates a dictionary for every attribute name where all terms are associated with a set of attributes and every term is associated with a post-erior probability of belonging to a pa rticular attribute. The system can detect an attribute for an incoming term using this dictionary. There is no generally accepted benchmark to evaluate product query segmentation. In the secti on of related work we mentioned several evaluated results of the query segmentation system which were introduced by other authors. There is no generally accepted benchmark to evaluate product qu eries segmentation and we can-not make a straightforward comp arison of our results with pre-viously reported semi-supervised approach [1] as we have no access to the datasets used in re ference [1]. Therefore we provide evaluation experiments using a strong baseline, based on [1], and our own  X  X round truth X  datasets, described below. Data Description: The data for the experiments is a union of query and click logs to the S hopping.com site which were col-lected from following months: September 2009, December 2009, March 2010. The total number of queries is 29,257 . These include clicks on products from computers categories which combine five sub-categories: Laptops , Software , Hard Drives , Printers , and Laptop Accessories . Ground Truth: We select 450 unique queries from our search query log described above to construct  X  X round truth X . We impose the constraints that queries in  X  X old standard X  should have length more than one word but less than six. The human  X  X round truth X  judgments were obtained by using the Amazon Mechanical Turk workers, in batches of 50 queries per assignment, resulting in 450 queries labeled overall. Up to 10 workers per batch were assigned. We developed a detailed guide for MT users which contains an explanation with examples of how labeling should be performed. Ten (distinct) queries from pre-evaluated dataset were injected into each batch, in order to provide a calibration baseline to discard poor-quality work. As a result, the work of the annotators with ratings that correlated less than 65% on the pre-evaluated subset of the batch, or those that failed the rule was discarded (approximately 30% of the submitted ratings were discarded through this procedure). Hence the ground truth includes evaluation results fr om reliable users we can assert that we use a high quality  X  X round truth X  for our evaluation. Training Set Construction: The final training set is a combina-tion of real queries, automatica lly labeled using AQLA, and the SQ set. The set of automatically labeled queries was evaluated using the constructed  X  X round truth X . We empirically measure precision, recall and f1-measure for distinct cosine similarity val-ues. The f1-measure obtains a maximum value where the similari-ty between term and attribute equals to 0.3 . Therefore we suggest the following constraints to create the final TS: (1) each term in the derived query should be define d by target attributes with weight over 0.3 , (2) the derived query could contain terms which are defined as  X  X nknown X  , but at least two terms must have target attribute. Table 1 presents derived metrics for the enhanced AQ-LA which uses the additional data sources UA (Section 3) and BD (Section 3). The relative improvements are shown in the brackets. All derived metrics are reported across all sub-categories. Preci-sion increases due to introducing UA and BD. Recall increases due to the using of UA. Table 1. Relative improvements of AQLA on the automated query labeling task (Category : Computers). Method Precision (%) Recall (%) F1 (%) Baseline 78 47 57 
AQLA 86 (+10.3) 63 (+34) 72 (+26.3) Query Segmentation Evaluation: The developed query segmen-tation system derives results with a computed confidence level (marginal probability) (CL) in range [0, 1]. Our hypothesis is that it shows  X  assurance X  for a particular prediction and could be used as a filter. The baseline algorithm for segmentation process builds a dictionary of the terms form database for every attribute and calculates posterior probability for each term in this dictionary. It assigns to every given term an at tribute with the highest posterior probability. The different TSs were used to teach CRFs model: (1) TS1 is a subset of set of automatically labeled queries which does not contain the queries with terms defined as  X  unknown X  and (2) TS2 is a combination of labeled queries which contain  X  X nknown X  and SQ. The evaluation was performed across all five sub-categories and the results are presented in Table 2. The f1-meassure is maximized at CL value equals to 0.3. The derived evaluation result proves that the a dding of SQ into TS significant-ly increases the quality of the segmentation system. The obtained segmentation result looks better compared to our baseline. The described new feature set improves overall result of prediction by 5-6% relative to the method of training CRF over the TS1. Table 2. Relative improvements on the query segmentation task (Category : Computers).
 Baseline 70 51 59 TS1+CRF 65 (-7) 36 (-29) 47 (-20) TS2+CRF 75 (+7.1) 53 (+4) 62 (+5) The presented unsupervised machine learning approach outper-forms the previous state of the art baseline, based on reference [1]. Our experiments have shown that the segmentation method ob-tains precision of 75%, which is higher than both our baseline and the reported result of 72% reported in reference [1] for the compa-rable  X  computer X  category. We proposed a novel unsupervised machine learning approach to structure search queries with produc t intent. Our approach is scal-able, in that it relies primarily on query and click logs and does not require human-annotated traini ng data. Specifically, we intro-duced two innovations: first, a new method, AQLA, for automated and robust training dataset construction that uses a product data-base and click events, and SQGA, which uses the observed data distribution to generate syntheti c comprehensive training data for rare items that may not have app eared in the query logs in the past. Second, we proposed a new method for generating a feature set for training a query segmentati on model. Possible future direc-tions include making the system even more general to allow ap-plications of our method to othe r vertical domains without addi-tional tuning. [1] Li X., Wang Y.-Y. and Acero A. A Extracting structured infor-[2] Kiseleva J., Agichtein E., Guo Q., Billsus D., Chai W. Unsuper-[3] Amini M.-R., Goutte C., Usunier N. Combining coregularization [4] Bradley J. K., Guestrin C. Learning Tree Conditional Random [5] Mann G., McCallum A. Efficient Computation of Entropy Gra-[6] Mikhail Bilenko and Raymond J. Mooney. Adaptive Duplicate [7] Li X., Wang Y.-Y. and Acero A. Learning query intent from 
