 Taylor X  X  concept of levels of information need [16] has been cited in over a hundred IR publications since his work was first published. It concerns the phases a searcher goes through, starting with the feeling that information seems missing, to expressing a query to the system that hopefully will provide that information. As every year more IR publications refer-ence Taylor X  X  work, but none of these so much as attempt to formalize the concept they use, it is doubtful that the term is always used with the same connotation. Hence we propose a formal definition of levels of information need, as especially in IR with its formal underpinnings, there is no excuse to leave frequently used terms undefined.
 We cast Taylor X  X  informally defined levels of information need  X  and the transitions between them  X  as an evolving dynamical system subsuming two subsystems: the searcher and the search engine. This moves the focus from optimiz-ing the search engine to optimizing the search interface. We define the quality of an interface by how much users need to compromise in order to fill their information need. We show how a theoretical optimum can be calculated that as-sumes the least compromise from the user. This optimum can be used to establish a base-line for measuring how much a search interface deviates from the ideal, given actual search behavior, and by the same token offers a measure of com-parison among competing interfaces.
Over the years, much work in information retrieval (IR) has focused on improving effectiveness and efficiency of search algorithms, notably encouraged by the TREC program and nourished by the SIGIR conferences. Early in the history of IR, however, several researchers emphasized that the func-tion of IR systems is first and foremost, to quote Belkin c  X  [3]  X ...to help people solve problems, rather than directly to solve problems posed to them X  (p. 42). This led to experi-ments aimed at helping searchers formulate their questions, such as suggesting suitable keywords [4], prompting them to be more talkative [14], or comparing the effects of writ-ten versus spoken queries [8]. The general finding is that if searchers could express their information need more in the way they would talk to a fellow-human, and in particular in everyday language, then this would benefit both the search results and the user satisfaction [12]. IR researchers recog-nized that the searcher X  X  struggle to formulate a query has an obvious analog in a person browsing a library with only an approximate idea of the information needed. However, the librarian can assist a searcher with considerable more verve than we can expect from today X  X  search interfaces. And thus the librarian as shining role model for future search inter-faces explains the growing IR interest in the process of query formation. The latter process has been exemplary described in Taylor X  X  [16]  X  X he process of asking questions X  which can be summarized with a direct quote from his abstract:
Four levels of question formation may be isolated and analyzed: the actual, but unexpressed, need for infor-mation; the conscious within-brain description of the need; the formal statement of the question; and the question as presented to the information system (p. 391). In his article the word  X  X nformation X  in information retrieval denotes tangible things such as books, reports, and draw-ings, rather than information per se. In the case of IR we can take the images on a computer screen as perfect proxies for those books, reports etc. (printed on paper if necessary). And the analogy goes further. One could argue that in re-cents years IR has reached a phase of diminishing returns [11], as more and more effort is needed to achieve only a slight improvement in search performance. So further im-provement can only be expected from improving the query, moving the onus from search engine back to the searcher. This is the point of Belkin X  X  remark in the beginning of this section. That, in other words, means that IR should not be about getting the right answer, but about asking the right question. In the library context this is where the librarian steps in. This lead Taylor to write a follow-up ar-ticle on question-negotiation for librarians [17]. In practice, though, IR researchers are still trying to push this part into the search engine, as we are about to see. Yet, it would be careless to write off Taylor X  X  work as old hat, since biblio-metric analysis shows [7] that the number of references to his approach increases each year, with IR notably occupying most of those references.
In Information Retrieval (IR) the term information need is ubiquitous, important, and intuitively clear. Surprisingly, attempts to formally define the notion are all but nonexis-tent [10]. Publications that tried a philosophical or sociolog-ical approach toward a definition got stuck in their attempts to cover everything that the term might connote. The last decade, following Broder X  X  work [6] a movement is afoot to study the related notion of  X  X ntent X  instead. The sugges-tion is that if a search engine could infer the intent of the searcher, it would be better equipped to provide an optimal answer. There are, however, several issues with studying  X  X ntent X  in isolation: The latter has serious consequences for the study of intent as a road to improve search, as we will see in a moment.
About a century ago, it was common to assess a person X  X  intelligence by measuring size and form of the skull. These measurements were extremely reliable : Someone who mea-sured a second time would get the same answer, and some-one else making the same measurement would get about the same answer as well. Yet, as Binet [5] showed at the time, these measurements had little to do with the  X  X ntelligence X  it was supposed to measure. Binet then introduced what be-came known as the Stanford-Binet test, which until today is considered a valid measurement, i.e. one that actually measures what it is supposed to measure (intelligence). Ap-plying this distinction to the IR studies, it turns out that in the dozens of publications, the assessors of the query in-tent were different from the searcher who formulated the query. So, as with the studies of intelligence: even if the measurements were reliable, were they actually measuring the searcher X  X  intent? To answer this question we carried out a careful meta-study of intent assessment: We recorded the interaction with a search engine from the participant X  X  formulation of a query, the subsequent interaction with the search interface, and ending with the instruction to formu-late the original intent. Afterwards the query and the in-teraction were presented to external assessors who were to guess the intent. What we found was a substantial discrep-ancy between the two [18]. That is, the measurements we found in the dozens of publications we studied, even if they were reliable, are not necessarily valid. It follows that: The last point is bad news for search algorithms, obviously. The tension is located in the transition from Taylor X  X  third level to his fourth level. That is, from the formalized need which is the searcher X  X  expression of the information need that he hopes the system will answer, to the compromised need , which is the question asked in a way that the he thinks the system can answer (i.e. in a compromise to the system). This to us seems the main issue with the intent studies: they attempt to distill the third level from the fourth level. We are aware of many proposals to relax the compromise de-manded from the user, such as making the interface more like a conversation between two humans [1, 12]. But in light of [18] it would be moot to try to push the envelope of stud-ies of questionable validity. Instead, and at the same time to obviate the issues with defining  X  X ntent, X  we undertake a formalization of Taylor X  X  levels of information need and we shift attention from ranking the search engine to ranking the interface . For this reason we need to dedicate a substantial part of this paper to the informal rendering.
Taylor X  X  informal definitions are rather verbose, so we ex-tract the parts that are essential for our formalization. To formalize the different levels, we found the terminology from quantum mechanics (QM) most convenient. Hopefully this will not deter the reader, as the terminology fits like a glove, as we will see. (So keep in mind that we do not want to de-scribe a physical system let alone a Schr  X  odinger equation.) At the first level (the visceral need ) we find: ...the conscious and unconscious need for information not existing in the remembered experience of the inves-tigator [...] It may be only a vague sort of dissatisfaction [...] which would bring from the ideal system exactly what the inquirer needed, if he could state his need (p. 392).
 Belkin [3] refers to this level as the anomalous state of knowl-edge . The correlate of the first level is the observable in QM, a superposition of states, in this case of mental states. The searcher is sitting and waiting for a query to come to the fore, no definite (mental) state exists at that time. After the searcher becomes aware of this, the first attempt at con-sciously describing what is missing arrives. This is what Taylor calls the second level (the conscious need ): the conscious mental description of an ill-defined area of indecision [...] He qualifies his area of doubt by various oral and physical means.
 This is the correlate of a measurement in quantum mechan-ics. Next comes the third level (the conscious need ) at which the searcher forms: ...a rational and unambiguous description of his doubts.
This question is what we like to believe the information system answers. It may not be, however, and probably is not, the question asked of the system.
 This unambiguous description is the outcome of a measure-ment. In QM terminology: through the measurement the observable collapses into a query Q . The searcher could have come up with another query, assuming it is not a de-terministic event but a probability distribution over queries p ( Q ). Finally level four (the compromised need ):
The question is recast in anticipation of what the in-quirer thinks he will get out of the system.
 The searcher has made a compromise here, instead of his original query (the measurement) he expresses a query that he thinks the search engine is able to answer. In today X  X  search technology, instead of using everyday language as he would do to another human, he uses the well-known terse query of two to three keywords. Only now the interaction with the search engine begins. We consider the state of the search engine as a second observable. Presumably there is a deterministic process underlying the search engine. But the links in it are updated, deleted, or created, in a way that for all intents and purposes is as opaque to us as the superpo-sition of mental states that gave rise to a query. The first measurement, the query Q , is presented to the search engine, resulting in a set of documents R , which is a second mea-surement (a measurement of the search engine), governed by distribution p ( R ). We are now ready to describe how the back and forth of the measurements can be described as the dynamics of the information need.
We continue to denote the query and search results as the measurements Q and R with probability distributions p ( Q ) and p ( R ). So far we could have abstained from the QM terminology, as we have only used other names for unde-fined terms, e.g. by calling the visceral level an observable and the query a measurement. If we were not going to use the terms, this would only be window dressing. But we are going to exploit the QM model by looking at the observ-ables as (Hermitian) operators. And more importantly as operators that do not commute. For this four page short paper there is not enough space to work out the constraints of how exactly the interaction between searcher and search engine could proceed. For example, there can be no way in which the searcher with just a feeling of missing information would cause the search engine to behave in a particular way. So what we will do is borrow from the insight of quantum systems and ask the reader to bear with us in the formal treatment. We may or may not presume an interaction be-tween the two observables (the searcher and the search en-gine). And here is were we are going to use not just the QM terminology but the QM model. In that model we have to distinguish three cases: 1. Q and R belong to one system but they do not inter-2. They belong to two different systems. 3. They belong to one system but they do interact. This The first two cases are easy, so onwards with the last one: two systems, Q and R , that have some interaction. In the case of classical mechanics (commuting operators) we could consider a joint probability p ( Q,R ), from which the marginal distributions can be computed. But the converse is not true: for a pair of marginals, many joint probabilities could give rise to these marginals. So suppose one samples distributions from the searcher and the search engine, Is there a joint distribution given the marginals that deserves a special place? The next section will point out that special place.
The foregoing may remind the reader of approaches to compute the cost of searching, such as Azzopardi X  X  using economic principles [2]. These can be used to explore op-timal search strategies given a search interface. Here we explore the opposite however, optimality of interfaces given search behavior. It addresses the compromised information need: given a choice of interfaces, which one requires the fewest compromises? The less searchers have to compromise to the technology, the less interaction they need to amend their query (in level 3) when the technology gets in the way.
Suppose we can avail ourselves to a joint probability in-teraction between searcher and search engine, such as click traces or interactions accumulated from a number of users. A joint probability distribution can then be derived by sam-pling queries and search engine results. How can we, given the joint probabilities decide which one required the least in-teraction? Interestingly, this problem can be formally solved as we will do in a moment. For the reader not familiar with the mathematics in the next paragraph: what we derive is a formal criterion for the optimality of search interfaces, based on the interaction they demand from the user. More com-promise requires more interaction to fulfill the information need. Therefore, we propose to measure the quality of the search interfaces by the amount of interaction they demand .
We are going to use a technique proposed by Jaynes [13] for statistical mechanics. Let us choose the distribution clos-est to the independent case (1) above [9]. As there is no weaker interaction than no interaction at all, this assumes the weakest interaction among the candidate distributions. In other words, we are looking for a distribution that is the most difficult to distinguish from the independent case (by the best test). So by definition of K-L divergence KL (  X || X  ), we need the joint probability with the smallest divergence from the independent case. That is, we are looking for a p ( x,y ) that minimizes constrained by what we know about p ( Q ) and p ( R ), such as their moments and, since they are probabilities, also the con-dition that P Q P R p ( x,y ) = 1. This is a variational prob-lem that can be solved using Langrange multipliers , yielding are the Langrange multipliers to be found for the F and G . For example if we would know the means of the query and search engine observables P Q x  X  p ( x ) and P P y  X  p ( y ), we would have: with  X  to abbreviate  X  x,y, X  1 , and analogous expressions with  X  2 if the variances were known (and  X  i  X  X  for each ad-ditional constraint).

This model is ready for experiments to see how viable the technique is. This is imminent future work. Compare the design of it to TREC experiments where different search engines can be evaluated using a standardized corpus and topics, and precision and recall as metrics. In this vein we think of using one search engine and possibly similar standardized information needs to experiment with differ-ent search interfaces. This allows marginals over the queries to be computed and these can be compared to the marginals found by the proposed minimal interaction marginal. The interface nearest this minimum would then be counted as the best interface.

Of course this will be no sinecure, as no experimental work is. But the important message of this paper is: we now have a formal way to rank search interfaces, just as for years there has been wide consensus about how to rank search algorithms.
We showed how to formalize Taylor X  X  levels of informa-tion as a quantum system. It contains two interacting sub-systems, with query and search results as measurements of searcher and search engine. Presuming a quantum charac-ter, their statistical properties can be used to compute a parsimonious candidate for the minimal interaction needed to fulfill an information need during interaction.

Useful for future work are the manually constructed rele-vance data from the IR experiments of yesteryear. For ex-ample, the classical Cranfield paradigm provides correlations between query and relevant documents,  X  ( Q,R ), that can be added as Lagrange constraint. The results will then serve as the base-line to compare the performance for different search interfaces, ranked according to their K-L divergence with the base-line.

Such work will tell if this is indeed a viable way to compare interfaces. But even if we are not immediately successful in applying this advice to IR, perhaps our operational defini-tion of quality as optimal interaction may lead the way to investigate the necessity of evaluating search interfaces, in line with of Taylor X  X  advice [16] that summarizes this goal:
These areas of ignorance require discussion, experimen-tation, and analysis, not only for better design, but also to make the information system an effective and con-tinuous element in the research process. The approach to such a Utopia will come only when we recognize that the inquirer is an integral part of the information system and not a stranger knocking at the door for directions (p. 396). [1] J. Allan, W. B. Croft, A. Moffat, and M. Sanderson. [2] L. Azzopardi. The economics in interactive [3] N. J. Belkin. Anomalous states of knowledge as a basis [4] N. J. Belkin, P. Marchetti, and C. Cool. BRAQUE: [5] A. Binet. The mind and the brain . London: Kegan [6] A. Broder. A taxonomy of web search. SIGIR [7] Y.-W. Chang. The influence of taylors paper, [8] F. Crestani and H. Du. Written versus spoken queries: [9] S. Guiasu. Joint probability distribution of composite [10] E. Hoenkamp. On the notion of  X  X n Information [11] E. Hoenkamp. Taming the terabytes: a [12] E. Hoenkamp and P. Bruza. How everyday language [13] E. T. Jaynes. Information theory and statistical [14] D. Kelly, V. D. Dollu, and X. Fu. The loquacious user: [15] F. Radlinski, M. Szummer, and N. Craswell. US [16] R. S. Taylor. The process of asking questions. [17] R. S. Taylor. Question-negotiation and information [18] S. Verberne, M. van der Heijden, M. Hinne,
