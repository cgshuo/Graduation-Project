 Recently, the content-based publish/subscribe (pub/sub) has become a pop-ular paradigm in Internet to decouple information producers and consumers (i.e., publishers and subscribes , respectively) with help of brokers .Insucha system, subscribers declare their personal interests by defining subscription con-ditions, and publishers produce publication messages. On receiving publication messages from publishers, brokers match publications with registered subscrip-tions, and forward each matched public ation to needed subscribers. Due to the excellent decoupling property and fine-grained expressiveness, pub/sub has been widely used for many real applications, such as event-based streaming process-ing, information-centric network and e-Commerce.

As the core task of pub/sub, the matching of each received publication against subscriptions typically utilizes a subscription indexing structure for higher effi-ciency. For example, by building a R-tree s tructure to index registered subscrip-tions, pub/sub systems can correctly find all matched subscriptions by processing a subset of subscriptions instead of all s ubscriptions. Unfortunately, due to the diverse interests of publishers and subscr ibers, the semantic space associated with publications and subscriptions becomes high dimensional and very sparse. For example, in e-commence applications [2], there exists a variety of product items (as publications) and each item contains significantly different attributes; meanwhile subscribers define subscripti on conditions based on their very per-sonalized interests. Such publications and subscriptions lead to high dimensional and very sparse semantic space. Consequently, the full-space indexing structure such as R-Tree is inefficient to match publications against indexed subscriptions. Though the very recent work OpIndex [2] partially tacked the issue caused by the high dimensional and very sparse space, the base of OpIndex is fully built upon an assumption that pivot attributes needed by OpIndex must be known before the construction of OPIndex. Due to the decoupling and dynamic proper-ties of pub/sub, it is practically impossible to acquire the pivot attributes before subscriptions are registered and publications are published.

To overcome the above issue, we propose a novel coding approach to save the space cost subscription index and improve publication matching efficiency. As the main contribution of our work, the proposed coding approach can unify the optimization of subscription indexing and publication matching. By using a single approach, we can achieve the both goals without scarifying any of the both goals.

The rest of paper is organized as follows. Section 2 first gives the preliminaries and Section 3 reports the overview of our approach. After that, Sections 4 and 5 present the detail of subscription index and matching algorithm, respectively. Section 6 shows the evaluation and Section 7 finally concludes the paper. In this section, we introduce the data model and review related work. 2.1 Data Model There are three roles in a content-based pub/sub system: publishers , subscribers and brokers . Publishers are information provider, and publish information via publications . Subscribers are information consumer, and declare user interests via subscriptions . Brokers are responsible for the matching between subscrip-tions and publications, and next forward matching publications to subscribers of interest.

A publication consists of a set of attribute-value pairs. Each pair contains an attribute with its data type and a single value, and the size of a publication is the amount of pairs. A subscription consists of a collection of predicates. The size of a subscription is the amount of predicates. There are usually three elements in a predicate: an attribute A with its data type, an operator op andanoperand m . The example predicate int price &gt; 5 contains the attribute price ,operator &gt; and operand 5 . Table 1 gives a list of 7 subscriptions.

In this paper, we treat every predicate as a Boolean function f . It receives a publication e as an input parameter to evaluate the publication e . Given a subscription s with the size s , the subscription s matches the publication e on the condition that f ( e )= true for all predicates in s . For example, a publication price = 10 successfully matches a predicate price &gt; 5 . Formally, [4] gives the matching problem definition:  X  X iven a publication e and a set S of subscriptions, the matching problem is to find all subscriptions that are satisfied by e  X . 2.2 Related Work The classic work [4] divides the set of subscriptions into distinct predicates and builds indexes respectively based on equality predicates and non-equality pred-icates. It maintains a bit vector to r ecord whether a predicate is matched by an incoming publication. The key point of [4] is to pick out as few candidate subscriptions as possible. By the idea of schema-based subscription clustering, it organizes subscriptions into clusters by the size of subscriptions. In order to find clusters quickly, it defines a hash configuration to locate clusters using hash functions.

Sharing the very similar idea, [3] and [9] design a graph-based indexing struc-ture. The terminal node of the graph is the matching result. In the binary de-cision diagram[3], the non-terminal node represents a Boolean function (stand for a predicate), and each has two edges marked 0 and 1 to indicate whether the predicate is matched, and every terminal node is the final matching result for one subscription. To realize a matching tree[9], the first step is to divide a predicate into a test part and a result part, and the test part represents the non-terminal node; result represents the tree edge as we ll as the subscription itself represents the leaf node of the tree. For each incoming event, it will go through the tree. Each path that goes to the leaf node indicates the subscription in the leaf node matches the event.

The very recent work [2] is designed to ta ckle the sparse and high-dimensional subscription database. The aim of the index is to pick out as few subscriptions to process the matching algorithm as possible for each incoming event. The index mechanism uses two-level partition scheme, first is to partition subscriptions based on pivot attributes into subscription lists and second is to further partition the list to predicate lists based on predicate operators(= ,  X  ,  X  ). The definition for pivot attribute is to choose an attribute  X  A in a subscription that occurs the least times in event stream. The paper provides two optimizing approaches bit vector and hash function in second partition to quickly find the targeted predicates. There is also an counter referencing each subscription to judge whether it is fully matched to the incoming event. We first highlight the challenges of pub/sub systems. When given a huge amount of registered subscriptions, the pub/sub systems need to maintain a data struc-ture to index such subscriptions. Due to the huge amount of subscriptions, we would like to save the space cost of such an index. Meanwhile, when publica-tions arrive, the pub/sub systems matc h the incoming publications against the subscription index in order to find those matching subscriptions. Considering a high arriving rate of publications, the matching time is critical to optimize the throughput of pub/sub systems.

Until now, we have two optimization goals: the space cost of subscription index and running time of matching algorithm. Given the two goals, we propose a scheme to unify the two goals. The key of the proposed scheme is to design a coding approach to meet the two goals. First, the approach can compress the subscription index for lower space cost, and meanwhile the fast bitwise operations atop the coding approach can greatly speedup the matching algorithm for less running time.

Before going into the details in the following sections, we would like to give an overview of the proposed scheme Fig. 1 as follows. First, after subscribers register subscriptions into a pub/sub system, the system requires three steps to maintain an index for the registered subscriptions. First in step ( a.1 ), the system builds multiple matrices based on registered subscriptions. This step is to discrete the continuous ranges in subscriptions and then binary elements in the matrices. ( a.2 ) Due to the diverse interests of subscribers, the matrices in the previous step could be very sparse and lead to high space cost. Then we would like to compress the matrices for lower space cost. The key of this step is to design a coding approach for compression and we will focus on this part. ( a.3 ) Based on the compressed matrices, we finally build an indexing structure for registered subscriptions and such a structure uses less space cost than the compressed matrices.

Next, when a publisher publishes messages into a pub/sub system (step b.1 ), the system then evaluates the publications with help of the subscription index ( b.2 ) to select the candidates of matched subscriptions. The candidate selection algorithm can leverage machine bitwise operations atop the subscription index to avoid the expense scan of such an index. After that, the system finally refines such candidates for the matched subscriptions ( b.3 ).

During the above steps, the proposed coding approach not only helps com-pressing sparse matrices for lower space cost, but only optimizes the matching algorithm by machine bitwise operations for faster matching time. Therefore, we expect to achieve the two optimization goals by a single coding approach. In the rest of this paper, we will give the detail of the above steps. In this section, we give the details of three steps to index subscriptions. 4.1 Subscription Matrices In this section, we give an overview of the matric that is used to build the sub-scription index, and denote such a matrix as subscription matrix . Given a set of input subscriptions, we first group the subscriptions by the size of subscriptions. For example, given the 7 subscriptions in Table 1, we group such subscriptions by their size.

Now for each attribute appearing in a set of grouped subscriptions, we build a corresponding subscription matrix. In the subscription matrix associated with an attribute say A k (1  X  k  X  K )where K is the dimensionality of the pub/sub system semantic space), each row re presents a subscription containing A k ,and a column indicates a range of attribute values of A k . Given the columns of the subscription matrix, we discretize the allowable range of A i and set the element values of the matrix. In the i -th row and j -th column of a subscription matrix, the element e ij is a binary value by either 1 or 0. That is, if the predicate represented by the i -th row overlaps the range represented by the j -th column, we set e ij =1andotherwise e ij = 0. For example, suppose that the allowable range of attribute A is [1 , 200], and we discretize the range into 10 columns each of which has the granularity width 20. Then given the predicate { 1  X  A  X  7 } in S 1 of Table 1, we set the first elements by 1 and others by 0, as shown in Table 2(1). It is because the range [0 , 20) associated with the first column overlaps the predicate 1  X  A  X  7. Instead, for the predicate 3  X  A  X  200 in S 3 , we similarly set all elements from 1st column to 10-th column to be 1 and none of them zero. 4.2 Tuning Granularity During the above discretization, we note that the granularity decides the number of columns in the subscription matrix and thus the associated space cost. In this section, we focus on how to tune a reasonable granularity that is used to divide the allowable range of a given attribute A k .

We would like to first give a baseline solution to set the granularity before the proposed approach. Let us consider three subscriptions S 1 ,S 2 ,S 3 in Table 1. For the predicates on attribute A ,wehave s 1 : { 1  X  A  X  7 } ,s 2 : { 5  X  A  X  9 } and s 3 : { 3  X  A  X  200 } . Based on the predicates, we have the allowable range 1  X  A  X  200. Next, we might simply utilize the machine word length denoted by B (e.g., 32 bits or 64 bits) and set the granularity G = 200 /B . Just for simplicity and illustration, we consider the case that B =20andset G = 200 / 20 = 10. Following the setting, we have 10 columns in the subscription matrix of attribute A and the interval width is 20 as shown in Table. 2(1).

In the above figure, the three subscriptions S 1 , S 2 and S 3 all set the elements in the first column by 1. It is not hard to find that two of them cover the interval of only one columns. We will show that such a case will harm the matching efficiency. Depending on the tradeoff be tween the space cost of subscription matrix and matching time, we set a threshold t (e.g., t = 2) to set the minimal number of columns, such that any subscrip tion covers the associated intervals.
To overcome the above issue, we propose t o further divide the intervals of those columns covered by too many subscripti ons. Still following the above example, we further divide the interval of the first column into 10 sub-columns. Here the key is to ensure that the number of sub-columns is just equal to the one of the parent columns. As shown in Table 2(2), we have 10 sub-columns that are divided from the first column in Table 2(1). Based on the sub-columns, we can set the elements in the sub-columns when a subscr iption covers the interval associated with the sub-columns. Now, in Table 2(2), we find that the number of covered sub-column by any subscription is not smaller than the threshold t =2.
Finally, we consider the predicate in S 6 : A  X  4. Differing from the above three predicates, we have an infinity point in S 6 . Therefore, we define two special columns: UB and LB (i.e, short name for upper bound and lower bound. Then we can transform A  X  4into LB  X  A  X  4, and have Table 2(3). 4.3 Compressed Subscription Matrices Given the above subscription matrix, we note that the matrix could be very sparse. It is particularly true when subs cribers define personalized and diverse subscription conditions. Due to high s pace cost caused by a sparse matrix, we would like to compress the matrix for low space cost.

The basic idea of the proposed compre ssion is to treat the elements in each row of the above subscription matrix as binary bits and then encode the bits into integer numbers. For example, given Table 2(2), the row of S 1 is associated with the binary bits 0011100000. Given the 10 binary bits, given a base number b = 4, we then divide the 10 binary bits into three parts 0011, 1000 and 0000, which can be respectively encoded by three integers 3, 8 and 0. Now, instead of maintaining 10 elements for each subscription, we would like to maintain three integers, leading to less space cost. Besides the encoded numbers, we need to maintain the starting ID of the non-zer o encoded numbers, such that we can easily restore the original rows. Thus, the bits 0011100000 are encoded by three pairs 0 , 3 , 4 , 8 and 8 , 0 . For less space cost, we do not maintain the encoded numbers equal to zero, and thus maintain only two pairs 0 , 3 and 4 , 8 .
We note that by setting a larger base number for example b =8,wethen treat the entire 10 bits as the binary format of two integers 56 = (00111000) and 0. Since we not maintain the pairs with the encoded numbers equal to zero, the 10 bits can be maintained by only one pair 0 , 56 . Thus, a larger base number could help optimize the space cost for subscription matrix. Depending on the physical machine and operating system, we typically set b = 32 or 64. 4.4 Subscription Index In this section, we leverage the similarity of subscriptions to merge similar sub-scriptions (rows in the matrix) into single rows. In this way, we have chance to reduce the number of rows in a subscription matrix, and thus optimize the space cost of subscription matrices. Based on the compressed matrices with fewer number of rows, we design a subscription index.

Recall that each row (i.e., a subscription s i ) of a subscription matrix is asso-ciated with a set of binary bits. Given two subscriptions S i and S i ,wedenote the associated bits to be B i and B i , respectively. In case that the bits in B i are a subset of those in B i , we then merge the rows of such subscriptions together into a single one by adding subscription S i to the subscription list of S i .
Given an input matrix, we show how to build a subscription index by an iterative manner. First, for the matrix in the current iteration, we conduct the subscription merging operation on pairwise rows and form the new matrix in the next iteration. If the bits B i of s i are a subset of B i , then the two subscriptions S i and S i are merged together. We continue the merging process until no rows can be merged, and have the final subscription index.

By the merging operation over the 7 subscriptions in Table 1, we build a subscription index as shown in Table 3. The column partition for each attribute is not the same due to the different value ranges. In our design, there are 11 main columns for attribute A(details in Table 2), 5 main columns for attribute B and each stands for one enumerate value, 7 main columns for attribute C and value span is 10 for each column, as well as 8 columns for attribute D with value span of 1 and upper/lower bound signals. Therefore the start column ID for each attribute is 0,11,16 and 23 respectivel y. The start column ID stands for key in each key-value pair. As for each subscription, it will mark 0 or 1 in each column and get a compressed value for each attribute. Specifically, there has occurred sub columns division in column of ID 1 in attribute A as well, and it results in 2 key-value pairs for attribute A. The index format for s 5 is &lt; 23 , 3 &gt; , and it can definitely put into the relating list of s 7 .
 Based on the above coding scheme and subscription index, we highlight the proposed matching by using the very fast machine bitwise operation as follow. Consider subscription S 2 with the predicate A  X  [5 , 9] and a publication with at-tribute value A = 8 and the base number b = 8. If we follow Table 2(2) to divide the matrix, the predicate A  X  [5 , 9] is associated with the bits 0011100000. Since the point value 8 falls inside the interval [7 , 9), we then mark the 3-th column to 1 and all others 0, and have the bin ary bits 0001000000. Next , we conduct the machine bitwise operation AND : 0011100000 AND 0001000000 = 0001000000. We then determine that the publication successfully matches the predicate. Simi-larly, given another publication with attribute value A = 3 encoded by the bits 0100000000, we again co nduct the bitwis e operation 0011100000 AND 0100000000 = 0100000000 and infer that th e publication with A = 3 does not match the predicate.

Based on the above example, we find that the bitwise operation can help the matching algorithm. Specifically, for a specific attribute A ,wedenote B A ( s ) and B A ( s ) to be the bits encoded for the attribute value of a given publication e and predicate of a given subscription s , respectively. Then, it not hard to find that B A ( e ) AND B A ( s )= B A ( e ) is the necessary condition of the claim that s successfully matches e .Asaresult,if B A ( e ) AND B A ( s ) = B A ( e ), we then claim that s must fail to match e . Algorithm 1: Filtering Algorithm
Alg. 1 gives the pseudocode of the proposed matching algorithm. In the initi-ated state, there is an empty container f or each event that is prepared to store all the matched candidate subscription IDs(Line 1). Given a set of events E and for every event of the set, it first conv erts each event to the same format with subscription index, then comes the machine bitwise operation AND between each subscription index and the event(Line 3  X  9). Only if all the pairs in the index matches then the index as well as its relating list will put into the candidate container.

Events in the stream will first transform to key-value pairs before bitwise operation. Given an event: e 1 : A =2  X  B = { L } X  C =30  X  D = 10. It is to the column division in Table 3. Its start column ID is 0, 11 and 16. So bitwise operation is conducted on the three pair groups. The first pair group is We further check the pair of sub columns with start ID 1, the bitwise operation case. The next pair group is matched and the third is not in this way. After the three checks, the index is not regarded as the candidate for e 1 in the end. At last, s 6 and s 7 are matched, and s 5 will also put into the candidate container for it is in the relating list of s 7 .
 We evaluate the proposed comp ression-based m atching scheme (COMPME for short) and compare it with the recent w ork OPIndex [2]. The implementation of OPIndex is kindly provided by the author of the paper. For fairness, we im-plement COMPME in C and conduct the experiment on ubuntu 14.04. Follow-ing OPIndex [2], we generate all subscriptions and publications by uniformaly distributed datasets as OPIndex does. In our experiments, we vary the num-ber of subscriptions, attributes, maximal size of subscriptions( MSS for short) and events( MES for short) respectively, an d compare COMPME with OPIn-dex. The experiments are conducted in high dimension scene(i.e. attribute num-ber=20000)( H for short) as well as low dimension scene(i.e. attribute number is equal to MES )( L for short). In our setting, MES is always five times of MSS . Obviously, larger MSS and MES result in more memory cost, matching time and index building time. We conduct at least two cases of MSS and MES in each experiment to improve the experiment results. 1 Memory Usage : Fig. 2(a) shows the comparison of the memory usage be-tween COMPME and OPIndex by measuring the space cost of the source data of subscriptions and the index in high and low dimension scenes by setting the MSS (4) and MES (20). Fig. 2(b) is the experiment result of OPIndex,COMPME in high dimension scene to further approve the experiment result. Both figures show that the memory usage grows linearly with the number of subscriptions, and the memory usage of OPIndex is much larger than COMPME. 2 Matching Time : Fig. 2(c) is the comparison of the two algorithms in high-dimensional space. From the figure we can see that average match time is almost linear to the number of subscriptions. OP Index is more efficient with extremely small subscription size in very high dimension scene. Under the case of MSS (20) and MES (100), the time cost of OPIndex is much more than the other two cases while ours are more stable. We can conclude from the figure that as the sub-scription size becomes larger, the matching performance of OPIndex decreases sharply and COMPME becomes much more efficient than OPIndex.

Fig. 2(d) is the experiment result in low dimensional scene. As shown, the lines of COMPME almost overlap and its cost is much lower compared to OPIndex. The matching time in different dimensions varies a lot between the two algo-rithms. Fig. 2(e) directly approves that our algorithm is quite stable whenever in high and low dimensional space while OPIndex is much more efficient in high dimensional space. 3 Index Building Time : Building time in both algorithms includes reading subscription items from the external file a nd constructing relevant indexes. Fig. 2(f) shows the build time for the two algorithms. As shown, index build time is almost linear to the number of subscrip tions in all cases. And OPIndex is more efficient than our algorithm in building the subscription indexes.

However, there is a drawback in generating data in OPIndex X  X  algorithm that the two files are generated accordingly and the pivot nodes are selected in the generation step. Actually it is not possible in real pub/sub system. In our de-sign, events and subscriptions are generated independently and there is no pre-processing before executing building program and matching program. Therefore, our algorithm costs more build time than OPIndex in my experiment. In this paper, we design a novel filtering mechanism that integrates compression operation to store subscription indexes. The algorithm mainly aims to decrease space cost for index data structure while matching process stays effective and fast. Given a large scale of subscriptions and high rate of incoming event streams, the algorithm shows excellent performance in both building indexes, memory us-age and matching process.

We propose the idea of granularity to transform interval value to a point value and utilize the idea in [5] to do the compression job. The experiments are all executed in a single machine. My future plan is to improve and transplant the filtering mechanism to distributed system.

