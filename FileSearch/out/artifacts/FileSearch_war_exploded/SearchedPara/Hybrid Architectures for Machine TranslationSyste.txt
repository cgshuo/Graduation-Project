 GREGOR THURMAIR Abstract. Although some progress has been made on the quality of Machine Translation in recent years, there is still a significant potential for quality improvement. There has also been a shift in paradigm of machine translation, from  X  X  X lassical X  X  rule-based systems like METAL or LMT 1 towards example-based or statistical MT. 2 It seems to be time now to evaluate the progress and compare the results of these efforts, and draw conclusions for further improvements of MT quality.
 The paper starts with a comparison between statistical MT (henceforth: SMT) and rule-based MT (henceforth: RMT) systems, and describes the set-up and the evaluation results; the second section analyses the strengths and weaknesses of the respective approaches, and the third one discusses models of an architecture for a hybrid system.
 1. Baseline An experiment was performed to compare the current quality of different MT approaches to identify a baseline for further improvement. 3 It used a state-of-the-art statistical MT package, and a commercial rule-based MT system. The comparison was done using Translation Memory material, German to English, in the domain of the SAP R/3 system. The amount of data, more than 100.000 segments, seems to be sufficient to make meaningful statistical experiments.
 Aachen; this team had the best results in the Verbmobil project (Vogel et al ., 2000), and is a leading centre of statistical MT in Europe (Och and Ney 2001, 2003).
 material was split into a training corpus (with 1.068 mio German and 1.128 mio English tokens, representing 44.400 German and 26.600 English types, respectively). This was used as input for the alignment template SMT system to train the MT.
 of (randomly chosen) 14 tokens of length and containing no unknown words were selected. This resulted in 68 sentences. 4 rule-based MT system (linguatec X  X   X  X  X ersonal Translator X  X  German-to-Eng-lish, Version 2002).
 transfers only), such that this action should not influence the rest of the MT system (i.e. deteriorate the system quality on other texts in favour of the current experiment). This was done to meet the requirement that all words should be known (as it holds for the statistical MT). Coding took less than 10 minutes of time. No further tuning was done. 1.2.1. Evaluation Criteria There is a systematic difference in the evaluation criteria for the rule-based and statistical paradigm. Statistical approaches often use the cri-terion of a  X  X  X ord error rate X  X , which measures the distance of the MT output to some reference translation (e.g. in the BLEU score). 5 However, this pre-supposes that such a canonical translation exists, which is not the case; it is a basic assumption of translation science that the same text can, and even should, be translated very differently by different transla-tors, for different users, in different applications and contextual situa-tions: 6 Cf.: Here, A and B are both correct and possible, and a computation of a word error rate would not make too much sense. Also, the examples given below show that some RMT translations are perfectly acceptable, even if not identical to human translation.
 divides the MT output into three categories: 92 Such an evaluation scheme, or a similar classification, is a common standard in commercial MT development, and often used for quality assessment. 7 1.2.2. Evaluation Result Based on this evaluation metric, a comparison between the two approaches was made; the resulting figures are given in the following table; it shows the dis-tribution of the sentences for the three evaluation categories. Even if the amount of data on which the comparison is based is not very high, it seems that looking at more example sentences would not significantly change the global picture.
 1. It can be seen that the rule-based system produces significantly more 2. It can also be seen that there is a strong tendency in the statistical MT 3. What should also be seen, is a significant amount of incorrect output in Therefore it may be worthwhile to have a closer look at the output of the two types of system, in order to learn about the strengths and weaknesses of the respective approaches.
 2. Analysis 2.1. Statistical approaches This type of system basically works on chunks of input and assigns trans-lations running a language model over the target words. Correlations of such chunks in source and target are learned, and used to translate the test corpus. like in (29, 60). Such failures count for about 45% of the cases where translation quality was evaluated  X  X  X rong X  X . However, even if proper chunks are identified the translation fails in typical cases. Such failures can well be described in linguistic terms, i.e. they can be generalised ( X  X  X ule-based X  X ). Typical failures are: German verb order and Satzklammer (split verbs) phenomena. Verb phrases in subordinate clauses must go from sentence end in German to second position in English, and German Satzklammer verbs need to be contracted in English. Here the sys-tem is not able to build a proper verb phrase (5, 27, 58), or drops one verb part altogether (31, 19). 94 Constituent order: The system tends to keep the constituent order as in the source language (37, 68); cases where re-ordering is required (like in (63) where the German direct object is topicalised) tend to fail. Cf. also the wrong adverb placement in (57). Special constructions like German conditional clauses without subjunction (47). The system translates plain indicative. Pronouns have several transla-tions; the system tends to drop them altogether (22). Such mis-handlings are systematic, they are responsible for about 55% of the  X  X  X rong X  X  evaluations. Another systematic grammatical problem is to be mentioned, which is morphology. Several examples above (cf. 19, 31, 47) show that words are improperly inflected, e.g. in cases of number placement (singular/plural) or verb forms. This problem is aggravated if more mor-phology needs to be used: Statistical MT systems going from e.g. English into languages with richer morphology often fail in assigning proper number and case information to their target output, in particular if the case indicates some functional relationship (like functional subject/object).
 is able to collect proper translation proposals from the training corpus; this feature is exploited in systems for bilingual term extraction from aligned text. Sometimes wrong translations are given, however (4, 61, 64). 96 These systems try to do a full parse on the input, and identify the basic syntactic functions in the sentence which are used for translation. Translation is done by looking up the words in the transfer dictionary and generating a proper constituent structure and word inflection.
 Parse failures do not allow to identify the sentence parts, or do wrong assignment of syntactic functions (cf. 55, 53): The second main source of bad translations consists in lexical failres. This is not just that a word has no transfer entry in the dictionary; very often the problem is that there are several transfers in the dictionary and the system picks the wrong one. Examples are (10, 37, 57) In the tests mentioned above, about 60% of the  X  X  X rong X  X  evaluation for the rule-based MT system are due to the problem of incorrect lexical selection; so this source of errors seems to be at least as serious as the wrong-parse problem. 9 A sub-section of this problem is translation of prepositions. They are noto-riously difficult to translate, and there is knowledge involved which is not rule but collocation-based; cf. (27, 56, 58). In general, statistical MT seems to perform better in cases of translation selection than rule-based MT. It is more robust than the strategies of rule-based systems, and it never picks translations which are outside the domain (i.e. would simply not occur in a given corpus). Also, translation of prepo-sitions contains less errors in statistical than in rule-based MT. 10 Which conclusions can be drawn from this evaluation result for a MT architecture focusing on quality improvement? To answer this question, a short review of some MT challenges seems to be appropriate, identifying difficulties and solutions of the respective approaches. 2.3.1. Analysis 2.3.1.1. Input quality. Bad input quality causes problems for RMT systems; SMT systems tend to have advantages in this respect. 11 However, different types of input errors must be distinguished: spelling errors affect both SMT and RMT systems. The difference seems to be that RMT systems  X  X  X ropa-98 gate X  X  the error to the sentence level as they try to find a spanning interpre-tation for the whole sentence, while SMT systems do not do this and keep the error on a local, or phrase level. This seems to be one of the reasons why SMT systems have advantages in robustness. 2.3.1.2. Missing words. No system will cover all words in a given text, and the question is how systems cope with missing words in an input text. RMT systems try to default information on such terms (part of speech, inflection etc.) and run the risk of parse failures in case of unknowns; SMT systems will not find a matching pattern in the target language, and the missing word deteriorates the calculation of alignment probabilities for the whole segment significantly.
 dictionary quickly, this is less obvious for SMT systems; even if users can add terms to the system (cf. the LanguageWeaver system) 12 the statistical model on the basis of which such terms could be integrated is not really obvious. 2.3.1.3. Syntactic functions. Analysis consists of two logical steps: The first step identifies constituents or phrases, the second step assigns functional information to them. While the first level (part of speech tagging, constituent building) is well understood by both types of MT approaches, assignment of structural information to complete sentences, and, based on this, identifica-tion of syntactic X  X emantic functions of constituents, is only performed in RMT systems; attempts to integrate such information into statistical mod-elling have just started (cf. Och et al ., 2003). However, syntactic functions on the analysis side determine both constituent ordering as well as case marking in the target language, and the results of the evaluation above (longer dis-tance dependencies, case marking etc.) show clearly that the lack of quality of SMT results from the lack of a notion of syntactic function. 2.3.1.4. Textual relations. Focussing the analysis on one single sentence has always been felt to be an artificial limitation; and there is clear evidence that it leads to mistakes in translation if textual relations are not taken into account; this holds not just for anaphoric relations (pronouns, definiteness etc.), but also for thema X  X hema structures (Steiner et al ., 1988) and other features. Only few RMT systems, and no SMT system, work on these phe-nomena, although it is obvious that e.g. a missing or mis-referencing pronoun breaks the understanding of the complete sentence. 2.3.2. Transfer 2.3.2.1. Structural transfer. In structural transfer, systematic variations be-tween two languages have to be considered. There are three types of struc-tural transfer: 1. Constituent level regularities, e.g. the placement of adjectives (before 2. Sentence level regularities, like constituent ordering, are less well mas-3. There is a third kind of structural phenomena which requires the col-2.3.2.2 Lexical transfer. Two typical phenomena are considered here: mul-tiple transfers (a source term has more than one translations in the target language) and multiword concepts (one semantic unit is expressed by more than one word). 1. Multiple transfers means that one term can have several translations in On the other hand, SMT systems are restricted to one given application only, and their default heuristics is that there is just one translation for a given term, which is clearly an inadequate assumption, even in a specialised do-main. Translations which have alternatives tend to fall below the threshold of statistical correlation, and then are not used at all; however, approaches can be found to overcome this deficiency, e.g. by using domain frequency information (Samiotou et al ., 2004). 2. Multiword concepts are concepts which have non-matching syntactic 100 While both RMT and SMT systems started with just single word corre-spondences, both approaches have overcome these drawbacks; however, it should be noted that systems which relate only single words are conceptually inadequate. 2.3.3. Generation Generation for RMT systems means to build surface strings from some for-mal representations (tree structures, formal predicates). While the strategic part (i.e. what to generate) is already solved in an MT environment (as defined by the source part of the system), the tactical part (i.e. how to say it, cf. Jablonski et al. , 1990) relies on the terms to be used in the target, and on their syntactic X  X emantic relations, expressed in some  X  X  X eep-structure X  X  description, and mainly face the tasks of constituent ordering and case marking.  X  X  X onvert English subject X  X erb X  X bject order into German subject X  X bject X  verb order for subordinate clauses, and mark the object with accusative affixes X  X ). SMT systems do not do this. They start with a set of target phrases with no additional information, and usually use language models for gen-eration, with limited scope and knowledge. It is not straightforward to see how a generation component for SMT could be improved without a notion of the basic generation parameters (esp. syntactic functions), which are determined on the analysis side of the system. 13 2.3.4. Adaptation issues Most people agree that a general-purpose high-quality MT system does not (yet) exist; however there are very successful special-purpose MT systems which reach error rates comparable or even lower than those of human translators. 14 Tuning MT systems for different domains is therefore an issue to be considered as it strongly influences translation quality. A major factor here is the effort involved. It is worth noting that the SMT and RMT ap-proaches start from different sides of the problem: SMT systems start (and end) focussing on specific domains, represented by a given text corpus. 15 Changing the domain means to build a new system, on the basis of a new text corpus; multi-domain MT system means either to maintain several statistical models in parallel, and select the most appropriate one for a given input situation, or create a really general purpose SMT system, covering multiple domains in one model. So the effort here depends on (the availability of resources and) the number of domains to be covered.
 the rules of a language hold for all its special domains), and must provide means for tuning  X  X  X own X  X  into different domains. The effort to do this con-sists mainly in dictionary adaptation, and significant progress has been made in making this process efficient (extraction of unknown terms, defaulting of linguistic features 16 etc.). Overall, the efforts to set up an MT system for a specific domain seem to be comparable. 17 However, for new language directions, RMT systems need more ramp-up time, and SMT systems have the clear advantage here that results are available earlier, because it takes time to build language resources for a new translation direction. 18 3. Architecture Issues Given the situation just described, the question is how an architecture for an MT system could look like which integrates the best elements of the existing approaches into a hybrid architecture. Taking a principle-based point of view for a moment, it is well understood in the tradition of linguistic theory (Chomsky, 1957 and before) that there is a difference in language between competence , i.e. the ability of a language participant to create new sentences, by applying rules, and performance , i.e. the language use, the behaviour of selecting and preferring rules, combining them to some idiosyncratic output, forming collocations, etc.
 on the former aspect, SMT systems seem to focus on the later. Linguistic tradition, however, insists that both aspects are necessary to fully describe the language capabilities, and so should NLP systems do when trying to model them. Extensions of current architectures are available in both directions: enriching SMT systems with linguistic knowledge, and enriching RMT systems with probabilistic information. 1. Adding linguistic information to an SMT system is possible in two 102 2. Adding probabilistic information to RMT systems is mainly an issue of Such a system would use the mechanism of statistical correlations of phrases in source and target, but add some intelligence (i.e. aspects of language competence ) to such patterns, by analysing them in more detail linguistically, and using such annotations when creating proper target language expressions. cases, this information must be attached to the phrase patterns used by statistical processing.
 There are two principal ways how this could be performed: to take more knowledge into statistical processing, or to run a validation/evaluation step after statistical analysis.

The first approach has already been examined; recent publications try to integrate syntactic knowledge into the statistical analysis. (Och et al ., 2003) report on work whereby shallow and deep syntactic features were sup-posed to be detected, dependency trees and their correlations were exam-ined, in order  X  X  X o integrate better models of syntactic structure into statistical models for machine translation X  X  (Och et al. , 2003: 101). The material was taken from English and Chinese resources, like tree banks and other sources of annotated corpora.

Although it turned out that such an approach is computationally expensive even for short sentences, and that the results stay close to the baseline, 20 this work documents that there is growing importance of the field of hybrid MT.

A second approach would insert a phase of  X  X  X econd analysis X  X  where the (n best) phrases identified by the SMT system would undergo some linguistic evaluation which would analyse and validate them (e.g. in terms of syn-tactic functions). Such annotations then would be used in the target sen-tence generation, for constituent ordering, case marking, number and agreement generation, etc. The amount of information to be generated will depend on the requirements of the generation component, and may be different for different language pairs.

Such a system has not been proposed yet, and there are many topics left for research, e.g. the relationship of statistical target phrase selection and result of linguistic analysis (e.g.: best matching phrase is in plural, linguistic analysis states it should be singular), or the question of automatically assigning annotation patterns for certain input structures. This approach would try to add aspects of language performance to the aspects of language competence as documented in the rule base of the system. It would use a standard transfer-based approach, dividing the translation process into the phases of analysis, transfer, and generation; but each of these phases would be re-modelled.
 performance aspect would lie in making use of the observed frequency with which such rules would fire, and in other properties of the input data (like collocations, frequency aspects in PP-attachment etc.). This requirement would also influence the way how rules are designed. 21 In addition, it would lead to a revision of the treatment of parse failures, and create nice robust fallback possibilities.
 modelled. The current approach of selecting transfer alternatives by using a series of semantic X  X yntactic tests down to some default translation would have to be reviewed in the light of target language performance aspects: target vocabulary selection, identification of target collocations, idiosyncratic translations of prepositions etc., would have to be researched there. used in the target language, by analysing typical patterns of the target lan-guage and measuring the distance between the generated target text the  X  X  X eal target language, as in the ESTeam system. 22  X  X  et al. , 2001) present an approach for example-based MT, starting from a classical rule-based source text analysis, and trying to find transfer selection based on a statistically created knowledge structure called  X  X  X indNet X  X  which combines lexical, statistical, and linguistic information. The goal of the ap-proach was to show that tuning of a system to a new domain can be done very efficiently (in a few days).
 104 partial implementations have been tried, and again, significant research areas are left, like the relationships between linguistic transfer tests and statistical transfer selection. Also, as most of the SMT systems are restricted to a single domain, it needs to be investigated what kind of data such hybrid systems could be based on, in order to keep the generality of current RMT systems. Given the growing amount of foreign language information e.g. in the in-ternet, there is growing demand for automatic translation tools. While sig-nificant progress has been made to make MT an easy-to-integrate software component, 23 the critical success factor for machine translation is still quality. The examples above show that the existing approaches leave room for improvement, and that hybrid architectures for MT could be interesting if quality is in the focus of research.
 Notes 106 References
