 Clustering Analysis is an important way in knowledge discovery fields. A cluster is a between clusters. The degree of similarity is usually described by the distance between objects. The greater is the distance, the smaller the similarity is, vice versa. An ideal algorithms have been proposed in the past years. The existing methods can be classified density-based methods, grid-based methods, model-based methods [1]. The typical algorithms are K-means algorithm [2], CURE algorithm [3], DBSCAN algorithm [4], CLIQUE algorithm [5], BIRCH algorithm [6] [7], etc.. They solve some specific problems by specific methods. However, the multi-layer clustering of high dimensional data with arbitrary shape is also a challenge research fields. This paper proposes an improved nearest distance clustering algorithm X  X earest Neighbors Absorbed First (NNAF) based on the idea of objects in the same cluster must be near. approach or top-down approach. The former starts with each object forming a separate group. Then it successively merges the objects or groups close to one another, until all hierarchical clustering algorithms are BI RCH algorithm, CURE algorithm, Shortest Distance algorithm [8], CHAMALEON algorithm [9], and so on so forth. 
There are some common features among NNAF algorithm and Shortest Distance algorithm. In the Shortest Distance algorithm, in order to get the nearest neighbors of And it can not process noisy data efficiently. With these statements in mind, NNAF algorithm that can process efficiently cluste ring with arbitrary shape and noisy data is domain knowledge. 3.1 Definitions Definition 1. Given a dataset V in a high dimensional space and distance threshold d, where d&gt;0, V  X  {p 1 , p 2 , ... ,p n }  X  then 
The basic idea of NNAF algorithm is classifying the two objects satisfying NN (p 1 )= p cluster, then the two clusters recombine into one new cluster and all objects that belong to the two clusters are classified into the new cluster. Definition 2 . Given a dataset V  X  {p 1 , p 2 , ... ,p n }, where p i  X  V, p k  X  V: 
Emerging nearest neighbor to each other or classified nearest neighbor is the clustering termination condition of NNAF. 3.2 Nearest Neighbors Searching (SNN) Algorithm To avoid comparing the distance between one object to all other else when searching its Using SNN algorithm, the nearest neighbors can be found by only comparing the distances from one object to the objects in its  X  domain. p  X  V , p dimension of p. Corollary 1. Suppose p and q are two objects in n-dimensional space and the project of the distance from p to q on a dimension is d. If p is in the d domain region of q, namely D(p, q)  X  d, then the coordinates of p is same as that of q on other dimensions. algorithm based on corollary 1. Algorithm 1. Searching Nearest Neighbors (SNN) certain-dimension, which is denoted by sorted dimension; distance threshold d. Output: T he 5-tuple attributes of all objects, where Cluster=NULL, the objects in the attributes of Neighbors and Reverse-Neighbors is that the distance holds the distance threshold. 
By SNN, it does not need calculate the dist ance from one object to all others and only compare the distance from it to the objects in a small domain of it. Thus the computing speed is increased greatly. The time complexity of SNN is O(n*log(n)). If the objects are obtained by scanning image, the data ha s been sorted after scanning. So the time complexity will be O (n). However, that of Shortest Distance algorithm by comparing threshold d, the algorithm only needs search the nearest neighbors of outliers that have been found in the last time by SNN. 3.3 Nearest Neighbors Abso rbed Firstly (NNAF) Algorithm The idea of NNAF is described as follows: At first, an object Obj1 is classified into a cluster, then all nearest neighbors of Obj1 and the objects whose nearest neighbor is Obj1 are added in the cluster. Finally, all the nearest neighbors of the objects that have been added in the cluster and the objects whose nearest neighbors are the objects that process until no objects add in this cluster. In other words, all the nearest neighbors of the objects in this cluster and the objects whose nearest neighbors are the object in this classified into a new cluster and performing the clustering follows the above way, until all objects have been added in a certain cluster. The clustering is finished. Algorithm 3. NNAF algorithm Output: the attribute Cluster of every object following the idea described above. 
In NNAF algorithm, getting the clusters need scan the database only once with the O(n*log(n)). Therefore the total time complexity is O(n*log(n)). When the objects are obtained by scanning image, the time complexity will decrease to O(n). 3.4 Algorithm Analysis needs two thresholds. The values of the thresholds can be tried many times until the satisfied clustering is obtained. 
The clustering based on the nearest neighbors in NNAF has nothing to do with the dimensionality. The time complexity of the algorithm is O(n) since it scans the database only once. The sum of the time complexity is O(n*log(n)) after adding the searching nearest neighbors time. All of our experiments are conducted on a PC with Intel Pentium III 1GHZ processor and 256 MB memory, which runs Windows XP professional operation system. The initial data of 2-dimensional is shown as Figure 1. It is obviously there are many noisy Figure 2 by NNAF. 
In this experiment the distance threshold is 2. When it is over 2 the clustering result is nearly the same one. It is because the nearest neighbors can not change however the distance threshold increases when the distance from data to their nearest neighbors are dramatically by increasing the distance threshold. 
The experimental results show that the algorithms proposed in this paper can solve efficiently the clustering problem with arbitrary shape and noisy data. 
Two methods of searching nearest neighbor s are used in order to evaluate the performance of SNN. The first one is SNN and the second one is the traditional method. The traditional method is the method which finds the nearest neighbors of every object by comparing all the distances from it to all the other else. The experimental results are shown in Table 1. In Table1 the first column is the number of data, the second and the third columns are the time being used by the two methods respectively. The time unit is millisecond. We can see that SNN is better than the traditional algorithm. It is should be stated that the data comes from scanning Figure 1. The sorting time is saved since the data have been sorted by coordinates after scanning. Although the sorting time is add the SNN is also faster than the traditional algorithm. Because the time complexity of traditional algorithm is O  X  n 2  X  and that of the SNN is O(n*log(n)). In summary, a serial of algorithms about clustering on higher dimension and some related theorems are proposed in this paper. The experiment results indicate that the algorithms are reasonable and can produce satisfied clustering over various granularities. NNAF is also an effective clustering algorithm. 
