 Privacy and security concerns can prevent sharing of data, derailing data mining projects. Distributed knowledge dis -covery, if done correctly, can alleviate this problem. The k ey is to obtain valid results, while providing guarantees on th e (non)disclosure of data. We present a method for k -means clustering when different sites contain different attribute s for a common set of entities. Each site learns the cluster of each entity, but learns nothing about the attributes at othe r sites.
 H.2.8 [ Database Management ]: Database Applications X  Data mining ; H.2.7 [ Database Management ]: Database Administration X  Security, integrity, and protection ; H.2.4 [ Database Management ]: Systems X  Distributed databases Security Privacy
Data mining and privacy are often perceived to be at odds, witness the recent U.S. Senate proposal of a  X  X ata Min-ing Moratorium Act X  X 11]. Data mining results rarely vio-late privacy, as they generally reveal high-level knowledg e rather than disclosing instances of data. However, the con-cern among privacy advocates is well founded, as bringing data together to support data mining makes misuse easier. The problem is not data mining, but the way data mining is done.

Imagine the following scenario. A law enforcement agency wants to cluster individuals based on their financial trans-actions, and study the differences between the clusters and known money laundering operations. Knowing the differ-ences and similarities between normal individuals and know n money launderers would enable better direction of investig a-tions. Currently, an individual X  X  financial transactions m ay be divided between banks, credit card companies, tax collec -tion agencies, etc. Each of these (presumably) has effective controls governing release of the information. These contr ols are not perfect, but violating them (either technologicall y or through insider misuse) reveals only a subset of an individ-ual X  X  financial records. The law enforcement agency could promise to provide effective controls, but overcoming these controls now gives access to an individual X  X  entire financia l history. This raises justifiable concerns among privacy ad-vocates.

Privacy and data mining can coexist. The problem with the above scenario is not the data mining results, but how they are obtained. Current U.S. regulations require banks to report certain transactions (e.g., large cash deposits) , but law enforcement does not have full access to accounts. If the results were obtained without sharing information, betwee n the data sources, and the results could not be used to deduce private information, data mining would not reduce privacy. Using these results to devise more effective regulations on what transactions must be reported could actually improve both privacy and the ability to detect criminal activity.
While obtaining globally meaningful results without shar-ing information may seem impossible, it can be done. Al-gorithms have been developed to efficiently solve several types of distributed computations in a secure manner. This paper presents a method for k -means clustering in scenar-ios like the above, demonstrating how results from secure multiparty computation can be used to generate privacy-preserving data mining algorithms. We assume vertically partitioned data: The data for a single entity are split across multiple sites, and each site has information for all the ent i-ties for a specific subset of the attributes. We assume that the existence of an entity in a particular site X  X  database may be revealed, it is the values associated with an entity that are private. The goal is to cluster the known set of com-mon entities without revealing any of the values that the clustering is based on.

K -means clustering[9, 13] is a simple technique to group items into k clusters. The basic idea behind k -means clus-Figure 1: Two dimensional problem that cannot be decomposed into two one-dimensional problems. tering is as follows: Initialize the k means  X  1 . . .  X  k to 0.

Arbitrarily select k starting points  X  0 1 . . .  X  0 k repeat until the difference between  X  1 . . .  X  k and  X  0 1 . . .  X  ceptably low.
 Each item is placed in its closest cluster, and the cluster centers are then adjusted based on the data placement. This repeats until the positions stabilize.

The results come in two forms: Assignment of entities to clusters, and the cluster centers themselves. We assume tha t the cluster centers  X  i are semiprivate information, i.e., each site can learn only the components of  X  that correspond to the attributes it holds. Thus, all information about a site X  X  attributes (not just individual values) is kept priv ate; if sharing the  X  is desired, an evaluation of privacy/secrecy concerns can be performed after the values are known.
At first glance, this might appear simple  X  each site can simply run the k -means algorithm on its own data. This would preserve complete privacy. Figure 1 shows why this will not work. Assume we want to perform 2-means clus-tering on the data in the figure. From y  X  X  point of view (looking solely at the vertical axis), it appears that there are two clusters centered at about 2 and 5.5. However, in two dimensions it is clear that the difference in the horizont al axis dominates. The clusters are actually  X  X eft X  and  X  X ight  X , with both having a mean in the y dimension of about 3. The problem is exacerbated by higher dimensionality.

Given a mapping of points to clusters, each site can inde-pendently compute the components of  X  i corresponding to its attributes. Assigning points to clusters, specifically com-puting which cluster gives the minimum d ( i,  X  j ), requires cooperation between the sites. We show how to privately compute this in Section 2.1. Briefly, the idea is that site A generates a (different) vector (of length k ) for every site (including itself) such that the vector sum of all the site ve c-tors is ~ 0. Each site adds its local differences | point  X   X  its vector. At the same time, the vector is permuted in an order known only to A . Each site (except a single holdout) sends their permuted vector to site B . Site B sums the re-ceived vectors, then the holdout site and B perform a series of secure additions and comparisons to find the minimum i without learning distances. B now asks A the real index corresponding to i , giving the proper cluster for the point.
The second problem is knowing when to quit, i.e., when the difference between  X  and  X  0 is small enough; we show how to privately compute this in Algorithm 2. This makes use of secure sum and secure comparison, described in Sec-tion 2.3. We will begin with details of the algorithm. We will introduce background work as necessary, particularly in the security discussion of Section 3. We discuss mitigating the risks from colluding parties in Section 4, and communi-cation cost in Section 5. We conclude with a discussion of related work, as well as suggestions for future research.
We now formally define the problem. Let r be the number of parties, each having different attributes for the same set of entities. n is the number of the common entities. The parties wish to cluster their joint data using the k -means algorithm. Let k be the number of clusters required.
The final result of the k -means clustering algorithm is the value/position of the means of the k clusters, with each side only knowing the means corresponding to their own attributes, and the final assignment of entities to clusters .  X  ij represent the projection of the mean of cluster i on party j . Thus, the final result for party j is
The k -means algorithm also requires an initial assignment (approximation) for the values/positions of the k means. This is an important issue, as the choice of initial points de -termines the final solution. Research has led to mechanisms producing a good initial assignment [4]. Their technique uses classic k -means clustering done over multiple subsam-ples of the data, followed by clustering the results to get th e initial points. For simplicity, we assume that the k means are selected arbitrarily. Since the underlying operations in [4] involve k -means clustering, it is quite easy to extend our algorithm to search for and start off with good initial means.
Thus, for i = 1 . . . k , every party selects its share  X  any given mean. This value is local to each party and is unknown to the other parties.

The basic algorithm directly follows the standard k -means algorithm. The approximations to the true means are itera-tively refined until the improvement in one iteration is belo w a threshold. At each iteration, every point is assigned to th e proper cluster, i.e., we securely find the cluster with the mi n-imum distance for each point (this is described in Section 2.1.) Once these mappings are known, the local components of each cluster mean can be computed locally. We then use Algorithm 2 ( checkT hreshold ) to test termination: was the improvement to the mean approximation in that iteration below a threshold? This is shown formally in Algorithm 1. Algorithm 1 Privacy Preserving k -means clustering Require: r parties, k clusters, n points. 1: for all sites j = 1 . . . r do 2: for all clusters i = 1 . . . k do 3: initialize  X  0 ij arbitrarily 4: end for 5: end for 6: repeat 7: for all j = 1 . . . r do 8: for i = 1 . . . k do 10: Cluster [ i ] =  X  11: end for 12: end for 13: for g = 1 . . . n do 14: for all j = 1 . . . r do 15: { Compute the distance vector ~ X j (to each clus-16: for i = 1 . . . k do 17: x ij = | data gj  X  D  X  ij | 18: end for 19: end for 20: Each site puts g into Cluster [ closest cluster ] 21: end for 22: for all j = 1 . . . r do 23: for i = 1 . . . k do 24:  X  0 ij  X  mean of j  X  X  attributes for points in 25: end for 26: end for 27: until checkT hreshold { Algorithm 2 } Algorithm 2 checkThreshold: Find out if the new means are sufficiently close to old means Require: T h is a threshold for termination, Random 1: for all j = 1 . . . r do 2: d j  X  0 3: for i = 1 . . . k do 5: end for 6: end for 7: { Securely compute if P d j  X  T h . } 8: At P 1 : m = rand() 9: for j=1 . . . r-1 do 10: P i sends m + d j (mod n ) to P j +1 11: end for 12: At P r : m = m + d r 13: At P 1 : T h 0 = T h + r 14: P 1 and P r return secure add and compare ( m  X  T h 0
The checkT hreshold algorithm (Algorithm 2) is straight-forward, except that to maintain security (and practical-ity) all arithmetic must be mod n . This results in a non-obvious threshold evaluation at the end, consisting of a se-cure addition/comparison. Intervals are compared rather than the actual numbers. Since T h &lt; n/ 2 and the domain than n/ 2, and if it is negative, due to the modulo operation, if and only if m &lt; T h 0 , and the correct result is returned.
This algorithm is used as a subroutine in the k -means clustering algorithm to privately find the cluster which is closest to the given point, i.e., which cluster should a poin t be assigned to. Thus, the algorithm is invoked for every single data point in each iteration. Each party has as its input the component of the distance corresponding to each of the k clusters. This is equivalent to having a matrix of distances of dimension k  X  r . For common distance metrics; such as Euclidean, Manhattan, or Minkowski; this translate s to finding the cluster where the sum of the local distances is the minimum among all the clusters.

The problem is formally defined as follows. Consider r parties P 1 , . . . , P r , each with their own k -element vector P 1 has ~ X 1 = The goal is to compute the index l that represents the row with the minimum sum. Formally, find For use in k -means clustering, x ij = |  X  ij  X  point j | , or site P  X  X  component of the distance between a point and the cluster i with mean  X  i .

The security of the algorithm is based on three key ideas. 1. Disguise the site components of the distance with ran-2. Compare distances so only the comparison result is 3. Permute the order of clusters so the real meaning of The algorithm also requires three non-colluding sites. The se parties may be among the parties holding data, but could be external as well. They need only know the number of sites r and the number of clusters k . Assuming they do not collude with each other, they learn nothing from the algorithm. For simplicity of presentation, we will assume the non-colludi ng sites are P 1 , P 2 , and P r among the data holders. Using external sites, instead of participating sites P 1 , P 2 and P to be the non-colluding sites, is trivial.

The algorithm proceeds as follows. Site P 1 generates a length k random vector ~ V i for each site i , such that P ~ 0. P 1 also chooses a permutation  X  of 1 ..k . P 1 then engages each site P i in the permutation algorithm (see Section 2.2) to generate the sum of the vector ~ V i and P i  X  X  distances The resulting vector is known only to P i , and is permuted know  X  or ~ V i . P 1 and P 3 . . . P r  X  1 send their vectors to P
Sites P 2 and P r now engage in a series of secure addition / comparisons to find the (permuted) index of the mini-mum distance. Specifically, they want to find if P r i =1 v closest to the point. P r has all components of the sum ex-cept ~ X 2 + ~ V 2 . For each comparison, we use a secure circuit evaluation (see Section 2.3) that calculates a 2 + a r &lt; b without disclosing anything but the comparison result. Af-ter k  X  1 such comparisons, keeping the minimum each time, the minimum cluster is known.

P 2 and P r now know the minimum cluster in the permuta-tion  X  . They do not know the real cluster it corresponds to (or the cluster that corresponds to any of the others items in the comparisons.) For this, they send the minimum i back to site P 1 . P 1 broadcasts the result  X   X  1 ( i ), the proper cluster for the point.
 The full algorithm is given in Algorithm 3. Several opti-Algorithm 3 closest cluster : Find minimum distance clus-ter Require: r parties, each with a length k vector ~ X of dis-1: { Stage 1: Between P 1 and all other parties } 2: P 1 generates r random vectors ~ V i summing to ~ 0 (see 3: P 1 generates a random permutation  X  over k elements 4: for all i = 2 . . . r do 5: ~ T i (at P i ) = add and permute ( ~ V i ,  X  (at P 1 ) , 6: end for 7: P 1 computes ~ T 1 =  X  ( ~ X 1 + ~ V 1 ) 8: 9: { Stage 2: Between all but P 2 and P r } 10: for all i = 1 , 3 . . . r  X  1 do 11: P i sends ~ T i to P r 12: end for 13: P r computes ~ Y = ~ T 1 + P r i =3 ~ T i 14: 15: { Stage 3: Involves only P 2 and P r } 16: minimal  X  1 17: for j=2..k do 18: if secure add and compare ( Y j + T 2 j &lt; Y minimal 19: minimal  X  j 20: end if 21: end for 22: 23: { Stage 4: Between P r (or P 2 ) and P 1 } 24: Party P r sends minimal to P 1 25: P 1 broadcasts the result  X   X  1 ( minimal ) mizations are possible, we discuss these when analyzing the complexity of the algorithm in Section 5. We now describe the two key building blocks borrowed from the Secure Multi-party Computation literature. We first give the permutation algorithm. We then describe the secure addition compari-Algorithm 4 genRandom: Generates a (somewhat) ran-dom matrix V k  X  r Require: Random number generator rand producing val-Ensure: The sum of the resulting vectors is ~ 0. 1: for all i = 1 . . . k do 2: P artSum i  X  0 3: for j = 2 . . . r do 4: V ij  X  rand () 5: P artSum i  X  P artSum i + V ij (mod n ) 6: end for 7: V i 1  X  X  X  P artSum i (mod n ) 8: end for son, which builds a circuit that has two inputs from each party, sums the first input of both parties and the second input of both parties, and returns the result of comparing the two sums. This (simple) circuit is evaluated securely using the generic algorithm described in Section 2.3. Fol-lowing these, we will prove the security of the method. A graphical depiction of stages 1 and 2 is given in Figures 2 and 3. The secure permutation algorithm developed by Du and Atallah simultaneously computes a vector sum and permutes the order of the elements in the vector. We repeat the idea here for completeness, for more details see [7]. We do presen t a more formal proof of the security of the algorithm than that in [7], this is given as part of the overall security proo f of our algorithm in Section 3.2.

The permutation problem is an asymmetric two party al-gorithm, formally defined as follows. There exist 2 parties, A and B . B has an n -dimensional vector ~ X = ( x 1 , . . . , x and A has an n -dimensional vector ~ V = ( v 1 , . . . , v has a permutation  X  of the n numbers. The goal is to give B the result  X  ( ~ X + ~ V ), without disclosing anything else. In particular, neither A nor B can learn the other X  X  vector, and B does not learn  X  . For our purposes, the ~ V is a vector of random numbers from a uniform random distribution, used to hide the permutation of the other vector.
 The solution makes use of a tool known as Homomorphic Encryption . An encryption function H : R X  X  is called ad-ditively homomorphic if there is an efficient algorithm Plus to compute H ( x + y ) from H ( x ) and H ( y ) that does not reveal x or y . Many such systems exist; examples include systems by Benaloh[3], Naccache and Stern [24], Okamoto and Uchiyama[25], and Paillier [26]. This allows us to per-form addition of encrypted data without decrypting it.
The permutation algorithm consists of the following steps: 1. B generates a public-private keypair ( E k , D k ) for a 2. B encrypts its vector ~ X to generate the encrypted vec-3. B sends ~ X 0 and the public key E k to A . 4. A encrypts its vector ~ V generating the encrypted vec-5. A now multiplies the components of the vectors ~ X 0 6. A applies the permutation  X  to the vector ~ T 0 to get 7. B decrypts the components of ~ T 0 p giving the final result Secure two party computation was first investigated by Yao [29] and was later generalized to multiparty compu-tation. The seminal paper by Goldreich proves that there exists a secure solution for any functionality[15]. The ap-proach used is as follows: the function f to be computed is first represented as a combinatorial circuit, and then the parties run a short protocol for every gate in the circuit. Ev -ery participant gets (randomly selected) shares of the inpu t wires and the output wires for every gate. Since determining which share goes to which party is done randomly, a party X  X  own share tells it nothing. Upon completion, the parties exchange their shares, enabling each to compute the final result. This protocol can be proven to both give the desired result and to do so without disclosing anything other than the result. This approach, though appealing in its generali ty and simplicity, means that the size of the protocol depends on the size of the circuit, which depends on the size of the input.

This is impractical for large inputs and many parties, as in data mining. However, for a limited number of simple two-party operations, such as the secure add and compare func-tion used in Algorithms 2 and 3, the complexity is reason-able. For two parties, the message cost is O ( circuit size ), and the number of rounds is constant. We can add and com-pare numbers with O ( m = log( number of entities )) bits using an O ( m ) size circuit. We first need to define formally what we mean by secure. For this, we turn to the definitions of Secure Multiparty Computation.
To prove that our k -means algorithm preserves privacy, we need to define privacy preservation. We use the framework defined in Secure Multiparty Computation .

Yao first postulated the two-party comparison problem (Yao X  X  Millionaire Protocol) and developed a provably se-cure solution[29]. This was extended to multiparty compu-tations by Goldreich et al.[15]. They developed a framework for secure multiparty computation, and in [14] proved that computing a function privately is equivalent to computing it securely.

We start with the definitions for security in the semi-honest model. A semi-honest party follows the rules of the protocol using its correct input, but is free to later use wha t it sees during execution of the protocol to compromise secu-rity. A formal definition of private two-party computation in the semi-honest model is given below.
 Definition 1. (privacy w.r.t. semi-honest behavior):[14]
Let f : { 0 , 1 }  X   X  { 0 , 1 }  X  7 X  X  X  { 0 , 1 }  X   X  { 0 , 1 } abilistic, polynomial-time functionality, where f 1 ( x, y ) (re-spectively, f 2 ( x, y )) denotes the first (resp., second) element of f ( x, y )); and let  X  be two-party protocol for computing f .

Let the view of the first (resp., second) party during an ex-ecution of protocol  X  on ( x, y ), denoted view  X  1 ( x, y ) (resp., view  X  2 ( x, y )), be ( x, r 1 , m 1 , . . . , m t ) (resp., ( y, r r represent the outcome of the first (resp., r 2 the second) party X  X  internal coin tosses, and m i represent the i th message it has received.

The output of the first (resp., second) party during an execution of  X  on ( x, y ) is denoted output  X  1 ( x, y ) (resp., output  X  2 ( x, y )) and is implicit in the party X  X  view of the ex-ecution.
 X  privately computes f if there exist probabilistic polyno-mial time algorithms, denoted S 1 , S 2 such that where  X  C denotes computational indistinguishability.
The above definition states that a computation is secure if the view of each party during the execution of the protocol can be effectively simulated knowing only the input and the output of that party. This is not quite the same as saying that private information is protected. If information can b e deduced from the final result, it is obviously not kept privat e under this definition. For example, if two entities map to different clusters, they must have some attribute values tha t are different. If one site has exactly the same values for thos e entities, it has learned the  X  X rivate X  information that tho se entities have different values in the attributes held by some other site. This cannot be helped, as this information can always be deduced from the result and the site X  X  own input.
A key result we use is the composition theorem. We state it for the semi-honest model. A detailed discussion of this theorem, as well as the proof, can be found in [14].
Theorem 1. (Composition Theorem for the semi-honest model): Suppose that g is privately reducible to f and that there exists a protocol for privately computing f. Then ther e exists a protocol for privately computing g.
 Proof. Refer to [14].

Our protocols are somewhat stronger than the semi-honest model. The proofs hold in any situation where the parties do not collude to discover information; a single malicious party may disrupt the results, but cannot learn private in-formation that would not be revealed by the result. This will become apparent in the proofs below.
The permutation algorithm reveals nothing to A , so A  X  X  view must be simulated using only it X  X  own input. B gets the result vector.

Theorem 2. The Permutation Algorithm (Section 2.2) privately computes a permuted vector sum of two vectors, where one party knows the permutation  X  and the other gets permuted sum  X  ( ~ X + ~ V ) .
 Proof.
 A s view: A receives an encryption key E k and a encrypted vector ~ of size n . It can simulate the encryption key by generating a single random number from a uniform random distribution. Assuming security of encryption and since A knows the n , the vector ~ X 0 can also be simulated simply by generating n randoms from an uniform distribution. Using its own vector ~ V and the simulated input, the simulator for A can perform steps 4 X 6 to complete the simulation of A  X  X  view. B 0 s view: The simulator for B performs steps 1 and 2 to generate E k ~ , B encrypts the components of the result T p =  X  ( ~ X + t
The simulator for both runs in time linear in the size of the input vectors, meeting the requirement for a polynomial -time simulation.
Algorithm 3 returns the index of the closest cluster (i.e., the row with the minimum row sum). To prove this algo-rithm is privacy preserving, we must show that each party can construct a polynomial time simulator for the view that it sees, given only its own input and this closest cluster in-dex.

Theorem 3. Algorithm 3 privately computes the index of the row with the minimum row sum, revealing only this result assuming parties do not collude to expose other information .
Proof. The simulator is constructed in stages, corre-sponding to the stages of the algorithm.
 Stage 1. The only communication occurring in this stage occurs in the r  X  1 calls to the Permutation Algorithm. Thus, we simply need to apply the composition theorem stated in Theorem 1, with g being the closest cluster computation algorithm and f being the permutation algorithm. What remains is to show that we can simulate the result T i . The simulator for P 1 is exactly the algorithm used by P 1 , without sending any data. For the remaining sites, since the v i are unknown and chosen from a uniform distribution on (0 ..n  X  1), v i + x i will also form a uniform distribution on (0 ..n  X  1). Each P i , i = 2 . . . r can simulate the vector ~ T i by selecting values randomly from a uniform distribution on (0 ..n  X  1). This is indistinguishable from what it sees in the algorithm . Stage 2. All the parties other than P permuted result vectors to the receiver. Since only P r sees new information, we need only concern ourselves with sim-ulating what it sees. The received vectors can be simulated by P r exactly as they were simulated by the P i in Stage 1. The vector ~ Y is equal to the actual distances minus ~ However, since ~ T 2 consists of values uniformly distributed over (0 ..n  X  1), ~ Y is effectively distances  X  v , and is thus also uniformly distributed over (0 ..n  X  1). However, we can-not simulate it by generating random values, as we must preserve the relationship ~ Y = ~ T 1 + P r j =3 T j (mod n ). For-tunately, the sum of the simulator-generated ~ T i will give a vector ~ Y that both meets this constraint and is uniformly distributed over (0 ..n  X  1), giving a view that is indistin-guishable from the real algorithm.
 Again, we use the composition theorem. Each comparison is secure, so we need only show that we can simulate the sequence of comparison results.

The simulator uniformly chooses a random ordering of the k clusters from the k ! possible orderings. We regard this as the distance-wise ordering of the clusters relative to the point. This ordering is used to choose the appropriate result,  X  or &gt; , for each comparison. Effectively, the sim-ulator runs steps 17-21, but makes the comparisons locally based on the random ordering. The probability of any given ordering is 1 /k !, the same as the probability of any given or-dering achieved after the permutation  X  in the actual view. Therefore, the probability of any given sequence of compari -son results is the same under the ordering as under the view seen in the actual algorithm.

Note that all of the possible 2 ( k  X  1) sequences are not equally likely, e.g., the sequence of all &gt; s corresponds to only one ordering, while the sequence of all  X  s corresponds to ( k  X  1)! orderings. However, selecting random total order-ings generates sequences matching the (non-uniform) prob-ability distribution of the actual sequences of comparison s. true index i t is the final result known to all the parties, and P 1 decides upon the permutation  X  , the simulator generates  X  ( i t ) = i as the message it receives.

The final result i t is sent to all parties. Since this is the final result, obviously all the parties can simulate it.
Since this simulator is also linear in the size of the in-put, and we have proven the permutation algorithm to be secure, application of the composition theorem proves that Algorithm 3 preserves privacy.
Before analyzing the security of the entire k -means al-gorithm, we prove the security of the threshold checking Algorithm 2.
 Theorem 4. Algorithm 2 determines if P |  X  0 ij  X  D  X  ij | &lt; T h | , revealing nothing except the truth of this statement.
Proof. Steps 10 and 14 are the only steps of Algorithm 2 requiring communication, so the simulator runs the algo-rithm to this point. In step 10, party P 1 first sends m + d (mod n ) where m is the random number known to P 1 . Each of the parties P j , j = 2 . . . r receive a message m + P from their left neighbor. Since m is chosen from a uniform distribution on (0 . . . n  X  1), and all arithmetic is mod n , this sum forms a uniform distribution on (0 . . . n  X  1) and can be simulated by generating a random number over that distri-bution:
The secure add and compare algorithm gives only the fi-nal result m  X  T h 0 (mod n ) &gt; T h 0  X  m (mod n ) = P T h . Step 14 is easily simulated knowing that result.
This simulator runs in the O ( k ) time required by the Al-gorithm, and is thus polynomial. Applying the composition theorem with Algorithm 2 as f and secure add and compare algorithm as g , along with the other facts given above, proves that Algorithm 2 is secure.
We now analyze the security of the entire k -means algo-rithm. In every iteration, the following things are reveale d to the parties: These values are the desired result of the final iteration. Since it is impossible to know in advance the number of iterations required to halt, the number of iterations needs to be accepted as part of the final output. The results from the intermediate iterations may be used to infer information beyond this result. For example, if the cluster centers for site j do not change between iterations, and a point moves between two clusters, site j knows that those two clusters are both relatively close to the point across the sum of the other sites. However, since the location of the point in the other dimensions is not known, this information is of little use. In any iteration the final assignment of points to clusters is the same for every party. If this intermediate assignment should not be revealed, either a genuine third party will be required or else the algorithm will be quite inefficient. Allowing the intermediate results to be accepted as part of overall results allows an efficient algorithm with provable security properties. Forbidding knowledge of intermediat e results would prevent each site from computing the next iteration locally, making the entire computation much more expensive.

We therefore state the proven overall security properties in the following theorem.

Theorem 5. Algorithm 1 is a private algorithm comput-ing the k clusters of the combined data set, revealing at most the point assignment to clusters at each iteration and the number of iterations required to converge.

Proof. All of the communication in Algorithm 1 all oc-curs in the calls to Algorithms 3 and 2. The results of Algo-rithm 3 are point assignments to clusters, and can be simu-lated from the known result for that iteration. The results of Algorithm 2 are easily simulated; for all but the final it-eration it returns false, in the final iteration it returns tr ue. Applying the composition theorem shows that within the defined bounds the k -means algorithm is secure.
Parties P 1 , and P r have more information than the others during the execution of the above algorithm. Specifically, P 1 knows 1. the permutation  X  , and 2. the values of the random splits (i.e., the random matrix P r learns 1. the permuted result vectors of the permutation algo-2. the comparison results. (Note that P 2 also learns the comparison results.) While we have proven that this information is meaningless in isolation , collusion between P 1 and P r provides enough information to derive the distances between each point and each party X  X  means. It is necessary to carefully select these two parties so that all parties are confident the two will not collude.
The assumption of non-collusion is often implicitly made in the real world. For example, take the case of lawyers for parties on opposite sides in court. While no techni-cal means prevent collusion, safeguards exist in the form of severe punishments for breaking this rule as well as the business penalty of lost reputation. Similar legal and rep-utation safeguards could be enforced for privacy-preservi ng data mining. In addition, if there were not at least two par-ties who did not want to share information, there would be no need for a secure algorithm. Since collusion between P and P r reveals P 1  X  X  information to P r , P 1 would be unlikely to collude simply out of self-interest.

However, technical solutions are more satisfying. Let p , 1  X  p  X  r  X  1, be a user defined anti-collusion security pa-rameter. We present a modification of the algorithm that guarantees that at least p + 1 parties need to collude to dis-close additional information. The problem is in Algorithm 3. The key idea is that stage 1 is run p times, each time selecting a new party to act as P 1 . Thus, the permuta-tion  X  and the random matrix V k  X  r is different for every run, however the row sum of each V matrix is ~ 0, so the to-tal sum is still the actual distance. In stage 4, to get the true index from the permuted index, the p parties apply their inverse permutations in order. Thus, the true index is  X  1 (  X 
We give a bottom-up analysis of the communication cost of one iteration of the algorithm. The total cost is dependen t on the number of iterations required to converge, which is dependent on the data. Assume r parties, n data elements, and that encrypted distances can be represented in m bits.
The permutation algorithm requires only two rounds of communication. For length-n vectors, the total bit cost is 2 n  X  m + public key size = O ( n ) bits.

The secure add and compare algorithm is a two party protocol, implemented using secure circuit evaluation. Th ere are several general techniques for implementing circuit ev al-uation that optimize different parameters such as compu-tation cost, communication cost (number of rounds or to-tal number of bits), etc. The basic tool used, one out of two oblivious transfer, can also be implemented in sev-eral ways. Methods exist that require a constant number of rounds of communication (by parallelizing the oblivious transfers) with bit communication cost linear in the number of gates in the circuit. An excellent survey is given in[12]. The secure add and compare algorithm requires two addi-tion circuits and one comparison circuit, all of m = log n bits (where n is based on the resolution of the distance). Both addition and comparison require a number of gates that is linear in m . Therefore this step requires a constant number of rounds and O ( m ) bits of communication.

In Algorithm 3, closest cluster , communication occurs in several places. Steps 4  X  5 make r  X  1 calls to the permutation algorithm with size k vectors. Steps 10  X  11 require r  X  2 rounds of communication and ( r  X  2)  X  k  X  m bits. Steps 17  X  18 use k  X  1 calls to the secure add and compare algorithm. Steps 24  X  25 require two rounds with O ( r log k ) bit cost. Thus the total cost is 2( r  X  1) + r  X  2 + ( k  X  1)  X  const  X  3 r + const  X  k = O ( r + k ) rounds and 2 k  X  m  X  ( r  X  1)+ k  X  m  X  bits.

The collusion resistant variant of Section 4 multiplies the cost of steps 4  X  5 and step 24 by a factor of p . This gives O ( pr + k ) rounds and O ( pkr ) bits.
 We now give a communication analysis of Algorithm 2. Step 10 involves r  X  1 rounds of communication, with bit cost ( r  X  1)  X  m . Step 14 makes one call to secure add and compare , for constant rounds and O ( m ) bits. Thus, the total cost is O ( r ) rounds and O ( rm ) bits.
 Finally, we come to the analysis of the entire algorithm. We do not count any setup needed to decide the ordering or role of the parties. One iteration of the k -means algorithm requires one call to the closest cluster computation for eve ry, point and one call to the checkT hreshold algorithm. Since all points can be processed in parallel, the total number of rounds required is O ( r + k ). The bit communication cost is O ( nrk ).
The cost of secure comparisons in Stage 3 of Algorithm 3 can be eliminated with a security compromise that would often be innocuous. First, the random vector generated in step 2 is generated so the rows sum to randomly chosen r instead of 0. In Stage 2, all parties (including P 2 ) send their permuted vectors to P r . Now P r can independently find the index of the row with the minimum row sum. Thus, the communication cost is 2( r  X  1) + r  X  1 + 2  X  3 r = O ( r ) rounds and 2 k  X  m  X  ( r  X  1)+ k  X  m  X  ( r  X  1)+2(log k )  X  3 krm bits.

The problem with this approach is that P r learns the rel-ative distance of a point to each cluster, i.e., it learns tha t p is 15 units farther from the second nearest cluster than from the cluster it belongs to. It does not know which cluster the second nearest is. Effectively, it gets k equations (one for each cluster) in k + 1 unknowns. (The unknowns are the location of the point, the location of all clusters but the on e it belongs in, and the distance to the closest cluster center .) Since the permutation of clusters is different for each point , as is the random R , combining information from multiples points still does not enable solving to find the exact loca-tion of a point or cluster. However, probabilistic estimate s on the locations of points/clusters are possible. If the par -ties are willing to accept this loss of security in exchange f or the communication efficiency, they can easily do so.
Let us now compare our communication cost with that of the general circuit evaluation method. For one iteration of the algorithm a circuit evaluation would be required for eac h point to evaluate the cluster to which the point is assigned. Even with an optimized circuit, the closest cluster computa -tion requires at least r  X  1 addition blocks for each cluster. I.e., it requires approximately kr addition circuits, and k  X  1 comparison blocks. These blocks are all of width at least m bits. The best known general method still requires at least r 2 bits of communication for every circuit. Thus, a lower bound on the amount of bits transferred is O ( kmr 3 ) bits.
A simple upper bound on non -secure distributed k -means is obtained by having every party send its data to one site. This gives O ( n ) bits in one round. Privacy is adding a factor of O ( r + k ) rounds and O ( rk ) bit communication cost. While this tradeoff may seem expensive, if the alternative is not to perform data mining at all, it seems quite reasonable.
There has been work in distributed clustering that does not consider privacy issues, e.g., [6, 19]. Generally, the g oal of this work is to reduce communication cost. The idea is to find important data points or patterns locally and utilize these to compute the global patterns. However, sharing loca l patterns inherently compromises privacy. Our work ensures reasonable privacy while limiting communication cost.
There recently been a surge in interest in privacy-preservi ng data mining. One approach is to add  X  X oise X  to the data before the data mining process, and using techniques that mitigate the impact of the noise from the data mining re-sults[2, 1, 10, 27].

The approach of protecting privacy of distributed sources was first addressed for the construction of decision trees[2 2]. This work closely followed the secure multiparty computa-tion approach discussed below, achieving  X  X erfect X  privac y, i.e., nothing is learned that could not be deduced from one X  X  own data and the resulting tree. The key insight was to trade off computation and communication cost for accuracy, improving efficiency over the generic secure multiparty com-putation method. There has since been work to address association rules in horizontally partitioned data[17, 16 ], EM Clustering in Horizontally Partitioned Data[21], asso-ciation rules in vertically partitioned data[28], and gene ral-ized approaches to reducing the number of  X  X n-line X  par-ties required for computation[18]. While some of this work makes trade-offs between efficiency and information disclo-sure, all maintain provable privacy of individual informat ion and bounds on disclosure, and disclosure is limited to infor -mation that is unlikely to be of practical concern.
Clustering in the presence of differing scales, variability , correlation and/or outliers can lead to unintuitive result s if an inappropriate space is used. Research has developed ro-bust space transformations that permit good clustering in the face of such problems [20]. Such estimators need to be calculated over the entire data. An important extension to our work would be to allow privacy preserving computation of such estimators, giving higher confidence in clustering r e-sults. Similarly, extending this work to the more robust EM -clustering algorithm [5, 23] under the heterogeneous database model is a promising future direction. Another problem is to find the set of common entities without re-vealing the identity of entities that are not common to all parties.
 We have made use of several primitives from the Secure Multiparty Computation literature. Recently, there has be en a renewed interest in this field, a good discussion can be found in [8]. Currently, assembling these into efficient priv acy-preserving data mining algorithms, and proving them se-cure, is a challenging task. Our paper has demonstrated how these can be combined to implement a standard data mining algorithm with provable privacy and information disclosur e properties. Our hope is that as the library of primitives and known means for using them grow, standard methods will develop to ease the task of developing privacy-preserving data mining techniques.
We thank Patricia Clifton for comments, corrections, and catching a flaw in an earlier proof of Stage 3. We also thank the anonymous reviewers for their detailed suggestions for improving the paper and acknowledge Murat Kantarcioglu for a synopsis of secure multiparty computation definitions and relationship to this work. [1] D. Agrawal and C. C. Aggarwal. On the design and [2] R. Agrawal and R. Srikant. Privacy-preserving data [3] J. Benaloh. Dense probabilistic encryption. In [4] P. S. Bradley and U. M. Fayyad. Refining initial [5] A. P. Dempster, N. M. Laird, and D. B. Rubin.
 [6] I. S. Dhillon and D. S. Modha. A data-clustering [7] W. Du and M. J. Atallah. Privacy-preserving [8] W. Du and M. J. Atallah. Secure multi-party [9] R. Duda and P. E. Hart. Pattern Classification and [10] A. Evfimievski, R. Srikant, R. Agrawal, and [11] M. Feingold, M. Corzine, M. Wyden, and M. Nelson. [12] M. Franklin and M. Yung. Varieties of secure [13] K. Fukunaga. Introduction to Statistical Pattern [14] O. Goldreich. Secure multi-party computation, Sept. [15] O. Goldreich, S. Micali, and A. Wigderson. How to [16] M. Kantarcioglu and C. Clifton. Privacy-preserving [17] M. Kantarc X o X glu and C. Clifton. Privacy-preserving [18] M. Kantarcioglu and J. Vaidya. An architecture for [19] H. Kargupta, W. Huang, K. Sivakumar, and [20] E. M. Knorr, R. T. Ng, and R. H. Zamar. Robust [21] X. Lin and C. Clifton. Privacy preserving clustering [22] Y. Lindell and B. Pinkas. Privacy preserving data [23] G. J. McLachlan and T. Krishnan. The EM Algorithm [24] D. Naccache and J. Stern. A new public key [25] T. Okamoto and S. Uchiyama. A new public-key [26] P. Paillier. Public key cryptosystems based on [27] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy [28] J. Vaidya and C. Clifton. Privacy preserving [29] A. C. Yao. How to generate and exchange secrets. In
