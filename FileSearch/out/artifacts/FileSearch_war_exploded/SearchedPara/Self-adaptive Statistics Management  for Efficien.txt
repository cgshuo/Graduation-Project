 Mission-critical information systems require consistently good performance. To this end, virtually all large databases are managed by well paid system administrators. The administrators must consistently monitor workload and system performance, predict unforeseen or detect existing problems and give corresponding reaction. However, the task has become more challenging due to increasing complexity and skilled system administrators have become more scarce and expensive to employ. This situation calls for a new generation of self-tuning database technologies. Over the past decade, the importance and urgency of self-tuning database technologies have been deeply understood. Gerhard Weikum in his brilliant work [1] showed the challenges, achievements and direction toward a self-tuning database. Most DBMS vendors provided tools to help automate the process of database administration which now mainly focus on index and materialized view recommendation [2-6], table partition [7], statistics organization and maintenance [8-12]. 
Statistics, especially histograms, are widely used by the query optimizer of a relational database in choosing good execution plans [13]. The automation of statistics management is of great value in improving system performance. Research work toward automating statistics management can be classified to Static-Workload-Analysis (SWA) approach and Execution-Feedback-Analysis (EFA) approach. SWA approach is solely based on the form of queries in the workload and gives its recommendations for statistics maintenance through analyzing the query workload. The representative example of this approach is given by the SQL Server technique described in [8] and [14]. EFA approach automates statistics recommendation and refresh by monitoring feedback from the execution engine. Our approach falls into this category. DB2 UDB, Microsoft SQL Se rver and Oracle 10g all exploit this approach [9]. In DB2 UDB, query feedback inform ation is stored in a QFW. Through analyzing QFW, stale statistics are recognized, and appropriate number of frequent values, column-group statistics are recommended [9]. Moreover, the learning optimizer LEO in DB2 uses the actual selectivity feedback from each operator in the query plan to maintain adjustments that were used to correct the estimation errors from histograms, and doesn X  X  change the histograms themselves [15]. Different from DB2, we recommend histograms not frequent values, and the refining is directly carried on histograms themselves. Self-Tuning histograms proposed by the SQL Server technique described in [16, 17] can use query feedback information to adjust frequencies of buckets in existing histograms. However, later refining will ruin results of former ones as pointed out in [18]. Further more, histogram reconstruction doesn X  X  consider workload information and can only redistribute memory within one histogram, while our technique considers access frequencies in the workload for all histograms and can globally distribute me mory to the most critical histograms. Jagadish et al in [19] present several greedy and heuristic algorithms for distributing memory among a set of single attribute histograms, but they doesn X  X  address the problem of finding the sets of attributes to build histogram on as in our technique. Lim et al in [20] also propose a query-feedback-driven variant of the synopsis approach where Junction trees of Ghordal Graphes and Delta Rule are used for histogram recommendation and refining. Though interesting, as pointed out in [9], this approach suffers from the scalability problem. Our former work [18] proposed approaches for construction, refining and selectivity estimation of Self-Learning Histograms (SLH) which can overcome the shortcomings of [16]. In this paper we extend it by addressing the issue of recommending SLH histograms and dynamically adjusting memory distribution among them. 
In summary, our contributions are:  X 
We develop a new method to recommend and maintain an optimal set of SLH histograms using on query feedback information, which avoids scanning the base data, and can well adapt to workload and data distribution changes.  X 
We propose a new approach which can dynamically and globally distribute memory distribution to the most useful histograms in the workload.  X 
We carried out extensive experiments to validate the effectiveness of our techniques. 
The rest of this paper is organized as follows. In section 2 we give some definitions used in this paper. Section 3 describes query feedback processing and selectivity estimating in detail, which is the main body of this paper. Section 4 shows our experimental results and section 5 summarizes the whole paper.  X  to represent a range query on attribute represented by [, ) low high , where low and high are the lower and higher bound of r respectively. The frequency of range r on relation R is defined to the number of tuples in relation R satisfying i low A high  X &lt; .
 range query i Ar  X  is denoted by which is used by the query optimizer to choose efficient execution plans in a cost-based manner. 
A histogram i H on attribute i A is an approximation to the frequency distribution of attribute i A . It is constructed by partitioning the data distribution of i A into several buckets and approximating the frequencies and values in each bucket. A SLH &lt;&gt; where = means the frequency of range [, )
Fvv f f c ci j j i  X  X  = X  =  X  +  X  +  X  . Rules can be used to infer current value of SCF (defined later) when the rule is introduced into the histogram. It is used to drop outdated rules from the histogram, as we discussed in [18]. 
Unit-frequency reflects the average frequency of each value in a bucket i B based System Change Factor (SCF) represents the changes to data. The initial value of percentage of modified tuples. E.g. if 20% tuples are deleted, SCF will increase 0.2. 
A query feedback is a quadruple (, , ,) i FB A low high n where i A is the attribute accessed, low and high represent the lower and higher bound of the query range respectively, and n is the actual number of tuples satisfying the query l i ow A high  X &lt; . 3.1 Framework Overview In this section, we propose SASM, a general framework aimed at recommending and maintaining a set of SLH histograms within fixed amount of memory. SASM monitors query feedback, and by analyzing estimation errors of queries, gives its recommendations. When statistics memory limit is reached, SASM dynamically reclaim some buckets from non-essential histograms and allocate them to the most critical histograms. The workflow of SASM is shown in Fig. 1. 
Workload Monitor (WM) monitors how frequently each attribute is accessed. It maintains an Access-Counter for each attribute. The Access-Counter will be used to dynamically distribute memory among all histograms which we will describe in subsections 3.3. The output of WM is recorded in Statistics Access Frequency (SAF) which is organized in a table. For each column, the table it belongs to, and the corresponding Access-Counter are stored in the table as a tuple. Attributes absent from the table means that they are not frequently accessed in the current query workload, and it is non-essential to maintain statistics for them. 
When the Query Optimizer (QO) chooses the best execution plan for a query based on costs of different ones, the size of the query, namely the number of tuples satisfying the query predicates, is estimated by its cost-estimation model. And when the chosen plan is executed by the Execution Engin (EE), the actual query size can be gained. Query Feedbck Collector (QFC) collects these kinds of information together with the skeleton of the execution plan. Table 1 shows an example of the information QFC collects. The first tuple in Table 1 means the estimated and actual output size of query 18 20 Age  X &lt; is 9485 and 8945 respectively, and the estimated output size (9485) is obtained using a histogram. The query feedback information collected by QFC is then analyzed by the Query Feedback Analyzer (QFA). QFA computes the estimation error for the query and judges whether the estimation error exceeds a given threshold  X  . If exceeds, the attribute referenced by the query is recommended as a candidate column for statistics building or refining, else it is ignored. The estimation error used is relative error defined as follows. where '  X  and  X  denotes the estimated and actual query size respectively. The recommendation information is similar to that showed in Table 1. 
Recommendation for statistics building or refining given by QFA may all ask for memory to build new histograms or accommodate new buckets. If available statistics memory is not enough, it must be reclaimed from non-essential histograms. Statistics Maintainer (SM) is responsible for these issues. It uses information in SAF table and existing histograms to determine from which histograms to reclaim memory and build a new histogram or refine an existing histogram using query feedback information that QFC collects. In section 3.2 and 3.3, we will show how SM works in detail. 3.2 Candidate Statistics Recommendation and On-line Refining In this section, we show how to use query feedback information to recommend candidate histograms and to refine existing histograms. First we consider there is enough memory. Suppose the query feedback information on i A in R
FB A X Y n . When memory is enough and no histogram exists on i A , a new 
HVFCT XY n SCFSCF ==&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt; . i H and other existing histograms form the set of candidate histograms. Later i H will be refined when accessed and the estimation error exceeds the given threshold  X  . A histogram i H may already exist on i A , then it is just refined using algorithm HistogramRefining in Fig.2. Output: newly built i H or i H refined by (,,,) i FB A X Y n BEGIN If X ( or Y ) doesn X  X  equal to any boundaries of i B (or j B ) Compute 1 Set a c ( or b c )to a value different from any existing CQFs Set ab fnf  X = +  X  // estimation error using histogram i H else{ Set ' c to a value different any existing CQFs expect a c and b c ; For each CQF i c in i H , if ( || iaib cccc == == ) , set ' i cc = ; Set a  X  and b  X  to the current value of SCF, namely set ab SCF  X  X  == ; END. 3.3 Dynamic Memory Distribution Among Histograms In SASM, global memory redistribution is achieved by splitting and merging buckets among all histograms. Bucket splitting is processed when refining histograms using query feedback information when available statistics memory is enough, which has been discussed in section 3.2. When available statistics memory is not enough, SM will reclaim memory from non-essential histograms by merging some adjacent buckets in them. In this section, we focus on this issue by determining which histograms are non-essential and how to reclaim buckets from them. Merging may cause accuracy losses. Ideal merging tactic should lower the loss to the least. 
Merging tactic based only on frequencies as that in [16] is unsatisfying. In [16], adjacent buckets with similar frequencies are merged. However, see Fig.3, the frequency difference between i B and 1 i B + (|10-90|=80) is much larger than that accuracy loss, e.g. before merging, the selectivity of query 2 110 A  X  X  X  is 10 merging, the selectivity changes to 10 1.9 (1 0 9 ) + can lead to no accuracy loss, for data in them is uniformly distributed and the frequency of each value in the two buckets is always 1 no matter before or after merging. 
Merging adjacent buckets with similar unit-frequency seems a good choice. But since we want to lower the estimation errors for the current running workload, only unit-frequency can X  X  meet this goal. E.g. the unit-frequency difference of bucket j B and 1 j B + is |10(111)9(10111)|0.9  X  X  X  X  X   X  = , much smaller than that of k B and 1 k B + and 1 j B + , for 3 H is accessed so seldom, reclaim buckets from it will do little harm of the current workload. 
In SASM, we combine the access frequency and unit-frequency of histograms when choosing buckets to merge. We compute the Merge-Factor (MF) of two adjacent buckets of all the histograms. If the MF of two adjacent buckets i B and + is in the they belong to is taken as a non-essential histogram. MF is defined to: where i UF accumulative frequency) of bucket i B . It should be emphasized that estimated using all related rules as described in [18] with each bucket k B being seen as 
After merging, i B and 1 i B + become to one bucket 2 [, ) ii Bv v + , the cumulative frequency and CQF of i v and 2 i v + are the same as before. If a histogram remains only one bucket due to merging, and its Access-Counter is very low, we can drop it from the system. In this way, the origin set of candidate histograms is shrunken and memory is dynamically distributed to the most critical histograms. 4.1 Setup for Experiments We made comparisons in accuracy and maintenance cost between SASM and other approaches including Self-Tuning, MaxDiff, Equi-Depth histograms. We use a database consists 10 tables with each table having more than 5 randomly generated attributes. A Zipfian distribution [21] generator is used to generate skewed data for columns in the database. The degree of skew in the data is controlled by the Zipfian parameter z, varied between 0 (uniform) and 4 (highly skewed). Which attribute a histogram is built on is randomly chosen to simulate the initial status of the workload. 
Experiments No DSk WS MT SL DSc 4 changing 1 0.2 1800Byte 10*100K tuples 
Query workload consisted 6000 queries of the form i xA y  X &lt; , i Ax  X  and i Ay &lt; , where x and y were generated. Not all attribute are accessed equally, and the access frequency of each attribute is also controlled by the Zipfian data generator. For example, a class Zipfian(1, nATTs, nQueries, nATTs, z ) can distribute nQueries to nATTs attribute with a skew z. 
When the query workload was executed, estimation errors and maintenance costs were computed for each approach. We used both average absolute error abs E and average relative error abs E as accuracy metric in evaluating the accuracy of each approach in estimating range query result size. They were computed as: where N represents the number of queries in the workload, i  X  and ' i  X  represent the actual and estimated output size of the i th query in the workload. Since results using both error metric show no intrinsic difference, we only presents experimental results using average relative error in this paper in the interest of space. 4.2 Results We have done extensive experiments to evaluate the effectiveness of our technique under various kinds of situations, but due to limited space, we only show results of six representative experiments. We first give the parameter setting of each experiment in Table 2. DSk, WS, MT, SL and DSc mean Data Skew, Workload Skew, Merge Threshold, Space Limit and Data Scale respectively. Each figure corresponds to the result of one experiment using parameters shown in one tuple in Table 2. Fig.4.(a) shows the estimation error of SASM changes with the Merge Threshold. ST, MD and ED stands for Self-Tuning hi stograms in [16], Maxdiff histograms and Equi-Depth histogram respectively. SASM is our approach. From it, when Merge Threshold increases but keeps smaller than 20%, the accuracy of SASM improves, since more memory can be globally distributed to most critical histograms. However when the threshold keeps increasing, the accuracy drops drastically. This is because when Merge Threshold becomes very large, the number of buckets merged in each redistribution of memory among all histograms will be very large and those reclaimed buckets are not all assigned to histograms at once, so space currently occupied by SASM is reduced. From the figure we can see 20% is an ideal value for Merge Threshold, so we will use this value in later experiments. Fig .4. (b) shows the estimation error changes with space limit. Generally, when space limit is large, more buckets can be assigned to each set of histograms and hence they can achieve good approximation to data. Fig.4. (b) shows this trend. When space limit increases, estimation errors of all sets of histograms decrease. When space limit is large enough, all errors keep in a nearly stable state. This is because when existing space is enough to realize the data distribution, more memory can lean to no improvement in accuracy. SASM performs better than ED and ST, while poorer than MD. 
Fig.5. (a) shows the estimation error changes with increased workload skew of each set of histograms. We can see that when the workload skew increases, the estimation error all increases except SASM. When workload skew becomes large enough (about z=2), estimation error of SASM begins to drop. This is because only SASM can globally distribute memory among all histograms. When workload skew is large, buckets from non-essential histograms are reclaimed and allocated to those heavily accessed histograms. Fig.5.(b) shows the estimation error changes with data accurate. MD is the most accurate. SASM is nearly as accurate as ED. When data skew increases, the accuracy of all histograms drops slowly. When data skew is very large, the accuracies of MD and ST drop drastically as pointed out in [16] while that of SASM increases instead. This is because when data skew is large, the number of distinct values becomes very small, and by self-refining using query feedback information, SASM can well adapt to this change. 
In this experiment, we want to compare the costs (seconds) for query processing using ST and SASM. Since MD and ED are static histograms, cost comparison between SASM and them is non-essential. Fig.6. (a) shows the cost of processing the workload changes with the total number of tuples (measured in thousand, e.g. 5 represents 5000 tuples for each table) in the database. We can see that the both costs increase as data becomes larger and the cost of SASM is nearly the same as that of ST. Fig.6. (b) is the result of costs changes with memory limit. The cost of SASM is slightly higher than that of ST. However, since both ST and SASM piggyback on the process of query answering, the cost is very small contrast to the cost of query due to decreases in reconstruction frequency when memory limit is large enough. (a) Estimation Error-Workload Skew (b) Estimation Error-Data Skew In this paper, we presented a unified framework SASM for autonomic statistics management in DBMSs. SASM not only can recommend, construct and refine SLH histograms using only query feedback information without accessing the base data, but also can dynamically distribute fixed memory to the most critical histograms. Histogram recommendation and refining are based on estimation error analysis, which makes SASM adapt well to wo rkload and data changes and using CQF, statistics can Experiments showed SASM can reduce estimation errors to a satisfying degree while keep acceptable maintenance cost. 
