 The emergence of numerous data sources online has pre-sented a pressing need for more automatic yet accurate data integration techniques. For the data returned from query-ing such sources, most works focus on how to extract the embedded structured data more accurately. However, to eventually provide an integrated access to these query re-sults, a last but not least step is to combine the extracted data coming from different sources. A critical task is finding the correspondence of the data fields between the sources X  a problem well known as schema matching. Query results are a small and biased sample set of instances obtained from sources; the obtained schema information is thus very im-plicit and incomplete, which often prevents existing schema matching approaches from performing effectively. In this paper, we develop a novel framework for understanding and effectively supporting schema matching on such instance-based data, especially for integrating multiple sources. We view discovering matching as constructing a more complete domain schema that best describes the input data. With this conceptual view, we can leverage various data instances and observed regularities seamlessly with holistic, multiple-source schema matching to achieve more accurate matching results. Our experiments show that our framework consis-tently outperforms baseline pairwise and clustering-based approaches (raising F-measure from 50-89% to 89-94%) and works uniformly well for the surveyed domains.
 H.2 [ DATABASE MANAGEMENT ]: Miscellaneous Algorithms, Experimentation, Performance
The emergence of large structured databases on the Web (so-called deep-Web) has provided users the choice of many alternative sources to seek their desired information. As an example, a user planning a flight may issue queries to differ-ent sources (e.g., expedia.com, travelocity.com, and so on) and look within their returned results for the ticket with the lowest price. Such similar needs of finding information in al-ternative or comparative sources happen often for the users daily X  e.g., looking for buying books, cars, albums, etc. To provide systematic solutions to address such needs, many tasks have been pursued to enable an integrated access to the disparate relevant sources X  for example, creating an in-tegrated query interface to mediate the sources [9, 21] and extracting the embedded data records returned in the result pages [4, 5]. Upon these tasks, in this paper we particularly study the problem of integrating query results obtained from multiple sources in the same domain (e.g., airfares, books, cars). Figure 1a shows an example of three book sources S S , and S 3 (for illustration, we put a tip x ij to indicate each data field j of source S i at its upper-right corner). The data records of each source are supposed to be extracted (e.g., via existing automatic extraction tools [1, 5]), and we aim to construct an integrated table combining the data records of all sources, as the one shown in Figure 1c. This facility, if combined with an integrated query interface and automatic data extraction, will provide users a uniform access and view of the data returned from numerous sources, and also bene-fit the construction of many useful applications such as do-main portals , comparison shopping , meta-search and vertical search engines .

Schema matching is fundamental for supporting this query result integration. Given data records extracted, we need to determine automatically yet accurately the correspondence of the data fields between different sources. E.g., the data fields x 12 of source S 1 , x 21 of S 2 and x 32 of S 3 in Figure 1 are corresponded (where they are title ) and thus will be put in the same column of the integrated table ( a 2 of Figure 1c). This problem has been well known as schema matching. As schema matching has been studied extensively [18], this task initially appears to be straightforward X  i.e., by picking up an appropriate approach from the rich literature work.
The traditional matching approaches mostly focus on two sources, namely pairwise . We thus try to utilize such pair-wise matching. From our initial experiment (we will do de-tailed comparisons in Section 5), matching two sources can generally achieve adequate performance (e.g., average accu-racy 87% for matching two testing book sources). However, when we try to match different source pairs and combine their matching results, the final integrated table (of multi-ple sources) gets a degrading accuracy (to 58-64%). We ob-serve that the matching errors of each individual pairwise matching seem accumulated and propagated when combin-ing them. For example, let x, y, z be three fields in three sources, respectively. Suppose ( x, y ) and ( y, z ) are matches discovered; then after combining them, x, y, z will be put in the same column of the final table, implying ( x, y, z ) are matched. Now suppose ( x, y ) is an error match; then ( x, z ) becomes an inherent matching error caused due to combin-ing multiple imperfect matchings.

From these observations, we recognize that an effective matching approach to our integration task (i.e., combining query results from  X  X any X  sources) should accomplish mul-tiple sources holistically , in order to potentially eliminate such accumulated errors that are mainly due to the isolated matchings of individual two sources. Thus, to enhance the overall matching accuracy, we develop a novel framework for understanding and supporting multiple-source schema matching. Although the framework is motivated by inte-grating query results, it is quite general and potential for various schema matching tasks.

Below, we provide our observations on this task, followed by briefly presenting our proposed approach.
Query results are preprocessed by extraction, followed by schema matching to create the integrator. For a particular source, the data records embedded often have the same tem-plate structure (i.e., HTML layout). The existing extraction tools, while realized with different techniques, mainly utiliz e this phenomenon: Given a few initial result pages, they ex-tract data records by finding repeated similar HTML frag-ments; they segment the extracted records into data fields by comparing and aligning these fragments X  the record tem-plates are thus discovered. Following, with these initial ex-tracted data, schema matching is involved to identify which fields between sources are matched. The extraction record templates, together with the field matching information, will be used to process other incoming query results from these different sources into an integrated table.

Data fields are the basic units processed by matching. A data field can be viewed as a label plus a set of values  X  label is often the common heading string of the field occurring in all records, and the values are the real data instances. E.g., in source S 1 of Figure 1, field x 16 has label  X  X etail: X  and values {  X $18.29 X ,  X $16.95 X  } . Clearly, some fields that have obvious meanings (e.g., title ) may not have labels. Annotat-ing a field instance into label and values can accompany the extraction process or be achieved by additional tools [2].
Schema matching on such data is at first glance viewed as instance-based : The data fields are matched mainly based on the content similarity of their data labels and values. Fortunately, some characteristics of such data make identi-fying similar content even easier. First, the data of different sources are usually obtained by issuing similar queries X  im-plying that some fields will contain the query keywords so become similar X  e.g., querying  X  X arry Potter X  implies that the obtained title fields are similar. Second, because pre-sented to the end users, the results usually follow some con-tent conventions. The displayed fields are common (e.g., { title , publish-date , ISBN } for books) and understandable for the end users (e.g., time with format hh:mm) X  there are rare opaque fields and values (e.g., internally used key or barcode values). These conventions benefit a lot on identifying simi-lar fields via instance-based comparison X  e.g., in our experi-ment, matching any two sources can achieve adequately high accuracy (77-100% in books).

However, on the other hand, these data also have essential challenges. We lack explicit and complete schema informa-tion. The data records are extracted from query results, a small and biased sample of the backend databases X  the ob-tained schema information is implicit and incomplete : No explicit data types and constraints are available X  they are useful to match same fields with different data appearances (e.g., the field x 15 and x 38 in Figure 1 both are date but with different formats). Each field may not have a complete sam-ple of values X  same fields may lack overlapping content evi-dences to be identified as similar (e.g., x 14 and x 39 , while are format , do not share similar values). Some fields may have labels but some may not X  often some ambiguous fields that have almost identical value appearances (for example, the depart-time and arrive-time ) cannot be distinguished without further semantic labels or other non-content information.
To conquer such challenges, we observe some niches in this context of integrating query results: First, we often need to integrate multiple sources. Some useful effects nat-urally occur when cross-referencing many sources. Second, although no schema-based constraint is available, there are indeed useful regularities that can be observed from many sources. These regularities, treated as observed domain con-straints, are very helpful for matching discovery. Below, we use examples to illustrate them.
 Example 1 (Cross-Source Effects): In Figure 1a, fields x 14 {  X  X aperback X  } and x 39 {  X  Format: Hardcover X  } are dis-similar if we compare their labels and values directly. How-ever, if counting in x 23 {  X  X aperback X ,  X  X ardcover X  } , fields x 14 and x 39 are thus linked through the bridge x 23 (namely, bridging effects [10, 20]).

In addition, fields x 14 and x 23 , which originally don X  X  have labels, can be enriched by adding the label of field x 39  X  Format:  X ).
 Take another example: fields x 25 and x 33 are similar ( prices ). But, if x 25 matches x 16 ( list/retail-price ), x 33 matches x ( our-price ), and x 16 doesn X  X  match x 17 (separated fields in the same source), then x 25 and x 33 wouldn X  X  be matched, through the known mismatch between x 16 and x 17 . This leverages the property that some fields co-occur in some sources but not in others. Thus, by cross-referencing them, some error matches or mismatches can get recovered. Example 2 (Domain Constraints): Figure 1b shows the example matched fields and some domain constraints. Here, we represent a constraint as a predicate (e.g., num  X  ( a with a confidence (e.g., 1) to indicate how likely the sources in the domain obey it.

Now, suppose we aim to match ambiguous fields x 16 , x 17 with x 24 , x 25 . If knowing that list/retail-price is always greater than or equal to our-price (e.g.,  X  ( a 7 , a 8 ):1), then we can pair x 16 with x 25 and x 17 with x 24 . Another example is that if a column in the final table always has data (e.g., exist( a like the title field in books), then for each source, there must be a field assigned to this column ( a 2 ).

Such constraints would be even more beneficial for dis-covering matching in more complicated domains. Taking another example of airfares in Figure 2, it is clear that the departure information is always displayed before the arrival information (e.g., ( depart-time , arrive-time ):1). So, even without given clear labels, some ambiguous fields (like { z z } of S 1 and { z 25 , z 26 } of S 2 ) may still be matched cor-rectly by involving this structure ordering regularity.
We notice that both such cross-source effects and domain constraints can only be achieved effectively when considering multiple sources holistically . Cross-source effects leverage the overlapping of fields across sources; as more sources are available, more chances it has to complement the match-ing through cross reference. Domain constraints leverage the concerted conventions of fields across sources; because they are not prescribed but need to be derived, they can be obtained reliably only when many sources are observed, showing a statistical convergence to the domain. Two, or just a few, sources would not reveal such a convergence.
These observations are intuitively appealing. With the instance-based comparison as the basics, supplemented by the cross-source effects and constraints observed on many sources, matching might be achieved more accurately. To the best of our knowledge, no existing instance-based schema matching approaches can match multiple sources together. (We will review and compare some existing holistic, multiple-source matching approaches developed for Web query forms in Sections 2 and 5). We thus ask: What would be a princi-pled framework to realize such holistic schema matching?
To understand our approach, we emphasize that matching is essentially to enrich and then complete the schema, which is implicit and incomplete at the beginning. The enrich-ment occurs basically in three levels: First, the content of a field: By matching, the labels and values can be enriched by the matched peer fields, so as to have more complete con-tent evidences (like in [13]). Second, the kinds of fields: By matching, we can discover different kinds of fields existent in the domain. With more sources available, the more kinds of fields get found and then converged. Any particular field (e.g., format ) chances to occur in some sources, and each source contains different coverage (a subset) of the kinds of fields. Third, the constraints of fields: By matching, we will learn the implicit regularities existing among fields. These regularities enrich a schema by adding  X  X onstraints. X  With all the above enrichment, we learn a more complete schema to describe the whole input data. This learned schema can thus help us in making further matching.

Upon this insight, we hypothesize that the data records are guided by an underlying domain schema. Discovering matching is thus constructing a schema that best describes the whole input data. We then realize a schema as consist-ing of a set of field content models (modeling the label and values) and a set of statistical constraints (modeling the reg-ularities), and develop an iterative optimization algorithm to solve this matching problem.

As a summary, this paper makes the contributions:  X  We study schema matching in a holistic, multiple-source manner, particularly for X  but not limited to X  query result integration.  X  We realize such holistic schema matching as domain schema discovery and develop a framework for it  X  We evaluate our framework on both the correct data and real extracted data, and validate that it is indeed effective. In the rest of the paper, we first relate our work (Section 2). Then, we develop the framework and algorithm (Sections 3 and 4). Finally, we report the experiments (Section 5).
As schema matching is crucial for data integration, and many other data sharing/exchange applications [18], it has been studied extensively, yet remains an important problem.
For schema matching on query results of multiple sources, there are very few works directly addressing this particular setting. Wang et al. [19] proposes a query probing approach to match any two of interface schema, result schema, and global schema for one source. Our scenario takes the same advantage of using same queries to obtain similar query re-sults. However, because there are data fields that cannot not be queried, query probing is not helpful for matching such fields. Besides, it needs a manually crafted global schema to connect multiple sources.

For general schema matching, most previous studies ad-dress matching two sources. They utilize field names, types, instances, constraints, and other schema information that can be explicitly obtained from the input schemas to find the similar fields, using various techniques such as machine-learning [8, 12], rule/constraint-based [16], graph-matching [14, 15], or hybrid [6, 14] approaches (see [18] for a sur-vey). Basically, query results can be viewed as a set of sam-pled instances. While these methods are not specifically designed for instance-based schemas, some indeed contain components to handle data instances and thus can be ap-plied. There are also works specific to instance-based match-ing: For example, [3] uses the duplicate instances between sources to find matching; [11] utilizes the dependency be-tween data, specifically suitable for handling the fields with un-interpretable data values. Overall, the major shortage of applying the pairwise matching approaches is that when they are extended to integrate multiple sources, the errors from individual pairwise matching are accumulated, thus re-sulting a relatively poor final table (see Section 5).
A work that needs to be mentioned is the corpus-based approach [13]: Given two schemas, it utilizes a corpus of schemas to augment the evidences of the elements to match. This shares with us a similar insight of enriching fields from the information of multiple sources. However, this approach fundamentally matches only two sources, while treats the other sources as an auxiliary corpus. It misses the benefit of cross-referencing multiple sources when discovering match-ing, and thus has the same shortage of other pairwise match-ing. Our experiment (Section 5) will show that matching all sources together will get much improved results.

The idea of matching multiple schemas holistically was first proposed in [10] to match a set of Web query forms. The input is a set of extracted terms (e.g.,  X  X epart From X ,  X  X rrive To X , etc) from query forms, where a term indicates the name of a query field. These terms are then matched by utilizing their co-occurrence information. However, query results have quite different data properties from query forms. Query results mainly consist of data values (e.g.,  X $38.95 X ,  X  X .K. Rowling X ); names (labels) may be missed for some extracted fields. We thus need to rely on measuring their content similarity; the idea of co-occurrence cannot be di-rectly applied. Besides, it is not clear how to leverage various structure information in their approach. A clustering-based approach was also proposed to match query forms [20]. The idea of clustering can be easily applied on query results X  i.e., clustering the extracted data fields based on their similarity. Thus, we will compare our approach with such a clustering-based approach in the experiments. The main advantage of our framework is that it can natively leverage any auxiliary structure information, which will be shown beneficial.
This section develops the insight of viewing matching as schema discovery and the framework it entails.
Schema matching is traditionally finding the correspond-ing pair of fields between two given schemas (i.e., field pair { x 1 , x 2 }  X  S 1  X  S 2 for schemas S 1 , S 2 ). As we look for the correspondence of fields among multiple sources, we thus view it as finding the match group of fields (i.e., { x 1 i =1 S i for schemas S 1 , ..., S n where x 1 , ..., x k are supposed to be the same kind of fields).

We first give some basic notations. Suppose there are n sources S 1 , ..., S n (also define S = { 1 , . . . , n } ). Let X { x s 1 , ..., x s` s } be the set of fields for the s -th source, where each x si indicates a field and there are ` s fields. A field x is further a set { x si, 1 , x si, 2 , ... } , where each x field instance of the j -th record X  e.g., in Figure 1, instance x 12 , 1 is  X  X one with The Wind X .

As matching is essentially grouping those similar fields to-gether, we suppose at the end there are groups A = { a 1 , a Then, as a fair abstraction, matching is actually discovering the assignment of the groups in A to the fields of each source: where Y s = ( y s 1 , ..., y s` s ) and each y si  X  A is the group that source field x si  X  X s is assigned as. If the fields of different sources are assigned in the same group (i.e., been assigned as the same label a  X  A ), they are considered matched. Together, Y = { Y s : s  X  S } is our holistic matching result for all sources S 1 , ..., S n .
 Example 3 (Matching): Suppose A = { a 1 , a 2 , . . . } for the book sources (Figure 1b). For source S 1 , the fields X 1 ( x 11 , x 12 , ..., x 17 ) can be assigned with the matching Y ( a 1 , a 2 , ..., a 7 ).
 For n sources S 1 , ..., S n and m groups A , we can think of matching as a process of filling the fields of all sources into an n  X  m matrix, just like the one shown in Figure 1b.
Notice that the formulation of Eq.(1) provides the flexi-bility to capture both the matching scenarios of processing all sources in a batch and adding one source at a time, in-crementally ; both are useful for integration. For matching many sources in a batch, as the target groups are unknown and need to be figured out during the matching process, the mapping function Eq.(1) comes to be unsupervised (e.g., clustering the input fields into groups). For the incremental situation, the matching of prior sources already gives the field groups; thus, matching becomes some supervised func-tion (e.g., classifying the fields of a new source into the exist-ing groups). Our framework fundamentally supports these two scenarios, while in this work we focus on matching all sources in a batch.
To reveal the insight of viewing matching as schema dis-covery, we analyze: What does matching bring to us?
Clearly, matching partitions the data fields of different sources into groups. Each group contains those fields that are judged as similar, and thus can be viewed as an implicit domain field. Take the book domain in Figure 1b, where we show an ideal matching table. Groups are named anony-mously as { a 1 , a 2 , ... } , where a 2 combines all title fields, a authors , a 4 format , etc. Each group captures the content information of a domain field.

Further, given the set of domain fields (groups found by matching), we can capture some soft constraints among them X  as we have shown in Example 2, we represent such a soft con-straint as a predicate plus a confidence value. For example, referring to Figure 1b: The possibility that a 1 occurs in any given individual source is 2/3 ( S 1 , S 2 have data for a does not) and a 2 is 3/3 X  we learn constraints exist( a 1 and exist( a 2 ):1. The floating number contained in a 7 (i.e., list/retail-price ) is always greater than or equal to that of a ( our-price ) X  implying the constraint num  X  ( a 7 , a 8 ):1. The field a 2 (i.e., title ) always occurs before a 3 ( authors ) or the chance that a 2 is displayed as the first field in a source is 1/3 and a 3 is 0/3 X  that is, the constraints pos ( a 2 , a first( a 2 ): . 33, first( a 3 ):0. The constraints are of many types X  e.g., field distributions (exist), data comparison (num  X  ), po-sition information (pos , first), and so on. These soft con-straints are very helpful for matching discovery, which we have illustrated in Example 2.

If we are given some predicate functions (such as, exist, num  X  , pos , first, etc), we are able to examine whether they occur in the input sources and then learn from the match-ing results of all the sources to reveal how confident each constraint occurs in the domain. The learned constraints can in turn help matching discovery. We assume that the predicates to check are given as a set F , and will describe how we implement them in Section 4.

Thus, what matching actually brings to us is an instance-based statistical schema for describing the input data. Such a schema, just like the conventional schema, consists of fields and constraints: First, it has a set of unnamed fields for the whole domain, each of which is a group of source fields. Unlike the traditional schema-based field (with explicit data type and constraints, e.g., key), such a domain field is instance-based, containing the instances combined from the included source fields. Second, it has a set of statistical constraints, describing the regularities of domain fields observed from the data. They are derived, unlike the prescribed schema-based constraints.

Based on such observations and analysis, we hypothesize there exists such a domain schema. We then can give a simple but fairly principled abstraction of generating data records for any of the sources. Let the domain schema be M = ( A, B ), where A is the set of domain fields and B the statistical constraints. For each source S s : First, it projects M onto a source schema M s = ( Y s , V s ), where Y s is a sub-set of A to be the fields of source S s , and V s is a set of con-straints instantiated from B ; second, to construct the source instances X s (Section 3.1), for each record j and each field a si  X  Y s , it generates an instance from a si to be the instance of x si,j ; third, V s is translated as U s by substituting Y X ; finally, it renders the data X s to the output, follow-ing the guidance of U s . Let X  X  denote the instance model as I s = ( X s , U s ). This procedure of data generation can be conceptually sketched as: Now let X  X  look at an example.
 Example 4: Use Figure 1b: Suppose the domain schema is M = ( A, B ) where A = { a 1 , ..., a 11 } and B = { first( a first( a 2 ): . 33, pos ( a 2 , a 3 ):1 } .

To generate data for source S 1 , we project M to a source schema M 1 = ( Y 1 , V 1 ) where Y 1 = { a 1 , ..., a 5 , a V 1 = { first( a 1 ):1, first( a 2 ):0, pos ( a 2 , a 3 ):1 } . (Each con-straint in V 1 reflects that constraint observed in source S
Then, we generate data using source schema M 1 . It first maps Y 1 as X 1  X  e.g., a 2 is mapped as x 12 . It then generates field instances for records X  e.g., X  X one with The Wind X  X o be x 12 , 1 and  X  X omeo and Juliet X  X o be x 12 , 2 . The constraints V are also translated as U 1 by substituting Y 1 using X 1  X  e.g., first( a 1 ) in V 1 is rewritten as first( x 11 ) in U 1 , pos ( a as pos ( x 12 , x 13 ), and so on.

Finally, the instances X 1 are displayed in pages, using the guidance of constraints U 1  X  e.g., x 11 must be displayed as the first field according to constraint first( x 11 ):1, and x put before x 13 because of pos ( x 12 , x 13 ):1.

Upon this conceptual model, if the matching Y is given, the domain schema can be derived directly from the data, using statistical methods (e.g., maximum likelihood) to es-timate the parameters. Let the data observed from source S s be I s = ( X s , U s ). Given the matching Y = { Y s : s  X  S } , learning the best domain schema can be described as a prob-abilistic optimization expression: where p ( I s | Y s , M ) is the conditional likelihood of observ-ing I s given a candidate schema model M and the Y s that matches source fields in X s to the domain fields in M .
Similarly, if the domain schema M is given, the best matching Y  X  = { Y  X  s : s  X  S } can be discovered, again using statistical techniques (e.g., classification or labeling) to find out the most likely assignment of domain fields to the fields of each source:
Example 4 has shown how we can project a domain schema to a source schema. Below, let X  X  look at an example to il-lustrate how to learn a domain schema from some observed source instances.
 Example 5: Suppose there are two source inputs X 1 = { x 11 , x 12 , x 13 } and X 2 = { x 21 , x 22 } . And suppose we have one predicate function to check: first. Then, we obtain the instances I 1 = { X 1 , U 1 } where U 1 = { first( x 11 ):1 } , and I 2 = { X 2 , U 2 } where U 2 = { first( x 21 ):1 } . (We ignore those constraints with probability 0, such as first( x 12 ):0)
Suppose the matching assignment for X 1 is Y 1 = { a 1 , a and for X 2 is Y 2 = { a 2 , a 3 } . We can then construct two source schemas M 1 = ( Y 1 , V 1 ) where V 1 = { first( a and M 2 = ( Y 2 , V 2 ) where V 2 = { first( a 2 ):1 } , by rewriting the constraints in U i via substituting the items in X i using those in Y i (e.g., x 11 is replaced as a 1 , x 12 as a 2
It is clear that first( a 1 ) holds for M 1 but not M 2 . Thus, first( a 1 ) has confidence 0 . 5. Thus, combining source schemas M 1 and M 2 , the domain schema then becomes M = ( A, B ) where A = { a 1 , a 2 , a 3 } and B = { first( a 1 ): . 5 , first( a
Overall, if the domain schema is given, the matching can be derived, and vice versa. As a conclusion, discovering the matching is equivalent of constructing the domain schema.
Viewing discovering matching as constructing a domain schema, we are thus able to design our framework. We turn the task of matching n sources by n sources into matching n sources by 1 domain schema. Figure 3 sketches this frame-work. We will explain it later in this section. Below we first concretely formalize the two components X  the domain field models and constraints.
 Field Models First, we define the domain fields A = { a 1 , a 2 , . . . } . A do-main field aims to capture the information shared by the instances of same fields across different sources. It requires content-based analysis to discover such information. Many heuristics have been designed to measure similar data X  e.g., using character or word distributions, average string lengths, data types, and so on. The results of these analyses, at the end, are combined, either ad hoc or via some learning techniques, as similarity values that will be used to com-pare fields. Since these heuristics are various and sometimes
Figure 3: The framework of matching discovery. domain-dependent, to maintain the flexibility of the frame-work, we use a statistic model to unify them.
 Definition 1 (Field Model): A field model a is a statistic model specifying how to generate instances. Or, specifically, a field model a is a function that accepts an instance z and produces p ( z | a ), indicating the likelihood that z is an in-stance produced by the field model a .
 Notice that we are not going to propose any new content-based similarity analysis. Instead, we aim to leverage the existing approaches in a principled statistic model. Statistical Constraints Then, we define the statistical constraints B = { b 1 , b As motivated in Section 1.1, they are predicates with uncer-tainty: Definition 2 (Statistical Constraint): A statistical con-straint b is written as f ( e ): c , where f is a predicate name, e is the vector of elements, and c is a confidence value of range [0,1].
 Figure 1b and 2b have shown many such example constraints X  e.g., first( a 1 ): . 67 and pos ( a 2 , a 3 ):1.

We further model the instantiation of a statistical con-straint from another as a Bernoulli process. For a constraint b = f b ( e b ): c b , it means that we have probability c the constraint f b ( e b ) in the data. If we actually observe a constraint h = f h ( e h ): c h in the data, then the likelihood that h is instantiated from b is: p ( h | b ) = For example, if a constraint b = first( a 1 ): . 67 and another is h = first( a 1 ):1, then p ( h | b ) = . 67.
 Framework Overview The overall framework has been shown in Figure 3. In our design, we conceptually hypothesize that the data produced from the sources are guided by an underlying schema M , as explained as Eq.(2).

Hence, reacting to this concept, we design our matcher, being the reverse of data generation process in Eq.(2), as constructing a schema that best fits the observed data. First, the raw data, which are usually the Web pages contain-ing query results, are passed to a pre-processing layer, in which data extraction and cleaning are performed, to ob-tain the structured records. Then, the records are processed as instance models I s  X  X  by applying both the content anal-ysis (e.g., extracting features and calculating their frequen-cies) and the predicate functions (e.g., enumerating the con-straints U s  X  X  exhibited in the data). Finally, the Matchers collaborate together to seek the most possible schema M . This final step is the core step of our framework. An algo-rithm to it will be given in the following section.
Overall, our framework translates the problem of instance-based matching into a schema-discovery problem. With such a strategy, we leverage not only the data instances (mod-eled as domain fields) but also the regularities observed from the data (modeled as statistical constraints) in a principled way. This conceptual view is novel for instance-based match-ing. Traditional instance-based approaches seek and apply various heuristics to determine the similarity between fields based on their instances, and then pick up a set of most sim-ilar field pairs as matches. We view instance-based match-ing as constructing a schema to describe the input data. If more sources are observed, the derived schema is believed more effective to model the whole domain.
As Section 3.2 motivated, to solve our matching problem, we need to discover either an optimal matching Y  X  or an optimal schema M  X  . If one of them is obtained, the other can be derived (using Eq.(3) and (4)). However, they both are not available at the beginning. As a solution, we thus develop an iterative optimization approach by discovering the matching Y and the schema M concurrently. The basic idea is to start an initial guess of the matching Y and iter-atively improve it using the schema M that is derived from the current estimation of Y .
 The Overall Algorithm We first describe the overall algorithm HoliMatch , shown as Figure 4. It has two phases: initialization and iterations. In the initial step, it first applies a set of predicate functions F on the input data to enumerate the instance constraints, and then calls InitMatch to generate an initial matching, to be the start point for iterations. In each iteration, for each source s , it uses all the other sources (i.e., S  X  X  s } ) to learn a schema M  X  s , and applies it to re-label source s (correspond-ing to the operation implied by Eq.(4)). Removing source s from training is to avoid any potential bias of applying the learned schema back to source s . With re-labeling, it thus updates the matching between source s and other sources. At the end of each iteration, we collect n modified match-ings. A meta-matching module is then called to aggregate these n intermediate matchings into a final matching (the operation implied by Eq.(3)). The whole process is repeated several times. At the end, the final matching and schema are returned.

Note that the matching between sources is mutually up-dated by iteratively applying SchemaMatch (leveraging richer field and constraint models) and MetaMatch (leveraging the effects of cross reference). Below we describe each function. EnumRelations : Enumerate Relations We need to identify the constraints occurring in the input data. Currently, we design our system to accept the input predicate functions with the following specification. Definition 3 (Predicate Function): A k -element boolean predicate function f is defined in a general form as: where i 1 , . . . , i k denotes which elements to check their sat-isfaction with the predicate f and X is the original data. The predicate function returns true if the input satisfies the predicate and false otherwise.
 Example 6 (Predicates): Here we give some illustrative predicate functions: num  X  ) if two elements have numbers (recognized by some regular expressions, like re num = /[0-9]+(.[0-9]+)?/), they can be compared by their values num  X  ( i 1 , i 2 , X s )  X  re num ( x si 1 )  X  re num ( x pos ) an element occurs before another element: This representation is convenient to implement many con-straints. In general, we can think of these predicate func-tions as extracting structural features from the data. In our current system, we use predicates on field distribution (e.g., exist), positions (e.g., first, pos , last, adjacent), number, time and date comparison (e.g., num  X  , time  X  ), etc. LearnSchema : From Matching to Schema LearnSchema aims to construct a schema based on a given matching. We first group the matched source fields together. Each group is then trained as a field model.

All the data instances will be parsed as a bag of tokens. In addition, we use basic data types as extra content features, including work , integer , float , date , time , punct uation, and html-tag . For example, a text  X $39.65 X  will be transformed, parsed by some regular expressions to recognize the above data types, as a bag of features {  X $ X ,  X 39.65 X , float , punct } .
As Section 1.1 motivated, a field is an optional label plus a set of values. We thus model it as a 2-state HMM (Hid-den Markov Model). Figure 5 shows the model topology, where  X   X  X  are the initial probabilities and  X   X  X  encode state emission probabilities. Learning an HMM a given a set of instances and computing the probability p ( z | a ) for a given instance z will follow the standard HMM training and in-ference algorithms. As HMM has been quite standard and well-studied, we omit it here for space reason. Readers, if interested, please refer to [17] for the details. Notice that as mentioned in Section 3, any other way of similarity measures can be used instead, but this is not our focus in this work.
For the statistical constraints of fields, we first substitute the elements in the instance constraints with the domain field labels. Then, the confidence of each constraint is com-puted as the proportion of the sources containing that con-straint. Example 5 has given the illustration.
 SchemaMatch : From Schema to Matching Given the domain schema, matching becomes labeling the elements of sources with the appropriate domain fields. We need to consider both the content and constraints when doing labeling. Let the schema be M = ( A, B ) where A = { a 1 , . . . , a m } and B = { b 1 , b 2 , . . . } . For any X { x s 1 , . . . , x s` s } , we seek a label assignment Y s = { y where y i  X  A and x si is assigned as label y i . Let X  X  define q ( a ) as the a posteriori probability that y i = a given an observation instance I s and the schema M : The most likely value for each y i is thus: Before continuing, let X  X  define z as a normalization operator: If  X  = (  X  1 , . . . ) and  X  = (  X  1 , . . . ), then  X  = z X  means  X   X  / ( P j  X  j ); that is,  X  is the normalized version of  X  .
Let  X  i ( a ) be the a priori probability of choosing y i i.e.,  X  i ( a ) = p ( y i = a |M ), and let  X  j ( y j ) denote p ( x To compute q i ( a ), we have the following derivation: q i ( a ) = p ( y i = a |I s , M ) The above formula consists of three terms. The first term  X  ( a ) indicates how likely x i is an instance of y i . Since it depends only on the content part, we name it as the intrin-sic evidence. The second term  X  i ( a ) considers the a priori distribution of domain fields. Since we can model this in constraints (i.e., using the predicate  X  X xist X  as illustrated in Example 2), we assume  X  i is uniform. The third term E i ( a ) takes into account the auxiliary information introduced by the constraints. We thus call it the extrinsic evidence. It is infeasible to compute q i ( a ) directly using Eq.(7) since E ( a ) considers the effects from all elements, and has com-plexity m ` s  X  1 . Thus, we further use an approximation ap-proach. The idea is to take into account the effect of each constraint separately, and then aggregate their predictions. For each h j  X  V s with the corresponding b j  X  B , let their constraint be f j ( y i 1 , . . . , y i k ), we define q i,j ( a ) = z X  i ( a )  X  i ( a ) The aggregated probability is then obtained: The new version of complexity is | V s | m k  X  1 , where k is the maximum number of elements taken by any of the con-straints in V s . Because, in practice, the involved constraints are with low number of elements (e.g., 2 or 3-element predi-cates; for example, pos (  X  ,  X  ) accepts 2 elements), the com-putation is effective.
Thus, for each variable y i , we assign the a with the max-imum q i ( a ) value, as shown in Eq.(6). Although the whole derivation appears complicated, the final computation steps are straightforward, as shown in Eq.(8) and (9).
 MetaMatch : Meta Matching In HoliMatch steps 10 X 11, given the current matching Y , we re-position each source individually; together we obtain n matchings and thus seek to aggregate them to achieve a final matching that is most consistent with these matchings. For this purpose, we apply a meta approach on top of these n matchings. Note that this step mainly leverages the cross effects, i.e., two elements mismatched in one matching might be recovered by cross-referencing other matchings. First, we adopt F-measure to measure the consistency. The F-measure of a group j to another group i is defined as where R i,j (recall) and P i,j (precision) are defined as n and n i,j /n j , respectively, where n i,j is the number of com-mon elements of group i and j , n j is the size of group j , and n i is the size of group i . For two matchings m 1 and m using m 1 as testee and m 2 as tester, F-measure is defined as the weighted average of all the group F-measures: where n is the total number of elements and n i is the number of elements in tester group i .

Then, we generate candidate matchings. The similar-ity between two source fields is designed as the number of matchings that group them together. We first treat each source field as a group itself; then, we iteratively merge the two most similar groups as a new one. Thus, during each iteration, we produce a set of groups and treat it as a match-ing candidate. Let these candidates generated during this process be C and the n matchings be R = { r 1 , . . . , r final matching is obtained as: InitMatch : Initial Matching InitMatch aims to guess an initial matching, to be the start point of the iterative computation. Here, we re-use the ar-chitecture of HoliMatch for this purpose. Since there is no given matching to start, we learn a schema for each source and use it to label the other sources. This gives us n total matchings, which are then fed into MetaMatch to achieve a final matching as the output. Figure 6 sketches these steps. Note that InitMatch can be considered as returning a match-ing result that aggregates n x( n -1) pairwise matchings X  the matchings of all source pairs.
For evaluation, we test our framework on the query results obtained from four domains. We compare it with different methods in both the correct and real extraction data, to see whether the framework can generally perform well.
 Data set.
 To setup, we collected data from four domains: a irfare , b ook , c ar , and cd -album . For every domain, we collected 10 sources from the deep-Web. They are all popular sources X  for exam-ple, book sources include { amazon,bn } .com; airfare sources include { expedia,united,aa } .com. For each source, we sub-mitted three or four queries; we used the same queries for all sources X  therefore, the obtained data should be similar and thus benefit matching. Example queries were { artist = X  X nya X  } for albums and { titile = X  X arry Potter X  } for books. For each query, we collected the first response list page, which roughly contained 10 records. Hence, for each domain, there were 10 sources, totally 30-40 sample pages, containing 300-400 records. We used this data set for experiments.

For evaluation, we first applied some existing data extrac-tion tools (we will mention them when dealing with real ex-traction data in Section 5.2) on the pages to extract the data records and fields, and then manually corrected the extrac-tion errors. We further identified the correct field matching between sources, thus creating a clean integrated table to be the correct data for evaluating various comparisons. Table 1 summarizes these data; for example, airfare has a total 43 fields among all sources, in average 25.9 fields per source, and 77% overlapping of fields between any two sources (source overlap).
 Comparison Methods We expect to compare our framework on the matching ac-curacy both between two sources and multiple sources, so we design several comparison methods accordingly.

First, we adopted the best-first strategy for matching two sources. Let X  X  name it as PairMatch. Given any two sources, PairMatch continuously picks up the two most similar fields as matches until there is no valid matched pair. Previous studies [15] have shown that this approach could produce best results for a variety of schema matching tasks. In ad-dition, we also adopted the corpus-based approach [13] as a pairwise method when comparing pairwise performance.
Then, we designed several multiple-source matching strate-gies (there is not much such work). First, we adopted clus-tering [20]; let X  X  name it ClusMatch: It first treats each in-put field as a singleton cluster; then it merges the two most similar clusters as a new one iteratively until a pre-specified cluster number is reached. The fields clustered together are considered matched.

We also extended pairwise matching PairMatch to work in a multiple-source manner, by exploring two scenarios: First, ChainMatch: Given a sequence of sources (e.g., 1-2-3-4), it first matches each two consecutive sources (e.g., 1-2, 2-3, 3-4) and then combines their matchings, through the bridge sources in the linear chain (e.g., 2 and 3). Sec-ond, ProgMatch: Given a sequence, it matches the first two sources (e.g., 1-2), combines them as a bigger source us-ing the matching result, and progressively adds into it one source by another (e.g., becoming (((1-2)-3)-4). These two approaches show how to match multiple sources using exist-ing pairwise matching, and thus provide us the baselines for comparison.

Note that InitMatch can also be viewed as an extension of using pairwise matching. As illustrated in the algorithm of Figure 6, given n sources, it matches every source pair and then generate (via meta-matching) a holistic matching that is most consistent with these pairwise matchings.
 Performance Metric To measure the matching performance, we compare the re-sult with the manually-prepared integrated table. The match-ing accuracy is measured using F-measure [7]. The formula we use has been presented in Eq.(10). Given the result matching m and the correct matching c , the F-measure is F ( m, c ), indicating how close m is to c .

Below, we first extensively evaluate our work in the correct data, and then test it in the real extraction data.
We first evaluated how the various matchers work in the correct data for multiple sources. We ran these matchers on the manually-extracted data, i.e., with correct field extrac-tion. For each domain, we used all 10 sources as the input. To run ClusMatch, which needs a pre-given number of clus-ters, we used the correct field number of each domain (see Table 1; for example, the correct field number of airfare is 43, and that of book is 18). For ChainMatch and ProgMatch, we simulated an incremental matching process by randomly ordering the sources and adding them one by one into the approaches. For each domain, we repeated the whole pro-cess 30 times, and recorded the average. We perform the following analyses.

Matchers : Table 2 shows the results of different matchers on the 4 domains. Overall, ChainMatch and ProgMatch per-form relatively worse. The reason, as we analyze, is that the errors of isolated pairwise matching would be accumulated when extending to multiple sources; hence, their overall per-formance is not good. ClusMatch performs generally well ex-cept for the domain airfare . The main cause is the existence of many ambiguous fields (depart-time, arrival-time, and so on), which HoliMatch can handle better with the domain schema model that learns some regularities from the match-ing results. InitMatch, although not better than ClusMatch, performs quite consistently for the four domains. From this comparison, HoliMatch indeed performs constantly better than the other matchers, in these 4 testing domains.
Iterations : When running HoliMatch, we also recorded the results of each iteration. Figure 7 plots them. From the curves, it shows that the performance improves as the itera-tions increase X  the model learned from the previous holistic matching results can indeed help achieve better matching. These curves also indicate that the performance converges quickly. For domains book , car , and album , it takes only 2 X 3 iterations to converge. For airfare , which appears more com-plicated, it needs more iterations. However, even in such a
Figure 7: Matching performance for iterations (a) case, running a few iterations already achieves good perfor-mance, e.g., .84 for 3 iterations. In general, a few iterations are enough to obtain performance convergence.
 Sources : We then look at the factor of source number. We fed different numbers of sources to each matcher. For HoliMatch, we ran it with 3 iterations, with which it al-ready could achieve good results (as analyzed above). Fig-ure 8a shows the accuracy to the numbers of sources for the book domain. It shows that the accuracy in general de-creases as the number of sources increases. The matchers that are originally designed to handle multiple sources, i.e., HoliMatch and ClusMatch, are abler to tolerate the incre-ment of sources X  their performances degrade less. HoliMatch in general can outperform others.

Figure 8b shows the time each matcher spends. It is clear that HoliMatch takes more time due to its  X  X terative X  and more complicated computation. The time increase is roughly linear to the number of sources. As it can produce better results and such matching is performed as an offline task for constructing the integrator, the computation is quite acceptable. Note that InitMatch is part of HoliMatch, so we don X  X  measure its running time separately.

Pairwise : We also examine how well the matching be-tween any two sources is when multiple sources are pro-cessed together. For this comparison, instead of PairMatch, we also particularly compare the corpus-based matching [13] because it shows a different way to utilize multiple sources to help matching two sources X  that is, given two schemas to match, it augments the elements of the two candidate schemas using the evidences obtained from a corpus of other schemas, where such augmented evidences are considered helpful for determining the similarity between the elements. We thus implemented this augmenting idea: Let X  X  name it CorpusMatch. Among the 10 sources, to match any two of them, we treated all the other 8 sources as the corpus. CorpusMatch would augment each candidate field with the instances from its similar fields found in the corpus.
For the space reason, we only report the pairwise perfor-mance for the sources in airfare (as it appears harder), as listed in Table 3, where each cell contains ( x, y ) a b : ( x, y ) means matching source x and y , a is the performance of us-ing CorpusMatch, and b is the performance from HoliMatch.
In this comparison, it clearly indicates that matching mul-tiple sources together, with our approach, helps the match-ing of any two sources. For each source pair, the perfor-mance by HoliMatch is generally much better. The average performance of CorpusMatch is .80; but HoliMatch achieves .95 (PairMatch achieves .77). While CorpusMatch augments
Figure 9: Performance on the input with errors. the target schemas using the static corpus, it does not uti-lize the dynamic information learned during matching other sources. Treating other sources as a side corpus is not the most effective way of utilizing them. Thus, if there exist multiple sources, e.g., in most integration tasks, then it is beneficial to match many sources together.
As automatic extraction usually produces results with some errors, we wonder how the matchers, which will be the con-sumers of such extraction data in automatic integration, per-form on the data with extraction errors, i.e., some data fields are not extracted correctly.

To examine this, we applied a real extraction tool on the collected query results (we used TurboSync [4], which would generate data with different errors during the extraction pro-cess). For each domain, we collected ten sets of extraction results, with different percentages of errors. We then ap-plied our testing matchers on these results. Figure 9 plots the matching performance, where each graph is for one do-main. To examine the correlation of extraction errors and matching accuracy, in each graph, we also plot the curve of extraction error rate for the data sets, where the extraction error rate is the average percentage that a field is extracted incorrectly in a record. Since the performance of Chain-Match is similar to ProgMatch, we ignore it in the graph.
These curves clearly show that, no matter which matcher we adopt, the matching performance has a negative corre-lation with the extraction error rate: The matching perfor-mance gets improved when the error rate decreases. This phenomenon indicates that the errors or noises contained in the input will cause the matcher not to obtain good per-formance. Thus, a good extractor is really important for schema matching, as well as the overall data integration.
Comparing the matchers, we observe that ProgMatch again performs worst. ClusMatch is now ranked to the third, gen-erally worse than InitMatch, which is not as it did in the correct input. This is likely because that noises or errors in the input will affect the computed similarity between data fields, which ClusMatch relies on to decide to merge clus-ters. Conversely, InitMatch performs quite well in such an imperfect situation. The reason is perhaps that it performs some meta-matching to only keep those strongly connected fields as matches, therefore is less impacted by the errors. Our HoliMatch, among all matchers, still performs well and shows that it is reliable.
Starting from the task of integrating query results, in this paper we address instance-based schema matching on mul-tiple sources. We view discovering matching as constructing a domain schema, which can encode instances and various structure information in a principled way, and also naturally support holistic, multiple-source schema matching. The ex-tensive experiments show that the framework is promising.
