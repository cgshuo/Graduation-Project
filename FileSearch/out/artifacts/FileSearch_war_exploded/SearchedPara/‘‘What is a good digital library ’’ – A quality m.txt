 1. Introduction
What is a good digital library? As was pointed out in Fuhr, Hansen, Mabe, Micsik, and So  X  lvberg (2001) , the answer to this question depends on whom you ask. Many consider that what differentiates a good DL assessment and enforcement of those quality properties, thereby supporting prevention and elimination of these issues in a common framework. Moreover, the formal nature of our DL theory allows us to add preci-sion as we define specific DL quality dimensions and corresponding numeric indicators. the stronger term quality measure . Only after one has a number of indicators, and they are validated example, through focus groups) 4 the proposed quality indicators do not qualify as measures yet. Also, it should be stressed that the proposed quantities are only approximations of or give quantified indication of term  X  X  X easure X  X  when talking about standard measures that have long been used by the CS/LIS communities. The distinction should be clear in context.

This article is organized as follows. Section 2 provides background and context necessary to understand the applications to key DL concepts. Section 7 deals with the connections between the proposed dimensions and
Borgman et al. X  X  Information Life Cycle ( Borgman, 1996 ). Section 8 shows the evaluation of the proposed quality model with a focus group. Section 9 covers related work and Section 10 concludes the article. 2. Background and context
In this section, we summarize the 5S theory from Gonc  X alves et al. (2004) . Here we take a minimalist approach, i.e., we define, according to our analysis, the minimum set of concepts required for a system to be considered a digital library. Accordingly, let: Structs be a set of structures, which are tuples, ( G , L , F ), where G =( V , E ) is a directed graph and F :( V [ E ) ! L is a labeling function.
 tor space.

Scs ={ sc 1 , sc 2 , ... , sc d } be a set of scenarios where each sc sequence of events that also can have a number of parameters p tional states; parameters represent specific variables defining a state and their respective values. ural numbers ( a , b ) corresponding to a segment of a stream.

Coll ={ C 1 , C 2 , ... , C f } be a set of DL collections where each DL collection C set of digital objects. Each digital object do k =( h k , Stm Stt 2 k  X  Structs , X k  X  St 2 , and h k is a handle which represents a unique identifier for the object.
Cat  X f DM C associated with nodes.
 them (see Gonc  X alves et al. (2004) for details on the semantics of these operations).
Serv ={ Se 1 , Se 2 , ... , Se s } be a set of services where each service Se Soc =( Comm , S ) where Comm is a set of communities and S is a set of relationships among communities.
SM ={ sm 1 , sm 2 , ... , sm j } and Ac ={ ac 1 , ac 2 , ... , ac
Being basically an electronic entity, a member sm k of SM distinguishes itself from actors by defining or implementing a set of operations f op 1 k ; op 2 k ; ... ; op by a triple ( n ik , sig ik , imp ik ), where n ik is the operation X  X  name, sig includes the operation X  X  input and output parameters), and imp operations define the capabilities of a service manager sm
C:collection) 6 indicates that a SearchManager contains or defines an operation  X  X  X atch X  X  with two para-meters: a query and a collection.
 According to the 5S formal framework a digital library is a 4-tuple ( R , Cat , Serv , Soc ).
The set of main DL concepts defined above was derived from a comprehensive review of the DL related sions described below.

Table 1 shows a summary of proposed candidate dimensions of quality for some of the most important DL concepts defined above and factors affecting the measurement of the corresponding quality dimensions. following sections explain these indicators in detail by: (1) motivating them and discussing their meaning/utilization; (2) formally defining them and specifying their corresponding numerical computation; and same way that the formalized 5S theory helps to precisely define the higher level DL concepts used here, we will use these formalizations to help define the quality indicators and their corresponding computations. 3. Digital objects 3.1. Accessibility associated with that type of accessibility.

Let access constraint be a property of some metadata specification of a digital object do
Also let struct _ streams ( do x )= X x be the set of structured streams of do digital object do x to an actor ac y is: 0, if there is no collection C in the DL repository R such that do otherwise acc  X  defined as an indicator function: by rights management, but also by technological constraints, such as lack of Acrobat Reader to open a full-text paper in PDF format, temporary network disconnection, or restriction on the number of simultaneous themselves and of the relationships between the actor and the objects.

Example of use. At Virginia Tech, a student can choose, at the moment of submission, to allow her elec-tronic thesis or dissertation (ETD) to be viewed worldwide, by only those at the originating university, or regarding patents or publication of results in journals/conferences.

Therefore the accessibility acc ( etd x , ac y ) of a Virginia Tech ETD etd 0, if etd x does not belong to the VT-ETD collection; otherwise defined as an indicator function:
Table 3 shows a partial view of the numbers of VT-ETDs that are unrestricted (worldwide, accessibility = 1 to everybody), restricted to the VT campus (accessibility = 0 worldwide, 1 to members of VT along with the degree of accessibility acc ( etd x , ac y overall accessibility to non-VT actors 1/6 or 0.167. Note that accessibility for the Virginia Tech ETDs has 3.2. Pertinence ground, current task, etc.

Let Inf ( do i ) represent the  X  X  X nformation X  X  8 (not physical) carried by a digital object do nents, IN ( ac j ) be the information need 9 of an actor ac interaction and ambient environment. A complete formalization of context is out of the scope of this work.
The reader is referred to a workshop on  X  X  X ontext in Information Retrieval X  X  for a number of papers on the subject ( Ingwersen, van Rijsbergen, &amp; Belkin, 2004 ).
 ges Ac , as: users : set of actors with an information need who use DL services to try to fulfill/satisfy that need, query. We also assume that an external-judge cannot be assigned to judge the relevance of a document to a query representing her own information need, i.e., at each point in time users \ external judges = ; .
The pertinence of a digital object do i to a user ac j at a time k is an indicator function nence ( do i , ac j , k ): Inf ( do i )  X  IN ( ac j )  X  Context ( ac 1, if Inf ( do i ) is judged by ac j to be informative with regards to IN ( ac 0, otherwise.

Since pertinence is a subjective judgment made by a user in a particular context it can ultimately can be accessed only by the user themself. 3.3. Preservability processes to which the object is submitted (e.g., migration).

There are four main technical approaches to digital preservation: (1) Migration : transforming from one digital format to another format, normally a successive subsequent (3) Wrapping : packaging the object to be preserved with enough human readable metadata to allow it to be
Note that here we are not considering physical deterioration of the medium in which the object is stored, problem, for which  X  X  X efreshing X  X  is the normally used approach.
 on migration issues.
 we can define the preservability of a digital object do i As mentioned before, obsolescence is a complex notion to capture, depending on many contextual factors.
Since the choice of how to deal with obsolescence generally depends on resources at the disposal of the DL ognize many factors that can affect the cost, including: capital direct costs:  X  software development/acquiring or license updating for newer versions,  X  hardware (for preservation processing or storage); indirect operating costs:  X  identifying candidate digital objects,  X  evaluating/examining/negotiating intellectual property issues and rights,  X  storage, and  X  staff training (on software/procedures).
 do within the context of the specific digital library dl .

The fidelity of the migration process p of a digital object do on the inverse of the distortion or noise introduced by the migration process mp , i.e.,
Distortion can be computed in a number of ways depending on the type of object and transformation ( Say-ood, 1996 ). One very common measure, when converting between similar formats, is the mean squared error (mse) . In the case of a digital object, mse can be defined as follows. Let { x and { y n } be the converted/migrated stream; the mean squared error mse  X f x where N is the size of each stream. The average mean square error for the whole object do digital object will be converted exactly.

Example of Use. Let us consider the following scenario adapted from Hunter and Choudhury (2004) .In 2004, a librarian receives an email notifying her that a special collection ware no longer supports TIFF 5.0. The librarian decides to migrate all digital photos to JPEG 2000, which now has become the de facto image preservation standard, recommended by the Research Libraries Group (RLG) ( Hunter &amp; Choudhury, 2004 ).

The librarian does a small search for possible migration options and finds a tool, costing $500, which con-20 hours. Assume also that the hourly rate in this library is $66.60 per hour per employee.
TIFF 5.0, dl ) = (1/9, ($500+ $66.60 * 20)/1000) = (0.11, $1.83). 3.4. Relevance carried by digital objects and their metadata specifications.

The relevance of a digital object to a query is an indicator function Relevance ( do 1, if do i is judged by an external-judge to be relevant to q ; 0, otherwise.

The most common measures for relevance estimates/predictions are based on statistical properties of the streams of the digital object and the queries. For example, in the vector space model, this relevance is between the actor and her information need ( Foskett, 1972; Kemp, 1974 ).

The distinction we have made between pertinence and relevance is derived from a view held by part of the information science community ( Cosijn &amp; Ingwersen, 2000; Foskett, 1972; Kemp, 1974; Saracevic, 1996, 1975 ). We have just formalized the two notions in the context of our framework. In Saracevic X  X  work, for cognitive information need of a user and the objects retrieved. Cognitive correspondence, informativeness, novelty, information quality, and the like are criteria by which cognitive relevance is inferred.
The external judges should evaluate the relevance of the object to the query without the cognitive load applicable. 3.5. Significance culated based on raw citedness  X  the number of times a document do tify/measure.

Example of Use. We used 98,000 documents from the ACM Digital Library, which corresponded to approximately 1,093,700 (outgoing) citations (average of 11.53 citations per document). Table 4 shows the top five documents in the ACM collection with the highest values of significance.

Notice that significance, as defined, is supposed to increase with time, as more people take notice of the see below, as well) since older publications have more chance of being cited. 3.6. Similarity relevant or pertinent object has a good chance of also having these properties, but an object too similar to another supposedly different object can reveal a lack of quality (e.g., plagiarism, which might be found through plagiarism software) unless it is a variant version which can be identified through a de-duping process.

Similarity can be measured based on the digital object X  X  content (streams) (e.g., use and frequency of Similarity measures also may use link or citation information to compute the relatedness of two objects. coupling ( Kessler, 1963 ), and the Amsler measure. The last one is a combination of the previous two, so we will explain only the Amsler measure ( Amsler, 1972 ).

According to Amsler, two documents d i and d j are related if (1) d d and d j cite the same document, or (3) d i cites a third document d parents of d i , and let Cd i be the set of children of d defined as
Eq. (2) tells us that, the more links (either parents or children) d related. The absolute Amsler degree of a document d i in collection C is defined as
Example of use. Table 5 shows the top five documents in the ACM collection we studied with the highest absolute values of Amsler. 3.7. Timeliness cited.
 since it X  X  a measure that: (2) is independent from the actor that receives the object and the time the object is delivered; and (3) reflects the overall importance of the object inside its community of interest.
Therefore the timeliness of a digital object do i can be defined as: (current time or time of last freshening) (creation time or publication time), if object is never cited. quently. Notice that for this indicator, the lower the timeliness value, the better.
Example of use. Fig. 2 shows the distribution of timeliness (0 through 10) for documents in the ACM DL be cited. 4. Metadata specifications and metadata format
Three main dimensions of quality can be associated with metadata specifications and metadata formats: accuracy, completeness, and conformance. 4.1. Accuracy
Accuracy is defined in terms of properties of a metadata specification for a digital object. Accuracy of a words, a metadata specification can be seen as a labeled digraph. The triple st =( F ( v statement (derived from the descriptive metadata specification), meaning that the resource labeled F ( v intended use, etc. Examples are given below. Thus, the degree of accuracy acc ( ms ms x can be defined as Example of Use. To illustrate the application of such an indicator we used OCLC X  X  NDLTD Union Catalog.
We chose OCLC X  X  NDLTD Union Catalog because of its numerous problems regarding metadata accuracy, author information is very commonly found in the title field ( X  X  X he concept of the church in the thought of
Rudolf Bultmann  X  by Paul E. Stambach X  X ) and sometimes the abstract contains all kinds of information (see below) but not the thesis/dissertation X  X  summary. We defined the following rules for the dc.author, dc.title, and dc.abstract fields.
 author information; 0.5 otherwise. In case it is empty or null it receives a 0 (zero) value. 0 otherwise. The decision of whether a dc.abstract field corresponds to a summary or not was based on the tation X  X , it is not a summary; (2) if dc.abstract contains phrases like  X  X  X itle from page of PDF file X  X ),  X  X  X ocument formatted into pages X  X ,  X  X  X ncludes bibliographical references X  X ,  X  X  X ode of access X  X , among others, it is not a summary.

According to these two rules the average OCLC accuracy for all its metadata records (approximately 14,000 records, in September 2003) 15 was calculated as around 0.79, assuming a maximum of 1. 4.2. Completeness
Completeness is a pervasive quality dimension that is associated with many of the DL concepts. The general that concept). This notion can be adapted or instantiated to specific DL concepts. specification ms x can be defined as 16
Notice that the assumption here is that the more complete, the better. However, we acknowledge that there can be situations, for example, determined on purpose in accordance with local needs, in which this is not always true.
 catalogs of the NDLTD Union Archive administered by OCLC as of February 23, 2004, relative to the Dublin
Core metadata standard (15 attributes). 4.3. Conformance
The conformance of a metadata specification to a metadata standard/format/schema has been formally issues.
A metadata specification ms x is cardinally conformant to a metadata format if: (2) each attribute att xy of ms x appears at least once if att (3) att xy does not appear more than once if it is not marked as repeatable in the schema. sidered conformant, if it is not marked as mandatory in the schema. The degree of conformance of a metadata specification ms x can be defined as
The degree of conformance of att xy is an indicator function defined as 1 if att ified in the above definition; 0 otherwise.
 Example of use . Fig. 4 shows the average conformance of the metadata records in the catalogs of the NDLTD
Union Archive, relative to the ETD-MS metadata standard for electronic theses and dissertations. it is defined as non-conformant.
 5. Collection, metadata catalog, and repository 5.1. Collection completeness way to determine the ideal real-world collection such as in the Web or in hidden databases. Advanced judi-cious sampling or probing of alternative repositories whose completeness has been established manually can give crude estimates ( Ipeirotis &amp; Gravano, 2002 ). An example could be to approximate a measure of the completeness of a computer science collection of papers on a specific topic by sampling the ACM or
IEEE-CS digital libraries, DBLP, and some other commercial publishers X  on-line databases. In other cases ness ( C x ) of a collection C x , can be defined as the ratio between the size of C tion, i.e.,
Example of use. The ACM Guide is a collection of bibliographic references and abstracts of works published by ACM and other publishers. The Guide can be considered a good approximation of an ideal computing in the Guide comes from Proquest-UMI, which receives copies of almost all dissertations defended in the completeness of several CS-related collections 18 when compared with the Guide. 5.2. Catalog completeness and consistency The degree of completeness of a catalog DM c for a collection C can be defined as have the same metadata description. A catalog in which this occurs is therefore considered inconsistent. It should be noted, though, that an object can have more than one metadata specification (e.g., a Dublin Core and a MARC one).

Consistency, accordingly, is an indicator function defined as 0, if there is at least one set of metadata specifications assigned to more than one digital object; 1, otherwise.

Example of Use . In April 2004, the NDLTD Union catalog administered by OCLC tried to harvest data from the Brazilian Digital Library of Electronic Theses and Dissertations (BDTD). Because of problems in
BDTD X  X  implementation of the OAI protocol and problems with the Latin character set handling by OCLC, only 103 records were harvested from the repository. The BDTD collection contained 4446 records. Therefore the completeness of the harvested catalog for BDTD in OCLC would be completeness(BDTD in OCLC
Union Catalog) =1 (4446 103)/4446 = 0.023. Note that completeness significantly improved by 2006. 5.3. Repository completeness and consistency itory R is defined as terms of these two components. Therefore, repository consistency is an indicator function defined as 1, if the consistency of all catalogs with respect to their described collections is 1; 0, otherwise.
 Example of use . We will use the ACM Guide as the ideal collection. Not considering the Bibliography and of CITIDEL can be calculated as 4 (ACM + IEEE + NCTRL + NDLTD-CS)/11 (total number of collections) or 0.36. 6. DL services view. Issues in system construction, operation, design, and implementation should be considered here. 6.1. Effectiveness and efficiency
The two most obvious external quality indicators of DL services, as perceived by end users, are efficiency and effectiveness. Efficiency is most commonly measured in terms of speed, i.e., the difference between the times for request and response. More formally, let t ( e ) be the time of an event e , and let e and the final events of scenario sc x in service Se . The efficiency of service Se is defined as
Effectiveness is normally related to information satisfaction services and can be measured by batch experi-ments with test collections or through experiments with real users. Different types of information services 1999 ), extensively used to assess quality of searching or filtering services. 6.2. Extensibility and reusability
Regarding design and implementation of DL services, there are two main classes of quality properties: (1) those regarding composability of services; and (2) those regarding qualitative aspects of the models and this work we will concentrate on composability aspects but we acknowledge the importance and complexity of the latter issues.
 number of requirements including exporting clear interfaces, providing mechanisms/protocols for connections and passing of parameters, offering gateway or mediator services to convert between disparate document for-ascertain from a set of services and service managers that run or implement those services, which managers agers SM that run those services, two quality indicators of extensibility and reusability can be defined. Macro-Extensibility  X  Serv  X  X  is an indicator function defined as Micro-Extensibility  X  Serv  X  X  code of all operations of a service manager and sm x runs Se Since reuse/inclusion has a different semantics of extension, reusability can accordingly be defined as Macro-Reusability  X  Serv  X  X  Micro-Reusability  X  Serv  X  X  code of all operations of a service manager and sm x runs Se
Example of use. Table 7 shows the lines of code ( LOC ) needed to implement service managers that run sev-service managers) are implemented as ODL components ( Suleman, 2003 ). These services are searching, anno-tating, recommending, and (union) cataloging.

The wrapping services, the ones that really reuse and provide the services offered by the DL components, other components (like the user interface). However, the additional code for those wrappers is only a very small percentage of the total lines of code required for implementing the components. In the ETANA-DL pro-totype (in September 2004), only a few important services were componentized and therefore reused Macro-
Reusability(ETANA DL Services) = 4/16 = 0.25. However, Micro-Reusability = 3630/11,910 = 0.304 makes it clear that we can re-use a very significant percentage of DL code by implementing common DL services as components. Moreover, as more service managers are componentized, more code and managers are poten-tially inherited from/included by more DLs. 6.3. Reliability ability of a service Se x as
A failure is characterized as an event that (1) was supposed to happen in a scenario but did not, or (2) did happen but did not execute some of its operations, or (3) did happen, where the operations were executed, but the results were not the correct ones.
Example of use. Table 8 shows reliability figures for the most popular services of CITIDEL, according to a shows how flaws in design can be found with such quality-oriented analysis. 7. Quality and the information life cycle prevented, detected, and eliminated.

The connections are shown in Fig. 5 . The life cycle (see inner portion) has four major phases: information set of activities/services.

Similarity to other information, digital objects, or versions can be assessed at time of creation and modi-phase in the cycle deals with metadata creation and information organization and description; therefore all quality dimensions associated with metadata specifications are located here. Special metadata quality pro-ness, and conformance).
 tinence, significance) can be assessed during the utilization phase. 8. Evaluation: focus group and digital libraries.

This focus group meeting included a presentation of approximately 60 min duration about 5S and the pro-posed quality indicators (with examples) by the researchers/moderators, followed by a 30 min discussion.
Questions, comments, and discussions were allowed during the presentation. In particular, the discussions were focused around four questions: Are you able to understand the 5S model? How does it relate to (your) library world? How do the proposed indicators relate to your practices in the library?
Would you be willing to apply these measures to your (digital) libraries? 8.1. Presentation  X  discussions The moderator emphasized that to precisely define digital libraries was one of the main goals of the work.
When first confronted with 5S, some of the participants felt that the framework made sense, but the con-the participants also said that she had a hard time seeing how the 5S terminology maps to the concepts nor-framework was suggested. For example, another participant raised the question  X  X  X hat does a database mean in this framework? X  X . After learning that for that participant a database means a storage of documents, we concluded that it corresponded to the 5S notions of collections and repositories.

One of the most discussed aspects was the  X  X  X inimalist X  X  approach we took in this work. There was almost a essential in the library world  X  to the minimal DL. This raised concerns that we were dealing with DLs as standable by the general public and librarians. Finally some of the relationships among the services (e.g., between indexing and searching) and additional (traditional) DL services were discussed. ipants. Another question which drove part of the discussion was  X  X  X hat do you mean by  X  X ood X ? X  X  and  X  X  X y good you mean only from the user perspective? X  X  This shifted the presentation to the connections between the proposed quality indicators and the several phases of the information life cycle.
The discussion then shifted to each proposed quality indicator. Participants seemed to agree with most of objects. One participant argued that in some instances it is impossible to find the age of every object. It was proposed to have a categorization for  X  X  X geless X  X  objects  X  those never reviewed, reviewed in 5 years, words). There was a consensus that practical aspects of dealing with storage space and limited resources are rarely discussed in the field.

The strongest reactions were generated by the issues of catalog and collection completeness. It was thought indicators would be more applicable should be elaborated upon and that these indicators in some cases had more theoretical value than practical application. In the particular case study presented (viz., OCLC NDLTD
Union Catalog), it was conjectured whether the low values for completeness of one catalog  X  MIT  X  were due many indicators for each concept, one argued that we really did need several indicators to get something meaningful (e.g., practically useful indicators might be computable based on some function applied to some combination of several of our indicators). 8.2. Post-presentation discussion
The post-presentation discussion started with one of the moderators encouraging the participants to think much associated with 5S. He suggested that if the discussions were viewed like a novel, he would think that the  X  X 5S X  X  character had disappeared when quality was considered. between would be the ideal. The criticism was not restricted to our study, but also applied to most similar
Another important question was raised by another participant. In her own words:  X  X  X hat do I do with these
One of the moderators shifted the discussion to the broader questions of  X  X  X hich ideas apply to LIS? Which to DL? Which to both? X  X  The first reaction was that DL is only a part of the library; some things cannot be within LIS. The same participant expressed the personal opinion that 5S would not be much use to him but it this work to be practically useful.
 come a long way with 5S and that is extremely impressive, but more needs to be done before this thing gets widely accepted and practically used X  X . 9. Related work DL quality and evaluation is a very underrepresented research area in the digital library literature. ogy. However, his analysis concluded that there are no clear agreements regarding the elements of criteria, et al. (2001) proposed a descriptive scheme for DLs based on four dimensions: data/collection, system/tech-nology, users, and usage. We see the work proposed in this paper regarding DL quality issues and evaluation as a next, complementary step in this area, one that is based on a sound, formal theory for DLs. Papers in a workshop on  X  X  X valuation of Digital Libraries X  X  touched on some of the issues discussed here. be worth discussing whether the 5S is an appropriate model for facing this kind of (evaluation) issue and plified by recent activities coordinated as part of DELOS efforts. 10. Conclusion case studies. Connections with the Information Life Cycle and a focus-group-based evaluation of the model were also discussed.

This work may help current managers of digital libraries to begin to develop a more quantitative assessment as operational quality of service.

In future work we hope to extend our efforts toward developing a quality toolkit for digital libraries that 2003 ). Finally, we hope to connect this research with the development of curriculum materials that will be helpful for teaching and learning about digital libraries ( Pomerantz et al., 2006 ). Acknowledgements
Thanks go to sponsors of our work, which include: AFOSR (Grant F49620-02-1-0090), AOL, IMLS, NSF (Grants DUE-0121679, IIS-0325579, IIS-0535057) and CNPq project 5S-VQ (Grant MCT/CNPq/CT-INFO 551013/2005-2). Thanks also go to those in Virginia Tech X  X  Digital Library Research Laboratory, and to all those involved in our various related projects.
 References
