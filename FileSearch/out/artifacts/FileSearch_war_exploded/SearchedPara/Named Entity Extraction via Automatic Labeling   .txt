 Named entity extraction is a f u ndamental task for many knowled g e en g ineerin g appli-since the hi g h cost of labelin g . For example, the En g lish dataset for the CoNLL 2003 shared task consists of 14,987 sentences for fo u r entity cate g ories, P ER, LOC, ORG, learnin g al g orithms have reached their capacity. Th u s the major concern in this paper is how to prepare trainin g data for entity extraction on the Web. matically labelin g known entities in doc u ments. For examples, personal names, loca-tion names, and company names can be obtained from a Who  X  s Who website, and pose a semi-a u tomated method to collect data that incl u de known named entities and label answers a u tomatically. While s u ch trainin g data may contain errors, self-testin g can be applied to filter u nreliable labelin g with less confidence. from the other two classifiers in order to prepare new labeled trainin g data for learn-in g . By estimatin g the error rate of each learned classifier, we can calc u late the max-im u m n u mber of new consens u s answers to ens u re the error rates are red u ced. 
This paper extends o u r previo u s work on semi-s u pervised seq u ence labelin g based on tri-trainin g for Chinese person name extraction [4] and compares vario u s selection methods to explore their effectiveness in tri-trainin g . We g ive the complete al g orithm for the estimation of initial error rate and the choice of a label seq u ence with the lar g -CRF (conditional random field) with 7000 known celebrity names has a performance random selection which o u tperform the S2A1D (Two A g ree One Disa g ree) approach proposed by Chen et al [3]. u ments, which is one of the information tasks to test how well a machine can u nder-stand the messa g es written in nat u ral lan gu a g e and a u tomate m u ndane tasks normally performed by h u man. The development of machine learnin g research from classifica-tion to seq u ence labelin g s u ch as the Hidden Markov Model (HMM) and the Condi-tional Random Field (CRF) [11] has been widely disc u ssed in recent years. While s u pervised learnin g shows an impressive improvement over u ns u pervised learnin g , it approaches are proposed as will be disc u ssed next. 
Semi-s u pervised learnin g refers to techniq u es that also make u se of u nlabeled data for trainin g . Many approaches have been previo u sly proposed for semi-s u pervised thods [14] and information-theoretic re gu larization [13]. In contrast, altho ug h a n u m-accordin g to a different philosophy. classes u sin g only 12 labeled web pa g es as examples [2]. This co-trainin g al g orithm they cond u cted their experiments on the same (WebKB co u rse) data set u sed by [2]. 
Goldman and Zho u relaxed the red u ndant and independent ass u mption and pre-separate classifier from the provided labeled data [4]. Empirical res u lts demonstrated that two standard classifiers can be u sed to s u ccessf u lly label data for each other. If the answer was not draw (eq u al answers) then we co u ld tr u st the answer is correct as trainin g data to u pdate classifier  X   X  in the next iteration. 
While tri-trainin g has been u sed in many classification tasks, the application in se-most probable label seq u ence from each model and u sed the a g reement meas u re as 
S2A1D). label res u lt by  X   X  . The process iterates u ntil no more u nlabeled examples are availa-ble. Th u s, Chen et al.  X  s method does not ens u re the P AC learnin g theory. In this paper, we propose a semi-s u pervised learnin g model for named entity reco g -nition (NER). The idea of semi-s u pervised trainin g comes from two aspects: the strated in Fi g . 1. 3.1 Tri-training for Se q Let L denote the labeled example set with size | U | . to label the answer of each g ive the same answer, the n trainin g example, i.e. L ( i,j,k  X   X  1,2,3  X  ,i  X  j  X  k ). To when re-train h  X  , Eq. (2) m where  X   X   X  denotes the erro r in the  X  -th ro u nd u sin g the examples by  X   X  and  X   X  b y same label, as shown in Eq .
If |  X   X   X  | is too lar g e, s u ch select maxim u m  X  examp l  X   X  , i.e.  X  X  X  3.2 Modification for Co-Labeling reco g nition performance was low d u e to less trainin g examples. Based on this reason, since the votin g strate g y compared to specific statistical method was lower acc u racy. 
For seq u ence labelin g , we need to define what sho u ld be the common labels for the model can o u tp u t the  X  best labeled seq u ences labels with hi g hest probability (m =  X  . We select the common label with the lar g est probability s u m,  X   X   X   X  |  X   X   X  X   X   X  X  X  X  X  , defined as follows: provided to  X   X  . 
D u rin g testin g , the common label  X  for an instance  X  is determined by three mod-three models with a confidence  X  3 X  or  X  2 X  . If the label with the lar g est probability the label with the lar g est probability s u m from three models is not g reater than  X  3 X  , then we choose the one with the lar g est probability s u m from two models with a con-fidence of  X  2 X  . The last selection criterion is the label with the maxim u m probabili-ty estimated by the three models as shown in Eq. (7). 3.3 Modification for the Initialization |  X   X  | after s u bsamplin g , i.e.,  X  , is still bi gg er than |  X   X  X   X   X  by Eq. (9), th u s:  X  and  X   X   X   X  X   X   X ,  X   X  is ill u strated in Fi g . 2. u pper bo u nd of |  X   X   X  | , in the first ro u nd.
The modified al g orithm for tri-trainin g is shown in Fi g . 3, where line 13 and 18-21 are modified to s u pport the new estimation of | L  X   X  | , while line 15 and 38 are modified for seq u ence co-labelin g as disc u ssed above. We apply o u r proposed approach on Chinese personal name extraction on the Web. We u se known celebrity names to q u ery search en g ines from fo u r news websites (in-cl u din g Liberty Times, Apple Daily, China Times, and United Daily News) and col-lect the top 10 search res u lts for sentences that contain the q u ery keyword. We then Given different n u mbers of personal names, we prepare six datasets by a u tomatically labelin g and consider them as labeled trainin g examples (  X  ) (see Table 1). 
We also crawl these fo u r news websites from 2013/01/01 to 2013/03/31 and obtain 20,974 articles for u nlabeled and testin g data. To increase the possibility of containin g person names, we select sentences that incl u de common s u rname followed by some tences with 54,449 person names (11,856 distinct person names) as the testin g data. names, job titles, n u meric tokens, alphabet tokens, p u nct u ation symbol, and common characters in front or behind personal names. The predefined dictionaries contain 486 job titles, 224 s u rnames, 38,261 first names, and 107 symbols as well as 223 common words in front of and behind person names. For the ta gg in g scheme, we u sed BIESO ta gg in g to mark the named entities to be extracted. We u se CRF++ [8] for the follow-and F-meas u re based on the n u mber personal names. 4.1 Performance of Basic Model with Automatic Labeling and Self-testing words to collect and label the collected news articles with  X  celebrity names and six reporter name patterns. While this proced u re does not ens u re perfect trainin g data, it lar g e trainin g data can g reatly improve the performance. 
Based on this basic model, we apply self-testin g to filter examples with low confi-dence and retrain a new model with the set of hi g h confidence examples. The perfor-mance is improved for all datasets with confidence levels from 0.5 to 0.9. An im-celebrity names we have (0.815 for D1 and 0.889 for D6). 4.2 Improvement of Modified Initialization for Tri-Training Second, we show the effect of the modified initialization for tri-trainin g (Fi g . 5). With the new initialization by Eq. (13), the n u mber of examples that can be sampled from improvement of 2.4% in F-meas u re (from 0.815 to 0.839). For dataset 2, the final data provement of 2.7% (from 0.830 to 0.857). For dataset 6, since |L  X   X  | is too lar g e to be loaded for trainin g with L , we only u se 75% for experiment. The improvement in F-meas u re is 1.5% (from 0.889 to 0.904). Overall, an improvement of 1.2% ~ 2.7% can be obtained with this proposed tri-trainin g al g orithm for seq u ence labelin g . 4.3 Comparison of Sel e Finally, we compare Chen  X  u sin g error rate in the traini n the proposed method base d when the error rate increas e based on S2A1D contin u es Th u s, the error rate fl u ct u a t words, the modified tri-trai n and there  X  s no gu arantee th a presents an u pward trend a different iterations. As for S ed by the other two classi fi seems the final o u tp u t do e similar res u lt as the basel i co u ld combine opinions of named entity reco g nition. We introd u ced the tri-trainin g al g orithm for seq u ence labe-lin g and compare Chen et al.  X  s selection method based on S2A1D with the proposed method based on most probable seq u ence. The res u lt shows that the proposed method retains the spirit of P AC learnin g and provides a more reliable method for co-labelin g with random selection o u tperforms Chen et al.'s method in dataset 6 (0.904 vs. 0.890). Meanwhile, we proposed a new way to estimate the n u mber of examples selected initialization improves 1.3%~2.3% over the ori g inal initialization. Acknowledegement. This work is partially s u pported by National Science Co u ncil, Taiwan u nder g rant 102-2511-S-008-008. 
