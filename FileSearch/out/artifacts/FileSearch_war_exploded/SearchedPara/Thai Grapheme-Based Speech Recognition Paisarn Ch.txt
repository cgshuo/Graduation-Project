 past with varying degrees of success (Besling, 1994; Black et al., 1998). Nevertheless, these methods still require post editing by a human ex-pert or using another manually generated pronun-ciation dictionary. 
As a solution to this problem, grapheme-based speech recognition (GBSR) has been proposed re-cently (Kanthak and Ney, 2002). Here, instead of phonemes, graphemes  X  orthographic representa-tion of a word  X  are used as the sub word units. This makes the generation of the pronunciation dictionary a trivial task. GBSR systems have been successfully applied to several European languages (Killer et al., 2003). However, because of the gen-erally looser relation of graphemes to pronuncia-tion than phonemes, the use of context dependent modeling techniques and the sharing of parameters across different models are of central importance. 
The variations in the pronunciation of phonemes in different contexts are usually handled by cluster-ing the similar contexts together. In the traditional approach, decision trees are used to cluster poly-phones  X  a phoneme in a specific context  X  to-gether. Due to computational and memory constraints, individual trees are grown for each sub-state of each phoneme. This does not allow the sharing of parameters across polyphones with dif-ferent center phonemes. Enhanced tree clustering (Yu and Schultz, 2003) lifts this constraint by growing trees which cover multiple phonemes. 
In this paper we present our experiments on ap-plying grapheme-based speech recognition for Thai language. We compare the performance of the grapheme-based system with two phoneme-based systems, one using a hand-crafter dictionary, and the other using an automatically generated diction-We use simple heuristic rules for this purpose; 10 rules for reordering and 15 for merging. In our ini-tial experiments, reordering alone gave better re-sults than reordering plus merging. Hence, we only used reordering rules for the rest of the experi-ments. 3 Thai Grapheme-Based Speech Recognition In this section, we explain the details of our Thai GBSR system. We used the Thai GlobalPhone corpus (Suebvisai et.al., 2005) as our data set, which consists of read-speech in the news domain. The corpus contains 20 hours of recorded speech from 90 native Thai speakers consisting of 14k utterances. There are approximately 260k words covering a vocabulary of about 7,400 words. For testing we used 1,181 utterances from 8 different speakers. The rest was used for training. The lan-guage model was built on news articles and gave a trigram perplexity of 140 and an OOV-rate of 1.4% on the test set. 
To start building the acoustic models for Thai, we first used a distribution that equally divided the number of frames among the graphemes. This was then trained for six iterations followed by writing the new labels. We repeated these steps six times. As can be seen in Table 1, the resulting system (Flat-Start) had poor performance. Hence we de-cided to bootstrap from a context independent acoustic model of an existing phoneme-based speech recognition (PBSR) systems. 3.1 Bootstrapping We trained two grapheme-based systems by boot-strapping from the acoustic models of two different PBSR systems. The first system (Thai) was boot-strapped from a Thai PBSR system (Suebvisai et al., 2005) trained on the same corpus. The second system (Multilingual) was bootstrapped from the acoustic models trained on the multilingual GlobalPhone corpus (Schultz and Waibel, 1998) which shares acoustic models of similar sounds across multiple languages. In mapping phones to graphemes, when a grapheme can be mapped to states of all phonemes. The clustering procedure starts with all the polyphones at the root of the tree. The decision tree can ask questions regarding the identity of the center phoneme and its neighboring phonemes, plus the sub-state identity (be-gin/middle/end). At each node, the question that yields the highest information gain is chosen and the tree is split. This process is repeated until the tree reaches a certain size. Enhanced tree clustering is well suited to implicitly capture the pronuncia-tion variations in speech by allowing certain poly-phones that are pronounced similarly to share the same set of parameters. Mimer et al. (2004) shows that this approach can successfully be applied to grapheme based speech recognition by building separate trees for each sub-state for consonants and vowels. 
For the experiments on enhanced tree clustering, we used the same setting as the grapheme-based system. Instead of growing a single tree, we built six separate trees  X  one each for begin, middle and end sub-states of vowels and consonants. Apart from the question set used in the grapheme-based system, we added singleton questions, which ask about the identity of different graphemes in a cer-tain context. To apply the decision tree algorithm, a semi-continuous recognition system was trained. Since the number of models that share the same codebook drastically increases, we increased the number of Gaussians per codebook. Two different values were tested; 500 (ETC-500) and 1500 (ETC-1500) Gaussians. Table 4 shows the recogni-tion results on the test set, after applying enhanced tree clustering to the system based on trigraphemes (MUL-TRI). As can be seen from Table 3, the enhanced tree clustering has significant improvement over the best grapheme-based system. ETC-500 with rela-tively lesser number of parameters has outper-formed ETC-1500 system. Performance decreases when we increase the number of leaf nodes in the tree, from 500 to 2000. A closer look at the cluster trees that used the enhanced clustering reveals that the initial context independent system, different number of acoustic models and different contexts for the polygraphemes. We also tried the enhanced tree clustering method as a means of sharing pa-rameters across models. The results show that the system with 500 acoustic models based on tri-graphemes produce the best results. Additionally, the enhanced tree clustering significantly improves the recognition accuracy of the grapheme-based system. Our system outperformed a phoneme-based system that uses an automatically generated dictionary. These results are very promising since they show that the grapheme-based approach can be successfully used to generate speech recognition systems for new languages using little linguistic knowledge. 
