 Transduction relies on the fundamental assumption that training and test data should exhibit similar behavior. For instance, in large margin classification a popular concept is to assume that both training and test data should be separable with a large margin [4]. A similar matching assumption is made by [8, 15] in requiring that class means are balanced between training and test set. Corresponding context of sufficient statistics on the marginal polytope by [3, 6].
 Such matching assumptions are well founded: after all, we assume that both training data X = { x 1 ,...,x m } X  distributed from the same distribution p ( x ) on a domain X . It therefore follows that for any function (or set of functions) f : X  X  R the distribution of f ( x ) where x  X  p ( x ) should also behave in the same way on both training and test set. Note that this is not automatically true if we get to choose f after seeing X and X 0 .
 Rather than indirectly incorporating distributional similarity, e.g. by a large margin heuristic, we cast this goal as a two-sample problem which will allow us to draw on a rich body of literature for comparing distributions. One advantage of our setting is its full generality. That is, it is applicable without much need for customization to all estimation problems, whether structured or not. Further-more, our approach is scalable and can be used easily with online optimization algorithms requiring no additional storage and only an additional O (1) computation per observation. This allows us to following: rather than minimizing only the empirical risk, regularized risk, log-posterior, or related quantities obtained only on the training set, let us add a divergence term characterizing the mismatch in distributions between training and test set. We show that the Maximum-Mean-Discrepancy [7] is a suitable quantity for this purpose. Moreover, we show that for certain choices of kernels we are able to recover a number of existing transduction constraints as a special case.
 Note that our setting is entirely complementary to the notion of modifying the function space due to the availability of additional data. The latter stream of research led to the use of graph kernels and similar density-related algorithms [1]. It is often referred to as the cluster assumption in semi-supervised learning. In other words, both methods can be combined as needed. That said, while distribution matching always holds thus making our method always applicable, it is not entirely clear whether the cluster assumption is always satisfied (e.g. assume a noisy classification problem). Distribution matching, however, comes with a nontrivial price: the objective of the optimization problem ceases to be convex except for rather special cases (which correspond to algorithms that have been proposed as previous work). While this is a downside, it is a property inherent in most transduction algorithms  X  after all, we are dealing with algorithms to obtain self-consistent label-ings, predictions, or regressions on the data and there may exist more than one potential solution. Supervised Learning Denote by X and Y the domains of data and labels and let Pr( x,y ) be a distribution on X  X  Y from which we are drawing observations. Moreover, denote by X,Y sets of data and labels of the training set and by X 0 ,Y 0 test data and labels respectively. In general, when designing an estimator one attempts to minimize some regularized risk functional or alternatively (in a Bayesian setting) one deals with a log-posterior probability is a mapping X  X  R (for scalar problems such as regression or classification) or X  X  R d (for multivariate problems such as named entity tagging, image annotation, matching, ranking, or more generally the clique potentials of graphical models). Note that we are free to choose f from one of many function classes such as decision trees, neural networks, or (nonparametric) linear models. The specific choice boils down to the ability to control the complexity of f efficiently, to one X  X  prior knowledge of what constitutes a simple function, to runtime constraints, and to the availability of scalable algorithms. In general, we will denote the training-data dependent term by and we assume that finding some f for which R train [ f,X,Y ] is small is desirable. An analogous reasoning applies to sampling-based algorithms, however we skip them for the sake of conciseness. Distribution Matching Denote by f ( X ) := { f ( x 1 ) ,...,f ( x m ) } and by f ( X 0 ) := test set respectively. For f chosen a-priori, the distributions from which f ( X ) and f ( X 0 ) are drawn coincide. Clearly, this should also hold whenever f is chosen by an estimation process. After all, we want that the empirical risk on the training and test sets match. While this cannot be checked directly, we can at least check closeness between the distributions of f ( x ) . This reasoning leads us to the following additional term for the objective function of a transduction problem: leads to an overall objective for learning when performing transductive inference. For instance, we could use the Kolmogorov-Smirnov statis-tic between both sets as our criterion, that is, we could use the L  X  norm between the cumulative distribution functions F associated with the empirical distri-butions f ( X ) and f ( X 0 ) to quantify the differences between both distributions. The problem with the above choice of distance is that it is not easily computable: we first need to evaluate f on both X and X 0 , then sort the arguments, and finally compute the largest deviation between both sets before we can even attempt computing gradients or using a similar optimization procedure. Such a choice is clearly computationally undesirable.
 Instead, we propose the following: denote by H a Reproducing Kernel Hilbert Space with kernel k defined on X . In this case one can show [7] that whenever k is characteristic (or universal), the map characterizes a distribution uniquely. Examples of a characteristic kernel is Gaussian RBF, Laplacian and B 2 n +1 -splines. It is possible to design online estimates of the distance quantity which can be used for fast two-sample tests between  X  [ X ] and  X  [ X 0 ] . Details on how this can be achieved are deferred to Section 4. Before discussing a specific algorithm let us consider a number of special cases to show that this basic idea is rather common in the literature (albeit not as explicit as in the present paper). Mean Matching for Classification Joachims [8] uses the following balancing constraint in the balance the outputs between training and test set, [8] imposes the linear constraint Assuming a linear kernel k on R this constraint is equivalent to requiring that Note that [8] uses the margin distribution as an additional criterion which will be discussed later. This setting can be extended to multiclass categorization and estimation with structured random variables in a straightforward fashion [15] simply by requiring a constraint corresponding to (9) to be satisfied for all possible values of y via This is equivalent to a linear kernel on R Y and the requirement that the distributions of the values f ( x,y ) match for all y .
 Distribution Matching for Classification G  X  artner et. al. [5] propose to perform transduction by on the test set matches the empirical class probability on the training set. Again, this can be cast in terms of distribution matching via 1+ e  X  y X  . Note that instead of choosing the logistic transform g we could have picked a large number of other transformations. Indeed, we may strengthen the requirement above to hold for all g in some given function class G as follows: If we restrict ourselves to g having bounded norm in a Reproducing Kernel Hilbert Space we obtain exactly the criterion (7). Gretton et. al. [7] show by duality that this is equivalent to the distance proposed in (11). In other words, generalizing distribution matching to apply to transforms other than the logistic leads us directly to our new transduction criterion. Figure 1: Score distribution of f ( x ) =  X  w,x  X  + b on the  X  X ris X  toy dataset. From left to right: induction scores on the training set; test set; transduction scores on the training set; test set; Note that while the margin distributions on training and test set are very different for induction, the ones for transduction match rather well. It results in a 10% reduction of the misclassification error. Distribution Matching for Regression A similar idea for transduction was proposed by [10] in the context of regression: requiring that both means and predictive variances of the estimate agree between training and test set. For a heteroscedastic regression estimate this constraint between train-ing and test set is met simply by ensuring that the distributions over first and second order moments of a Gaussian exponential family distribution match. The same goal can be achieved by using a polynomial kernel of second degree on the estimates, which shows that regression transduction can be viewed as a special case.
 Large Margin Hypothesis A key assumption in transduction is that a good hypothesis is charac-terized by a large margin of separation on both training and test set. Typically, the latter is enforced by some nonconvex function, e.g. of the form max(0 , 1  X  X  f ( x ) | ) , thus leading to a nonconvex opti-mization problem. Generalizations of this approach to multiclass and structured estimation settings is not entirely trivial and requires a number of heuristic choices (e.g. how to define the equivalent of the hat function max(0 , 1  X  X   X  | ) that is commonly used in binary transduction).
 matically obtain a loss function which enforces the large margin hypothesis whenever it is actually achievable on the training set. After all, assume that f ( X ) exhibits a large margin of separation ers by minimizing the discrepancy of the distributions. The key point is that by using a two-sample criterion it is possible to obtain such criteria automatically without the need for heuristic choices. See Figure 1 for illustrations of this idea. Streaming Approximation In general, minimizing D ( f ( X ) ,f ( X 0 )) is computationally infeasi-evaluations on a small sample. However, for Hilbert-Space based distance measures it is possible to find an online estimate of D as follows [7]: The symbol  X  ( . ) denotes a second set of observations drawn from the same distribution. Note that (13) decomposes into a sum over 4 kernel functions, each of which takes as arguments a pair of instances drawn from p and p 0 respectively. Hence we can find an unbiased estimate via
D := under the assumption that X and X 0 contain iid data. Note that the assumption automatically fails if there is sequential dependence within the sets X or X 0 (e.g. we see all positive labels before we see the negative ones). In this case it is necessary to randomize X and X 0 . Stochastic Gradient Descent The fact that the estimator of the distance  X  D decomposes into an average over a function of pairs from the training and test set respectively means that we can use D i as a stochastic approximation. Applying the same reasoning to the loss function in the regularized risk (1) we obtain the following loss as a stochastic estimate of the objective function defined in (5). This suggests Algorithm 1, which is a nonconvex variant of [12]. Note that at no time we need to store past data even for computing the distance between both distributions.
 Algorithm 1 Stochastic Gradient Descent Input: Convex set A , objective function  X  l
Initialize w = 0 for t = 1 to N do end for Remark: The streaming formulation does not impose any in-principle limitation regarding matching both distributions different weights (1/m and 1/m X  respectively), e.g. by modifying the sampling procedure (see Table 3, Section 5).
 DC Programming Alternatively, the Concave Convex Procedure, best known as DC program-solving a succession of convex programs. DC programming has been used extensively in almost any other transductive algorithms to deal with non-convexity of the objective function. It works as follows: for a given function F ( x ) that can be written as a difference of two convex functions G and H via F ( x ) = G ( x )  X  H ( x ) , the below inequality holds for all x 0 with equality for x = x 0 , due to the convexity of H ( x ) . This implies an iterative algorithm for finding a local minimum of F by minimizing the upper bound  X  F ( x,x 0 ) and subse-quently updating x 0  X  argmin x F ( x,x 0 ) to the minimizer of the upper bound.
 In order to minimize an additively decomposable objective function as in our transductive estima-tion, we could use stochastic gradient descent on the convex upper bound. Note that here the convex upper bound is given by a sum over the convex upper bounds for all terms. This strategy, how-ever, is deficient in a significant aspect: the convex upper bounds on each of the loss terms become increasingly loose as we move f away from the current point of approximation. It would be con-siderably better if we updated the upper bound after every stochastic gradient descent step. This variant, however, is identical to stochastic gradient descent on the original objective function due to the following: In other words, in order to compute the gradient of the upper bound we need not compute the upper bound itself. Instead we may use the nonconvex objective directly, hence we did not pursue DC programming approach and Algorithm 1 applies. To demonstrate the applicability of our approach, we apply transduction to binary and multiclass classification both on toy datasets from the UCI repository [16] and the LibSVM site [17], plus a larger scale multi-category classification dataset with 3 . 2  X  10 6 observations. We also perform experiments on a structured estimation problem, i.e. Japanese named entity recognition task and CoNLL-2000 base NP chunking task.
 Algorithms Since we are not aware of other transductive algorithms which can be applied easily to all the problems we consider, we choose problem-specific transduction algorithms as competitors. Multi Switch Transductive SVM ( MultiSwitch ) is used for binary classification [14]. This method is a variant of transductive SVM algorithm [8] tailored for linear semi-supervised binary classifi-cation on large and sparse datasets and involves switching of more than a single pair of labels at a time. For multiclass categorization we pick a Gaussian processes based transductive algorithm with distribution matching term ( GPDistMatch ) [5].
 We use stochastic gradient descent for optimization in both inductive and transductive settings for binary and multiclass losses. More specifically, for transduction we use the Gaussian RBF kernel to compare distributions in (14). Note that, in the multiclass case, the additional distribution matching term measures the distance between multivariate functions.
 Small Scale Experiments We used the following datasets: binary (breastcancer, derm, optdigits, wdbc, ionosphere, iris, specft, pageblock, tae, heart, splice, adult, australian, bupa, cmc, german, pima, tic, yeast, sonar, cleveland, svmguide3 and musk) from the UCI repository and multiclass (usps, satimage, segment, svmguide2, vehicle). The data was preprocessed to have zero mean and unit variance.
 Since we anticipate the relevant length scale in the margin distribution to be in the order of 1 (after all, we use a loss function, i.e. a hinge loss, which uses a margin of 1 ) we pick a Gaussian RBF kernel width of 0.2 for binary classification. Moreover, to take scaling in the number of classes into account we choose a kernel width of 0 . 1 number of classes. We could indeed vary this width but we note in our experiments that the proposed method is not sensitive to this kernel width.
 We split data equally into training and test sets, performing model selection on the training set and assessing performance on the test set. In these small scale experiments, we tune hyperparameters via 5-fold cross validation on the entire training set. The whole procedure was then repeated 5 times to obtain confidence bounds. More specifically, in the model selection stage, for transduction we adjust the regularization  X  and the transductive weight term  X  (obviously, for inductive inference we only need to adjust  X  ). For MultiSwitch Transduction the positive class fraction of unlabeled data was estimated using the training set [14]. Likewise, the two associated regularization parameters were tuned on the training set. For GP transduction both the regularization and divergence parameters were adjusted.
 Results The experimental results are summarized in Figure 2 for a binary setting and in Table 1 for a multiclass problem. In 23 binary datasets, transduction outperforms the inductive setup in 20 of them. Arguably, our proposed transductive method performs on a par with state-of-the-art transductive approach for each learning problem. In the binary estimation, out of 23 datasets, our method performs significantly worse than MultiSwitch transduction algorithm in 4 datasets (adult, bupa, pima, and svmguide3) and significantly better on 2 datasets (ionosphere and pageblock), using a one-sided paired t-test with 95% confidence. Overall, both algorithms are very comparable. The advantage of our approach is that it is  X  X lug and play X , i.e. for different problems we only need to use the appropriate supervised loss function. The distribution matching penalty itself remains approach scales well.
 Larger Scale Experiments Since one of the key points of our approach is that it can be applied to large problems, we performed transduction on the DMOZ ontology [20] of topics. We selected the top 2 levels of the topic tree (575) and removed all but the 100 most frequent ones, since a large number of topics occurs only very rarely. This left us with 89.2% of the initial webpages. As feature vectors we used the standard bag of words representation of the web page descriptions with TF-IDF weighting. The dictionary size (and therefore the dimensionality of our features) is Figure 2: Error rate on 23 binary estimation problems. Left panel, DistMatch against Induction; Right panel, DistMatch against MultiSwitch. DistMatch: distribution matching (ours) and MultiSwitch: Multi switch transductive SVM, [14]. Height of the box encodes standard er-ror of DistMatch and width of the box encodes standard error of Induction / MultiSwitch. Table 1: Error rate  X  standard deviation on a multi-category estimation problem. DistMatch: distribution matching (ours) and GPDistMatch: Gaussian Process transduction, [5]. dataset m classes Induction DistMatch GPDistMatch usps 730 10 0.143  X  0.021 0.125  X  0.019 0.140  X  0.034 satimage 620 6 0.190  X  0.052 0.186  X  0.037 0.212  X  0.034 segment 693 7 0.279  X  0.090 0.206  X  0.047 0.181  X  0.020 svmguide2 391 3 0.280  X  0.028 0.256  X  0.020 0.231  X  0.018 vehicle 423 4 0.385  X  0.070 0.333  X  0.048 0.336  X  0.060 Table 2: Error rate on the DMOZ ontology for increasing training / test set sizes. training / test set size 50,000 100,000 200,000 400,000 800,000 1,600,000 induction 0.365 0.362 0.337 0.299 0.300 0.268 transduction 0.344 0.326 0.330 0.288 0.263 0.250 Table 3: Error rate on the DMOZ ontology for fixed training set size of 100,000 samples. test set size 100,000 200,000 400,000 800,000 1,600,000 induction 0.358 0.358 0.357 0.357 0.357 transduction 0.326 0.316 0.306 0.322 0.329 Table 4: Accuracy, precision, recall and F  X  =1 score on the Japanese named entity task. induction 96.82 84.15 72.49 77.89 transduction 97.13 84.46 75.30 79.62 Table 5: Accuracy, precision, recall and F  X  =1 score on the CoNLL-2000 base NP chunking task. induction 95.72 90.99 90.72 90.85 transduction 96.05 91.73 91.97 91.85 1,319,489. For these larger scale experiments, we use a dataset of up to 3 . 2  X  10 6 observations. To our knowledge, our proposed transduction method is the only one that scales very well due to the stochastic approximation.
 For each experiment, we split data into training and test sets. Model selection is perform on the training set by putting aside part of the training data as a validation set which is then used exclusively for tuning the hyperparameters. In large scale transduction two issues matter: firstly, the algorithm needs to be scalable with respect to the training set size. Secondly, we need to be able to scale the algorithm with respect to the test set. Both results can be seen in Tables 2 and 3. Note that Table 2 uses an equal split between training and test sets, while Table 3 uses an unequal split where the test set has many more observations. We see that the algorithm improves with increasing data size, both for training and test sets. In the latter case, only up to some point: for the larger test sets (800,000 and 1,600,000) it decreases (although still stays better than inductive X  X ). We suspect that a location-dependent transduction score would be useful in this context  X  i.e. instead of only minimizing the discrepancy between decision function values on training and test set D ( f ( X ) ,f ( X 0 )) we could also introduce local features D (( X,f ( X )) , ( X 0 ,f ( X 0 ))) .
 Japanese Named Entity Recognition Experiments A key advantage of our transduction algo-named-entity recognition dataset provided with the CRF++ toolkit [18]. The data contains 716 Japanese sentences with 17 annotated named entities. The task is to detect and classify proper nouns and numerical information in a document into categories such as names of persons, organizations, locations, times and quantities. Conditional random fields (CRFs) [9] are considered to be the state-of-the-art framework for this sequential labeling problem [11].
 As the basis of our implementation we used Leon Bottou X  X  CRF code [19]. We use simple 1D chain CRFs with first order Markov dependency between name tags. That is, we have clique potentials joining words and labels ( x i ,y i ) . Since the former do not depend on the test data there is no need to enforce distribution matching. For the latter, though, we want to enforce that clique potentials are distributed in the same way between training and test set. The stationarity assumption in the potentials implies that this needs to hold uniformly over all such cliques.
 Since the number of tokens per sentence is variable, i.e. the chain length itself is a random variable, we perform distribution matching on a per-token basis  X  we oversample each token 10 times in our experiments. This strikes a balance between statistical accuracy and computational efficiency. The additional distribution matching term is then measuring the distance between these over-sampled clique potentials. As before, we split data equally into training and test sets and put aside part of the training data as a validation set which is used exclusively for tuning the hyperparameters. We relied on the feature template provided in CRF++ for this task. We report results in Table 4, that is precision (fraction of name tags which match the reference tags), recall (fraction of reference tags returned), and their harmonic mean, F  X  =1 are reported. Transduction outperforms induction in all metrics.
 CoNLL-2000 Base NP Chunking Experiments Our second structured estimation experiment is the CoNLL-2000 base NP chunking dataset [13] as provided in the CRF++ toolkit. The task is to divide text into syntactically correlated parts. The dataset has 900 sentences and the goal is to label each word with a label indicating whether the word is outside a chunk, starts a chunk, or continues a chunk.
 Similarly to Japanese named entity recognition task, 1D chain CRFs with only first order Markov dependency between chunk tags are modeled. We considered binary-valued features which depend on the words, part-of-speech tags, and labels in the neighborhood of a given word as encoded in the CRF++ feature template. The same experimental setup as in named entity experiments is used. The results in terms of accuracy, precision, recall and F1 score are summarized in Table 5. Again, transduction outperforms the inductive setup. We proposed a transductive estimation algorithm which is a) simple, b) general c) scalable and d) works well when compared to the state of the art algorithms applied to each specific problem. Not only is it useful for classical binary and multiclass categorization problems but it also applies to ontologies and structured estimation problems. It is not surprising that it performs very comparably to existing algorithms, since they can, in many cases, be seen as special instances of the general purpose distribution matching setting.
 Extensions of distribution matching beyond simply modeling f ( X ) and instead, modeling shrinkage of the function class via the distribution matching constraint, and applications to other function classes (e.g. balancing decision trees) are subject of future research. [1] O. Chapelle, B. Sch  X  olkopf, and A. Zien, editors. Semi-Supervised Learning . MIT Press, [2] T. Pham Dinh and L. Hoai An. A D.C. optimization algorithm for solving the trust-region [3] G. Druck, G.S. Mann, and A. McCallum. Learning from labeled features using generalized [4] A. Gammerman, Volodya Vovk, and Vladimir Vapnik. Learning by transduction. In Proceed-[5] T. G  X  artner, Q.V. Le, S. Burton, A. J. Smola, and S. V. N. Vishwanathan. Large-scale multiclass [6] J. Grac  X a, K. Ganchev, and B. Taskar. Expectation maximization and posterior constraints. In [7] A. Gretton, K. Borgwardt, M. Rasch, B. Sch  X  olkopf, and A. Smola. A kernel method for the [8] T. Joachims. Transductive inference for text classification using support vector machines. In [9] J. D. Lafferty, A. McCallum, and F. Pereira. Conditional random fields: Probabilistic modeling [10] Q.V. Le, A.J. Smola, T. G  X  artner, and Y. Altun. Transductive gaussian process regression with [11] A. McCallum and W. Li. Early results for named entity recognition with conditional random [12] Y. Nesterov and J.-P. Vial. Confidence level solutions for stochastic programming. Techni-[13] E.F. Tjong Kim Sang and S. Buchholz. Introduction to the CoNLL-2000 shared task: Chunk-[14] V. Sindhwani and S.S. Keerthi. Large scale semi-supervised linear SVMs. In SIGIR  X 06: [16] UCI repository, http://archive.ics.uci.edu/ml/ [17] LibSVM, http://www.csie.ntu.edu.tw/  X  cjlin/libsvmtools/ [18] CRF++, http://chasen.org/  X  taku/software/CRF++ [19] Stochastic Gradient Descent code, http://leon.bottou.org/projects/sgd [20] DMOZ ontology, http://www.dmoz.org
