 The technique of processing distributed data stream has attracted the researchers in the database community [1,2,3]. In distributed data stream systems, the distributed remote receives users X  queries and returns answers to users. The available communication works, the battery energy, which sensors use to transmit the data, is also a bottleneck resource [4]. So, one research issue in distributed data stream systems is how to reduce the transferred data volume as much as possible under the constraint of the precision of queries, in order to save the communication cost or the electric energy. 
At present, there are some kinds of methods to reduce communication cost [1,4,5] in distributed data system systems. However, these work can X  X  extensively support que-ries in real time with a good precision guarantee. Note that the frequent items in data streams occupy most of the communication cost. We propose to transfer the estimated data stream systems for the purpose of saving communication overhead. Meanwhile, in order to guarantee the precision of queries, the difference between the estimated and true occurrence times of each frequent item is also sent to the central stream processor. Thus, our method can not only overcome the drawback of the previous methods and guarantee the precision of queries, but also reduce the communication overhead. 2.1 Model of Distributed Data Stream Systems Figure 1 illustrates the model of distributed data stream system. All kinds of processor nodes consist of the central stream processor node, relay nodes and remote data source nodes. Remote data source nodes produce and collect data, and transmit raw data to the relay nodes. Relay nodes preprocess the received raw data and transmit it to the central stream processor node. The central stream processor node takes charge of user X  X  queries and returns the answers. The controller on the central stream processor node is respon-sible for sending the registered requirement and precision of queries to the relay nodes. 2.2 Frequent Items (i.e. time order) which is determined by the time when r enters the data stream system or when the remote data source produces r [6]. Suppose the items in data streams form frequent item in data stream and  X  is the support-degree of frequent items. spectively. When the derived-body is a forecast-body (denoted by Prb ), Count means the estimated occurrence times of r within T v . When the derived-body is a correct-body (denoted by Crb ), Count means the difference between the estimated and true occur-rence times of r within T v . 
Each registered query, especially for motoring queries, can specify a querying time interval, which can be represented by querying-metadata. The controller on the central processor node collects querying-metadata based on the requirement of registered generating derived-bodies of frequent items in data streams, each relay node maintains hold. 2.3 FDI Structure Each relay node maintains a data structure about frequent data items (denoted by FDI) described as in Figure 2, which preserves the corresponding information of the frequent items who will occur within the future period of time T p . The information includes the the approximate estimated value of r.f r . We use TopK to denote the set of all frequent items in FDI. 
Information of frequent items in FDI structure is maintained as follows. Initially, for each frequent items r in FDI, the value of r.fr is set to zero. When the relay node re-ceives a raw item s from remote data source nodes, it will examine whether s  X  TopK holds. If it holds, the value of s . f r in FDI is increased by one. 2.4 Research Issue Based on the model of distributed data stream systems in Figure 1, the research issue in this paper is how relay nodes generate derive d-bodies of frequent items in data streams, straint of precision of queries. Meanwhile, the method for processing derived-bodies on the central stream processor node also needs to be studied. 3.1 Determining Frequent Items In distributed data stream systems, reducing the volume of transferred frequent items can decrease the communication overhead greatly. Therefore, frequent items in data streams need to be determined firstly. In our work, we can adopt one of the well-known algorithm of finding frequent items over data streams such as Lossy Counting algorithm [7], Majority algorithm [8] and hCount algorithm [9], which we refer to as FFDS al-gorithm. During the time interval T h , suppose FFDS algorithm outputs the set of fre- X  times of all items within T h . 3.2 Processing Frequent Items 3.2.1 Generating Forecast-Bodies In fact, the forecast-bodies are the compressed form of frequent items in data streams. communication cost. Forecast-bodies should be generated and transmitted at the be-ginning of their lifetime. Otherwise, it will cause the delay for querying frequent items on the central stream processor. Concretely, forecast-bodies of frequent items should be generated at the end time of the first querying requirement in querying-metadata series (mentioned in Section 2.2). Following is the algorithm of generating forecast-bodies of frequent items. Algorithm 1: Generate-Prb ranges from the time of generating forecast-bodies to the end time of the first querying requirement in querying-metadata series. In fact, generating forecast-bodies is the process of estimating the occurrence times of frequent items within the lifetime of FDI. 3.2.2 Processing Data During Lifetime of FDI stream processor as much as possible. Mean while, relay nodes also prepare to generate the next round forecast-bodies of frequent items. During this process, there are some variables needed to be computed respectivel y, including the true occurrence times of the summation of frequent items (denoted by S f ) and the summation of all items (de-noted by S r ). The algorithm of dealing with data during the lifetime T p of FDI on relay nodes can be described as follows. Algorithm 2: Processing-within-Tp 
Relay nodes filter raw frequent items in data streams and only transmit the non-frequent items to the central stream processor. Thus, the communication overhead is reduced greatly. Meanwhile, relay nodes take the new arrival of raw data as the input of FFDS algorithm, i.e. predicting the future frequent items based on the newest his-torical data, which can enhance the performance of algorithms. 3.2.3 Generating Correct-Bodies tween the estimated occurrence times in forecast-bodies and the true occurrence time of frequent items. To guarantee the precision of queries on the central stream processor node, relay nodes should also transmit the correct-bodies of frequent items to correct the content of transferred forecast-bodies. Correct-bodies should be generated and transmitted before the next round forecast-bodies are generated, i.e. the end time of the lifetime of FDI. Note that, the time of generating the correct-body of frequent item k is the deadline of forecast-body of k . Following is the algorithm of generating correct-bodies. Algorithm 3: Generate-Crb 3.3 Algorithm of Processing Data Streams on Relay Nodes The algorithm of processing data streams on relay nodes is given as follows. Algorithm 4: RelayNode-Processing 
For each repetition in RelayNode-Processing algorithm, correct-bodies generated by step (5) are corresponding to the forecast-bodies produced by step (3). In this paper, we mainly focus on aggregate queries over distributed data streams. In aggregate queries plans, the input data flows through several middle operators and fi-nally arrives aggregate operators (such as SUM, COUNT and so on) that will output the querying results. In this section, we will discuss how operators in query plans process derived-bodies and skip the simple case of project and select operators. 4.1 Join Operators windows and Now denotes the current system clock. The structure of a join operator is sliding windows over A and B respectively. Figure 3(b) illustrates the data structure of sliding windows, where the column StreamData preserves the data coming from data sliding windows. Expiring: The condition of expiring the data in sliding windows is Dl &lt; Now . The time windows.
 set Deadline of r to be r . Timestamp + T . The time complexity is O (1). isfying the join condition should be probed and joined with r . Then, the join-result is yielded. Due to space limitation, we skip the content of processing r s , which has been completely discussed in our full paper [11]. 4.2 Aggregate Operators It is straightforward for aggregate operators to process derived-bodies. When handling derived-bodies, aggregate operators directly regard them as many same items. Suppose sults before after processing db . So, we have: (1) aggV X  COUNT = aggV COUNT + C . (2) aggV X  SUM = aggV SUM + k  X  C . (3) aggV X  AVG = aggV X  SUM / aggV X  COUNT . (4) aggV X  MAX = max{ aggV MAX , k }. (5) aggV X  MIN = min{ aggV MIN , k }. stream systems. Replacing frequent items with derived-bodies, not only the transferred data size is reduced greatly, but also the precision of queries can be guaranteed. 
