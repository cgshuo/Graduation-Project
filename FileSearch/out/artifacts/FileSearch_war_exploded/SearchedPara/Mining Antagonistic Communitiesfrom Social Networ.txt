 We form opinions and at times strong convictions on various issues and questions. Based on similarity in opinions and ideals, it is common that sub-groups or communities of users are formed. As members support or uphold a particular view or even conviction, we also observe th e dynamics of human social interaction of antagonistic groups , i.e., two groups that consistently differ in opinions.
Opposing groups and their nature have been studied in the sociology domain [17,5,4,14,10,6]. Understanding the formation of these groups and wide-spread-ness of opposing communities are of researc h interest. They could potentially sig-nify signs of disunity in the larger community and point to sub-communities that oppose one another. If these issues coul d be detected early, unwanted tensions between communities could potentially be averted. Identification of antagonistic communities is also the first step to further studies on: e.g., how the antagonistic communities are formed, why they are formed, how does the antagonistic commu-nities grow over time, when do the communities stop being antagonistic, etc.
Aside from enriching studies on dynamics of social interactions, information on groups of people having opposing opinions could potentially be used for: designing better marketing/product survey strategy by deeper understanding on the nature of each sub-community and potentially an opposing one, better recommendation of friends, or even recommendation of  X  X on-friends X , e.g., those whose reviews one could ignore, etc.

In this study, our goal is to discover antagonistic communities automati-cally from their history of interactions. We design a novel pattern mining al-gorithm to directly mine antagonistic communities. We take as input a database of user opinions/views over things, bucketized into high/medium/low or posi-tive/neutral/negative. From this database, we extract every two sets of users that are antagonistic over enough number of common items/issues with a high likelihood. Each mined pattern identifies a group of users that oppose another group over a sufficient number of common i ssues/items of interest (i.e., enough support ) with a high likelihood (i.e., enough confidence ).

Our approach explores the search space of all possible opposing communities and prunes those that appear with not enough frequency/support. An apriori-like anti-monotonicity property is used to prune the search space. Eventually the patterns mined are checked if the confidence is sufficient. If it is, it would then be reported. As a frequent antagonistic pattern would have many sub-patterns that are frequent we only report patterns that are closed . A pattern is closed if there exists no super-pattern having the same support and confidence.
To show the scalability of our approach, we developed a synthetic data gener-ator in a similar fashion as the IBM data generator used for mining association rules [2]. The data generator is used to test the scalability of our approach on several dimensions of interest. The result shows that our algorithm is able to run well on various parameter settings. We also investigates a rating dataset from Amazon. Our algorithm is able to run on the real dataset and extract antago-nistic communities. A few hundred communities are mined from the dataset.
The contributions of our work are as follows: 1. We propose a new problem of mining antagonistic communities from so-2. We propose a new algorithm to mine for antagonistic communities that is 3. We extract antagonistic communities from real datasets shedding light to The structure of this paper is as follows. Section 2 describes some related work. Section 3 formalizes some concepts and the semantics of antagonistic communi-ties. Section 4 describes our mining algorithm. Experiments and case studies are described in Section 5. We finally conclude and describe future work in Section 6. There have been a number of studies on finding communities in social net-work [3,9,8]. In this study we enrich pa st studies by discovering not cohesive communities but ones with opposing sub-communities. We believe these two source of information could give more light to the social interactions among users in Web 2.0.

Antagonistic communities is also related to the concept of homophily. Mem-bers of a pair of antagonistic communities, intuitively share more preferences with those in the same community and sha re less preferences with others from the opposing community. There have been a number of studies on homophily in social networks [16]. In this work, our mined communities not only express sim-ilar preferences but also opposing prefer ences. Homophily and trust are closely related as users with similar preferences are more likely to trust each other [11]. In this sense, our work enriches existing studies on homophily and trust [12,15,13].
In the sociology, economics, and psycho logy communities, the concept of inter-group antagonism has been studied by various work [17,5,4,14,10,6]. We extend this interesting research question by providing a computation tool to automati-cally identify opposing communities from a history of their behaviors. We believe our tool could potentially be used to help sociologist in understanding the be-haviors of communities from the wealth of available data of user interactions in Web 2.0.

Our algorithm belongs to a family of pattern mining algorithms. There have been a number of pattern mining algorithms including those mining associa-tion rules (e.g., [2]), frequent sequences (e.g., [18]), frequent repetitive sequences (e.g., [7]), frequent graphs, etc. The closest to our study is the body of work on association rule mining [2]. Association rule mining also employs the concept of support and confidence like us. However, association rule mining extracts fre-quent transactions, and relationship between transactions. On the other hand, we extract two sets of opposing users t hat share many commo n interests/form opinions/commonly rated items but oppose each other with high likelihood. This problem is inherently different from association rule mining. We show that a similar apriori-like anti-monotonicity property holds but we employ a different algorithm to mine for antagonistic communities. Similar to the work in [18], we do not report all frequent and confident groups rather only the closed ones. We formalize past histories of user social interactions in terms of ratings to items which can be objects, views, or even ideas. Hence there is a bipartite graph between users and objects where the arrows are labeled with rating scores. We divide all rating scores to be high, medium, low rating polarities depending on the score ranges. For example in Epinions where there is a 5-point scale assigned to an item by a user, we bucketize rating scores of 1  X  2tobeoflow rating polarity, 3 to be of medium rating polarity, and 4  X  5 to be of high rating polarity. We formalize our input as a database of ratings, defined in Definition 1. We refer to the size of a rating database DB R as | DB R | which is equal to the number of mapping entries in the database.
 Definition 1. Consider a set of users U and a set of items I. A database of ratings consists of a set of mappings of item identifiers to a set of pairs, where each pair consists of user identifier and rating score. There are three types of rating scores considered: high (hi), medium (mid), and low (lo). The database of ratings could be formally represented as:
DB R = { it id  X  X  ( us id ,rtg ) ,... }| it id  X  I  X  us id  X  U  X  rtg  X  X  hi,mid,lo } X  Two ratings are said to be common between two users if the ratings are assigned by the two users on the same item. A set of ratings is said to be common among a set of users if these ratings are on a commo n set of items rated by the set of users. Definition 2 (Antagonistic Group): Let U i and U j be two disjoint sets of users. ( U i ,U j ) is called an antagonistic group (or simply, a-group) if at least  X  of their common ratings satisfy all the following conditions:  X  Users from U i share the same rating polarity p i ;  X  Users from U j share the same rating polarity p j ;and  X  p i and p j are opposite polarities.
 The number of common ratings between two sets of users U i and U j is known as their support count and is denoted by count ( U i ,U j ). The support of the two all items.

The number of common ratings between U i and U j that satisfy the three con-ditions in the antagonistic group definition (see Definition 2) is called the an-tagonistic count , denoted by antcount ( U i ,U j ). Obviously, antcount ( U i ,U j )  X  count ( U i ,U j ). The antagonistic support of the two user sets asupport ( U i ,U j ) Definition 3 (Frequent Antagonistic Group): An antagonistic group ( U i ,U j ) is frequent if support ( U i ,U j )  X   X  and asupport ( U i ,U j )  X   X   X   X  where  X  is the support threshold (  X  (0 , 1) ), and  X  is the antagonistic confidence threshold (  X  (0 , 1) ).
 We consider ( U i ,U j ) to subsume ( U i ,U j )if:(a) U i  X  U i and U j  X  U j ;or(b) U Frequent a-groups satisfy the important Apriori property as stated below. Due to space constraint, we move the proof to [1].
 Property 1 (Apriori Property of Freq. A-group): Every size ( k  X  1) a-group ( U i ,U j ) subsumed by a size-k frequent a-group ( U i ,U j )isfrequent. Definition 4 (Valid Antagonistic Group): An a-group ( U i ,U j ) is valid if it is frequent and aconf ( U i ,U j )  X   X  . Definition 5 (Closed Antagonistic Group): A valid a-group ( U i ,U j ) is antcount ( U i ,U j ) = antcount ( U i ,U j ) .
 Example 1. Consider the example rating database in Table 1 (left). Suppose  X  =3and  X  =0 . 5. Both ( a, d )and( a, bd ) are valid a-groups. However, since count ( a, d )= count ( a, bd )=3and antcount ( a, d )= antcount ( a, bd )=2,( a, d ) is not a closed a-group and is subsumed by ( a, bd ). Hence, ( a, d )isconsideredas redundant. On the other hand, both ( a, b )and( a, bc ) are closed a-groups even though both aconf ( a, b )and aconf ( a, bc ) has the same value which is 2 3 .Thisis so as count ( a, b ) = count ( a, bc )and antcount ( a, b ) = antcount ( a, bc ). Note that count ( U i ,U j )= count ( U i ,U j ) does not imply that antcount ( U i ,U j )= antcount ( U i ,U j ) for any ( U i ,U j ) can show this using the rating database example in Table 1 (middle). In this example, we have count ( a, b )= count ( a, bc ) = 3 but ( antcount ( a, b )=3) &gt; ( antcount ( a, bc )=2).Wealsohave antcount ( d, e )= antcount ( d, ef ) = 1 but ( count ( d, e )=2) &gt; ( count ( d, ef )=1).
 Definition 6 (Antagonistic Group Mining Problem): Given a set of items I rated by a set of users U , the antagonistic group mining problem is to find all closed antagonistic groups with the given support threshold  X  and antagonistic confidence threshold  X  . We develop a new algorithm to mine for antagonistic groups from a database of rating history. The database could be viewed as a cleaned representation of people opinions or views or convictions on various items or issues. Our algorithm systematically traverses the search space of possible antagonistic groups using a search space pruning strategy to remove unfruitful search spaces.

The a-group mining algorithm runs for multiple passes. In the initialization pass, we calculate the count and antcount of all the size-2 a-group candidates and determine which of them are frequent. In the next pass, with the set of frequent a-groups found in the previous pass, we generate new potential frequent a-groups, which are called candidate set. We then count the actual count and antcount values for these candidates. At the end of this pass, we determine the frequent candidates, and they are used to generate frequent a-groups for the next pass. After that, we filter the previous frequent a-group set with the newly generated frequent a-group set by removing non-closed a-groups. Then we move on to the next pass. This process continues until no larger a-groups are found. After successful mining of all frequen t a-groups, we deriv e the valid a-groups from them.

Algorithm 1 shows the a-group mining algorithm known as Clagmine. Two basics data structures are maintained namely L k the intermediary set of frequent a-groups of size k and C k a candidate set of size k for valid a-groups checking. The first two lines of the algorithm derives size-2 candidates to get the fre-quent size-2 a-groups. It forms the base f or subsequent processing. A subsequent pass, say pass k , consists of three phases. First, at line 5, the a-groups in L k  X  1 found in k  X  1 pass are used to generate the candidate a-group set C k ,usingthe antGrpMining-gen method in Algorithm 2. Next, the database is scanned and the count and antcount of candidates in C k is updated (lines 7 to 13). We make use of the hash-tree data structure described in [2] to hold C k andwethenusea subset function to find the candidates overlap with the raters of an item. After we marked all the overlapped candidates, we update the count and antcount of them. Frequent a-groups can be deter mined by checking count and antcount against the support threshold and  X   X   X  thresholds respectively. Following that, L  X  1 is filtered with the newly generated a-groups to remove non-closed a-groups (line 15). After all the passes, the valid a-group is determined from the frequent a-group set (line 17). The following subheadings zoom into the various compo-nents of the mining algorithm in more detail.
 Candidate Generation and Pruning. The antGrpMining-gen function de-scribed in Algorithm 2 takes L k  X  1 , the set of all frequent size-( k  X  1) a-groups as input. It returns a superset of all frequent size-k a-groups. It works as below. First, we merge all the elements in L k  X  1 that share the same sub-community of size-( k -2). Each of them can be merged into a size-k candidate a-group consist-ing of the common sub-community and the two differing members. We add the candidate a-groups to C k . Next, in the pruning stage, we delete g k  X  C k if some ( k  X  1) subset of g
The pruning stage X  X  correctness is guaranteed by Property 1. From the prop-erty, if g k is frequent, all its ( k  X  1) subsets must be frequent. In other words, if any one ( k  X  1) subset of an a-group g k is not frequent, g k is not frequent too. We thus prune such g k s. The correctness of antGrpMining-gen function follows from Lemma 1. Due to space constraint, we move the proofs of all lemmas and theorems to [1].
 Lemma 1. For k  X  3, given a set of all size-( k  X  1) frequent a-group, i.e., L k  X  1 , every size-k frequent a-group, i.e., L k , is in the candidate set, i.e., C k ,output by Algorithm 2.
 An example to illustrate the process of candidate generation via merging and deletion is given below.
 serving as apriori-based pruning, will delete the a-group ( u 1 u 5 ,u 2 u 3 ) because in C 4 .
 Subset Function. Candidate a-groups are stored in a hashtree as mentioned in line 7 of Algorithm 1. Each node of the hashtree contains either a hashtable (interior node), or a list of candidates (leaf). Each node is labeled with a user identifier representing the user associated with this node. The hashtable at in-terior nodes contains mappings to nodes at the next level, with each hash key being the corresponding user identifier. Every candidate is sorted according to the user identifier, and is then inserted into the hashtree.

The subset function in line 9 of Algorithm 1 finds all the candidate a-groups among raters of item t . The raters of item t is first sorted by their user identifiers. The raters are then traversed one by one. A pointer list is kept to maintain a list of nodes which are visited, which initially has only the root of the hashtree. For arater u , we traverse through all the nodes in the pointer list, if a child node of the current node is found with label u , the child node is further checked to see whether it is interior or leaf. If it is an interior node, we add it to the pointer list and if it is a leaf, every a-group st ored in the leaf is marked as a subset of raters of t . A node is removed from the pointer list if all of its child nodes are in the list (i.e., are visited). The process is repeated through all the raters of item t . At the end, all the candidates which are subset of raters of t will be marked. Filtering Non-Closed A-Group. The filtering of non-closed a-groups corre-sponds to line 15 in Algorithm 1. The function works as follows. For each a-group g k in L k , we traverse through every a-group g k  X  1 in L k  X  1 .If g k subsumes g k  X  1 , and the count and antcount of the two groups are equal, g k  X  1 can be filtered. This step ensures all the a-groups in L k  X  1 are closed. By iterating through k , we can have all the non-closed a-group of any size filtered. Note that a closed a-group could potentially subsumes a combinatorial number of sub-groups. Re-moval of non-closed a-group potentially reduces the number of reported a-groups significantly.
 Correctness of the algorithm. The correctness of the algorithm is guaranteed byTheorems1&amp;2statedbelow.
 Theorem 1. Mined a-group set G contains all valid and closed a-groups. Theorem 2. Mined a-group set G contains only valid and closed a-groups. Scalability Variant: Divide and Conquer Strategy. At times, the main memory required to generate all the candidates could be prohibitive. If there are too many L 2 patterns, storing all of them in the memory would not be feasible. To address this issue, we perform a divide and conquer strategy by partitioning the database, mining for each partition, and merging the result. We first state some new definitions and describe a property.
 Definition 7 (User Containment). Consider a member m = it id  X  PairSet in a database of ratings DB R . We say that a user u i is contained in the entry, denoted by u i  X  m ,iff  X  ( u i ,rtg ) where rtg  X  X  hi, lo, mid } and ( u i ,rtg ) is in PairSet . We also say that a user u i is in an a-group a = ( S 1 ,S 2 ) iff ( u i  X  S 1  X  u i  X  S 2 ) Example 3. To illustrate, consider the first entry etr in the example rating database shown in Table 1(left). The first entry etr contains users a , b and d : a  X  etr , b  X  etr ,and d  X  etr . Definition 8 (Database Partition). Consider a user u i and a database of ratings DB R . The partition of the database with respect to user u i , denoted as DB R [ u i ] is defined as: { etr | u i  X  etr  X  etr  X  DB R } Example 4. To illustrate, projection of the database shown in Table 1(left) with respect to user d is the database shown in Table 1(right).
 Using the two definitions above, Lemma 2 describes the divide and merge mining process.
 Lemma 2 (Divide and Merge). Consider a database of ratings DB R ,sup-port threshold  X  , and confidence threshold  X  .Let U set be the set of users in DB R and Cm be the shorthand of the Clagmine operation in Algorithm 1. The follow-ing is guaranteed:
Cm (  X ,  X , DB R )= u Based on Lemma 2, our algorithm to perform divide and conquer is shown in Algorithm 3. The algorithm partitions the database one item at a time and sub-sequently calls the original closed antagonistic group mining algorithm defined in Algorithm 1. Theorem 3 guarantees that the mined result is correct and a complete set of a-groups are mined by Algorithm 3.
 Theorem 3. Algorithm 3 would return a complete set of closed and valid a-groups and all returned a-group would be closed and valid.
 Note that the divide and conquer algor ithm reduces memory costs however it could potentially increase the runtime cost since the database would now need to be scanned more number of times. In Section 5, we show the results of running the two algorithms over a number of datasets. In this section we describe our performance study using various data generated from our synthetic data generator with various parameter values. We then de-scribe a case study from a real book rating dataset.
 Performance Study. As a summary, our synthetic data generator accepts as input I (in  X 000)(the number of items), U (in  X 000)(the number of users), P (the expected number of users rating an item), N G (average size of maximal potential large a-group), and N L (in  X 000) (number of maximal potential large a-group). We use the following datasets:
The result for dataset DS 1 when varying the support threshold from 0.002 to 0.006 with  X  =0.7 is shown in Figure 1. The first graph shows the runtime needed to execute the algorithm at various support thresholds.  X  X on-split X  and  X  X plit X  correspond to Algorithms 1 &amp; 3 respectively. We only include 3 data points for  X  X on-split X , as mining at lower thresholds are too long to complete. The second graph shows the numbers of a-groups mined at various support thresholds.
The result shows that the time taken grows larger when support threshold is reduced. This growth is accompanied by the growth in the number of a-groups mined. Also, many longer patterns are mined as the support threshold is lowered.
For DS 2 , we consider a larger number of users. The results for various support thresholds with  X  =0.7 are shown in Figure 2. We have also conducted additional performance studies and their results can be found in our technical report [1].
The performance study has shown that the algorithm is able to run well on various settings. The lower the support threshold the more expensive it is to mine. Also, the larger the number of user s (or items or expected number of users rating an item  X  see [1]), the more expensive it is to mine.
 Case Study. For the case study, we consider a dataset of book ratings from Amazon. There are a total of 99,255 users ratings 108,142 books in 935,051 reviews. The experiment is run with  X  =0.5. The result is shown in Figure 3.
The number of mined a-groups in the real dataset is small even on much lower support threshold. Interestingly, we find that antagonistic behavior is not so much apparent on item ratings.This might be the case since the objects rated are not  X  X ensitive X  items that tend to divide people into opposing groups.
Several interesting a-groups are discovered from the Amazon dataset by run-ning the mining algorithm with absolute support (i.e.,  X   X | I | )of10and  X  =0.5. Out of 167 a-groups generated, 147 are of size 2, 18 of them are of size 3, and 2 of them are of size 4. We post-process to retain those with aconf &gt; 0.7, and at least one user has (commonly-rated-items/ totally-rated-items) &gt; 0.6.
After post-processing, we note 5 of the most interesting a-groups. We select those having highest aconf and average (common-item/total item) over all con-stituent users. They are represented in table 2. We select the first a-group and observe the following:  X  High antagonistic level : We observe that the two users in the first a-group  X  Antagonistically rated books : We found that for books with opposite ratings  X  Antagonistically behaved users : It is interesting that Weissgarber appears in In this study, we proposed a new pattern mining algorithm to mine for an-tagonistic communities. Our algorithm traverses the search space of possible antagonistic groups and uses several pruning strategies to remove search space containing no antagonistic pattern. We also propose a new variant of the al-gorithm that adopts a divide and conquer strategy in mining when the first algorithm becomes prohibitively expensive to run. A performance study is con-ducted on various synthetic datasets to show the scalability of our approach on various parameter values. We also mine from an Amazon book rating dataset. The result shows that antagonistic communities exists but are not particularly many or large in the Amazon dataset. In the future, we plan to investigate more  X  X ensitive X  datasets and further speed up the mining algorithm.
 Acknowledgement. This work is supported by National Research Foundation of Singapore under project NRF2008I DM-IDM004-036. We would like to thank Paolo Massa for sharing his Epinions dataset. We would also like to thank Bing Liu for sharing the book ratings dataset.

