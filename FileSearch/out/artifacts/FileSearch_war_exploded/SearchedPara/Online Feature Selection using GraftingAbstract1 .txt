 Simon Perkins s.perkins@lanl.gov James Theiler jt@lanl.gov Intheclassicformulationofthefeatureselectionprob-lem, alearningsystemis presentedwitha trainingset D consisting of ( x ,y ) pairs, where the x values are represented by fixed-length numeric feature vectors, and the y values are typically numeric scalars. The learner X  X task is to select a subset of the elements of x that can be used to derive a mapping function f from x to y that isas X  X oodaspossible X  X ccordingto some criterion C , and sparse with respect to x . This standard formulation assumes that all candidate featuresareavailablefromthebeginning,butconsider howthingschangeiffeaturesareinsteadonlyavailable one at a time. Assume that we cannot afford to wait until all features have arri ved before learning begins, and so the problem is to derive an x  X  y mapping at eachtimestep, thatisasgoodaspossibleusingasub-setofjustthefeaturesseensofar. Wecallthisscenario online feature selection or OFS. The OFS problem is in some sense a dual to the standard online learning (SOL) problem. In SOL, the length n of the training feature vectors is fixed, but the number m of training examples increases over time. In OFS, the number of trainingexamplesisfixed,butthelengthofthefeature vectors increases over time.
 One approach to OFS is simply to take the set of all features seen at each time step, and then apply what-everstandardfeatureselect iontechniquewelike,start-ingafresheachtime.However,giventhatthesetof features only increases b y one every time step, this is very inefficient. The analogy in SOL would be to retrain from scratch ever y time a new training exam-plearrived. Thereforeweinsistthatwhatevermethod we use, it must allow efficient incremental updates. Specifically, in atrue onlinesituation, weusuallyhave a fixed, limited amount of computational time avail-able in between each feature arrival, and so we want touseamethodwhoseupdatetimedoesnotincrease without limit as more features are seen.
 Standardfeatureselectionmethods canbebroadlydi-videdintofilterandwrappermethods(Kohavi&amp;John, 1997). How do these approaches adapt to an online scenario? Filter methods typically use some kind of heuristic to estimate the relative impor tance of different features. They can be divided into two groups: those that as-sess the worth of a set of features used together, e.g. Hall (2000), and those that evaluate each feature in-dependently,e.g. KiraandRendell(1992). Wecanre-jecttheformergroupforO FS because the time taken to apply the filter would almost certainly increase as more features are seen. In the current work we also reject the second group because we explicitly want to handlesituationswherefeaturesmayonlybeusefulin conjunction with other features.
 Wrappermethodsdirectlyev aluatetheperformanceof a subset of features by measuring the performance of a model trained on that subset. Under OFS, at each time step we need to consider the possibility not only ofselecting the mostrecently arrivedfeature,but also of droppingany of the currently selected features. We mayalsoaskifanypreviousl yrejectedfeaturesshould now be included. A wrapper approach to answering these questions would require many model retrainings ateachupdatestep,andsowerejectwrappermethods due to online time constraints. Before we introduce our proposed alternative, it is worth taking a little time to consider under what cir-cumstances OFS is of practical use. 2.1. When Features are Expensive Mostlearningsystemsassumethatallthefeaturesas-sociatedwiththetrainingdataarereadyandavailable at the start of the learning process. In doing so, they ignore the often considerable computational cost in-volved in generating those features.
 Consider a texture-based image segmentation prob-lem. The task is to assign a label to each pixel in the image according to the texture type that that pixel lies within. Texture is a property of a pixel X  X  neigh-borhood, so imagine that we have a large number of different  X  X exture filters X  that can be applied to each neighborhood in the image, in order to generate fea-tures for the pixel. A training image for this task might easily contain tens of thousands of labeled pix-els, and each filter might be costly to apply. Rather thanspendalotofcomputationaleffortgeneratingall thosefeaturesupfront,itmightbefarmorepreferable togeneratethefeaturesoneatatime,anduseanOFS learning system to return to the user a model that is as good as possible, given the features seen so far. As time goes on, more and more features are generated, and the model will become better and better. 2.2. Subset Selection in Infinite Feature Spaces Consider the texture segmentation task again. Now, imagine that we dramatically increase the number of differenttexturefiltersthatareconsidered X  X tiseasy todosobyconsideringdifferen tscales,spatialfrequen-cies and texture models. It may well be the case now that there are far more features than we can ever af-ford to generate in a reasonable time. We are going to have to settle for a solution that depends on only asubsetofavailablefeatures,andwehavetopicka reasonable subset without generating all the features first! How is that possible? Onewayofmanagingthissituationisto generatefea-tures, one at a time in a random order, and to use OFS to select a  X  X est so far X  set of features. As time goes on, the currently select ed subset of features and associatedmodelwillgetbetterandbetter. Whenthe performance of the model reaches a certain threshold, we can stop generating featu res and return the latest model.
 Anintriguingvariantofthisapproachistousetheset ofcurrently selectedfeatur es to heuristically drive the choiceofwhatcandidatefeaturestogeneratenext. For instancewemightchoosetogeneratenewfeaturesthat are variations on existing s elected features. Perkins et al. (2001) describe an image segmentation system thatworksalongtheselines,g eneratingspatio-spectral featuresthatarethencombinedusingasupportvector machine. We now turn our attention to developing a formalism and framework for online feature selection. 3.1. Regularized Risk Minimization In recent years, a lot of attention has been given to the idea that certain forms of regularization may be usedasanalternativetofea turesubsetselection. This provides the foundation of our incremental approach. To developthe argument, webeginby consideringthe problemofderivingagoodmapping,givenafullsetof features,asoneof regularized risk minimization .That is, the criterion to be optimized, C , takes the form: where L (  X  ,  X  )isalossfunction,and X ( f )isaregulariza-tion term that penalizes complex mapping functions. We have used f i as a shorthand for f ( x i ). 3.2. Loss Functions Different loss functions are appropriate for different types of learning problem. In this paper we will deal with binary classification problems, with y taking val-ues of  X  1, and so a suitable loss function is the bino-mialnegativelog-likelihood,usedinlogisticregression (Hastie et al., 2001, ch. 4): TheBNLLlossfunctionhasseveralattractiveproper-ties. Itisderivedfromamodelthattreats f ( x )asthe log of the ratio of the probability that y =+1tothe probability that y =  X  1, which allows us to calculate 1 p ( y =+1 | x ) using the following relation: The loss function is also convex in f ( x ), which has positive implications for finding a global optimum of C . Finally, it only linearl y penalizes extreme out-liers, which is important for robustness. We denote the mean loss over all training points as L bnll . Most of what follows in this paper applies to other commonly used loss functions as well, and we indicate this by dropping the BNLL subscript, except where weneedto be specific. A regr essiontask,forinstance, wouldbemorelikelytoemployasumofsquarederrors loss function. 3.3. Regularizers Thechoiceofregularizerin(1)dependsupontheclass of models used for f . Here, we will restrict ourselves to classesof models whose dependence on x is param-eterized by a weight vector w . Linear models fall into thiscategory,asdovariouskindsofmulti-layerpercep-tronsandradialbasisfunctionnetworks. Acommonly used regularizer for these models is based on a norm of the weight vector: where  X  is a regularization coefficient, p is a non-negative real number, and n is the length of w .This type of regularizer is the familiar Minkowski p norm raised to the p  X  X h power, and so is usually called an p regularizer. If p =2, then the regularizeris equiva-lenttothatusedinridge-regression(Hoerl&amp;Kennard, 1970)andsupportvectormachines(Boseretal.,1992). If p = 1, then the regularizer is the  X  X asso X  (Tibshi-rani, 1994). If p  X  0 then it counts the number of non-zero elements of w .
 The p =1 lasso regularizerhas s ome interesting prop-erties. Firstly, it is the smallest p for which  X  p is a convex function of w . This means that, if the loss function in (1) is also a convex function of weights, then optimizing C with respect to w using gradient descentisguaranteedtofindtheglobaloptimum,since the sum of two convex functions is also convex. For our work, the second crucial property 2 of the 1 regularizeris that there is a discontinuity in its gradi-ent with respectto w j at w j =0, which tends to force a subset of elements of w to be exactly zero at the optimum of C (Tibshirani, 1994), which is precisely what werequirefor a model that is sparsein features. Forthesereasonsweusethe 1 regularizerinourwork here.
 Notethatthemodelfor f mayhaveadditionalparam-eters, e.g. bias terms, wh ich we do not include in the regularization.
 With the BNLL loss function and 1 regularization, the learning optimization criterion becomes: 3.4. Normalization The  X  p regularizer penalizes all weights in the model uniformly. This only makes sense if all the features used as input to the model have a similar scale, which can be achieved by normalizing all features as they arrive. A convenient and efficient normalization pro-cessistolinearlyrescaleea chfeaturesothatthemean ofeachfeature(overalltrainingdata)iszero,andthe standarddeviationisone,i.e. werescaleincomingfea-ture values x j to normalized feature values x j ,using the relation: where x j is the meanrawfeature value, and  X  x j is the standard deviation. It is obviously necessary to use the same rescaling when applying the learned model to new unseen data. Perkins et al. (2003) describe a stagewise gradient descent approach to feature selection in a regularized risk framework, called grafting . 3 The basic grafting technique is used to build a sparse model froma large set of pre-calculated features, but the same idea can be adaptedto OFS, wherethe featuresarriveoneata time. Grafting is related to other stagewise modeling meth-ods such as additive logistic regression (Friedman et al., 2000), boosting (Freund &amp; Schapire, 1996) and matching pursuit (Mallat &amp; Zhang, 1993). 4.1. Basic Approach Grafting is a generalpurpose technique thatcan work with a variety of models that are parameterized by a weight vector w , subject to 1 regularization, and other un-regularized parame ters, as described in sec-tion 3.3 above. We also requirethat the output of the model be differentiable with respect to all model pa-rameters. Thebasisforgraftingistheobservationthat incorporatingafeatureintoanexistingmodelinvolves adding one or more non-zero weights to that model X  X  weightvector. Everynon-zeroweight w j added to the modelincursaregularizerpenaltyof  X  | w j | . Therefore, itcanonlymakesensetoaddthatweighttothemodel ifthereductioninthemeanloss L outweighstheregu-larizer penalty. More specifically, careful examination of (1) and (2) reveals that gradient descent will only take w j away from zero if: Figure 1 illustrates the criterion graphically. The grafting procedure consists of carrying out this gra-dient test for each weight that might be added to a model, associated with a newly seen feature. If no weights pass the test, then the corresponding feature is discarded. If at least one weight passes the test, then the weight with the highest magnitude  X  L/ X  X  j isaddedtothemodelandthemodelisoptimizedwith respect to all its parameters. The tests are then re-peated for all the weights that were just tested, since the results may change after optimizing the model. Itisinstructive tobreakth e lossderivativeintopieces using the chain rule: This is equivalent (apart from the factor of 1 /m )to a dot product in an m -dimensional function space be-tween a loss gradient vector  X  f L , and a function gra-dient vector. The loss gradient vector depends only upon the loss function and the current output values ofthemodel, butnotonthedetailsofthemodel. The functiongradientdependsonlyuponthedetailsofthe model. It is only necessary to calculate the loss gra-dient vector once in between re-optimizations of the model. This is the key to efficient updates in OFS us-inggrafting: testingtoseewhetheraweightassociated with a feature should be added to an existing model simply involves computing a single dot product. It is also clear from this picture that the magnitude of the dot product will be maximized when the loss gradient and the function gradient line up as much as possible. FortheBNLLlossfunctiondescribedearlier, we have: 4.2. Optimization Optimization of the model with respect to its param-eters can be carried out using any standard uncon-strained optimization algorithm. We currently use a conjugate gradient (CG) procedure, on account of its simplicity and low book-keeping overhead. See Fletcher (1987) for implementation details. The CG method requires the use of a  X  X lack-box X  line mini-mization method but apartfrom that the code is very simple.
 Before adding any weights to the model, we per-form a one-time optimization with respect to the un-regularized parameters. After each weight is added, the modelis optimizedwith respectto allparameters, which may result in certain weights going to zero. In practice care must be taken to catch those weights which go to zero and explicitly prune them, since the gradient discontinuity can cause problems for the line minimization routine.
 If the output of the model is a linear function of the model parameters, and the loss function is a convex function of the model output values, then the mean lossis a convexfunction of the model parameters. All the models and loss function s described in this paper meet these criteria. Since the 1 regularizer term is alsoaconvexfunctionofmodelparameters,thenthese conditions imply that C has a single global optimum with respect to the model parameters. The question arises: how close is the solution found by grafting to this optimal solution? The grafting solution is at a global optimum with re-spect to those weights included in the model, since we do a full re-optimization at each step. However, the algorithmdescribedsofardoes notnecessarilyleadto the same global optimum that would be found by do-ing a full optimization including all possible weights and features seen so far. In order to make the corre-spondence complete, we must ensure that anytime we add a feature to the model, we also go backand reap-ply the gradient test to all features seen in previous time steps. Although this procedure results in an up-date time that increases indefinitely as more features are seen, the time taken to test previous features is usually very small compared to the time taken to add anewfeature,duetothe speedofthe gradienttest. If necessary, we can impose a limit on how many times a feature can be considered and rejected, before it is removed from future consideration altogether. 4.3. Model Examples Theprecisedetailsofthegraftingprocessdependupon the formofthe model for f , sowewill illustrategraft-ing for OFS with two ex ample model classes. 4.3.1. Linear Model Consider a linear model in n features, parameterized by n weights and a bias term: We initialize things by setting n = 0, and performing a simple 1-D optimization of C with respect to b . At each time step t , a new feature arrivesin the form of a length m vector: where x i,t is the t  X  X h feature for the i  X  X h data point. We temporarily augment the existing model with a new weight w t associated with the new feature. The derivative of the mean loss with respect to w t is: If  X  L/ X  X  t &gt; X  , then the weight and corresponding feature are retained in the model, n is incremented, and we optimize with respect to w and b .Otherwise the weight is dropped and the feature is rejected. 4.3.2. Non-Linear Model Various non-linear models could be used for OFS and grafting. We use a simple model inspired by additive logisticregression(Hastieetal.,2001)andradialbasis function networks: where g (  X  )canbeanarbitrarynon-linear1-Dfunction, but is typically a Gaussian: g ( x )  X  1  X  e  X  ( x/ X  ) 2 .This modelisasimplesumofnon-linear1-Dfunctions,each ofwhichiscomposedofalinearmixtureofradialbasis functions. Foreachfeature,thenon-linearmixturecan be composed of between 1 and K max RBFs, where K max is typically 10. The manner of choosing these RBFs and their centers c j,k is detailed below. We start as with the linear model, setting n =0,and optimizing with respect to the bias term b . At each time step t , a new feature arrives. This time, instead of considering a single weight associated with the new feature, we consider K max of them, corre-sponding to the weights on K max different 1-D RBFs. The centers of these RBFs, c t, 1 through c t,K max ,are determinedbypartiallysortingthedatapointsaccord-ingtothevalueofthe t  X  X hfeature, inordertofind the boundariesof K max  X  1equi-percentiles. AnRBFcen-ter is placed at each of these boundaries, and at the minimum and maximum values. Note that the posi-tions of these centers are fixed by the data, and are not adjustable parameters.
 We then proceed in the familiar grafting fashion by calculatingderivativesfor eachofthe K max candidate weights: and comparing the magnitudes of these derivatives with  X  . If none of the derivative magnitudes ex-ceed  X  thenthefeatureandcorrespondingweightsare dropped from the model. If at least one derivative magnitude exceeds  X  , then we incorporate the weight correspondingthemaximummagnitudederivativeinto the model, and optimize with respect to all existing model parameters. The testing process is then re-peatedfortheremainingweightsuntiltheyhaveeither all been added, or have all been rejected. 5.1. The Datasets Weusedthreedatasetsintheseexperiments,labeled A through C .Eachdatasetconsistsofatrainingsetand a test set. Datasets A and B are synthetic problems, while dataset C is a real world problem, taken from the online UCI Machine Learning Repository (Blake &amp; Merz, 1998).
 The two synthetic problems are variations of the threshold max (TM) problem (Perkins et al., 2003). In the most basic version of this problem, the feature spacecontains n r informativefeatures,eachofwhichis uniformly distributed between -1and +1. The output label y for a data point x is defined as: The y =  X  1 points occupy a large hypercube wedged into one corner of the larger hypercube containing all thepoints. The y =+1pointsfilltheremainingspace. Theconstantintheaboveexpressionischosensothat halfthefeaturespacebelongstoeachclass. Variations of this basic problem are derived by adding n i irrele-vantfeaturesuniformlydistributedbetween-1and+1, and n c redundantfeatureswhicharejustcopiesofthe informative features. Afte r generation, the features are ordered randomly.
 Dataset A is the TM problem with n r = 10, n c = 0and n i = 90. This dataset explores the effect of irrelevant features in the TM problem.
 Dataset B is the TM problem, with n r = 10, n c = 90 and n i = 0. This dataset explores the effect of redundant features in the TM problem.
 Training and testing sets for each of these problems, eachcontaining1000points,wererandomlygenerated. For each experiment involving the synthetic datasets, tendifferentinstantiationsofeachdatasetweregener-ated and the results shown are mean results. Dataset C is the  X  X ultiple Features X  database from the UCI repository. This is a handwritten digit recog-nitiontask,wheredigitizedimagesofdigits havebeen represented using 649 features of various types. The tasktackledhereistodistinguishthedigit X 0 X  X romall otherdigits. Thetrainingandtestsetsbothconsistof 1000 points. The features were all scaled to have zero mean and unit variance before being used here. 4 5.2. The Experiments Six different experiments, w hich we denote by the let-ters (a) through (f) , were carried out on each of the three datasets described above: (a) OFS/grafting with the linear model. (b) OFS/grafting with the non-linear model. (c) Step-wise training of a fully-connected version of (d) Step-wise training of a fully-connected version of (e) LinearSVMappliedtoallfeaturesinbatchmode. (f) Gaussian RBF kernel SVM with default libsvm The grafting algorithms were implemented in Mat-lab, while the SVM experiments made use of libsvm (Chang&amp;Lin,2001),writteninC++. Regularization parameters X   X  forthegraftingexperiments, C forthe SVM experiments  X  were cho sen using five-fold cross validation oneach ofthe trainingsets. The non-linear models used K max =10and  X  =0 . 3.
 In order to simulate an OFS scenario, the set of fea-tures for each of the datasets was presented to the grafting algorithms one-by-one, in a randomly chosen order.
 Experiments (c) and (d) provide a non-grafting ap-proachtoOFSforspeedcomparison. Themodelsand criteria being optimized co rrespond exactly to those in experiments (a) and (b) , but no gradient testing is done to see which weights should be added to the model. Instead, at each time step we simply add all possible new weights to the relevant model before re-optimizing. Duringthereoptimizationprocessmostof the newweightsaddeddropoutdue toregularization. 5.3. Results and Conclusions For the OFS experiments (a) , (b) , (c) and (d) we recordedthe number of weights in the model, the test performance and the elapsed processor time. These measurements are summarized in Figure 2. Since the SVMcodeweusedwasimplementedinC++rather than Matlab, a direct timing comparison between batch and online experiments was not performed. The results show that the stagewise 1 regularized riskminimizationapproachis abletoselecta minimal yet good set of features for the problem at hand, in the presenceofmanyirrelevantorredundantfeatures. The timing experiments demonstrate that grafting is an efficient way of solving t he OFS problem, with an updatetimethatisalmostindependentofthenumber of features seen so far.
 Theresultsalsoclearlyshowthatthesolutionobtained is only as good as the underlying model being used. While the non-linear model performed excellently on allproblems(outperformingthenon-linearSVMinall cases), the linear models per formed relatively poorly on the highly non-linear synthetic problems. Despite being fairly flexible, the no n-linear model presented herehasthepropertyofhavingasingleglobaloptimal solution, whichthe graftingapproachisguaranteedto find.
 Tosummarize,graftingprovidesanapproachtoonline featureselectionthatcombinesthespeedoffilterswith the accuracy of wrappers. The  X  X radient test X  used to decide if a weight should be added to a model, is an extremely quick test, being essentially just a dot product of length m . Yet it gives an exact and direct answer to the question as to whether a given weight should be added to the current model.
 Blake, C., &amp; Merz, C. (1998). UCI repos-itory of machine learning databases. www.ics.uci.edu/~mlearn/MLRepository.html .
University of California, Irvine, Dept. of Informa-tion and Computer Science.
 Boser, B., Guyon, I., &amp; Vapnik, V. (1992). A train-ing algorithm for optimal margin classifiers. Proc. Fifth Annual Workshop on Computational Learning Theory (pp. 144 X 152). Pittsburgh, ACM.
 Chang, C., &amp; Lin, C. (2001). LIBSVM: A library for support vector machines. Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm .
 Fletcher,R.(1987). Practical methods of optimization . Wiley. 2nd edition.
 Freund, Y., &amp; Schapire, R . (1996). Experiments with anewboostingalgorithm. Machine Learning: Proc. 13th Int. Conf. (pp. 148 X 156). Morgan Kaufmann. Friedman,J.,Hastie,T.,&amp;Tibshirani,R.(2000). Ad-ditivelogisticregression: Astatisticalviewofboost-ing. Annals of Statistics , 28 , 337 X 307.
 Hall,M.(2000).Correlation-basedfeatureselectionfor discrete and numeric class machine learning. Proc. Int. Conf. Machine Learning (pp.359 X 365).Morgan Kaufmann.
 Hastie,T.,Tibshirani,R.,&amp;Friedman,J.(2001). The Elements of Statistical Learning . Springer. Hoerl,A.,&amp;Kennard,R.(1970).Ridgeregression: Bi-ased estimation for nonorthogonal problems. Tech-nometrics , 12 , 55 X 67.
 Kira, K., &amp; Rendell, L. (1992). A practical approach to feature selection. Proc. Int. Conf. on Machine Learning (pp. 249 X 256). Morgan Kaufmann.
 Kohavi, R., &amp; John, G. (1997). Wrappers for feature subsetselection. Artificial Intelligence , 97 ,273 X 324. Mallat,S.,&amp;Zhang,Z.(1993). Matchingpursuitwith time-frequency dictionaries. IEEE Transactions on Signal Processing , 41 , 3397 X 3415.
 Perkins,S.,Harvey,N.R.,Brumby,S.P.,&amp;Lacker,K. (2001). Supportvectormachinesforbroadareafea-ture classification in r emotely sensed images. Proc. SPIE 4381, Aerosense 2001 . Orlando.
 Perkins, S., Lacker, K., &amp; Theiler, J. (2003). Graft-ing: Fast, incremental feature selection by gradi-ent descent in function space. Journal of Machine
Learning Research . In press. Also at: http://nis-www.lanl.gov/  X simes/pubs.
 Tibshirani, R. (1994). Regression shrinkage and se-lection via the lasso (Technical Report). Dept. of
Statistics, University of Toronto.
