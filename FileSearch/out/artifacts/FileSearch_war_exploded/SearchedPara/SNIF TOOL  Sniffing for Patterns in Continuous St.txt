 Continuous time-series sequence matching, specifically, m atch-ing a numeric live stream against a set of predefined pattern sequences, is critical for domains ranging from fire spread tracking to network traffic monitoring. While several al-gorithms exist for similarity matching of static time-series data, matching continuous data poses new, largely unsolved challenges including online real-time processing require ments and system resource limitations for handling infinite strea ms. In this work, we propose a novel live stream matching frame-work, called n-Snippet Indices Framework (in short, SNIF), to tackle these challenges. SNIF employs snippets as the basic unit for matching streaming time-series. The insight is to perform the matching at two levels of granularity: bag matching of subsets of snippets of the live stream against prefixes of the patterns, and order checking for maintain-ing successive candidate snippet bag matches. We design a two-level index structure, called SNIF index, that sup-ports these two modes of matching. We propose a family of online two-level prefix matching algorithms that trade off between result accuracy and response time. The effective-ness of SNIF to detect patterns has been thoroughly tested through experiments using real datasets from the domains of fire monitoring and sensor motes. In this paper, we also present a study of SNIF X  X  performance, accuracy and toler-ance to noise compared against those of the state-of-the-ar t Continuous Query with Prediction (CQP) approach.
 H.2.8 [ Database Application ]: Data mining Design, Performance, Reliability  X 
This work was partly supported by National Science Foun-dation under grants IIS 0414567, SGER 0633930 and CRI 0551584.
 Streaming Time-series, Similarity Queries, Prefix Matchin g
The recent technological advances in sensor networks and mobile devices produce high volume data streams. Applica-tions such as environmental monitoring of hazardous waste and poisonous attack clouds, network traffic monitoring and tracking web click stream require on-the-fly matching of streaming time-series sequences to a set of known patterns. Continuous time-series matching poses several research ch al-lenges [8, 9, 12, 16, 25].

A live stream is defined as a potentially infinite series of relational records. A time-series is a sequence of real num-bers representing values from some given domain at specific points in time, also called data sequences. A live stream composed of time-series data is called a streaming time-series [8, 9].

According to [3], the processing of queries over stream-ing time-series is more complex than traditional static time-series for the following reasons. First, the elements in a live stream must be processed online due to the real-time requirements of the applications. The data tends to be con-tinuously appended to the end of the live stream. Thus, to keep up with the high input rates, the most recent elements typically must be processed before the next elements arrive . In contrast, in static time-series stored in a database, the re is no limit on the processing time. Second, the streaming time-series are assumed to have infinite lengths, and hence cannot be stored in a database in their entirety. Since static time-series are finite, algorithms for processing them can access the whole sequences either sequentially or by preprocessin g them into some indexed form for faster access. Third, any portion of the streaming time-series obtained previously c an-not be assumed to be available at a later time. Since stream-ing time-series have infinite lengths, the data obtained in t he far past must either be explicitly stored by the system in a compressed form or otherwise simply discarded. In contrast , in traditional static time-series database, the entire tim e-series can be retrieved at any time. Thus multiple passes can be performed.

To further complicate the problem, continuous similarity matching over a live stream may need to decide on matching intermittently while only partially knowing the live strea m. Also the data sources may be noisy and gaps between the live stream and the pattern sequence may arise.
In this paper, we propose n-Snippet Indices Framework (in short SNIF) for efficiently matching a streaming time-series against a set of numeric pattern sequences. As the live stream is infinite we work with chunks of data from the live stream. Based on the notion of n-Grams [6, 18, 14], orig-inally introduced for textual information retrieval, we in tro-duce the concepts of n-snippets and m-snippetCollections a s the foundation for our matching framework. The insight is to match small snippets of the live stream against prefixes of the patterns. The longer the pattern prefixes are identified to be similar to the live stream, the better the confirmation of the match becomes.

In our framework, the live stream matching is performed using two layers of matching, namely, bag matching for quick matching of sets of snippets while allowing partial disor-der and order checking for maintaining the sequence of the match at this more coarse-grain level. The bag matching step performs approximate matching of small chunks of the live stream data to quickly discard subsequences of pattern se-quences within the live stream that definitely did not match. The order checking step is analogous to subsequently stitch-ing the adjacent subsequences to discover which of the pat-tern sequences match the live stream and incrementally com-puting how closely each such potential candidate matches. SNIF can perform range queries as well as nearest neigh-bor searches. We design a two-level index structure, called the SNIF index, that supports these two layers of matching. In an offline step, the pattern sequences are preprocessed and then loaded into this SNIF index. During the online live stream matching step streaming time-series is matched on-the-fly against the indexed pattern sequences.
The main contributions of this paper are as follows: 1. We abstract the Continuous time-series sequence match-2. We define a two-layered progressive matching tech-3. SNIF combines all the features desired in Continuous 4. SNIF is implemented inside the data stream engine
The rest of this paper is organized as follows. Section 2 presents the background and the matching problem def-inition. We introduce in Section 3 the proposed solution while Section 4 describes the matching framework. Section 5 presents evaluation while Section 6 reviews related work. Section 7 summarizes our work. Symbols Definitions Len(S) Length of a sequence S (S L or S P )
D (S 1 , S 2 ) Distance between sequences S 1 and S 2 based
Without loss of generality, we assume that all time-series are one-dimensional, i.e., each entry is of the form S[t], wh ere S[t] is the data value at time t. We also assume that all time-series are sampled at equidistant time intervals. If originally they were sampled at unequal intervals, then we interpolate the values to make them equally intervaled. We further as-sume that the first sample is taken at time 0. A time-series S is finite if it extends only up to a finite length L  X  0 (Len(S) = L), denoted as h S[0], S[1], S[2],. . . , S[L] i . A time-series S is infinite if no such L exists.
A pattern sequence S P is a finite sequence of time-series data, such as a sequence of sensor readings that records the characteristic behavior during a phenomenon (such as a fire event). Given a library of such pattern sequences, similari ty queries find those pattern sequences from a library that are most similar to a query sequence S Q , given by the user. Many similarity measures are possible, for instance weight ed Euclidean distance [15], time warping [13], and wavelets [4 ].
Definition 1. Given a library Lib P of N pattern sequences, h S
P 0 , S P 1 , . . . , S P N  X  1 i , each having the same length L, a pattern S P i is said to be the Nearest Neighbor of the query sequence S Q if for all other S P j , j 6 = i, D (S Q , S S
P j ). Similarly, the k  X  Nearest Neighbors (NN) is a set of size k NN of the top k patterns in Lib P ranked by their distance from S Q .

The above assumes that both the query sequence and the pattern sequences are finite and static. In a streaming en-vironment, a live stream replaces the fixed finite query se-quence S Q . The pattern sequences S P i also need not be of same lengths. In the static sequence matching scenario S
Q and S P are available in full to be compared against each other, while in a live streaming scenario the query sequence s S Q need to be extracted out of the ever growing live stream S .

A live stream , denoted as S L , is an infinite time-series data sequence to which new data entries are continuously appended at every time unit. S L consists of a sequence of data values collected starting at time 0 until the current time t c , denoted as S L [0: t ] = S L [0], S L [1], ..., S subsequence of S L of length l ending at a time t s is denoted by S L [t s -l+1: t s ]. At any time t s , the distance between the live stream S L and a pattern sequence S P i , having length L , is denoted as D (S L [t s -L i +1:t s ], S P i ). The definition of a similarity query changes to accomodate the dynamic nature of the live stream.

Definition 2. Given a current time t c  X  0, a pattern S P i is the Nearest Neighbor of S L at t c if for all other patterns S P j , j 6 = i, D (S L [t c -L i +1:t c ], S P i ) &lt; D (S Similarly, to find the k-Nearest Neighbors of S L , at time t all the patterns are ranked by their distances from S L and the top k are output.

Real-time continuous time-series matching technique must aim at facilitating early detection of the patterns within t he live stream. For critical applications such as the detectio n of fire patterns, the ability to find a complete pattern of the overall fire event is a little too late, i.e., the fire would have come and burned down. Notice in Figure 1 that for the different length values L i of patterns, several suffixes of the live stream of the form S L [t c -L i +1:t c ] are used as the query sequence, t c being the current timestamp. The suffixes of S L are continuously matched against the prefixes of the patterns S P aiming for early detection of the match. Thus we match several query sequences against the library of patterns now. Rather than requiring to collect the full pattern length of data from the live stream, we propose to incrementally match the live stream against the prefixes of the patterns. We call this prefix matching (Figure 2). The longer the prefix of the pattern matched with the portion of the live stream the better the confirmation of the match.
Definition 3. Given a live stream S L matched against a library Lib of patterns S P i , continuous time-series similarity query using prefix matching is accomplished by maintaining, for each pattern S P i of Length L i in the Lib , S Q suffixes  X  extracted from S L of the form h S L [t c :t c ], S L [t c S [t c -L i +1:t c ] i and prefixes  X  of each pattern S P i Figure 2: Prefix Matching: matching prefixes of the patterns against the suffixes of the live stream = D(S L [t c -j+1:t c ], S P i [0:j-1])  X   X  X hreshold, where j is the length of the matched prefix  X  and suffix  X  . Similarly, Near-est Neighbor and k-NN for current time t c can be obtained as the prefix of the pattern matched closely with the suffix of S L until the current time t c .
In this section we first introduce the concepts of n-Snippets and m-SnippetCollections that form the building blocks for our match framework. Then we describe alternative match-ing approaches using n-Snippets and m-SnippetCollections .
An n-snippet is our basic unit for matching. We continu-ously extract snippets from a sequence by collecting groups of n consecutive data values. Two adjacent snippets of size n overlap by n-1 datapoints. Figure 3 represents a sequence of temperature readings from sensor DAN2 taken from the EDaFS [24] dataset.
Definition 4. An n-snippet , or henceforth also called snip-pet , is a subsequence of n consecutive data values in a se-quence S, represented as a tuple h p , S[p : p+n-1] i starting at the p th position of S.
 In our framework, a snippet need not hold the n datapoints in their entirety. The snippet can be a reduced represen-tation of the n datapoints capturing the essential content of the snippet sequence. Possible representations may be fourier coefficients, wavelets or data statistics such as ave r-age, slope, and standard deviation. While any representa-tion can be plugged in, the best choice greatly depends on the domain and the dataset as demonstrated in [22].
A similarity measure that is a good distinguisher between alternate patterns in the domain is the most suitable snippe t representation. Moreover, the representation should idea lly eliminate noise and be inexpensive to compute. As there is much overlap between consecutive snippets, an incremen-tally computable measure is desirable. Moreover, the com-bination of measures used to represent a snippet may be a better confirmation of the match.

For our work, we chose the pair of the average and the standard deviation of the n datapoints to form the snip-pet representation. Both metrics are inexpensive to com-pute even on live streams. A moving average smoothes the data, thus eliminating some noise. We observe empirically that this pair of metrics forms a significant distinguisher b e-tween the pattern sequences in the datasets we examined. The standard deviation by itself is not a strong candidate since the same standard deviation value can occur at to-tally different temperature bandwidths. A combination of the two metrics (average &amp; standard deviation) as the sim-ilarity criteria is a more reliable match measure than eithe r taken alone. This reduces distance computation costs as we need to match only the two data statistics instead of n data values (assuming n  X  2).

To summarize, an n-snippet of sequence S, starting at p th position, is henceforth represented as h p, (Avg(S[p : p+n-1]), Stdev(S[p : p+n-1])) i . For simplicity, we henceforth use Euclidean distance over the normalized average &amp; stdev pair (Formula 1) to compare two snippets, though weighted Euclidean distance or any other similarity measure could be plugged in too.  X (Snip A ,Snip B ) = p (Avg A  X  Avg B ) 2 + (Stdev A  X  Stdev
Definition 5. A snippet pair (Snip A , Snip B ) is said to have matched if  X (Snip A ,Snip B )  X  a user defined tolerance  X  X vgStdev.
We propose two strategies for snippet-based matching of sequences, namely, bag matching and order checking . We will note that these alternatives work irrespective of the choice of snippet representation.
 Figure 4: Bag matching of snippets over sequences
Definition 6. Bag matching is a sequence matching strat-egy where the set of snippets of S Q snip-set(S Q ) , is matched against the set of snippets of S P snip-set(S P ) . The match score S BM (S Q , S P ) is computed using Formula 2. The se-quence pair (S Q , S P ) is said to have matched with score S
BM (S Q , S P ) if S BM (S Q ,S P ) is within a certain user speci-fied threshold S Col Threshold for bag match.
 S Figure 5: Order checking of snippets over sequences
Intuitively, we consider S Q and S P matched if they have enough snippets in common. See Figure 4 for an example.
In bag matching there is no notion of sequence matching as the order of occurrence of the snippets is not considered. For this, we introduce the notion of order checking .
Definition 7. Order checking is defined as a sequence match-ing step where the order of occurrence of terms (here, snip-pets or collections of snippets) within sequences is checke d. The order checking score is maintained in a match store for each possible prefix  X   X  of a pattern S P i , the match score can be computed up to any position  X  in the pattern using Formula 3. A match store is a triplet h  X  ,  X  [1:  X  ], S  X  1. Match Position  X  -Position of current snippet up to 2. Match Vector  X  [1:  X  ] -A vector recording  X (Snip A ,Snip 3. Match Score S  X  OC -Cummulative score of the indi-
In Formula 3, C j is the weight associated with snippet at position j,  X  [j] is the  X (Snip A ,Snip B ) score at position j. An auxiliary structure called match store maintains the S score. As shown in Figure 5, S Q is said to have matched with S
P if the strict order of the snippets is maintained between them. In other words, the order checking score S  X  OC (S Q being within a certain user-specified threshold is a measure of the extent of match between the (S Q , S P i ) pair. However, the strict ordering of terms is a rather stringent condition whereas in practice an approximate match as opposed to an exact match may be more realistic. Our solution takes advantage of the best of both strategies as explained in the following section.
On the one hand, we would like to perform a bag match allowing some local disorder among the snippets. On the other hand, we would like to assure that the order within the sequences is mostly maintained. To facilitate this we now introduce another layer of granularity between indi-vidual snippets and complete sequences. We call it an m-SnippetCollection or simply a collection. Forming collections of m consecutive snippets out of a sequence S divides S into  X  (Len(S)/m+n-1)  X  groups of consecutive snippets. Each snippet collection consists of m+n-1 consecutive data val-ues. Two consecutive collections overlap by just n-1 data values, where n is the snippet size.
Instead of conducting either bag matching or order check-ing at the snippet level, we now propose to integrate these methods into a two-layered matching technique (as illus-trated in Figure 6): 1. Bag matching across snippets within a collection of m 2. order checking across the matched m-snippetCollections
This arrangement achieves our goal of allowing local dis-order while still maintaining overall order of the sequence s. The bag match score for each matching collection pair is passed on to its position in the match vector for computa-tion of the order checking score for the sequence. An order match between a S Q and a particular pattern S
P i is established only if the consecutive collections of snip-pets of S Q are found in exactly the same order as that of collections of snippets in S P i . Similar to order checking over snippets, here also we make use of a match store for each S to maintain the match with slight modifications, namely,  X  is now the position of the current collection up to which the S
P i , The match vector  X  [1:  X  ] records the bag matching scores of the collections in the order they occur in the original S An example of a match store is h 3, h 0.98 | 1.0 | 0.89 i , 0.95 i . Here 3 denotes the match position  X  . h 0.98 | 1.0 | 0.89 i denotes the scores of the first 3 consecutive collections of S P i 0.95 is S 3 OC computed according to Formula 3. The value of  X  for a S P i can vary from 0 to  X  Len(S P )  X  (m+n-1)  X  , i.e., the number of collections the S P i can be divided into. n determines the degree of smoothing. To preserve the significant patterns yet be able to eliminate noise, n needs to be small compared to the sequence length (n  X  Len(S)). Setting n = 1 corresponds to no smoothing, whereas, setting a large n value may cause over-smoothing. Hence, smooth-ing over a small number of data values, in our case 3  X  n  X  8 has been found to be a good choice. m is the degree of allowed disorder in the snippets while still calling it a match. Ideally we would avoid the choice of extreme values for m. m =1 means order checking over individual snippet, whereas, m = Len(S) (i.e., equal to the size of the sequence) will mean bag matching of all the snip-pets in the sequence. Hence, for almost all domains we will keep low value of m (say 3  X  m  X  30) compared to sequence sizes (m  X  Len(S)).
SNIF performs the matching of the live stream S L against the set of patterns S P in two phases: 1. Off-line Preprocessing Phase : Each S P is scanned once 2. On-line Live Stream Matching Phase : As new data
One of the greatest challenges of the live stream matching problem is that the two layers of our proposed matching technique need to be performed on-the-fly between the live stream S L and each of the pattern sequences S P . We propose to store the pattern sequences S P in a hierarchical structure composed of two inverted indices (for each match layer). An inverted index reduces the memory required to store the patterns, allows quick lookup and, as an inherent feature, returns matches ordered by frequency counts.

We first define the terms occurrence list and inverted in-dex. For a term (here snippets or collections), an occurrence list consists of the identifier of S P and the list of offsets where the term occurs within S P . An inverted index consists of a map between the terms (here snippets or collections) and their occurrence list. The two indices are shown in Figures 7 and 8.
The front-end inverted index, also called the snippet index (Figure 7), uses snippets as indexing terms. For each snip-pet it maintains an occurrence list that contains informati on about the occurrence of the snippet within the collections. The occurrence list information corresponds to a vector h lection in which the snippet exists along with each of the off-sets o i within the collection where the snippet occurs. This information is used for bag matching of snippets to report what fraction of a collection has matched.

The back-end inverted index (Figure 8) uses the identifier of the collections as indexing terms. For each collection, i t maintains an occurrence list that contains information abo ut the occurrence of the collection within S P . The occurrence list information is h S ID , h o 1 ,o 2 ,..,o i i i where S identifier of the S P in which the collection exists along with each of the offsets within the S P where the collection occurs. The back-end index, also called the m-SnippetCollection in -dex, is used for order checking of collections within S P Figure 9: Building the hierarchical two-level index ture called Avg-StdevSortedTree (ASTree) of the snippets present in the front-end index. It is sorted on the snippet similarity measure values.
 The snippets and snippetCollections are extracted from S
P and loaded in the index during preprocessing. Every time we collect m number of snippets, they are grouped together and given a unique collection identifier. The snip-pets are loaded into the snippet inverted index, called fron t-end index, as during matching it is matched against the snippets of the live stream. In a similar manner, the m-SnippetCollections are loaded into the collection inverte d in-dex, called the back-end index, as this is not directly probe d by S L .

During live stream matching, first, a range search would be performed on the ASTree to extract similar (based on the similarity measure) snippets. The snippets would resul t in multiple (likely redundant) front-end index probes. To avoid this, we reduce the index size by clustering the snip-pets on the similarity measure values using some third party clustering tools [10].

To summarize, the preprocessing phase consists of three tasks: 1. Extracting snippets and collections from each S P . 2. Clustering snippets and associating with a cluster iden-3. Loading the two levels of the index.
Using the two-level index structure, the live stream match-ing is divided into two layers of matching: 1. Snippet index lookup for bag matching of snippets to 2. Collection index lookup for order checking of the col-
These two abstract layers of matching make it possible to match the live stream against S P of different lengths.
As new data is being appended to S L , live snippets L S are extracted from S L (see Section 3.1). L S identifiers cannot di-rectly probe the n-Snippet index. As an intermediate step, the similarity measure values (here, average and standard deviation) of L S are used to perform a range query over the ASTree. The retrieved identifier of a snippet is then used to probe the n-Snippet index to retrieve the potential collec-tions to which L S belongs. The matching phase uses auxil-iary structures for recording the matches at the two layers. The structure called Collections-Latest-m-L S , records each extracted L S and the list of the collections corresponding to it.

As the input stream is infinite, the question arises for how many such live snippets L S we need to maintain the can-didate collections? As the name suggests, we propose to maintain the collection of Collections-Latest-m-L S for the m current L S , i.e., equal to the count of snippets in each collection of a S P . For example, we discard L Si and its corresponding list of collections as L Si + m is extracted, and so on, for any general i th L S . This in turn means that we need to store just the latest m+n-1 data points of S L . If a time-series data point uses  X  X  X  bits, then (m+n-1)  X  b bits of memory is required to store the live stream portion used in SNIF matching.
 In our case, each of the Collections of S P and also the Collections-Latest-m-L S are of size m. To compute the frac-tion of bag matching, we maintain the frequency count of each collection existing in the list of Collections-Latest-m-L
S across the latest m L S . We utilize another auxiliary structure called FrequencyCount-Latest-m-L S to record the counts. For each collection in the collection list, the scor e is the ratio between its frequency count across m L S and the value m. Finding all m snippets of a collection, called a complete match, corresponds to the count m/m = 1.
The process of bag matching is illustrated using the two snapshots in Figure 10. Say, for our example, m = 26 and n = 5. As each live snippet L S is extracted from the live stream S L , it probes the front-end index and extracts candi-date collections. These collections are listed with the pro b-ing L S in the Collections-Latest-m-L S . When we have m L
S we can perform the frequency count of each collection listed in Collections-Latest-m-L S and either create an entry in the FrequencyCount-Latest-m-L S with its count or update an existing entry. The two figures show bag matching steps for live snippets 1 to 26 and 2 to 27. In Figure 10 as we tran-sition from Snapshot 1 to Snapshot 2 , when L S 27 arrives, L
S 1 gets eliminated. The frequency counts for each collec-tion can be incrementally computed by taking into account the outgoing L S 1 and the incoming L S 27 .
For the order checking step, the back-end index is looked up by the collection identifiers to fetch their correspondin g occurrence lists. Out of the collections listed in FrequencyCount-Latest-m-L S only the ones with count scores above the user defined threshold S Col Threshold are used to look up the back-end index. By probing the back-end index the can-didates S P are obtained from the occurrence lists.
Figure 11 illustrates the process of order checking us-ing the back-end index. Say, the S Col Threshold = 0.65. Out of the collections in the FrequencyCount-Latest-m-L S the unshaded ones are highly ranked, i.e., having S BM  X  S Col Threshold and are used to look up the back-end index. below the threshold. From S P and position information of the occurrence list the match for each candidate S P can be recorded in the S P match stores. Given the S P Threshold = 0.85, looking at the match stores in Figure 11, the highly having S OC  X  S P Threshold. Only a high-ranked S P will be reported as a candidate match.

The individual collection score is the result of bag match-ing between the collection and the latest m L S . At the next layer, while reporting a match for a S P , the order of the collections is checked. A score for a collection is added to a  X  [1:  X  ] of a S P only if that collection is at a position p  X  (  X  + 1) and with a score above the S Col Threshold. These S
P match stores are also incrementally evaluated and main-tained just like the FrequencyCount-Latest-m-L S . Figure 11: Order Checking using Collection Index Lookup
Next we discuss alternative approaches for incremental evaluation of S P match stores. First, while several S P matches can be formed, a mechanism is required for pruning adhoc matches and false positives. We propose to use another threshold, we call S lower P Threshold ( &lt; S P T hreshold ) to dis-card S P matches that have S OC &lt; S lower P Threshold. Second, many collections, especially adjacent collections within a S share similar snippets. For this reason multiple collectio ns within a S P may have high scores in the latest m L S . There are several options how best to address this. One may main-tain just a single  X  [1:  X  ] for a S P based on either the best match score (best S OC value) or the extent of the match (the  X  value). Alternatively, multiple match vectors can be maintained for each S P . We found that maintaining just the single  X  [1:  X  ] for a candidate S P works well for our two experimental datasets. However, clearly this is a heuristi c and, in general, multiple  X  [1:  X  ] allows any one of those to become the best choice later. There is a trade off between the response time and result accuracy. Hence, there needs to be an upper bound on the maximum number of match vectors to be maintained per S P .

We propose four variations of the live stream matching according to the number of match vectors maintained per S . The variations allow the user the capability to choose between the two conflicting characteristics of result accur acy versus response time. The variations are: 1. Best 1 : Only a single match vector is maintained per 2. Multiple 1 per position : Multiple matches for a S P but 3. Best k : The top-k match vectors are maintained per 4. Best k with 1 per position : Multiple match stores main-
We list the complete algorithm for the live stream match-ing step in Algorithm 1.
In this section we study the performance, the accuracy and the robustness of SNIF matching framework by a thorough comparative study against the state-of-the-art Continuou s Query with Prediction (in short, CQP) proposed by Gao et. Al [9].

System Implementation. SNIF and CQP are both im-plemented in java over an existing continuous stream pro-cessing engine, CAPE [20]. For CQP implementation [11] FFT package was used. Experiments were conducted on an Intel(R) Pentium(R) machine with processor speed 1.70 GHz and 2GB memory. Algorithm 1 Live Stream Matching Algorithm Input: The 2-level indices, Live stream sequence S L Output: Potential pattern sequences S P and their respec-1: Range search on ASTree. 2: SC [ ][ ] =  X  3: counter = 0; 4: for each n tuples in S L do 5: Form snippets LS i = &lt; L Sid , Avg, Stdev &gt; 6: counter++ 7: for each LS i do 8: // find the set of matched pattern snippets 9: SC [ i ] =  X  10: for P S j  X  RangeSearch(ASTree, LS i ) do 11: // find a set of snippetCollections 12: SC [ i ] = SC [ i ]  X  FrontEndIndexLookUp( P S j ) 13: if counter == m then 14: OList[ ] =  X  15: for each SC j  X  SC [][] do 16: if FREQUENCY COUNT( SC J , SC [ ][ ])  X  17: // Determine the occurrence list of all patterns 18: // (and its corresponding offsets) in which SC j 19: // exists of the form &lt; S P 1 , offset P 1 &gt;, . . . &lt; 20: OList[j]  X  BackEndIndexLookUp( SC j ) 21: for each OList[j]  X  OList[ ] do 22: for each S P i  X  OList[j] do 23: MatchStores( S P i ) 24: if MatchScore( S P i ) &gt; S P T hreshold then 25: return S P as candidate 26: Remove SC [0] from SC [][]
Real Data Sets. The experiments were conducted on 2 different real datasets, namely EDaFS [24] fire dataset and the sensor network motes dataset [21]. The EDaFS dataset contains temperature, smoke CO readings recorded during several live fire tests conducted in NIST fire labs to study smouldering and flaming fires. Motes dataset [21] con-sists of 4 groups of sensor measurements (i.e., light intens ity, humidity, temperature, battery voltages) collected using 48 Berkeley Mote sensors at different locations in a lab, over a period of a month. Streams are heterogeneous streams, i.e., temperature shows a weak daily cycle and a lot of bursts, whereas humidity does not have any regular pattern.
Pattern Sequences . We use a collection of pattern se-quences of various lengths, namely 200  X  300, 500  X  600 and 700  X  800. Each collection consists of 50  X  60 patterns which are extracted from each of the two real datasets. The pat-tern sequences are maintained in a two-layered index along with its auxiliary tree structure (ASTree).

We have designed three sets of experiments. First, we measure and compare the average CPU execution time of the proposed algorithms versus the state-of-the-art CQP. Figu re 12 identifies that the SNIF algorithms execute at least 5 fold s faster than CQP for all the three pattern lengths. The in-crease in pattern length drastically reduces the performan ce of CQP. Our two-level indexing strategy facilitates our SNI F algorithms to show better performance even for longer pat-tern lengths.

In the second set of experiments, we compare the accu-racy of the different algorithms based on the match score Figure 12: Comparing Average CPU costs of SNIF algorithms against CQP measured on a scale from 0 to 1, with the perfect match score as 1. To faciliate this comparison we introduce error in the live stream using the error model, Err sqrt , proposed in CQP. In Err sqrt , the absolute error increases in the or-der of O(  X  k , where k is the prediction step, RAND is a uniformly distributed random variable having values between -0.5 to +0.5, a is the error control which can scale up the prediction error as needed. In our experiments a is set to be 1. The actual Euclidean distances and the distances from the CQP algorithm are normalized and subtracted from 1 to compare against the match scores of the SNIF algorithms. In Fig-ure 13 we clearly see that longer the sequence is subjected to error the less accurate of a match it is. In our experi-ments, the match score is a function of the algorithm tested and the portion of sequence subjected to error (equivalent to the prediction length for CQP). For all three pattern sets (200  X  300, 500  X  600, 700  X  800), the SNIF algorithms sustain their match scores. While CQP matches deteriorate with longer predictions.

In the third set of experiments, we measure the robustness of our proposed algorithms against random noise . We ex-amine three pairs of the snippet size n and collection size m, namely, (n=1, m=10), (n=5, m=10) and (n=5, m=3). For each pair we set the corresponding sizes for the pattern se-quences and the live stream. We introduce different amounts of noise in the live stream ranging from 0% up to 20% by randomly dropping data values from them. We observe that for a given live stream, the match score is a function of the noise level and the (snippet size, collection size) pair . We find in Figure 14.A that snippet size set to 1 means no smoothing and the SNIF algorithms lose their accuracy be-yond 5% noise level. On the contrary, setting moderate sizes , snippet size = 5 &amp; collection size = 10 (Figure 14.B) truly brings out the robustness of the SNIF algorithms. Moreover, Figure 14.C having short collection sizes while maintainin g the snippet size = 5, makes the SNIF algorithm vulnerable to the noise beyond 8 % error. Therefore, moderate snippet size and collection size make SNIF a robust stream matching algorithm.
For static time-series data, numerous algorithms [1, 2, 7, 23, 19, 5] have been proposed for a variety of similarity matching queries. However, similarity matching over con-tinuous streams still lacks a generic approach that can be used across domains. combinations of the Snippet Size (n) and the Collection Size (m).
Gao and Wang [8] propose a prediction-based matching technique called Continuous Query with Prediction (in shor t, CQP). CQP monitors the streams to search patterns that are relevant and solves Nearest Neighbor and h-Near Neigh-bor queries (h being the distance tolerance) for whole match -ing. The already arrived data is used to predict future sub-sequences. They pre-compute the distances between the query sequence and the predicted subsequences employing Fast Fourier Transform (FFT). When the actual data ar-rives, prediction error and predicted distances is used to filter false positives. Their experiments show performance gains over a naive FFT approach with reasonable prediction errors. However, as admitted by the authors, in our experi-mental study we did not find the approach useful under large prediction errors such as when the live sensor streams have abrupt changes and high noise levels. CQP faces obvious overheads of performing on-the-fly FFT computations and adjusting the prediction error before every next batch pro-cessing. Moreover, their experimental results are based on synthetic data, hence CQP  X s applicability to real data is un -known. In our work, we compare our solution to this CQP approach and demonstrate superiority of our approach in performance and match accuracy.

Gao et. Al [9] propose another sequence matching method using prefetching which solves the k-Nearest Neighbor quer ies. Prefetching transforms the query sequences, extracted fro m the live stream, into lower-dimensional points, and stores them to disk in a multi-dimensional index. For new arriv-ing data points, k-nearest query sequences are searched fro m the database. The arrived data values are used to predict k-NN candidates for the near future. The multidimensional index and the amortized disk reads handle a large number of query sequences. The prefetching solves k-NN for only fixed length patterns and it relies on a fixed tolerance of the pattern sequences, which is less applicable in real scenari os.
Kontaki et. Al [16] propose the IDC-index for stream-ing time-series matching in which DFT computations are performed incrementally over the streaming sequences. An R*-tree storing the dimensionality-reduced points is main -tained for the streaming time-series data. Application of computationally expensive FFT over the live stream and si-multaneously building an index structure requires a respon se time longer than desired by critical real-time application s. To avoid frequent on-the-fly updates to the R*-tree, they propose a deferred update policy.

Han et. Al [12] present techniques for ranked subsequence matching using time warping, that finds top-k matches. They introduce minimum-distance matching-window pair (mdmwp) as a lower bound between the pattern subsequences and a query sequence. Based on the mdmwp-distance, they de-velop a ranked subsequence matching algorithm to prune false positives. Their method uses DTW [13] which suffers from the dimensionality curse. They also require all the data values for distance computation. Also, DTW does not satisfy the triangle inequality, so that spatial indexing t ech-niques cannot be applied.

Overall, the state-of-the-art stream sequence matching al -gorithms have been extensions to the well-established static sequence matching techniques. Most reuse the dimension-ality reduction as used for static time-series which are ex-pensive to compute on-the-fly. These limitations motivate us to explore new avenues. One such matching technique, namely, n-Gram matching using inverted-index is yet to be explored for sequence time-series matching. n-gram [6, 17, 18] based inverted index is a very popu-lar and efficient information retrieval technique. Significa nt work has been done in enhancement of n-grams [18, 14]. Kim et. Al [14], propose a two-level n-gram inverted in-dex. Their proposed index has shown significant improve-ment in the query performance while preserving the advan-tages of the n-gram inverted index. However, the scope of n-gram is restricted to text matching. In this work, we ex-tend n-grams to apply to numeric time-series data, calling i t n-Snippets and develop approximate matching methods for prefix matching over the live streaming data.
In this paper, we abstract the continuous time-series se-quence matching problem into a prefix matching problem and propose a generic snippet-based framework. We call it the n-Snippet Indices Framework (in short, SNIF). We in-troduce the concepts of n-snippets and m-snippetCollectio ns for numeric data. We also propose to apply two abstract lay-ers of matching, namely, bag matching and order checking . The framework addresses challenges of the streaming envi-ronment, namely, noise elimination, incremental evaluati on, and efficient CPU utilization.

We demonstrate the efficiency and effectiveness of SNIF in matching live streams to sets of patterns having different lengths. We also compare SNIF to the state-of-the-art CQP [8] approach and demonstrate superiority of our approach in performance and match accuracy. We further demonstrate the robustness of SNIF to various noise levels. We success-fully test the framework over two distinct datasets. [1] R. Agrawal, C. Faloutsos, and A. N. Swami. Efficient [2] R. Agrawal, K.-I. Lin, H. S. Sawhney, and K. Shim. [3] B. Babcock, S. Babu, M. Datar, R. Motwani, and [4] K.-P. Chan, A. W.-C. Fu, and C. T. Yu. Haar [5] L. Chen and R. T. Ng. On the marriage of lp-norms [6] J. D. Cohen. Recursive hashing functions for n-grams. [7] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. [8] L. Gao and X. S. Wang. Continually evaluating [9] L. Gao, Z. Yao, and X. S. Wang. Evaluating [10] S. Guha, A. Meyerson, N. Mishra, R. Motwani, and [11] T. Hammond, C. F. Gerald, and P. O. Wheatley. [12] W.-S. Han, J. Lee, Y.-S. Moon, and H. Jiang. Ranked [13] E. J. Keogh and M. J. Pazzani. Scaling up dynamic [14] M.-S. Kim, K.-Y. Whang, J.-G. Lee, and M.-J. Lee. [15] S.-W. Kim, D.-H. Park, and H.-G. Lee. Efficient [16] M. Kontaki, A. N. Papadopoulos, and [17] J. H. Lee and J. S. Ahn. Using n-grams for korean [18] E. Miller, D. Shen, J. Liu, and C. Nicholas. [19] N. Roussopoulos, S. Kelley, and F. Vincent. Nearest [20] E. A. Rundensteiner, L. Ding, T. M. Sutherland, [21] J. Sun, S. Papadimitriou, and C. Faloutsos.
 [22] A. S. Varde, E. A. Rundensteiner, C. Ruiz, [23] C. Wang and X. S. Wang. Supporting content-based [24] J. W. Woycheese, R. Venkatesh, and K. Mihyun. [25] H. Wu, B. Salzberg, G. C. Sharp, S. B. Jiang,
