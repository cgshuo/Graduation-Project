 As researchers seek to apply their machine learning algorithms to new problems, corpus annotation is increasingly gaining im portance in the NLP community. But since the community currently has no general paradigm, no textbook that covers all the issues (though Wilcock  X  X  book published in D ec 2009 covers som e basic ones very well), and no accepted standards, setting up and perfor m ing small -, medium -, and large -scale annotation projects remain s some thing of an art. To attend, no special expertise in computation or linguistics is required. This tutorial is intended to provide the attendee with an in -depth look at the procedures, issues, and problems in corpus annotation, and highlights the pitfalls that the an notation manager should avoid. The tutorial first discusses why annotation is becoming increasingly relevant for NLP and how it fits into the generic NLP method ology of train -evaluate -apply. It then reviews currently available resources, services, and frameworks that support someone wishing to start an annotation p roject easily. This includes the QDAP annotation center, Amazon X  X  Mechanical Turk, annotation facilit ies in GATE, and other resources such as UIMA. It then discusses the seven major open issues at the heart of annotation for which there are as yet no stan dard and fully satisfactory answers or methods. Each issue is described in detail and current practice is shown. The seven issues are: 1. How does one decide what specific phenomena to annotate? How does one adequately capture the theory behind the phen omenon/a and express it in simple annotation instructions? 2. How does one obtain a balanced corpus to annotate, and when is a corpus balanced (and represen tative)? 3. When hiring annotators, what characteristics are important? How does one ensure that th ey are adequately (but not over -or under -) trained? 4. How does one 
