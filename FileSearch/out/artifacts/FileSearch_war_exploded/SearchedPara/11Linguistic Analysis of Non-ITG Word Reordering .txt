 In machine translation (MT), one of the most important issues is word reordering. Because word order often differs between languages, we need to rearrange words in the source language (or select which source word should be translated in which target position) so that the translation becomes a natural sentence in the target language. Formally, word reordering is a problem of finding a correct permutation of the source sentence, where the number of all possible permutation grows factorial to the number of the words. Hence, word reordering has been generally approximated in previous studies.

Inversion Transduction Grammar (ITG) constraints proposed by Wu [1997] have been widely used for word reordering in machine translation studies. ITG is a subclass of synchronous context-free grammar (SCFG) that allows the orientation of nontermi-nals to be straight or inverted. The ITG constraints have global reordering capacity that overcome the limitation of the simple distortion model, for example, which re-stricts the maximum range of movements [Koehn et al. 2003]. Because every ITG can be expressed as an equivalent ITG in a two-normal form, there exist polynomial time algorithms for both monolingual O ( n 3 ) and bilingual O ( n 6 ) parsing. Thus, the ITG constraints provide an efficient approximation for restricting the search space of word reordering.

Unfortunately, the ITG constraints make it impossible to cover all possible word re-ordering needs. Under ITG constraints, a nonterminal symbol always covers adjacent words in both the source and target languages. In other words, ITG cannot describe a pair of languages if a nonterminal needs to cover discontinuous words in either the source or target language. In real situations, non-ITG word reordering is often required when translating between linguistically divergent language pairs. ITG constraints re-strict certain kinds of word reordering, for example, wh-questions which have non-ITG word reordering, as shown in Table I.

We transcribe the gloss for each Korean word, where TOP is a topic marker, NOM a nominative marker, and ACC an accusative marker, respectively. The five words in English  X  X ho, you, think, she, invited X  and their corresponding words in Korean  X   X  /you,  X   X  /she,  X   X  /who,  X   X   X   X   X  /invited,  X   X   X   X  /think X  1 cannot be described with ITG constraints, because none of the continuous words in one language has its corresponding continuous words in other language.

We raise the following research questions that need to be answered. 1) Is it sufficient to cover word reordering phenomenon under ITG constraints in real situation? 2) If not, what are the characteristics of non-ITG word reordering, and how significant are they? 3) If there are significant portion of non-ITG word reordering phenomena, how to deal with them in an efficient manner?
As the answers of the first two questions, 2 this article is organized as follows: First, we briefly illustrate the characteristics of ITG for word reordering, and summarize related works (Section 2). Then, we investigate three corpora (Chinese-Korean, English-Japanese, and English-Korean) between subject-verb-object (SVO) and subject-object-verb (SOV) languages to analyze the characteristics of non-ITG word reordering (Section 3). Here, we identify four types of non-ITG word reordering, and find that they appear in approximately 4% to 10% of all sentences. It is possible to con-vert or rewrite sentences that require non-ITG word reordering, in order to satisfy ITG constraints (Section 4). Finally, we conclude that word reordering methods should deal with such non-ITG cases, especially between linguistically divergent language pairs (Section 5). Previous studies have focused on investigating the capabilities and function of ITG constraints between English and Chinese [Wu 1997], other European languages [S X gaard and Wu 2009; Zens and Ney 2003], and Arabic [Wu et al. 2006]. Wellington et al. [2006] summarized the results for an English-Hindi corpus, where Hindi is an SOV language, as well as for English-European languages and English-Chinese. While Wu [1997] was  X  X nable to find the real example X  in their data, others [Wellington et al. 2006; Wu et al. 2006; Zens and Ney 2003] reported the coverage of ITG constraints at sentence level. In addition to the sentence-level coverage, S X gaard and Wu [2009] estimated empirical lower bounds for the full class of ITGs at the level of translation units. Xiong et al. [2010] analyzed reordering patterns in a phrase structure tree and investigated the three reasons for a non-reorderable case.

Although previous works reported the percentage of sentences or translation units violating ITG constraints, we think that it is more novel to perform a linguistic anal-ysis that identifies types of non-ITG word reordering with concrete examples. We also report two quantitative measures that reveal the significance of non-ITG word reorder-ing, which are inspired by Wellington et al. [2006] and Wu [1997]. French-English and Chinese-English pairs were already examined in Wellington et al. [2006] in a differ-ent way. The  X  X ailure rates for hierarchical alignment of bilingual bitexts under word alignment constraints only X  (Table 2 in their paper) are 1% and 5% for French-English and Chinese-English, respectively, which are roughly comparable with the portion of non-ITG word reordering in this article (approximately 4% 10%). In addition, we sug-gest a simple heuristic to convert sentences belonging two of four non-ITG types into ITG-constrained ones. Theoretically, ITG coverage decreases drastically as permutation length grows, as shown in Figure 1. It is possible for two non-ITG cases to appear in a length-4 per-mutation. For a length-5 permutation, ITG cannot describe 25% of cases, though it is questionable this may happen in real situations. Hence, we analyze three word-aligned corpora, and manually identify four types of non-ITG word reordering.

In this article, three aspects of non-ITG word reordering are investigated. First, we categorize the types of non-ITG word reordering and collect their statistics. Second, we collect statistics of the size of the word sequence causing non-ITG word reordering. Third, we measure the distribution of minimum SCFG rank to handle non-ITG word reordering.
 We used three corpora consisting of different language pairs and genres. The Chinese-Korean corpus was collected from a newswire service, the English-Japanese corpus from Wikipedia articles [Neubig 2011], and the English-Korean corpus from example sentences in an electronic dictionary, respectively. Each corpus consists of sentence pairs between SVO and SOV languages, but with different characteristics such as av-erage sentence length. The statistics of the corpora are illustrated in Table II.
For the Chinese-Korean and English-Japanese corpora, human-annotated word alignments are available, but not for the English-Korean corpus. As an alternative, an automatic word alignment was performed for the analysis of the English-Korean cor-pus. We used MGIZA [Gao and Vogel 2008] to obtain automatic word alignment of the development data together with the training data, consisting of approximately 600K sentences. For the high accuracy of word alignment, the intersection of bidirectional word alignment was analyzed. English sentences were segmented by tokenizer.perl included in Moses [Koehn et al. 2007], Japanese sentences by KyTea [Neubig et al. 2011], and Chinese and Korean sentences by in-house morphological analyzers.
A simple way to identify the sentences that require non-ITG word reordering is the use of a shift-reduce algorithm analogous to Huang et al. [2009]. Using a stack  X  and a buffer  X  , each step performs one of the actions that follows:  X  Shift: ( X  ,[ k |  X  ] )  X  ( [  X  | k ],  X ) otherwise, where i and j are top two elements in  X  , i  X  j is a reduced element covering i and j ,and k is the front element in  X  . After the termination (neither action is applicable), the ITG parsing is successful if the size of stack |  X  |= 1: otherwise, the sentence requires non-ITG word reordering.
 We categorize four types of non-ITG word reordering: wh-questions, adverbials, spe-cific examples of divergences, and others. For the English-Korean corpus, we identify non-ITG word reordering based on an automatic word alignment, which may contains many errors. Thus, we manually exclude 202 sentences that contain word alignment error from the analysis. Even in human annotated word alignment, there exist minor errors of word alignment. We also manually exclude these sentences (around 0.8% of sentences) in the Chinese-Korean and English-Japanese corpora. 3.2.1. Wh-questions. A language pair with different word-order typologies often re-quires non-ITG word reordering to translate wh-questions. For a rigid word-order language like English, the order of constituents in wh-questions is almost completely fixed. For a relatively free-order language like Korean, in contrast, it is flexible. There-fore, ITG word reordering does not guarantee correct results for wh-questions between rigid and relatively free word-order languages.

Some examples of wh-questions are shown in Table IIIa. In (1), the word alignment is  X   X   X  ). The word order in English is rearranged into  X  X olice, why, schoolyard, bullies, raid, don X  X  X  in Korean, and none of adjacent words in one language is adjacent in the other language. The example (8) also requires non-ITG word reordering for the word order in Korean  X  X enator, China, trip, on, what, achieve. X 
Because newswire and Wikipedia rarely utilize wh-questions, 3 we only found this type of non-ITG word reordering in the English-Korean corpus. We found a total of 16 wh-question sentences requiring non-ITG word reordering among 1,693 sentences with no errors of word alignment. They account for 39% of 41 wh-questions in this corpus.

We found that this type of non-ITG word reordering would be recognized as a gen-eralized pattern. Let AUX be an auxiliary verb, S a subject, V a verb, and VP/PP a verb/preposition phrase, respectively. The example of Table I can be generalized as a pattern (Wh-AUX S 1 V 1 S 2 V 2 /S 1 S 2 Wh-V 2 V 1 ). The example (1) of Table IIIa shows a pattern (Wh-AUX S 1 VP, S 1 Wh-VP AUX), and (2) a pattern (Wh-AUX S 1 V 1 PP, S 1 PP Wh-V 1 ), respectively. 3.2.2. Adverbials. Adverbials have a higher degree of freedom in word order than other constituents.  X  X n reality, adverbials are very free in their placement, appearing in dif-ferent positions in the sentence, not just sentence final X  [Brinton 2000] in English. Generally, the relatively free order of adverbials is language universal. Therefore, ad-verbials often result in non-ITG word reordering phenomena during translation.
Some examples of adverbials are shown in Table IIIb. In (3), an adverb  X   X   X  / /mostly X  is located between the subject  X   X   X  / /fat X  and the main predicate  X   X   X   X  /accumulate X  in Chinese, while its corresponding word  X   X   X  / /mostly X  appears at the begging in Korean. The example (4) also shows that an adverb phrase  X  X n 1594 X  at the beginning of the English sentence is located between  X   X  X  X  X  /as X  and  X   X   X  / /Fushimi X  in Japanese.
Regardless of domains and language pairs, adverbials incur non-ITG word reorder-ing. After excluding the erroneous word alignment, there remains around 0.8% of sen-tences that need non-ITG word reordering because of adverbials. This type takes the smallest portion among those we found for each corpus as shown in Figure 2. We also found that this type of non-ITG word reordering can be generalized. For (3), a pattern would be (S AdvP V PP / AdvP PP S V), and for (4), it is (AdvP S V PP / S PP AdvP V), where AdvP is an adverb phrase. 3.2.3. Specific Examples of Divergence. Translation divergences are a well-known prob-lem in machine translation [Dorr 1994]. We found that certain specific examples of divergence, such as head-switching, structural, and categorial divergences, cause non-ITG word reordering. Head switching divergence refers to cases where the dependency relation between two constituents has switched after translation. For example, the ex-ample (5) of divergence in Table IIIc shows that the dependency relation between a main verb  X  X pent X  and its argument  X  X elping X  in English is switched in Korean.
The structural or categorial divergences refer to the syntactic structure or category changes during translation, respectively. For example, (6) in Table IIIc shows that the to-infinitive phrase  X  X o handle practical matters X  in English becomes the one-word noun phrase  X   X   X  /handle-practical-matters X  in Japanese. The example (7) also shows that the argument  X  X urakudai X  of the preposition  X  X f X  in English becomes the subject  X   X   X   X  /Jurakudai X  in Japanese. 4
In general, the percentage of non-ITG word reorderings caused by translation diver-gences is larger than by wh-questions and adverbial cases. Especially, in the English-Japanese corpus, translation divergences are the most significant reason for non-ITG word reordering. For the Chinese-Korean corpus, head-switching accounts for 40% and categorial 60%; For the English-Japanese corpus, head-switching 27.8%, structural 32.8%, and categorial 39.4%; For the English-Korean corpus, head-switching 23.5%, structural 35.3%, and categorial 41.2%, respectively. They show a wide variety of non-ITG word reorderings, which are hard to fully describe using simple patterns or rules. 3.2.4. Others. The fourth type of non-ITG reordering includes discontinuous transla-tion units, natural translation, and so on. Here, discontinuous translation units mean that they have discontinuity in either the source or target language only. In such cases, discontinuous translation units in one language are translated into a word or adjacent words in the other language, so that correct word reordering of discontinuous trans-lation units (DTUs) can improve machine translation. In Table IIId, the example (8) shows this type of non-ITG word reordering. A translation units  X  X ecame one of the Emperor X  X  ... wives X  in English is translated into two adjacent words  X   X   X  /become-queen  X   X  /did X .

As opposed to literal translation, natural translation often drops some constituents during translation. In (9), the first main verb  X   X   X  /decrease X  in the Chinese sentence is omitted in the Korean sentence. Hence, two Chinese words  X   X   X  /decrease X  correspond to one Korean word  X   X   X   X   X  / /decrease X , which causes non-ITG word reordering. In addition, there are difference in writing style between languages. For example, a list of pairs in one language is written in two separated lists in the other language as follows:  X  X  is a, B b, and C c, respectively X  in English  X  X , B, C  X  /TOP  X  X  X  / /respectively a, b, c  X   X  / /is X  in other language.
 This type of non-ITG word reordering accounts for the largest percentages of the Chinese-Korean and English-Korean corpora. As the corpora have different charac-teristics, the causes for this type are different. For the Chinese-Korean corpus, the omission of counterparts in one language accounts for 66.6% and the different style of writing 33.3%; For English-Japanese corpus, the omission 63.5%, DTUs 23%, and the style 13.5%; For English-Korean corpus, the omission 44%, DTUs 44%, and the style 12%, respectively. Similar to the third type, this type depends on so specific lexical pattern that we cannot find any generalized/structural patterns. We report the smallest size of the word sequence causing non-ITG word reordering, which is computed from failed ITG parsing results. After parsing, if a sequence of ele-ments in the stack  X  forms a continuous span in the target, we regard its corresponding word sequence in the source language as a non-ITG word reordering sequence. Many different sub-sequences in a sentence may require non-ITG word reordering. Among certain sequences, the minimum size is regarded to be equivalent to the size of non-ITG word reordering of the sentence. For example, the size of non-ITG word reordering of the example of Table I is 6, because the stack is [who, do, you, think, she, invited, ?] after the ITG parsing and  X  X ho, do, you, think, she, invited X  is the minimum size of the word sequence forming a continuous span in the target sentence.
 The histogram of the size of non-ITG word reordering is illustrated in Figure 3. The Chinese-Korean and English-Japanese corpora have longer sentences on average than English-Korean one, and the size of non-ITG word sequence from 11 to 15 accounts for the largest portion. For the English-Korean corpus, the largest portion ranges from 6 to 10 and the average is 9.25, which almost reaches the average sentence length of 11.92 for this corpus. This indicates that non-ITG word reordering is more likely to be global reordering than local one. It is also valuable to inspect the minimum SCFG rank to deal with non-ITG word reordering. The rank of an SCFG is the maximum number of the nonterminal symbols in the right hand side of the grammar. The expressive power of an SCFG with arbitrary rank, which generates all possible permutations for a given sequence, is generally much greater than that for ITG. The minimum rank of non-ITG word reordering is also computed from the failed ITG parsing result. After parsing, if a sequence of elements in  X  forms a continuous span in the target, the number of elements in the sequence is the rank. Among certain sequences consisting of at least 4 elements, the minimum rank is regarded as the minimum SCFG rank of non-ITG word reordering of the sentence.
The distribution of the minimum rank is illustrated in Figure 4. Most non-ITG word reordering requires a rank-4 SCFG, while there exist long tails of lager ranks. Ob-viously, ITG constraints, which has an expressive power of a rank-2 SCFG, is insuf-ficient because it misses a certain amount of non-ITG word reordering. In next sec-tion, we explore the possibility of transforming non-ITG word reordering to satisfy ITG constraints. We found many non-ITG word reordering cases between SVO and SOV languages. One major reason is the degree of freedom in word order. The SOV languages have a general tendency of having flexible word order, and they are morphologically-rich languages to indicate the roles of constituents. Adverbials are another source of freedom of word order regardless of languages.

In a head-final language with a flexible word order such as Korean or Japanese, nearly all constituents except the main predicate can be located anywhere before its head. The examples (2) to (4) are such cases that constituents except the main predi-cate can be scrambled. A simple rule for handling the freedom of word order is moving the wh-words and adverbials in front of the clause they belong to. This is a possible so-lution converting the word order without harming the meaning of the source sentence. In Table I, for example, the following two Korean sentences have the same meaning, but Korean 1 causes non-ITG word reordering, while Korean 2 does not. The brackets denote the clause boundaries.
 Converting the wh-question type.
 English: who do you think she invited? Korean 1 :[  X  /you  X  /TOP [  X   X  /she  X  / /NOM  X   X  /who  X  /ACC  X   X   X   X   X  /invite]  X   X   X   X  /think-do ?] Korean 2 :[  X  /you  X  /TOP [  X   X  /who  X  /ACC  X   X  /she  X  / /NOM  X   X   X   X   X  /invite]  X   X   X   X  /think-do ?]
For the English-Korean corpus, 5 we inspect the portion of acceptable conversions using the simple rule, and 30 sentences of 16 wh-questions and 14 adverbials types are indeed successful, accounting for 100%. This simple heuristic is also applicable to sentences including more than one adverbials as follows. 6 Converting the adverbial type.
 English: I really want to 1 speak to 2 her directly.
  X   X  / /want].
  X   X  / /want].

The third and fourth types of non-ITG word reordering would be transformed by rewriting the sentence. For (7) of Table IIIc, it is possible to make Japanese 1 as close to its literal translation as possible like Japanese 2 .
 Rewriting the divergence type.
 English: the construction of Jurakudai began in February 1586.
 Japanese 1 :  X   X   X  /Jurakudai  X  /TOP 1586  X  /1586 2  X  /February  X  /in  X   X  / /construction-begin  X  X  X   X  / /was.
 Japanese 2 :  X   X   X  /Jurakudai  X  /GEN  X   X  /construction  X  /TOP 1586  X  / /1586 2  X  /February  X  /in  X   X  /begin  X  X  X  /was.
 For (9) of Table IIId, it is similarly possible to rewrite Korean 1 as Korean 2 , as follows. Rewriting the other type.
 Chinese:  X  / /mixed-oil  X   X  /decrease  X  /to 8%.
 Korean 1 :  X  X  X   X  /refined-oil  X   X   X  /tariff-rate  X  /TOP 10%  X  / /to,  X   X   X  /mixed-oil  X  / /TOP 8%  X  /to  X   X  / /respectively  X   X   X   X  / /decrease.
 Korean 2 :  X   X   X  / /refined-oil  X   X   X  /tariff-rate  X  / /TOP 10%  X  /to  X   X   X   X  /decrease-and,  X   X   X  /mixed-oil  X  /TOP 8%  X  /to  X  X  X  / /respectively  X   X   X   X  / /decrease.

Among 17 divergences and 20 other types in the English-Korean corpus, 20 sen-tences are successfully converted by moving words properly, and 17 sentences by re-wording, which account for 54% and 46%, respectively, Although we cannot find any non-ITG sentences that are genuinely impossible to rewrite in a way that allows the ITG constraint. In practice, it is hard to manually correct all sentences in parallel corpora, and an automatic method of this process would be necessary as a future work. With three parallel corpora, we manually categorized the source of non-ITG word re-ordering between three SVO and SOV languages. We measured the size of non-ITG word reordering and the corresponding distribution of the minimum SCFG ranks. As a result, significant amount of non-ITG word reordering can be found. Although the portion of non-ITG word reordering in practice is much smaller than that in theory, it is nevertheless considerable. Therefore, ITG constraints is not adequate to the mod-elling of word reordering in machine translations in real situation. It remains difficult to correct sentences that violate ITG constraints automatically.

Dealing with non-ITG word reordering in an efficient manner is still a challenging problem. The search space beyond ITG constraints is much larger than that within ITG constraints, and  X  X nconstrained reordering is only helpful if we are able to esti-mate the reordering probability reliably [Zens et al. 2004]. X  One possible solution is to improve the distortion model used in statistical machine translation [Al-Onaizan and Papineni 2006; Green et al. 2010; Goto et al. 2013]. With a large amount of distortion or unlimited distortion, these approaches achieved translation quality over a simple distance-based distortion model. Utilizing translation units with gaps (or discontin-uous translation units) is also another approach [Crego and Yvon 2009; Galley and Manning 2010; Simard et al. 2005]. Some preordering approaches cast word reorder-ing problem to a well-known mathematical problem such as the Travelling Salesman Problem [Khapra et al. 2013; Visweswariah et al. 2011; Zaslavskiy et al. 2009] or the Linear Ordering Problem [Tromble and Eisner 2009]. Their methods have potential to deal with non-ITG word reordering as well, though Tromble and Eisner [2009] restrict the search space with ITG constraints for efficiency. In future, we will deal with the problem of non-ITG word reordering to overcome the limitation of ITG constraints, to enhance the capabilities of word reordering, and in this way eventually to improve translation quality.

