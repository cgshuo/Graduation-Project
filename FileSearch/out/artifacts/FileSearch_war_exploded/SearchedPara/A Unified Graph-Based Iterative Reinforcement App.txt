 General information retrieval systems do not perform well in satisfying users X  individual information need [20]. Many existing retrieval systems fail to discern indi-viduals X  search goals since most queries (usually short, ambiguous and lacking dis-criminative terms in general) don X  X  provide a complete specification of the user X  X  information need. In order to overcome su ch problems, we need to exploit users X  personalized information to accurately captu re user X  X  information need. There have back [15]. Both methods are effective. However, they require users X  extra effort; users are usually reluctant to provide additional information [1]. 
Implicit Feedback is a method which does not need the user X  X  extra effort. Implicit 19, 12] have shown that implicit feedback can improve retrieval accuracy. In this immediately viewed documents (also named click-through data), which are the clicked search results in the same query. 
Besides the implicit feedback information, there are many other resources which can be used for query model construction and result re-ranking. The clustering hy-pothesis [24] implies the following: closely related documents should have similar scores when ranking the document, and closely related terms should have similar scores when constructing the query model, so the relationships among terms and the relationships among search results can be exploited to improve effectiveness. The TT-Relationship (Relationship among terms) has been used for query model construction in [5, 2]. The contextual terms can be mutual ly reinforced. For example, the weight of  X  X omputer X  increases as many related contextual terms such as  X  X ardware X  and  X  X oftware X  co-occur. RR-Relationship (Relationship among search results) is also a since the immediately viewed result can be used to vote for similar search results. 
In the web, because there are many redundant and duplicate pages, ranking method system fail to learn much from the feedback. Diversity is important for obtaining good feedback information, especially when there is not sufficient information for the ommended, a greedy algorithm is used to penalize the search results overlap with user X  X  feedback information. 
This paper aims to make contributions on the following aspects: (1) We exploit three kinds of mutual reinforcement relationships: RR-Relationship (Relationship among search results), RT-Relationship (Relationship between search results and terms), TT-Relationship (Relationship among terms); (2) Based on the three kinds of HITS to produce better ranked results and better query model mutually and itera-tively, and the query model is updated when there is new implicit feedback informa-search results to recommend. 
In our approach, RR-Relationship reflects the mutual reinforcement among search results, RT-Relationship reflects the mutual reinforcement between search results and terms, and TT-Relationship reflects the mutual reinforcement among terms. To the best of our knowledge, how to exploit and utilize the three kinds of relationships in a unified model has not been well addressed in previous works. Moreover, our approach produces better ranked results and a better query model mutually and itera-improvements on retrieval effectiveness. 
The remainder of this paper is organized as follows. Section 2 describes previous work related to our approach. Section 3 describes our novel approach for personalized search. Section 4 provides the architecture of GBAIR system and some specific tech-experiments and the evaluation results. Section 6 draws some conclusions of our work. feedback information, and the related graph-based ranking methods. 
Many studies exploited query logs to capture users X  information need. UCAIR [16], PAIR [12] and [19] all use query history (query terms and clickthough data) to PAIR uses the search-related query history in the last 24 hours. [19] tries to mine the long-term search history. Both UCAIR and PAIR integrate the interaction information interactions [3] are also exploited to improve retrieval performance. Some studies [20, 8] combined several kinds of implicit feedback information. Our approach also util-izes the query-related query logs and immediately viewed documents. The main three kinds of relationships (RR, RT and TT) into a unified graph-based model. 
In recent years, several graph-based ranking methods similar to HITS algorithm [11] or PageRank [4] have been proposed. [22] uses sentence-to-word relationships to the results and words. [23] uses the affinity graph to compute the information richness of each search result. [21] utilizes sentence-to-sentence, word-to-word and sentence-to-word relationships to rank the sentences and words. The graph-based model in our work is partly inspired by [21]. However, they use it to select the sentences and then to form a document summarization while we focus on how to combine the relation-ships with the implicit feedback information (query logs and immediately viewed documents) to discern individuals X  search goals by producing better ranking results and a better query model mutually and iteratively. [12] is closely related to our work in that they also exploit immediately viewed documents and short-term history in query logs, and use a graph model to implement result re-ranking and query expansion. However, our work differs from that of [12] in Relationship) and the relationship among terms (TT-Relationship), thus, their result relied on the scores of search results, which will make query language model deviate too much from its initial value; (3) They don X  X  take the diversity of the recommended results into consideration. 3.1 Overview In this study, we exploit three kinds of mutual reinforcement relationships: reinforcement among search results. and a term should be relevant if it occurs in many relevant results, which reflects the mutual reinforcement between search results and terms. (3). TT-Relationship: a term should be relevant if it is linked with many other relevant terms, which reflects the mutual reinforcement among terms. Through these mutual reinforcement relationships, the query model and the ranked mutually and iteratively in a unified model. And the implicit feedback information can be utilized naturally to trigger the iterative algorithm by this unified model. Based on these mutual reinforcement relationships, we can leverage the ideas of PageRank construct these graphs in detail in the following section. 3.2 Graph Construction The proposed approach uses PageRank-like model to reflect the relationships among terms and relationships among search results, and use HITS-like model to reflect the relationships between terms and search results. We build the three sub-graphs based on the above relationships. To reflect the RR-Relationship, we build a directed graph G 1 = (V 1 , E 1 ), where the nodes V 1 correspond to the search results, and an edge  X  11 (, ) pqEpqV  X  X  X   X   X  is weighted by the con-tent similarity between p and q. where the nodes V 2 correspond to the terms, and an edge  X  22 (, ) pqEpqV  X  X  X   X   X  is weighted by the word relationship between p and q. where an edge  X  312 (, ) pqEpVqV  X  X  X   X   X   X  is weighted by the importance of term p in the search result q. 3.3 Parameters of the Graph The initial value of the node will be discussed in section 4. Here we will describe the computation of the weights of the edges. 3.3.1 RR-Relationship weight as follows: 3.3.2 RT-Relationship weight of the edge specifies the importance of t i in r j , which is computed as follows: the length of r j . 3.3.3 TT-Relationship We use the following formulas to estimate the relationships between words: 
Ptjti is the language model based on the collection Cq constructed by the t within the predefined window W in the collection Cq. ( | ) Cq ji Ptt can make the rela-tionship among words more suitable for the query, as the user give new feedback and then the relationship model can be updated. The relationships between two words are asymmetrical. 3.4 Iterative Algorithm After initialization, the iterative process of result score computation and query model optimization starts. We use (| ) iter pt  X  to represent the score of term t in the iterative algorithm, (| ) pt  X  to represent the query model, and () Sr to represent the score of result r. value of the search result r j after k-th iteration. The first term implies that the weight of the term relies on the search results linked with it, and the second term implies that the weights of the term rely on the terms linked with it. search result relies on the search results linked with it. The query model will be updated after each i t eration: order to compute the score of the search results and the terms, the following steps are repeated until convergence or the iterative time reaches a predefined threshold. 1. Apply (4) and (5) to compute the value of 1 (| ) k iter pt  X  + and 1 () k Srj search results. 3. Apply (8) to update the query model. are smaller than some predefined threshold  X  (e.g. 10 -6 ), the changes c is computed as the following formula: 3.5 Greedy Algorithm for Conformity Penalty After the iterative algorithm, the search results are ranked by the relevance, however, the top search result may be very similar and redundant. In order to get rich feedback applied to select n search results which are recommended to the users, and it is similar to the MMR[6] criterion, the algorithm goes as follows: algorithm, the number of recommended results n. 2. Select the search result r i which has the highest score, n=n-1 For each search result r j , j X  X : 3. Go to step 2 and iterate until n = 0. 
It decreases the ranking score of the result that is similar to the results which have information, the search goal becomes cl earer, the conformity penalty should be smaller. After the greedy algorithm, the t op n unseen search results are recommended to the user, here n is a predefined number (i.e. n=3). Also, the top m (i.e.50%) terms with highest weights in the query model are remained. 4.1 System Architecture plug-in based on the popular Web search engine Google. As showed in Figure 2, GBAIR has three main modules: (1) Result retrieval module retrieves results from search engine; (2) The user modeling module captures user X  X  implicit feedback infor-query model and triggers the iterative algorithm; (3) Iterative Algorithm module implements the graph-based iterative algorithm described in section 3, this module updates the query model and re-ranks the unseen search results. 4.2 Trigger Iterative Algorithm th rough Implicit Feed back Information Each query log contains query text, query time and the corresponding clicked search results (consist of URL, title and snippet). We judge whether a query log is related to are represented as a vector. If the similarity between the two vectors exceeds a prede-fine threshold, the query log will be consid ered to be related. When there are related query logs, the system utilized a method similar to PAIR [12] to extract representative terms from query logs, and then use the Fixed Coefficient Interpolation method of [17] to build initial query model. 
Immediately clickthrough document is important implicit feedback information we utilize. When the user click a result to view, the system utilized a method similar to PAIR [12] to extract representative terms extracted from immediately viewed documents. After extracting the representative terms, we apply Bayesian estimation method used in [17] to update the query model. 
When the system captures new implicit feedback information, the iterative algo-immediately viewed result when the iterative algorithm is triggered by the immedi-ately viewed result, otherwise, the initial scor es of a search results are set to be equal. 5.1 Experiment Setup We evaluate seven systems in our experiments: Google, PAIR[12]( a system which utilizes RT-Relationship ) , GBAIR BASE (the basic GBAIR system which do not use the RR-Relationship and TT-Relationship, the conformity penalty is imposed, RT-Relationship is used), BASE+RR (GBAIR system which use the RR-Relationship beyond GBAIR BASE), BASE+TT (GBAIR system which use the TT-Relationship beyond GBAIR BASE), BASE+TT+RR (GBAIR system which use the TT-Relationship and RR-Relationship beyond GBAIR BASE), BASE+TT+RR-DIV (BASE+TT+RR system which do not impose conformity penalty). PAIR [12] is se-lected as our baseline model, PAIR extracts representative terms from Query Logs and immediately viewed documents for result re-ranking and query expansion, it can be considered as a variation of pseudo-relevance feedback (PRF). 
GBAIR is based on the results from Google: when the user input a query, the sys-tem fetches the top N (N=30) results from Google, and adds them into a pool; when new expanded terms are obtained, the system will also fetched some new results and adds them to the pool. The process is the same as that of PAIR. 
It is a challenge to quantitatively evaluate the potential performance improvement adopt a similar quantitative evaluation to that of [16] and [12] to evaluate our system GBAIR. We recruited 8 students to participate in our experiments. Our experiments contain the following steps: First, we gave each participant a query set which contains HTRDP 2005 and 2004 topics 1 and some frequent queries from a commercial search engine, each participant browsed the query set and selected the queries related to their was used to help the user to form query. Each query was submitted to the seven sys-just as in normal web search. Then, at the end of each query, the 30 top ranked search results from these seven different systems were randomly and anonymously mixed together so that every participant would not know where a search result comes from. For every search result, the participants gave a rating ranging from 0 to 2, dividing the spectively measure the precision and NDCG (Normalized discount cumulative gain) [9] at top 5, 10, 20 and 30 documents of these systems. In the experiment, each par-calculated as follow: where r(j) is the rating of the j-th document in the list, and the normalization constant Zn is chosen so that the perfect list gets a NDCG score of 1. 5.2 Results and Analysis experiment, and the average evaluated documents for each query is 57; 645 docu-The corresponding numbers of relevant documents from PAIR,  X  X BAIR BASE X ,  X  X ASE+TT X ,  X  X ASE+RR X ,  X  X ASE+RR+TT X ,  X  X ASE+RR+TT-DIV X  are: 827, 825, 835, 852, 879 and 834 respectively. Table 1 shows the average precision of these seven systems at top n results among the 65 queries, and Table 2 shows the NDCG at top n results. 
As we can see, all the versions of GBAIR perform better than PAIR;  X  X ASE+RR+TT X  system performs best. Comparing  X  X BAIR BASE X  with PAIR, we can see  X  X BAIR BASE X  performs better than PAIR. This indicates that integrating query logs considered to be related to the current query deviate from the information need, the original query model may be not accuracy, the performance of  X  X BAIR BASE X  decreases more than PAIR. 
The performance of  X  X ASE+TT X  is better than that of  X  X BAIR BASE X . This shows that reinforcement relationships among terms are helpful in improving retrieval effectiveness. One explanation is that the approach can mine the term related the supported by many related terms. Through the reinforcement relationship, this term the search results can be improved.  X  X ASE+RR X  outperforms  X  X BAIR BASE X . This indicates the reinforcement rela-tionships among search results are effective. A possible explanation is that a relevant search result may be not relevant to the query because the terms in the relevant search score through the reinforcement relationships among search results. When a search result is clicked, the relevance can be transmitted to the similar search results. There-fore using the reinforcement relationships can better rank the search results.  X  X ASE+RR+TT X  system can greatly improve the retrieval effectiveness compared to  X  X ASE+RR X  and  X  X ASE+TT X . This indicates that although a single factor can work, integrating the three kinds of reinforcement relationships can produce an even better performance. The effects of the factors can be mutually boosted.  X  X ASE+RR+TT X  has better performance than  X  X ASE+RR+TT-DIV X . The greedy algorithm concerning the diversity is effectiv e. For one thing, keeping the diversity of more results(the user are not likely to click result which is very similar to those he/she  X  X ASE+RR+TT X  and  X  X ASE+RR+TT-DIV X  respectively is 2.2 and 1.9), which can give the system more feedback information. When the query is difficult, much of the search results are not relevant,  X  X ASE+RR+TT X  can outperform  X  X ASE+RR+TT-DIV X  more. 5.3 Efficiency of GBAIR The approach we proposed is efficient. The relationship among words is computed offline. The average iteration times of our approach in the experiment are 9, and the response time of the proposed approach (exclusive the time for fetching results from Google) is imperceptible for users (usually less than 0.1s on a desktop). kinds of mutual reinforcement relationships to improve retrieval effectiveness for personalized search. Unlike most previous work, we utilize a novel graph-based itera-tive algorithm that can make use of query logs, immediately viewed documents, and the three kinds of reinforcement relationships (RR-Relationship, RT-Relationship, TT-Relationship) to update the query model and re-rank the search results mutually and iteratively. Experiments clearly show that our approach is both effective and efficient. 
The work can be further improved on several aspects, such as exploiting other approach, etc. This work was supported by the National Science Foundation of China (60736044, 60773027), as well as 863 Hi-Tech Research and Development Program of China (2006AA010108, 2008AA01Z145). 
