 There has been a huge raise in digital cont ent production during the last decade. Due to this rapid increase and large amount of data, finding relevant information has turned to become a very challenging task for web users. 
A large number of studies have tackled this problem in information retrieval (IR) systems to enhance the performance of existing systems. One category of such meth-ods utilizes user X  X  judgment (relevance feedback) over the retrieved documents to items. This method has proved to be very efficient and has been widely used in many operational search engines. Query reformulation techniques proposed in the literature fall into two categories. retrieved document to reformulate the original query. Two main strategies have been proposed: local clustering [1], [2] and global analysis [3], [4] or a combination of both local and global context [5]. query expansion and term reweighing [6], [7], [8]. Query expansion techniques consider over entire corpus to assemble a revised new query. 
Applications of genetic techniques for processing query optimization have been proposed by several authors. Gordon [9] adopted a GA to derive better descriptions of documents. Each document is assigned N descriptions represented by a set of index-ing terms. Genetic operators and relevance judgment are applied to the descriptions in order to build the best document descriptions. The author showed that the GA pro-duces better document descriptions than the ones generated by the probabilistic model. Redescription improved the relative density of co-relevant documents by 39.74% after twenty generations and 56.61% after forty generations. 
Yang et al. [10] proposed a GA for query optimization by reweighing the query term indexing without query expansion. They used a selection operator based on a stochastic sample, a blind crossover at two crossing points, and a classical mutation to renew the population of queries. The experiments showed that the queries converge to their relevant documents after six generations. 
Horng et al. [11] propose a novel approach to automatically retrieve keywords and approach is demonstrated by comparing the results obtained to those using a PAT-tree based approach. 
One drawback with a large number of previous studies on query expansion is, they use a fixed criteria for choosing expansion terms and mainly ignore the habits, inter-ests and needs of the users which might change over time. In this work we tackle this shortcoming by proposing a new query expansion technique using GP to evolve new varying needs. Specifically Genetic programming is used to find a formula for select-ing a set of terms to be added to the original submitted query. 
The reminder of the paper is organized as follows. Principles of our proposed ap-periments and results in section three. Section four brings conclusions. In this work, we use genetic programming [12] to evolve a formula for query expan-sion during evolutionary process. Like probabilistic RF [13], it then adds a number of highly weighted terms to the query. 
To start the evolutionary process, a set of queries and tagged relevant documents to each one is needed. Success of GP is dependent on the size of this set. For this pur-pose, we used Cranfield dataset which is largest of the three datasets we used in terms of number of queries. In all experiments discussed in this paper, weighting functions train, test and validation fractions with 100, 50 and 75 queries in each fraction respec-tively. Validation set is used to overcome the over-fitting. 
For each query in the training set, a fixed number of documents (DCV 1 ) are re-trieved. As relevant and non-relevant documents for each query are known, statistical features could be calculated at leaves of trees after query submission. Terminals used by the GP are listed in table 2. 
To evaluate a term weighting formula, m (=10) terms with highest weight, were se-maining set of documents in the dataset. It is important to notice that at this stage, the first set of retrieved documents must be eliminated when evaluating the revised query. marked by the user. Effectiveness of this weighting function is evaluated as the mean precision over 11 standard recall points. Best formula from the final population is considered as the weighting function. Evolved formula in this way is evaluated over a test query set of either the same data-local minima, we stop the GP as soon as a decrease over validation set is observed. In a typical scenario, DCV documents are first retrieved and presented to the user. performed using generated weighting function. Terms of the relevant documents are weighted according to this weighting function and a number of terms with highest over all queries is considered as the fitness of the individual. Applying genetic opera-final population, the same is done for all queries in the test set and the average preci-sion over all queries is reported as the performance. In order to evaluate the proposed method, we conducted two experiments over three standard datasets. Statistics of these sets are given in table 1. 
For stop-word elimination we used the smart system [14]. Stemming was per-formed using porter stemmer [15]. Remaining indexing terms were weighted by Tf-Idf weighting formula. A cosine similarity measure was used. Parameters used for constructing trees are shown in tables 2 and 3. Functions (operators) +, -,  X , /, sqrt, log Fitness function Average precision over all queries Parse tree initial depth 3 Number of retrieved documents for a query 25 Terms added to each query (m) 10 Population size (pop) 30 Generations (maxgen) 20 Cross-over 0.6 (tree replacement) Mutation rate 0.1 (Single node mutation) 3.1 Experiment I In this experiment, a subset of 125 queries was randomly selected from Cranfield dataset. Best evolved formula over this set was then evaluated over the test queries of the Cranfield. Due to stochastic nature of GP, we averaged the results over ten runs of Reported results in both experiments are compared against the bared original query and query enhanced by PRF. Improvements are calculated as percentage of the differ-ence between GP and PRF. Best individual derived after evolution is given in following equation. 3.2 Experiment II Lower performance than of Cranfield using a genetically evolved weighting function also supports the idea that there might be more promising weighting functions over all datasets which work better than previously suggested by experts. Expanded query using GP showed a higher performance over both datasets than the original query. In this paper we proposed a new query expansion method using GP based on relevance feedback. In the first experiment an evolved formula over a training query set was evalu-ated over a distinct query test set randomly picked from the same dataset. In the second, evolved classifier over the first dataset was applied to the second and third datasets. 
In both of experiments, we observed that very small and very large values for m do not enhance results significantly maybe because small number of terms are not enough and large numbers are ineffective as they cause great overlap among queries. From the computational complexity point of view, PRF and GP perform the same as offline and then a function is then used for query expansion in online search. 
The gain in retrieval performance we achieved in this study, approach the five per-formance improvement. Our results are in accordance with this finding. These results indicate the merits of further investigation of our method. 
