 We present Sedano , a system for processing and indexing a continuous stream of business-related news. Sedano defines pipelines whose stages analyze and enrich news items (e.g., newspaper articles and press releases). News data coming from several content sources are stored, processed and then indexed in order to be consumed by Atoka, our business in-telligence product. Atoka users can retrieve news about spe-cific companies, filtering according to various facets. Sedano features both an entity-linking phase, which finds mentions of companies in news, and a classification phase, which clas-sifies news according to a set of business events. Its flexible architecture allows Sedano to be deployed on commodity machines while being scalable and fault-tolerant.
 business intelligence; news retrieval; entity linking; text clas-sification
Nowadays a deluge of news articles and press releases of-ten bewilders readers; this explains why news aggregators have surged in popularity. While news aggregators do a good job for readers in general, they may not be enough if someone is interested in specific business-related news and events, e.g.: which are the news where a particular company is mentioned? Which news recently talked about company events, like lay-offs or mergers and acquisitions? Which are the interesting events regarding a specific company? For this reason we created Sedano , a system that is able to ingest, process and enrich news stream in a scalable manner. The news are indexed and offered via a RESTful API, in order to be consumed by our end-user product Atoka 1 , a semantic tool for lead generation , but also by other business clients that integrate the information provided by Sedano in their products. http://atoka.io tent is well-structured) which later help us understand if that news item is  X  X ood X  or not (and therefore whether or not it should be served to certain clients).
 Deduplication. News items are then deduplicated. Since finding duplicates by comparing new documents with previ-ously indexed ones would be costly, we adopt a more scalable on-line approach, based on a novel Locality-Sensitive Hash-ing (LSH) algorithm which mixes the Solr 6 approach with the Nilsimsa algorithm 7 to hash similar news items into the same code. A news item is then tagged as a duplicate if and only if another news item with the same hash code is known to have been processed before. To keep this infor-mation consistent across worker nodes, we rely on a scalable key-value store with strong consistency guarantees. Enrichment. The remainder of this section discusses the two main enrichment components in the Sedano pipelines: the Dandelion Company API (Section 2.1), an entity link-ing platform focused on the identification of company men-tions in news, and Selino (Section 2.2), an ensemble of linear multi-label text classifiers whose classes are business events of interest.
Dandelion API 8 is a platform for text-analytics as a ser-vice: it is the evolution of Tagme [1], a state-of-the-art en-tity linking system based on a knowledge graph extracted from Wikipedia, whose main benefits are its performance on short texts and its speed. Our partnership with Cerved 9 , the leader of business information in Italy, gave us access to data of all Italian companies. We used this data to specialize the entity linking system into the Dandelion Company API for identifying company mentions. It includes information on almost 3M companies, which are added as new entities to our knowledge graph. Despite the huge number of entities that have been added, the system preserves its speed.
Since the new entities do not have cleaned data like Wiki-pedia ones, they may introduce noise. For this reason we added a new layer, based on a Named Entity Recognition (NER) classifier, which is able to identify named entities of type  X  X ompany X . The result of the NER classifier is used as an additional feature for the subsequent disambiguation step 10 , in order to better identify company entities.
We carried out several tests with data sets created by means of crowd-sourced annotations, and we yield a F 1 of 60%. However, for each annotation we also compute a con-fidence score; setting a threshold for this score can be used to balance prevision vs. recall. Since for this kind of prod-uct we are mainly interested in precision, we decided to set the threshold to maximize the F 0 . 5 , yielding a precision of  X  80% and a recall of  X  45%.
Selino is a component of the Sedano pipeline dedicated to the automatic classification of news according to a pre-defined set of categories. The categories we are interested in are business events with negative connotation (i.e.: lay-offs, strikes, shutdowns, material damages, financial losses, frauds and legal issues) plus other generic events (mergers http://lucene.apache.org/solr https://en.wikipedia.org/wiki/Nilsimsa Hash https://dandelion.eu https://www.cerved.com
Refer to [1] for further details and terminology
