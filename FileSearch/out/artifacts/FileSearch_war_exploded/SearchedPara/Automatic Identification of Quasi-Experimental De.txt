 Researchers in the social and behavioral sciences routinely rely on quasi -experimental designs to discover knowledge from large data bases. Quasi -experimental designs (QEDs) exploit fortuitous circumstances in non -experimental data to identify situations (sometimes called  X  X atural experiments X ) that provide the equivalent of experimental control and randomization. QEDs allow researchers in domains as diverse as sociology, med icine, and marketing to draw reliable inferences about causal dependencies from non -experimental data. Unfortunately, identifying and exploiting QEDs has remained a painstaking manual activity, requiring researchers to scour available databases and apply s ub stantial knowledge of statistics. However, recent advances in the expressiveness of databases, and increases in their size and complexity, provide the necessary conditions to automatically identify QEDs. In this paper, we describe the first system to di scover knowledge by applying quasi -experimental designs that were identified automatically. We demonstrate that QEDs can be identified in a traditional database schema and that such identification requires only a small number of extensions to that schema, knowledge about quasi -experimental design encoded in first -order logic, and a theorem -proving engine. We describe several key innovations necessary to enable this system, including methods for automatically constructing appropriate experimental units and f or creating aggregate variables on those units. We show that applying the resulting designs can identify important causal dependencies in real domains, and we provide examples from academic publishing, movie making and marketing, and peer -production system s. Finally, we discuss the integration of QEDs with other approaches to causal discovery, including joint modeling and directed experimentation .
 H.2.8 [ Database Applications ]: Data Mining Algorithms, Design, Experimentation, Languages, Theory.
 Quasi -Experimental Design, Causal Discovery. Quasi -experimental designs are a staple of research in the social and behavioral sciences, economics, and medicine. A quasi -experimental design (QED) is an approach to data analysis that exploits fortuitous characteristics of the data that allow the equivalent of experimental control or randomization [4] [5] [19] . QEDs are s ometimes called  X  X atural experiments X  because they emulate the conditions that allow investigators to infer causal dependencies from small amounts of data using laboratory experiments.
 QEDs can be a powerful tool for inferring causal knowledge, but applyin g these designs is a painstaking manual affair, requiring extensive knowledge of both the data and the conditions under which a QED can be applied. As a result, the opportunity to apply QEDs can be missed by investigators, even though such application requ ires no additional data collection. Investigators must cull through their data schema with great care to identify situations in which QEDs can be applied, and opportunities for causal inference using these designs can go unrecognized.
 In addition, the oppo rtunities to apply QEDs in more general settings have increased dramatically in recent years [11] . First, the expanding complexity of databases is increasing the number of situations that match the conditions necessary to apply a QED. Second, the expanding size of databases is increasing the prob -ability that the subsets of data used by QEDs will provide the necessary statistical power to identify subtle causal dependencies. Finally, the availability of new data and knowledge rep resenta -tions, particularly relational and temporal representations, and their associated inference methods, is making it possible to reason automatically about the preconditions for applying QEDs.
 In this paper, we report the first instance of a fundament ally new approach to knowledge discovery in databases. We describe and evaluate a proof -of -concept system that shows how QEDs can be identified automatically. We show that QEDs can be found using only a relational database schema, additional information ab out the temporal durations of specific events, and limited prior knowledge about potential causes. We report several representational innovations that facilitate automated discovery of QEDs, including automatic construction of event streams and aggregated variables. Finally, we apply the approach to several data sets and discover non -trivial and useful causal dependencies based on the identified QEDs. Many of the ideas that led to this work are illustrated by recent studies published in the sociolog y literature. In late 2007, sociologists at The Ohio State University published a paper in the Journal of Youth and Adolescence [1] . The paper reported that early sexual activity among adolescents increases their risk of delinqu ency. 1 The study not only concluded that the two types of behavior are statistically correlated, but that early sexual activity actually causes an increase in delinquency. Their findings indicated that, to reduce delinquency, public programs should focus, at least in part, on efforts to reduce early sexual activity. The study was based on a mostly manual analysis of a large and complex data set  X  the National Longitudinal Study of Adolescent Health  X  commonly known to researchers as  X  X dd Health X . The data set resulted from a nationally representative study that explored health -related behaviors of more than 15,000 adolescents in grades 7 through 12 and their outcomes in young adulthood [21] . The Add Health data allow researchers to examine how adolescents' experiences and social contexts (families, friends, peers, schools, neighborhoods, and communities) influence their health and risk behaviors. The data have been used in more than 1,000 published reports and journal articles.
 Th e Ohio State researchers were trying to do something very difficult: draw causal conclusions from non -experimental data. One primary challenge of such work is that, to conclude that a statistical association between two variables indicates causal dependenc e, the analysis must account for the effects of all common causes of the variables. To address this concern, the researchers attempted to control for potential common causes of both sexual activity and delinquency by modeling those effects and mathematical ly removing them, an approach often called  X  X tatistical control. X  The potential common causes they modeled included gender, race, parental education, receipt of public assistance, family structure, prior delinquency, depression, school grades, parental su pport, illegal substance use, relative physical development, dating experience, and virginity pledge status.
 Unfortunately, it appears that these controls were inadequate. Another study, completed by researchers at the University of Virginia at Charlottesv ille [8] and first released just a few months later, came to a very different conclusion. The study found that genetic and environmental differences between families explained the statistical association between early sexual exp erience and delinquency. Indeed, after controlling for these genetic and environmental causes, early sexual experience predicted slightly lower levels of delinquency in early adulthood rather than the higher levels that the Ohio State researchers had found . The findings suggest that some other factor, perhaps genetics, increases risk -taking behaviors, including both sexual activity and delinquency. The study was so convincing that the authors of the  X  X elinquency X  refers generally to illegal acts by minors, including those applicable only to minors, such as truancy and alcohol use. In these studies, researchers assessed delinquency by scoring self -reported incidents of graffiti, property damage, shoplifting, other theft, and drug dealing. first study later agreed to this reinterpretation of their findings [22] .
 Why was the later study so convincing? Rather than apply statistical controls, the second group of researchers applied a quasi -experimental design. Specifically, they identified 534 same -sex twin pairs in the Ad d Health data. Twins share similar or identical genetics (depending on whether they are fraternal or identical twins) and similar fetal and early childhood environments. As a result, studying twins provides a way to control for genetic and environmental fa ctors without the need to explicitly identify and model the effects of these factors. In the case of the Add Health data, focusing on twins allowed the Virginia team to control for additional factors that were not successfully measured or controlled in the initial study.
 This example points to one of the key insights about QEDs for knowledge discovery: analyzing only a subset of all available data can increase the validity of the resulting conclusions, provided that subset meets some highly specific conditi ons. Indeed, such subsets can provide evidence for stronger conclusions about causality than can an uninformed analysis of the entire data set. QEDs make it possible to discover causal knowledge from observational data. Here, caus ality means th e assertion that dependence exists between A (the cause) and B (the effect) such that manipulation of the cause will result in the manipulation of the effect. Causation implies that varying A will make B vary. Causal knowledge differs substan tially from the type of knowledge identified by most knowledge discovery algorithms, which captures only statistical associations . Classification trees, association rules, support vector machines, Bayesian classifiers, and nearly all other types of statist ical models constructed by knowledge discovery algorithms make no commitments about causality. They only attempt to represent statistical associations. Knowing the value of A will help you predict the value of B , but changing the value of A may or may not affect the value of B . Causal knowledge has unique advantages over knowledge that identifies only statistical association. Causal knowledge is actionable in ways that statistical associations are not. A statistical association between two variables A and B could indicate that A causes B , that B causes A , or that some third variable C causes both A and B . If the goal is to affect the value of B , each of these situations implies different actions. For additional details, see a recent discussion with examples of causal knowledge discovery [11] .
 In addition, causal knowledge provides a more compact representation of knowledge about the associations among a set of variables. Rather than showing a complex pattern of statistical associat ions among a set of variables, causal models show a much smaller set of causal dependencies from which the larger set of statistical associations can be derived. Inferring causal dependencies from data is strictly more difficult than iden tifying statistical associations. Classically, the inference that A causes B relies on three conditions:  X  Association  X  The values of A and B are statistically  X  Direction  X  The direction of causality is known (e.g., based  X  No common causes  X  The effects of all common causes of A The challenge of eliminating common causes is particularly daunting, and different methods for causal inference approach this challenge in different ways.
 One approach i s to employ a classical experiment in which researchers can explicitly affect the conditions under which data are gathered. In classical experiments, researchers use both control and randomization to eliminate the effects of potential common causes [7] . Control holds potential confounding variables constant so that they cannot affect the experimental outcome, and randomization assigns experimental subjects to treatments randomly so that potentially confounding variables cannot sy stematically affect outcomes. Randomization is particularly powerful, because it can eliminate or implicate entire classes of variables as potential common causes, even if an investigator has never defined or measured those variables. For example, an exper imenter need not know which characteristics of an experimental subject (e.g., a medical patient) might be a common cause of A and B outside of the experimental context , as long as subjects are randomly assigned to groups receiving different treatments (val ues of A ) within the experiment. The random assignment of A removes the potential for any variable to be a common cause of both A and B .
 However, investigators often wish to infer causality in situations that are not amenable to classical experiments, eith er for logistical or ethical reasons. An alternative to an experiment is to use observational (non -experimental) data and to identify, measure, and model potential common causes of A and B . With an accurate model, an investigator can mathematically remove the effects of common causes and then ascribe any unexplained association to the causal effect of A . This approach has been pioneered over the past several decades by researchers in several fields, including statistics [9] [10] [18] , computer science [16] , and philosophy [20] . Successfully applying this approach requires identifying and measuring all potential common caus es, an assumption referred to as  X  X ausal sufficiency. X  The Ohio State team took one version of this approach in their study (although their analysis appears to have violated the causal sufficiency assumption).
 Another approach to analyzing observational d ata is to apply quasi -experimental designs. QEDs identify configurations of the data that provide the equivalent of control or randomization (sometimes called  X  X seudo -control X  or  X  X seudo -randomization X ). These designs were pioneered by sociologist Donald T . Campbell and his colleagues, beginning in the 1960s [4] [5] [19] , and they have since been used in thousands of published papers in the social sciences, economics, and medi cine. QEDs employ a variety of methods to emulate control and randomization. For example, one design (the non -equivalent control group design) attempts to identify two sets of data instances that have similar responses to temporal events but that differ in whether they experience a given treatment event. Another (the regression -discontinuity design) models the combined effect of both a discrete treatment and another variable that determines which units receive treatment. Other types of quasi -experimental de signs that have been devised include the proxy pretest design, double pretest design, non -equivalent dependent variables design, pattern matching design, and the regression point displacement design [5] .
 Nearly all QEDs can be t hought of as exploiting the temporal or relational structure of the world to provide quasi -control or quasi -randomization. For example, the twin design employed by Harden et al. exploits the fact that two different individuals share (are related to) a comm on genotype. As a result, systematically examining behavioral differences between twins can control for the vast array of genetic factors that could affect behavior. Similarly, the several QEDs exploit the fact that the characteristics of a single entity ( say, a company) are likely to remain relatively stable over short time -periods. This fact facilitates the inference that an external event causes company behavior if that behavior changes substantially just after the event. QEDs have a number of advantages over statistical control or classical experiments. First, QEDs can surpass the validity of attempts at statistical control because they can control for entire classes of variables, even though those variables are not i dentified, measured, or modeled. Statistical control requires all three of these things, while some QEDs identify subsets of data for which the relational structure assures that entire classes of variables will be controlled. For example, the Virginia team was able to use a QED to factor out variables characterizing genetics and early family environment, even though they did not specifically identify, measure, or model any variables in these sets. Rather, they relied on the fact that twins had identical gen etics and early family environment, regardless of which aspects of these factors might have influenced sexual activity or delinquency.
 Second, QEDs can surpass the validity of controlled randomized experiments because they apply to data collected  X  X n place  X  rather than in an artificial laboratory setting. While laboratory experiments often allow exquisite levels of control and randomization, these advantages are often purchased at a high price by introducing artificiality into the study. Thus, while experim ents have higher  X  X nternal validity X  (they are internally consistent), they can sacrifice  X  X xternal validity X  (ability to generalize to the real world) [4] . Conclusions reached by QEDs typically have higher external validity tha n the corresponding experimental study, though they may sacrifice some degree of internal validity.
 Third, QEDs do not require the collection of additional data. Instead, investigators can apply them to an existing data set and draw strong causal conclusio ns. Indeed, as we show below, the identification of a QED does not require any data collection, only a specification of a data schema. This means that designs can be identified in advance and then used to guide data collection. Finally, QEDs do not preclud e alternative methods for causal inference. Indeed, they can serve as a valuable adjunct to statistical control (by eliminating or identifying potential causal relationships) and to experiments (by limiting the number of potential dependencies that must be experimentally evaluated). That said, QEDs also suffer from several limitations. First, the designs are only applicable in a very limited number of situations. The increasing size and complexity of relational databases offer expanding opportunities for ap plying QEDs, but still only a small fraction of causal dependencies will be amenable to examination by these designs.
 Second, because many QEDs use only a subset of the data to infer causal dependencies, the validity of their conclusions relies on the repr esentativeness of that subset. For example, twin studies rely on the assumption that twins do not differ substantially from non -twins with respect to the characteristics under study. This assumption has been largely valid in the past, because twins occurre d relatively randomly within the population of all births. However, in the past two decades, fraternal twins have become far more common due to the use of in vitro fertilization. These children tend to be born to older mothers, among other differences, and thus may differ systematically from non -IVF children. QEDs are widely used because of their advantages and despite their limitations. As one rough indicator, Google Scholar lists over 4,500 citations to each of two classic text s on the subject [4] [5] and lists over 20,000 papers that use the terms  X  X uasi -experimental design X  or  X  X uasi -experiment X . However, these uses are entirely manual  X  investigators identify the potentia l to apply a QED based on their own knowledge of the data and of QEDs, and they do so without help from an automated system. We are unaware of any prior work on automated or semi -automated systems for identifying applicable QEDs based on information about a database.
 That said, the potential benefits of an automated system are large. First, such a system would allow automated checking of large and complex schemas for applicable QEDs. As the example in the introduction shows, it is easy for even experienced investigators to overlook important opportunities to apply QEDs. An automated system could alert researchers to applicable designs with relatively little work on their part.
 Second, an automated system would allow easy rechecking when changes occur to a da tabase's schema or the knowledge of potential causal dependencies. When one study confirms or disproves a given causal dependence, it is not currently easy to assess the wider implications of this finding for the applicability of QEDs for other potential d ependencies. An automated system could continuously evaluate the impact of new findings and alternative sets of assumptions made by an investigator on applicable QEDs. This, in turn, could significantly aid the process of collaboratively constructing knowl edge bases (e.g., [17] ). Finally, an automated system for identifying QEDs would allow these methods to be integrated with other automated methods for causal modeling [16] [18] [20] . These methods learn the structure and parameters of a joint probability model of a large collection of variables. While research on these methods continues, they face a large number of challenges both in terms of accura cy and computational complexity. These challenges could be partially addressed by applying QEDs whenever possible to identify key dependencies, reduce the size of the search space, and reduce the sample complexity of learning. This is particularly true as the complexity of models increases, as it has with the relatively recent advent of relational and temporal models. To evaluate whether automated discovery is possible and realistic, we have developed AIQ (for  X  X utomated Identification of Quasi -experiments, X  pronounced  X  X  -eye -que X ), a system for reasoning about the applicability of QEDs to specific data sets. AIQ (v. 1.0) is implemented in SWI Prolog. 2 Source code and Prolog -encoded http://www.swi -prolog.org inputs for several public databases are available from ou r website. 3 The algorithm takes as input a relational database schema augmented with information about the temporal extent of specific types of entities and relationships, along with information about the potential causes of specific variables on those ent ities and relationships. From this information, AIQ constructs several types of intermediate representations, including temporal streams of events, aggregated variables on those streams, and units that identify the data entities that will be used to test s pecific causal dependencies. There are a large number of combinations of these intermediate representations, and each combination applies to only a handful of potential QEDs. The algorithm checks which combinations of these intermediate representations cor respond to valid QEDs, and outputs all such designs. The investigator can then evaluate the validity of each design and run appropriate statistical tests based on them. Alternatively, designs output by the algorithm may indicate flaws in the database schem a or ancillary information, in which case the investigator can modify the database -specific information and iterate. In section 4 , we provide results of running AIQ on several data sets, for which we encoded their database schema and ancillary information in first -order logic. For convenience, we illustrate those schemas through augmented Entity -Relationship (ER) diagrams [6] . Specifically, we represent the ER diagram using a slightly modified Barker Notation [2] where entities are rectangular boxes and the relationship between two entities is a solid connecting line with the cardinality of the relationship represented as symbols on both ends of th e connection. Entities can be related through one -to -one, one -to -many, or a many -to -many cardinality. For example, given the two entities paper and conference and a relationship where a paper appears in one conference but a conference has many papers would be considered as many -to -one cardinality. In Barker Notation, open circles are used to identify zero, a vertical bar or dash is used to identify one, and a symbol where three lines intersect represents many. For simplicity, we do not use cardinality of ze ro, and cardinality of one is represented by an absence of a symbol.
 Many QEDs rely on knowledge about the existence of events and the temporal extent of entities. ER diagrams do not specify such temporal characteristics of data, so we must augment the sch ema with this information. Temporal extent identifies the average lifetime of an object and is used in causal modeling to identify if a stream associated with an entity can be a valid cause for some observed effect. Temporal frequency identifies how often one object changes in relation to another object.
 Our temporal ER diagrams identify the extent duration of entities by adding a time label inside of the entity box (see section 4.1 ). To introduce temporal frequency, we have exte nded the ER diagram to include a frequency label that annotates one -to -many relationship between entities. Where a many -to -many relationship exists, two directed temporal frequencies would be provided, one on either side of the many -to -many relation. For e xample a Store may have many Customers, and the temporal frequency from the Store to Customers would represent how often the Store receives a new Customer. In cases where the frequency is varied across http://kdl.cs.umass.edu/causality/ different objects of the same type, an average frequen cy is used to represent the set. For all temporal annotations in this paper, we measured frequencies in days. In addition to temporal annotations on entities and relations, individual variables in AIQ are annotated with information about t heir potential causes. By default, every other variable in the database is a potential cause, but prior knowledge of investigators and existing analysis approaches (e.g., joint modeling) can be used to prune the set of potential causes. In the most extreme case, an investigator might know that a variable has no causes; in the language of QEDs, this variable would be considered quasi -random . For example, some government programs that provide services to individuals (e.g., job training) are allocated by lotte ry among all qualified applicants. Clearly, such situations represent highly useful knowledge for identifying potential QEDs. From the database schema and temporal annotations, AIQ automatically constructs streams that repr esent series of events occurring over a period of time with respect to a given static entity. For example, scientific researchers typically produce multiple papers at irregular intervals each year; from the perspective of the researcher, there exists a str eam of papers over their entire career. AIQ automatically identifies potential streams based on the augmented database schema. Streams are defined as pairs of entities and an associated connecting path. Valid streams must match three conditions: (1) The tw o entities must be connected by a path of relationships; (2) The first entity must have a one -to -many relationship with the second entity; and (3) The first entity must have an extent longer than the average frequency along the stream.
 These conditions def ine the structure of a stream  X  a base entity, followed by a sequence of zero or more items on a relationship path, followed by an entity that is  X  X ynamic X  with respect to the base entity. It also gives rise to the algorithm in which streams can be recursi vely defined by enumerating all candidate paths. Additionally, in a particular direction, a  X  X any X  relationship will be propagated for the remainder of the path. For example, if item A is connected to B through a one -to -many relationship, and item B is con nected to item C through a many -to -one relationship, then item A has a one -to -many relationship with item C.
 Given a stream, AIQ also constructs a set of variables on those streams that can be used in one or more designs. Stream variables include aggregati ons of variables on the dynamic entity, such as the average box office receipts of movies released by a given studio (the dynamic and base entities, respectively) or the sum of the page counts of articles published by a given author. Stream variables also include existence variables, which allow QEDs to identify causal influences on the occurrence of an entity. Any variable defined on an entity that becomes the dynamic entity of a stream can be aggregated into a stream variable. The notion of an experimental unit is crucial for developing effective quasi -experimental designs [19] . Essentially, a unit defines the boundaries for possible causes in an experiment. For example, in a clinical trial, a unit would be a person receiving a drug treatment. However, in the relational setting a unit can be any collection of related entities. We automatically define our units based on generated streams. The base item common to the two streams in a proposed design is the c ore of the unit, and the dynamic items, as well as the items on the paths in the streams, compose units in our QEDs. Additionally, a unit is defined with respect to a specific period of time, which is also automatically derived from the temporal frequencie s provided through the schema description. AIQ combines input information (the database schema and potential causes) with information it constructs (potential streams and units) to identify and evaluate potential QEDs. In version 1.0, we focus on a single class of QEDs  X  the non -equivalent control group design . This design combines relative simplicity, wide applicability, and intuitively understandable results. Future versions of AIQ will implement a much wider array of classes of QEDs. The non -equivalent control group design, also called the  X  X on -equivalent comparison group design, X  is similar to one of the most widely used experimental designs (the  X  pretest -posttest control group design X  ). The experimental version of this design randomly assigns units to either a control group or a treatment group, measures a set of variables on all units (the pretest), then administers treatment to only the treatment group, and measures the variables again (the posttest). In the quasi -experimenta l version of the design, investigators cannot assign treatment randomly. Instead, in the non -equivalent control group design, treatments are assigned non -randomly and causal inferences are based on the relative rates of change of the two groups (e.g., the threats to validity might be judged low if the treatment group X  X  observed response increases sharply after treatment and the control group X  X  response remains unchanged) [19] . That said, AIQ currently also requires that all poten tial common causes be ruled out (a condition most frequently met by treatments being designated as quasi -random), to provide additional confidence that treatment and control groups are similar.
 AIQ identifies an instance of the non -equivalent control group design whenever: (1) two distinct stream variables  X  potential cause A and potential effect B  X  can be defined with respect to the same unit; (2) A and B have no common causes (e.g., A is quasi -random); and (3) the entities defining A and B match certain temporal constraints (e.g., causes occur less frequently than effects). Such cases correspond to the canonical non -equivalent control group design, in which a potential causal event happens rarely enough that measurements of effects can be made both before (pretest) and after (posttest) the potential causal event. When identified, instances of this QED are output for inspection and evaluation by the investigator. The QED specifications identified by AIQ provide sufficient information that f ormulating a statistical test for causal dependence is fairly simple, given that data are readily available. In theory, the test could be done automatically by AIQ, but there were a sufficient number of implementation decisions that could crucially affect the validity of the hypothesis test that we chose to leave such tests outside the boundaries of automation (see section 4.3 for an example). These include questions of sampling, test statistic, and aggregation method for stream variables. Instead, AIQ 1.0 identifies the QED in sufficient detail that statistical tests can be run fairly easily by the investigator. To evaluate the utility of the AIQ algorithm, we applied it to three public databases that are widely used in the KD research community and that have reasonably complex relational schemas. While it is not a simple matter to objectively assess the performance of the algorithm, we report both subjective and quantitative results on these data sets. We provide several detailed examples, including one discovered causal dependence and one case of iterative refinement of the database schema to identify more interesting and useful QEDs. HEP -Th  X  HEP -Th is a bibliographic database of papers from the ArXiv.org repository. Originally published as part of the 2003 KDD Cup competition, 4 the data set contains preprints from 1992 until 2003, with over 30,000 papers, 13,000 authors, and 500,000 links among them. Figure 1 shows the relationship between authors, their submissions and papers, journals, and citations. We have represented the submissions and specific author credits as separate entities in the data set.
 Figure 1: Entity -Relationship diagram with temporal fre -quencies and extents for the HEP -Th database. Authors make submissions to ArXiv t hat may or may not become papers for a journal and papers can refer to other papers giving authors credits. We assume that authors make submissions to ArXiv about once a month, that it takes a submission about 3 years to undergo journal review and that the status of the paper while in review can change monthly. The remaining frequen -cies are estimates used to reflect the dynamic nature of cita -tions. We assume that authors and papers are a part of the repository for at least 20 years and that journals last even longer.
 IMDb/Netflix  X  The Internet Movie Database 5 information on movies released worldwide, including release dates, directors, producers and actors, as well as the nominees and recipients of Academy Awards. We selected a subset of these aw ards covering films released in the years 1997 to 2007. We included information on the nominees and winners of Best Picture, Best Director, Best Actor, and Best Actress. We augmented the IMDb data with the Netflix Prize data set, contains the title and year of release for 17,770 movies released on DVD and ratings of those movies from more than 400,000 http://www.cs.cornell.edu/projects/kddcup/ ht tp://www.imdb.com/ http://www.netflixprize.com/ customers. The date range for ratings is from November 11, 1999 to December 31, 2005. The schema shown in figure 2 represents the combination of the tw o data sets.
 Figure 2: Entity -Relationship diagram with temporal frequencies and extents for the IMDb+Netflix database. Each movie has a series of actor and director stints as well as a review by a user of the Netflix Prize database. Awards are presented to actors, directors, and movies. We assume that movies, actors, and directors last as long as the database itself. Reviews can occur daily and award ceremonies occur once a year. Actors work on two films a year, directors make one movie per year, and onc e an actor or director works on a film, that information never changes.
 Wikipedia  X  Wikipedia 7 is a collaborative peer -production system with the ultimate goal of providing free encyclopedia content to everyone. The database consists of millions of article s maintained by thousands of users. Anyone that registers can become a user and edit any page. Consequently, vandalism is inevitable, and occasional misinformation is provided. Thus, actions on users and pages frequently occur (e.g., users can have privile ges revoked, pages can be restricted), and these events are stored in logging tables. The schema in Figure 3 presents the relationships among users editing articles, as well as the specific logging events that may take place. The main temporal assumption f or this data set is that logging and editing events are frequent enough to assume they occur daily.
 Figure 3: Entity -Relationship diagram with temporal frequencies and extents for the Wikipedia database. This simple view shows how users can edit pages, a nd logs can be created to record the activity in the database. The assumption that editing and logging events can occur daily is reflected in the temporal frequency labels. We assume that users and pages last for the duration of the Wikipedia database. http://www.wikipedia.com/ From a large number of possible designs, determined by the cardinality of entities, relations, and variables, AIQ identifies a relatively small number of plausible designs. To evaluate the degree to which the algorithm can focus the attention of investigators on plausible designs, we compared the total number of available designs to those selected by AIQ. Table 1 shows data on the total available QEDs, the total number actually identified, and the breakdown of those designs by base e ntity. The larger the number of possible QEDs, the greater the percentage reduction in the QEDs actually identified by AIQ as plausible.
 The next reasonable question is the degree to which AIQ X  X  identified designs are actually useful for identifying previously unknown causal dependencies. We selected and evaluated several of th e QEDs identified by the algorithm. The majority showed neither statistically significant associations nor sufficient statistical power to conclude independence between the variables. However, several were statistically significant.
 For example, one instan ce of a QED identified by AIQ on the IMDb/Netflix data involves the variables of award existence and an aggregate of user ratings on a base item of movies. This design implies, rather intuitively, that the granting of an Academy Award to a movie may cause changes in user ratings of that movie. This design was made possible because whether an award entity exists was designated as pseudo -random among all nominated movies (i.e., all nominated movies are equally likely to win an award). This is clearly an assum ption, but a plausible one.
 We test this design by computing the average rating a movie receives in the two months prior to and the two months after Academy Awards are granted. For each movie, we computed the difference in the average ratings. Then we comp ared the mean difference for movies that won an award with the mean difference for those who were nominated but did not win. This general configuration of a hypothesis test is directly implied by the matching QED (the non -equivalent control group design), though the details still require prior knowledge of the movie domain not encoded within the domain -specific knowledge base. For example, we restrict the ratings to a window of two months since movies are not generally released on DVD until shortly before the Academy Award ceremony. Additionally, since the major nominations for the Academy Awards consist of best picture, best director, best actor, and best actress, we only consider these four categories as potential influences on user ratings.
 We perform a two -sample t -test on the differences in average ratings for these two populations of movies. The average rating decreases by 0.066 for movies that win an award compared to a drop of 0.247 for those that do not. This difference is weakly significant (p=0.07 ; N 1 =14, N 2 =47) indicating a causal relationship between winning an award and user ratings. The relative differences in the two populations could be due to a variety of underlying mechanisms, including anchoring (the Academy Award confers a high initial ra ting that raters are loath to change). Note that both populations see an overall decrease in average ratings, which could be due to regression toward the mean (early raters of movies tend to give higher ratings), unreasonably high expectations (award -winni ng movies are expected to very good), or seasonal effects. The potential utility of AIQ goes beyond a simple one -shot analysis of an input schema. The algorithm can be used in an iterative manner to refine a schema to beco me more useful for causal discovery.
 For example, the initial HEP -Th schema consisted of entities for journals, authors, papers, citations, credits, and submissions and the relations between them (see figure 1). For this schema, AIQ generated a set of 60 p ossible QEDs. Many of the designs suggested that variables on submission caused variables on citation. While this might be plausible, another potential cause seemed more likely.
 We added an entity to the schema called publication status . These entities rep resent events in the life of a paper, including being in review, accepted, rejected, or published, and each status entity occurs at a specific point in time. The addition of the publication status entity increased the number of possible QEDs to 97. We agai n reviewed the set of designs, and several of them now indicated that changes in paper status could causally influence the existence of citations, an entirely plausible and interesting design. To evaluate this design, we selected a list of papers from HEP -Th that were published at least one year after they were first submitted. For each of these papers, we counted the number of citations the paper received during the first year it waited for publication and for the two years after publication. Then we selec ted the set of papers that were submitted but were not published. For each of these, we counted their number of citations during the three years after they were first submitted.
 We computed the difference in the means of the citation rate for the two time periods for each group of papers. For published papers, the difference in the means indicated that, in the period after publication, the paper's citation rate improved by 40%. For the unpublished papers, the difference also indicated an improvement in thei r citation rate, but only by 14%. We applied a two -sample t -test to analyze the difference between the two sub -populations. The test indicated a highly significant difference between the citation rates of the published and unpublished papers (p=2.2e -16; N 1 =17394, N 2 =4559).
 However, is this strong evidence for a causal dependence between publication and citation rate? Unfortunately not. Upon reflection, the augmented schema leaves out any measure of paper quality, a potential common cause of both publicatio n and citation. Good papers are both more likely to be accepted for publication and more likely to be cited by other authors. On the one hand, this is precisely the type of situation that AIQ was designed to avoid; on the other hand, AIQ was unable to excl ude such a QED because it lacked the information that would have allowed it to identify this possibility. The schema should be changed. While we have no data measuring this variable, we can include it in the schema and eliminate this QED from consideration .
 This example only contains two iterations of schema redesign, but it illustrates how, through many such iterations, an investigator could refine the schema to both expand and trim the list of QEDs. The most obvious body of prior work concerns the manual application of experimental and quasi -experimental designs [4] [5] [7] [19] . This covers a long tradition of philosophical writing stre tching back to the origins of modern science, as well as work on experimental design since the 1920s and formal quasi -experimental design beginning with the work of Campbell and Stanley [4] and continuing to the present day [19] . We build on this work to produce algorithms to identify QEDs automatically. Work in cognitive psychology and artificial intelligence has investigated a related area  X  the processes by which scientific experiments are designed and analyzed. Heuristic search has been used in systems that are capable of rediscovering laws and inventing new ones in fields of science such as physics and chemistry [3] [15] . For example, the KEKAD A program has been used to model the process by which Hans Krebs developed and executed the experiments necessary to discover the urea cycle [14] .
 Similar advances have been exploited to automatically plan and conduct actual exp eriments. For example, researchers have recently automated the nearly the entire process needed to discover gene functions in yeast [13] . This  X  X obot scientist X  automatically generates hypotheses from the available data, designs and runs experiments, and analyzes the results. The algorithm's experiment selection has been shown to have equivalent or better performance than humans and vastly improves upon random selection of experiments.
 To our knowledge, however, no prior work exi sts on automatic identification of QEDs for the analysis of non -experimental data. With the increasing use of large -scale systems for data collection, the number and size of observational data sets is growing at unprecedented rates. These data sets provide a rich resource that should be automatically exploited to infer causal knowledge. AIQ offers a first step in that direction.
 A second large body of relevant research concerns causal discovery through joint modeling [9] [10] [16] [20] . As mentioned in the introduction, this work differs substantially from the topic of this paper. It uses the entire data set to jointly model the probabilistic dependen cies among all variables, rather than selecting subsets of data to control or randomize the effects of large classes of variables and thus allow individual dependencies to be tested with high statistical power. In addition, nearly all work on joint modeli ng for causal discovery assumes the data consist of independent and identically distributed (i.i.d.) instances. In contrast, our work (along with much of the work on manual identification of QEDs) assumes that data instances are joined by relations that re present temporal, genetic, organizational, or institutional linkages. These relations imply dependencies between variables on related entities, and they are essential background knowledge to identifying QEDs, whether manually or automatically. Little work on causal discovery exploits these relations (though a notable exception is Karimi &amp; Hamilton [12] , who use temporal information to identify causal sequences). That said, both work in QEDs and joint modeling use similar underly ing notions of causality, control, randomization, and statistical inference. In addition, some of the more complex quasi -experimental designs (e.g., the regression point displacement and regression discontinuity designs) rely on some degree of statistical modeling to achieve their effect. There is substantial scope to combine these methods in complementary ways, and perhaps even to unify them into a common framework for causal discovery. The results and examples in this paper de monstrate the potential for automatic identification of quasi -experimental designs. For the first time, an automated program can identify QEDs within large and complex databases. AIQ 1.0 is only the first step toward a more complete and useful tool. While our implemented designs are not perfect, AIQ makes it possible to quickly see the implications of different assumptions, and to evaluate and improve those assumptions. The system provides a  X  X hat if X  capability for investigators, and facilitates rapid impr ovement and exploration.
 Still, a wide variety of improvements remain. Future versions of AIQ should search for a much wider array of QED types and allow specification of unobserved entities and variables. More extensive changes would involve automated hyp othesis testing of the potential causal dependencies and integrating QEDs with joint modeling algorithms that are currently used for causal discovery. Finally, a much more extensive evaluation is necessary, examining questions such as the breadth of applic ation of QEDs, the proportion of all causal dependencies that are discoverable by QEDs, and the extent to which the use of QEDs facilitates joint modeling (and vice versa). This material is based on research sponsored by the Air Force Resea rch Laboratory and the Intelligence Advanced Research Projects Activity (IARPA), under agreement number FA8750 -07 -2 -0158. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notatio n thereon. The views and conclusion contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Air Force Research Laboratory and the Intelli gence Advanced Research Projects Activity (IARPA), or the U.S. Government. [1] Armour, S. and Haynie, D. 2007. Adolescent sexual debut [2] Barker, R. 1990. CASE*Method: Entity Rel ationship [3] Bradshaw, G., Langley, P., and Simon, H. 1983. Studying [4] Campbell, D. and Stanley, J. 1963. Experimental and Quasi -[5] Cook, T. and Campbell, T. 1979. Quasi -Experimentation: [6] Chen, P. 1976. The entity -relationship model -Toward a [7] Cochran, W. and Cox, G. 1954. Experimental Designs . [8] Harden, K., Mendle, J., Hill, J., Turkheimer, E., and Emery, [9] Holla nd, P. 1986. Statistics and causal inference. Journal of [10] Holland, P. and Rubin, D. 1988. Causal inference in [11] Jensen, D. 2008. Beyond prediction: D irections for [12] Karimi, K. and Hamilton, H. 2003. Distinguishing causal and [13] King, R., Whelan, K., Jones, F., Reiser, P., Bryant, C., [14] Kulkarni, D. and Simon, H. 1988. The processes of scientific [15] Langley, P. 1981. Data -driven discovery of physical laws . [16] Pearl, J . 2000. Causality: Models, Reasoning, and Inference . [17] Richardson, M. and Domingos, P. 2003. Building large [18] Rubin, D. 1974. Estim ating causal effects of treatments in [19] Shadish, W., Cook, T., and Campbell, D. 2002. Experimental [20] Spirtes, P., Glymour, C., and Scheines, R. 2000. Causation, [21] UNC Carolina Population Center. 2008. Add Health Home [22] Wei ss, R. 2007. Study debunks theory on teen sex, 
