 1. Introduction
One of the most active subjects in control engineering is optimal control of nonlinear systems. Such control problems arise in many applications, e.g., in economics, chemical engineering, robotics and aeronautics. To solve optimal control for a nonlinear system using classic optimal control theory, the nonlinear Hamilton X  X acobi X  X ellman (HJB) partial differential equations must be solved ( Bryson and Ho, 1975 ). However, in practice, the nonlinear HJB equations are very difficult to be solved. As a result, it is necessary to employ numerical methods to solve nonlinear optimal control (NOC) problems.

Several works in the literature were proposed to solve NOC problems, numerically. Gradient descents are the most elegant and precise numerical methods to solve NOC problems. Never-theless, they have the possibility of getting trapped at local optimum depending on the initial guess of solution. In order to achieve a good final result, these methods require very good initial guesses for control variable trajectory. Besides, as the complexity of the system increases, the specification of a suitable initial guess can become troublesome ( Bayo  X  n et al., 2009 ). Alternatively, Iterative Dynamic Programming (IDP) ( Luss, 2000) is a powerful method for solving optimization problems, but usually the CPU time used to solve the problem is quite long and it may also converge to the local optimum ( Lopez Cruz et al., 2003; Bayo  X  n et al., 2009 ).

Since solving optimal control of nonlinear complex dynamics lead to presenting multiple local optimums, global optimal control approaches can be used to find the global optimum or a sufficiently close approximation. Heuristic optimization algorithms such as genetic algorithms (GA) ( Holland, 1975; Goldberg, 1989 ); differ-ential evolution (DE) ( Price and Storn, 1997 ) and particle swarm optimization (PSO) ( Kennedy and Eberhart, 1995 ) are found to have a better ability to converge to a global solution than the traditional methods in complex optimization problems ( Onwubolu and Babu, 2004 ). Among their advantages are: (1) the objective function X  X  solution and (3) they usually do not get stuck into a local optimum.
Based on these advantages, they have been successfully applied in many NOC problems ( Sewald and Kumar, 1995; Yamashita and
Shima, 1997; Lopez Cruz et al., 2003; Sarkar and Modak, 2004; Babu and Angira, 2006; Varadarajan and Swarup, 2008; Arumugam and Rao, 2008; Herrera and Zhang, 2009 ).

Recently, PSO algorithm has been found to be a promising technique for real world optimization problems ( Clerc and Kennedy, 2002 ). Compared to GA, PSO takes less time for each function evaluation as it does not use many of GA operators like mutation, crossover and selection operator. Although PSO has shown some advances by providing high speed of convergence in specific problems, however, it does exhibit some shortages. First, it may convergence to a local optimum when facing with complex optimization problems. Second , the convergence rate decreased considerably in the later period of evolution; when reaching a near optimal solution, the algorithm stops optimizing, and thus the achieved accuracy of algorithm is limited ( Kennedy et al., 2001 ). overcome these two shortages. First, an improved PSO (IPSO) algorithm is proposed to enhance global search ability and also convergence speed of PSO. Second, to achieve faster convergence speed around global optimum and also higher convergence accuracy, the proposed IPSO is combined with successive quadratic programming (SQP) algorithm. Although the ability of SQP is weak to escape local optimum, it can achieve faster convergence speed around global optimum and the accuracy can be higher. The fundamental idea in the proposed method is that at the beginning stage of searching for the optimum, IPSO algorithm is employed to find a near optimum solution and accelerate the training speed.
When the change in fitness value is smaller than a predefined value, or the particles in swarm being close to the global optimum, the best solution found by IPSO algorithm will be taken as the initial starting point for the SQP and the searching process is switched to SQP searching to accelerate the search process and find an accurate solution. In this way, this hybrid algorithm may find an optimum solution more quickly and accurately.

SQP method for an optimization problem was done by Victoire and Jeyakumar (2004) . They used it for solving economic dispatch with valve-point effect. However, our proposed method has two distinctions with the previous one. First, an improved PSO is proposed to enhance global search ability of PSO algorithm and also increase the convergence speed and accuracy of PSO. Second this is the first research that used a hybrid PSO X  X QP method for solving a dynamic optimization problem, i.e., nonlinear optimal control problems. In order to show the feasibility of the proposed method, two benchmark NOC problems are considered. The proposed algorithm is evaluated on these two NOC systems and its results are compared with those obtained by two well-known evolutionary algorithms, namely GA and DE algorithms, and also with three improved PSO algorithms. The results show that the proposed algorithm has better performance than others in terms of robustness and accuracy.
 describes a general form of optimal control problems. In Section 3, both GA and the DE algorithms are described. Section 4 introduces
PSO algorithm. In Section 5, a brief description of the SQP algorithm for the solution of optimal control problems is given.
Section 6 introduced the hybrid IPSO X  X QP algorithm. Section 7 contains simulation results obtained by the proposed method when applying it to three benchmark optimal control problems.
Finally, conclusion is presented in Section 8. 2. Optimization problem formulation differential equation: _ x  X  f  X  x  X  t  X  , u  X  t  X  , t  X  X  1  X  u ( t ) A R m is the control vector bounded by u min o u i  X  t  X  o u max , i  X  1 , 2 , ... , m  X  2  X  like c i  X  X  X  r 0 , i  X  1 , 2 , ... , l  X  3  X 
The performance index associated with this system is a scalar function, which can be formulated as follows: J  X  u  X  t  X  X  X  f  X  x  X  t f  X  , t f  X  X  where J is a scalar performance index (PI), f (.)is final state cost chosen to achieve an appropriate design goal. The objective is to determine the optimal control policy u ( t ) in the time interval t
A [ t 0 , t f ] such that PI is minimized or maximized.
To solve this type of problems numerically, there are two general approaches: indirect and direct methods ( Stryk and
Bulirsch, 1992 ). Indirect method is based on the solution of a calculus of variations problem through the use of the Pontryagin X  X  minimum principle (PMP) ( Bryson, 1999 ). In a direct approach, the optimal control problem is approximated by a finite dimen-sional optimization problem, which can be cast in a nonlinear programming (NLP) form and solved accordingly ( Agrawal and Fabien, 1999 ). This is achieved through control parameterization.
In our case the control u ( t ) is assumed to be a piecewise constant such as ( Lopez Cruz et al., 2003 ) u  X  t k  X  X  u k , t A  X  t k , t k  X  1 , k  X  0 , 1 , ... , N 1 , t
As a result N m parameters determine the control over [0, t
The NLP problem is to find the stacked control vector defined by ~ u  X  X  u T 0 , u T 1 , ... , u T N 1  X  X  ~ u 1 , ... , ~ u N m scalars. 3. Two classes of evolutionary algorithms: GA and DE
In this section, the two well-known evolutionary algorithms, namely GA and DE, which have been used earlier for solving NOC problems, are introduced briefly. 3.1. Genetic algorithm (GA)
Genetic algorithm (GA) ( Holland, 1975; Goldberg, 1989 )isa population based optimization technique that searches the best solution of a given problem based on the concepts of natural selection, genetics and evolution. The search is made starting from an initial population of individuals, often randomly generated. An individual is considered to be a possible candidate solution for the optimization problem in hand. At each evolu-tionary step, individuals are evaluated using a fitness function.
The evolution (i.e., the generation of a new population) is made by means of three kinds of operator: breeding, mutation and selection. Selection involves killing a given proportion of the population based on probabilistic  X  X  X urvival of the fittest X  X . Killed individuals are replaced by children, which are created by breeding the remaining individuals in the population. For each child produced, breeding first requires probabilistic selection of two parent individuals, getting a more chance to choose fitter individuals. Mutation allows new areas of the response surface to be explored by random alterations of optimization variables. GA iteratively improved the set of tentative solutions by applying the aforementioned stages to find a good solution.

In the traditional GA, all the variables of interest must be encoded as binary digits (genes) forming a string (chromosome).
After a manipulation of binary-coded GA, the final binary digits are then decoded as original real numbers. On the other hand, in a real-coded GA, all genes in a chromosome are real numbers. To deal with practical engineering problems, the real-coded GA is more suitable than the binary-code GA ( Chambers, 1995; Chang, 2007 ).
 3.2. Differential evolution (DE)
As other evolutionary algorithms, the differential evolution (DE) proposed by Price and Storn (1997) is a population based optimization algorithm. DE starts with the random initialization of a population of individuals in the search space. Then, evolution mechanism is applied to parameter vectors. To the next iteration, only those parameter vectors of the procedure survive that produce the best performance for an objective function. The evolution mechanism contains a mutation procedure, which consists of adding a weighted difference between two vectors while creating new one and comparing a newly created vector to the one from an existing population. In order to increase the diversity of the muted vectors, one introduces the crossover. Crossover procedure generates trial vector by randomly mixing the muted vector with the last target vector. If the trial vector produces a better performance for an objective function than that compared to, the new vector replaces it in the population. This procedure is called selection. DE iteratively improved the set of tentative solutions by applying the aforementioned stages until satisfactory results are obtained or certain criteria of termination are met. We recommend the readers to refer to Price and Storn (1997) and Lopez Cruz et al. (2003 ) for further details. 4. Particle swarm optimization (PSO) 4.1. Standard PSO
Particle swarm optimization (PSO) is a heuristic population based optimization algorithm simulating the movement and flocking of birds ( Kennedy and Eberhart, 1995 ). In the beginning of search process, a population of candidate solutions, called particles, is created randomly in the solution space. Each particle is associated with a velocity. Then, the velocity of every particle is iteratively adjusted according to the corresponding particle X  X  experience and the particle X  X  companions X  experiences. It is expected that the particles will move towards better solution areas. The fitness of every particle can be evaluated according to the objective function of optimization problem. At each iteration, the velocity of every particle will be calculated as follows: v i  X  o v t i  X  c 1 r 1  X  pbest t i x t i  X  X  c 2 r 2  X  gbest best previous position of this particle (i.e., personal best), gbest the best previous position among all the particles in t th iteration (i.e., global best), o is the inertia weight, c 1 and c 2 coefficients and are known as the cognitive and social parameters, respectively. Finally, r 1 and r 2 are two random numbers in the range [0, 1]. After calculating the velocity, the new position of every particle can be worked out: x
The PSO algorithm performs repeated applications of the update equations provided until a stopping criterion is met. 4.2. Inertia weight adaptation and the proposed PSO algorithm
The success of PSO during search is highly dependent on a good balance between exploration and exploitation. Exploration allows searching the entire search space by ensuring the redirection of the search towards new regions, while exploitation favors a quick convergence towards the optimum. To do a good balance between exploration and exploitation, one can use an appropriate adaptation mechanism for inertia weight factor. A big inertia weight facilitates exploration, but it makes the particle take long time to converge. Conversely, a small inertia weight facilitates exploration and makes the particle to converge fast, but it sometimes leads to local optimal.

Several researchers proposed PSO algorithms with an adaptive inertia weight ( Shi and Eberhart, 1998; Chatterjee and Siarry, 2006; Modares et al., 2010a, 2010b ). First of all, a PSO with linearly decreasing inertia weight (PSO X  X DW) is proposed by Shi and Eberhart (1998) . In PSO X  X DW, the inertia weight linearly decreases as follows: o t  X  where iter max is the maximal number of iterations and t is the current number of iterations. So as iterations go, o decreases
After that several nonlinear inertia weight adaptation mechan-isms were proposed to enhance the performance of PSO algorithm. Among them, Chatterjee and Siarry (2006) proposed the well-known PSO with nonlinearly decreasing inertia weight (PSO X  X DW). The inertia weight starts with a high value o max and nonlinearly decreases to o min at the maximal number of iterations. This means that the representations are the same as those in the PSO X  X DW method except that the inertia weight factor changes according to o t  X 
As for a  X  1, the system becomes a special case of the method in Shi and Eberhart (1998 ).

Since the search process of PSO is nonlinear and highly complicated, linearly and nonlinearly decreasing inertia weight with no feedback taken from the global optimum fitness cannot truly reflect the actual search process. In the beginning of the search process, the particles are far away from the optimum point and hence a big inertia weight is needed to globally search the solution space. Conversely, when the best solution found by the population improves greatly after some iteration, i.e., the particles find a near optimum solution, only small movements are needed and inertia weight must be set to small values. Based on this, in one of our previous works, we proposed an improved PSO algorithm ( Modares et al., 2010a ) in which the inertia weight was set as a function of global optimum fitness during search process of PSO algorithm as follows: o t  X  1 =  X  1  X  exp  X  a F  X  gbest t  X  X  X  X  10  X  where F ( gbest t )is the fitness of global best in t th iteration. The parameter a needs to be predefined. It can be set to the inverse of the value of global optimum fitness in the first iteration ( a  X  1/
F ( gbest 1 )). In this case, o changes according to the rate of global best fitness improvement.

However, introducing the same iner tia weight for all particles, by ignoring the differences among particle performances, simulated a roughly animal background, not a more precise biological model. In fact, during the search every particle dynamically changes its position, so every particle is located in a complex environment and faces a different situation. Therefore, every particle may have different tradeoffs between global and local search abilities.
Motivated by the aforementioned, to incorporate the differ-ence between particles in PSO, similar to our recent work ( Modares et al., 2010b ), in this paper we developed an improved
PSO (IPSO) in which the value of inertia weight for every particle in t th iteration is dynamically calculated by o t  X  1 =  X  1  X  exp  X  a F  X  pbest t i  X  X  X  X  11  X  except replacing the global best fitness by the fitness of personal best fitness. Under the assumption above, it can be concluded that 0.5 r o i o 1.
 while the fitness of a particle is far away from the real global optimal, the value of inertia weight will be large resulting in strong global search abilities and locating the promising search areas. Meanwhile, when the fitness of a particle is achieved near the real global optimal, the inertia weight will be set small, depending on the nearness of its best fitness to the optimal value, to facilitate a finer local explorations and hence accelerate convergence. 4.3. Performance analysis of the proposed PSO algorithm constraint benchmark optimization problems ( Mathur et al., 2000 ) are considered and listed in Table 1 . Originally PSO algorithms are designed to solve unconstrained static optimiza-tion problems. To our knowledge, the penalty function method has been the most popular constraint-handling technique due to its simple principle and ease of implementation ( Homaifar et al., 1994; Joines and Houck, 1994; Coello, 2000 ). The violations of constraints of the solutions are incorporated into the objective function so that the original constrained problems are trans-formed into unconstrained ones. Thus, in this method, the fitness function is defined as the sum of the objective function and a penalty term that depends on the constraint violation. To compare the accuracy of IPSO with other aforementioned
PSO algorithms, a maximum iteration of 100 is considered as a stopping condition. In addition, in all PSO X  X DW, PSO X  X DW and IPSO algorithms, we set c 1  X  c 2  X  2 as suggested by Shi and
Eberhart (1998 ). In PSO X  X DW and PSO X  X DW, o decreases from 0.9 to 0.4. Moreover, in NDW X  X SO n is set to 1.2 ( Chatterjee and Siarry, 2006 ).

Tables 2 and 3 list the results obtained by each algorithm, where each algorithm is implemented 20 times independently, for a population size of 20 and 40, respectively. As shown in Tables 2 and 3, it is clear that the worst result obtained by IPSO is similar to or even better than the best result obtained by others. Also,
Figs. 1 and 2 show how PSO algorithms convergence to the global optimum for functions 1 and 2, respectively. It is clearly obvious that the proposed IPSO has a great advantage of convergence speed compared to PSO X  X DW and PSO X  X DW algorithms. 5. SQP algorithm
SQP is a nonlinear programming method that starts from a single searching point and finds a solution using the gradient information. Although this optimizing method is less time consuming than the population based search algorithms, it is highly dependent on the initial estimate of solution ( Costa et al., 2005; Bayo  X  n et al., 2009 ).

The method resembles closely to Newton X  X  method for con-strained optimization just as is done for unconstrained optimiza-tion. SQP is based on iterative formulation and on the solution of quadratic programming sub-problems. The sub-problem is obtained by linearizing the constraints and approximating the Lagrangian function quadratically: L  X  x , l  X  X  J  X  x  X  X  At each iteration, an approximation of the Hessian of the Lagrangian function H k is made.

The process starts from given iteration x k , then, the following quadratic programming (QP) sub-problem is formed to solve: min 1 2 d T H k d  X  r f  X  x k  X  T d  X  13  X  r c i  X  x k  X  T d  X  c i  X  x k  X  X  0 , i  X  1 , ... , m e  X  14  X  r c i  X  x k  X  T d  X  c i  X  x k  X  Z 0 , i  X  m e , ... , md A
This sub-problem is a quadratic programming (QP) sub-problem whose solution is used to form a search direction for a line search procedure. In other words, the solution is used to form the next iterate: x
The step length parameter a k is determined by an appropriate line search procedure so that a sufficient decrease in a merit function is obtained. The method is vastly used in optimization problems, but it is also known that it depends on the initial estimate ( Costa et al., 2005 ).

A number of authors have successfully applied SQP method to the solution of optimal control problems. In particular, Goh and
Teo (1988) and Teo et al. (1991) approximate the control variable as piecewise constant and solve the NLP problem using the SQP technique. 6. Hybrid IPSO X  X QP algorithm for optimal control
The proposed IPSO X  X QP is an optimization algorithm combin-ing an improved PSO (IPSO) algorithm with SQP algorithm, in order to solve NOC problems. The PSO algorithm is a global algorithm, which has a strong ability to find global optimistic result. However, it has a disadvantage that the search around global optimum is very slow. The SQP algorithm, on the contrary, has a strong ability to find local optimistic result for NOC problem, but its ability to find the global optimistic result is weak. Although it has advantages in terms of computational robustness and their usefulness for practical problems, it is usually difficult to choose appropriate initial solutions.
 as IPSO X  X QP hybrid algorithm is formulated in this paper. Similar to the PSO algorithm, the IPSO X  X QP algorithm X  X  searching process is also started from initializing a group of random particles. First,
IPSO algorithm is run to search the global best position in the solution space. Then SQP algorithm is used to search around the global optimum. In this way, this hybrid algorithm may find an optimum more quickly and accurately. The procedure for this IPSO X  X QP algorithm can be summarized as follows: 7. Simulation results solving NOC problems, two benchmark problems are considered: (1) the continuous stirred-tank chemical reactor and (2) a mathematical system with nonlinear inequality constraint. Then, the performance of the proposed IPSO X  X QP algorithm is compared with some heuristic algorithms used earlier for solving NOC problems, such as real-coded GA ( Sarkar and Modak, 2004 ), DE ( Lopez Cruz et al., 2003 ) and PSO ( Herrera and Zhang, 2009 ).
Three improved PSO algorithms are used, instead of standard PSO algorithm with a fixed inertia weight employed by Herrera and
Zhang (2009) : PSO X  X DW, PSO X  X DW and the proposed IPSO algorithm. The motivation is to show that the proposed IPSO algorithm is superior to the earlier well-known PSO algorithms for integrating with SQP algorithm. For all simulations, both c are set to 2 ( Shi and Eberhart, 1998 ) for all PSO algorithms; in both PSO X  X VIW and PSO X  X TVIW algorithms o max and o min are set to 0.9 and 0.4, respectively, and the modulation index, n is set to 1.2 in PSO X  X TVIW ( Chatterjee and Siarry, 2006 ). For GA, the crossover and mutation rates are considered as 0.8 and 0.1, respectively ( Grefenstette, 1986 ). For DE, all of its parameters are the same as in Lopez Cruz et al. (2003) . All the methods are coded in Matlab 7.7 on PC with Pentium V, 7500 MHz/1024 MB RAM. 7.1. Continuous stirred-tank chemical reactor (CSTCR) several researchers ( Luus and Cormack, 1972; Ali et al., 1997; their methods. The state equations for a CSTCR are _ x  X  X  2  X  u  X  X  x 1  X  0 : 25  X  X  X  x 2  X  0 : 5  X  exp _ x  X  0 : 5 x 2  X  x 2  X  0 : 5  X  exp from the steady-state temperature, x 2 ( t ) is the deviation from the steady-state concentration and u ( t ) is the normalized control variable that represents the effect of the flow-rate of the cooling fluid on chemical reactor. The objective is to determine the unconstrained u * ( t ) to minimize the quadratic performance measure: J  X 
The performance measure indicates that the desired objective is to maintain the temperature and concentration close to their steady-state values without expending large amount of control effort.

This optimal control problem provides a good test problem for optimization procedures and is a member of the list of benchmark problems proposed in the handbook of test problems in local and global optimization ( Floudas et al., 1999 ).

Ali et al. (1997) used eight stochastic global optimization algorithms to solve this problem and their results vary from
J  X  0.135 to 0.245. Lopez Cruz et al. (2003) used four evolutionary algorithms (EA) and compared their results with the first order gradient method and the IDP. For the first-order gradient algorithm, they showed that its convergence to the local or global optimum highly depends on the initial values for the control. In fact, if the initial conditions are selected appropriately, then it converges to global optimum, precisely. Also they show that the
CPU time used by IDP is quite long and it may still converge to the local optimum. Finally, they showed that the minimum obtained with four EA algorithms varies from J  X  0.1358 to 0.1449.
To solve this problem by means of the proposed method, the time interval [ t 0 , t f ] is discretized in N  X  13 time intervals, as done by Lopez Cruz et al. (2003 ). The search process of GA, DE,
PSO X  X DW, PSO X  X DW and IPSO algorithms is terminated when the change in fitness value is smaller than 0.0001 for 10 iterations.
Also, the search process of PSO algorithm is switched to SQP method, when the change in fitness value is smaller than 0.0001 for 10 iterations
Tables 4 and 5 list the results obtained by each algorithm, where each algorithm is implemented 20 times independently for a population size of 20 and 40, respectively. The results indicate in how many iterations and the necessary time the convergence of the solution or success is met. The average of elapsed time in 20 runs is considered as a criterion for computational time.
From these tables, the following results can be concluded. First of all, it is clearly obvious that IPSO algorithm has better solution accuracy and less computational time than GA, DE, PSO X  X DW and PSO X  X DW algorithms. So, the proposed IPSO algorithm is more appropriate than other algorithms for combining with SQP algorithm. Second, it is clear that the computational time for the proposed hybrid IPSO X  X QP algorithm is considerably less than GA, DE, PSO-LDW and PSO X  X DW algorithms. However, since in the hybrid IPSO X  X QP algorithm, when the region of global optimum is reached by IPSO, the region is fine tuned by running some SQP iterations; the number of iterations for IPSO X  X QP algorithm is more than IPSO algorithm. But, since the simulation time of SQP algorithm is small, the computational time of IPSO X  X QP is very close to the computational time of IPSO algorithm. Third, it is apparent that IPSO X  X QP is more accurate and more robust than other algorithms, since the worst and the best results obtained by the proposed IPSO X  X QP algorithm are very close to each other. In fact, when SQP is integrated with the IPSO, it produces quality solutions as compared to the one produced by other algorithms.
Finally, comparing the results of the proposed method with other heuristic methods reported by Ali et al. (1997) and Lopez Cruz et al. (2003) , it is clear that the proposed method is more robust and more accurate than other earlier reported methods. Fig. 3 shows the optimum control trajectory obtained by IPSO X  X QP. 7.2. Mathematical system with nonlinear inequality constraint
This system involves a nonlinear inequality constraint and has been studied by several researchers ( Mehra and Davis, 1972; Goh and Teo, 1988; Vlassenbroeck, 1988; Teo et al., 1991; Elnagar et al., 1995; Mekarapiruk and Luus, 1997 ). The state equations for the system are _ x  X  x 2  X  20  X  _ x  X  x 2  X  u  X  21  X  _ x  X  x 2 1  X  x 2 2  X  0 : 005 u 2  X  22  X  with initial condition X (0)  X  [0 10] T .

The nonlinear inequality constraint to be satisfied is h  X  X  X  X  x 2  X  0 : 5 8  X  t 0 : 5  X  2 r 0  X  23  X 
The control is bounded by 20 r u r 20  X  24  X  The performance index to be minimized is
J  X  x  X  t f  X  X  25  X  where t f  X  1. To solve this problem by means of the proposed method, the time interval [ t 0 , t f ] is discretized in N  X  20 time intervals as done by Mekarapiruk and Luus (1997 ).

Goh and Teo (1988) solved this problem using the control parameterization technique, and the result obtained was
J  X  0.1816. Mekarapiruk and Luus (1997) proposed a penalty function and solved this inequality state constraint. They obtained a result of J  X  0.1769.

Again, to show the superiority of the proposed algorithm, the performance of the IPSO X  X QP algorithm is compared with GA, DE, PSO X  X DW, PSO X  X DW and IPSO algorithms. Tables 6 and 7 list the results obtained by each algorithm, where each algorithm is implemented 20 times independently for a population size of 40 and 60, respectively.
 computational time and also better solution accuracy as com-pared with GA, DE, PSO X  X DW and PSO X  X DW algorithms and hence it is more proper for integrating with SQP algorithm. Also, the computational time of the proposed hybrid IPSO X  X QP algorithm is less than GA, DE, PSO X  X DW and PSO X  X DW algorithms and is a bit more than IPSO algorithm. Once again, it is obvious that the hybrid IPSO X  X QP algorithm is more robust and accurate than GA, DE, PSO X  X DW, PSO X  X DW and IPSO algorithms.
Finally, comparing the results of the proposed method with Goh and Teo (1988) and Mekarapiruk and Luus (1997) , it is concluded that the proposed method has better accuracy than others. Fig. 4 shows the optimum control trajectory obtained by IPSO X  X QP. The trajectory of the function of state h ( X ) is shown in
Fig. 5 . As can be seen, the constraint is satisfied throughout the time interval. 8. Conclusion
To solve NOC problems, we proposed a method based on combination of an improved PSO (IPSO) algorithm and successive quadratic programming (SQP) algorithm, namely IPSO X  X QP. We showed that the hybrid method has the advantage of both IPSO and SQP methods while does not inherent their drawbacks. As the
IPSO algorithm successfully searches all space during the initial stages of a global search, we used IPSO algorithm at earlier stage of IPSO X  X QP. As long as the change in the fitness of global optimum is less than a predefined value, the algorithm switches to SQP to find an accurate solution. The results of the proposed hybrid method were compared with some heuristic optimization algorithms such as GA, DE, PSO X  X DW, PSO X  X DW and IPSO, on two NOC problems. The results showed that the proposed hybrid method is more robust and accurate than other heuristic algorithms.
 References
