 Most of recommender systems try to find items that are most rel-evant to the older choices of a given user. Here we focus on the  X  X urprise me X  query: A user may be bored with his/her usual genre of items (e.g., books, movies, hobbies), and may want a recommen-dation that is related, but off the beaten path, possibly leading to a new genre of books/movies/hobbies.

How would we define, as well as automate, this seemingly self-contradicting request? We introduce TANGENT, a novel recom-mendation algorithm to solve this problem. The main idea behind TANGENT is to envision the problem as node selection on a graph, giving high scores to nodes that are well connected to the older choices, and at the same time well connected to unrelated choices. The method is carefully designed to be (a) parameter-free (b) ef-fective and (c) fast. We illustrate the benefits of TANGENT with experiments on both synthetic and real data sets. We show that TANGENT makes reasonable, yet surprising, horizon-broadening recommendations. Moreover, it is fast and scalable, since it can easily use existing fast algorithms on graph node proximity. H.2.8 [ Database Management ]: Database applications X  Data min-ing ; H.3.3 [ Information Storage and Retrieval ]: Information search and retrieval X  Clustering, search process Algorithms, Experimentation
Recommender systems are vital for e-commerce sites, with most striking examples being Amazon, Netflix, Pandora, Strands, etc. Recommender systems are doubly useful: On one hand, they help users filter through enormous numbers of available items, and fo-cus on the few ones that match their preferences; on the other hand, recommender systems help enterprises increase their sales (e.g. movies, books, songs), on the long tail. Numerous algo-rithms for collaborative filtering [28] have been studied for recom-Copyright 2009 ACM 978-1-60558-495-9/09/06 ... $ 5.00. mender systems; whereas, graph-based algorithms have been at-tracting great interest among researchers recently.

Most of the recommendation algorithms focus on the precision in the proximity to user preferen ces. However, this strategy tends to suggest items only on the center of user preferences and thus narrows down the users X  horizons. According to the research about the quality of recommender systems [20], broadening users X  hori-zons is one of important qualities for recommender systems. Such systems provide a win-win situation: users may find more interest-ing items, and e-commerce enterprises increase their sales and their user satisfaction.
 Figure 1: The difference between conventional recommenda-tion algorithms and TANGENT. Square nodes represent users and circular nodes denote movies. Users are connected to movies which they like. Black nodes are a target user and his/her favorite movies.

In order to solve this seemingly self-contradicting problem, we proposed TANGENT, a recommendation algorithm that takes into account the connectivity to other groups in order to broaden users X  horizons. It is based on the graph mining technique of comput-ing similarity between nodes and can be applied to any dataset that can be represented as a graph. Figure 1 illustrates the difference of results between conventional recommendation algorithms and TANGENT. We assume that this synthetic bipartite graph records rating information by users to movies. There are two groups in this graph; fans for comedy movies and those for horror movies. If  X  X ser A X  rates two movies in the comedy group as favorite movies, conventional recommendation algorithms would suggest movies in the same group. In contrast, our proposed TANGENT method sug-gests a movie between two groups, to  X  X urprise X  the user and to gently broaden his/her horizons.

The rest of the paper is organized as follows: we first review the related work in Section 2; the proposed algorithm is presented in Section 3; the experimental results are presented in Section 4; and we conclude the paper in Section 5.
In this section, we briefly review related work, which can be categorized into three parts: graph mining, recommender system and ranking and proximity on graphs.

Graph Mining. The main idea behind TANGENT is to envision the problem as node selection on a graph. Graph mining itself is a hot research topic in the recent y ears. For static graphs, repre-sentative work includes pattern and law mining [1, 6, 22], frequent substructure discovery [34, 14], collective classification [4], fraud and anomaly detection [21, 24], community mining and graph par-tition [11, 12, 16, 19], etc. More recently, there has been an increas-ing interest in mining time-evolving graphs, such as densification laws and shrinking diameters [18], community evolution and dy-namic [2], etc.

Recommender System. To our knowledge, there is little work in recommender systems which focuses on broadening users X  in-terest. The work of Kamahara et al. [15], who explore methods for locating unexpected items from similar clusters to user X  X  cluster, is close to our problem. However, parameters such as the number of clusters and thresholds, which are required in [15], are not easy to be tuned. McNee et al. [20] raise a question about the current accuracy metrics and propose some aspects which should give to evaluation of recommender system.

Recommender systems have been attracting considerable research interest, with recent emphasis on graph-based such systems. Fouss et al. propose in [9] to apply Euclidean commute time distance, which is one of random-walk-based methods of computing simi-larities between nodes, to a co llaborative recommendation. Wang et al. [33] apply a node similarity algorithm to item-based recom-mendation. Bell et al. [3] propose a low rank matrix approximation method for collaborative filtering and successfully apply it to the NetFlix competition. Although diff erent in the specific methods, the basic idea behind all these methods is to find items that are most relevant to the older choices of the given user.

Ranking and Proximity on Graphs. In the literature, there are several methods for calculating relevance (a.k.a similarity) be-tween nodes on graphs. Because the shortest path, which is a con-ventional property for representing relevance, fails to capture the multiple faceted relationship b etween nodes on the graph, random walk based techniques such as PageRank [25], personalized Pager-Rank [13], Random walk with restart [30, 32], Euclidean commute time distance [9], escape probability [8, 17] have been widely ap-plied recently. In this paper, we use random walk with restart; how-ever, the idea behind TANGENT can be naturally extended to other proximity measurement.

The upcoming  X  X ridging score X  in our proposed TANGENT is also related to the node betweenness: The betweenness of a node is high if the node lies on the paths between many other pairs of nodes. Intuitively, such a node is a good  X  X ridge X , and deleting such a node may often disconnect the graph. Freeman [10] pro-poses a method for computing betweenness based on shortest paths, and Brandes [5] studies a fast algorithm for computing centrality. On the other hand, Newman [23] also proposes fast algorithms to compute, by using a random walk on the graph.

The degree of connectivity in a graph (which is the core idea be-hind the bridging score in the proposed TANGENT) is also related to the degree of anomaly in a graph because the nodes with consid-erable links to various groups are considered to be anomalies. Sun et al. [30] introduce the normality score of a node as a measure of how homogeneous (i.e., interconnected) its neighbors are.
Although potentially useful for TANGENT, none of these meth-ods have been used in a recommender system.
In this section, we describe details of the proposed TANGENT algorithm.
Table 1 gives the main symbols used in this paper. We assume that we are given a weighted, undirected graph G =( V, E ) ,where V denotes the set of nodes and E represents the set of edges. the number of nodes and m is the number of edges. This graph has weights w ij &gt; 0(( i, j )  X  E ) on the edges. Since the graph is undi-rected, the weights are symmetric (i.e. w ij = w ji ). The weight should indicate the strength of the relation between node j .Let A =( a ij ) i,j  X  V be the adjacency matrix of the graph with a ij = w ij if ( i, j )  X  E and a ij =0 otherwise. A set of query nodes can be represented by Q =( q i ) 1  X  i  X  k .

Let us consider a movie-rating data set. Basically this database consists of three kinds of information; demographic information about the users, information about the movies, and information about rating which users assigned to movies they have watched. Each user and movie corresponds to a node, and each user is con-nected to the corresponding movies by edges weighted according to the degree of rating. This graph expresses the relation between users and movies (a user-movie graph), and is constructed as a bi-partite graph. In this graph, nodes can be divided int o two disjoint sets such as V = { V 1 ,V 2 } . A query node corresponds to a user to whom the recommender system want to give recommendations (i.e. k =1 ).
 Now we define the TANGENT problem as follows: P ROBLEM 1 (TANGENT).
 Given: an edge-weighted undirected graph G with adjacency ma-trix A , the set of query nodes Q =( q i ) 1  X  i  X  k . Find: a node that (1) is close enough to Q , and (2) has high poten-tial to reach other nodes.
Here we quickly review algorithms for computing ranking and proximity on graphs and introduce alternatives we have explored to solve our problem but find to be inapplicable because of subtle problems.

Relevance Score. As described in Section 2, there are numer-ous methods to measure similarity r i,j between a pair of nodes ( j ): escape probability, random walk w ith restarts, electricity-based [26], maximum flow, to name a few. Although most of them give reasonable scores, none of them takes into account the connectiv-ity to other groups. Therefore, they can fulfill only the first of our requirements.

It is an additional, subtle question on how to measure group prox-imities, that is, how close is node i to the set of query nodes Averaging, or just adding the individual scores sonable, but not necessarily the best choice. Another choice would be to take the maximum such score, roughly corresponding to an  X  X R X : a node gets high score if it is close to at least one of the query nodes. The list continues: the product is also a reasonable choice (corresponding to an  X  X ND X ), and the CePS algorithm [31] gives additional, more sophisticated choices.

Negation of Relevance Score. One of our first approaches to solve the  X  X urprise me X  query problem was to consider negation. Specifically:  X  X ind nodes close to one query node, but far away from all other query nodes. X  That is, we want a candidate node that has high proximity to only one of the query nodes, and as far as possible from the rest. We assume that a relevance score corre-sponds to probab ility, such as steady-state probability [32]. Since multiplication of s cores corresponds to conjunction, 1-complement would correspond to negation, and thus the score of a node be
However, although this equation has solid foundation in logic, when used on large, real graphs, it gives almost the same arith-metic scores as max 1  X  j  X  k ( r q j ,v ) . This is because most proxim-ity/relevance scores are extremely low ( 10  X  2 ) and thus the prod-uct of the (1  X  r q i ,v ) terms is practically equal to 1.
Entropy. Among the methods we tried but eventually did not work, is an entropy-based idea, inspired by maximum marginal gains: a candidate node v would be good, if it would make max-imum difference in the existing distribution of proximities. This would mean that it opens horizons. That is, let r Q,i be the score of node i wrt Q ;let ` r Q,i be the score if we add node v to the query set Q . We want the node v that maximize the difference of the en-tropy (i.e., H (` r Q,i )  X  H ( r Q,i )=  X  P
However , despite the fact that maximum marginal gain should lead to  X  X urprising X  choices, they are too far away from query nodes because they are the best choices to make uniform distribution of proximities, which maximize the entropy.

Our main point of this detour is that, despite the wealth of ideas on node proximity, there are subtle issues that need to be carefully thought out.
In this subsection, we illustrate the framework of our proposed algorithm.
 The function of TANGENT can be described as t Q = tangent ( ) where t Q =( t Q,i ) i  X  V is a vector of degree of recommendation, to which we refer as TANGENT score in this paper. We would like to have a recommendation algorithm for suggesting items which are not only relevant to user preferences but also have large con-nectivity to other groups. In order to fulfill these requirements, TANGENT algorithm consists of three parts as follows. 1. Calculate relevance score (RS) of each node : r Q . 2. Calculate bridging score (BRS) of each node : b . 3. Compute the TANGENT score ( t Q )bysomehowmerging
Moreover, the algorithm for computing bridging score is de-signed to use relevance score, which re-uses the result of relevance scores calculated at the first part and also prevents the last merging part from being complicated.

The rest of this section describes details of each part.
First we would like to compute the relevance score of a single node j, for a single query node q i . There are several methods for computing the relevance score between nodes, as described in Sec-tion 2. Although we can use any algorithm to compute relevance score, we propose to use random walk with restart [30, 32] in this paper.

According to [30, 32], the relevance score r q i is computed by the following formula: where  X  A is the normalized adjacency matrix of A by normalized graph Laplacian (  X  A = D  X  1 / 2 AD  X  1 / 2 ,where D is the degree matrix of A .) and (1  X  c ) denotes the fly-out probability. 1 Note that A is symmetric because a ij = w ij = w ji = a ji . r determined by from the derivation of equation (2).

One of solutions to obtain r q i from equation (2) is the iterative method, iterating equation (2) until it convergences; however, we propose to pre-compute R because we can obtain the solution of r i for all nodes from equation (3) with less online computation costs. Details are described in subsection 3.7. Note that it can be proved by equation (3) that
If there are multiple query nodes, we compute a relevance score from all query nodes by taking Boolean  X  X R X  of relevance scores to query nodes by
Bridging score means the degree of connectivity to other groups on a graph. Although betweenness [5, 10, 23] might be one of the criteria for it, their algorithms are completely different and also require a considerable computation costs. Or, we might use the sum of weight of links connected to the corresponding node as an index considering that the popular items might have potential to bridge groups. However, popularity does not always correspond to the connectivity to other groups.

We proposed to apply an anomaly detection algorithm on a bi-partite graph [30], which is based on the relevance scores described above, to any kinds of graph. The level of connectivity of a node on a graph is related to the level of anomaly on a graph because the nodes with considerable links to various, otherwise disjoint groups are considered to be anomalies. Moreover, the merit of using the same algorithm is that we can share the result of computing rele-vance scores. From equation (4), R expresses the relevance scores from each node to each node and we can re-use R for computing the bridging score. This is impor tant, because TANGENT only needs a is the only parameter in the proposed TANGENT. However, we find that the recommendation result of TANGENT is insensitive to c . Therefore, we fix c to be 0 . 5 throughout this paper. few relevance scores, and thus it can exploit any of the fast, known algorithms, to compute such scores, like B LIN/BB LIN [32] and variants.
 Figure 2: Illustration of the procedure of computing bridging score.

Figure 2 presents the procedure of computing bridging score. Let l be the number of edges connected to node i . Given a node first find the set of nodes to which i links: S i = { s i,j l } . Then we compute the relevance scores between any pair of elements in S i and construct a l i  X  l i similarity matrix that, we take the mean of all non-diagonal elements in R i b by inverting it. If node i is connected by only one edge or it has no connection, we define its bridging score as b i =0 , which means that it is not taken into account as a candidate of recommendation.
Figure 3 shows the intuition of computing bridging score. If is connected to one group, then the relevance scores between any pair of elements in S i should be high and as a consequence, become small. On the other hand, if i has links to several groups, the relevance scores between different groups have small numbers and we get large b i .

Algorithm 1 summarizes the algorithm of computing bridging score. Note that b is independent from query nodes Q . Therefore, it can be pre-computed.
There are several ways to combine the above two criteria. How-ever, again, reasonable-looking choices may suffer from subtle is-sues. We discuss them first, and then give our proposed combina-tion method.

Reasonable-Looking, but Unsuccessful Choices. One natural method to try is linear combination: i.e. t Q,j = r Q,j +  X   X  b j the coefficient). However, (a) the two values typically differ by or-ders of magnitude, and the larger, b j , typically overshadows (b) the method is not parameter-free anymore: somebody, some-how, needs to determine a good value of  X  , which may need to be changed as the graph grows.

Our second approach, also reasonable-looking, but also unsuc-cessful, is to use skyline queries . Since we do not know how much Algorithm 1 Bridging Score (BRS) Computation Algorithm 1: Given: Adjacency matrix A 2: for i =1 to n do 6: else 9: Take the average of all non-diagonal elements in R i and obtain 11: end if 12: end for 13: return a vector of bridging scores b . weight to give to each of the two criteria (relevance vs. bridge-ness), we could try multi-objective optimization, which leads to skyline queries [27]: Given a set of multidimensional points skyline query finds the skyline points from D , that is, those points that are not totally dominated by any other point in D .Forexam-ple, if a point p is on the skyline, there is no data point such that p is larger than p for the values in all dimensions. The example of a skyline query is shown in Figure 4. Movie A, B and C are on the skyline and there are no other nodes which have larger relevance score as well as larger bridging score than points on the skyline.

However , using skyline queries for our setting suffers from the following subtle drawbacks: (1) it cannot keep the balance between the two criteria; for instance, a skyline query extracts a node which has the highest relevance score even if it has zero bridging score (see Movie C in Figure 4) and vice versa, (2) the skyline also ne-glects second-best candidates. (In Figure 4, movie Z dominates everything else, and thus we would only return that movie, even if Movie Y is also a good candidate.)
Proposed Combination Method. A reasonable and well perform-ing method is multiplication: i.e. t Q,j = r Q,j  X  b j = r can be seen from the equation above that t Q,j represents the ratio between relevance score to query nodes and relevance score among neighbors. Notice that all our propos ed choices are parameter-free, making TANGENT parameter-free, as we required. We want TANGENT to be parameter-free 2 , effective and fast. The first goal is achieved as we showed. The second goal is dis-cussed in details later. Here we illustrate the achievement speed. Specifically, we discuss the scalability of the TANGENT algorithm by discussing each of the first two parts. The third part, merg-ing, is O ( n ) since it needs just a multiplication for each of the n  X  q = O ( n ) candidate nodes.

Computing Relevance Score. Although computing R in a straight-forward way requires cubic computation cost to the number of node,
As mentioned before, the only parameter c in TANGENT has little influence on the result and is fixed to be 0 . 5 throughout this paper. there is a fast algorithm to get good approximate solution of ran-dom walk with restart proposed by [32]. Once we pre-compute R , online computation cost for computing relevance score for each node is only matrix-vector multipli cation shown in equation (3). Computing Bridging Score. It can be seen in Algorithm 1 that, R , which is pre-computed for computing relevance score, can be re-used in computing bridging score. Therefore, the online com-putation of this algorithm takes time O ( n ) . Moreover, in case of a user-movie bipartite graph, we do not need to compute bridging scores of user nodes for recommendation; therefore, the computa-tion cost can be reduced to the number of movies. If faster online computation is required, we can pre-compute it since the bridging score is independent of the query.
In this section, we evaluate the effectiveness of TANGENT. Since the objective of TANGENT is to find the neighbors of user pref-erence with large connectivity to other groups, not to improve the accuracy of recommendation, conventional evaluation metrics such as degree of agreement[9], a percentile score[9], a recall score[9], mean absolute error[29], MSE[33], and NMSE[33] do not work on the evaluation of effectiveness for TANGENT algorithm, neither does questionnaires asking whether the recommendation made by the algorithm is satisfactory or not. Therefore, we evaluate its po-tential on a number of synthetic graphs as well as on real data sets. For both synthetic and real data set, we present (1) the case stud-ies which show that TANGENT gives reasonable results; and (2) systematic comparisons with conventional recommendation algo-rithms (i.e., by relevance score) which show that TANGENT tends to return more surprising results. Let n tan and n rel be the surpris-ing nodes in the returned recommendation list by TANGENT and by conventional recommendation algorithms, respectively. We de-fine the  X  X urprising Gain X  as n tan  X  n rel n rel . A big  X  X urprising Gain X  means that TANGENT returns more surprising results compared with conventional recommendation algorithms.
Case Studies on Unipartite Graphs. We start off by presenting unipartite graphs, which have several groups in them and are con-nected by nodes. In the experiment, we compare the ranked lists based on relevance score, bridging score, and TANGENT score.
The graph on the left side of Figure 5 has two groups; nodes 1 -4 in Group 1 and nodes 6 -9 in Group 2, which are connected through node 5, and we run a query for node 1. Node 2 gets the highest rele-vance score among nodes except the query node, followed by nodes 3 and 4. This result would be same as what conventional recom-mendation algorithm would give. On the other hand, comparing bridging scores, we find that node 5 gets the highest score, because the neighbors of node 5 (nodes 3, 4, 6 and 7) are separated in half into two groups and, as a consequence, the average of relevance scores among them becomes small. Notice that nodes 7, 3 and 4 also get relatively high bridging scores. As a result, nodes 3 and 4 are ranked as No. 1 in terms of TANGENT score, as reflects our in-tuition that these nodes are close enough to the query node as well as getting close to Group 2.

The graph on the right side of Figure 5 has four groups and two query nodes in different groups. In this case, both node 3 and node 12 are considered as bridging nodes; however node 3 should be considered as a better bridging node than node 12 because node 3 leads to Group 2, which is larger than Group 3. As we can see, TANGENT algorithm gives a result which follows our intuition.
Case Studies on Bipartite Graphs. We next evaluate the ef-fectiveness of TANGENT algorithm on synthetic bipartite graphs. Figure 6 illustrates the structure of graphs and the results. As we Figure 5: Relevance score, bridging score, and TANGENT score of each node on synthetic unipartite graphs. A query node is represented by a black node. described in Figure 1, square nodes represent users, circular nodes denote movies, and edges correspond to ratings by users. Graph 1 and Graph 2 in Figure 6 have almost same structure, except that user 1 and movie 24 are linked with each other in Graph 2. Figure 6: No.1-ranked movie for several query nodes on syn-thetic bipartite graph. Dark nodes are query nodes.

We can derive some fascinating observations from this figure as follows: (1) In Graph 1, movie 16 gets the highest TANGENT score for user 1. This result completely agrees with our motiva-tion described in Figure 1. (2) In Graph 1, TANGENT algorithm concludes movie 20 to be the best recommendation for user 5, not movie 16. It is a reasonable result because movie 20 is watched by three groups; while movie 16 is watched by two groups. (3) In Graph 2, TANGENT algorithm still suggest movie 16 for user 1, not movie 20. Recommender system does not have to be sen-sitive to outliers. In this case, user 1 X  X  preference still lies on the group where s/he involves and TANGENT takes it into account. This result indicates that TANGENT is robust to exceptionally fa-vorite movie. (4) In Graph 2, movie 24 gets the highest TANGENT score for user 12, despite the fact that movie 20 is recommended in Graph 1. Comparing movie 20 and movie 24, we find that movie 24 has higher relevance score than movie 20, and also movie 24 has connectivity to another group in Graph 2. This structural change causes the difference of the recommendation results.

Comparison with Relevance Score. Finally, we systematically compare the proposed TANGENT with conventional recommen-dation algorithms. The goal of TANGENT is to provide some  X  X urprising X  recommendations, i.e., to find the neighbors of user preference with large connectivity to other groups. Formally, for a given query node q , we say the recommended node i is  X  X urpris-Figure 7: Comparison of TANGENT and conventional recom-mendation algorithms on synthetic graphs. Higher is better. ing X  if (1) nodes i and q belong to the same group, but the node has some links to other groups; or (2) nodes i and q belong to the different groups, but the node i has some links to the same group as the query node q . For example, in the left graph of Figure 5, nodes 3-5 are  X  X urprising X  wrt the query node 1; while the nodes 2, 6-9 are not  X  X urprising X  results. Figure 7 present the comparison between TANGENT and conventional recommendation algorithms (Rel), where x-axis is the length of the recommendation list and y-axis is the average surprising nodes in the returned recommenda-tion list. It can be seen that TANGENT consistently gives more sur-prising results. On average, the  X  X urprising Gain X  of TANGENT on synthetic data sets is 1.95.
Here, we present the experimental result on a real movie-rating data set MovieLens ( http://www.movielens.org/ ). Movie-Lens data set was collected by GroupLens Research Project at the University of Minnesota and contains 100,000 rating information from 943 users on 1682 movies. Each user has rated at least 20 movies from 1 (strongly unsatisfactory) to 5 (strongly satisfactory). Using this data set, we construct a user-movie bipartite graph. We choose positive ratings (4 and 5) and connect users and movies by edges weighted by 4 rating  X  4 in order to emphasize strongly sat-isfactory ratings. The reason why we do not take into account neg-ative ratings (1 -3) is that treating negative ratings requires another mechanism and we would like to focus on the evaluation of effec-tiveness of TANGENT algorithm. As a result, a user who gives only negative ratings and movies which receive only negative rat-ings are neglected; and 942 users, 1447 movies and 55375 ratings remain. We apply BB Lin [32] to our system for fast computation of relevance scores and pre-compute only R .

Case Studies. Figure 8 illustrates the transition of rankings be-tween the relevance score and our TANGENT score. For each movie, we mention its genre(s) -the abbreviations are in the up-per right of the figure. The top of Figure 8 are for users who prefer to slapstick movies. Notice that the top 10 movies by relevance score consist mainly of comedy movies. On the other hand, niche comedy movies such as  X  X ce Ventura: When Nature Calls X  and  X  X enaissance Man X  are out of top 10 ranking by TANGENT score and popular comedy movies such as  X  X he Princess Bride X ,  X  X oy Story X ,  X  X onty Python and the Holy Grail X  and  X  X en in Black X  emerge instead. That is, the TANGENT algorithm recommends a wider variety of genres and gives No.1 rank to  X  X tar Wars X , which scores high with both user preference as well as with the connec-tivity to other groups. Note that, especially  X  X he Flintstones X  de-creases its ranking dramatically, because it has only one positive rating.

The lists on the bottom of Figure 8 are for users whose prefer-ence is horror movies. Although th e transition between two lists is more moderate than that in case of slapstick movies, TANGENT al-gorithm still recommends diverse genres of movies; not only horror but also thriller, crime, and drama. Figure 9: Comparison of TANGENT and conventional recom-mendation algorithms on MovieLens data set. Higher is better.
Comparison with Relevance Score. Here, for a query movie q the query user who likes movie q ). We say a recommended movie i is a  X  X urprising movie X  if (1) movies i and q share some com-mon genres; and (2) movie i has some new genres that the query movie q does not have. For example, for the query movie  X  X obin Hood: Men in Tights (Comedy) X ,  X  X ack (Comedy and Drama) X  is treated as a surprising recommendation; while neither  X  X py Hard (Comedy) X  or  X  X aiders of the Lost Ark (Action and Adventure) X  is treated as surprising recommendations. Figure 9 presents the com-parison between TANGENT and conventional recommendation al-gorithms (Rel), where x-axis is the length of the recommendation list and y-axis is the average surprising nodes in the returned rec-ommendation list. Again, TANGENT consistently gives more sur-prising results and the  X  X urprising Gain X  of TANGENT on this data set is 0.08.
This data set is from CIKM proceedings (http://www.informatik. uni-trier.de/ ley/db /conf/cikm/). We construct an author-paper bi-partite graph. The authors are annotated with one or more key-words as his/her attribute based on the session names where the corresponding paper was presented. For instance,  X  X ali Brodian-skiy X  has published a paper (titled with  X  X elf-Correcting Queries for XML X ) in CIKM 2007 and the paper was presented in  X  X ML Query Processing X  sessi on. Therefore, he is associated with  X  X ML X  and  X  X uery X  as his attribute. Totally, we have 952 paper nodes, 1,895 author nodes, and 158 keywords.

Case Studies. Table 2 lists the top-5 recommended authors for  X  X rank Hing-Wah Luk X  by TANGENT score and by relevance score, respectively.  X  X rank Hing-Wah Luk X  has published one paper (ti-tled with  X  X riple-Node Hierarchies for Object-Oriented Dababases Indexing X ) and he is associated with  X  X ndex X  as his attribute. So, clearly, he is a databases person in CIKM community. From Ta-ble 2, it can be seen that while the two methods agree on the first two recommended authors ( X  X da Wai-Chee Fu X  and  X  X e Wang X ), TANGENT provides more diverse recommendations compared with relevance score, -the recommended authors by TANGENT ( X  X abo Xu X ,  X  X iawei Han X , and  X  X ian Pei X ) are cross-disciplinarity in both dababases and data mining. On the other hand, relevance score will recommend pure databases persons ( X  X eixiong Rao X ,  X  X ei Chen X , and  X  X ingyi Bu X ) instead.

Comparison with Relevance Score. For a given query author we say the recommended author i is  X  X urprising X  if (1) authors and i share some common keywords, and (2) the author i has some new keywords that the query author q does not have. Figure 10 presents the comparison between TANGENT and conventional rec-dexing X  and he is associated with  X  X ndex X  as his attribute. ommendation algorithms (Rel), where x-axis is the length of the recommendation list and y-axis is the average surprising nodes in the returned recommendation list. Again, TANGENT consistently gives more surprising results and the  X  X urprising Gain X  of TAN-GENT on this data set is 0.22. Figure 10: Comparison of TANGENT and conventional recom-mendation algorithms on CIKM data set. Higher is better.
Case Studies. We also test the proposed TANGENT on DBLP data set (http://www.informatik.uni-trier.de/ ley/db/). Here, we con-struct a series of different author-paper bipartite graphs from two conferences. One conference is always  X  X DD X , and the other con-ference is either  X  X IGMOD X ,  X  X CML X ,  X  X WW X ,  X  X IGIR X ,  X  X IKM X ,  X  X IGCOMM X ,  X  X IGGRAPH X  or  X  X SMB X . Table 3 gives the 1 st rec-ommended authors on such bipartite graphs by TANGENT score and by relevance score, respectively. We can see that TANGENT provides more surprising recommendations compared with rele-vance score. For example, on the bipartite graph from  X  X DD X  and  X  X CML X , conventional recommendation algorithms will recom-mend  X  X oiss Goldszmidt X  for  X  X ise Getoor X , which makes sense since both of them are interested in probabilistic reasoning and graphical models. On the other hand, TANGENT will recommend  X  X haru C. Aggarwal X  instead.  X  X haru C. Aggarwal X  is mainly in-terested in performance, data mining and databases. So, compared with  X  X oiss Goldszmidt X ,  X  X haru C. Aggarwal X  is a more surpris-ing recommendation for  X  X ise Getoor X . Yet, the recommendation by TANGENT is still close enough to the query author. For in-stance,  X  X haru C. Aggarwal X  is also interested in uncertainty in databases which is closely related to probabilistic reasoning, -one of the research interest of  X  X ise Getoor X .

Comparison with Relevance Score. Here, we use the authors who publish in only one of the two conferences as the query authors. And if the recommended author publishes in both conferences, we say that it is a surprising recommendation. Figure 11 presents the comparison between TANGENT and traditional recommendation algorithms (Rel), where we always fix the length of the ranked list to be 5 and the number below the corresponding bars is the  X  X ur-prising Gain X . Again, TANGENT consistently gives more surpris-ing results. For example, on the bipartite graph constructed from  X  X DD X  and  X  X IGMOD X , the  X  X urprising Gain X  of TANGENT is 0.78; while on the bipartite graph constructed from  X  X DD X  and  X  X IGGRAPH X , TANGENT achieves 0.70  X  X urprising Gain X  etc. Figure 11: Comparison of TANGENT and conventional recom-mendation algorithms on DBLP data set. Author-Paper bipar-tite graph is constructed from  X  X DD X  plus one more confer-ence. The number below the corresponding bars is the  X  X ur-prising Gain X . Higher is better.
We define a novel recommendation problem, namely, how to make a recommendation that broadens the horizons of the user, in the sense that it is close enough to his/her current interests to be pleasant, but also towards a new area that the user has not dis-covered yet. The motivation is how to respond to a user that says  X  X urprise me X : suppose that a user that consistently chooses, say, slapstick  X  X omedy X  movies, may occasionally get bored with that genre, and s/he would like to try something slightly different -what should we recommend? As humans, we would probably recom-mend, say,  X  X orror comedy X ,  X  X artoons X , or a  X  X omedy-musical X . Our goal is to automate the response to such  X  X urprise me X  query. Our approach is to find items that are close to the user preferences, while they also have high connectivity to other groups.
One major contribution of this work is exactly the problem defi-nition. Additional contributions are the following: 1. Careful design decisions, so that the resulting method is (a) 2. Extensive comparison of the numerous alternatives; while all 3. Experiments on synthetic and real data sets, illustrating the
Future work could focus on the implementation of TANGENT on the emerging Hadoop/MapReduce architecture [7], for Tera-and Peta-byte scale recommender systems.
This material is based upon work supported by the National Sci-ence Foundation under Grants No. DBI-0640543 IIS-0705359 CNS-0721736 IIS0808661. Also, by the iCAST project sponsored by the National Science Council, Taiwan, under the Grants No. NSC97-2745-P-001-001 and by the Ministry of Economic Affairs, Tai-wan, under the Grants No. 97-EC-17-A-02-R7-0823. Also, un-der the auspices of the U.S. Department of Energy by University of California Lawrence Livermore National Laboratory under con-tract DE-AC52-07NA27344 (LLNL-CONF-404625), subcontracts B579447, B580840. This work is also partially supported by an IBM Faculty Award, a Yahoo Research Alliance Gift, a SPRINT gift, and a gift from Sony, with additional funding from Intel, NTT and Hewlett-Packard. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the au-thor(s) and do not necessarily reflect the views of the National Sci-ence Foundation, or other funding parties.
