 Some burgeoning applications have appear ed which needs the high availability and extra high performance of data insertion operations. The records of web behavior, such as the records of personal search behavior in search engines, online stock trans-can improve the users X  search experiences based on Personalized Search [3]. This information should be written into a large database in a real-time mode and queried repeatedly when the user uses the search en gine again. All of these archived streams applications have the following common characteristics: 
We call these applications as log-intensive web applications. [11] is the first one which optimizes querying on the live and archived streams, but doesn X  X  study the insertion performance and system X  X  availability. [14] studies the availability of an updatable data warehouse filled with less-update data. It bases on the general-purpose 2PC which is not efficient enough for the high-rate archived streams. 
The first contribution of this paper is to optimize the insertion operations by writ-ing no online-log and archived-log in databases and committing data in bulk. The second is providing a simple consistency protocol based on the no-update feature of the data. The third is designing an efficient recovery method for high-rate insertions. The remains of this paper are: Section 2 is the problem statement and related work. Section 3 is transaction processing and consistency protocol. Section 4 introduces the recovery approach; Section 5 is the experiments; Section 6 is the conclusion. Let X  X  consider the classical log-intensive applications: when the users are accessing generated at all times. These record items must be real-time stored and queried by subsequent web accesses. A high available and efficient system, such as a database servers, each having its own processors and disks, and running a  X  X lack-box X  DBMS [1]. The  X  X ead One Write All Available X  policy [2] is always adopted. It means when a read request is received, it is dispatched to any one node in the available nodes. 
In [8], bulk loading is adopted to optimize the insertion performance; however it doesn X  X  focus on availability. The primary/secondary replica protocol [9] in commer-cial databases [10, 12] ships updates logs from the primary to the secondary. This way decreases the insertion performance for the IO access in log-intensive applications. The 2PC [2] keeps all replicas up-to-date, but has poor performance for its force-writes logs and poor recovery performance based on complex ARIES [7, 14]. 
In order to avoid force-writes, ClustRa [13] uses a neighbor logging technique, in which a node logs records to main memory both locally and on a remote neighbor; HARBOR[14] avoids logs by revising the 2PC protocol, but the revised 2PC is too complex to the insertion-intensive and no-update applications. [15, 16] is not based on 2PC and propose a simple protocol, but it needs to maintain an undo/redo log. problem of high availability and high performance for these log-intensive applica-set a consistency fence for every table in the data processing phase. All recovery approaches are based on the transaction processing. This section will introduce the details about insertion and query processing. 3.1 System Framework: Transaction Types and Unique External Timestamp As is discussed in Section 1, in the log-intensive workloads, all the transactions can be transactions. The insertion means inserting high-rate data into databases. The query means querying the massive non-update history data. 
The following are adopted to reach our objects: 1) Buffer and insert the data into a database in bulk. The experiments show bulk insertions always outperform standard single insertions by an order of magnitude. 2) Write no online logs in databases for insertions. 3) Insert multiple objects in parallel. Eliminating the dependency of the insertions on different objects could be r eached by simply canceling the foreign key constraints. 4) Recovery methods based on no-log must be developed. 
According to 1), a coordinator is added upon a database cluster to buffer and insert data in bulk in Fig. 1. For every table, an insertion thread is always running since the coordinator processes the same data more easily than any underlying database. Thus only one thread for one table is enough. For a query request, a query thread dynami-cally starts and ends with that request. The insertion threads refresh the meta-info TF and ANS (introduced in Section 3.2) and the query threads read this on time. 
Another mechanism, the unique external timestamp, is designed to implement the can construct a unique id for every record by adding a field log_number which can differentiate the different records with the same log_time . Thus every record has a virtual unique identifier log_id through binding log_time and log_number . The allied timestamp is also used in [14]. However it is generated in the database core when the insertion is committed which will destroy the autonomy of the underlying databases. 3.2 Insertion and Query Processing replicas(  X  in Fig. 2), it refreshes the Time Fence (TF) and Available Node Set (ANS) (  X  in Fig. 2). Only if the insertion thread meets a database replica failure, it will write B-out into local log files (  X  in Fig. 2). Before the failed replica is recovered, a group of insertion log files will be maintained. Every table has a TF . It is used to synchronize the query threads and insertion threads. 
From the above analysis, it X  X  obvious that no logs are generated on the coordinator node and database nodes as [14]. Since the volume of the log is at least larger than the more efficient than [15] which stores logs both on middleware and database nodes. to synchronize the result sets of every database replicas, an extra condition of log_id is added according to the TF of every table. The revising rule is as Table 1. Thus all query threads have a uniform logical view about the data in the replicas even though the same data may be not inserted synchronously by an insertion thread. Step two is terms of some load balance policy like current requests number. Original Rewritten SELECT tuples FROM table_a WHERE original_predicates; 3.3 Replication Protocol The replication protocol is to keep copies (replicas) consistent despite updates [5]. The 2PC or its variation [14] can be used to synchronize the data, but it is too expen-sive for its communication overhead. Recently some efficient eager replication proto-cols[6] can partly solve the problem of throughput and scalability but not the latency. All these general-purpose protocols seem too complex for the simple transaction semantics of log-intensive workloads and inefficient for SQL log and complex locks. 
In the log-intensive workload, the atomicity and consistency of an insertion trans-table_a  X  X  TF . After that it can refresh the table_a  X  X  TF and the ANS . Before a query thread revises a query SQL, it must wait until it attains a share (read) lock of table_a  X  X  TF . Thus the committed data will not be seen until all replicas have committed it. This simply guarantees insertion transactions X  at omicity because no query will see the data before the TF is changed.
 Fig. 2). We design a recovery algorithm on a granularity of tables. This algorithm is constituted of a recovery manager thread rm_thread and many recovery threads recovery_thread(node_id, table_id). The rm_thread always runs on the background and monitor which failure database needs to be recovered. If it finds some one, it will create one recovery_thread for every table on that database. After a recovery_thread recovers a table, it will inform the rm_thread. The recovery procedure of every recovery_thread can be divided into three phases in Section 4.1. 4.1 Recovery from Instance Failure (1) Phase 1: Recover From the Latest Save Point part of data of the insertion request is stored in the database while other in the mem-ory is lost. In order to save the stored data and avoid duplicating it, we should get the The LSP can be got in this standard SQL clause: 
Just as mentioned in Section 3.2, we can leverage the oldest insertion log file of the logs group. The pseudo code is just like: database. Then the other insertion log files can be directly loaded into the database. one database and the recovery of multiple failure databases can be done in parallel. (2) Phase 2: Catch Up with Data Logs This phase is a subsequent step of phase 1 and simpler. The pseudo code is: 
In this phase, we can optimize the recovery by merging several small files into big files. This can improve the recovery pe rformance due to decreasing the access times network, disk, cpu of two sides. The effect of merging will be shown in Section 5. (3)Phase 3: Catch Up with Current Insertion After loading all the log files of table_id , the recovery_thread will inform the rm_thread and the insertion_thread( table_id ). The insertion_thread will push the cur-rent insertion to the database of node_id . After the insertion_thread has completed this insertion, it will refresh the TF of table_id and added the recovered database into the the table of table_id of the recovered database. insertion_thread( table_id ) will no longer write log files. 4.2 Recovery from Media Failure When a database meets a media failure, such as some data files can X  X  be read or writ-ten, the recovering procedure can be implemented like the following two steps: introduced in details. 2) Recover the instance like Section 4.1. In these experiments, a database cluster of three nodes and a coordinator node is built. All the four nodes have two CPUs of Xeon 2G, 4G RAM, two 70G SCSI disks and are installed on Redhat AS 3.0. The three database nodes are installed with Oracle 10.1.0.4. And all the codes are written in GNU C++. The experimental data comes from the access records of some commercial search engine. A record item X  X  size is about 329 bytes. 5.1 Runtime and Recovery Performance Fig. 3, 4 are about runtime performance. Fig. 5, 6 are about recovery performance. 
In Fig. 3, we can find two conclusions: 1) The optimized loading X  X  performance is 50-100 fold of the standard INSERT SQL X  X  and 2PC used in [14]. 2) As the results show, when a database node writes online and archived log, online log, no log, the time ratio in average is about 1.43:1.14:1. 3) The insertion time is proportional to the size of the data. In Fig. 4, the bulk size is 80MB and the time is the average process-ing time of multi-users. Three scenes are simulated: writing online log on databases and the coordinator (it happens when a database node fails), writing online log on databases and writing no log. The ratio is 1.28:1.11:1. 
In Fig. 5, we compare the classical ARIES recovery method and ours. The results show that when the recovered data size is less than 4.5MB, the ARIES is better, but after that point our method gets a better performance. When the recovered data size is small, the startup cost of our method is greater than ARIES and later the complexity of ARIES leads to its long recovery time. In Fig. 6, the time of three recovery phases is shown. The startup time in phase 1 and the catching up time in phase 3 is a constant time, while the insertion time in phase 2 is proportional to the data to be recovered. 5.2 Performance During Failure and Recovery The transaction processing performance during the databases X  failure and recovery is y-axis is the insertion performance whose criterion is MB/s, and the right y-axis is the query performance whose criterion is the completed transactions per second. 
Before the 10th second, the system runs in the normal state. At the 10th second, one of the three databases fails, the coordinator detects this and the DBA restarts the database at the 15th second. During this period, the insertion performance decreases a little about 13% because the log files need to be stored on the coordinator X  X  disk, and the query performance decreases about 31% because 1/3 of the three nodes can X  X  process the query requests. From 15th second to 25th second, the recovery phase 1 and 2 complete, and the performance is just as the 15th second because the recovery will not decrease the online performance. From 26th to 27th second, the phase 3 completes, and the performance return to the normal level. 
From Fig. 7, we can find that there is no sharp performance degradation because other transactions will not be interrupted when one database fails. In this paper we have studied the problem of how to store and recover high-rate archived streams in a database cluster. According to the log-intensive applications, we present an optimized data insertion method based on reducing the disk IO access cost and a simple and efficient consistency protocol. The experiments results show that our approach can reach efficient data loading and query and get shorter recovery time than the traditional database cluster recovery methods. 
