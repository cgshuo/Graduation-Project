 Understanding how topics in scientific literature evolve is an inter-esting and important problem. Previous work simply models each paper as a bag of words and also considers the impact of authors. However, the impact of one document on another as captured by ci-tations, one important inherent element in scientific literature, has not been considered. In this paper, we address the problem of un-derstanding topic evolution by leveraging citations, and develop citation-aware approaches. We propose an iterative topic evolu-tion learning framework by adapting the Latent Dirichlet Alloca-tion model to the citation network and develop a novel inheritance topic model. We evaluate the effectiveness and efficiency of our approaches and compare with the state of the art approaches on a large collection of more than 650,000 research papers in the last 16 years and the citation network enabled by CiteSeerX. The results clearly show that citations can help to understand topic evolution better.
 H.1.m [ Information Systems Models and Principles ]: Miscella-neous Algorithms, Experimentation, Human Factors topic evolution, citations, Inheritance Topic Model  X  X warfs standing on the shoulders of giants. X  In scientific re-search, many new topics and new principles evolve from existing ones. Our knowledge, as well as the development of our knowl-edge, have been largely recorded in detail by a huge amount of archived scientific literature in the last several hundred years. De-tailed research papers can be summarized by topics. Can we under-stand how topics evolve over time by mining the archived scientific literature?
Topic evolution in scientific literature shows how research on one topic influenced research on another and helps us understand the lineage of topics. Understanding such topic evolution is an im-portant problem with a few interesting applications. For example, in sociology of science, topic evolution analysis can help us un-derstand and objectively evaluate the contribution of a scientist or an article. Moreover, topic evolution analysis may lead to infor-mation retrieval tools that can recommend citations for scientific researchers.

Due to its importance and great application potential, topic evo-lution has recently attracted fast growing interest in the informa-tion retrieval community [23, 19, 20, 28, 27, 33, 22]. Existing approaches [33, 6, 7, 13] for topic evolution in scientific literature model a paper as a bag of words, and detect topics on documents in different time periods. Then, topic evolution is analyzed by com-paring the changes of topics over time as well as the number of doc-uments of different topics. Some recent work further tries to ana-lyze the roles of social network analysis (i.e., the co-authorship [29, 33, 21] or direction-sensitive messages sent between authors [18]), annotated data [4], named entities [25] and ontologies [22] in topic detection and evolution. Section 2 reviews those existing methods briefly.

A research paper contains more information than just a bag of words. Particularly, for topic evolution, citations, the important in-herent elements in scientific literature, naturally indicate linkages between topics. Surprisingly, citations have not been considered by most of the existing methods for topic evolution. Bolelli et al. [6, 7] propose a segmented author-topic model to identify topic evo-lution by simply using citations to identify and boost the weight for the top  X  X opic-bearing X  words in documents. To the best of our knowledge, no existing work directly infers citations in the Bayesian framework and fits topic evolution to the temporal de-velopment of citations. One of the key advantages of a Bayesian framework for modeling citations is that the uncertainty associated with the citation parameters (e.g., influential weights on citing pa-pers) can be quantified. We propose such a Bayesian model to iden-tify the evolution of topics.

Can citations be easily used in topic evolution? One challenge is that the impact of citations cannot be captured by casting them in a straightforward manner into a bag of words. Intuitively, when a paper A cites another paper B , more often than not, A wants to use some content of B to extend the content of A . Therefore, the topics in B should have some impact on the topics in A . Without considering such impact, we may miss some topics related to A .
How can we capture such impact in an effective way? We need to develop a comprehensive model to integrate both the main body of a document, modeled as a bag of words, and citations. Another challenge is that there exists a huge amount of literature. Under-standing topic evolution on a large number of research papers de-mands high efficiency and scalability in the underlying models and analysis methods.

In this paper, we tackle the problem of topic evolution analysis on scientific literature by leveraging citations. When detecting top-ics in a collection D ( t ) of new papers, in addition to those papers in D ( t ) , we also consider the papers not in D ( t ) but cited by the pa-pers in D ( t ) . To the best of our knowledge, we are the first to tackle the problem in this manner. We make the following contributions.
First, we present a simple yet effective model for topic evolution analysis. We quantify the similarity of topics and measure the rela-tionship between two topics in different types of topic evolution.
Second, we develop effective and efficient methods for topic evo-lution analysis systematically. We explore two steps. Since the Latent Dirichlet Allocation (LDA) model [3] has been extensively adopted in information retrieval [4, 12, 25, 29, 33, 18, 22, 24], as the first step we extend LDA for topic evolution analysis. For each unit time period, we generate the topics independently , and then compare the topics with the previous topic space to track topic changes. The temporal order of documents within the same time period has not been considered. As the next step, we successively release the constraints of this simple solution one by one. Topics depend on documents not only in the current time period, but also from previous time periods. We further propose a novel inheritance topic model that conceptually captures how citations can be used to analyze topic evolution in an explicit way. In this model, citations are explicitly modeled as topic inheritance. The temporal order of documents even at the same time period has been considered and must respect the partial order of citation graph.

Last, we conduct an extensive empirical study using a real dataset of more than 650,000 research papers in the last 16 years and the citation network enabled by CiteSeerX, a scientific literature digi-tal library and search engine focusing primarily on the literature in computer and information science. The results clearly show that ci-tations can help to understand topic evolution better, and our meth-ods are effective and efficient.
In this section, we briefly review previous work in topic models and their applications on topic detection and topic evolution. Other previous work not using topic models but solving similar problems is discussed as well.
The LDA model on the bag of words [3] was extended to model 1) the impact of authors [29, 33]; 2) the impact of the direction-sensitive messages sent between social entities (e.g., persons) [18]; 3) the impact of one type of annotation on another type of annota-tion at the topic-level for annotated data [4]; 4) the impact of named entities [25]; and 5) the impact of ontologies [22].

None of the above has modeled the impact of citations while gen-erating topics. Recent work including [10, 12, 24] respectively used pLSA model, LDA model and a combination of them to predict the citations between documents by modeling topicality of citations. If the topic distribution of a citation can be generated by two docu-ments with a high probability, this citation was recommended to link these two documents. Instead of predicting citations, we ex-plicitly use citations to enhance topic evolutions in our novel inher-itance topic model, which is partially motivated by [11], where the citations were also modeled as inheritances. However, the latter can only handle the simple bipartite citation graph, not the com-plex citation network as ours does. Moreover, in [11], any paper that cites and is cited by other papers needs to be cloned, with one cloned version being treated as a citing paper and another as a cited paper. The cloning operation adds another difficulty, as the topics associated with the two clones are statistically unrelated.
Topic detection was defined to generate the topics from a docu-ment stream, which has been extensively studied by the topic detec-tion and tracking (TDT) community in the past [1]. The main task of TDT does not include topic evolution as we target at in this pa-per. The pair-wise topic relations are crucial in our problem, which cannot be solved by existing TDT techniques.

Moreover, no existing work on topic detection has considered the citations between documents, except for Jo et al. [16], which attempted to combine citations and text for topic detection. Heuris-tically, if a term (2-gram words) is relevant to a topic, the sub-citation graph consisting of those documents containing this term has a denser connectivity than any sub-citation graph consisting of documents randomly selected. In other words, citations are only used to model the topical similarity between documents.

In fact, the previous work on topic detection did not consider the relations among topics thoroughly, though some of them [8, 9] tried to implicitly link correlated topics by understanding documents us-ing natural language processing techniques.

In this paper, we propose a generative topic model for topic de-tection. Our topic detection model is designed to detect topics for the main task of topic evolution. Moreover, our generative model explicitly uses citations between documents to model topics, so that the connection between new topics and old topics can be more eas-ily captured compared to citation-unaware topic models.
The main task of topic evolution is to discover how and what topics change over time.
Changes of topics are monitored by treating each topic as a dis-tribution over words or a mixture over documents. Morinaga and Yamanishi [23] used a finite mixture model to represent documents at each discrete time. Their algorithm detects topic changes on certain documents if the topic mixtures drift significantly from the previous ones. Mei and Zhai [19] conducted clustering sequentially and then correlated clusters via a temporal graph model, which was in turn used to represent the topic evolutions in a document stream. Mei et al. [20] used a probabilistic approach to detect spatiotempo-ral theme patterns and then observed the evolution of theme pat-terns by comparing the theme life cycles and theme snapshots. Spiliopoulou et al. [28] detected and tracked changes in clusters based on the content of the underlying data stream. Schult and Spiliopoulou [27] used a clustering approach to find out the ontol-ogy/taxonomy evolution for documents.
Recently, many studies used generative topic models to observe topic evolution on document streams. Zhou et al. [33] used the LDA model to observe temporal topic evolution over scientific lit-erature. Specifically, a k -component LDA model is constructed over the whole dataset to generate k global topics. For each topic, the trend is obtained by simply counting the number of papers be-longing to the topic year by year. The author information is also used to explain why some topics tend to decline yet some others expand.

Blei and Lafferty [5] developed a dynamic topic model (DTM) by assuming that topic models evolve gradually in time and are distributed normally. Specifically, a k -component LDA analysis is conducted at each time slice t . Each topic is modeled as a Gaussian process centered upon the previous value. Similar to [33], the topic is global and the topic trend is obtained by counting the number of papers. The dynamic topic model assumes that all papers at time t are correlated to all papers at time t  X  1 . In our work, only cited papers at time t  X  1 are related to their citing papers at time t . Wang et al. [31] further extended this discrete DTM to a continuous version.

Morchen et al. [22] used probabilistic topic models to annotate recent articles with the most likely ontology terms. They also pro-posed a solution for automatically determining how new ontology terms can evolve from old terms. AlSumait et al. [2] extended the LDA model to an online version by incrementally updating the cur-rent model for new data and claimed that this model has certain ability of capturing the dynamic changes of topics. Gohr and Hin-neburg [13] used latent variables to index new words while deleted those outdated words within a sliding window for a stream of doc-uments. Those indexed new words were used to portray the topic changes for the information retrieval domain.

All the above work on topic evolution models a paper as a bag of words without considering the citations at all. More recently, Bolelli et al. [6, 7] proposed a generative author topic model that integrated the temporal ordering of the documents to model topic trends sequentially, where the discovered topics at an early time were propagated to influence the topics generated later. They use citations to identify  X  X opic-bearing X  words whose weights should be doubled. Mann et al. [17] used an n-gram topic model to iden-tify the influence of one topic on another. However, this approach modeled citations indirectly in the topic model, and the resulting topic influence is also time irrelevant.

Our work is distinguished from the previous work on topic evo-lution in three ways. First, we consider both content and citations in a full-generative inheritance topic model. Second, we infer cita-tions directly in the Bayesian framework. Third, we use a citation network analysis approach to explicitly emphasize the relationship between topics. In this section, we first describe the problem of topic evolution. Then, we present two citation-unaware Latent Dirichlet Allocation approaches.
Let W = { w 1 , . . . , w V } be a vocabulary set . A (probabilistic) vocabulary distribution on W is a point in the V  X  1 dimensional simplex, functioned as f : W  X  [0 , 1] such that A vocabulary distribution f can also be written as a vector f =  X  w 1 : f ( w 1 ) , . . . , w V : f ( w V )  X  . For two vocabulary distributions f and g , the similarity between them is modeled as the cosine sim-
Let D = { d 1 , . . . , d m } be a set of scientific publication corpus in question. A document d consists of a vocabulary distribution, a citation set L d , and a timestamp.

A topic z is a vocabulary distribution. Intuitively, a topic is pop-ular if it is similar to many documents in D . Imagine that we vir-tually combine all documents in D into a single long document d . We can get a word vector w for d 0 . Each element of w is a word from d 0 . If a word w appears n times in d 0 , then there are n duplicates of w in w . We call w the word sampling space . By conducting a Bernoulli trial (appear or not appear) for each element in the word sampling space, we can generate a vocabulary distribu-tion, which is a candidate topic. Fixing the number of topics (e.g., k ), the task of a topic detection method T is to generate k topics
A point in the V  X  1 dimensional simplex can be easily mapped to the V dimensional Euclidean space using the natural parameter-ization [5], so that the cosine similarity can be calculated properly. Figure 1: The topic evolution bipartite over time. Each rectan-gle represents a topic and the arc between 2 rectangles indicates various types of topic evolution. maximizing the likelihood of the observed data.

To conduct topic evolution analysis, we divide the document cor-pus D into exclusive temporal subsets D (1) , . . . , D ( n ) according to the timestamps of the documents such that D =  X  n t =1 Z ( t ) be the k topics generated by T from D ( t ) . The problem of topic evolution analysis at time t is to analyze the relationship be-tween the topics in Z ( t ) and those in Z ( t  X  1) .

Concretely, we need to specify the pairwise relationship between topics in Z ( t  X  1) and Z ( t ) . For two topics z i ( t  X  1)  X  Z ( t  X  1) and z j ( t )  X  Z ( t ) , we have We simply use the raw similarity rather than computing the true conditional probability. This is a design decision because given an existing topic z i ( t  X  1) , we never know the whole topic space which could evolve from it. If we simply assume that k topics in Z ( t ) consist of the candidate set (each has a uniform prior 1 /k ), then probabilities conditioned on different previous topics are in-comparable to each other. Fortunately, the raw similarity does not take any topic as the reference object and thus affords a fair mea-sure for all pairs of topics in comparison. The raw similarity is also constrained within the unit range [0 , 1] , making the fair comparison practical by setting some global parameters.

Using two user-specified parameters  X  1 and  X  2 such that 1  X   X  1 &gt;  X  2 &gt; 1 /k , we define three types of relationships between z ( t  X  1)  X  Z ( t  X  1) and z j ( t )  X  Z ( t ) : Same topic: z j ( t ) and z i ( t  X  1) are very similar. Specifically, Similar topic: z j ( t ) are similar to z i ( t  X  1) , that is, New topic: z j ( t ) looks new compared to z i ( t  X  1) , that is,
The two threshold parameters  X  1 and  X  2 may be determined ex-perimentally. A user may also judge whether a topic is meaningful. We thus set up the fourth type, noisy topic, which means such a topic does not correspond to any meaningful topic, i.e., it contains mainly stopwords that are always present.

For simplicity, in this paper, the number of topics for each dis-crete time is fixed as k . It can be easily extended to any dynamic number of topics using algorithms such as Hierarchical Dirichlet Process [30].

Based on the above four types of topic evolution, we can generate a topic evolution bipartite over time for the whole document corpus D , as elaborated in Figure 1. An arc from one topic z i another one z j ( t ) indicates that within Z ( t  X  1) , z maximum conditional probability to z j ( t ) .
Let us consider two simple approaches for topic evolution.
Given the current time t , the independent topic evolution learn-ing method detects topics only from D ( t ) . In other words, Z ( t ) is independent from Z ( t  X  1) , as illustrated in Figure 2. The learning process is defined as follows.
 where p ( d | Z ( t )) is the likelihood of document d given Z ( t ) by assuming all documents in D ( t ) are equally important for Z ( t ) .
Can we consider the dependence of the topics in Z ( t ) on the documents at time instant t and before? The accumulative topic evolution learning method, as elaborated in Figure 3, learns the current topic space Z ( t ) from all papers published at time t and before, i.e., from document set  X  t i =1 D ( i ) . The learning process is assuming all documents in  X  t i =1 D ( i ) are equally important for Z ( t ) .

Both methods are citation-unaware since they do not consider the citations. The independent topic evolution learning method tends to generate a large number of isolated new topics irrelevant to existing topics. In the accumulative topic evolution learning method, the existing topics tend to dominate the topic space as time goes by.

To learn topic spaces in the two citation-unaware methods, i.e., maximizing the likelihood of the data, any traditional topic mod-els can be applied. Here, we use one of the most popular models in machine learning and information retrieval, the Latent Dirichlet Al-location (LDA) [3] framework, to generate topics. Collapsed Gibbs sampler can be used to infer the LDA posterior probabilities [14]. We denote by i-LDA the Gibbs sampling algorithm of independent topic evolution learning, and by a-LDA the Gibbs sampling algo-rithm of accumulative topic evolution learning.
In this section, we extend the LDA approaches in Section 3 by taking citations into account. We also develop an approach explic-itly modeling citations as inheritance in documents.
To be citation aware, the current topic space Z ( t ) should be gen-erated not only from D ( t ) , but also from L D ( t ) , the set of papers in At time t , a simple citation aware method to compute Z ( t ) is assuming all documents in D ( t )  X  L D ( t ) are equally important for Z ( t ) . Again, we can use LDA in topic generation. We denote by c-LDA the algorithm of Eq. 3 using LDA.

Is c-LDA a good solution to balance new topics and existing top-ics via citations? There are two problems. First, not all citations are equally important. Among all papers cited by a document d , typ-ically only a small subset is topic-related to d . Therefore, treating all citations equally may dilute the truly important topics. Second, due to the sheer number of historical papers, some out-of-date top-ics may be resurrected by citations solely if the citations are not properly associated with the current topics. We call such topics ghost topics .

To address the above concerns, we propose a learning method based on Dirichlet prior smoothing [32]. At the given time t , we learn the topic space by, where p ( d | Z ( t )) =  X   X  p ( d | Z ( t )) + (1  X   X  )  X  is the likelihood of document d given Z ( t ) linearly combining two factors: the language models for both citing and cited documents, weighted by  X  , and the topical influence from all cited documents, individually weighted by the vector  X  .

Eq. 4 actually defines an iterative learning process, where the topic models of both the citing paper and all its cited papers are learnt using the same procedure. To reduce the number of tuning parameters, we assume Dirichlet priors  X   X  and  X   X  for  X  and  X  , respectively. Here,  X  is drawn from a Beta distribution Beta (  X  while  X  is drawn from a Dirichlet distribution Dirichlet (  X  ging in the distributions, we have where the indicator variable s denotes whether a word is sampled from the cited papers ( s = 0 ) with topic assignment z or from the citing paper ( s = 1 ) with topic assignment z 0 , and is drawn from a Bernoulli distribution Bernoulli (  X  ) , the variable c indicates for a word sampled from the cited papers ( s = 0 ) which cited paper should be sampled from the citation list L d , and is drawn from a multinomial distribution Multi (  X  ) , and p ( c = d j |  X  ) represents the topical influence of the cited paper d j on the citing paper d .
To the best of our knowledge, no existing topic model is able to support the iterative learning process defined in Eq. 5. We therefore have to develop our own topic model.
We propose the Inheritance Topic Model (ITM for short) in Fig-ure 5 and notation is summarized in Table 1. In our topic model, a paper d is virtually separated into two parts: the inherited part d and the autonomous part d 1 , which are generated independently. The model captures the real world situations where a paper often reuses ideas and techniques of previous work reflected by the cited papers, simultaneously, contains some new material. Technically, for a paper d , the inherited part d 0 is a mixture of the autonomous parts of all papers in L d . The detailed generative process of ITM is given as below.
Similar to LDA, in ITM, we also need to infer the ITM posterior probability. The joint probability of generating the word sampling space w at a time instant is We use collapsed Gibbs sampler algorithm to approximate the above joint distribution, which is denoted by c-ITM . At each iteration of Gibbs sampling, we update the latent variables for every word po-sition using the following processes until the latent variables con-verge. We use the notation in Table 1.
One advantage of ITM is that c-ITM can further refine the newly generated topic space by monitoring the inheritance relations among topics. For example, among the k topics in D ( t ) produced by c-ITM , a few topics may not truly exist in D ( t ) but are instead inher-ited from D ( t 0 ) , t 0 &lt; t via citations. Since we sample words from the inherited and autonomous parts of a document separately, we can similarly separate the topic space Z ( t ) into two parts: an in-herited part and an autonomous part, to each of which a topic z has a certain probability.

One simple way is to use a k  X  k topic motivation (correla-tion) matrix Q for D ( t ) . Each cell Q ij represents the motiva-tion probability of topic z i on z j . Each row sums to be 1. Given document d , a word w in its inherited part d 0 is assigned a topic z ( t )  X  Multi (  X  ) . We can assume that z i ( t ) motives another autonomous topic z l ( t )  X  Multi (  X  ) if
The motivation probability relies on how frequently the words in d 0 and z i ( t ) co-occur with the words in d 1 and z as l 6 = i and z i ( t ) has a same topic in Z ( t  X  1) , topic z be regarded as an inherited topic that is no longer hot in the cur-rent topic space. This is reasonable because if z i ( t ) were popular at time t , there should have been many papers in topic z cite papers from the same topic, so that the motivation probability to itself at time t is still significant. Ideally, diagonal probabili-ties should dominate the motivation matrix for the topic evolution category of  X  same topic  X .
 Building the topic motivation matrix is straightforward based on LDA as below.
The time complexity of the four algorithms fully depends on the efficiency of the k -component LDA/ITM. Let N be the dimension-ality of the word sampling space w . There are a total of kN param-eters to infer during each iteration for the LDA model under Gibbs sampling. Let n be the number of iterations, the time complexity for i-LDA , a-LDA and c-LDA is O ( nkN ) .

For ITM, there are kN + 2 N + | L d | X  N parameters to be in-ferred in each duration, where the dimensionality of the indicator vector s is 2 and | L d | is the average number of citations of each paper in the dataset (i.e., the average dimensionality of the dummy index vector c ). Since | L d | is a constant given a document, the k -component ITM model does not grow with the size of the data. The time complexity of c-ITM is O ( n ( k + 2 + | L d | ) N ) .
Since both LDA and ITM can be convergent after a limited num-ber of iterations, given n , all four algorithms thus have a linear scalability with respect to N , the only factor that solely relies on the size of data. We tested topic evolution models on the literature archived at CiteSeerX. The dataset contains research papers in computer and information science. We selected papers published in the last 16 years (1993-2008). After removing duplicate papers, papers with-out explicit publication timestamps, we obtained 650 , 918 unique papers dated until early 2008. For each paper, we extracted its ti-tle and abstract as content, ignoring the rest. The distribution of number of papers over publication year is shown in Figure 6(a).
We used a year as the time unit in our analysis. The set of papers published in year t (1993  X  t  X  2008) is fed into i-LDA to learn the topic space of the year. a-LDA uses all papers published in or before year t to learn the topic space of the year. For both c-LDA and c-ITM , we extract all cited papers prior to each year. For simplicity, only 1-hop citations are considered. Please note that only those cited papers in the dataset are used by c-LDA and c-ITM . Figure 6(b) shows the distribution of the average number of citations per paper over different years.
For the LDA model, we used the free Mallet tool 2 . We imple-mented our ITM model in C++. For the hyper parameter settings,  X   X  = 0 . 1 ,  X   X  = 0 . 01 ,  X   X  = 1 . 0 ,  X   X  0 = 3 . 0 ,  X   X   X  = 0 . 1 . All these hyper parameter settings simply follow the tradition of topic modeling [3]. All experiments were conducted on a Linux server with 7 CPU processors of 2.4GHz and 16G memory.
We evaluated the four topic evolution algorithms for their effec-tiveness, efficiency, and scalability.
We extracted the top 30 topics by default following the sugges-tion of [15]. We set the parameters  X  1 = 0 . 5 and  X  2 = 0 . 2 . Fig-ures 7(a)-(d) show the distribution of the different types of topic evolution found by i-LDA , a-LDA , c-LDA , and c-ITM , respectively. We can obtain some interesting observations. i-LDA tends to produce the largest average number of new topics (10.53) and noisy topics (4.4). On average, almost half of the topics (14.93) generated by i-LDA are either new or noisy. Refer to Figure 8(a), the smaller amount of data, the more new or noisy topics i-LDA generates. For example, as the data volume in years 1998-2005 increases, i-LDA shares more topics from the topic spaces in the previous years. However, as the data in year 2008 is incomplete (papers crawled after early 2008 are not included) and thus much smaller (less than 1/10) compared to the other years, almost all generated topics are either new or noisy. a-LDA is on the other end of the extreme: historical topics tend to dominate the topic space every year. For example, after year 1999, as the accumulation of historical data, the topic space of the current year is almost completely dominated by the previous year X  X  topic space (on average, 2/3 generated topics are same topics ). In contrast to i-LDA , a smaller data volume (of the current year) re-sults in fewer new topics in a-LDA . As shown in Figure 8(b), after year 1999, the average number of new topics has a convergence range from 0 to 2. a-LDA generates noisy topics without a clear trend: on one hand, the dominance of historical topics can elimi-nate noisy topics; on another hand, the noisy words contributed to noisy topics are also accumulated along the time.

The two citation-unaware methods suffer from either heavy topic drifting or heavy topic inheritance, both are undesirable for topic evolution. Moreover, both methods are very sensitive to changes in data size.

The citation-aware methods c-LDA and c-ITM strike a good bal-ance between i-LDA and a-LDA . Both are less sensitive to changes in data size. Specifically, c-ITM tends to generate more new top-ics (9.33 vs. 5.93 on average) and the fewest noisy topics (2.33 on average), while c-LDA tends to produce slightly more same topics (11.27 vs. 9.87 on average).

The cited papers may boost the importance of some old topics that are no longer hot in the current year. Therefore, the citation-http://mallet.cs.umass.edu/ the according category.
 aware methods tend to produce more same topics and less new topics . The disparity can be seen by comparing c-LDA to i-LDA . This is because using citations may inherit from the historical topic space and thus affect the generation of new topics, especially when new topics appear for the first time.

Fortunately, c-ITM is able to reach a good balance. For exam-ple, the word space in year 2008 shrinks more than 70% relatively due to the much smaller data volume. Under the same number of partitions, most of topics in year 2008 are too specific and thus dif-ferent to historical topics. That is to say, most of major historical topics have been lost in year 2008. However, c-LDA still generates 23 same topics and similar topics based on the small word space. Apparently, the cited papers dominate the generation of the topic space in c-LDA for year 2008. However, c-ITM does not suffer from such a problem; half of topics (15) in year 2008 are new.
Figure 9 shows the trend of average topic similarity. To draw the curves, in year t , a topic z is matched with a topic z 0 with the highest topic similarity. Then, the average similarity of a year is the average of similarity of the topics in the year and the matched topics in the previous year. The larger the similarity, the more similar the topic spaces in two consecutive years.

The topic similarity trends tell the differences among our four topic evolution methods: i-LDA always has the smallest topic sim-ilarities so that topics oscillate the most. a-LDA always has the highest topic similarities so that topics tend to retain. c-LDA and c-ITM stay in the middle yet sometimes c-ITM has a bit smaller topic similarities, so that c-ITM can generate a bit more new topics . Last, when the data volume increases in some year, the differences among the four methods become smaller.
Although c-ITM strikes a good balance between new topics and same topics , some old topics that have been declining in the current year still may be inherited along the citations. We can optionally build the topic motivation matrix to filter the topic space produced by c-ITM . We used year 2006 as an example to generate the topic motivation matrix ( 27  X  27 after removing 3 noisy topics), as shown in Figure 10.
 Table 2: Top topic motivation probabilities for ghost topics in 2006.
Among the 10 same topics , we identified two ghost topics (top-ics 5 and 25) that exist in the previous year topic space, and have high motivation probability to the other topics, but low motivation probabilities to themselves. These ghost topics exist only in the cited papers. Table 2 shows in detail how the two ghost topics were cited by other valid 2006 topics. Limited by space, only the top 2 words were used to represent each topic without manual labels.
Figure 11 shows the number of ghost topics yearly. Compared to the number of same topics , only a small portion of same topics are ghost topics. c-ITM did not generate many ghost topics.
To better understand the topic evolution process, here we present some real topic evolution examples related to the category of image
Figure 13: Topic strength trend for image-related topics. processing , as shown in Figure 12. Each topic is described using the top 5 words without any human labels.

There are two main topics related to image processing: image compression which mainly evolved from 1994 to 2001, and face recognition which mainly evolved from 1998 to 2007. Specifically, image compression evolved from the topic image surface in 1994 and subsequently evolved into the new topic face recognition in 1998. In 1998, image compression further evolved from static im-age compression to video compression . Except for the year 1999 in which video compression was suddenly interrupted by channel coding which was still hot for image compression, we believe the other evolutions are consistent and reasonable. We can also con-clude that wavelet coding is a very important tool for both static image compression and video compression , rather than others like channel coding .

Figure 13 further depicts the topic strength trends for two main topics: image compression and face recognition . In Figure 13, we simply group static image compression , video compression and channel coding into the same topic named image compression , dis-card the other unimportant branches like camera objects etc., and assume that year 2008 does not have enough data to support the topic evolution in image processing. The topic strength trend clearly tells how these two topics evolve over the time. Interestingly, when image compression reaches the bottom in 2002, the topic face recog-nition also reaches its peak at the same time.
We analyze the scalability and time efficiency of our topic evolu-tion methods. The scalability of LDA has been tested in many pre-vious work. Here, we only test the ITM model. The total number of word occurrences N across 16 years in our dataset is 42 , 389 , 066 . Accordingly, we sampled 10% , 20% , . . . , 100% of the word oc-currences to test the scalability. Note that except for a-LDA , we will never have a chance to use 100% of all word occurrences. We showed that the time complexity of ITM is linear with respect to the number of word occurrences, the number of iterations, and the size of topic space. Figure 14(a) further verifies our claim with k = 30 and 1 , 000 Gibbs sampling iterations.
Previous work (e.g., [14]) reported that LDA under Gibbs sam-pling normally requires around 500 -1 , 000 iterations to reach con-vergence. Here, we also compared the convergence rate for two topic models: ITM and LDA under Gibbs sampling. We used the minus likelihood of the data to measure how our model fits the data (the whole word space w ), which is defined as Suppose that d is the document from which the word w i originates, p ( w i ) =
Figure 14(b) shows the convergence rate of models. After about 100 iterations, the likelihood of the data stabilizes and does not change significantly for both models. Overall, LDA converges a bit faster and stabilizes after 200 iterations. Instead, ITM cannot improve the likelihood further after 300 iterations. But after con-vergence, ITM has a higher likelihood. The result indicates that the convergence speed of our model is comparable to LDA under the Gibbs sampling; and our model fits the citation graph data better.
Lastly, we tested the running time of all topic evolution methods with k = 30 , as shown in Figure 15. For a fair comparison, we ran 1 , 000 iterations for each method. The running time of all methods grows/declines linearly as the data volume (refer to Figure 6) and the word sampling space increase/decrease. Under the same data distribution, c-ITM is slower than c-LDA as the former needs to infer 2 additional latent variables.
In this section, we compare our topic evolution results with the previous topic evolution work on the CiteSeerX data, which is nar-rowed to Jo et al. [16] (denoted by term-graph ), Zhou et al. [33] (denoted by author-interaction ) and Bolelli et al. [6, 7] (denoted by Figure 16: Comparing the topic evolution for topics related to machine learning . citation-boost ). Topics were examined from 1991 to 2004 in [33], from 1994 to 2004 in [16], and from 1990 to 2004 in [6, 7].
We use the topic category  X  X achine learning X  as the example to compare with previous work within the common time periods 1994-2004. The term-graph generated thousands of topics based on terms, yet the other three only only produced k topics each time; so that much fewer documents were grouped to topics by term-graph then others. We multiply the percentage of documents by five for the topics generated by term-graph , only for a comparable visualization.

Figure 16 visualizes the evolution of topics related to machine learning for all methods. The topics neural network and SVM clas-sification are related. In our method, we detected neural network at the very beginning. It started to decline in 1998 and evolved to SVM classification around 1999-2000. In 1999, the top 5 words of the according topic in our model are learning, neural, models, network and classification , which can be seen as a mixture of neu-ral network and classification . We can thus treat the year 1999 as a transitional period between these two topics; and the mixed topic learning, neural, models, network and classification as the according transitional topic. This transitional topic was announced as similar topic by our model. Before year 1999, neural network was hot; after year 1999, SVM classification was uplifted to the hot topic list. We simply assumed that these two topics co-existed with the same weight in 1999 to highlight such a transitional period in Figure 16.
 In author-interaction , neural network has a decreasing trend and SVM classification has an increasing trend, both from the begin-ning to the end. After considering the impact of authors, author-interaction found the reason for the declining of neural network and increasing of SVM for classification : some authors worked on neural network might move to the area of SVM classification . This finding is consistent with our results.

In term-graph , the topic neural network was not found and a topic denoted by the term support vector was found with an increas-ing trend as the term support vector at the 5th position in the list of top topics since 2000. In citation-boost , a more general topic la-beled by machine learning was found in the very beginning. It first has a decreasing trend until year 1996; after that, its topic strength increases.

Based on the above results, we conclude a few findings to differ-entiate our method from the previous work.  X  All methods except for citation-boost have consistent topic strength trend: neural network declines before 1999 and SVM classifica-tion boosts after 1999. It is not clear why citation-boost has an inconsistent concave point in 1996 (partially because machine learning covers other unknown topics).  X  Only our method and term-graph are able to tell cause and ef-fect for two related topics, where one topic evolves from another one. Our method finds out such hot topic transition through a transitional topic (it is very likely in the topic evolution category similar topic or new topic ), yet term-graph bridges two related topics by counting the common authors.  X  The topics found by term-graph are more fine-grained (with fewer in-topic documents). In the contrary, citation-boost generated rather general topics (with more in-topic documents). Both meth-ods cannot find out pairwise relations for topics.
Since no benchmark topics exist for topic evolution, we evaluate the quality of the automatically detected topics by comparing them to the top manually-confirmed topics found by term-graph . The term-graph offered two ranking lists for topics before and since 2000. Those top topics of each list are the most frequent terms happened in each time period. Thus, term-graph provided a bench-mark for evaluating the topic evolutions. For example, if an impor-tant topic has evolved from the past after 2000, it might appear in the top list of topics since 2000 only (not in the list before 2000). We picked the top 25 topics from the list since 2000, and removed those topics that also appeared in the top 100 of the list before 2000. In the end, we got 20 topics in total that did not appear in top 100 list before 2000 but appear in the top 25 list since 2000, as shown in Table 3. These 20 topics are then treated as the benchmark that evolved from the part and newly became hot after 2000.

In Table 3, we checked the meaningfulness of these benchmark topics manually, as well as how these topics evolved over our method and the other two: author-interaction and citation-boost . We found that only 12 benchmark topics are proper hot topics since 2000. Among the rest 8 topics, 4 topics were detected repeatedly and an-other 4 are too specific to be proper topics (they might be specific methods rather than topics). This result indicates that the enor-mous topic space (thousands of topics) produced by term-graph is not clean.

Based on Table 3, we made the following conclusions.  X  Assuming that term-graph has the highest recall ( 100% ), our method successfully detected most of important topic evolutions with a recall of 91 . 67% (11 over 12), only missing 1 topic image retrieval which was covered by the topic information retrieval . The citation-boost has a recall of 58 . 33% by missing 5 topics.
The author-interaction has a recall of 25% by detecting 3 topics.  X  Among the hit topics, our method and author-interaction have a finer grain. The generated topics match the most frequent terms well. However, citation-boost only produced coarse top-ics. Based on citation-boost , it is not clear how topics evolved from one topic to another in detail.  X  In term-graph , only the top topics are meaningful as term-graph generated many specific topics. Heavy duplications also exist in term-graph . Instead, the other three work only produced gen-eral topics without ranking. Only author-interaction and our method produced pairwise topic relations. Compared to author-interaction , our method can tell the exact boundary of topic evo-lution, but in author-interaction , topics were spanned over the whole time range.
In this paper we studied the topic evolution problem for scaled scientific literature. We first investigated the citation-unaware ap-proaches based on the LDA model, along with their limitations on topic evolution, i.e., the correlated topics were generated in-dependently. We then proposed the citation-aware approaches for topic evolution. Moreover, an iterative topic learning framework based on citation network was presented to fully utilize the impact of citations. A novel Inheritance Topic Model was then naturally proposed for this learning process. Our algorithm can be quickly convergent under the Gibbs sampling and has a linear scalability with respect to the size of dataset. The experimental results show that our approach can track the topic evolution in a large dataset containing more than 650,000 papers over 16 years. The experi-mental results clearly indicate that citations are able to portray the inherent dependence among correlated topics, and citation-aware approaches are thus good choices for tackling the sequential topic evolution problem.
This material is based upon work supported by the National Sci-ence Foundation under Grant Nos. 0535656 and 0845487.
