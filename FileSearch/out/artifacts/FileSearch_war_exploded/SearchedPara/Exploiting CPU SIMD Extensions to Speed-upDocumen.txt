 Scoring documents with learning-to-rank ( LtR ) models based on large ensembles of regression trees is currently deemed one of the best solutions to effectively rank query results to be returned by large scale Information Retrieval systems.
This paper investigates the opportunities given by SIMD capabilities of modern CPUs to the end of efficiently evaluat-ing regression trees ensembles. We propose V-QuickScorer ( vQS ), which exploits SIMD extensions to vectorize the doc-ument scoring, i.e., to perform the ensemble traversal by evaluating multiple documents simultaneously. We provide a comprehensive evaluation of vQS against the state of the art on three publicly available datasets. Experiments show that vQS provides speed-ups up to a factor of 3.2x.
Additive ensembles of regression trees, such as GBRT [3] and  X  -MART [6], are nowadays considered among the most advanced LtR models for ranking documents in IR systems, although these require very efficient scoring algorithms for processing queries by strict time budgets [1]. The state-of-the-art algorithm for efficient scoring via additive ensemble of regression trees is QuickScorer ( QS ) [4]. The main novelty of QS is given by the novel traversal strategy of a tree ensemble T : QS does not traverse T one tree at a time, but rather evaluates the branching nodes of the trees in a feature-wise order. This strategy was proven to be very efficient for a number of reasons: (i) a very small number of nodes is actually visited, (ii) the exploited data structures have a cache-friendly access pattern, and (iii) fast bitwise operations with few and predictable branch instructions are performed.

In this paper we discuss how QS can be parallelized by exploiting the advanced SIMD capabilities of mainstream CPUs [5]. Streaming SIMD Extensions (SSE) and Advanced Vector Extensions (AVX) are sets of instructions exploiting wide registers of 128 and 256 bits. A single SIMD instruc-tion performs parallel operations on simple data types, e.g., a 128 bit register can manage four single precision or two double precision floats simultaneously. We use in the follow-ing a notation similar to the one of Intel Intrinsics 1 , where a SIMD instruction codes in its name: (i) a prefix mm or mm256 stating if 128 or 256 bits registers are used; (ii) the name of actual operation; (iii) a suffix indicating the types of the operands, e.g., ps or pd for 32 and 64 bit floats, respectively. For instance, is a SIMD instruction that works on two registers  X  X  X  a and of 128 bits, each storing a sequence of four single precision floats, and performing four greater than comparisons in par-allel. The result is stored in a 128-bit register  X  X  X  c , which will contain four 32-bits sequences of 1s or 0s, depending on the test outcome of the four comparisons. In the following, we will use the notation  X  X  X  c  X  X  c 3 ,c 2 ,c 1 ,c 0  X  to refer to the four elements of a SIMD register.

In this work we propose V-QuickScorer ( vQS ) 2 , a ver-sion of QS that exploits CPU vector extensions to boost the efficient traversing of additive ensembles of regression trees. Since exploiting SIMD instructions requires to identify data parallelism opportunities in the code, in QS the most natu-ral source of data parallelism derives from the need of scor-ing multiple documents for a given query. In particular, we discuss the use of both SSE-4.2 and AVX-2, providing dif-ferent register widths as well as different SIMD instruction sets, to score up to 8 documents in parallel. Experiments show that vQS provides up to 3.2x speedup compared to the state-of-the-art sequential QS algorithm.
Given a query-document pair ( q,d i ), represented by a fea-ture vector x , a LtR model based on an additive ensem-ble of regression trees predicts a relevance score s ( x ) used for ranking a set of documents. Typically, a tree ensem-ble encompasses several binary decision trees, denoted by T = { T 0 ,T 1 ,... } . Each interal (or branching) node n  X  T associated with a Boolean test over a specific feature f  X  and a constant threshold  X   X  R . Tests are of the form x [  X  ]  X   X  , and, during the visit, the left branch is taken Algorithm 1: The QuickScorer Algorithm iff the test succeeds. Each leaf node stores the tree pre-diction, representing the potential contribution of the tree to the final document score. The scoring of x requires the traversal of all the ensemble X  X  trees and it is computed as a weighted sum of tree predictions.
 Algorithm 1 illustrates QS [4]. One important result of QS is that to compute s ( x ) it needs to identify only the branching nodes whose tests evaluate to false, called false nodes . To do so, QS maintains for each tree T h  X  T a bitvector leafindexes[ h ] , made of  X  bits, one per leaf. Ini-tially, every bit in leafindexes[ h ] is set to 1. Moreover, each branching node n is associated with a binary mask nodemasks[ n ] idendifying the set of unreachable leaves in case the corresponding test evaluates to false. When-ever a false node is visited, the set of unreachable leaves leafindexes[ h ] is updated through a logical and with nodemasks[ n ] . Eventually, the leftmost bit set in leafindexes[ h ] identifies the leaf corresponding to the score contribution of T h , stored in the lookup table leafvalues . To efficiently identify all the false nodes in the ensemble, QS processes the branching nodes of all the trees feature by feature and in ascending order of their predicate thresholds. Specifically, for each feature f  X  , QS builds a list N  X  ples (  X ,h,n ), where  X  is the predicate threshold of node n occurring in tree T h . When processing N  X  in ascending or-der by  X  , as soon as a test evaluates to true, i.e., x [  X  ]  X   X  , the remaining occurrences surely evaluate to true as well, and their evaluation is thus safely skipped.

We call mask computation the first step of the algorithm during which all the bitvectors leafindexes[ h ] are updated, and score computation the second step where such bitvectors are used to retrieve tree predictions.
SIMD extension of modern CPUs provide powerful fine-grained parallelism which can be exploited to score multiple documents simultaneously. Note that the QS paper [4] al-ready investigated multiple documents scoring as a strategy to improve cache performance. In this work, we propose V-QuickScorer ( vQS ), a SIMD-based algorithm exploiting the natural data parallelism deriving from this strategy.
Both the mask computation and score computation steps of
QS can be engineered to take advantage of SIMD regis-ters. During the first step, multiple documents can be tested Algorithm 2: The vQS Algorithm (SSE-4.2,  X  = 32) against a given node predicate and their leafindexes[ h ] updated in parallel. Similarly, the score of multiple docu-ments can be computed simultaneously during the second step. The data structure leafindexes used to encode the exit leaves must be replicated to accomodate the documents scored simultaneously.
 The specific optimizations used by vQS depend on the SIMD register width available and on the maximum num-ber of leaves  X  in the ensemble. We first discuss how vQS exploits SSE-4.2 or AVX-2 instructions when  X  = 32, then we highlight the differences when  X  = 64.
 SSE-4.2 registers are 128 bits wide, and permit processing 4 documents simultaneously during the mask computation step. Therefore, as shown in Alg. 2, vQS is given in input a set of four instances { x i } i =0 , 1 , 2 , 3 , and a vector scores of four double precision floats where the scores are stored upon completion.

During the mask computation step, one 128-bit SIMD reg-ister  X  X  X   X  is used to store 4 copies of the same test threshold  X  , and another register  X  X  X  x to store the feature x i [  X  ], i = 0 , ... , 3 of the 4 input instances (lines 5-6). A single instruction is used to compare the feature values of these four documents against  X  (line 7). If all tests evaluate to true, i.e., we do not have any false node , then the next feature is pro-cessed, otherwise leafindexes is updated. Note that unlike the QS sequential implementation, the need of verifying the true condition for all 4 documents rather than for a single one, may lead to some overheads in the strategy aimed at identifying false nodes only in the tree ensemble.
The update of leafindexes involves potentially four doc-uments and should occur only for those where x i [  X  ] &gt;  X  . Since SSE-4.2 does not support masked/predicated SIMD instructions, to avoid conditional branches vQS implements the update with two bitwise operations. Let leafindexes i be a 32-bit vector ( X  = 32), relative to tree T h and associ-ated with document x i . Let variable c i store a string of 32 bits of 1s or 0s, depending on the outcome of the test x [  X  ] &gt;  X  . We can rewrite the update as: leafindexes i [ h ]  X  ( nodemask [ n ]  X  X  c i )  X  leafindexes where the bitwise logical or has the effect of leaving nodemask [ n ] unaltered when x i [  X  ] &gt;  X  , or making it useless otherwise. We can re-write the expression as follows by applying the De Morgan law: leafindexes i [ h ]  X  X  (  X  nodemask [ n ]  X  c i )  X  leafindexes which we can straightforwardly implement by a repeated application of the SIMD function andnot ( x,y ) =  X  x  X  y . The layout of leafindexes is tree-wise, i.e., given a tree T h the bitvectors leafindexes i [ h ] of the four x i are stored contiguously in memory. As shown in Alg. 2 (lines 9 X 13), this allows loading the four bitvectors with a single 128-bit load instruction, and to apply them the two SIMD andnot instructions. Indeed, first the four leafindexes 3:0 loaded into the register  X  X  X  m . After composing  X  X  X  m ,  X  X  X  c and finally copied back to memory.

The score computation is also parallelized (see Alg. 2, from line 15). To provide the required precision, tree predictions are stored as double precision float values (64 bits), which means that only 2 document scores can be processed simul-taneously using 128-bit registers. Thus, vQS uses two ( pd ) SIMD variables, namely  X  X  X  s 1:0 and  X  X  X  s 3:2 , to maintain the score of our 4 documents. For each tree, the predicted partial scores related to the 4 input instances are similarly stored in  X  X  X  X  v 1:0 and  X  X  X  X  v 3:2 , and added up to update the final document scores. Eventually, the computed scores for the 4 documents are copied to vector scores 3:0 .
 When AVX-2 is supported, it is possible to increase the par-allelism degree of vQS . Trivially, 8 document features tests can be performed simultaneously instead of 4, and 4 docu-ment scores updated instead of 2. In this case, vQS scores 8 documents at each invocation. We do not discuss the pseudocode for the document feature testing and document scores calculation, as it simply requires to adopt the 256-bit versions of the respective instructions illustrated above.
More interestingly, AVX-2 also provides additional instruc-tions, such as mm256 maskstore ps : this copies a 256-bit register to memory according to a given mask enabling/dis-abling sub-groups of 32-bits. This makes it possible to con-ditionally update each of the 8 elements of leafindexes 7:0 (or to leave it unchanged) depending on the output of the 8 node predicates, which is stored in  X  X  X  c . Lines 11 X 13 of Alg. 2 are replaced as follows, where the vector variables involved are now 256 bit registers: I ncreasing  X  (the maximum number of tree leaves) impacts on the size of the bitwise structures leafindexes and node-mask , as each bitvector they store is  X  bits wide. As a con-sequence, the number of bitvectors (either leafindexes or nodemask ) that can be processed simultaneously in a SIMD register decreases. Recall that, when  X  = 32, the number of tests and the number of bitvectors fitting in a SIMD register are the same, either 4 or 8 for SSE-4.2 or AVX-2, respec-tively. Therefore, the variables  X  X  X  m ,  X  X  X  c and processed together. When  X  = 64, there is a mismatch be-tween the 32 bits returned by each predicate test, and the 64 bits of the leafindexes and nodemask bitvectors.
For 128-bits registers, let  X  X  X  c  X   X  c 3 ,c 2 ,c 1 ,c 0  X  be the out-come of the four comparisons against a threshold  X  . For the subsequent update of the 64-bits masks, vQS requires to process  X  X  X  c in order to obtain two variables, storing only two comparison outcomes of 64 bits each. To this end, we use the following two instructions, working on the low and high half of  X  X  X  c , respectively.  X  c 1 ,c 1 ,c 0 ,c 0  X  X  X  _mm_unpacklo_ps (  X  X  X  c ,  X  X  X  c )  X  c 3 ,c 3 ,c 2 ,c 2  X  X  X  _mm_unpacklhi_ps (  X  X  X  c ,  X  X  X  c ) Once prepared these two result variables, they are used in the subsequent andnot operations, similarly to Alg. 2. The only difference is that the code from line 11 to 13 must be repeated twice, one for updating the two copies of leafindexes associated with the first pair of documents, and the other for the second pair.

By using 256-bits registers on AVX-2, vQS performs 8 tests in parallel, while we update the 8 copies of leafind-exes by exploiting two blocks of SIMD instruction, each performing 4 operations in parallel on the 64-bit bitwise data structures. As before, from  X  X  X  c  X   X  c 7 ,c 6 ,...,c would like to extract two vectors with the following layout  X  c ,c 3 ,c 2 ,c 2 ,c 1 ,c 1 ,c 0 ,c 0  X  and  X  c 7 ,c 7 ,c 6 ,c Unfortunately, the AVX-2 instructions for unpacking these bitmasks, namely mm256 unpacklo ps and mm256 unpackhi ps , work by considering each 256-bits reg-isters as two 128-bit lanes, and thus pick the least/most significant 64 bits from each of these lanes. The solution adopted by vQS is to set a different layout for  X  X  X  c in order to be able to apply the above unpacking instructions. To this end, we load the 8 features of  X  X  X  x , to be compared with the threshold  X  , in the following suitable order: This new 256 bit instruction replaces line 6 of Alg. 2.
Datasets . We used three publicly available datasets: Mi-crosoft LETOR ( MSN-1 3 ) and Yahoo LETOR ( Y!S1 4 ), com-monly used in the scientific community for LtR experiments, and a new larger one called Istella LETOR ( istella 5 ). istella is composed of 33,018 queries and 10,454,629 query-document pairs, where each pair is represented by a vector of 220 fea-tures. This is split in training and test sets with a 70%-30% Table 1: Per-document scoring time in  X  s of QS , vQS (SSE 4.2) Speedups over the baseline QS are reported in parentheses. partitioning. To the best of our knowledge, this is the largest publicly available LtR dataset, particularly useful for large-scale experiments on the efficiency and scalability of LtR so-lutions. In all the three datasets, feature vectors are labeled with judgments ranging from 0 (irrelevant) to 4 (perfectly relevant).

Experimental methodology . We trained  X  -MART [6] models optimizing NDCG@10 on the three datasets, and generated models with  X  = 32 or  X  = 64 leaves and with |T| =1,000 or |T| =10,000 trees. We used the open source im-plementation of  X  -MART by [2], however it is worth noting that the results reported in this work are independent of the training algorithm implementation. To provide a fair com-parison, vQS was implemented by engineering the source code of QS . In the following we reported the average per-document scoring time averaged over 10 runs. The tests were performed on a machine equipped with an Intel Xeon CPU E5-2630 v3 clocked at 2.40GHz with 20 MB of cache L3 and 64GB RAM.

Efficiency evaluation . Table 1 reports the average time (in  X  s) for scoring a single document across the three datasets, when varying both the number of trees and leaves in the en-semble. The best improvements are achived with  X  = 32, as vQS can use either 4-or 8-way parallelism for both fea-ture predicate testing and bitvectors updating. When using AVX-2, speed-ups range from 1.9x (for MSN-1 with 10,000 trees) to 3.2x (for Y!S1 with 1,000 trees). These are greatly reduced woth SSE 4.2, with a maximum speedup of 2.4x for the 1,000 trees model over Y!S1 . As expected, performance worsen with  X  = 64, with a maximum speed-up of 1.8x. The lower improvement is due to inefficiencies deriving from additional processing required to align the 4-/8-way com-parisons to the 2-/4-way conditional mask updates.

A final note regards the overheads of the vectorized code during the scan of the ordered list of feature thresholds N While QS stops as soon as the single document feature is greater of the current threshold, vQS must continue as long as at least one among the 4 or 8 documents evaluated si-multaneously does not match the exit criterion. We instru-mented the code to measure this difference. The tests con-ducted on MSN-1 , with 10K trees and  X  = 64, confirmed the hypothesis: to score a single document QS executes in average 15 . 76 tests per tree, while this number increases to 22 . 80 and 26 . 68 for the SSE 4.2 and AVX-2 versions of vQS , respectively. In fact, we observed that while the score computation step benefits significantly of the increased par-allelism provided by AVX-2, the mask computation step ex-hibits only a limited improvement, due to the additional comparison costs mentioned above.
We discussed in depth the vectorization of QS , the state-of-the-art algorithm for scoring documents with LtR tree ensembles. Using SIMD capabilities of mainstream CPUs, namely SSE 4.2 and AVX 2, vQS can process up to 8 doc-uments in parallel, although there is a tradeoff due to the possible increase in the number of operations carried out. We also highlighted some features of these SIMD coproces-sors, which force to re-design algorithms in non trivial ways.
The upcoming AVX-512 extension, due to wider regis-ters, would allow to further increase the parallelism degree up to 16 documents. Wider registers are not the only ben-efit, since many new instructions will be available. One ex-ample is mm512 lzcnt epi32 , which counts the number of leading zeros, i.e., the index of the first bit set to 1, in each of the 16 sub-groups of 32 bits. This would allow to par-allelize the code at lines 18-19 of Alg. 2, where the indexes of 16 exit leaves in leafvalues would be computed simul-taneously. Moreover, masked/predicated instructions would allow to more easily pipeline comparision, update and store operations.

Acknowledgements. This work was partially supported by the EC H2020 Program INFRAIA-1-2014-2015 SoBig-Data: Social Mining &amp; Big Data Ecosystem (654024). [1] N. Asadi, J. Lin, and A. P. de Vries. Runtime [2] G. Capannini, C. Lucchese, F. M. Nardini, S. Orlando, [3] J. H. Friedman. Greedy function approximation: a [4] C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, [5] O. Polychroniou, A. Raghavan, and K. A. Ross.
 [6] Q. Wu, C. J. Burges, K. M. Svore, and J. Gao.

