 We propose an integration of term proximity scoring into Okapi BM25. The relative retrieval effectiveness of our re-trieval method, compared to pure BM25, varies from collec-tion to collection. We present an experimental evaluation of our method and show that the gains achieved over BM25 grow as the size of the underlying text collection increases. We also show that for stemmed queries the impact of term proximity scoring is larger than for unstemmed queries. H.2.4 [ Systems ]: Textual databases; H.3.4 [ Systems and Software ]: Performance evaluation Experimentation, Performance Information Retrieval, Query Processing, Term Proximity
Document retrieval functions based on the vector space model, such as Okapi BM25 [2] [3], have been shown to be highly effective in ad-hoc information retrieval tasks. One of their shortcomings is that their bag-of-words approach does not take the proximity of query terms within a doc-ument into account and consequently gives the same score to a document regardless whether the query terms appear close to each other within that document or far apart. This contradicts the intuitive understanding that, in a relevant document, query terms appear relatively close to each other and not in completely unrelated parts of the document.
Rasolofo and Savoy [1] were able to show that integrating term proximity into existing vector space retrieval methods can improve the quality of the search results significantly. While trying to reproduce their results on different text col-lections and to find new ways of integrating term proximity into vector-space-based retrieval functions, we found that term proximity only improves the quality of the search re-sults on some text collections, while it leaves the search sys-tem X  X  retrieval effectiveness unaffected on others, or even causes a slight deterioration. Two of the text collections we used in our experiments were the TREC45-CR collection Collection size (#docs) 528,155 25,205,204 Avg. doc. length (terms) 561 1,721 P@10 (BM25/BM25TP) 0.382/0.381 0.529/0.600 P@20 (BM25/BM25TP) 0.308/0.309 0.494/0.561 Table 1: Collection characteristics and retrieval ef-fectiveness for TREC45-CR and GOV2. Effective-ness for BM25 and BM25TP (BM25 + proximity) was evaluated using 100 topics from the TREC 2003 Robust track (TREC45-CR) and 50 topics from the TREC 2004 Terabyte track (GOV2), respectively. (TREC disks 4&amp;5, without the Congressional Record), con-sisting of 528,000 documents with an average length of 561 tokens, and the GOV2 collection used in the TREC Terabyte track, consisting of 25.2 million documents with an average length of 1,721 tokens. We found that, while the use of term proximity improved the retrieval effectiveness signifi-cantly for GOV2 (paired t-test: p&lt; 0 . 02 for P@10; p&lt; 0 . 01 for P@20), the smaller TREC45-CR collection seemed unim-pressed efforts and did not divulge more relevant documents to our term-proximity-based retrieval method than to plain Okapi BM25 (details in Table 1).

Based on the characteristics of the collections, this lead us to two hypotheses: 1. Term proximity is more important when the search 2. Term proximity becomes more important as the size We performed additional experiments, with the goal of val-idating (or refuting) these two theories. We present an ex-perimental evaluation that supports the second hypothesis. For the first hypothesis, no such support could be found. We also show that term proximity is more important for stemmed queries than for unstemmed queries, an aspect that we had ignored in our initial experiments.
Given a query containing the terms T 1 ,T 2 ,...,T n BM25 relevance score of a document D is: BM25TP, with stemming either turned on or off. where f D,T i is the number of occurrences of the term T i within D , | D | is the length of D (number of terms), avgdl is the average document length in the collection, and w T is T i  X  X  IDF weight: w T i =log N N T number of documents in the text collection, and N T i is the number of documents containing T i .

Our integration of term proximity into the BM25 scoring function is very similar to that presented by Rasolofo and Savoy [1]. For the presentation in this paper, we chose to use our own method instead of theirs, since it produced slightly better results in almost all of our experiments.

Suppose a user submits the query Q = { T 1 ,...,T n } .Then our implementation of BM25 fetches the posting lists for all query terms from the index and arranges them in a prior-ity queue. It then starts consuming postings from all post-ing lists, one posting at a time, in ascending order, to find matching documents and simultaneously compute the rele-vance scores of all matching documents found (document-at-a-time approach). If an index with full positional infor-mation is used, Term proximity can be integrated into this process without much effort. With every query term, we associate an accumulator that contains that term X  X  prox-imity score within the current document. Whenever the search system encounters a posting that belongs to the query term T j , it looks at the previous posting, belonging to the query term T k , and determines the distance (number of post-ings) between the current posting and the previous one. If T = T k ,thenbothterms X  X ccumulatorsareincremented: where w T i is T i  X  X  IDF weight (cf. equation 1). For T T , the accumulators remain unchanged. When the end of the current document is reached, the document X  X  score is computed, and all proximity a ccumulators are reset to zero. The score of a document D is: where k 1 and K are are the same as in the original Okapi equation. The difference to the strategy followed by Ra-solofo and Savoy is that in our approach only neighbor-ing query term X  X  can affect each other X  X  accumulator and that the impact of term proximity on the document score is smaller because the term weight w T is limited to 1.
For our experiments, we split up the GOV2 collection into 100 random chunks, containing 252,000 documents each. From these chunk, we built subcollections containing 10%, 20%, ... , 90% of the documents in the whole collection. For each size, we constructed 20 such subcollections by ran-domly picking an appropriate number of chunks and combin-ing them. We then fed 100 queries from the 2004 and 2005 TREC Terabyte ad-hoc retrieval tasks into our system and executed them using different system configurations (BM25 with or without term proximity; stemming enabled or dis-abled). Note that this is different from our initial experi-ments, where we only used the 50 topics from 2004. The results depicted in Figure 1 represent the mean precision values over all subcollections of the respective size. The fig-ure shows that the relative gain achieved by BM25TP, com-pared to the original BM25, increases as the underlying text collection grows. This observation is true for both P@10 and P@20. It also shows that the relative gain is greater for stemmed queries than for unstemmed queries. We sur-mise that this is because term proximity helps distinguish between stem-equivalent terms that represent the same se-mantic concept and stem-equivalent terms that don X  X . We also performed experiments for subcollections of GOV2 con-taining documents of different average length. However, the results obtained did not indicate any correlation between average document length and the effectiveness of term prox-imity scoring.

Our explanation of the fact that term proximity is more important for bigger text collections is that for larger collec-tions the likelihood of finding non-relevant documents that contain the query terms by chance is greater than for smaller collections. Term proximity, as an additional feature, helps distinguish between these documents and documents that are actually relevant. An important implication of this find-ing is that, although using a document-level index instead of a positional index can reduce both time and space complex-ity greatly when dealing with very large text collections, it is advisable to keep full positional information, as this can significantly increase the system X  X  retrieval effectiveness. [1] Y. Rasolofo and J. Savoy. Term Proximity Scoring for [2] S. E. Robertson, S. Walker, and M. Hancock-Beaulieu. [3] S.E.Robertson,S.Walker,S.Jones,
