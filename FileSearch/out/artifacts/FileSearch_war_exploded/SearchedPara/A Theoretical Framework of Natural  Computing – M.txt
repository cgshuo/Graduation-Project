 phenomenon and the corresponding optimization procedures. In this paper, we propose inspired by the nature. For example, Geneti c algorithm (GA) [1], Ant colony algorithm conditions are satisfied. This framework is very similar to increment learning. However, based on natural computing because (1) human beings lack well understanding to natural phenomenon, (2) those methods are subjectively proposed, and (3) the methods and the algorithms only modify some parameters and then simulate on some given data, objective criteria in judging different optimization methods. We propose a Good Lattice Points method (GAGLP) based on natural computing. Some experiment results are given to illustrate to advantages of the new method. 
This paper is organized as follows. Section 2 comments on current methods of natural computing and points out that it should have criteria to judge advantages and disadvantages for comparing different methods. Section 3 proposes a theoretical model for natural computing and shows the advantage of the proposed new method. A conclusion and suggestion for further research work. (GA), Ant colony algorithm (ACA), Particle swarm optimizer algorithm (PSO) and Immunity algorithm (IA). For Genetic algorithm (GA), An algorithm based on imitating natural evolution procedure is to: 1) Select a subset P1 from universe X; 2) of V 1 by using hormone effected on all nodes; 3) Determine new moving direction set V each point; 3) Determine the new velocity V 2 and obtain  X  X 2 , V2  X  ; 4) Repeat above procedures until the termination conditions are satisfied. Lastly for Immunity corresponding subset (antibody) X 1 according some regulations; 3) When a new 
From the above algorithms we can see that most current methods of natural  X  X ubjectively X  proposed and no criterion is given to judge the advantages and with some examples. efficiency. We have found that discrepancy on number theory is a very useful criterion propose a new method to improve current algorithms such as genetic algorithm. 3.1 The Problem Statement max () fx . We assume that for any () fx and its domain () ux ; it is proportional for Intuitively, for finding the maximum, the probability at the neighbor of a larger object function is bigger than that of a smaller one [16]. may contain the optimal point with the largest possibility is chosen in such a way that probability to choose the optimal point. Now how to define the  X  X ost X  uniform distribution  X  What is the most uniform distribution  X  The answer is the least  X  X iscrepancy X  from the number theory [8]. 3.2 Definition of Di screpancy and Good Latti ce Point with Properties 
Pi in  X  , |  X  | denotes the measure of  X  and () = . Definition 2 [11] : Let = ) is called a good lattice point set and r the good lattice point (GLP) if positive number). (t-dimensional bounded variation functions), then Where () Vf is total value of bounded variable f . with discrepancy not more than () n  X  . Theorem 3[11]: If () fx satisfies given n points with any weighted approximates the integral of f on t G . Remark 1. Theorem 3 shows why good lattice points are defined because it is discrepancy of GLP is 1 () On  X   X + , so it is reasonable to define the GLP set, where  X  is an arbitrary small positive number. the number of points n but not on dimension t of the space. That is why it will give a very useful algorithm for solving the high dimensional problem. That means our algorithm is dimensional independent to problem solving. Remark 3 . From theorems 1, 2 and 3, we can see that it will be the best method for the n points chosen in a GLP way, if the linear combination of function f approximates the integral f on t G . Remark 4: Theorem 4 shows that if we know nothing about a problem and choose an discrepancy is much smaller for point set chosen in a GLP way than for which chosen randomly. That is the theoretical reason why an algorithm with GLP method converges much faster! 3.3 Estimation for Distribution of Object Function However, for a domain X if point sets are not uniformly distributed, we can define good lattice point sets (GLP sets) as follows.  X  =  X  =  X  X  X  X  then () discrepancy () n  X  for (,()) t Gpx . 
Let probability density of t G be: () ( ), ( ,..., ) ii t the measurement in cuboids [0, ] i i x space t G with measurement () px . = in lattice point set for (,()) t Gpx . uniformly distributed, then the physical meaning of discrepancy is the same as in the case of uniform distribution. By choosing 2cos2 / ,1 , k rkpkt  X  = X  X  X   X  X  X  where p is the smallest prime number satisfying (3)/2 pt  X  X  X  , then r is a GLP set, or denotes the fractional part of x and we have Theorem 5: Let cuboids t G be of density distribution () ( ) ii smallest prime number which satisfies inequality (3)/2 pt  X  X  X  , then with (,()) t Gpx . satisfies  X  X   X   X  X  X   X   X + = X = = X  X  X  X  and hence for (,()) t Gpx . This completes the proof. components of x  X  ** * { (1), (2),..., ( )} jj j xx xn in a rising order. Let And let ( (0), (0)) (0, 0), ( ( 1), ( 1)) (1,1) ab an bn =++= . () px empirical estimation distribution of 3.4 Construction of GLP Set Property 1. Choose 2cos(2 / ) ,1 , k rkpktp  X  = X  X  X   X  X  X  is the smallest prime satisfying (3)/2 pt  X  X  X  , then denotes the fractional part of x . 
For example, let t =12, from (3)/2 pt  X  X  X  , we can know that p = 29, then rk kt  X  = X  X  X   X  X  X  from Property 1, or ,1 k Property 2. 3.5 A Model of New Computing Method Inspired by the Nature provided, then it is hard for us to find optimal value for () fx . So it is necessary for us to give some assumption for distribution of () fx . Assumption 1: For t xG  X  X   X  and a neighborhood of () ux  X  then probability of () fx in () ux is proportional to that of () fx in () ux . 
Now we can estimate empirical estimation distribution of object function () fx according to object function values on some subset of t G . Remark 6 . The most important step of the above algorithm is in step 4). How to find not consider discrepancy when choosing the next generation point set 2 P . We applying discrepancy on number theory and hence it can guarantee point set 2 P to be chosen in a  X  X est X  way and the algorithm converges much faster. Another advantage parameters is to be optimized. In this case we regard these parameters as the point set solving. In the next section we will show some examples using the above algorithm. (GA) which is mainly changed on the cross-over operator to produce the next generation and to apply some optimization problems such as standard function optimization, TSP, SAT and knapsack problem. The method is as the following. 
Let A 1 , A 2 be two individuals produced by standard GA, revise crossover operator (12/16,10/16,13/16)  X  (3/4,5/8,13/16), which is a point in 3 -dimensional cuboids. denotes the fractional part of a [11]. Let the k -th chromosome of the generations of n after cross-over operator be In this way, we produce the generations of n after crossover operator, and then select operator. 
The construction of GLP set in the situation of nonuniformly distribution is almost the same as in the case of uniformly distribution. Now we can show some experiment results in the following subsections. 
The following examples are chosen from [18] which are somewhat difficult to find discontinued in their domain. We wish to find the maximum for: 1. max f 1 (x)  X  where b We find the maximum of functions by Good Lattice Point Genetic Algorithm (GAGLP) with fitness function f (x) g (x)+C, such that f (x)&gt;0. We found that the Genetic Algorithm (GA). The results are shown in Table 1. function Average f 1 5 x = (5.11, 5.03, 5.01, 5.11, 5.08) f * = 25 f 2 10 x = (-0.6667, 1.9995) f * = 509084.2342 f 3 8 x = (9.976196, 9.180981) f * = 171.3242 f
We also worked TSP on 144 cities in China with GAGLP with the result postgraduate students[17] worked on knapsack problem with GAGLP and found that GAGLP is much better than GA on the accuracy of solutions, and the speed of finding the optimal solutions. We guess that might be the best solution to the problem. solving by using a good lattice point (GLP) set method from the number theory. The advantage of our new method is that (1) the discrepancy of GLP set is minimized of some other computing methods inspired by the nature. 
For future work we will use our new model to deal with some other computing protein forecasting and some other NP-hard problems. Cheng, W.L. Wu and W. Li for the program to calculate some numerical examples. 
