 University of Dundee, Dundee, Scotland, UK Emilio Jes  X  us Gallego Arias EMILIOGA @ CIS . UPENN . EDU University of Pennsylvania, Philadelphia, USA Privacy is becoming a paramount concern for ma-chine learning and data analysis tasks, which often operate on personal data. For just one example of the tension between machine learning and data privacy, Netflix released an anonymized dataset of user movie ratings for teams competing to develop an improved recommendation mechanism. The competition was a great success (the winning team improved on the ex-isting recommendation system by more than 10% ), but the ad hoc anonymization was not as successful: Narayanan &amp; Shmatikov (2008) were later able to re-identify individuals in the dataset, leading to a lawsuit and the cancellation of subsequent competitions. Differentially private query release is an attempt to solve this problem. Differential privacy is a strong for-mal privacy guarantee (that, among other things, prov-ably prevents re-identification attacks), and the prob-lem of query release is to release accurate answers to a set of statistical queries. As observed early on by Blum et al. (2005), performing private query release is sufficient to simulate any learning algorithm in the statistical query model of Kearns (1998).
 Since then, the query release problem has been ex-tensively studied in the differential privacy literature. While simple perturbation can be used to privately an-swer a small number of queries (Dwork et al., 2006), more sophisticated approaches can accurately answer nearly exponentially many queries in the size of the private database (Blum et al., 2013; Dwork et al., 2009; 2010; Roth &amp; Roughgarden; Hardt &amp; Roth-blum, 2010; Gupta et al., 2012; Hardt et al., 2012). A natural approach, employed by many of these al-gorithms, is to answer queries by generating synthetic data : a safe version of the dataset that approximates the real dataset on every statistical query of interest. Unfortunately, even the most efficient approaches for query release have a per-query running time linear in the size of the data universe , which is exponential in the dimension of the data (Hardt &amp; Rothblum, 2010). Moreover, this running time is necessary in the worst case (Ullman, 2013), especially if the algorithm pro-duces synthetic data (Ullman &amp; Vadhan, 2011). This exponential runtime has hampered practical eval-uation of query release algorithms. One notable ex-ception is due to Hardt et al. (2012), who perform a thorough experimental evaluation of one such al-gorithm, which they called MWEM . They find that MWEM has quite good accuracy in practice and scales to higher dimensional data than suggested by a the-oretical (worst-case) analysis. Nevertheless, running time remains a problem, and the approach does not seem to scale to high dimensional data (with more than 30 or so attributes for general queries, and more when the queries satisfy special structure 2 ). The crit-ical bottleneck is the size of the state maintained by the algorithm: MWEM , like many query release al-gorithms, needs to manipulate an object that has size linear in the size of the data universe (i.e., exponential in the dimension). This quickly becomes impractical as the record space grows more complex.
 We present DualQuery , an alternative algorithm which is dual to MWEM in a sense that we will make precise. Rather than manipulating an object of exponential size, DualQuery solves a concisely rep-resented (but NP-hard) optimization problem. Criti-cally, the optimization step does not require a solution that is private or exact, so it can be handled by exist-ing, highly optimized solvers. Except for this step, all parts of our algorithm are extremely efficient. As a re-sult, DualQuery requires (worst-case) space and (in practice) time only linear in the number of queries of interest, which is often significantly smaller than the number of possible records. Like existing algorithms for query release, DualQuery has a provable accuracy guarantee and satisfies the strong differential privacy guarantee.
 We evaluate DualQuery on a variety of datasets by re-leasing 3-way marginals (also known as conjunctions or contingency tables ), demonstrating that it solves the query release problem accurately and efficiently even when the data includes hundreds of thousands of fea-tures. We know of no other algorithm to perform ac-curate, private query release for rich classes of queries on real data with more than even 100 features. Related work. Differentially private learning has been studied since Blum et al. (2005) showed how to convert learning algorithms in the SQ model of Kearns (1998) into differentially private learning algo-rithms with similar accuracy guarantees. Since then, private machine learning has become a very active field with both foundational sample complexity re-sults (Kasiviswanathan et al., 2011; Chaudhuri &amp; Hsu, 2011; Beimel et al., 2013; Duchi et al., 2013) and numerous efficient algorithms for particular learning problems (Chaudhuri &amp; Monteleoni, 2008; Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012; Chaudhuri et al., 2012; Thakurta &amp; Smith, 2013). In parallel, there has been a significant amount of work on privately releasing synthetic data based on a true dataset while preserving the answers to large numbers of statistical queries (Blum et al., 2013; Dwork et al., 2009; Roth &amp; Roughgarden; Dwork et al., 2010; Hardt &amp; Rothblum, 2010; Gupta et al., 2012). These results are extremely strong in an in-formation theoretic sense: they ensure the consistency of the synthetic data with respect to an exponentially large family of statistics. But, all of these algorithms (including the notable multiplicative weights algo-rithm of Hardt &amp; Rothblum (2010), which achieves the theoretically optimal accuracy and runtime) have running time exponential in the dimension of the data. With standard cryptographic assumptions, this is nec-essary in the worst case for mechanisms that answer arbitrary statistical queries (Ullman, 2013). Nevertheless, there have been some experimental evaluations of these approaches on real datasets. Most related to our work is the evaluation of the MWEM mechanism by Hardt et al. (2012), which is based on the private multiplicative weights mechanism (Hardt &amp; Rothblum, 2010). This algorithm is inefficient (it manipulates a probability distribution over a set expo-nentially large in the dimension of the data space) but with some heuristic optimizations, Hardt et al. (2012) were able to implement the multiplicative weights al-gorithm on several real datasets with up to 77 at-tributes (and even more when the queries are restricted to take positive values only on a small number of dis-joint groups of features). However, it seems difficult to scale this approach to higher dimensional data. Another family of query release algorithms are based on the Matrix Mechanism (Li et al., 2010; Li &amp; Miklau, 2012). The runtime guarantees of the matrix mechanism are similar to the approaches based on multiplicative weights X  X he algorithm manipulates a  X  X atrix X  of queries with dimension exponential in the number of features. Yaroslavtsev et al. (2013) evalu-ate an approach based on this family of algorithms on low dimensional datasets, but scaling to high dimen-sional data also seems challenging. A recent work by Zhang et al. (2014) proposes a low-dimensional ap-proximation for high-dimensional data distribution by privately constructing Bayesian networks, and shows that such a representation gives good accuracy on some real datasets.
 Our algorithm is inspired by the view of the syn-thetic data generation problem as a zero-sum game, first proposed by Hsu et al. (2013). In this interpre-tation, Hardt et al. (2012) solves the game by hav-ing a data player use a no-regret learning algorithm, while the query player repeatedly best responds by optimizing over queries. In contrast, our algorithm swaps the roles of the two players: the query player now uses the no-regret learning algorithm, whereas the data player now finds best responses by solving an optimization problem. This is reminiscent of  X  X oost-ing for queries, X  proposed by Dwork et al. (2010); the main difference is that our optimization problem is over single records rather than sets of records. As a result, our optimization can be handled non-privately. Differential privacy has become a standard algorith-mic notion for protecting the privacy of individual records in a statistical database. It formalizes the re-quirement that the addition or removal of a data record does not change the probability of any outcome of the mechanism by much.
 To begin, databases are multisets of elements from an abstract domain X , representing the set of all pos-sible data records. Two databases D,D 0  X  X are neighboring if they differ in a single data element ( k D 4 D 0 k X  1 ).
 Definition 2.1 (Dwork et al. (2006)) . A mechanism M : X n  X  R satisfies (  X , X  ) -differential privacy if for every S  X  R and for all neighboring databases D,D 0  X  X  n , the following holds: Definition 2.2. For any predicate  X  : X  X  X  0 , 1 } , the linear query Q  X  : X n  X  [0 , 1] is defined by We will use a fundamental tool for private data analy-sis: we can bound the privacy cost of an algorithm as a function of the privacy costs of its subcomponents. Lemma 2.3 (Dwork et al. (2010)) . Let M 1 ,...,M k be such that each M i is (  X  i , 0) -private with  X  i  X  . Then M ( D ) = ( M 1 ( D ) ,...,M k ( D )) is (  X , 0) -private for  X  = P k i =1  X  i , and (  X , X  ) -private for for any  X   X  (0 , 1) . The analysis of our algorithm relies on the interpreta-tion of query release as a two player, zero-sum game (Hsu et al., 2013). In the present section, we review this idea and related tools.
 Game definition. Suppose we want to answer a set of queries Q . For each query q  X  Q , we can form the negated query q , which takes values q ( D ) = 1  X  q ( D ) for every database D . For the remainder, we will assume that Q is closed under negation; if not, we may add negated copies of each query to Q . Let there be two players, whom we call the data player and query player. The data player has action set equal to the data universe X , while the query player has ac-tion set equal to the query class Q . Given a play x  X  X  and q  X  X  , we let the payoff be where D is the true database. As a zero sum game, the data player will try to minimize the payoff, while the query player will try to maximize the payoff. Equilibrium of the game. Let  X ( X ) and  X ( Q ) be the set of probability distributions over X and Q . We consider how well each player can do if they random-ize over their actions, i.e., if they play from a probabil-ity distribution over their actions. By von Neumann X  X  minimax theorem, min for any two player zero-sum game, where is the expected payoff. The common value is called the value of the game , which we denote by v A . This suggests that each player can play an optimal strategy, assuming best play from the opponent X  X his is the notion of equilibrium strategies, which we now define. We will soon interpret these strategies as solu-tions to the query release problem.
 Definition 3.1. Let  X  &gt; 0 . Let A be the payoffs for a two player, zero-sum game with action sets X , Q . Then, a pair of strategies u  X   X   X ( X ) and w  X   X   X ( Q ) form an  X  -approximate mixed Nash equilibrium if for every strategy u  X   X ( X ) ,w  X   X ( Q ) .
 If the true database D is normalized to be a distribu-tion b D in  X ( X ) , then b D always has zero payoff: Hence, the value of the game v A is at most 0 . Also, for any data strategy u , the payoff of query q is the negated payoff of the negated query q : which is A ( u, q ) . Thus, any query strategy that places equal weight on q and q has expected payoff zero, so v A is at least 0 . Hence, v A = 0 .
 Now, let ( u  X  ,w  X  ) be an  X  -approximate equilibrium. Suppose that the data player plays u  X  , while the query player always plays query q . By the equilibrium guar-antee, we then have A ( u  X  ,q )  X   X  , but the expected payoff on the left is simply q ( D )  X  q ( u  X  ) . Likewise, if the query player plays the negated query q , then so q ( D )  X  q ( u  X  )  X  X  X   X  . Hence for every query q  X  X  , we know | q ( u  X  )  X  q ( D ) |  X   X  . This is precisely what we need for query release: we just need to privately calculate an approximate equilibrium.
 Solving the game. To construct the approximate equilibrium, we will use the multiplicative weights update algorithm (MW). This algorithm maintains a distribution over actions (initially uniform) over a se-ries of steps. At each step, the MW algorithm receives a (possibly adversarial) loss for each action. Then, MW reweights the distribution to favor actions with less loss. The algorithm can be found in the full ver-sion of this paper.
 For our purposes, the most important application of MW is to solving zero-sum games. Freund &amp; Schapire (1996) showed that if one player maintains a distribu-tion over actions using MW, while the other player selects a best-response action versus the current MW distribution (i.e., an action that maximizes his ex-pected payoff), the average MW distribution and em-pirical best-response distributions will converge to an approximate equilibrium rapidly.
 Theorem 3.2 (Freund &amp; Schapire (1996)) . Let  X  &gt; 0 , and let A ( i,j )  X  [  X  1 , 1] m  X  n be the payoff matrix for a zero-sum game. Suppose the first player uses mul-tiplicative weights over their actions to play distribu-tions p 1 ,...,p T , while the second player plays (  X / 2) -approximate best responses x 1 ,...,x T , i.e., Setting T = 16 log n/ X  2 and  X  =  X / 4 in the MW algorithm, the empirical distributions form an  X  -approximate mixed Nash equilibrium. By the game interpretation, the algorithm of Hardt &amp; Rothblum (2010) (and the MWEM algorithm of Hardt et al. (2012)) uses MW for the data player, while the query player plays best responses. For privacy, their algorithm selects the query best-responses privately via the exponential mechanism of McSherry &amp; Tal-war (2007). Our algorithm simply reverses the roles. While MWEM uses a no-regret algorithm to main-tain the data player X  X  distribution, we will instead use a no-regret algorithm for the query player X  X  distribu-tion. Likewise, instead of finding a maximum payoff query at each round, our algorithm selects a minimum payoff record at each turn. The full algorithm can be found in Algorithm 1.
 Our privacy argument differs slightly from the analy-sis for MWEM . There, the data distribution is public, and finding a query with high error requires access to the private data. Our algorithm instead maintains a distribution Q over queries which depends directly on the private data, so we cannot use Q directly. In-stead, we argue that queries sampled from Q are pri-vacy preserving. Then, we can use a non-private opti-mization method to find a minimal error record versus queries sampled from Q . We then trade off privacy (which degrades as we take more samples) with accu-racy (which improves as we take more samples, since the distribution of sampled queries converges to Q ). Given known hardness results for the query release problem (Ullman, 2013), our algorithm must have worst-case runtime polynomial in the universe size |X| , so is not theoretically more efficient than prior approaches. In fact, even compared to prior work on query release (e.g., Hardt &amp; Rothblum (2010)), our algorithm has a weaker accuracy guarantee. However, our approach has an important practical benefit: the computationally hard step can be handled with stan-dard, non-private solvers.
 The iterative structure of our algorithm, combined with our use of constraint solvers, also allows for sev-eral heuristics improvements. For instance, we may run for fewer iterations than predicted by theory. Or, if the optimization problem turns out to be hard (even in practice), we can stop the solver early at a subop-timal (but often still good) solution. These heuristic tweaks can improve accuracy beyond what is guaran-teed by our accuracy theorem, while always maintain-ing a strong provable privacy guarantee.
 Algorithm 1 DualQuery
Input: Database D  X  R |X| (normalized) and linear queries q 1 ,...,q k  X  X  0 , 1 } |X| .

Initialize: Let Q = S k j =1 q j  X  q j , Q 1 uniform dis-tribution on Q ,
T = For t = 1 ,...,T : Output synthetic database b D := S T t =1 x t . Privacy. The privacy proofs are largely routine, based on the composition theorems. Rather than fix-ing  X  and solving for the other parameters, we present the privacy cost  X  as function of parameters T,s, X  . Later, we will tune these parameters for our experi-mental evaluation. DualQuery satisfies the following privacy guarantee. (All proofs can be found in the full version of this paper (Gaboardi et al., 2014).) Theorem 4.1. Let  X   X  (0 , 1) . Algorithm 1 is (  X , X  ) -private for Accuracy. We show accuracy in two steps. First, we show that the  X  X verage query X  formed from the sam-ples is close to the average query weighted by Q t Next, we show that our algorithm finds an approxi-mate equilibrium of the query release game.
 Theorem 4.2. With probability at least 1  X   X  , DualQuery finds a synthetic database that answers all queries in Q within additive error  X  .
 Remark 4.3. The guarantee in Theorem 4.2 may seem a little unusual, since the convention in the literature is to treat  X , X  as inputs to the algorithm. We can do the same: from Theorem 4.1 and plugging in for T, X ,s ,  X  = O for  X  &lt;  X /T . In our algorithm, the computationally difficult step is finding the data player X  X  approximate best response against the query player X  X  distribution. As mentioned above, the form of this problem depends on the partic-ular query class Q . In this section, we first discuss the optimization problem in general, and then specifically for the well-studied class of marginal queries Thaler et al. (2012); Gupta et al. (2013); Dwork et al. (2014). For instance, in a database of medical information in binary attributes, a particular marginal query may be: What fraction of the patients are over 50, smoke, and exercise? The best-response problem. Recall that the query release game has payoff A ( x,q ) defined by Equa-tion (1); the data player tries to minimize the pay-off, while the query player tries to maximize it. If the query player has distribution Q t over queries, the data player X  X  best response minimizes the expected loss: To ensure privacy, the data player actually plays against the distribution of samples the database D is fixed and best-response problem is argmin 3-way marginal queries. To look at the precise form of the best-response problem, we consider 3-way marginal queries. We think of records as having d bi-nary attributes, so that the data universe |X| is all bit-strings of length d . We write x i for x  X  X  to mean the i th bit of record x .
 Definition 5.1. Let X = { 0 , 1 } d . A 3-way marginal query is a linear query specified by 3 integers a 6 = b 6 = c  X  [ d ] , taking values Recall that the query class Q includes each query and its negation. So, we also have negated conjunctions: Given sampled conjunctions { junctions { In other words, this is a MAXCSP problem X  X e can associate a clause to each conjunction: q abc  X  ( x a  X  x b  X  x c ) and q abc  X  ( x a  X  x b  X  x c ) , and we want to find x  X  { 0 , 1 } d satisfying as many clauses as possible.
 Since most solvers do not directly handle MAXCSP problems, we convert this optimization problem into a more standard, integer program form. We introduce a variable x i for each literal x i , a variable c i for each sampled conjunction pled negated conjunction ing integer program. max X with  X  Note that x i , 1  X  x i corresponds to the literals x i , x and c i = 1 , d i = 1 exactly when their respective clauses are satisfied. Thus, the objective is the number of satisfied clauses. The resulting integer program can be solved using any standard solver; we use CPLEX . Dataset Size Attributes Binary attributes Adult 30162 14 235 KDD99 494021 41 396 Netflix 480189 17,770 17,770 We evaluate DualQuery on a large collection of 3 -way marginal queries on several real datasets (Fig-ure 1) and high dimensional synthetic data. Adult and KDD99 are from the UCI repository (Bache &amp; Lich-man, 2013), and have a mixture of discrete (but non-binary) and continuous attributes, which we discretize into binary attributes. We also use the (in)famous Net-flix movie ratings dataset, with more than 17,000 bi-nary attributes.
 Rather than set the parameters as in Algorithm 1, we experiment with a range of parameters. For instance, we frequently run for fewer rounds (lower T ) and take fewer samples (lower s ). As such, the accuracy guar-antee (Theorem 4.2) need not hold for our parameters. However, we find that our algorithm gives good error, often much better than predicted. In all cases, our pa-rameters satisfy the privacy guarantee Theorem 4.1. Accuracy. We evaluate the accuracy of the algo-rithm on 500 , 000 3 -way marginals on Adult, KDD99 and Netflix. We report maximum error in Figure 2, averaged over 5 runs. (Marginal queries have range differentially private, with  X  ranging from 0 . 25 to 5 . Scaling to More Queries. Next, we evaluate accu-racy and runtime when varying the number of queries. We use a set of 40 , 000 to 2 million randomly gen-erated marginals Q on the KDD99 dataset and run DualQuery with (1 , 0 . 001) -privacy. As shown in Fig-ure 3, both average and max error remain mostly stable, demonstrating improved error compared to simpler perturbation approaches. For example, the Laplace mechanism X  X  error growth rate is O ( p |Q| ) under (  X , X  ) -differential privacy.
 Scaling to Higher Dimensional Data. Finally, we evaluate accuracy and runtime behavior for data di-mension ranging from 50 to 512 , 000 . We evaluate DualQuery under (1 , 0 . 001) -privacy on 100 , 000 3 -way marginals on synthetically genearted datasets. We report runtime, max, and average error over 3 runs in Figure 4; note the logarithmic scale for attributes axis. We do not include query evaluation in our time measurements X  X his overhead is common to all ap-proaches that answer a set of queries.
 When generating the synthetic data, one possibility is to set each attribute to be 0 or 1 uniformly at random. However, this generates very uniform synthetic data: a record satisfies any 3 -way marginal with probability 1 / 8 , so most marginals will have value near 1 / 8 . To generate more challenging and realistic data, we pick a separate bias p i  X  [0 , 1] uniformly at random for each attribute i . For each data point, we then set at-tribute i to be 1 independently with probability equal to p i . As a result, different 3 -way marginals have dif-ferent answers on our synthetic data.
 Implementation details. The implementation is written in OCaml, using the CPLEX constraint solver. We ran the experiments on a mid-range desktop ma-chine with a 4-core Intel Xeon processor and 12 Gb of RAM. Heuristically, we set a timeout for each CPLEX call to 20 seconds, accepting the best cur-rent solution if we hit the timeout. For the experiments shown, the timeout was rarely reached.
 Data discretization. We discretize KDD99 and Adult datasets into binary attributes by mapping each possible value of a discrete attribute to a new bi-nary feature. We bucket continuous attributes, map-ping each bucket to a new binary feature. We also ensure that our randomly generated 3 -way marginal queries are sensible (i.e., they don X  X  require an origi-nal attribute to take two different values).
 Setting free attributes. Since the collection of sam-pled queries may not involve all of the attributes, CPLEX often finds solutions that leave some at-tributes unspecified. We set these free attributes heuristically: for real data, we set the attributes to 0 as these datasets are fairly sparse; for synthetic data, we set attributes to 0 or 1 uniformly at random. Parameter tuning. DualQuery has three parame-ters that can be set in a wide variety of configurations without altering the privacy guarantee (Theorem 4.1): number of iterations ( T ), number of samples ( s ), and learning rate (  X  ), which controls how aggressively to update the distribution. For a fixed level of  X  and  X  , there are many feasible private parameter settings. Performance depends strongly on the choice of pa-rameters: T has an obvious impact, increasing s in-creases the number of constraints in the integer pro-gram for CPLEX . We have investigated a range of parameters; for the experiments we have used some informal heuristics coming from our observations (pa-rameters details deferred to our full version). Parameter setting should be done under differential privacy for a truly realistic evaluation. Overall, we do not know of a principled approach to handle this issue; private parameter tuning is an area of active research (see e.g., Chaudhuri &amp; Vinterbo (2013)). We have given a new private query release mechanism that can handle datasets with dimensionality multiple orders of magnitude larger than what was previously possible. Indeed, it seems we have not reached the limits of our approach X  X ven on synthetic data with more than 500 , 000 attributes, DualQuery continues to generate useful answers with about 30 minutes of overhead on top of query evaluation (which by itself is on the scale of hours). We believe that DualQuery makes private analysis of high dimensional data prac-tical for the first time.
 However, this remarkable improvement in running time is not free: our theoretical accuracy bounds are worse than those of previous approaches (Hardt &amp; Rothblum, 2010; Hardt et al., 2012). For low dimen-sional datasets for which it is possible to maintain a distribution over records, the MWEM algorithm of Hardt et al. (2012) likely remains the state of the art (for an experimental comparison, see our full version of the paper). Our work complements MWEM by al-lowing private data analysis on higher-dimensional data sets.
 Acknowledgments We thank Adam Smith, Cynthia Dwork and Ilya Mironov for productive discussions, and for suggest-ing the Netflix dataset. This work was supported in part by NSF grants CCF-1101389 and CNS-1065060. Marco Gaboardi has been supported by the Euro-pean Community X  X  Seventh Framework Programme FP7/2007-2013 under grant agreement No. 272487.
