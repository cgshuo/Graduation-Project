 Social networks facilitate a variety of social, economic, and political interactions. Homophily and social influence sug-gest that preferences (e.g., over products, services, political parties) are likely to be correlated among people whom di-rectly interact in a social network. We develop a model, preference-oriented social networks , that captures such cor-relations of individual preferences, where preferences take the form of rankings over a set of options. We develop prob-abilistic inference methods for predicting individual prefer-ences given observed social connections and partial observa-tions of the preferences of others in the network. We exploit these predictions in a social choice context to make group decisions or recommendations even when the preferences of some group members are unobserved. Experiments demon-strate the effectiveness of our algorithms and the improve-ments made possible by accounting for social ties.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information filtering, Retrieval models, Selection process Algorithms, Experimentation, Measurement Group recommendation; social networks; preferences; prob-abilistic models; probabilistic inference
Social networks play a crucial role in many social and economic interactions [17], including discovery of job oppor-tunities [15], the products we consume [13], or even weight  X  Currently on leave at Google, Inc. Mountain View.
 c  X  gain [10]. Due to such factors, it is widely recognized that individuals X  behaviors and preferences are correlated with those of their friends or connections (e.g., music tastes [21]).
Because of this, and increasing availability of user prefer-ence and behavioral data, it is essential to study the inter-play of social network structure and individual behaviour, attitudes, and preferences. This has lead to research fo-cused on inferring individual attributes and behaviour us-ing social connections, e.g., inference of ratings over items [23, 24, 18], latent group membership [19], or latent  X  X o-cial positions X  [16]. Yet surprisingly, using social networks to infer individual preferences X  X n the form of rankings of alternatives X  X as received little attention. Methods for in-ference and learning of preference rankings are studied in econometrics, psychometrics, statistics, and machine learn-ing and data mining; in the latter case, they find application to recommender systems, information retrieval and group decision/recommendation problems (i.e., social choice), es-pecially when faced with partial information. In contrast to cardinal utilities, preference rankings (or ordinal prefer-ences) are of special interest in social choice and group rec-ommendation, since they help circumvent, to some extent, the problem of interpersonal comparisons of utilities [2, 36].
In this work, we address how to use social network struc-ture to support more accurate inference of preference rank-ings and to make group decisions when some individual preferences are unknown. Specifically, we exploit the fact that homophily or social selection  X  X ssociation with simi-lar individuals X  X nd social influence  X  X doption of proper-ties and attitudes of those to whom one is connected X  X an be used to infer individual preferences more efficiently and with less data. This can in turn support more accurate group decision making with partial preferences.

To capture correlations of preference rankings over social networks, we introduce preference-oriented social networks (POSNs) , a generative model in which the similarity of the preference rankings of two individuals determines the odds with which they are connected. We exploit this model to in-fer unobserved individual preferences given observed prefer-ences of others in the network. Intuitively, if we know some-thing about the preferences of an individual X  X  friends, fam-ily or colleagues X  X r their friends, etc. X  X e should be able to more accurately predict their preference ranking if ho-mophily or social influence shapes network dynamics. More-over, we demonstrate how network structure, by allowing such predictions, can be used to support effective group rec-ommendations/decisions with incomplete preferences.
We start by outlining our basic model (we contrast it with existing network generation models in Sec. 3). A preference-oriented social network (POSN) consists of: (i) a social net-work, where nodes represent individuals, and edges repre-sent some social relationship; and (ii) a finite set of options over which individuals have preferences, where these prefer-ences take the form of an ordering or ranking. The model also includes a probabilistic generative process used to gen-erate individual preferences and connections that induce cor-related preferences.

The network in a POSN is an undirected graph G = ( N ,E ) over individuals N = { 1 ,...,n } . We use a binary ad-jacency matrix [ e ij ] where e ij = 1 iff ( i,j )  X  E . We assume a finite set of alternatives (or options) A = { a 1 ,...,a e.g., a set of products, political candidates, policies, genre of movies, etc. over which individuals have preferences. The preference of node i is a ranking (or strict total order) r over A . Let  X ( A ) denote the set of all m ! rankings over A .
The generative process for POSNs has two stages: first, in-dividual preferences are drawn from a ranking distribution; then individuals form connections with a probability increas-ing with the similarity of their preferences. Each node i  X  X  preference ranking r i is drawn independently from some dis-tribution  X  ( r |  X  ) over  X ( A ) with parameters  X  . Many rank-ing distributions can be used, e.g., Plackett-Luce, Bradley-Terry, etc. [25]. Here, we focus on the Mallows  X  -model , characterized by a  X  X odal X  reference ranking  X  and a disper-sion parameter  X   X  [0 , 1), with the probability of a ranking r decreasing exponentially with its  X  -distance from  X  : where d  X  ( r, X  ) is Kendall X  X   X  distance between r and  X  (see below) and z (  X  ) is a normalization constant.

To compute connection probabilities, we define the simi-larity of two rankings using the  X  metric, frequently used in psychometrics and social choice: Intuitively, d  X  ( r i ,r j ) measures the number of pairwise swaps needed to transform r i to r j . 1 A strictly decreasing connec-tion probability function c ( d ) : [0 ,  X  )  X  [0 , 1] specifies the probability that two nodes i,j are connected given the dis-tance d  X  ( r i ,r j ) between their corresponding rankings. We use the following connection function [38]: Here  X  controls average node degree and  X  &gt; 1 determines the extent of homophily (greater  X  implies more homophily). We use  X   X  (0 , 1] to control the odds of connecting nodes with the same ranking (accounting for the discrete nature of ranking space). We sometimes write the connection prob-ability as c ( r i ,r j ). Denote the parameters of c by  X  = (  X , X , X  ); the parameters of the ranking distribution by  X  = (  X , X  ); and all POSN parameters by  X  = (  X  ,  X  ). Fig.1 il-lustrates a small POSN, where individuals have preferences over three options; nodes with similar preferences are more
Other distance metrics for rankings can be used as well, e.g., Spearman X  X  rho or footrule, or Hamming distance. densely connected. Our POSN model is an instance of a more general notion of a ranking network , a latent space network model (see Sec. 3), in which latent attributes are generic rankings over options. We analyze general topolog-ical properties of this model in [33]; here we focus directly on inference and group recommendation.
We now address two tightly connected problems, prefer-ence inference and single-option group recommendation (or consensus decision making). While preference inference is interesting in its own right, it plays a vital role in group recommendation when preferences of some group members are unobserved. We assume that individuals are partitioned into two sets: O  X  N , whose complete preference rankings are observed (e.g., elicited or otherwise revealed); and U = N \ O , whose preferences are unknown or  X  X issing. X  Let R O = { r i | i  X  O } be the set of observed rankings and R U = { r i | i  X  U } be the set of random variables associated with unknown pref-erences. In this work, we assume that the network G and model parameters  X  are known. Learning model parameters given observed preferences is an important problem (and the subject of ongoing research); but learning can exploit our so-lution to the inference problem (e.g., when using EM).
Our goal in preference inference is to compute the poste-rior distribution over unobserved preferences Pr( R U | G,R given observed preferences R O . We discuss sampling meth-ods for approximating the posterior distribution in Sec. 5. Other inference problems include the most probable expla-nation (MPE) , i.e., finding the instantiation of R maximizes the posterior: We may also be interested in the posterior over the prefer-ences of a single individual i  X  U : and as well as the  X  X ndividual MPE: X 
A key goal in this work is to exploit social network struc-ture to make higher quality group decisions with incomplete preference information. Suppose we need to select an option from A for a group or  X  X ubpopulation X  S  X  N using some preference aggregation method (i.e., a social choice function , for example, a voting rule). We distinguish the subsegment S (e.g., friends planning an activity, the electorate in a small district) from the larger society N (e.g., users of an online social network, eligible voters in a country): while many group decisions are local, they can be supported by knowl-edge of the preferences of individuals outside that group. We focus on the choice of a single option with an emphasis on  X  X ocial welfare maximization X  relative to a scoring rule g : ( N , N )  X  R + where g ( k,m ) is the positional score of an option ranked k th relative to m options (the Borda and plurality score are common examples, we define Borda in Sec. 6). Define the social welfare of a  X  X  : with the goal of selecting a  X   X  X  that maximizes sw ( ., S ).
In general, we will not know the preferences of all individ-uals in S , requiring that we infer the social welfare of an op-tion a given the observations at hand. Define sw ( a, S| R to be this inferred social welfare , which varies depending on the method of inference (we sometimes omit mention of G and  X  ). Assuming each individual X  X  contribution to social welfare is independent, it can be decomposed into a revealed component sw rev ( a,R O S ) (corresponding to observed prefer-ences) and an inferred component sw inf ( a,R U S | R O ) (for un-observed preferences): The revealed component is straightforward: But there are various ways to define the inferred component. Expected Score (ES). The most natural, principled way to define inferred component is the expected score : which can be computed in O ( m ! | U S | | U S | ) time (where U those individuals with unobserved preferences). If Pr( r i is pre-computed for each i  X  U S , we can write which can be computed in O ( m ! | U S | ) time.
 Joint Most Probable Explanation Score (JMPES). This uses the unobserved preferences, R MPE , which maxi-mizes the joint posterior Pr( R U | G,R O ,  X  ): It can be computed in O ( | U S | ) time if R MPE is given. Individual Most Probable Explanation Score (IM-PES). This uses the instantiation r MPE j for each j  X  U that maximizes the posterior Pr( r j | G,R O ,  X  ):
It is computable in O ( | U S | ) time if the r MPE j are given.
We review the related work on group recommendation, network formation models, nodal attribute inference, prefer-ence ranking learning, collaborative filtering methods using social networks, and decision making on social networks. Group Recommendation. Group recommendation can be broadly categorized as follows: (i) Virtual/artificial pro-file methods (see, e.g., [29]), where joint artificial user pro-files for each group of users are created to keep track of their joint revealed/elicited preferences; (ii) Profile-merging methods (see, e.g., [42, 5]), which merge group member pro-files to form a group profile, based on which recommenda-tions are made; (iii) Recommendation/scoring aggregation methods (see, e.g., [27, 3, 1, 35, 12]), which aggregate the recommendations (or inferred preferences) for each group member into single group recommendation list (or recom-mended option). This aggregation is usually conducted by a group consensus function (or social choice function). Our method falls into this third category.
 Network Formation Models. Our POSN model lies in the class of random, static network formation models [31]. It is also a spatial (or latent space) networks [16, 4], where nodes possess latent attributes and are connected with odds determined by these attributes. The Waxman model [39] distributes nodes uniformly at random on the plane with node connection probabilities decreasing exponentially with Euclidean distance. Hoff et al. [16] develop a similar model where nodes are points in a d -dimensional  X  X ocial space X . The hidden variable model [7] generalizes the Waxman model, giving nodes a hidden (real-valued or integer) random at-tribute drawn independently from a specified distribution. Nodal Attribute Inference. Inference of nodal attributes, given social network structure, has also received attention. Hoff et al. [16] develop inference and learning methods for spatial models. Kim and Leskovec [19] propose a variational EM method for learning model parameters given network structure and node attributes, and for inferring latent at-tributes. Other related work includes collective classification [37] and active learning over networks [6].
 Learning Preference Rankings. Distributional mod-els of rankings are widely studied in statistics, psychomet-rics and machine learning, though accounting for social net-work structure has been unaddressed. EM has been used to learn model parameters of mixtures of distance-based rank-ing models given completely or partially observed individual rankings [30, 9, 22]. Our model is distinct from those above as it models preference correlations induced by social ties, requiring new sampling and inference methods.
 Collaborative Filtering and Social Networks. Col-laborative Filtering (CF) methods which exploit social net-works for rating prediction have recently become popular (see for example, [23, 18, 24, 41, 14, 26, 20] and [40] for a recent survey). These methods X  X long with traditional CF methods X  X all into two broad categories, memory-based [14, 26, 20] and model-based [23, 18, 24, 41] approaches. In memory-based approaches, the social network structure is usually taken into account when computing the pairwise similarity scores (or trust values) between users [14, 26]. These scores are then used for prediction of missing rat-ings. Model-based approaches focus largely on latent space probabilistic models in which users and items are embed-ded in a low-dimensional latent feature space, and ratings are generated by combining these feature vectors while ac-counting for social network structure. Our model differs in that it considers preference ranking correlations rather than ratings correlations over social networks, and in its focus on group rather than individual recommendation.
 Group Recommendation using Social Factors. Group recommendations based on social factors or interaction pat-terns have recently drawn a fair amount of attention. Mas-thoff and Gatt [28] analyse the effect of group member re-lationship types on their emotional conformity and conta-gion in a group recommendation task. Social relationship strength has been considered in a group collaborative filter-ing context [32]. Salehi-Abari and Boutilier [34] study empa-thetic social choice in social networks, in which individuals derive benefit based on both their own intrinsic preferences and empathetic preferences, the latter determined by the satisfaction of their neighbors.
We describe the form and structure of the joint distri-bution induced by POSNs. Assuming that the preference distribution parameters  X  are given, the joint over R U is: where  X  ( r |  X  ) is the preference distribution. To specify the distribution over G , given  X  , we first focus on the probability Pr( e ij = 1) with which an edge occurs between two nodes i and j in G . We define it under three conditions: (1) the preferences of both i and j are unobserved (and drawn in-dependently from  X  ( r |  X  )); (2) one is observed and the other unobserved; and (3) both are observed.
 Unobserved preferences for both nodes. In this case, Pr( e ij = 1 |  X  ) is the chance of an edge between two nodes whose preferences are drawn independently from  X  ( r |  X  ): (The expected number of edges in a POSN is n 2 E (  X  ).) Unobserved preference for one node. When only one node X  X  preference is observed (say i ) Pr( e ij = 1 | r i D ( r,  X  ) also determines the expected degree of a node with ranking r , which is simply ( n  X  1) D ( r,  X  ).
 Observed preferences for both nodes. The edge prob-ability between i and j when both r i and r j are observed is Pr( e ij = 1 | r i ,r j ,  X  ) = c ( d  X  ( r i ,r j ) |  X  ) . Using these edge probabilities, the probability Pr( G | R of graph structure G given observed preferences R O is:
We formulate Pr( G | R U ,R O ) by focusing on the probabil-ity Pr( e ij | r i ,r j ) of an edge between i and j . Since Pr( e c ( r
Using Bayes rule, the posterior over R U given observed preferences R O and network G is given by: where one can use Eq. 3, Eq. 6, and Eq. 7 for computation of Pr( R U |  X  ), Pr( G | R O ,  X  ), and Pr( G | R U ,R O
For both preference inference and group recommendation, we must compute the joint posterior Pr( R U | G,R O ,  X  ). Ex-act computation is, not surprisingly, computationally expen-sive. So we develop sampling methods to approximate the posterior. At a high level, we sample L preference profiles R (1) ,...,R ( L ) from the posterior, where each profile consists of a preference ranking for each individual i  X  U . Let R denote the sampled preference ranking of individual i  X  U in the t th profile. We approximate the posterior preference of any individual i  X  U , Pr( r i = l | G,R O ,  X  ),  X  l  X   X ( A ), and the expected score of the inferred component of social welfare sw E inf a,G,R O ,O as follows:
Here g ( R ( t ) i ( a ) ,m ) is the positional score of option a in i  X  X  preference ranking for the t th sample. L must be sufficiently large to ensure a good approximation. More critically, we must be able to draw independent samples from the (un-known) posterior. To do this, we use an MCMC algorithm, specifically, Gibbs sampling , where individual variables are in turn sampled using Metropolis sampling .

We use iterative Gibbs sampling to sample unobserved preferences R U . It begins with an initial preference profile R (0) , completing the rankings for all unobserved preferences. At each iteration l , we sample r ( l ) i for each i  X  U from the conditional distribution The order in which preferences are sampled can impact the efficiency of the method. The order can be deterministic or stochastic, and may be based on node degree or the number of observed preferences of their neighbors. In our experi-ments, we use a fixed arbitrary ordering.

To sample r i from the distribution Pr( r i | R \ i ) we use Metropo-lis sampling . By Eqs. 6 X 8 and 3, the probability of r i all other individual preferences is Pr( r i | R \ i )  X   X  p ( r which can be computed in O ( n ) time. To sample r i at iter-ation l of Gibbs, we sample r  X  from a conditional proposal distribution which is a Mallows distribution that uses the previous sam-ple of i  X  X  preference R ( l  X  1) i as its reference ranking and a dispersion parameter  X   X  i (below we fix  X   X  i =  X  , preference dispersion parameter). We accept proposal r  X  as R ( l ) set R ( l ) i = r  X  ) with probability otherwise, we set R ( l ) i = R ( l  X  1) i . To sample from the Mallows model q ( . ), we use the repeated insertion model [11]. One can sample L preference profiles given | R U | unob-served preferences in O ( L | R U | nm ) time using our proposed method. Assuming | R U | is a constant fraction of n , our sampling methods runs in O ( Ln 2 m ) time, which may prove intractable for very large networks. Designing more scalable sampling methods is an important future direction.
We conduct experiments to assess the effectiveness of our inference and group recommendation algorithms. We mea-sure the accuracy of preference inference, and more impor-tantly, assess the quality of the group decisions reached when exploiting network structure to better deal with missing preferences of certain group members.
 Experimental Setup. We experiment on three types of data sets: two-sided synthetic data in which both preferences and networks are randomly generated; one-sided real-world data in which preferences are derived from Irish electoral data, but networks are synthetically generated; and two-sided real-world data in which both preferences and network structure are derived from Flixster. We assume the model parameters  X  are known (e.g., learned from a similar popu-lation). Unless otherwise noted, we set (  X , X , X  ) = (2 , 0 . 7 , 1) and n = 200. We use Borda as our scoring rule where g ( r ( a ) ,m ) = m  X  r ( a ) . While other rules can be used, Borda is a useful surrogate for random utility models [8] and serves to illustrate the value of the POSN model.

We vary the degree to which preferences are observed with parameter  X   X  [0 , 1], the probability that any node X  X  ranking is observed. By varying  X  , we can assess the impact of preference observability on the efficiency of our methods. We select the decision making group S  X  X  (with n s members), for whom a group recommendation is to be made, using one of three methods. RSA (Random Selection from All) selects n s individuals uniformly at random from N . RSU (Random Selection from Unobserved) select n s individuals uniformly at random from U (e.g., reflecting a company with access to a social network and the preferences of existing customers, and wanting to market to new prospects without knowing their preferences). RSC (Random Selection from Community) selects a connected community: it first selects a  X  X eed X  individual at random, then extends the group by selecting n s  X  1 friends of this seed at random; if this set is smaller than n s  X  1, friends of these friends are selected at random to complete the group.
 Performance Metrics. To measure prediction accuracy, we determine how close inferred preferences are to the true
Table 1: Avg. MSEK (10 instances), various m ,  X  . unobserved preferences from a held out test set. We measure closeness using mean scaled expected Kendall- X  (MSEK) : where  X  r i is the true preference of i and m 2 is maximum  X  -distance between two rankings over m options. MSEK lies in [0 , 1]: MSEK = 0 if all preferences are inferred correctly, while MSEK = 1 implies maximum  X  X naccuracy. X 
To examine the decision/recommendation quality using inferred preferences, we compare its social welfare with that of the decision that would be made had actual preferences been observed . Let sw (  X  ) denote social welfare with true preferences, and a  X  and a  X  inf be the optimal options under given actual and inferred preferences. Rather than directly comparing social welfare, we define relative social welfare loss (RSWL) to be [ sw ( a  X  )  X  sw ( a  X  inf )] / sw ( a as a percentage).
 Benchmarks. We consider several other ways of dealing with missing preferences in decision making, and use these as benchmarks. In  X  -mallows inference (PM) , we assume that all unobserved preferences are independent and are drawn from a  X  -mallows model (with parameters identical to those in the POSN model). We calculate the same inferred so-cial welfare functions as in our model, namely, ES, JMPES, IMPES. Note that ES will be the same for all unobserved preferences and can be computed once. Moreover, JMPES and IMPES must be the same as the reference ranking  X  . Another approach to missing preferences, dubbed Discard Unobserved (DU) , is to ignore them and make a decision using only observed preferences.
 For each fixed setting, we generate 10 partially observed POSNs. In each, we burn-in 1000 samples, then collect 1000 samples using our Gibbs-Metropolis method. We report MSEK averaged over the 10 instances. For each instance, we also randomly select 40 decision making groups of fixed sizes { 3 , 5 , 10 , 15 , 20 } using RSA, RSU, or RSC, giving 400 social choice instances per an experimental setting. RSWL is reported as the average over these 400 instances. Two-sided synthetic. We set  X  = 0 . 85,  X  = (1 ,...,m ), and  X  as stated above. Table 1 shows average MSEK for var-ious  X  and m . Unsurprisingly, MSEK increases with m and decreases with  X  . As m increases, the number of rankings increases factorially, as does the the support of the ranking distribution. In such cases, lower MSEK requires more in-formation for accurate prediction. When m = 3, n = 200 is sufficient to push MSEK to almost 0. With m = 4, it remains very low. To examine the effect of n on MSEK, we fix m = 6 and  X  = 0 . 8 but vary n : Table 2 shows that MSEK decreases with n as expected. Decision quality of our methods in this setting is qualitatively similar to those discussed below. Our ES and IMPES methods outperform the other benchmark methods in most settings, including over all group sizes, group selection methods, and various m (even for m = 6 with relatively high MSEK). F igure 2: Avg. RSWL (over 400 instances) for various group sizes n fixed  X  = 0 . 5 ,  X  = 0 . 2 .
T able 2: Avg. MSEK (10 instances),  X  = 0 . 8 , m = 6 . T able 3: Avg. MSEK,  X  = 0 . 5 , n = 200 , Irish data set. Irish data. We test our methods using real-world pref-erences from the 2002 Irish Election, Dublin West Con-stituency, with 9 candidates and 29 , 989 ballots of the top-t form, of which 3800 are complete rankings. We created pref-erence data sets with various values m from these complete preferences, by choosing m candidates with highest aggre-gate Borda score, and limiting each individual X  X  preferences to these m options.

For each m , we learn  X  and  X  from its corresponding fil-tered data set and used those parameters in our methods (hence we have a loose prior over preferences, but not a pre-cise prior for specific group , see below). For each experimen-tal setting, we generate 10 partially observed POSNs with  X  = 0 . 5 and 200 individuals with preferences drawn from the filtered Irish data set. We then generate the POSN using our model, but with additional noise: we randomly change the parity of each e ij (i.e., delete or add an edge) with proba-bility  X  . Though we create a synthetic social network using our POSN model, adding noise in this fashion reflects sce-narios in which the social network is not generated using our specific model, or when learned model parameters provide a less-than-ideal fit to the underlying data.
 Table 3 reports average MSEK when  X  varies ( m = 4 , 5). Unsurprisingly, MSEK increases with both m and  X  when n and  X  are fixed. MSEK is very low when m = 4, even with high  X  = 0 . 05 (10 edge flips per node in expectation). Tables 1 and 3 show comparable MSEK values for m = 4 , 5, suggesting that that even in scenarios where the preference distribution  X  ( . ) is not known a priori , but is a learned  X  -mallows model, POSNs support effective inference.

Fig. 2 shows average RSWL with  X  = 0 . 5 and  X  = 0 . 02 (400 expected edge flips in the network). We vary m , the group selection method and the inference method. Our POSN-ES and POSN-IMPES approaches outperform the other benchmarks in most settings, including: all situations in which no group preferences are observed (see Fig. 2(b) and 2(e)); and even with m = 5 (see Fig. 2(d)-2(f)) despite its relatively high MSEK (see Table 3). RSWL in all bench-mark methods (PM-ES, PM-JMPES, DU) is very sensitive to group size, increasing dramatically as group size decreases (see Fig. 2(a)-(f)). However, POSN-ES and POSN-IMPES are more robust to group size (see Fig. 2(a)-(f)). POSN-IMPES approximates POSN-ES reasonably well, while POSN-JMPES also performs well.
 Flixster data. The Flixster dataset [18] consists of a social network of movie watchers and their ratings of movies, and allows a test of our methods using both real-world network and preference data. Because movie ratings are sparse, we aggregate them into preferences over movie genres (genres were determined automatically using the Rotten Tomatoes and IMDB web sites). Let  X  r um be the rating of user u for movie m where  X  r um  X  { 0 . 5 , 1 ,  X  X  X  , 5 } if u has rated m oth-erwise 0 (for missing ratings). For each user u and genre g , we define a user-genre score where  X  I u = P sign(  X  r um ) is the number of movies rated by u , and A mg = 1 if movie m has genre g (and A mg 0 otherwise). This score reflects the relative number of movies of each genre watched by a specific user. This is converted into a ranking of genres for each user u by or-dering genres according to their scores S C ug . We limit our focus to four diverse genres X  X omedy, Drama, Kids/Family POSN-ES 7.34 5.04 2.86 2.57 2.66 POSN-JMPES 9.89 7.67 4.33 3.69 3.29 POSN-IMPES 9.59 7.09 4.34 3.89 3.77 PM-ES 9.36 8.07 7.56 6.76 6.73 PM-JMPES 9.72 8.54 8.63 7.84 7.48 DU 20.61 12.07 5.31 2.92 2.12 Table 4: Std. RSWL in percentage (Flixster,  X  =0.5) and Mystery/Suspense. 2 We run our methods on a 272-node subgraph of the Flixster data set, with 924 edges. We estimate a  X  -Mallows model and POSN model parameters using maximum likelihood methods on this sub-network; the learned parameters are (  X , X , X , X  ) = (2 . 05 , 1 . 06 , 0 . 07 , 0 . 33). For each run, we test our methods on 10 instances of a par-tially observed network, censoring each individual X  X  genre preference with probability  X  = 0 . 5 or  X  = 0 . 3.
Average MSEK is 0 . 242 and 0 . 256 for  X  = 0 . 5 and  X  = 0 . 3 (resp.). This suggests that genre preferences are reasonably predictable using the POSN model. Fig. 3 shows decision making performance, i.e., average RSWL, for the various methods described above using RSC to select groups. Each of our POSN-sensitive methods X  X S, IMPES, and JMPS X  outperform the  X  -Mallows benchmark for all group sizes, and outperform DU significantly for small groups. DU per-forms comparably to methods that account for network struc-ture when groups are larger (15 or 20 individuals) since, in expectation, the preferences of 7 X 10 group members are observed: this is sufficient to make a good decision with-out estimating missing preferences explicitly due to normal sampling bounds from the underlying Mallows model. This, in addition to the fact that homophily across a large group makes it likely that the missing preferences are similar to those observed, means that making a group decision based only on observed preferences usually results in near-optimal decisions. Table 6 reports the std. dev. for these results when  X  = 0 . 5. ES has the smallest variance in RSWL in general, implying more robustness in the decisions made. Overall, ES is the most reliable method of those analyzed here. (Results for  X  = 0 . 3 are qualitatively similar).
We focus on these four genres in part to increase data  X  X en-sity. X  Our choice of these genres may impact the results below; future investigation is needed to assess this impact.
We introduced preference-oriented social networks (POSNs) to capture the correlation of preference rankings between individuals who interact in social networks. We developed effective inference methods to predict an individual X  X  pref-erences by exploiting these correlations. We also developed methods for group recommendation when the preferences of some (or even all) group members are unobserved. Our ex-periments showed the value of accounting for social ties in inference and group recommendation when faced with miss-ing preferences.

This work is a starting point for the deeper modeling of preferences in a social network context. Interesting future directions include: empirical investigation of preference cor-relations in real-world networks; scalable learning methods for estimating model parameters; more efficient sampling methods based on network topology; studying other aggre-gation functions (e.g., other social choice functions, voting rules, bargaining solution concepts, etc.), and extensions to other social choice problems (e.g., matchings, assignments).
Of practical importance is investigating the extent to which preference rankings are correlated and play a role in shap-ing connections in real-world social networks. Developing scalable methods for learning model parameters is essential; such learning techniques can exploit our inference methods as important building block (e.g., in EM-based algorithms). More efficient sampling methods can be designed by taking into account the presence or absence of subsets of possible edges. Our model can provide the basis for more effective preference elicitation. As decision making using MPE seems to provide a reasonable approximation to optimal decisions, studying how MPE can be computed or approximated with-out the use of sampling remains of interest. Similar to active learning methods [6], the tighter integration of inference and decision making methods would also be of value.

There are a number of potential extension to our POSN model. This includes accommodating partial information about the preferences of specific users (e.g., a small set of pairwise comparisons); and incorporating both the strength and types of relationships between individuals. Such gener-alizations may offer greater performance in certain prefer-ence inference and group recommendation settings.
 Acknowledgements. This research was supported by NSERC. [1] S. Amer-Yahia, S. B. Roy, A. Chawlat, G. Das, and [2] K. Arrow. Social Choice and Individual Values . 1951. [3] L. Baltrunas, T. Makcinskas, and F. Ricci. Group [4] M. Barth  X elemy. Spatial networks. Physics Reports , [5] S. Berkovsky and J. Freyne. Group-based recipe [6] M. Bilgic, L. Mihalkova, and L. Getoor. Active [7] M. Bogu  X n  X a and R. Pastor-Satorras. Class of correlated [8] C. Boutilier, I. Caragiannis, S. Haber, T. Lu, A. D. [9] L. M. Busse, P. Orbanz, J. M. Buhmann. Cluster [10] N. A. Christakis and J. H. Fowler. The spread of [11] J.-P. Doignon, A. Pekec, and M. Regenwetter. The [12] M. Gartrell, X. Xing, Q. Lv, A. Beach, R. Han, [13] M. Gladwell. The Tipping Point: How Little Things [14] J. Golbeck and J. Hendler. Filmtrust: Movie [15] M. S. Granovetter. The strength of weak ties. [16] P. D. Hoff, A. E. Raftery, and M. S. Handcock. Latent [17] M. Jackson. Social and Economic Networks . 2008. [18] M. Jamali, M. Ester. A matrix factorization technique [19] M. Kim and J. Leskovec. Latent multi-group [20] I. Konstas, V. Stathopoulos, J. Jose. On social [21] K. Lewis, M. Gonzalez, and J. Kaufman. Social [22] T. Lu and C. Boutilier. Learning mallows models with [23] H. Ma, I. King, M. Lyu. Learning to recommend with [24] H. Ma, H. Yang, M. R. Lyu, and I. King. SoRec: [25] J. I. Marden. Analyzing and Modeling Rank Data . [26] P. Massa, P. Avesani. Controversial users demand [27] J. Masthoff. Group modeling: Selecting a sequence of [28] J. Masthoff and A. Gatt. In pursuit of satisfaction and [29] J. F. McCarthy, T. D. Anagnost. Musicfx: An arbiter [30] T. Murphy, D. Martin. Mixtures of distance-based [31] M. Newman. Networks: An Intro. Oxford, 2010. [32] L. Quijano-Sanchez, J. Recio-Garcia, B. Diaz-Agudo, [33] A. Salehi-Abari and C. Boutilier. Ranking networks. [34] A. Salehi-Abari and C. Boutilier. Empathetic social [35] S. Seko, T. Yagi, M. Motegi, and S. Muto. Group [36] A. K. Sen. Collective Choice and Social Welfare . [37] P. Sen, G. M. Namata, M. Bilgic, L. Getoor, [38] M. A. Serrano, D. Krioukov, and M. Bogu  X n  X a. [39] B. M. Waxman. Routing of multipoint connections. [40] Y. Xiwang, Y. Guo, Y. Liu, and H. Steck. A survey of [41] X. Yang, H. Steck, Y. Liu. Circle-based [42] Z. Yu, X. Zhou, Y. Hao, and J. Gu. TV program
