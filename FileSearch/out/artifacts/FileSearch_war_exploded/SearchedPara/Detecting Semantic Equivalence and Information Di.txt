 Given two documents about the same topic writ-ten in different languages ( e.g. Wiki pages), con-tent synchronization deals with the problem of au-tomatically detecting and resolving differences in the information they provide, in order to produce aligned, mutually enriched versions. A roadmap to-wards the solution of this problem has to take into account, among the many sub-tasks, the identifica-tion of information in one page that is semantically equivalent, novel, or more informative with respect to the content of the other page. In this paper we set such problem as an application-oriented, cross-lingual variant of the Textual Entailment (TE) recog-nition task (Dagan and Glickman, 2004). Along this direction, we make two main contributions: (a) Experiments with multi-directional cross-lingual textual entailment. So far, cross-lingual textual entailment (CLTE) has been only applied to: i) available TE datasets (uni-directional rela-tions between monolingual pairs) transformed into their cross-lingual counterpart by translating the hy-potheses into other languages (Negri and Mehdad, 2010), and ii) machine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we ex-periment with the only corpus representative of the multilingual content synchronization scenario, and the richer inventory of phenomena arising from it (multi-directional entailment relations). (b) Improvement of current CLTE methods. The CLTE methods proposed so far adopt either a  X  piv-oting approach  X  based on the translation of the two input texts into the same language (Mehdad et al., 2010), or an  X  integrated solution  X  that exploits bilin-gual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated ap-proach, however, still rely on phrasal matching tech-niques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguis-tically motivated features, we propose a novel ap-proach that improves the state-of-the-art in CLTE. CLTE has been proposed by (Mehdad et al., 2010) as an extension of textual entailment which consists of deciding, given a text T and an hypothesis H in dif-ferent languages , if the meaning of H can be inferred from the meaning of T. The adoption of entailment-based techniques to address content synchronization looks promising, as several issues inherent to such task can be formalized as entailment-related prob-lems. Given two pages ( P1 and P2 ), these issues include identifying, and properly managing: (1) Text portions in P1 and P2 that express the same meaning (bi-directional entailment). In such cases no information has to migrate across P1 and P2 , and the two text portions will remain the same; (2) Text portions in P1 that are more informa-tive than portions in P2 (forward entailment). In such cases, the entailing (more informative) portions from P1 have to be translated and migrated to P2 in order to replace or complement the entailed (less in-formative) fragments; (3) Text portions in P2 that are more informa-tive than portions in P1 (backward entailment), and should be translated to replace or complement them; (4) Text portions in P1 describing facts that are not present in P2 , and vice-versa (the  X  X nknown X  cases in RTE parlance). In such cases, the novel infor-mation from both sides has to be translated and mi-grated in order to mutually enrich the two pages; (5) Meaning discrepancies between text portions in the two pages ( X  X ontradictions X  in RTE parlance).
CLTE has been previously modeled as a phrase matching problem that exploits dictionaries and phrase tables extracted from bilingual parallel cor-pora to determine the number of word sequences in H that can be mapped to word sequences in T. In this way a semantic judgement about entailment is made exclusively on the basis of lexical evidence. When only unidirectional entailment relations from T to H have to be determined (RTE-like setting), the full mapping of the hypothesis into the text usually provides enough evidence for a positive entailment judgement. Unfortunately, when dealing with multi-directional entailment, the correlation between the proportion of matching terms and the correct entail-ment decisions is less strong. In such framework, for instance, the full mapping of the hypothesis into the text is per se not sufficient to discriminate between forward entailment and semantic equivalence. To cope with these issues, we explore the contribution of syntactic and semantic features as a complement to lexical ones in a supervised learning framework. In order to enrich the feature space beyond pure lex-ical match through phrase table entries, our model builds on two additional feature sets, derived from i) semantic phrase tables, and ii) dependency relations.
Semantic Phrase Table (SPT) matching repre-sents a novel way to leverage the integration of se-mantics and MT-derived techniques. SPT matching extends CLTE methods based on pure lexical match by means of  X  X eneralized X  phrase tables annotated with shallow semantic labels. SPTs, with entries in the form  X  [LABEL] word 1 ... word n [LABEL]  X , are used as a recall-oriented complement to the phrase tables used in MT. A motivation for this augmenta-tion is that semantic tags allow to match tokens that do not occur in the original bilingual parallel cor-pora used for phrase table extraction. Our hypothe-sis is that the increase in recall obtained from relaxed matches through semantic tags in place of  X  X ut of vocabulary X  terms ( e.g. unseen person names) is an effective way to improve CLTE performance, even at the cost of some loss in precision.

Like lexical phrase tables, SPTs are extracted from parallel corpora. As a first step we annotate the parallel corpora with named-entity taggers for the source and target languages, replacing named entities with general semantic labels chosen from a coarse-grained taxonomy (person, location, orga-nization, date and numeric expression). Then, we combine the sequences of unique labels into one sin-gle token of the same label, and we run Giza++ (Och and Ney, 2000) to align the resulting semantically augmented corpora. Finally, we extract the seman-tic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al., 2007). For the matching phase, we first annotate T and H in the same way we labeled our parallel corpora. Then, for each n-gram order (n=1 to 5) we use the SPT to cal-culate a matching score as the number of n-grams in H that match with phrases in T divided by the num-ber of n-grams in H. 1
Dependency Relation (DR) matching targets the increase of CLTE precision. Adding syntactic con-straints to the matching process, DR features aim to reduce the amount of wrong matches often occur-ring with bag-of-words methods (both at the lexi-cal level and with recall-oriented SPTs). For in-stance, the contradiction between  X  Yahoo acquired Overture  X  and  X  Overture compr  X  o Yahoo  X , which is evident when syntax is taken into account, can not be caught by shallow methods. We define a de-pendency relation as a triple that connects pairs of words through a grammatical relation. DR matching captures similarities between dependency relations, combining the syntactic and lexical level. In a valid match, while the relation has to be the same, the con-nected words can be either the same, or semantically equivalent terms in the two languages ( e.g. accord-ing to a bilingual dictionary). Given the dependency tree representations of T and H, for each grammati-cal relation ( r ) we calculate a DR matching score as the number of matching occurrences of r in T and H, divided by the number of occurrences of r in H. Separate DR matching scores are calculated for each relation r appearing both in T and H. 4.1 Content synchronization scenario In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entail-ment pairs which we equally divided into training and test sets. Each pair in the dataset is annotated with  X  X idirectional X ,  X  X orward X , or  X  X ackward X  en-tailment judgements. Although highly relevant for the content synchronization task,  X  X ontradiction X  and  X  X nknown X  cases ( i.e.  X  X O X  entailment in both directions) are not present in the annotation. How-ever, this is the only available dataset suitable to gather insights about the viability of our approach to multi-directional CLTE recognition. 2 We chose the ENG-GER portion of the dataset since for such lan-guage pair MT systems performance is often lower, making the adoption of simpler solutions based on pivoting more vulnerable.

To build the English-German phrase tables we combined the Europarl, News Commentary and  X  X e-news X  3 parallel corpora. After tokenization, Giza++ and Moses were respectively used to align the cor-pora and extract a lexical phrase table (PT). Simi-larly, the semantic phrase table (SPT) has been ex-tracted from the same corpora annotated with the Stanford NE tagger (Faruqui and Pad  X  o, 2010; Finkel et al., 2005). Dependency relations (DR) have been extracted running the Stanford parser (Rafferty and Manning, 2008; De Marneffe et al., 2006). The dic-tionary created during the alignment of the parallel corpora provided the lexical knowledge to perform matches when the connected words are different, but semantically equivalent in the two languages. To combine and weight features at different levels we used SVMlight (Joachims, 1999) with default pa-rameters.

In order to experiment under testing conditions of increasing complexity, we set the CLTE problem both as a two-way and as a three-way classification task. Two-way classification casts multi-directional entailment as a unidirectional problem, where each pair is analyzed checking for entailment both from left to right and from right to left. In this condi-tion, each original test example is correctly clas-sified if both pairs originated from it are correctly judged ( X  X ES-YES X  for bidirectional,  X  X ES-NO X  for forward, and  X  X O-YES X  for backward entail-ment). Two-way classification represents an intu-itive solution to capture multidirectional entailment relations but, at the same time, a suboptimal ap-proach in terms of efficiency since two checks are performed for each pair. Three-way classification is more efficient, but at the same time more challeng-ing due to the higher difficulty of multiclass learn-ing, especially with small datasets.

Results are compared with two pivoting ap-proaches, checking for entailment between the orig-inal English texts and the translated German hy-potheses. 4 The first (Pivot-EDITS), uses an op-timized distance-based model implemented in the open source RTE system EDITS (Kouylekov and Negri, 2010; Kouylekov et al., 2011). The second (Pivot-PPT) exploits paraphrase tables for phrase matching, and represents the best monolingual model presented in (Mehdad et al., 2011). Table 1 demonstrates the success of our results in prov-ing the two main claims of this paper. (a) In both settings all the feature sets used outperform the ap-proaches taken as terms of comparison. The 61.6% accuracy achieved in the most challenging setting (3-way) demonstrates the effectiveness of our ap-proach to capture meaning equivalence and informa-tion disparity in cross-lingual texts. (b) In both settings the combination of lexical, syn-tactic and semantic features (PT+SPT+DR) signif-icantly improves 5 the state-of-the-art CLTE model (PT). Such improvement is motivated by the joint contribution of SPTs (matching more and longer n-grams, with a consequent recall improvement), and DR matching (adding constraints, with a consequent gain in precision). However, the performance in-crease brought by DR features over PT is mini-mal. This might be due to the fact that both PT and DR features are precision-oriented, and their effec-tiveness becomes evident only in combination with recall-oriented features (SPT).

Cross-lingual models also significantly outper-form pivoting methods. This suggests that the noise introduced by incorrect translations makes the pivot-ing approach less attractive in comparison with the more robust cross-lingual models. 4.2 RTE-like CLTE scenario Our second experiment aims at verifying the effec-tiveness of the improved model over RTE-derived CLTE data. To this aim, we compare the results ob-tained by the new CLTE model with those reported in (Mehdad et al., 2011), calculated over an English-Spanish entailment corpus derived from the RTE-3 dataset (Negri and Mehdad, 2010).

In order to build the English-Spanish lexical phrase table (PT), we used the Europarl, News Com-mentary and United Nations parallel corpora. The semantic phrase table (SPT) was extracted from the same corpora annotated with FreeLing (Carreras et al., 2004). Dependency relations (DR) have been ex-tracted parsing English texts and Spanish hypotheses with DepPattern (Gamallo and Gonzalez, 2011).
Accuracy results have been calculated over 800 test pairs of the CLTE corpus, after training the SVM binary classifier over the 800 development pairs. Our new features have been compared with: i) the state-of-the-art CLTE model (PT), ii) the best mono-lingual model (Pivot-PPT) presented in (Mehdad et al., 2011), and iii) the average result achieved by participants in the monolingual English RTE-3 eval-uation campaign (RTE-3 AVG). As shown in Ta-ble 1, the combined feature set (PT+SPT+DR) sig-nificantly 5 outperforms the lexical model (64.5% vs 62.6%), while SPT and DR features separately added to PT (PT+SPT, and PT+DR) lead to marginal improvements over the results achieved by the PT model alone (about 1%). This confirms the con-clusions drawn from the previous experiment, that precision-oriented and recall-oriented features lead to a larger improvement when they are used in com-bination. We addressed the identification of semantic equiv-alence and information disparity in two documents about the same topic, written in different languages. This is a core aspect of the multilingual content syn-chronization task, which represents a challenging application scenario for a variety of NLP technolo-gies, and a shared research framework for the inte-gration of semantics and MT technology. Casting the problem as a CLTE task, we extended previous lexical models with syntactic and semantic features. Our results in different cross-lingual settings prove the feasibility of the approach, with significant state-of-the-art improvements also on RTE-derived data. This work has been partially supported by the EU-funded project CoSyne (FP7-ICT-4-248531).
