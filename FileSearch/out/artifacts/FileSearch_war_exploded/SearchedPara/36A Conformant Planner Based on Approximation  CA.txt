 VIEN TRAN, KHOI NGUYEN, TRAN CAO SON, ENRICO PONTELLI , New Mexico State Automated planning is the problem of finding a course of actions that transforms the world from one state to a state satisfying a given property. Let us consider, for example, a robot that can navigate between locations in a building and open/close doors. Let us suppose that, for simplicity, there are only two rooms A and B , and both rooms are closed. The robot is inside A , and would like to get to B . Intuitively, a plan for the robot to achieve its goal is: open A , get out of A ,close A , navigate to B , open B ,andenter B .In this example, the robot is aware of every property of the environment in which it is in.
Planning, when the agent has complete knowledge about the initial state and its actions, is often referred to as classical planning . Classical planning is known unde-cidable in the general case [Chapman 1987; Erol et al. 1995]. Its complexity reduces to PSPACE-complete for finite and deterministic domains [Bylander 1994]. By making certain assumptions, such as requiring the length of plans to be polynomially bounded by the size of the problem and requiring actions to be deterministic, it is possible to reduce the complexity of the problem to NP-complete [Baral et al. 2000].

Classical planning is often criticized as being unrealistic, due to the assumption of complete information. One of the research directions that has been developed to ad-dress this issue is conformant planning [Smith and Weld 1998]. Conformant planning problems do not assume that the agent has complete information about the initial state of the world. A solution to a conformant planning problem is a sequence of actions that achieves the goal from any possible initial state of the world. Conformant planning is generally harder than classical planning. Under the assumption that actions are deterministic and the plan X  X  length is polynomially bounded by the size of the prob-lem, the conformant planning problem is 2 P -complete [Baral et al. 2000]. Conformant planning can be viewed as a special case of decision-theoretic approaches to planning [Kaelbling et al. 1998] which employ a Partially Observable Markov Decision Process (POMDP) [Bertsekas 1995; Putterman 1994]. We note that planning problems consid-ered by POMDP-based approaches can contain sensing actions and nondeterministic actions which will not be considered in this article.

Since its inception, conformant planning has attracted the attention of several re-search groups and several conformant planners have been developed (e.g., Brafman and Hoffmann [2004], Cimatti et al. [2004], Bryce et al. [2006], Palacios and Geffner [2009], To et al. [2009], Tran et al. [2009]). One of the main difficulties encountered in conformant planning is the possibly high degree of uncertainty in the initial state, since the number of possible initial states can be exponential in the number of propositions.
The Planning Domain Definition Language (PDDL) [Ghallab et al. 1998; Gerevini and Long 2005; Younes and Littman 2004] introduces two constructs to express incom-plete knowledge about the initial state of the world: mutual exclusion statements (ex-pressed using one -of clauses) and disjunctive statements (expressed using or clauses). Frequently, one -of clauses are used to specify the possible initial states and or clauses are used to eliminate infeasible states. Because of this, the number of possible initial states depends mainly on the number and the size of the one -of clauses, that is, the number of uncertain propositions. Furthermore, the number of uncertain propositions will be dependent on the ground instantiations of the planning problem, which is often exponential in the number of object constants present in the problem instance. For example, several instances in the 2006 and 2008 planning competition have this prop-erty (Table I). Being able to deal effectively with the number and size of one -of clauses proves to be critical for conformant planners X  scalability.

Several approaches have been proposed to deal with the large number of possible ini-tial states. Some conformant planners, such as POND [Bryce et al. 2006] and KACMBP [Cimatti et al. 2004], employ an Ordered Binary Decision Diagram (OBDD) represen-tation [Bryant 1992] of belief states. 1 The DNF [To et al. 2009] and CNF [To et al. 2010] systems adopt a Disjunctive Normal Form (DNF) and Conjunctive Normal Form (CNF) representation, respectively. CFF [Brafman and Hoffmann 2004] instead uses a combination of a CNF formula and action sequences for belief state representation. These types of encodings avoid dealing directly with the exponential number of states, but they require extra work in order to determine the truth value of certain proposi-tions after the execution of a sequence of actions in the initial belief state. For instance, CFF needs to make a call to a SAT-solver with the initial state and the sequence of actions; some of the OBDD-based planners have demonstrated the need to recompute the OBDD representation, which could also be an expensive operation. Methods for dealing with exponential number of states in POMDP-based approaches have been developed in Ong et al. [2010] and Shani et al. [2008]. Observe that the problem of determining the truth value of a proposition after the execution of a single action in a belief state is co-NP complete [Baral et al. 2000].
An alternative approach to deal with the large number of possible initial states is used by the planners cf2cs(ff) [Palacios and Geffner 2006] and C P A [Son et al. 2005b], and further investigated in their successors t0 [Palacios and Geffner 2009] and C P A+ [Son and Tu 2006]. This approach relies on an approximation semantics in reasoning with incomplete information [Son and Baral 2001]. The planners cf2cs(ff) and t0 2 reduce the number of possible initial states to a single one, by introducing additional propositions, transforming the original problem to a classical planning problem, and using FF, a classical planner [Hoffmann and Nebel 2001], to find solutions. On the other hand, C P AandC P A+ reduce this number by dividing them into groups and using the intersection of each group as its representative during planning.

C P A+ and t0 implement the idea of approximations differently. While C P A+ could be seen as a standard heuristic search forward planner, t0 follows a translational approach. The performance of C P A+ is dependent on its heuristic function and its ability to approximate the initial belief state to a manageable set of partial states. On the other hand, the performance of t0 largely depends on the performance of FF.
In this article, we describe the design and implementation of C P A( H ), our entry 3 in the Uncertainty Track of the 6 th International Planning Competition 2008 (IPC), co-located with the International Conference on Automated Planning and Scheduling (ICAPS), 2008, Sydney, Australia. We describe the basic reasoning mechanism of C
A( H ) and present the various techniques introduced to improve efficiency and scalability. We begin with a short overview of the problem representation and the basic reasoning mechanism of the planner (Section 2). We then discuss the design present some representative results of our experimental comparison of C P A( H )with some of state-of-the-art conformant planners, allowing us to emphasize the impact of the techniques introduced in C P A( H ) and how they relate to the structure of different planning domains. Section 7 presents conclusions and directions for future work. Following the notation in Palacios and Geffner [2006], we describe a problem specifica-tion as a tuple P = F , O , I , G , where:  X  F is a set of propositions;  X  O is a set of actions;  X  I describes the initial state of the world; and  X  G describes the goal.
 A literal is either a proposition p  X  F or its negation  X  p .  X  denotes the complement of a literal and is defined as  X  = X  where  X  X  p = p for any p  X  F .Wesaythat and  X  are complementary literals. For a set of literals L , L ={  X  |  X  L } . In this article, we will often represent a conjunction of literals as a set.

A set of literals X is consistent if there exists no p  X  F such that { p ,  X  p } X  X .A state s is a consistent and complete set of literals, that is, s is consistent, and for each p  X  F , either p  X  s or  X  p  X  s .A belief state is a set of states. A set of literals X satisfies a literal (respectively, a set of literals Y ) iff  X  X (respectively, Y  X  X ). We write X |= (respectively, X |= Y ) to denote that X satisfies (respectively, Y ).

Each action a in O is associated with a precondition  X  (denoted by pre ( a )) and a set of conditional effects of the form  X   X  (also denoted by a :  X   X  ), where  X  and  X  are sets of literals and is a literal. We will often write a :  X   X  1 ,..., n as a shorthand for the set { a :  X   X  1 ,..., a :  X   X  n } .

The initial state of the world I is the union of three types of formulas and can be written as I = I d  X  I o  X  I r where:  X  I d is a set of literals; and  X  I r is a set of or clauses, each of the form or (  X  1 ,..., X  n ). where each  X  i is a set of literals.

An one -of clause indicates that the  X  i  X  X  are mutually exclusive, while an or clause is a Disjunctive Normal Form (DNF) representation of a formula. A set of literals X  X   X  X and for every j = i ,1  X  j  X  n ,  X  if there exists some 1  X  i  X  n such that  X  i  X  X . Given a one -of clause or an or clause the notations, we write X |= o to say that a set of literals X satisfies o .
By ext ( I ) we denote the set of all states satisfying I d , every one -of clause in I o ,and {{ g , f } , { g ,  X  f }} .
 The goal of the problem, G , is a collection of literals and or clauses.
 Example 1 . Let us consider the 2  X  2 dispose problem with one object o 1 from Palacios and Geffner [2006]. The object is on a 2  X  2 grid. The agent can move, one step at a time, within the grid. It can pick up an object, move along with the object, and drop it where a trash-can is. Different representations can be used for this domain. In this article, we use the encoding proposed in the IPC-08. In this setting, the grid denote the fact that the two locations l and l are adjacent, thus allowing the agent to move between l and l . The goal is to collect all the objects on the grid and dispose them into the trash-can, which is located at l 11 . Initially, the locations of the objects are unknown.

Let us denote the problem by D [2 , 2 , 1], that is, the problem is on a 2  X  2 grid and there is one object to be disposed of.
 propositions is 4 indicates that the trash-can is at the location x , holding ( o 1 ) states that the agent holds that the agent is at the location x .
 The set of actions with their conditional effects can be represented as follows. Here x 1 , x 2 , x  X  Loc , x 1 = x 2 . In addition, we have that The initial state of the problem can be given by I = I d  X  I o where and This initial state description will give rise to a belief set containing four possible states, depending on the possible location of o 1 . Finally, the goal of the problem is given by in s , denoted by e a ( s ), is defined by The execution of a in a state s results in a successor state succ ( a , s ) which is defined by succ is extended to define succ  X  , which computes the result of the execution of an action in a belief state, as follows. We assume also that succ  X  ( a , failed ) = failed for any action a . Finally, we can define the function succ to compute the final belief state resulting from the execution of a plan. An action sequence  X  is a solution of P iff succ (  X , S 0 ) = failed and G is satisfied in every state belonging to succ (  X , S 0 ).

Example 2 . Consider the planning problem in Example 1; let us assume that the mo v e action is allowed only between adjacent locations, the adjacent relation adjacent ( l 22 , l 12 ). We can easily check that the sequence of action problem D [2 , 2 , 1]. As we have mentioned earlier, the size of the initial belief state, that is, the number of states in ext ( I ), is a challenge for conformant planners. In Son et al. [2005b], a new approach to conformant planning is proposed. This approach extends the notion of approximation proposed in Son and Baral [2001] to languages with state constraints. The original approximation proposes to approximate a belief state by a set of literals that are true in all the states belonging to it, and develops a transition function to reason about the effects of actions on approximation states. The advantage of this approach lies in that conformant planning using approximation is NP-complete, while it is 2 P -complete with respect to the complete semantics [Baral et al. 2000]. The trade-off is its incompleteness. This issue has been addressed in Son and Tu [2006].
Formally, we refer to a consistent set of literals as a partial state . A set of partial states is called a cs-state . For a partial state  X  ,by ext (  X  ) we denote the belief state { s |  X   X  s } . A proposition p  X  F is unknown in  X  if  X   X  X  p ,  X  p }= X  . Intuitively, a partial belief state n i = 1 ext (  X  i ).

The reasoning with respect to partial states is characterized by a function ( succ A ) that maps an action and a partial state to a partial state. The possible effects of a in a partial state  X  are given by The successor partial state from the execution of a in  X  is defined by Similarly to succ  X  and succ , succ A can be extended to define succ  X  A (mapping cs-states to cs-states) and succ A for computing the result of the execution of an action sequence starting from a cs-state. For an action a and a cs-state ,let Just as in the case of succ  X  , we assume that succ  X  A ( a , failed ) = failed . For an action sequence [ a 1 ,..., a n ] and a cs-state ,let The soundness of the approximation states that for every partial state  X  , action se-[Son and Baral 2001]. 5 This shows that succ A (or succ A ) can be employed in the imple-mentation of a conformant planner, provided that we can select an appropriate cs-state such that S  X   X   X  ext (  X  ). Because S  X  ext ( u  X  S u ) for every belief state S , we could of conformant planners using approximation [Son et al. 2005a, 2005b; Tu et al. 2006], which we will refer to as approximation-based conformant planners hereafter. The principal advantage of this choice is that the size of the cs-state is small (one), which is a significant reduction from 2 | F | , the number of possible states of a domain ( F is the set of propositions in the domain). This choice, however, does not guarantee completeness due to the incompleteness of the approximation when actions have conditional effects. This can be seen in the following example.
 Example 3 . Given the planning problem where I = X  and G ={ h } , we can easily check that and The first equation indicates that a is a solution of P . On the other hand, the second one states that if the initial belief state is approximated to  X  then a is not a plan with respect to the approximation, that is, an approximation-based conformant planner, which employs succ  X  A in the search for solutions, that might be incomplete.
To guarantee the completeness of approximation based conformant planners and still exploit the advantages of the approximation, whenever it is possible, we need to identify an appropriate partition ={ 1 ,..., k } , called a complete partition ,of ext ( I ) such that:  X  i  X  j = X  for each i = j ,and  X  X or each formula  X  and sequence of actions  X  , succ A (  X , {  X  1 ,..., X  k } ) |=  X  iff succ (  X , ext ( I )) |=  X  , where  X  i = s  X  in i .
 Observe that if a complete partition of ext ( I ) can be found, then an approximation-based conformant planner can search for a solution of a problem P starting with the cs-state ( ) ={  X  = s  X  s |  X  } .
 not always necessary to consider the trivial partition. For example, the partition ple 3. Observe that this means that an approximation-based conformant planner can start searching for a solution using the cs-state {{ f } , { X  f }} and it is guaranteed that the planner will find (at least) a solution if the problem is solvable.

The existing research has investigated sufficient syntactical conditions to identify complete partitions, based on the identification of propositions that should be explicitly distinguished in different partitions (see, e.g., Son and Tu [2006] and Tu [2007]). The planner C P A( H ) employs the partitioning technique described in Son and Tu [2006] and Tu [2007] which aims at reducing the size of the initial belief state of a conformant planning problem. A parallel development can be observed in a series of papers by the authors of t0 [Palacios and Geffner 2006, 2007, 2009] who identified conditions for the completeness of the translation implemented by t0 . The key idea of the partition technique lies in the notions of dependency between literals and dependency between actions and literals. For the sake of completeness, we include next the definition of these two notions, as they are used in the design and implementation of C P A( H ). 6
Definition 1 . Let P = F , O , I , G be a planning problem. A literal l is related to a literal g , written as l g , iff one of the following conditions holds: (1) l = g . (2) O contains an action a with a conditional effect a :  X   X  l such that g  X   X  . (3) There exists a literal h such that l h and h g . (4) The complement of l is related to the complement of g ,thatis,  X  l  X  g . Intuitively, l g means that knowledge about g might be needed in reasoning about the truth value of l after the execution of some action sequences.

A literal l is related to a set of literals  X  if l g for some g  X   X  . A disjunction of literals  X  = l The relationship between actions and literals is defined next.

Definition 2 . Let P = F , O , I , G be a planning problem. An action a is related to a literal l , written as a l , iff one of the following conditions is satisfied: (1) l  X  pre( a ). (2) There exists a literal g such that a g and g l . Intuitively, a l means that l might have influence on determining the executability of action a .

The relationships among literals and between literals and actions are used to de-termine a set of propositions, called decisive set , whose truth values must be explic-approximation-based conformant planner to be complete. The decisive set can be used in the creation of a complete partition of ext ( I ). An algorithm for this purpose is developed in Tu [2007]. Instead of starting the search for a complete partition of ext ( I ) from the set of possible initial states ( ext ( I )), the algorithm starts with a cs-state P satisfying I and extends it to a new cs-state  X  such that { ext (  X  ) |  X   X   X  } is a complete partition of ext ( I ). The algorithm for computing the initial cs-state will be reviewed next. We need the following additional notations.

Let P = F , O , I , G be a planning problem with I = I d  X  I o  X  I r . We assume that all or clauses of the form or ( f ,  X  f ) have been removed from I r . This is because an or clause of the form or ( f ,  X  f ) is equivalent to the trivial fact that f is unknown.
For a set of literals X , mod ( X ) denotes the set of all possible interpretations respect to  X  ) partial state that satisfies X . For an one -of or an or clause o ,let Similarly, let us assume that I r ={ r 1 ,..., r j } ,then Given two cs-states 1 and 2 , 1  X  2 denotes the cs-state {  X  1  X   X  2 |  X  1  X  1 , X  2  X  Intuitively, P is an initial cs-state satisfying the property ext ( P ) = ext ( I )andfor every  X   X  P ,  X  is a minimal in the sense that each  X   X  ,either or  X  l occurs in I . For ex-each partial state in P is a minimal interpretation of I . In Algorithm 1, we will use
P to compute a complete partition of I . It is possible to prove that the result of Algo-rithm 1 is a complete partition of ext ( P ) which is also a complete partition of ext ( I ) [Tu 2007]. The previous section provides the basis for the development of an approximation-based conformant planner. This section presents the theoretical background of the two techniques that help C P A( H ) achieve the level of performance exhibited in the 6 th IPC. Both techniques aim at reducing the size of the grounding problem that the planner needs to deal with during the search for a solution. The first technique, called one -of combination, reduces the size of the initial belief states by combining several one -of clauses into a single one. The second technique, called goal splitting , divides a planning problem into a sequence of smaller planning problems whose solutions can be computed sequentially and then combined into a solution of the original problem. Readers who section is organized as follows.  X  X ection 3.1 provides some preliminary definitions, focusing predominantly on for-malizing notions of dependence among propositions and actions;  X  X ection 3.2 introduces the one-of combination technique, along with its correctness proof (Propositions 1 and 2);  X  X ection 3.3 proposes the goal-splitting technique, along with proof of soundness (Propositions 3 and 4).

In the rest of the section, P denotes an arbitrary planning problem. Let a be an action, we denote and
Definition 3 . Let a be an action and be a literal. a depends on , written as a , if: (1)  X  conditions ( a ); or (2) there is an action b such that conditions ( a )  X  effects ( b ) = X  and b .
Intuitively, a depends on indicates that the truth value of could influence the result of the execution of a .By preact ( ) we denote the set of actions depending on ,thatis, preact ( ) ={ a | a } . For a set of literals L , we define preact ( L ) =  X  L  X  L preact ( ).
Consider the domain in Example 1. The action drop ( o 1 , x ) depends on holding ( o 1 ), at ( x ), and trash at ( x ). Furthermore, For the action a in Example 3, it is easy to see that a depends on f and  X  f .
Definition 4 . Two literals and are distinguishable if = and there is no action that depends on both and ,thatis, preact ( )  X  preact ( ) = X  .
 Obviously, the distinguishable relation is symmetric and irreflexive. Two sets of literals L 1 and L 2 are distinguishable if preact ( L 1 )
The dependence between a literal and an action, often used in reachability analysis , is defined next.

Definition 5 . Let a be an action and be a literal. depends on an action a , written as  X  a ,if: (1)  X  effects ( a ); or (2) there exists an action b with b :  X   X  in P and some  X   X   X  pre ( b ) such that
Intuitively, depends on a implies that the truth value of may be affected by the execution of the action a . In other words, to change the truth value of , we might need to execute the action a .By deps ( a ) we denote the set of literals that depend on a ,that the following property about the dependency of a literal on a set of actions.
L EMMA 1. Let A be a set of actions and b :  X   X  X  } X  be a conditional effect such that  X  deps ( A ) . Then,  X  deps ( A ) .

P ROOF .  X  deps ( A ) implies that there exists some a  X  A such that  X  deps ( a ), that is,  X  a .ByDefinition5(Case2),wehavethat  X  a . Thus,  X  deps ( A ).

In the following, we denote with postact ( ) ={ a |  X  deps ( a ) } the set of actions deps ( preact ( L )) plays a special role in the rest of this article and will be denoted with rel ( L ). Intuitively, a literal  X  rel ( L ) if the truth value of depends on some action whose execution might be affected by literals in L .
 We now define the notion of independence between literals and actions.

Definition 6 . Two literals 1 and 2 are independent if 1 = 2 and there exists no action that both 1 and 2 depend on, that is, postact ( 1 )  X  postact ( 2 ) = X  .
Two actions a and b are independent if there exists no literal which depends on both a and b ,thatis, deps ( a )  X  deps ( b ) = X  .

We say that two sets of literals L 1 and L 2 are independent if postact ( L 1 )  X  The idea of this technique is based on the noninteraction between actions and propo-sitions in different subproblems of a conformant planning problem. By a subproblem of a planning problem we mean a planning problem obtained from the original plan-ning problem by removing some possible initial states. As the proposed technique can be applied to any conformant planner, the discussion in this section will be based on the reasoning method using the function succ (Section 2.1). The results are valid for C A( H ) due to its completeness. We will begin with an example illustrating this idea. Example 4 . Let us consider a modified version of the 2  X  2 dispose problem from propositions and actions are similar to their counterparts in D [2 , 2 , 1] and are omitted for brevity. Assume that the initial state of the problem is given by I = I d  X  I o where and The goal of the problem is given by We can check that the sequence {  X  The four initial states are shown in Figure 1. In the figure, R denotes the robot and trash denotes the trash-can.
 Let D [2 , 2 , 2] be the problem obtained from D [2 , 2 , 2] by replacing I o with I o , where We can easily check that  X  is also a solution of D [2 , 2 , 2] . Furthermore, each solution ber of states in the initial belief state that a conformant planner has to consider in D [2 , 2 , 2] is 2, while it is 4 in D [2 , 2 , 2]. This transformation is possible because the discussed next.

The previous example shows that different one -of clauses can be combined into a single one -of clause, which effectively reduces the size of the initial belief state that the planner needs to consider in its search for a solution. Theoretically, if the size of the two one -of clauses in consideration is m and n , then it is possible to achieve a reduction in the number of possible states from m  X  n to max( m , n ). Since in many problems the size of the one -of clauses increases with the number of objects, being able to combine the one -of clauses could provide a significant advantage for the planner. The key question is when two one -of clauses can be combined. We will answer this question by defining the notion of combinability between two sets of literals.

Definition 7 . Two disjoint sets of literals L 1 and L 2 are combinable if:  X  preact ( L 1 )  X  preact ( L 2 ) = X  ;  X  rel ( L 1 )  X  rel ( L 2 ) = X  ;and  X  rel ( L 1 )  X  lit ( L 2 ) = X  and rel ( L 2 )  X  lit ( L 1 ) = X  .

Intuitively, L 1 and L 2 are combinable if, for every action sequence  X  , the execution of  X  , as well as its direct and indirect effects, will never depend on the truth value of literals in L 1 and L 2 simultaneously. When  X  is the empty action sequence, it means that L 1 is the set of literals whose truth value depends on some action whose execution might be affected by literals in L 2 . This leads to the third condition and the condition of L 1 and L 2 being disjoint. When  X  is a nonempty sequence of actions, it leads to the first and second condition: the set of actions depending on lit ( L 1 ) is disjoint from the set of related to L 1 , rel ( L 1 ) is disjoint from those that are related to rel ( L 2 ).
In the following, we will prove several properties related to the combinability between sets of literals. We need some additional notations. For a state s and a set of literals X , we define tions occurring in X with respect to s . g ( s , X ) are literals that belong to s and could be generated by actions that are dependent from literals in X except those in lit ( X ). Using these notations, one can see that, for two combinable sets of literals 1 and 2 , i ( s , 1 ), g ( s , 1 ), i ( s , 2 ), and g ( s , 2 ) are pairwise disjoint. Let conditional effects of actions of the form a :  X   X  . We consider the case a  X  preact ( 1 ) (respectively, a  X  preact ( 2 )).

L EMMA 2. Let 1 and 2 be two combinable sets of literals and s be a state. Then, for every action a  X  preact ( 1 ) and conditional effect a :  X   X  in O, it holds that: ( 1 )  X   X  ( i ( s , 2 )  X  g ( s , 2 )) = X  , and ( 2 )  X  ( i ( s , 2 )  X  g ( s , 2 )  X  rest ( s , 1 , 2 )) .

P ROOF . Observe that  X  rel ( 1 ) because a  X  preact ( 1 ). (1) We prove the conclusion by showing that  X   X  i ( s , 2 ) = X  and  X   X  g ( s , 2 ) = X  .
The preceding lemma shows that if 1 and 2 are combinable and a  X  preact ( 1 ) then the precondition of any conditional effect of a does not depend on literals in 2 or those that depend on 2 (Item (1)). Furthermore, its execution changes only literals that belong to 1 or depend on 1 (Item (2)). These conclusions allow us to define a notion of coverage between states which is invariant to the combinability between 1 and 2 and the execution of a . Before we present the precise definition of this notion, we prove a similar result for the case a  X  ( preact ( 1 )  X  preact ( 2 )).
L EMMA 3. Let 1 and 2 be two combinable sets of literals, s be a state, and a  X  ( preact ( 1 )  X  preact ( 2 )) be an action which is executable in s and a :  X   X  is a conditional effect in O. Then, the following properties hold: ( 1 )  X   X  ( i ( s , 1 )  X  i ( s , 2 )) = X  . ( 2 )  X   X  g ( s , 1 ) = X  or  X   X  g ( s , 2 ) = X  and (1) We prove the first item of the lemma by contradiction. Assume the contrary,  X   X 
We will next prove an important property of combinability sets which guarantees the soundness of planners utilizing the technique called one -of combination. The key idea of this technique lies in the reduction of the size of the initial belief state. Instead of dealing with ext ( I ), the technique allows the planner to consider a belief state S whose size is smaller than ext ( I ). This idea has been illustrated in Example 4 where two one -of clauses are combined into a single one. Given a planning problem P = F , O , I , G ,we the initial belief state. To see how is it possible, let us consider a planning problem P = F , O , I , G with a set of one -of clauses { o single one -of clause. The number of possible initial states, before the combination, is given by the formula c  X  ( n 1  X  X  X  X  X  n k ) where n i  X  2 is the number of conjunctions in o i , and c is a number depending on the other components of I (e.g., other one -of clauses or the set of or clauses). The number of possible initial states, after the combination, is c  X  max { n 1 ,..., n k } .

It is important to note that the technique is only useful if it guarantees equivalence of the set of solutions of P = F , O , S , G and P = F , O , I , G , where S is the set of possible initial states after the one -of combination. One possible idea is to require that the combination is done only when the execution of a sequence of actions  X  in every state s  X  ext ( I ) \ S will lead to the goal if the execution of  X  from S leads to the goal. We say that S covers s when this condition is true. The following is the formalization of this idea.

Definition 8 . Let S be a set of states and s be a state. We say that S covers s with respect to two combinable sets of literals 1 and 2 ,if S contains two states u and v such that: (1) i ( u , 1 ) = i ( s , 1 )and g ( u , 1 ) = g ( s , 1 ); (2) i ( v, 2 ) = i ( s , 2 )and g ( v, 2 ) = g ( s , 2 ); and (3) rest ( v, 1 , 2 ) = rest ( u , 1 , 2 ) = rest ( s , 1 , 2 ).

Figure 2 provides the intuition behind this notion. Intuitively, a state s is covered by u and v with respect to 1 and 2 if the two states u and v , together, contain all the 1) or indirectly (the set g ( u , 1 ), labeled 2) must have the same truth value in u and s . This is stated in the first condition. The symmetry between 1 and 2 results in the same requirement on v and s with respect to 2 . This requirement is expressed in the second condition (the sets labeled 3 X  and 4 X  in Figure 2). Finally, literals that are not related to 1 and 2 in some ways (the set labeled 5 in Figure 2) should have the same truth value in all three states. This leads to the third condition. We note that key idea behind the notion of coverage in Definition 8 is to guarantee the completeness of the combination of one -of clauses. In this sense, it is similar to the idea behind the covering translation in Palacios and Geffner [2009].

In the next lemma, we show that the coverage property between belief states and states is an invariant over the execution of actions.

L EMMA 4. Let S be a set of states and s be a state such that S covers s with respect to be two combinable sets of literals 1 and 2 . Let a be an action executable in S. Then, succ  X  ( a , S ) covers succ ( a , s ) with respect to 1 and 2 .

P ROOF .Since S covers s with respect to 1 and 2 , there exist u and v in S such that u , v ,and s satisfy the conditions in Definition 8. Since rest ( u , rest ( s , 1 , 2 ), we have that This shows that a is executable in s since a is executable in both u and v . We consider the following cases. (1) a  X  preact ( 1 ). Lemma 2 implies that for every conditional effect a :  X   X  such (2) a  X  preact ( 2 ). This is analogous to the previous case, thanks to the symmetry of u (3) a  X  preact ( 1 )and a  X  preact ( 2 ). Let us define the following sets of effects. The three cases prove the conclusion of the lemma.

We next apply the results of Lemma 4 in combining one -of clauses. We first define the combinability of two one -of clauses as follows.

Definition 9 . Let P = F , O , I , G be a planning problem. Two one -of clauses o 1 and o 2 are combinable if lit ( o 1 )and lit ( o 2 ) are combinable.

As noted, the one -of clauses in Example 4 are combinable. Let Assume that n  X  m .A combination of o 1 and o 2 , denoted by o 1  X  o 2 (or o 2  X  o 1 ), is the clause
Intuitively, a combination of o 1 and o 2 is an one -of clause whose elements are pairs obtained by composing each element of o 1 with exactly one element of o 2 so that each element of o 2 appears at least once in the new one -of clause.

P ROPOSITION 1. Let P = F , O , I , G be a planning problem, where G is a conjunction of literals and o 1 and o 2 are two combinable one -of clauses in P. Let P = F , O , I , G , where I is obtained from I by replacing o 1 and o 2 with o 1  X  o 2 . Then each solution of P is a solution of P and vice versa.

P ROOF . The proof requires showing that if  X  isasolutionof P then it represents a solution of P and vice versa. (1) Let us consider the case where  X  is a solution of P . The conclusion of the proposition (2) Let us now consider the case where  X  is a solution of P .Let 1 = lit ( o 1 )and Observe that the preceding proposition may not hold if P contains disjunctive goals, as shown next.

Example 5 . Let P ={ q , g , h , p , i , j } , O , I , G where:  X  I ={ one -of ( h , g ) , one -of ( p , q ) ,  X  i ,  X  j } ,  X  G = or ( i , j ), and  X  O consists of a : p ,  X  q  X  i , c : p , q  X  i , b : g ,  X  h  X  j ,and d :  X  g , h  X  j . [ a , b ]isasolutionof P but not a solution of P .
 The combinable notion can be generalized as follows.

Definition 10 . Aset X of one -of clauses is combinable if o and o are combinable for every pair of o and o in X such that o = o .
 generalized as follows.

P ROPOSITION 2. Let P = F , O , I , G be a planning problem, where G is a con-junction of literals. Let { o 1 ,..., o k } be a combinable set of one -of clauses in P. Let We have that each solution of P is a solution of P and vice versa.
 P ROOF . Trivial, by induction over k .
 Reducing the size of the initial state only helps the planner to start the search. It does not necessarily imply that the planner can find a solution. Furthermore, the technique is not always applicable, as we will show in a later section (see also Tables IV and VIII). In this section, we present another technique, called goal splitting , which can be used in conjunction with the combination of one -of to deal with large planning problems. This technique can be seen as a variation of the goal ordering technique in Hoffmann et al. [2004] and it relies on the notion of dependence proposed in Definition 6. The key idea is that if a problem P contains a subgoal whose truth value cannot be negated by the actions used to reach the other goals, then the problem can be decomposed into smaller problems with different goals, whose solutions can be combined to create a solution of the original problem. This is illustrated in the following example.
Example 6 . Consider the problem P = D [2 , 2 , 2] of Example 4. It is easy to see that the two subgoals disposed ( o 1 )and disposed ( o 2 ) are independent in that we can solve the problem by computing the plan to achieve each subgoal independently, one after another. More formally, P can be decomposed into two subproblems and O P 1 and
Let us start with a definition capturing the condition that makes the splitting of goals possible.

Definition 11 . Let P = F , O , I , G be a planning problem and let  X  G .Wesay that is G -separable if, for each  X  G \{ } we have that  X  and are independent.
For a planning problem P and a literal  X  G , a splitting of P with respect to is a pair ( P , P G \{ } ) of planning problems where P = F , postact ( ) , I , and P G \{ } =
F , postact ( G \{ } ) ,  X  , G \{ } and the  X * X  in P According to this definition, the subgoals in Example 4 are G-separable since once disposed ( o i ) is achieved, it cannot be made false by the actions which may be necessary to achieve disposed ( o j ).
 We prove that G -separability is sufficient for goal splitting.

P ROPOSITION 3. Let P = F , O , I , G be a planning problem. Assume that  X  G is G-separable. Let P = F , postact ( ) , I , and  X  be a solution of P .LetP G \{ } =
F , postact ( G \{ } ) , I , G \{ } , where I = succ (  X , I ) ,and  X  be a solution of P  X  ;  X  is a solution of P.

P ROOF . Trivial since postact ( G \{ } ) does not contain any action that can make  X  true.

Proposition 3 guarantees the soundness of the splitting technique. On the other hand, it is easy to see that not every plan of P can be split into two parts  X  and  X  such that  X  isasolutionof P and  X  isasolutionof P G \{ } . It is also possible that not every decomposition of P can be used to search for a solution of P , even when the goals are separable. This can be seen in the following example.
 Example 7 . Consider the problem.

Clearly, h and  X  k are independent because postact (  X  k ) = X  . Similarly,  X  h and k are independent because postact (  X  h ) = X  . Therefore both h and k are G -separable with respect to h  X  k . Furthermore, the problem has a solution [ b , a ].
 Let us consider performing the goal splitting of this problem into two problems P k ={ f , g , h , k } , { b : g , f  X  k } , { f , g ,  X  h ,  X  k } , k and P h ={ f , g , h , k } , { a :  X  X  g , h } , { f , g ,  X  h , k } , h .
 This splitting allows us to find the plan [ b , a ]. On the other hand, the splitting of P into P h = { f , g , h , k } , { a :  X  X  g , h } , { f , g ,  X  h ,  X  k } , h and
P k ={ f , g , h , k } , { b : g , f  X  k } , I , k yields no solution.
 Proposition 3 can be generalized as follows.

P ROPOSITION 4. Let P = F , O , I , G be a planning problem and G be the set of P  X  X  1 = I and  X  X  j = succ (  X  1 ; ... ;  X  j  X  1 , I ) for 1 &lt; j  X  k.
 Then,  X  1 ; ... ;  X  k is a solution of P.

P ROOF . By induction over k . The internal organization of the proposed C P A( H ) planner is illustrated in Figure 3. The planner is composed of two modules.

The first module ( Preprocessor ) is a static analyzer that performs a number of trans-formations of the problem specification. Along with a grounder (which also applies standard simplifications, such as forward reachability), the preprocessor applies some novel transformations ( one -of clause combination and goal splitting) aimed at drasti-cally reducing the size of the search space. The second module ( Planning engine )isa heuristic search engine implementing forward search planning. The next subsections present the design of these modules.
 C
A( H ) employs the succ  X  A function in the context of a planning algorithm which im-plements forward search planning using a traditional best-first heuristic search. The procedure is sketched in Algorithm 2.
 C
A( H ) computes the following basic heuristics.  X  The cardinality heuristic. Since the initial cs-state could potentially be the same as prefer cs-states that have small cardinality. In other words, h card ( ) =| | where is a cs-state. Note that we use this heuristic in a forward fashion, and this is different from its use in Bertoli et al. [2001] and Bryce and Kambhampati [2004].  X  The relaxed graphplan heuristic. For a cs-state , we define h rgp ( ) =  X   X  d (  X  ), where d (  X  ) is the well-known sum heuristic value given that the initial state is  X   X  X  X  p | p  X  F , p  X   X ,  X  p  X   X  } [Nguyen et al. 2002]. The formula h significantly from the additive heuristic in Bonet and Geffner [2001] in that the summation is over the partial states belonging to the cs-states, not over the subgoals belonging to the goal.  X  The number of satisfied subgoals. This heuristic counts the number of satisfied sub-goals and is denoted by h gc ( ). Formally, h gc ( ) =  X   X  sat (  X  ) where sat (  X  )isthe number of subgoals satisfied by  X  .
 Observe that an advantage of these individual heuristics is that they are very inexpen-sive to compute. On the other hand, none is admissible. h gc was implemented in C P A + , the predecessor of C P A( H ), with very positive results. The addition of h card relies on the complexity results indicating that conformant planning is in general harder than solving classical planning, and thus the desire of moving towards a reduced level of uncertainty (that is, giving preference to transitions towards a problem that is closer to being classical). The third heuristic, h rpg , is added to remedy the situation, frequently observed, where the combination of the other two heuristics is not informative, that is, the search space contains many cs-states with the same heuristic value for h card and h gc . We have experimented with several heuristics proposed in Nguyen et al. [2002] that can be extracted from the planning graph. h rpg has been selected due to the fact that it is inexpensive to compute and yields reasonably good performance.
 C P A( H ) implements a combination of the aforementioned heuristics, denoted by h css . Formally, h css is defined as We say that has a better heuristic value than , denoted by h css ( ) &gt; h css ( ), if: This is a slight variation of a lexicographic ordering among the values of h css .Inother words, the planner prefers cs-states with smaller size. Among the cs-states with the same size, the planner prefers those with higher number of satisfied subgoals. Finally, among the cs-states with the same size and the same number of satisfied subgoals, the planner prefers those with the smaller relaxed graphplan heuristic value. While the main reason for preferring h card over h gc and h rpg lies in the low-complexity result of classical planning versus conformant planning, the ordering between h gc and h rpg is obtained via experiments. The main goal of the preprocessor is to simplify the planning problem, using different techniques. This section presents the basic definitions underlying these techniques. Among them, some are standard (e.g., reachability analysis); others are specific to C
A( H ). The key to the analysis in the preprocessor is the notion of dependence between actions and propositions, similar to the notion of dependence between actions and literals explored in Son and Tu [2006] and presented in the previous section. In what follows, we denote with P an arbitrary but fixed planning problem. 4.2.1. Standard Transformations. The preprocessor starts its operations with a number of basic normalization steps, aimed at reducing the number of propositions and the number of actions present in the problem specification. These steps have also been implemented by several other planners. More precisely, the preprocessor implements the traditional forward reachability simplification aimed at detecting: (1) propositions whose truth value cannot be affected by the actions in the problem (2) actions whose execution cannot be triggered with respect to the extended initial
This process can be modeled as a fixpoint computation and easily be implemented using Prolog. As the forward reachability analysis was developed originally for domains with complete information, the preprocessor of C P A( H ) starts the computation with an extended initial state , defined by The set of forward applicable actions, f w a , and relevant propositions, f w p , are defined by and The preprocessor computes f w a and f w p , and removes from the problem description those actions and propositions not belonging to f w a and f w p , respectively. 4.2.2. Combination of one -of Clauses. Proposition 2 guarantees the soundness and com-pleteness of the one -of combination technique. For this reason, we implement this technique in the planner C P A(H). This requires a procedure for detecting combinable groups of one -of clauses. Algorithm 3 is used to detect sets of combinable one -of clauses of a planning problem P . It is easy to see that the running time of Algorithm 3 is poly-nomial in the size of P , because testing if two sets of literals are combinable can be done in polynomial time in the size of P , and the number of pairs that need this test is quadratic in the number of propositions.
 The combination of the one -of clauses is completed with the implementation of Algorithm 4, which computes the combination of a set of combinable one -of clauses.  X  ( o 1 ,..., o k ). 4.2.3. Goal Splitting. The main difference between the one -of technique and the goal-splitting technique lies in that the former is sound and complete but the latter is only sound (Example 7). Completeness of the goal-splitting technique could be guaranteed if: ( i ) an appropriate order among the goals can be found; or ( ii ) the goals are independent. The former is a well-known hard problem [Hoffmann et al. 2004] and the latter proves to be too strong (none of the domains from the literature satisfies this condition). For this reason, we decided to implement the goal-splitting technique as an option for C A( H ), that is, C P A( H ) X  X hen run with this option X  X ight be incomplete.
The preprocessor of C P A( H )checksforthe G -separability between subgoals (Definition 11) and splits a planning problem P into a sequence of problems P 1 ,..., P n (Proposition 4), whenever it is possible. The main reason behind this decision is that checking for G -separability according to Definition 11 is polynomial in the size of P . It is worth mentioning that in our experiments, whenever a solvable problem can be split, the sequence of subproblems does yield a solution. C
A( H ) is built from the C++ source code of C P A+ [Son and Tu 2006]. The main dif-ferences between C P A+ and C P A( H ) lie in the use of a more complex heuristic, the application of the one -of combination technique, and the use of the goal-splitting tech-nique in C P A( H ). Since both techniques are characterized by syntactical conditions, they can be processed by a static analyzer. We will now elaborate on the implementa-tions of the two components of C P A( H ): the preprocessor and the planning engine. The preprocessor is implemented in Prolog (specifically, SICStus Prolog). The choice of Prolog was natural, as it provides several features needed by the problem at hand.  X  X he components of a problem specification have an obvious representation as Prolog terms and clauses; PDDL actions and fluents have parameters and they can be encoded as complex terms, for example, the action go up with parameters elevator, floor, floor , is naturally represented by the term go up(Elev,Floor1,Floor2) .  X  X DDL statements can be readily mapped to a collection of Prolog rules; in particular,
Prolog allows us to keep a nonground representation, and offers a quick access to the various components of the domain specification. For example, the PDDL action specification of the action go up is translated to the Prolog rules in Figure 4.
Grounding can be obtained for free by simply collecting all valid instances of an action (e.g., using setof ). Unification allows us to easily select components of the problem specification that meet desired requirements, for example, a simple goal like executable(go up(e0,X,Y),L) gives us access to the executability conditions of any instance of the action go up targeting elevator e0 .  X  X iewing action specifications as Prolog clauses allows us to write elegant meta-interpreters to perform abstract executions; for example, if we represent an approx-imate state as an ordered list L of terms (representing the fluent literals that hold in that partial state), then determining the executable actions and the derived con-sequences from applying such actions can be reduced to simple Prolog statements, a findall applied to the goal executable(A,C), ord subset(C,L), causes(A,Cons, ) .
Meta-interpreters allow us to simulate both progression (i.e., if action is applicable, apply and repeat) and regression (i.e., from the goal find actions that produce the goal and replace goal with their preconditions). Note that abstractions of progressions and regression are needed to compute forward reachability and goal relevance.

The preprocessor maps the input PDDL theory to a collection of Prolog clauses. This mapping nicely avoids the need of explicitly grounding the problem specification a priori. The transformations are implemented as fixpoint computations on the Prolog clauses representing the problem specification. As we have mentioned earlier, the planning engine is built from the source code of C
A+ [Son and Tu 2006] and is implemented as a C++ program, running on a Linux, gcc 4.2.1 version, with STL library. A partial state is implemented as a set (a basic data structure in STL) of literals. The engine implements the best-first search over the search space of cs-states (Algorithm 2). Each cs-state is a data structure consisting of a set of partial states, a plan to reach that cs-state, and the heuristic values: h card , h gc ,and h rpg . A modified version of the algorithm presented in Long and Fox [1999] is implemented to compute h rpg . succ  X  A is used to compute the next cs-state. A hash table (respectively, priority queue) is used to store the visited (respectively, unvisited) cs-states. A special module is de-veloped to compute the initial cs-state, which consists of the set of initial partial states and guarantees the completeness of C P A( H ) (Algorithm 1).

Choosing to implement the initial cs-state as a set (of the set of initial partial states) makes the computation of the successor cs-state (the result of succ  X  A ) easier. The main disadvantage of this choice is that the size of the initial cs-state can be exponential in the size of the number of object constants in the problem. This is also the main reason why reducing the size of the initial cs-state is critical to our planner. In this section, we present some of the results of our experimental evaluation of C P A( H ) and the effectiveness of the two main techniques employed in C P A( H ) in other planners. We compare C P A( H ) with several other conformant planners: Conformant-FF (CFF) [Brafman and Hoffmann 2004], KACMBP [Cimatti et al. 2004], POND [Bryce et al. 2006], t0 [Palacios and Geffner 2009], and DNF [To et al. 2009]. These are some of the fastest conformant planners on most of the benchmark domains in the literature. The authors of To et al. [2009] recently developed two other conformant planners whose performance is comparable to DNF. For this reason, we only present the results of our comparison with DNF. We would like to mention that, in this article, we only compare C P A( H ) with other conformant planners with the same capabilities. Among other things, the representation language employed in the discussed planners is, in one way or another, a propositional language with limited expressive power. Furthermore, all these planners are complete. For this reason, we do not compare C P A( H )withthe PKS system Petrick and Bacchus [2002] (improved in Petrick and Bacchus [2004]) which employs a richer representation language and the knowledge-based approach to reason about effects of actions in the presence of incomplete information; furthermore PKS is incomplete and requires a different encoding (XML-based encoding) which is different from all planners used in our experiments.

To make the comparison between the different planning systems as fair as possible, we try our best in not altering the problem specifications obtained from the different repositories. Nevertheless, this is almost impossible, since the collected planners do generally disagree on input formats. For example, KACMBP requires the input in a different format, all other systems receive the same PDDL input in all domains and t0 does not support negative preconditions.

The experiments have been conducted on a Linux platform, based on an Intel Pen-tium 4 3.06 GHz chipset and 1GB of RAM. We tested the performance of C P A( H )using four collections of benchmarks, discussed in the following sections. 8 The IPC-05 domains [Bonet and Givan 2006] consist of six domains used in the 2006 planning competition. The adder domain is the synthesis of an adder Boolean circuit. The coins domain is similar to the well-known transportation domain, where the goal is to collect coins from different, initially unknown, positions. The sortnet domain is a synthesis of sorting networks; the domain has disjunctive goals and a large number of possible initial states. The comm domain encodes a communication protocol; the domain X  X  main difficulty lies in the huge size of the initial state. The uts domain is the computation of universal transversal sequences for graphs; in this domain, the numbers of actions and uncertainty are more manageable compared to other domains. The test suite also contains some problems from the block-world domain.

Table II describes a few parameters of these problems. The table describes the num-ber of actions, propositions, goals, and initial states; the table also indicates the reduc-tion in these numbers achieved by the previously mentioned simplifications. In this table, the theoretical number of actions (respectively, propositions) equals the number of ground actions (respectively, propositions) obtained by instantiating the variables in the domain description with their corresponding object constants given in each in-stance. The number of actions (respectively, propositions) after the simplification is the number of actions (respectively, propositions) present after the standard transforma-tions (see Section 4.2.1). For example, in the comm-10 instance, the theoretical numbers of actions and propositions are 529 and 419, respectively. The simplification reduces these numbers to 203 and 69, respectively. The most significant reduction obtained is, however, in the number of partial states in the initial state: a reduction from 2 11 to 2. Observe, however, that the reduction in the number of initial partial states is achieved only in three out of six domains.

Table III contains some representative results 9 of our experiments with the IPC05 domains. For each instance, we record the time needed to find the first solution and the length of the solution. The time for C P A( H ) consists of the preprocessing time and the time needed by the planning engine. As can be seen, our planner competes well with the other planners on most domains. There is only one domain, adder , where our planner fails to find a solution (time-out), while other planners are successful. Our planner can find solutions in several instances where others fail (e.g., in sortnet , where t0 and CFF cannot be used, in comm where KACMBP times out). t0 is more consistent and has better performance in most of the domains that are applicable to it. Note that some of the results reported in Table III for the planner planner t0 used in our experiment, obtained from one of its authors, is an earlier version of t0 that does not consider disjunctive goals. C P A( H ) is comparable to CFF in most instances, except for comm-25 . In general, DNF performs better than C P A( H ). One of the main reasons for this is the compact belief state representation used by DNF. POND tends to be faster in smaller instances but it does not seem to scale up well in larger instances, compared to C P A( H ). It is interesting to observe that POND and KACMBP are especially good in the sortnet domain. It seems that the underlying representation of the initial belief state employed by these planners is well-suited for this domain. We observe that the one -of combination is not applicable in this domain. This implies that the size of the initial cs-state is large for C P A( H ) which is a reason for the poor performance of C P A( H ) in this domain comparing to POND or KACMBP. The inapplicability of the one -of combination also indicates that translation used by t0 might result in a problem whose size is too large for its classical planner to deal with.
It should be mentioned that the combined heuristics h css is not an admissible heuristic and this is reflected in the length of the solutions found by C P A( H ); they are often longer than those found by other planners. This can also be seen from the results of DNF, which employs similar heuristic to C P A. It is also interesting to note that only KACMBP can solve the adder-01 and adder-02 instance. This domain has a very large number of actions whose preconditions are empty, and the cardinality heuristic does not help, since the number of states is constant in every step of the computation. Furthermore, the goal is a huge formula with disjunctions, which might indicate that the treatment of formulas in KACMBP is better than other planners. This test suite consists of the domains that seem to be challenging for conformant planners, as detailed in Palacios and Geffner [2007]. These are variations of the grid problems. dispose is about retrieving objects whose initial location is unknown and placing them in a trash-can at a given location. push-to is a variation where objects can be picked up only at two designated positions in the grid to which all objects have to be pushed. 1-dispose is a variation of dispose where the robot hand being empty is a condition necessary for the pick-up action. look-n-grab is about picking up the objects that are sufficiently close, if there are any, and each object picked has to be dropped in the trash-can before continuing. Table IV summarizes the characteristics of these benchmarks.
 Table V contains the results of our experiments with the challenging domains from Palacios and Geffner [2007]. We obtained the scripts for generating these domains from the authors of t0 . As described in Palacios and Geffner [2007], CFF, POND, or KACMBP cannot handle these domains. For this reason, we did not compare C P A( H ) with CFF, POND, and KACMBP planners on the challenging domains.

As can be seen, C P A( H ) is faster than t0 in most of the challenge domains. It can also solve more problems compared to t0 . In these domains, the cardinality heuristic does very well. Yet C P A( H ) tends to produce longer plans than t0 .

As in other domains, DNF performs better than C P A( H ) and can solve more problems than t0 . It is interesting to observe that the solutions produced by DNF are shorter than those produced by t0 and C P A( H ). DNF also displays better scalability as it is the only one that can solve l-dispose-8-2 or look-n-grab-8-1-2 .

The main reasons for the better performance of C P A( H ) versus t0 have been dis-cussed in detail by the authors of t0 in Palacios and Geffner [2009] which included the effectiveness of the one -of combination technique, the expensive complete transla-tion used by t0 in solving these problems, and the effectiveness of the heuristic h css in domains such as dispose . This test suite consists of six domains used in the 2008 planning competition. The blockworld and adder from the previous competition are reused without any change. A modified version of the uts , which was also used in the 2006 competition, is used in the 2008 competition. In particular, the topology of the mobile ad hoc network is fully known in the IPC-05 domain while in this version, the topology is partially known. The raos-keys domain is to find keys behind locked gates under different lights. It is not known which key opens which gate and which key is located under which light. The difficulty in this domain is the size of the initial state, which increases exponentially in the number of lights and keys. The forest domain is a hierarchical structure domain. The top level is an unobservable grid navigation problem with a classical subproblem at each grid point. The classical subproblem for each grid node is randomly generated from the set: a two-city logistics problem, the Sussman anomaly blockworld, or a small grid navigation problem. In this domain, the size of the grid influences the size of the initial belief state. The characteristics of these domains are detailed in Table VI.
Table VII contains the results of our experiments with the domains from IPC-06. We report here only the results on the domains that were not used in the IPC-05 or the challenging domains. 10
It is noted that t0 performed much better than other planners in forest . We suspect that the cardinality heuristic is not effective here, since the initial belief state is small (in size). On the other hand, this implies that the size of the problem obtained by the translation of t0 is small, that is, the input to FF by t0 is small. This could be the reason why t0 performs better in this domain. The fourth test suite contains some domains from the distribution of CFF and t0 ,such as the ring , safe ,and logistics domains, and were used in previous IPCs. In the ring domain, one can move in a cyclic fashion (either forward or backward) around an n -room building to lock windows. Each room has a window and the window can be locked only if it is closed. The uncertainty lies in the lack of knowledge about the initial state of the windows. The goal is to have all windows locked. In the safe domain, a safe has one out of n possible combinations, and one must try all combinations in order to open the safe. The logistics domain is the  X  X ncomplete version X  of the well-known logistics domain. The uncertainty is in the initial position of each package within its origin city. We add the cleaner domain to this test suite. It is a modified version of the ring domain. The difference is that instead of locking the window, the robot has to clean objects. Each room has p objects to be cleaned. Initially, the robot is in the first room and does not know whether the objects are clean. The goal is to clean all of the objects. The properties of these benchmarks are summarized in Table VIII.

Table IX reports the results of our experiments. In these domains, CFF provides the best results. However, it times out in safe-50 , while both t0 and C P A( H ) can solve this instance. C P A( H ) and POND provide comparable performance, though C P A( H ) can solve a larger number of instances. The previous subsections show that C P A( H ) performs very well on a variety of bench-marks. We would like to note that the performance and scalability of C P A( H ) are tied to the new heuristics and the one -of combination and goal-splitting techniques. This can be observed from the fact that C P A( H ) is a modification of C P A+ [Son and Tu 2006] and C P A [Tu et al. 2011], obtained by: ( i ) adding the two preprocessing techniques; and ( ii ) updating the heuristic function.

As can be seen in Tu et al. [2011], C P A cannot even solve sortnet-11 , or lags behind t0 in most instances of uts . In our experiments, C P A+ cannot even start the search in most of the challenging domains. This is because the completeness condition of C P A+ does not reduce the size of the initial cs-state. The comparison between C P A( H )and C
A+, presented in Tran et al. [2009], proves the usefulness of the two simplification techniques.

To study the effects of the new heuristic function on the performance of C P A( H ), we also ran an experiment comparing C P A( H )andC P A( H )  X  with the original heuristic function (only number of satisfied subgoals). C P A( H ) outperforms C P A( H )  X  in all do-mains, sometimes with significant margin (e.g., coins-20 2 ms versus 45 ms; dispose-8-3 300 ms versus 600 ms; uts-10 23 ms. versus time out). This indicates that the new heuristics function contributes significantly to the efficiency of C P A( H ).
We will now present the results of some of our experiments which show that the proposed techniques can be useful in other planners. We tested the effectiveness of the one -of combination in POND and the goal-splitting technique in CFF.

We selected POND to experiment with the one -of combination because a combina-tion of several one -of clauses is a one -of clause whose elements are conjunctions of literals, and POND is the only planner capable of accepting this type of inputs. Table X shows the results of our experiment in the comm and coins domains. As we can see, the performance of POND improves in these problems, and the improvement is more significant when the size of the problem is large. However, this technique does not help POND to scale up: it stops with coins-17 and comm-21 ( comm-16* is smaller than comm-17 but larger than comm-16 ). In some cases, the new representation requires more time for grounding and instantiation and might lead to a larger number of generated states and longer plan (for coins-15 , POND spends more time in grounding and instantiation (0.03 sec versus 0.00 sec); generates more states (743 versus 688); and computes longer solutions (144 versus 124 actions)). We observed that the idea of the one -of combina-tion is related to the definition of a basis for a conformant planning problem [Palacios and Geffner 2009] and has been implemented in the planner t1 [Albore et al. 2011], asuccessorof t0 . It is easy to see that one -of -combination provides a way to identify a basis for a conformant planning problem. The notion of a basis, however, is more closely related to the notion of a decisive set in Son et al. [2009] than to the one -of combination.

We tested the impact of the goal-splitting technique in CFF in the coins domain, where CFF works well but cannot scale up to solve the instances coins-21 ,. . . , coins-30 . By using this technique, CFF can scale up and solve all instances of this domains, with time ranging from 2 . 13 seconds (for coins-25 ) to 103 . 14 seconds (for coins-23 ). The difficulty in these problems lies in the large number of elevators and coins. The goal-splitting technique divides each instance into a sequence of subprob-lems, each dealing with one coin but still keeping all elevators. CFF can deal with it and goes on solving all subsequent problems. We observed that CFF spends most of the time finding the solution for the first problem. This is reasonable since the locations of the elevators are unknown in the first problem and some of these locations will be known at the end of the first solution. In this article, we presented the complete design and implementation of an efficient conformant planner, called C P A( H ). The planner was the winner of the 2008 Inter-national Planning Competition X  X ncertainty Track. The performance and scalability exhibited by C P A( H ) can be fundamentally related to three main aspects. (1) We use approximations to reduce the size of the belief states. (2) We introduce of simplification techniques (i.e., forward reachability, one-of combi-(3) We use a combination of simple but effective heuristic functions.

In the article, we analyzed these aspects, with particular focus on laying the theo-retical foundations to support the simplification techniques. The understanding of the properties of these techniques is essential to determine their scope, how they can be implemented, and how they can be adapted to other planning systems. The article also presented a detailed analysis of how the three techniques have been implemented in the context of C P A( H ), enabling the system to demonstrate the level of performance necessary to outperform other planning systems in the 2008 competition. A prelimi-nary investigation on the usefulness of the proposed techniques in other planners has been presented, and the results suggest that these two techniques are general and could be useful in the development of other conformant planners.

The future developments of this project include exploring whether alternative meth-ods for the internal implementation of cs-states (e.g., OBDD) can further enhance performance, and whether the proposed techniques could be strengthened to deal with domains where the current techniques are inapplicable. For example, the current sim-plification techniques do not take into consideration the representation of the initial belief state (e.g., CNF, DNF, or prime implicates). This could be a source for improve-ment. Another interesting question would be the applicability of other heuristics such as those developed in Cushing and Bryce [2005].

Finally, let us observe that we did not focus on the efficiency of the preprocessor in this version of C P A( H ). More precisely, the current implementation of the preprocessor is composed of fairly naive fixpoint computations, and as such it is not particularly fast (especially for certain large instances, as in the comm domain). An optimized code for this module could improve the overall performance of C P A( H ).

