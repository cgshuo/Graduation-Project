 University of Stuttgart University of Stuttgart heads of those phrases is usually extracted from gold-standard parse trees. We show that the
PP attachment does not produce realistic performance numbers. We argue that PP attachment without using information from the gold-standard oracle. 1. Introduction One of the main challenges in natural language parsing is the resolution of ambiguity. One frequently studied type of ambiguity is prepositional phrase (PP) attachment.
Given the quadruple (v,n1,p,n2), where v is the head of a verb phrase, n1 is the head of an NP1 dominated by v, p is the head of a prepositional phrase, and n2 the head of an
NP2 embedded in the PP, the task of PP attachment is to determine whether we should attach the PP to the verb v or the noun n1 (Hindle and Rooth 1993). provides the quadruple (v,n1,p,n2), where we define an oracle as a mechanism that pro-vides information that is not present in the data in their naturally occurring form. In PP attachment, the oracle is usually implemented by extracting the quadruple (v,n1,p,n2) from the gold-standard parse trees. In an application, a PP attachment module would analyses produced by a parser X  X r reattach them. The problem with oracle-based work on PP attachment is that when the parser does not find the gold-standard NP1 or PP, for instance, the attachment ambiguity is not recognized, and the correct solution cannot method to find the correct attachment if the heads n1 or n2 are not correctly identified by the parser. The oracle approach to PP attachment differs from many other tasks in
NLP like part-of-speech tagging or parsing, in which usually no data based on manual parsing accurately reflect the performance we would expect in an application whereas PP reattachment results arguably do not.
 when an oracle is available. This means that the current evaluation methodology for
PP attachment does not produce realistic performance numbers. In particular, it is not clear whether reattachment methods improve the parses of state-of-the-art parsers. This argues for a new evaluation methodology for PP attachment, one that does not assume that an oracle is available.

Bikel X  X  parser (Bikel 2004). With the removal of the oracle and the introduction of the parser, the baseline performance also changes. It is no longer the performance of always choosing the most frequent attachment. Instead, it is the attachment performance of the parser. In fact, we will see that it is surprisingly difficult for reattachment methods to beat this baseline performance.
 attachment. We find that standard parsers do well, further questioning the soundness of the traditional evaluation methodology.

Manning, and Ng (2004; henceforth TM&amp;N). We call these three methods PP reattach-ers . We selected these three methods because they perform best on the widely used PP attachment evaluation set created by Ratnaparkhi, Reynar, and Roukos (1994). We call this data set RRR . RRR consists of 20,801 training and 3,097 test quadruples of the form (v,n1,p,n2). The performance of the three reattachers on RRR is shown in Table 1. reattachers on oracle-based reattachment with that of a standard parser (using artificial sentences built from the RRR set) and finds no significant difference in performance.
In Section 3, we look at reattachment without oracles (using the Penn Treebank) and argue that realistic performance numbers can only be produced in experiments without oracles. Sections 4 and 5 discuss the experiments and related work. Section 6 concludes. 470 2. Experiment 1 2.1 Method
In Experiment 1, we convert the RRR set into artificial sentences. The data consist of quadruples of the form (v,n1,p,n2): verb, noun, preposition, and embedded noun. To create sentences, we add the generic subject they . For example, the quadruple join board as director V becomes: example, subject and verb need not agree.
 of the embedded noun n2 because the Bikel parser does not percolate non-head infor-standard lexical head X  X ead relationships. To simulate a parser that takes into account noun: (e.g., have-of-million vs. revenue-of-million ). To avoid problems with sparseness, we re-strict the annotation to the N most frequent n2 nouns of the RRR train data. We chose
N = 20 based on the performance on the development set. 3 2.2 Results
Table 2 shows the accuracy of Bikel X  X  parser in bilexical and trilexical mode. The parser correctly identify the PP. We call these cases NAs (non-attachment cases) and compute three different evaluation measures: NA-error NAs are counted as errors.
 NA-default Noun attachment (the more frequent attachment) is chosen for NAs. NA-disc(ard) NAs are discarded from the evaluation.
 ambiguity is recognized, namely, non-NA cases. It would then change the attachment decision in these cases. After reattaching, for this particular set of cases, the accuracy would correspond to the reattachment method X  X  accuracy. We are interested in whether the reattacher is able to beat the performance of the parser we use. realistic evaluation measure, because when integrated into a parser, reattachers can only correct the attachment in those sentences where the attachment ambiguity was correctly identified. The parser often identifies one of the possible attachments correctly, but not the other. The reattacher cannot operate on these sentences.
 and TM&amp;N on the same 3,082 sentences (which O&amp;M and TM&amp;N kindly provided to us) and the results of our implementation of the C&amp;B-algorithm. 3. Experiment 2
The setup in Experiment 1 is typical of work on PP attachment, but it is not a realistic model of PP attachment in practice. In Experiment 2, we look at reattachment in natu-rally occurring sentences if an oracle that identifies the two alternative attachments is not available.
 ple the sentence in the Penn Treebank (PTB) 0.5 it was extracted from. However, we were not able to train the Bikel parser on this set because of inconsistencies and other versions, a considerable number of the quadruples was missing in PTB 3.
 quadruples had been extracted from because for testing we only need string inputs (and the gold-standard attachment annotations of the quadruples).
 number of 49,208 PTB 3 sentences after removing (i) the 3,097 test sentences and (ii)
PTB 3 sentences that correspond to RRR development set quadruples. (Note that some test sentences had no corresponding sentence in PTB 3.) sentences) RRR-sent . The RRR-sent training set contains a mixture of sentences with 472 and without PP attachment ambiguities. We believe that this is the optimal experimental setup because parsers are usually not trained on a subset of sentences with a particular construction. RRR-sent is available at http://ifnlp.org/  X  3.1 Method
In bilexical mode, we trained and tested the parser as before except that RRR-sent was parser and ran it on the test data to identify the n2 heads of embedded noun phrases.
We then head-annotated the prepositions in RRR-sent (both train and test data) using left unchanged. Note that prepositions also remain unannotated in sentences where the parser does not recognize the embedding PP. We then trained and tested a second instance of the Bikel parser on the head-annotated data. 3.2 Results
Table 3 shows results for Experiment 2. There are many more things that can go wrong in a long natural sentence than in a 5-word artificial one. Thus, the parser recognizes the PP ambiguity less often in this experiment without an oracle than in Experiment 1, where an oracle was available.
 in all cases). For NA-discard there is no significant difference. 4. Discussion
In Experiments 1 and 2 the cases in NA-discard are the only ones where an ambiguity methods could actually be employed. But the reattachers fail to considerably improve the parser on these sentences. It is only the absence of an oracle that makes the parser seem worse in the NA-error and NA-default cases. This result shows that PP attachment methods need to be evaluated with respect to whether they can improve a parser. we use information about the noun in the PP. We believe that one reason for this is that we cannot identify the head noun n2 with certainty due to incorrect preliminary parses.
This again points to the methodological problems in previous work on PP attachment: it relies on an oracle that provides the two alternative attachments, including the four heads involved. Results on the traditional task have a tenuous relation at best to perfor-mance on PP attachment if no oracle is available.
 ber of quadruples (more than 1,000) in the RRR training set do not occur in the RRR-sent training set due to differences between the 0.5 and 3 treebanks. Conversely, at least as many of the quadruples we extracted from the training set in RRR-sent do not match quadruples in RRR. 5. Related Work approach (Stetina and Nagao 1997; Ratnaparkhi 1998; Pantel and Lin 2000; Olteanu 2004; Bharati, Rohini, Vishnu, Bendre, and Sangal 2005), including several recent papers (Calvo, Gelbukh, and Kilgarriff 2005; Merlo and Ferrer 2006; Volk 2006; Srinivas and
Bhattacharyya 2007). None of these papers attempt to improve a parser in a realistic parsing situation.
 without oracles (Olteanu 2004; Atterer and Sch  X  utze 2006; Foth and Menzel 2006). Our experimental results suggest that the evaluation strategy of integrating PP reattachers into a baseline parser should be adopted more widely.

Web data, or named-entity recognizers and stemmers, we restrict ourselves to com-paring non-oracle reattachment to work that is evaluated using the training data only (and no other resources) as input. Although we have not replicated experiments with additional resources (e.g., Toutanova, Manning, and Ng 2004; Stetina and Nagao 1997), the question as to the significance of oracle-based results for realistic NLP applications arises independently of the use of resources. 6. Conclusion
Our experiments show that oracle-based evaluation of PP attachment can be mislead-ing. Comparing the bilexical and trilexical cases we note the following: when accurate n2 information (i.e., oracle-based information about which word heads NP2) is added in Experiment 1, disambiguation results improve. When noisy n2-information is added in Experiment 2 (in the absence of an oracle), disambiguation results get worse. Simi-larly, oracle-based disambiguation performance (84.14%) is much higher than unaided performance (80.01%) in Experiment 2.
 state-of-the-art parsers. Although the differences between the best parsing results and the best reattacher results are not significant in Experiments 1 and 2, the reattachers had consistently higher performance. This makes it likely that PP reattachment (performed either by a reattacher or by a reranker [Charniak and Johnson 2005; Collins and Koo 2005] that processes a feature representation with PP attachment information) would improve the parsing results of state-of-the-art parsers. This is a promising direction for future work on PP reattachment.
 ment is problematic. It computes numbers that are overly optimistic when compared to 474 the performance that is to be expected in realistic applications without oracles. Instead,
PP reattachers should be directly compared to state-of-the-art parsers to show that they importantly, PP reattachers should be tested on the type of data they are intended to process X  X utput from a parser or another module that detects PP attachment ambigu-ities. Evaluating reattachers on the output of an oracle allows no inferences as to their real performance.

PP attachment is one of the tasks that has stimulated much interesting research. There available, however. Given the differences we have found between evaluations with and without oracles, one should think carefully about the experimental framework for PP attachment work one adopts and whether any oracle-based findings carry over to more realistic scenarios without oracles.
 ations likely apply to other disambiguation tasks such as attachment of relative clauses and coordinated phrases. In our opinion the evaluation of disambiguation algorithms on oracle-based data should always be justified by stating specifically what has been learned for the non-oracle case.
 Acknowledgments References
