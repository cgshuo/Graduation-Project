 Studies have shown that imbalanced training data can adversely affect classifica-tion accuracy of a classifier [7]. In particular, SVM classifiers are known to favor negative decisions when trained with significantly larger proportion of nega-tive examples [1, 11]. In multi-label cla ssification problem using SVM classifiers, imbalanced training data can often be caused by the one-against-all learning strategy. That is, with positive training examples given for each category, the one-against-all strategy trains SVM classifier of the category using the training examples belonging to the category as positive examples, and all training ex-amples not belonging to the category as negative examples. In our study, we address the problem of imbalanced text classification using SVM classifiers with one-against-all strategy.

We focus on the under-sampling approach and propose a generic algorithm known as FISA (Feature-based Instance Selection Algorithm), to select only a subset of negative training documents for training SVM classifier. FISA operates in two steps: feature discriminative power computation and instance selection . In the first step, the discriminative power of each feature is computed using some feature selection technique. In the s econd step, for each negative training document, a representativeness score is computed based on both the number of discriminative features appearing in the document and their discriminative pow-ers. The higher the score, the more significant the document in representing the negative training examples, and hence more useful in learning SVM classifiers. Given a smaller training set consisting of only negative training documents with high representativeness scores, a SVM classifier will take a much shorter time to learn while delivering comparable or even better classification accuracy.
We evaluated FISA on the 20-Newsgroups dataset. Two FISA methods us-ing feature selection techniques Odds Ratio and Information Gain have been evaluated, known as FOR and FIG respectively. FOR and FIG were compared with baseline SVM, Different Error Cost (DEC) method and Stratified Random Instance Selection (SRIS) method. Bo th FOR and FIG delivered significantly better classification accuracies than DEC using only 35% negative training ex-amples and 60% learning time required by DEC. Our experiments also showed that random selection of negative training examples compromised the classifica-tion accuracy.
 The rest of the paper is organized as follows. We survey related work in Section 2 and discuss FISA in Section 3, followed by experiments and results in Section 4. We finally conclude this paper in Section 5. The two main approaches to address the imbalanced classification problems are the data-level approach and the algorithmic-level approach. Data-level ap-proach includes under-sampling methods that select only a subset of negative instances for training [3, 5, 6], and over-sampling methods that synthetically gen-erate positive training instances [2]. Nevertheless, studies have shown that over-sampling with replacement does not significantly improve the classification accu-racy. For methods using the algorithmic-level approach, one can assign different classification-error costs on positive/negative training instances, or modify the classifier-specific parameters [1, 11].

One extreme case in imbalanced text cl assification is to use one-class SVM classifiers [8, 10]. One-class SVM learns from positive training documents only and totally ignore the negative training documents. However, Manevitz and Yousef [8] demonstrated that one-class SVM is very sensitive to the choice of feature representation (e.g., binary or tfidf ) and SVM kernels. Given a target category c i , a set of positive training documents Tr + i and a much larger set of negative training documents Tr  X  i ,say | Tr  X  i | X  10  X | Tr + i | ,the problem is to select a subset of negative training documents from Tr  X  i , denoted by Ts  X  i , such that the classification accura cy of a SVM classifier learned using i and Ts using Tr + i and Tr  X  i while reducing the learning time. Note that, in this paper, |
S | denotes the number of elements in the set S .
The training of a SVM classifier involves finding a hyperplane that separates positive training examples from the negative ones with the widest margin. As the hyperplane is defined by both the positive and negative training examples, intuitively, the hyperplane lies in the boundaries between the positive and neg-ative training examples; most importantly, the negative training examples used to define the hyperplane (i.e., the support vectors) are the ones that are close to the positive examples. Given the large set of negative training documents, many of them are expected to be far away from the positive ones and are less useful in SVM classifier traning. These negative training documents are known as less representative examples with respect to the target category. We there-fore try to remove these less representa tive examples to ob tain more balanced positive/negative training examples and to achieve comparable or better classi-fication accuracy using shorter learning time.

The proposed FISA algorithm includes a feature discriminative power com-putation step and an instance selection step. In the first step, a feature selection technique is applied to compute the discriminative power of each term feature. Most feature selection tec hniques rooted in information theory can be used. For each category c i , a feature selection technique com putes the discriminative power t k appears in at least one positive training document in c i . In the second step, the representativeness of each negativ e training document is computed. Those with representativeness sc ores larger than a threshold r  X  will be selected to learn a SVM classifier. The representativeness of a document d j with respect to a category c i , denoted by r ( c i | d j ), is defined as the average discriminative powers of the features found in d j (see Equation 1 where w jk is the weight of term feature t k in document d j ).
To determine the document representativeness threshold, we adopt the con-cept of quality control from statistics [9].
In Equation 2,  X  is the standard deviation of rep resentativeness scores of all negative training documents. Given a huge number of negative training docu-ments, we can assume that their represent ativeness scores follow a normal dis-tribution and the z parameter determines the proportion of documents to be selected.

Note that, feature selection technique is applied in FISA for feature discrim-inative power computation only; the final training of SVM classifiers actually involves all the features of positive training and the selected negative train-ing instances. This is because SVM is kn own to perform well without feature selection [4].
 We evaluated FISA with two well-studied feature selection techniques, namely, Odds Ratio (OR) and Information Gain (IG). Those two FISA methods are therefore known as FOR and FIG resp ectively. FOR and FIG were compared with baseline SVM , Different Error Cost (DEC), and Stratified Random Instance Selection (SRIS) methods. In our experiments, SV M light was used as the base-line classifier for those five methods. DEC method was implemented by adjusting the cost-factor (parameter j )in SV M light to be the ratio of the number of neg-ative training examples over positive ones. The same cost-factor setting was also applied to FOR, FIG, and SRIS after instance selection in these methods. For a fair comparison, the number of instances selected by SRIS was the larger one selected by FOR and FIG.

The experiments were conducted on 20-Newsgroups 1 dataset with different z values from -0.4 to 1.0. Binary document representation was used after stopword removal and term stemming. The percen tage of the selected negative training documents (e.g., selection ratio), training time 2 and micro-averaged F 1 (denoted by F  X  1 ) of these five methods are shown in Figures 1(a), 1(b), and 1(c) respec-tively.

The larger the z the fewer negative examples were selected in training as ex-pected (see Figure 1(a)). Particularly, when z =0 . 4, only about 35% of negative training examples were used for FOR, FIG and SRIS. In terms of training time, SRIS was clearly the winner as no document representativeness computation was required. Figure 1(b) also shows that smaller number of training documents led to less training time. When z =0 . 4, FIG and FOR used about only 60% of training time required by DEC or baseline SVM. In terms of classificatoin accuracy, baseline SVM was clearly the worst. The F  X  1 of SRIS decreases as z increases. An incease of z , on the other hand, had little effect on FOR and FIG when z was not greater than 0.4. When z =0 . 4, the two FISA methods deliev-ered better F  X  1 than DEC using 35% of the latter X  X  negative training documents and 60% of its training time. This experi ment shows that with carefully selected less number of training instances, faster and better classification results can be achieved. In this paper, we studied imbalanced text classification using SVM classifiers with one-against-all learning strategy. We proposed a generic algorithm known as FISA to select instances based on we ll-studied feature selection methods. Our experiment results on the 20-Newsgroups dataset confirmed that instance selection was useful for efficient and effective text classification using SVM clas-sifiers. The major limitation of the proposed FISA algorithm is that duplicates or nearly duplicated documents receive si milar representativeness scores and therefore could all be selected. However , the training of a SVM classifier does not benefit much from duplicated documents. Addressing this limitation will be part of our future research.

