 Many applications produce large amounts of uncertain data, such as, sensor data management [10], information integration [2,5]. A probabilistic database is used to manage uncertain data. Informally, a probabilistic database is a probability distribution over a set of deterministic databases (namely, possible worlds ).
Efficient processing of updating information in probabilistic databases is re-quired in several applications. In the context of data cleaning [4], several rules are specified to remove impossible value assignments of data. Continuous learn-ing and survey introduce significant new rules. Updating probabilistic databases based on new rules is important to a wide range of applications. For exam-ple, personal information systems may require updating databases based on an additional rule of different persons having unique ids. In the context of sensor networks [9], sensor readings are usually represented using correlated probabilis-tic models. Many applications benefit from updating correlated sensor data, for example, obtaining the latest value of one sensor to find the values of the other correlated sensors. Similar applications exist in data integration [2].
Conditioning is to update the probability distribution of possible worlds of a probabilistic database. Specifically, conditioning probabilistic databases is an operation of removing possible worlds which do not satisfy a given condition from a probabilistic database and re-defining the new probabilities of the re-maining possible worlds by their conditional probabilities. Several techniques have been proposed for conditioning probabilistic databases. Koch and Olteanu [8] and Tang et al. [11] have studied the conditioning problem for probabilistic relational databases. Koch and Olteanu develop ws-trees to capture constraint information. However, it is not easy to construct a tree which is efficient to compute the probability of the represented constraint and perform condition-ing. Tang et al. devise efficient conditioning algorithms for some special classes of mutually exclusive constraints. However, one of the challenges in condition-ing probabilistic databases is that the existing methods of enumerating possible worlds are exponential over the number of variables in the probabilistic database, ables involved in the formulae of tuples, the time complexity of conditioning is
We tackle this challenge under a general uncertainty models allowing for prob-abilistic correlations. Our techniques are based on two ideas: (1) considering the assignments of variables appeared in the constraint only, instead of enumerat-ing possible assignments of all variables in the probabilistic database; and (2) applying variable-replaced mechanisms to update the formulae of tuples, while avoiding the replacement of every variable in the probabilistic database.
Our main contributions towards this goal are summarized as follows. (1)We construct a constraint-based conditioning framework, which minimizes the set of tuples whose formulae have to be updated. (2)We prove the correctness of the proposed constraint-based conditioning algorithm, by showing that it guarantees an equivalent representation of a con-ditioned probabilistic database. (3)We conduct an extensive experimental study to evaluate our algorithm. The experiments evaluate our algorithm in different configurations, showing the algorithm in different practical settings.

The remainder of this article is organized as follows. We review related works in Section 2. Then, we present in Section 3 necessary preliminaries on probabilis-tic databases and conditioning. Section 4 describes our proposed constraint-based conditioning algorithm for probabilistic relational databases. Experimental study andconclusionareshowninSect ion 5 and Section 6 respectively. While there has been a significant amount of work on uncertain databases in the past few decades, surprisingly not muc h work has focused on modifications.
Abiteboul and Grahne [1] consider various modification operations over in-complete databases, which are broadly defined as a transformation from one set of possible worlds to another. They s tudy classes of modifications, such as inserting, deleting possible worlds, and c onstraining the set of possible worlds. The main result of the paper is to study expressiveness in representing results after modifications over different uncer tain data models. Hegner [7] views the data modification problem as a programming language and maps programs to operations on possible worlds. While the language is quite expressive, no query answering techniques are present ed for any uncertain data model.

Koch and Olteanu [8] are the first to study the conditioning problem for prob-abilistic relational databases. They adapt algorithms and heuristics for Boolean validity checking and simplification to solve the general NP-hard conditioning problem. They use the attribute-level m odel and develop ws-trees to capture data correlations. Confidence computation and conditioning benefit from small ws-tree decompositions. Unfortunately, if the number of constraints added into the probabilistic database is large, the represented ws-trees trend to be very deep, which causes the techniques used for conditioning to be inefficient.
Tang et al. [11] propose a framework for conditioning probabilistic relation instances. They have defined constraints as a part of the data model. They devise P-TIME algorithms for some special classes for mutually exclusive constraints, while we consider the arbit rary constraint case. 3.1 Probabilistic Databases is a discrete probability space PDB =( W, P ) ,where W = { w 1 ,...,w n } is a set mapping from possible worlds to probability values, such that n j =1 P ( w j )=1 . The extensional representation of probabilistic databases can express any finite set of deterministic databases, however, it is not compact to enumerate all possi-ble worlds and hence there is a need to have a concise representation formalism. Definition 2. A probabilistic database in the intensional representation is a quadruple D = ,E,P,f ,where is a traditional relational database, E is a set expression composing of variables, namel y f(t), whose truth value determines the of composed variables [6].
 A possible world w i is a traditional database instance such that the expression associated with the tuple in the possible world is true, the expression associated P ( w i )= w the joint value V j ( E ) is a joint value leading to the possible world w i . Example 1. Assume a probabilistic database D in Fig.1 only includes one relation R .Table V P in Fig.1 records a set of independent Boolean variables (in column V ) and their probabilities being true. Column f in R 1 records Boolean formulae true is the existence probability of tuple t in the actual world.

Each assignment of variables in V P represents one possible database instance of
D : R corresponding probability of w i .
 Definition 3. Given an extensional probabilistic database PDB =( W, P ) ,and an intensional representation of a probabilistic database D = ,E,P,f , assume W D is the set of possible worlds of D and P D is the probability distribution of W
D ,wesay D and PDB are equivalent representations, denoted by D  X  r PDB , if and only if W D = W and  X  w i  X  W, P ( w i )= P D ( w i ) .
 In Example 1, D (in Fig.1) is an equivalent representation of a probabilistic database with eight possible worlds shown as in Fig.2.
 3.2 Conditioning Probabilistic Databases Conditioning allows users to start with a database of priori probabilities, to add some evidences, and enforce it to a posteriori probabilistic database. We call the new evidences as condition ing constraints, and call the generated posteriori probabilistic database as conditioned probabilistic database.
 Definition 4. Given a probabilistic database D = ,E,P,f , a conditioning constraint C is a well-formed logical expression composing of variables in E , with  X  ,  X  ,  X  .
 Definition 5. Given a probabilistic database D = ,E,P,f , a conditioning as: where P ( C )= w probabilistic database PDB { D ,C } is: Definition 6. Given a probabilistic database D = ,E,P,f , a conditioning constraint C, the problem of conditioning probabilistic databases is to find a probabilistic database D = ,E ,P ,f such that D  X  r PDB { D ,C } .
 Example 3. Fig.3 shows an intensional representation of the conditioned prob-abilistic database PDB { D ,C } in Example 2 by the existing method [11](refer as D based ). In D based approach, possible worlds in W { D ,C } in Example 2 are enumerated. Since these po ssible worlds are mutually exclusive, their formulae the same as in Example 2. The formula of each tuple (shown as in R 1 )iscon-structed by disjunction of formulae of possible worlds in which the tuple exists. In this section we present our proposed algorithm in detail.
 Definition 7. Given a set of Boolean variables or Boolean formulae X = { x 1 , assignment vector of X , all the possible I ( X ) be denoted by SI ( X ) . Example 4. Assume E = { e 1 ,e 2 } is a set of Boolean variables, SI ( E )= { (1 , 1) , (1 , 0) , (0 , 1) , (0 , 0) } Theorem 1. Given a probabilistic database D = ,E,P,f , and a conditioning S = { e 1 ,...,e s } is a mapping from S to Boolean formulae composing of a set of new independent Boolean variables U ,and S and U satisfy the following conditions: (a) SI ( S )= C  X  I ( S ) I ( S ) ;(b) P ( I ( S )) = V PDB { D ,C } can be generated by replacing S with U , and replacing each variable e j in S with e j in each f ( t ) .
 Proof. By Definition 2,  X  w i  X  W D ,w i = { t | t  X  ,f ( t )  X  V j ( E ) }
P ( w i )= w where f ( t )  X  V j ( E )representsthat f ( t ) is true according to V j ( E ). where C  X  V j ( E ) represents the joint assignment V j ( E )canmake C be true.
A joint assignment of variables in S determines the truth of C .Thus,  X  w where V j ( E )  X  V ( S )demonstrates V ( S ) is the assignment value of variables in S when E takes the joint assignment V j ( E )and C  X  V ( S )representsthe assignment of S can make C be true.
 e j in f ( t ). Since SI ( S )= C  X  I ( S ) I ( S ), for  X  true. Therefore, if w  X  V ( E ), then w  X  V ( E ).
 E is a set of independent variables, and U and S are independent, thus, 4.1 New Variable Set Property 1. Given a conditioning constraint C , assume S = { e 1 ,...,e s } is the set of variables appeared in C ,and DNF C = { cf 1 ,...,cf k } is the set of con-junctive clauses in the completed disjunctive normal form of C , any one joint assignment V ( S )of S makes at most one conjunctive clause in DNF C be true, therefore, there exist k joint assignments of S that can make C be true. These k assignment vectors of S are the set of assignment vectors of S = { e 1 ,...,e s Example 5. In Example 2, C = e 1  X  e 2 ,S = { e 1 ,e 2 } (0 , 1) } cf satisfies the following conditions: ( a ) SI ( DNF C )= C  X  I ( DNF ( b )When I ( DNF C )= I ( DNF C ) ,P ( I ( DNF C )) = P ( I ( DNF C )) /P ( C ) .
Each assignment vector of DNF C = { cf 1 ,...,cf k } makes one and only one cf j be true. Thus, we construct the following mapping by a set of independent variables U { u 1 ,...,u k  X  1 } [11]: cf 1 = u 1 ,cf 2 =  X  u 1  X  u 2 , ..., cf k  X  1 =  X  u 1  X  ...  X  u k  X  2  X  u k  X  1 cf k =  X  u 1  X  ...  X  X  u k  X  1 P ( u k  X  1 )= P ( cf k  X  1 ) / ( P (  X  u 1 )  X  ...  X  P (  X  u k  X  2 )  X  P ( C )) Example 6. In Example 5, the mapping of DNF C is constructed as follows: DNF C = { cf 1 ,cf 2 ,cf 3 } ,cf 1 = u 1 ,cf 2 =  X  u 1  X  u 2 ,cf 3 =  X  u 1  X  X  u 2 P ( u 1 )= P ( cf 1 ) /P ( C )= P ( e 1  X  e 2 ) /P ( e 1  X  e 2 ) 4.2 Variable Mapping Given a conditioning constraint C ,if DNF C is constructed by mapping in Sec-tion 4.1, DNF C corresponds to all the assignments of S where C is true. If a variable e i  X  S takes false in every assignment of S where C is true, e i corre-assignments of S where e i and C both are true. Therefore, the set of variable mappings S = { e 1 ,...,e s } for S = { e 1 ,...,e s } is constructed as follows: Example 7. In Example 6, U = { u 1 ,u 2 } e 1 = u 1  X  (  X  u 1  X  u 2 ) ,e 2 = u 1  X  (  X  u 1  X  X  u 2 ) Proof. For any V ( S ) ,C  X  V ( S ), assume V ( S )makes cf l be true. Since when C  X  I ( DNF e  X  S ,if e v DNF C , e i = cf cf  X  I ( S )= I ( S ) .
 Since when I ( DNF C )= I ( DNF C ) ,P ( I ( DNF C )) = P ( I ( DNF C )) /P ( C )
P ( cf i )= P ( cf i ) /P ( C )  X  SI ( S )= 4.3 Algorithm Theorem 1 guarantees we obtain an equivalent representation of the conditioned probabilistic database if the new set of variables and the mapping satisfy some conditions, and Theorem 2 guarantees the mapping obtained by Equation 1 satisfies the conditions in Theorem 1. Conditioning Based (for short, we call it C Based ) only enumerates the conjunctive clauses in DNF form of C .Each conjunctive clause corresponds to an assignment of variables appeared in C . Since these conjunctive clauses are mutually exclusive, we construct mapping for each conjunctive clause by creating a set of Boolean variables U . Then the mapping for each variable appeared in C is constructed as in Equation 1. C based is shown as in Algorithm 1.

Given a probabilistic database D 1= ,E 1 ,P 1 ,f 1 , and a conditioning con-straint C ,let n R be the number of tuples in the database, n C be the number of variables appeared in conditioning constraint C ,and n E be the number of variables in the formulae of tuples in the database. D Based enumerates all the plexity. While C Based only enumerates all the possible joint assignments of variables in constraint C, and takes O ( n R +2 n C ) time complexity. Example 8. In Example 2, C = e 1  X  e 2 , by the algorithm C Based , the con-ditioned probabilistic database D 2= ,E 2 ,P 2 ,f 2 obtained by C Based is shown as in Fig.4. In this section we conduct the experimental study of C based approach and D based approach for conditioning probabilistic databases.
 Algorithm 1. Conditioning Based
We study the effect of n R (the number of tuples in the database), n C (the number of variables appeared in constraint C ), and n E (the number of vari-ables in the formulae of tuples in the relation) on the efficiency of C based and D based approaches. We compare the efficiency of C based and D based by varying n C ,n E ,n R , one at a time. Both of C based and D based approaches are implemented in Java, and all our experiments are conducted on a Pentium 2.5 GHz PC with 3G memory, running XP. We generate our synthetic data sets by varying the three parameters: fixing n C and n E , n R varies from 1 K to 10 K ; to n E .

Effect of Varying n R : We evaluate the effect of varying the number of tuples on the efficiency of C based approach and D based approach . Fig.5 shows the exe-cution time of C based approach and D based approach , with the number of tuples varying from 1 K to 10 K and n E = n C = 10. Increasing the number of tuples linearly degrades the performance of C based approach and D based approach . This is because these two algorithms perform conditioning on the database tuple by tuple, and the running time of updating the formula of each tuple is almost the same. Fig.5 also shows that C based approach is much more efficient than D based approach , because the number of possible worlds of the constraint C (as considered in C based approach ) is much smaller than the number of possible worlds of the database (as considered in D based approach ).

Effect of Varying n E : We evaluate the effect of varying n E on the effi-ciency of C based approach and D based approach , as shown in Fig. 6 (while n
R =1 k,n C = 5). The execution time of D based approach grows exponentially by increasing n E . This is due to the fact that disjunctive normal form over the variables in database for each tuple is computed in D based approach . Increasing n
E does not affect the performance of C based approach . C based approach com-putes the mapping for each variable appeared in C with O (2 n C ) time complexity, does not affect the efficiency of C based approach . The performance of C based approach remains stable when scaling n E up to 1 K and fixing n R and n C .We do not present the running time in figure since the running time of D based approach is too large when n E is greater than 20.

Effect of Varying n C : We evaluate the effect of varying n C on the efficiency of C based approach and D based approach . Fig.7 shows the execution time of C based approach and D based approach when increasing n C from5to14and fixing n R to be 1 K and n E to be 14. The execution time of C based approach increases slowly when n C increases. n C does not affect the efficiency of D based approach since n C is not a time-complexity factor of D based approach .The maximum execution time when n C = 14 is 8436 seconds for D based approach and is 12.5 seconds for C based approach . C based approach is on average 100 times faster than D based approach .

Real Datasets (MOV): We also perform experiments on a real-world prob-abilistic dataset [13], which stores uncertain data of movie-viewer ratings. We normalize the dataset by the data model introduced in Definition 2. This dataset contains 10037 tuples and 6693 variables. Figure 8 shows the execution time of C based approach over this real dataset when n C varies from 11 to 20. The ex-ecution time grows slowly when n C increases from 11 to 17, and grows nearly exponentially when n C increases from 17 to 20. The reason is that when n C is greater than 17, the time for computing variables mapping (which is O (2 n C )) is much larger than the time for updating formulae of tuples (which is O ( n R )). The execution time is dominated by that of variables mapping when n C &gt; 17 over this dataset. We do not present the execution time of D based approach in the figure since it is too large over this dataset.
C Based approach avoids enumerating the truth vales of all the variables in the formulae of tuples, but only considers the variables in the given constraint, and applies variable-replaced mechanisms to update the formulae of tuples, while avoiding the replacement of every variable in the probabilistic database. There-fore, C Based approach performs better than D Based approach in every con-figuration. In this paper, we proposed a framework for conditioning probabilistic relational databases efficiently. The proposed conditioning algorithm only focuses on vari-ables in the conditioning constraint while avoiding involving the other variables. We proved the correctness of the proposed constraint-based conditioning algo-rithm, by showing that it guarantees an equivalent representation of a condi-tioned probabilistic database. By conducting experimental studies, we found that (1) increasing the number of variables in the constraint does not contribute to large increases in the execution time of our algorithm; (2) scaling the num-has no influence on conditioning; (3) conditioning time increases linearly when scaling the number of tuples in the probabilistic relational database.
