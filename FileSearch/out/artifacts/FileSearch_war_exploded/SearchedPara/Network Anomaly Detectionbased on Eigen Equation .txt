 This paper addresses the issue of unsupervised network anomaly detection. In recent years, networks have played more and more critical roles. Since their outages cause serious economic losses, it is quite significant to monitor their changes over time and to detect anomalies as early as possible. In this paper, we specifically focus on the management of the whole network. In it, it is important to detect anomalies which make great impact on the whole network, and the other local anomalies should be ignored. Further, when we detect the former anomalies, it is required to localize nodes re-sponsible for them. It is challenging to simultaneously perform the above two tasks taking into account the nonstationarity and strong correlations between nodes.

We propose a network anomaly detection method which resolves the above two tasks in a unified way. The key ideas of the method are: (1) construction of quantities representing feature of a whole network and each node from the same input based on eigen equa-tion compression, and (2) incremental anomalousness scoring based on learning the probability distribution of the quantities.
We demonstrate through the experimental results using two bench-mark data sets and a simulation data set that anomalies of a whole network and nodes responsible for them can be detected by the pro-posed method.  X 
This work was done while the author belonged to NEC Corpora-tion.
 K.6.4 [ Management of Computing and Information Systems ]: System Management Algorithms, Management eigen equation compression, network anomaly detection
In recent years, networks are considered more and more impor-tant because they are essential for information technologies, mis-sion critical tasks and so on. Since their outages cause serious eco-nomic losses, it is quite significant to monitor their changes over time and to detect anomalies as early as possible. Since it is quite difficult to monitor complicated networks manually, technologies for automatically detecting network anomalies early are in one of the highest demands.

Motivated by the situation, we address the issue of detecting anomalies in networks where nodes correlate with each other, specif-ically from the viewpoint of the management of the whole network. We deal with the problem consisting of the following two tasks and call it  X  X etwork anomaly detection problem X . The first task is to decide on whether the whole network is anomalous or not. Espe-cially, for the whole network management, it is required to only detect anomalies which make great impact on the whole network, and to ignore the other local anomalies. For example, link redistri-butions of small number are routinely conducted and they should not be detected as anomalies. The second task is to localize nodes which are responsible for the anomaly. This task is required for early recovery of the network.

The problem has the following properties. First, anomalies of the whole network usually appear not in individual nodes but rather in relationships between nodes. We therefore cannot localize anoma-lous nodes if we separately monitor the individual nodes. Second, networks are systems varying with time and thus it is difficult to define anomalous states. Third, supervised information about the behavior of each node is generally not given. Thus, we need to treat the problem in an unsupervised learning fashion.

In addition to taking into account these properties, it is required to estimate the anomalousness of a whole network and that of each node from a single framework when we solve the tasks. If they are estimated from different ones, the relation between the anomalous-ness is not clear and thus localization becomes difficult. However, it is not trivial how to make the connection between the anomalous-ness of a whole network and that of each node.

We propose a novel method for solving the network anomaly detection tasks. It enables us to conduct the simultaneous anoma-lousness estimation with taking into account the above mentioned properties. The key ideas of the method are summarized as follows.
First, we employ a formulation with eigen equations of corre-lation strength matrices. Employing it, the correlations between nodes are explicitly taken into account (corresponding to the first property of the problem).

Second, we compress the eigen equation of the correlation strength matrix (namely derive a low-dimensional representation of the eigen equation) taking into account the correlation structure around each node. By conducting eigen equation compression, we can derive the quantities representing the features of a whole network and each node simultaneously from the same matrix. Thus, by track-ing these quantities, we can treat anomalies of a whole network and each node simultaneously in one framework.

In the compression, we divide the all nodes into three clusters from the view point of a node. These three clusters represent a node itself, those close to the node, and those far from the node. Based on the clustering, we construct 3  X  3 ( X  X ompressed X ) matrix which represent how the whole network is seen from the node, namely correlation between the clusters. By monitoring the matrix, anoma-lous nodes are detected as those around which correlation structures have largely changed.

Third, the ordinary patterns of the quantities are learned incre-mentally in an unsupervised learning fashion. Then, anomalous-ness scores representing how largely the quantities have deviated from the ordinary patterns are computed. By the incremental learn-ing and scoring, we can treat systems varying with time and can estimate their anomalousness in an unsupervised fashion (corre-sponding to the second and the third properties).

To the best of our knowledge, this is the first work which pro-poses a method for simultaneously detecting whole network anoma-lies and nodes responsible for them by using eigen equation com-pression.
There have been proposed many methods for analyzing time se-ries, which include unusual motif discovery[1], change-point de-tection[2, 3] and so on. However, it is difficult to apply them to our problem. This is because we cannot localize anomalous nodes if we separately monitor the individual nodes due to the first property of the network anomaly detection problem.

Methods for mining multivariate time series by recognizing them as weighted graphs were proposed [4, 5, 6, 7, 8]. In the methods, multivariate time series are represented as weighted graphs, namely matrices, where each node represents one dimension of the time series, and each link represents relation between two nodes (for ex-ample, correlation strength, similarity, and so on). By the methods, anomaly detection from networks can be conducted. However, they did not simultaneously detect anomalies of a whole network and nodes responsible for them. Ide has proposed methods for detecting whole network anomalies by tracking eigenvector[4] and detecting anomalous nodes by tracking anomalous correlation structure[8]. However, it is difficult to unify results derived by their different methods straightforwardly.

Methods for compressing matrices include Lanczos method[9] and Density Matrix Renormalization Group method[10]. They are methods for solving eigen equations effectively and are not de-signed to derive compressed matrices representing features of a specific node as we conduct. Thus, they are not directly applica-ble to anomaly detection problems.

The rest of this paper is organized as follows. Section 2 pro-vides the problem setting. Section 3 yields a framework of network anomaly detection. Section 4 shows experimental results. Section 5 gives concluding remarks.
In this section, we describe our problem settings. The overview of the settings is summarized in Figure 1.
 Figure 1: Overview of our problem setting. Input data is a set of time series observed at each node. From the input, we wish to compute the anomalousness scores of a whole network (system) and each node (degree of freedom).
We deal with a strongly correlated system having n degrees of freedom such as a communication network consisting of n nodes ( n servers). Hereafter let us call the degrees of freedom nodes and the system network.

At each node, real-valued time series is observed synchronously with a fixed frequency. Let u i ( t ) be the observation of the i -th node at the t -th time step ( i =1 ,  X  X  X  ,n, t =1 , 2 ,  X  X  X  ple, u i represents sum of traffics incoming to the i -thserverofa communication network in 5 minutes.

We consider the time series { u i } n i =1 to be input data for our problem. From the input, we want to detect the network anomalies which we describe below.

When we conduct anomaly detection from a network, the time series may be observed at each pair of nodes. However, we assume that the observation is conducted at each node for the following reasons. First, in real applications, the pairwise observation costs much more than the nodewise one. Second, the pairwise observa-tion can be easily translated into the nodewise observation by sum-ming them up at each node and thus the below described method can be applied to the pairwise observation cases.
Using a set of the time series { u i } n i =1 as input, we want to solve network anomaly detection problem. We define network anomaly detection problem as one consisting of the following two tasks. The first one is to decide on whether a whole network is anomalous or not. The second one is to find nodes which are responsible for the anomaly (namely localize the anomalous nodes).

We consider (1) the whole network is anomalous when the gener-ating mechanism of the correlation structure of the whole network has been changed, and (2) the node is anomalous when it largely contributes to the change of the whole network. Then, our task is to detect such anomalies.

For this purpose, we wish to compute anomalousness scores of a whole network and each node, where a higher score indicates a higher possibility of being an anomaly. Then, we can solve the problem as follows: (1) we compute the anomalousness scores, and (2) we search nodes or networks with high scores and con-sider them to be anomalous. In Section 3, we explain our method to compute the anomalousness scores.

The anomaly detection method which solves the tasks should satisfy a number of requirements. First, it can compute the anoma-lousness score of the whole network and that of each node from a single framework. If they are estimated from different ones, the relation between the anomalousness is not clear and thus the local-ization becomes difficult.
 Figure 2: Topological and non-topological changes. Nodes with a link denote those with strong correlation.

Second, it can detect only global structural changes as whole network anomalies. We aim to detect changes of a whole network. Thus, small changes should be ignored to reduce false alarms. For example, link redistributions of small number are routinely con-ducted and they should not be detected as anomalies. For this pur-pose, we define global topological changes as the structural changes to be detected. An example of topological and non-topological changes is illustrated in Figure 2. From the network A, the change to B is non-topological ( A is transformed to B by rotation) and those to C and D are topological. In many cases, non-topological changes indicate normal role-sharing changes, while topological ones indicate anomalies. For example, let us consider the case where the number of e-mails are observed as { u i ( t ) } works. Non-topological changes indicate that the source and the destination of e-mails has changed, and thus they are not anoma-lous. On the other hand, topological changes indicate that the de-viation of mail sending has changed and thus they imply anomalies such as worms X  spreading (change from A to C).

Third, the anomalousness score of each node is also insensi-tive to small changes. We aim to detect nodes responsible for the whole network anomalies generating global changes. The corre-lation structures around such nodes change largely. Thus, for lo-calizing anomalous nodes, small changes should not be detected in order to reduce false alarms.
We propose a network anomaly detection method consisting of compressing eigen equations and learning probability distributions. The overall flow is summarized in Figure 3.

We consider a set of time series { u i ( t ) } n i =1 which are observed at each node to be input.

First, in order to treat strong correlation between nodes, we con-struct time series of matrices A ( t ) , whose component represents correlation strength between a pair of nodes: Here C ij ( t ) ( A ij ( t ) )represents ij component of matrix C ( A )at time step t and u i t represents the sliding window average of u at time step t with the window size w . Hereafter we call the matrix A ( t ) correlation strength matrix. We consider the time series of the matrix A to be input of the next step (eigen equation compression).
Second, we create two data sets from A ( t ) at each time step based on eigen equation compression. One is a set of the m largest eigenvalues of A ( t ) . By tracking them, we detect anomalies of a whole network. The other is a set of n low-dimensional matrices each of which represents correlation structure around a node. By tracking them, we detect anomalous nodes.

Third, we conduct anomalousness scoring to these data incre-mentally. The scorings are based on learning and the scores repre-sent how significantly a data deviates from learned normal patterns. Thus, high scores indicate anomalous data with high probability. Then, we consider that data of higher scores have caused anoma-lies.

We explain the detail of the second step ( X  X igen equation com-pression X ) and the third step ( X  X earning and scoring X ) in the follow-ing. In this section, we derive, from the correlation strength matrix A , a quantity which represents features of a whole network and is independent of specific node (or common to all nodes) and a quantity representing features of each node. As a method to derive them simultaneously, we employ compression of eigen equations.
Here let us describe how to compress eigen equations. What we want to do is to derive an eigen equation of a low-dimensional (com-pressed) matrix, which maximally conserves information of the original eigen equation A .

Let us denote the input matrix A ( t )  X  X  l -th largest eigenvalue as  X  t ) and its corresponding eigenvector as l ( t ) : We compress these equations.

We assume that a set of clusters C = { C k } M k =1 is given and each node belongs to one of them. We define a matrix representing (2) compution of anomalousness scores based on learning. projection to the k -th cluster as P C ,k : Here e i is a vector whose i -th component is 1 and the others are 0 . The projection matrices { P C ,k } M k =1 have the following properties: where I denotes a unit matrix and  X  k k denotes Kronecker X  X  delta, which becomes 1 if k = k and 0 otherwise. Eq. (7) indicates there is no overlap between any two clusters. Eq. (8) indicates the union of all the clusters covers all the nodes.

By using the projection matrices, we derive low-dimensional representation of A ( t ) and compressed eigen equations.
First, by multiplying the identity represented as Eq. (8) to an eigenvector l ( t ) ,weget  X  ,k ( t )= ,k ( t )= Eq. (12) is derived from Eqs. (7) and (11). Eqs. (9)  X  (12) implies that we can rewrite l ( t ) as a linear combination of M (number of tion, Eq. (12), is derived from the orthonormal condition of projec-tion matrices, Eq. (7).

Then, by using M (number of clusters) orthonormal basis, we can derive M -dimensional representation of the original eigen equa-tion. By substituting Eq. (9) to Eq. (4), By multiplying C l C ,k ( t )  X  from the left of Eq. (13) and using the orthonormal condition Eq. (12), we get A ( t ) is an M -dimensional matrix and we represent its k k com-ponent as represent its k -th component as
We see that Eq. (14) is an M -dimensional compressed equation of A ( t )  X  X  eigen equation corresponding to the l -th largest eigen-value for the following reasons. First, Eq. (14) is an eigen equa-tion derived from A ( t ) . Second, Eq. (14) exactly conserves the l -th largest eigenvalue  X  l ( t ) . Third, Eq. (14) conserves the squared sum of the eigenvector X  X  components in a cluster (namely, the ratio of the eigenvector components in the clusters): wherewedenotethe i -th component of l ( t ) as
Using the compressed eigen equations, we derive a quantity which represents features of a whole network and that which represents features of each node. From the below mentioned discussion, we employ a compressed matrix and its eigenvalues as such quantities representing a node and a whole network respectively.

First, let us discuss how to construct a quantity representing features of each node. The compressed matrix A l C ( t ) is a low-dimensional matrix including the information of the cluster struc-ture C ( t ) . Thus, A l C ( t ) can be recognized as a quantity representing a node if C ( t ) is constructed based on features of a node.
In order to conduct such clustering, we use correlation structure around a node. Let us denote the clustering for the i -th node as C ( t ) .As C i ( t ) , we divide all nodes into three clusters accordingly to the correlation strength A ij ( t ) : where  X  is a threshold parameter which a user have to set and has been set to  X  =0 . 80 in this paper. In three clusters, L sents the nodes which are the neighbors of the i -th node at time t in terms of the correlation strength. On the other hand, R i those far from the i -th node.
 Note that C i ( t ) is not derived from the eigen equation of A ( t ) . C ( t ) is derived by simply sorting the correlation strength A with fixed i as Eq. (19)  X  (21).

Note that our proposed method is applicable with general clus-tering. However, we have employed the clustering in Eq. (18). De-termining the optimal clustering for network anomaly detection is a challenging research issue and thus one of our future works.
By compressing with the clustering C i ( t ) ( 1  X  i  X  n ), we derive the following compressed eigen equations: Here A l C i ( t ) is 3  X  3 matrix whose k k component is defined in Eq. (15). For example, its 2 , 3 component, sented as
Then, we consider A l C i ( t ) to be a quantity representing features of the i -th node for the following reasons. First, A l C mation of correlation between the i -th node and the others because it is derived by compressing A ( t ) , which includes all information of correlation between nodes. Second, A l C i ( t ) represents how the whole network is seen from the i -th node. This is because it is constructed based on the correlation strength structure from the viewpoint of the i -th node. In addition, these statements are also supported by the fact that compressed eigen equations (partially) conserve the information of the original matrix.

Next, let us discuss how to construct a quantity representing fea-tures of a whole network. We require that the quantity is indepen-dent of a specific node, namely to represent features common to all nodes. This is because, by including the learning of node inde-pendent quantities, we can construct a network anomaly detection method so that it satisfies the requirements mentioned in Section2 as follows. First, we can detect global and topological changes of a whole network. This is because topological changes are indepen-dent of a specific node ( As the change from A to C in Figure2, topological changes can be detected without knowing the index of each node). Second, we can construct a method which is robust to noisy fluctuations caused by a specific node by ignoring specific node dependent features.
 As such node independent quantities, we employ eigenvalues of A ( t ) for the following reasons. First, looking at the compressed eigen equations in Eq. (22), we see that the eigenvalue  X  independent of a node and common to all nodes. Second, indepen-dently of the compression, eigenvalues are independent of a node in terms of their node index permutation invariance. We explain this invariance below.

The eigenvalues of matrix A ( t ) are invariant under an orthogonal transformation U as we show below.
 Eq. (24) is derived by multiplying U from the left of Eq. (23) and thus they are equal. From them, we can see that matrix A ( t ) and eigenvector l ( t ) are transformed like A ( t )  X  UA ( t ) U l ( t )  X  U l ( t ) under an orthogonal transformation. On the other hand, eigenvalue  X  l ( t ) is transformed like  X  l ( t )  X  plies eigenvalues are invariant under an orthogonal transformation, which includes node index permutation. Thus, eigenvalues are node independent.
Once we have matrices { A l C i ( t ) } and eigenvalues { conduct anomalousness scoring to them at each time step. The scorings are based on learning and the scores represent how signif-icantly a data deviates from learned normal patterns and thus high scores indicate anomalous data with high probability.
 Among { A l C i ( t ) } and {  X  l ( t ) } , we only use { {  X  l ( t ) } m l =1 (we have employed m =3 ) for scoring. This is an approximation taking into account only dominant terms of eigen-value decomposition. We define an m -dimensional vector  X  (  X  1 ( t ) ,  X  X  X  , X  m ( t ))  X  and learn the probability distributions of and  X  .

We employ matrix variate normal distributions[11] and multi-variate normal distributions for representing probability distribu-step t respectively: Here we denote the dimension of matrix A 1 C i as d (now, d =3 ). In Eq. (25),  X  t and  X  t are a parameter representing covariance and a vector parameter representing mean respectively. In Eq. (26),  X  and  X  i,t are d  X  d matrix parameters representing covariance M i,t is a d  X  d matrix parameter representing mean.
 We update the parameters of the distributions at each time step. Let us denote an anomalousness score of a whole network at time t as S NW ,t and that of each node as S i,t ( i =1 ,  X  X  X  ,n ). Using the incrementally updated distributions, we compute these scores by which measure how significantly newly coming data deviates from learned normal patterns. Thus, high scores indicate anomalous data with high probability.

We detect network anomalies by considering (1) high S NW ,t plies an anomaly of a whole network, and (2) nodes with high S i,t are anomalous because correlation structure around them are largely changed. Especially, we consider that high S i,t with high S
NW ,t indicates that the i -th node is responsible for the whole net-work anomaly.
When we consider A 1 C i to be a d 2 -dimensional vector, its covari-ance matrix in a multivariate normal distribution is a d 2  X  In matrix variate normal distributions, the covariance matrix is ap-proximately represented as  X  i,t  X   X  i,t using a direct product.
In this section, let us qualitatively describe the properties of our proposed method.
We need a principle for determining how to construct quantities representing a whole network and each node. This is because there are many ways to make such quantities. For example, we can con-struct a low-dimensional matrix representing each node by dividing A ( t ) into some blocks and summing up components in a block with any weights.

As a principle, we have employed eigen equation compression, namely information conservation of A ( t )  X  X  eigen equations for the following reasons. First, formulations with eigen equations are effective and widely used for looking at features of systems with strong correlation (for example, Principal Component Analysis in data mining, Schr X dinger equations in quantum physics, and so on). Second, it is natural to require information conservation as a principle. Third, we can simultaneously detect anomalies of a whole network and each node because a compressed eigen equa-tion includes quantities representing a network (eigenvalue) and a node (compressed matrix) at once. This is because a matrix and its eigenvalue are transformed in different ways under orthogonal transformations.

One more advantage of eigen equation compression is that we can conduct anomaly detection from networks where the number of nodes changes with time, such as growing networks. Learning probability distributions becomes very difficult when the dimen-sion of input variables varies. This holds true in the case of growing networks and thus it is difficult to conduct anomaly detection. We can avoid this difficulty by employing eigen equation compression. This is because (1) the dimension of the compressed matrices are constant independently of the dimension of a whole network (num-ber of nodes), and (2) the dimension of the vector  X  are constant too. In this paper, we do not discuss any more or conduct any ex-periments with growing networks.
Here let us discuss anomalies detectable by tracking the anoma-lousness scores, S NW ,t and S i,t ( i =1 ,  X  X  X  ,n ).

By tracking S NW ,t , we can detect global and topological changes of correlation structures as required in Section 2. This is because S
NW ,t is computed based on eigenvalues of the correlation strength matrix A ( t ) . As discussed, eigenvalues are quantities which rep-resent features of a whole network and are invariant under orthog-onal transformations. This implies eigenvalues represent topologi-cal (orthogonal transformation invariant) structure of a whole net-work. In addition, it is known that eigenvalues are indices which are sensitive to topological changes of a whole network[12]
For example, by tracking it, it is expected that we can detect spread of worms in PC networks, wide area congestion in commu-nication networks and so on.

By tracking S i,t , we can detect structural changes of the correla-tions around the i -th node. This is because S i,t is computed based on a compressed matrix A 1 C i ( t ) , which represents how the whole network is seen from the i -th node. Because structure around the i -th node are tracked, S i,t is insensitive to small changes as required in Section 2
In Ref. [12], it has been shown that eigenvalue density distri-butions of networks X  adjacency matrices are not changed by lo-cal changes such as link redistribution of small number, but are changed by global topological changes such as changes from ran-dom network to scale-free network.

For example, by tracking them, it is expected that we can de-tect anomalies, where traffics become concentrated to neighbors of Server i in a communication network after Server j breaks down and traffics start to bypass it. In this case, both Server i and j are detected as anomalous nodes.

As discussed, the proposed method is not designed to detect changes in very small region. By ignoring such changes (anoma-lies), the proposed method can reduce false alarms.
In this section, we demonstrate the utility of the proposed method using three data sets consisting of strongly correlated time series. Note that there is no standard method for simultaneously detecting network anomalies, those of a whole network and each node, which have the features mentioned in Section 1.
We observed the anomaly detection accuracies of the proposed method. As a measure of the accuracies, we employed the area un-der the curve (AUC) of a ROC (Receiver Operator Characteristic) curve. The horizontal axis and the vertical axis of ROC curves rep-resent the false positive rate and the true positive rate respectively. We conducted anomaly detection using the time series of S and { S i,t } n i =1 . For each time series, we considered a time step whose score was higher than a threshold to be anomalous. We esti-mated the detection accuracy by observing whether the alarms were correctly anomalous.

For each time series, we drew a ROC curve by gradually chang-ing the threshold. Then, we computed the area under the curve (AUC). AUC is in 0  X  AU C  X  1 and higher value corresponds to higher accuracy. AUC becomes 0 . 5 if we detect anomalies by random search.

We employed AUC as a measure of the detection accuracy. We denoted AUC of S NW ,  X  and S i,  X  as AU C ( NW ) and AU C ( i ) respec-tively. We represented the node average of AU C ( i ) as AU C ( AU C = 1 n
High AU C ( NW ) implies that anomalies of a whole network have been detected with high accuracy by tracking S NW ,t , anomalous-ness score of a whole network. Let us denote an anomalous node as i  X  . It is expected that S i = i  X  ,t is insensitive to changes of cor-relation structure around the i  X  -th node and thus AU C ( i = i smaller than AU C ( i ) . Therefore, high AU C ( i  X  ) with relatively low AU C implies that anomalies of the i  X  -th node have been detected with high accuracy and the other nodes have been recog-nized less anomalous, by tracking { S i,t } n i =1 , score of each node. Thus, this implies that the i  X  -th node has been detected as the node responsible for anomalies of a whole network.
In order to measure the performance of the proposed method quantitatively, we conducted an experiment with a synthetic data simulating traffics on communication networks.
We constructed artificial data sets simulating traffics on commu-nication networks of 30 nodes accordingly to the following four steps. First, we generated links between nodes accordingly to BA model[14] for constructing networks where the number of links of a node had large deviation. Second, we constructed the nodewise observation u i ( t ) (see Section 2.1) from t =1 to t = 990 using the link structure of the network. We generated an artificial traffic by randomly selecting the source node i , the destination node j and one of the shortest path between i and j . We repeated this gener-ation 4000 times at each time step, and considered the number of traffics incoming to the i -th node at time step t to be the nodewise observation u i ( t ) . Third, we changed the link structure by erasing one existing link. We denote two nodes the link between which were erased as i  X  and j  X  . Fourth, we constructed the time series from t = 991 to t = 1000 using the one-link-erased network. We considered a whole network, node i  X  and node j  X  after t = 990 to be anomalous. We observed whether these anomalies were de-tected by the proposed method. We estimated the performance of the proposed method by repeating the above mentioned procedure 10000 times.

By this experiment, we aimed to observe the relation between the performance and how largely the network X  X  structure has been changed. The impact of the structural change was dependent on the importance of the erased link. Thus, we employed the impor-tance of the link as a measure of the structural change. As the link importance measure, we employed the link centrality. We denoted the link centrality of the erased link as  X  and it was defined as (the number of the shortest paths including the link)/ (the number of the all shortest paths).
We show the experimental results in Figure 4. The horizon-tal axis of the figure represents the link centrality  X  , namely how largely the network has been changed. The vertical axis represents AUC. Each bar represents AU C ( NW ) ( X  X hole NW X  in the figure), average of AU C ( i  X  ) and AU C ( j  X  ) ( 1 2 ( AU C ( i  X  X ode X  in the figure), and AU C ( X  X ode Average X  in the figure).
When  X  was small, all AUCs were small. This indicates that the proposed method was insensitive to changes in very small re-gion, as required in Section 2. Namely, the proposed method could ignore small changes and could reduce false alarms for the net-work anomaly detection tasks. The amount of traffics which had to bypass an erased link with small  X  was small because there were many other shortest paths around the link. Therefore, the network structure was not largely changed by erasing small- X  link.
When  X  became higher, AU C ( NW ) went higher and became enough high to detect the anomalies. This implies that the whole network anomaly detection by tracking S NW ,t succeeded in detect-ing anomalies where whole network structures were globally changed (anomalies with high  X  ).

In the case of nodewise anomaly detection, 1 2 ( AU C ( i AU C ( j  X  )) and 1 2 ( AU C ( i  X  )+ AU C ( j  X  ))  X  AU C also went higher and became enough high when  X  became higher. This in-dicates (1) the anomalies could be detected by tracking S S  X  ,t ,and(2) S i  X  ,t and S j  X  ,t were much more sensitive to the proposed method could detect anomalous nodes which were re-sponsible for the anomalies with global structural changes.
There appeared  X  region where 1 2 ( AU C ( i  X  )+ AU C ( j high and much higher than AU C ( NW ) (for example, the region 0 . 015  X   X &lt; 0 . 020 ). This implies that there existed cases where anomalous nodes were detected while whole networks were not considered to be anomalous. The proposed method detects anoma-lous nodes by tracking nodes around which the correlation structure is largely changed. Thus, such cases correspond to situations where the structure around a node largely changes while its influence does not spread to the entire area of the network.
Our proposed method is applicable to anomaly detection from systems where components correlate with each other. Failure de-tection from machineries is one of the promising applications of the proposed method. In order to show the applicability to the failure detection, we conducted an experiment using a simulation data set of currents in machinery. Figure 5: The five time series, x 1  X  x 5 .In x 1 and x 2 parts are included in t&gt; 1000 region.

We constructed data simulating a failure in machinery where sev-eral parts broke down, using MotorCurrent data, which is available from UCR archive[13]. MotorCurrent data consists of time series of currents observed in different components of a induction motor, generated by state space simulations. Each time series has a label. Among them, we used time series with labels healthy and 1 bro-ken bar. From the data, we constructed 20 time series consisting time series as { x i } 20 i =1 , and replaced t&gt; 1000 region of x to randomly selected 1 broken bar labeled time series. We defined the replaced part as anomalies to be detected. The five time series, x  X  x 5 ,areshowninFigure5.

Thus, what we had to observe were (1) whether the method could detect the anomaly of a whole network (machinery) starting at t = 1001 , and (2) whether it could identify x 1 and x 2 as anomalous nodes (time series or components). Figure 6: AUC of each node. The anomalous nodes x 1 and x lead the two largest AUCs. the erased link.

The experimental results are summarized in Table 1. The results indicate that the whole network anomaly and two anomalous nodes have been detected by the proposed method for the following rea-sons.
 First, the anomalies were detected in terms of the high AUC. Second, two anomalous nodes (node 1 and node 2 ) were detected as nodes responsible for the anomaly. In Figure 6, AUCs of all nodes are shown. We see that AU C (1) and AU C (2) were larger than the others. This implies that the scores of the anomalous nodes were the most sensitive to the anomaly. Thus, node 1 and node 2 could be recognized as the nodes responsible for the anomaly.
The results indicate that the proposed method is applicable to failure detection from machineries where components correlate with each other.
Another promising application is change detection from eco-nomic time series. In order to show the applicability, we conducted an experiment with economic time series consisting of currencies and stocks.
We used 20 economic time series consisting of 9 currencies and 11 stocks of 11 countries, Australia (USDAUD and AORD), Brazil (USDBRL and BVSP), Canada (USDCAD and TSX), France and Germany (USDEUR, CAC and DAX), Hong Kong (USDHKD and HANGSEN), Japan (USDJPY and N225), Russia (USDRUB and RTSI), South Korea (USDKRW and KOSPI), UK (USDGBP and FTSE) and USA (DJI). Each time series was daily data from 1 st June 2003 to 21 st October 2008 and consisted of 1970 data points (time steps). The currency time series took values per 1 USD. The number of currencies and that of stocks were different because the currency of France and Germany was equal and we neglected that of USA (USDUSD is always 1 and thus it was meaningless to in-clude it).

We employed them for the following reasons. First, economic data included the great depression starting in September 2008 as the anomaly which had to be at least detected. Second, economic data was one of the data which had strong correlations and included anomalies where relation between several nodes broke down. Third, the experimental results from it were intuitively interpretable.
In this experiment, we observed the behaviors of the proposed method only qualitatively because we could not know what were the anomalies to be detected.

However, the experimental results indicate that the proposed method detected sudden changes of correlations as anomalies and they cor-responded to economic events.
 Figure 7: Anomalousness score time series of the whole net-work.

The anomalousness score time series of the whole network are shown in Figure 7. In Figure 7, we see that there appeared three peaks after 1 st January 2007 . Each peak corresponded to a big eco-nomic event. The first peak appeared on 5 th October 2007 ,where many currencies suddenly changed after U.S.A. announced the em-ployment statistics. The second peak appeared on 15 th September 2008 , where Lehman Brothers announced its bankruptcy. The third peak appeared 13 th October 2008 (Monday), where DJI had gone below 8000 dollars and Nikkei had gone below 9000 yen on the last Friday. The second and the third peak indicate that the pro-posed method detected the great depression starting in September 2008 as anomalies.

Nodes with high scores corresponded to currencies and/or stocks which started to break from the tendency of the others. As an exam-ple, we show the score time series of Japanese currency and stock in Figure 8. There appeared three peaks in USDJPY (Japanese Yen), on 30 th June 2006, 11 th June 2007 and 5 th August 2008. At the first and the third peak, only Yen did not change while the others Figure 8: Anomalousness score time series of Japanese cur-rency (solid line) and Japanese stock (dashed line). went up. The second peak appeared because Yen went down while the other currencies went up. In the case of N225, there appeared two peaks, on 28 th November 2006 and 16 th October 2008. At the first peak, N225 went up while the other stocks went down. The second peak appeared due to the correlation breaking caused by the great depression.

The experimental results indicate that the proposed method is ap-plicable to change ( X  X nomaly X  in a sense) detection from economic time series. We have proposed a method for detecting network anomalies. The key ideas of the method are (1) deriving quantities represent-ing a whole network and each node by compressing eigen equa-tions, and (2) learning probability distributions of these quantities incrementally. By employing eigen equation compression, we can detect anomalies of a whole network and each node simultaneously. We have demonstrated the utility of our approach using two bench-mark data sets and a simulation data set.

Future works include more experiments with larger scale net-works. They also include further extension of our proposed method (1) to treat asymmetric matrix, namely directed correlation struc-ture, as input, and (2) to treat cases where the number of clusters changes over time by employing methods for estimating dynam-ically changing probabilistic model sequences, such as the tech-nique of dynamic model selection (DMS[15]). [1] E. Keogh, J. Lin, S. H. Lee, and H. V. Herle. Finding the [2] V. Guralnik and J. Srivastava. Event detection from time [3] K. Yamanishi and J. Takeuchi. A unifying framework for [4] T. Ide and H. Kashima. Eigenspace-based anomaly detection [5] J. Sun, H. Qu, D. Chakrabarti, and C. Faloutsos.
 [6] S. Papadimitriou, J. Sun, and P. Yu. Local correlation [7] J. Sun, Y. Xie, H. Zhang, and C. Faloutsos. Less is more: [8] T. Ide, S. Papadimitriou, and M. Vlachos. Computing [9] G. H. Golub and C. F. van Loan. Matrix computations (3rd [10] S. R. White. Density matrix formulation for quantum [11] A. K. Gupta and D. K. Nagar. Matrix Variate Distributions. [12] J. N. Bandyopadhyay and S. Jalan. Universality in Complex [13] E. Keogh and T. Folias. The UCR time series data mining [14] A. L. Barabasi and R. Albert. Emergence of scaling in [15] K. Yamanishi and Y. Maruyama. Dynamic syslog mining for
