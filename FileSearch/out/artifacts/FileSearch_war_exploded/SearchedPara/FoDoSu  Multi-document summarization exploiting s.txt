 1. Introduction  X  address this problem, various document summarization techniques have been studied to efficiently summarize the core of a single original document. More recently, multi-document summarization techniques have been researched to summa-by looking at a short summary.

Over the past few years, multi-document summarization has received more attention and made much progress. However, document summarization techniques analyze semantic relationships between words in a document by exploiting probabil-ity theory, machine learning techniques, and external knowledge-bases such as WordNet. are not present in WordNet.

In this paper, we propose a novel multi-document summarization system, called FoDoSu (Folksonomy-based Multi-Doc-among them, and finally make a summary of the documents.
 2008 and 2009 datasets. Finally, we conclude our work in Section 5 . 2. Related work briefly introduce HITS for a better understanding of the algorithm in Section 2.2 . 2.1. Multi-document summarization
In the literature, the development of multi-document summarization has been largely promoted by the Document Under-standing Conferences (DUC) 2 and Text Analysis Conferences (TAC).
Multi-document summarization techniques can be classified into two approaches. One is the extractive summarization summary by using natural language processing techniques. Although the abstraction-based method can summarize a docu-the overall frequency of the words they contain such as the TF-IDF technique ( Luhn, 1958; Edmundson, 1969; Brandow, the semantics of the relationships between the words and sentences ( Chali, Hasan, &amp; Joty, 2011 ). Hennig and Labor (2009) proposed a multi-document summarization method based on Probabilistic Latent Semantic plex computation.
 Wan (2008) also proposed a document summarization model using the Hypertext Induced Topic Search (HITS) algorithm. the document-to-sentence bipartite graph to compute the saliency scores of the sentences. As we will explain in next clusters to be authorities, and then exploit them to analyze the semantics of the word.
Dang and Luo (2008) proposed a method to detect key sentences using keyword extraction based on statistics and syn-analyze the relationship between the semantics of the words in Web documents because there are many proper nouns and newly-coined words in the original documents which are not defined in WordNet.

Zhu et al. (2009) proposed a tag-oriented Web document summarization approach using both the document itself and the analyzes the relationships between users and tags in the Folksonomy system.

To overcome these drawbacks, we propose a novel multi-document summarization system FoDoSu that employs tag 2.2. HITS algorithms on a given topic.
 follows: as authorities to exploit the HITS algorithm for analyzing the semantics of the words. 3. FoDoSu: Folksonomy-based multi-document summarization
Fig. 2 shows the framework of our multi-document summarization system FoDoSu. Given multiple documents that need multiple documents. Finally, the sentence analysis module generates the final summary of the documents by selecting the top n ranked sentences. The main phase of the framework will be described in the following subsection. 3.1. Preprocessing
The preprocessing module extracts sentences from the input documents, and then performs tokenization. Next, the stop given a weighted score based on the importance and contributions of the words in each sentence. 3.2. Word analysis
To analyze how much each word contributes to the document, we construct a Word Frequency Table ( WFT ) using tag the WFT 0 and analyze the semantics of each word. 3.2.1. Creation of the Word Frequency Table First, we construct a WFT to calculate the frequency of each word in the documents, which can be represented as
In Eq. (1) , w i =( w 1 , w 2 , ... , w n ) is the i -th word in the documents, and c lyzing the semantics of the words, there are many proper nouns and newly-coined words in the documents such as the semantics of proper nouns and newly-coined words.
 WordNet.
 and WordCluster information is updated. The final word frequency table WFT X  is represented as follows: 3.2.2. Analyzing the contribution of a word using HITS and the words in the WFT 0 as a hub.
 where a ( w i ) and h ( w i ) are the authority score and hub score of word w
Eq. (4) shows an authority measurement of the word w i . If word w trast, Eq. (5) shows a hub measuring the word w i for the case that the WordCluster of w the hub score h ( w i ) increases by 1, otherwise it is zero. The number of words in the WFT 0 having words w summed. Analysis of the hub of word w i is quite similar to the analysis of the authority of w tion to a given document by summing its authority and hub scores. 3.3. Sentence analysis a contiguous sequence of k words without duplicates.
 not consider the sequence of words.

Fig. 5 shows an illustrative example of computing the relationship between words. Assume that there are three words,  X  X  X  X  X ,  X  X  X  X  X , and  X  X  X  X  X , and each word has its own WordCluster,  X  X  Cluster includes word  X  X  X  X  X , but does not include word  X  X  X  X  X . Cluster words  X  X  X  X  X  and  X  X  X  X  X  have a medium semantic relationship because only Cluster grams as follows: where We then compute the score of a sentence as follows: where s is the sentence that includes the rel-gram, TF IDF ( w each term (where a + b + c = 1).
 Algorithm 1 Sentence Scoring Input: multi-documents
Output: summarized documents 1: for n =1to k // k= the number of rel-gram 2: if(n == 1) 3: take one word w in WFT X  4: for eachsentences 5: find s includes w 6: ScoreTable = Score( s , w ) 7: end for 8: else 9: compute rel-gram in WFT X  10: for each sentence s 11: find s includes rel-gram 12: ScoreTable = Score( s ,rel-gram) 13: end for 14: end if 15: end for 16: Sort(ScoreTable) by SentenceScore sentence.
 ing the relationships between words. The FoDoSu system summarizes documents using sentences assigned the highest ated a final summary of the given documents based on the top n scored sentences in the Score Table. 4. Experiments applications in JAVA on a Microsoft Windows 7 PC. 4.1. Data set and evaluation metric
We used the TAC 2008 and TAC 2009 data sets to test our proposed method empirically. Both data sets are open bench-has been widely adopted by the Document Understanding Conference (DUC) for automatic summarization evaluation. It pairs between the candidate summary (a summary by summarization techniques) and the reference summary (a summary grams), ROUGE-2 (recall against bigrams), ROUGE-L (longest common subsequence), and ROUGE-SU (skip bigram plus uni-gram). ROUGE-N is an n -gram recall measure computed as follows:
In Eq. (9) , n is the length of the n -gram, and Ref stands for the reference summaries, Count where ROUGE-2 and ROUGE-SU4 are automatic ROUGE evaluation scores. We show ROUGE-2 and ROUGE-SU4 metrics in the experimental results. 4.2. Parameter optimization 2 and ROUGE-SU4 gradually increase until the value of a reaches 0.3. In case of TAC 2008, both ROUGE-2 and ROUGE-SU4 is mainly influenced by the contributions of words and the semantic relationships between them. 4.3. Experimental results on TAC 2008 number of rel-grams on the summarization. On TAC 2008, our proposed system showed good performance when k = 3 and the number of words was 15. 4.4. Experimental results on TAC 2009 summarization. Using TAC 2009, our proposed system showed good performance when k = 4 and the number of words was 10. 4.5. Effect of tag cluster
The proposed system exploits the tag clusters used in Folksonomy to analyze the semantics of the words with low com-investigate how the HITS algorithm helps the summarization performance of FoDoSu, we have investigated the following outHITS), and in the final case, the HITS algorithm (WithHITS) was used.

Figs. 15 and 16 show the F-measure of ROUGE-2 and ROUGE-SU4 on datasets TAC 2008 and TAC 2009. OnlyFREQ shows
The performance of WithHITS on TAC 2008 and TAC 2009 was improved by 8.9 X 11.5% compared to OnlyFREQ, and by 2.7 X  to OnlyFREQ, and by 2.1 X 5.2% compared to WithoutHITS. From these experiments, we confirmed that FoDoSu effectively documents. 4.6. Comparison of performance
Tables 3 and 4 show the results when comparing our proposed system FoDoSu, which uses TF-IDF and HITS algorithm together, with the related multi-document summarization techniques on TAC 2008 and TAC 2009. In these experiments, rithm for summarizing documents. DocHITS considers the documents and sentences as hubs and authorities in the HITS other the HITS algorithm based systems for document summarization.
 the document, FoDoSu performed with low computational cost. Second, FoDoSu analyzed proper nouns and newly-coined words, such as the names of people and products. 4.7. Scope of semantic analysis of words in WordNet and tag cluster
Fig. 17 shows the ratio of words used to analyze semantics in TAC 2008 and TAC 2009 using WordNet and tag clusters semantics of the words in the document. 5. Conclusions In this paper, we propose FoDoSu which is a novel multi-document summarization system using tag clusters from a lyzing the semantics of words in the document, FoDoSu performed with low computational cost. Second, FoDoSu analyzed iments on TAC 2008 and TAC 2009 datasets, our proposed system FoDoSu always performs better than the other systems. and newly-coined words. In addition, we will improve our proposed multi-document summarization. Acknowledgement funded by the Ministry of Education (2013R1A1A2059663).
 References
