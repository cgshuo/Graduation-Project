 Web forums are platforms for personal communications on sharing information with others. Such information is often expressed in the form of advice. In this paper, we address the problem of advice-revealing text unit ( ATU ) extraction from online forums due to its usefulness in travel domain. We represent advice as a two-tuple comprising an advice-revealing sentence and its context sentences. To extract the advice-revealing sentences, we propose to define the task as a sequence labeling problem, using three different types of features: syntactic, contextual, and semantic features. To extract the context sentences, we propose to use a 2Di-mensional CRF (2D-CRF) model, which gives the best per-formance compared to traditional machine learning mod-els. Finally, we present a solution to the integrated problem of extracting both advice-revealing sentences and their re-spective context sentences at the same time using our pro-posed models, i.e., Multiple Linear CRF (ML-CRF) and 2 Dimensional CRF Plus (2D-CRF+). The experimental re-sultsshowthatML-CRFperformsbetterthananyother models studied in this paper for extracting advice-revealing sentences and context sentences.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing Algorithms, Performance, Experimentation Advice Mining, Sequence Labeling, Conditional Random Field
Web forums contain a huge number of posts generated by millions of internet users and grow every day. They enable the users to easily discuss with others various topics as well as share their personal experiences and thoughts on desig-nated topics. For example, Web forums such as Tripadvisor , Fodors ,and Amazon make it easy for people to share their experiences with others about the places they visited, the hotel services they received, new cameras they purchased, interesting books they read, or the latest film they watched. Web forums often contain explicit key lessons and know-how X  X  gleaned from people X  X  past experiences which are re-ally worthy to be well selected and presented to other people and/or intelligent agents to help providing context-sensitive assistance. Such key lessons are often expressed in the form of advice .

In the travel domain, for example, travelers usually seek pieces of advice from travel Web forums before they visit some tourist places [2, 6]. They provide a perspective on where they should travel, what they should do, and what they should be aware of. When advice is represented in an appropriate form and indexed with situational and contex-tual variables, it can serve as useful knowledge for decisions to be made on the go using a mobile device [23]. In fact, we chose the travel domain for our research with some po-tential applications in mind, such as advice retrieval system for travelers, context-aware advice generation, and tourism marketers X  assessment tools.

As part of an effort to mine experiential knowledge, we ad-dress a new problem referred to as advice mining in which advice is extracted and aggregated from Web forum, and subsequently stored with well-organized indices. As the first step toward a full-fledged advice mining, we tackle the prob-lem of extracting an advice-revealing text unit ( ATU )com-prising the following two elements: 1. Advice-revealing sentence: a sentence that con-2. Context sentence: a sentence that explains or clar-While a finer-level analysis of an advice sentence would help mining pieces of advice, this capability can serve the pur-pose of retrieving advice-containing articles with the advice anchored in a particular context for human consumption as well as for further processing to result in a formal represen-tation of advice broken down into smaller elements for in-ferencing. Below are examples of advice-revealing sentences as well as their corresponding context sentences extracted from well-known Web forums. 1. advice-revealing sentence:  X  But you are advised to 2. advice-revealing sentence:  X  Instead of standing on Constructing an ATU constitutes solving two problems: (1) advice-revealing sentence extraction and (2) context sentence extraction in the text region. For the advice-revealing sen-tence extraction problem, we propose to define it as a se-quence labeling problem using three different types of fea-tures: syntactic, contextual, and semantic features. There are two reasons why we treat it as a sequence labeling prob-lem rather than a binary classification. First, we found that advice-revealing sentences tend to appear contiguously in a forum thread. Second, we saw a potential to apply the Skip-Chain CRF model that considers dependency between re-peated mentions, where our sentence generalization method is employed to find redundant sentences and construct the skip-edges.

Knowing only advice-revealing sentences without their con-texts is not enough for the advice mining task. For exam-ple, a forum thread contains an advice-revealing sentence  X  instead of standing on a long line with your purchases, just take your receipt to a VAT Tax machine, which will scan the bar code on it and validate it  X . Storing only this sentence in advice repository would create problems when it is asked for because the system would not know when or in what situa-tion the advice could be relevant and useful. If the system also stores the corresponding context sentence like X  there are several things all travelers to Paris (and Europe generally) should know  X  (which is also located in the same thread), the advice-revealing sentence becomes clearer and can be given only to the people who are or will be in Paris . Therefore, extracting context sentences is essential to making advice-revealing sentences useful. While the context sentence ex-traction problem can be solved with a regular binary classi-fier using traditional machine learning models, we propose to use the 2D-CRF model since it can capture dependency between any contiguous position in the context sentence can-didate sequences. Our experimental results shows that the 2D-CRF gives the best performance compared to traditional machine learning models for extracting context sentences.
Finally, We present a novel solution that extracts advice-revealing sentences and their respective context sentences at the same time in a single pass by using two new CRF-based models referred to as Multiple Linear CRF (ML-CRF) and 2 Dimensional CRF Plus (2D-CRF+). ML-CRF and 2D-CRF+ can model two types of dependency: (1) dependency between contiguous positions in two different candidate se-quences ( advice-revealing sentence candidate sequence and context sentence candidate sequence ), (2) dependency be-tween these two types of candidate sequence. In brief, our main contribution is to define and cope with a new prob-lem referred to as advice-revealing text unit ( ATU )detection from Web forums , which was never addressed in the past.
Works on extracting useful knowledge have been done in the past. Park et al. [17], and Inui et al. [9] tried to harvest human X  X  experience from Weblogs for experience retrieval and experiential knowledge distillation. Moreover, we have also seen the flourishing of research in the area of opinion mining in the recent years [16]. Computational approaches to opinion mining currently eschew a general theory of emo-tions and focus on extracting the affective content of a text from the detection of expressions of sentiment [1]. Asher et al. [1] mentioned that it is important for NLP systems to go beyond positive and negative sentiment expressions and identify a wide range of opinion expressions. Moreover, they categorize opinion expressions using a typology of four top-level categories: Sentiment expressions, which is the current focus of opinion mining, Reporting expressions, Judgment expressions, and Advice expressions, which urge the reader to adopt a certain course of action or opinion [1]. They hope that opinion mining researchers will go beyond these four categories in the future. Our work contributes in extracting advice expressions together with their contexts from texts, especially online forums, which was never addressed before.
While there is no previous work that addressed the same problem like ours, two previous studies addressed only the problem of extracting advice-revealing sentences. Kozawa et al. [11] proposed methods to extract prior-advice from the Web in order to provide users prior-information before they do a particular activity. Wicaksono and Myaeng [24] ad-dressed the problem of extracting advice-revealing sentences from English Weblogs. Our work has two unique technical challenges compared to the previous work. First, since Web forums have unique characteristics compared to Weblogs and other online platforms, we face the problem of handling categorically different features for an optimal performance, which may require a new computational model. For exam-ple, we found that advice-revealing sentences tend to appear contiguously in forum threads, which means that devising a model that is capable of capturing this information is very crucial. Second, we face a new problem of extracting context sentences that correspond to advice-revealing sentences. To construct a collection for the experiments, we crawled Web forum threads from two well-known travel forums ( In-sightVacations 1 and Fodors 2 ). We then selected 150 threads randomly from each Web forum to result in a dataset of 300 threads containing 5199 sentences. Two annotators were asked to label advice-revealing sentences and their corre-sponding context sentences. The kappa statistic for inter-annotator agreement is 0.76 in identifying advice-revealing sentences, and 0.68 in identifying context sentences. We used the intersection of the two annotators X  judgments for the advice-revealing sentence extraction task and the union of the two annotators X  judgments for the context sentence extraction task. Table 1 shows our data in detail. On aver-http://forums.insightvacations.com http://www.fodors.com age, each thread has 7 advice-revealing sentences and each advice-revealing sentence has 3 context sentences.
This section focuses on how to automatically extract advice-revealing sentences from online forums. To give a better un-derstanding of this task, we formally define it as follows: given a thread with | S | sentences { s 1 ,s 2 ,s 3 , ..., s task of advice-revealing sentence extraction aims to deter-mine a prediction function H , which maps a sentence s i into one of two predefined labels (i.e., advice and non-advice). Formally, we determine a prediction function H so that Y = H ( s i ), where Y i  X  X  Advice, NonAdvice } .

We propose a machine learning approach to automatically extract advice-revealing sentences from Web forums, which means that devising good features that can characterize ad-vice as well as non-advice revealing sentences is a very im-portant process.
The features we defined for our machine learning model are categorized into three as described in Table 2. Syntactic Feature . Syntactic features leverage linguistic information of the target sentence to be classified. To de-termine whether or not a sentence contains an imperative mood expression, we use the heuristic method proposed by Wicaksono and Myaeng [24].

Class sequential rules (CSRs) are discovered using CSR mining algorithm, which is known as a data mining tech-nique that can find all labeled sequential patterns with a user-specified minimum support [13]. Each discovered CSR serves as a binary feature for our models. That is, there are their respective CSRs, where m is the number of discov-ered CSRs. If a sentence s contains a particular CSR, then f ( s ) = 1; otherwise f i ( s ) = 0. Intuitively, the discovered patterns can act as good cue patterns since they appear fre-quently in either advice-revealing sentences or non-advice-revealing sentences. To construct a sequence database in our case, we process each sentence in our dataset as well as its corresponding label to generate rules in the form of X  X  X  X  where l  X  X  Advice, NonAdvice } . To create a sequence X , first, we tokenize the corresponding sentence into a list of words. Second, we only keep pronouns, modal words (e.g.,  X  X ould X ,  X  X an X , etc.), and cue phrases/words (e.g.,  X  X ake sure X ,  X  X  suggest X ,  X  X ecommend X , etc.), skipping all others. Third, we use a part-of-speech tag, instead of a word, in ev-ery position before and after modal words. For example, the sentence  X  X  would like to recommend X  is transformed into  X  X  would VB recommend X , where  X  X B X  is a part-of-speech tag. Cue words are usually good indicators for advice-revealing sentences while part-of-speech tags reduce the sparseness of words.

Typed dependencies within a sentence are determined us-ing the Stanford dependency parser [14]. It provides a simple description of the grammatical relationships in a sentence. In our case, we only pay attention to conjunct , clausal sub-ject ,and nominal subject relations, which are denoted by  X  X onj X ,  X  X subj X , and  X  X subj X , respectively. Forum-specific cue phrases are mostly indicators of non-advice sentences be-cause they are usually expressions of greetings, gratitude, or hope. Typed dependency based features and forum-specific features are essentially binary features. If a sentence con-tains a particular feature, its corresponding feature function value is set to 1; otherwise it is set to 0.
 Context Feature. Context features provide information  X  X tored X  between neighboring sentences in a forum thread. For example, Jaccard similarity is computed to capture de-pendency between a target sentence and fixed numbers of its preceding and succeeding sentences. Each similarity feature is a single real-valued feature.
 Semantic Feature. Each word actually carries a differ-ent amount of information contributing to the informative-ness degree of a sentence. Bearing in mind that an advice-revealing sentence must be informative to the users, we can obviously leverage term informativeness theory to define one of our features for this classification task. There are several well-known term informativeness measures such as inverse document frequency (IDF) [20], burstiness [4], and residual IDF [5]. In our experiment, we used these three measures as basis for our semantic feature.

To use a term informativeness measure as one of our fea-tures, we introduce the notion of sentence informativeness measure , which is simply a summation of informativeness scores of all the nouns contained in a sentence. Sentence informativeness value is then used as a single real-valued feature for our models. The rationale behind using nouns is that they are usually content words expressing the topic of a sentence. Alternatively, informativeness of a sentence S is defined as follows.
 where SI ( S ) is an informativeness score of sentence S , N is the number of nouns contained in S ,and TI ( nw i )isa term informativeness score of i th noun computed by IDF, burstiness, or residual IDF.

In computing TI ( w ), we make a distinction between lo-cal and global informativeness. For TI local ( w ) representing local informativeness score , we treat each sentence in a fo-rum thread as a single document and a forum thread as one collection of documents. For TI global ( w ) representing global informativeness score , however, the sentences contained in the whole forum threads are now treated as one collection of documents. Now, TI ( w ) is computed by combining both local and global informativeness scores as in the following equation.
 where  X  is set empirically 3 . The rationale behind using this combination is that a term sometimes seems to be very im-portant with respect to a particular forum thread (local in-formation), but not necessarily from the global view. In order to incorporate forum-specific information, we penalize the informativeness score if the sentence has at least one of the following conditions: located in the first post , aquestion sentence ,or incomplete .
Based on our further observation, we found that advice-revealing sentences tend to appear contiguously in the Fo-rum data. As in Table 3, we can see that sentence Y t tends to have the same label with its previous sentence Y t  X  1 .AChi-square statistical test value of 1,390 ( p  X  value &lt; 0 . 001) in-dicates general strong dependency between contiguous sen-tences in a thread, although the likelihood varies with their location in a thread. Therefore, a good model for the prob-lem should be able to capture this dependency well. Unfor-tunately, traditional machine learning models such as SVM and Maximum Entropy cannot capture this kind of depen-dency naturally. Therefore, instead of treating the task as binary classification using traditional machine learning mod-els (as in [11, 24]), we see it as a sequence labeling problem to consider the sentence-level dependency.
 Table 3: Dependency Between Contiguous Sen-tences (  X  2 =1 , 390 ,p  X  value &lt; 0 . 001 )
Linear Conditional Random Field (Linear CRF) [12] is known to be a state-of-the-art algorithm for solving sequence labeling problems. In recent years, many researchers in the natural language processing area have successfully employed Linear CRF to solve their problems such as syntactic pars-ing and named entity recognition [22, 15]. In brief, given an observable sequence X =( x 1 ,x 2 , ..., x n ), where n is the number of sentences in a post, the goal is to find the sequence of hidden labels Y =( y 1 ,y 2 , ..., y n ) using a conditional dis-tribution function as follows. We set  X  to 0.6 in our experiment where {  X  } are the potentials over several feature functions as well as their respective weights, and Z ( x ) is a normalization factor.
When the same entity is mentioned more than once in a sequence, in many cases all entity mentions have the same la-bel. We can take advantage of this fact by favoring labelings that treat repeated entities identically, and by propagating pieces of evidence from all entity mentions so that the ex-traction decision can be made based on global information (all mentions separated by long-range positions). However, Linear CRF cannot take advantage of this dependency since it is based on the markov assumption among labels (i.e., dependency between nearby nodes only). The goal of Skip-Chain CRF is to relax this assumption by modeling depen-dency between distant nodes as well as nearby nodes [21]. Figure 1 shows the graphical model of Skip-Chain CRF. The distribution over hidden labels is defined as follows. where  X  is a set of skip-edges, {  X  } are the potentials over the linear-chain edges, {  X  } are the potentials over the skip-edges, and Z ( x ) is the normalization factor.

In our case, skip-edges cannot be constructed and found easily since few entities representing sentences are identical. We need to operate at a more general level to ensure that a sufficient number of skip-edges exist for a meaningful mod-eling. To do that, we propose to use sentence generalization with top-N features in constructing skip-edges between se-quential sentences in our data. Suppose S and O are non-empty sets, where S = { s 1 ,s 2 , ..., s m } is a list of sentences bels. Then, there exists a mapping  X  : S  X  O from S into O which assigns to each member of S a unique member in O . The process of determining the mapping  X  is described as follows. 1. We obtain top-N feature set F N = { f 1 ,f 2 , ..., f n 2. We extract F s j , i.e., the set of features of a sentence 3. Each distinct k-tuple in the dataset is then re-labeled
Finally, skip-edges are constructed between any pair of two positions ( y u ,y v ), where  X  ( s u )=  X  ( s v ).
In this section, we aim to extract context sentences for each extracted advice-revealing sentence. Here, we assume that all real advice-revealing sentences have been extracted using the method described in the previous section.
In our definition, context sentences are located in the same thread where their corresponding advice-revealing sentences are extracted. An advice revealing sentence may correspond to more than one context sentences, and vice versa. More-over, an advice revealing sentence may act as a context sentence for other advice-revealing sentence. The context sentence extraction task can be formally defined as follows: set of advice-revealing sentences A = { a 1 ,a 2 , ..., a in the thread, where a i  X  S and m  X  n , the task is to find whether a pair { ( a i ,s j ) | a i  X  A, s j  X  S } is an ATU consist-ing of an advice-revealing sentence and its context sentence.
We propose two different methods for extracting context sentences. Both of the methods are based on supervised machine learning in which the models are trained using the predefined features.
For a forum thread of M advice-revealing sentences, this method performs M runs of a context extraction algorithm for each advice-revealing sentence. Given an advice-revealing sentence a i in a thread, a traditional machine learning model (e.g., SVM and Maximum Entropy) is employed to detect whether or not each sentence s j  X  S inthesamethreadisa context sentence of a i . The features for extracting context sentences are listed below.
 Feature-1. Jaccard similarity between an advice-revealing sentence and its corresponding context sentence candidate. The rationale behind this feature is that an advice-revealing sentence and its context sentence would share similar words. Feature-2. Semantic similarity between an advice-revealing sentence and its corresponding context sentence candidate. This similarity measure is used to bridge the lexical gap be-tween an advice-revealing sentence and its context sentence candidates. We use a sentence relatedness measure provided in Open Roget X  X  project [10].
 Feature-3. Whether a context sentence candidate is lo-cated before its corresponding advice-revealing sentence in a forum thread. Based on our observation, context sentences tend to appear before the corresponding advice-revealing sentence.
 Feature-4. Whether a context sentence candidate has not been identified as an advice-revealing sentence.
 Feature-5. Whether a context sentence candidate is incom-plete. Incomplete sentences usually do not contain meaning-ful information since they usually represent greetings (e.g.,  X  good morning all  X ) or hopes (e.g.,  X  enjoy your trip  X ). An incomplete sentence can be detected using a dependency parser 4 and an imperative mood detector like the one pro-posed by Wicaksono and Myaeng [24]. If a non-imperative sentence does not contain a nominal subject , denoted by the  X  X subj X  dependency relation, it means that it is incomplete; otherwise it is considered complete. We use Stanford Dependency Parser [14] Figure 2: 2 Dimensional Conditional Random Field (2D-CRF) Feature-6. Whether a context sentence candidate contains a proper noun. A proper noun usually represents a named entity such as country-name , city-name , date , organization , etc. This is obviously a good indicator for a context sen-tence.
The method described in the previous sub-section is a straightforward application of traditional machine learning based on the features we identified. It is based on the as-sumption that there is no dependency in between context sentence candidate sequences that correspond to their re-spective advice-revealing sentences. This assumption does not necessarily hold as we have shown the nature of fo-rum threads that tend to have dependency between con-tiguous positions. To capture such dependencies, we use 2 Dimensional Conditional Random Field (2D-CRF). Us-ing 2D-CRF enables us to extract context sentences for all advice-revealing sentences together. The 2D-CRF has been used for a few natural language processing tasks. Ding et al. [8] employed 2D-CRF to detect contexts and answers of questions in forum threads. Qu and Liu [18] also used 2D-CRF to label the dependency relation between sentences in forum threads.

The graphical model of 2D-CRF is shown in Figure 2 (only the hidden states). There are m rows and n columns in the graphical model. For the ATU extraction problem, the i th row and j th column correspond to an advice-revealing sentence and a sentence in a forum thread, respectively. One row represents one pass of extracting context sentences for a particular advice-revealing sentence using the traditional machine learning model. 2D-CRF described in Figure 2 consists of m chains, where y i,j is the variable in chain i at time j . The clique indices forthis2D-CRFareoftheform { ( i, j ) , ( i, j +1) } for each of the within-chain edges and { ( i, j ) , ( i +1 ,j ) } for each of the between-chain edges . The distribution over hidden labels is defined as follows. where {  X  } are the potentials over the within-chain edges, {
 X  } are the potentials over the between-chain edges, and Z ( x ) is the normalization factor. The potentials factorize according to the features { f } and weights {  X  } as in the following formulation.
 where { f a k } are features for within-chain edges that exploit dependency between contiguous positions in a thread and { f g } are features for between-chain edges that exploit de-pendency between advice-revealing sentences. For { f a k } { f g } , we use the same feature set as for context sentence extraction using traditional machine learning models.
In the previous section, we tackle the advice-revealing sen-tence extraction and the context sentence extraction tasks separately. In Section 5, we specifically mention the meth-ods for tackling context sentence extraction task by assum-ing that advice-revealing sentences have been perfectly ex-tracted (with 100% accuracy) previously. Considering that the advice-revealing sentence extraction task is still far from perfect, it is desirable to find a new robust method that can handle both of the tasks together and reflect the reality. We propose a solution, in which we extract advice-revealing sentences and their corresponding context sentences at the same time (in one pass). To do that, we propose to use two new CRF-based models referred to as Multiple Linear CRF (ML-CRF) and 2D-CRF Plus (2D-CRF+). ML-CRF and 2D-CRF+ can model two types of dependency: (1) de-pendency between contiguous positions in two different can-didate sequences, i.e., advice-revealing sentence candidate sequence and context sentence candidate sequence ,(2)de-pendency between these two types of candidate sequence. The first dependency can be modeled using previously men-tioned CRF-based methods such as Linear CRF, Skip-Chain CRF, and 2D-CRF when we extract advice-revealing sen-tences and context sentences separately. However, the sec-ond dependency can only be modeled when we extract both advice-revealing sentences and context sentences at the same time.

We define our new task as follows: given a set of sen-tences S = { s 1 ,s 2 , ..., s n } in a thread, the task is to dis-cover two sets: (1) a set of advice-revealing sentences A = { a 1 ,a 2 , ..., a m } , and (2) a set of context sentence lists C = { c 1 , c 2 , ..., c m } ,where a i  X  S , m n , c i = { c i, 1 is a set of context sentences for a i (i.e., a pair { ( a A ,c i,j  X  c i } is an ATU ), c i,j  X  S ,and k n .Thistask definition is similar to those in other previous studies such as questions-answers detection from Online forums and Email conversations [7, 19] and contexts-questions detection from Online forums [8]. It means that our ML-CRF and 2D-CRF+ also be applied for these tasks.

Previously, the definition of context sentence only applies to the sentences that explain or clarify an advice-revealing sentence in more detail, which means that we only focus on extracting context sentences for those advice-revealing sen-tences that have been extracted before. We cannot apply such definition on our new task since the advice-revealing sentences and context sentences are unknown when the ex-traction algorithm is executed at the first time. To solve this problem, we need to define  X  X ontext sentence X  in a more abstract level. Based on this abstraction, all sentences in a Web forum thread (advice and non-advice revealing sen-tences) can have their respective context sentences. Another problem was then raised since our dataset only contains annotated context sentences for advice-revealing sentences. We did not hire annotators to label context sentences for non-advice-revealing sentences. Therefore, we had to com-plete our dataset before applying ML-CRF and 2D-CRF+ for tackling the new task.

To complete our dataset, we employed semi-supervised approach, which means that annotating context sentences for non-advice-revealing sentences was done automatically using a machine learning algorithm. Moreover, the auto-matically labeled data is used only for the training, which is in fact more desirable than requiring them to be done manually, and has nothing to do with the evaluation result. The machine learning model was then trained using all avail-able context sentences (for advice-revealing sentences) that had been manually tagged by our annotators. We modified the features described in Section 5.1 for our machine learn-ing model. We omitted feature-4 since advice-revealing sen-tences were unknown. We generalized Feature-1, Feature-2, and Feature-3 so that they applies for all sentences in a fo-rum thread. Moreover, we employed a Linear CRF as the machine learning model for exploiting the modified features since it gave the best performance compared to traditional machine learning models (i.e., SVM and maximum entropy) (this will be shown in Section 7.2).
Multiple Linear Conditional Random Field (ML-CRF) is an undirected model that encode a conditional probability distribution between a state sequence y ( 1 ) = { y (1) j multiple state sequences { y ( 2 ) i } , given the an observation sequence x = { x j } , in which a state y (1) j is associated with a state sequence y 2 j = { y (2) j,k } .Forthe ATU extraction prob-lem, y (1) j  X  X  Advice, NonAdvice } and y (2) j,k corresponds to a candidate of a context sentence for the sentence x j ,where y are n rows and n columns in the graphical model (only the hidden states), where n is the number of sentences in a forum thread. One row (in the unshaded area) represents one pass of extracting context sentences for the corresponding candi-date of an advice-revealing sentence; meanwhile, the shaded sequence, which transverses through the diagonal area (see { y sentences.

Specifically, we use ML-CRF m to denote an ML-CRF in which dependency edges are constructed between a state y i and several states | i  X  x | m } .Wecall m as the value of sliding window edge . This edge construction may reveals the dependency between a state in the advice-revealing sentence candidate sequence ( y ( 1 ) ) and a corresponding state in a context sentence se-quence as well as its neighboring context sentence sequences. Figure 3 shows an example of ML-CRF 1 ,inwhich,forex-ample, edges are constructed for the following three pairs: { y over hidden states is defined as follows: where n is the number of sentences in a forum thread, m is the value of sliding window edge, {  X  } are the potentials over the edges in the context sentence candidate sequences, {  X  } are the potentials over the edges in between two types of sequence (this depends on the value of m ), {  X  } are the potentials over the edges in the advice-revealing sentence candidate sequence, and Z ( x ) is the normalization factor. The potentials factorize according to the features { f } and weights {  X  } as in the following formulation.
  X  ( . )=  X  ( . )= exp where { f (1) g } is a set of features for advice-revealing sen-tence extraction (see Table 2), { f (2) m } is a set of features for context sentence extraction (see Section 5.1), and {  X  and {  X  (2) m } are the respective weights for each of two fea-ture sets. In this integrated solution, we modified features for context extraction described in Section 5.1 since advice revealing sentences are unknown when the extraction algo-rithm is executed at the first time. We omitted feature-4 and generalized Feature-1, Feature-2, and Feature-3 so that they applies for all sentences in a forum thread. As shown in Equation 9, ML-CRF also allows a state y (2) i,j in the context sentence candidate sequence to utilize features of a state y in the advice-revealing sentence candidate sequence. A 2 Dimensional Conditional Random Field Plus (2D-CRF+) is similar to the ML-CRF model. The 2D-CRF+ also encodes a conditional probability distribution between a state sequence y ( 1 ) = { y (1) j } and multiple state sequences { y i } , given the an observation sequence x = { x j } ,inwhich a state y (1) j is associated with a state sequence y 2 j Moreover, the application of the 2D-CRF+ for the ATU extraction problem is completely the same as the applica-tion of the ML-CRF for the same problem. The difference is that the 2D-CRF+ models dependency between two con-tiguous context sentence candidate sequences by construct-ing between-chain edges, just like the 2D-CRF described in Section 5.2.

Specifically, we use 2D-CRF m + to denote a 2D-CRF+ in which dependency edges are constructed between a state y i and several states | i  X  x | m } and m is the value of sliding window edge. Figure 4 shows an example of 2D-CRF 1 + (only the hidden states). We need to modify Equation 8 by adding a new tion over hidden states, in which {  X  } are potentials over the between-chain edges in the context sentence candidate sequences. The factorization of the potentials {  X  } is com-pletely the same as {  X  } (i.e.,  X ( . )= X ( . )), which means that we just transfer all features from within-chain edges into between-chain edges in the context sentence candidate sequences.
Several experiments were carried out to see the perfor-mances of our models. We used precision, recall, and F1-score to measure the performance of the proposed method and the baselines. Due to the rather limited size of the dataset, we used 5-fold cross validation.
For baselines, we implemented two baselines: baseline #1 [24] and baseline #2 [11]. Both baselines defined the prob-lem as binary classification using SVM model. Baseline #2 used various Japanese-specific linguistic features and base-line #1 introduced several features for English data, such as the presence of imperative mood expression and opinionated copula. While the baseline #1 was applied directly to our dataset, the second one had to be modified because it was developed for Japanese data. The performances of the two baselines are shown in Table 4.

For the case of using local information alone, we ran an experiment using two state-of-the-art traditional machine learning models (i.e., SVM and Maximum Entropy) and a Linear CRF model. We used all the proposed features but only local information for sentence informativeness measure. Moreover, we also tried three different term informativeness measures in this experiment. The results are very promising as in Table 4. First, our proposed method significantly out-performs the two baselines, perhaps because we leveraged forum-specific information as features. Second, the Linear CRF model outperforms the two traditional machine learn-ing models across all the different informativeness measures because it can leverage dependency between contiguous sen-tences. The result also signifies that it is a good idea to treat the problem as sequence labeling problem rather than a bi-nary classification problem.
 Table 4: Baseline performances and comparison be-tween traditional ML model and Linear CRF using all proposed features (only local information for se-mantic feature) for advice-revealing sentence extrac-tion
We also ran an experiment using the same setting as be-fore, except that we used both local and global information for semantic feature. Since using both outperforms the case of using local information alone, this performance becomes a baseline when we examine the benefit of using Skip-Chain CRF.
 We ran an experiment using our improved model (Skip-Chain CRF) to see the effect in comparison with the Linear CRF. To construct the skip-edges (using our sentence gener-alization method), we employed the Fisher scoring method as the feature selection tool since it is known to be inde-pendent of the classifier being used [3]. As shown in Table 5, combining both local and global information for sentence informativeness score generally improved the performance across all the models from the previous setting. We can also see that Skip-Chain CRF performs better than Linear CRF because it can take advantage of long-range dependency be-tween similar entities.
 Table 5: Comparison between traditional ML model, Linear CRF, and Skip-Chain CRF using all proposed features (local and global information for semantic feature) for advice-revealing sentence ex-traction
In this experiment, we used traditional machine learning models to extract context sentences individually (for each advice-revealing sentence) leveraging all the features men-tioned in Section 5.1. As shown in Table 6, SVM and Maxi-mum Entropy models have similar performance for the con-text sentence extraction task, achieving around 53% in terms of F1-score.

Furthermore, we used Linear CRF for extracting context sentences individually. As shown in Table 6, the result shows that Linear CRF significantly outperforms the traditional machine learning models. This is not surprising due to the nature of a Web forum thread that has dependency between contiguous sentences.

We finally ran an experiment with 2D-CRF model for the context sentence extraction task. In this case, the con-text sentences of all the detected advice-revealing sentences Table 6: SVM, Maximum Entropy, Linear CRF, and 2D-CRF model for context sentence extraction are extracted together at once. We used the same fea-tures as mentioned in Section 5.1 for within-chain edges and between-chain edges. As shown in Table 6, 2D-CRF signif-icantly outperforms the traditional machine learning mod-els since 2D-CRF can model dependency for both between-chain positions and within-chain positions. Moreover, 2D-CRF is still better than Linear CRF in terms of F1-score.
In this sub-section, we show our experimental results for the case of using our proposed CRF-based models (i.e., ML-CRF m and 2D-CRF m +) for extracting advice-revealing sen-tences and their respective context sentences at the same time. Basically, we ran experiments using the value of slid-ing window edge m = { 0 , 1 , 2 , 3 , 4 ,n } ,where n is the number of sentences in a forum thread. Moreover, we used syntac-tic, context, and semantic (burstiness &amp; local+global) fea-tures as well as all the features mentioned in Section 5.1, except Feature-4, since advice revealing sentences are un-known when the extraction algorithm is executed at the first time. Table 7 shows that results for advice-revealing sentence extraction. Even though it is not significant, ML-CRF m ( m = { 0 , 1 , 2 } ) shows an improvement compared to the use of Skip-Chain CRF. Meanwhile, 2D-CRF m + wors-ens the performance significantly. The results shown in Ta-ble 7 suggest the fact that there exists dependency between advice-revealing sentence candidate sequence and context sentence candidate sequences. But, when we create too many dependency edges either in between two types of se-quence or among context sentence candidate sequences (e.g, 2D-CRF+), it may harm the performance. This may be a byproduct of non-convergence during optimization since there are many additional parameters and the dataset is fairly small.
 Table 7: The Performance of ML-CRF and 2D-CRF+ for extracting advice-revealing sentences We then evaluated the performance of ML-CRF and 2D-CRF+ for context sentence extraction. In this experiment, we evaluated the performance of context sentence extrac-tion only for the corresponding correctly extracted advice-revealing sentences, because we obtained the results from two different tasks at the same time. For example, in case of ML-CRF 2 , we only evaluated extracted context sentences only for all advice-revealing sentences indicated by Preci-sion = 76.8%, Recall = 74.6%, and F1-score = 75.7% (true positive). Therefore, we cannot directly compare the results obtained in this experiment with the results described in Section 7.2 since experiments mentioned in Section 7.2 as-sumed that advice-revealing sentences have been perfectly extracted (with 100% accuracy) previously.

To compare the performance of ML-CRF and 2D-CRF+ with the previous models for context sentence extraction, we can run once again either SVM, Maximum Entropy, or Lin-ear CRF for only those advice-revealing sentences that have been correctly extracted (true positive). We chose the Lin-ear CRF since it gave the best performance compared to the traditional machine learning as described in Table 7. Unfor-tunately, we cannot run the 2D-CRF in this case since it requires an ideal situation, i.e., all real advice-revealing sen-tences in a target thread must be known before. Moreover, when we used the Linear CRF to extract context sentences.
Table 8 shows the performances of the ML-CRF m and the 2D-CRF m + for extracting context sentences. We only show top-2 model settings from both ML-CRF and 2D-CRF+ that give the best performance as mentioned in Table 7. In Table 8, we use a term sector to denote an area between two horizontal lines. A sector describes the performance of a model (either ML-CRF or 2D-CRF+) and the performance of the Linear CRF that ran over the same set of advice-revealing sentences.

As shown in Table 8, the ML-CRF and 2D-CRF+ outper-formed the Linear CRF significantly for context sentence ex-traction. Specifically, ML-CRF performed better than 2D-CRF+. Once again, the results suggest the fact that captur-ing dependency between an advice-revealing sentence candi-date sequence and context sentence candidate sequences is important. But, constructing too many dependency edges, especially among context sentence candidate sequences, will harm the performance for context sentence extraction. Table 8: The Performance of ML-CRF and 2D-CRF+ for extracting context sentences. The results are also compared with the Linear CRF model
We presented a methodology to extract advice-revealing sentences as well as their context sentences from Web fo-rums. Our experiments show that the Skip-Chain CRF per-forms better than the Linear CRF and traditional machine learning models for advice-revealing sentences since it can model dependency between nearby sentences as well as two similar sentences separated by long range of positions. In case of context sentence extraction, the 2D-CRF performs better than traditional machine learning model because it can model dependency for both between-chain positions and within-chain positions. Finally, we show that our Multi-ple Linear CRF (ML-CRF) performs better than any other models studied in this paper for extracting advice-revealing sentences and context sentences, which means that the ML-CRF is currently the best model for implementing ATU extraction system in the real situation. Given the promising results, we plan to explore along two lines. First, we still need to improve the performance by devising other features and models. At the same time, we also need to evaluate the efficiency side. Second, we plan to work on actually imple-menting advice mining system by designing a refined model of expressing advice. The first author is a grantee of a Korean Government Scholarship from the Ministry of Education, Science and Technology (MEST), Republic of Korea. [1] N. Asher, F. Benamara, and Y. Mathieu. Appraisal of [2] Travel Industry Association. Executive Summaries -[3] Y. W. Chen and C. J. Lin. Combining svms with [4] K. W. Church and W. A. Gale. Poisson mixtures. [5] K. W. Church and W. A. Gale. Inverse document [6] Compete, Inc. Embracing Consumer Buzz Creates [7] G. Cong, L. Wang, C.-Y. Lin, Y.-I. Song, and Y. Sun. [8] S. Ding, G. Cong, C. Y. Lin, and X. Zhu. Using [9] K. Inui, S. Abe, K. Hara, H. Morita, C. Sao, [10] A. Kennedy and S. Szpakowicz. A supervised method [11] S. Kozawa, M. Okamoto, S. Nagano, K. Cho, and [12] J. D. Lafferty, A. McCallum, and F. C. N. Pereira. [13] B. Liu. Web Data Mining: Exploring Hyperlinks, [14] M.-C. D. Marneffe, B. MacCartney, and C. D.
 [15] A. McCallum and W. Li. Early results for named [16] B. Pang and L. Lee. Opinion mining and sentiment [17] K. C. Park, Y. Jeong, and S. H. Myaeng. Detecting [18] Z. Qu and Y. Liu. Sentence dependency tagging in [19] L. Shrestha and K. McKeown. Detection of [20] K. Sparck-Jones. Index term weighting. Information [21] C. Sutton and A. Mccallum. Mccallum: Collective [22] Y. Tsuruoka, J. Tsujii, and S. Ananiadou. Fast full [23] M. Van-Setten, S. Pokraev, and J. Koolwaaij. [24] A. F. Wicaksono and S.-H. Myaeng. Mining advices
