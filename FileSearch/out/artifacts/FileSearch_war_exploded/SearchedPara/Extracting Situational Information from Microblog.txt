 Microblogging sites like Twitter have become important sources of real-time information during disaster events. A significant amount of valuable situational information is available in these sites; how-ever, this information is immersed among hundreds of thousands of tweets, mostly containing sentiments and opinion of the masses, that are posted during such events. To effectively utilize microblog-ging sites during disaster events, it is necessary to (i) extract the situational information from among the large amounts of senti-ment and opinion, and (ii) summarize the situational information, to help decision-making processes when time is critical. In this pa-per, we develop a novel framework which first classifies tweets to extract situational information, and then summarizes the informa-tion. The proposed framework takes into consideration the typi-calities pertaining to disaster events where (i) the same tweet often contains a mixture of situational and non-situational information, and (ii) certain numerical information, such as number of casual-ties, vary rapidly with time, and thus achieves superior performance compared to state-of-the-art tweet summarization approaches. Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval]: selection process; H.3.5 [On-line Information Ser-vices]: Web-based services Keywords: Disaster events; Twitter; situational information; clas-sification; summarization. In recent years, microblogging sites such as Twitter have become important sources of real-time information, especially during dis-aster events. Several recent research studies [1, 12, 17, 19, 26, 28, 30] have shown the importance of microblogging sites in enhancing sit-uational awareness [20] during such events.

In a disaster situation, various types of information are posted by users in huge volume and at rapid rates, which include situational c  X  information, sentiment (e.g., sympathy for those affected by the disaster) and personal opinion (e.g., on the adequacy of relief oper-ations). While different types of information have different utilities, situational information  X  information which helps the concerned authorities to gain a high-level understanding of the situation dur-ing disasters (including the actionable items [26] such as number of affected people)  X  is critical for the authorities to understand the situation and plan relief efforts accordingly. Hence it is important to develop automated methods to extract microblogs / tweets which contribute to situational information [27]. 1 A related, yet differ-ent, challenge is to deal with the rapid rate at which microblogs are posted during such events  X  this calls for summarization of the situational information . Further, some of the situational informa-tion, such as the number of casualties or injured / stranded persons, changes rapidly with time, asking for special treatment. Since time is critical in a disaster situation, these tasks have to be performed in near real-time , so that the processed information is readily avail-able to the authorities.

In this work, we observe that the tweets posted during disas-ter events have certain specific traits, which can be exploited for the above tasks. For instance, most of the important information is centered around a limited set of specific words, which we call content words (verbs, nouns, numerals). It is beneficial to focus on these content words while summarizing the situational tweets. Furthermore, a significant fraction of tweets posted during disas-ters have a mixture of situational and non-situational information within the same tweet (e.g.,  X  X yyo! not again! :( Blasts in Hyder-abad, 7 Killed: tv reports X  ). Again, many tweets contain partially overlapping information (e.g. an earlier tweet  X  X even people died X , followed by a later tweet  X  X even died. high alert declared X ). We show that separating out the different fragments of such tweets is vital for achieving good summarization.

The present work proposes a novel classification-summarization framework for extracting situational information from microblog streams posted during disaster scenarios. We develop a classifier which uses low-level lexical and syntactic features to distinguish between situational and non-situational information (Section 4). Using vocabulary-independent features enables our classifier to func-tion accurately in cross-domain scenarios, e.g., when the classi-fier is trained over tweets posted during earlier disaster events and then deployed on tweets posted during a later disaster event. We
Tweets which provide situational information are henceforth re-ferred to as situational tweets, while the ones which do not are referred to as non-situational tweets. then propose a novel content-word based summarization approach (COWTS) to summarize the situational tweet stream (Section 5) by optimizing the coverage of important content words in the sum-mary, using an Integer Linear Programming (ILP) framework. We also devise a scheme where we utilize the direct objects of disaster-specific verbs (e.g.,  X  X ill X  or  X  X njure X ) to continuously update impor-tant, time-varying actionable items such as the number of casualties (Section 5.3).

Figure 1 gives an overview of our approach. First, the tweets are preprocessed and fragmented based on end-markers such as  X ! X  and  X ? X . The fragmented tweets are classified to extract situ-ational tweets. The situational tweet stream (after removing dupli-cate tweets) is then summarized using the content word based ap-proach. To enable real-time summarization of long tweet streams (e.g., during disasters such as floods and typhoons, which can span several days), we maintain hourly snapshots of the tweets and the summaries generated previously, so that specific parts of the tweet stream can be summarized quickly when the user demands.

Experiments conducted over tweet streams related to four diverse disaster events show that the proposed classification model outper-forms a vocabulary based approach [27] for various in-domain and cross-domain settings. The classification-summarization model also surpasses various state-of-the-art tweet summarization approaches [7, 8, 21, 31] in terms of ROUGE-1 Recall and F-scores over all the datasets (Section 6). Additionally, the proposed scheme is also de-ployed on tweets related to a recent (at the time of writing the pa-per) disaster event  X  the Nepal earthquake in April 2015 [11]  X  and it is found that the proposed scheme performs significantly better than several state-of-the-art summarization approaches.

As a final contribution, we make the tweet-ids of the tweets re-lated to all these disaster events publicly available to the research community at http://cse.iitkgp.ac.in/~krudra/disaster_ dataset.html . Microblogging sites are serving as useful sources of situational in-formation during disaster events [1, 12, 17, 19, 26, 28, 30]. However, for practical utility, such situational information has to be extracted from among a lot of conversational content, and summarized in near real-time. This section briefly discusses some recent studies on classification and summarization of tweets.
 Classification of tweets during disaster events: Several studies have attempted to extract situational information during disaster events [26, 27]. Specifically, Verma et al. [27] observed that sit-uational tweets are written in a more formal, objective, and imper-sonal linguistic style as compared to non-situational tweets, and used bag-of-words classifier models to classify tweets based on these features. However, as reported by Verma et al. themselves [27], this approach is heavily dependent on the vocabulary of a specific event, and does not work well in the practical cross-domain sce-nario where the classifier is trained on tweets of some past events and is used to classify tweets of a new disaster event. To over-come the limitations of bag-of-words model, this study uses low-level lexical and syntactic features of tweets to develop an event-independent classifier for situational and non-situational tweets, that outperforms the bag-of-words model.
 Tweet summarization: Most of the prior research on tweet sum-marization has focused on summarizing sets of tweets, e.g., tweets posted during a sports event [2, 8, 22]. However, what is necessary during a disaster event is online / real-time summarization of con-tinuous tweet streams , so that the government authorities can mon-itor the situation in real-time. A few approaches for online summa-rization of tweet streams have recently been proposed [13, 21, 31]. Shou et al. [21] proposed a scheme based on first clustering similar tweets and then selecting few representative tweets from each clus-ter, finally ranking these according to importance via a graph-based approach (LexRank) [4]. Olariu et al. [13] proposed a graph-based abstractive summarization scheme where bigrams extracted from the tweets are considered as the graph-nodes. Osborne et al. [14] proposed a real event tracking system using greedy summarization. Along with standard summarization approaches, a few recent stud-ies [7] have also focused specifically on summarization of tweets posted during disaster events. The studies in the TREC temporal summarization track [24] also attempt to summarize information related to events such as disasters, but the focus is on summariza-tion of sentences rather than tweets (which are likely to be written more informally).
 Though there have been separate prior works on extracting situa-tional information during disasters and on summarization of tweets (as discussed above), to our knowledge, no prior work has attempted to combine the two classical tasks. In this work, we show that summarization of tweets during disaster events can be better ac-complished if different types of information (e.g., situational and non-situational) are first separated out, and then summarized sepa-rately. Additionally, the methodology proposed in this work sepa-rately identifies and summarizes time-varying actionable informa-tion such as the number of casualties, which constitute some of the most important information during disaster events, but has not been considered in any prior work. This section describes the datasets of tweets that are used to evalu-ate our classification X  X ummarization approach. We considered tweets posted during the following disaster events  X  (i) HDBlast  X  two bomb blasts in the city of Hyderabad, India (ii) SHShoot  X  an assailant killed 20 children and 6 adults at the Sandy Hook elementary school in Connecticut, USA (iii) UFlood  X  devastating floods and landslides in the Uttaranchal state of India, and (iv) THagupit  X  a strong cyclone code-named Typhoon Hagupit hit Philippines.
 Note that the events are widely varied, including both man-made and natural disasters occurring in various regions of the world. Hence, the vocabulary / linguistic style in the tweets can be ex-pected to be diverse as well.

We collected relevant tweets posted during each event through the Twitter API [25] using keyword matching. For example, the keywords  X  X yderabad X ,  X  X omb X  and  X  X last X  were used to identify tweets related to the HDBlast event, while the keywords  X  X andy-hook X  and  X  X hooting X  were used to collect tweets related to the SHShoot event. For each event, we selected the first 5,000 En-glish tweets in chronological order. A tweet was considered to be in English if at least half of the words in the tweet (after remov-ing @mentions and URLs) appeared in a standard English dictio-nary (similar to the approach in [6]). We make the tweet-ids of these tweets publicly available to the research community at http: //cse.iitkgp.ac.in/~krudra/disaster_dataset.html . As stated earlier, tweets posted during a disaster event include both tweets contributing to situational awareness, and non-situational tweets. We employed human volunteers to observe the different categories of situational and non-situational tweets, and to annotate the tweets (details in Section 4). The different categories of tweets observed (which agrees with prior works [17]) are as follows. Some example tweets of each category are shown in Table 1.
 Situational tweets: Tweets which contain situational information are primarily of the following two types: (i) Status updates  X  up-dates such as the number of casualties, and the current situation in various regions affected by the disaster, and (ii) Helping relief op-erations  X  information that can immediately help relief operations, e.g., phone numbers of nearby hospitals.
 Non-situational Tweets: Non-situational tweets (which do not con-tribute to situational awareness) are generally of the following types: (i) Sentiment / opinion  X  sympathizing with the victims, or praising / criticizing the relief operations, opinion on how similar incidents can be prevented in future, (ii) Event analysis  X  post-analysis of how and why the disaster occurred, findings from police investiga-tion in case of man-made disasters, and (iii) Charities  X  related to charities being organized to help the victims.
 The next two sections discuss our proposed methodology of first separating the situational and non-situational information from tweet streams (Section 4), and then summarizing the situational informa-tion (Section 5). In this section, we focus on separating the situational and non-situational tweets by developing a supervised classifier. Since train-ing such a classifier requires gold standard annotation for a set of tweets, we used human annotators to obtain this gold standard (de-tails below). During annotation, it was observed that a significant number of tweets posted during disaster events contain a mixture of situational and non-situational information . Table 2 shows some examples of such tweets. This observation motivated us to prepro-cess the tweets in order to identify the different fragments, and then process the fragments separately for classification and summariza-tion steps. This preprocessing stage is described next. To effectively deal with tweets containing a mixture of situational and non-situational information, we perform the following prepro-cessing steps. (1) We use the Twitter-specific part-of-speech (POS) tagger [15] to identify POS tags for each word in the tweet. Along with nor-mal POS tags (nouns, verbs, etc.), this tagger also labels Twitter-specific keywords such as emoticons, retweets, and so on. We ig-nore the Twitter-specific words (that are assigned tag  X  X  X  by the POS tagger [15]) because they represent abbreviations, foreign words, and symbols which do not contribute to meaningful information. (2) We apply standard preprocessing steps like case-folding and lemmatization. Further, we use a standard abbreviation dictionary to replace contracted forms (such as ppl, abt, shld, cud ) with their expanded versions. This is necessary since tweets often contain ab-breviations due to the 140-character limit on their length. We also maintain uniformity across different representations of numeric in-formation (e.g.  X 7 X  and  X  X even X ). (3) Subsequently, we focus on particular end-markers (e.g.,  X ! X ,  X . X ,  X ? X ) to split a tweet into multiple fragments. In case of the  X . X  end-marker, we break a tweet into two consecutive fragments if both the fragments possess their own verb; this prevents splitting a tweet at unnecessary breakpoints, such as the  X . X  in the tweet  X  X pd Msg #31, Tropical Storm -Hagupit, NW Pacific Ocean, JTWC . [url] X . As a result of these preprocessing steps, each tweet is decomposed into multiple fragments, and all the subsequent steps are carried out on these fragments. For training the classifier, we considered 1000 randomly selected tweet fragments related to each of the four events. Three human volunteers independently observed the tweet fragments, deciding whether they contribute to situational awareness. 2 Before the anno-tation task, the volunteers were acquainted with some examples of situational and non-situational tweets identified in prior works [27, 28]. We obtained unanimous agreement (i.e., all three volunteers labeled a fragment similarly) for 82% of the fragments, and major-ity opinion was considered for the rest of the fragments.
After this human annotation process, we obtained 416, 427, 432 and 453 tweet-fragments that were judged as situational, for the HDBlast, UFlood, SHShoot and THagupit events respectively. From each of these four datasets, we next selected an equal number of tweet-fragments that were judged non-situational, in order to con-struct balanced training sets for the classifier. Prior research [27] has shown that the situational tweets are writ-ten in a more formal and less subjective style, and from a more impersonal viewpoint, as compared to the non-situational tweets. We consider a set of low-level lexical and syntactic features, as listed in Table 3, to identify the more complex notions of subjec-tivity and formality of tweets. Briefly, situational tweets / tweet-fragments are expected to have more numerical information, while non-situational tweets are expected to have more of those words which are used in sentimental or conversational text, such as sub-jective words, modal verbs, queries and intensifiers.

We use a Support Vector Machine (SVM) classifier  X  specifi-cally, the LIBSVM package [3] with the default RBF kernel  X  to classify the fragmented tweets into two classes based on the fea-tures described in Table 3. We compare our classifier with a stan-dard Bag-of-Words (BOW) model similar to that in [27], where the same SVM classifier is used considering as features  X  the fre-quency of every distinct unigram and bigram, POS tags, presence of strongly subjective words, and presence of personal pronouns.
We compare the performance of the two feature-sets (using the same classifier) under two scenarios  X  (i) in-domain classification ,
All volunteers are regular users of Twitter, have a good knowledge of the English language, and none of them is an author of this paper. T ype Ev ent T weet text ayyo! not again! :( Blasts in Hyderabad, 7 Killed: TV REPORTS oh no !! unconfirmed reports that the incident in #newtown #ct may be a school shooting. police on the way 58 dead, over 58,000 trapped as rain batters Uttarakhand,
UP.....may god save d rest....NO RAIN is a problem....RAIN is a bigger problem @Iv anCabreraTV: #Hagupit is forecast to be @ Super Typhoon strength as it nears Philippines. [url] Oh no! Not again! where the classifier is trained and tested with the tweets of the same event using 10-fold cross validation, and (ii) cross-domain classifi-cation , where the classifier is trained with tweets of one event, and tested on another event. Table 4 shows the accuracies of the clas-sifier using bag-of-words model (BOW) and the proposed features (PRO) on the fragmented tweets.
 In-domain classification : BOW model performs well in the case of in-domain classification (diagonal entries in Table 4) due to the uniform vocabulary used during a particular event. However, the proposed features significantly outperform the BOW model. The result is specially significant since it shows that good classification can be achieved even without considering the event-specific words. Cross-domain classification : The non-diagonal entries of Table 4 represent the accuracies, where the event stated on the left-hand side of the table represents the training event, and the event stated at the top represents the test event. The proposed classification model performs much better than the BOW model in such scenarios, since it is independent of the vocabulary of specific events.
 Benefit of fragmentation and preprocessing before classifica-tion: As described earlier, our methodology consists of prepro-cessing and fragmenting the tweets before classification. A natural question that arises is whether the preprocessing and fragmentation steps help to improve the classification performance. To answer this question, we apply the same classifier as stated above on the raw tweets ; the classification accuracies are reported in Table 5. Comparing the classification accuracies in Table 4 (on preprocessed and fragmented tweets) and Table 5 (on raw tweets), we can ver-ify that the initial fragmentation and preprocessing steps help to improve the performance of both the BOW model as well as the proposed model. We shall also show later (in Section 6) that the preprocessing phase also helps in improving information coverage during the summarization process.
 Thus the proposed classification scheme based on lexical and syn-tactic features performs significantly better than word-based classi-fiers [27] under various experimental settings. However, since the best achieved classification accuracy is still around 80%, a ques-tion naturally arises as to whether the 20% mis-classification would substantially impact the subsequent summarization step. We shall discuss the effect of mis-classification on summarization in Sec-tion 6. The good cross-domain performance of the proposed classification scheme (as stated above) implies that the selected low-level features can robustly distinguish between situational and non-situational tweets irrespective of the specific type of event under consideration, or the vocabulary / linguistic style related to specific events. Additionally, since we train our classifier using low-level patterns, we expect that the accuracy of the classifier will not vary significantly based on the size and diversity of training set (e.g., if multiple past disasters of various types are used to train the classifier).

To demonstrate this, we performed another set of experiments taking THagupit (the most recent of the four events under con-sideration) as the test event, and instead of training the classifica-tion model with only one event, we combined the remaining two / three events for training. The classifier achieved accuracy values of 79.24%, 79.47%, 78.97% and 80.46% respectively when trained on (HDBlast and UFlood), (HDBlast and SHShoot), (UFLood and SHShoot), and all three events taken together. These accuracy val-ues show that as the classifier is trained on more patterns of ex-pressing situational and non-situational information related to var-ious types of disasters, the classifier X  X  accuracy with cross-domain information becomes almost equal to that when it is trained with in-domain information. Thus, we conclude that the proposed classifi-cation framework can be trained over tweets related to one or more past disaster events, and then deployed to classify tweets posted during future events. After separating out situational tweets using the classifier described in the previous section, we attempt to summarize the situational tweet stream in real-time. For the summarization, we focus on some specific types of terms which give important information in disaster scenario  X  (i) numerals, (e.g., number of casualties or af-fected people, or emergency contact numbers), (ii) nouns (e.g., names of places, important context words like people, hospital etc.),
Count of non-situational words and (iii) main verbs (e.g.,  X  X illed X ,  X  X njured X ,  X  X tranded X ). We refer to these terms as content words . This section describes our pro-posed methodology, which we call COWTS (COntent Word-based Tweet Summarization). We observe a specific trend in case of situational tweets posted during disaster events, which is very different from tweet streams posted during other types of events. As tweets are seen in chrono-logical order, the number of distinct content words increases very slowly with the number of tweets, in case of disaster events.
To demonstrate this, we compare tweet streams posted during disaster events with those posted during three political, sports, and technology-related events; these streams were made publicly avail-able by [21]. Figure 2 plots the variation in the number of distinct content words seen across the first 5,000 tweets in these three tweet streams, as well as the situational tweet streams posted during three disaster events. It is evident that the number of distinct content words increases very slowly in case of the disaster events. We find that this is primarily due to (i) presence of huge number of retweets or near-duplicates of few important tweets, and (ii) presence of large number of tweets giving latest updates on some specific con-texts, such as the number of people killed or stranded. This leads to heavy usage of some specific content-words (primarily, verbs)  X  such as  X  X illed X ,  X  X njured X  and  X  X tranded X   X  and rapidly changing numerical information in the context of these content-words.
The above observations indicate that summarizing situational in-formation in disaster scenarios requires a different approach, as compared to prior approaches developed for other types of events. Hence, we (i) remove duplicate and near-duplicate tweets (using the techniques developed in [23]), (ii) focus on the content words during summarization (as described in Section 5.2), and (iii) adopt specific strategies for the heavily-repeated content words associ-ated with frequently changing numerical information (described in Section 5.3). The summarization framework we consider is as follows. Tweets relevant to the disaster event under consideration are continuously collected (e.g., via keyword matching), and situational tweets are extracted using the classifier. At any given point of time, the user may want a summary of the situational tweet stream, by specifying (i) the starting and ending timestamps of the part of the stream that is to be summarized, and (ii) a desired length L which is the number of words to be included in the summary. Notation Meaning
L Desired summary length (number of words) n Number of tweets considered for summarization m Number of distinct content words included in the i inde x for tweets j inde x for content words x i indicator variable for tweet i (1 if tweet i should y j indicator variable for content word j Leng th ( i ) number of words present in tweet i Score( j ) tf-idf score of content word j T j set of tweets where content word j is present C i set of content words present in tweet i
Considering that the important information in a disaster situation is often centered around content words, an effective way to attain good coverage of important information in the summary is by op-timizing the coverage of important content words in the tweets in-cluded in the summary. The importance of a content-word is com-puted using the standard tf-idf score (with sub-linear tf scaling) con-sidering the set of tweets containing it.

We use an Integer Linear Programming (ILP)-based technique [16] to optimize the coverage of the content words. Table 6 states the notations used. The summarization is achieved by optimizing the following ILP objective function: subject to the constraints where the symbols are as explained in Table 6. The objective func-tion considers both the number of tweets included in the summary (through the x i variables) as well as the number of important content-words (through the y j variables) included. The constraint in Eqn. 2 ensures that the total number of words contained in the tweets that get included in the summary is at most the desired length L (user-specified) while the constraint in Eqn. 3 ensures that if the content word j is selected to be included in the summary, i.e., if y then at least one tweet in which this content word is present is se-lected. Similarly, the constraint in Eqn. 4 ensures that if a particular
T imestamp Extract from tweet 14:13:55 se ven killed in hyderabad blast [url] 14:16:18 at least 15 feared dead in hyderabad blast, follow live 14:19:01 10 killed in hyderabad blast more photos, [url] 14:20:56 h yderabad blast, 7 people are feared dead and 67 oth-tweet i is selected to be included in the summary, i.e., if x then the content words in that tweet are also selected.

We use GUROBI Optimizer [5] to solve the ILP. After solving this ILP, the set of tweets i such that x i = 1 represents the summary at the current time. As stated earlier, a special feature of the tweet streams posted dur-ing disaster events is that some of the numerical information, such as the reported number of victims or injured persons, changes rapidly with time. For instance, Table 7 shows how, during the HDBlast event, the reported number of victims / injured persons changed during a period of only seven minutes. Since such information is important and time-varying, we attempt to process such actionable information separately from summarizing the rest of the informa-tion. To our knowledge, none of the prior works on processing tweet streams during disaster events have attempted to deal with such rapidly changing (or even conflicting) information. 3
Specifically, we consider particular disaster-specific key verbs like  X  X ill X ,  X  X ie X ,  X  X njure X ,  X  X trand X , etc., and report the different nu-merical values attached to them, coupled with the number of tweets reporting that number. For instance, considering the tweets in Ta-ble 7, the information forwarded would be:  X  X even people killed X  is supported by two tweets, while  X  X en killed X  and  X  X ifteen killed X  is supported by one tweet each.
 Assigning numeral values to keywords: It is often non-trivial to map numeral values to the context of a verb in a tweet. For in-stance, the number  X  X wo X  in  X  X M visits blasts sites in hyderabad, three days after two powerful bombs killed X  is not related with the verb  X  X illed X  , as opposed to the number  X  X even X  in the tweet  X  X even people were killed X  . Therefore, whenever the numeral is not di-rectly associated with the main verb, we extract the direct object of the main verb and check whether (i) the numeral modifies the direct object, and (ii) the direct object is a living entity. We used the POS tagger and dependency parser for tweets [9] to capture this infor-mation. If a numeral is directly associated with a main verb (i.e., if an edge exists between numeral and the verb in the dependency
Note that we only attempt to report all versions of such informa-tion; verifying which version is correct is beyond the scope of the current work. tree), we associate that numeral with the verb (e.g.,  X  X even X  with  X  X illed X  in  X  X even killed in hyderabad blast X  ). The list of living-entity objects for disaster specific verbs was pruned manually from the exhaustive list obtained from Google syntactic n -grams (details omitted for brevity). 4 The performance of our methodology is dis-cussed in the next section. This section compares the performance of the proposed framework with that of four state-of-the-art summarization techniques (base-lines). We first briefly describe the baseline techniques and the experimental settings, and then compare the performances. We considered the four disaster events described in Section 3 for the experiments. For each dataset, we considered the first 5000 tweet fragments in chronological order, extracted situational tweet-fragments using our classifier, and passed the situational tweets to the summarization modules. We considered five breakpoints at 1K, 2K, 3K, 4K and 5K tweets, i.e., the summaries were demanded at the corresponding time-instants.
 Establishing gold standard summaries: At each of the break-points, three human volunteers (same as those involved in the clas-sification stage) individually prepared summaries of length 30 tweets from the situational tweets. To prepare the final gold standard sum-mary at a certain breakpoint, we first chose those tweets which were included in the individual summaries of all the volunteers, followed by those tweets which were included by the majority of the volun-teers. Thus, we create a single gold-standard summary containing 30 tweets for each breakpoint, for each dataset.
 Baseline approaches: We compare the performance of our pro-posed summarization scheme with that of four prior approaches, as described below. These include both generic tweet summarization approaches and disaster-specific approaches.
A vailable at http://commondatastorage.googleapis. com/books/syntactic-ngrams/index.html . (i) Sumblr: the online tweet summarization approach by Shou et al. [21] is taken as the first baseline with a simplifying assumption  X  whereas the original approach considers the popularity of the users posting specific tweets (based on certain complex functions), we give equal weightage to all the users. (ii) RTS: the Real-Time Summarization approach by Zubiaga et al. [31]. We consider all words after removing hashtags, URLs, and Twitter-specific words, compute their weights, and prepare the final summary based on the ranking methodology of [31]. (iii) DIS: the methodology proposed by Kedzie et al. [7], meant for summarizing news articles posted during disaster events. In our experiment, we apply their technique over the processed tweet streams. DIS is a semi-supervised method, requiring some prior knowledge of what to include in the summary; for this purpose, we consider some of the tweets that were selected in multiple sum-maries generated by human volunteers (as described above). (iv) NAVTS: Since COWTS considers nouns, numerals and main verbs as content words, a question arises as to whether this choice of content words is prudent. To verify this, we devise a compet-ing baseline where noun, verbs and adjectives are taken as content words; these parts of speech were found to be important for tweet summarization (not online) in a prior study by Khan et al. [8]. We applied COWTS and all the above baseline methods on the same situational tweet stream (obtained after classification), and retrieved summaries of the same length, i.e. the number of words present in the 30 tweets of the gold standard summary for a cer-tain breakpoint (described earlier). To maintain fairness, the same situational tweet stream (after classification) was input to all the summarization approaches.
 Evaluation metrics: We used the standard ROUGE [10] metric for evaluating the quality of the summaries generated. Due to the informal nature of tweets, we actually considered the recall and F-score of the ROUGE-1 variant. Table 8 and Figure 3 give the ROUGE-1 F-scores and recall for the five algorithms for the four datasets, at the various breakpoints re-spectively. It is evident that COWTS performs significantly better than all the baseline approaches. For instance, mean scores indicate an average improvement of more than 60% in terms of F-scores over Sumblr [21] which is a general-purpose (i.e., not disaster-specific) summarization scheme. The proposed methodology also performs better than the disaster-specific summarization technique DIS [7] in all cases  X  on an average, we obtain improvement of 20% for F-scores and 12% for recall over DIS. Further, the higher F-scores for COWTS than those for NAVTS indicate that our se-lected content words lead to better summarization. Figure 3 shows that the trend holds even if we increase the number of tweets for summarization.

To give an idea of the nature of the summaries generated by the methodologies, Table 9 shows summaries generated by COWTS and DIS (both disaster-specific methodologies) from the same tweet stream  X  the first 300 situational tweets posted during the THagupit event. The two summaries are quite distinct, with no tweet in com-mon. We find that the summary returned by COWTS is more in-formative, and contains crucial information about hotline numbers, food packs, critical areas and information necessary for volunteers. On the other hand, the summary returned by DIS mostly contains the same information (about the nature or intensity of the storm) expressed in various ways.
 Time taken for summarization: Since time is critical during dis-aster events, it is important that the summaries are generated in real-time. Hence, we analyze the execution times of the various techniques. At the breakpoints of 1K, 2K, 3K, 4K and 5K tweets, the proposed COWTS method takes 5.953, 8.084, 10.295, 12.627 and 15.135 seconds on average (over the four datasets) respectively to generate summaries. The time taken increases sub-linearly with the number of tweets and is comparable to those taken by the RTS and NAVTS baselines (on the same situational tweet streams), and significantly better than those taken by Sumblr and DIS. Specifi-cally, DIS requires more time due to computation of large similarity matrices and execution of affinity propagation algorithm, whereas Sumblr requires large time due to the LexRank graph generation. Benefit of classification before summarization: We verified that separating out situational tweets from non-situational ones signifi-cantly improves the quality of summaries. Considering all the four events together, the mean ROUGE F-score at breakpoint 1000 for COWTS was 0.61 without prior classification (i.e., when all tweets were input to the summarizer) as compared to 0.78 after classifica-tion. Table 10 gives the mean F-score of COWTS on classified and unclassified tweets, averaged over all the four events.
 Effect of misclassification on summary recall: As stated in Sec-tion 4, the proposed classifier achieved around 80% accuracy in classifying between situational and non-situational tweets. We now investigate how the 20% error in classification affects the subse-quent summarization of situational information.

Evidently, errors where a situational tweet is misclassified as non-situational are far more critical since they may impact the re-call of the subsequent summarization step. We find that out of all classification errors, such errors account for only 8.09%, 10.94%, 7.25% and 9.69% for the four datasets respectively (in the order stated in Table 4). Thus, very few situational tweets are actually left out from the summarization process due to mis-classification.
We further checked what fraction of content-words are really missed out due to misclassification. Across all the four datasets, more than 84% of the content-words present in the mis-classified tweets are also covered by the correctly classified situational tweets; this implies that only a small fraction of the content-words are missed in the stream sent for summarization.
 Effect of choice of content words: Choosing what type of words to focus on is important for achieving good summarization of tweet streams, as also observed in [8]. As stated in Section 5, we consid-ered three types of content words  X  numerals, nouns, and verbs. From the comparison between COWTS and NAVTS, it has already been established that our choice of content words achieves better summarization for tweets posted during disaster events, than the information words proposed in [8].

We now analyze whether all the three chosen types of content words are effective for summarization. For this, we analyze the quality of the summaries generated in the absence of one of these types of content words. Figure 4 compares the F-scores (averaged over all four datasets) considering all three types of content words, with those obtained considering any two types of content words. It is clear that all three types of content words are important for the summarization quality, numerals and nouns being the most im-portant ones (since the numeral-noun combination outperforms the
ROUGE-1 F-score other 2-combinations). Side by side, as a sanity check, we have also included adjectives among the content words and run COWTS; we observed that the performance deteriorates noticeably.

Note that most of the earlier summarization frameworks dis-carded numerals contained in the tweets, whereas we show that numerals play a key role in tweets posted during disaster events, in not only identifying situational updates but also in summarizing frequently changing information (which we evaluate next). Handling frequently changing numerals: Figure 5 shows how the numerical value associated with the key verb  X  X ill X  changes with time (or sequence of tweets, as shown on the x -axis) during two different disaster events. Clearly, there is a lot of variation in the reported number of casualties, which shows the complexity in in-terpreting such numerical information.

We now evaluate the performance of our algorithm in relating such numerical information with the corresponding key verb (as detailed in Section 5.3). Specifically, we check what fraction of such numerical information could be correctly associated with the corresponding key verb. We compared the accuracy of our algo-rithm with a simple baseline algorithm where numerals occurring within a window of 3 words on either side of the verb were se-lected as being related to the verb. Considering all the four datasets together, the baseline algorithm has a precision of 0.63, whereas our algorithm has a much higher precision of 0.95  X  this shows the effectiveness of our strategy in extracting frequently changing numerical information. We envisage that the classification-summarization framework de-veloped in the present work will be trained over tweets related to past disaster events, and then deployed to extract and summa-rize situational information from tweet streams posted during fu-ture events. In this final section, we demonstrate the utility of the framework by deploying it on tweets posted during a more recent disaster event  X  the earthquake in Nepal in April 2015 [11].
We collected related tweets using keyword matching, and then considered the first 1,000 matching tweets in chronological order. We trained our classifier model on the HDBlast dataset, then used the classifier to extract situational tweets, and then summarized the situational tweet stream. We also used the baseline methods NAVTS, Sumblr, and RTS on the same tweet stream in similar set-tings; however, the DIS method was not used since it is a semi-supervised method, requiring some prior knowledge about what to include in the summary.

Since for this dataset, we do not have any ground truth summary, we performed a manual evaluation of the summaries generated by all the different methods. Five human volunteers were asked to rank the summaries (anonymized, i.e., the volunteers were not told which summary was generated by which methodology) based on their informativeness. We tabulate the rankings given by the vol-unteers in Table 11. It is evident that all the volunteers ranked the summary produced by COWTS as the most informative.

Further, in order to test the scalability of COWTS, we consid-ered the first 20,000 tweets related to the event in chronological order, and then summarized the situational tweet stream at the two breakpoints  X  10,000 and 20,000 tweets. COWTS took 32.130 and 47.412 seconds respectively to summarize the tweets at the two breakpoints, and all the five human evaluators expressed satisfac-tion at the content of the summary. This experiment shows that COWTS is able to summarize tweet streams posted during new dis-aster events satisfactorily, and in near real-time. A deeper look at various baseline techniques helps us to under-stand their shortcomings and the reasons behind the superior per-formance of COWTS. NAVTS, which is a variation of COWTS with different types of content words, brings out the importance of choosing proper content words for summarization. Out of the other baseline techniques, Sumblr and RTS [21, 31] do not discriminate among different types of POS tags. Additionally, RTS [31] suffers from potential redundancies  X  this methodology ranks tweets and selects the top-ranking ones for the summary, which may lead to redundancy if most of the top-ranking tweets have similar content. Sumblr [21] maintains clusters of related information and finally chooses one top scoring tweet from each cluster. If the desired summary length is not equal to the number of clusters, then it needs to be decided as to which clusters are important and should be se-lected for preparing the final summary. Similar types of tweet se-lection problem also arises in case of DIS [7], when we have large number of exemplar tweets. To resolve such issues, focusing on particular POS-tags and ILP-based technique (as used in COWTS) proves to be very handy.

To be fair to other methods, most of them are not specifically de-signed to summarize tweet streams posted during disaster-specific events, which have their own peculiarities. We observe that across all types of disaster events, numerals, nouns, and key verbs pro-vide salient situational updates during disasters. Hence, we set our summarization objective to maximize the coverage of these parts of speech in the final summary, by using an ILP-based technique. The strong points in favor of COWTS is that it is completely unsu-pervised and can be applied to any type of disaster events. This paper presents a novel classification-summarization frame-work for disaster-specific situational information on Twitter. We derive several key insights  X  (i) it is beneficial to work with tweet fragments rather than entire tweets, (ii) distinct lexical and syn-tactic features present in tweets can be used to separate out sit-uational and non-situational tweets, which leads to significantly better summarization, (iii) content words are especially significant for summarization of disaster-specific tweet streams, and (iv) spe-cial arrangements are needed to deal with a small set of actionable keywords which have numerical qualifiers. We develop a domain-independent classifier which performs better than domain-dependent bag-of-words technique, and an ILP-based summarization frame-work that out-performs other summarization methods in summa-rizing the situational tweets.

We had several realizations during the course of this work. For instance, whereas some disasters are instantaneous and span short time durations (such as bomb blast, or shooting incidents), other events such as floods and hurricanes span much longer time peri-ods. In such long ranging disasters, users may be interested both in current summaries (e.g., the last few hours) as well as historical summaries (e.g., the last week). Both these types of summaries can be generated by a minor modification of the underlying data struc-tures of the present scheme. The Content Word Dictionary  X  which maintains the content words as well as the rate at which they are ap-pearing in the tweets  X  can be created for each epoch, and accord-ingly both recent as well as historical summaries can be obtained as per user-requirement. We hope to formalize this in more detail in our future work, which includes deploying a live system. Fur-ther, the module which we develop to handle continuous updates of the actionable numerical items shows that conflicting numbers often get posted at the same time, and a robust technique needs to be developed to differentiate between rumours and authentic infor-mation. This would be another potential future work.

As a final note, we believe that our work is significant espe-cially in developing countries, where government-sponsored so-phisticated systems to monitor situational updates in disaster sce-nario is largely missing.
 Acknowledgement: This research was partially supported by a grant from the Information Technology Research Academy (ITRA), DeITY, Government of India (Ref. No.: ITRA/15 (58)/ Mobile/ DISARM/ 05) Additionally, K. Rudra was supported by a fellow-ship from Tata Consultancy Services, and S. Ghosh was supported by a fellowship from the Alexander von Humboldt Foundation. K. Rudra would also like to thank Google and Flipkart for their travel support.
