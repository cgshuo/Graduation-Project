 We presen t novel semi-sup ervised boosting algorithms that incremen tally build linear com binations of weak classi ers through generic functional gradien t descen t using both la-beled and unlab eled training data. Our approac h is based on extending information regularization framew ork to boosting, bearing loss functions that com bine log loss on lab eled data with the information-theoretic measures to enco de unlab eled data. Even though the information-theoretic regularization terms mak e the optimization non-con vex, we prop ose simple sequen tial gradien t descen t optimization algorithms, and ob-tain impressiv ely impro ved results on syn thetic, benc hmark and real world tasks over sup ervised boosting algorithms whic h use the lab eled data alone and a state-of-the-art semi-sup ervised boosting algorithm.
 I.2 [ Arti cial Intelligence ]: Learning Algorithms, Exp erimen tation, Performance Ensem ble metho d, semi-sup ervised learning
Boosting, as one of the most powerful learning ideas in-troduced in early 1990s (Hastie et al. 2009), is a sup er-vised mac hine learning and data mining technique that in-cremen tally builds linear com binations of \weak" mo dels to generate a \strong" predicativ e mo del and is pro ved to be one of the most successful and practical metho ds in ma-chine learning. Schapire (1990) dev elop ed the rst pro vable polynomial-time boosting algorithm, based on PAC learn-ing, and sho wed how to impro ve a weak learner's perfor-mance by training two additional classi ers. Freund and Schapire (1997) later invented the popular AdaBo ost al-gorithm using the idea of adaptiv ely resampling the data: that is, AdaBo ost starts with a weak classi er and seeks its impro vemen ts iterativ ely based on its performance on the training data. Since its inception, AdaBo ost algorithm for classi cation has attracted much atten tion in the mac hine learning comm unit y as well as in related areas in statistics. Various varian ts of AdaBo ost algorithm have pro ven to be very comp etitiv e in prediction accuracy in a variet y of ap-plications. Boosting metho ds were originally prop osed as ensem ble metho ds, whic h rely on the principle of generating multiple predictions and ma jorit y voting (averaging) among the individual classi ers.

Semi-sup ervised learning (Chap elle et al. 2006) is a ma-chine learning technique that uses both lab eled and unla-beled data for training | typically a small amoun t of la-beled data with a large amoun t of unlab eled data. Semi-sup ervised learning is touted as one of the most natural forms of training for prediction tasks, since unlab eled data is plen tiful whereas lab eled data is usually limited or ex-pensiv e to obtain. Man y approac hes have been prop osed for semi-sup ervised learning (Chap elle et al. 2006), includ-ing: generativ e mo dels (Castelli and T. Cover 1996, Co-hen and Cozman 2006, Nigam et al. 2000), self-learning (Celeux and Govaert 1992), co-training (Blum and Mitc hell 1998), information-theoretic regularization (Grandv alet and Bengio 2004, Cordunean u and Jaakk ola 2006) and graph-based transductiv e metho ds (Zhou et al. 2004 and Zhu et al. 2003).

Although highly desirable, semi-sup ervised boosting has not been studied as widely as the other semi-sup ervised set-tings men tioned above, with very few exceptions (Benett et al. 2002, Chen and Wang 2007, d'Alc he-Buc et al. 2002, Valizadegan et al. 2008). These approac hes are essen tially a self-learning algorithm where the class lab els of unlab eled data are updated iterativ ely; they essen tially operate like self-training where the class lab els of unlab eled examples are updated iterativ ely: rst a classi er is constructed using a small amoun t of lab eled data, then it is used to predict the pseudo-lab els for unlab eled examples; a new classi er is then constructed using both lab eled and pseudo-lab eled ex-amples; the pro cesses of constructing classi ers and predict-ing pseudo-lab els alternate iterativ ely until certain stopping criterion is reac hed. The main dra wbac k of this approac h is that it relies solely on the pseudo-lab els predicted by the classi ers constructed so far when generating new classi ers. Since the pseudo-lab els predicted by the constructed classi-ers could be inaccurate, esp ecially at the rst few steps, the resulting new classi ers migh t also be unreliable. The errors migh t propagate due to this ripple e ect, thus nally hurt the performance.

We prop ose semi-sup ervised boosting algorithms that use information-theoretic measures suc h as entrop y and/or mu-tual information (Grandv alet and Bengio 2004, Cordunean u and Jaakk ola 2006, Wang et al. 2009) as a vehicle for reg-ularization on unlab eled data. The motiv ation is that min-imizing conditional entrop y or minimizing mutual informa-tion over unlab eled data encourages the algorithm to nd putativ e lab elings for the unlab eled data that are mutually reinforcing with the sup ervised lab els; that is, greater cer-tain ty on the putativ e lab elings coincides with greater con-ditional likeliho od on the sup ervised lab els, and vice versa. For a single classi cation variable, minimizing entrop y crite-rion has been sho wn to e ectiv ely partition unlab eled data into clusters (Grandv alet and Bengio 2004, Rob erts et al. 2000). Later on, this work was extended to semi-sup ervised learning for structured prediction suc h as sequence lab el-ing (Jiao et al. 2006) and image segmen tation (Lee et al. 2006), achieving very impressiv e impro vemen ts over using lab eled data alone. Recen tly Wang et al. (2009) presen t a mutual information regularized semi-sup ervised learning as a data compression scheme that is form ulated into a rate distortion (Co ver and Thomas 1991) framew ork, and demonstrate encouraging results with two real-w orld prob-lems to sho w the e ectiv eness of the prop osed approac h: text categorization as a multi-class classi cation problem, and hand-written character recognition as a sequence lab el-ing problem. In this pap er, we demonstrate how to use sim-ilar ideas for semi-sup ervised boosting. Di eren t with exist-ing self-learning type semi-sup ervised boosting algorithms, our approac h is grounded on a rm information theoretic motiv ation. We prop ose simple sequen tial gradien t descen t optimization algorithms, and obtain impressiv ely impro ved results on syn thetic, benc hmark and real world tasks over sup ervised boosting algorithms (whic h use the lab eled data alone) and a state-of-the-art semi-sup ervised boosting algo-rithm, ASSEMBLE prop osed in (Benett et al. 2002).
A fundamen tal theoretical issue for AdaBo ost and its man y varian ts is con vergence, whic h is not addressed in the orig-inal AdaBo ost pap er (Freund and Schapire 1997). In fact, much work has been done to pro ve the con vergence of boost-ing algorithm in terms of an optimization metho d. They can be categorized into two basic approac hes: greedy function optimization and maxim um entrop y approac h.

In the rst approac h, AdaBo ost is view ed as a sequen-tial gradien t descen t algorithm in function space, inspired by numerical optimization and statistical estimation. It was Breiman (1999) who made this path-breaking observ ation. This insigh t opened new persp ectiv es and was extended to a variet y of related objectiv e functions. Man y varian t of Ad-aboost, suc h as logistic regression and least square (Fried-man, et al, 2000, Mason et al. 1999) have also been dev el-oped for con texts other than classi cation, suc h as regression and densit y estimation. In this approac h, statistical mo dels are typically additiv e expansions in a set of basis functions and are tted by minimizing a loss function averaged over the training data. For man y loss functions or basis func-tions, this requires computationally intensiv e numerical op-timization techniques. The boosting approac h is a forw ard stagewise additiv e mo deling (Friedman et al. 2000) that appro ximates the solution by sequen tially adding new basis functions to the expansion without adjusting the parameters and coecien ts of those that have already been added. At eac h iteration, one solv es for the optimal basis function and corresp onding coecien ts to add to the curren t expansion. This pro duces new expansion and the pro cess is rep eated.
In the second approac h (Collins et al 2002, Della Pietra et al. 1997, Lebanon and La ert y 2002, Ha ari et al. 2008), the boosting algorithm is cast in terms of maximizing gen-eralized entrop y sub ject to certain linear feature constrain ts, enforcing their exp ectations meet the empirical exp ectations. AdaBo ost can be describ ed as a greedy feature induction al-gorithm that incremen tally builds random elds to solv e the maxen t problem. The greediness of the algorithm arises in steps that select the most informativ e feature. In these steps eac h feature in a pool of candidate features is evaluated by estimating the reduction in the Kullbac k-Leibler div ergence that would result from adding that feature to the eld. This reduction is appro ximated as a function of a single parameter and is equal to the exp onen tial loss reduction. This appro x-imation is one of the key elemen ts making it practical to evaluate a large num ber of candidate features at eac h stage of the induction algorithm. By using an auxiliary function to bound the change in generalized K-L div ergence from be-low, the iterativ e scaling algorithm can be deriv ed and thus con vergence to the global optimal solution is pro ved.
The rst of these two metho ds searc hes the weak learner myopically . Thus it only appro ximately nds the best one and then obtains this weak learner's optimal voting param-eter . The second metho d, in con trast, looks into weak learners one by one, then chooses the weak learner that in-duces largest loss reduction. However, it is more compu-tationally exp ensiv e since the optimal voting parameter for eac h weak learner has to be calculated. Moreo ver, for gen-eral loss functions, it is in general very hard to construct auxiliary functions with closed form solutions. In this pa-per, therefore, we adopt the rst approac h. Let X be a random variable over data to be lab eled, and Y be a random variable over corresp onding lab els ranging over a nite lab el alphab et Y . Assume we have a set of lab eled examples, D l = ( x 1 ; y 1 ) ; ; ( x N ; y N ) , and unla-beled examples, D u = x N +1 ; ; x M . We would like to construct a discriminan t function of the form suc h that the prediction error is small. Here h ( x ; t ) : X ! Y denote weak learners, for example, decision stumps whose predictions are +1 and -1, from a xed class H , characterized by a set of parameters and t 2 &lt; are the weak learner weigh ts. They also corresp ond to the features in random elds (Della Pietra et al. 1997) and sucien t statistics in an exp onen tial mo del (Lebanon and La ert y, 2002). Our goal is to learn suc h a mo del from the com bined set of lab eled and unlab eled examples, D l [ D u .

Just as in sup ervised learning case for boosting, the es-timation for the com bination is simply minimization of the follo wing surrogate risk functional over 0/1 loss; where the rst term denotes the surrogate loss for lab eled data, whic h is a monotonically decreasing and di eren tiable function of its argumen t y i h t ( x i ), suc h that the more the discriminan t function agrees with the lab el y i , the smaller the loss. The second term represen ts the surrogate loss for unlab eled data whic h beha ves like a clustering criterion. is a trade-o parameter that con trols the in uence of the unlab eled data.

To deriv e the boosting algorithm that can accommo date any loss function, supp ose that we have already included t 1 comp onen t classi ers and we wish to add another h ( x ; ). The estimation crite-rion for the overall discriminan t function, including the new comp onen t with votes , is given by
Note that we explicate only how the objectiv e dep ends on the choice of the last comp onen t and the corresp onding votes, since the parameters of the t 1 previous comp onen ts along with their votes have already been set and won't be mo di ed further.

As in the case of sup ervised boosting, there are two pa-rameters to optimize. We implemen t this optimization ap-pro ximately in two steps. We rst nd the new comp onen t or parameters so as to maximize its poten tial in reduc-ing the surrogate loss, \poten tial" in the sense that we can subsequen tly adjust the votes to actually reduce the surro-gate loss. More precisely , we set so as to minimize the deriv ativ e where dL( z ) = dL( z ) dz . Note this deriv ativ e d d precisely captures the amoun t by whic h we would start to reduce the surrogate loss if we gradually increase the votes for the new comp onen t with parameters . Minimizing this reduction seems like a sensible estimation criterion for the new comp onen t or . This strategy permits us to set and subsequen tly optimize to actually minimize the surrogate loss.

De ne the follo wing weigh ts and normalized weigh ts w on the training examples: w i ( y ) = dL l ( yh t 1 ( x i )) for i = N + 1 ; ; M 8 y Note that for eac h piece of unlab eled data, since its lab el is unkno wn, we assign an individual weigh t for eac h possible lab el using the derivative of loss functions for labeled data . In fact, how to choose the weigh t on eac h lab eled and un-lab eled data is quite arbitrary , but the main purp ose is to incorp orate a scaling pro cedure for numerical consideration, since eac h time we add a weak classi er, the cost function becomes smaller and will exceed the precision range of essen-tially any mac hine (ev en in double precision). Thus de ning a weigh t is the only reasonable way to perform the compu-tation.

Then the normalized weigh ts w on the training examples are
These weigh ts are guaran teed to be non-negativ e since the loss function for lab eled data is a decreasing function of its argumen t (its deriv ativ e has to be negativ e or zero). By ignoring the multiplicativ e constan t (constan t at iteration t ) we will estimate by minimizing
After we nd ^ , we solv e the minimization problem for t over the follo wing objectiv e function, This can be done by one-dimensional numerical line searc h
The searc h is quite exp ensiv e since it is to be performed at eac h round t . In fact, we can compute from the data a nite interv al to whic h we kno w that belongs. This gives us a form ula for a worst case searc h of appro ximate (Jano det et al. 2004).
We are now ready to cast the steps of the semi-sup ervised boosting algorithm as function gradien t descen t in a form similar to AdaBo ost.
 1. Initialize the observ ation weigh ts w 2. For t = 1 to T ; 3. Output nal classi er
The follo wing result sho ws the con vergence of the above algorithm to a local minim um or stop early at round T . Let L l and L u be any lower bounded Lipsc hitz di eren tiable cost functionals. Either the sequence of com bined classi ers generated by the algorithm above halts on round T with its gradien t being positiv e, or the com bined loss function con verges to a local minim um J , in whic h case lim t !1 r J ( h t ) ; h t &gt; = 0. A similar result has been sho wn in (Mason et al. 1999), where J ( ) is a con vex function to guaran tee con vergence to a global minim um, here we relax J ( ) to be non-con vex, thus only local minim um can be reac hed. The pro of technique is similar to that in (Mason et al. 1999) with minor mo di cations (Bertsek as 1999).
We use information-theoretic measures, entrop y and mu-tual information, as regularization for the use of unlab eled data. The rationale of using these terms has been explained in Grandv alet and Bengio (2004), Jiao et al. (2006) and Wang et al. (2009). Unfortunately both measures on unla-beled data are not con vex over , mainly because they are comp osition functions of con vex/conca ve functions over the parameters . Jiao et al. (2006) explained one simple case, the entrop y of exp onen tial mo dels; justi cation for general situations can be found in (S. Boyd and L. Vanden berghe 2004).

For ease of exp osition, we rst consider binary classi ca-tion, that is, y 2 f 1 ; 1 g . We then extend to classi cation with multiple classes. In both cases, we use normalized log-Consider normalized log-linear mo dels p ( y j x ) = e ( yh ( x )) we use the logistic loss, that is, negativ e log-probabilit y, for lab eled data,
L l ( y i h t ( x i )) = log p ( y i j x i ) = log(1 + e ( y Note that there should exist a constan t 2 inside the exp o-nen tial but we omit it by scaling the weak er learners by half.
Let L l ( z ) = log(1 + e z ), then dL l ( z ) = e z log(1+ e z ) the weigh ts are given by ^ w i ( y ) =
For unlab eled data, again we have two options. We can minimize either the negativ e conditional Kullbac k-Leibler div ergence
D ( p ( y j x ) ; U ( y j x )) = X where U ( y j x ) is the uniform distribution and ~ p ( x ) denotes the empirical distribution of X , or the mutual information of unlab eled data the deriv ation for using both entrop y and mutual informa-tion as regularization on unlab eled data.
 Entrop y regularization Minimizing negativ e conditional Kullbac k-Leibler div ergence is equiv alen t to minimizing the sum of the conditional entrop y of unlab eled data,
L u ( h t ( x i )) = X
At the rst sigh t, it seems that similar idea can be applied to unnormalized mo del once we use generalized conditional Kullbac k-Leibler div ergence (Lebanon and La ert y 2002) to de ne the entrop y and mutual information for unnormalized mo del, however it doesn't work for entrop y case, the surro-gate loss in Step 2(b) in this case is lowerly unbounded. Looking at the above form ula, clearly entrop y regulariza-tion is merely plain boosting with the unlab eled examples replaced by lab eled examples with all classes, where eac h class is assigned a weigh t by the class conditional probabil-ity given unlab eled example.

Let L u ( z ) = 1 1+ e z log(1 + e z ), then dL u ( z ) = ( 1 + log(1 + e z )).

The loss function for the weak er learner in step 2(a) is We look over all of the weak learners and choose the one h ( ; ^ ) whic h has the lowest value of this loss function.
The minimization over the surrogate loss in Step 2(b) is used to determine the optimal value of .

Mutual information regularization Minimizing mu-tual information of unlab eled data is equiv alen t to minimiz-ing the sum of the di erence between the entrop y of unla-beled data and the conditional entrop y of unlab eled data,
L u ( h t ( x i )) = X dL u ( z ) can be computed easily .

The loss function for the weak er learners in step 2(a) is Again we look over all of the weak learners and choose the one h ( ; ^ ) whic h has the lowest value of this loss function.
The minimization over the surrogate loss in Step 2(b) is used to determine the optimal value of .
In the multi-class classi cation setting, we use the ap-proac h prop osed in (Zh u et al. 2005) and reco de the class lab el y 2 Y = f 1 ; ; K g with a K -dimensional vector c , with all entries equal to 1 K 1 except a 1 in position k if y = k , i.e. c = ( c 1 ; ; c K ) T , and and there is a one-to-one corresp ondence between y and c . We use c ( y ) to denote the vector corresp onding to class y .
A generalization of the exp onen tial loss function for the lab eled data to the multi-class case then naturally follo ws: class k and h ( x ) satis es symmetric constrain t: So when K = 2, this multi-class exp onen tial loss function reduces to the binary exp onen tial loss.

We require the weak learner h ( x ; ) to satisfy the sym-metric constrain ts: Speci cally , at a given x , h ( x ) maps x onto C ; h : x ! C , where C is the set con taining K K -dimensional vectors:
It is easy to chec k that all the deriv ation for binary clas-si cation will remain the same for multi-class classi cation with simple mo dular mo di cation: substitute yh ( x ) with c ( y ) T h ( x ).
It is natural to see that the normalized log-linear mo del is p ( y j x ) = e ( log-probabilit y, for lab eled data, is The entrop y of unlab eled data is then
Again it is easy to chec k that all the deriv ation for binary classi cation will remain the same for multi-class classi ca-tion with simple mo dular mo di cation: substitute e e P c ( y ) T h ( x )).

Similar deriv ations can be obtained for mutual informa-tion case.

The nal classi er is given by and for new sample data x , we assign its class lab el as
In this section, we rep ort exp erimen tal results on syn-thetic, benc hmark, and real world data. It is imp ortan t to note that it is not our inten tion to sho w that the pro-posed semi-sup ervised boosting algorithm alw ays outp er-forms a variet y of semi-sup ervised learning algorithms. In-stead, our objectiv e is to demonstrate that the prop osed semi-sup ervised boosting algorithm is able to e ectiv ely im-pro ve the accuracy of the well-kno wn sup ervised boosting al-gorithms using the unlab eled examples, and it is more e ec-tive than the existing semi-sup ervised boosting algorithms. Hence, the empirical study is focused on a comparison with the existing sup ervised and semi-sup ervised boosting algo-rithms, rather than a wide range of semi-sup ervised learning algorithms. To be more speci c, we evaluate empirically su-pervised AdaBo ost and LogitBo ost, and a state-of-the-art semi-sup ervised boosting algorithm, Assem ble (Bennett et al. 2002), (Assem ble.LogitBo ost) with our prop osed semi-sup ervised boosting metho ds. The weak learner we used in all of our exp erimen ts is the decision stump FindA ttrT est as describ ed in (Freund and Schapire, 1996). All of the exp er-imen ts are rep eated 10 times, the results are expressed by the mean and its standard deviation.
We rst consider a 2-class problem with a 10-dimensional input space. Eac h class is generated by a normal distri-bution with equal mixing weigh t probabilit y. The mean of the rst class is (4 ; ; 4) T and the mean of the second is ( 4 ; ; 4) T . The covariance matrix is diagonal matrix with standard deviation being 20. We set the num ber of la-beled data N = 50 and we increase the num ber of unlab eled data from 50 to 1500. We use dev elopmen t data to choose the best value of regularization parameter, i.e. in our pro-posed metho d and and in Assem ble metho d. The size of dev elopmen t and test data is 450. Figure 1: Test errors on data generated by two mix-
Figure 1 and Table 1 sho w the results of the classi ca-tion error rate on test data using Assem ble.LogitBo ost and both entrop y and mutual information on unlab eled data as regularization term when we increase the size of unlab eled data. Clearly this result sho ws that our semi-sup ervised boosting algorithms overcomes both AdaBo ost and Logit-Boost as well as Assem ble.LogitBo ost. Esp ecially , unlab eled data does help impro ve performance. With the incremen t of unlab eled data, the error rates of our algorithms tend to decrease.

In the exp erimen t, we also nd that, in terms of error rate on test data, both entrop y based semi-sup ervised boosting algorithm and mutual information based semi-sup ervised boosting algorithm con verge more quic kly than AdaBo ost and LogitBo ost. Figure 2 sho ws how the error rate on test data changes at eac h iteration when the ratio of unlab eled data and lab eled data is set to 5. Clearly both entrop y and mutual information regularization terms on unlab eled data beha ve as excellen t data dep enden t regularizers, and entrop y based approac h has better regularization e ect than mutual information based approac h. We've also used l 2 norm of the parameters suggested in (Lebanon and La ert y 2002) as a regularization term, but unfortunately it has almost no a ect on the performance.

Since the minimization problem in Step 2(b) is simply one-dimensional one, we study the objectiv e function being minimized when we use conditional entrop y on unlab eled data as a regularization term. Figures 3 and Figure 4 il-lustrate the loss curv es at the 5th iteration where we set = 0 : 2 and = 1 resp ectiv ely, and the ratio of unlab eled data and lab eled data is 5. The loss function on lab eled data is con vex and the loss function on unlab eled data is non-con vex. When the regularization parameter is small, Figure 2: Test errors vary at each iteration with max-Figure 3: Loss curves to be minimized at the 5th itera-the loss function on lab eled data dominates to force the total loss function to be con vex, this guaran tees that we indeed nd a global minim um solution using line searc h; When the regularization parameter is large, the loss function on la-beled data is not able to dominate, so the total loss function is non-con vex, as Figure 4 illustrates, there are one mini-mum and sev eral saddle points exist. When the iteration gets larger, the loss functions look more like in Figure 3 and the total loss function becomes con vex, this is true even for large . In all the exp erimen ts on syn thetic, benc hmark and real data, usually smaller regularization parameter gives better test error, thus non-con vexit y of the objectiv e func-tion is not a big issue at all in practice. We have similar observ ation when we use mutual information on unlab eled data as a regularization term. Figure 4: Loss curves to be minimized at the 5th itera-Finally we apply our algorithms to 3-class syn thetic data. Eac h class is still generated by a 10-dimensional normal dis-tribution with equal mixing weigh t probabilit y. The means of eac h class are ( 8 ; ; 8) T , (0 ; ; 0) T and (8 ; ; 8) resp ectiv ely. The covariance matrix is diagonal with stan-dard deviation being 10. The num ber of lab eled data is N = 30, and the num ber of unlab eled data is 210. We also use unlab eled data as test data. In this exp erimen t, the error rate of LogitBo ost is 33.81% (2.71), the error rate of Assem ble.LogitBo ost is 32.86% (4.49), while error rate of the entrop y based semi-sup ervised boosting is 30.47% (2.04) with = 0 : 05, and error rate of mutual information semi-sup ervised boosting is 29.50% (2.82) with = 0 : 05. In this exp erimen t, we use sev eral benc hmark datasets: Balance scale weigh t &amp; distance, Pima, Wisconsin diagnostic breast cancer and BUP A liver disorders, in UCI Mac hine Learning Rep ository to test the performance of our prop osed semi-sup ervised boosting algorithms. We use 15% as lab eled data and 85% as unlab eled data. These unlab eled data are used as the test data in the exp erimen t. Table 2 sho ws the results of the classi cation error rates on test data. Data Logit Assem ble MI Entrop y Bala 27.43(1.52) 25.76(1.47) 24.80(1.72) 24.10(2.02) Pima 22.50(2.52) 20.87(3.47) 20.44(3.75) 19.87(3.03) Wins 5.14(0.74) 4.15(1.12) 2.92(0.77) 3.77(1.07) BUP A 37.24(5.59) 36.17(3.40) 29.84(3.79) 31.77(2.31) Table 2: Error rates (%) on four benchmark UCI data
This exp erimen t sho ws that our semi-sup ervised learning algorithms can get helpful information from unlab eled data and signi can tly impro ve the classi cation results.
We now rep ort results on a real-w orld problem: human men tal workload classi cation task in mo dern aviation sys-tems. Men tal workload refers to the information pro cessing demands imp osed on the operator by the performance of cognitiv e tasks, accurate and reliable real-time assessmen t of operators' cognitiv e states, i.e. their men tal abilities to carry out the jobs in time is the key for successful imple-men tation of adaptiv e human-aiding techniques in mo dern aviation systems, suc h as uninhabited air vehicles (UA Vs) and uninhabited com bat air vehicles (UCA Vs). One of the measures of men tal workload is the Electro encephalogram (EEG), a measuremen t of electrical activit y pro duced by the brain as recorded from electro des placed on the scalp, and it is used to predict human workload.

In this exp erimen t, we use real EEG data to mo del human work load. The input variable X is a 105 dimensional vector and the class lab el Y has three states \Lo w", \Medium" and \High" .

First we com bine the \Lo w" class and \Medium" class to-gether as one class and solv e a binary classi cation problem. We set the num ber of lab eled data to be N = 30, we then increase the num ber of unlab eled data from 60 to 240. We use dev elopmen t data to choose the best value of regular-ization parameter. The size of dev elopmen t data is 50. We rep eat this pro cess 10 times.

Figure 5 and Table 3 sho w the results of the classi cation error rate on EEG test data using both entrop y and mutual information on unlab eled EEG data as regularization terms when we increase the size of unlab eled EEG data.

Finally we consider 3-class cases of EEG data, in whic h we do not com bine \Lo w" class and \Medium" class. In this exp erimen t, the num ber of lab eled data is 30, and the num-ber of unlab eled data is 70. Unlab eled data are still the Figure 5: Test errors for LogitBo ost (blue), As-
Ratio Logit Assem ble MI Entrop y 2 17.78(3.01) 17.32(2.32) 16.67(2.60) 16.25(3.70) 4 18.21(3.23) 16.03(2.17) 13.75(2.59) 13.61(3.70) 6 18.46(1.63) 16.24(2.25) 12.80(2.31) 13.13(2.51) 8 17.63(1.78) 16.93(1.84) 12.29(1.68) 11.67(1.10) Table 3: Error rates on EEG test data for both entrop y and mutual information based semi-sup ervised boosting when varying the ratio of the size of unlab eled and lab eled EEG data, where the corresp onding values of regularization param-eter for both entrop y based metho d are 0.015, 0.007, 0.015 and 0.009 and mutual information based metho d are 0.0015, 0.0009, 0.0005 and 0.0005. test data. We rep eat this pro cess 10 times. The error rate of LogitBo ost is 32.94% (2.47); the error rate of Assem-ble.LogitBo ost is 31.01% (1.97); the error rate of our en-trop y semi-sup ervised boosting algorithm is 29.43% (2.44) when = 0 : 07, and the error rate of mutual information based semi-sup ervised boosting algorithm is 30.58% (2.51) when = 0 : 05.
In this pap er, we presen t semi-sup ervised boosting learn-ing where information theoretic terms, both entrop y and mutual information, are used to enco de the information pro-vided by unlab eled data and beha ve as data dep enden t pri-ors. The com bined loss functions are non-con vex, we deriv e simple sequen tial gradien t descen t optimization algorithms and test these algorithms on syn thetic, benc hmark and real world tasks. Exp erimen tal results sho w that by exploiting the availabilit y of auxiliary unlab eled data, our prop osed semi-sup ervised boosting algorithms can impressiv ely im-pro ve the performances of both sup ervised boosting algo-rithms and a state-of-the-art semi-sup ervised boosting algo-rithm. We are working on a formal analysis to give some theoretical justi cations on why these information measures can be used to impro ve classi cation performance. The authors wish to thank researc hers at the 711th HPW/ RHCP lab of the Wrigh t Patterson Air Force Base for pro-viding them the EEG human men tal workload classi cation dataset. [1] K. Benett, A. Demiriz and R. Maclin. Exploiting [2] D. Bertsek as. Nonline ar Programming , 2nd Edition, [3] A. Blum and T. Mitc hell. Com bining lab eled and [4] S. Boyd and L. Vanden berghe. Convex Optimization , [5] L. Breiman. Prediction games and arcing classi ers. [6] V. Castelli and T. Cover. The relativ e value of lab eled [7] G. Celeux and G. Govaert. A classi cation EM [8] O. Chap elle, B. Scholk  X  opf and A. Zien.
 [9] K. Chen and S. Wang. Regularized boost for [10] I. Cohen and F. Cozman. Risks of semi-sup ervised [11] M. Collins, R. Schapire and Y. Singer. Logistic [12] A. Cordunean u and T. Jaakk ola. Data dep enden t [13] T. Cover and J. Thomas. Elements of Information [14] F. d'Alc he-Buc, Y. Grandv alet and C. Am broise. [15] S. Della Pietra, V. Della Pietra and J. La ert y. [16] Y. Freund and R. Schapire. Exp erimen ts with a new [17] Y. Freund and R. Schapire. A decision-theoretic [18] J. Friedman, T.Hastie and R. Tibshirani. Additiv e [19] Y. Grandv alet and Y. Bengio. Semi-sup ervised [20] G. Ha ari, Y. Wang, S. Wang, G. Mori and F. Jiao. [21] T. Hastie, R. Tibshirani, J. Friedman. The Elements [22] J. Jano det, R. Nock, M. Sebban and H. Suc hier. [23] F. Jiao, S. Wang, C. Lee, R. Greiner and D.
 [24] G. Lebanon and J. La ert y. Boosting and maxim um [25] C. Lee, S. Wang, F. Jiao, D. Schuurmans and R. [26] L. Mason, J. Baxter, P. Bartlett and M. Frean. [27] K. Nigam, A. McCallum, S. Thrun and T. Mitc hell. [28] S. Rob erts, R. Everson and I. Rezek. Maxim um [29] R. Schapire. The strength of weak learnabilit y. [30] H. Valizadegan, R. Jin and A. Jain. Semi-sup ervised [31] Y. Wang, G. Ha ari, S. Wang and G. Mori. Rate [32] D. Zhou, O. Bousquet, T. Navin Lal, J. Weston and [33] J. Zhu, S. Rosset, H. Zhou and T. Hastie. Multiclass [34] X. Zhu, Z. Ghahramani and J. La ert y.

