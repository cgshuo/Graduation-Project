 This paper presents a novel framework for correct-ing preposition errors. Its most significant advan-tage over previous methods is that it can provide learners with feedback messages, that is, explana-tory notes describing why the detected preposi-tion is erroneous and should be corrected as in-dicated, as shown in Fig. 1. Despite the fact that appropriate feedback messages are essential in language learning assistance (Ferris and Roberts, 2001; Robb et al., 1986), which is one of the im-mediate applications of grammatical error correc-Figure 1: Error correction and feedback messages provided by the proposed method. tion, almost all previous methods are incapable of providing feedback messages.

Grammatical error correction has been inten-sively studied in recent years. Current methods mostly exploit machine learning-based classifiers to correct target errors; examples are errors in ar-ticle (Han et al., 2006; Nagata et al., 2006; Ro-zovskaya and Roth, 2011), preposition (Chodorow et al., 2007; Felice and Pulman, 2008; Rozovskaya and Roth, 2011; Tetreault et al., 2010), and tense (Nagata and Kawai, 2011; Tajiri et al., 2012), to name a few. Recently, Wu and Ng (2013) and Rozovskaya and Roth (2013) proposed methods for simultaneously correcting multiple types of er-rors using integer linear programming. Another major approach is to use a language model (LM) for predicting correct words or phrases for a given context. Some researchers (Brockett et al., 2006; Yoshimoto et al., 2013) use statistical machine translation (SMT) for the same purpose, which can be regarded as the mixture of a classifier and an LM. With these diverse techniques, correction performance has dramatically improved against a wide variety of target errors.

As noted above, however, one of the crucial limitations of these previous methods is that they are not capable of providing feedback messages. They are not suitable for generating open-class text such as feedback messages by their nature. Some researchers (Kakegawa et al., 2000; McCoy et al., 1996) made an attempt to develop hand-crafted rules for correcting errors with feedback messages. However, this approach encounters the tremendous difficulty of covering a wide variety of errors using hand-crafted rules.

In view of this background, this paper presents a novel error correction framework called error case frames an example of which is shown in Fig. 2. They are case frames specially designed for de-scribing and correcting errors in preposition at-tached to a verb; the reader may be able to see that it describes preposition errors such as *John often goes shopping to the market with his family. and that the preposition to should be replaced with at . This paper proposes a method for automatically generating them by comparing learner and native corpora. Achieving a comparable correction per-formance, they have the following two advantages over the conventional approaches: (i) they are in-tuitively interpretable and manually modifiable to enrich them; (ii) they are capable of providing feedback messages.

The rest of this paper is structured as fol-lows. Sect. 2 introduces the definition of error case frames. Sect. 3 discusses the method for generat-ing error case frames. Sect. 4 describes how to cor-rect preposition errors with feedback messages by error case frames. Sect. 5 describes experiments conducted to evaluate error case frames. Sect. 6 discusses the experimental results. An error case frame consists of a verb, cases, and lowing explains error case frames in detail based on this example; occasionally consulting it may help understanding the following sections.
An error case frame always has a verb. In Fig. 2, the verb is go .

Cases are arguments the verb takes in an error case frame. A case consists of a case tag and case elements. A case tag and case elements describe, respectively, the role that the case plays in the er-ror case frame and a set of words that are allowed to appear as the argument. For instance, in Fig. 2,  X  X ubj: { PERSON }  X  is a case where its case tag and element are  X  X ubj: X  and  X  { PERSON } , X  re-spectively, denoting that a person such as John plays a role of the subject of the verb. Note that tokens in all upper case such as  X  X ERSON X  refer to a group of words such as { john,he,  X  X  X } in this paper.

Cases are classified into two categories: basic and preposition cases. Basic cases are either a sub-ject or a particle, whose case tags are  X  X ubj: X  and  X  X tr: X , respectively. The  X  X ubj: X  case is obliga-tory while the  X  X tr: X  is optional. Preposition cases correspond to the prepositions the verb takes as its arguments. Its case tag has the form of  X  X rep x  X  where x ranges over the target prepositions. It should be emphasized that direct and indirect ob-jects are included in the preposition cases for effi-ciency; their case tags are denoted as  X  X rep dobj X  and  X  X rep iobj X , respectively. Preposition cases are classified into those obligatory and optional. Optional here means that the verb can constitute a sentence with or without the preposition. Op-tional prepositions are written in parentheses as in  X (Prep with: { family } ) X .

Preposition cases describe the information about an error. An error case frame is constrained to contain only one erroneous preposition case. It is marked with the symbol  X * X . So, the preposi-tion case  X *Prep to: { store,market }  X  is erroneous in Fig. 2. The correct preposition is described af-ter the symbol  X   X   X  as in  X   X  Prep at X .

Error case frames are furnished with feedback messages. Unlike verbs and cases, which are au-tomatically filled based on corpus data, they are manually edited. A human annotator interprets error case frames and adds explanatory notes to them. This may seem time-consuming. How-ever, the editing is far more efficient than manually creating correction rules with feedback messages from scratch because error case frames are highly abstracted as explained in Sect. 3. Above all, it is a significant advantage over the previous classifier-/LM-based methods considering that there exists no effective technique for augmenting these meth-ods with feedback messages. The method proposed here exploits two sources of corpus data: native and learner corpora. Case frames (error case frames without the information about an error and a feedback message) can be automatically extracted from parsed sentences as Kawahara and Uchimoto (2008) show. The pro-posed method generates error case frames by com-paring case frames generated from the learner cor-pus with those from the native corpus. The basic approach is to extract, as error case frames, case frames which appear in the learner corpus but not in the native corpus. However, this approach is so simple that it extracts undesirable false error case frames which do not actually correspond to prepo-sition errors. To overcome the problem, the fol-lowing procedures are applied: (1) Filtering input sentences (2) Extracting case frames (3) Recognizing optional cases (4) Grouping case frames (5) Selecting candidate error case frames (6) Determining correct prepositions (7) Enriching error case frames (8) Manually editing error case frames (1) Filtering input sentences : This is a pre-process to filter out unsuitable input sentences for case frame generation. Accurate parsing is es-sential for accurate case frame generation. Pars-ing errors tend to occur in longer sentences. To reduce parsing errors, Kawahara and Uchimoto (2008) propose filtering out sentences which are longer than 20 words. We adopt this filtering in our method. We also filter out sentences contain-ing commas, which often introduce complex struc-tures. We apply the filtering pre-process only to the native corpus; the availability of learner cor-pora is still somewhat limited and therefore we use all the sentences available in the learner corpus for better coverage of preposition errors. (2) Extracting case frames : This procedure can be viewed as a slot filling task where the slots are the verb and the cases in a case frame. To achieve this, the corpus data are first parsed by a parser. Then, for each verb, the predicate-argument structures are extracted from the parses as shown in Fig. 3. Here, only head words are ex-tracted as arguments. They are reduced to their base form when extracted. Certain classes of words are replaced with their corresponding sense (e.g., John to PERSON ); the mapping between words and their senses is shown in Appendix A. In the case of the learner corpus, mis-spelt words are automatically corrected using a spell-checker. Finally, a case frame is created by filling its slots with the extracted predicate-argument structures. Hereafter, case frames generated from the native and learner corpora will be referred to as the na-tive and learner case frames, respectively. (3) Recognizing optional cases : it is crucial for generating flexible error case frames to recog-nize optional preposition cases. Optional preposi-tion cases are determined by the following heuris-tic rules: (a) Objects are always obligatory; (b) The number of obligatory preposition cases (ex-cept objects) is at most one; (c) Prepositions ap-pearing left of the verb are optional; (d) Preposi-tions appearing right of the verb are optional ex-cept the one which is nearest to the verb. Rule (a) states that objects are always recognized as oblig-have at most one obligatory preposition. Certain verbs sometimes have more than one obligatory preposition as in range from A to B . However, the large majority of verbs satisfy rule (b). Rule (c) states that prepositions appearing left of the verb in the input sentence are optional preposition cases as in In the morning , he went shopping. Rule (c) is based on the assumption that obligatory cases are tied to the verb more strongly than optional cases. In other words, obligatory cases cannot easily change their position. Conversely, optional cases have more freedom of their position, which enables them to appear left of a verb. Admittedly, obligatory prepositions can appear left of a verb as in To school , he went in certain circumstances such as in poetry. However, this usage is not so frequent in corpora normally used as training data such as newspaper articles. Rule (d), together with rule (b), states that if more than one preposition appears right of the verb, the one nearest to the verb is obligatory and the rest are optional. Rule (d) is based on the same reasoning as in rule (c).
Optional preposition cases are sometimes deter-mined naturally by comparing two case frames. In this case, one of them must consist of only the object(s) as its preposition case(s) as in  X  X go Subj: { PERSON } Prep dobj: { shopping } ]. X  Then, the other case frame must consist of the same verb, the same basic cases, and the same object(s). The only difference between them is preposition cases (except the object(s)) (e.g., [go Subj: { PERSON } Prep dobj: { shopping } Prep at: { market } ]). The case frame only with the object(s) proves the other to be valid without the preposition case(s). Thus, these preposition cases are recognized as optional (e.g., [go Subj: { PERSON } Prep dobj: { shopping } (Prep at: { market } ) ]). (4) Grouping case frames : Similar case frames in the native case frames are grouped into one, which will play an important role in (7) Enriching error case frames . Case frames comprising sim-ilar cases tend to denote similar usage of a verb. Considering this, case frames are merged into one if they consist of the same verb, the same basic cases, and the same case tags of the obligatory preposition cases. The grouping procedure is illus-trated in Fig. 4. When preposition cases are oblig-atory in one case frame and optional in the other, the discrepancy is resolved by setting the prepo-sition case to optional in the merged case frame. Note that this grouping procedure is not applied to the learner case frames so that erroneous usages in the learner case frames do not propagate to other (correct) learner case frames. (5) Selecting candidate error case frames : Candidates for error case frames are selected from the learner case frames. If a learner case frame does not match, ignoring optional preposition cases, any native case frame, it is selected as a candidate for an error case frame on the assump-tion that case frames corresponding to erroneous usages do not appear in the native corpus.
Alternatively, an error-annotated learner cor-pus can be used to select error case frames; sim-ply extracting case frames of which preposition is marked as an error gives error case frames. In this dure (7) is directly applied after procedure (5). (6) Determining correct prepositions : Now, correct prepositions for the candidate error case frames are explored. Each case tag of the prepo-sition cases in a candidate is replaced, one at a time, with one of the other target prepositions. This replacement can be interpreted as error cor-rection. Take as an example the following can-didate error case frame: [go Subj: { PERSON } Prep dobj: { shopping } Prep to: { market } ]. Re-placing the case tag  X  X rep to X  with  X  X rep at X  cor-responds to correct expressions such as John of-ten goes shopping at the market. Note that re-placing a direct object with one of the preposi-tions corresponds to correcting an omission er-ror as in  X  X rep dobj X  with  X  X rep to X  in  X  X go Subj: { PERSON } Prep dobj: { market } ] X . Simi-larly, replacing a preposition with an object cor-responds to correcting an extra-preposition er-ror (e.g.,  X  X rep to X  with  X  X rep dobj X  in  X  X go Subj: { PERSON } Prep to: { shopping } ]) X .
To examine whether each correction is valid or not, the native case frames are again used; if the replaced case frame matches one of the na-tive case frames, the correction is determined to be valid. Here, we define the match as the two case frames consisting of the same verb, the same basic cases, the same obligatory preposition cases, and the same preposition case to which the cor-rection is applied (if it is an optional one). If the condition is satisfied, the information on the error and correction is added to the candidate error case frame. If a valid correction is found, the candi-date is determined to be a valid error case frame. In total, their validity is double-checked, once in (5) and once in (6), by comparing them with the native case frames. (7) Enriching error case frames : The gener-ated error cases are limited in error coverage be-cause the procedures so far solely rely on prepo-sition errors appearing in the learner corpus. In other words, it is impossible to generate error case frames corresponding to preposition errors which do not appear in the learner corpus. To overcome this limitation, the generated error case frames are enriched using the native case frames. For each er-ror case frame, we already know the correspond-ing native (thus, correct) case frame, which is ob-tained in (6). The corresponding native case frame is normally much richer in preposition cases be-cause of the optional cases and grouping given by procedures (3) and (4), as shown at the top of Fig. 5. These additional cases are useful to enrich error case frames.

For the preposition case which is determined to be erroneous, its correct preposition is found in the error case frame (e.g.,  X   X  Prep at X  at the top-left of Fig. 5). Also, its correct preposition case is found in the corresponding native case frame (e.g.,  X  X rep at: { market,store }  X  at the top-right). Replacing the case element of the erroneous case by one of the case elements of the correct preposition case gives a new can-didate for an error case frame (e.g., replacing market of  X *Prep to: { market }  X  by store gives  X  X go Subj: { PERSON } Prep dobj: { shopping } *Prep to: { store } ]. X  It should be emphasized that this new error case frame is still a candidate at this point and the usage might be correct. To verify if it really describes an erroneous preposition use, the native case frames are searched for; if it matches one of them, that means that the use of the preposition actually appears in the native corpus. Therefore, it should be discarded. Only if a match is not found, is the case element added to the erroneous preposition case in the original error case frame. This process is illustrated in the box denoted as Verification in Fig. 5.

For the other preposition cases which are not er-roneous, the enriching procedure is much simpler. They are simply added to the error case frame as shown in Fig. 5. One thing we should take care of is that there might be a discrepancy in obliga-tory/optional between the cases of the error case frame and the native case frame. This discrepancy is solved by setting the preposition case in the er-ror case frame to optional. The resulting expanded error case frame after procedure (7) is shown at the bottom of Fig. 5 where the enriched cases are shown in red. (8) Manually Editing Error Case Frames : The most important editing is the addition of feed-back messages. A human annotator interprets the generated error case frames and adds explanatory notes to them. Although this basically requires manual editing, part of feedback messages can be automatically created to facilitate the procedure. For example, example sentences corresponding to an error case frame can be automatically added to it, whether correct or error examples, because the original sentences from which the (error) case frames extracted are available in the native and learner corpora. Besides, setting a variable to the feedback message allows it to be adaptable to correction results as shown in Fig. 6. In Fig. 6, X
Prep to is a variable. It is replaced with one of the case elements of  X  X rep to: X  depending on correction results. Also, it will be beneficial to link similar error case frames each other, which allows the user to obtain additional information. For example, the example error case frame in Fig. 6 may be linked to similar case frames such as  X  X  go Subj: { PERSON } Prep dobj: { sightseeing } *Prep to: { Baltimore } X  Prep in ]. X  One can re-trieve similar error case frames from the generated error case frames where the similarity between two error case frames are defined by the overlap in the verb, the basic cases, and the case tags of the preposition cases.

The generated error case frames may be further edited to enrich them. As we can see in Fig. 5, the generated error case frames are easy to interpret. This property enables us to manually edit them to enrich their preposition cases. For example, one might add a case element such as supermarket to the preposition case  X  X rep to: { market,store }  X  in the example error case frame. Conversely, one might discard unnecessary case elements, cases, or even error case frames. Preposition errors are corrected by applying the generated error case frames to the target text. Case frames are first extracted from the target text by the same procedures (2) and (3) in Sect. 3. Then, each extracted case frame is examined if it matches one of the error case frames. If a match is found, the preposition is detected as an error and the correct preposition is suggested with the feedback mes-sage according to the matched error case frame. The match between a case frame and an error case frame is defined in the exact same manner as in procedure (4) in Sect. 3. Sometimes, a case frame matches more than one error case frame suggest-ing different corrections. In this case, the most frequent correction among the candidates is cho-sen to correct the error, which was applied in the
One of the advantages of error case frames is that they do not require an error-annotated corpus as explained in the previous section. This means that the target text itself can be used as part of a learner corpus for generating error case frames at the time of error correction. Applying procedures (2) to (7) to the target text generates additional er-not available in these additional error case frames, they are still useful for improving correction per-formance, especially in recall. Hereafter, this way of error case frame generation will be referred to as active generation .

A pre-experiment using a development data set revealed that there were some preposition errors for which error case frames were not generated even though the corresponding erroneous and cor-rect preposition usages appeared in the learner and native corpora, respectively. They are preposition errors where the preposition is incorrectly used with an adverb as in *John went to there . To be precise, they are either an adverb denoting a place (e.g., there ) with a preposition concerning a place ( at , in , on , and to ) or a noun denoting time, fre-quency, and duration with a preposition concern-ing time, frequency, and duration ( at , for , in , and on ). In the native corpus, these adverbs or nouns are correctly used without a preposition and thus they are not recognized as a prepositional phrase by a parser. Therefore, corresponding native case frames are never found for these types of errors in procedure (6), and in turn error case frames are never generated for them.

Considering that they are limited in number because they are independent of verbs and ba-sic cases, we decided to manually create er-ror case frames describing these types of er-rors. In these error case frames, the verb and the basic cases are filled with ANY denot-ing any word. The preposition cases are man-ually filled based on the linguistic knowledge known as absence of preposition (Quirk et al., 1985). For example, an error case frame for the above error would be  X  X ANY Subj: { ANY } *Prep to: { here,somewhere,there } X  Prep dobj ]. X  Certain errors involve a phrase such as *John goes shopping in every morning . To handle these cases, these manually created error case frames are al-lowed to have phrases as their case elements (e.g., [ANY Subj: { ANY } *Prep in: { every morning } X  Prep dobj ]). We evaluated the proposed method from two points of view: correction performance and use-fulness of feedback messages. We measured cor-rection performance by recall, precision, and F -measure. In the evaluation on usefulness of feed-back messages, three human raters (a teacher of English at college and two who have a master degree in TESOL) separately examined whether each feedback message was useful for learning the correct usage of the preposition. We defined use-fulness by the ratio of feedback messages evalu-ated as useful to the total number of feedback mes-sages.

We used the following data sets in the evalua-tion. We selected the Konan-JIEM (KJ) learner corpus (Nagata et al., 2011) as the target texts. The KJ learner corpus is fully annotated with grammat-ical errors. In addition, it includes error correc-tion results of several benchmark systems. This means that one can directly compare correction results of a new method with those of the bench-mark systems, which reveals where the method is strong and weak compared to the benchmark sys-tems. The KJ corpus consists of training and test sets. We used the training set to generate error case frames and evaluated correction performance on the test set. In addition to these data sets, we cre-ated a development set, which we had collected to develop the proposed method. We did not use it in the final evaluation. As a native corpus, we used the EDR corpus (Japan electronic dictionary research institute Ltd, 1993), the Reuters-21578 the lexicalized dependency parser in the Stanford Statistical Natural Language Parser (ver.2.0.3) (de Marneffe et al., 2006) to obtain parses for the data sets. Table 1 shows the statistics on the data sets.
Using these data sets, we implemented three versions of the proposed method. The first one was based on error case frames generated from the training set of the KJ corpus. The second one was the first one with active generation. To implement
Table 1: Statistics on the data sets for evaluation. the third one, we manually edited the error case frames of the first version to remove unnecessary error case frames and case elements (but no addi-tion) and to add feedback messages to them. Af-ter this, active generation was applied to augment the edited error case frames. In implementing the proposed methods, we selected as target preposi-tions the ten most frequent prepositions, the same as in previous work (Rozovskaya and Roth, 2011): about , at , by , for , from , in , of , on , to , with .
For comparison, we selected two conventional methods. One was the best-performing sys-tem among the benchmark systems, which is the classifier-based method (Sakaguchi et al., 2012) which had participated in the HOO 2012 shared task (Dale et al., 2012). The other was the SMT-based method (Yoshimoto et al., 2013) which was the best-performing system in preposition error correction in the CoNLL 2013 shared task (Ng et al., 2013). In addition, we evaluated performance of hybrid methods combining the correction re-sults of the third version of the proposed method with those of the classifier-/SMT-based method; we simply took the union of the two.

Table 2 shows the evaluation results. The sim-ple error case frame-based method achieves an F -measure of 0.189. It improves recall when com-bined with active generation, which shows the effectiveness of active generation for augment-ing error case frames. It further improves pre-cision without decreasing recall by manual edit-ing; note that manual editing was only applied to the error case frames generated from the train-ing data but not to those generated by active gen-eration. The performance is comparable to both classifier-/SMT-based methods. The hybrid meth-ods achieve the best performances in F -measure.
In the usefulness evaluation, the third version of the proposed method was able to provide 20 feed-back messages for the target texts. The three hu-man raters evaluated 80%, 80%, and 85% of the ECF: Error Case Frame, ME-ECF: Manually Edited Error Case Frame, AG: Active Generation Table 2: Correction performance in recall ( R ), precision ( P ), and F -measure ( F ). 20 feedback messages as useful (82% on average). The agreement among the raters was  X  =0 . 67 in Fleiss X  X   X  . As the experimental results show, the proposed method achieves a comparable correction perfor-mance with the classifier-/SMT-based methods. A closer look at the correction results reveals the dif-ferences in correction tendencies between these methods, which explains well why the hybrid methods achieve better performance.

One of the tendencies is that the proposed method performs better on preposition errors where relatively wider contexts are required to correct them. Error case frames naturally exploit wider contexts based on the cases which are extracted by parsing. In contrast, classifier-/SMT-based methods rely on narrower contexts such as a few words surrounding the preposition in question. Take as an example the following sentence which appeared in the test set: *In the univerysity, I studied English in the morning 8 . To confirm that the preposition In is erroneous requires the verb studied and the object English . The proposed method successfully corrected this error by the error case frame  X  X study Subj: { PERSON } Prep dobj: { english,math,  X  X  X } *Prep in: { university } X  at ] X  in the evaluation. This would be difficult for methods relying on only a few words surrounding the preposition In .
It is also difficult for classifier-/SMT-based methods to correct missing preposition errors. Classifier-based methods need to be informed of the position of the preposition to predict a cor-rect preposition. Because the position of a miss-ing preposition is implicit, classifier-based meth-ods would have to make a prediction at every single position between words, which would be inefficient. Because of this, the classifier-based method used in the evaluation (and often other classifier-based methods) excludes missing prepo-sition errors from its target. SMT-based methods do not perform well either on missing preposition errors because of the fact that they implicitly, but not directly, handle missing preposition errors. In contrast, error case frames directly model miss-ing prepositions by treating objects as one of the preposition cases (i.e., Prep dobj ).

Grammatical errors other than preposition er-rors influence both the proposed and classifier-/SMT-based methods, but differently. Grammat-ical errors appearing around the preposition in question seem to influence the previous methods more significantly than the proposed method be-cause they rely on words surrounding the prepo-sition. On the other hand, structural errors such as errors in voice tend to degrade performance of the proposed method. For instance, if an error in voice occurs as in *I excited this , correctly, I was excited by this , error case frames are not properly applied.

The precisions of the proposed methods are high compared to those of the previous methods. To be precise, the number of false positives is only seven in the third version of the proposed method. Out of seven, four false positives are due to prob-lems with the used error case frames themselves. Two are the influence of other grammatical errors (e.g., *I like to look beautiful view . was corrected as look at beautiful view by the proposed method but as see beautiful view in the error annotation).
Unlike false positives, it is difficult to precisely point out causes for false negatives, which often involve several factors. One cause which is theo-retically clear is errors in preposition attached to a noun phrase (NP), which amounts to 11 % of all false negatives. Since error case frames de-scribe errors in preposition attached to a verb, they do not target these types of errors. Extending er-ror case frames to general frames might overcome this limitation, which will require further investi-gation. Similarly, error case frames are not gener-ated for preposition errors where prepositions are incorrectly used with words other than a noun as in *make me to happy (5 % of all). Although er-ror case frames can describe these types of errors, case frames are not extracted for their correspond-ing correct usages from the native corpus. This is because the word in question (e.g., happy ) cor-rectly appears without the erroneous preposition in the native corpus, and thus it is not recognized as a preposition case. This means that a correspond-ing correct case frame is never found for any er-ror of these types in the generation procedure (6). Accordingly, error case frames are never gener-ated for these types of errors. The most influen-tial cause of false negatives, which is also a major cause of false negatives in the previous methods, is other grammatical errors (at least 22 % of all). One of such errors is errors in voice as already ex-plained (4%). Another is the omission of the ob-ject of a verb (4%). In these cases, even if an ap-propriate error case frame exists, it is not applied because of the grammatical error.

In addition to correction performance, error case frames are effective in providing feedback messages; Fig. 1 (on the first page) shows excerpts of the feedback messages provided in the evalua-tion. The evaluation shows that 82% of the pro-vided feedback messages were actually rated as useful for language learning on average (the rest were mostly evaluated as not-useful due to false positive corrections). With the feedback messages of error case frames, we now have the follow-ing three choices as the way of error correction: (a) just indicating the correct preposition (as in previous methods); (b) indicating the correction preposition with a feedback message; (c) display-ing only a feedback message. In (a), the learner might just copy the correct preposition to correct his or her writing, which would result in little or no learning effect. This suggests that the ultimate goal of grammatical error correction for language learning assistance is not to correct all errors in the given text but to maximize learning effect for the learner. (b) might give a similar result because the learner can copy the correct preposition without reading the feedback message. In (c), the learner has to actually read and understand the feedback message to select the correct preposition. Taking these into consideration, (c) will likely give the learner better learning effect than the other two. Therefore, we propose applying the feedback (c) to language learning assistance. To the best of our knowledge, it is only the error case frame-based method that is capable of this manner of error cor-rection. This paper presented a novel framework called error case frames for correcting preposition er-rors with feedback messages. The evaluation showed that (i) automatically generated error case frames achieve a performance comparable to con-ventional methods; (ii) they are intuitively in-terpretable and manually modifiable to improve them; (iii) feedback messages provided by error case frames are effective in language learning as-sistance. Considering these advantages and the fact that it has been difficult to provide feedback messages by automatically generated rules, error case frames will likely be one of the major ap-proaches for preposition error correction. The following list shows the mapping between words and senses developed based on the Word-Net (Miller, 1995) and GSK dictionary of places token for a sense, its definition, examples of its member. DRINK (drink): tea, coffee FOOD (food): cake, sandwich MONTH (names of months): January, February MINST (musical instruments): guitar, piano PERSON (persons): John, he PLACE (place names): Canada, Paris SPORT (sports): football, tennis SPORTING (sporting activities): swimming WEEK (the days of the week): Monday VEHICLE (vehicles): train, bus We would like to thank Daisuke Kawahara for his advice on case frame generation. We also would like to thank Keisuke Sakaguchi and Mamoru Ko-machi for providing the authors with their system outputs. Finally, we would acknowledge the help from the members of the ILES group at LIMSI, Orsay (France) where the first author performed part of this work. This work was partly supported by Kaken Grant-in-Aid for Young Scientists (B) (26750091).
