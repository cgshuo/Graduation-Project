 Query processing with precomputed term pair lists can improve efficiency for some queries, but suffers from the quadratic num-ber of index lists that need to be read. We present a novel hybrid index structure that aims at decreasing the number of index lists retrieved at query processing time, trading off a reduced number of index lists for an increased number of bytes to read. Our ex-periments demonstrate significant cold-cache performance gains of almost 25% on standard benchmark queries.
 Categories and Subject Descriptors: H.3.1 [Content Analysis and Indexing ]: Indexing methods General Terms: Performance, Experimentation Keywords: proximity scoring, efficiency
Precomputed indexes for term pairs, not just single terms, have recently been proposed to improve not only quality of results, but also processing efficiency [4, 5]. While they can greatly improve performance for short queries, they are not that efficient for large queries or when lists are not available in a cache, but need to be read from disk. This disadvantage is rooted in the quadratic num-ber of term pair lists that need to be accessed for every query. Es-pecially with the pruning methods from [4] that store only a few thousand entries per pair list, query processing time is dominated by the time to locate and open index lists. Reducing the number of index lists for processing a query can therefore significantly im-prove efficiency, even if more data must be read from each list.
This paper introduces a novel hybrid index structure that de-creases the number of index lists accessed at query processing time, trading it off for an increased number of bytes read from each list. Our experiments demonstrate significant performance gains for query processing on cold caches with our new index structure, using queries from TREC Terabyte and Efficiency Tracks.
We base on and extend the index framework for terms and term pairs presented in [4]. That paper proposes to use an index with TextLists (TL) that store, for each term, documents and their BM25 score for this term, and additional CombinedLists (CL) that store, for each pair of terms, a proximity-based score (a variant of the score proposed in [2]) for each document that contains both terms and additionally the document X  X  BM25 scores for both terms. That paper proposes to sort TLs by score, CLs by proximity score, and runs a top-k algorithm to compute the best results for a query with early pruning. Experimental results indicated that it is enough to heuristically keep only the best few thousand entries in each list to achieve good result quality.

In earlier work [1], we pushed this setup to the limits by storing short prefixes of TLs and CLs in compressed form sorted by docid (applying delta encoding for docids and v-byte encoding for scores) and processing queries by a very efficient document-at-a-time al-gorithm, yielding average cold cache runtimes of about 59ms on GOV2 with about 10K bytes read.
For further improving this runtime, especially for medium-sized queries, it is necessary to reduce the number of lists accessed by each query. For a query with 5 terms, up to 10 term pair lists and 5 term lists need to be opened. The hybrid framework that we pro-pose in this paper can reduce this to at most 10 lists in the best case, reducing the number of lists to open by 33%. We achieve this by combining the CL for a term pair ( t 1 ,t 2 ) with the TLs for t , yielding an extended CombinedList (CLExt) that now contains the best documents for both the term pair and the single terms. We can expect that many documents will be included in two or three of the lists, so that the number of entries in the resulting CLExt will be less than the aggregated number of entries of the three source lists. Within the CLExt, we store all entries in the same format, replacing unknown scores by 0, and sort all entries by their docid.
At query processing, only CLExt lists need to be read, reducing the number of index lists by n (for queries with n terms). For queries with 3 terms, the number of lists is only 3 compared to 6 in the existing approach. For queries with larger number of terms, the technique is less effective since there is still a relatively large number of CLExts to read, and information from one TL is now included in several CLExts, so some of the information read during query processing is not needed. We will see later that the break-even point is around 8 terms per query. Note that TLs need to be kept in the index for queries with just a single term.
If we build a hybrid index as we just explained, the size of that index will be a lot larger than the size of the index with just TLs and CLs. While this comes as a surprise at first view, it has a sim-ple explanation: many pairs of terms hardly occur together in the same document, so the corresponding CL is very short, but they frequently occur in isolation, so the (prefix of the) TL of each term in the index is long. The CLExt for such pairs is therefore orders of magnitude larger than the CL for the same pair.

We can lower the required space for the hybrid index by using additional information on how frequently pairs are used, for exam-ple from a query log. We then build CLExt lists only for term pairs that are used frequently enough; for all other pairs we keep the old CL scheme. This drastically reduces the size of the hybrid index, while still providing reasonable performance improvements. With the TREC GOV2 collection, generating CLExt lists only for term pairs that occur at least once in the AOL query log reduced the on-disk size of the CLExt lists from over 3TB to 131.7GB; the on-disk size of all CL lists in the standard index was 93.2GB. We evaluated our proposed hybrid index with the well-known GOV2 collection, using the 150 adhoc topics from the TREC 2004 X  2006 Terabyte tracks and the first 10,000 queries from the Terabyte Efficiency Track (EffTrack) 2005 [3] as query loads. [1] elaborates on an index tuning approach that determines list pruning parame-ters under controlled result quality given a maximum index size. In this work, all TLs and CLs are pruned to at most 310 entries, and entries in CLs have a proximity score of at least 0.05; experiments in [1] have shown that this is enough to yield a similar quality for top-10 documents as produced by a BM25 score with unpruned in-dex lists. We report average cold-cache runtimes (averaged over six independent runs) and access costs for top-10 retrieval with the original index (TL+CL) and the hybrid index with log-based pruning (TL+CLExt Qlog ); file-system caches were emptied before running each query , which is a very conservative setting. Note that runtimes and cost are largely independent of the number of retrieved results.

For the Terabyte queries, using the hybrid index improved run-time from 59ms to 49ms per query over the original index; for the EffTrack queries, the improvement was even better (55ms vs. 42ms per query). This clearly shows that our hybrid index can greatly im-prove cold-cache performance. We will now evaluate the impact for queries of different length, and the influence of log-based pruning. Figure 1: Average runtimes for Terabyte and EffTrack queries
Figure 1 reports average query times for the two query loads, grouped by number of terms per query. Improvements are best for short queries, but we see improvements up to 7 terms. The chart also indicates the standard deviations which are pretty low.
Figure 2 details the average number of bytes read per query for the EffTrack. The hybrid index reads up to twice as many bytes from disk, but is (as we saw before) still faster because it needs to open fewer lists (also depicted in this figure by triangles and diamonds).
 Figure 3 shows the influence of log-based pruning on runtime. We computed, for each EffTrack query, the fraction of term pairs covered in the log, and grouped queries into five buckets from low coverage (0%-20%) to high coverage (80%-100%). Our method gives benefit only for queries with term pair coverage of at least Figure 2: Average cost in bytes and average number of opened lists, for the EffTrack queries Figure 3: Effect of query term pair coverage in the AOL query log on runtime, for the EffTrack queries 60%; however, these are the most frequent queries in this load (in-dicated by the black dots). For the remaining queries, our method does not create a performance penalty.
We have demonstrated that our hybrid index structure signifi-cantly improves cold-cache query processing times by decreasing the number of fetched index lists, at the price of reading more from each list. Highest improvements are achieved for short queries. Our future work will therefore concentrate on improving performance for long queries, for example by precomputing lists for frequently used phrases. [1] A. Broschart and R. Schenkel. Real-time text queries with [2] S. B X ttcher, C. L. A. Clarke, and B. Lushman. Term proximity [3] C. L. A. Clarke, F. Scholer, and I. Soboroff. The trec 2005 [4] R. Schenkel, A. Broschart, S.-w. Hwang, M. Theobald, and [5] H. Yan, S. Shi, F. Zhang, T. Suel, and J.-R. Wen. Efficient
