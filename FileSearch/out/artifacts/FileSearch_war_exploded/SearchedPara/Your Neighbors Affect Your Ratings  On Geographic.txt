 Rating prediction is to predict the preference rating of a user to an item that she has not rated before. Using the business review data from Yelp, in this paper, we study business rating prediction. A business here can be a restaurant, a shopping mall or other kind of businesses. Di ff erent from most other types of items that have been studied in various recommender systems ( e.g., movie, song, book), a business physically exists at a geographical location, and most businesses have geographical neighbors within walking dis-tance. When a user visits a business, there is a good chance that she walks by its neighbors. Through data analysis, we observe that there exists weak positive correlation between a business X  X  ratings and its neighbors X  ratings, regardless of the categories of businesses. Based on this observation, we assume that a user X  X  rat-ing to a business is determined by both the intrinsic characteristics of the business and the extrinsic characteristics of its geographical neighbors. Using the widely adopted latent factor model for rating prediction, in our proposed solution, we use two kinds of latent fac-tors to model a business: one for its intrinsic characteristics and the other for its extrinsic characteristics. The latter encodes the neigh-borhood influence of this business to its geographical neighbors. In our experiments, we show that by incorporating geographical neighborhood influences, much lower prediction error is achieved than the state-of-the-art models including Biased MF, SVD ++ , and Social MF. The prediction error is further reduced by incorporating influences from business category and review content.
 H.3.3 [ Information Systems ]: Information Search and Retrieval X  Information Filtering Recommendation; Rating prediction; Matrix factorization; Yelp
Recommender systems have attracted significant attention from both academia and industry since the last decade. Various recom-mender systems have been developed to facilitate the matching be-tween consumers ( i.e., users) with appropriate products or services ( i.e., items). Example items include songs, movies from content providers as well as books from E-commerce websites. Recently, recommender systems have also been applied to social network platforms ( e.g., Facebook, Twitter, Linkedin) for people recom-mendation, e.g., recommending friends to a user or recommend-ing who to follow. The prevalence of GPS-enabled devices ( e.g., smart phones) in the past few years further extends the landscape of recommender systems in location-based social networks (LBSN), exemplified by Foursquare and Gowalla.

Depending on the application, di ff erent recommendation prob-lems have been defined and studied. The top-N item recommenda-tion and rating prediction are two most widely studied categories of recommendation problems. On the one hand, top-N item recom-mendation tasks aim to recommend a user a list of items that she may be interested in. For example, in LBSN, POI recommenda-tion aims to recommend unvisited POIs to users. Here POI stands for point-of-interest, referring to a focused geographic entity such as district and street, or a specific point location such as landmarks and restaurants [20]. Rating prediction, on the other hand, is to pre-dict the preference rating of a user to a product or service that she has not rated before. The products or services with high predicted ratings are recommended to users. In this study, we are interested in the business rating prediction problem with business review data from Yelp.

Yelp is a business review site and has attracted 47 million reviews to local businesses since 2004. Example businesses in Yelp include restaurants, shopping malls, beauty &amp; spas, etc.. The website re-ports that it had an average of approximately 117 million monthly unique visitors in the third quarter of 2013. 1 A Yelp user or Yelper can share her experience with a business by posting a review of the business and also a rating from 1 to 5 stars. Our task is therefore to predict how many stars a user would give to a business that she has yet reviewed .

At first glance, rating prediction of business is the same as pre-diction of user X  X  rating to any other kind of items ( e.g., a song or a movie), with the only di ff erence that the item here refers to a business. The key di ff erence, between a business and other kind of items that have been studied in literature, is that a business physi-cally exists at a specific geo-location with latitude / longitude coor-dinates. More importantly, most businesses ( e.g., restaurants and shops) are not geographically isolated from others. That is, when a user visits a business, there is a good chance that she walks by its neighbors if they are located within walking distance. The over-all environment of that region might a ff ect a user X  X  view about a business and subsequently a ff ect user X  X  review and rating to the business. For example, the hygiene standard of a region might af-fect user X  X  rating to many restaurants located in that region. On the other hand, a region distinguishes itself from other regions and becomes attractive to visitors often because there are a few good businesses co-located in the region. For business rating prediction, an interesting question here is: Is there any correlation between a business X  X  rating and the rating of its geographical neighbors ? To answer the question above, we conducted data analysis on Yelp X  X  business rating data. We observe that there does exist weak positive correlation between the rating of a business and the rating of its neighbors, regardless of the category of the business. Based on this observation, we incorporate geographical neighborhood in-fluence into our business rating prediction model which is based on the widely adopted latent factor model realized by Matrix Factor-ization (MF). Together with influences from other factors includ-ing user reviews, business category, and business popularity, we show that the proposed model outperforms state-of-the-art base-lines including Biased MF, SVD ++ and Social MF [12, 17], mea-sured by both Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). To the best of our knowledge, this is the first study exploiting geographical neighborhood influence in business rating prediction. We note that geographical influence has been consid-ered in POI recommendation and POI prediction. However, we ar-gue that both POI recommendation and POI prediction are di ff erent research problems from business rating prediction (see Section 2 for more details). To summarize, the main contributions arise from this study are as follows:
The rest of this paper is organized as follows. We review the related work on rating prediction, POI recommendation and POI prediction in Section 2. The data analysis is reported in Section 3. The details of the proposed business rating prediction model is pre-sented in Section 4, followed by experimental evaluation in Sec-tion 5. Finally, Section 6 concludes this paper.
In this section, we briefly review the recent advances in recom-mender systems, mainly focusing on the applications of collabora-tive filtering on rating prediction. As one of the major contributions of this study is the influence of geographical neighborhood, we also review the related work employing geographical influence for POI recommendation and POI prediction. We then highlight the major di ff erences between our research problem and these two problems.
Collaborative filtering (CF) is the most widely used technique in recommender systems [11, 12, 18, 19]. The underlying assump-tion of CF is that similar users would rate items similarly or similar items would receive similar ratings from users. Ratings here in-dicate users X  preferences to items. There are mainly two kinds of approaches, namely, memory-based CF and model-based CF.

The basic idea of memory-based CF is to find similar users or items by using similarity measures, i.e., user-based CF [1, 10] and item-based CF [8, 21]. The commonly used similarity measures are Pearson X  X  correlation and cosine similarity, computed based on user-item ratings as well as other user-/ item-specific features de-pending on the application. The similar users or items are also known as neighbors and therefore memory-based CF is also known as neighborhood-based CF. However  X  X eighbor X  in this context is defined by the chosen similarity measure. Di ff erent similarity mea-sures lead to di ff erent sets of neighbors for a given user or item. In this paper, the neighborhood of a specific business refer to the businesses that are located physically close to it, i.e., geographical neighborhood.

Model-based CF usually employs machine learning techniques to build models from the observed user-item ratings, and then to predict the unobserved ratings. Latent factor model is one of the most successful CF models, in which users and items are jointly mapped into a shared latent space of much lower dimensionality. As the most successful realization of latent factor model, matrix factorization (MF) [12,14,17] has been successfully applied to var-ious recommender systems including music rating prediction for Yahoo! Music [11] and Last.fm [24], movie rating prediction for Netflix [12, 13] and Douban [17, 24], and personalized tweet rec-ommendation [2].

Among various MF models proposed, SVD ++ [12] is probably one of the most successful models. This model integrates the im-plicit feedback information from a user to items ( e.g., based on user X  X  purchase history or browsing history). More specifically, the user vector of latent factors in this model is complemented by the latent factors of the items to which the user has provided implicit feedback. Recently, Ma [17] proposed a social regularization MF method, named Social MF, to employ the similar and dissimilar relationships between users and / or items to improve recommenda-tion accuracy. The similarity between items is measured based on their ratings using Pearson X  X  correlation or cosine similarity. In our experiments, the proposed models achieve better rating prediction accuracy than Social MF indicating that the influence from geo-graphical neighborhood is more e ff ective than the influence from neighbors chosen by rating-based similarity measures.

Based on MF, influence from other aspects of users or items be-sides the ratings can be flexibly and easily modeled. For example, Koenigstein et al. [11] incorporated rich item bias into MF model to capture the taxonomy information of music. Each music has mul-tiple types of information such as track, album, artist and genre. In their proposed model, MF was extended by adding shared bias pa-rameters for items linked by common taxonomy. Moreover, some other work has also shown that popularity is helpful in improving the recommendation accuracy [7, 22]. To capture users X  interests over tweet content, Chen et al. [2] proposed to use topic-level latent factors. Instead of directly asking whether a user is interested in a tweet, the model captures user X  X  preference over the words in the tweet. In our problem setting, we consider the review from a user further elaborates about the rating. We model the words in review as latent factors and incorporate the review into rating prediction.
POI recommendation has attracted significant attention recently with the popularity of LBSN [3, 6, 25, 26]. Because geographical neighborhood is the main focus in our study, there is a need to re-view recent advances in POI recommendation. The main research issue in POI recommendation is to accurately recommend unvisited POIs to users. Geographical influence and temporal influence are major considerations in POI recommendation [25, 26]. Geograph-ical influence is based on the observation that users tend to visit nearby POIs of their home or o ffi ce locations, as well as nearby lo-cations of the POIs in their favor. Temporal influence is reflected by the observation that users check-in di ff erent types of POIs at dif-ferent time slots of a day ( e.g., restaurant in lunch hour and bar in night). Moreover, POI recommendation has also considered social influence among friends [25].

POI prediction aims to predict which POI a user would visit next given her current location and time [4,6]. Di ff erent from POI rec-ommendation, the POI predicted for a user to be visited next may have been visited by the user before. Similarly, both geographical influence and temporal influence have been considered in the mod-eling. Liu et al. [16] proposed a category-aware POI prediction model by exploiting users X  preference transition over location cat-egories. In this model, MF is utilized to predict a user X  X  preference transitions over categories and then the locations in the correspond-ing categories by considering geographical influences. The model was evaluated on Gowalla check-in data with three-level category hierarchy. In our model, we also consider category information of the business. However, we directly incorporate category latent fac-tors into our factorization model to reflect the a ffi nity of businesses linked by the categories they belong to. Note that, categories in the Yelp dataset are not organized in hierarchy.

In this paper, we study the impact of geographical neighborhood influence to business rating prediction. We argue that the geograph-ical neighborhood influence in our research problem is essentially di ff erent from the geographical influence in POI recommendation and / or prediction. For POI recommendation / prediction, the geo-graphical influence is more related to the cost of travel ( e.g., time cost or monetary cost) from a user X  X  point of view. For rating pre-diction, on the other hand, we predict a user X  X  degree of preference to a yet reviewed business. The cost of travel here is expected to be a less important factor. The contextual factors ( e.g., the current location, the time of visiting) which have demonstrated e ff ective in POI recommendation / prediction are also less relevant to our re-search problem. In our research problem, geographical neighbor-hood influence is more related to the business environment created by the surrounding businesses to one business at a specific location. Next, we conduct data analysis of the Yelp data.
Our study is based on the recently released Yelp Dataset Chal-lenge. 2 The data is sampled by Yelp from the greater Phoenix, AZ Figure 1: Percentage of businesses having at least 1, 3, 6, 10 neighbors within a distance threshold from 20 to 2000 meters metropolitan area from March 2005 to January 2013. It contains 11 , 537 businesses, 229 , 907 reviews by 43 , 873 users, and 8 , 282 check-in sets. This dataset was used as training data in ACM Rec-Sys Challenge 2013. 3
A business has a unique id, name, address, latitude longitude, its categories and some other attributes like city, state, and neigh-borhoods. However, we observe that the neighborhoods attribute is empty in the dataset. A review contains business id, user id, rating from 1 to 5 stars, date, review text, and voting. In this study, we do not use the voting feature for its less relevance to our research prob-lem. Table 1 reports the minimum, maximum, and average number of ratings per user and per business respectively. A check-in set for a business contains the aggregated number of check-ins in ev-ery hour from Monday to Sunday. The largest number of check-ins to one business observed from the data is 22 , 977. Note that, the dataset does not provide detailed check-in records of which user checkin a business at what time, and there are only about 72% of businesses have check-in sets. The percentage becomes 85.13% among all businesses having at least 5 reviews. In other words, a business may have a number of reviews but no check-in records. The dataset does not provide much details of a user .
Tobler X  X  First Law of Geography states  X  X verything is related to everything else, but near things are more related than distant things X  [23]. Next, we present 3 observations made from the data with respect to geographical neighborhood.

O bservation 1. Most businesses have neighbors within a short geographical distance from their locations. More than 44% of businesses have one neighbor next to it within 20 meters and 95% of businesses have one neighbor within 500 meters.

Based on the business latitudes and longitudes, we calculate the geographical distance between two businesses using Haversine for-mula. 4 Figure 1 plots the percentage of businesses having at least 1, 3, 6, and 10 neighbors respectively, within a geographical distance threshold ranging from 20 to 2000 meters. It shows that most busi-nesses are not isolated geographically from others. Specifically, Figure 2: Pearson X  X  correlation between a business X  X  rating and the average rating of its {1, 3, 6, 10} nearest neighbors (NN), within a distance threshold. 44.3% of businesses have one neighbor next to it within 20 meters. The percentage rises to 95.6% if the distance threshold is set to 500 meters, a distance for a 6-minute walk. 5 Within this walking dis-tance, about 80% of businesses have at least 6 neighbors, and 66% have at least 10 neighbors.

O bservation 2. The average rating of a business is weakly pos-itively correlated with the average rating of its neighbors.
Before exploring a new place, we often receive advice on which region is famous for good food ( e.g., a few famous restaurants col-locating in that region), or advice on which region to avoid for shopping because the shops there are infamous for cheating. This phenomenon of  X  X hings of one kind come together X  is also reflected from the positive correlation between the ratings of businesses and their geographical neighbors.

We calculate the average rating of a business from all its user re-views. Hereafter, for easy presentation, we refer this average rating simply as the rating of a business or a business X  X  rating when the context is clear. Figure 2 plots the Pearson X  X  correlation coe ffi cient between a business X  X  rating and the average rating of its 1, 3, 6, and 10 nearest neighbors, at di ff erent distance thresholds from 20 to 2000 meters. For a given distance threshold, if a business has no neighbors within the distance, then this business is excluded from the computation. If a business has fewer than the number of nearest neighbors specified ( e.g., 10NN) within the distance threshold, then the ratings of all its nearest neighbors within the distance threshold are averaged. For reference, for each business participated in the computation within a distance threshold, we also randomly sample a business from the dataset (regardless of the distance between the two) and then compute the Pearson X  X  correlation between the two sets of ratings, labeled  X  X andom X  in the plot.

From Figure 2, we observe that the rating of a business is weakly positively correlated with the average rating of its nearest neigh-bor(s). Pearson X  X  correlation coe ffi cient is in the range of 0.109 to 0.173. The correlation is relatively stronger within a smaller distance ( e.g., 20 or 50 meters) and becomes stable for distance threshold of 500 meters or larger. In comparison, correlation coef-ficient between the ratings of the same set of businesses and their randomly selected counterparts is in the range of -0.002 to 0.002, i.e., no correlation, as expected.

We have two interpretations of the weak positive correlation be-tween ratings of businesses and their neighbors. First, the rating of a business should mainly depend on the intrinsic characteristics of the business ( e.g., quality of products / services), not its neigh-bors. Second, a business is not geographically independent from its neighbors. When a user visits one business, she has at least glanced over its neighbors if not visited them. These neighbors give her the sense of the surrounding environment of the business ( e.g., hygiene standard). Such extrinsic characteristics may a ff ect her view of the business, leading to the weak positive correlation. Based on the weak positive correlation, we expect more accurate business rat-ing prediction can be achieved by considering the influence of the geographical neighbors of a business.

O bservation 3. The weak positive correlation in ratings is inde-pendent of the categories of the businesses and / or their neighbors.
A business in Yelp is assigned one or more category labels ( e.g., restaurant, shopping). Plotted in Figure 3, the number of businesses in categories demonstrate a power-law like distribution, with a few categories each containing a large number of businesses and many small categories each has only one or two businesses. Restaurants , the largest category, covers nearly 40% of the 11 , 537 businesses in the dataset. Next, we study the 5 largest categories as representa-tive examples. They are: Restaurants (4 , 503), Shopping (1 , 681), Food (1 , 616), Beauty &amp; Spas (764), and Nightlife (640), where the numbers in parentheses indicate the number of businesses in each category.

For each of the 5 categories, we calculate the rating correla-tion between the businesses in the category and their neighbors, regardless of the categories of their neighbors because the neigh-bors here are defined geographically. The category-wise rating cor-relations with 1NN and 6NN are plotted in Figures 4(a) and 4(b) respectively. The lines labeled  X  X andom X , plotted for reference pur-pose, report the correlation between the ratings of businesses in any of the 5 categories and randomly selected businesses from the dataset (regardless of their categories and geographical distance). Shown in Figure 4(a), businesses in Beauty &amp; Spas demonstrate slightly stronger rating correlation with their 1NN compared with businesses in Nightlife and Shopping . When the number of nearest neighbors is enlarged to 6, this pattern becomes less apparent, par-ticularly when the distance threshold reaches 500 meters, plotted in Figure 4(b). In both Figures 4(a) and 4(b), weak positive correla-tion is observed for ratings of businesses in all 5 categories across all distance thresholds. 6
Figures 4(c) and 4(d) show the percentage of the nearest neigh-bors that are also in the same category. The two figures show very similar patterns: (i) Restaurants are more likely collocated with restaurants with about 50% chance that the neighbors of a restaurant are also restaurants; (ii) Beauty &amp; Spas on the other (d) Percentage of 6NN being in the same category hand is much more distinctive from their neighbors. Below 20% of their neighbors are also in the same category. With respect to Fig-ures 4(a) and 4(b), we argue that weak positive rating correlation between businesses and their neighbors is independent of whether the neighbors are in the same category.

In summary, the three observations made from the data suggest that geographical neighborhood has influences on the rating of a business. Next, we incorporate geographical neighborhood influ-ence into business rating prediction.
The problem of rating prediction has been well formulated in literature. We use r ui to denote the review rating that user u gives to item i ( i.e., a business). r ui is in the range of 1 to 5 stars with more stars indicating higher preference. Given the existing ratings made by m users to n items, the task is to predict the unknown rating  X  r if user u has not rated item i before. In the following, we first briefly introduce matrix factorization and then present our proposed model by incorporating various influences into the prediction. Table 2 lists the notations used in this paper.
Our proposed method is based on the latent factor model realized by matrix factorization. Through matrix factorization, each user and each item is associated with a f -dimensional vector, where f  X  min( m , n ). The inner product of a user vector p u  X  R and an item vector q i  X  R f  X  1 is used to approximate the user X  X  preference to the item (see [13] for a detailed introduction of matrix factorization). Accordingly, the predicted rating of user u to item i is computed using where p u and q i can be learned from the user-item rating matrix with known ratings. However, users may have certain degree of bi-
N i Set of geographical neighbors of item i
C i Set of categories item i belongs to
R i Set of words in item i  X  X  review
K Set of ( u , i ) pairs with known r ui ratings r ui ,  X  r ui Observed and predicted ratings of user u to item i  X  Mean of all known r ui ratings b u , b i Bias parameters for user u and item i , respectively p u Latent factors of user u q i Latent factors of item i for its intrinsic characteristics v i Latent factors of item i for its extrinsic characteristics d c Latent factors of category c q w Latent factors of review word w  X  i Normalized popularity of item i  X  i Popularity weighting parameter for item i  X  u , i Normalized geo-distance between user u and item i  X  u Geo-distance weighting parameter for user u ases: some users are more lenient and some are very strict about rat-ings. Similarly, items may also have some degree of biases because of location or branding for example. To achieve more accurate rat-ing prediction, Biased MF extends the basic matrix factorization by considering the biases, where  X  is the average rating of all known ratings; b u and b the user bias and item bias, respectively. Learning the unknown pa-rameters p u , q i , b u , and b i is an optimization problem to minimize the regularized squared error on the set of known ratings K . min In this equation,  X  1 and  X  2 are regularization parameters used to avoid overfitting. Both stochastic gradient descent (SGD) and al-ternating least squares (ALS) algorithms can be used to solve the optimization function and learn the parameters [12,13]. In this pa-per, we adopt SGD to learn the parameters following the algorithm presented in [12].
Based on our observations in Section 3.2, most businesses have neighbors within a short geographical distance, and more impor-tantly, the rating of a business is weakly positively correlated with the rating of its neighbors. These observations suggest that con-sidering the geographical neighborhood influence may improve the accuracy of business rating prediction.

In this paper, to model users X  rating behavior on businesses, we first assume that a user X  X  rating to a given business is determined by its intrinsic characteristics and the extrinsic characteristics of its geographical neighbors. For a business i , we use q i model its intrinsic and extrinsic characteristics, respectively. More specifically, q i models the intrinsic characteristics of a business ( e.g., taste of food and quality of service) observable by users who have interacted with the business. v i models the extrinsic char-acteristics of a business ( e.g., hygiene standard) in influencing its geographical neighbors observable by the  X  X ass-by X  visitors.
Let N i be the set of geographical neighbors of a business i , sat-isfying certain selection criteria ( e.g., the top-6 nearest neighbors). Let n  X  N i be a neighbor of business i . Incorporated with influence from geographical neighbors, the predicted rating is now computed with both q i and v n  X  X , shown in Equation 2. In above equation, parameter  X  1  X  [0 , 1] controls the importance of geographical neighborhood influence in business rating predic-tion, | X | denotes the cardinality of a set. Accordingly, the objective function is updated with regularization components for v n in Equation 6 in Table 3, where  X  3 is the newly introduced regular-ization parameter, similar to  X  1 and  X  2 .

Note that, by considering v n  X  X  in the prediction, Equation 2 par-tially addresses the cold-start problem for newly established busi-nesses that do not appear in training data. Although q i of a new business is empty, the v n  X  X  of its geographical neighbors are not empty if they appear in training data. Therefore Equation 2 can be applied to make rating prediction of an existing user to a newly established business by using p u , b u and v n  X  X .
Analyzed in Section 3.2, a business in Yelp may belong to one or more categories. The category of a business usually reflects the characteristics of a business, e.g., product / service o ff ered by the business or the way the business is conducted. Intuitively, users may use di ff erent criteria to evaluate businesses in di ff erent cat-egories. For example, the criteria commonly used for reviewing restaurant ( e.g., taste of food) cannot be used to review businesses in beauty &amp; spas category. Moreover, a recent study has also shown that POI recommendation achieves better accuracy by considering the categories of the POIs [16].

In our model, we introduce category latent factors to exploit busi-ness categories for more accurate business rating prediction. For a business category c , it is associated with a latent vector d Let C i be the set of categories a business i belongs to. By incor-porating the category influence, the predicted rating  X  r fined in Equation 3, where  X  2  X  [0 , 1] is a parameter that controls the importance of category influence in rating prediction. The ob-jective function is updated accordingly, see Equation 7 in Table 3.  X  r ui =  X  + b u + b i + p  X  u
In Yelp, when giving a rating to a business from 1 to 5 stars, the user usually writes a review. Typically, the review elaborates the reason behind the rating and partially reflects the characteris-tics of the business. Collectively, words in all reviews to a busi-ness provide a much better description about the business than the learned vector of  X  X atent X  factors. However, in order to make use of the review words in the prediction model, the review words have to be mapped to the same f -dimensional vector space. Similar to the topic level decomposition of tweets for tweet recommenda-tion in [2], we decompose the latent factors of a business q a combination of latent factors of review words. Let R i be the set of words that appear in business i  X  X  review, the decomposition is shown as follows, where q w denotes the latent factors of word With the decomposition, the predicted rating is now shown in Equa-tion 5. The objective function is shown in Equation 8 in Table 3.
Next, we discuss two features that have been studied in POI rec-ommendation, namely popularity and geographical distance . In Section 1, we argue that the key di ff erence between a business with other kind of items that have been studied in rating prediction is that a business physically exists at a geographical location. Al-though we argue that business rating prediction is di ff erent from POI recommendation, it remains interesting to investigate whether the features explored in POI recommendation are useful here.
Regional popularity is mentioned as one of the unique charac-teristics in LBSNs which distinguish POI recommendation from other recommendation tasks [15]. For example, businesses located in downtown area are likely to receive more visits than those in suburban. In the Yelp dataset, a business has check-in sets and re-views, both are indicators of business popularity. Note that, a user may write one review to a business but may check-in at the busi-ness multiple times. However, the Yelp dataset only provides the aggregated check-in numbers on hourly basis from Monday to Sun-day but not user-specific check-ins. Some of the businesses in the dataset do not have check-in sets. We therefore simply sum up the number of reviews and the number of check-ins of a business to be its popularity.

In POI recommendation, geographical distance is a major con-sideration because users tend to visit nearby POIs [25, 26]. With users X  review data, we estimate a user X  X   X  X ome location X  by using the recursive grid search algorithm proposed in [5]. Then the geo-graphical distance between a user and an unrated business can be easily calculated based on the estimated user location and the loca-tion of the business. b + b 2 i +  X  3 X b + b 2 i +  X  3 + / -+  X  2 b 2 u + b 2 i +  X  3 + / -+  X  2 b 2 u + b 2 i +  X  2 i +  X  2 u +  X  3
For simplicity, we model both popularity and geographical dis-tance as a rating bias z . In above equation,  X  i is the normalized popularity of item i by tak-ing the common logarithm of its raw popularity value;  X  u , i normalized distance between user u and business i by taking the common logarithm of the geographical distance. The two parame-ters  X  i and  X  u are the weighting parameters for business i and user u respectively; both are learned from the training data. With rating bias z , the predicted rating is shown in Equation 11.  X  r ui =  X  + b u + b i + z
Note that, we do not replace the user bias b u and item bias b by rating bias z . The reason is that the rating bias  X  i captures biases specific to popularity and geographical distance re-spectively, while b u and b i are used to capture bias from all un-known factors. The objective function considering both popularity and geographical distance is shown in Equation 9 in Table 3.
We now conduct experiments on the Yelp dataset to evaluate the proposed models and compare the proposed models with state-of-the-art baselines. Dataset . We use the Yelp dataset that has been studied in Sec-tion 3.1 in our experiments. The preprocessing of the dataset in our experiments includes removal of businesses and users having fewer than 10 reviews, stop words removal and stemming in reviews. Af-ter the preprocessing, we have 113 , 514 ratings by 3 , 965 users to 3 , 760 businesses. For each user, we sort her ratings in chronolog-ical order. The first 70% of ratings are used for training, and the remaining 30% for testing. As the result, we have 79 , 309 ratings to build the matrix factorization model for the prediction of the re-maining 34 , 205 ratings. The data sparsity is 99.47%.
 Evaluation Metric . We adopt two popular evaluation metrics, namely, Mean Absolute Error (MAE) and Root Mean Square Er-ror (RMSE). The smaller MAE or RMSE value means better rat-ing prediction accuracy. In the following equations, T is the set of user-item rating pairs ( u , i ) used in testing.
 Baseline Methods . We compare the proposed models with the fol-lowing 8 baseline methods. All these baseline methods are imple-mented by using the MyMediaLite library [9]. 1. Global Mean : this method predicts an unknown rating to be 2. User Mean : this method utilizes the mean rating of each user 3. Item Mean : this method uses the mean rating of each item to 4. User KNN : this method is the user-based collaborative filter-5. Item KNN : this method is the item-based collaborative fil-6. Biased MF : this is the MF model with user and item biases 7. SVD ++ : this model considers implicit feedback from users 8. Social MF : this model considers implicit social information Proposed Methods . We extended Biased MF to incorporate influ-ences from multiple factors: geographical neighborhood ( N ), busi-ness category ( C ), review content ( R ), business popularity ( P ), and geographical distance ( D ). The proposed methods are denoted us-ing the letters in parentheses to indicate the influences considered in each method. 9. N-MF : this method incorporates geographical neighborhood 10. NC-MF : this method incorporates both geographical neigh-11. NCR-MF : this model incorporates neighborhood, category 12. NCRP-MF : this model incorporates neighborhood, category, 13. NCRPD-MF : this model incorporates all factors: neighbor-We also evaluate another two methods: CRP-MF and CRPD-MF . These two methods do not incorporate geographical neighborhood influence but incorporate influences from other factors ( i.e., C , R , P , and D ) indicated by the method names.
 Parameter Setting . We performed 5-fold cross-validation on the training set to empirically set the hyperparameters. The number of latent factors f = 20; the relative importance of neighborhood and category influences are set to  X  1 = 0 . 8,  X  2 = 0 . 6; The regu-larization parameters:  X  1 = 0 . 8,  X  2 = 0 . 4,  X  3 = 0 . 6. The latent factors are learned by SGD with initial learning rate  X  = 0 . 008, which decreases by a factor of 0.9 after each iteration (see Ap-pendix A). The same parameters are used in all methods for fair comparison for all our proposed methods and the baseline methods whenever applicable. For example, the number of latent factors is also set to 20 in baseline methods Biased MF , SVD ++ and Social MF . For geographical neighborhood influence, by default, the pro-posed methods use the 6 nearest neighbors for each business. For all the methods based on matrix factorization, the reported results are averaged over 5 runs to avoid the impact of initialization in pa-rameter learning.
We first compare the proposed methods with baseline methods and then evaluate the two schemes for defining the set of geograph-ical neighbors for a business. Lastly, we evaluate the proposed methods with cold-start setting.
The prediction errors measured by MAE and RMSE of all meth-ods are reported in Table 4 with best results highlighted in boldface. We make four observations from the results.

First, incorporating geographical neighborhood influence into busi-ness rating prediction greatly reduces prediction errors measured Table 4: MAE and RMSE of all methods, the lower the better. by both MAE and RMSE. All the proposed methods with geo-graphical neighborhood influence ( i.e., methods 9 -13) outperform all baseline methods (methods 1 -8). The best prediction accuracy is achieved by NCRP-MF which considers geographical neighbor-hood (N), business category (C), review content (R), and business popularity (P). With geographical neighborhood influence alone, N-MF outperforms all baselines including state-of-the-art meth-ods SVD ++ and Social MF . This result suggests that geographi-cal neighbors are more e ff ective than the  X  X eighbors X  derived from rating-based similarity as in Social MF .

Second, compared with geographical neighborhood, further con-sidering factors like business category ( C ), review content ( R ), and business popularity ( P ) leads to relatively small additional reduc-tion in prediction errors. The geographical distance factor ( D ) ad-versely a ff ects business rating prediction accuracy. Method NCRPD-MF performs the worst among all methods with geographical neigh-borhood influence measured by both MAE and RMSE. This result suggests that the geographical distance factor introduces noise in the prediction model. Such result supports our earlier discussion that geographical distance between users and items is less relevant to the problem of business rating prediction.

Third, without incorporating geographical influence, CRP-MF performs poorer than most methods with geographical neighbor-hood influence including N-MF , NC-MF , NCR-MF , and NCRP-MF . The poorer performance of CRP-MF against N-MF suggests that the geographical neighborhood influence is more e ff ective than the combination of the three factors ( C , R , and P ) in business rating prediction. The much poorer performance of CRPD-MF in com-parison with CRP-MF again suggests the adverse e ff ect of geo-graphical distance factor ( D ). On the other hand, the e ff ectiveness of geographical neighborhood influence is also reflected from the better performance of NCRPD-MF compared with CRPD-MF .

Last, among the 8 baseline methods, SVD ++ and Social MF , the two state-of-the-art methods, perform the best evaluated by RMSE. By MAE measure, User KNN gives surprisingly low error rate and the two methods SVD ++ and Social MF remain among the three best methods.
Given a business, its geographical neighbors can be defined based on either a geographical distance threshold or the number of nearest neighbors. In this set of experiments, we evaluate the two schemes on their impact to the prediction error of the N-MF method. The (b) Neighbors by neighborhood size (MAE) (d) Neighbors by neighborhood size (RMSE) N-MF method is selected as the method for evaluation because it only considers the geographical neighborhood factor.
 Figures 5(a) and 5(c) respectively plot MAE and RMSE of the N-MF method by defining geographical neighbors with a distance threshold ranging from 20 to 2000 meters. Figures 5(b) and 5(d) respectively plot the MAE and RMSE of the method by taking the number of nearest neighbors ranging from 1 to 10. The y -axes of the two sets of figures are plotted in the same scale for easy com-parison. From the two sets of figures, either the distance threshold of 1000 meters or the top-6 nearest neighbors give the best pre-diction accuracy by considering both MAE and RMSE. Plotted in Figure 1, with a distance threshold of 1000 meters, more than 90% of businesses have at least 6 neighbors and about 84% of the busi-nesses have at least 10 neighbors. Because some businesses may have a large number of neighbors within 1000 meters, we choose to use 6 nearest neighbors mainly for minimizing computational cost. We have also evaluated the method by using at most 6 near-est neighbors within a 1000-meter distance threshold. However, poorer prediction accuracy was obtained compared with simply us-ing 6 nearest neighbors without a distance threshold.
Cold-start is a challenging issue in any recommender systems when there is no enough information about either users or items. We now evaluate the performance of the proposed methods in pre-dicting ratings by existing users to newly established businesses. Recall that in our data preprocessing (see Section 5.1), businesses and users with fewer than 10 reviews were removed. In this set of experiments, we try to predict the ratings by existing users in the training data to the businesses that were removed in data pre-processing. That is, from existing training data, we have the user vector of latent factors p u , but not the item vector q i  X  X ewly established X  businesses were not the training data. In total, there are 20 , 395 ratings made by 3 , 319 existing users to 6 , 939 new businesses. This collection of ratings will be used as test set.
Among all baseline methods, Global Mean and User Mean can be easily applied. Item Mean , User KNN and Item KNN cannot be applied as we assume that the newly established businesses have no reviews yet. Both Biased MF and SVD ++ are reduced to  X  + b because b i and q i are both unknown (see Equation 1). Social MF is not applicable here because it relies on similar items by some similarity functions. Among the proposed methods, both the latent factors for the extrinsic characteristics of geographical neighbors ( i.e., v n  X  X  of existing businesses) and business category ( i.e., d can be utilized in prediction. Here, we assume the category of the newly established business is known ( e.g., restaurant or bookstore). The prediction is made by Equation 3 after removing b i and q from the equation.

Reported in Table 5, the proposed method NC-MF achieves the best prediction accuracy by considering both geographical neigh-borhood and business category. Utilizing geographical influence alone, N-MF is the second best performing methods by both MAE and RMSE. Both User Mean and Biased MF are better than Global Mean with the former achieves better MAE and the latter achieves better RMSE. In summary, the proposed methods predict more ac-curate ratings for existing users to newly established businesses in cold-start setting.
To the best of our knowledge, this is the first study on geograph-ical neighborhood influence to users X  business rating behavior. We believe the observation that a business X  X  rating is weakly positively correlated with its geographical neighbors X  rating is an important one. Based on this observation, we model a business with two vec-tors of latent factors one for its intrinsic characteristics and the other for its extrinsic characteristics (or its influence to its geographical neighbors). In our experiments, we show that by incorporating ge-ographical neighborhood influence, the proposed methods outper-form state-of-the-art methods. Other factors like business category, popularity, and review content can further improve the rating pre-diction accuracy. Nevertheless, the geographical distance between a user and a business adversely a ff ects the prediction accuracy, al-though it is an important factor in POI recommendation and POI prediction. The incorporation of geographical neighborhood in-fluence also partially enables our methods to better handle cold-start situation, for rating prediction of newly established businesses based on both their geographical neighbors and business categories. As a part of our future work, we are interested in investigating the influence of geographical neighborhood in POI recommendation and sentiment analysis of business reviews. [1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis [2] K. Chen, T. Chen, G. Zheng, O. Jin, E. Yao, and Y. Yu. [3] C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused matrix [4] C. Cheng, H. Yang, M. R. Lyu, and I. King. Where you like [5] Z. Cheng, J. Caverlee, K. Lee, and D. Z. Sui. Exploring [6] E. Cho, S. A. Myers, and J. Leskovec. Friendship and [7] P. Cremonesi, Y. Koren, and R. Turrin. Performance of [8] M. Deshpande and G. Karypis. Item-based top-n [9] Z. Gantner, S. Rendle, C. Freudenthaler, and [10] R. Jin, J. Y. Chai, and L. Si. An automatic weighting scheme [11] N. Koenigstein, G. Dror, and Y. Koren. Yahoo! music [12] Y. Koren. Factorization meets the neighborhood: A [13] Y. Koren. Collaborative filtering with temporal dynamics. In [14] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization [15] B. Liu, Y. Fu, Z. Yao, and H. Xiong. Learning geographical [16] X. Liu, Y. Liu, K. Aberer, and C. Miao. Personalized [17] H. Ma. An experimental study on implicit social [18] S. Moghaddam, M. Jamali, and M. Ester. ETF: Extended [19] N. Natarajan, D. Shin, and I. S. Dhillon. Which app will you [20] A. Rae, V. Murdock, A. Popescu, and H. Bouchard. Mining [21] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based [22] H. Steck. Item popularity and recommendation accuracy. In [23] W. R. Tobler. A computer movie simulating urban growth in [24] D. Yang, T. Chen, W. Zhang, Q. Lu, and Y. Yu. Local [25] M. Ye, P. Yin, W.-C. Lee, and D.-L. Lee. Exploiting [26] Q. Yuan, G. Cong, Z. Ma, A. Sun, and N. M. Thalmann.
All the objective functions ( e.g., Equations 6, 7, 8, and 9) in the proposed models share the same form. Next, we detail the param-eter estimation for Equation 9 (where z =  X  i  X  i +  X  u  X  example using Stochastic Gradient Descent (SGD) algorithm [12]. Let e ui be the error associated with the prediction e ui The parameters are learned by moving in the opposite direction of the gradient with a learning rate  X  in an iterative manner. In our experiments, learning rate  X  is set to 0 . 008 in the first iteration and is decreased by a factor of 0.9 after each subsequent iteration.  X  w  X  R i : q w  X  q w +  X   X  e u i  X   X  n  X  N i : v n  X  v n +  X   X  e ui  X   X  1  X  c  X  C i : d c  X  d c +  X   X  e ui  X   X  2
