 been paid to attributes reduction and evaluation. As an important task for knowledge-based systems, its key problem is how to identify the most related subset to the given successful performance of this task, the reduction of data dimensions and the assumption space shall be achieved which would enable the algorithm to have quicker execution speed and higher efficiency. Attributes reduction and evaluation are also a we should investigate. Genetic algorithm differentiates itself from other searching problem of attributes searching. Another important factor in system design is how to heuristic method can evaluate the degree of association among attributes and measure the contribution of attributes (subsets) to cl assification. It can serve as the evaluation criterion for attributes reduction. 
This paper proposes a GA-CFS method by combining genetic algorithm with correlation-based evaluation. The proposed method solves not only the problem of searching efficiency caused by "combinatorial explosion" of attributes combination, but also the problem of correlation measure among attributes. Some researchers have implemented attributes reduction [1-3] using genetic mechanism without combining it with correlation-based feature reduction. The problem of how to find the (approx-devoted to in this paper. 
The remainder of this paper is organized as follows. The next section describes the searching strategies as well as the evaluating strategies of attributes reduction and its formalization. Then section 3 describes the genetic algorithm in brief. Section 4 focuses on the process of attributes reduction using GA-CFS based on the genetic algorithm and correlation-based evaluation. Section 5 verifies the performance of GA-CFS with the method of combining C4.5 algorithm with K-fold cross validation, section 6 concludes this paper and points out future work. subsets that have the most classifiable ability. In general, attributes reduction includes two parts: (1) searching strategy in the attr ibutes space; (2) evaluation strategy for the selected attributes subset. They are both the indispensable segments of the process. 2.1 Searching Strategy and Evaluation Strategy of Attributes Reduction Attributes reduction is a combination optimization problem. It has high complexity and requires an efficient searching algorith m. Each searching state can be mapped as a subset in the searching space for a searching problem. An n-dimensional data set has Searching strategies of attributes include: best first [4], forward reduction, stochastic searching, exhaustive searching, genetic algorithm [1, 2], ordering method, etc. 
From the viewpoint of an evaluation function, attributes evaluation figures out the have the highest scores as the optimal subset. The evaluation function directly different subsets will be formed. Generally, attributes evaluation methods include: principal component analysis, chi-mean square evaluation, etc. Attributes evaluation is the reduction problem of the evaluation function in a genetic algorithm. 2.2 Formalization of Attributes Reduction which the cardinal number is N (M  X  N). Where, M f represents the special attribute vector of attributes set M F while N f represents that of attributes set N F . The process of attributes reduction is the process of searching for optimal or approximate optimal M F . nature, the algorithm uses random genetic operators to generate several new solutions, eliminates the poorer, and keeps the better and promising ones. The information of the searching space. Since its effective use of historic information that makes every search moving forward according to the best direction, genetic algorithm is similar to not only a random searching approach, but also a directing random searching approach. 
Genetic algorithm can be formally defined as an 8-tuple: l is also a positive integer, which denotes the length of the symbol string (chromosome); 
Genetic algorithm presented by Holland initially adapted binary coding, that means } 1 , 0 { =  X  . But generally speaking, it can be expanded into any data structure. integer vector, Lisp expressions or neural networks. In this paper, we use binary-coded string to denote the attribute vector. The code  X 0 X  denotes that the represented attribute is not appeared in the search, while  X 1 X  denotes the opposite. The settings of genetic operators are given in section 4.2. 4.1 Reduction of Evaluation Method quality subset M F are highly correlated to class i C while the attributes themselves are irrelevant to each other. certain to have a correspondence to a high -correlated attribute. The acceptance degree while other attributes can not. The evaluation function CFS of the subset is defined as follows: attribute correlation average value. 
For successive value data, the relativity between attributes can be calculated as follows: value data. 
If one of the two attributes is successive and the other is discrete, the relativity can be calculated as follows: 
If both attributes are discrete, the relativity can be calculated as follows: 
According to the above formul ations, correlation of the attributes can be calculated reduction criterion in the next step of the genetic searching until the final criterion of the algorithm is met. 4.2 Settings of Genetic Operator operations need to be set: 1. Initialization of the population. Select N random initial points to form a population. 
The amount N of the individuals in a population is the population size. Each chromosome of the population is coded by binary string. Chromosomes denote the optimized parameters. Each initial individual denotes the initial solution. roulette wheel. The reduction should embody the principle of  X  X urvival of the fittest X . On the basis of the fitness value of each individual, the best individual can be selected as the next generation population for repropagation. 
Thus searching can be effective in the solution space, meanwhile decrease the destruction to the effective scheme. Crossover is a mechanism of the information exchange between two chromosomes. 4. Mutation. According to the given mutation probability m p , we can select some individuals randomly from the population while make the mutation calculation to the selected individuals in correspondence with certain strategy. The mutation calculation is an important factor to enlarge the population diversities. It enhances the ability for genetic algorithm to find the optimal solutions. 4.3 Evaluation Method of Attribution Reduction In order to evaluate the performance of the subset of attributes M F which is selected by the GA-CFS method that combines GA with correlation-based attributes reduction, this paper uses the method which combines C4.5 algorithm [6] with k-fold cross validation to verify the classification performance of M F . Meanwhile, we compare the classification performance with that of the original subset N F . 
C4.5 algorithm is the improvement of ID3 [5]. It can deal with the following problems: the attributes of successive value, the deficiency and deterioration of attribute value, pruning of decision tree and the creation of rules, etc. Its core concept is to adapt the information-entropy-based sorting strategy of attributes. 
K-fold cross validation is also called rotation estimation. It divides the whole set of case library (S) into k non-overlap and equal subsets (S 1  X  S 2  X   X  X  X   X  S k ) randomly. obtained from the average value by calculating the testing precision for k times separately: experiment described next in this paper, K =10 [9]. In order to evaluate the validation of GA-based attributes reduction, we use GA-CFS with correlation-based heuristic before attributes reduction. related performance values of subset, we can review the performances of the algorithm proposed in this paper. Our GA-CFS approach is implemented in Java and experiments were conducted on a Pentium(R) 4 CPU 2.80GHz with 256MB RAM running under Windows 2000. In the experiment, we select 4 data sets from UCI ML database repository from the University of California. The detailed information is given in Table 1. 
Parametric setting of genetic algorithm is as follows: population scale N=20, crossover probability Pc=0.66, mutation proba bility Pm=0.033, the largest number of iteration is 20. 
Use C4.5 algorithm to compute the classification precision before and after classification precision. Obtain computing results by averaging after executing 10 times. The experimental results are given in Table 2 and Table 3. 
The experimental results indicate that using GA-CFS to select subset, concerning the reduction of attributes, can reduce attributes in the 4 data sets by 44.44% at least, and by 86.67% at most as show in Table 2. So the reduction of dimensions is attributes reduction as shown in Table 3, we can see that the accuracy of anneal data set reduces less than 1%, breast_cancer and sick dataset reduce about 1% and arrhythmia data set even increases. 
By analyzing the data set above we can conclude, by comparing with the original about 1% only, just as shown in Fig. 1 
Hence, the proposed GA-CFS algorithm has achieved much better outcomes. It classification precision. Attributes reduction and evaluation is an important task for knowledge-based systems. They can identify the most related attributes to the problems of the system, clear away complexity of systems, and improve the performance of systems. 
We have proposed a GA-CFS method to guide the evolution of systems until it finds an approximate optimal subset. We have implemented the original searching approach using the genetic operator that introduces a correlation-based subset evaluation method as the evaluation function. By using C4.5 algorithm combined with k-fold cross validation to evaluate its performance, we have concluded that the GA-CFS method can identify the most related subset to classify and predict with reducing the representation space of the attributes dramatically whilst hardly decreasing classification precision. 
In the future, we would like to do some benchmark work on attributes reduction. It relates to these theory and techniques, such as Rough Set (RS), Prime Component Analysis (PCA), entropy-based attributes reduction, etc. We believe that it would benefit the use of the various attributes reduction methods. 
