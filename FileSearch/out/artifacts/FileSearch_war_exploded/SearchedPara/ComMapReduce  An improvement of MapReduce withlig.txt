 1. Introduction in many companies [4  X  7] and research communities [8  X  14].
 efficiency of MapReduce.
 simple and efficient lightweight communication mechanisms, the performance of MapReduce can be improved.
In this paper, we propose a new framework named ComMapReduce to improve the MapReduce framework. ComMapRedcue  X  A framework with simple lightweight communication mechanisms, named ComMapReduce, is proposed. The Mappers and of the original MapReduce framework.  X 
Postpositive, are proposed to obtain the shared information and effectively process big data applications.  X 
The implementations of three applications on ComMapReduce, k NN, skyline and join, are given to demonstrate the wide applicability of the ComMapReduce framework.  X 
Extensive experiments are conducted to evaluate our ComMapReduce framework using many synthetic datasets. The experimental results demonstrate that ComMapReduce outperforms the original MapReduce in all metrics. performance of our proposed framework.
 2. ComMapReduce framework In this section, after analyzing MapReduce framework in depth in Section 1 , we propose our ComMapReduce framework in
Section 2 . The availability and scalability of ComMapReduce are analyzed in Section 3 . 2.1. MapReduce analysis in-depth
MapReduce is a parallel programming framework processing the large scale datasets on clusters with numerous commodity the final outputs written into the Distributed File System.
 Example 1. Simple top-k query
The initial input dataset has 15 data from  X  1  X  to  X  15  X   X  14  X  and  X  15  X  are the final results. user-defined Map function in parallel. For example, the first Mapper reads data emit the final results of this top-2 query.
 the shuffle phase. Therefore, Combiner cannot play an efficient role in the global data compression. are written into their disks, if the Mappers can first receive data intermediate data with simple communication mechanisms, the output of Mappers can be decreased drastically. The input of Reducer can be decreased from data  X  15  X  ,  X  14  X  ,  X  proposed. 2.2. ComMapReduce overview
For optimizing MapReduce framework, we propose ComMapReduce, an efficient lightweight communication framework extending MapReduce by generating the shared information to prune more unpromising data for big data applications.
Fig. 3 shows the architecture of ComMapReduce framework. Our ComMap Reduce framework inherits the basic MapReduce framework and takes Hadoop Distributed File System (HDFS), communicate with the Mappers and Reducers with simple lightweight communication mechanisms. The Coordinator node can used in a wide application areas.
 In MapReduce, the users need to implement Map interface and Reduce interface to implement a MapReduce application. 2.3. ComMapReduce analysis 2.3.1. ComMapReduce Availability
The availability of ComMapReduce is dependent on MapReduce. The recovery strategies of the Master node and the Slave
ComMapReduce has the same availability as MapReduce. 2.3.2. ComMapReduce scalability scalability of the Coordinator node from two aspects: time complexity and memory usage. affected by the Coordinator node.  X  complexity of the Master node receiving Map task requirements of locating data chunks.  X 
Second, the time complexity of the Coordinator node identifying the global shared information is the same as the time complexity of the Master node identifying the data chunk locations to Map tasks.  X  complexity of the Master node sending the locations of data chunks to Map tasks. Coordinator node from the aspect of memory usage.

MapReduce. 3. ComMapReduce Communication Strategies Eager and Hybrid, and two optimization communication strategies, Prepositive and Postpositive. Example 2. Complex top-k query
Top-5 query returns the 5 biggest data as the final outputs, 3.1. Lazy Communication Strategy input than the Reducers in MapReduce.

Fig. 5 shows the complex top-k query processing on ComMapReduce with LCS. Each Mapper processes its own data and local shared information of Mappers,  X  37  X  ,  X  16  X  ,  X  19
LCS filters the intermediate data which are not the final results largely. 3.2. Eager Communication Strategy writing into the local disks. This course still repeats until all the Mappers on the platform complete. mentations of the first and the second Mapper. Step 1. After the first Mapper is completed, it sends data as its shared information . Step 2. After receiving  X  37  X  the first Mapper. Step 3. The final intermediate data of the first Mapper are data
The second Mapper sends its local shared information  X  16 the intermediate data of the second Mapper are smaller than showing in Fig. 6 . This course continues until the last Mapper is completed and then generates the final results. data. 3.3. Hybrid Communication Strategy
Coordinator node waits for a preassigned a period of time ( t information to the Coordinator node and receives the global shared information immediately. are two completed Mappers in each preassigned a period of time t and the second t w . Step 1. The first Mapper generates  X  receiving  X  37  X  , the Coordinator node waits for the second Mapper completing in the first t  X  16  X  instead of generating a global shared information in time. Step 2. After receiving
Mapper filter their intermediate data by  X  37  X  . Step 4. In the second t local shared information  X  19  X  and  X  39  X  to the Coordinator node. Step 5. After receiving  X  19 and does not need to wait for a long time to generate a better global shared information . need to wait for a t w to send the global shared information . So, we can choose a smaller t information is not stable. The Coordinator node should wait for a longer t more suitable global shared information . and Reducers on the platform. When there is no new shared information during t maximum of T and n m t wold . When there is new shared information during t m t wold and m  X  T . Therefore, we can identify an optimal period time t 4. Optimization communication strategy together to further improve the performance of ComMapReduce. 4.0.1. Prepositive Optimization Strategy also decreases.
  X  37  X  with HCS after the first and the second Mapper complete. Step 4. The other three unprocessed Mappers retrieve Mappers send their intermediate data to the Reducer only with PreOS not using any communication strategy above. 4.0.2. Postpositive Optimization Strategy again. Therefore, the Reducers process the input data after filtering to enhance the performance of ComMapReduce. node generates a temporary global shared information  X  37
Reducer retrieves the temporary global shared information
Reducer. 5. Typical applications of ComMapReduce
ComMapReduce can effectively prune the unpromising intermediate data, especially when the users are interested in a join. 5.1. kNN query processing similarity function, a k NN query returns the k data ( k  X  function. ComMapReduce can effectively process big data k NN query with any communization strategy of ComMapReduce in example.
 four Mappers. Suppose there are also two completed Mappers in a t are smaller than unit 3, data (10) and (11). In the second t unpromising data (13). In Reduce phase, the Reducer generates the final results of this k NN query. 5.2. Skyline query processing Communication Strategy.
 Monitoring Algorithm (SWSMA) [17] to evaluate the filtering ability of the skyline points. into four splits and processed by four Mappers. We still suppose that there are two completed Mappers in one t shared information and sends it to the completed Mappers in the first t are all filtered. The same course is applied to the second t skyline query. 5.3. Join query processing emerges as an important application of data analysis done by MapReduce. MapReduce can be used to compare statistical
There are several research achievements on the join query applications by MapReduce [8 framework can process join query.
Two join tables are shown in Fig. 14 with the join attribute tag to make sure the source table of one b key , value &gt; pair, where tag 1 presents the data from table R from table R 2 . Therefore, the intermediate data of Mappers are extracted as
Fig. 15 by HCS of ComMapReduce. In Map phase, after processing table R process table R 1 send their local shared information (join attribute merges the local shared information and gains the global shared information , table T ( n
The Coordinator node restarts the Map task queue and begins to process table R ( n Reducer generates the final results of this equi-join between the two tables. attributes, n 1 , n 2 , and 6 data records, so its join ratio is 2 same, we scan the smaller size table first.
 6. Experiments compare with MapReduce (MR).
 need to evaluate this communication strategy. 6.1. Experimental setup  X  10 G. The default number of k value of top-k query is 1000.  X   X  ranging from 0.2 G to 0.4 G. The default number of data dimensions of skyline query is 4.  X  20 G. The default attribute distribution proportion is 5%, with a range of 1%, 5%, 10%, 65%, and 75%. 6.2. Experiments of top-k query Fig. 16 (d).
 filter their unpromising data in the initial phase by PreOS, so its running time is shorter than the others. Reducer input records of ComMapReduce are both better than MapReduce.

Table 1 shows the performance of changing t w of HCS processing top-k query. When setting larger t time of the shared information adds running time. When setting smaller t receiving the share information . So, a suitable t w is important to the executions of big data applications. 6.3. Experiments of kNN Query filtering numerous unpromising data.
 number of Reducer input records is much fewer than MapReduce showing the efficient filtering ability of ComMapReduce. records of ComMapReduce are much superior to MapReduce.
 6.4. Experiments of Skyline Query to compare with the other strategies. number of Reducer input records increase accordingly. ComMapReduce is more optimal to MapReduce under different data accordingly, the performance of ComMapReduce is still better than MapReduce. small, but our ComMapReduce is better than MapReduce.
 number of Reducer input records of MapReduce keeps a constant. 6.5. Experiments of join query also becomes longer. Our ComMapReduce can filter the unpromising attribute data, so the performance of ComMapReduce can see that ComMapReduce has nice scalability.

Fig. 27 shows the performance of changing the order of the two tables. MapReduce keeps the same performance under
Therefore, the order of the two tables is important to enhance the performance of ComMapReduce framework. 7. Related work famous open source implementation of MapReduce, where HDFS, Hadoop MapReduce, HBase [7] and Zookeeper the implementations of Google's GFS [16], MapReduce [3], Big Table [22] and Chubby [23]. language and programming interfaces. ComMapReduce enhances the efficiency of MapReduce with lightweight communication mechanisms to obtain the shared information .

The research of query processing has become a focus of cloud computing and distributed environments [25 query.
 not to analyze all the join algorithms in detail. 8. Conclusions
MapReduce is a parallel programming framework processing the large scale datasets on clusters with numerous com-
ComMapReduce. ComMapReduce is an improved version of MapReduce framework with lightweight communication mechanisms, want to identify more optimized mechanisms of choosing the shared information according to different applications. Acknowledgment
This research was partially supported by the National Natural Science Foundation of China under Grant Nos. 60933001,
Program under Grant No. 2012AA011004, the Public Science and Technology Research Funds Projects of Ocean Grant No. 201105033, and the Fundamental Research Funds for the Central Universities under Grant No. N110404009.
References
