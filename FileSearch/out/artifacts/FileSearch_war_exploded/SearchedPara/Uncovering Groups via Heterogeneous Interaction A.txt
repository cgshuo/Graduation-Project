 The recent boom of online social networking sites (e.g., Del.icio.us, Flickr, YouTube, Facebook, MySpace, Twit-ter, etc.) facilitate human beings to interact with each other more conveniently than ever. It enables traditional social network analysis from hundreds of subjects to hundreds of thousands, and even more. With the readily availability of large-scale interaction networks in social media, it is gaining increasing attentions from a variety of disciplines to study the modeling and prediction of human collective behavior, including sociology, anthropology, economics, epidemics, business marketing, and behavioral science.

One fundamental task in social network analysis to under-stand human collective behavio r is to identify actors X  social positions or cohesive subgroups (a.k.a. communities) whose group members interact with each other more frequently than those outside the group [1]. This group information can be utilized for post-analysis or other related tasks such as visualization [2], group evolution [3], [4] or detecting stable clusters across temporal changes [5], group formation [6], The interaction can also be noisy since it is relatively much easier to get connected to another user in social media than in the physical world. No wonder some users have thousands of online friends whereas this is hardly true in reality. For instance, one user in Flickr connects to more than 19,000 friends 2 . For this kind of users, it is really fuzzy to mine the real community he X  X  involved in given the friend network alone. On the other hand, a substantial number of users in the network might have only one or two contacts. With this noisy and highly imbalanced interactions, relying on one type of interaction alone might miss the true user community subscription. Instead, integrating assorted forms of interaction information can compensate the incomplete information at each dimension as well as reducing the noise and obtaining a more reliable community structure.

Intuitively, with a multi-dimensional network, one can use richer information to infer more accurate latent community structures among actors. However, idiosyncratic personali-ties lead to varied local correlations between dimensions. Some people interact with other members within the same group in one form of activity consistently, but may be inactive in another. It thus becomes a challenge to identify groups in multi-dimensional networks as we have to fuse the information from all the dimensions for joint analysis.
In this work, we first review modularity maximiza-tion [11], [12], a recently developed measure to quantify community partitions in social networks. We discuss its application in one-dimensional networks, and then introduce simple strategies to extend modularity maximization from one-dimensional (1-D) networks to multi-dimensional (M-D) networks. Since the straightforward extensions are po-tentially sensitive to noise, we propose a two-phase strat-egy to handle community detection in multi-dimensional networks. We first extract potential structural features from each dimension via modularity analysis. In the second phase, we concatenate these features to find groups. Typically, a real-world network does not have full information for the ground truth about the group membership. So a novel cross-dimension validation procedure is proposed to compare the clustering results obtained from different approaches. Our experiments on both synthetic and real-world network data validate the superiority of our proposed approach. Moreover, our approach can be easily paralleled and thus applicable for large-scale networks.

In this section, we briefly review the concept of modu-larity in the context of 1-D networks. In large-scale social networks, three patterns are frequently observed [13]: 1) small-world phenomenon, i.e., the distance among any pair of nodes in a network is small; 2) scale-free property, or alternatively, the node degree in a network follows a and a rank-one matrix ( dd T / 2 m ) , the multiplication of matrix B and a vector x can be calculated as: The same trick can be applied to any structured matrix similar to B (a sparse matrix plus low-rank update). This strategy is employed later in our baseline approaches as well.
The degree of freedom of k clusters is k  X  1 ,sowe can compute the top k  X  1 eigenvectors to form a low-dimensional embedding of the interaction network into a Euclidean space. Then a post-pr ocessing optimization step like k-means can be applied to find out a discrete community assignment [14].

Occasionally, interactions are weighted rather than boolean. It is trivial to extend modularity to handle weighted networks. Instead of counting the number of edges, we can set the degree d i of one node v i and the total number of degrees 2 m in Eq. (3) as follows:
In the previous section, we have reviewed the scheme of modularity maximization to i dentify communities in 1-D networks. Here, we extend the modularity analysis to multi-dimensional networks. A d -dimensional network is represented as A i represents the interaction among actors in the i -th di-mension satisfying where n is the total number of actors involved in the network. Here, we concentrate on symmetric networks 3 .
In a multi-dimensional network, the interactions of actors are represented in various forms. In certain scenarios, a latent community structure exists among these actors, which ex-plains these interactions. The goal of this work is to infer the shared latent community structure among the actors given a multi-dimensional network . In particular, we attempt to find out a community assignment such that Q i is maximized for i =1 ,  X  X  X  ,d . Different extensions following this general criterion are derived as presented below.
 A. Average Modularity Maximization (AMM)
A simple strategy to handle a multi-dimensional network is to treat it as single-dimensional. One straightforward As shown in Figure 1, it consists of two steps: structural feature extraction and cross-dimension integration.
 A. Structural Feature Extraction
Structural features are the network-extracted dimensions that are indicative of community structure. Recall that in Section II, to maximize the modularity, we compute a low-dimensional embedding using the top eigenvectors of the modularity matrix. In other words, those selected eigenvectors represent possible community partitions. Thus, the eigenvectors can be treated as the important structural features extracted from the network.

One concern with previous AMM and TMM is that they are not robust to noisy dimensions of a network. This motivates us to consider denoising each dimension of the network first. Since those eigenvectors with negative or small eigenvalues contribute marginally to the modularity and are very likely to be noise, they should be abandoned. For a multi-dimensional network, we can extract social features from each dimension of the network. Only those eigenvectors with a positive eigenvalue should be kept. We can also retain just some top-ranking community indicators to reduce noise.
 B. Cross-Dimension Integration
Assuming a latent community structure is shared across dimensions in a multi-dimensional network, it is expected that the extracted structural features should be similar. However, the features based on modularity maximization are not unique. Dissimilar structural features do not suggest that the corresponding community structures are drastically different. Let S be the top-eigenvectors that maximize Q , and V an orthonormal matrix such that It can be verified that SV also maximize Q : Essentially, SV and S are equivalent under an orthogonal transformation. In the simplest case, S =  X  S is also a valid solution. Instead, we expect the structural features of different dimensions to be highly correlated after transfor-mation. To capture the correlations between multiple sets of variables, (generalized) canonical correlation analysis (CCA) [16], [17], is the standard statistical technique. CCA attempts to find a transformation for each set of variables such that the pairwise correlations ar e maximized. Here we briefly illustrate one scheme of generalized CCA which turns out to equal to principal component analysis (PCA) in our specific case. Algorithm: Principal Modularity Maximization 1. Compute top eigenvectors of the modularity matrix 2. Select the vectors with positive eigenvalues as S i ; 3. Compute slim SVD of X =[ S 1 ,S 2 ,  X  X  X  S d ]= UDV T ; 4. Obtain lower-dimensional embedding U = U (: ,k  X  1) ; 5. Normalize the rows of U to unit length; 6. Calculate the cluster idx with k-means on U .

Recall that our structural features extracted from each dimension is essentially the top eigenvectors of the modularity matrix satisfying S T i S i = I . Thus, matrix diag ( C 11 ,C 22 ,  X  X  X  ,C dd ) in Eq. (10) becomes an identity matrix. Hence w =[ w 1 ,w 2 ,  X  X  X  ,w d ] T corresponds the top eigenvectors of the full covariance matrix in Eq. (9), which is equivalent to PCA applied to data of the following form: To compute the ( k  X  1) -dimension embedding, we just need to project the above data onto the top ( k  X  1) principal vectors. Suppose X = UDV T is the SVD of X , it follows that the top ( k  X  1) vectors of U are the lower-dimensional embedding.

The detailed algorithm is summarized in Figure 2. In summary, we first extract structural features from each dimension of the network via modularity maximization; then PCA is applied on the concatenated data as in Eq. (11) to select the top eigenvectors. Thus, we name our approach as Principal Modularity Maximization (PMM). After projecting the data onto the principal vectors, we obtain a lower-dimensional embedding which captures the principal pattern across all the dimensions of the network. Then we can perform k-means on this embedding to find out the discrete community assignment.

In this section, we evaluate and compare different strate-gies applied to multi-dimensional networks. Typically, a real-world network does not provide the ground truth in-formation of community membership, so we first resort to synthetic data to conduct some controlled experiments. The synthetic data has 3 clusters, with each having 50, 100, 200 members respectively. There are 4 dimensions of interactions among these 350 social actors. For each dimension, group members connect with each other follow-ing a random generated within-gr oup interaction probability. The interaction probability differs with respect to groups at distinct dimensions. After that, we add some noise to 0 to 20) to the interaction matrix of the second dimension. Note that after this change, the performance of using the second dimension alone is decreasing from 0.5 to 0.1. That is, this dimension actually does not help identify the latent structure. With such a dominant dimension, both AMM and TMM fail. On the contrary, our proposed PMM still achieves reasonable good performance. This implies that PMM is more robust to noisy dimensions in multi-dimensional networks.

Figure 4 just shows one example. We regenerate 100 different synthetic data sets and report the average perfor-mance of each method plus its standard deviation in Table I. Clearly, multi-dimensional outperforms single-dimensional community detection method with lower variance. Due to the randomness of each run, it is not surprising that single-dimensional method shows larger variance. Among the three multi-dimensional modular ity maximization strategies, PMM, with lowest variance, outperforms the other two and is more stable.

In the previous section, we compare different strategies on synthetic data with clear ground truth information. Here, we examine our approach on real-world social media. A big challenge for evaluation is that the community membership information is often unknown in reality. To manually verify and label the community me mbership for each user is acceptable for a small network but hardly can it scale to large online social networks. To address this issue, we first describe a cross-dimension network validation procedure following the idea of cross validation as in conventional data mining. After that, the detail of the data and experiment results are presented.
 A. Cross-Dimension Network Validation
Since a latent community structure is shared across dif-ferent dimensions, a good community structure extracted from some dimensions should match the interaction at other dimensions. Akin to cross validation, we can perform cross-dimension network validation as follows: Given a multi-dimensional network Net = { A i | 1  X  i  X  d } , we can use d  X  1 dimensions for training and the remaining one as test data. That is, we learn a community structure from d  X  1 dimensions of the network. Based on the obtained two unidirectional interactions: Essentially, if two social actors both subscribe to the same set of users, it is likely that they are similar and share the same community; On the other hand, if two are referred by the same set of actors, their similarity tends to be higher than that of random pairs. This is similar to the two roles of hub and authority of web pages as mentioned in [19]. It is also adopted for semi-supervised learning on directed graphs [20].

To utilize all aspects of information in our collected data, we construct a 5-dimensional network: A : contact network: the contact network among those A : co-contact network: two active users are connected A : co-subscription network: the connection between two A : co-subscribed network: two users are connected if they A : favorite network: two users are connected if they share The interactions in all dimensions are weighted 8 .TableII shows the connection density of each dimension. Contact dimension is the most sparse one, while the other dimen-sions, due to the construction, are denser. Figure 5 shows the degree distribution in contacts network and favorite network. Both follow a power law pattern as expected.
 C. Comparative Study
AMM, TMM and PMM as well as single-dimensional modularity maximization methods are compared. We cluster the active users involved in the network into different num-ber of communities ranging from 10 to 100. The clustering performance of single-dimensional and multi-dimensional methods when k =20 , 40 and 60 are presented in Tables III-V. We omit the detailed results for other cases as a similar trend is observed. In these tables, the rows represent methods and the columns denote the dimensions used as test data. The bold face denotes the optimal performance in each column. Note that in our cross-dimension network validation procedure, the test dimension is not available during training, multiplies. This is partly due to the resolution limit of modularity [22]. It is shown that modularity measure favors network partitions with groups of modules combined into larger communities, which explains the decay of modularity with respect to increasing number of modules in the ex-periment. However, here we focus on the comparison of different methods and the number of communities is fixed for all methods. The resolution limit of modularity does not invalidate the conclusions about the superiority of different methods.
 D. Weighted AMM &amp; TMM
AMM and TMM both treat the interaction of each di-mension equivalently. If one dimension X  X  community struc-ture is more prominent, it seems reasonable to trust that dimension more, which asks for a weighted summation of the interaction or modularity. Since modularity calibrates the community effect of a network, one hypothesis is that whether we can use the modularity at each dimension as a guide to do the weighted average.

Let Q i denotes the modularity computed for each dimen-sion. For weighted AMM, the average interaction matrix in Eq. (4) becomes In a similar vein, we compute the eigenvectors of the following matrix for weighted TMM:
Figure 7 shows the results with different weights associ-ated with each dimension as stated in Eq. 14) and (15). The weighted extension helps for AMM but does not help for TMM. It requires more insightful understanding upon the based on multiple clustering results, which are prepared via feature or instance sampling or disparate clustering algorithms. A similar idea is applied to community detection in social networks [29]. A small portion of connections between nodes are randomly removed before each run, leading to multiple different clustering results. Those clus-ters occurring repeatedly ar e considered more stable, and are deemed to reflect the natural communities in reality. However, all the cluster ensemble methods concentrate on either attribute-based data or one-dimensional networks.
Another related field is multi-view clustering. Bickel and Scheffere [30] propose co-EM and an extension of k-means and hierarchical clus tering to handle data with two conditional independent views. Sa [31] creates a bipartite based on the two views and tries to minimize the disagree-ment. Different spectral frameworks with multiple views are studied in [32] and [33]. The former defines a weighted mixture of random walk over each view to identify com-munities. The latter assumes clustering membership of each view is provided and finds an optimal community pattern via minimizing the divergence of the transformed optimal pattern and the community membership of each view. As for real-world social networks, one striking observation is that spectral clustering always finds tight and small-scale but al-most trivial communities (say, the community is connecting to the remaining network via one edge) [34]. Modularity maximization, on the other hand, tends to find modules composed of small-scale communities [22]. A comparison between spectral clustering and modularity maximization within a large-scale multi-dimensional network is worthy of future work.

Some theoretical analysis of multi-view clustering via canonical correlation analysis is presented in [35]. It shows that under the assumption that the views are uncorrelated given the cluster label, a much weaker condition is required for CCA to separate clusters successfully. But the conclusion is based on two views with each being attributes. How to generalize the theoretical result to networks of multiple heterogeneous interactions requires further research.
Unsupervised multiple kernel learning [36] is relevant if we deem each dimension of the network as a similarity or kernel matrix. Multiple kernel learning aims to find a combination of kernels to optimize for classification or clustering. Unfortunately, its limited scalability hinders its application even to a medium-size network.

Multi-dimensional networks commonly exist in many so-cial networking sites, reflecting diverse individual activities. In this work, we propose to detect the latent communal struc-ture in a multi-dimensional network. We formally describe the community detection problem in multi-dimensional networks and discuss two straightforward extensions of
