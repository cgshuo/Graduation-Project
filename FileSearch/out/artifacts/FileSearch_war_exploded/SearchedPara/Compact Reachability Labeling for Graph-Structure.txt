
Testing reachability between nodes in a graph is a well-known problem with many important applications, including knowledge representation, program analysis, and more recently, biological and ontology databases inferencing as well as XML query processing. Various approaches have been proposed to encode graph reacha-bility information using node labeling schemes, but most existing schemes only work well for specific types of graphs. In this paper, we propose a novel approach, HLSS( H ierarchical L abeling of S ub-S tructures), which identifies different types of substructures within a graph and encodes them using techniques suitable to the charac-teristics of each of them. We implement HLSS with an efficient two-phase algorithm, where the first phase identifies and encodes strongly connected components as well as tree substructures, and the second phase encodes the remaining reachability relationships by compressing dense rectangular submatrices in the transitive clo-sure matrix. For the important subproblem of finding densest sub-matrices, we demonstrate the hardness of the problem and propose several practical algorithms. Experiments show that HLSS handles different types of graphs well, while existing approaches fall prey to graphs with substructures they are not designed to handle. Categories and Subject Descriptors: H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing General Terms: Algorithms, Design, Performance Keywords: graph reachability labeling
Consider a directed graph G = ( V, E ) . Graph reachability is the following decision problem: Given two nodes u and v in there a path from u to v ? If the answer is yes, we say that reach v , or u  X   X  v .

Graph reachability has been a well-known problem with many traditional applications, e.g., testing concept subsumption in knowl-edge representation systems; and reasoning about inheritance in compiler design for object-oriented programming languages. Re-cently, the interest in graph reachability work has been rekindled by new applications of graph-structured databases. There are sev-eral well-known projects in bioinformatics, including the Biopath-ways Graph Data Manager [11] and the BioCyc project [18]. They Copyright 2005 ACM 1-59593-140-6/05/0010 ... $ 5.00. model data such as protein interactions, metabolic pathways and gene regulatory networks as directed graphs. Nodes in them rep-resent entities such as compounds, promoters and proteins whereas edges specify how entities are related. In these projects, researchers are interested in reachability questions such as whether a reactant u might indirectly activate or inhibit protein v through some chain of reactions. In the Semantic Web, two key technologies RDF and OWL are designed to capture graph data. Reasoning and subsump-tion query on them are both reachability queries. In addition, al-though XML is generally modelled as a tree, there exist many XML applications where cross-reference edges (through IDREF/ID) are treated as first-class citizens [16, 15, 7], making the data graph-structured. In this case, the ancestor/descendant axis  X  XML query is an instance of graph reachability query. Finally, the reachability query is also a basic building block of other types of graph queries such as subgraph isomorphism. Efficient support for reachability testing is crucial since it might be invoked heavily for large data and complex queries.

The well-known single-source shortest path algorithm can be used to answer reachability queries. However, the algorithm has a high complexity of O ( | E | ) , making it infeasible for efficient query processing. On the other extreme, we can precompute and store the transitive closure of the graph. Reachability queries can then be answered with constant-time matrix lookups. However, the space requirement is O ( | V | 2 ) , making it infeasible for large graphs.
If we only consider reachability in trees (or forests), interval la-beling is a nice solution that takes linear space and supports reach-ability queries in constant time. This approach can be dated back to the 1980 X  X  [10], and has been extensively applied to XML query processing in recent years (e.g., [20, 3, 4]). It labels each node in the tree by an interval [ start ( u ) , end ( u )] that is incremented whenever the traversal enters or leaves a node; start ( u ) and end ( u ) are assigned the value of the counter when the interval labeling has the following property: Given two tree nodes and v , u  X   X  v iff [ start ( u ) , end ( u )]  X  [ start ( v ) , end ( v )] reachability can be verified in constant time. Unfortunately, this approach is not directly applicable to graphs.

Labeling a general graph to support efficient reachability queries is a hard problem. Cohen et al. [9] has shown that there exist graphs for which any reachability labeling scheme would require O ( | V | X | E | 1 / 2 ) . Still, a variety of labeling schemes have been proposed, and we survey them in Section 2. Briefly, the two most relevant and popular schemes are the interval-based approach by Agrawal et al. [1] and the 2 -hop approach by Cohen et al. [9]. The interval-based approach extends the basic interval labeling to work on DAGs, and is effective on graphs that mostly resemble trees or forests. However, the performance degrades when the graph contains many non-tree edges. The 2 -hop approach identifies sub-graphs where one set of nodes connect to another set of nodes via a  X  X op X  node; between these two sets, reachability relationships can be encoded compactly. This approach is thus optimized for graphs that contain many good  X  X op X  nodes, i.e., nodes that connect two large sets of other nodes. However, the approach is less efficient for graphs with other types of substructures, e.g., long, branchless paths or one-way bipartite graphs.

In summary, there is currently no single approach that works well for all types of graphs. Our goal is to develop a labeling scheme that is robust for a larger variety of graphs. We note that each exist-ing approach to reachability labeling exploits certain substructural features in graphs. We seek to combine the strengths of these differ-ent approaches to achieve generality of our labeling scheme. More specifically, this paper makes the following contributions:
Before discussing related work, we recast the problem of graph reachability labeling as the problem of finding a compact represen-tation for a transitive closure matrix. From this viewpoint, we will analyze the two most popular existing approaches, interval-based and 2 -hop, and then discuss other related work.

We can represent a directed graph G = ( V, E ) by its | V | X | V | binary adjacency matrix A , where a ij = 1 iff there is an edge from the i -th node to the j -th node. The transitive closure of represented by a | V | X | V | binary matrix T = A | V | , the power of A . If we compute and store T , we can answer reachabil-ity queries in constant time by looking up appropriate entries in However, it is too costly to store T for large graphs. The goal of reachability labeling is indeed to represent a transitive closure ma-trix in a succinct way that supports reachability queries efficiently. Interval-Based Approach As described in Section 1, the interval approach labels nodes by intervals, whose containment relation-ships encode ancestor-descendant relationships among nodes in a tree. In the transitive closure matrix, each directed path in the graph corresponds to a reordered submatrix with 1  X  X  in the upper triangle and 0  X  X  in the lower triangle (Figure 1). This submatrix can be en-Figure 2: A bipartite graph and its transitive closure matrix coded succinctly by labeling the nodes involved with nested inter-vals. Thus, the interval approach is effective in compressing those transitive closure matrices that contain many such upper triangular submatrices. This approach works especially well for graphs with long paths: The longer the path, the better the compression ratio.
Although originally proposed for trees [10], the interval-based approach was extended by Agrawal et al. [1] to DAGs. Each node u is assigned a set of non-overlapping intervals L ( u ) ; u every interval in L ( v ) is contained in some interval in ing is done by first finding a spanning forest and assigning interval labels for nodes in the forest. Next, to capture reachability relation-ships through non-spanning-forest edges, we add additional inter-vals to labels in reverse topological order of the DAG; specifically, if ( u, v ) is an edge not in the spanning forest, then all intervals in L ( v ) are added to L ( u ) (as well as labels of all nodes that can reach u ). Consider the graph in Figure 2. Using the spanning tree rooted at a , we label a , d , e , and f with [1 , 8] , [2 , 3] , [4 , 5] spectively; we label b and c with [9 , 10] and [11 , 12] as they belong to separate trees in the spanning forest. Both b and c also receive and L ( c ) = { [11 , 12] , [2 , 3] , [6 , 7] } .

With more complicated graphs, the size of a label can become linear in the graph size. For example, if d and f have many non-spanning-forest descendants, their labels will become larger, which will in turn cause ancestors of b and c to have larger labels. Since reachability queries involves checking containment for all intervals in a label, large labels can seriously impact query performance. 2 -Hop Approach The 2 -hop approach was recently proposed as an alternative to the interval-based approach by Cohen et al. [9]. For each node u , let C in ( u ) denote the set of nodes that can reach u , and C out ( u ) the set of nodes that can be reached by key observation of this approach is that every node in C in reach every node in C out ( u ) . For example, in Figure 3, { a, b, c, x } and C out ( x ) = { x, d, e, f } . The 2 -hop approach as-signs each node two sets of nodes as its in-label and out-label , such that u  X   X  v iff the out-label of u intersects with the in-label of Thus, reachability relationships from nodes in C in ( x ) C out ( x ) can be encoded succinctly by adding x to the out-label of every node in C in ( x ) , and the in-label of every node in
From the viewpoint of compressing the transitive closure matrix, the 2 -hop approach seeks to compress the submatrix induced by x consisting of all ones; its columns correspond to the nodes in C in ( x ) and its rows correspond to the nodes in C out ( x ) trated in Figure 3. Thus, this approach works especially well on graphs with many well-connected hop nodes. Its effectiveness de-Figure 3: Two sets of nodes connected through a single node, and the corresponding submatrix in T . pends on the area-to-circumference ratio of submatrices identified for compression: The larger the area compared with circumference, the better the compression ratio. The 2 -hop algorithm repeatedly and greedily encodes the submatrix induced by x that maximizes trix that have been previously encoded.

On the other hand, it is obvious from the matrix compression viewpoint that the 2 -hop approach may miss many submatrices that are high-quality candidates for compression, because the approach only considers submatrices induced by hop nodes. For example, in Figure 2, the submatrix spanned by rows { a, b, c } and columns { d, f } consists of all ones and would be a good choice to compress, but it is not induced by a hop node.
 Other Existing Approaches Graph reachability encoding has a wide range and long history. In objected-oriented programming languages, a series of schemes based on bit vector encoding were developed for labeling class inheritance hierarchies. The bottom-up labeling scheme by A  X   X t-Kaci et al. [2] (called modulation ) uses O ( n ) bits per label, where n is the number of nodes. The top-down labeling scheme by Caseau [5] (called compact hierarchical encod-ing ) exploits possible reuses of bit positions to achieve more com-pact encoding, although in the worst it still requires O ( n ) label. In network optimization, Katz et al. [14] proposed a scheme for labeling flow and connectivity in weighted flow graphs; how-ever, their scheme assumes undirected graphs, for which reachabil-ity is much simpler to encode than for directed graphs.

Recently, graph reachability labeling problem has enjoyed re-newed interest because of its application in XML and the Semantic Web. Vagena et al. [19] investigated techniques for evaluating twig queries over graph-structured XML data. They used the 2 -hop ap-proach to label directed graphs, and noted that planar DAGs could be handled more efficiently from [13]. For a non-planar DAG, they proposed converting it into a planar DAG by adding dummy nodes at crossing points; however, this approach may introduce many false positives that may be expensive to filter out subsequently.
Christophides et al. [8] applied efficient labeling schemes to the problem of encoding subsumption hierarchies for the Semantic Web. They compared three main families of labeling schemes: Besides the interval-based and bit vector encoding approaches discussed earlier, they also considered prefix-based approach exemplified by Dewey encoding [6]. To extend Dewey encoding to a DAG, they proposed propagating each node X  X  Dewey prefix (obtained from a spanning forest) to all nodes that it can reach in the graph. Each result label consists of a set of Dewey prefixes, which can then be compressed by eliminating those that are strict prefixes of others in the set. However, since the length of each Dewey prefix is propor-tional to the depth of the spanning forest, this approach does not work well for graphs with tall spanning forests; recursive propaga-tion of Dewey prefixes further increases the size of the labels.
As we have seen, existing approaches to labeling graph reacha-bility each have their respective strengths and weaknesses, and are most effective on specific types of graphs. The interval-based ap-proach works best on tree-like graphs, while the 2 -hop approach works best on graphs with many well-connected hop nodes. By combining the power of these approaches and other optimizations that we have developed, we propose HLSS, a hierarchical labeling scheme that can work well for graphs with different characteristics.
HLSS assigns labels in two phases, each focusing on exploit-ing different characteristics of the input graph G . The first phase, tree-reachability reduction , begins with a preprocessing step that identifies each strongly connected component, collapses the com-ponent into one representative node, and uses this node to label others in the component. Then, we identify tree structures in assign interval labels to nodes based on these tree structures. Con-tainment of interval labels implies reachability through tree paths. This phase also computes a remainder graph G r that captures any remaining reachability information not encoded by interval labels. Specifically, a node can reach another node through portals in We label nodes by their portals to facilitate reachability checking.
The second phase, remainder graph-reachability encoding , aims at compressing the reachability information in the remainder graph G r produced by the first phase. We do so by assigning additional labels to portals so that reachability among them can be checked efficiently by comparing their labels. We will present several tech-niques for assigning such labels, including an enhanced version of the 2 -hop approach as well as techniques inspired by data mining, linear algebra, and graph algorithms.

To summarize, these two phases will create a label of a 4 hierarchy for each node u : Next, we describe the two phases in Sections 4 and 5. In Section 6, we show how to answer reachability queries using these labels. Due to the lack of space, label maintenance due to graph updates is dis-cussed in the technical report [12] and omitted here. our goal in this first phase is to preprocess the graph G lapse strongly connected components, extract tree structures within the result graph, capture their implied reachability relationships us-ing interval-based labeling, and produce a remainder graph taining the remaining reachability relationships for the next step. We first identify the strongly connected components (SCC) in G . If two nodes u and v belong to the same SCC, they are indistin-guishable from each other in terms of reachability. For any node if w  X   X  u , then w  X   X  v ; similarly, if u  X   X  w , then v  X  we collapse each SCC of G into one single representative node that retains all edges coming in and out of this SCC. Subsequently, we will only deal with this representative node; nodes strongly con-nected to it receive it as their SCC label ( l s ). All SCCs could be found in O ( | V | + | E | ) time by Tarjan X  X  algorithm. By replacing all SCCs with their representative nodes, we obtain a result graph with no cycles. The idea of reducing a cyclic graph to its SCCs is considered in [17] as well for computing the 2-hop cover.
Next, we identify a spanning forest T of G 0 and assign interval lationships in T . The identification of T and assignment of interval labels can be done easily in linear time of | V G 0 | and omitted here.
Finally, we must capture all remaining reachability relationships in a remainder graph G r , which is usually much smaller than Nodes of G r are a subset of nodes in G 0 , which we call portals . We label each node u of G 0 with two portals: an in-portal l an out-portal l out p ( v ) . To support efficient reachability checking, portal labels and G r must have the following property: (P1) For any two nodes u, v  X  G 0 , u  X   X  v iff In other words, unless u can reach v via tree edges in the spanning forest, the only way for u to reach v is by going through the out-portal of u and the in-portal of v . To this end, we define l ( u ) , and G r as follows: a spanning forest T of G 0 , a node u  X  G 0 is exposed if there exists an edge ( u, v ) (or ( v, u ) ) in G 0 such that u is not descendant, respectively) in T . or out-portals of some nodes in G 0 . There is an edge between two nodes u and v in G r iff u  X   X  v in G 0 .
 The definition of portals assumes that ancestor and descendant re-lationships are reflexive, i.e., a node is an ancestor and descendant of itself. Note that an out-portal is not necessarily exposed; a non-exposed node can be an out-portal if it is the lowest common an-cestor of some exposed nodes. Figure 4 shows a sample graph where solid edges belong to the spanning forest T . Based on the definition, gray nodes are exposed nodes. Node 6 is not exposed, but it is the out-portal of node 3 since it is the least common ances-tor of all node 3  X  X  exposed descendants (nodes 8 and 9 ). The following theorem ensures that the reduction of G 0 into given by Definition 1 preserves all remaining reachability informa-tion. The proof of this theorem is provided in Appendix A of [12].
T HEOREM 1. The portal labels and remainder graph defined by Definition 1 have property (P1).

Algorithm 4.1, R EDUCE , assigns portal labels and constructs the remainder graph in linear time. Basically, R EDUCE performs a depth-first traversal on each tree in T . During the traversal, R DUCE maintains a stack of all exposed ancestors to make in-portal Algorithm 4.1 Assign portal labels and construct remainder graph. R
EDUCE ( G 0 , T ) 2: for each root node t in T do R
EDUCE H ELPER ( u, S ) { S : a stack with u  X  X  exposed ancestors in T } 1: if u is exposed then 5: for each child v of u in T do 10: else 19: return ; label assignments. Out-portal labels are computed bottom-up. Por-tals and their incoming edges are added to the remainder graph as they are identified. In fact, we can augment R EDUCE can also find the spanning forest T and assign interval labels in the to assign portal labels and construct the remainder graph given
Finally, we note in the following theorem that the size of the remainder graph is linear in the number of  X  X on-tree X  edges, i.e., those that are not in T or implied by T . The proof of Theorem 2 is provided in [12]. Therefore, in practice, the remainder graph can be much smaller than the original graph. In particular, if the input graph is a tree or forest, the remainder graph would be empty and all portal labels would be unassigned, and our scheme basically degenerates into the interval-based approach.

T HEOREM 2. Let E nt denote the set of edges in G 0 that are not from a node to its descendant in T . The remainder graph fewer than 4 | E nt | nodes and 5 | E nt | edges.
After extracting reachability relationships in the spanning forest, we now turn to the problem of encoding remaining reachability relationships in the remainder graph G r . As outlined in Section 3, our goal in this phase is to assign the remainder labels L L r ( u ) for each node u in G r to help checking reachability among nodes in G r . Let T r denote the transitive closure matrix of The general idea is to compress the content of T r into remainder labels, in a way that allows any T r entry to be recovered efficiently. While many compression algorithms can be applied to T r (e.g., Blocked Huffman coding or LZW), most of them do not support efficient recovery of individual entries. Our approach is to identify a dense submatrix of T r with mostly ones, and encode it compactly in remainder labels of the nodes associated with rows and columns of the submatrix. This process is repeated until unencoded ones in Algorithm 5.1 F
IND DSM 2A PPROX ( A ) 2: while R 6 =  X  and C 6 =  X  do 9: R  X  R  X  X  r } ; 10: else 11: C  X  C  X  X  c } ; T r are sparse enough to be stored efficiently in a sparse matrix. In Section 5.1, we describe in detail how to encode a dense submatrix with remainder labels, and how to quantify the quality of encoding in term of encoding density of the submatrix. In Section 5.2, we first show the hardness of finding the submatrix with the highest encoding density, and then present several algorithms that attempt to find such submatrices. The overall algorithm for encoding the entire T r matrix will be given in Section 5.3.
Suppose R and C are two non-empty sets of nodes in the remain-der graph G r . Let T r ( R, C ) denote the submatrix of by
R and C , i.e., the submatrix whose rows and columns corre-spond to nodes in R and C , respectively. This submatrix captures reachability relationships from R nodes to C nodes. To encode these reachability relationships, we pick a unique symbol add s to L out r ( u ) for each node u  X  R and to L in r ( v ) v  X  C . In addition, for each entry ( u, v ) of T r with value add the pair ( u, v ) to a zero-exception set E 0 . Clearly, Intuitively, adding a common symbol to | R | + | C | remainder labels has the effect of remembering T r ( R, C ) as a submatrix of all ones. Any zero in it needs to be remembered in E 0 as an exception. Thus, we no longer need to store entries of T r ( R, C ) in T r
The amount of space used in remainder labels to encode T r is in bits; in addition, the amount of space used in the zero-exception set is n 0 ( T r ( R, C ))  X  size ( e 0 ) , where n x (  X  ) of entries with value x in a matrix, and size ( e 0 ) denotes the size of an entry in E 0 . We can quantify the quality of encoding by the encoding density of the submatrix T r ( R, C ) , defined as the ratio between the number of ones in the submatrix and the amount of space used in encoding the submatrix: density ( T r ( R, C )) = The higher the encoding density of a submatrix X  X r in short, the denser the submatrix X  X he better it is to apply our encoding. The overall remainder graph-reachability encoding algorithm, to be pre-sented in Section 5.3, greedily identifies a dense (if not the densest) submatrix of T r , encodes it, marks its entries as encoded (using a value other than one or zero), and repeats the process. Thus, in the general case that parts of T r have already been encoded, Equa-tion (1) defines the encoding density to be the ratio between the number of unencoded ones and the amount of additional space used in encoding (zeros covered by previously encoded parts are already remembered in E 0 and thus do not require additional space).
The encoding density in the 2 -hop is essentially a restricted case of our definition. As discussed in Section 2, the 2 -hop approach only considers submatrices induced by single nodes. The subma-trix of T r induced by node u is T r ( C in ( u ) , C out call from Section 2, C in ( u ) is the set of nodes that can reach and C out ( u ) is the set of nodes that u can reach. Note that all en-tries in this submatrix are ones, so n 1 ( T r ( C in ( u ) , C | C in ( u ) | X | C out ( u ) | and n 0 ( T r ( C in ( u ) , C our definition of encoding density reduces (up to a constant factor) number of ones in the submatrix that have been encoded.
A critical step of our remainder graph-reachability encoding al-gorithm involves identifying a submatrix of T r to encode, prefer-ably the densest one. Before we present the algorithms for finding such submatrices, we give a formal definition of the general prob-lem and show its hardness.
 est submatrix problem ( DSM ) is defined as follows: Given a binary matrix A and non-negative parameters size ( s ) and size ( e subset R of rows and a subset C of columns from A that maximize density ( A ( R, C )) , the encoding density of the submatrix spanned by R and C .

T HEOREM 3. Under the plausible assumption that 3 -SAT does not have a sub-exponential time algorithm, DSM is hard to ap-proximate within a factor of 2 (log n )  X   X  1 for some  X  &gt; 0 denotes the total number of rows and columns in the input matrix to the DSM problem.

The proof of Theorem 3 is provided in Appendix C of [12]. This result implies that, for the general DSM problem, it may be fruit-less to go after the optimal solution. Thus, we turn to heuristics or algorithms that consider a restricted solution space or special in-stances of the DSM problem for which efficient approximation is possible. The rest of this section covers two such algorithms. We also propose another SVD-based algorithm in [12], but it has higher complexity and therefore is omitted here.
The first algorithm, F IND DSM 2A PPROX (Algorithm 5.1), is greedy. To obtain a dense submatrix of A , it simply keeps remov-ing the row or column with the least number of ones from A at a time. This process produces a sequence of submatrices as in-termediate results. The densest submatrix among them is chosen.
F IND DSM 2A PPROX can be made an efficient O ( n 2 ) algorithm, where n denotes the total number of rows and columns in A main loop runs at most n times. Without any optimization, each it-eration of the loop would take O ( n 2 ) time, most of which is spent on counting ones. However, for each row (or column) to be re-moved, we can remember the count of its ones, and update this count whenever a column (or row, respectively) is removed. This maintenance only takes O ( n ) time per iteration, and the cost of finding the row or column with the least number of ones is reduced to
O ( n ) per iteration. Thus, we have reduced the overall complex-ity of F IND DSM 2A PPROX to O ( n 2 ) . For simplicity of presenta-tion, we do not show this optimization in Algorithm 5.1.
Additional good news is that, for the instance of DSM with size ( e 0 ) = 0 , F IND DSM 2A PPROX turns out to be a 2 mation algorithm, i.e., it returns a submatrix whose encoding den-sity is in a factor of two of the densest one. Note that this instance of DSM is not at all unreasonable: Setting size ( e 0 ) = 0 Algorithm 5.2 F
IND DSM E XT 2H OP ( A ) 12: else 16: else 17: break ; 18: return ( R, C ) ; tion (1) does not imply that the cost of zero-exception list is ig-nored, because the numerator, n 1 ( A ( R, C )) , still favors submatri-ces with more ones. Theorem 4 is proven in Appendix D of [12].
T HEOREM 4. F IND DSM 2A PPROX is a 2 -approximation al-gorithm for finding the densest submatrix A ( R, C ) with encoding density defined as density
Recall that the 2 -hop approach considers only submatrices in-duced by single nodes, and picks the densest submatrix among them. The approach does not consider any submatrix containing zeros, or any submatrix corresponding to a bipartite subgraph such as the one illustrated in Figure 2. Our second algorithm, F DSM E XT 2H OP (Algorithm 5.2), removes these limitations by further extending the submatrix found by the 2 -hop approach with additional rows and columns as long as they increase density. The resulting submatrix may contain zeros, and its ones may correspond to paths that do not go through a common node. In sum, F DSM E XT 2H OP considers a larger solution space than the approach, while using the 2 -hop solution to seed the search.
In F IND DSM E XT 2H OP , the 2 -hop loop requires only O ( n time, because density calculation is simplified by the fact that all submatrices considered by the 2 -hop approach contain no zeros. The second loop for extending the result submatrix runs at most n times, and each iteration can be optimized to run in O ( n ) using two optimizations that we have applied earlier to the previ-ous algorithm. First, for each remaining row (or column), we can record the count of ones that it can add to the current submatrix, and update this count whenever a column (or row, respectively) is added; this optimization brings down the cost of finding the row and column with the most ones to O ( n ) . Second, we can record the numbers of ones and zeros in the submatrix and update the two counts in each iteration; this optimization brings down the cost of density calculation to O ( n ) . Overall, the complexity of F DSM E XT 2H OP becomes O ( n 2 ) .
We now present E NCODE (Algorithm 5.3), the overall algorithm for encoding remainder graph reachability. The input is the remain-der graph G r . The algorithm first computes the transitive closure rithm greedily identifies a dense submatrix of T r using one of the two algorithms in Section 5.2. The content of this submatrix is en-Algorithm 5.3 Assign remainder labels.
 E
NCODE ( G r ) 5: loop 8: break ; 10: for each u  X  R do 12: for each v  X  C do coded in remainder labels and the zero-exception set E 0 , using the procedure described in Section 5.1. Next, the algorithm marks the entries of the submatrix as already encoded, by setting their values to 0 . 001 . As the loop continues, unencoded ones become fewer and sparser, submatrix densities become less, and dense subma-trices become smaller. When eventually dimensions of candidate submatrices shrink to 1  X  1 , we terminate the loop and remember all unencoded ones in a one-exception set E 1 . Both E 0 be implemented using hash tables.

Let m denote the number of nodes in G r (i.e., the portals). The running time of E NCODE is O ( m 3 ) . Computation of the transi-tive closure matrix can be done easily in O ( m 3 ) , using a simpli-fied version of the Floyd-Warshall algorithm. We can control the main loop so that it executes at most O ( m ) times. First, note that F
IND DSM E XT 2 HOP can be run O ( m ) times before triggering the break condition of the main loop, because each run uses up one hop node. For F IND DSM 2A PPROX , we can run them O ( m ) times and then simply switch to running F IND DSM E XT 2 HOP subsequently, which results in at most O ( m ) iterations of the main loop overall. The cost of each iteration is dominated by finding a dense subma-trix, which takes O ( m 2 ) time as discussed in Section 5.2.
Given two nodes u and v , testing whether u  X   X  v is straight-forward. If either one has a strongly connected component label, the node in the label is checked instead. Then check their inter-val labels. If the answer is not affirmative, we look up their portal labels and check reachability between u  X  X  out-portal and portal, which involves testing whether their remainder labels inter-sect, and whether the pair belong to zero-and one-exception sets (implemented as hash tables). All steps take constant time except testing intersection of two remainder labels, which takes time linear to the lengths of these labels. The algorithm is provided below.
In this section, we demonstrate the effectiveness of HLSS and compare it with other approaches using experiments on a variety of graphs. We have implemented HLSS as well as two other label-ing schemes for comparison: the interval-based approach [1] and the 2 -hop approach [9]. One primary metric for measuring the ef-Algorithm 6.1 I
R EACHABLE ( u, v ) 3: return true ; 6: return true ; 8: return true ; 10: return false ; 12: return true ; 13: return false ; fectiveness of a labeling scheme is its compression factor , which is defined as the total number of entries in the transitive closure matrix (i.e., the number of bits needed to store this matrix in dense format) divided by the number of bits required by the labeling scheme. For HLSS, we count the space used by labels as well as the zero-and one-exception sets. The larger the compression factor, the greater the space saving. For all three schemes we are comparing, the time to answer a reachability query is linear in the size of labels. There-fore, compression factor is a rough indicator of average query per-formance. To get an more accurate picture of overall query perfor-mance, we also measure the distribution of individual label sizes. Random Graphs with Varying Densities For the first set of ex-periments, we generate  X  X andom graphs X  as follows. We fix the number of nodes at 1000 and create each edge by choosing its source and sink uniformly at random. We vary the number of edges from 1000 to 3000 ; as we will see, this range is large enough to cap-ture the trends in results. Figure 5 shows the compression factors of three labeling schemes as we vary the graph density , i.e., the ratio between the number of edges and the number of nodes.

At low graph densities, compression factors tend to fluctuate be-cause reachability relationships heavily depends on the randomly generated topologies; the difference among the three scheme is small. However, a clear trend emerges as we increase the graph density. Even though the graphs remain sparse (the densest one has on average only 3 edges per node), as the number of edges increases, the fraction of nodes in SCCs increases quickly. All la-beling schemes benefit from this increase. For the 2 -hop approach, there are more and better hop nodes. For the interval-based ap-proach (with our extension for handling SCCs), the original graph is reduced to a much smaller DAG. As shown in Figure 5, the com-pression factors of both schemes quickly approach a common limit. This limit can be obtained analytically based on the observation that, for both schemes, each label must have at least two compo-nents: in-label and out-label for the 2 -hop approach, and two inter-val endpoints for the interval-based approach. This limit works out to be 50 for a graph of 1000 nodes (detailed calculation omitted), which is confirmed by Figure 5. HLSS, on the other hand, uses only a single representative node to label nodes in the same SCC. Therefore, HLSS compression factor can grow beyond this limit. Synthetic Graphs with Varying Parameters As shown in the previous set of experiments, the dominating factor in the perfor-mance of labeling schemes on a random graph with moderate to high density turns out to be how well they handle SCCs. To expose other factors affecting performance, we need finer control over the properties of synthetic graphs. To this end, we generate graphs with three adjustable parameters: p s , the percentage of nodes in SCCs; p , the percentage of unexposed nodes (recall Definition 1) in the remaining DAG (after collapsing SCCs); and d o , the average out-degree of exposed nodes in the remaining DAG. For lack of space, we omit the details of how to construct a graph with these parame-ters. We have experimented graphs with various numbers of nodes and found relative performance of the three schemes to be consis-tent. So we only present results for graphs with 2000 nodes.
Figure 6 shows the compression factors of the three schemes as we vary p s (percentage of nodes in SCCs) from 0 to 0 . 6 p u = 0 . 4 and d o = 3 . From the figure, we see that HLSS out-performs the other two approaches by a big margin because of its efficiency in handling SCCs. The interval-based approach performs worst because the remaining DAG is complex enough (with an av-erage out-degree of 3 ) that the label of a node will be propagated to a large number of nodes that can reach it. As p s increases, all three schemes become more effective, with HLSS widening its lead for reasons discussed earlier under the results for random graphs.
Next, Figure 7 compares the three schemes as we vary d o (the average out-degree of exposed nodes in the remaining DAG) from 1 to 100 . We fix p s = 0 . 2 and p u = 0 . 4 . When d o interval-based approach works best as expected, because the DAG mized. HLSS is also quite effective for d o = 1 , but the proach is not nearly as good as the others. As d o increases (from to 10 ), however, the interval-based approach see the most dramatic drop in compression factor, because the DAG quickly increases in complexity and many intervals end up being propagated to many nodes. The 2 -hop approach handles complex DAGs much more gracefully, eventually outperforming the interval-based approach; HLSS handles complex DAGs just as gracefully as the 2 -hop ap-proach, and maintains the lead over the 2 -hop approach. As continues to grow beyond 10 , the DAG becomes increasingly con-nected, and its transitive closure matrix grows denser. Hence, all compression factors begin to increase again. The interval-base ap-proach manages to pick up the largest gain because of increasing opportunities in applying the following optimization: If two inter-vals touch each other, they can be merged into one bigger interval. Overall, HLSS is superior to the other approaches almost all the time except the case of d o = 1 , where the interval approach really shines and HLSS ranks as a close second.

Finally, Figure 8 shows the results of varying p u (the percentage of unexposed nodes in the remaining DAG) from 0 . 3 to 0 . 9 fixing p s at 0 . 2 . Here, since adjusting p u changes the number of exposed nodes, keeping d o constant would make topologies of the resulting DAGs very different for different p u . To focus on study-ing the effect of p u , we fix an alternative parameter, edge density , to 0 . 01 ; edge density is defined as the ratio between the number of edges in the generated DAG and the maximum number of edges possible for a DAG of this size. When p u is small, the graph has lit-tle resemblance to a tree, because only a small number of nodes are connected only through tree edges. Therefore, the interval-based approach suffers and performs much worse than the other two. As p u increases, the graph looks more like a tree, and the interval-based approach performs much better. Again, HLSS is almost al-ways the best except the extreme case where HLSS is a little behind the interval-based approach for a graph with mostly tree edges.
In conclusion, we see that HLSS consistently delivers perfor-mance better than or comparable to the the other two approaches, while they each have their respective strengths and weaknesses for different types of graphs. The interval-based approach is able to outperform HLSS by a small margin for tree-like graphs. However, the compression factor is so high for such graphs that the actual ure 7). But HLSS provides much more substantial space savings
Figure 5: Random graphs.
Figure 7: Varying d o ( p = 0 . 4 , p s = 0 . 2 ). Label Size Distribution Because of space constraint, we present the distributions of individual label sizes only for one graph with 2000 nodes, p s = 0 . 2 , p u = 0 . 3 , and d o = 5 . In Figure 9, the logarithmic horizontal axis shows the label size in terms of number of units , where each unit represents the amount of space required to store a node identifier, a symbol, or an interval end-point. The vertical axis shows the percentage of labels whose size is less than or equal to the given size. The legend also shows the maximum label size, the average label size, and the standard deviation for each scheme. The interval-based approach has the widest range of possible label sizes; it has a large percentage of short labels (around 40% have length no more than 4 units), but unfortunately also a significant percentage of long labels (around 25% have length greater than 100 units), which would be quite ex-pensive when queried. In contrast, the 2 -hop approach has mostly medium-sized labels. Interestingly, HLSS inherits the good fea-tures from other two approaches and does much better than both of them. There are roughly 20%  X  p s of the labels with unit size; they correspond to node in SCCs. Close to 24%  X  (1  X  p s the labels have length 3 ; they correspond to non-portal nodes (recall Section 4). In this region of the graph, HLSS behaves much like the interval-based approach. The remaining part of the HLSS curve re-sembles the curve of the 2 -hop approach, in that fewer and fewer labels have longer labels. The maximum label length is 50 nificantly less than the other two. Overall, HLSS demonstrates the most favorable label size distribution among the three approaches.
In this paper, we have revisited the important problem of labeling graph reachability. Many labeling schemes have been proposed in the past, but most of them are optimized to exploit particular types of substructures in graphs and do not work well on other substruc-tures. We have proposed a hierarchical approach that combines the strengths of existing approaches by labeling different types of sub-structures differently. Our two-phase algorithm is an efficient real-ization of this hierarchical approach; experiments have shown that it handles different types of graphs well, while existing approaches suffer from substructures that they do not handle well.
