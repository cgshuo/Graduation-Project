 Most existing approaches for text classification represent texts as vectors of words, namely  X  X ag-of-Words. X  This text representa-tion results in a very high dimensionality of feature space and fre-quently suffers from surface mismatching. Short texts make these issues even more serious, due to their shortness and sparsity. In this paper, we propose using  X  X ag-of-Concepts X  in short text repre-sentation, aiming to avoid the surface mismatching and handle the synonym and polysemy problem. Based on  X  X ag-of-Concepts, X  a novel framework is proposed for lightweight short text classifica-tion applications. By leveraging a large taxonomy knowledgebase, it learns a concept model for each category, and conceptualizes a short text to a set of relevant concepts. A concept-based similarity mechanism is presented to classify the given short text to the most similar category. One advantage of this mechanism is that it facili-tates short text ranking after classification, which is needed in many applications, such as query or ad recommendation. We demonstrate the usage of our proposed framework through a real online applica-tion: Channel-based Query Recommendation . Experiments show that our framework can map queries to channels with a high de-gree of precision ( avg: precision = 90 : 3% ), which is critical for recommendation applications.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.2 [ Pattern Recogni-tion ]: Design Methodology X  Classifier design and evaluation Algorithms, Experimentation Short Text Classification; Query Recommendation; MSN Channel; Taxonomy Knowledge
This work was done when the first author was an intern in Mi-crosoft Research Asia.

The explosive growth of information makes people feel over-whelmed when browsing for information online. Fortunately, many information technologies have been invented to help. Text Classifi-cation is one of the key techniques for organizing online informa-tion. It has been widely used in News Categorization, Opinion Min-ing and Spam filtering. Before performing any classification task, text representation is one of the most fundamental tasks [1]. Most well-known techniques [28, 19, 20, 8, 26] represent texts as vectors of terms (words or phrases), namely  X  X ag-of-Words X  (BoW).
However, BoW simply looks at the surface word forms and ig-nores all semantic or conceptual information in the text. Poor per-formance of BoW is unavoidable in Short Text Classification (STC), because short texts (e.g., search queries, tweets, or Facebook status) are sparse, noisy, and ambiguous. The drawback of surface-based similarity is even more serious in short texts, since two short texts with similar meanings do not necessarily share many words. Most existing work tries to expand the short text by leveraging search engines [31, 11, 37] or external knowledge bases [33, 25, 27] (e.g., ODP, WordNet, and Wikipedia), which needs a time-consuming collection for these expansions. Besides, these expansions are still weak in semantics.  X  X ag-of-Words X  limits text classification in many applications, especially in short texts or other lightweight online applications that require faster training and new words adaption. As an alternative, we propose representing the short text from a higher perspective of concepts, rather than directly using terms that appear in the text. The notion of  X  X ag-of-Concepts X  is first proposed by Sahlgren, et al. [29]. But the concepts in their paper are some synonym sets or latent dimensions of  X  X ag-of-Words, X  not the hyponymy in se-mantics. Other work defines concepts as units of knowledge, such as entities in WordNet [18] or Wikipedia [14]. For instance, agri-culture , agricultural sector and agricultural can be represented by Agriculture . Indeed, these concepts can handle problems with syn-onymy. However, they are still specific representations with lim-ited contribution to semantic similarity. For example,  X  X eep X  and  X  X onda X  are not synonymy, but they are very similar because they belong to the same concept Car .

In this paper, we define a concept as a set or class of entities or  X  X hings X  within a domain 1 , such that words belonging to sim-ilar classes get similar representations. For instance,  X  X eep X  and  X  X onda X  can be represented by Car . These generic concepts can benefit short text classification. For example, although the two short texts  X  X eyonce named People X  X  most beautiful woman X  and  X  X ady Gaga Responds to Concert Band X  share no common words, http://www .cs.man.ac.uk/ stevensr/onto/node3.html the y are likely to be the same class of Music , since  X  X ady Gaga X  and  X  X eyonce X  can be represented by the same concept Singer , which is highly related to Music .

There are two advantages of this  X  X ag-of-Concepts X  (BoC): 1. Replace surface matching with semantic similarity : BoC mea-2. Tolerance with new terms : New term arises always but the
We propose a novel framework based on  X  X ag-of-Concepts X  for lightweight short-text oriented classification applications (Boc-STC). Specifically, given the training texts per class, BocSTC first constructs a concept model for each class, namely  X  X ag-of-Concepts X  for each class. During this construction, a large taxonomy knowl-edgebase is needed to convert terms to concepts. Then, given a short text to be classified, the framework needs to understand its content and associate the short text with the relevant concepts (here we call this operation Conceptualization [35]). Based on the con-ceptual expression, we propose a concept-based similarity mech-anism for short text classification and ranking. The framework is suitable for many online lightweight applications, such as query-related applications (e.g., query recommendation) and Ads classi-fication and ranking.

We demonstrate the usage of BocSTC through a real online ap-plication: Channel-based Query Recommendation . Major Internet portals as MSN and Yahoo! provide diverse channels to facilitate users to browse news by categories. Fig. 1 shows a screenshot for channels on the MSN website.

Channel-based Query Recommendation aims to provide the hottest search queries for users when they browse the channels. These queries are recently issued by other people. Given a channel, it will recommend highly related queries, taking into account the query di-versity and interestingness. Fig.2 shows a screenshot of the Channel-based Query Recommendation. There are two key tasks in this ap-plication: 1. Mapping query to channel : Two challenging issues exist in 2. Query ranking : For queries to be recommended, how to mea-
BocSTC represents channels and queries as vectors of concepts, which can simplify the above issues to a large extent. Compared with traditional text classification methods (e.g., SVM), fewer texts are needed for building the concept model for each channel. This saves us much time for manually labeling large numbers of train-ing data and makes it possible to update the learnt model quickly.  X  X ag-of-Concepts X  also makes the learnt models tolerance with word changing. For query ranking, BocSTC measures the semantic similarity between the query and channel, which can avoid surface mismatching. Regarding the concepts as subtopics, it is able to di-versify the recommendations directly from the subtopic level, with-out extra query clustering process. Comprehensive experiments are designed to prove its high quality of query recommendations. The techniques we describe in this paper is in production for query rec-ommendation.

The main contributions of this paper are as follows:
The rest of the paper is organized as follows. Section 2 briefly introduces the knowledgebase we use for concept model genera-tion. Section 3 first gives the whole picture of BocSTC and then describes its main modules in detail. Section 4 demonstrates the usage of BocSTC in Channel-based Query Recommendation . Ex-periments are presented and analyzed in Section 5. We discuss related work in Section 6 and conclude in Section 7.
In this section, we describe a large knowledgebase that we use to transform  X  X ag-of-Words X  to  X  X ag-of-Concepts. X  We also in-troduce two useful functions to better capture concept information from the knowledgebase, namely Typicality and Concept Cluster .
We can learn the concepts of words by leveraging existing large-scale knowledgebases, such as Wikipedia, Yago [36] and Probase [40]. We will take Probase as a running example in this paper. Definitely, our techniques can be applied to other knowledgebases. Probase is a probabilistic semantic network that contains millions of con-cepts. It is rich enough to cover a large proportion of concepts about worldly facts. Terms in Probase are connected by a variety of relationships. Here, we focus on the Is-A relationship (although other relationships such as AttributeOf [21] are also important to conceptualization). The version of Probase 2 we use contains al-most 2.7 million concepts and 4.5 million Is-A relationships. For example,  X  X obin  X  is-a bird , and  X  X enguin  X  is-a bird .
The concepts in Probase are fine-grained, which can increase the capacity to distinguish between close classes. For example, given  X  X ngelina Jolie, X  Probase will return many fine-grained concepts such as actress , Hollywood star and movie star . For  X  X eyonce, X  it returns pop star , famous singer and musician . Other knowledge bases do not have such a huge fine-grained concept space. Most of the time, they can map both of  X  X ngelina Jolie X  and  X  X eyonce X  to celebrity . But celebrity is too general to discriminate between the two close classes - X  X ovie X  and  X  X usic. X 
For mapping instances to the concept space, we use a probabilis-tic way to measure the Is-A relations, called Typicality . For exam-ple, given an instance e , which has Is-A relationship with concept c , Typicality P ( c | e ) is given by Eq. 1, reflecting how typical of c is among all concepts that contain instance e .
 where n ( e; c ) denotes the co-occur frequency of e and c . n ( e ) and n ( c ) are the frequencies of e and c occur during their extraction. Similarly, P ( e | c ) can measure how typical or popular e is when given c . In our framework, we leverage the Typicality to select typical concepts for instances in concept model construction.
Among the large amount of concepts in Probase, many concepts are similar to each other, such as  X  X ountry X  and  X  X ation, X   X  X usic star X  and  X  X op star, X  etc. We use Concept Clusters to gather similar concepts together, by using a k-Medoids clustering algorithm pro-posed by Li et al. [22]. One concept cluster can represent one sense or a general topic, recognized with its center concept. For example, for the cluster centered around country , most of its members are highly related to country , such as nation , asian country , develop-ing country , region etc. In this paper, we use the concept cluster in multiple-ways including sense detection in short texts and subtopic representation in the targeted categories.
In this section, we present the novel framework (BocSTC) for lightweight short-text oriented classification applications (Fig. 3). It consists of two components: offline learning and online classifi-cation.

The offline component aims to learn a concept model with good distinguishing power for each target class. Specifically, given the training data for a class i , it first extracts entities from the text, then generates concept candidates by mapping each entity to a concept
Probase data is publicly available at http://probase.msra.cn/dataset.aspx Figur e 3: The framework of concept-based short-text classifi-cation and ranking set. A large taxonomy knowledgebase is exploited for the map-ping. A more challenging task is to select representative concepts. The selected concepts should not be too general or too specific for representing class i . We propose weighting the candidates with the combination of entity idf value, concept idf value and typi-cal probabilistic p ( c | e ) , and filter concepts with low weight score. This ranking mechanism is also able to reduce the noise caused by entity-concept mapping. More details are given in subsection 3.1.
At runtime, when a short text is coming, we need to first under-stand its main topics by leveraging conceptualization. This enables us to translate the short text to  X  X ag-of-Concepts, X  so as to classify it in the same concept level as the concept models.

However, entity disambiguation is a major challenge to accu-rate conceptualization. Subsection 3.2 shows the details of con-ceptualization with disambiguation. Based on  X  X ag-of-Concepts, X  we propose a similarity-based mechanism to classify short texts. One advantage of this approach is that we can rank the short texts within a class directly using the similarity score, which is conve-nient for many applications with classification and ranking require-ment, such as ads recommendation. Subsection 3.3 explains this approach in detail.

Finally, the ranked results are returned with similarity scores.
Given training data D l = { d i ; i = 1 ; 2 ; ::; N } for the class CL we learn its concept model by leveraging the large knowledgebase Probase. The learnt concept model is represented as a concept vec-tor CM l = (  X  c 1 ; w 1  X  ; :::;  X  c i ; w i  X  ; :::;  X  c where w i denotes the weight of concept c i in class CL l weight could reflect the representative strength of concepts within a class. Specifically, this process is divided into three subtasks: En-tity Recognition , Candidates Generation and Concept Weighting .
To gain concept expression, we first need to detect the entities in the text so as to access concepts through entities. During the recog-nition, documents are first split to sentences, and then Backward Maximum Matching is used to detect the entities from each sen-tence. The version of Probase we use contains about 8.26 million instances (e.g.,  X  X eyonce, X   X  X ady Gaga, X  and  X  X arack Obama X ). Thus, we use all instances in Probase as the matching dictionary. Stemming is also performed to assist in the matching process. After recognition, the extracted entities are merged together and weighted by idf based on different classes. Those with low idf value are re-moved, because low idf reflects that these entities have low class distinguishing ability.
We generate concept candidates from all the extracted entities by leveraging the large amount of Is-A relations in Probase. Given entity e j , we select its top N t concepts ranked by the Typicality P ( c | e ) (Eq. 1), as its typical concepts. The N t is usually in the order of tens (in this paper N t = 20). We merge all the typical con-cepts as the primary candidate set, and then clean it in the following two ways: (1) removing stop concepts 3 , which tend to be too general to rep-(2) computing the idf value for each concept in the class level, and
Although we remove many non-representative concepts, the noise concepts still exist because simply selecting the top N t incapable of processing ambiguous entities. For example, given en-tity  X  X ython X  in class Technique , our mapping method will result in its top N t concepts list including animal , which is a noise to class Technique . We leave this problem to the next subtask.
In this subtask, we weight the candidates to measure their repre-sentative strengths for each class. Specifically, for each candidate c , we aggregate the weights of votes to it from all its entities in CL l , as its weight in CL l . Meanwhile, the idf value of c typicality P ( c k | e j ) is also considered, as Eq. 2 shows:
According to the weights, we rank the candidate concepts. The noise concepts brought by the Candidates Generation , tend to have low ranking scores, since there are few supporting entities for them in CL l . Thus, concepts with low weights are removed. Finally, we get the concept model CM l for the class CL l .
Short Text Conceptualization aims to abstract a set of most rep-resentative concepts that can best describe the short text [35, 39]. To avoid over abstracting, specific entities are preferred during en-tity recognition from the short text. Therefore, we first detect all possible entities and then remove those contained by others. For example, given the short text  X  X indows phone app, X  the recognized entity set will be { X  X indows phone, X   X  X hone app X  X , while  X  X in-dows, X   X  X hone, X  and  X  X pp X  are removed. The entity set is then used to conceptualize the short text.

Given the entity list E st i = { e j ; j = 1 ; 2 ; :::; M text st i , we conceptualize them by leveraging the tens of millions of concept-instance pairs in Probase. Song, et al. [35] estimate the probability of concepts using a naive Bayes model. However, they do not refer to entity disambiguation, which is a key issue affecting the conceptualization accuracy. A typical example is to understand the short text  X  X pple ipad X  , where  X  X pple X  has two senses, namely
Stop concepts generally have many diverse instances and tend to be in the high level of concept hierarchy. These concepts are al-ready pre-recognized with these two rules. a famous Company and a kind of Fruit . In this paper, we use the context  X  X pad X  to assist mapping  X  X pple X  to Company . We observe that the context has the ability to disambiguate a vague term. For example, when  X  X hina X  and  X  X ordan X  occur together,  X  X ordan X  tends to be a Country , while when it appears with  X  X ike, X  it is more likely to be a X  X rand, X  because a vague term tends to have the same sense with its near context. Formally, we conceptualize the short text st in the following two steps:
Sense Detection : This step aims to detect different senses for each entity in E st i , so as to determine whether the entity is am-biguous. Probase provides concept clusters to gather similar con-cepts within a same sense. Thus, we detect the senses of entity e directly using the concept clusters of its typical concepts. De-note C e j = { c k ; k = 1 ; 2 ; :::; N t } is e j  X  X  typical concept list and CCl e j = { ccl m ; m = 1 ; 2 ; ::: } is e j  X  X  concept cluster set. We estimate the ambiguity of e j by its entropy of concept cluster dis-tribution (Eq. 3).
 where P ( ccl m | e j ) denotes the probability of e j belonging to clus-ter ccl m , which is estimated by aggravating the typicality scores for all its concepts belonging to ccl m . An entity with high entropy value tends to have high uncertainty of cluster distribution.
Disambiguation : Given the entity list E st i and the identified vague entities, we disambiguate vague entity by leveraging its un-ambiguous context entities. Denote the vague entity as e v unambiguous entity e u j . For each cluster of e v i , we re-weight them with Eq. 4 where CS ( ccl m ; ccl n ) denotes the concept cluster similarity, cal-culated with Eq. 5.

CS ( ccl m ; ccl n ) = 1 | where E c k is the entity list including typical entities that belong to concept c k . We reserve the ccl  X  e v as e v i  X  X  sense. For unambiguous entities, we choose their domi-nant clusters marked as ccl  X  e u from all entities in E st i as { is represented as a concept vector marked as C j , where each com-ponent is a Probase concept valued with P ( c | e j ) , so that each short text is conceptualized in the same concept space as the concept models.
In this subsection, we describe the similarity-based mechanism to classify the given short text st i and rank the items assigned to a class CL l .
The intuition of classification is simple: classify the short st the class CL l that is most similar with st i based on the same con-cept space. Given the concept model CM l for class CL l , and st concept expression C st i = { C j ; j = 1 ; 2 ; :::; M } , we measure the similarity between st i and CL l with Eq. 6.

Sim ( st i ; CL l ) = W e select CL  X  l (Eq. 7) that has the maximum similarity with st the classification result. The max similarity score is assigned to st as its weight in CL  X  l .

A possible adjustment to this method is that one can define a threshold for each class to further refine the classification. For ap-plications with high accuracy requirement, it is necessary to filter out the items with low maximum similarity score.
Apart from classification, many applications require ranking their items in the meanwhile, such as channel-based query recommen-dation, advertisement matching for some topics, etc. Our concept-based classification framework has advantages for ranking classifi-cation results in a class. Specifically, two ranking mechanisms are proposed to meet with two typical ranking requirements: Ranking by Similarity and Ranking with Diversity .

Ranking by Similarity : This is the most common way to rank items. For example, in an ads matching problem, search engines rank bid keywords by their similarities to the user query. In our framework, as each short text st i assigned to CL l has a similarity score, we can rank them directly by their scores in descending or-der. Based on the simple ranking mechanism, items with more typi-cal concepts of CL l tend to have higher ranked positions. Based on concept level similarity, term mismatching can be tackled to some extant.

Ranking with Diversity : Diversity is an important feature for recommending related applications, which affects the User Expe-rience directly. Most existing approaches [12, 23, 16] diversify the recommendations based on different aspects or subtopics of the recommended target. Generally, a clustering or other subtopic min-ing process is needed to generate different aspects. While in our framework, this step is no longer needed because we can directly gain class aspects by leveraging Probase concept clusters. This makes our framework more adaptive to real-time ranking applica-tions. Regarding the concept clusters as subtopics of the class, we can diversify the short texts by subtopic Proportionality proposed by Dang et al [12].
In this section, we demonstrate the usage of BocSTC through a real application: Channel-based Query Recommendation.

This online application aims to anticipate user search needs when browsing different channels, by recommending the hottest and highly related queries for a given channel. There are three difficulties in this application: i) the recommended target (Channel) is  X  X hort, X  lack of training data or any user preference logs; ii) a need to understand the short text (user query); iii) requiring both classifi-cation and ranking (how to identify which channel the query be-longs to and how to rank the recommendations with diversity). These difficulties also indicate the application scenarios of our pro-posed framework. The following three subsections describe how we tackle these issues using BocSTC.
The recommended target -channel tends to be a general cate-gory, such as Living , Money , or Entertainment . Unlike traditional recommendation system, we have no log data as query click data or user reading preferences (article click data) in the given channel. It is not practical to label the training samples artificially. Moreover, the content in the channels is changing fast along with constantly updated hot news. This puts forward a higher requirement of adapt-ing word changing. A more promising way is to seize the core topics hidden behind the surface words appeared in the channel.
BocSTC tries to capture the typical concepts from the hot news crawled from pages listed in each channel. We just need to process the titles to get typical concepts, since the article title can reflect the main topics of the article. This saves us much time to process a large amount of long texts, so as to enable the learnt concept models to adapt quick updating. Table 1 gives some typical examples of the learnt concept model. It shows the learnt typical concepts in different concept clusters (topics) for Channel Music . Table 1: The Learnt Concept Model for  X  X hannel Music X 
In order to map the query to an appropriate channel, we first need to know what the query is talking about, namely understanding the search intent of the user issued the query.

Understanding query intent is one of the most basic components of information retrieval systems [10], which has been studied ex-tensively in recent years. Most existing approaches utilize machine learning techniques to predict the user X  X  intent. However, it often needs to enrich query features through search engines [31, 11] or utilize log data (i.e., query log and search-click-through log) [4, 24] as unlabeled data for training a query classifier. For map-ping queries to appropriate channels, these methods are not desir-able. First, enriching a query through search engines is too time-consuming for a real-time online application. Second, there are not sufficient training samples for training a query classifier using traditional statistic machine learning methods. Manual labeling is unpractical in this application.

With very little human effort, BocSTC captures query topics from the concept level, by leveraging the short text conceptualiza-tion module mentioned in subsection 3.2. Query conceptualization infers typical concepts from a set of instances detected from the query text, so as to map the query to an appropriate channel in the same concept space as the learnt concept models. During this process, we also consider the entity disambiguation by using its context entities in the query. Table 2 shows some examples of our query conceptualization.

In this subsection, we describe the usage of our Classification and Ranking module customized for channel-based query recom-mendation.
After the former two steps, both of the channels and candidate queries to be recommended are represented as  X  X ag-of-Concepts. X  Based on the same concept space, we first classify query candidates with the similarity-based method mentioned in subsection 3.3.1. We then recommend queries with the diversity ranking method pro-posed in subsection 3.3.2. The queries classified to the channel are first ranked by their similarity scores, and then the top N (i.e., N = 100 ) queries are reserved for diversity recommendation. This is done to filter non-typical queries classified to the channel, so as to improve the quality of the recommendation.

We use the proportionality -base algorithm PM-2 [12] to diver-sify the recommendations, where the concept clusters are used as the channel aspects. PM-2 considers a result list most diverse, with respect to some set of topics related to the recommended target, when the number of queries it provides on each topic is propor-tional to the topic X  X  popularity. Given the list R of the top N queries in channel CL l , the seat number N s (we generally set N 20) and the topic list CCL l = { ccl i ; i = 1 ; 2 ; :::M nel. It first selects a topic with the most quotient and then assigns a relevant query to the selected topic ccl  X  i . It iterates these two steps until all the seats are sold out. In the second step, it considers other topics as well (Eq. 8). q = argmax Where qt [ i ] denotes the quotient of the topic i and P ( q notes the probability that the query q j belongs to cluster ccl a parameter for tuning the weight between ccl  X  i and other topics.
PM-2 focuses more on the diversity of the topic level, while the surface word level is neglected, which also has a significant impact on the user experience. For example, given the former recommen-dation  X  X lton john worries lady gaga, X  recommending  X  X lton john lady gaga health X  will damage the user experience. In this paper, to avoid repeating recommendations, we introduce a word distance factor when assigning a query to ccl  X  i (Eq. 9) Where we abbreviate Score P M -2 to the original PM-2 score in Eq. 8 due to the space limitation. Distance ( q j ) denotes the mini-mum word distance of q j to the selected queries that already have a seat(Eq. 10).
 Where S  X  is the set of queries that already have a seat and W denotes the word set of q i .
In this section, we evaluate the performance of BocSTC on the real application -Channel-based query recommendation . The ex-periments are divided into two evaluation parts: Query Classifica-tion and Result Diversity . We first introduce the datasets and then present experimental results to assess the effectiveness of our pro-posed BocSTC.
Four commonly used channels are selected as our targeted chan-nels: Money , Movie , Music and TV . Note that the last three ones are somewhat similar to each other. We select them with the aim of testing the classification performance of similar categories. We now introduce the real-world training and test datasets used in our experiment.

Training dataset : Given the hot news crawled from pages listed in each channel, we randomly select 6,000 items for each channel, as Tab. 3 shows. We then extract the title and body text from each article. The titles are used as training data for BocSTC. The body texts together with the titles are used for training other baseline models. From this angle, we can see that much fewer texts are needed in BocSTC.

T est dataset : We use the real queries from a Bing query flow over the course of 5 hours as the source of our test dataset. To alle-viate the burden of manual annotation, we first filter these queries with a pre-trained classifier, then annotate the pre-classified queries manually. We obtain 841 labeled queries, from which, 200 are selected randomly for verification and 600 for testing, as Tab. 4 shows. Note that a query may belong to multiple channels.
Unlik e articles in the training dataset, queries are generally very short. To gather more information about the short queries for base-line methods, we expand queries by leveraging popular search en-gines. According to Dou Shen, et al. [33], we use the snippets of the top 40 returned pages to represent it. We remove stop-words and perform stemming for all the data. Some statistical numbers from the training and test data are listed in Tab. 5.

In this subsection, we present the query classification perfor-mance of our model on each channel.
In order to demonstrate the effectiveness of BocSTC, we com-pare it with the following methods: (1) A naive entity-based method (Entity_ESA) . Many Wikipedia-(2) Vector Space Model (VSM) [30]: VSM is an algebraic model (3) Language Model (LM) [34]: It is used in a similar way as VSM (4) Support Vector Machine (SVM) [8]: SVM is a kind of statisti-
Among the baseline methods, in VSM, Cosine is used as the similarity measurement and the normalized T F is used for the di-mension value. In estimating p ( D j | Q i ) for LM, we use the Dirich-let smoothing method proposed by C. Zhai [42]. There is a Dirich-let Prior to be set. After turning, we set to 500 for LM d 2000 for LM ch . In training the SVM classifier, we verify the clas-sifier with the query verification dataset. Also, the normalized T F is used as the value on each dimension.
In this evaluation, the P recision , Recall , F -value are em-ployed as the performance metrics to evaluate the quality of Query Classification. The F -value is the harmonic mean of precision and recall. F 1 is commonly used when the precision and recall are evenly weighted. While in the case of emphasizing precision , F 0 : 5 is used. We use both of them for better evaluation.
Experimental results of the baseline methods on the real query test dataset are respectively plotted in Fig. 4. For the four metrics, the vertical axis represents the average score of the four channels. From this figure, we draw the following observations: (1) BocSTC performs much better than other baselines in terms (2) Specifically, the methods LM ch , SV M and V SM use the ex-(3) Entity_ESA also attracts our attention because it gets the worst
Figure. 5 shows the detailed precision performance of these methods on each channel. We can see that our BocSTC has a signif-icant advantage in three channels except for the  X  X ovie X  channel. The best performance in this channel goes to LM ch , higher than our model by nearly 20%. This forces us to investigate the result of  X  X ovie Channel X  in detail.

We look up the test data and compare it with our predicted ones, listed in Tab. 6. We can see that nearly half of the queries in the Movie channel are not assigned to any channel label (73/152), which greatly reduces the recall . We believe this is because the entity coverage in Probase is still limited. Since many queries in this channel contain movie titles, such as  X  X ourney 2 The Myste-rious Island. X  New film names come out continually. It is barely covered by the knowledgebase in time. However, this can be easily resolved by named entity extraction techniques.
As can be seen from Tab. 6(b), queries in the Music channel make a lot trouble for accurately predicting Movie queries. This is because the two channels are similar to each other. In fact, most of the stars have a variety of careers (e.g., actor, singer, host or pro-ducer), such as  X  X eyonce X  of America and  X  X hao Wei X  of China. However, we can make up for this kind of mistake by leveraging the ranking score given by BocSTC.

In this subsection, we evaluate the performance of BocSTC in terms of recommendation interestingness.
For each channel, the input of our query ranking module is the queries with scores assigned by classification module in BocSTC . In order to demonstrate the effectiveness of the proposed ranking method (section 4.3), we compare it with following methods:
In this evaluation, we set the seat number N s to 20 , namely rec-ommending 20 queries for each channel. For each of the baselines, we select the top 20 queries as a result list to be labeled. Then, we manually annotate these lists with the following guidelines:
We use nDCG as the evaluation metric. Since we do not know the ideal DCG in our datasets, we set it to the highest score, which is computed with the Eq. 16: where r el ideal is the ideal label, which is 2 in this evaluation. Fig. 6 shows the experimental results, where our refined version of PM-2 is marked as BocSTC-PM2+ , which combines term diversity with subtopic diversity.

From this figure, we draw the following observations: (1) By using PM-2 , the diversity performance of query recommen-(2) Our diversity method is a significant improvement over LM
We present example queries recommended by BocSTC , LM ch and SVM in Tab. 7.

From the examples of SVM , we can see that directly ranking by classification scores can hardly perform well in diversity recom-mendation. For instance, in the Movie channel ,  X  X onny depp X  is ranked higher than  X  X epp movie awards X  (it is not ranked in the top 5), but the latter seems to be more interesting because it provides extra information. This cannot be handled by traditional text clas-sifiers. As for LM ch , although its top ranked queries are related to the channels, their topics are relatively monotonous. For exam-ple, in the Music channel ,  X  X usic youtube, X   X  X hris brown music, X  and  X  X eyonce music X  appear in the top 5 at the same time. This is detrimental to the user experience.

The queries recommended by BocSTC are more interesting, es-pecially in the Movie channel and the Music channel , because they cover most subtopics of their channels. In other words, queries re-flecting more topics are more likely to be interesting. It also takes word distance into consideration, so as to avoid repeating queries in different subtopics but with similar words.
Techniques proposed in this paper are mainly related to short text classification and query recommendation .
Short text classification delivers short texts (e.g., queries, tweets and comments) to some pre-defined categories based on content analysis. Most existing approaches are mainly based on feature ex-panding. Generally, there exists two expanding directions. One is to obtain extra context information through search engines [31, 11, 37]. The expanded short texts are regarded as long texts and can be classified with long text classification approaches [32]. But this ex-pansion is not an ideal solution for some online applications, since it is very time consuming and heavily dependent on search engine quality. The other one is to expand features by leveraging large ex-ternal knowledgebases such as Wikipedia and WordNet [33, 25, 17, 27]. These methods discover a set of explicit or implicit topics and then connect the short text through these topics. Using pre-defined topics or taxonomy relaxes the dependence on search engines. But its adaptability can be an issue since the pre-defined topics may not be available for certain applications [7], and the topic granularity is hard to be defined.
Query recommendation (QR) is a common tool used by search engines to assist users in searching or browsing information. When generating query recommendations for a user, a natural approach is to leverage the user search session (the user X  X  most recently submit-ted queries) [43], the clicked documents [9] or other log data [3]. Techniques for QR based on these context information have been studied extensively [38, 13, 2].

However, not all the scenarios of QR have such a sufficient con-text information, such as the application we mentioned in this paper -Recommending Queries to Channels . When there is a lack of user preference or any other query logs for a given target, existing ap-proaches are powerless in recommending high related queries to the targeted object. Bordino et al. [5] try to suggest interesting queries to users when they X  X e reading an article. Similarly, they don X  X  have any user preference. But the long text of the viewed article can be leveraged to recognize the core entities the user is interested in. But for a channel, the preference can not be obtained from one ar-ticle. In this case, we propose learning the topical preference of the targeted channel from its content, and map a given query to an appropriate channel from the topic level. From this perspective, our work seems to be similar to the issue of Query Classification (QC) [33]. However, QC only assigns a query a category. It does not refer to rank these queries after the classification.
In this paper, we propose a novel framework for short text clas-sification and ranking applications. Compared with existing ap-proaches for short text classification, our framework has two advan-tages: i) It measures the semantic similarities between short texts from the angle of concepts, so as to avoid surface mismatch. ii) Fewer training data are needed to learn the concept model per class, since few terms together are able to reflect one concept. These ad-vantages make it suitable for online lightweight applications that need to deal with short texts with requirements of fast learning and word changing adaption. We demonstrate the usage of our pro-posed framework through a real online application: Channel-based Query Recommendation . The experimental results show that our method can significantly improve classification precision by 9 : 73% and also perform well on diversity recommendation.

There is also much future work. For example, we can further im-prove it by exploiting the similarities between concepts. Besides, the classifier/ranking in current framework is actually a simple dis-tance model. It will be very interesting to incorporate powerful ma-chine learning techniques on top of the  X  X ag-of-Concepts X  vectors to improve the discrimination effectiveness.
This work was supported by NSFC (Grand Nos. 61170189, 61370126, 61202239), the Research Fund for the Doctoral Pro-gram of Higher Education (Grand No. 20111102130003), the Fund of the State Key Laboratory of Software Development Environment (Grand No. SKLSDE-2013ZX-19), and Microsoft Research Asia Fund (Grand No. FY14-RES-OPP-105). This work was partially supported by the National Key Basic Research Program (973 Pro-gram) of China under grant No. 2014CB340403 and the National Natural Science Foundation of China under grant No. M13210007. [1] C. C. Aggarwal and C. Zhai. Mining text data . Springer, [2] A. Anagnostopoulos, L. Becchetti, C. Castillo, and [3] R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query [4] S. M. Beitzel, E. C. Jensen, O. Frieder, D. D. Lewis, [5] I. Bordino, G. De Francisci Morales, I. Weber, and [6] C.-C. Chang and C.-J. Lin. Libsvm: a library for support [7] M. Chen, X. Jin, and D. Shen. Short text classification [8] C. Cortes and V. Vapnik. Support-vector networks. Machine [9] N. Craswell and M. Szummer. Random walks on the click [10] W. B. Croft, M. Bendersky, H. Li, and G. Xu. Query [11] H. K. Dai, L. Zhao, Z. Nie, J.-R. Wen, L. Wang, and Y. Li. [12] V. Dang and W. B. Croft. Diversity by proportionality: an [13] H. Feild and J. Allan. Task-aware query recommendation. In [14] E. Gabrilovich and S. Markovitch. Overcoming the [15] E. Gabrilovich and S. Markovitch. Computing semantic [16] J. He, V. Hollink, and A. de Vries. Combining implicit and [17] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting internal [18] L. Huang. Concept-based text clustering . PhD thesis, The [19] A. Jordan. On discriminative vs. generative classifiers: A [20] Y.-H. Kim, S.-Y. Hahn, and B.-T. Zhang. Text filtering by [21] T. Lee, Z. Wang, H. Wang, and S.-w. Hwang. Attribute [22] P. Li, H. Wang, K. Q. Zhu, Z. Wang, and X. Wu. Computing [23] R. Li, B. Kao, B. Bi, R. Cheng, and E. Lo. Dqr: a [24] X. Li, Y.-Y. Wang, and A. Acero. Learning query intent from [25] Y. Li, D. McLean, Z. A. Bandar, J. D. O X  X hea, and [26] H. T. Ng, W. B. Goh, and K. L. Low. Feature selection, [27] X.-H. Phan, L.-M. Nguyen, and S. Horiguchi. Learning to [28] J. R. Quinlan. Induction of decision trees. Machine learning , [29] M. Sahlgren and R. C X ster. Using bag-of-concepts to [30] G. Salton, A. Wong, and C.-S. Yang. A vector space model [31] D. Shen, R. Pan, J.-T. Sun, J. J. Pan, K. Wu, J. Yin, and [32] D. Shen, R. Pan, J.-T. Sun, J. J. Pan, K. Wu, J. Yin, and [33] D. Shen, J.-T. Sun, Q. Yang, and Z. Chen. Building bridges [34] F. Song and W. B. Croft. A general language model for [35] Y. Song, H. Wang, Z. Wang, H. Li, and W. Chen. Short text [36] F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of [37] A. Sun. Short text classification using very few words. In [38] I. Szpektor, A. Gionis, and Y. Maarek. Improving [39] Z. Wang, H. Wang, and Z. Hu. Head, modifier, and constraint [40] W. Wu, H. Li, H. Wang, and K. Q. Zhu. Probase: A [41] E. Yeh, D. Ramage, C. D. Manning, E. Agirre, and A. Soroa. [42] C. Zhai and J. Lafferty. A study of smoothing methods for [43] Z. Zhang and O. Nasraoui. Mining search engine query logs
