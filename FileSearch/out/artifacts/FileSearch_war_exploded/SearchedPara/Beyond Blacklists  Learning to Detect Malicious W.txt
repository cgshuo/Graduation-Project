 Malicious Web sites are a cornerstone of Internet criminal activi-ties. As a result, there has been broad interest in developing sys-tems to prevent the end user from visiting such sites. In this paper, we describe an approach to this problem based on automated URL classification, using statistical methods to discover the tell-tale lex-ical and host-based properties of malicious Web site URLs. These methods are able to learn highly predictive models by extracting and automatically analyzing tens of thousands of features poten-tially indicative of suspicious URLs. The resulting classifiers ob-tain 95 X 99% accuracy, detecting large numbers of malicious Web sites from their URLs, with only modest false positives. C.2.0 [ Computer-Communication Networks ]: General X  Secu-rity and protection ; I.5.1 [ Pattern Recognition ]: Models X  Statis-tical ; I.5.2 [ Pattern Recognition ]: Design Methodology X  Feature evaluation and selection Algorithms, Security supervised learning, malicious Web sites, L1-regularization
The Web has become a platform for supporting a wide range of criminal enterprises such as spam-advertised commerce (e.g., counterfeit watches or pharmaceuticals), financial fraud (e.g., via phishing or 419-type scams) and as a vector for propagating mal-ware (e.g., so-called  X  X rive-by downloads X ). Although the precise commercial motivations behind these schemes may differ, the com-mon thread among them is the requirement that unsuspecting users visit their sites. These visits can be driven by email, Web search re-sults or links from other Web pages, but all require the user to take some action, such as clicking, that specifies the desired Uniform Resource Locator (URL).
 Clearly, if one could inform users beforehand that a particular URL was dangerous to visit, much of this problem could be allevi-ated. To this end, the security community has responded by devel-oping blacklisting services  X  encapsulated in toolbars, appliances and search engines  X  that provide precisely this feedback. These blacklists are in turn constructed by a range of techniques including manual reporting, honeypots, and Web crawlers combined with site analysis heuristics. Inevitably, many malicious sites are not black-listed  X  either because they are too new, were never evaluated, or were evaluated incorrectly (e.g., due to  X  X loaking X ). To address this problem, some client-side systems analyze the content or behavior of a Web site as it is visited. But, in addition to run-time overhead, these approaches can expose the user to the very browser-based vulnerabilities that we seek to avoid.

In this paper, we focus on a complementary part of the design space: lightweight URL classification  X  that is, classifying the rep-utation of a Web site entirely based on the inbound URL. The mo-tivation is to provide inherently better coverage than blacklisting-based approaches (e.g., correctly predicting the status of new sites) while avoiding the client-side overhead and risk of approaches that analyze Web content on demand.

In particular, we explore the use of statistical methods from ma-chine learning for classifying site reputation based on the relation-ship between URLs and the lexical and host-based features that characterize them. Unlike previous work, we show that these meth-ods are able to sift through tens of thousands of features derived from publicly available data sources, and can identify which URL components and meta-data are important without requiring heavy domain expertise. Indeed, our system automatically selects many of the same features identified by domain experts as being typical of  X  X alicious X  Web sites. But more importantly, our system se-lects new, non-obvious features that are highly predictive and yield substantial performance improvements. We evaluate this approach across 20,000 to 30,000 URLs drawn from different sources, and show that it can obtain an overall prediction accuracy of 95 X 99%, detecting a large fraction of malicious websites while maintaining a very low false positive rate.

We begin the remainder of this paper with an explanation of the formal basis for our approach.
In this section, we provide a detailed discussion of our approach to classifying site reputation. We begin with an overview of the classification problem, followed by a discussion of the features we extract, and finally the set of machine learning classifiers we use for the study.

For our purposes, we treat URL reputation as a binary classifi-cation problem where positive examples are malicious URLs and negative examples are benign URLs. This learning-based approach to the problem can succeed if the distribution of feature values for malicious examples is different from benign examples, the training set shares the same feature distribution as the testing set, and the ground truth labels for the URLs are correct.

Significantly, we classify sites based only on the relationship be-tween URLs and the lexical and host-based features that character-ize them, and we do not consider two other kinds of potentially use-ful sources of information for features: the URL X  X  page content, and the context of the URL (e.g., the page or email in which the URL is embedded). Although this information has the potential to im-prove classification accuracy, we exclude it for a variety of reasons. First, avoiding downloading page content is strictly safer for users. Second, classifying a URL with a trained model is a lightweight operation compared to first downloading the page and then using its contents for classification. Third, focusing on URL features makes the classifier applicable to any context in which URLs are found (Web pages, email, chat, calendars, games, etc.), rather than dependent on a particular application setting. Finally, reliably ob-taining the malicious version of a page for both training and testing can become a difficult practical issue. Malicious sites have demon-strated the ability to  X  X loak X  the content of their Web pages, i.e., serving different content to different clients [20]. For example, a malicious server may send benign versions of a page to honeypot IP addresses that belong to security practitioners, but send mali-cious versions to other clients. Nonetheless, we show in Section 4 that classifying on lexical features of the URL and features about the host are sufficient for highly accurate prediction.
We categorize the features that we gather for URLs as being ei-ther lexical or host-based.

Lexical features: The justification for using lexical features is that URLs to malicious sites tend to  X  X ook different X  in the eyes of the users who see them. Hence, including lexical features allows us to methodically capture this property for classification purposes, and perhaps infer patterns in malicious URLs that we would other-wise miss through ad-hoc inspection.

For the purpose of this discussion, we want to distinguish the two parts of a URL: the hostname and the path. As an example, with the URL www.geocities.com/usr/index.html , the hostname portion is www.geocities.com and the path portion is usr/index.html .

Lexical features are the textual properties of the URL itself (not the content of the page it references). We use a combination of features suggested by the studies of McGrath and Gupta [16] and Kolari et al. [13]. These properties include the length of the host-name, the length of the entire URL, as well as the number of dots in the URL  X  all of these are real-valued features. Additionally, we create a binary feature for each token in the hostname (delimited by  X . X ) and in the path URL (strings delimited by  X / X ,  X ? X ,  X . X ,  X = X ,  X - X  and  X  X  X ). This is also known as a  X  X ag-of-words. X  Although we do not preserve the order of the tokens, we do make a distinction between tokens belonging to the hostname, the path, the top-level domain (TLD) and primary domain name (the domain name given to a registrar). More sophisticated techniques for modeling lexical features are available, such as Markov models of text. However, even with the bag-of-words representation, we can achieve very accurate classification results.

Host-based features: The reason for using host-based features is that malicious Web sites may be hosted in less reputable host-ing centers, on machines that are not conventional web hosts, or through disreputable registrars. To an approximate degree, host-based features can describe  X  X here X  malicious sites are hosted,  X  X ho X  own them, and  X  X ow X  they are managed.

The following are properties of the hosts (there could be multi-ple) that are identified by the hostname part of the URL. We note some of these features overlap with lexical properties of the URL. 1. IP address properties  X  Is the IP address in a blacklist? Are 2. WHOIS properties  X  What is the date of registration, update, 3. Domain name properties  X  What is the time-to-live (TTL) 4. Geographic properties  X  In which continent/country/ city This list of features we use is not exhaustive, as there is always the possibility of generating or aggregating new meta-information about the URL such as popularity rankings in Netcraft, indexing in Google, etc. Nevertheless, the list is still extensive, as it repre-sents many pieces of information about the URL and host (much of which is publicly available) that we can collect efficiently through the automated crawling tools at our disposal.
We use the features described in the previous section to encode individual URLs as very high dimensional feature vectors. Most of the features are generated by the  X  X ag-of-words" representation of the URL, registrar name, and registrant name; binary features are also used to encode all possible ASes, prefixes and geographic locales of an IP address. The resulting URL descriptors typically have tens of thousands of binary features.

The high dimensionality of these feature vectors poses certain challenges for classification. Though only a subset of the generated features may correlate with malicious Web sites, we do not know in advance which features are relevant. More generally, when there are more features than labeled examples, we enter the regime in which statistical models are most prone to overfitting.

In this section, we briefly review the models that we studied for classification, as well as their relative strengths and weaknesses. For all these models, we adopt the following notation. We use n to denote the number of labeled examples in the training set and d to denote the dimensionality of the feature space (i.e., the number of features). We use x  X  X  X  d to denote a feature vector and x denote its j th component. Finally, we use y  X  X  0 , 1 } to denote the label of an example, with y = 1 for malicious sites and y = 0 for benign ones.

We provide further details on the individual classifiers below. In particular, for each classifier, we briefly describe its testing process (how it predicts a label from the features of URLs) and its training process (how it learns the decision rule to predict these labels).
Naive Bayes: Commonly used in spam filters, this basic model assumes that for a given label, the individual features of URLs are distributed independently of the values of other features [5]. Let-ting P ( x | y ) denote the conditional probability of the feature vec-tor given its label, the model assumes P ( x | y ) = Q d j =1 Then, from Bayes rule, assuming that malicious and benign Web sites occur with equal probability, we compute the posterior proba-bility that the feature vector x belongs to a malicious URL as: Finally, the right hand side of eq. (1) can be thresholded to predict a binary label for the feature vector x .

A Naive Bayes classifier is most easily trained by computing the conditional probabilities P ( x j | y ) from their maximum likelihood estimates [5]. For real-valued features, we model P ( x j Gaussian distribution whose mean and standard deviation are com-puted over the j th component of feature vectors in the training set with label y . For binary-valued features, we estimate P ( x as the fraction of feature vectors in the training set with label y for which the j th component is one.

The model parameters in the Naive Bayes classifier are estimated to maximize the joint log-likelihood of URL features and labels, as opposed to the accuracy of classification. Optimizing the lat-ter typically leads to more accurate classifiers, notwithstanding the increased risk of overfitting.

Support Vector Machine (SVM): SVMs are widely regarded as state-of-the-art models for binary classification of high dimen-sional data. SVMs are trained to maximize the margin of cor-rect classification, and the resulting decision boundaries are robust to slight perturbations of the feature vectors, thereby providing a hedge against overfitting. The superior generalization abilities of SVMs have been borne out by both theoretical studies and experi-mental successes [23].

The decision rule in SVMs is expressed in terms of a kernel function K ( x , x  X  ) that computes the similarity between two feature vectors and non-negative coefficients {  X  i } n i =1 that indicate which training examples lie close to the decision boundary. SVMs classify new examples by computing their (signed) distance to the decision boundary. Up to a constant, this distance is given by: where the sum is over all training examples. The sign of this dis-tance indicates the side of the decision boundary on which the ex-ample lies. In practice, the value of h ( x ) is thresholded to predict a binary label for the feature vector x .

SVMs are trained by first specifying a kernel function K ( and then computing the coefficients  X  i that maximize the margin of correct classification on the training set. The required optimiza-tion can be formulated as an instance of quadratic programming, a problem for which many efficient solvers have been developed [6]. In our study, we experimented with both linear and radial basis function (RBF) kernels.

Logistic Regression: This is a simple parametric model for bi-nary classification where examples are classified based on their dis-tance from a hyperplane decision boundary [11]. The decision rule is expressed in terms of the sigmoid function  X  ( z ) = [1 + e  X  which converts these distances into probabilities that feature vec-tors have positive or negative labels. The conditional probability that feature vector x has a positive label y =1 is the following: where the weight vector w  X  X  X  d and scalar bias b are parameters to be estimated from training data. In practice, the right hand side of eq. (3) is thresholded to obtain a binary prediction for the label of the feature vector x .

We trained models for logistic regression using a regularized form of maximum likelihood estimation. Specifically, we chose the weight vector w and bias b to maximize the objective function: The first term computes the conditional log-likelihood that the model correctly labels all the examples in the training set. The second term in eq. (4) penalizes large magnitude values of the elements in the weight vector w . Known as  X  1 -norm regularization, this penalty not only serves as a measure against overfitting, but also encourage s sparse solutions in which many elements of the weight vector are exactly zero. Such solutions emerge naturally in domains where the feature vectors contain a large number of irrelevant features. The relative weight of the second term in eq. (4) is determined by the regularization parameter. We selected the value of  X  in our experi-ments by cross validation.

We included  X  1 -regularized logistic regression for its potential advantages over Naive Bayes and SVMs in our particular domain. Unlike Naive Bayes classification, the parameters in logistic regres-sion are estimated by optimizing an objective function that closely tracks the error rate. Unlike SVMs,  X  1 -regularized logistic regres-sion is especially well suited to domains with large numbers of ir-relevant features. (In large numbers, such features can drown ou t the similarities between related examples that SVMs expect to be measured by the kernel function.) Finally, because  X  1 -regularized logistic regression encourages sparse solutions, the resulting mod-els often have decision rules that are easier to interpret in terms of relevant and irrelevant features.
This section describes the data sets that we use for our evalu-ation. For benign URLs, we used two data sources. One is the DMOZ Open Directory Project [19]. DMOZ is a directory whose entries are vetted manually by editors. The editors themselves go through a vetting process, with editors given responsibility for larger portions of the directory as they gain trust and experience. The second source of benign URLs was the random URL selector for Yahoo X  X  directory. A sample of this directory can be generated by visiting http://random.yahoo.com/bin/ryl .
 We also drew from two sources for URLs to malicious sites: PhishTank [21] and Spamscatter [3]. PhishTank is a blacklist of phishing URLs consisting of manually-verified user contributions. Spamscatter is a spam collection infrastructure from which we ex-tract URLs from the bodies of those messages. Note that the ma-licious URL data sets have different scopes. PhishTank focuses on phishing URLs, while Spamscatter includes URLs for a wide range of scams advertised in email spam (phishing, pharmaceuticals, soft-ware, etc.). Both sources include URLs crafted to evade automated filters, while phishing URLs in particular may be crafted to visually trick users as well.

Table 1 summarizes the number and types of features in the data sets that we use in our evaluations. The four data sets con-sist of pairing 15,000 URLs from a benign source (either Yahoo or DMOZ) with URLs from a malicious source (5,500 from Phish-Tank and 15,000 from Spamscatter). We refer to these sets as the DMOZ-PhishTank (DP), DMOZ-Spamscatter (DS), Yahoo-Phish-Tank (YP), and Yahoo-Spamscatter (YS) sets. We collected URL features between August 22, 2008  X  September 1, 2008.

We normalized the real-valued features in each feature set to Table 1: Breakdown of feature types for data sets used in eval-uations. lie between zero and one, shifting and rescaling each real-valued feature so that zero and one corresponded to the minimum and maximum values observed in the training set. Values outside this range in the testing set were clipped to zero or one as appropriate. The normalization served to equalize the range of the features in each feature set, both real-valued and binary. Intuitively, it reflects our prior belief that the real-valued and binary-valued features are equally informative and therefore should be calibrated on the same measurement scales.

One further complication arises due to undefined, or missing, features. Many real-valued features are undefined for large num-bers of examples in the data set (e.g., DNS time-to-live values). We handled missing values using the following heuristic: for each real-valued feature, we defined an extra binary feature indicating whether the feature was defined. This heuristic enables the classi-fiers to learn how to treat missing features from the way they appear in the training set.
In this section, we evaluate the effectiveness of the classifiers on identifying URLs to malicious sites. Specifically, we want to answer the following questions: Does using more features lead to more accurate classification? What is the most appropriate classifi-cation model to use? What is the impact on accuracy if we tune the classifier for lower false positives? Can we effectively classify data from once source with a model that was trained on a different data source? What trends do we see among the relevant features? And what do the misclassified examples have in common?
We start by describing our experimental methodology. For each feature set and data set in our experiments, we perform classifi-cation over 10 random splits of the data, and the splits are 50/50 between training and testing. We learn a decision threshold t that will minimize the overall classification error (see Section 2.2 for methodology of learning t ). We show the average classification results of those 10 splits.
 We ran our experiments on a machine with 2 dual-core 2.33 GHz Xeon processors with 4 GB memory. Memory exhaustion was not an issue, but typical usage was on the order of a few hundred megabytes. We implemented a Naive Bayes solver in MATLAB. For the SVM solvers, we used the .mex implementations of LIB-SVM [6] and LIBLINEAR [7] that interface with MATLAB. We Figure 1: Error rates for LR with nine features sets on each of the four URL data sets. Overall, using more features improves classification accuracy. implemented a custom optimizer for  X  1 -regularized logistic regres-sion in MATLAB using multiplicative updates [24].
Our first experiments on URL classification were designed to explore the potential benefits of considering large numbers of auto-matically generated features as opposed to small numbers of man-ually chosen features. Fig. 1 compares the classification error rates on the four data sets described in Section 3 using nine different sets of features. The different feature sets involve combinations of features reflecting various practical considerations. For brevity, we only show detailed results from  X  1 -regularized logistic regression (LR), which yields both low error rates (see Section 4.3) and also highly interpretable models (see Section 4.6). However, the other classifiers also produce qualitatively similar results.

Table 2 shows the total number of features in each feature set for the Yahoo-PhishTank data set. For these experiments, we also re-port the number of relevant features that received non-zero weight from  X  1 -regularized logistic regression. (The other three data sets yield qualitatively similar results.) The feature sets are listed in as-cending order of the total number of features. In what follows, we describe the detailed compositions of these feature sets, as well as their effects on classification accuracy.
 We start with a  X  X asic X  feature set that corresponds to the set of URL-related (not content-related) heuristics commonly chosen by various anti-phishing studies, including Fette et al. [8], Bergholz et al. [4] and CANTINA [28]. This set consists of four features: the number of dots in a URL, whether the hostname contains an IP address, the WHOIS registration date (a real-valued feature), and an indicator variable for whether the registration date is defined. Under this scheme, the classifier achieves a 10% error rate. The next three feature sets (Botnet, Blacklist, and Blacklist + Botnet) represent the use of current spam-fighting techniques for predicting malicious URLs. The features for  X  X otnet X  are from the SpamAssassin Botnet plugin (Section 2.1). These consist of five binary features indicating the presence of certain client-or server-specific keywords, whether the hostname contains an IP address, and two more features involving the PTR record of the host. With these features, we obtain a 15% error rate at best. Table 2: Total and relevant number of features for the LR clas-sifier and the Yahoo-PhishTank data set. We reference the over-all error rate from Figure 1.

The  X  X lacklist X  feature set consists of binary variables for mem-bership in six blacklists (and one white list) run by SORBS, URIBL, SURBL, and Spamhaus. These lists combined provide at best a 20% error rate. When we combine the blacklists with the SpamAs-sassin Botnet plugin features in the  X  X lacklist+Botnet X  feature set, the error rate improves to 12%.

These small features sets are reasonably effective, but including features that result in very large feature sets significantly improve classification accuracy.

The WHOIS registration date was a popular feature in previous studies [8][4][28]. Inspired by these examples, we also create a WHOIS feature set that includes the registration date as well addi-tional WHOIS properties. The  X  X HOIS X  set we evaluated includes the registration, update, and expiration dates, as well as a bag-of-words representation of the registrar and registrant. The feature set grows to nearly 4,000 on the YP data set (Table 2.1), while reduc-ing the error to 3 X 15% across the data sets. WHOIS features can provide useful information for differentiating malicious and benign URLs, since creators of legitimate sites are likely to adopt different registration patterns than creators of malicious sites (whose sites are taken down more frequently, or who want to anonymize their registration information).

WHOIS features, however, are just a subset of the available host-based features. If we also include the remainder of our host-based features  X  IP, DNS, and geographic properties as well as mem-bership in a blacklist and SpamAssassin Botnet plugin features  X  the feature sets from our data sets grow to over 10,000 features. And these additional features are beneficial: the LR classifier has an even lower error rate of 1.2 X 6%. Using host-based features pro-vides a richer set of properties for the classifier to capture phenom-ena such as malicious sites being hosted from a particular IP prefix, ISP, country and the like.

In addition to host-based features, we can also use lexical prop-erties of the URLs themselves as potentially strong features (again, we are not considering the Web page content). That is, if the URLs themselves  X  X ook X  malicious, then a lexical feature set can help us automatically learn the tell-tale strings that characterize a malicious or benign URL. For example, malicious sites may have legitimate-looking tokens appended to the sub-domain of the hostname, or have them embedded in the path of the URL for obfuscation pur-poses. In the  X  X exical X  set, we consider a  X  X ag-of-words X  represe n-tation of the tokens in the URL augmented with additional proper-ties such as the length of the hostname, the length of the entire URL and the number of dots. This is indeed an effective feature set, with a resulting error is between 1.9% and 3.5%.

Combining the host-based and lexical features into the  X  X ull X  feature set, we obtain the lowest classification error among all fea-ture sets at 0.9 X 3.0%. For YP, the FP/FN rates are 0.8%/2.6%. Figure 2: Overall error rates for the  X  X ull X  feature set using different classification algorithms and data sets. The SVM and LR classifiers do well with large feature sets such as  X  X ull X  as compared to Naive Bayes.

Finally, blacklists and WHOIS information provide us known high-quality information for classifying URLs. But do the low clas-sification error rates of the  X  X ull X  feature set critically depend on those particular features? The results for  X  X /o WHOIS/Blacklist X  show the error rates without WHOIS and blacklist features are 1.1 X  3.4%. Since the error rates across this feature set remain close to those of the  X  X ull X  set, we find that the remaining features provide sufficient information for achieving accurate classification results  X  using high-quality WHOIS and blacklist information is not nec-essary for excellent results.

Having reviewed the composition and results for each feature set, we point out two noticeable trends: (1) Before  X  X HOIS, X  the DMOZ-PhishTank set has similar error rates to Yahoo-PhishTank, but starting with  X  X HOIS X  the Yahoo-trained set has lower error. This happens because the distribution of WHOIS and lexical fea-tures between DMOZ and Yahoo are distinct enough that certain URL tokens and certain WHOIS properties receive more weight in one data set than the other. (2) Prior to  X  X HOIS, X  the PhishTank-trained sets have better error rates because PhishTank Web sites have more undefined WHOIS registration dates (hence better  X  X a-sic X  results), more IP addresses in the hostname (better  X  X otnet X  results), and more URLs in blacklists (better  X  X lacklist X  results). But starting with  X  X HOIS, X  the Spamscatter-trained sets do bet-ter because the introduction of registrar/registrant names provides a wealth of information for differentiating malicious and benign sites, and the distribution of lexical tokens in Spamscatter is dis-tinct enough from benign sources to provide traction for accurate classification results.

These results demonstrate that different data sets provide differ-ent feature distributions for distinguishing malicious and benign URLs. Rather than manually discovering and adjusting the deci-sion rules for different data sets, machine learning techniques can adapt to these differing distributions by learning the appropriate de-cision rules automatically.
Next we compare the accuracy of the four classifiers described in Section 2, each of which has different tradeoffs between model complexity and training execution time. We use the  X  X ull X  feature set from Section 4.2 for comparison.

Figure 2 compares the results of the classifiers: Naive Bayes (Bayes), SVM with a linear kernel (SVM-lin), SVM with an RBF kernel (SVM-rbf), and  X  1 -regularized logistic regression (LR). The bars show the overall error rates for each classifier on each of our four data sets. Additionally, Table 3 shows the training and testing times for each classifier. The cross-validation time refers specifi-cally to the cross-validation process used in LR to choose a regu-larization constant. Although expensive, it can be effectively amor-tized when training over time.
 Table 3: Training and testing times for the Yahoo-PhishTank data set.
 The SVM and LR classifiers have at least half of the error of Naive Bayes, which is not surprising given the models that we chose. Naive Bayes is a classifier that sees wide-spread use in spam filters and related security applications, in part because the training and testing performance of Naive Bayes is fast. However, the bene-fit of reduced training time is outweighed in this case by the benefit of using classifiers whose explicit goal is to minimize errors. This tradeoff is particularly worthwhile when we are dealing with a large feature set.

As mentioned in Section 2.2, SVM classifiers can perform poorly if irrelevant features in a large feature set make the kernel functions poor measures of similarity. Given that the difference in error be-tween SVM and LR is so small, though, this problem did not mate-rialize in our data set. As such, we continue to show the results for LR for the remaining experiments because of its interpretability, which is useful for understanding how the model performs (Sec-tion 4.6) and how it might be improved (Section 4.7).
An advantage of using these models is that they can tradeoff false positives and false negatives. We have seen in the previous sections that classifying with the  X  X ull X  feature set yields very low overall error rates. For policy reasons, however, we may not want to choos e a decision threshold t to minimize the overall error rate. Instead, we may want to tune the threshold to have very low false positives at the expense of more false negatives (or vice versa).

Consider blacklisting as a motivating example. Blacklisting has the intrinsic advantage that it will have very low false positives. Suppose a network administrator wants to take advantage of the benefits of classifying over a full feature set while maintaining the low false positives of a blacklist-only policy as applied to URL classification. To do so, we can select a threshold for the full feature set that will yield a false positive rate competitive with blacklisting while having a much lower false negative rates.

Figure 3 shows the results of this experiment as an ROC graph with respect to the decision threshold t . We see that even if we tune the decision threshold of the full-featured classifier to the same false positives as a blacklist-only classifier, the full-featured classi-fier still predicts malicious URLs with much better accuracy than with blacklists alone.
Coupling the appropriate classifier with a large feature set can yield a highly accurate classifier when trained and tested on disjoint sets of the same data source. But do these results hold when train-ing and testing examples are drawn from different data sources? To answer this question, we experiment with training and testing on various combinations of benign and malicious sources of URLs. (We use the abbreviations defined in Section 3 to refer to each com-bination of data sources, e.g. YP for Yahoo-PhishTank).

Table 4 shows classification results using  X  1 -regularized logistic Figure 3: Tradeoff between false positives and false negatives: ROC graph for LR over an instance of the Yahoo-PhishTank data set using (1) the  X  X ull X  feature set and (2) blacklists only. We highlight the points where the false positives are tuned to 0.1%.
 Table 4: Overall error rates when training on one data source and testing on another (possibly different) data source using the LR classifier. regression. Each row represents a pairing of benign and malicious URL training sources, and each column represents a pairing of be-nign and malicious URL testing sources. As expected, the entries along the NW-SE diagonal yield the lowest classification errors be-cause they represent matching similar data sources (these numbers are repeated from previous experiments). When only the benign URL source is mismatched (e.g., YS and DS), error increases due to higher false positives. And if only the malicious URL source is mismatched (e.g., YS and YP), error increases due to higher false negatives. Nevertheless, we note that training on the Spamscatter set  X  which includes URLs advertising a wide range of scam sites  X  generally performs better on a mismatched source (YS-YP at 6%, DS-DP at 14%) than the PhishTank set (YP-YS at 21%, DP-DS at 23%)  X  which focuses only on phishing sites (Section 3).
Finally, if the training and testing sources are completely mis-matched (SW-NE diagonal), the error ranges between 18 X 44%. Al-though better than random, the disparity in accuracy emphasizes the judicious selection of training data. This selection is of partic-ular importance for use in a deployment: the training data should reflect the  X  X esting X  environment in which the system is used. To that end, if we use all four training sources, the generalization abil-ity of the classifier is strong across all testing sources (last row). Thus, in a deployed system practitioners will want to pay special attention to collecting training data that is representative.
Besides high classification accuracy, LR has the advantages of performing automatic feature selection as well as providing an in-terpretable linear model of the training data. In particular, because the output of a linear model depends on the weighted sum of the features, the sign and magnitude of the individual parameter vector coefficients can tell us how individual features contribute to a  X  X a-licious X  prediction or a  X  X enign X  prediction. Positive coefficients Table 5: Breakdown of features for LR for an instance of the Yahoo-PhishTank data set. We show total number of features in each feature type category, the number of relevant (non-zer o) features, as well as the number of selected features with nega-tive (benign) and positive (malicious) coefficients. correspond with malicious features while negative coefficients cor-respond with benign features. Additionally, the training phase for  X  -regularized logistic regression yields a sparse parameter vec-tor w where the number of non-zero coefficients is much smaller than the total number of features, making it easier for us to focus on a smaller number of relevant features (a zero coefficient means that the corresponding feature will not contribute to the prediction outcome). These properties simplify the analysis of trends in mali-cious and benign features.

In this section, we analyze the model that LR constructed for one of the ten random splits of the Yahoo-PhishTank data set, and discuss trends that we observe in the model and correlate them with real-world phenomena. This example has 3,962 active (non-zero) features out of a total of 30,783 features. There are 1,658 negativ e (benign) coefficients and 2,304 positive (malicious) coefficients in the weight vector. Table 5 shows a breakdown of the different types of features selected in this LR model. Overall, we find that the automatic feature selection of certain feature groups are specific to the data set at hand, while other feature types indicate broader trends in malicious sites.

Not surprisingly, the weights learned for the blacklist features are all non-zero because the presence of domain names and IPs in one of the six blacklists, or its absence in the whitelist, is an accurate indicator of maliciousness.

Additionally, the weights selected for the  X  X pamAssassin plu-gin X  features match their purpose as an indicator. For example, the model learned negative weights for having server words in the host-name, PTR records, and full-circle records. And it learned positive weights for having client words or an IP address in the hostname.
The miscellaneous IP address properties indicate whether the A record of a host shares the same prefix or AS as its MX or NS record. These features are considered benign on all counts, which makes sense because hosting the Web site and email server in the same data center reflects a more orthodox hosting setup that a cus-tomer would purchase through legitimate means, as opposed to a hosting infrastructure acquired by compromising a scattered array of machines.

Next, the classifier selected 40 out of the 284 top-level TLD fea-tures. Generic TLDs like  X .gov X ,  X .edu X ,  X .com X ,  X .org X , and cou ntry-level TLDs like  X .ca X  and  X .se X  are the top-6 benign features by weight. By contrast,  X .info X ,  X .kr X ,  X .it X ,  X .hu X , and  X .es X  form the top-6 malicious features by weight, domains correlated with some malicious sites.

For hostname tokens that do not include the TLD, the model selected 315 out of 3,112 features. Some interesting examples of malicious hostname tokens include the appearance of  X  X om X  in the name, resulting from URLs to malicious sites that prepend the to-kens of legitimate hostnames (e.g., from banks) as an obfuscation measure. And while it is no surprise to see that the presence of  X  X ww X  is considered a benign (albeit spoofable) feature,  X  X embers X  receives the most negative weight because of its co-occurrence with benign sites hosted on  X  X embers.aol.com X ,  X  X embers.tripod.com X  and other free hosting services.

Although the URL X  X  path tokens contribute the most features (about 8,000), the model selects 419 relevant path tokens during training, 324 of which are malicious. Among the automatically se-lected malicious features are  X  X ccount X ,  X  X ebscr X ,  X  X ogin X ,  X  X bayis-api X ,  X  X ignin X ,  X  X anking X , and  X  X onfirm X   X  for comparison, these tokens the model learned automatically are also 7 out of the 8 manually chosen path tokens that were considered tell-tale phish-ing features in the study by Garera et al. [9]. Additional selected path tokens include  X  X mages X ,  X  X om X ,  X  X ww X , and  X  X aypal X . To-kens like these indicate attempts by the site authors to spoof le-gitimate sites by including domain names within the URL path ( X  X ww.example.com X ). Even  X  X ttp: X  is considered a malicious fea-ture, aiding in the prediction of URLs that attempt to hide legitimate-looking URLs in the path component (the case of using a legitimate domain X  X  redirection facilities was more rare).

Out of the 3,959 WHOIS information features (mainly tokens in the names of the registrar and registrant of the domain name), the classifier selected 633 as relevant. As for dates in the WHOIS record, missing any of the three WHOIS dates (registration, update, expiration) is considered a malicious feature. Moreover, having a recent registration or update date is considered malicious  X  this corresponds with the behavior of malicious sites having newer reg-istration dates because they are taken down more frequently. Hav-ing a newer expiration date is the only benign WHOIS date feature. For connection speed features, the model selected 19 out of 29. Having a T1 speed for the DNS A and MX records are the top-2 be-nign features, while a residential cable, DSL or satellite connection hosting an address in the A, MX or NS record of an entry is consid-ered malicious. These features reflect the phenomenon of malicious sites hosted on compromised machines in residential ISPs.
Finally, the selected DNS A/MX/NS record features and geo-graphic features correspond to hosting activity associated with var-ious regions of the Internet address space. For example, IP ranges belonging to Google, Yahoo and AOL are treated as benign fea-tures. Also, having DNS NS records in IP ranges belonging to major registrars such as RIPE (the network information center for Europe) are considered benign features. However, having an NS record in one of the IP prefixes run by GoDaddy is considered a malicious feature.

Overall, the classifier was able to automatically select malicious and benign features for which domain experts had prior intuition. Perhaps more importantly, the classifier automatically selected new, non-obvious features that were highly predictive and yielded addi-tional, substantial performance improvements.

When faced with such a reputation system, the ability of adver-saries to evade detection depends on their ability to avoid conform-ing to the trends and selections determined by the classifier; we discuss the issue further in Section 5.
A machine learning approach using a full feature set, consist-ing of both lexical and host-based features, yields a URL repu-tation classifier that has low false positive and low false negative rates. Despite the high accuracy of this approach, in this section we examine examples of misclassified URLs to reveal trends that can suggest refinements to our current approach, and also help us understand the limitations of using just URL features for classi-fication (as opposed to additionally including features from Web page content). For our analysis, we examine one of the instances of the Yahoo-PhishTank data sets from the LR classifier, chosen ran-domly, which had 60 false positives and 71 false negatives (other instances resulted in similar conclusions).

The most common cause of false positives (benign sites mistak-enly classified as malicious) was due to sites hosted at disreputable ISPs. This is a case of guilt by association  X  our classifier penal-izes legitimate sites hosted in the same AS or IP prefix as malicious sites. This set of false positives could be mitigated by examin-ing the content of a site. Also, if reputation systems become more prevalent, such false positives imply that it would behoove legiti-mate site owners to seek service providers that have a reputation for cracking down on malicious sites hosted on their networks.
The false negatives (undetected malicious sites) fell into the fol-lowing categories: (1) URLs to sites with benign tokens in the URL, (2) malicious sites using free hosting services (such as  X  X eoc-ities.com X  or  X  X ripod.com X ), (3) compromised sites, (4) redirection services, (5) sites hosted in reputable geographic regions (such as the US), and (6) sites with international TLDs hosted in the US. The first category shows that if certain lexical features have substantial weights in classification, false negatives can result. Eliminating this false negative could be accomplished by more careful vetting of which URL tokens become features.

The last five categories are related because they reflect the situ-ation where host-based features of a malicious URL appear to be non-malicious. However, the remedies for mitigating these kinds of false negatives differ. For example, eliminating malicious sites in category (3) is a matter of encouraging sites to maintain up-to-date patches of software, and category (5) reflects the practice of purchasing services from a reputable ISP; such remedies, though, are out of the control of a reputation system. However, the closely-related category (6) sites could be addressed by adding features that indicate whether the country of a site X  X  TLD corresponds to the country where the ISP is located. Finally, mitigating false neg-atives in (2) and (4) may require examining the content of a site.
If deployed and effective, adversaries will naturally try to in-vent methods for evading this statistical modeling approach. As we discussed in Section 2, the effectiveness of statistical modeling depends on a few key assumptions. When hosting malicious sites, adversaries can try to violate these assumptions to evade detection.
One approach for evasion is to reduce the information content in the lexical features of URLs. For example, using redirection ser-vices such as TinyURL produces fewer distinguishing lexical fea-tures (e.g., an identical host name coupled with a random token). Another approach is to acquire many benign host-based features, such as hiding behind the well-provisioned infrastructure provided by legitimate free hosting services (e.g.,  X  X eocities.com X  or  X  X ri-pod.com X ). These aliasing techniques could provide adversaries methods for misclassifying their sites as benign.

As discussed in Section 4.6, the weights assigned to features in our classifiers reflect trends in the features of malicious and benign URLs. An adversary evading detection can strive to craft a site that can spoof sufficient benign features with high weights, and avoid acquiring sufficient malicious features, to appear as a benign site to the detection algorithm. For instance,  X .org X  is a benign TLD according to our classifier, yet costs only $10/year to register.
There are, however, functional and cost-related limits to an ad-versary X  X  ability to forge features. For instance, older WHOIS reg-istration dates have high weights as benign features, but are difficult to casually obtain for malicious sites. Further, whether a site ap-pears on a blacklist is out of its control. Whether such features are sufficient in the long term for differentiating benign from malicious sites remains an open question. As with any security approach fac-ing an adaptable adversary, though, we envision having to evolve a deployment in response over time.
This section surveys related approaches in URL classification, related applications of statistical modeling, and other techniques.
The work by Garera et al. is the most closely related to our study [9]. They use logistic regression over 18 hand-selected fea-tures to classify phishing URLs. The features include the presence red flag key words in the URL, features based on Google X  X  Page Rank and Google X  X  Web page quality guidelines. Although a di-rect comparison with our approach is difficult without access to the same URLs or features, they achieve a classification accuracy of 97.3% over a set of 2,500 URLs. Though similar in motivation and methodology, our approach differs significantly in both scope (aim-ing to detect other types of malicious activity) and scale (consider-ing an order-of-magnitude more features and training examples).
McGrath and Gupta do not construct a classifier but neverthe-less perform a comparative analysis of phishing and non-phishing URLs [16]. For examples, they compare non-phishing URLs drawn from the DMOZ Open Directory Project [19] to phishing URLs from PhishTank [21] and a non-public source. The features they analyze include IP addresses, WHOIS thin records (containing date and registrar-provided information only), geographic information, and lexical features of the URL (length, character distribution, and presence of pre-defined brand names). We build on their work by incorporating similar sources and features into our approach.
Provos et al. perform a study of drive-by exploit URLs and use a patented machine learning algorithm as a pre-filter for VM-based analysis [22]. Unlike our approach, they extract content-based fea-tures from the page, including whether IFrames are  X  X ut of place, X  the presence of obfuscated javascript, and whether IFrames point to known exploit sites.

CANTINA classifies phishing URLs by thresholding a weighted sum of 8 features (4 content-related, 3 lexical, and 1 WHOIS-related) [28]. Among the lexical features, it looks at dots in the URL, whether certain characters are present, and whether the URL contains an IP address. The WHOIS-related feature CANTINA ex-amines is the age of the domain. We use similar features in our approach, but entirely different models of classification.
Fette et al. use statistical methods in machine learning to clas-sify phishing emails [8]. Their classifiers examine the properties of URLs contained within a message (e.g., the number of URLs, number of domains, and number of dots in a URL), but unlike our approach they also consider features of the email structure and con-tent. Bergholz et al. further improve the accuracy of Fette et al. by introducing models of text classification to analyze email con-tent [4]. Abu-Nimeh et al. compare different classifiers over a cor-pus of phishing emails, using as features the frequency of the 43 most-popular words in the corpus [1].

Kolari et al. use URLs found within a blog page as features to de-termine whether the page is spam [13]. They use a  X  X ag-of-words X  representation of URL tokens, and we use a similar set of features.
Highly Predictive Blacklists use a Page Rank-style algorithm to estimate the likelihood that an IP address will conduct a network intrusion against particular networks [27].

Moshchuk et al. use VMs to analyze downloaded trojan executa-bles, relying on third-party anti-spyware tools to detect whether VMs were infected by executables [18]. Wang et al. detect drive-by exploits by using behavioral detection (monitoring anomalous state changes in the VM) as well as detecting exploits of known vulnera-bilities [25]. Provos et al. monitor VM state changes and use multi-ple anti-virus engines to detect VM infection [22]. Moshchuk et al. also construct a VM-based web proxy defense that uses behavior-based detection and adds only a few seconds of overhead to page rendering for the end-client [17].

Many commercial efforts exist to detect malicious URLs, includ-ing McAfee SiteAdvisor [15], IronPort Web Reputation [12], the WebSense ThreatSeeker Network [26], WOT Web of Trust [2], and Google Toolbar [10]. These approaches are based on blacklist con-struction, user feedback, and proprietary feature analysis.
We have described an approach for classifying URLs automat-ically as either malicious or benign based on supervised learning across both lexical and host-based features. We argue that this ap-proach is complementary to both blacklisting  X  which cannot pre-dict the status of previously unseen URLs  X  and systems based on evaluating site content and behavior  X  which require visiting potentially dangerous sites. Further, we show that with appropriate classifiers it is feasible to automatically sift through comprehensive feature sets (i.e., without requiring domain expertise) and identify the most predictive features for classification.

An open issue is how to scale our approach to handle millions of URLs whose features evolve over time. We address the issue in subsequent work by using online learning algorithms [14]. Thanks go to Alvin AuYoung, Kirill Levchenko, Patrick Verkaik and Michael Vrable for insightful comments on earlier drafts of this paper. Thanks to anonymous reviewers for their valuable feedback. This work was supported by National Science Foundation grants NSF-0238323, NSF-0433668 and NSF-0829469 and by generous research, operational and in-kind support from Cisco, Google, Mi-crosoft, Yahoo and the UCSD Center for Networked Systems.
