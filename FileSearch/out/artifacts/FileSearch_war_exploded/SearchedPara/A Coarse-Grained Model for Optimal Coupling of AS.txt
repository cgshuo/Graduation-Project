 Speech translation is the process of translating speech in the source language to text or speech in the target language. This process is typically structured as a three step pipeline. Step one in-volves training an Automatic Speech Recognition (ASR) system to transcribe speech to text in the source language. Step two involves extracting an appropriate form of the ASR output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1-best output can be used as the source text to trans-late. It may be useful to consider alternative ASR hypotheses and these take the form of an N -best list or a word-lattice. An N -best list can be in-cluded easily into the tuning and the decoding pro-cess of a statistical machine translation (SMT) sys-tem (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Ric-cardi, 2000; Dyer et al., 2008a; Bertoldi and Fed-erico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the com-plexity of the decoding process because of the ex-ponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface.

This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows: 1. Using downstream information : Hypoth-2. Coarse-to-fine grained decoding : An in-3. Phrase units vs. word units : When a phrase In this section, we describe the featurized model (coarse-grain MT decoder) for hypothesis selec-tion that uses information from the ASR and SMT systems (impedance matching). We assume the presence of ASR and SMT systems that have been trained separately. In addition to creating almost no disruption in the traditional pipeline approach, this allows us to incorporate local gains from each system. To elaborate, our methods avoid joint op-timization of the ASR and the SMT system with respect to a translation metric (Vidal, 1997; Ney, 1999), which is not feasible for larger datasets. Also, considering the dearth of speech translation training datasets, this method allows independent training of the ASR and SMT systems on data cre-ated only for ASR training and parallel data for SMT. We start by introducing the formal machin-ery that will be used and by presenting a simple example to motivate the model. The complete fea-turized model follows this exposition.

Let  X  and  X  be alphabets of words and phrases respectively in the source language. Using these, we can define the following finite state machines: 1. Word Lattice ( L ) : A finite state accep-2. Phrase segmentation Transducer ( S ) : A 3. Weighted word lattice (  X  L ASR ) : A weighted 4. Phrase acceptor (  X  W MT ) : A finite state ac-Figure 1: A toy example for producing a phrase length weighted phrase lattice. (a) An unweighted word lattice. (b) A phrase segmentation trans-ducer which transduces words to phrases and has a weight of one per path. Each path is a source phrase in the phrase table. (c) A phrase lat-tice produced by composing the word lattice and phrase segmentation transducer. 5. Phrase lattice (P) : The result of the com-2.1 A simple model : Maximum Spanning We motivate our model with this fairly simple scenario. Suppose that we believe that if our SMT input could be covered by longer source side This may be viewed as a tiling problem where the tiles are the source phrases in the phrase table and the goal is to select the ASR hypothesis that re-achieve this using our existing machinery, we cre-ate  X  S , a weighted version of S (Figure 1 (b)), such that put and output projections respectively. Using this segmentation transducer and an unweighted word lattice, L (Figure : 1 (a)), we produce a phrase lattice  X  P MT . Assuming the weights are in the log-Figure 1(c) shows an example of this phrase lat-tice. Weights in the phrase lattice follow the same definition as the weights in the segmentation trans-ducer. Hence, the weight of a path in the phrase lattice is simply the number of phrases used to lattice  X  P MT , corresponds to the hypothesis we were looking for. This simple example, demon-strates how we may be able to use SMT features (source phrase length in this case) to select hy-potheses from the phrase lattice. 2.2 A general featurized model for We now present a general framework in which hypothesis selection can be carried out using knowledge (features) from the ASR and the SMT system. As described earlier, this form of  X  X mpedance X  matching allows us to select hypothe-ses from an unpruned ASR word lattice for which the SMT system is more likely to find good trans-lations. Incorporating ASR weights also ensures that we take into account what the ASR system considers to be good hypotheses. We start with the previously discussed idea of a phrase lattice, using weights from the ASR system only. That is, Now, we use the weighted phrase acceptor  X  W MT with the weighted phrase lattice, we get where (  X  W MT )  X  is the Kleene closure of (  X  W MT ) . We assume that the edge weights are in the log-semiring. Hence, after these two compositions, the edge weights in  X  P ASR,MT can be represented as feature weights, f ASR and f MT are features from the ASR and SMT system respectively. This form represents a log-linear model (our features are al-ready assumed to be in log-space). where f i is any feature and  X  i is the corresponding feature weight. We may now extract the one-best, N -best or lattice input for the SMT system from  X  P ASR,MT . 2.2.1 A discussion about related techniques 1. Decoding (Translation) : Our model closely 2. Lattice Decoding : (Dyer et al., 2008b) sug-3. Language model re-scoring : One may use a 2.2.2 Training Training the hypothesis selection model can be carried out using standard methods for log linear models on a held-out set. This also requires decod-ing (translation) of a deep N -best list derived from the held-out set. The objective of training then simply becomes maximization of the translation quality given any metric that provides sentence level scores. Each time our model produces a hy-pothesis, its score can be looked up from the pre-translated N -best list. Also, whenever the weights are updated, the only structures that need to be re-built are  X  W  X  2.2.3 Features We use the following features in our implementa-tion of this model. However, any relevant ASR and SMT feature may be readily added to this model. 1. ASR scores : We incorporate the ASR acous-2. Source phrase count : As described in sec-3. Length normalized phrase unigram prob-4. Phrase translation entropy : For each 5. Lexical translation entropy : Similarly, we We use the Fisher and Callhome Spanish-English Speech Translation Corpus (Post et al., 2013) for our experiments. This Fisher dataset consists of 819 transcribed and translated telephone conver-sations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model.
 We use the Kaldi speech recognition tools (Povey et al., 2011) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of (Zhang et al., 2014). The word-error-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29 . 80% , 29 . 79% and 25 . 30% respectively.
 For the SMT system, we use the phrase based translation system of Moses (Koehn et al., 2007) with sparse features. The system is trained and tuned on the train and dev partitions of the Fisher dataset respectively. The BLEU scores of the MT output for the the dev-2 and the test partitions are 65 . 38% and 62 . 91% respectively. While decoding the ASR output, we tune on the 1-best ASR output for the dev partition. With this modified system, the BLEU scores for the ASR 1-best output of the dev2 and the test partitions are 40 . 06% and 40 . 4% respectively. We use this system as the baseline for our experiments (Table 1).
 from our ASR system as input to the SMT system, we get a BLEU score of 46.59% for the dev2 par-tition of the Fisher dataset. This indicates that the best gain (+BLEU) that an oracle lattice reranker could get is only 6.53%.

To tune the weights of the coarse decoder, we decode 500 -best ASR outputs for the tuning set with the SMT system. This maps each ASR hy-pothesis to a target language translation. An OOV feature was added to handle words that were not seen by the SMT system. The tuning process was then carried out so as to maximize the BLEU with Experiment BLEU (dev2) BLEU (test) Transcripts 65.4% 62.9% Lattice Oracle 46.59% 46.17% ASR 1-best 40.06% 40.4% Coarse decoder 40.26% 40.46% Table 1: Performance when using the coarse de-coder interface compared to the the decoding the human transcripts, the ASR 1-best or the lattice oracle (the path in the ASR lattice with the least WER : not available during test time.) respect to the reference translation of the ASR hy-pothesis selected by the coarse grained decoder. We used ZMERT (Zaidan, 2009) for tuning which was configured to expect a 300-best list from the decoder at every iteration using the Fisher dev set. 15 iterations of tuning were carried out for each experiment. We then use the tuned weight vec-tor to decode the Fisher-dev2 and the Fisher-test set using our coarse grained decoder. We extract the one-best output and use it as input to the pre-trained SMT system (description in the preceding section). Table 1 reports the results achieved the featurized coarse grained decoder. We present a coarse-to-fine featurized model which acts as the interface between ASR and SMT systems. By utilizing information from the up-stream (ASR) and the downstream (SMT) sys-tems, this model makes more informed decisions about which hypotheses from the ASR word lat-tice may result in better translation results. More-over, the model takes the form of a coarse finite state transducer based translation decoder which imitates the downstream system. This enables it to estimate translation quality even before the com-plete SMT system is used for decoding. Finally, the proposed model is featurized and may accept any weight from the ASR and SMT system that are deemed useful for optimizing translation quality.
The Spanish Fisher corpus is one of a few con-versational speech translation datasets available, and we start with a strong baseline system. We therefore persevere with the experimental setup described above, even though the maximum (ora-cle) improvement by any rescoring method is only 6.5% BLEU, as noted above. This partially ex-plains the small gains reported here, and suggests that this method should be evaluated further on an-other corpus, e.g. the Egyptian Arabic translation dataset, with greater headroom for improvement. This work was partially supported by NSF award No No  X  The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of NSF, DARPA or the U.S. Government.
