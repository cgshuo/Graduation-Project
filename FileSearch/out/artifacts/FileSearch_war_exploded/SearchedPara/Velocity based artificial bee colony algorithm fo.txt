 fi elds because of having fewer control parameters, high global search 1. Introduction
Global optimization is a branch of applied mathematics and numerical analysis that deals with the optimization of a function or a set of functions according to some criteria. Typically, a set of bound and more general constraints is also present, and the decision variables are optimized considering also the constraints.
During the past years many methods have been proposed for tackling the problem of global optimization. These methods can be divided into two main categories, namely deterministic and stochastic. Methods belonging to the fi rst category are more dif fi cult to implement and they depend on priory information about the objective function. Moreover, these methods involve the use of gradients or higher-order derivatives of the fi tness function.
However, they are not well-suited for many real-world problems such as quadratic assignment, timetabling and scheduling pro-blems. These problems using discrete states generate non-continuous objective functions that are unreachable through analytical methods( Eric Bonabeau, 1999 ; Eberhart and Yuhui Shi, 2001 ). On the other hand, stochastic optimization methods were designed to deal with highly complex optimization problems. Furthermore, these methods are implemented more easily and they do not require priory information about the objective function.
 Several metaheuristic algorithms such as Random Line Search, Adaptive Random Search ( Bremermann., 1970 ), Competitive Evo-lution ( Jarvis, 1975 ), Controlled Random Search ( Price, 1983 ), Simulated Annealing ( van Laarhoven, 1987; Kirkpatrick et al., 1983; Corana et al., 1987 ), Genetic Algorithm ( Goldberg, 1989; Elsayed et al., 2014 ), Differential Evolution ( Storn and Price, 1997; Deng et al., 2013 ), Tabu Search ( Cvijovi and Klinowski, 1995 ), Ant colony optimization (ACO) ( St X tzle, 2004 ), Particle swarm optimi-zation (PSO) ( Chen and Chi, 2010; Kennedy and Eberhart, 1995; Pedersen and Chipper fi eld, 2010; Shelokar et al., 2007; Sun et al., 2013; Wang and Shoup, 2011 ), Arti fi cial bee colony(ABC) ( Akbari et al., 2012; Gao and Liu, 2012; Karaboga and Akay, 2009; Karaboga and Basturk, 2008; Li et al., 2012a ) and Dolphin echolocation ( Kaveh and Farhoudi, 2013 ), have been developed for solving stochastic optimization problems. The advantage of using metaheuristic algorithms is that they do not rely explicitly on the gradient of the problem to be optimized, so the method can be readily employed for a host of optimization problems. This is especially useful when the gradient is too laborious or even impossible to derive. Furthermore, another advantage is that they do not require the mathematical gradient in order to optimize a problem; thus, they can be employed directly on the fi tness measure to be optimized.

The metaheuristic algorithms can be classi fi ed into different groups depending on the criteria being considered, such as population based, trajectory based and iterative based. An algo-rithm working with a group of solutions and trying to improve them is called population based. Developed and investigated for two decades, quite a few population based algorithms such as GA,
ACO, PSO and ABC have been proposed in order to solve dif optimization problems. Common features of these methods with interaction between populations are that they are population-based and nature-inspired. These algorithms have been adopted by researchers so far and are well suited to solve various complex computational problems such as multi-objective of objective functions ( Akbari et al., 2012; Zhou et al., 2011 ), fl ow shop scheduling problem ( Bank et al., 2012 ), pattern recognition ( Prasartvit et al., 2013; Yu and Duan, 2013 ), feature selection ( Chen et al., 2013; Jung and Zscheischler, 2013; Kabir et al., 2012; Xue et al., 2013 ) and data clustering ( Banharnsakun et al., 2013; Chuang et al., 2011; Cura, 2012; Karaboga and Ozturk, 2011; Liu et al., 2011; Niknam et al., 2011; Yan et al., 2012 ).
One of the most recent population based methods is the arti fi cial bee colony (ABC) algorithm which was fi rst proposed by
Karaboga by simulating foraging behaviors of honey bee colonies, and it was used for solving both continuous and discrete optimi-zation problems ( Gao and Liu, 2012; Karaboga and Akay, 2009;
Karaboga and Basturk, 2008; Karaboga, 2005 ).The ABC algorithm provides solutions in an organized form by dividing the bee objects into three groups including employed bees, onlooker bees, and scout bees. These three groups of bees determine the objects of problems by sharing information with other bees. The perfor-mance of the ABC has been compared with the other population based algorithms and the comparison results showed the effec-tiveness of the ABC on unimodal and multimodal numerical optimization problems with an advantage of employing fewer control parameters ( Karaboga and Akay, 2009 ). Due to its simpli-city and ease of implementation, the ABC was considered by the researchers and it has been successfully used in solving combina-torial optimization problems such as clustering ( Karaboga and
Ozturk, 2011 ), training neural networks ( Bullinaria and AlYahya, 2014 ), pattern classi fi cation and TSP problems ( Li et al., 2012b ).
The main challenging problem of the ABC algorithm is that its convergence speed is typically lower than those of representative population-based algorithms such as differential evolution ( Storn and Price,1997 ) and PSO when handling unimodal problems and it can easily get trapped in the local optima when solving complex multimodal problems ( Karaboga and Akay, 2009 ). The main reason is the poor exploitation mechanism of the ABC, while it has effective exploration ability. The exploration process concerns the ability to search for the global optimum independently, while the exploitation process concerns the ability to apply the existing knowledge to seek for better solutions. Therefore, a few modi algorithms have been proposed in order to further balance and accelerate the exploration and exploitation processes, which results in accelerated convergence speed and avoidance of the local optima. The modi fi ed ABCs including GABC ( Zhu and Kwong, 2010 ), ABC/best1, ABC/best 2 ( Gao et al., 2012 ), MABC ( Gao and Liu, 2012 ), best so far ABC ( Banharnsakun et al., 2013 ), I-ABC, PS-ABC ( Li et al., 2012a ), HPA ( K  X  ran and G X nd X z, 2013 ), COABC ( Gao and
Liu, 2012 ), ERABC ( Xiang and An, 2013 ) and SAABC ( Chen et al., 2012 ), have better performances than the original ABC.
Swarm intelligence algorithms use different exploration and exploitation strategies to solve optimization problems. Therefore, to overcome the poor exploitation ability of the ABC, one can hybridize it with those algorithms with good exploitation mechan-ism. For example, the PSO has good exploitation ability, but when the population or particles get stuck in a local minimum, the PSO does not have the ability to get rid of the local minimum, and the
PSO is insuf fi cient for the exploration of the search space ( K and G X nd X z, 2013; Kuo and Lin, 2010; Kuo et al., 2012; Liu et al., 2010; Montalvo et al., 2010; Sun et al., 2013 ). Therefore, in this paper we proposed anew algorithm namely VABC which hybri-dized ABC with PSO to solve continuous numerical optimization functions. As a result of the hybridization, the proposed method exploits the exploitation property of the PSO with the effective search ability of the ABC. The proposed method fi nds the optimal solution in three phases. In the fi rst phase, the method uses the exploration property of ABC to search the problem space. In the second phase, the optimal solution of each particle is found using the exploitation property of PSO. Finally in the third phase, the best solutions are kept and the others are replaced by new random particles. The experimental results and comparisons show the effectiveness and ef fi ciency of the proposed VABC algorithm in most areas.
 brie fl y presents the necessary background, including discussion of basic particle swarm optimization and arti fi cial bee colony algo-rithms, and the proposed VABC algorithm is explained in Section 3 . Section 4 discusses the simulation results over 23 benchmark functions. Finally, concluding remarks are made in Section 5 . 2. Background 2.1. Basic particle swarm optimization intelligence methods which is based on natural fl ocking and swarming behavior of birds and proposed by Kennedy and
Eberhart in 1995 ( Kennedy and Eberhart, 1995 ). The PSO algorithm operates iteratively and in each iteration a produced solution which is called a particle is compared with the local best and global best to achieve the global minimum. Furthermore, each particle is associated with a fi tness value which is determined by an objective function. Each particle has its own velocity ( V position ( x id ), and is updated towards a personal best ( P global best ( g best position of each particle has to be generated randomly for each particle. In the PSO algorithm the optimal solution is determined by iterative calculations. Meanwhile in each iteration, each particle can memorize its own personal best when searching for the optimal solution, and the personal best values are further com-pared to determine the best one ( Eberhart and Kennedy, 1995 ).
Therefore, the velocity and position update rules of PSO are shown as follows: the learning factor of cognition model which represents indivi-duals' knowledge of the searching space, c 2 is the learning factor of social model which indicates the information sharing and coop-eration between one particle and another, r 1 and r 2 are random real values in interval  X  0 ; 1 ; v id A  X  v max ; v max , and v nated value. The c 1 and c 2 parameters are used to control the fl ying speed and are important for velocity and position updates and generally are set to 2 (e.g. c 1  X  c 2  X  2). When the best population location reaches a designated value or after running a de fi ned upper limit iteration number, the program will output the best solution and terminate.
 2.2. Basic arti fi cial bee colony algorithm
Arti fi cial Bee Colony (ABC) algorithm was proposed by Kara-boga for solving numerical optimization problems ( Karaboga, 2005 ). The algorithm belongs to the class of swarm intelligence techniques which simulate the intelligent foraging behavior of honey bee swarms. In ABC algorithm, there are three groups of arti fi cial bees including employed bees, onlookers and scouts. Each employed bee searches the solution space to fi nd a food source.
In other words, the number of the employed bees is equal to that of the food sources. Onlooker bees wait on the dance area and share the information on the food sources found by employed bees for making a decision to choose better ones and explore around them. If some food sources are not improved for several cycles, the scout bees carry out random searches for discovering new sources.
The position of a food source represents a possible solution to the optimization problem and the nectar amount of a food source indicates the fi tness of the associated solution, calculated as follows: fit  X  1 1  X  f i  X  3  X 
In the ABC algorithm the number of the employed bees and the onlooker bees is equal to the number of solutions in the swarm.
In the fi rst step of the ABC, a randomly distributed initial popula-tion of solutions is generated and then the global optimum solution is found iteratively through the search processes of the employed bees, the onlooker bees and the scout bees. An employed bee performs a modi fi cation on the solution based on its local information and tests the fi tness value of the new solution. Provided that the fi tness value of the new solution is higher than that of the previous one, the bee memorizes the new solution and forgets the old one. Otherwise, she keeps the previous solution in her memory. When the search processes of all employed bees are completed, the solutions and their corre-sponding fi tness values will be shared with the onlooker bees on the dance area. An onlooker bee evaluates the fi tness values from all the solutions of the employed bees and chooses a solution with a probability value associated with that solution, pi, which is calculated as follows: p  X  fit i where SN is the number of solutions, equal to the number of employed bees, and fit i is the fi tness of the solution given in Eq. (3) which is inversely proportional to the f i . In order to produce a candidate solution from the old one, the following equation is used: x  X  x
X  X  X  x i 1 ; x i 2 ; ... ; x iD represents the old solution, k and j
A f 1 ; 2 ; ... ; D g are randomly chosen indexes which have to be different from each other,  X  ij is a random number in the range  X  1 ; 1 and D is the problem dimension.

After the generation of the candidate solution its fi tness value is compared with that of the old one. If the new solution has equal or better quality to/than the old source, it replaces the old one in the memory. Otherwise, the old one is retained. In other words, a greedy selection mechanism is employed as the selection opera-tion between the current and the old solution. If a solution cannot be improved further through a predetermined number of itera-tions, then the solution is replaced by the new randomly gener-ated one. In the ABC a random solution is produced according to the following expression: x where x min ; j and x max ; j denote the lower and upper bounds of the j th parameter respectively and j A f 1 ; 2 ; ... ; D g . 3. Proposed method 3.1. The exploitation mechanisms for ABC
The ABC algorithm is an ef fi cient method for solving the wide range of optimization problems. Moreover, this algorithm is very easy to understand and implement, and not only has it already proved a high-performance optimizer, but also it requires little computational bookkeeping. Like the other population-based optimization algorithms, the exploration process of the ABC refers to the ability to seek the unknown regions in the solution space to discover the global optimum, while the exploitation process refers to the ability to apply the knowledge of the existing solutions to look for better solutions ( Karaboga and Akay, 2009 ). Moreover, the processes of exploration and exploitation should be carried out together in the population-based optimization algorithms. How-ever, these processes contradict each other and should be well balanced to achieve good optimization performance.

In the ABC algorithm, the neighborhood search strategy for employed bees and onlookers is described by Eq. (5) . In this equation, the new candidate solution is produced by moving the old solution towards another solution selected randomly from the population. Moreover, the coef fi cient  X  ij is a uniform random number in  X  1 ; 1 and x kj is a random individual in the population; therefore, the solution search dominated by the equation is random enough for exploration. Therefore, the solution search equation performed by employed bees and onlookers is good at exploration but poor at exploitation ( Gao et al., 2012; Li et al., 2012a; Luo et al., 2013; Zhu and Kwong, 2010 ). Moreover, the onlooker selects a food source with a probability related to the nectar amount shared by employed bees. Thus, a food source with a better nectar amount will have a higher probability to call for more onlookers. To sum up, the exploration mechanism depends on a random search process executed by scout bees and a neighborhood search strategy performed by employed bees and onlookers, while the exploitation property depends on neighbor-hood search and a greedy selection mechanism executed by employed bees and onlookers. This mechanism would be good for exploration and help to escape from the local solutions. Therefore, in order to achieve good performance and improve the convergence speed of the algorithm, the method of generating new candidate solutions based on the information on previous solutions should be improved.
 Based on the analysis of the ABC algorithm, it is seen that basic ABC does not directly use the global best solution of the popula-tion, which results in poor exploitation. The best solutions in the current population are very useful sources that can be used to improve the convergence. There are a few algorithms developed to improve the exploitation of the ABC algorithm ( Banharnsakun et al., 2011; Gao et al., 2012; Luo et al., 2013; Tsoulos and Stavrakoudis, 2010; Xiang and An, 2013; Zhu and Kwong, 2010 ). In GABC ( Zhu and Kwong, 2010 ), the solution search equation is modi fi ed as follows by applying the global best solution to guide the search of new candidate solutions: x where the third term on the right-hand side is called the global best term, x bj is the j th element of the global best solution, uniform random number in  X  0 ; C , where C is a nonnegative constant. Note that the parameter C controls the balance between the exploration and exploitation of the candidate solution search.
In ABC/best1 and ABC/best2 ( Gao et al., 2012 ), to increase the exploitation of the ABC algorithm, the new candidate solutions are respectively derived only around the best solution of the previous iteration as follows: x x where the indices r 1 ; r 2 ; r 3 and r 4 are mutually exclusive integers randomly chosen from  X  1 :: SN and different from the base index i and SN in the number of onlooker bees.

In COABC ( Luo et al., 2013 ), all onlookers are placed directly on the global best food source so far and then updated one by one.
The update process used in the onlooker stage is described as follows: best solution is equal to the number of onlookers. In this way, the candidate food source modi fi ed around the best food source in the current group can increase the exploitation of the ABC algorithm. described as follows: where w ij is the inertia weight which controls impacts of the previous solution x ij ,  X  ij are random numbers in [0, 1], are positive parameters that could control the maximum step size.
Moreover, in best so far ABC ( Banharnsakun et al., 2011 ), the new candidate solutions of onlooker is generated as follows: x  X  x ij  X   X  ij fit  X  x b  X  X  x ij x bj  X  X  12  X 
In the best-so-far ABC algorithm, the exploitation process is focused on the global best solution which makes the algorithm achieve an extremely high convergence speed. Moreover, in order to increase the diversity of the feasible solutions in the search space, the values in all dimensions of each food source are also updated in each iteration. Moreover, in ERABC ( Xiang and An, 2013 ), the best-so far solution search equation is modi fi follows: x  X  x ij  X   X  ij  X  x ij x bj  X  exp iteration MCN  X  13  X  where iteration represents the number of iterative processes and
MCN indicates the number of maximum cycles. In order to incorporate the advantages of Eq. (12) , in ERABC, the greedy selection is applied between these equations. 3.2. Velocity based ABC
The modi fi ed strategies are introduced to drive the new candidate solution towards only on the global best solution. However, there is no speci fi c algorithm to substantially achieve the best solution for all optimization problems. Some algorithms only give a better solution than others for some particular problems. Hence, searching for a well improved or new optimization method is very necessary. In this work, inspired from the PSO exploitation mechanism, a new neighborhood search strategy is proposed for onlookers. In the proposed search strategy the generation of a new solution not only depends on the global best from the population, but also depends on the local best of the current solutions. Therefore, in order to produce a candidate food in memory, the following exp ression is used as follows: x  X  x ij  X  v id  X  14  X  (problem dimension) and v ij denotes the velocity of the i -th particle over j -th dimension which is de fi ned as follows: v  X  wv ij  X  c 1 r 1  X  x b ij x ij  X  X  c 2 r 2  X  x bj x ij  X  X  15  X  where x bj is the global best solution of the current population over j -th dimension, x b ij represents the local best position of the particle x over j -th dimension, w is an inertial parameter, c 1 and c learning factors, and r 1 and r 2 are random real values. Inspired from
PSO the values in all dimensions of each food source are also updated in each iteration. According to Eq. (15) , once the global best one falls into the optima, all the solutions will converge rapidly to its position.
The aim of the proposed method is to combine the exploration process of the ABC and the exploitation strategy of the PSO to improve the optimization process. To this end, in the proposed method, which is called velocity based ABC, in short VABC, each iteration consists of three steps. In the fi rst step, as in the fi rst step of the ABC, the employed bees go onto their food sources and evaluate their nectar amounts and then share the nectar information of the sources with the bees waiting on the dance area. The update process used in the employed bee stage still keeps as Eq. (5) .In fact, in this step, the exploration strategy of the ABC is used to search the solution space. In the second step after sharing the nectar information of food sources, the best solutions explored in the history are used to direct the movement of the population using Eqs. (14) and (15) . To this end, the explored solutions will be chosen depending on the probability values associated with the solutions based on their corresponding values. Finally in the third step, when the food source positions are not replaced continuously over the prede fi ned number of trials limit, employed bees will abandon the food source positions and become scout bees. On the other hand, the weak particles will be replaced by the new random particles. These three steps are repeated through a predetermined number of iterations until a termination criterion is satis fi ed. The complete computational procedure of the proposed method is outlined in Fig. 1 . 3.3. Fitness computation
To compare the new solution with the old one, basically the value is used. The fi tness value can be obtained using Eq. (3) . has a very small value (e.g. 1E 30) the fi tness value of equation 1/(1  X  1E 30) is rounded to 1 and 1E 30 is ignored. Therefore, there is no difference between 1E 30 and 1E 120. Consequently in the new solution with a better fi tness value than the old one will be ignored. In order to solve this problem, we directly use the objective value of the function to compare the solutions and select the better one. 3.4. Computational complexity
The proposed method consists of four parts namely (1) initializa-tion, (2) employed bee phase, (3) onlooker phase and (4) scout phase. In the initialization part (line 2), the method creates n solutions randomly. Since each solution is a vector of d dimension, the time complexity of this part is Ond  X  X  : In the second part (lines 4 each employed bee, one of the randomly chosen dimensions is changed accordingly. Therefore the complexity of this part is O  X  n  X  .In the onlooker phase part (lines 15  X  31), fi rst of all a probability is computed for each solution and then each onlooker is selected based on its probability. The selected onlookers are changed over all their dimensions using Eq. (15) . Moreover, the equation needs the global best of the swarm, so the complexity of this part is O  X  n  X  n  X  nd  X  . Furthermore, the computational time of the fourth part (lines 32 is less than O  X  nk  X  where k  X  n denotes the number of onlookers which replaced by the new random solutions. It should be noted that parts 2, 3 and 4 will be repeated m times where m is the maximum number of cycles. Therefore, the overall complexity of the algorithm is equal to original ABC algorithm which is equal to  X  nd  X  2 mn  X  mnd  X  . However, when we focus on the upper bound of the complexity of problems, both VABC and original ABC algor ithms use computational time
O  X  mnd  X  . It should be noted that although the computational complex-ity of the VABC is higher than that of the original ABC at the same maximum iteration, the VABC can fi nd the optimal solution before it reaches the maximum iteration. Thus the actual computation time of the proposed method may be reduced relative to that of original ABC. Moreover, VABC needs additional O  X  n  X  memory compared to those of
ABC, GABC, IABC, ABC/best1 and SAABC to memorize the local best of each solution. 4. Performance evaluation 4.1. Benchmark functions method in terms of solution qualities and search abilities, 23 well known functions taken from ( Gao et al., 2012; Li et al., 2012a; Xiang and An, 2013 ) are employed. These functions are presented in
Tables 1 and 2 . Table 1 presents a set of 15 multidimensional test functions, while Table 2 shows functions with fi xed dimensions. This set includes different kinds of problems such as unimodal (U), multi-modal (M), separable (S) and non-separable (NS). The global optimum these functions is in  X  0 D . Moreover, if a function has more than one local optimum, it is called multimodal. However, unimodal functions such as f 1 f 9 have only one local optimum and that is global optimum. Multimodal functions (e.g f 10 f 15 ) are used to test the ability of algorithms to get rid of local minima. If the exploration process of an algorithm is poor, it cannot search the whole space ef fi ciently; therefore, the algorithm gets stuck in local minima.
Another group of test problems is that of separable/non-separable the sum of the n functions of one variable. But a non-separable function cannot be written in this form because there is interrelation among variables of these functions. It is clear that optimizing non-separable functions is more dif fi cult than separable functions. More-over, to test the abilities of the algorithms on the high dimensional search spaces, the benchmark functions in the Table 1 can be set with different dimensions ( D ) and increasing the dimension leads to an increase in the dif fi culty.

Fig. 2 graphically presents the surface plots for (a) f 1 (c) f 5 (d) f 9 , (e) f 10 , and (f) f 19 functions. From the fi seen that the f 1 and f 2 and f 5 functions have only one global optimum, so these functions are unimodal. Furthermore, some functions such as f 5 have fl atness on the surface. Thus, solving such functions is dif fi cult for algorithms because these functions do not give any direction information to the methods. Moreover, from the fi gure, it can be seen that the surfaces of the f f functions is covered with many local minimums. Therefore these functions are multimodal and the locations of the local minimums are distributed. The dif fi cult part about fi nding optimal solutions to these functions is that an optimization algorithm can easily be trapped into a local optimum on its way towards the global optimum. Therefore, to obtain good results for these types of functions, the optimization algorithm must combine effectively the exploration and the exploitation strategies. 4.2. Parameter setting
In all the experiments in this section, the values of the common parameters such as maximum cycle number ( MCN ), dimension of the functions ( D ) and termination condition were chosen to be the same.
Maximum number of cycles was set to 1000. Moreover the dimen-sions were set to 60 and 100 in turn and the termination condition of the algorithms was set to the maximum cycle number. Furthermore, for each function all the methods were run 10 times with random seed on the PC with Intel Core 2 Due, 3 GHz CPU and 4 GHz of RAM. The other speci fi c parameters of the algorithms were set as follows: For PSO, CPSO ( Wan et al., 2012 ), DBMPSO ( Yang et al., 2012 ),
TCPSO ( Sun and Li, 2014 ) and VABC, cognitive and social components, c and c 2 , were set to be 2. Moreover, inertia weight, which determines how the previous velocity of the particle in fl velocity in the next iteration, was set to w  X  0 : 6 as recommended in ( Kennedy and Eberhart, 1995 ). The upper and lower bounds for v were set to be the maximum upper and lower bounds of x ,i.e. v ;  X  X  X  X  x min ; x max  X  . If the sum of accelerations would cause the velocity on that dimension v  X  t  X  1  X  to exceed v mix velocity on that dimension was limited to v mix or v max ,respectively.
For ABC, GABC ( Zhu and Kwong, 2010 ), ABC/best1 ( Gao et al., 2012 ), IABC ( Li et al., 2012a ), SAABC ( Chen et al., 2012 ) and VABC the limit control parameter was set to 10. In these algorithms when a solution cannot be improved in the prede fi ned number of trials (i.e. limit ), it will not be exploited anymore and will be assumed to be abandoned. In order to investigate the effect of the limit and number of employed bees (EB), control parameters and the performance of VABC, we tested the algorithm for values of EB 20, 60, 100, 160 and 200 and different limit values 4.3. Results
In order to test the performance of VABC for global optimiza-tion of continuous functions, we tested it on several well-known benchmark functions which are listed in Table 1 . To compare the performance of the proposed VABC with the performance of the original PSO and ABC methods and the other existing state-of-the-art hybrid ABC methods including SAABC ( Chen et al., 2012 ), GABC ( Zhu and Kwong, 2010 ), ABC/best1( Gao et al., 2012 ) and IABC ( Li et al., 2012a ), and some state-of-the-art PSO based methods including CPSO ( Chuang et al., 2011 ), DBMPSO ( Yang et al., 2012 ) and TCPSO ( Sun and Li, 2014 ), several sets of experiments were carried out and the detailed results are given below. 4.3.1. Comparison of VABC with ABC and PSO
In order to compare the performance of the VABC method with those of the PSO and ABC methods, we have shown the results in terms of means and standard deviations (Std.) of the solutions obtained in the 10 independent runs in Table 3 for multidimen-tional functions (e.g. f 1 f 15 ) with dimensions D  X  60 and D  X  100. According to the Table 3 results it can be seen that PSO produces better results than ABC when the functions have unimodal characteristics (e.g. f 1 f 8 ). This is due to the poor exploitation ability of ABC compared to PSO. On the other hand, if the functions have many local optima, the exploration property of the method is more important than its exploitation property. The exploration properties of ABC and PSO have been tested on multimodal functions (e.g. f 9 f 15 ), and in most cases PSO has poor exploration property compared to ABC. Particularly, the exploration property of VABC originates from ABC and the exploitation property of
VABC originates from PSO, and VABC is superior to PSO and ABC for all of the unimodal and multimodal functions. Therefore, while the characteristics of the functions are important factors for the ABC and PSO, they are not important for the VABC algorithm.
As another comparison, the table results indicate that when the dimensions of the functions increase, all of the methods produce worse results compared to those with lower dimensions. For example for dimension D  X  60, ABC, PSO and VABC, obtain 9.36E  X  01, 2.66E  X  01and 7.02E 05, respectively, for minimization of the f 4 function, while for dimention D  X  100, the values 9.64E  X  01, 2.80E  X  01 and 1.59E 04 were respectively reported for ABC, PSO and VABC. However, in this case the results obtained by VABC are much closer to the theoretical optima, and the proposed method VABC is superior to ABC and PSO in terms of searching quality and derivation of results. In particular, VABC can graphically presents the comparis on of VABC, ABC and PSO in terms of convergence curves in solving the six different problems. These results clearly show that the convergence rate of VABC is much better than those of ABC and PSO on the test functions. In short, it can be concluded that, the superiority in terms of search ability and ef of VABC should be attributed to an appropriate balance between exploration and exploitation.
 of ABC and PSO on the fi xed dimensional benchmark functions (e.g. f 6 f 23 ). It can be seen from the Table 4 results that ABC performs better than VABC but the results obtained by VABC are of the same order of magnitude as the results achieved by ABC. On the whole, the VABC exhibits an extremely high convergence speed and very accurate results on all the multidimensional benchmark functions and outperforms conspicuously both AB C and PSO. Consequently, from the results it can be concluded that the VABC has shown a very high ef fi ciency and a good robustness especially on high dimensional optimization problems. 4.3.2. Comparison of VABC with state-of-the-art ABC and PSO based methods
The performance of the solution accuracy of VABC is compared with that of state-of-the-art ABC variants including SAABC ( Chen et al., 2012 ), GABC ( Zhu and Kwong, 2010 ), ABC/best1 ( Gao et al., 2012 ) and IABC ( Wang and Shoup, 2011 ). Moreover, the performance of VABC is also compared with those of recent
PSO variants including CPSO ( Chuang et al., 2011 ), DBMPSO ( Yang et al., 2012 ) and TCPSO ( Sun and Li, 2014 ). The comparison results are shown in Tables 5  X  7 in terms of means and standard deviations (Std) of the solutions in the 10 independent runs. Tables 5  X  6 show the results for D  X  60 and D  X  100 respectively on multidimensional functions and Table 7 reports the results on the fi xed dimensional functions. As seen from the Tables 5 results, VABC found the near optimal values for all the functions except f 13 and f 14 and for f 15 when dimension is set to D  X  60. It can be seen that the VABC can fi nd global optimal values on functions f 8 and f 11 with D  X  60. On the other hand, for test functions f 1 , f 2 , f 3 , f 4 , f 5 , f 6 , f 7 , f 9 , f obtained by VABC are extremely close to global optima. However, the results show that VABC offers the highest accuracy for most of the multidimensional test functions and achieves better perfor-mance. For example when D  X  100, the VABC achieves the mean value 5.84E 11 for f 12 function while in this case SAABC, GABC, IABC, ABC/Best1, CPSO, DBMPSO and TCPSO respectively obtained the 9.26E  X  00, 1.21E  X  01, 1.12E  X  01, 1.02E  X  01, 7.33E  X  00, 9.50E  X  00 and 1.14E  X  01mean values. Moreover, the performance of the proposed method is further compared with those of state-of-the-art methods on fi x dimensional test functions. The results are reported in Table 7 . From the results it can be seen that PSO based methods (e.g. CPSO, DBMPSO and TCPSO) perform better than ABC based methods (e.g. SAABC, GABC, IABC, ABC/Best1 and VABC) on fi xed dimensional problems. Therefore, it can be concluded from the results reported in Tables 5  X  7 , that the advantage of VABC is that it improves the bees' searching abilities for high dimensional optimization problems. 4.3.3. Convergence analysis of VABC
In order to compare the convergence characteristics of the evolutionary process of the VABC algorithm with those of state-of-the-art ABC based and PSO based algorithms, graphs of solutions quality are plotted as functions of time. Fig. 4 compares the convergence curves of the proposed method with those of ABC based algorithms including SAABC, GABC, IABC and ABC/Best1.
However, from Fig. 4 , it can be concluded that VABC converges much faster compared to SAABC, GABC, IABC and ABC/Best1 for the benchmark function with different dimensions. However, the experiments were also conducted for comparing the convergence properties of VABC with those of PSO based methods including
CPSO, DBMPSO and TCPSO, and the convergence curves are shown in Fig. 5 . The results show that in this case the proposed algorithm outperforms all the other methods and quickly converges to the global optimum. 4.3.4. Experiments to analyze the VABC control parameters
VABC has a number of controlled parameters that affect its performance. These parameters are the number of employed bees ( EB ), limit , w ; c 1 and c 2 which have been already introduced in different parts of the paper. The parameters w ; c 1 and c used in the Eq. (15) , have been taken from the PSO algorithm.
Therefore, w ; c 1 and c 2 in the experiments were respectively set to 0 : 6 ; 2 and 2 as recommended in ( Kennedy and Eberhart, 1995 ).
Therefore, in this section the effects of different values of EB and limit on the behavior of the VABC algorithm have been investigated and the corresponding results are presented in Tables 8 and 9 , respectively. In these tables the effectiveness of the VABC algorithm under different settings of the control parameters is measured. The limit value which controls the occurrence of scout bees for VABC can be calculated as limit  X   X  EB D where EB is the number of bees and D is the dimensionality of the problem. Table 8 presents the mean value obtained by the proposed method for different values of tions with D  X  60 and D  X  100. It can be perceived from the results that limit can in fl uence the results. We can observe from the results that VABC obtained the equal objective values for the functions the other cases, the best results were obtained using different limit values but there is no signi fi cant difference between the best and worst values. For example the best a nd the worst results for function f 2 ( f 5 )withdimension D  X  100 were reported 2.53E 203, 5.33E-201 (1.51E 197, 2.12E 195) respectively. Based on the results, it can be concluded that the effect of limit on the performance of VABC is value for all the test functions.
 bees (i.e. EB  X  20, Eb  X  60, EB  X  100, EB  X  160 and EB  X  200) on the quality of solutions obtained by the VABC algorithm was investi-gated and the results are shown in Table 9 . In this table the best results are in bold face and underlined and the second best are bold faced only. From the results it can be observed that when
EB  X  200 for all the functions except f 3 , VABC obtained the best and the second best results. Moreover for function f 3 , the VABC algorithm obtained the third best value when EB  X  200. Therefore, it can be concluded from the results that increasing the number of individuals results in an increase in the chance of getting the optimal solution from the algorithm. As expected, for most of the benchmark functions choosing a greater number of employed bees (i.e. EB  X  200), results in an increase in the quality of the solutions obtained by VABC. 4.3.5. Experiments to analyze the execution time The results of various numerical experiments show that the
VABC algorithm is a well performed optimization algorithm which can solve continuous optimization problems successfully. However, in this section the computational time requirement of the proposed method is compared with those of ABC, PSO, SAABC, GABC, IABC, DBMPSO and TCPSO. Table 10 shows the mean execution time (in seconds) obtained by the algorithms to solve the benchmark functions with D  X  60 and D  X  100 : As seen from the Table 10 results, PSO based methods (e.g. PSO, DBMPSO and TCPSO) were able to obtain shorter computational times, while ABC based methods including SAABC, GABC, IABC and VABC require considerably long computational times. On the other hand from the Tables 3  X  7 and Figs. 3  X  5 results, it is clear that PSO based methods obtained the worst quality of results compared to those of ABC based methods for multidimensional test functions.
Furthermore, VABC obtained the worst computational time but there is not much difference compared to those of ABC based methods. On the other hand, the quality of the VABC results is superior to those of the other methods for high dimensional test functions. Therefore, there is a trade-off between the goodness of the results and the corresponding computational time. In addition, it can be concluded from the results that the total runtime of the solution is dependent on the type of the problem. For example the f 2 function takes the least computational efforts while f consumes the maximum. 5. Conclusion
PSOABC was proposed for the optim ization of continuous numerical functions. The exploration and e xploitation properties of ABC and
PSO were used to increase the performance and the convergence rate of the VABC method. The ef fi ciency of the proposed method was examined on unimodal and multimodal benchmark functions. The results show that the proposed VABC is superior to original ABC and some state-of-the-art ABC variants including GABC, SAABC, ABC/ Best1 and IABC on multidimensional benchmark functions. Moreover the results also indicate that the proposed method outperformed original PSO and some recent PSO based methods including: CPSO,
DBMPSOandTCPSO.IntheVABCtheexplorationabilityofABCis used to search the solution space and the exploitation ability of PSO is used to fi nd the best solution and prevent the algorithm from dropping into local optima. Future works will be focused on two directions. The fi rst is to apply the VABC to practical applications such as data clustering, feature selection, data mining, design and optimization of communication ne tworks, and the second direction istoextendtheproposedmethodtobeappliedtomulti-objective optimization problems.
 References
