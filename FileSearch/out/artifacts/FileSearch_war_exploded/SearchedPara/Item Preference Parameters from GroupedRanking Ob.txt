 Over the years, there have been a number of efforts to develop models and ana-lytic techniques for item rankings or order ings of objects. So far, various models of ranking have been proposed according to the assumption of the underlying mechanism how rankings are generated. Bradley and Terry [1] have proposed a model in which each item I i has a real valued parameter  X  i and the probability of being chosen item I i over item I j is given by P ( I i I j )=  X  i  X  means I i is preferred to I j . This model is based on Luce X  X  choice axiom [2], and referred to as the Bradley-Terry-Luce model. The natural extension of the Bradley-Terry-Luce model is given by Plackett [3] and we refer to the model as the Plackett-Luce model henceforth. Wit h the item preference level parameter  X  = {  X  i } N i =1 for N items, in the Plackett-Luce model, the probability of ranking is defined as where a ( j ) denotes the index of the item that occupies the j -thpositioninthe ranking. In this model, greater value of  X  i implies that the item I i is highly ranked.

In this paper, we generalize the Plackett-Luce model to cope with the grouped ranking observations, in which each of U judges (users, henceforth) rates N items on a scale of 1 to M , M  X  N . We suppose there is a latent ordering in a set of the same rated items, but we only observe M groups of items which are divisions of N items. For example, when 7 items I = { I 1 ,...,I 7 } are rated with a scale of M = 3, we get a grouped ranking observation from a user u observations are available from U individual users, i.e. we get a set of observations such that  X  i &gt; 0 , N i =1  X  i = 1, and our goal is to estimate the parameter  X  Model Description and the Likelihood Function Suppose that U users independently give ratings of N items I = { I 1 ,...,I N } , ranging from 1 to M . The indexes of the most preferred items by user u are grouped into G u 1 , and that of next preferred items are grouped into G u 2 ,andsoon where G u m = { i  X  X  1 ,...,N }| I i  X  m -th group } .Inthispaper, D u is called a grouped ranking observation henceforth.

When we need to consider the order of elements in group G u m ,weusetheaction of a permutation  X  on G u m . For example, when we write G u m = { 2 , 6 , 7 } ,wedo not consider its order in the group. By the action of a permutation  X  = we get  X  ( G u m )=(7 , 2 , 6) as an ordered index set, and the operations such as summation or product over its elements should be taken in the order of  X  ( G u m ),
Given U grouped ranking observations, we consider the problem of inferring We can not make comparison between item s within the same rated group in the observations, however, we assume that there is a latent ordering within a group and a user makes a grouped ranking observation as the following procedure: 1. Give a full ranking to all N items, 2. Divide N items into M groups without changing item ordering.
 In our grouped ranking model , the given data set is composed of grouped ranking not observable.

Let us explain details of the model, and derive the likelihood function for our model. Suppose we have a grouped ranking observation D u = { G u 1 ,G u 2 ,G u 3 } for 7 items. We know that any item in G u 1 is preferred to any item in G u 2 by this user, however, there are no information for the order of items in the same groups. Suppose the user gave the ranking I 7 I 2 I 6 in G u 2 , for example. Since the items in G u 1 are already chosen and excluded, the probability that the probability that the items in the group G u m are chosen in the order specified by  X  . Generalizing the above example, we get the general form of the joint probability as the group G u m .Wecall  X  u m a group parameter of the group G u m  X  D u henceforth.
As the latent order in each group is expressed by the action of a permutation  X  in the group G u m . Then the expectation of occurrence for the group G u m is a sum of the joint probabilities over possible latent orders which is nothing but the marginalization of permutations. As a result, from equations (2) and (3), we get a log likelihood of a group G u m as Obviously, if every group consists of only one item and M = N , our model is reduced to the original Plackett-Luce model. By summing up l (  X , m, u ) for all groups and for all users, we get the likelihood of the given data as It is worth noting that Huang et al .[4] have mentioned a similar generalization of the Plackett-Luce model, which they call the multiple team comparison model . They considered the ranking of the grouped items (teams) instead of items itself. In their model, the number of groups ca n vary depending on each user, which is denoted by M u , and the group ranking probability is defined as P ( G u 1 G u 2 which looks similar to a lower bound of the likelihood (5) of our model which will be derived later in this section. The difference between this model and our proposed model is whether the model considers the orderings in the groups. In their model, in other words, they assu me that groups of items are somehow predefined and users only give rankings of those groups.
Note that the maximization of the likelihood for our model is apparently a hard task, especially for a large size of items and/or users. The major source of the complexity is the existence of latent orderings in the model.
 Lower Bound of the Log Likelihood We derive a lower bound of the log likelihood function (5) in which no marginal-ization or no permutation is contained. The denominator in the expression (4) reflects the normalization of parameters  X  i in the sequential item selection. As an approximation of this normalization, we replace the denominator in (4) by n  X  m  X  u n . With this replacement, we get a lower bound of (4) as l (  X , m, u )=log Note that by replacing the denominator of (4) in such a way that it does not contain terms depending on the permutation  X  , the marginalization in (4) is omit this constant factor henceforth. By summing up l (  X , m, u ) for all groups and all users in the observations, we get a lower bound of the log likelihood function of the given data as to a maximization of L (  X  ). We note that for the original Plackett-Luce model, [5] gave a lower bound of the likelihood and proposed an iterative algorithm to maximize the function with respect to the item preference level parameter  X  .
We can now apply any non-linear optimizer to maximize L (  X  ) with respect to  X  , however, still direct optimization of L (  X  ) may cause two possible problems. The first problem is computational complexity. As the lower bound is a non-linear function of  X  , its complexity increases with the number of items N .The second problem is the need for the rema ximization of the likelihood when the new user join the system with new ranking data. In the next section, we will propose an alternative approach to estimate the item preference parameter. As is clear from its formulation, the computational time of the algorithm, which will be derived in the next section, mainly depends on the number of users U , and scales linearly with U . Remember that our motivation of maximizing the likelihood is to find the item preference level parameter  X  which is consistent with the observations as much as possible. With this notion, we decompose the second term of L (  X  )to U in-dependent optimization problems with respect to group parameters  X  u m , X  u m  X  0 D These problems are relatively small-sized optimization problems with linear con-straints, and efficiently solved with arbitrary nonlinear optimizers.
We will show that the problem of finding the optimal parameter  X  which is most consistent with the observations is solved by the em algorithm in the information geometry literature[6]. The solutions of the optimization problems (9) can be seen as incomplete observations of the item preference level parameter. As the item preference parameters {  X  i } are constrained to be positive and add up to 1,  X  = {  X  i } N i =1 forms a manifold known as the standard ( N  X  1)-simplex  X  m } of  X  N  X  1 (Figure 1(a)). The optimal parameter  X  is a point in  X  N  X  1 that is the nearest to all the submanifolds {D u } U u =1 in terms of Kullback-Leibler (KL) divergence KL (  X ,  X  ):= N i =1  X  i log(  X  i / X  i ). The em algorithm gradually minimizes the KL divergence by repeating the e -step and m -step alternately.
Suppose we have an estimated parameter  X  ( t )after t times iterations. In the e -step, we find the points  X   X  u ( t ) on the submanifolds D u which are nearest in terms of KL divergence from the previous estimate  X  ( t )(Figure 1(b)). That is, ( t ):=argmin  X   X  X  u KL (  X  , X  ( t )). This procedure is called the e -projection and written as sponding group parameter. In the m -step, we find the point  X  ( t +1) on  X  N  X  1 which minimizes the sum of KL divergences from the points  X   X  u ( t ) on the sub-This procedure is called the m -projection and written as (locally) optimal parameter  X  ( t ). To save space, we omit details of calculus that show the e -and m -projection , i.e. minimization of sum of KL divergences from submanifolds to a point  X  are described as (10) and (11) respectively. Figure 1 shows these procedures in the case of N =3, U =3, M =2.The em algorithm for our model is summarized as follows: Algorithm 1 (The em algorithm for grouped ranking model) input grouped ranking observations { D u = { G u 1 ,...,G u M }} U u =1 . initialize choose initial parameter  X  (0) , and solve the optimization problems (9) repeat from t =0 , until convergence output converged parameter  X  ( t ) . Synthetic Data We apply the proposed algorithm to synthetic data to show how the proposed algorithm works. We fixed the number of groups to 5, and the number of items N to 10 for simplicity. We vary the number of users as U =10 , 20 , 50 , 100, and show how the number of observations affects to parameter estimation. We randomly choose 100 true parameters for data gen eration and averaged the KL divergences of the estimated parameter from the true parameter.

The data are generated as described in Section 2. We first set the true item preference parameter  X   X  =(  X   X  1 ,..., X   X  10 ). Then each user u =1 ,...,U makes full rankings, and divides N items into M = 5 groups without changing item order-ing. To these U grouped ranking observations, we apply our proposed algorithm and get the estimated parameter. For each true parameter value and for each user size, we generate grouped ranking observations 100 times. In Table 1, we show the mean and standard deviation of the KL divergence of the estimated parameters from the true parameters. The right most column of the Table 1 is the average of the KL divergence of the uniform distribution from the true parameters as a baseline value. We can see that our algorithm can get closer to the true parameter in average.

We also show how the average KL divergence from the true parameter de-creases and how the lower bound of the log likelihood L (  X  ) increases as the algorithm progresses. Figure 2 shows the change of the average KL divergence of the estimated parameter from the true parameter (solid line), and the average lower bound of the likelihood (dashed line) for the estimated parameter when the number of users is fixed to 100. We can see that with only a few iterations, the algorithm converges and successfully finds estimates of the parameters. Real-world Data: Application to MovieLens Data We show a preliminary result of the application of preference level parameter estimation to find the most commonly preferred movies in the MovieLens data set. The MovieLens data set consists of 100 , 000 ratings ranging from 1 to 5 for 1682 movies by 943 users. We first selected 100 most frequently rated movies, and then extracted 554 users who rated more than 20 of the 100 movies. The evaluation criterion for the parameter estimation is the accuracy of the rating predictions by highly estimated parameter values. We get estimated parameter values for 100 movies, and we suppose that the movies with the highest and the second highest parameter value may be rated as 5 (very good) by most of the users. That is, the accuracy of the ratin g prediction means that the frequency of the user X  X  high ratings for the highest a nd the second highest estimated movies. We set aside one user X  X  rating data and estimate the preference level parameter using the rest of the data. If the user set aside gave rating 5 to the movie which has the highest and second highest parameter value, we count this case as a positive case, and if the user have given rating 4 or below, we count as negative case. To examine the appropriateness of the model, we also implemented the log likelihood function (6) of the multiple team comparison (MTC) model proposed in [4], and maximized the likelihood to find the optimal parameter. Table 2 shows the accuracy of the rating predictions by estimated parameter of our grouped ranking model and the MTC model. From Table 2, we see that the highest ranked movie we found by our model is a movie to which more than 60 % of users have given the highest rating. We can also see that the ability of our model to predict the item ratings by the estimated parameter is superior to that of the MTC model when applied to the MovieLens data set, and we can infer that the movie rating mechanism in this data set is closer to our grouped ranking model than the MTC model as expected. In this paper, we proposed a novel model for grouped ranking observations parametrized by item prefer ence level parameter. We derived the likelihood func-tion of the parameter, and gave a lower bound of the function which is easy to estimate. We also proposed the em algorithm to find the item preference level parameter which is the most consistent with observations. We conducted small numerical experiments both for synthet ic and real-world data. From the result for synthetic data, we can conclude that the proposed algorithm can reduce the KL divergence from the true parameters by iterative optimization, and from the result of real-world data, we got promising accuracy to predict the most popular items.

We suggested that we can apply our model and algorithm to recommender systems, however, it is not able to mak e personalized reco mmendations yet. To make a recommender system with the proposed model, we think we need the mixture of ranking models and the way to combine the multiple preference parameters. The work in this direction is now in progress, and it will enable us to compare other r ecommender systems with our method.

