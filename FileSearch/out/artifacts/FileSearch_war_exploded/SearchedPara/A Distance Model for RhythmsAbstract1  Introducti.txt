 Jean-Fran  X cois Paiement paiement@idiap.ch Yves Grandvalet Yves.Grandvalet@utc.fr Samy Bengio bengio@google.com Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043, USA Douglas Eck douglas.eck@umontreal.ca 3J7, Canada Reliable models for music would be useful in a broad range of applications, from contextual music genera-tion to on-line music recommendation and retrieval. However, modeling music involves capturing long-term dependencies in time series, which has proved very dif-ficult to achieve with traditional statistical methods. Note that the problem of long-term dependencies is not limited to music, nor to one particular probabilis-tic model (Bengio et al., 1994).
 Music is characterized by strong hierarchical depen-dencies determined in large part by meter , the sense of strong and weak beats that arises from the inter-action among hierarchical levels of sequences having nested periodic components. Such a hierarchy is im-plied in western music notation, where different levels are indicated by kinds of notes (whole notes, half notes, quarter notes, etc.) and where bars establish measures of an equal number of beats. Meter and rhythm pro-vide a framework for developing musical melody. For example, a long melody is often composed by repeating with variation shorter sequences that fit into the met-rical hierarchy (e.g. sequences of 4, 8 or 16 measures). It is well know in music theory that distance patterns are more important than the actual choice of notes in order to create coherent music (Handel, 1993). In this work, distance patterns refer to distances between sub-sequences of equal length in particular positions. For instance, measure 1 may be always similar to measure 5 in a particular musical genre. In fact, even random music can sound structured and melodic if it is built by repeating random subsequences with slight variation. Many algorithms have been proposed for audio beat tracking (Dixon, 2007; Scheirer, 1998). Probabilistic models have also been proposed for tempo tracking and inference of rhythmic structure in musical audio (Whiteley et al., 2007; Cemgil &amp; Kappen, 2002). The goal of these models is to align rhythm events with the metrical structure. However, simple Markovian as-sumptions are used to model the transitions between rhythms themselves. Hence, these models do not take into account long-term dependencies. A few generative models have already been proposed for music in gen-eral (Pachet, 2003; Dubnov et al., 2003). While these models generate impressive musical results, we are not aware of quantitative comparisons between models of music with machine learning standards, as it is done in Section 3 in terms of out-of-sample prediction ac-curacy. In this paper, we focus on modeling rhyth-mic sequences, ignoring for the moment other aspects of music such as pitch, timbre and dynamics. How-ever, by capturing aspects of global temporal struc-ture in music, this model should be valuable for full melodic prediction and generation: combined with an audio transcription algorithm, it should help improve the poor performance of state-of-the-art transcription systems; it could as well be included in genre classifiers or automatic composition systems (Eck &amp; Schmidhu-ber, 2002); used to generate rhythms, the model could act as a drum machine or automatic accompaniment system which learns by example.
 Our main contribution is to propose a generative model for distance patterns, specifically designed for capturing long-term dependencies in rhythms. In Sec-tion 2, we describe the model, detail its implemen-tation and present an algorithm using this model for rhythm prediction. The algorithm solves a constrained optimization problem, where the distance model is used to filter out rhythms that do not comply with the inferred structure. The proposed model is evalu-ated in terms of conditional prediction error on two distinct databases in Section 3 and a discussion fol-lows. In this Section, we present a generative model for distance patterns and its application to rhythm se-quences. Such a model is appropriate for most music data, where distances between subsequences of data exhibit strong regularities. 2.1. Motivation Let x l = ( x l 1 ,...,x l m )  X  R m be the l -th rhythm se-quence in a dataset X = { x 1 ,..., x n } where all the sequences contain m elements. Suppose that we con-struct a partition of this sequence by dividing it into i  X  X  1 ,..., X  } . We are interested in modeling the dis-tances between these subsequences, given a suitable metric d ( y i ,y j ) : R m/ X   X  R m/ X   X  R . As was pointed out in Section 1, the distribution of d ( y i ,y j ) for each specific choice of i and j may be more important when modeling rhythms (and music in general) than the ac-tual choice of subsequences y i .
 Hidden Markov Models (HMM) (Rabiner, 1989) are commonly used to model temporal data. In princi-ple, an HMM is able to capture complex regularities in patterns between subsequences of data, provided its number of hidden states is large enough. However, when dealing with music, such a model would lead to a learning process requiring a prohibitive amount of data: in order to learn long range interactions, the training set should be representative of the joint dis-tribution of subsequences. To overcome this problem, we summarize the joint distribution of subsequences by the distribution of distances between these sub-sequences. This summary is clearly not a sufficient statistics for the distribution of subsequences, but its distribution can be learned from a limited number of examples. The resulting model, which generates dis-tances, is then used to recover subsequences. 2.2. Decomposition of Distances Let D ( x l ) = ( d l i,j )  X   X   X  be the distance matrix asso-ciated with each sequence x l , where d l i,j = d ( y l i Since D ( x l ) is symmetric and contains only zeros on the diagonal, it is completely characterized by the up-per triangular matrix of distances without the diago-nal. Hence, where In words, we order the elements column-wise and do a standard factorization, where each random variable depends on the previous elements in the ordering. Hence, we do not assume any conditional indepen-dence between the distances.
 Since d ( y i ,y j ) is a metric, we have that d ( y i ,y equality is usually referred to as the triangle inequality . Defining we know that given previously observed (or sampled) distances, constraints imposed by the triangle inequal-ity on d l i,j are simply One may observe that the boundaries given in Eq. (3) contain a subset of the distances that are on the con-ditioning side of each factor in Eq. (1) for each indexes i and j . Thus, constraints imposed by the triangle in-equality can be taken into account when modeling each posed by previously observed/sampled distances given in Eq. (4). Figure 1 shows an example where  X  = 4. Using Eq. (1), the distribution of d l 2 , 4 would be condi-y 1 and y know that y l 2 and y l 4 cannot be far. Conversely, if sub-sequences y l 1 and y l 2 are far and y l 1 and y l 4 are close, we know that y l 2 and y l 4 cannot be close. 2.3. Modeling Relative Distances Between We want to model rhythms in a music dataset X con-sisting of melodies of the same musical genre. We first quantize the database by segmenting each song in m time steps and associate each note to the near-est time step, such that all melodies have the same length m 1 . It is then possible to represent rhythms by sequences containing potentially three different sym-bols: 1) Note onset, 2) Note continuation, and 3) Si-lence. When using quantization, there is a one to one mapping between this representation and the set of all possible rhythms. Using this representation, symbol 2 can never follow symbol 3. Let A = { 1 , 2 , 3 } ; in the remaining of this paper, we assume that x l  X  A m for all x l  X  X  .
 When using this representation, d l i,j can simply be cho-sen to be the Hamming distance (i.e. counting the number of positions on which corresponding symbols are different.) One could think of using more gen-eral edit distance such as the Levenshtein distance. However, this approach would not make sense psycho-acoustically: doing an insertion or a deletion in a rhythm produces a translation that alters dramatically the nature of the sequence. Putting it another way, rhythm perception heavily depends on the position on which rhythmic events occur. In the remainder of this paper, d l i,j is the Hamming distance between subse-quences y i and y j .
 We now have to encode our belief that melodies of the same musical genre have a common distance structure. For instance, drum beats in rock music can be very repetitive, except in the endings of every four mea-sures, without regard to the actual beats being played. This should be accounted for in the distributions of the corresponding d l i,j . With Hamming distances, the conditional distributions of d l i,j in Eq. (1) should be modeled by discrete distributions, whose range of pos-sible values must obey Eq. (4). Hence, we assume that the random variables ( d l i,j  X   X  l i,j ) / (  X  l i,j  X   X  l be identically distributed for l = 1 ,...,n . As an ex-ample, suppose that measures 1 and 4 always tend to be far away, that measures 1 and 3 are close, and that measures 3 and 4 are close; Triangle inequality states that 1 and 4 should be close in this case, but the de-sired model would still favor a solution with the great-est distance possible within the constrains imposed by triangle inequalities.
 All these requirements are fulfilled if we model d i,j  X   X  i,j by a binomial distribution of parameters (  X  i,j  X   X  i,j ,p i,j ), where p i,j is the probability that two sym-bols of subsequences y i and y j differ. With this choice, the conditional probability of getting d i,j =  X  i,j +  X  would be with 0  X  p i,j  X  1. If p i,j is close to zero/one, the relative distance between subsequences y i and y j is small/large. However, the binomial distribution is not flexible enough since there is no indication that the distribution of d i,j  X   X  i,j is unimodal. We thus model each d i,j  X   X  i,j with a binomial mixture distribution in order to allow multiple modes. We thus use j , and S i,j defined similarly as in Eq. (2). Parameters can be learned with the EM algorithm (Dempster et al., 1977) on rhythm data for a specific music style. In words, we model the difference between the ob-served distance d l i,j between two subsequences and the minimum possible value  X  i,j for such a difference by a binomial mixture.
 The parameters  X  i,j can be initialized to arbitrary val-ues before applying the EM algorithm. However, as the likelihood of mixture models is not a convex func-tion, one may get better models and speed up the learning process by choosing sensible values for the initial parameters. In the experiments reported in Sec-tion 3, the k-means algorithm for clustering (Duda et al., 2000) was used. More precisely, k-means was used to partition the values ( d l i,j  X   X  l i,j ) / (  X  l into c clusters corresponding to each component of the each of these clusters. We initialize the parameters  X  i,j with We then follow a standard approach (Bilmes, 1997) to apply the EM algorithm to the binomial mixture in Eq. (6). Let z l i,j  X  X  1 ,...,c } be a hidden variable telling which component density generated d l i,j . For every iteration of the EM algorithm, we first compute where  X   X  i,j are the parameters estimated in the previous iteration, or the parameters guessed with k-means on the first iteration of EM, and Then, the parameters can be updated with p and This process is repeated until convergence.
 Note that using mixture models for discrete data is known to lead to identifiability problems. Identifiabil-ity refers here to the uniqueness of the representation (up to an irrelevant permutation of parameters) of any distribution that can be modeled by a mixture. Estimation procedures may not be well-defined and asymptotic theory may not hold if a model is not iden-tifiable. However, the model defined in Eq. (6) is iden-p.40). While this is the case for most d i,j , we observed that this condition is sometimes violated. Whatever happens, there is no impact on the estimation because we only care about what happens at the distribution level: there may be several parameters leading to the same distribution, some components may vanish in the fitting process, but this is easily remedied, and EM be-haves well.
 As stated in Section 1, musical patterns form hierarchi-cal structures closely related to meter (Handel, 1993). Thus, the distribution of p ( D ( x l )) can be computed for many numbers of partitions within each rhythmic sequence. Let P = {  X  1 ,... X  h } be a set of numbers of partitions to be considered by our model, where h is the number of such numbers of partitions. The choice of P depends on the domain of application. Following meter, P may have dyadic 2 tree-like structure when modeling music (e.g. P = { 2 , 4 , 8 , 16 } ). Let D  X  r ( x be the distance matrix associated with sequence x l di-vided into  X  r parts. Estimating the joint probability Q in this section leads to a model of the distance struc-tures in music datasets. Suppose we consider 16 bars songs with four beats per bar. Using P = { 8 , 16 } would mean that we consider pairs of distances be-tween every group of two measures (  X  = 8), and every single measures (  X  = 16).
 One may argue that our proposed model for long-term dependencies is rather unorthodox. However, simpler models like Poisson or Bernoulli process (we are work-ing in discrete time) defined over the whole sequence would not be flexible enough to represent the particu-lar long-term structures in music. 2.4. Conditional Prediction For most music applications, it would be particularly helpful to know which sequence  X  x s ,...,  X  x m maximizes events are the most likely given the past s  X  1 obser-vations would be useful both for prediction and gen-eration. Note that in the remaining of the paper, we refer to prediction of musical events given past obser-vations only for notational simplicity. The distance model presented in this paper could be used to predict any part of a music sequence given any other part with only minor modifications.
 While the described modeling approach captures long range interactions in the music signal, it has two short-comings. First, it does not model local dependen-cies: it does not predict how the distances in the smallest subsequences (i.e. with length smaller than m/ max( P )) are distributed on the events contained in these subsequences. Second, as the mapping from sequences to distances is many to one, there exists several admissible sequences x l for a given set of dis-tances. These limitations are addressed by using an-other sequence learner designed to capture short-term dependencies between musical events. Here, we use a standard Hidden Markov Model (HMM) (Rabiner, 1989) displayed in Figure 2, following standard graph-ical model formalism. Each node is associated to a random variable and arrows denote conditional depen-dencies. Learning the parameters of the HMM can be done as usual with the EM algorithm. The two models are trained separately using their re-spective version of the EM algorithm. For predicting the continuation of new sequences, they are combined by choosing the sequence that is most likely according to the local HMM model, provided it is also plausible regarding the model of long-term dependencies. Let p
HMM ( x l ) be the probability of observing sequence x l estimated by the HMM after training. The final pre-dicted sequence is the solution of the following opti-mization problem:  X   X   X   X   X   X   X  where P 0 is a threshold. In practice, one solves a La-grangian formulation of problem (7), where we use log-Algorithm 1 Simple optimization algorithm to max-imize p ( X  x i ,...,  X  x m | x 1 ,...,x i  X  1 ) Initialize  X  x s ,...,  X  x m using Eq. (9)
Initialize end = false while end = false do end while
Output  X  x s ,...,  X  x m . probabilities for obvious computational reasons: where tuning  X  has the same effect as choosing a threshold P 0 in Eq. (7) and can be done by cross-validation.
 Multidimensional Scaling (MDS) is an algorithm that tries to embed points (here  X  X ocal X  subsequences) into a potentially lower dimensional space while trying to be faithful to the pairwise affinities given by a  X  X lobal X  distance matrix. Here, we propose to consider the pre-diction problem as finding sequences that maximize the likelihood of a  X  X ocal X  model of subsequences un-der the constraints imposed by a  X  X lobal X  generative model of distances between subsequences. In other words, solving problem (7) is similar to finding points between which distances are as close as possible to a given set of distances (i.e. minimizing a stress func-tion in MDS). Naively trying all possible subsequences to maximize (8) leads to O ( | A | ( m  X  s +1) ) computations. Instead, we propose to search the space of sequences using a variant of the Greedy Max Cut (GMC) method (Rohde, 2002) that has proven to be optimal in terms of running time and performance for binary MDS op-timization.
 The subsequence  X  x s ,...,  X  x m can be simply initialized with ( X  x s ,...,  X  x m ) = max  X  x using the local HMM model. Then, Algorithm 1 car-ries on complete optimization.
 For each position, we try every admissible symbol of the alphabet and test if a change increases the proba-bility of the sequence. We stop when no further change can increase the value of the utility function. Obvi-ously, many other methods could have been used to search the space of possible sequences  X  x s ,...,  X  x m , such as simulated annealing (Kirkpatrick et al., 1983). We chose Algorithm 1 for its simplicity and the fact that it yields excellent results, as reported in the following section. Two rhythm databases from different musical genres were used to evaluate the proposed model. Firstly, 47 jazz standards melodies (Sher, 1988) were interpreted and recorded by the first author in MIDI format. Ap-propriate rhythmic representations as described in Sec-tion 2.3 have been extracted from these files. The com-plexity of the rhythm sequences found in this corpus is representative of the complexity of common jazz and pop music. We used the last 16 bars of each song to train the models, with four beats per bar. Two rhyth-mic observations were made for each beat, yielding ob-served sequences of length 128. We also used a subset of the Nottingham database 3 consisting of 53 tradi-tional British folk dance tunes called  X  X ornpipes X . In this case, we used the first 16 bars of each song to train the models, with four beats per bar. Three rhyth-mic observations were made for each beat, yielding observed sequences of length 192. The sequences from this second database contain no silence (i.e. rests), leading to sequences with binary states.
 The goal of the proposed model is to predict or gener-ate rhythms given previously observed rhythm pat-terns. As pointed out in Section 1, such a model could be particularly useful for music information re-trieval, transcription, or music generation applica-tions. Let  X  t i = 1 if  X  x t i = x t i , and 0 otherwise, with x t = ( x t of the evaluated prediction model on the i -th posi-tion when given ( x t 1 ,...,x t s ) with s &lt; i . Assume that the dataset is divided into K folds T 1 ,...,T K (each containing different sequences), and that the k -th fold T k contains n k test sequences. When using cross-validation, the accuracy Acc of an evaluated model is given by Note that, while the prediction accuracy is simple to estimate and to interpret, other performance criteria, such as ratings provided by a panel of experts, should be more appropriate to evaluate the relevance of music models. We plan to define such an evaluation protocol in future work. We used 5-fold double cross-validation to estimate the accuracies. Double cross-validation is a recursive application of cross-validation that enables to jointly optimize the hyper-parameters of the model and evaluate its generalization performance. Standard cross-validation is applied to each subset of K  X  1 folds with each hyper-parameter setting and tested with the best estimated setting on the remaining hold-out fold. The reported accuracies are the averages of the results of each of the K applications of simple cross-validation during this process.
 For the baseline HMM model, double cross-validation optimizes the number of possible states for the hidden variables. 2 to 20 possible states were tried in the re-ported experiments. In the case of the model with dis-tance constraints, referred to as the global model, the hyper-parameters that were optimized are the num-ber of possible states for hidden variables in the local HMM model (i.e. 2 to 20), the Lagrange multiplier  X  , the number of components c (common to all dis-tances) for each binomial mixture, and the choice of P , i.e. which partitions of the sequences to consider. Values of  X  ranging between 0.1 and 4 and values of c ranging between 2 and 5 were tried during double cross-validation. Since music data commonly shows strong dyadic structure following meter, many subsets of P = { 2 , 4 , 8 , 16 } were allowed during double cross-validation.
 Note that the baseline HMM model is a poor bench-mark on this task, since the predicted sequence, when prediction consists in choosing the most probable sub-sequence given previous observations, only depends on the state of the hidden variable in position s , where s is the index of the last observation. This observation implies that the number of possible states for the hid-den variables of the HMM upper-bounds the number of different sequences that the HMM can predict. How-ever, this behavior of the HMM does not harm the validity of the reported experiments. The main goal of this quantitative study is to measure to what extent distance patterns are present in music data and how well these dependencies can be captured by the pro-posed model. What we really want to measure is how much gain we observe in terms of out-of-sample predic-tion accuracy when using an arbitrary model if we im-pose additional constraints based on distance patterns. That being said, it would be interesting to measure the effect of appending distance constraints to more com-plex music prediction models (Pachet, 2003; Dubnov et al., 2003) in future work.
 Results in Table 1 for the jazz standards database show that considering distance patterns significantly improves the HMM model. One can observe that the baseline HMM model performs much better when try-ing to predict the last 32 symbols. This is due to the fact that this database contains song endings. Such endings contain many silences and, in terms of accu-racy, a useless model predicting silence at any position performs already well. On the other hand, the end-ings are generally different from the rest of the rhythm structures, thus harming the performance of the global model when just trying to predict the last 32 symbols.
Results in Table 2 for the hornpipes database again show that the prediction accuracy of the global model is consistently better than the prediction accuracy of the HMM, but the difference is less marked. This is mainly due to the fact that this dataset only contains two symbols, associated to note onset and note con-tinuation. Moreover, the frequency of these symbols is quite unbalanced, making the HMM model much more accurate when almost always predicting the most com-mon symbol.
 In Table 3, the set of partitions P is not optimized by double cross-validation. Results are shown for dif-ferent fixed sets of partitions. The best results are reached with  X  X eeper X  dyadic structure. This is a good indication that the basic hypothesis underlying the proposed model is well-suited to music data, namely that dyadic distance patterns exhibit strong regulari-ties in music data. We did not compute accuracies for  X  &gt; 16 because it makes no sense to estimate distribu-tion of distances between too short subsequences. The main contribution of this paper is the design and evaluation of a generative model for distance pat-terns in temporal data. The model is specifically well-suited to music data, which exhibits strong reg-ularities in dyadic distance patterns between subse-quences. Reported conditional prediction accuracies show that such regularities are present in music data and can be effectively captured by the proposed model. Moreover, learning distributions of distances between subsequences really helps for accurate rhythm predic-tion. Rhythm prediction can be seen as the first step towards full melodic prediction and generation. A promising approach would be to apply the proposed model to melody prediction. It could also be read-ily used to increase the performance of transcription algorithms, genre classifiers, or even automatic com-position systems.
 The choice of the HMM to initialize the model is not optimal. However, this has no impact on the validity of the reported results, since our goal was to show the importance of distance patterns between subsequences in rhythm data. In order to sample to models to gen-erate subjectively good results (Pachet, 2003; Dubnov et al., 2003), one could use other benchmark and ini-tialization techniques, such as repetition of common patterns.
 Finally, besides being fundamental in music, modeling distance between subsequences should also be useful in other application domains, such as in natural language processing. Being able to characterize and constrain the relative distances between various parts of a se-quence of bags-of-concepts could be an efficient means to improve performance of automatic systems such as machine translation (Och &amp; Ney, 2004). On a more general level, learning constraints related to distances between subsequences can boost the performance of  X  X hort memory X  models such as the HMM.
 This work was supported in part by the IST Program of the European Community, under the PASCAL Net-work of Excellence, IST-2002-506778, funded in part by the Swiss Federal Office for Education and Science (OFES) and the Swiss NSF through the NCCR on IM2.
 Bengio, Y., Simard, P., &amp; Frasconi, P. (1994). Learn-ing long-term dependencies with gradient descent is difficult. IEEE Transactions on Neural Networks , 5 , 157 X 166.
 Bilmes, J. (1997). A gentle tutorial on the EM algo-rithm and its application to parameter estimation for Gaussian mixture and hidden Markov models. Cemgil, A. T., &amp; Kappen, H. J. (2002). Rhythm quan-tization and tempo tracking by sequential Monte Carlo. Advances in Neural Information Processing Systems 14 (pp. 1361 X 1368).
 Dempster, A. P., Laird, N. M., &amp; Rubin, D. B. (1977). Maximum likelihood from incomplete data via the
EM algorithm. Journal of the Royal Statistical So-ciety , 39 , 1 X 38.
 Dixon, S. (2007). Evaluation of the audio beat tracking system beatroot. Journal of New Music Research , 36 , 39 X 50.
 Dubnov, S., Assayag, G., Lartillot, O., &amp; Bejerano, G. (2003). Using machine-learning methods for musical style modeling. IEEE Computer , 10 .
 Duda, R. O., Hart, P. E., &amp; Stork, D. G. (2000).
Pattern classification, second edition . Wiley Inter-science.
 Eck, D., &amp; Schmidhuber, J. (2002). Finding temporal structure in music: Blues improvisation with LSTM recurrent networks. Neural Networks for Signal Pro-cessing XII, Proc. 2002 IEEE Workshop (pp. 747 X  756). New York: IEEE.
 Handel, S. (1993). Listening: An introduction to the perception of auditory events . Cambridge, Mass.: MIT Press.
 Kirkpatrick, S., Gelatt, C. D., &amp; Vecchi, M. P. (1983). Optimization by simulated annealing. Sci-ence, Number 4598, 13 May 1983 , 220, 4598 , 671 X  680.
 Och, F. J., &amp; Ney, H. (2004). The alignment template approach to statistical machine translation. Com-putational Linguistics , 30 , 417 X 449.
 Pachet, F. (2003). The continuator: Musical interac-tion with style. Journal of New Music Research , 32 , 333 X 341.
 Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recogni-tion. Proceedings of the IEEE , 77 , 257 X 285. Rohde, D. L. T. (2002). Methods for binary multidi-mensional scaling. Neural Comput. , 14 , 1195 X 1232. Scheirer, E. (1998). Tempo and beat analysis of acous-tic musical signals. Journal of the Acoustical Society of America , 103 , 588 X 601.
 Sher, C. (Ed.). (1988). The New Real Book , vol. 1-3. Sher Music Co.
 Titterington, D. M., Smith, A. F. M., &amp; Makov, U. E. (1985). Statistical analysis of finite mixture distri-butions . Wiley.
 Whiteley, N., Cemgil, A. T., &amp; Godsill, S. J. (2007).
Sequential inference of rhythmic structure in mu-sical audio. Proc. of IEEE Int. Conf. on Acous-tics, Speech and Signal Processing (ICASSP 07) (pp.
