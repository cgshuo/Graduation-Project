 Most statistical and machine-learning algorithms assume that the data is a random sample drawn from a station-ary distribution. Unfortunately, most of the large databases available for mining today violate this assumption. They were gathered over months or years, and the underlying pro-cesses generating them changed during this time, sometimes radically. Although a number of algorithms have been pro-posed for learning time-changing concepts, they generally do not scale well to very large databases. In this paper we propose an efficient algorithm for mining decision trees from continuously-changing data streams, based on the ultra-fast 
VFDT decision tree learner. This algorithm, called CVFDT, stays current while making the most of old data by growing an alternative subtree whenever an old one becomes ques-tionable, and replacing the old with the new when the new becomes more accurate. CVFDT learns a model which is similar in accuracy to the one that would be learned by reapplying VFDT to a moving window of examples every time a new example arrives, but with O(1) complexity per example, as opposed to O(w), where w is the size of the window. Experiments on a set of large time-changing data streams demonstrate the utility of this approach. 
H.2.8 [Database Management]: Database Applications--concept learning; 1.5.2 [Pattern Recognition]: Design Me-
Decision trees, Hoeffding bounds, incremental learning, data streams, subsampling, concept drift requires prior specific permission and/or a fee. KDD 01 San Francisco CA USA 
Copyright ACM 2001 1-58113-391 -x /01/08...$5.00 
Modern organizations produce data at unprecedented rates; among large retailers, e-commerce sites, telecommuni-cations providers, and scientific projects, rates of gigabytes per day are common. While this data can contain valuable knowledge, its volume increasingly outpaees practitioners' ability to mine it. As a result, it is now common practice either to mine a subsample of the available data or to mine for models drastically simpler than the data could support. 
In some cases, the volume and time span of accumulated data is such that just storing it consistently and reliably for future use is a challenge. Further, even when storage is not problematic, it is often difficult to gather the data in one place, at one time, in a format appropriate for mining. 
For all these reasons, in many areas the notion of mining a fixed-sized database is giving way to the notion of mining an open-ended data stream as it arrives. The goal of our re-search is to help make this possible with a minimum of effort for the data mining practitioner. In a previous paper [9] we presented VFDT, a decision tree induction system capable of learning from high-speed data streams in an incremental, anytime fashion, while producing models that axe asymp-totically arbitrarily close to those that would be learned by traditional decision tree induction systems. 
Most statistical and machine-learning algorithms, includ-ing VFDT, make the assumption that training data is a random sample drawn from a stationary distribution. Un-fortunately, most of the large databases and data streams available for mining today violate this assumption. They ex-ist over months or years, and the underlying processes gen-erating them changes during this time, sometimes radically. 
For example, a new product or promotion, a hacker's attack, a holiday, changing weather conditions, changing economic conditions, or a poorly calibrated sensor could all lead to vio-lations of this assumption. For classification systems, which attempt to learn a discrete function given examples of its in-puts and outputs, this problem takes the form Of changes in the target function over time, and is known as concept drift. 
Traditional systems assume that all data was generated by a single concept. In many cases, however, it is more accurate to assume that data was generated by a series of concepts, or by a concept function with time-varying parameters. Tradi-tional systems learn incorrect models when they erroneously assume that the underlying concept is stationary if in fact it is drifting. 
One common approach to learning from time-changing data is to repeatedly apply a traditional learner to a slid-ing window of ~v examples; as new examples arrive they are inserted into the beginning of the window, a corresponding number of examples is removed from the end of the win-dow, and the learner is reapplied [27]. As long as w is small relative to the rate of concept drift, this procedure assures availability of a model reflecting the current concept gen-erating the data. If the window is too small, however, this may result in insufficient examples to satisfactorily learn the concept. Further, the computational cost of reapplying a learner may be prohibitively high, especially if examples ar-rive at a rapid rate and the concept changes quickly. 
To meet these challenges we propose the CVFDT system, which is capable of learning decision trees from high-speed, time changing data streams. CVFDT works by efficiently keeping a decision tree up-to-date with a window of exam-ples. In particular, it is able to keep its model consistent with a window using only a constant amount of time for each new example (more precisely, time proportional to the number of attributes in the data and the depth of the in-duced tree). CVFDT grows an alternate subtree whenever an old one seems to be out-of-date, and replaces the old one when the new one becomes more accurate. This allows it to make smooth, fine-grained adjustments when concept drift occurs. In effect, CVFDT is able to learn a nearly equivalent model to the one VFDT would learn if repeatedly reapplied to a window of examples, but in O(1) time instead of O(w) time per new example. 
In the next section we discuss the basics of the VFDT sys-tem, and in the following section we introduce the CVFDT system. We then present a series of experiments on synthetic data which demonstrate how CVFDT can outperform tradi-tional systems on high-speed, time-changing data streams. Next, we apply CVFDT to mining the stream of web page requests for the entire University of Washington campus. We conclude with a discussion of related and future work. The classification problem is generally defined as follows. A set of N training examples of the form (x, y) is given, where y is a discrete class label and x is a vector of d at-tributes, each of which may be symbolic or numeric. The goal is to produce from these examples a model y = f(x) which will predict the classes y of future examples x with high accuracy. For example, x could be a description of a client's recent purchases, and y the decision to send that cus-tomer a catalog or not; or x could be a record of a cellular-telephone call, and y the decision whether it is fraudulent or not. One of the most effective and widely-used classifi-cation methods is decision tree learning [4, 20]. Learners of this type induce models in the form of decision trees, where each node contains a test on an attribute, each branch from a node corresponds to a possible outcome of the test, and each leaf contains a class prediction. The label y = DT(x) for an example x is obtained by passing the example down from the root to a leaf, testing the appropriate attribute at each node and following the branch corresponding to the attribute's value in the example. A decision tree is learned by recursively replacing leaves by test nodes, starting at the root. The attribute to test at a node is chosen by compar-ing all the available attributes and choosing the best one according to some heuristic measure. Classic decision tree learners like C4.5 [20], CART, SLIQ [17], and SPRINT [24] Inputs: Output: Procedure VFDT (S, X, G, ~, r) Let HT be a tree with a single leaf ll (the root). Let Xl = X U {X X }. 
Let G1 (X X ) be the ~ obtained by predicting the most frequent class in S. For each class yk For each value xij of each attribute Xi E X For each example (x, y) in S Sort (x, y) into a leaf I using HT. For each xij in x such that X~ E Xz 
Label l with the majority class among the examples Let nL be the number of examples seen at I. 
If the examples seen so far at l are not all of the same 
Return HT. 98 use every available training example to select the best at-tribute for each split. This policy is necessary when data is scarce, but it has two problems when training examples are abundant: it requires all examples be available for consid-eration throughout their entire runs, which is problematic when data does not fit in RAM or on disk, and it assumes that the process generating examples remains the same dur-ing the entire period over which the examples are collected and mined. 
D_ecision T.ree learner) system, which is able to learn from abundant data within practical time and memory constrai-nts. It accomplishes this by noting, with Catlett [5] and oth-ers [12, 19], that it may be sufficient to use a small sample of the available examples when choosing the split attribute at any given node. Thus, only the first examples to arrive on the data stream need to be used to choose the split at-tribute at the root; subsequent ones are passed through the induced portion of the tree until they reach a leaf, are used to choose a split attribute there, and so on recursively. To determine the number of examples needed for each decision, 
VFDT uses a statistical result known as Hoeffdin9 bounds or additive Chernoff bounds [13]. After n independent ob-servations of a real-valued random variable r with range R, the Hoeffding bound ensures that, with confidence 1-6, the true mean of r is at least V-e, where V is the observed mean of the samples and 
This is true irrespective of the probability distribution that generated the observations. Let G(XI) be the heuristic mea-sure used to choose test attributes (we use information gain). the best heuristic measure and Xb be the attribute with the second best. Let AG = G(X~) -G(Xb) be a new random variable, the difference between the observed heuristic val-ues. Applying the Hoeffding bound to AG, we see that if 6), we can confidently say that the difference between G(X~) tribute.l.2 Table 1 contains pseudo-code for VFDT's core al-gorithm. The counts nijlc are the sufficient statistics needed to compute most heuristic measures; if other quantities are required, they can be similarly maintained. When the suffi-cient statistics fill the available memory, VFDT reduces its memory requirements by temporarily deactivating learning in the least promising nodes; these nodes can be reactivated later if they begin to look more promising than currently active nodes. VFDT employs a tie mechanism which pre-cludes it from spending inordinate time deciding between as an average over all examples seen at the leaf, which is the case for most commonly-used heuristics. For example, if information gain is used, the quantity being averaged is the reduction in the uncertainty regarding the class membership of the example. tributes have sufficiently smaller gains that their probability of being the true best choice is negligible. We plan to lift this assumption in future work. If the attributes at a given node are (pessimistically) assumed independent, it simply involves a Bonferroni correction to 6 [18]. attributes whose practical difference is negligible. That is, 
VFDT declares a tie and selects Xa as the split attribute any time AG &lt; e &lt; r (where I" is a user-supplied tie thresh-old). Pre-pruning is carried out by considering at each node a "null" attribute X X  that consists of not splitting the node. 
Thus a split will only be made if, with confidence 1 -6, the best split found is better according to G than not splitting. 
Notice that the tests for splits and ties are only executed once for every n,,,in (a user supplied value) examples that arrive at a leaf. This is justified by the observation that 
VFDT is unlikely to make a decision after any given exam-ple, so it is wasteful to carry out these calculations for each one of them. The pseudo-code shown is only for symbolic attributes; we are currently developing its extension to nu-meric ones. The sequence of examples S may be infinite, in which case the procedure never terminates, and at any point in time a parallel procedure can use the current tree HT to make class predictions. fast as data can be read from disk. The time to incorporate an example is O(ldvc) where l is the maximum depth of 
HT, d is the number of attributes, v is the maximum num-ber of values per attribute, and c is the number of classes. 
This time is independent of the total number of examples already seen (assuming the size of the tree depends only on the "true" concept, and not on the dataset). Because of the use of Hoeffding bounds, these speed gains do not necessar-ily lead to a loss of accuracy. It can be shown that, with high confidence, the core VFDT system (without ties or de-activations due to memory constraints) will asymptotically induce a tree arbitrarily close to the tree induced by a tra-ditional batch learner. Let DToo be the tree induced by a version of VFDT using infinite data to choose each node's split attribute, HT6 be the tree learned by the core VFDT system given an infinite data stream, and p be the proba-bility that an example passed through DToo to level i will fall into a leaf at that point. Then the probability that an arbitrary example will take a different path through DT~ and HT6 is bounded by 6/p [9]. A corollary of this result states that the tree learned by the core VFDT system on a finite sequence of examples will correspond to a subtree of DT~ with the same bound of 6/p. See Domingos and 
Hulten [9] for more details on VFDT and this 6/p bound. learner) is an extension to VFDT which maintains VFDT's speed and accuracy advantages but adds the ability to detect and respond to changes in the example-generating process. 
Like other systems with this capability, CVFDT works by keeping its model consistent with a sliding window of ex-amples. However, it does not need to learn a new model from scratch every time a new example arrives; instead, it updates the sufficient statistics at its nodes by incrementing the counts corresponding to the new example, and decre-menting the counts corresponding to the oldest example in the window (which now needs to be forgotten). This will statistically have no effect if the underlying concept is sta-tionary. If the concept is changing, however, some splits that previously passed the Hoeffding test will no longer do so, because an alternative attribute now has higher gain (or the two are too close to tell). In this case CVFDT begins to grow an alternative subtree with the new best attribute at 99 Inputs: S 
Output: HT 
Procedure CVFDT(S, X, G, 6, ~', w, nm~) /* Initialize */ Let HT be a tree with a single leaf 11 (the root). 
Let ALT(I1) be an initially empty set of alternate 
Let G1 (X X ) be the G obtained by predicting the most Let Xx = X U {X~ ). Let W be the window of examples, initially empty. For each class yk /* Process the examples */ For each example (x, #) in S Return HT. Procedure CVFDTGrow(HT, n, G, (x, y), 6, nmi~, r) Sort (x, y) into a leaf I using HT. Let P be the set of nodes traversed in the sort. For each node lpi in P 
Label l with the majority class among the examples seen Let nl be the number of examples seen at I. 
If the examples seen so far at l are not all of the same its root. When this alternate subtree becomes more accurate on new data than the old one, the old subtree is replaced by the new one. 
Table 2 contains a pseudo-code outline of the CVFDT algorithm. CVFDT does some initializations, and then pro-cesses examples from the stream S indefinitely. As each example (x,y) arrives, it is added to the window 3, an old example is forgotten if needed, and (x, y) is incorporated into the current model. CVFDT periodically scans HT and all alternate trees looking for internal nodes whose sufficient statistics indicate that some new attribute would make a better test than the chosen split attribute. An alternate subtree is started at each such node. 
Table 3 contains pseudo-code for the tree-growing por-tion of the CVFDT system. It is similar to the Hoeffding 
Tree algorithm, but CVFDT monitors the validity of its old decisions by maintaining sufficient statistics at every node in HT (instead of only at the leaves like VFDT). Forget-ting an old example is slightly complicated by the fact that 
HT may have grown or changed since the example was ini-tially incorporated. Therefore, nodes are assigned a unique, monotonically increasing ID as they are created. When an example is added to W, the maximum ID of the leaves it reaches in HT and all alternate trees is recorded with it. An example's effects are forgotten by decrementing the counts in the sufficient statistics of every node the example reaches 3The window is stored in RAM if resources are available, otherwise it will be kept on disk. 100 Procedure ForgetExample(HT, n, (x~, yw), IDa) in HT whose ID is &lt; the stored ID. See the pseudo-code in Table 4 for more detail about how CVFDT forgets examples. ing for ones where the chosen split attribute would no longer be selected; that is, where G(Xa) -"G(Xb) &lt; e and e &gt; r. 
When it finds such a node, CVFDT knows that it either initially made a mistake splitting on Xa (which should hap-pen less than ~% of the time), or that something about the process generating examples has changed. In either case, 
CVFDT will need to take action to correct HT. CVFDT grows alternate subtrees to changed subtrees of HT, and only modifies HT when the alternate is more accurate than the original. To see why this is needed, let IA be a node where change was detected. A simple solution is to replace 
IA with a leaf predicting the most common class in l/,'s suf-ficient statistics. This policy assures that HT is always as current as possible with respect to the process generating examples. However, it may be too drastic, because it ini-tially forces a single leaf to do the job previously done by a whole subtree. Even if the subtree is outdated, it may still be better than the best single leaf. This is particularly true when l/, is at or near the root of HT, as it will result in drastic short-term reductions in HT's predictive accuracy -clearly not acceptable when a parallel process is using HT to make critical decisions. being considered as replacements for the subtree rooted at the node. Table 5 contains pseudo-code for the CheckSplit-
Validity procedure. CheckSplitValidity starts an alternate subtree whenever it finds a new winning attribute at a node; that is, when there is a new best attribute and A~ &gt; e or if e &lt; r and A~ &gt; r/2. This is very similar to the procedure used to choose initial splits, except the tie criteria is tighter to avoid excessive alternate tree creation. CVFDT supports a parameter which limits the total number of alternate trees being grown at any one time. Alternate trees are grown the same way HT is, via recursive calls to the CVFDT pro-cedures. Periodically, each node with a non-empty set of alternate subtrees, Ire,t, enters a testing mode to determine if it should be replaced by one of its alternate subtrees. Once in this mode, lt~st collects the next m training examples that arrive at it and, instead of using them to grow its children or alternate trees, uses them to compare the accuracy of the subtree it roots with the accuracies of all of its alternate subtrees. If the most accurate alternate subtree is more ac-curate than the ltest, ltest is replaced by the alternate. Dur-ing the test phase, CVFDT also prunes alternate subtrees that are not making progress (i.e., whose accuracy is not in-Procedure CheckSplitValidity(HT, n, ~) For each node l in HT that is not a leaf 
CVFDT remembers the smallest accuracy difference ever achieved between the two, /k,n~,,(ltest, lilt). CVFDT prunes any alternate whose current test phase accuracy difference is at least A,ni~(lt~st, l~lt) + 1%. 4 
One window size w will not he appropriate for every con-cept and every type of drift; it may be beneficial to dynam-ically change w during a run. For example, it may make sense to shrink w when many of the nodes in HT become questionable at once, or in response to a rapid change in data rate, as these events could indicate a sudden concept change. Similarly, some applications may benefit from an in-crease in w when there are few questionable nodes because this may indicate that the concept is stable -a good time to learn a more detailed model. CVFDT is able to dynamically adjust the size of its window in response to user-supplied events. Events are specified in the form of hook functions which monitor S and HT and can call the SetWindowSize function when appropriate. CVFDT changes the window size by updating w and immediately forgetting any exam-ples that no longer fit in W. 
We now discuss a few of the properties of the CVFDT sys-tem and briefly compare it with VFDT-Window, a learner that reapplies VFDT to W for every new example. CVFDT requires memory proportional to O(ndvc) where n is the number of nodes in CVFDT's main tree and all alternate trees, d is the number of attributes, v is the maximum num-ber of values per attribute, and c is the number of classes. 
The window of examples can be in RAM or can be stored on 4When RAM is short, CVFDT is more aggressive about pruning unpromising alternate subtrees. 101 disk at the cost of a few disk accesses per example. There-fore, CVFDT's memory requirements are dominated by the sufficient statistics and are independent of the total num-ber of examples seen. At any point during a run, CVFDT will have available a model which reflects the current con-cept generating IV. It is able to keep this model up-to-date in time proportional to O(ledvc) per example, where lc is the length of the longest path an example will have to take through HT times the number of alternate trees. VFDT-
Window requires O(lvdvcw) time to keep its model up-to-date for every new example, where Iv is the maximum depth of HT. VFDT is a factor of wlv/lc worse than CVFDT; em-pirically, we observed lc to be smaller than l~ in all of our experiments. Despite this large time difference, CVFDT's drift mechanisms allow it to produce a model of similar ac-curacy. The structure of the models induced by the two may, however, be significantly different, for the following reason. 
VFDT-Window uses the information from each training ex-ample at one place in the tree it induces: the leaf where the example falls when it arrives. This means that VFDT-
Window uses the first examples from IV to make a decision at its root, the next to make a decision at the first level of the tree, and so on. After an initial building phase, CVFDT will have a fully induced tree available. Every new example is passed through this induced tree, and the information it contains is used to update statistics at every node it passes through. This difference can be an advantage for CVFDT, as it allows the induction of larger trees with better proba-bility estimates at the leaves. It can also be a disadvantage and VFDT-Window may be more accurate when there is a large concept shift part-way through IV. This is because 
VFDT-Window's leaf probabilities will be set by examples near the end of IV while CVFDT's will reflect all of W. 
Also notice that, even when the structure of the induced tree does not change, CVFDT and VFDT-Window can out-perform VFDT simply because their leaf probabilities (and therefore class predictions) are updated faster, without the "dead weight" of all the examples that fell into leaves before the current window. 
We conducted a series of experiments comparing CVFDT to VFDT and VFDT-Window. Our goals were to evaluate 
CVFDT's ability to scale up, to evaluate CVFDT's ability to deal with varying levels of drift, and to identify and char-acterize the situations where CVFDT outperforms the other systems. 
The experiments with synthetic data used a changing con-cept based on a rotating hyperplane. A hyperplane in d-dimensional space is the set of points x that satisfy where x, is the ith coordinate of x. Examples for which ~'~=1 wix~ ~ wo are labeled positive, and examples for which ~i=1 wixi &lt; wo are labeled negative. Hyperplanes are use-ful for simulating time-changing concepts because we can change the orientation and position of the hyperplane in a smooth manner by changing the relative size of the weights. 
In particular, sorting the weights by their magnitudes pro-vides a good indication of which dimensions contain the most information; in the limit, when all but one of the weights are zero, the dimension associated with the non-zero weight is the only one that contains any information about the concept. This allows us to control the relative informa-tion content of the attributes, and thus change the optimal order of tests in a decision tree representing the hyperplane, by simply changing the relative sizes of the weights. We sought a concept that maintained the advantages of a hy-perplane, but where the weights could be randomly modi-fied without potentially causing the decision frontier to move outside the range of the data. To meet these goals we used a series of alternating class bands separated by parallel hyper-planes. We start with a reference hyperplane whose weights are initialized to .2 except for wo which is .25d. To label an example, we substitute its coordinates into the left hand side of Equation 2 to obtain a sum s. If Isl _&lt; .1 * w0 the example is labeled positive, otherwise if Isl _&lt; .2 * w0 the example is labeled negative, and so on. Examples were gen-erated uniformly in a d-dimensional unit hypercube (with the value of each xi ranging from [0, 1]). They were then labeled using the concept, and their continuous attributes were u~iformly discretized into five bins. Noise was added by randomly switching the class labels of p~ of the exam-ples. Unless otherwise stated, each experiment used the fol-lowing settings: five million training examples; /f = 0.0001; f = 20, 000; nm~ = 300; r = 0.05; w = 100, 000; CVFDT's window on disk; no memory limits; no pre-pruning; a test set of 50,000 examples; and p = 5%. CVFDT put leaves into alternate tree test mode after 9,000 examples and used test samples of 1,000 examples. All runs were done on a 1GHz Pentium III machine with 512 MB of RAM, running Linux. The first series of experiments compares the ability of 
CVFDT and VFDT to deal with large concept-drifting data-sets. Concept drift was added to the datasets in the follow-ing manner. Every 50,000 examples wl was modified by adding 0.01d~r to it, and the test set was relabeled with the updated concept (with p% noise as before), tr was initially 1 and was multiplied by -1 at 5% of the drift points and also just before wl fell below 0 or rose above .25d. Figure 1 compares the accuracy of the algorithms as a function of d, the dimensionality of the space. The reported values are obtained by testing the accuracy of the learned models ev-ery 10,000 examples throughout the run and averaging these results. Drift level, reported on the minor axis, is the av-erage percentage of the test set that changes label at each point the concept changes. CVFDT is substantially more accurate than VFDT, by approximately 10~ on average, and CVFDT's performance improves slightly with increas-ing d. Figure 2 compares the average size of the models induced during the run shown in Figure 1 (the reported val-ues are generated by averaging after every 10,000 examples, as before). CVFDT's trees are substantially smaller than 
VFDT's, and the advantage is consistent across all the val-ues of d we tried. This simultaneous accuracy and size ad-vantage derives from the fact that CVFDT's tree is built on the 100,000 most relevant examples, while VFDT's is built on millions of outdated examples. We next carried out a more detailed evaluation of 
CVFDT's concept drift mechanism. Figure 3 shows a de-tailed view of one of the runs from Figures 1 and 2, the one for d = 50. The minor axis shows the portion of the test 103 25 i:i~:i ,~ 20 :!i!::: ~5 i iill ~o i:iiii 
Figure 4: Error rates as a function of the amount of concept drift. 
Figure 6: Error rates over time of CVFDT, VFDT, and VFDT-Window. to VFDT, at a cost of increasing the running time by a fac-tor of 17,000. CVFDT provides 75% of VFDT-Window's accuracy gain, and introduces a time penalty of less than 0.1% of VFDT-Window's. 
CVFDT's alternate trees and additional sufficient statis-tics do not use too much RAM. For example, none of 
CVFDT's d = 50 runs ever grew to more than 70MB. We never observed CVFDT to use more RAM than VFDT; in fact it often used as little as half the RAM of VFDT. The systems' RAM requirements are dominated by the sufficient statistics which are kept at the leaves in VFDT, and at every node in CVFDT. We observed that VFDT often had twice as many leaves as there were nodes in CVFDT's tree and all alternate trees combined. This is what we expected: VFDT considers many more examples and is forced to grow larger trees to make up for the fact that its early decisions be-come incorrect due to concept drift. CVFDT's alternate tree pruning mechanism seems to be effective at trading memory for smooth transitions between concepts. Further, there is room for more aggressive pruning if CVFDT exhausts avail-able RAM. Exploring this tradeoff is an area for future work. 
We are currently applying CVFDT to mining the stream of Web page requests emanating from the whole Univer-sity of Washington main campus. The nature of the data is described in detail in Wolman et al. [29]. In our experi-ments so far we have used a one-week anonymized trace of all the external web accesses made from the university campus. 
There were 23,000 active clients during this one-week trace period, and the entire university population is estimated at 50,000 people (students, faculty and staff). The trace con-tains 82.8 million requests, which arrive at a peak rate of 17,400 per minute. The size of the compressed trace file is about 20 GB. 5 Each request is tagged with an anonymized organization ID that associates the request with one of the 170 organizations (colleges, departments, etc.) within the university. One purpose this data can be used for is to im-prove Web caching. The key to this is predicting as accu-rately as possible which hosts and pages will be requested in the near future, given recent requests. We applied decision-tree learning to this problem in the following manner. We split the campus-wide request log into a series of equal time slices To,T1,... , Tt,... ; in the experiments we report, each time slice is an hour. For each organization O1, O2,... , O~,  X  .. , Ol~0 and each of the 244k hosts appearing in the logs 
H1,... , Hi,... , H244k, we maintained a count of how many times the organization accessed the host in the time slice, 
C~#. We discretized these counts into four buckets, repre-senting "no requests," "1 -12 requests," "13 -25 requests" and "26 or more requests." Then for each time slice and host accessed in that time slice (Tt, Hi) we generated an ex-ample with attributes CI,#,... , Cijt,... C170,jt and class 1 if Hj is requested in time slice Tt+i and 0 if it is not. This can be carried out in real time using modest resources by keeping statistics on the last and current time slices Ct-z and Ct in memory, only keeping counts for hosts that actu-ally appear in a time slice (we never needed more than 30k counts), and outputting the examples for Ct-z as soon as 
Ct is complete. Using this procedure we obtained a dataset containing 1.89 million examples, 60.9% of which were In-'This log is from May 1999. Traffic in May 2000 was more than double this size. 
Our exploration was designed to determine if CVFDT's 
Schlimmer and Granger's [23] STAGGER system was one 
Ganti, Gehrke, and Ramakrishnan's [11] DEMON frame-
In earlier work [12] Gehrke, Ganti, and Ramakrishnan 
There has been a great deal of work on incrementally are added to the database. Sarda and Srinivas [22] have also particularly relevant, as it addresses association rule main-tenance specifically in the high-speed data stream domain where blocks of transactions are added and deleted from the database on a regular basis. 
Aspects of the concept drift problem are also addressed in the areas of activity monitoring [10], active data mining [1] and deviation detection [6]. The main goal here is to explicitly detect changes, rather than simply maintain an up-to-date concept, but techniques for the latter can obvi-ously help in the former. 
Several pieces of research on concept drift and context-sensitive learning are collected in a special issue of the jour-nal Machine Learning [28]. Other relevant research ap-peared in the ICML-96 Workshop on Learning in Context-
Sensitive Domains [15], the AAAI-98 Workshop on AI Ap-proaches to Time-Series Problems [8], and the NIPS-2000 Workshop on Real-Time Modeling for Complex Learning 
Tasks [26]. Turney [25] maintains an online bibliography on context-sensitive learning. 
We plan to apply CVFDT to more real-world problems; its ability to adjust to concept changes should allow it to perform very well on a broad range of tasks. CVFDT may be a useful tool for identifying anomalous situations. Cur-rently CVFDT discards subtrees that axe out-of-date, but some concepts change periodically and these subtrees may become useful again -identifying these situations and taking advantage of them is another area for further study. Other areas for study include: comparisons with related systems; continuous attributes; weighting examples; partially forget-ting examples by allowing their weights to decay; simulating weights by subsampling; and controlling the weight decay function according to external information about drift. 
This paper introduced CVFDT, a decision-tree induction system capable of learning accurate models from the most demanding high-speed, concept-drifting data streams. 
CVFDT is able to maintain a decision-tree up-to-date with a window of examples by using a small, constant amount of time for each new example that arrives. The resulting accuracy is similar to what would be obtained by reapplying a conventional learner to the entire window every time a new example arrives. Empirical studies show that CVFDT is effectively able to keep its model up-to-date with a massive data stream even in the face of large and frequent concept shifts. A preliminary application of CVFDT to a real world domain shows promising results. This research was partly supported by a gift from the Ford 
Motor Company, and by NSF CAREER and IBM Faculty awards to the third author. [1] R. Agrawal and G. Psaila. Active data mining. In Proceedings of the First International Conference on Knowledge Discovery and Data Mining, pages 3-8, 
Montreal, Canada, 1995. AAAI Press. [2] N. F. Ayan, A. U. Tansel, and M. E. Arkun. An [3] P. L. Bartlett, S. Ben-David, and S. R. Kull~rni. [4] L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. [5] J. Catlett. Megainduction: Machine Learning on Very [6] S. Chakrabaxti, S. Sarawagi, and B. Dora. Mining [7] D. W.-L. Cheung, J. Han, V. Ng, and C. Y. Wong. [8] A. Danyluk, T. Fawcett, and F. Provost, editors. [9] P. Domingos and G. Hulten. Mining high-speed data [10] T. Fawcett and F. Provost. Activity monitoring: [11] V. Ganti, J. Gehrke, and R. Ramakrishnan. DEMON: [12] J. Gehrke, V. Ganti, R. Ramakrishnan, and W.-L. [13] W. Hoeffding. Probability inequalities for sums of [14] M. G. Kelly, D. J. Hand, and N. M. Adams. The [15] M. Kubat and G. Widmer, editors. Proceedings of the [16] P. M. Long. The complexity of learning according to [17] M. Mehta, A. Agrawal, and J. Rissanen. SLIQ: A fast [18] R. G. Miller, Jr. Simultaneous Statistical Inference. [19] R. Musick, J. Catlett, and S. Russell. Decision [20] J. R. Quinlan. C~.5: Programs for Machine Learning. [21] M. Salganicoff. Density-adaptive learning and [22] N. L. Sarda and N. V. Srinivas. An adaptive algorithm [23] J. C. Schlimmer and R. H. Granger, Jr. Beyond [24] J. C. Sharer, R. Agrawal, and M. Mehta. SPRINT: A [25] P. Turney. Context-sensitive learning bibliography. [26] S. Vijayakumar and S. Schaal, editors. Proceedings of [27] G. Widmer and M. Kubat. Learning in the presence of [28] G. Widmer and M. Kubat. Special issue on context [29] A. Wolman, G. Voelker, N. Sharma, N. Cardweli, 
