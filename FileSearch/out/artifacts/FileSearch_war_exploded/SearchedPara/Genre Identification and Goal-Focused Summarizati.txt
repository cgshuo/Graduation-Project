 In this paper, we present a nove l technique of first performing document genre identification, then utilizing the genre for producing tailored summaries ba sed on a user X  X  information seeking needs  X  genre oriented goal-focused summarization  X  such as a plot or opinion summary of a movie review. We create a test corpus to determine genre classification accuracy for 16 genres, and examine performance on various amounts of training data for machine learning algorithms -Random Forests, SVM light and Na X ve Bayes. Resu lts show that Random Forests outperforms SVM light and Na X ve Baye s. The genre tag is used to inform a downstream summarization engine. We define types of summaries for 7 genres, create a ground truth corpus and analyze the results of genre oriented goal-focused summarization, showing that this type of us er based summarization requires different algorithms than the leading sentence baseline which is known to perform well in th e case of news articles. H3.1 [Information Storage and Retrieval ]: Content Analysis and Indexing H.3.3 [Information Search and Retrieval ]: Information filtering, Selection Process Algorithms, Design, Experi mentation, Performance Genre Identification, Text Classi fication, Text Categorization, Machine Learning, Summarization, Metadata Extraction, Data Mining, Task-based Informa tion Retrieval, Evaluation With the continuing rapid growth of the Web, it is becoming essential to find ways of categor izing and filtering information to be able to quickly locate and access particular items of interest. An information-access system has a mechanism to connect users and their information seeking needs with a store of information. For the internet this mechanism has focused on search algorithms and short summaries intended to assist the user in choosing relevant web pages to view. Some search engines include clustering processes (www.clusty.com), which are usually organized around topically based keywords or concepts. Topic alone may be insufficient for cat egorizing documents/web pages -for a given product, one user may be interested in a product press release, another may be interested in reviews and a third might be interested in stores that are offering the product for the cheapest price. A user may decide what pages to view based on the genre. Thus, genre may be a preferable way to organize and label documents. Genre information can be determined from the web page and used as categorical me tadata about the document as a means of indexing and retrie ving documents. Roussinov and colleagues, in preliminary studies of people searching the Web, discovered that the genre of the document was one of the clues used in assessing relevance, valu e, quality and usefulness [6]. There are many different definiti ons of genre; most include two principal characterizations -the intended communicative purpose and form . Some contain a third -the content of the document [7]. We utilize this triple since content will inform downstream processes, such as summarization. For example, a movie review is often organized differently to that of a product review. A reader of both reviews may want to know about the author X  X  opinions. However, a reader of the product review may also want to learn about the functionality of the product as well as the price whereas the reader of the movie review may want to know about the some information about the pl ot as well as the running time of the film. We therefore introduce a new form of summarization  X  genre oriented summarization  X  summary creation based on the characteristics of a genre. For the movie review genre, one user might want a summary of the pl ot, whereas another may want a summary of the reviewer X  X  opinion. This motivates the concept of genre oriented goal-focused summarization.
 In this paper, we first examine the performance of machine learning techniques to classify certain types of web pages by genre based on a corpus collected from the web. The level of accuracy by which a classification system can identify genre will affect the results of the downstream summarization system. For example, if a movie review is misclassified as a biography, information such as rating and running time will not be extracted. After examining classification performance, we discuss the performance of goal-focused summarization algorithms on a gold standard sentence extract summarization corpus (created by 3 human summarizers). We collected a genre corpus from the web with the particular goal of examining the effects of genre classification output on summarization. We selected 9 categories (Table 1) for genre-identification, 7 of which are targeted towards summarization experiments (Table 2). Data was collected resulting in approximately a total of 1000 documents per category (empty frame files were deleted). A maximum of 10 data items were collected from any web site. We added 1000 randomly selected documents from 7 additional categories that were collected by CMU in previous studies [2] to form a total of 16 genres. Table 1: Genre Document Collection  X  16 genres The goal of genre oriented summarization is to be able to tailor the summary to the users' needs. For example, one might want to have a plot or opinion summary for a movie review summary in contrast to the most salient poi nts as produced by a newswire summary. Accordingly, for the 7 genres in Table 2, three senior English students collectively determined the types of summaries a user might want to view -the genre oriented goal-focused summaries. We selected the sentence as the basic summarization unit, decided a sentence summary length and guidelines for selecting particular sentences for each summary type. Interviews, which tend to be long, were allo wed more summary sentences. Table 2: Corpus Description including # of documents collected, # of sentences in summary and # of summary types and types for that genre. O= Overview, Pl=Plot, Op=Opinion, Pe=Personal, Pr=Professi onal, T=Thematic. For example, for Movie Reviews, there are three types of summaries: Plot: like movie trailer. Opinion: reviewers X  or others X  opinions. Overview: 1 pl ot sentence, 1 opinion sentence, 1 cast sentence, 1 movie genre sentence, 1 other supporting sentence. Genre classification has been studied since the early 1990s, when Karlgren and Cutting [3] used disc riminant analysis to classify four categories using features derived from part of speech analysis, structural cue, lexical cues, character-level cues and derivative cues. Recent research has used these types of cues for classification of press genres, positive or negative reviews and email speech acts. Dewdney and colleagues [2] used these types of cues (89 features) to cate gorize seven genres using three classifiers Na X ve Bayes, C4.5, and SVM-light. Our research differs in that we combine genre identification with summarization and use a greater number of categories than prior researchers. Some categories have a high degree of topical overlap to allow investigate the effects of confusable conditions, e.g., editorials and articles with a topic of Bush as well as product press releases, product review s and product store pages. Furthermore, we examine the effects of the number of training documents on classification resu lts, as well as compare Random Forests (RF) to Support Vector Machines (SVM). There has been, to our knowledge, no publishe d research comparing RF to SVM for genre classification or text categorization. Expanding on Dewdney X  X  research [2], our feature extractor contains 119 features: a baselin e of 66 items consisting of a combination of layout, character and structural features (e.g., number of white space lines, number of quotes, counts of words appearing in headings) plus de rivative cues (e.g., readability measures), 26 grammatical features (includes items such as the number of verbs), and 27 genre oriented topic content words lists., which were derived from an inde pendent sample of similarly collected genres. Three different classifiers were used for our experiments: WEKA X  X  implementation of Na X ve Bayes with the default settings [5], Joachims X  implementation of Support Vector Machines SVM-light with a radial basic functi on and the default settings [8] and Random Forests (RF) [1]. Random Forests grows many classification trees; we use 100 trees and the number of variables selected at random at each node is set to the square root of the number of features (suggested by Leo Breiman). The predicted value for classification is the class with the majority of the forest votes. Since SVM-light builds binary models, Random Forests has the characteristic that the training time is significantly less than for SVM-light especially for large numbers of genres. Evaluation results for the three classifiers using 10-fold cross-validation are shown in Table 3. Results are reported for precision, recall and F 1 using the micro-average, in which each relevant document is a point in the average. RF performs better than SVM, a result that occurred c onsistently across the data. All algorithms perform better for 16 genres, perhaps due to the addition of more training data. RF performs extremely well just using our baseline 66 general features, with results that match SVM for the full 119 features. The content words did not provide a large increase in scores; we plan to investigate this result. Due to the much lower performance of Na X ve Bayes compared to RF and SVM, the rest of the paper will not report Na X ve Bayes results. Table 3: Classification results Micro-Average F 1 (10 fold cross validation) on 9 and 16 genres for Random Forests (RF), Support Vector Machine (SVM) and Na X ve Bayes (NB). Features \ Classifier RF SVM N B RF SVM N B Baseline (basic) (66) 0. 81 0.67 0.48 0.86 0.76 0.63 Baseline+grammatical (92) 0.85 0.78 0.58 0.88 0.83 0.69 Baseline+gramm+content (119) 0.87 0.81 0.63 0.90 0.85 0.71 Table 4 shows the individual scores per genre for all 16 genres. From the confusion matrices ( not presented), Editorials are confused with the Articles on the same topics and Product Reviews are often confused with Product Press Releases. RF does better than SVM at distinguishing these confusable categories. Table 4: Overall within-genre statistics for Random Forests on 16 genres, 119 features . Genre P R F 1 P R F 1 Finally, we examine the overall effects on training/test corpus on results for both our baseline 66 features and our full set of 119 features (Figure 1). Note that for Random Forests, after 250 documents, the increase in collection effort for the extra documents might not be wo rth the performance gain. Figure 1: Performance Effects based on Number of Documents for Random Forests, 16 genres, 66 features (baseline) and 119 features (10 fold cross validation). In this section, we have shown that we can obtain very good genre identification performance of approximately 0.9 F 1 (Figure 1) with RF. An increased number of genres appear to assist scores. 100-250 documents with some carefully chosen lexical and topical features seem to result in performance scores close to 0.8 F , possibly adequate for a genre oriented summarization system. Summarization systems have focu sed on two types of summaries: the generic or overview summary, which gives an overall sense of the document's content, or a query-based summary, which presents the content that is mo st closely related to the initial search query. Most summarization research has focused on the news event genre and the scientific article genres [4, 9] for which this type of methodology works well. Recent work has focused on creating opinion summaries for web reviews and news editorials. Consider, however, the genre of movie reviews. A user may want an overview of a review (generic), a specific answer to a question (query-based ), plot details, or reviewers X  opinions. Accordingly, the movi e review genre, as do others, require a new class of summary , that of the goal-focused summary. Summaries that reflect a user X  X  information seeking needs requires genre oriented goal-focused summarization. Our summarizer creates summaries based on a particular genre and goal. Sentences receive a score using document features such as position, matches to created wo rd lists for a genre and content derived features (e.g., number of people). Sentences are ordered in the output summary according to the order they appear in the document. Each summary consists of specific features based on the genre and focus, e.g., newswi re summaries often include the first sentence. These features are given weights, which were tuned by experimentation, e.g., the first sentence feature is given a lower weight for the movie review genre than for newswire where the first sentence may be a catchy lead-in. Due to paper page constraints, the algorithms show n in Figure 2 are only for movie summaries. People, organizations and locations are extracted using Alias-I X  X  Lingpipe (www.a lias-i.com/lingpipe) and then counted. The opinion word list is Wilson X  X  list of subjectivity and sentiment clues [10]. All other word lists were created based on the specific genre. A sentence match score with a list is based on cosine similarity. All sentence features scores are normalized within the document before combination into the final score. Figure 2: Movie Review Summary Algorithms Table 5 shows the results of all algorithms. The highest ranking sentences are selected for each algorithm up to the number of summary sentences for that genre, N G (Table 2). The normalized score is computed by counting the system summary sentences that match any human summary sentence (score of 1 for a match) and dividing by N G . For news articles, which tend to be summaries, lead (document initial) sentences often create good overview summaries. Accordingly, we use lead sentences as our baseline for all genres. From Table 5, note that many algorithms still outperform the lead even if they are not the best performing algorithm, motivating the need for summaries beyond lead -genre oriented, goal-focused summaries . Additionally, such summaries provide supplementary information, which is lacking without the genre tag. For movie-reviews, the genre information allows the extraction of the running time and movie rating and the goal-focus allows for summaries of a different composition (Figure 3). Thus, if the genre classifier can pass an accurate tag (for movie reviews, F 1 = 0.86, Table 4), the system can present a tailored summary. Figure 3: Movie Review  X  Movie Genre Overview Summary compared to Newswire Genre: Lead Sentence Summary ([Doc. Sent. Number] followed by Sentence). Extra items extracted by use of the movie genre tag are in bold. We examined classifier perform ance, comparing Support Vector Machines, known to perform well for categorization to Random Forests as well as Na X ve Bayes, a commonly used machine learning algorithm. Random Fore sts performed better than SVM, which outperformed Na X ve Bayes. The training time for RF was much faster than SVM. Additionally, we showed that identifying the genre could assi st a summarization system to produce more informative summaries by including information in the summary based on the genre tag. For example, in the movie review genre, the rating and running time could be extracted and included in the summary. Thus, genre oriented summaries have more utility over straight summarization algorithms. We also motivated the need for various summary types according to the genre and a user X  X  information seeking goals and presented a case showi ng genre oriented goal-focused summaries require varying summarization algorithms. [1] Breiman, L, Consistency for a Simple Model of Random Forests, [2] Dewdney, N., VanEss-Dykema, C., and McMillan, R. The form is [3] Karlgren, J. &amp; Cutting D., Recognizing Text Genres with Simple [4] Mani, I., House, D., Klain, G., Hirschman, L, Obrst, L., Firmin, T., [5] Na X ve Bayes WEKA implementation: www.cs.waikato.ac.nz/ml/weka [6] Roussinov, D., Crowston, K., Nilan, M., Kwasnik, B., Liu, X., &amp; Cai., [7] Shepherd, M and Watters, C., The Functionality Attribute of [8] SVM light webpages: http://svmlight.joachims.org [9] Teufel, S., and Moens, M., Sentence extraction as a classification [10] Wilson, T, Wiebe, J., Hoffman, P., Recognizing Contextual Polarity 
