 Search engine query log is an important information source that contains millions of users X  interests and information needs. In this paper, we tackle the problem of discovering la-tent geographic search topics via mining search engine query logs. A novel framework G-WSTD that contains search ses-sion derivation, geographic information extraction and geo-graphic search topic discovery is developed to support a va-riety of downstream web applications. The core components of the framework are two topic models, which discover ge-ographic search topics from two different perspectives. The first one is the Discrete Search Topic Model (DSTM), which aims to capture the semantic commonalities across discrete geographic locations. The second one is the Regional Search Topic Model (RSTM), which focuses on a specific region on the map and discovers web search topics that demonstrate geographic locality. We evaluate our framework against sev-eral strong baselines on a real-life query log. The framework demonstrates improved data interpretability, better predic-tion performance and higher topic distinctiveness in the ex-perimentation. The effectiveness of the framework is also verified by applications such as user profiling and URL an-notation.
 H.3.3 [ Information Search and Retrieval ]: Text Mining Algorithms, Experimentation Geographic, Search Engine, Query Log
Search queries are the embodiment of the users X  inter-ests and information needs. Thus, search engine query log, which accumulates millions of users X  search queries, becomes a valuable information source that serves as the basis of many functionalities [1, 5, 12, 15] of search engines. Re-cently, topic modeling has been successfully developed to power geographic-related applications in web media such as Flickr and Twitter [3, 20, 24]. Since query log has advan-tages over other web media in capturing the users X  interests and preferences, it is valuable to investigate how to conduct geographic topic modeling on query logs and explore the potential applications of the discovered topics.

Query log posits several unique challenges that render tra-ditional topic models inapplicable or they can only work suboptimally. First, geographic information is not always available in a query log. Different from web services with geo-tagging functionality, search queries are typically not associated with GPS locations. Therefore, geographic infor-mation needs to be discovered somehow from the raw log entries. This challenge also illustrates the f undamental dif-ference between our work and those that study Location-based Services (LBS) [19], which utilize the users X  real-time locations to carry out geographic-aware services. We aim to capture the search topics that are related to some locations in which the users are interested, and these locations are not necessarily the same as the users X  real-time locations. Second, each search query is very short and on average con-tains only 2.35 terms [11]. Therefore, simply considering each query as a document and applying traditional topic models on them results in poor topic estimation due to the shortness of each query [13]. Third, different from the typi-cal scenario of document modeling which faces homogeneous items, query log is composed of two heterogeneous items, the query terms and the URLs, which have different natures and are not independent of each other. Thus, topic modeling on query log needs to handle the heterogeneous items and cap-ture the complicated co-occurrence between them.

In this paper, we propose a new framework named Ge-ographic Web Search Topic Discovery (G-WSTD), which addresses the aforementioned challenges and conducts ge-ographic web search topic discovery from two perspectives: the discrete perspective and the regional perspective .The discrete perspective assumes that each search topic is asso-ciated with some discrete locations. The geographic relation between the locations, such as the distances between them, are not considered in the discrete perspective. In contrast, the regional perspective assumes that search topics have geo-graphic locality, and each search topic is adherent to a region on the map. We now illustrate the motivations of the two perspectives via the search queries shown in Table 1. Example 1. (Motivation) Consider the search queries in Table 1, the search topic of queries q 1 , q 2 and q 3 are all about Disneyland, just like the reality that Disneyland resorts are located in different countries, the locations related to this topic, such as Orlando, Tokyo and Paris, are remote from each other. In contrast, q 4 , q 5 and q 6 areaboutthetopicof Scotland culture, the locations related to this topic, Glasgow and Edinburgh, are in geographic proximity.

If we view the queries from the discrete perspective, the topic about Disneyland is related to Orlando, Tokyo and Paris while the topic about Scotland culture is associated with Glasgow and Edinburgh. The latent semantics that the topic about Scotland culture characterizes the features of a region such as the Central Belt 1 is lost. Even worse, since we do not impose proximity on the geographic information of a topic, the probability of q 4 , q 5 and q 6 that are assigned as the same topic can be very low, and the topic about Scotland culture may not be discovered at all.

If we view the queries from the regional perspective, the topic about Scotland culture covers a region such as the Cen-tral Belt. However, the topic about Disneyland covers a wide region, which is across America, Europe and Asia. Although this geographic information may be helpful in some case, the semantics that the topic about Disneyland characterizes cities such as Orlando, Tokyo and Paris is lost. Even worse, since the regional perspective assumes that each topic has the geographic locality, a topic that is associated with widely dis-persed locations can have very low probability, and the topic about Disneyland may not be discovered at all.

Example 1 shows that the search topics generated from the two geographic perspectives are complimentary and thus a framework which supports discovering search topics from the two perspectives provides comprehensive coverage of the latent semantics in query log. Thus, we explore two prob-abilistic topic models to discover geographic search topics from the two perspectives. The first model is the Discrete Search Topic Model (DSTM), which differentiates the loca-tions from the general query terms and assumes that the locations follow a different multinomial distribution given the search topic. With the DSTM model, we aim to find the commonality across different locations. We further propose the Regional Search Topic Model (RSTM), which aims to find search topics that are adherent to a specific region on the map. The region X  X  spectrums are modeled by two Gaus-sian distributions over latitude and longitude. As long as geographic search topics are successfully generated from the two perspectives, they can be utilized together and spawn a series of new web applications such as checking the com-monalities of different locations and showing a region X  X  char-acteristics. Additionally, we can consider geographic search http://en.wikipedia.org/wiki/Central Belt topic discovery as a geographic-aware process of dimension reduction, and profile search engine users by the discovered search topics. Finally, since G-WSTD captures the seman-tic relations between query terms and URLs, the framework also supports URL annotation, which is effective to improve the quality of web search results [9].

The contributions of this paper are primarily threefold:
The rest of the paper is organized as follows: we review the related work in Section 2. In Section 3, we outline the archi-tecture of the framework and its components. In Section 4, we discuss the generative processes and inference strategies for DSTM and RSTM, respectively. In Section 5, we present the experimental results. Finally, the paper is concluded in Section 6.
Probabilistic topic modeling is gaining momentum in text mining. Blei et al. [2] proposed the pioneering Latent Dirichlet Allocation (LDA) to analyze electronic archives. Griffiths et al. [6] reported that LDA is effective to find scientific topics. Following LDA, many topic models that specialize in different tasks are proposed. Wang et al. [21] proposed a topic model to explicitly capture the relation-ships between locations and words in news and blogs. With the development of GPS technology, several studies have been done on geo-tagged social media. Yin et al. [24] studied the problem of discovering geographic topics from GPS-associated tweets. Sizov et al. [20] proposed Bayesian models for characterization of social media by combining text features with spatial knowledge. Eisenstein et al. [3] proposed a multi-level generative model that reasons about lexical variation across different geographic regions. Hao et al. [7] proposed the location-topic model to mine location-representative knowledge from a large collection of travel-ogues.

Our work is also related to geographic information anal-ysis in search query log. Gan et al. [4] studied geographic search queries that employ geographic terms in an attempt to restrict results to a particular region or location. Wang et al. [22] defined a search query X  X  dominant location and pro-posed a solution to correctly detect it. Yi et al. [23] proposed and developed a geographic intent analysis system that uses minimal supervision to lear n a model from a large amount of web-search log for the intent discovery.
Despite the wide acceptance of using the probabilistic topic modeling approach on analyzing articles and web doc-uments, there seems very little research work that analyzes query log from the geographic perspective. Therefore, our work is different from previous ones in two aspects: First, we fill the aforementioned research gap by proposing a new framework that seamlessly integrates search session deriva-tion, geographic location extraction and probabilistic topic modeling for discovering web search topics. It is the first time that a methodology which is specialized for topic mod-eling on query log is proposed. Second, different from pre-vious works that model the geographic information in a sin-gle mathematical distribution, we explore two distinct as-sumptions of geographic web search: discrete and regional . We then develop two topic models that capture the latent geographic semantics of query log by different mathemati-cal distributions. Though extensive experiments, the results verify that the assumptions are reasonable and effective in the scenario of web search analysis.
In this section, we discuss the three major components of G-WSTD, whose architecture is illustrated in Figure 1. Section 3.1 discusses the component of search session deriva-tion. Section 3.2 describes the component of geographic in-formation extraction. Section 3.3 outlines the search topic discovery component and downstream applications.
Search session is defined as a series of queries that satisfy the same information need. The goal of session derivation is to group semantically related queries together. We prioritize the coherency of each session to avoid irrelevant queries in a session. As query reformulation taxonomy based method demonstrates high precision in detecting the semantic rel-evance between queries, we utilize the method proposed in [10] to segment search query log into search sessions, which are further utilized in geographic information extraction and search topic discovery.
In order to extract geographic information in a fine granu-larity, we focus on extracting city names in this paper. The task is challenging because of the ambiguity of proper names. Consider the query  X  X ew york times X . The simplistic match-ing of query n-grams and geographic locations gives us a false positive match with the city of New York. Only when we consider other properties of the query and the context in which  X  X ew york X  is mentioned, can we successfully iden-tify this query as non-geographic. We also find that general NLP tools such as named entity recognizer cannot be di-rectly applied to the task because of the shortness of search queries and the lack of capitalization. Therefore, we propose a supervised approach to classify queries into geographic and non-geographic categories.

We first build a training corpus of search queries, which are manually labeled as geographic or non-geographic. Then we construct training instances by extracting features of each query and its respective session. The details of the extracted features are presented below.
Using the training dataset, we train a classification model, which can then be used to classify all queries in our corpus as geographic or non-geographic. When a new search query comes, we first perform a simple lookup of query n -grams ( n  X  5) 2 in a geographic dictionary, in order to identify candidate locations . If no candidate location is found, the query is considered non-geographic. If there exist candi-date locations, we employ the trained model to classify the query. If the query is identified as geographic, then we out-put the candidate location as the geographic information of the query. Finally, a geographic dictionary is utilized to map each location onto its corresponding latitude and longitude (e.g., mapping  X  X ew york X  to [40.7142  X  N, 74.0064  X  W]). In
In our geographic dictionary, no location contains more than 5 terms. the process of location extraction, we assign higher priority to longer n -grams. For example, in the geographic query  X  X esidence new york X   X  X ew york X  rather than  X  X ork X  is rec-ognized as a location. Besides that, with an extended ge-ographic dictionary, our geographic information extraction method also supports extracting abbreviated names (e.g.  X  X Y X  for New York) as locations.
In this component, we utilize DSTM and RSTM to dis-cover geographic search topics. The details of DSTM and RSTM will be presented in Section 4. The discovered search topics will be presented in Section 5.3. The effectiveness of DSTM in discovering the commonalities of different loca-tions and the effectiveness of RSTM in discovering a region X  X  characteristics will also be demonstrated in Section 5.3. The downstream applications such as user profiling and URL an-notation are discussed in Sections 5.5 and 5.6.
In order to apply probabilistic topic modeling to query log, we first group the log entries of the same user as a doc-ument. Then we organize each document as bag of search sessions. We also filter out the non-informative query terms according to a stopword list provided in [14]. The common URLs of major search engines and popular portals such as  X  X ww.google.com X  and  X  X ww.yahoo.com X  are also sifted due to non-informativeness. Due to the large amount of search queries and the long-tail phenomenon, we only utilize the search queries whose frequency is larger than a predefined threshold. After the pre-processing, each user is associated with a document, each document contains several search ses-sions and each search session contains several query terms, search queries (if any), URLs (if any) and geographic in-formation (if any). The notations that will be used in the paper are presented in Table 2.
Query log contains two heterogeneous items: query terms and the URLs. These two items are not independent since the URLs result from the search queries, which are composed of the corresponding query terms. Therefore, in DSTM, we capture the relation between the query terms and the URLs via the search queries . We further assume that search queries, query terms and URLs in the same session share the same search topic. This assumption is consistent with the reality: information within the same session is to satisfy the same information need and thus is semantically coherent. The Bayesian graphical model of DSTM is presented in Figure 2. Each document is generated by first drawing a document-specific mix  X  over topic 1 ,...,K that is drawn from a Dirichlet prior  X  . As we constrain that search queries, query terms and URLs within a session share the same search topic, we use search session as the basic unit for topic assignment. Thus, a session-specific topic z is drawn from  X  . Within the session, some query terms are drawn from a multinomial distribution based on the topic z . Then these query terms are composed as search queries. Some search sessions, especially those with only one query, contains no clickthrough, therefore, no URL is recorded in the log. We use an indicator X to indicate whether there exists URL in a search session. If there exist URLs ( X = 1), the URLs are drawn from a multinomial distribution based on the topic z and the corresponding search query q . A session does not necessarily contain geographic information, thus another in-dicator Y is drawn to decide whether geographic information exists in a session. If there exists geographic information ( Y = 1), the locations are drawn from a multinomial distri-bution based on the topic z .

In DSTM, the topic assignment of a session is subject to the co-occurrence of the querie s, the query terms, the URLs and the locations within the session. Ultimately, each query term t is picked in proportion to how much the enclosing document prefers the topic z and how much the search topic prefers the query term t . Each URL is picked in proportion to how much the enclosing document prefers the topic z and how much the topic and the corresponding query prefers the URL u . Each location is picked in proportion to how much the enclosing document prefers the topic z and how much the topic prefers the location l . Notably, the model utilizes the geographic information in a discrete way, without considering the geographic distance between the locations.
We aim to find an efficient way to compute the joint like-lihood of the observed search queries, query terms, URLs and locations with the hyperparameters:
P ( z |  X  ) is the same as the standard LDA. This formula term ultimately contributes the same formula term to the full conditional as well as the sampling formula for updating individual topic assignments z i . Using the independence assumptions of the model, we consider the probability of the query terms, URLs and the locations.
 The probability of the query terms is given as follows: The probability of the URLs is given as follows: The probability of the locations is given as follows:
After combining the formula terms, applying Bayes rule and folding terms into the proportionality constant, the con-ditional probability of the k th topic for the i th session is defined as follows:
Note that the method proposed here is potentially scalable to very large datasets. For example, the LDA-style Gibbs sampling has been scaled to very large data sizes by [16]. We now analyze query log from the regional perspective. The Bayesian graphical model of RSTM is presented in Fig-ure 3. Different from the search topics discovered by DSTM, in which the locations can be widely dispersed on the map, RSTM assumes that search topics have geographic locality and each topic covers a region that is defined by two Gaus-sian distributions over latitude and longitude, respectively.
The major difference between DSTM and RSTM lies in the generative process of the geographic information. Simi-lar to DSTM, an indicator Y is chosen to determine whether there exists geographic information in the current search ses-sion. If Y = 1, then the search topic generates latitudes g and longitudes g lon from two topic-specific Gaussian distri-butions  X  lat and  X  lon . Due to the nature of the Gaussian distribution, the latitude and longitude that are close to the means of the two distributions are more likely to be cho-sen, thus the resultant topic tends to cover a specific region. Astute readers may suggest that the coordinate can be nat-urally modeled by a bivariate Gaussian distribution. How-ever, previous work already shows that bivariate Gaussian distribution results in poor convergence of parameter esti-mates [20]. Therefore, we model the latitude and longitude by using two separate Gaussian distributions. Empirically, we find that using two Gaussian distributions results in both quick convergence as well as coherent search topics.
Since the latitude and longitude information is observable in RSTM, the joint likelihood is as follows: where P ( z |  X  ), P ( q | t ), P ( t | z , X  )and P ( u | same as those in DSTM.

The probabilities of generating the latitudes and longi-tudes are listed as follows:
We also apply Gibbs sampling to estimate the latent pa-rameters. After combining the formula terms in Equation 6, applying Bayes rule and folding terms into the proportional-ity constant, the search topic of the i th session, z i ,isdrawn from the following conditional probability:
For the sake of simplicity and efficiency, we update the parameters of the two Gaussian distributions  X  lat z and  X  by the sample mean and sample variance after each iteration. where ( g lon i , g lon i )isthe i th (latitude, longitude) pair which exists in sessions that are assigned search topic z . Similar to DSTM, this method is also scalable to very large data.
In this section, we present the experimental results. Sec-tion 5.1 discusses the experimental setup. Section 5.2 evalu-ates the performance of the geographic information extrac-tion. Section 5.3 reports the discovered geographic search topics and analyzes their characteristics. In Section 5.4, we quantitatively evaluate the proposed models with three stan-dard metrics. In Sections 5.5 and 5.6, we demonstrate the utility of the proposed models in applications such as user profiling and URL annotation.
In order to estimate the effectiveness of the proposed mod-els, we use a real-world data search query log that is ob-tained from a major commercial search engine in the United States. The dataset contains 1,501,182 search queries that were submitted by 11,545 users. After carrying out the ses-sion derivation process, we obtain 650,164 search sessions from the dataset.
We first evaluate the proposed geographic information ex-traction method. We select 6,610 queries from 3,085 sessions and manually label them by four human judges. For the classification paradigm, we choose the widely used Support Vector Machine (SVM) and logistic regression. After train-ing the learning models, we evaluate their effectiveness by ten-fold cross validation. We use standard metrics of pre-cision , recall and F-measure for gauging the performance. The classification results are presented in Figure 5, in which the precision and recall of non-geographic queries are de-noted as precision( N ) and recall( N ) while the precision and recall of geographic queries are denoted as precision( G )and recall( G ). To establish the baseline, we perform n -gram matching of the query terms in a geographic database that contains world cities, counties, states and countries. If the n -gram matches a word with a location in the database, we recognize the word as a location. From the results, we ob-serve that detecting locations using bag-of-words as the clas-sification feature is not effective since the recall( G )isvery low. In contrast, the features presented in Section 3.2 are very effective for geographic query classification. Among all the methods, SVM that utilizes the full feature set achieves the best F-measure of 0.981, and thus we use it for running the location extraction of our dataset, from which 76,530 locations are extracted in total.
An informal but important measure of the success of the proposed model is the plausibility of the discovered search topics. For simplicity, we use the fixed symmetric Dirich-let distribution, which demonstrates good performance in our experiments. Some search topic examples discovered by DSTM and RSTM are presented in Table 3. We also visu-alize the geographic information of search topics discovered by DSTM and RSTM in Figure 4. For the topic discovered by DSTM, we mark the locations on the map. For the topic discovered by RSTM, we use a rectangle to represent the region that has a high probability (the value of probability density function is larger than 0.1) in both two Gaussian distributions.

In the search topic Education ,  X  X niversity X , X  X igh X  X nd X  X e-partment X  are the most frequent terms while Los Angles, Boston, Austin, Chicago and San Francisco are the top five locations in this topic. The fact that many universities are located in these cities verifies that higher education is the commonality of these locations, even these they are widely dispersed on the map. Similarly, the topic NBA contains terms like  X  X asketball X ,  X  X layers X , etc. It is strongly associ-ated with locations such as Salt Lake City, Dallas, Philadel-phia, Houston and Los Angeles, all of which are home to NBA teams. The topic Election is composed of terms like  X  X lection X ,  X  X onsulate X  X nd X  X olitics X . This topic is closely re-lated to locations such as Nashville, Chicago, Washington, Cleveland and New York and these cities usually host lots of political activities during election. We also observe that words like  X  X state X ,  X  X eal X ,  X  X istrict X  are the dominant terms in the search topic Real Estate , which is frequently associ-ated with heavily populated cities such as Los Angeles, San Diego, Denver, Miami and New York. The result suggests that hot real estate market used to be the commonality of these locations.

The search topic Recreation is primarily about X  X ics X , X  X un X  and X  X each X , and its spectrum covers the coastal area around Cape Hatteras National Seashore 3 , which is a popular park for recreation and relaxation. The search topic Sailing is about  X  X ailing X ,  X  X wim X ,  X  X ade X  and  X  X ay X . Its geographic spectrum covers the Chesapeake Bay Area in Maryland. http://www.nps.gov/caha/index.htm The result aligns with the fact that swimming, boating and sailing are extremely popular activities enjoyed around the Chesapeake Bay 4 . The search topic High-tech covers an area around the San Francisco Bay, where the Silicon Valley is home to many of the world X  X  largest technology corpora-tions. The search topic Energy is related to a region around Oklahoma, which is a major producer of natural gas and oil in the United States. The results are all consistent with the facts and thus suggest that RSTM can effectively find the characteristics of a specific region, which is the embodiment of the locality assumption.

The above results illustrate the output format of the pro-posed models and reveal some basic features of the discov-ered search topics. In the following subsection, we use three standard metrics to gauge the  X  X oodness-of-fit X  and the dis-tinctiveness of the search topics discovered by the two mod-els.
In this section, we utilize three metrics to compare DSTM and RSTM with some counterparts. We notice that few probabilistic topic models are proposed to analyze web search from the geographic perspective, thus it is hard to find di-rect competitors for the proposed ones. After an extensive survey, we select three models that are general enough to be applied to the task studied in this paper. The first base-line that we choose is Latent Dirichlet Allocation (LDA) [2]. The second baseline is LATM [21]. The third one is GeoFolk [20].

We first use a held-out dataset that contains 7,635 search queries to evaluate the models X  capability of predicting un-seen data. All the models in this study are trained by using the data mentioned in Section 5.1. Perplexity is a standard measure of evaluating the generalization performance of a probabilistic model [17]. It is monotonically decreasing in the likelihood of the held-out data. Therefore, a lower per-plexity indicates better generalization performance. Specif-ically, perplexity is calculated according to the following equation: where M is the model learned from the training process. The result of perplexity comparison is presented in Figure http://en.wikipedia.org/wiki/Chesapeake Bay 6(a), from which we observe that the two proposed mod-els demonstrate much better capability in predicting unseen data comparing with the three baselines. For example, when the number of search topics set to 1000, the perplexity of LDA is 1007.18, that of LATM is 846.12 and that of Geo-Folk is 833.09. DSTM significantly reduces the perplexity and achieves a perplexity of 358.56. RSTM reduces the per-plexity even further and demonstrates the lowest perplexity of 349.54. The result shows that DSTM and RSTM are more suitable for analyzing web search data.

Another metric is defined for gauging how effective the proposed models are in predicting the remaining query terms after observing a portion of the user X  X  search history. Sup-pose we observe the query terms w 1: P from a user X  X  query log, we are interested in finding which model provides a better predictive distribution p ( w | w 1: P ) of the remaining query terms. Specifically, we use each user X  X  first 80% search queries as the training data and the remaining 20% as the testing data. We use Equation 15 to calculate the perplexity of the testing data. The comparison results are presented in Figure 6(b). We observe that the proposed models again sig-nificantly outperform the three baselines. When the topic is set to 90. LDA demonstrates a perplexity of 611.89, LATM generates a perplexity of 540.45 and GeoFolk shows a per-plexity of 543.17. DSTM achieves a perplexity of 150.34 and RSTM achieve a perplexity of 160.79. The result suggests that DSTM and RSTM have better capability to predicting the user X  X  future web search given the user X  X  search history.
The third metric that we use for evaluation is the KL-divergence between discovered geographic search topics. Sim-ilar to [24], we use KL-divergence to evaluate the distinctive-ness of discovered search topics. The larger the average KL-divergence is, the more distinct the search topics are. We show the average distance of term distributions of all pairs of search topics measured by KL-divergence in Figure 6(c). We find that the KL-divergence of DSTM is higher than the three baselines. By incorporating the geographic informa-tion, the word distributions in the search topics discovered by DSTM are more distinctive than those obtained by the baselines. The result indicates that DSTM is effective to find different facets of the location commonalities. We also observe that by assuming the geographic locality, RSTM is able to discover search topics that are more distinct than the three baselines. This result is consistent with our ex-pectation that RSTM is useful for find some region-specific issues, which help improve the distinctiveness of discovered search topics.
In this section, we apply DSTM and RSTM to build user profiles for search engine users and demonstrate their effec-tiveness by comparing with several strong baselines. After processing each user X  X  search history by the proposed mod-els, the i th user X  X  profile is represented by a search topic dicates the i th user X  X  endorsement for the k th search topic. The value of  X  ik is computed according to the final states of the Markov chain after Gibbs sampling. The formula is defined as follows:
We evaluate the quality of user profiles by the task of un-supervised clustering. We prepare the ground truth with a small portion of the query log obtained from 1879 users who submitted geographic queries, and these queries are manu-allyclassifiedinto21ODP 5 categories and thus each user is represented by a 21-element vector, where each element is the frequency of the user X  X  queries that belong to the cor-responding category. After normalization, the 21-element vector serves as the ground truth profile.

We first compare DSTM and RSTM with the following three baselines. http://www.dmoz.org/
We then apply k -means algorithm [14] to the ground truth vectors and those from the baselines and the proposed mod-els. Our goal is to evaluate whether the user profiles ob-tained from the proposed models can generate communities that are similar to the ground truth. For community quality evaluation, we check the resultant relation between each pair of users against the results obtained from the ground truth. For the clustering result c p that is obtained from the user profiling method p and two users i and j ,iftherelation 6 i and j in c p  X  X  clustering result is consistent with the result c truth that is obtained from the ground truth, then we con-sider it as a positive judgment. We repeat this process for each pair of users and the final counting is normalized by the total number of user pairs. We regard this normalized value as Human Judgment Correlation Score (HJCS) and formally define it as follows:
In order to reduce the bias from the initialization of k -means algorithm, we run this algorithm for 100 times and utilize the average HJCS as the final one. From the result shown in Figure 7 (a), we observe that Location, DSTM and RSTM perform better than TF-IDF and SVD. For the task of geographic user clustering, DSTM and RSTM generally demonstrate the highest and the second highest correlations with human labeled ground truth. The performance superi-ority results from the capturing of latent semantics in search query log. We also compare DSTM and RSTM with the three baseline topic models on the same task and the result is shown in Figure 7 (b), in which DSTM and RSTM also show better alignments with human labeled data.
Another advantage of DSTM and RSTM is to find the semantic relation between query terms and URLs. Within each search topic, the query terms can be considered as the annotation of the URLs. Some examples of the URL an-notation are presented in Table 4. We observe that both DSTM and RSTM can effectively annotate URLs with se-mantically relevant terms. In order to quantitatively eval-uate the quality of URL annotation obtained from DSTM and RSTM, we compare them with M2 and baseline+M2, whichachievedthebestperformancein[9],onthetaskof URL classification. For a search topic k and a query q ,we
The relation means whether i and j are within the same clusterornot. use the top 10 query terms from topic k as the annotation of the top 2 URLs in  X  kq . In total 500 URLs are selected for this experiment. Other experimentally settings are the same as that discussed in [9] and are skipped here to save space. The result is shown in Figure 7 (c). DSTM and RSTM achieve the classification accuracies of 0.68 and 0.64, which outperform M2 X  X  0.54 and baseline+M2 X  X  0.57. The result shows that the DSTM and RSTM are effective to cap-ture the semantic relation between query terms and URLs. Thus, the resultant search topics are helpful for interpreting the URL X  X  content with higher accuracy.
In this paper, we study the problem of discovering geo-graphic search topics from search engine query logs. We pro-pose a new framework (G-WSTD) that is composed of search session derivation, geographic information extraction and two search topic models, the Discrete Search Topic Model (DSTM) and the Regional Search Topic Model (RSTM). DSTM discovers the commonalities between different loca-tions in a discrete way, disregarding their geographical dis-tances. RSTM assumes that search topics have the geo-graphic locality and discover the local characteristics within a region. To verify the effectiveness of our approach, we con-duct extensive experiments on a real-life search query log. The experimental results show that the proposed models outperform several strong baselines with respect to differ-ent metrics. The superiority of the proposed framework is further demonstrated by applications such as search engine user profiling and URL annotation.
This work is partially supported by RGC GRF under grant number HKUST 618509.
