 1. Introduction
As the immense amount of digital images are placed in the image archives, the need to efficiently search images from image databases that really meet the users X  interest is becoming increasingly important. Com-pared with the human-made annotations or keywords of images, the contents of images are more flexible and powerful for distinguishing images. Features employed for discriminating images in content-based image uses an n -dimensional feature vector which is composed of the pixel percentages of n predefined colors as the responding points in the n -dimensional Euclidean space. The feature vectors of the images in a database are then indexed and retrieved by the assistance of a spatial access method (SAM) [18] .

To utilize the higher level features for retrieval, a CBIR system needs to preprocess the images with the help of segmentation and object recognition techniques, probably semi-automated, to identify the domain objects tumor in a brain MRI (magnetic resonance imaging) image. In most of the applications, there may exist more than one object with the same symbol in an image, i.e. an image may have duplicated objects. Images with such recognized objects are called symbolic images , and a database with such images is a symbolic image data-base . Compared with the original pixel-level physical images, symbolic images can be manipulated with better ognized objects.

The object-level retrieval is performed by logical inference about the perception of the objects and the spa-tial relations between them in an image. For example, in the real estate marketing, a customer may ask a ques-spatial patterns is also useful in applications such as interior design [8] , in which we may need to retrieve is also possible in the medical application to retrieve all brain MRI images which have a tumor in the same position as the query image. Spatial patterns formed by image objects can also be used in the application area such as spatial data mining [17] .

We can roughly divide  X  X  X BIR by spatial constraints  X  into three types: exact match retrieval, subimage database that are identical to the query image. A retrieved image must have the same object set as the query image, and the spatial arrangements of all objects in both images must also be identical to a certain extent.
Some algorithms [4,13,22] have been proposed to perform the exact match retrieval in polynomial time com-plexity. The common techniques used by these methods are first extracting the spatial features from every two or three objects in an image, and then attaining a value, a vector, or a compound structure to represent this tion of the equality of the object sets in both images.

Analogous to exact match retrieval, subimage retrieval needs to match each object in the query image to one object in the database image with both symbolic and spatial satisfactions. But subimage retrieval allows some in this database that include this query image  X  . For a database image, the comparison result with the given the comparison process will be more efficient. Directional similarity [5] , a more flexible matching, has been proved to be NP-complete [26] . In addition to these object-matching methods, some algorithms hash or index or tree structure is performed off-line, its time complexity cannot be taken into account in the query search.
Therefore, the search time complexity is O( m ) in the best case for methods using hashing or O( m log n ) for methods using tree structure, where m is the number of features in the query image and n is the number of database images.

The third kind of retrieval is similarity retrieval which allows unmatched objects in both the query image and a database image. The purpose of similarity retrieval is to find those images in a symbolic image database a symbolic image database. Basically, there are three main types of similarity functions. The maximum com-mon subimage function returns the number of objects in the maximum common subimage between the query image and a database image [10,16] . A common subimage between two symbolic images is defined as that its objects appear in both images and the spatial relations among these objects are similar in both images. The category of similarity retrieval function is defined as the accumulation of object-pair similarities that come the time complexity is quadratic in terms of the number of objects, because the matching between objects from the query image and a database image is unique. Once the restriction of symbol duplication is released, the time complexity becomes exponential in the worst case because all possible object-matching between both images need to be calculated in order to find the maximum accumulated value. If not all possible matching are considered, the randomly or greedily selected associations may make the results far from optimal.
Another kind of similarity function returns the editing distance of two attributed relational graphs (ARG), which correspond to two symbolic images. The individual objects in an image are represented as vertices in the corresponding ARG and their relationships are represented as arcs between such vertices. The similarity degree between two symbolic images is the minimum editing distance from one ARG to the other, and the tial. If two symbolic images are represented as two ARG X  X , the maximum common subimage of the two images can also be obtained by calculating the maximum common subgraph (MCS) of the two corresponding ARG X  X .
However, finding the MCS of two graphs is an NP-hard problem because of the multiple matching of vertices between two graphs.

For other types of image representations and similarity functions, [14] uses a set of 4-tuples to represent a uses a rotation-invariant representation called RS-string, which is based on polar coordinates system rather than orthogonal system. In addition, some methods provide interactive process called reference feedback to affinity relations among the images through data mining process.

In this paper, we propose a similarity retrieval model with graph-based representation for conveying the objects and spatial information of an image. The main contribution of the proposed model is its remarkable posed model can be viewed as a combination of  X  X  X aximum common subimage  X  function and  X  X  X ccumulation-based  X  function. For the  X  X  X aximum common subimage  X  part, we use the maximum common subgraph of two  X  X  Spatial Relation Graph  X  (SRG X  X ) to calculate the similarity of two images, which has the advantage of good representing both symbolic images as two derived SRG X  X , in which the vertices denote objects in an image and the arcs denote the spatial relations between each pair of objects. Then the maximum common subgraph of these two derived SRG X  X  is attained, and then the size of the MCS is used to calculate the similarity degree of these two images. In such an SRG graph, vertices are labeled with the corresponding object class symbols and arcs with the spatial relation types between object pairs. The arc labels can be represented flexibly such that SRG model can adapt to different spatial similarity criteria. Besides, we employ some techniques in the process of building an SRG, by which the calculation of the MCS of two SRG X  X  is quadratic in terms of the number of image objects. We also propose the extended model SRG as SRG model.

The rest of the paper is organized as follows. Section 2 describes a number of similarity retrieval methods the proposed model SRG. The construction process of the SRG, the calculation of the similarity degree between two images via the operations on two derived SRG X  X , and the features of SRG X  X  are investigated. In Section 4 , we introduce the extension of SRG model named SRG sure. Section 6 summarizes the paper with a brief discussion of the contribution of the proposed model, fol-lowed by future direction. 2. Related work 2.1. Similarity retrieval k ( A )&gt; y-rank ( B ). The pair similarity can also be defined by the object coordinates [10] .
Let A be the symbol assigned to an object with x -coordinate (or x -rank) a and y -coordinate (or y -rank) b ,
Definition 1 ( type-i spatial similarity). Let [ A ,( x 1 [ A ,( a 1 , b 1 )] and [ B ,( a 2 , b 2 )] two objects in f
D follows: type-0 : D x D a P 0 and D y D b P 0. type-1 :( D x D a &gt;0or D x = D a = 0) and ( D y D b &gt;0or D type-2 : D x = D a and D y = D b .
 type-1 similar if they possess the same directional relations in both images. The directions include north, north-west, west, south-west, south, south-east, east, and north-east. As shown in f tions differ by one direction, e.g., [ A ,(1,2)] is west of [ D ,(6,2)] in f distances must also be the same in both images. Hence the two C  X  D object pairs in f Using Definition 1 , we can define the type-i common subimage of two symbolic images as follows. Let S and and f 2 , if there is a bijective function g from S to T such that for every object O the symbol of g ( O i ); and for any object pair O i  X  O j similar.

In Fig. 1 b and c, objects C , B ([ B ,(5,1)] in f 1 and f similarity function can be defined as the number of objects in the maximal common subimage of two com-pared images [10,16] . Lee et al. proposed a method LCS _ Clique to find the maximal common subimage by constructing a type-i graph and finding the maximal clique in this graph [16] . The possible matching of two objects O i 1 in f 1 and O j 1 in f 2 forms a vertex ( O i 1 tices ( O i 1 , O j 1 ) and ( O i 2 , O j 2 ) if two object pairs O Definition 1 .

Fig. 2 shows the type-1 graph of the two symbolic images in Fig. 1 b and c. The objects are ordered by hor-izontal positions and then by vertical positions, hence f vertex labeled  X  X  X  depicts that this vertex is the possible matching from the i th object of f f , and these two objects are both symbolized  X  X  X . For example, vertex (1,4) with label  X  A  X  X n Fig. 2 is the matching of the first object of f 1 and the fourth object of f
The maximal clique in this graph is the four vertices in the center. LCS_Clique is NP-complete because finding maximal clique is an NP-complete problem. Actually, Guan [10] proved that the time complexity nature of all the algorithms by finding the maximal common subimage under type-0 and type-1 criteria is NP-complete, even when all symbols are distinct. 2.2. Accumulation-based similarity function The similarity retrieval method SIM R based on similarity accumulation was proposed by Gudivada and
Raghavan [11] . The similarity degree of a database image with respect to a query image is obtained by calcu-objects, its edge list contains n ( n 1)/2 edges.
 To compare a database image I db with a query image I q , SIM for each edge e i of I q .If e j can be found then SIM R calculates the angle h the contribution of this edge pair to the total similarity degree by 100.0/( n ( n minus 1)/2) n is the number of objects in I q . Consider Fig. 3 with f the final similarity 88, where the range of similarity degree is 0 to 100.

SIM R has excellent efficiency by its accumulation approach when no objects have the same symbols within an image. However, as mentioned in Section 1 , the efficiency of SIM with symbol  X  A  X  X n f 1 can be mapped by the object  X  A  X  X n f to these eight mapping methods in order to find the maximal value as the final answer.
Notice that the similarity function of SIM R is not symmetric, i.e., sim( f objects of these two images are not equal. To achieve rotation invariance, SIM
An extension method SIM DTC [8] calculates the similarity degree by considering the directional relations as in SIM R , the number of common objects, and the topological relations. 2.3. Linear combination of two 1D strings
The idea behind 2D Be-string by Wang [30] is to process two one-dimensional strings separately and com-angle (MBR) with four boundary symbols: the beginning boundaries and the end boundaries along x -and y -axis, respectively. To make the 1D string along x -or y -axis, the begin boundary and the end boundary along two consecutive boundary symbols unless the coordinates of two boundary symbols are identical. Hence an layout of Fig. 1 c. The x -and y -axis strings of this image are e E e B b e D b e A b e B e e B b e D e e B e e A e e E b e E e C boundary of an object with symbol  X  A  X , respectively. In this example, the number of symbols in x -string is 25 and in y -string is 24 (no dummy symbol between E e and C of the number of objects.

To calculate the x -axis one-dimensional longest common subsequence (1D LCS) between two images, a modified dynamic-programming method is employed. This method needs to compute about 16 n
LCS. The similarity along y -axis is computed in the same manner. The total similarity is thus the linear com-bination of these two 1D similarities. The time complexity of this method is quadratic in terms of the number of image objects. The necessary computation includes sorting four 1D strings (two images each with two axes) and performing two dynamic-programming table calculations separately for x -and y -axis.
This method can handle topological relations between each pair of objects by considering the beginning and and the end boundary of A is larger than that of object B , object B is inside object A  X  X  X orizontally  X  ( e A e B e e A e e ). From the y -string ( e B b e A b e A e e B e dently considering the boundaries is that it cannot always correctly describe the two-dimensional topological relation between two objects. is independent of the symbol duplication rate. However, potential inaccuracy may occur in some cases. In addition to the topological case stated above, when the spatial relations of the object pairs along one axis are the same in both images whereas those along the other axis are in the opposite position, these two objects  X  B  X . This inaccuracy occurs due to the independency of two 1D calculations. By a real 2D geometry compu-tation, this pair of objects will provide less contribution. 3. The proposed method
To address the deficiency of the related work described above, and to enhance their advantages, the pro-tiveness. Besides, the efficiency of the proposed model should be smooth when the number of image objects increases, and should be identical when the symbol duplicate rate varies. In view of this, we propose a plain and efficient model SRG for similarity retrieval in symbolic databases. SRG model calculates the similarity degree of two symbolic images by constructing the corresponding  X  X  X erived SRG X  X   X  of the two compared images. Then the maximum common subgraph (MCS) of the two derived SRG X  X  is obtained, and the size sive; hence the efficiency of finding the MCS of two derived SRG X  X  is quadratic in terms of the number of image objects. The whole process is described in the following subsections. 3.1. Construct a derived SRG
A symbolic image f is represented as a spatial relation graph (SRG) G by the procedures described below, the corresponding derived SRG with its class symbol as the vertex label, but objects with the same symbol labels is { S (south), SW (south-west), W (west), NW (north-west), I (identical)}, where label I depicts two set because the directional relations induced by two objects can be represented by two analogous forms, and we only need to keep one of them. For example, object X to the northwest of object Y can be denoted as ( X , Y , NW ) and ( Y , X , SE ) analogously, and we only retain ( X , Y , NW ).

Fig. 5 a and b are the derived SRG X  X  G 1 and G 2 of images f f has four distinct object symbols A , B , C , and D , the derived SRG G not duplicate among different vertices within an SRG. This feature makes the manipulation of SRG more effi-cient than that of the ordinary labeled graphs with probable duplicated vertex labels. The proposed method will utilize this advantage in finding the maximum common subgraph of two SRG X  X  efficiently.
SRG X  X  are multi-graphs with possible self-loops. A self-loop depicts a spatial relation between two objects vertex and m 1 invisible embedded vertices. We state the relation between the number of self-loops and the number of embedded vertices in a derived SRG as Lemma 1 .

Lemma 1. If a vertex in a derived SRG has s self-loops, then  X  1  X  vertex.
 hence the number of embedded vertices in this vertex is m 1. The number of self-loops in this vertex is m ( m 1)/2 because every two objects with symbol  X  X  X  in the image produce one self-loop for this vertex.
Therefore, s = m ( m 1)/2, which also means m  X  X  1  X  of invisible embedded vertices. h
We now define the size of an SRG, which is used in the calculation of the similarity degree between two images.
 Definition 2. The size of a SRG is the sum of the numbers of vertices, arcs, and all embedded vertices.
For a derived SRG of a symbolic image with n objects, its size is also n + n ( n 1)/2, where n ( n 1)/2 is the number of spatial relations produced by these n objects. For example, the size of G of vertices) + 15 (the number of arcs) + 2 (the number of embedded vertices), which equals 6 + 6(6 1)/2 since image f 1 in Fig. 1 b has six objects. We can see that G substituting s = 1 to the formula of Lemma 1 twice yields the total number of embedded vertices.
We define the size of an SRG not merely by the number of vertices but also by the numbers of arcs and embedded vertices. The number of embedded vertices is taken into account because the embedded vertices stand for the invisible objects, and these objects should not be ignored. The reason of including the number similarity no less than multiple individual objects. Actually, common objects in two images are the bases that span the intersection of the two images, and the common spatial relations between the common object pairs (or common arcs connecting the common vertices, from the view of graph) accumulate the similarity.
In summary, SRG is a labeled multi-graph with self-loops and without vertex label duplication. It is easy to see that the time complexity of the building process of a derived SRG is O( n in the original symbolic image. This is because the number of the vertices m in the derived SRG is no greater than n , and the number of arcs in the derived SRG is n ( n 1)/2. 3.2. Find the MCS of two SRG X  X 
We say that a graph G =( V , E ) is the common subgraph of two graphs G there exist subgraph isomorphism from G to G 1 and from G to G (MCS) of G 1 and G 2 , denoted as MCS( G 1 , G 2 ), if there exists no other common subgraph of G larger than G . Finding the MCS of two labeled graphs is an NP-hard problem if vertex labels duplicate within a graph [9,29] . This is due to the multiple associations of the vertices in both graphs.
However, finding the MCS of two derived SRG X  X  is quadratic in terms of the number of vertices of the derived SRG and thus also quadratic in terms of the number of objects in the original images. This is because the vertex labels in an SRG do not duplicate and hence the associations of the vertices in both SRG X  X  are unique.
 The procedure of finding the MCS of two SRG X  X  is actually equivalent to performing  X  X  X ntersection  X  of two
SRG X  X . Let G 12 be the MCS of SRG G 1 and G 2 , the steps of finding G 1. Find the common vertices of G 1 and G 2 , i.e., V ( G 12 graph G . 2. For each pair of vertices v 1 and v 2 in V ( G 12 ), where v self-loops between these two vertices in G 1 and G 2 , then add them to E ( G arcs and self-loops of graph G . That is, for all arcs ( v E ( G 2 ).

As an example, the SRG in Fig. 5 c is the MCS of the SRG X  X  in Fig. 5 a and b. From the construction steps since a spatial relation cannot exist without indicating which object pair possesses it. On the other hand, G may contain isolated vertices representing the objects that are common in both images but cannot form com-mon spatial patterns with other objects.

It should be noticed that the steps used in constructing the MCS of SRG X  X  is not applicable to general graphs. We refer to general graphs as the graphs other than SRG X  X . Obtaining the MCS of two general graphs needs to match possible vertex pairs by traversing and backtracking in the state-space tree, which is known as an NP-hard problem.
 graphic orders, where m 1 and m 2 are the sizes of V ( G 1 finding common vertices between two sorted vertex lists is similar to that of merging two sorted lists. Notice that if the original images of G 1 and G 2 have n 1 and n second step finds all the common arcs between every vertex pair in V ( G dratic in terms of the number of vertices in the SRG X  X . Since the number of vertices in a derived SRG is no objects in the original images. 3.2.1. Flexible similarity criteria
SRG model also provides flexible similarity criteria. Actually, step 2 described above corresponds to type-1 same relative directions in both images. That is, an arc ( X , Y , l if l val under the other two criteria type-0 and type-2 as follows. For type-0 criterion, an arc ( X , Y , l also be matched to its neighbor arc in G 2 , e.g., the neighbor arcs of ( X , Y , W )in G pair of vertices are sorted in two SRG X  X , the matching process can be performed efficiently because it can be stopped as soon as possible.
 vector is no less than zero. Thus an arc ( X , Y , v 1 )in G and v 2 are two-dimensional vectors.
 pair.
 3.2.2. The estimation of embedded vertices in a calculated SRG
A calculated SRG is the operating result of the derived SRG X  X  such as the MCS of two derived SRG X  X . The difference between a derived SRG and a calculated SRG is that a derived SRG corresponds to a real symbolic image but a calculated SRG does not. For a calculated SRG, we can still compute its size by Lemma 1 but with some expansion. The first term of the equation in Lemma 1 is expanded to be the ceiling of  X  1  X  tion,  X  1  X  the same symbols in both images can only have zero or one common directional relation. Three objects can induce zero to three common self-loops, depending on the actual spatial arrangements in both images. In the estimate 3 as the number of objects that are involved in the vertex with two self-loops. Notice that four or more objects with the same symbol may also make two self-loops to the corresponding vertex (the range is 0 X 6 for four objects). Hence SRG model adopts a conservative approach in the estimation of the number of embedded vertices. 3.3. Similarity degree of two symbolic images
Let G 1 and G 2 be the derived SRG graphs of two symbolic images f the MCS of G 1 and G 2 . We have the following definitions: is that in [27] the size of a graph is defined by only the number of vertices.

We choose | G 1 |+| G 2 | | G 12 |asin [27] in the denominator of the second term in Eq. (2) instead of ing. Consider three derived SRG X  X  G 1 , G 2 , and G 3 , which represent symbolic images f
Assume | G 12 |=| G 23 | and | G 1 |&gt;| G 3 |. By using Eq. (2) , the similarity between G val because f 1 contains more irrelevant objects than f 3 denominator as in [2] , then sim ( G 1 , G 2 )and sim ( G
Consider the case that we make an image f 3 by adding some objects to the common subimage of f that the symbols of these new objects are not in f 2 and the number of objects in f case, let G 3 be the derived SRG of f 3 . Thus sim ( G 3 , G sim ( G 3 , G 2 )&gt; sim ( G 1 , G 2 ) when Eq. (2) is used.

SRG model transforms the problem of calculating the similarity degree of two symbolic images to the prob-lem of computing the similarity of the two corresponding derived SRG X  X . The similarity measure defined in
Eq. (2) has the following features: 1. sim ( G 1 , G 2 )= sim ( G 2 , G 1 ).

Since | G 12 |=| G 21 |, Eq. (2) is obviously symmetric. 2. sim ( G 1 , G 1 )=0.

Since | G 1 |=| G 11 |, the similarity of two identical SRG X  X  is
From the perspective of similarity image retrieval, the similarity of two identical symbolic images is 1. 3. 0 6 sim ( G 1 , G 2 ) 6 1, for any derived SRG pair G 1
It is obvious from our definition of G 12 that 0 6 | G 12
According to steps of constructing the MCS of two derived SRG X  X  in Section 3.2 ,| G is 0. if min{| G 1 |,| G 2 |} = | G 1 |, then and Eq. (3) becomes sim  X  G 1 ; G 2  X  6 if min{| G 1 |,| G 2 |} = | G 2 |, then j G 2 j j G and Eq. (3) becomes sim  X  G 1 ; G 2  X  6
As an example of the similarity of two SRG X  X , consider Fig. 5 c the MCS of the two derived SRG X  X  G
G in Fig. 5 a and b. The size of G 1 is 21 (=4 + 15 + 2), where these three numbers come from the number of vertices, the number of arcs, and the number of embedded vertices, respectively. In the same manner we can obtain that the size of G 2 is 21 (=5 + 15 + 1), and the size of G the two SRG X  X  is sim ( G 1 , G 2 ) = 12/(21 + 21 12) = 0.4.

However, the size of the union of two derived SRG X  X  does not hold the property of the set union by stan-dard Venn diagram. That is, | G 1 [ G 2 | is not always equal to | G but also by the numbers of arcs and embedded vertices, where the number of embedded vertices is estimated by the self-loops in a calculated SRG such as G 1 [ G 2 or G ded vertices is conservative; hence in some cases the estimated number does not comply with the real spatial arrangements of the objects. Fig. 6 shows three cases that | G | G |+| G 2 | | G 1 \ G 2 |, respectively.

Since the numbers of objects in these four images are all 4, the size of their derived SRG X  X  are all 4 + 4(4 1)/2 = 10. From Fig. 7 we can calculate the sizes of the intersections as j G 1 \ G 2 j X  1  X  3  X d X  1  X 
G 1 \ G 3 j X  1  X  5  X d X  1  X  j G 1 \ G 4 j X  1.

Also, the sizes of the unions are | G 1 [ G 2 |=1+9+4=14, | G 1 [ G 3 |=1+7+4=12,and | G 1 [ G 4 | = 1 + 12 + 5 = 18. Therefore, | G 1 [ G 2 | (= 14) = | G 1 |+| G 2 | | G 1 \ G 2 | (=10 + 10 6 = 14), | G 1 [ G 3 | (= 12) &gt; | G 1 |+| G 3 | | G 1 \ G 3 | (=10 + 10 9 = 11), | G 1 [ G 4 | (= 18) &lt; | G 1 |+| G 4 | | G 1 \ G 4 | (=10 + 10 1 = 19).

The reason why the efficiency of SRG model is quadratic is that SRG model does not try to find the asso-ciations of the objects between two images, even when some object symbols duplicate. Recall that the worst-case time complexity is exponential when we intend to obtain a mapping of objects between two images.
Henceforth, unlike the methods in [8,11] , the duplications of object symbols do not degrade the efficiency of SRG model. Furthermore, in SRG model the similarity of two images is accumulated by all type-i similar object pairs, thus no spatial similarity contributed by object pairs will be ignored. 4. SRG T : retrieve also by topological relations The spatial relations between a pair of objects include directional relation and topological relation [8] .
Egnehofer and Franzasa [7] defined eight fundamental topological relations: disjoint, meet, contain, inside, overlap, cover, covered by, and equal as shown in Fig. 8 . Notice that disjoint, meet, overlap, and equal are and cover is the complement of covered by , e.g., if A contains B then B is inside A.
The directional relation between two objects is formed by the pair of centroids. However, in some cases two object pairs in both images may have the same directional relations but different topological relations as graphic information systems, topological relations are important information for discriminating images.
In SRG T , two kinds of arcs are induced by each pair of objects in the original symbolic image. The first arc NW(3) A NW(6) resented by one relation. For example, in Fig. 9 a we only make an arc labeled  X  X  X ontain  X  from vertex  X  A  X  X o SRG T is the same as the number of the directional arcs. And the total number of the arcs in a derived SRG is twice as that in a derived SRG for the same symbolic image.
 As in SRG model, the number of embedded vertices is estimated conservatively. For the calculated SRG (the MCS of two SRG T graphs), we use the maximum value of directional and topological self-loops to sub-stitute into the expanded equation in Lemma 1 to assess the number of embedded vertices of the concerned vertex. We choose the maximum number of the two kinds of self-loops because we intend to estimate  X  X  X t least  X  how many objects are involved in making these directional or topological common patterns. At last, the process of finding the similarity of two images through SRG hence the time complexity of SRG T model is also quadratic. 5. Experimental results In order to verify the efficiency and the effectiveness of the proposed models SRG and SRG sets of experiments. Experiment 1 uses a synthetic dataset to record the average comparison time of four meth-ods, LCS_Clique, SIM R , 2D Be-string, and SRG model for observing their efficiencies. Experiment 2 employs a well-known image database used in the Simplicity System [28] , and the retrieval qualities of the above four methods and of SRG T are compared. The methods were all implemented in C++ language and were run on a 5.1. Experiment 1
A comparison is defined as the process of calculating the similarity degree between two images. The syn-thetic dataset consists of 1000 symbolic images, and each image is represented by a collection of objects with class symbols, x -axis/ y -axis coordinates, and boundaries. The location of each object is generated randomly within an 800 600 image area. To observe how the number of objects in an image can affect the performance of image comparisons, we equally divide the 1000 images into five groups, and the images in the same group have the same number of objects. The number of objects is increased by five from group 1 with 10 objects; therefore the images in group 5 have 30 objects.

The images in each group are equally divided into four subgroups according to their symbol duplication rates, and these rates are 0%, 20%, 40%, and 60%; hence each rate in a group contains 50 images. The distri-bution of symbol duplication within each rate is random. For example of the rate 20%, an image may have 20% of objects with symbol  X  A  X  whereas another image may have 10% of  X  A  X  and 10% of  X  B  X . The purpose of designing symbol duplication is to simulate the real-world behaviors of symbolic image databases since symbol repetitions occur frequently in real-world applications. A well-designed retrieval method is supposed to have steady average comparison time under varying duplication rates.

Every image is taken in turn as the query image to be compared with all the images in the same group are very similar to or even the same as the query image. The average comparison time for each group is obtained by averaging all the comparisons occurred within a group. The similarity criteria of LCS_Clique and SRG modelare both set to be type_1. Also we release the restriction of symbol exclusion for SIM it calculate the similarity degree of two images by using the maximal similarity of all possible matching.
From the results in Table 1 we can see that the average comparison time of SRG model rises smoothly when the number of objects increases. More precisely, the measured data show that SRG has quadratic com-parison time. For example, the average comparison time of the group with 20 objects (0.51 ms) is about four finding the maximal clique in a graph with a large number of vertices is time-consuming in theory and in prac-tice. The symbol duplication also makes the efficiency of SIM
The reason is that for images with higher symbol duplication rates and larger numbers of objects, the numbers of all possible matching grow in exponential speed. Although the time complexity of 2D Be-string is quadratic, its measured average comparison time is about 20 times as that of SRG. It is because 2D Be-string needs to calculate two tables ( x -and y -string) by modified dynamic-programming, and each table has about 16 n to compute, where n is the number of image objects.

Table 2 shows the average comparison time of the four methods in the group of 25 objects, under four levels of symbol duplication rate. We can see that SRG model outperforms other methods in all cases except in 0% of SIM R . Besides, it is obvious that the average comparison time of 2D Be-string and SRG model are inde-pendent of the symbol duplication rate, but SRG is about 20 times faster than 2D Be-string, as already shown well-known methods. Hence SRG model is especially suitable for the applications that have images with dupli-cated objects. 5.2. Experiment 2 aborigines, beach, ancient building, bus, dinosaur, elephant, flower, horse, mountain, and foods in the dish, respectively. Each image is preprocessed by us by a software-aided method with human intervention to rec-ognize the symbol, position, and boundaries of each object. For example, the objects (areas) recognized in image 860 (in left most of Fig. 10 ) are sky, cloud, mountains, water, land, and people. The number of objects in an image varies from 5 to 24 with average 13.2, and the symbol duplication rate in an image varies from 0% to 82% with average 37%.
 For the five methods including LCS_Clique, SIM R , 2D Be-string, SRG, and SRG query in turn to be compared with all the images in the database. Fig. 10 shows the top 8 retrieved images similar to image 860 by the expert and the five compared methods.

The R norm measure is used to assess the ranking quality here, which is also utilized by many similarity image images are relevant a bit as long as they have one or more common objects. Thus any two images are  X  X  X ele-vant  X  if their similarity degree is not zero. However, we cannot say two text documents are relevant only if they have one common keyword.
 0.0 to 1.0, and the higher values are for higher retrieval qualities. R the list produced by domain expert; S is the number of image pairs that are in the opposite order as those in the list of domain expert; and S  X  max is maximum possible number of S please refer to [1] or the appendix of [11] .

For each query image, a retrieval method produces a ranked list for the query, which will be compared with another ranked list given by an expert. The average R norm isons generated by each of the five methods.

The intention of this experiment is not to compare the absolute R we intend to verify that under the same environment whether the proposed models SRG and SRG patible with other well-known methods in retrieval quality. Although the efficiencies of the proposed models intend to avoid.
 However, we can still observe that the average R norm values of the compared methods are all very close. Among these, the lowest value is of 2D Be-string. The possible reason is that the similarity degree of 2D
Be-string is the linear combination of two independent 1D results as mentioned earlier. Most important, it can be seen that the average R norm value of SRG T is improved over that of SRG and is almost the same as that of LCS_Clique.

Although in an SRG or SRG T graph, multiple objects with the same symbol are represented as a single vertex, we can still find that R norm values of the proposed models are compatible with those of the compared methods. The possible reasons are stated as follows. Firstly, the numbers of invisible embedded vertices in a calculated SRG (the MCS of two SRG X  X ) are not ignored; they are estimated through Lemma 1 . Therefore, the terns are accumulated by counting the number of arcs in the MCS, hence the existing spatial relations are all included. Besides, SRG T improves SRG since it considers topological similarity further. The last column of Table 3 is the average comparison time of the five methods. This result confirms those of 100-fold speed up on average over other methods except SRG due to the extra management of topological information, it has compatible retrieval quality and 60 times speed up on average compared with LCS_Clique.

As mentioned above, the R norm values are calculated by comparing the ranked list from retrieval method and that from domain expert. We introduce another measure called average ranking percentile [23] , which does The average ranking percentile is defined as: We can see from Table 4 that the AP values of SRG and SRG age for a given query.
 6. Conclusion
The main characteristics of the proposed models are their simplicity and efficiency. This paper proposed a graph-based model SRG and its extension SRG T for similarity retrieval of symbolic images, which compare images by the contained objects and their spatial similarity. The time complexity is quadratic in terms of the number of image objects by analysis, and the efficiency has been verified by the experimental results. By con-structing the spatial relation graphs (SRG) of the compared images, the similarity degree of these two sym-bolic images is efficiently assessed by calculating the size of the maximum common subgraph of the two derived SRG X  X . SRG T as the extension of SRG considers topological relations as well as directional relations. The results of the conducted experiments show that the efficiency of SRG and SRG
Therefore, the proposed models are especially suitable for the applications with the images containing dupli-posed models is compatible with the three compared well-known methods. Future research directions include the addition of rotation invariance to the SRG model, and the study of fuzzy comparisons of object symbols and spatial relations.

References
