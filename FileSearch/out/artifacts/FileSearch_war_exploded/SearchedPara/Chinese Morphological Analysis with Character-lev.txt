 In recent years, t he focus of research on Chinese word segmentation, part -of -speech (POS) ta g-ging and parsing has been shifting from words toward characters . Cha racter -based methods ha ve shown superior performance in these tasks compared to traditional word -based methods ( Ng and Low, 2004; Nakagawa, 2004; Zhao et al. , 2006 ; Kruengkrai et al. , 2009 ; Xue, 2003 ; Sun, 2010 ) . S tudies investigating the morphological -level and character -level internal structures of words , which treat character as the true atom of morphological and syntactic processing, have demonstrated encouraging results ( Li, 2011; Li and Zhou, 2012; Zhang et al., 2013 ). This line of re search ha s provided great insight in revealing the roles of characters in word formation and syntax of Chinese language.

However, existing methods hav e not yet full y ut ilized the potentials of Chinese characters. While Li (2011) poi nted out that some characters Table 1. Character -level POS sequence as a more specified version of word -level POS: an example of verb . can prod uctively form new words by atta ching to existing words, the se characters c onsist only a portion of all Chinese charac ters and appear in 35% of the words in Chinese Treebank 5.0 (CTB5) (Xue et al., 2005) . Zhang ( 2013 ) took one step fur ther by investigating the character -level str uctures of words; h owever, the machine learning of inferring these internal structures r e-lies on the character form s , which still suffer s from data sparseness. 
In our view, since each Chinese character is in fact created as a word in origin with complete and independent meaning , i t should be treated as the actual minimal morphological unit in Chinese language , and therefore should carry specific part -of -speech . F or exam ple, the character  X   X   X  (beat) is a verb and the character  X   X   X  (broken) is an adjective . A word o n the other hand, is either single -char acter , or a com pound formed by si n-gle -charac ter words . For example, t he verb  X   X   X   X  (break) can be seen as a compound formed by the two single -character words with the co n-struc tion  X  verb + adjective  X  .

Under this treatment, we observe that w ords with the same construction in terms of character -level POS tend to also have similar syn tactic roles. For example, the words having the co n-struction  X  verb + adjective  X  are typically verbs, and those having the construction  X  adjective + noun  X  are typically nouns , as shown in the fo l-lowing examples : This suggests that character -level POS can be used as cues in predicting the part -of -speech of unknown words.

Another advantage of character -level POS is that, the sequence of character -level POS in a word can be seen as a more fine -grained version of word -level POS. An example is shown in T a-ble 1. T he five words in this table are very likely to be tagged with the same word -level POS as verb in any available annotated corpora, while it can be common ly agreed among native speaker s of Chinese that the syntactic behaviors of these words are different from each other , due to their distinctions in word constructions . For example, verb s having the construction  X  verb + noun  X  (e.g.  X  X  X  ) or  X  verb + verb  X  (e.g.  X  X  X  ) can also be nouns in some context , while others can no t; A nd verbs having the constructions  X  verb + adjective  X  (e.g.  X  X  X  ) require exact one object argument , while others generally do not . Therefore, co m-pared to word -level POS, the character -level POS can produce information for more expre s-sive features during the learning process of a morphological analyzer.

In this paper , we investigate the usefulness of character -l evel POS in the task of Chinese mo r-phological analysis . We propose the first tagset design ed for the task of character -level POS ta g-ging, b ased on which w e manually annotate the entire CTB5 . We propose a method that performs character -level POS tagging jointly with word seg mentation and word -level POS tagging. Through experiment s , we demonstrate that by introducing character -level POS information, the performance of a baseline morpho logical analy z-er can be significantly improve d .

Table 2. Tagset for character -level part -of -speech tagging. The underlined characters in the examples correspond to the tags on the left -most column. The CTB -style word -level 
POS are also shown for the examples. We propose a tagset for the task of character -level POS tagging . This tagset con tains 16 tags , as illustrated in Table 2 . The tagset is designed by treating each Chinese character as a single -character word , and each (multi -character) word as a phrase of single -character words . S ome of the se tags are directly derived from the commo n-ly accepted word -level part -of -speech, such as noun, verb, adjective and adverb. It should be noted that , for single -character words, the diffe r-ence between adjective and adverb can almost be ignored , because for any of such words that can be used as an adjective, it usually can also be used as an adverb. T herefore , we have merged these two tags into one . 
On the other hand, some oth er tags are d e-signed specifically for characters , such as tran s-literation , sur name, prefix and suffix . Unlike some Asian languages such as Japanese, there is no explicit character set in Chinese that are used exclusively for expressing names of foreign pe r-sons , places or organizations. However, some characters are used much more frequently than others in these situation s . For example, in the person  X  s name  X   X  X  X  X  X  X   X  ( X rp X d) , all the four characters can be frequently observed in word s bold lines.
 of transliterations. Similarly, surnames in Ch i-nese are also drawn from a set of limited number of characters. We therefore assign specific tags for this kind of character sets. The tags for pr e-fixes and suffixes are motivated by the previous studies (Li, 2011; Li and Zhou, 2012).

We have annotated character -level POS for all word s in CTB5 1 . Fortunately, character -level POS in most words are independent of context , which means it is sufficient to annotate word forms unless there is an ambiguity. The annot a-tion was conducted by two persons, where each one of them was responsible for about 70% of the documents in the corpus. T he redundancy was set for the purposes of style unification and quali ty control , on which we find that the inter -annotator agreement is 96.2%. Although the a n-notation also includes the test set, we blind this portion in all the experiments. 3.1 System Description Previous studies have shown that jointly pr o-cessing word segmentation and POS tagging is preferable to pipeline processing, which can propagate errors ( Nakagawa and Uchimoto , 2007; Kruengkrai et al. , 2009 ) . Based on these studies, w e propose a word -character hybrid model which can also utilize the character -level POS information. This hybrid model constructs a la t-tice that consists of word -level and character -level nodes from a given input sentence. Word -level nodes correspond to words found in the system X  X  lexicon, which has been compiled from training data. Character -level nodes have special tags called position -of -character (POC) that ind i-cate the word -internal position ( Asahara , 2003; Nakagawa , 2004 ) . We have adopted the 6 -tag tagse t, which ( Zhao et al. , 2006 ) reported to be optimal. This tagset is illustrated in Table 3 . Figure 2 shows an example of a lattice for the Chinese sentence:  X   X  X  X  X  X  X  X  X  X   X  (Chen Deming answers to journalists X  questions). The correct path is marked with blue bold lines. The upper part of the lattice (word -level nodes) re p-resents known words, where each node carries information such as character form, character -level POS , and word -level POS . A word that contains multiple characters is represented by a sub -lattice ( the dashed rectangle in the figure ) , where a path stands for a possible sequence of character -level POS for this word. For example, the word  X   X  X   X  (journalist) has two possible paths of character -level POS:  X  verb + suffix  X  and  X  noun + suffix  X  . Nodes that are inside a sub -lattice cannot be linked to nodes that are outside, except from the boundaries. T he lower part of the lattice (charac ter -level nodes) represents u n-known words , where each node carries a pos i-tion -of -character tag , in addition to other types of information that can also be found on a word -level node. A sequence of character -level nodes are considered as an unknown word if and only if the sequence of POC tags forms one of the cases listed in Table 3 . This table also illustrates the permitted transitions between adjacent character -level nodes. We use the standard dynamic pr o-gramming technique to search for the best path in the lattice. We use the averaged perceptron (Co l-lins, 2002), an efficient online learning algorithm, to train the model. 3.2 Features We show the feature templates of our model in Table 4 . The feature s consist of two catego ries : b aseline features, which are modified from the templates proposed in ( Kruengkrai et al. , 2009 ); a nd proposed features, which encode character -level POS information .

Baseline features: For word -level node s that represent known words, we use the symbols , and to denote the word form, POS tag and length of the word, respectively. The functions character of . If has only one character, we omit the templates that contain or indicate the current node and the previous node during a Viterb i search, respectively. For chara c-ter -level nodes, denotes the surface character, and denotes the combination of POS and POC (position -of -character) tags.

Proposed features: For word -level nodes, the func tion re turn s the pair of the cha r-a c ter -level POS tags of the first and last chara c-ter s of , and returns the sequence of character -level POS tags of . If either the pair or the sequence of character -level POS is ambi g-u ous, which means there are multiple pat hs i n the sub -lattice of the word -level node, then the va l-ues on the current best path (with local context) during the Viterbi search will be returned. If has only one character, we omit the templates that contain . For character -level nodes, the function returns its character -level POS. T he subscript indices 0 and -1 as well as other symbols stand for the same meaning as they are in the baseline features. 4.1 Setting s To evaluate our proposed method , w e have co n-ducted two sets of experiments on CTB5: word segmentation , and joint word segmentation and word -level POS tagging . W e have adopted the same data division as in ( Jia ng et al., 2008a; Jiang et al., 2008b; Kruengkrai et al., 2009; Zhang and Clark, 2010 ; Sun, 2011 ) : the trai ning set, dev set and test set have 18,089 , 350 and 348 sentences , respec tively. The models applied on all test sets are those that result in the best pe r-formance on the CTB 5 dev set.

We have annotated character -level POS i n-formation for all 508 ,768 word tokens in CTB5. As mentioned in section 2 , we blind the annot a-tion in the test set in all the experiments. To learn the characteristics of unknown words, we built the system X  X  lexicon using only the words in the training data that appear at least 3 times . We a p-plied a similar strategy in building the lexicon for character -level POS , where the threshold we choose is 2. Th ese threshold s w ere tuned using the development data. 
We have used precision, recall and the F -score to measure the performance of the systems. Pr e-ci sion ( ) is defined as the percentage of output token s that are consistent with the gold standard test data , and re call ( ) is the per ce ntage of t o-ken s in the gold standard test data that are reco g-nized in the output. The balanced F -score ( ) is defined as . 4.2 Experimental Results We compar e the performance between a baseline model and our proposed approach . The results of the word segmentation experiment and the joint experiment of segmentation and POS tagging are shown in Ta ble 5 (a) and Ta ble 5 (b), respectively . Each row in th e s e table s shows the performance of the corresponding system.  X  CharPos  X  stands for our proposed model which has been d e-scribed in section 3 .  X  Baseline  X  stands for the same model except it only enables features from the baseline templates.

The results show that , while the difference s between the baseline model and the proposed model in word segmentation accuracies are small, the proposed model achieves significant i m-provement in the experiment of joint segmentati -Table 6 . Comparison with previous studies on 
CTB5 . on and POS tagging 2 . This suggests that o ur pr o-posed method is particularly effective in predic t-ing the word -level POS , which is consistent with our observations mentioned in section 1.

I n Table 6 w e compare our approach with morphological analyzers in previous studies . The accuracies of the systems in previous work are directly taken from the original paper. As the results show, despite the fact that the perfo r-mance of our baseline model is relatively weak in the joint segment ation and POS tagging task, our proposed model achieves the second -best performance in bot h segmentation and joint tasks. We believe that by treating characters as the true atoms of Chinese morphological and syntactic analysis, it is possible to address the out -of -vocabulary problem that word -based methods have been long suffered from. In our error anal y-sis, we believe that b y exploring the character -level POS and the internal word structure ( Zhang et al., 2013 ) at the same time , it is possible to further improve the performance of morpholog i-cal analysis and parsing. We will address the s e issue s in our future work.
