 Peer-to-Peer (P2P) searc h requi res intelligen t decisions for query routing : selecting the best peers to which a given query , initiated at some peer, should be forwarded for re-trievi ng additiona l search resul ts. Thes e decis ions are based on statistical summ aries for each peer, which are usuall y or-ganized on a per-keyword basis and mana ged in a distributed directo ry of routing indices. Such architec tures disrega rd the possible correlations among keywords. Together with the coarse granularity of per-peer summari es, which are man-dated for scalabil ity, this limitation may lead to poor searc h resul t quali ty.

This paper develops and evaluat es two solutions to this prob lem, sk-ST AT based on single-k ey statistics only, and mk-STAT based on additional multi-k ey statistics. For both cases, hash sketch synopses are used to compact ly represent a peer's data items and are ecien tly dissem inated in the P2P network to form a decentralized directory. Experimen-tal studies with Gnutella and Web data demonstra te the viability and the trade-o s of the appr oaches.
 H.4 [ Information Systems Appli cations ]: Miscellaneous; H.3.3 [ Informati on Storag e and Retriev al ]: Information Searc h and Retrieval sele ctio n process, info rmatio n lter-ing ; H.3.4 [ Inform ation Storage and Retrieval ]: Sys-tems and Software Dis tribute d System s Algor ithms, Design, Experimentation Peer-to-Peer information systems , distribut ed IR, query rout-ing, key co-occurrences
Decen tralized search on top of peer-to-peer overlay ar-chitect ures is an intriguing researc h direction which aims to interconnec t many peers, each with its own local data collec-tion, and to utilize the aggregat ed resources of the underly-ing comput ers for decen tralized large-sca le search. The goal is to impro ve searc h result quali ty with unlimited scalabil ity and better capabilities for exploiting user behavior and rec-ommendations (e.g., click streams, bookmarks , etc.) [12, 43, 27, 24]. Applications for such a scenario are manifol d. Whil e early researc h was often driven by le sharing appli cations, where the searc h space typicall y consists of keywords con-tained in le names or manually given annota tions, today a huge amoun t of more challengi ng appli cation classe s are emergi ng. Consider a photo sharing comm unity that -free of commercial interests -wants to pool and searc h persona l snapshot s, e.g., taken at holida y sites. The search space in this scenario includes the examples given before, but also high-dimensi onal space image features, user annotations, or automaticall y generated anno tations, e.g. GPS coordinates.
As another scenario, we envision P2P Web searc h engines with thousands or millions of peers. The data shared by the data peers may be web pages harvested from Web crawls or speciali zed data collections. Here, the search space typically consists of keywords (or terms in IR jargon). Each peer autonomously builds and maintains its own topic-specic or personalized documen t collection that reect s the user's thematic interests; this could be done, for example, by using a focused crawler with a specically trained classi er.
When a peer issues a query , it shou ld rst be execut ed locally on the peer's own collection. Only when this local searc h does not return satisfacto ry or suciently many re-sults, the system can contact directory peers that -by fully decen tralized means, such as distributed hash tables -main-tain summ aries descri bing the local data collections of the data peers. Eventually, the query should be forwarded to a small number of judiciousl y chosen data peers that would have high likelihood of providing highly relevant additional resul ts. This query rout ing decisio n (aka. dynami c peer or database or resourc e selection) is the very core of a P2P searc h engine.

The selection of the most promising peers for a query with multiple keywords or attribute-values is driven by statisti-cal summaries that the P2P system keeps about the peers' local data collections. These summaries are themselves dis-tribut ed across the P2P network and can be managed in a variety of ways, e.g., in the form of routi ng ind ices stored at each peer [16, 27, 42] or in the form of a P2P directory built on top of a distributed hash table (DHT) (e.g., [1, 17, 37, 34]) or other kind of overlay network. For scalabili ty, the summaries have peer granularity, not data item granular-ity; so they capture, for exampl e, the best peers for certa in keywords, attribute values, or topics, but not the best spe-cic data items . Moreo ver, the summaries are usually orga-nized on a per-keyword (or per-attribute-value) basis, indi-cating how good a peer's collection is for a given keyword. For tractabil ity, there is no informat ion about keyword sets, phra ses, or other forms of correlation between multiple key-words. This limitation to per-ke y peer summari es seems unavoidable, for statistics on all keyword pairs would in-cur a quadratic explosion and a challenging issue of dis-tribut ed parameter estimation over a very-high-d imensi onal and extremel y sparsely populat ed feature space, leading to a breac h with the goal of scalability. On the other hand, completely disregarding correl ations among keys is a ma-jor impedim ent: togeth er with the restriction to peer rather than documen t summaries, it may lead to poor search result quali ty in the P2P setting.

In the following we refer to indiv idual keywords or values as key s and to key combinat ions that exhibit correlation or other mutual relationships as key sets . Note that deali ng with key sets in queries and routing indices is dierent from distributed searc h structures for partial-mat ch queries [4, 29], as the latter is limited to low-dime nsional spaces with xed dimensions, wherea s in our setting, arbitrary sets of keys from a very-high-d imensi onal feature space may appear together in a query.

The above dilemma is illustrat ed by the following exam-ple. Consi der two-or three-keyword queries such as Anna Kournik ova, native American music, or PhD admission. A stand ard approac h would decomp ose each query into indi-vidual keywords such as native, Ameri can, and music, identify the best peers for each of the keywords separat ely, and nall y combine them (e.g., by intersect ion or some form of aggregat ing the summ ary scores) in order to deriv e a can-didate list of peers to which the query should be forwarded. This approach may lead to medi ocre query results as the best peers for the entire query may not be among the top candidates for the individual keywords. In a worst case sce-nario, these peers might not have a single data item that matc hes all keywords at once. Hence, we miss out on the fact that, for example, PhD and admis sion are statisti-cally correlated in the underly ing corpora and that the best matc hes for the entire query shou ld exhibi t a higher-than-average frequency of both keywords.
In this paper we develop and evaluate two concept ually diverse approac hes to address the above stated problem : sk-STAT , using the already existing single-k eyword statistics to estimate a peer's quality for key sets, and mk-STAT , en-hanc ing the distributed directo ry to explicitly include also statistical information about judiciousl y chosen sets of mul-tiple keys.

Our methods can be used with a large variety of P2P overlay networks, including DHT s but also arbitrary graph topologies with reques ts being routed among peers based on peer-local routing indices. In the DHT case, the statisti-cal information that drives our query routing covers the en-tire P2P network, and is stored in a decen tralized director y that is physically imple mented by the DHT. In the routing-indices case, the statistical information known to one peer covers the peer's neighbors or some ecien tly reachable sub-graph of the network (e.g., all peers reachable from the near-est super-peer), and is stored locally at the peer itself. For easier presen tation, we will restrict oursel ves to the DHT case in the rest of the paper.

Whil e mk-ST AT in principle is the more powerful metho d, it faces the necess ity to identify those valuable key sets that are most likely to enable impro vemen ts, as it is practically infeasi ble to build and disseminate statistics for all possible key sets for combinato rial compl exity. Instead, the discovery of interesting key sets is initiated by mining locally gathered query logs, to impro ve the performance of frequen tly queri ed key combinations. This discovery phase can optionally trig-ger an in-dept h statistical analysis of the correlations within the peers' data collections. One of the paper's novel key con-tribut ions is how to make this analysis ecien t and scalable.
We show that our approac h is highly scalable by piggy-backing all network comm unication for gathering and dis-seminating statisti cal information on mess ages that need to be sent between peers anyway (for their regular query traf-c). sk-STAT, on the other hand, can readil y deal with all pos-sible key sets, as it only relies on combinat orial operations on the existing single-k ey statistics. However, it has higher band width requi remen ts at query time, as larger amou nts of these single-k eyword statistics have to be shipped to es-timate the statisti cs for key sets.

For both appro aches, we emplo y hash sketches (HS) [20] as compact synopses for capturing key-and key-set-specic col-lection quality, that we combine ecien tly for dierent keys and from dieren t peers in a distributed setting. The in-format ion gained is harness ed by the query routing process, utilizing the DHT infrastructure for eciency , and leads to signicantly better peer selection decisi ons for subse quen t queri es.

The compl ete procedure is fully impleme nted in the P2P searc h proto type system Minerva [7], and our experimen-tal studies demonstrat e the viability of the metho d and its performance impro vemen ts over the prior state of the art.
The rest of the paper is organized as follows. We con-clude the introduction with a brief overview of related work. Section 2 introduces background informat ion on distributed hash tables and hash sketches, major building blocks in both of our approa ches. Section 3 presen ts the system architec-ture for our correlation-aware P2P search network. Section 4 discuss es measures of key correlat ions. Sections 5 and 6 presen t our algorithms, sk-ST AT and mk-ST AT, for utilizing statistics on key sets to impro ve the query routing process. Section 7 discusses the scalability prop erties of our meth-ods. Section 8 presents experimental results with two major setups: one based on Gnutella-style le sharing data, one based on Web data. Section 9 concludes this paper.
In contrast to the early forms of unstru ctured P2P net-works based on message ooding and other forms of epi-demi c dissem ination, all structured P2P systems , e.g., for le sharing or sensor data managemen t, build on some form of routing indices or direct ories that are either kept locally at each peer or at designat ed peers [42, 24].

The latter can be chosen randoml y, hash-based, or based on attribut e range partitioni ng, and can be replicated if needed. The indices or directories contain peer lists with the best peers for indiv idual keywords or attribute values, known to the local peer or directo ry peer. If the network topology can be inuenced, some of these best peers may be chosen as the local peer's neighbors. A variant of this predominan t approa ch is that peers are classi ed into topics (e.g., Jazz music or Alpine climbing) and thematic related peers form neighbors of a semantic overlay network [16, 39, 14, 40, 36, 2]. Recen t work has addressed performance trade-os and optimizat ion issues for building and main tain-ing routing indices [42, 24, 27, 16].

Recen t work on P2P IR is related to earlier research on distributed IR and metasearch engines [12, 32], but older work assume d a small and static set of collections among which a query had to choose. In contrast, P2P systems consider a much larger scale and also face high dynamics, which rules out comprehensi ve and compl ex statisti cal mod-els for query routing. The most important routing methods in the literat ure are COR I [13], simple forms of statistical languag e models [35, 30], the decisi on-theoretic framew ork (DTF ) [21], and the overlap-a ware metho d [6, 33].
All of the above metho ds organ ize the statistics about peers, which drive the query routing decisions, on a per-term basis and thus disrega rd term correlations. The only recen t works that consi der term correlations in the context of P2P searc h are [8] and [3]. [8] only consi ders frequen t key combinations in query logs, does not consi der data statistics, and uses simple techniques for disseminating statistics in the network, with a very preliminary performance study. [3] prop oses a frame work for discriminativ e keys, which includes correlated term combinations; however, it does not give any algorithms for mana ging the corresp onding statistics in a distributed setting and for correlation-aware query routing.
Synopses for compact appr oximation of sets, multisets, and their statistical prop erties have recently received atten-tion in the context of sensor networks, data streams , content delivery, and estimation issues in structured databases [15]. The meth ods under consideration include Bloom lters [9], hash sketches [20], and min-wis e indep endent permutations [11], all of which are hash-based but dier in their strength s and limitations of representing various kinds of properties. The latter include set membership testing, set cardinality estim ation, estimating the number of distinct elemen ts in a multiset, forming intersect ions, unions, dierences, etc. Overlap-a warenes s in P2P IR has long been overlooked, with the except ions of [23] and the recen t work in [33], which fo-cuses on utilizing such synopses for estim ating the overlap of the data collections at dieren t peers.
Distributed Hash Tables, DHT s, (such as Chord [37], CAN [34], Pastry [17], etc.) have emerged as the preferred family of struc tured architect ures for overlay P2P networks. The main advantage of DHTs compared to unstru ctured P2P networks stems from the performanc e guara ntees that they can oer regarding the routing eciency and ultimately the network scalabil ity, even in the presence of high network dynami cs (such as high rates of node arrivals/departu res and failures/reco veries). DHTs oer two basic prim itives: ins ert(key , value) and lookup (key ) . DHT nodes and data items are assigned unique IDs. The node IDs dictate the place occupied by the node in the overlay topology . Each node is responsibl e for a well-dened subspace of the items' ID space. Each item is stored at the node responsible for the subspace containing the item's ID. To facili tate ecient and scalable routing, each node in an N -node DHT main tains the IP addresses (aka ngers) to O (log( N )) 1 other nodes in appr opriate positions in the overlay. With this O (log( N )) routing state at each node, DHTs guaran tee that routing be-tween any two nodes requi res an expected O (log( N )) mes-sages.
Flajolet and Martin in [20] prop osed Hash Sketches; a statistical tool for proba bilistically estimating the cardinal-ity of a multise t S (i.e., to count the number of distinct items in a multiset). Hash sketches rely on the existence of a pseudo-uniform hash function h () : S ! [0 ; 1 ; : : : ; 2 which spread s input values pseudo-un iformly over its output 1 All log( ) notation refers to base-2 logarithms. values . Durand and Flajolet further impro ved hash sketches [18] ( super-L ogLog counting ) by reducing the space comple x-ity for maintaining hash sketches and relaxi ng the require-ments on the statistical prop erties of the hash function.
In their essence, hash sketches work as follows. They use the function ( y ) : [0 ; 2 L ) ! [0 ; L ) which designat es the position of the least signican t 1 -bit in the binary represen-tation of y ; that is, and (0) = L , where bit ( y; k ) denot es the k -th bit in the binary represe ntation of y (bit-position 0 corresponds to the least signica nt bit). Estimating n , the number of distinct elemen ts in a multise t S , proceeds as follows. For all d 2 S , apply ( h ( d )) and record the least-signicant 1 -bits in a bitmap vector B [0 : : : L ] . Since h () distributes values uni-formly over [0 ; 2 L ) , it follows that
With the above process, note that in the bit vector B hosting the hash sketch, B [0] is expected to be set to 1 n= 2 times , B [1] n= 4 times , etc. From this follows that the quan tity R ( S ) = ma x d 2 S ( d ) constitutes an estimation of the value of log n . The statistical error can be reduced to very small quantities by utilizing multiple bit vectors B recording ( h ( d )) for some item d 2 S to only one of the vectors B i , producing an R i estim ate for each vector B and averaging over the R i estim ates; the standard deviation of this estim ation is 1 : 05 p m , for m bitmap vectors[18].
A key prop erty of hash sketches with great implications for the eciency of large-scale network applications (includ-ing distributed IR) lies in the ability to combine them. We can deriv e the hash sketch of the union of an arbitrary num-ber of multisets from the hash sketches of each multiset by taking their bit-wise OR . Thus, given the compact hash-sketch based synopses of a set of multisets, one can instantly estim ate the number of distinct items in the union of these multise ts.

More formally, we can claim that, if ( S ) is the set of bit positions ( h ( d )) for all d 2 S , then ( S 1 [ S 2 ( S 1 ) [ ( S 2 ) . Notice that, if both original collections carry a random document, the documen t will conceptua lly be counted only once, eectively providing dupli cate-insensi tive (i.e. distinct item) counting for the union of the original multise ts.

Furtherm ore, hash sketches can be used to estimate the cardinality of the intersection (overlap) of two sets. First, recall that
Second, one can derive the hash sketch for S A [ S B , and thus comput e the cardinal ity of j S A \ S B j by utilizing the combination method outlined above,
The above can be genera lized to more than two sets, using the inclusion-exclusi on principle and the sieve form ula by Poincar X  and Sylvester:
Table 1 summarizes the notation we will be using through-out the rest of this paper.
The operational environmen t is a P2P-based searc h en-gine. Every peer builds local collections and local per-key index es, (and perhaps also combining data from externa l sources), according to the user' s thematic pro le. We shall refer to such peers as the data peers . The local per-key in-dexes consist of inverted lists of data items relev ant to the corresponding key. Because the peers are functioning in-dependen tly, it is expected that there will be considerable overlap in the data collections (e.g. the set of data items known to indiv idual peers) and (consequen tly) in the in-dexes maintained by dieren t peers.

Dir ecto ry peers are responsible for maintaining very com-pact, aggregated meta-informat ion about the peers' local index es (to the extent that the indiv idual data peers are willing to share). Naturall y, each data peer can potentially also be a directo ry peer. More specically, each director y peer is responsibl e for the meta -information from all over the network regarding a random subset of all keys. For per-formanc e and fault tolerance reasons, the directory meta-data for a key may be replicated across multiple director y peers. A DHT is used to connect all (direct ory and data) peers. The DHT's lookup metho d can be used to determi ne the peer responsible for a particular key, in order to send information or retrieve information about this keyword.
Every data peer publishes per-key summ aries describi ng its local index to the distribut ed directory; these summaries will be referred to as Pos ts . The DHT's lookup meth od de-termines the direct ory peer curren tly responsible for a key, which main tains a PeerLis t, i.e., a list of all data peers' Posts regard ing this key. Posts contain contact information about the publi shing data peer, toget her with statistics to calcu-late quality measures for a key (e.g., frequencies or IR-st yle scores). Note again that this information does only capture the overall quali ty of a peer's index for a particular key, but does not represen t indivi dual data items . Typically, such statistics include the length of the inverted list for the key, the maximum and average score among the key's inverted list entries, etc. These statistics are used to supp ort the query routing process, i.e., determi ning the most promi sing peers for a particular query . Specica lly, the size of the in-verted list for a key that is, the frequency for key a at peer i , or df i ( a ) can be main tained in the form of a hash sketch; for each data item in p i 's collection regarding key a , the peer insert s an identier into a local hash sketch for this key, denoted HS i ( a ) .

Since there is a well-den ed directory peer responsibl e for each key, the hash sketch synopses represen ting the index lists of all peers for a particular key a are all sent to the same direct ory peer p ( a ) . Thus, p ( a ) can compute a moving-window estim ate for the global df value of a df ( a ) by performi ng an inexpensive bitwise-OR of all individual hash sketches HS i ( a ) sent by every peer i for term a . To deal with the high dynamics in a P2P network, each Post is assigned a Time -to-Live (TTL) value. If the orig-inato r peer has not updated (refreshed) its Post after this time interval, it is discarded. On the other hand , if a peer's metada ta has not changed in the mean time, it can refresh its metada ta by simple means, witho ut resending it comple tely.
Given the above, in general, query routing for a single-k ey query a proceeds as follows. First, the query initiator issues a request for the Posts regar ding the query key a to the underlyi ng overlay network, thus contacting the director y peer for the key, p ( a ) . After the retrieval of this PeerLi st and its associated information, the query initiator uses the per-key statistical summ ary to identify a set of promis ing data peers for the given query and forwards the query ac-cordingly. Eventuall y, the query initiato r merges the query resul ts individuall y returned by the selected data peers.
The state-of-the-art idea to deal with multi-key queries is to consider the intersection of the PeerLists for the query keys, i.e., to send the query only to (a subset of) data peers that indeed publi shed statistics for all queri ed keys. How-ever, this appro ach may fail miserably. A peer appearing in both PeerLi sts for a and b and, thus, in the intersect ion of Posts for the keys a and b , is only guaran teed to have data items regarding a or b separat ely, but not necessari ly data items regard ing both a and b simultaneousl y. To illustrate this point, consider the following extreme scenario. Assume peer p 1 containing a large number of data items for each of the two keys a and b separat ely, but none that contains both a and b together. Judg ing only by the posted single-key statistics for a and b , we might reach the conclusion that p 1 is a good candidate peer for the query ab , whereas the actual result set would be empt y!
Sections 5 and 6 present two dieren t approaches to over-come this problem, striking dieren t compromis es: while sk-STAT tries to estim ate the desired multi-k ey statistics from the existing single-k ey statistics with additional com-putational eorts and at higher networking costs, mk-STAT enhan ces the distributed directory by adding explicit statis-tics for judiciousl y selected key sets, namely, those that ex-hibit particularly high correlation or other forms of strong association among the individual keys in the key set. The choice of an appropriate correlation meas ure is the topic of the next section.
In this section we introduce the measure for capturing relatedness among the keys of a key set, co-occurring either in a query or in a data item, and we develop the correlation model that will drive the extended synop ses constr uction and query routing as explained in the subse quen t sections. We will restr ict ourselves to key pairs, as we expect the major benet when we move from single keys to correlated pairs.

The obvious choice for stand ard measures like the corre-lation coecient has the drawbac k that its estim ation re-quires knowledge (or an estimate) of the total number of data items in the network. Moreover, we may encoun ter situations where it is important to capture that key b is re-lated to key a , but the reverse direct ion is uninteresting. For exam ple, in popular Web queries the term soccer often im-plies that the same query contains also the term German y (because of the soccer world championshi p taking place in Germ any), but the reverse direction has a much weaker as-sociation from a user viewpoint. This discussion motivates considering the conditional probabili ty that a rando m data item contains key a given that it contains b , an asymm et-ric measure of relat edness, for which we have the following estim ator: where and df ( a [ b ) can be estimated by taking the bitwise OR of HS ( a ) and HS ( b ) (see Section 2.3). Obviousl y, a nice prop erty of this measure is that we can estimate it without knowing (or estim ating) j D j .

A design dimensi on orthogon al to the issue of which cor-relation meas ure we choose is the consideration of key sets in queries vs. data items . Both queries and data are sourc es of interesting correlations. For queries we can collect, either lo-cally at each peer or globally partitioned based on the DHT, comprehensiv e query logs and apply frequent itemset mining techniques [5, 19] so as to extract statisticall y signi cant key sets that exhibit a high degree of mutual association among their keys. We will show in Section 6 that such techniques are feasibl e within our P2P architecture withou t incurring extra comm unicat ion costs. For data items, a similar ap-proach is conceiv able but it may be more dicult to imple-ment without incurring extra messages. Moreover and most importantly, we are not really interested in correlated keys within data items per se, unles s there are actually queries about these keys. Thus, we pursue a two-sta ge approac h: 1. we discover correlated key pairs in queries as an indica -tion that special supp ort for such key pairs may be needed and justied; 2. we assess the identied key pairs as to their relatedness in the data items and take special action only if both the discovery and the assessment step are positive for some candidate key pair.

In the disco very step, a key pair is of interest if it is su-ciently frequent and its correlation is high in the query logs. Using the conditional probabil ity estimator of Equation 5, we identify the key pair ( a; b ) as interesting if either one of ^ P ( A j B ) or ^ P ( B j A ) is above some specied threshold .
In the assessment step the question is when a key pair, identied in the discovery step, deserves special action for posting statistical summ aries to the distributed directory. At rst glanc e, it may seem that we can use the same prin-ciple as in the discovery step: select key pairs for which the conditional-proba bility estimate is above some threshold -with the estimate based on data, not on queri es. However, this intuition is awed. Supp ose that for keys a and b the es-timate ^ P ( A j B ) is close to one; so the keys are very strongly , positively correlated. Then the best peers for b alone are likely to contain key a , too. For high recall on these good matc hes for ab we do not need any special Posts; we can use the statistics for b alone. It is just the opposite situation where we need additional information to nd the best peers for a multi-k ey query : when the keys are either uncorrelated or exhibi t strong negat ive correlation. The latter situation is the most interesting one: when the two keys in a pair ab have negativ e correlation close to minus one, there are only few data items in the network that contain both a and b , and we cannot nd them by selecting and combining the best peers for a and the best peers for b alone.

The conclusi on from this discuss ion is that the asses smen t step considers a pair ab as interesting if both ^ P ( A j B ) and ^ P ( B j A ) are below some threshold (e.g., = 0 : 1 ) within the data items . Table 2 shows some conditional proba bility es-timates for popular Google queries 2 , based on a large collec-tion that we have crawled recen tly. If we set , for example, to 0.1 we would identify ("Berlin", "Marat hon" ) as a valu-able key pair, but would dismiss ("Anna" , "Kournik ova") as not suciently valuable, as the Post for Kou rnikova alone would suce.

We see that the discovery step and the assessm ent step have dieren t and complementar y goals: nding highly cor-related keys to identify demand for special supp ort in the discovery step; nding uncorrelat ed keys or negatively corre-lated keys in the data as such key sets would be very poorly supp orted by the standa rd single-key statistical metada ta and established methods for query routing. Note that, of course, the selection in the assessment step refers only to the candidates that were identied in the discovery step.
Recall that the Post for the index content of a peer p i re-garding a key a contains the hash sketch HS i ( a ) , represen t-ing the peer's set of local data items D i ( a ) . By the nature of the hash sketch synopses, the knowledge of HS i ( a ) and HS i ( b ) for two keys a and b provides a means for estimating the cardinali ty of the number of data items with at least one of the keys a or b , i.e., j D i ( a ) [ D i ( b ) j .
Moreover, using Equation 3 from Section 2.3, we can also estim ate df ( ab ) = jf d j a 2 d ^ b 2 d gj , and this generali zes to key sets with more than two keys using the sieve for-mula. So we can indeed deriv e vital information for multi-key query routing from the existing single -key statistics in the distributed directory.
 Consi der a peer p init initiating a query ab . In the sk-STAT approac h, fully relying on the existing single-keyword statistics, p init then can proceed as follows: 1. it contacts p ( a ) and p ( b ) to retriev e the statistical sum-maries publi shed individuall y for the keys a and b , includ-ing all hash sketch synopses produced by the data peers, 2. for each remote peer p i appearing in both PeerLists, p computes an estimation of df i ( ab ) , indicating p i 's possible contribution to the query , 3. p init possibly combines this meas ure with other indicators of p i 's result quali ty and novelty, and 4. p init forwards the query ab to these selected peers and eventually merges their local resul ts.

A major advantage of sk-STAT, compared to producing additiona l explicit multi-k ey statistics (as in the mk-STAT appr oach) is that the estim ations can readi ly be perfor med for all possible key sets in the direct ory, and not only to judi-ciousl y selected valuable key sets, because sk-STAT only re-lies on the existing single-k ey synop ses. On the other hand, some disadvantages of sk-STAT also become apparen t:
In order to nd the truly best peers for ab from the ex-isting single-k ey Posts for a and b , a peer proba bly has to retriev e and inspect the PeerLi sts for a and b at much higher depth, compared a multi-k ey appr oach where the prex of a potentially very long list would quickly give you (with high probabil ity) the best peers. The reason is exact ly the fact that there is often no strong correlation between keys in the data and thus no correlation between between the rank of a peer p in the PeerLists for a and b separat ely; so to identify with high condence the ranking of some peer p for ab requi res longer prexes of PeerLis ts if not the entire lists includi ng the hash sketches for every 2 http://www.go ogle. com/zeitgeist peer in each list. This eect leads to much higher network load on the directory peers and the query initiator. If, like in mk-STAT, there readily exist Posts for combined key sets like ab , eectiv e prun ing becomes easy by fetching only the top entries from the PeerList for ab .
 Whil e it is possible to estimate df ( ab ) from the existing
Posts (i.e., an integer value estimating the cardinali ty of the combined set), it is not possible to derive the hash sketch synopsis actually describi ng the data items of a peer p i for ab , as we are not aware of a way to meaningfull y intersect hash sketches. Applying the sieve form ula, on the other hand, may well degrade the accura cy of the estim ated cardinality (i.e., increase the variance of the estim ator).

In order to prop erly aggregate the hash sketches, in partic-ular for queries with more than 3 or 4 keywords, combining the hash sketches by the sieve formula requi res nontrivial local data structures and entails non-negligible computa -tiona l costs for the query initiator.

Our experime nts have shown that the resource consump-tion of sk-ST AT becomes a signicant cost facto r under high arriv al rates of queries .
The obvious idea to overcome the problem s of sk-ST AT is to learn valuable key sets that frequen tly co-occur (e.g., in the data items or in user querie s), create and disseminate statistical summ aries for those key sets explicitly , and har-ness this information in order to impro ve the query routing process. The core idea of mk-ST AT is, thus, given a query ab , we nd pre-prep ared statistics descri bing the peers' local index quality for ab .

To this end we need to explore: 1) how to discover can-didate key sets, 2) how to asses s whether the key-set cor-relation in the data justies the additional investmen t of multi-k ey Posts, 3) how to notify data peers about these key sets, so they can start to create and disseminate ap-prop riate statistics, and 4) how to leverage the additional multi-k ey statistics to improve the query routing process.
The motivation for disco vering key sets that frequently co-occur in query logs is to improve the search experience of actual users . Thus, it would be a waste of resources to creat e, disseminate, and store summaries for a key set that is never queri ed by a user. Conseq uently, we can limit our eorts for discovering key sets with strongly related keys to the key sets in actual queries . In real-w orld searc h en-gines , the distribut ion of queri es is highly skewed (i.e., a small fraction of distinct queries makes up a large fraction of the compl ete query load); so a careful choice of frequen tly queri ed key sets allow us to remarkably impro ve the searc h experience for many users with mana geable eort.

The query routing process outlined earlie r turns directory peers into rendezv ous points for key combinat ions of the keys they are responsible for, making query-dr iven discovery of frequently co-occurring key sets very eci ent:
When retrieving the Post for each query key q i from p( q have the query initiator also send the actual query , i.e., all query keys, to p ( q i ) .

Have the directo ry peers p ( q i ) keep a log of queri es they receiv e. The size of the query logs that need to be kept can be bounded by periodicall y applying frequen t-itemset mining techniques [5, 19, 22] and trunca ting the logs. For exam ple, a reques t for all Posts regarding the query Michael Jorda n would be sent to the two directory peers p(Micha el) and p(Jor dan) . Each of these would retur n its respective PeerList for the key it is responsible for and simul-taneousl y log the query locally. Analyzi ng these logs (e.g., by frequent itemset mining) , each directory peer can iden-tify key sets that appear in queries with a frequency that is above some supp ort threshold and/or that appear together above some condence threshold.
Discovery of key correlations on the basis of query logs alone is fully suci ent; after all, if there exist correlations among keys which are not (frequently) queri ed, they are of little conseq uence and the production and dissemination of appr opriate multi-key statistics is of no (immediate) use. However, mining query logs and main taini ng previ ously dis-covered key correlations in this way depends on a number of hard-to-tune thresholds (such as the support level of oc-currences of keyword tuples in order to be deem ed as truly correlated) and requi res non-negli gible local computa tions. Furtherm ore, only a subset of the correlated keys discovered in queries may signica ntly benet from additional multi-key statisti cs: as we discussed in Section 4, it is exactly the uncor related or negativ ely correlated keys that mandate multi-k ey statistics, whereas the keys with high positive cor-relation also in the data do not really need these additional Posts.

Assume the directory peer p ( a ) wants to assess the relat-edness between a and b based on the data items in the P2P network. For this purpose, peer p ( a ) proceeds as follows: 1. First, p ( a ) contacts p ( b ) to retriev e the overall hash sketch
HS ( b ) for key b . This step requires O ( logN ) message hops in an N -node P2P network, while the bandwidth con-sumption is minimal by the following technique: instead of shipping the individual hash sketch synop ses HS i ( b ) of each peer p i , the directo ry peer p ( b ) locally comput es the union of these hash sketches by bit-wise OR and transfers only one combined hash sketch representing df b . 2. Then, p ( a ) can compute the hash sketch representing the union of D a and D b by a simple bit-wise OR over the hash sketch synopses HS ( a ) and HS ( b ) , yielding an estimato r for the cardinali ty of the set consis ting of all data items in the system that contain either a or b (i.e., D ( a _ b )). 3. The cardinali ty of D ( ab ) (i.e. df ( ab ) , the set of documen ts that contain both keywords) can now easily be deriv ed using equat ion 6. 4. From this, p ( a ) can nally comput e the conditional prob -abilities P ( A j B ) and P ( B j A ) using equation 5.
The cond itional prob abilities (cf. Section 4) provide us with a means to quan tify the relatedness between two keys in the data and assess the utility of explicit key-set statistics. As discussed in Section 4, the query routing process bene-ts mostly from explicit knowledge of statistical summaries for uncorrelated or negatively correlated keys. On the other hand , if a key set shows high conditional probabil ities of co-occurr ence within the data items, e.g., P ( A j B ) &gt; , the single-key statistics readil y available for b alone already yield promis ing peers also for the key set ab exactly because the existenc e of b in a data item strongly suggests the existenc e of a . In other words, a high P ( A j B ) value is a heuristic to base query routing decisi ons on the statistics for b alone, the expected benet s from additional summari es for the multi-key set is small. Smal l P ( A j B ) values , in contrast, show that the occurrences of a and b in the data items is largely indep enden t or even negatively relat ed, so that query rout-ing decis ions can highl y benet from the existence of pre-computed multi-k ey statistics for ab . Thus, we initiate the creation of a multi-k ey summary for a key pair ab if both P ( A j B ) and P ( B j A ) are below some threshold (set, e.g., to 0.1).
Note that the quan titative degree of relatedness is not vital to mk-STAT. However, applying the thresholding can decrea se the load on the data peers and the direct ory by limiting the number of key sets identied as valuable for the query routing process even beyond our initial appr oach to learn the sets from query logs.
When a key set has been identied to be a valuable can-didate to produce multi-key statistics, the data peers need to learn this fact in order to produce the appropriate multi-key statistics. The easiest way of doing so is to use the con-tinuous process of Post refreshmen t, i.e., peers periodically updating their summaries in the distribut ed direct ory: For any key a , when contacting p ( a ) in order to update the Post, a data peer retriev es information about such valuable multi-key sets containing a . Rem ember from Section 6.1 that all applicable key sets containing a have been identied at p ( a ) and, thus, are available there. The data peer can subse-quen tly start to produce multi-key statistics for those key sets and publi sh it during the next round of updating the Post. This procedure has the salient prop erty that it does not incur any additional messages compared to the standard single-key-based P2P system: both the noticat ions of data peers about interesting key sets and the postings of multi-key statistics can be piggybac ked on mess ages that need to be sent anyway.

Regarding the placement of multi-key statistics within the directo ry, a similar considerat ion suggests that the Post for the key set ab should be stored at one of the directory peers responsible for one of the keys in the set, or alternat ively, all or at least multipl e of these directory peers for higher avail-ability. If we choose exact ly one of the direct ory peers, i.e., either p ( a ) or p ( b ) for the two-keys case, a simple strat egy is to pick the peer that is responsible for the smalle r key-word in lexicographic order (i.e., p ( a ) if we assume a &lt; Again, this has the nice advantage that no additi onal mes-sages are needed, for any data peer publishing a summ ary for ab would also post a summ ary for a alone and p ( a ) would be contacted anyway. The approac h also simplies the re-trieval of the summ aries for query routing purp oses, as we will see in the next subsection.

Giving preference to the lexicographica lly smaller key-word does not lead to any critical load imbalances, as all keys are hashed and thus pseudo-randoml y assigned anyway.
Now that the summaries for ab are contained in the dis-tribut ed directory at peer p ( a ) , a peer p init initiating a multi-k ey query containing the keys a and b can proceed as usual by issuing requests for summ aries to p ( a ) and p ( b ) . Recall that these reques ts carry the full query ab . Because the summaries for ab are kept at peer p ( a ) , p ( a ) can easily check wheth er multi-key summari es for the full query (or any multi-key subset containing more than one query key) are available and deliver the appr opriate summari es back to the requestor . Note that, if no summari es for any multi-k ey subset regarding have been published, every directory peer ships the single keyword summ aries, so that basel ine query routing can proceed as usual. So falling back to the single-key case in those situations when no multi-key posts exist does not need additional mess ages either.

For queri es with more than two keys, there is an addi-tional compli cation: it could happen that there is no Post for the full key set Q of the query (either because this query was not discovered from the query log or the assessm ent step did not consider the full key set as sucien tly useful ), but there are several subs ets of Q that have explicit multi-key Posts. The situation is easy when there is a clear dominance among subsets, i.e., when one subset is a superset of another one. In this case, we would always prefer the Post with the highest number of keys. If, however, there are incompa-rable subsets, say abc and bcd for a ve-key query abcde , we have more options at hand. Currently, we resort to the simple heuristi cs that we select all maxim al subsets among the available multi-k ey Posts. This is ecient in terms of network costs because the entire query will be sent to all single-key directory peers anyway. So both p ( a ) and p ( b ) are contacted for the query routing decis ion and can return the Posts for abc and bcd to the query initiato r with no extra costs in comm unicat ion. But this considerat ion opens up a space of optimization strat egies; this issue is left for future work. Com bining such incomparable but mutually related multi-k ey statistics is reminiscen t of the recen t work on mul-tidim ensional histograms with incomplete information [31], but our setting has the additional complexi ty of very-high-dimensional key space (e.g., keywords over text documen ts).
The recently proposed methods for maki ng query routing overlap-a ware [33, 6] can be easily applied to mk-ST AT, if the statistical summaries published by the data peers con-tain appropriate data set synopses , e.g., hash sketches or min-wise independen t permutations [11]. In our approa ch, the multi-key Posts include per-peer hash sketches for the interesting key sets anyway. Thes e are kept at the corre-sponding directory peers, and these directo ry peers also pre-compute the union of all peers' hash sketches for the given key set.

Query routing decisi ons based on mk-STAT usually only need to fetch the PeerLis t for a key set, but not the hash sketches for the indivi dual peers in the list (recall that this is one of the advantages that mk-ST AT has over sk-ST AT, for sk-ST AT does indeed need the per-peer hash sketches). However, it we also want to estimate the overlap in the re-sult sets that we would obtain from dierent peers in the same PeerLi st, or equivalently estim ate the novelty of re-sults obtained by adding a particular peer to the targets for forwarding the query , then it is necessary to fetch the in-dividual peers' hash sketches, too. Note that this does not requi re any additional mess ages, but the size of the reply messages from the directo ry peers to the query initiator in-creases substan tially. Other than this, it is straigh tforw ard to incorporate the overlap-aware techniques from [33, 6] in order to combine it with our new metho ds for correlation awareness.
Among the two suggested methods, sk-STAT is more light-weight when main taining the P2P direct ory, but pays higher cost at query run-time, whereas mk-STAT has little over-head at query run-time but appears to be more costly at posting time. In this section we briey discuss to what ex-tent these tradeos aect the scalability of our metho ds. The critical question to address is whether the methods work well as the number of peers in the network grows (to say mil-lions of peers) while the data volume per peer and the rate of query generat ion per peer remai n constant.

The DHT-ba sed distributed direct ory provides a scalable lookup infrastru cture for queries in the P2P network. A query with m keywords triggers direct ory lookups at ex-actly m directo ry peers. This holds for both sk-STAT and mk-STAT. When a single keyword becomes a bottlenec k for the responsible direct ory peer (by being very frequent in a highly skewed query workload) , we can simply replicate the director y peer and use random selection among replicas; this is well supported by DHTs and also other kinds of over-lay networks. So there is no scalability bottleneck at query run-time, regarding the network trac.
When a data peer wants to post correlation information about two or more keys, it will actually send it only to the directo ry peer that is responsible for the lexicographically smallest key (unless we introduce replication) . Moreover, there is no need to send this statistical piece of informa-tion eagerly ; rather the data peer can postpone the posting until it needs to contact the same directo ry peer for a query-routing lookup anyway (for the same or a dierent key). So all posting mess ages can eectively be piggybacked on mes-sages that are sent on behalf of queries anyway. The mes-sages become slighly bigger, but the added information is compa ct so that the message size stays small. In this setting, the number of messages and the network latenc y are the critical factors in the overall network performanc e. Thus, mk-STAT is scalable also from a networking cost viewpoint. The sk-STAT metho d, on the other hand, may indeed re-quire more messages for accurat e estimates at query-r outing time, but is as ecient as mk-STAT at posting time.
The only situat ion where the posting cost may become critical is when a data peer wants to post statistics at a high rate, but has a much lower query-generat ion rate. In this situat ion, piggyba cking postings on direct ory lookups for query routing would not be practical. But this situation is very unlikely for two reasons. First, most P2P appli-cations exhibit many more queries than updates. Second and most importan tly, the postings that mk-ST AT newly introduces in addition to the data-update postings capture query key correlations and are thus triggered by locally is-sued queries ; therefore, a peer with few queri es will not issue many postings of this kind either.
We evaluate the performanc e of sk-STAT and mk-ST AT on two dieren t datasets. We consider a dataset deriv ed from an April 2003 crawl of a portion of the Gnutella net-work 3 . As an IR text retrieval scenario, we use real-w orld web data from a TREC[ 38] benchmark.

For both datasets, we compare the query result quali ty ob-tained by using a state-of-the-art COR I-style query routing appr oach [13] based on single-k ey frequencies 4 versus both of our approa ches.

COR I is a proba bilistic IR model that ranks peers for a given key based on the key frequency at a peer (i.e., the number of les that contain this key) and the key's inverse peer frequency (i.e., the number of peers that have at least one le with this key). For our experimental comparis on, we have created hypothetica l combined collections over all peers' local data collections and identied all globall y rele-vant items for each query on this collection. We report on relative recall w.r.t. this referenc e collection, as a function of the number of peers involved in the queries, i.e., the fraction of results that the reference collection would yield. This dataset is derived from a crawl of a portion of the Gnutella network performed in April 2003, containing in-format ion about almost 850,000 music (and other media) les shared by more than 4,000 users, and more than 11,000 queri es issued during that time period. As relat ed studies have shown that the users ' interests in such a network closely follow the chart trends, we use the US top-40 single charts of the week Apr 12, 2003 to identify key pairs and triplets that can be expected to appear frequen tly in user queries. For these key sets, all peers published additional, explicit metada ta (mk-STAT). 3 Available at http://www.comp.n us.edu.s g/ p2p/ 4 We denote this appro ach as sta nda rd in all upcomi ng g-ures
Each user was viewed as a separate peer, so our P2P net-work contained about 4,000 peers, with the original assign-ment of les to peers (including many duplicates at dierent peers).

As a benchmark query load, we took the original, ob-served user queri es from the dataset, eliminating all queries that were obviousl y not related to music (but typically to adult content). A le was assumed relevant to a query if its lename contained all query terms . The quality measure used is relative recall , based on the number of distinct rele-vant les returned by the peers (thus, eliminating duplicates returned by more than one peer).

Figure 1 shows the resul ts averaged over all remai ning dis-tinct queri es for stand ard CORI-ba sed query routing vs. sk-STAT and mk-STAT. Figure 2 considers only those queries that use at least one key pair or triplet from the chart-based training queries. Figure 3, nally, only consi ders those queri es that can benet from triplets derived from the charts. Additionally, all plots show a theoretic recall opti-mum that could be obtained from complete knowledge of all collections, which is of course infeasible in a large-scale P2P network.

The results clearl y show the recall impro vemen ts obtained by our novel methods. The number of peers that need to be queri ed in order to reach a relative recall of 50 % decreases from about 50 (COR I-style query routing) to about 25 peers in our approaches. mk-STAT outperforms sk-STAT, because it oers more accurat e, explicit statistics for the term pairs. The fact that sk-STAT is able to estimate cardinali ties for all key combi-nations cann ot comp ensate for that.

The relativ e recall gures may appear low for an MP3 le-sharing network. Note, however, that the workload queries were not very selectiv e; on average, 40 distinct les quali-ed for a query resul t, and in a few cases there were hun-dreds of results. With the original placemen t of les on peers, all results for a query are distributed across 135 peers on average (i.e., averaged over all querie s). These include many dupli cates, however. The minimum number of peers that together hold all distinct matches for a query was 30 peers, averaged over all queries, and sometimes more than 100 peers for some less selective queri es. Thus, to achieve a relativ e recall of 100 % would require contacting at least 30 peers on average and in the order of 100 peers for the most expensive querie s. However, this is a theoretical minimum and could be ecien tly achieved only with a centralized or nearly-cen tralized super-peer directo ry structure, neither of which ts with an ultra-sca lable P2P architecture. With a Gnutella-style overlay network where searc h requests are epidem ically disseminated to neigh bors, messages would be sent to many more peers, in fact, even more than the total number of peers that hold at least one match (i.e., 135 peers on average) .

In practice, the user-p erceiv ed improvemen ts can be even higher than shown in the gures, because the distribution of queri es observ ed in the real-world query logs of the Gnutella dataset are highly skewed. A small portion of distinct queries makes up a subst antial fract ion of the query load. As those frequen t queries are typicall y exact ly the queri es that will actuall y benet from the additional statistics (because the query -log analys is can identify them and trigger the produc-tion of appr opriate statistics), our novel metho d has benet s for an over-prop ortiona l fraction of the querie s and, thus, of the users .
As Web data, we consider the GOV documen t collection [38] with roughly 1.2 million documen ts compiled by a Web crawl of the .gov internet domain and used in TREC bench-marks . To evaluate the distributed behavior, we creat ed 750
Figure 2: Queries with applicable triplet or pair peers by randomly assigning documents to them. The ran-dom placemen t was chosen as a stress test for the query rout-ing metho ds. With thematic clustering, we could achieve much higher relative recall with fewer peers, but that would have simplied the query routing decis ions for all metho ds, whereas we wanted to obtain insights into performance dif-ferences under stress conditions. This explai ns why the re-sults given below show fairly small recall numbers. Note, however, that in Web searc h, users are typically satised with low recall as long as they have accept able precis ion among the top-10 or top-20 ranks.

For the query workload we used queri es from the topic-distillation track of the TRE C 2003 Web Track benchmark, eliminating the single term queri es, because we wanted to focus on the impro vements for multi-keyword queri es. The remai ning queries, expan ded to increase the document re-call, are shown in Table 3.
For each query we obtained the top-20 results from the peers that were chosen by the query routing metho d and merged them into a global result list based on their locally computed scores. The relat ive recall measure was computed for the top-50 of the global result lists (averaged over all queri es). That is, we report the overlap between the top-50 results of the P2P searc h engine and the top-50 results that a centralized engine would yield. We believe that is a reasonab le measure of query routing eectiveness.

Figure 4 shows that mk-STAT clearl y outperforms the other metho ds and is very close to the optim um. sk-STAT's performance degrades quickly. This is because, due to the small size of the data peers and the random placeme nt of the data items, only very few peers have a reasonable number of relevant documen ts for a query, for which sk-STAT's esti-mation of multi-key statistics is sensitive enough. Typicall y, after 4 or 5 peers, each additional peer has only one or two relevant documen ts to add. In this situat ion, the estimation accurac y of sk-ST AT's combinatorial comput ation degra des signicantly. In contrast, mk-STAT with its explicit multi-key statistics performed very well also for the peers with a very small number of relev ant documen ts. Note that the low recall values reported are due to the random placement of documen ts on 750 data peers. As the estim ated number of relev ant documents for a query is evenly distributed over all peers, there is no single peer that can contribute a large fraction of the relev ant documents. Nevertheless, mk-STAT manages to yield a recall of almost 20% for 100 out of these 750 peers. Our novel mk-ST AT metho d in this scenario de-creases the number of peers involved in a query necessary to reach a relat ive recall of 10% from 125 to less than 30.
We have developed ecient methods for capturing, dis-seminating, and exploiting statistics about correl ated key sets in a P2P network. Our experimen tal studies have shown signicant gains in terms of the benet/c ost ratio with ben-et dened in terms of query recall and cost prop ortional to the number of peers that participate in execut ing a query .
Among the strat egic issues that are left for future work is query optimization beyond the query routing decis ion. We plan to address adapt ive run-time adjustments to execution plans and other aspects of dynamic query optimization in P2P systems. [1] K. Aberer. P-Grid: A self-organizing access structure [2] K. Aberer and P. Cudr X -Mauro ux. Semantic overlay [3] K. Aberer, F. Klemm, T. Luu, I. Podnar, and [4] D. Agra wal, A. E. Abba di, and S. Suri.
 [5] R. Agrawal, T. Imielinski, and A. Swami. Mini ng [6] M. Bender, S. Michel, P. Triantallou, G. Weikum, [7] M. Bender, S. Michel, P. Triantallou, G. Weikum, [8] M. Bender, S. Michel, P. Triantallou, G. Weikum, [9] B. H. Bloom. Space/t ime trade-os in hash coding [10] A. Broder. On the resemblanc e and containmen t of [11] A. Z. Broder, M. Charikar, A. M. Frieze, and [12] J. Callan. Distributed information retrieval. Advanc es [13] J. P. Callan, Z. Lu, and W. B. Croft . Searc hing [14] E. Cohen, A. Fiat, and H. Kaplan. Associativ e search [15] G. Cormo de and M. N. Garofa lakis. Sketching streams [16] A. Cresp o and H. Garc ia-Molina. Seman tic overlay [17] P. Drusc hel and A. Rowstron. Pastry: Scalable , [18] M. Durand and P. Flajolet. Loglog counting of large [19] M. Fang, N. Shivakumar, H. Garcia-Molina, [20] P. Flajolet and G. N. Mart in. Prob abilistic counting [21] N. Fuhr. A decision-theoretic approa ch to database [22] J. Han and M. Kam ber. Da ta Mining Concepts and [23] T. Hernand ez and S. Kam bhampat i. Impro ving text [24] R. Huebsc h, B. N. Chun, J. M. Hellerstein, B. T. Loo, [25] M. Jelasity, W. Kowalczyk, and M. van Steen. An [26] M. Jelasity, A. Montresor, and O. Baba oglu.
 [27] P. Kalni s, W. S. Ng, B. C. Ooi, and K.-L. Tan. [28] R. M. Karp, C. Schindelhauer, S. Shenk er, and [29] W. Litwin and M.-A . Neim at. k-rp* s: A scalable [30] J. Lu and J. P. Callan. Content-based retrieval in [31] V. Markl, N. Megiddo, M. Kutsc h, T. M. Tran, P. J. [32] W. Meng, C. T. Yu, and K.-L. Liu. Building ecient [33] S. Michel, M. Bend er, P. Triantallou, and [34] S. Ratnasam y, et al. A scalable content-address able [35] L. Si, R. Jin, J. P. Callan, and P. Ogilvie. A langu age [36] K. Sripanidkulc hai, B. M. Maggs, and H. Zhang. [37] I. Stoica, et al. Chord: A scalable Peer-T o-Peer lookup [38] Text REtriev al Conference (TREC ). [39] P. Triantallou, C. Xiruhaki, M. Koubar akis, and [40] S. Voulgaris , A.-M. Kermarrec, L. Massouli X , and [41] L. Wasserm an. All of Sta tisti cs: A Concise Cours e in [42] B. Yang, P. Vinog rad, and H. Garc ia-Molina. [43] J. Zhang and T. Suel. Ecien t query evaluation on
