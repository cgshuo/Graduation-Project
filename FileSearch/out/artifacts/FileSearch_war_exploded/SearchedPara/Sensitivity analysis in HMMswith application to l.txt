 We consider a parameterized hidden Markov model (HMM) defined on continuous state and ob-( Y compact subset of R d .
 assume that we can sample this Markov chain using a transition function F and independent random numbers, i.e. for all t  X  0 , U = [0 , 1] p ,  X  is uniform, thus U t is a p -uple of uniform random numbers. For simplicity, we F (  X , U  X  1 ) with U  X  1  X   X  ).
 X  X  Y  X  [0 , 1] is the marginal density function of Y conditionally independent given the state.
 write the dependence of  X  (in K , F , g , X t , Y t , ...) when there is no possible ambiguity. vations ( y 1 , . . . , y n ) (written y 1: n ). The filtering distribution (or belief state) distribution More precisely, we estimate  X   X  n ( f ) (where  X  ( f ) , under the filtering distribution  X  n .
 We also consider as application, the problem of parameter identification in HMMs which consists in estimating the (unknown) parameter  X   X  of the model that has served to generate the sequence of observations. In a Maximum Likelihood (ML) approach, one searches for the parameter  X  that (in the sense that  X   X  n converges almost surely to the true parameter  X   X  when n  X   X  under some identifiably conditions and mild assumptions on the model, see Theorem 2 of [DM01]). Thus, using the ML approach, the parameter identification problem reduces to an optimization problem. used in a (stochastic) gradient method for the purpose of optimizing the likelihood. The approach is numerically illustrated on two parameter identification problems (autoregressive model and a stochastic volatility model) and compared to other approaches (EM algorithm, the Kalman filter, and the Likelihood ratio approach) when these latter apply. spaces where the Viterbi algorithm may apply or in linear-Gaussian models where the Kalman filter can be used). Thus, in this paper, we will make use of the so-called Sequential Monte Carlo methods (SMC) (also known as Particle Filters) which are numerical tools that can be applied to a large class of models, see e.g. [DFG01]. For illustration, a challenging example in finance is Gaussian continuous space HMM parameterized by three continuous parameters (see e.g. [ME07]) which will be described in the experimental section.
 A usual approach for parameter estimation consists in performing a maximum likelihood estimation space problems, the Expectation Maximization (EM) algorithm is a popular method for solving the MLE problem. However, in continuous space problems, see [CM05], the EM algorithm is difficult to is intractable in many situations. The Maximization part may also be very complicated and time-consuming when the model does not belong to a linear or exponential family. An alternative method consists in using brute force optimization methods based on the evaluation of the likelihood such as grid-based or simulated annealing methods. These approaches, which can be seen as black-box optimization are not very efficient in high dimensional parameter spaces. conditions, see [Pap07], and do not perform well in practice for a large number of time steps. the field of continuous space HMMs e.g. in [DT03, FLM03, PDS05, Poy06]. The idea was to use a simple path-based particle filter as Monte Carlo approximation method. This approach is efficient particles instead of being linear, like in path-based particle methods.
 The IPA approach proposed in this paper is an alternative gradient-based maximum likelihood ap-proach. Compared with works on gradient approaches previously cited, the IPA provides usually a in the number of particles.
 cesses) in [CDM08]. A similar FD estimator could be designed in our setting too but the resulting FD estimator would be biased (like usual FD schemes) whereas the IPA estimator is not. Given a measurable test function f : X  X  R , we have:  X  ( f ) , E [ f ( X n ) | Y 1: n = y 1: n ] = where we used the simplified notation: G t ( x t ) , g ( x t , y t ) and G 0 ( x 0 ) , 1 . based on a SMC method. But it should be mentioned that other methods (such as Extended Kalman filter, quantization methods, Markov Chain Monte Carlo methods) may be used as well to build the IPA estimator that we propose in the next section.
 empirical distribution  X  N n ( f ) , 1 N Algorithm 1 Generic Sequential Monte Carlo for t = 1 to n do end for
RETURN:  X  N n ( f ) = 1 N cle positions such as to preserve a consistency property (i.e. method [Kit96] which is optimal in terms of variance minimization.
 estimator of  X  n ( f ) . 4.1 Sensitivity analysis of the filtering distribution  X  [  X  n ( f )] =  X  estimator of  X  E [ f ( X n ) method and the Score Function (SF) method (also called likelihood ratio method), see for instance we know, it has never been used in this context. This is therefore the object of this Section.  X  E [ f ( X (where Z t ,  X  X t ) { By introducing this augmented Markov Chain in Equation (4) and using Equation (3) we can rewrite  X   X  n ( f ) as: We now state some sufficient conditions under which the previous derivations are sound. Proposition 1. Equation (5) is valid on  X  whenever the following conditions are satisfied: The proof of this Proposition is a direct application of Theorem 1.2 from [Gla91]. We notice that From Equation (5), we can derive the IPA estimator of  X   X  n ( f ) by using a SMC algorithm: ( X t , Z t , R t ) described in Algorithm 2.
 Algorithm 2 IPA estimation of  X   X  n for t = 1 to n do end for
RETURN: I N n = 1 N  X   X  n ( f ) almost surely. In addition, its (asymptotic) variance is O ( N  X  1 ) . Proof. We use the general SMC convergence properties for Feynman-Kac (FK) models (see [Del04] or [DM08]) which, applied to a FK flow with Markov chain X 0: n , (random) potential func-tions G ( X 0: n ) , and test function H ( X 0: n ) , states that the SMC estimate: 1 N in [DMDP07], shows that it is of order O ( N  X  1 ) . Applying those results to the test function H , f 0 ( X estimator (6) of (5).
 Remark 1. Notice that the computation of the gradient estimator requires O ( nN md ) (where m is in the number of parameters d , and has memory requirement O ( N md ) . 4.2 Gradient of the log-likelihood In the Maximum Likelihood approach for the problem of parameter identification, one may follow a stochastic gradient method for maximizing the log-likelihood l n (  X  ) where the gradient (5) and (4) for the predictive distribution applied to G t +1 :  X   X  with  X  E [ G We deduce the IPA estimator of  X  l n (  X  ) unbiased and consistent with  X  l n (  X  ) .
 so that local convergence occurs (e.g. such that for a detailed analysis of Stochastic Approximation algorithms.
 Algorithm 3 Likelihood Maximization by gradient ascent using the IPA estimator of  X  l n (  X  ) for k = 1 , 2 , . . . , Number of gradient steps do end for Figure 1: Box-and-whiskers plots of the three parameters (  X ,  X ,  X  ) estimates for the AR 1 model used n = 500 observations and N = 10 2 particles. Autoregressive model AR 1 is a simple linear-Gaussian HMMs thus may be solved by other meth-ods (such as Kalman filtering and EM algorithms) which enables to compare the performances of several algorithms for parameter identification. The dynamics are  X  = (  X ,  X ,  X  ) is a three-dimensional parameter in ( R + ) 3 .
 derivative securities, such as options. This is a non-linear non-Gaussian model, so the Kalman method cannot be used anymore. The dynamics are 5.1 Parameter identification lem and compares those with two other methods: Kalman filter (K) and EM (which apply since the bias of the three methods in the estimation of  X   X  (even for Kalman which provides here the exact that the method is not sensitive to the starting point.
 We observe that in terms of estimation accuracy, IPA is very competitive to the other methods, Kalman and EM, which are designed for specific models (here linear-Gaussian). The IPA method comparison is made here since Kalman does not apply and EM becomes more complicated). 5.2 Variance study for Score and IPA algorithms IPA and Score methods provide gradient estimators for general models. We compare the variance exact value (using Kalman). Figure 2: Box-and-whiskers plots of the three parameters (  X ,  X ,  X  ) estimates for the IPA method and N = 10 2 particles.
 Figure 3 shows the variance of the IPA and Score estimators of the partial derivative  X   X  l n (we it is better to use the Score estimator.  X  = (0 . 7 ,  X , 0 . 9) .
 of observations n increases. However, under weak conditions on the HMM [LM00], the filtering ready been used for EM estimators in [CM05] to show that fixed-lag smoothing drastically reduces would provide efficient variance reduction techniques for the IPA estimator as well. We proposed a sensitivity analysis in HMMs based on an Infinitesimal Perturbation Analysis and the usual Score method. We showed how this analysis may be used for estimating the gradient of the log-likelihood in a gradient-based likelihood maximization approach for the purpose of param-could be derived as well along this IPA approach, which would enable to use more sophisticated optimization techniques (e.g. Newton method). [CDM08] P.A. Coquelin, R. Deguest, and R. Munos. Particle filter-based policy gradient in [CGN01] F. C X rou, F. Le Gland, and N. J. Newton. Stochastic particle methods for linear tangent [CM05] O. Capp X  and E. Moulines. On the use of particle filtering for maximum likelihood [Del04] P. Del Moral. Feynman-Kac Formulae, Genealogical and Interacting Particle Systems [DFG01] A. Doucet, N. De Freitas, and N. Gordon. Sequential Monte Carlo Methods in Practice . [DM01] R. Douc and C. Matias. Asymptotics of the maximum likelihood estimator for general [DM08] R. Douc and E. Moulines. Limit theorems for weighted samples with applications to [DMDP07] P. Del Moral, A. Doucet, and GW Peters. Sharp Propagation of Chaos Estimates for [DT03] A. Doucet and V.B. Tadic. Parameter estimation in general state-space models using [FLM03] J. Fichoud, F. LeGland, and L. Mevel. Particle-based methods for parameter estimation [Gla91] P. Glasserman. Gradient estimation via perturbation analysis . Kluwer, 1991. [GSS93] N. Gordon, D. Salmond, and A. F. M. Smith. Novel approach to nonlinear and non-[Kit96] G. Kitagawa. Monte-Carlo filter and smoother for non-Gaussian nonlinear state space [KY97] H. J. Kushner and G. Yin. Stochastic Approximation Algorithms and Applications . [LM00] F. LeGland and L. Mevel. Exponential forgetting and geometric ergodicity in hidden [ME07] R. Mamon and R.J. Elliott. Hidden markov models in finance. International Series in [Pap07] A. Papavasiliou. A uniformly convergent adaptive particle filter. Journal of Applied [PDS05] G. Poyadjis, A. Doucet, and S.S. Singh. Particle methods for optimal filter derivative: [Pfl96] G. Pflug. Optimization of Stochastic Models: The Interface Between Simulation and [Poy06] G. Poyiadjis. Particle Method for Parameter Estimation in General State Space Models . [Sto02] G. Storvik. Particle filters for state-space models with the presence of unknown static
