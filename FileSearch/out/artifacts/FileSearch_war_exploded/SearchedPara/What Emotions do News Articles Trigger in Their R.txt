 We study the classification of news articles into emotions they invoke in their readers. Our work differs from previous studies, which focused on the classification of documents into their authors X  emotions instead of the readers X . We use various combinations of feature sets to find the best combination for identifying the emotional influences of news articles on readers. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Clustering Algorithms, Performance, Experimentation News Articles, Reader-Emo tion Classification, Text Classification Past researches on emotions c onveyed by documents focused on detecting the feelings that the authors of the documents were expressing [1]. Such studies are useful when we need a quick poll on how people feel about a particular event or item. Instead of uncovering the emotional states of the authors of documents, this paper aims to fi nd out what emotions documents trigger in their readers. Such research has novel applications. Suppose someone who likes pets is in a gloomy mood. He or she will definitely be cheered up by reading documents that are both about pets and heartwarming st ories. Existing information retrieval (IR) systems can deal with the former. That is, IR systems are quite capable of finding documents which contain information that users want to know about. In our example, they are the documents about pets. But current IR systems do not deal with the latter. They cannot discern a shocking story about pet abuse from a pleasant story about the cute things that pets do. Users can add positive words like  X  X eartwarming X  to a query, and request IR systems to exclude any documents containing negative words like  X  X buse X . But instead of requiring users to formulate a complex query, it is more convenient for them to simply click on a checkbox representing an emotion to tell IR systems to return documents that are both content a nd emotion relevant, e.g., about pets and heartwarming. A method capable of identifying the emotional effect of a document on its readers can serve as a filter to retain only the documents that cause desired emotions. For the experiments, we tried diffe rent combinations of features. The results are shown in Table 1. BI, WD, MT and EC denote bigram, word, metadata, and emotion category of word, respectively. For the baseline, we selected the emotion that occurred most frequently among the training instances as the predicted emotion. The  X  X ncl. Useful X  columns have the value  X  X es X  if useful was included as a class and the value  X  X o X  otherwise. Since news article r eaders rarely vote unanimously for a single emotion class, votes are usually distributed among several emotions in an article. Taking the multitude of emotional responses into consideration, we employed two kinds of evaluation metrics. For the Top-1 metric, a predicted class of an instance is correct if it agrees with the top-ranking emotion class of the instance. For Top-2 metric, a predicted class is correct if it agrees with one of the top two ranking emotion classes. From Table 1, we see that the baseline method has the worst accuracies in all rows. This is not because the training and testing data have very different distribu tions of emotions. In both training and testing data, happy class has the most number of instances. Hence, the corpus does not have a strongly uneven distribution of emotions that can be explo ited by the simplistic methods. The figures in Table 1 are consis tent in that BI performs better than WD, and BI+MT performs better than WD+MT. The p-values for their differences using paired t-test are 0.014 and 0.0016 respectively when useful class is included and the Top-1 metric is used. Holding all ot her conditions the same, Chinese character bigrams are better features than the segmented words. However, using BI and WD in combination with MT produces better accuracies than using BI and WD separately. Another observation from Table 1 is that the combination BI+WD+MT+EC performs slightly better than BI+WD+MT in all rows. It shows that the emotion category of words has certain influence on the classification accuracy. Table 2 shows that different classes have very different performance, ranging from having 59.10% correctly-classified instances to 89.66% using feat ures BI+WD+MT+EC. We were concerned that having highly distinguishing event words as features may be the cause of happy and angry having high percentage figures relative to other emotion classes. As event words may occur only for a short period of time and rarely be used again in future news stories, having event words as the primary distinguishing features is not going to be helpful in enhancing the general coverage of the classification system. To find out if this was really the case, we examined the most frequently occurring features for each class and computed the conditional probability P ( instance i X  X  true class is c|instance i has 
