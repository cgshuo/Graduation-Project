 We examine issues in the design of fully dynamic informa-tion retriev al systems supp orting both documen t insertions and deletions. The two main comp onen ts of suc h a system, index main tenance and query pro cessing, a ect eac h other, as high query performance is usually paid for by additional work during update operations. Tw o asp ects of the system { incremen tal updates and garbage collection for dela yed doc-umen t deletions { are discussed, with a focus on the resp ec-tive indexing vs. query performance trade-o s. Dep ending on the relativ e num ber of queries and update operations, di eren t strategies lead to optimal overall performance. H.2.4 [ Systems ]: Textual databases; H.3.4 [ Systems and Software ]: Performance evaluation Exp erimen tation, Performance
Although they are usually studied indep enden tly, index-ing and query pro cessing are two closely related topics in text retriev al. Man y query optimization techniques necessi-tate additional work at indexing time and thus represen t trade-o s between indexing and query pro cessing perfor-mance. While this may be ignored in traditional (static) retriev al systems, it is critical in dynamic searc h environ-men ts, in whic h the underlying text collection is con tinu-ously changing and the num ber of queries to be pro cessed may vary greatly . An example is le system searc h, where sev eral thousand index updates per day are not unusual [2]. Index updates include two types of update operations: doc-umen t insertions and documen t deletions.

Techniques to supp ort documen t insertions into an exist-ing index usually follo w a standard scheme: Tw o indices are main tained, one in memory , the other on disk. Postings for new documen ts are accum ulated in main memory until it is exhausted, at whic h point they are transferred to disk and com bined with existing on-disk data. This operation can be performed by follo wing an in-place update scheme [4] or by merging the old index with the new data, resulting in a new index that sup ercedes the old one [3]. Both ap-proac hes have in common that the entire on-disk index has to be read/written every time main memory is exhausted, causing performance problems for large collections ( In-plac e does not need to read the whole collection. However, it trades read operations for disk seeks, leading to the same type of problem). We sho w how, by allo wing multiple on-disk indices at the same time, the num ber of disk operations can be signi can tly reduced.

A thorough evaluation of techniques for documen t dele-tions has not been published. Moreo ver, a general discus-sion of the trade-o s asso ciated with index main tenance and query optimization techniques does not exist.
We discuss three di eren t strategies to merge sub-indices, represen ting di eren t trade-o levels.
 Strategy 1: Immediate Merge
The rst merge strategy has been prop osed by Lester et al. [3]. The indexing system main tains one on-disk and one in-memory index. As soon as main memory is full, the in-memory postings are merged with the existing on-disk index, creating a new index. The old index is deleted. This strat-egy minimizes the num ber of disk seeks necessary to fetc h a posting list. Its disadv antage is that for every merge opera-tion the entire index has to be scanned. Thus, the num ber of disk operations necessary to index the whole collection is quadratic in the size of the text collection.
 Strategy 2: No Merge
The second strategy does not perform any merge opera-tions. When memory is full, postings are sorted and written to disk, creating a new on-disk sub-index. On-disk indices are nev er merged. When the posting list for a given term has to be retriev ed from the index, sub-lists are fetc hed from all sub-indices. The adv antage of No Merge is its high in-dexing performance (linear num ber of disk operations). Its disadv antage is that fetc hing a posting list requires ( n ) disk seeks, where n is the size of the text collection. Strategy 3: Logarithmic Merge
The two strategies describ ed so far represen t the two ex-tremes. The third strategy is a compromise: A newly cre-ated on-disk sub-index is sometimes merged with an existing one, but not alw ays. We use the concept of index gener ation to decide when to merge sub-indices. An on-disk index that was created directly from in-memory postings is of genera-tion 0. An index that is the result of a merge operation is Figure 1: Comparison of sub-index merging strate-gies for a growing text collection and varying D Q U . of generation g + 1, where g is the highest generation of any input index. If, after creating a new on-disk index, there are two indices of the same generation, they are merged. This is rep eated until there are no more suc h collisions. The num ber of sub-indices is bounded by O (log ( n )), and the total num-ber of disk operations necessary to index the text collection is O ( n log( n )), where n is the size of the collection.
Documen t deletions are addressed by a garbage collection approac h. Postings that belong to deleted documen ts are ltered and ignored during query pro cessing, using a tech-nique similar to the invalidation scheme prop osed by Chiueh and Huang [1]. However, this is exp ensiv e in terms of time and space. Therefore, at some point, the garbage collector is started and remo ves all garbage postings from the index. Threshold-based Garbage Collection
A simple strategy is to keep trac k of the relativ e num ber of postings in the index that belong to deleted documen ts: As soon as this num ber exceeds a prede ned threshold , the garbage collector is started. = 0 guaran tees maxim um query performance. For = 1, index main tenance perfor-mance is maximal, but the query pro cessor spends a great amoun t of time fetc hing and decompressing postings that belong to deleted documen ts.
 On-the-Fly Garbage Collection
The threshold-based garbage collection strategy descib ed above has the disadv antage that it is indep enden t of the sub-index merging strategy emplo yed and thus causes additional disk operations that could have been avoided by integrating the garbage collector into the merge pro cess. We call this integration on-the-y garb age collection : If the com bined rel-ativ e amoun t of garbage postings in all sub-indices involved in a merge operation exceeds a threshold 0 , the garbage collector is integrated into the merge pro cess.
The retriev al system used in our exp erimen ts is the Wum-pus searc h engine. As the underlying text collection, we used the TREC 2004 Genomics corpus, consisting of 4.5 million documen ts with a total size of 14 GB.

In order to be able discuss indexing time vs. query time Figure 2: Comparison of garbage collection strate-gies for a fully dynamic collection and varying D U Q . trade-o s with resp ect to the amoun t of work the index-ing subsystem and the query pro cessor have to do, the ex-perimen ts were conducted with varying relativ e query and update loads. This ratio is expressed by D U Q , the num ber of update operations per query , and its coun terpart D queries per update operation. A system with D U Q = 0 pro-cesses queries for a static text collection. D U Q = 1 , on the other hand, describ es a system whic h only performs update operations and nev er pro cesses any queries. We conducted exp erimen ts for D U Q values realistic in le system searc h.
The rst series of exp erimen ts, depicted in Figure 1, in-volves a monotonically gro wing collection. The whole collec-tion is indexed, with queries being pro cessed concurren tly. It can be seen that Logarithmic Merge is the best strategy for a wide range of relativ e update/query loads. Only for very small D Q U , No Merge gives better overall performance.
In the second series of exp erimen ts, the system started from an index con taining 50% of the collection. Documen ts were added and deleted randomly . Figure 2 sho ws that a garbage threshold = 0 : 5 is a good choice under most cir-cumstances. On-the-y garbage collection increases perfor-mance sligh tly and gives a 3% impro vemen t over the pure threshold-based strategy .
The Wumpus searc h system, along with technical rep orts giving more details regarding the issues discussed in this pa-per, can be found on-line: http:/ /www.wumpus-searc h.org/. [1] T. Chiueh and L. Huang. Ecien t Real-Time Index [2] T. J. Gibson and E. L. Miller. Long-Term File Activit y [3] N. Lester, J. Zob el, and H. E. Williams. In-Place versus [4] A. Tomasic, H. Garc a-Molina, and K. Sho ens.
