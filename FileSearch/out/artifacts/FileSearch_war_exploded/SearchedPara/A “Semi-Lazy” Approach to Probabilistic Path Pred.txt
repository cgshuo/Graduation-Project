 Path prediction is useful in a wide range of applications. Most of the existing solutions, however, are based on eager learning meth-ods where models and patterns are extracted from historical trajec-tories and then used for future prediction. Since such approaches are committed to a set of statistically significant models or patterns, problems can arise in dynamic environments where the underlying models change quickly or where the regions are not covered with statistically significant models or patterns.

We propose a  X  X emi-lazy X  approach to path prediction that builds prediction models on the fly using dynamically selected reference trajectories. Such an approach has several advantages. First, the target trajectories to be predicted are known before the models are built, which allows us to construct models that are deemed relevant to the target trajectories. Second, unlike the lazy learning approach-es, we use sophisticated learning algorithms to derive accurate pre-diction models with acceptable delay based on a small number of selected reference trajectories. Finally, our approach can be contin-uously self-correcting since we can dynamically re-construct new models if the predicted movements do not match the actual ones.
Our prediction model can construct a probabilistic path whose probability of occurrence is larger than a threshold and which is furthest ahead in term of time. Users can control the confidence of the path prediction by setting a probability threshold. We conduct-ed a comprehensive experimental study on real-world and synthetic datasets to show the effectiveness and efficiency of our approach. H.2.8 [ DATABASE MANAGEMENT ]: Database Applications-Data mining; I.2.6 [ ARTIFICIAL INTELLIGENCE ]: Learning Trajectory Analysis; Spatial-temporal Data Mining; Lazy Learning
Path prediction is presently a popular area of research [13, 17, 18, 8, 16, 9, 28, 15, 20]. Predicting the future path of moving ob-jects has a broad range of applications, including navigation, traf-fic management, personal positioning, actionable advertising [16], epidemic prevention [12], event prediction [21], anomaly detection [4, 14] and even spatial query optimization [5].
 We study the path prediction problem in dynamic environments. An environment is considered to be dynamic if the movement of objects in the environment changes with some uncertain, aperiodic and irregular factors. Some real-life examples of dynamic envi-ronments include: (1) urban space where the movement of objects (e.g., cars) is affected by traffic signals, traffic jams and weath-er conditions; (2) massively multiplayer online games where the movement of game units varies depending on the placement of monsters and resources; (3) shopping malls where the movement of customers changes when certain shops are on promotions.
Existing path prediction methods mostly adopt the eager learn-ing approach [17, 8, 18, 28, 20], i.e., models or patterns are extract-ed from historical data and used to predict the future movements of objects. In such methods, historical trajectories are abandoned once the models or patterns are extracted. This results in a loss of information since the models or patterns are usually not fully rep-resentative of the data. Furthermore, since the models or patterns are generated without knowing the objects to be predicted, prob-lems arise when the target objects are moving through regions that are not covered with statistically significant models. In extreme cases where the environment is so dynamic that completely new situations can arise (e.g. once in 50 years flash flood, new game settings), the models or patterns can become invalid.

To overcome these problems, we propose a  X  X emi-lazy X  approach, called R2-D2 1 , to pR obabilistic path pR eD iction in D ynamic envi-r onments . In R2-D2, historical trajectories are kept and indexed. To perform prediction for a target object, we match its past tra-jectory against historical trajectories and extract a small set of ref-erence trajectories. Sophisticated machine learning techniques are then applied on the reference trajectories to construct a local model, which can predict the future movement of the target object.
Fig.1(a) shows an application example of R2-D2 in vehicle path prediction. R2-D2 continuously collects streaming trajectories of a large number of moving objects (the cars in Fig.1(a)). In Fig.1(b), the red solid line is the trajectory of object O p whose future path is to be predicted; while the blue dash lines are the historical trajec-tories which are selected as reference trajectories for predicting the path of O p .

R2-D2 has several advantages. First, the target trajectory is known before the model is derived from a set of similar reference trajecto-ries. This ensures that the model is highly relevant. Second, since the learning is performed on a small set of reference trajectories, we can afford to use slightly more complex learning algorithms. Given the power of modern hardware, the time taken to derive such local m odel is typically acceptable. Finally, since the actual movement of the target object can be compared against the predicted move-ment subsequently, we can dynamically derive new models if the actual movement and the predicted movement do not match. This leads to a self-correcting continuous prediction approach. F igure 1: (a) An application example of R2-D2 in vehicle path prediction; (b) Path prediction based on reference trajectories.
On top of these advantages, R2-D2 also supports probabilistic path prediction. Since there is always a trade-off between the pre-diction accuracy and the length of the predicted path, R2-D2 choos-es to predict the longest path (in term of time) with probability (confidence) higher than a given threshold. The user can thus use R2-D2 to predict paths of different lengths by setting different con-fidence thresholds, making it flexible enough be used in a broad range of applications that have different requirements for predic-tion confidence and predicted path length.

The rest of the paper is organized as follows. Section 2 gives a review of related work. Section 3 formalizes the problem and gives an overview of R2-D2. The prediction process of R2-D2 has three sub-processes:  X  X pdate X ,  X  X ookup X  and  X  X onstruction X , which are discussed in Section 4, Section 5 and Section 6, respectively. We evaluate R2-D2 in Section 7 and conclude the paper in Section 8.
Approaches for path prediction can be categorized into pattern-based path prediction and descriptive model-based path prediction.
Pattern-based prediction methods can be future categorized into two classes: personal pattern-based methods and general pattern-based methods.

Personal pattern-based prediction methods consider the move-ment of each object to be independent. In [27], Yavas et al. propose a method to predict a user X  X  future paths based on the user X  X  mobil-ity patterns. Jeung et al. [8] propose a hybrid prediction model which combines motion function and mobility patterns. Sadilek et al. [20] propose a model to support long-term mobility prediction.
General pattern-based prediction methods use common mobility patterns to predict future locations. In [17, 18], Morzy proposes methods to extract association rules from trajectories for predic-tion. For more of such methods, please refer to [28]. Mobility pat-terns are also used for destination prediction, such as WhereNext [16] and SubSyn [26], which predicts moving objects X  destinations without concerning paths of reaching the destinations.

Pattern-based methods do not work well in dynamic environ-ments. The main problem is that pattern mining is an expensive (in terms of time) process; therefore, it cannot quickly capture new patterns that emerge in a dynamic environment. Furthermore, the movement of many moving objects may not match any pattern, making it impossible to do prediction [28].
Descriptive model-based prediction methods use mathematical models to describe the movement of moving objects.

Motion function methods estimate objects X  future locations by motion functions [24, 23]. Recursive motion function [23] is one of the most accurate methods. The problem is that these methods do not take environment constraints into account.

Markov model methods are suitable for estimating future loca-tions of moving objects in a discrete location space [19]. However, these methods can only predict the short-term path. Some advanced mathematical models, such as Gaussian process and Dirichlet pro-cess [10], have been used to model objects X  behavior, but they do not address the location prediction problem.

There are also some path prediction methods that utilize road networks [11, 9]. Those methods can only be applied in network-constraint spaces. R2-D2 does not have such limitations.
As far as we known, R2-D2 is the first  X  X emi-lazy X  approach that on the fly finds reference trajectories to learn a path prediction model and then make path prediction.
F ig. 2 illustrates the architecture of R2-D2. It has two compo-nents: the Trajectory Grid (TG) and the Prediction Filter (PF). TG is a grid based indexing structure for storing historical trajectories. PF performs probabilistic path prediction.

There are also two separate processes:  X  X pdate X  and  X  X redic-tion X . In Fig. 2, we denote the  X  X pdate X  process by blue solid lines and denote the  X  X rediction X  process by red dotted lines . The  X  X p-d ate X  process continuously collects streaming trajectories from the dynamic environment and stores them in TG (see Section 4 ).
The  X  X rediction X  process makes path prediction. This process has two sub-processes:  X  X ookup X  and  X  X onstruction X . In Fig. 2, we want to predict the path of O p (the red car). In the  X  X ookup X  process, we use the trajectory of O p in the last few time steps as query trajectory to retrieve reference trajectories from TG (see tion 5 ). R2-D2 will only make a prediction if the number of ref-erence trajectories is greater than a predefined threshold. In the  X  X onstruction X  process, the reference trajectories are used to con-struct a model for making path prediction (see Section 6 ). Table 1 lists notations used throughout the paper. We use denote a moving object. A trajectory of O i is a sequence of times-tamped locations T i = &lt; O i 1 , ...,O i t ,... &gt; , where Figure 2: Architecture of R2-D2. It has an  X  X pdate X  process (blue solid lines ) and a  X  X rediction X  process (red dotted lines ).  X  Prediction X  process has two sub-process:  X  X ookup X  process and  X  X onstruction X  process. (Better viewed in color.)
Figure 3: An example of using R2-D2 to predict O p  X  s path. denoting that O i locates at location ( x,y ) at time t . We assume that all trajectories have synchronised timestamps. When this as-sumption is not valid, we interpolate the trajectories.
We refer to the trajectory of O p in the last h time steps as backward trajectory and denote it as W h . If t 0 is the current time, then W h = &lt; O p
The reference objects of O p , denoted as RO , is a set of objects which have certain sub-trajectories matched with W h . These ob-jects have a similar tendency as O p . We give a formal definition of the match function in Section 5.

For each object O i  X  RO , we denote O i v as the timestamped points of O p at t 0 are defined as RO 0 = { O i v | O i  X  RO } reference points of O p at t 0 + k , namely RO k , are defined as RO k = { O i v + k | O i  X  RO } . Note that the definition of based on RO 0 , because the value of v for each O i  X  RO is deter-mined at time t 0 . Moreover, we use RO 1: k to denote all reference points of O p from t 0 + 1 to t 0 + k , i.e., RO 1: k = S also call RO 1: k as reference trajectories of O p .

Let  X  ( centroid,radius ) denote a circle. We call a vector (  X  ( centroid,radius ) ,k ) a state of O p , which means within the circle at time t 0 + k . Since there could be several possible states for O p at time t 0 + k , we use s i k to denote a possible state whose identifier is i . We define the set of all possible states of time t 0 + k as a state space , i.e., S k = S s i k . We denote a sequence of states of O p from t 0 +1 to t 0 + k as SS 1: k = &lt; s We call SS 1: k a path of O p .

Given RO 1: k , we denote the probability that O p is in state p ( s k | RO 1: k ) . Similarly, given RO 1: k , we denote the probability Now, we can define the probabilistic path prediction problem. D a moving object O p and a probability threshold  X  at time t bilistic path prediction returns a path SS 1: k of length k time steps, which satisfies: (1) p ( SS 1: k | RO 1: k )  X   X  , and (2) for any path of length k + 1 time steps, p ( SS 1: k +1 | RO 1: k +1 ) &lt;  X  . E
XAMPLE 1. In Fig. 3, there are five moving objects: { O p O ,O 3 ,O 4 } . TG stores all their trajectories (see Section 4). At time t 0 = 11 , we want to predict the future path of O p use the 2-backward trajectory of O p , i.e. W 2 = &lt; O p to retrieve reference objects from TG (see Section 5), which are RO = { O 2 ,O 3 ,O 4 } .

Then, PF estimates a future path of O p in two steps. First, at each future time t = t 0 + k , we generate the state space S O p (see Section 6.2). For example, when k = 2 we have S 2 = { s 2 ,s 1 2 } . A sequence of states is a possible path. Next, PF select-s the longest path whose probability is larger than the probability threshold  X  . If there are multiple such paths, the one with the high-est probability is selected (see Section 6.1). In this example, if the user sets  X  = 0 . 4 , the predicted path is SS 1:2 = &lt; s  X  = 0 . 2 , the predicted path is SS 1:3 = &lt; s 0 1 ,s 0
The Trajectory Grid (TG) is a multi-level grid structure, which dynamically stores new (recent) trajectories as they emerge. We use a grid to divide the area of interest into a set of rectangular regions with fixed width. We refer to a region as a cell. Each cell is uniquely identified by a discrete coordinate ( x,y ) the position of the cell in the grid. Hereafter, we use cell ( x,y ) denote the cell. Fig. 4(b) shows the overall structure of TG. Each leaf node in TG corresponds to one cell. In the experiment part, we will discuss how to set the width of cells. If the trajectories do not have synchronised timestamps, we use a cache structure, called Moving Object Cache (MOC), to interpolate the trajectories.
In each cell, we record two pieces of information: density and trajectories passing the cell. The density of a cell indicates the popularity of the cell, i.e., how often the cell is visited. The density provides prior information for  X  X rediction Filter X  (see Eqn. (14)). Each cell in TG has a density counter. If a moving object visits the cell, we increase its density counter by 1. We also update the density of all the cells along the interpolated line (see Fig. 4(a)).
Each cell uses a hash table, called traHash , to store the trajecto-ries passing the cell. The key of traHash is a vector ( O means O i passes this cell at time t . The value of traHash is a vec-tor ( x,y ) , which is the coordinate of the next cell that In this way, we implicitly store moving objects X  trajectories in the cells X  hash tables. Knowing O i in cell ( x,y ) at time t retrieve its following trajectory after t (see Fig. 4(c)). E
XAMPLE 2. In Fig. 4(a), O 1 is in cell (2 , 2) at time t , then it moves to cell (5 , 4) at time t + 1 . We insert a record into the tra-Hash of cell (2 , 2) with key ( O 1 ,t ) and value (5 , 4) . Similarly, we insert the records into cell (5 , 4) and cell (6 , 6) . If we know O in cell (2 , 2) , we can recursively retrieve the approximate trajectory of O 1 after time t (see Fig. 4(c)).
 TG always stores moving objects X  trajectories in the most recent H time units. We denote H as TG buffer interval threshold. In the experiment part, we evaluate and discuss how to determine the value of H . When the moving objects report their new locations, TG updates the relevant cells X  density and traHash, and at the same time, TG also checks the oldest element in the traHash (traHash is implemented as linked hashtable , therefore, the oldest element is always at the end of the linked list). TG then discards the expired elements of trahHashs and updates density counters. F igure 4: (a) Density update; (b) Overall structure of TG; (c) Example of stored trajectory.
We describe how to retrieve reference objects, from which we can easily derive reference trajectories. The general idea is that if O of
The match function defines similarity between trajectories pairs by a boolean function. Given trajectory T i and trajectory have match ( T i , T j ) = true if dis ( T i ,T j )  X   X  , where is a distance function. Besides the high cost for building index to support such match function, it is also not easy to determine the threshold  X  . We define a new match function which has clear semantic meanings and can support high performance query in TG. The definition of match function is as below ( dis () is the Euclidean distance function): D &lt; O i 1 ,...,O i n &gt; is a sub-trajectory of O i and W O ,...,O p h } is the h -backward trajectory of O p , then we have match( T i n ,W h )=true if they satisfy: Intuitions behind the definition are as follows: (c1) requires and W h to be close to each other; (c2) requires every point in to be matched with a point in T i n ; (c3) requires O i and the same direction and tendency.
 In TG, a query is processed in three steps: (s1) for each W h , we define a range CR u =  X  ( O p u , X  ) ; (s2) we obtain objects that have visited any CR u ; (s3) the objects visited all the the time increasing order are reference objects. We omit the proof of this algorithm due to space constraints.

One problem is how to determine a proper value for  X  . The rule we use is to multiply the moving objects X  average velocity by half of the sampling time interval of the trajectories. For example, if the average velocity of the moving objects is 11 . 1 m/s and the sam-pling time interval is 30 seconds, then  X  = 11 . 1  X  15  X  160( m ) E
XAMPLE 3. In Fig. 3, the reference objects of O p are RO = { O 2 ,O 3 , O 4 } , which visit both CR 10 and CR 11 . The reference points of O p at k = 0 are RO 0 = { O 2 5 ,O 3 2 ,O 4 3 } .
The Prediction Filter (PF) is a model for path prediction. The input of PF is a set of reference points and the output of PF is a predicted path. The  X  X onstruction X  process, which iteratively con-structs state spaces and makes the path prediction, runs within PF. We first give an introduction of PF and the probabilistic path pre-diction in Section 6.1. Then, we introduce a hierarchical method to generate state spaces in Section 6.2. We then explain some im-portant functions used in PF in Section 6.3. Finally, we discuss self-correcting continuous prediction in Section 6.4.
PF is based on the Grid-based Filter model[1], which is a gen-eralization of Hidden Markov Model. Recall that s k is a state in state space S k , we denote the probability distribution function of S k by p ( s k | RO 1: k ) , where RO 1: k are observations of state constructs p ( s k | RO 1: k ) recursively, i.e., from p ( s to p ( s k | RO 1: k ) , which is computed by the following function [1]: where
Note that  X  () is the Dirac measure function and w 0 | 0 = 1 discuss functions p ( s i k | s j to generate a state space is discussed in Section 6.2.

To find the longest path whose probability is greater than the given threshold  X  , we increase the length of the predicted path un-til its probability is smaller than  X  . To realize this, we increase the value of k , and for each k value we find a path SS 1: k s ,...,s k &gt; whose value of p ( SS 1: k | RO 1: k ) is maximized and then check whether its probability is still greater than  X 
Let us define a function  X  k  X  1 ( j ) as follows:  X   X  k  X  1 ( j ) is the highest probability that the path ends with state s
Eqn. (4) can be solved by dynamic programming algorithms, such as the Viterbi Algorithm [7]. Algorithm 1 lists the pseudo code for the probabilistic path prediction. The result is a predicted path, whose probability (confidence) is larger than  X  and whose length (in term of time) is longest.
 E
XAMPLE 4. In Fig. 3, we have  X  2 (0) = 0 . 53 ,  X  2 (1) = 0 . 48 ; and  X  then SS 1:2 = &lt; s 0 1 ,s 0 2 &gt; ; if  X  = 0 . 2 , then SS
In this section, we discuss how to generate states of O p at time t = t 0 + k . In a nutshell, we cluster the reference points then convert each reference points cluster to a state.
Algorithm 1: P robabilistic Path Prediction Algorithm input : probability confidence threshold:  X  output : probabilistically predicted path: SS  X  0 (0) = 1 , X  0 (0) = 0 ,  X   X  = 1 ,k = 0 //  X  X ookup X  process, see Section 5 get RO and RO 0 from TG by W h
If | RO | &lt;  X  m Then return NIL //  X  X onstruction X  process, see Section 6 while  X   X   X   X  do 5 k = k + 1 6 get RO k from TG based on RO k  X  1 7 generate state space S k // Section 6.2 8 for i=1 to | S k | do 10  X  k ( i ) = arg max B acktrack SS from matrix  X  and return SS
We do not use traditional clustering methods (such as K-means o r DBSCAN) because it is hard to determine their parameters in our problem. Furthermore, we would like to generate states that cover small areas (i.e., the radius is small) but have high probabilities (i.e., p ( s k | RO 1: k ) is high). Traditional clustering methods are unable to find a compromise between these two contradictory criteria.
We propose a hierarchical method to generate states (see Fig. 5). Moreover, we define a score function to find local optimal that balances the area size against the probability of the state.
Now we discuss how to build a state space tree. We use a mod-ified agglomerative hierarchical clustering algorithm to merge the reference points. Then all clusters in each level of the cluster tree are converted to one candidate state space of O p (which is a set of states, one cluster for one state).

Suppose  X  is a set of reference points in RO k , i.e.,  X   X  RO we can define Centroid (  X  ) and Radius (  X  ) as follows:
The mean distance between two clusters is defined as :
The bottom-up red arrow in Fig. 5 shows the agglomerative clus-tering process. At level 0, we treat each reference point as a cluster. Then, we continuously merge a cluster with its nearest cluster by the mean distance, until its radius is larger than a threshold. Then we double the radius threshold, and merge the clusters again. The process repeats until there is only one root cluster. Initially, we set the radius threshold R =  X  (  X  is described in Section 5) since defines a proper size of the area in the environment.

Then, we generate the state space tree. For a cluster  X  i of the cluster tree, we construct a state s i k,l = (  X  ( Centroid (  X  Radius (  X  i l )) ,k ) . The state space at level l is S k,l Time complexity . We index reference points by a k-d tree [2]. Suppose the total number of reference points is n . The time cost for building k-d tree is O ( n log n ) . The time cost for nearest neighbor search in k-d tree is O ( n 1 2 ) . Our agglomerative clustering algorith-m is based on [6], and every point needs to merge with others only O (1) times. To sum up, the total time complexity is O ( n
We define a score function to select the state space with the high-est score from the state space tree by a top-down manner. All states in one level of the state space tree can be considered as a state space; we denote the state space at l th level as S k,l . The score function is to measure the quality of a state space. For a state, we hope it has a high probability ( P ( s k | RO small radius. However, the states at a higher level of the state space tree have larger probabilities, but also have larger radii; and vice versa. Our objective is to find an optimal compromise between the probability and the radius.
 Suppose the state with the largest probability in state space is r k,l is the radius of s  X  k,l . Our score function is:  X  in Eqn. (7) controls the compromise between the probability and the radius. We will evaluate how to set  X  . We choose the state space with maximum f k,l as our state space at time t 0 + k Fig. 5 we choose the states at level 2 as the state space.
The benefit of the top-down strategy is that we can prune nodes at low levels of the space tree. At one level, if all the states X  proba-bilities are smaller than  X  , we stop moving down to lower levels.
We improve the efficiency of state generation by reusing micro clusters. The basic idea is that objects X  locations are changing grad-ually [22]. By reusing previous clusters at time t 0 + k  X  1 reduce the time cost for state generation at time t 0 + k
A set of reference points in RO k is defined as a micro cluster mic k if Radius ( mic k )  X  d mic . The set of all micro clusters is denoted as MIC k = S on MIC k  X  1 . The whole process is as follows.

First, we get all reference points RO k , and divide them into d-ifferent reference points sets. The reference objects in the same micro cluster of mic j
Second, for every reference point O i v  X   X  j , we check whether it is within the circle  X  ( Centroid (  X  j ) , d mic ) . If the circle, it will be split out as a new micro cluster [22]. All the all the micro clusters generated in this step as MIC  X  k . Third, we use the bottom-up method to merge micro clusters in MIC  X  k , which is the same with the method in Section 6.2.1.
Reusing micro clusters reduces the time complexity of the bottom-u p process. The time complexity of the first and the second step is O ( n ) . For the third step, we need to perform a nearest neighbor query for each micro cluster in MIC  X  k which is indexed by k-d tree. The time complexity of each query is O ( m  X  1 2 ) . ( number of micro clusters in MIC  X  k .) As such, the time complexity of the third step is O ( m  X  3 2 ) . To sum up, the time complexity of reusing micro clusters is O ( n + m  X  3 2 ) . Note that m
The state transition function p ( s i k | s j ity that O p will go to state s i k at time t 0 + k given that s considering two factors: spatial factor and connection factor.
The spatial factor is the extent of spatial overlap between state s | s | s
Connection factor is based on the common reference objects be-tween s j jects within state s i k at t 0 + k . For example, in Fig. 3, we have RO ( s 0 2 ) = { O 2 ,O 3 } . The connection factor is defined as
We combine Eqn. (8) and Eqn. (9) into a linear function: where  X  is used to adjust the weight of these two factors. In our experiment, we set  X  = 0 . 5 . Initially, we have J ( s i up, we have:
The likelihood function represents the probability that RO observed given O p is in state s i k at time t 0 + k . By Bayes X  theorem, we have: p ( s i k | RO k ) can be computed according to the distribution of in different states. The more reference objects O i  X  RO are in state s i k , the higher value of p ( s i k | RO k ) is. Then we have: p  X  ( s i k ) is the prior probability that O will be in s density in TG. We use  X  ( s i k ) to denote the average density of which is the sum of density of all cells in s i k divided by the number of cells covered by s i k . Then the prior probability that in s i k can be expressed as:
Since p ( RO k ) is constant for every state, we have:
In real-life applications, we may need to predict the path of a moving object continuously. Continuous prediction gives us an op-portunity to improve the prediction result. During the prediction, the actual movement of the target object ( O p ) can be compared against the predicted movement. With this information, we can in-crementally refine the prediction model. The basic idea is to give more weight to the reference objects which help us make the cor-rect prediction. Let us consider the following example. E XAMPLE 5. In Fig. 3, at time t 0 = 11 , reference objects of O p are RO = { O 2 ,O 3 ,O 4 } . Suppose after 1 time unit, i.e., t = 12 , O p goes to the state s 0 1 . At t 0 = 12 , we have RO { O 1 ,O 2 ,O 3 ,O 4 } . Since { O 2 ,O 3 ,O 4 } have helped us make the correct prediction, it is reasonable that we can trust them more than O 1 when we make future prediction.

Now we introduce a new attribute, called credit , for the moving
We use a linear growth and exponential decay method to update moving objects X  credits. From t to t + 1 , the credits are computed as follows: (s1) Suppose O p is in state s j 1 at time t + 1 O ( linear growth ); otherwise, C i t =  X  1 2 C i t  X  ( e xponential decay Retrieve RO t +1 from TG at time t + 1 , and initialize the credits of the reference objects as 1. (s3) For each O i  X  RO t , if O
To integrate this self-correcting method into our prediction mod-el, we need two modifications. First, during the state generation (see Section 6.2), we use the weighted center of cluster Centroid to replace Eqn. (5):
Second, we integrate credits (as weighted coefficients) into Eqn. (9) and Eqn. (13). For example, we use Eqn. (17) to replace Eqn. (13). Eqn. (9) is modified in the same way.
We evaluate R2-D2 X  X  performance on real-world and synthetic data sets. We compare R2-D2 with two state-of-the-art prediction methods: RMF [23] and TraPattern [18]; and study R2-D2 X  distinct features, such as the confidence threshold  X  and the self-correcting continuous prediction. Efficiency issue is also discussed.
Data sets: Two real-world data sets and four synthetic data sets are used in our experiment, Table 2 summaries their details: [ST] is a collection of trajectories of 13,200 taxies in Singapore over one week [25]. Each taxi continuously reports its locations every 20-80 seconds. We interpolate the trajectories over fixed in-tervals with 30 seconds spacing. Totally, the dataset contains 268 million points. [HT] is a collection of human trajectories tracked from 30 min-utes surveillance video in a lobby of a train station [29]. The video is 24 fps with a resolution 480  X  720 . Since high sample rate is not necessary, we downsample the timestamp interval of trajectories to 1 second. There are 9,800 trajectories and 159K points. [BT] We use Brinkhoff generator [3] to generate four collections of synthetic trajectories on the road map of Oldenburg (see Table 2). Different from ST and HT, BT has 10 different types of moving objects. The speed of moving objects may change at each time unit. We also put 400 moving obstacles in the space to simulate the changes of the environment. We generate the trajectories for 400 time steps, and each moving object generates one point at each time step. We use the default time units and distance units of the generator. Note that the system performance is mainly affected by the total number of moving objects; therefore, these large synthetic datasets are also used to test the scalability of our model. Settings: The experiments are conducted on a PC with Intel Q9550 Core Quad CPU 2.83GHz and 3.00GB RAM running Win-dows XP. All programs are implemented in Java with JDK 1.7. Ta-ble 3 lists all parameters used throughout the experiments. Parame-ters are set to default values ( bold font ) unless explicitly specified.
Competitors: R2-D2 is compared with two state-of-the-art al-gorithms: (1) Recursive Motion Function (RMF) [23] that is a de-scriptive model-based path prediction method and is the most accu-rate motion function in literature [23, 8]; and (2) Frequent Trajecto-ry Pattern (TraPattern) [18] that is a general (i.e., not personalized) pattern-based path prediction method. Configurations of RMF and TraPattern are set for their best performance in terms of accuracy by their performance studies. In order to mine patterns for TraPat-tern, we use data between 19:00-20:00 from Monday to Friday of ST, use all trajectories of HT and BT.

Measurement: In order to assess the quality of the prediction result, we define four metrics. We use the centers of states as the predicted locations. All errors are measured by Euclidean distance. For a moving object, the prediction distance error at a predict-ed time is the spatial distance between the predicted location and the real location of the object. Maximal distance error is defined as the maximal prediction distance error during the whole predict-ed time frame. Prediction length is the length (time duration) of a predicted path. Prediction rate is the fraction of query trajec-tories for which the model outputs prediction (i.e., the number of predictable query trajectories over the total number of query trajec-tories). These measurements have been used to assess the quality of prediction models in [16, 8, 9].

Methodology: For ST data set, we randomly select 200 trajecto-ries between 19:50-20:00 on Tuesday as trajectories for prediction. We warm up TG with the Tuesday trajectories from 17:00-19:50. For HT data set, we randomly select 50 query trajectories within the [16,20] minute interval. We warm up TG with the trajectories within the [0,16] minute interval. For BT data set, we randomly se-lect 1000 query trajectories within the [380,400] interval. We warm up TG with trajectories within the [0-380] interval.
We find that R2-D2 outperforms the competitors in terms of pre-diction rate and prediction distance error by 2 to 5-fold.
We show the result on prediction rate in Fig. 6 (a), (c), (e). As the prediction length gets longer, the prediction rate gets lower. How-ever, the prediction rate of TraPattern is much lower than R2-D2 in all prediction lengths. For example, in Fig. 6(a), more than half of the predicted paths on ST can be longer than three minutes, while 20% trajectories have predicted paths with seven minutes. Where-as TraPattern cannot give prediction results for more than half of the prediction requests even when the predicted path length is short (e.g. 1 minute for ST). We do not show the prediction rate of RM-F in the figures since its prediction rate is always 100%, but the prediction error may be extremely large as shown in Fig. 6(b).
Fig. 6 (b), (d), (f) show that R2-D2 has not only higher pre-diction rate, but also much lower average prediction distance error than those of RMF and TraPattern. In term of average prediction distance error, R2-D2 outperforms RMF by 5 times on ST, 3 times on HT and 3.5 times on BT-200K; and R2-D2 outperforms Tra-Pattern by 2 times on all data sets. Note that the longest pattern mined by TraPattern is about 8 minutes, therefore, in Fig. 6(b) the TraPattern cannot predict any path longer than 8 minutes.
In this section, first, we can see the confidence threshold ables users to control the tradeoff between the prediction accuracy and the prediction length. Second, we show self-correcting contin-uous prediction can reduce the maximal distance error by 50%.
We study the effect of the confidence threshold  X  , in particular on the maximal distance error and the prediction time length. It is desirable to have a low maximal distance error and a long predic-tion path. However, a longer prediction path typically comes with a larger prediction error. Fortunately, in R2-D2 users can use the confidence threshold  X  to control the trade-off between them.
In Fig. 7, we show the result on ST and HT data sets. (R2-D2 has the similar result on BT, we do not show it due to space con-straints.) We can see that the maximal distance error and the predic-tion length are statistically correlated with the confidence threshold. When we increase  X  , both maximal prediction distance error and prediction length decrease.
We evaluate the effect of self-correcting continuous prediction of R2-D2. For each query trajectory, we perform prediction with a fixed prediction length (next 15 time steps). For each prediction, we do prediction with two different methods: R2-D2 with and without self-correcting continuous prediction (denoted as conR2-D2 dirR2-D2 , respectively). We set the current location to be the loca-tion of the object at next one time unit from the previous time, and repeat the same prediction process. For each prediction, we sum the maximal distance errors of conR2-D2 and dirR2-D2 , and com-pute the ratio of them, which is ratio = conR 2  X  D 2 indicates conR2-D2 performs better than dirR2-D2 ; and vice versa.
The curves in Fig. 8 show a clear trend that the performance of conR2-D2 improves gradually with the continuous prediction. (BT data sets have the same trend, and we do not show them due to space constraints.) Since the ratios are noised over time, we use Be ` zier Curve to fit them over all the prediction steps.
We show that R2-D2 makes path prediction in real time. In Table 4, we can see the average response time of R2-D2 is only several milliseconds on HT and ST. Even for the largest dataset BT-200K, the response time is still acceptable. From BT-25K to BT-200K, we can see R2-D2 can scale linearly with the number of objects. Be-sides, the update process of TG is quite efficient, we do not discuss it due to space constraints.

We do not show the response time of RMF and TraPattern. Since they only need to compute a math function or match patterns, their response time is faster than R2-D2. Note that we use a prefix tree to compress and index the patterns for TraPattern. Without such index, the time for matching patterns is unacceptable.

Effectiveness of reusing micro clusters: T able 5 shows that reusing micro clusters halves the response time. The value of means the times of cell width. We can see that when d mic cell _ width , average response time is about a half of that when d mic = 1  X  cell _ width . Note that d mic = 1  X  cell _ width reusing micro clusters is disabled since only points in one cell form a micro cluster. d mic has little effect on the prediction error and the prediction length, we do not show them due to space constraints.
W e present the effect of parameters in R2-D2. We only show the experimental results on ST due to space constraints. In Fig. 9, we use two y-axes: the left one is the maximal distance error and the right one is the prediction length. It is worth noting that for all datasets we set the same default value of h and  X  , and they work well.

Cell width of TG: Table 6 shows the memory needed by TG and the maximal distance error with different cell width. We can see that using larger cell size can reduce the memory cost, but al-so lead to larger maximal prediction distance error. The reason is that smaller cell size can better approximate the true distribution of moving objects.

TG buffer time interval H : H determines the length (in terms of time) of trajectories indexed in TG. From Fig. 9(a), we can see that both the maximal distance error and the prediction length in-crease with the increasing of H , but the maximal distance error increases a little faster. When H is larger, TG contains older trajec-tories, some of which may be misleading when being used as ref-erence trajectories. To balance the maximal distance error against the prediction length, we set H to 1 hour.

Backward steps h : Fig. 9(b) shows that as h increases, the maximal distance error reduces slightly but the prediction length reduces dramatically. When the number of backward steps is larg-er, the trajectories of the selected reference objects are more similar to that of the target object, therefore, the maximal distance error is reduced. However, at the same time fewer trajectories are used for prediction, therefore, the prediction time length reduces dramati-cally. To balance them, we set h=3.  X  of the score function: We investigate the effect of  X  of the score function (Equ. (7)), shown in Fig. 9(c). A larger  X  shorter prediction time length and smaller maximal distance error.
Figure 8: Self-correcting continuous prediction: ra-t io&lt;1 indicates R2-D2 with self-correcting is better than R2-D2 without self-correcting. T he reason is that when  X  is large the score function always gives a high score to the state space with the small radius; then the maximal distance error is reduced. However, since the state radius is small, the probability of this state is also small. It leads to the fact that the path probability decreases dramatically over time. To balance distance error against prediction time length, we set  X  to 1
W e also study the effect of other parameters in R2-D2, and find that they do not affect R2-D2 X  X  performance much. For example, if minimum support  X  m is not set too small (e.g., 3) or too large (e.g., 50), it has little effect on R2-D2 X  X  performance. For all data sets, we set  X  m = 10 , and it works well.
In this paper, we propose a  X  X emi-lazy X  approach for performing probabilistic path prediction. Unlike previous approaches adopting eager learning, we propose to leverage on the growth of computing power by building prediction model on the fly, which utilizes his-torical trajectories that are dynamically selected. Our experiment shows that this self-adaptive  X  X redict-on-the-go X  approach can out-perform existing eager learning methods in dynamic environments. We plan to apply this approach on other data mining tasks that are required to work in a dynamic environment.
We thank all anonymous reviewers for insightful comments. This research was carried out at the SeSaMe Centre. It is supported by the Singapore NRF under its IRC@SG Funding Initiative and ad-ministered by the IDMPO. The work by Wei Wu and Wee Siong Ng was partially supported by the A*STAR Grant No. 1021580037.
