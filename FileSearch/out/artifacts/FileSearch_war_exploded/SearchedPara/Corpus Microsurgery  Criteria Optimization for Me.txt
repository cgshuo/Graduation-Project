 Automatic subset selection from a parallel corpus signifi-cantly improves cross-lingual information retrieval (CLIR) performance, in addition to increasing its efficiency. Our selection method extracts relevant training data by incor-porating additional criteria (i.e. estimated corpus quality, taxonomy projection and size) in addition to lexical-based criteria. The challenge lies in combining these criteria using a meaningful scoring function that can be used for ranking parallel sentence candidates. We choose weighted geometric mean for its soft-AND properties, and we optimize crite-ria weights by wrapping the CLIR task in an optimization shell. Due to the indeterminate nature of the search space convexity properties, we have explored continuous reactive tabu search (CRTS), a global optimization method. We use a large parallel corpus in the medical domain to examine the effect of adaptation criteria and their combination on CLIR performance. In our experiments, 100 selected sen-tences yield 90% of the performance obtained with 5,000 times more in-domain parallel sentences. Our optimized cri-teria weights considerably outperform the uniform distribu-tion baseline, as well as lexical similarity adaptation. Categories and Subject Descriptors: H.3.3 Information Storage and Retrieval: Information Search and Retrieval  X  selection process General Terms: Algorithms, Experimentation Keywords: Cross-language information retrieval, domain-specific translation.
Domain-specific translation is crucial for cross-lingual re-trieval in patents, instruction manuals, medical articles or other technical literature. The performance penalty in these multilingual tasks is staggering unless translation model adap-tation is employed. For domain adaptation related work and an expanded motivation, see [2]. In the case of today X  X  heterogeneous parallel corpora, it is especially important to consider issues such as corpus and translation quality, noise, size distribution, redundancy, genre or other available meta-data in additional to lexical similarity. In this paper, we dis-cuss a CLIR corpus adaptation framework that incorporates several adaptation criteria, and we focus on the challenge of combining these criteria: in particular, on the problem of as-signing the relative importance to each criteria when ranking parallel sentence candidates.
The domain-specific corpus we are using is MedCat , a collection of half a million titles of French medical articles, together with their English counterpart and correspondng MeSH categories. The collection has been mined by the authors from the PubMed online database.

Our domain specific target corpus is Springer : 9 , 640 doc-uments (titles plus abstracts of medical journal articles) in English and in German, with 25 queries in both languages, and relevance judgments made by native German speakers who are medical experts and are fluent in English. We have augmented the dataset with French, Italian and Spanish ver-sions of the queries, translated by human domain experts.
We have built a corpus-based CLIR system that, given a parallel corpus, uses point-wise mutual information to mea-sure empirical association between term s (in the source lan-guage) to term t (in the target language)
We define the similarity of each candidate sentence in the parallel corpus to the domain sample as the probability of a segment to be generated by the domain sample. A candidate training instance (i.e. a parallel corpus sentence ) is selected according to its nearest neighbors in the domain sample. We use the mean reciprocal rank ( MRR ) over all domain sample datapoints in order to score a candidate.

The other criteria we examined are estimated corpus qual-ity (TQE), sentence length and taxonomy projection. For details on criteria implementation and discussion, see [2].
Post-normalization linear combination allows i.e. mis-aligned sentences (poor TQE) to have a high score if i.e. the domain match is high, which is not a desirable effect. Instead, we use weighted geometric mean,  X  c of the criteria with value c i and weight w i , which is defined as
The problem of assigning criteria weights requires optimiz-ing a highly non-linear, non-convex multi-dimensional func-tion. Since multiple local optima exist, we require a global constrained optimization method; most of them, however, suffer from several drawbacks: requiring a (fast) calculation of the objective function gradient, requiring smooth con-tinuous functions or the availability of a formula, and/or requiring too many objective function calls.

We are optimizing CLIR average precision f :  X   X  R , where  X  is the set of feasible points and a subset of R n fined by bounds on the n weights w i : 0  X  w i  X  1. Our function f  X  X  convexity and differentiability cannot be relied upon, therefore algorithms such as simple hill climbing are not recommended. We use CRTS [1], a global, deterministic, tabu-search based optimization method that uses the reac-tive affine shaker (RASH) algorithm as its local optimization routine. CRTS focuses on locating the set of promising boxes in the search space, and it initializes RASH while adapting box size and other search parameters. Figure 1 shows CLIR results on the Springer queries.The X-axis represents the number of parallel sentences selected. Figure 1: Springer FR-EN CLIR: MAP when the par-
Due to the medical terminology similarity in the two lan-guages, morphological processing alone with no translation performs higher than in the general domain. The random setting is a high baseline, due to the random selection be-ing performed in a corpus that is already domain-specific. We can manufacture an arbitrarily low strawman baseline by incorporating additional non-domain-specific data.
The best performance is obtained when the entire corpus ( 500K parallel sentences) is utilized. The important obser-vation emerging out of this log-scale plot is that 90% of the performance is obtained at the 100 sentences level, when they are selected using MRR. In other words, when MRR is used, the parallel corpus translation cost is reduced by sev-eral orders of magnitude, while the CLIR performance level is reduced by only 10%. Table 1: CLIR Average precision for criteria combina-
In this case, both RASH and CRTS reached the same optimum (convergence plots in [2]). The optimized criteria weights were used to adapt a 100-sentences parallel corpus to the test queries, then to evaluate the CLIR performance. Results are shown in Table 1.

It is important to note that the  X  X qual weights X  baseline significantly underperforms the MRR-only condition, which is outperformed by our optimized criteria weights.
We have examined the problem of learning the relative im-portance of miscellaneous criteria incorporated in a domain adaptation method or cross-language IR. In particular, we have used global and local optimization methods in order to find optimal weights assigned to criteria such as lexical similarity, corpus quality and instance size.

We have also introduced a new, large medical domain par-allel corpus, annotated with MeSH taxonomy information. By adapting the translation model, we significantly alleviate the considerable performance penalty incurred when using a proven high-performance (but general domain) CLIR system on domain specific test data.

When data is costly to translate -as it usually is the case with domain-specific data -appropriate selection is crucial. For CLIR, the results obtained under these circumstances show that 100 selected sentences can lead to 90% of the performance obtained with 5000 times more in-domain data.
Relative criteria weights optimized with two learning meth-ods (RASH &amp; CRTS) allow a corpus-based, domain specific CLIR system to outperform the two high baselines repre-sented by a) giving criteria equal importance and b) using lexical similarity alone.
