 Wearable devices such as Google Glass are receiving increas-ing attention and look set to become part of our technical landscape over the next few years. At the same time, lifel-ogging is a topic that is growing in popularity with a host of new devices on the market that visually capture life experi-ence in an automated manner. In this paper, we describe a visual lifelogging solution for Google Glass that is designed to capture life experience in rich visual detail, yet maintain the privacy of unknown bystanders.
 We present the approach called negative face blurring and evaluate it on a collection of lifelogging data of around nine thousand pictures from Google Glass.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Human Factors, Management Lifelogging is the process of digitally sensing life activities in detail and storing this in a digital archive for later refer-ral [5]. There are many forms of lifelogging from the Quan-tified Self style personal analytics to the extreme lifelogging of MyLifeBits [4] or the visual lifelogging of Lee et al. [8]. Lifelogging relies in the main on the availability of wear-able computing devices that can sense life activities in suffi-ciently high fidelity. The dominant lifelogging devices used to date are wearable cameras that passively capture user ac-tivities. Wearable cameras such as the OMG Autographer, the Narrative Clip, and even more flexible camera equipped wearable devices (e.g. Google Glass 1 ) , all support the gen-
Although Google Glass is not designed as a lifelogging de-vice, it is a programmable platform, hence we have been able to develop lifelogging tools as Glassware ging is that it can provide benefits to the user in terms of enhanced reminiscence or reflection about their past, the ability to search through past activities to answer specific questions ( retrival ) or to recollect past experiences or even to remember future intentions . Many of the early uses of lifelogging have focused on deploying wearable cameras to provide memory assistance for memory impaired and con-ventional users, along with a new source of data for long-term user studies [6].
 However, none of the previously developed lifelogging proto-types take a privacy-by-design [7] approach, which is a pro-posed framework for ubiquitous computing that integrates privacy and data protection as core considerations through-out the entire life cycle of a technology, from design, through use and eventual disposal. Privacy by design principles are based on seven foundations from [3]; proactive not reactive, privacy as the default configuration, privacy embedded into the design, privacy as additional (not reduced) functional-ity, end-to-end data security, visibility/transparency and re-spect for the privacy of the individual user. From these seven principles, we choose to make privacy the proactive default configuration, inherent in the design of the software, that separates the lifelogger from the data and which respects the privacy of unwilling subjects and bystanders.
 We believe that the identifiability of an individuals face in lifelog imagery is the main factor currently in preserving or violating that individual X  X  privacy. For this reason, the evaluation of our system is based on the effectiveness of face detection and face recognition in lifelogging images. Much previous research has been done on face detection and recognition, among the most widely used are Haar-like Feature-based Cascade Classifiers [11] for detection, and Eigenfaces [10], Fisherfaces [2] and Local Binary Patterns [1] for recognitation. Our system is composed of two parts: a Google Glass glass-ware application and an independent online server (the lifelog), see Figure 1. The glassware acts as the data gathering tool and can either capture images automatically based on time triggers, or can capture images triggered by a user blink. The glassware uploads the image to the server post-capture and there the images are stored (along with metadata) in their original form. Faces in the images are identified (see below) and at query/request time, the current privacy poli-cies are applied (using the privacy filter) before the data is shown to the lifelogger. The interaction interface is currently WWW-based.
 Although the expectation is that any source of faces could be employed to train the system to identify recognisable faces (for example a social network photo list), in this implemen-tation, the individual is required to provide sample face im-ages to generate the policy profile for that user. A face is blurred if it is not recognized to be a known face from the policy store, hence the default configuration of this system is that a face is blurred by default, unless it is recognised as a known and allowed face.
 in Figure 2. The interface presents images captured by Glass to the user chronologically. It allows the user to view, download and delete their own images, add and remove nom-inated friends, as well as offering a simple breakdown of the number of images captured per day, month and year. At present, the friend/bystander relationship is reciprocal, meaning that the image of the lifelogger will not be subject to blurring in the lifelogs of any of their nominated friends. Figure 2: WWW Interface showing showing the blurred face of an unknown bystander. Successful implementation of a user X  X  privacy policy is de-pendant upon two factors, face detection and face recogni-tion. To determine the effectiveness of our system, two eval-uations were performed using 8,657 images collected from Google Glass by three users over 148 days.
 For face detection, images containing faces, in which all faces were detected and images that contained no faces that were correctly identified as such, were considered a pass. Images containing faces in which any of the faces were not detected were considered a fail. Of the 8,657 images, the system produced 6,985 passes and 1,672 fails generating a pass face detection accuracy of 80.68%. Some faces fail to be detected because they are too small, heavily shadowed or are in some way occluded.
 For the second part of our evaluation we concerned ourselves with implementing the privacy policy and blurring unknown faces (the negative face blurring). Taking the output of the face detection process, each detected face was extracted from the image and the number of faces that were correctly classi-fied as friends, the number of false positives (i.e bystanders classified as friends) and false negatives (i.e. friends clas-sified as bystanders) were identified. For this evaluation, 1,300 pictures with faces were randomly selected from the data set. Using the approach outlined above, 1,310 faces were detected. The false positive rate was 0.76% and the false negative rate was 29.01%. A total of 67.18% of the faces were correctly identified as bystanders. In this paper, we presented a first implementation of a privacy-aware lifelogging solution and the first Google Glass visual lifelogging solution that actively blurs all faces except those
