 In this paper, we characterize the performance of the TPC-H bench-mark for a popular column-oriented database called MonetDB run-ning on a dual-core AMD Athlon machine. Specifically, we mea-sure the performance of key microarchitectural components and analyze in detail the nature of various stalls namely cache stalls, branch misprediction stalls and resource stalls. We compare our results with published results on the characterization of TPC-H for row-oriented databases. As opposed to the previous approaches, we use thread-level monitoring of database threads to study the perfor-mance of the database in isolation from the rest of the system. H.4.0 [ Information Systems Applications ]: General Measurement, Performance Performance profiling, TPC-H, column-oriented databases, Mon-etDB
Recent times have seen substantial academic research and cor-responding commercial ventures in the area of column-oriented database systems, including MonetDB [1], C-Store [2] and Ver-tica [3]. However, there have been relatively few detailed stud-ies in analyzing the performance of TPC-H workloads for column-oriented databases on modern hardware. In this paper, we present our perspective on the characterization of TPC-H workloads for a column-oriented database MonetDB run on a modern dual-core AMD Athlon processor. By comparing our results with existing published research on the characterization of TPC-H queries on row-oriented databases, we find that although column-oriented data-bases such as MonetDB typically outperform row-oriented data-bases, MonetDB does not dramatically outperform row-oriented databases in utilizing the underlying hardware.
Previous research shows that current row-oriented DBMSs per-form very poorly in OLAP (and even OLTP) applications on mod-ern processors [4, 5]. In superscalar processors, an average 50% of the time is spent on stalls that cannot be overlapped with com-putational execution for DSS workloads [4, 5]. L2 data cache and L1 instruction cache misses account for nearly 40%-90% and 5-20% of the total memory stall time, respectively [4]. Recently, L2 hit latencies become the dominating factor of execution time as L2 cache sizes increase. As a result, L1 data cache locality has become critical to improving database performance [6]. Ad-ditionally, branch mispredictions account for nearly 10-20% of the stall times [5]. Out-of-order execution of instructions in modern superscalar processors does not alleviate the problem completely. Resource stalls such as dependency stalls and functional unit stalls also account for nearly 10-30% of the total stall time [4]. Hence, there has been a growing interest in column-oriented databases [1 X  3]. However, there have been few investigations in characterizing the performance of TPC-H queries on column-oriented databases. Although Stonebraker et al. [2] presented compelling results on the run-time characterization of a column-oriented database  X   X  X -store X , we believe that there has not been any substantial investiga-tion in the detailed hardware characterization of TPC-H benchmark for column-oriented databases. This is precisely our objective in this paper.
As part of this work, we have evaluated the performance of a column-oriented database MonetDB on an AMD Athlon 64 X2 dual-core processor with each core running at 2.2 GHz. Each Athlon processor core has separate 64Kbyte, 2-way set-associative instruc-tion and data L1 caches. Each processor core also has a unified 512 Kbyte L2 victim cache. The data cache has eight banks to support concurrent access by two 64-bit loads or stores. The L1 Instruc-tion TLB (ITLB) and Data TLB (DTLB) are both thirty-two entry fully-associative TLBs each. The L2 TLB is a unified 512-entry, four-way set-associative TLB. Each entry in the TLB maps to a 4K page in memory. We measured the performance of the 22 queries from the TPC-H benchmark (with scaling factor = 1.0) using Mon-etDB on Fedora Core 8 (codename Werewolf) with Linux kernel version 2.6.23.9. This kernel was patched with perfmon2 to evalu-ate the per-thread performance of MonetDB version 4.
Figure 1 shows the overall breakdown of execution time. As seen from this figure, the database is performing useful computa-tion only for 40-50% of the time.

As can be seen from Figure 2, LS-Full (meaning load/store buffer full) is the single most important contributor to the stall, contribut-ing as much as 50-60% of processor stalls. As the Load-Store buffer is used to hold stores waiting to retire as well as requests that missed the data cache and are waiting to refill, this result indi-cates that extremely tight data dependencies in databases coupled with L1 and L2 data cache misses and hit latencies are a major con-tributor to the performance impediment of databases. The second most important contributor to the stalls is RS-Full (meaning integer tion reservation stations in an AMD Athlon are full nearly 18-25% of the time. Following these stalls were ROB-Full stalls (about 9-13%) and branch abort stalls (about 10-15%). These stalls indicate that database systems show there is a mismatch between instruc-tions in flight in the pipeline and the depth of the re-order buffer. It can also be attributed to the fact that ROB becomes full as memory intensive instructions are waiting to retire. This situation is exac-erbated by the fact that the ROB may become full and then due to branch mispredictions maybe flushed out causing unnecessary instruction paths to be stored in the ROB.
Figure 3 shows the components that contribute to memory stalls, namely, L1 instruction cache stalls, L1 data cache stalls, L2 cache stalls due to instruction and data misses, L1 ITLB stalls, L1 DTLB stalls and L2 TLB stalls for instructions and data. We have used the calibrator tool provided with MonetDB [1] to calculate these stall penalties. Table 1 shows the average percentages of all memory stalls in our work. Our results for L2 cache stalls for data are sim-ilar to those found by Ailamaki et al. [4]. L2 cache stalls for data are still one of the major contributors to memory stalls. Ailamaki et al. [4] reported that L1 data cache miss stalls contribute to approx-imately 5-6% of total memory stalls. Our results indicate that now, L1 data cache miss stalls (or L2 cache hit stalls) have become more important than L2 cache miss stalls for data. Moreover, Ailamaki et al. reported as much as 4-40% stalls due to L1 instruction cache misses. However, their results also showed that a  X  X ystem A X  having a small instruction footprint exhibited optimized instruction cache behavior that minimized L1 instruction cache stalls to at most 5% of the total memory stall time. Furthermore, they reported lower instruction TLB stalls for this system. Our results indicate that L1 instruction cache stalls are on average equal to 11.36% while L1 ITLB stalls are about 1.31%. This indicates that the real-time code expansion strategy employed by MonetDB [1] is indeed optimized for the L1 instruction cache as well as the L1 ITLB. Ailamaki et al. did not report the TLB stalls for data due to the limitation of their hardware performance counters. Our hardware platform allowed us to measure these stalls, and interestingly these stalls contribute to as much as 30% to the overall memory stall time. This can be due to the column-oriented nature of MonetDB. As columns might be stored in different pages, there can be a large number of L2 TLB misses for data when performing random scans that access multiple pages. However, once these pages have been fetched into the main memory, MonetDB exploits spatial locality of the data to optimally perform the query operations.
In this paper, we characterize the performance of MonetDB for the TPC-H benchmark queries on a modern dual-core AMD Athlon processor. By comparing our results with existing published re-search in [4, 6], we find that although MonetDB typically outper-forms row-oriented databases, MonetDB does not dramatically out-perform row-oriented databases in utilizing the underlying hard-ware namely, L1 caches, L2 caches, TLBs and the processor (a more detailed analysis can be found in [7]).This indicates that there is still a need to explore solutions to further accelerate column-oriented databases.
