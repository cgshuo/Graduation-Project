 XUAN SONG, XIAOWEI SHAO, QUANSHI ZHANG, and RYOSUKE SHIBASAKI HUIJING ZHAO, JINSHI CUI, and HONGBIN ZHA , Peking University The task of surveillance is to monitor the activities of people in a scene. This requires low-level detection, tracking, and classification, as well as high-level activity analysis and abnormality detection. Both the low-level and high-level tasks can be improved by knowledge of the scene structure (e.g., crowd flow, dominant paths, entry or exit). For instance,  X  X eople and cars are moving on different roads, X   X  X eople only appear/disappear at an entry/exit, X   X  X eople who are in a crowd flow can only follow the other people in it. X  A statistical scene model can provide a priori knowledge on where, when, and what types of activities occur. However, scene knowledge cannot be dynamically learned and updated under existing methods. Furthermore, tracking is the basis of surveillance, playing a crucial role in any kind of monitoring task, but this becomes especially challenging in a high-density, crowded scene, as shown in Figure 1.
In addition, abnormal activity detection is a key component of a surveillance system, and there is an increasing demand for a robust system to detect abnormal activity in a large and crowded area, such as a subway station, public square, or intersection (as shown in Figure 1). However, existing systems are usually based on cameras, which can only cover a small area, suffer from changes in weather conditions, or require the unreliable process of data labeling, and need huge training datasets. Moreover, most of these systems usually face difficulties in performing fully online abnormal activity detection. Due to the real-time nature of many surveillance applications, it is very desirable to have a completely online and automatic system that runs robustly and requires little human intervention. Thus, the purpose of this article is to develop such a fully online system that can not only cover a large and high-density area, but also simultaneously perform the tracking, semantic scene learning, and abnormality detection robustly in an unsupervised way.

The novelty of the proposed system is that tracking, semantic scene learning, and abnormality detection are integrated and can supplement each other in one framework. The key idea of this research and the proposed system is depicted by Figure 2: multiple single-row laser scanners are integrated and cover a large area, providing robust mea-surements of pedestrians. The tracking module then provides the system with a large number of trajectories. Thus, knowledge of the scene structure (e.g., dynamic versus static properties) can be dynamically learned and updated via an online unsupervised learning method. In the meantime, the learned statistical scene model supervises the tracking module to make the results increasingly accurate. Finally, abnormal activity can be detected with the tracking results and the learned semantic scene, both globally and locally. Therefore, this mode of cooperation among tracking, semantic scene learning, and abnormality detection becomes  X  X n adaptive loop, X  not only dynamically reflecting the change of scene structure and detecting abnormal activity, but also solving the tough problems encountered during tracking. Moreover, the entire process is completely online and automatic, thus requiring no human intervention.
The main contributions of this article can be summarized as follows: (1) We de-velop a unified framework that couples the tracking, semantic scene learning, and abnormality detection, which then supplement one another. (2) We apply an online learning algorithm [Vidal 2006] to the trajectories analysis, and make this task online. (3) We develop a fully online abnormality detection method, with the help of tracking and semantic scene learning, which can perform robustly in high-density areas in an unsupervised manner. (4) We present the first application of an online system that can robustly track more than 150 targets concurrently while performing abnormality detection in a real-life scene (JR subway station, Tokyo).

The remainder of this article is structured as follows. In the next section, we briefly review related work, and provide a system overview in Section 3. Section 4, Section 5, and Section 6 present details about the semantic scene learning by tracking, track-ing by semantic scene learning, and abnormality detection by tracking and semantic scene learning. Experiments and results are presented in Section 7, and the work is summarized in Section 8. Multiple Target Tracking (MTT) has been studied extensively, and an in-depth review of tracking literature can be found in a recent survey by Yilmaz et al. [2006]. Typ-ically, multitarget tracking can be solved through data association [Bar-Shalom and Fortmann 1998], which consists of the linear complexity based methods [Jiang et al. 2007] and exponential complexity based: Multi-Hypothesis Tracker (MHT) [Read 1979], Joint Probabilistic Data Association Filter (JPDAF) [Bar-Shalom and Fortmann 1998; Gennari and Hager 2004; Rasmussen and Hager 2001], Monte-Carlo-technique-based JPDA algorithms (MC-JPDAF) [Schulz et al. 2003; Vermaak et al. 2005], and Markov Chain Monte Carlo Data Association (MCMC-DA) [Khan et al. 2006; Yu et al. 2007]. In addition, MTT will encounter incredible difficulties when interactions or occlusions frequently take place among targets. Thus, research has also focused on how to model these interactions and solve the  X  X erge/split X  problem. Representative publications include Bose et al. [2007], Sullivan and Carlsson [2006], Lanz and Manduchi [2005], Leibe et al. [2007], Nillius et al. [2006], Qu et al. [2005], Yang et al. [2007], and Zhao and Nevatia [2004]. More recently, there has been a trend of introducing online learn-ing techniques into target tracking problems, and representative publications include Babenko et al. [2009], Ross et al. [2013], Song et al. [2008a, 2008b] and Avidan [2007]. However, most of the methods mentioned before are difficult to apply to the tracking of hundreds of targets in a high-density, crowded scene. To track a large number of targets in crowded environments, Betke et al. [2007] proposed two cluster-based data association approaches that are linear in the number of detections and tracked objects. However, this method is difficult to use in human-based surveillance applications. Ali and Shah [2008] proposed a floor fields-based method for tracking people in a crowded scene, which is very related to our work. The main difference between their method and ours is that: the computation of a dynamic floor field in Ali and Shah [2008] at a particular time period should use future information, which is not a completely online approach. Moreover, our proposed method is not only a tracking system, but also a semantic scene learning and abnormality detection system, which is quite different from Ali and Shah [2008].

Abnormal activity detection has, however, been an active area of research over the years, and an in-depth review of relevant literature can be found in a recent survey by Chandola et al. [2009]. Typically, abnormality detection approaches can be broadly cate-gorized as supervised learning based and unsupervised learning based. The supervised-learning-based methods must usually predefine the known a priori behavior classes (normal activities and abnormal ones), and utilize the supervised learning model to de-tect the abnormal ones. Representative publications include Mahadevan et al. [2010], Wu et al. [2010], Adam et al. [2008], Mehran et al. [2009], and Patino et al. [2010]. Hence, these methods usually need huge training datasets, which require significant human resources and efforts. In addition, the process of manual labeling is usually un-reliable, and sometimes it is quite difficult to obtain enough abnormal training samples.
In addition, researchers have also proposed some methods to detect abnormal activ-ity in an unsupervised way [Hu et al. 2007; Pusiol et al. 2010; Fu et al. 2005; Junejo and Foroosh 2007; Junejo et al. 2004; Makris and Ellis 2003]. These methods are usually based on trajectory analysis with the help of tracking. The trajectories obtained are clustered, and some small clusters are labeled as abnormal. Moreover, the semantic scene can be easily learned via the statistical trajectories model [Zhang et al. 2009; Wang et al. 2008, 2006]. However, most of these methods are batch, that is, the clus-tering of trajectories is obtained after all the data has been collected and their cluster structure cannot change as a function of time. Hence, they are difficult to apply in on-line and real-time applications. Recently, some promising camera-based systems have been proposed [Xiang and Gong 2008; Wang et al. 2010; Saleemi et al. 2009; Loy et al. 2010] that can perform intelligent surveillance and understand human activities. Due to some essential camera defects, it is difficult for these systems to perform robustly while the weather or light conditions are frequently changing. Moreover, they cannot be applied in some extremely crowded public spaces. Hence, in this article, we first propose a novel system (the earlier version is Song et al. [2010]) that can cover a large and crowded area, simultaneously outputing robust tracked trajectories of pedestrians, semantic scenes in both dynamic (crowd flow) and static (paths, exit/entrance) aspects, and abnormality detection results. In this research, we couple tracking, semantic scene learning, and abnormality detec-tion in a unified framework, and design the overall system as illustrated in Figure 2. The proposed system consists of four main components: sensor module, tracking mod-ule, semantic scene learning module, and abnormality detection module. In the sensor part (as shown in Figure 2), a number of laser scanners are exploited so that a rela-tively large area can be covered while occlusions can, to an extent, be solved. Each laser scanner is located at a separate position and controlled by a client computer. All client computers are connected through a network to a server computer, which synchronizes and integrates all of the data from the client computers. For data synchronization, each laser scan stream is stamped with a time log at the moment it is captured, or starts to be captured, using the client computer X  X  local clock, which is synchronized period-ically with that of the server computer. Data measured by different client computers that is stamped with the same time log is aligned to make up an integrated frame. For registration, a degree of overlay between different laser scans is retained. Relative transformations between the local coordinate systems of neighboring laser scanners are calculated by the pairwise matching of background images using the distances to common objects. Based on the registration, the range data can be easily converted into rectangular coordinates (2D laser points) in the sensors X  local coordinate system, and then the laser points from multiple laser scanners are temporally and spatially inte-grated into a global coordinate system. The final sensor measurements of our system are illustrated in Figure 1. For more details about the system platform, please refer to our previous work [Zhao and Shibasaki 2005].

The tracking module, semantic scene learning module, and abnormality detection module closely cooperate with and supplement each other in the overall system: at first, the tracking module provides the preliminary tracking results; based on these results, the semantic scene knowledge can be automatically learned online using the learning module. Meanwhile, the learned statistical scene model is used in turn to su-pervise and improve the tracking results. As time proceeds, with the increasing number and accuracy of tracked trajectories, the semantic scene model is increasingly accurate and can provide better supervision for the tracking module, which makes the tracking results more robust. Hence, we call this mode of cooperation between the tracking and learning modules  X  X earning by tracking X  and  X  X racking by learning. X  Furthermore, the trajectories provided by the tracking module and the semantic scene knowledge learned by the learning module are combined and simultaneously utilized for the detec-tion of abnormalities. Thus, the proposed system can simultaneously output tracking trajectories of people, semantic scene knowledge of environments, and some abnormal activities. In the following sections, we provide details on how to learn semantic scene knowledge with the tracking results, how to use the statistical scene model to improve tracking, and how to detect some abnormal activities. As illustrated in Figure 3, with the help of tracking, it is easy for us to obtain a large number of trajectories. We can use these trajectories to explore knowledge of a scene at a specific time. First, we should cluster these trajectories online based on different activity types. This is very easy to understand. As shown in Figure 3(a), at a specific time in a subway station, a large number of people get off a train and walk together to catch another train. This would become a crowd flow, and can be seen as a type of activity. Second, we extract knowledge of this scene from these clusters. Scene knowledge contains two properties: dynamic (e.g., information about the crowd flow) and static (e.g., walk paths and sinks/sources). This scene knowledge can provide great assistance to the tracking, and the overall pipeline is illustrated in Figure 3. In this section, we will provide details about these items.
Problem Formulation. At time t , person i is represented by x p trackers, we obtain the N trajectories { L i ( t ) } N i = need to cluster these trajectories into n clusters { S j ( t ) their activities, and each cluster can be seen as a crowd flow (as shown in Figure 3(b)). As time proceeds, some persons in one crowd flow may change their direction of movement, becoming a new crowd flow or associate to another crowd flow. Hence, in order to dynamically reflect such situations and the change of scene information, all of the clustering must be online and vary as a function of time. Therefore, in this research, we apply the online clustering algorithm [Vidal 2006] to our problem, and deal with online crowd flow learning.

The key idea of the overall algorithm is illustrated in Figure 4, and we consider each cluster S j ( t ) as a moving hyperplane. Thus, we can model a union of n moving hyperplane in R D , where S j ( t ) ={ x  X  R D : b j ( t ) x as the zero set of a polynomial with time varying coefficients. Starting from an initial polynomial at time t , the updated polynomial coefficients are computed using normalized gradient descent. The hyperplane normals are then estimated and updated from the derivatives of the new polynomial at each trajectory. Finally, the trajectories are grouped by clustering their associated normal vectors. As time proceeds, new data are added, and the estimates of the polynomial coefficients become more accurate. In addition, the hyperplane will change based on the newly obtained data. Hence, the overall clustering will vary as a function of time, and is fully online and automatic.
Algorithm Detail. In this part, we briefly review the theory of Vidal [2006], and provide the final clustering algorithm for our problem.

Given a point x ( t ) in one of hyperplane S j ( t ), there is a vector b that b j ( t ) x ( t ) = 0. In principle, for the N trajectories S ( t ), we could directly estimate and update their normal vectors through a normalized gradient recursive identifier . However, due to the uncertain laser measurements and frequent appearance/disappearance of persons from our tracking area, sometimes the tracking results are not reliable. Thus, we do not know which data to use for updating each one of the n identifiers in these cases. Therefore, in this research, the n hyperplanes are represented with a single polynomial whose coefficients do not depend on the segmentation of the data. By updating the coefficients of this polynomial, the normal vectors of all hyperplanes can be simultaneously estimated and updated without first clustering the point trajectories.

Thus, the following homogeneous polynomial of degree n in D variables must vanish at x ( t ). This homogeneous polynomial can be written as a linear combination of all the mono-mials of degree n in x , x I = x n 1 1 x n 2 2 ... x n D D n where e I ( t )  X  R represents the coefficient of the monomial x is known as Veronese map [Harris 1992] of degree n , which can be defined as where I is chosen in the degree-lexicographic order and M number of independent monomials.

As a result of polynomial Eq. (2), we can perform the online hyperplane clustering by operating on the polynomial coefficients e ( t ) rather than on the normal vectors { b j ( t ) Thus, at each time t , the estimate  X  e ( t )of e ( t ) can be computed as where the objective function is By using normalized gradient descent, the following recursive identifier can be updated by where the negative normalized gradient is computed as and where  X &gt; 0 is a fixed parameter.

Once we obtain the estimate of e ( t ), it is easy to estimate the normal vector to the hyperplane containing a trajectory x ( t )as where D  X  n ( x ) is the Jacobian of  X  n at x .

Thus, we have obtained the estimate  X  b v ec ( x i ( t )) for the normal to the hyperplane passing through each one of the N trajectories { x i ( t ) The next step is to cluster these normals into n groups. This is done by a recursive K-means algorithm. Essentially, we can seek the normal vectors group indicator  X  ij ( t )  X  X  0 , 1 } of trajectory i to hyperplane j by maximizing Vidal [2006] has proved that the recursive identifiers (6) X (8) provide L mates of the parameters and n can be a variable number. For more details about this proof, please refer to Vidal [2006]. Thus, the overall online clustering algorithm for our problem can be summarized as follows.
Dynamic Properties. Once we obtain the clustering results, it is easy to estimate the spatial extent of each cluster. Each cluster S j ( t ) can be seen as a crowd flow, and we should estimate its density and velocity distribution in the region. For cluster S the density distribution at position p i = ( x i , y i )attime t is estimated as where  X  d is a constant parameter. An example of density distribution is shown in Figure 3(c) where the color denotes the density value.
 ALGORITHM 1: Online Clustering Algorithm
The velocity distribution is based on the principal component of flow orientation, and can be built as Here &lt;, &gt; stands for dot product,  X  v is a constant parameter, ( the velocity expectation of cluster S p ( t ) at a particular position, and principal component in the distribution of flow orientation where Eq. (12) is the GMM model, and the parameters  X  m can be obtained through EM iteration. An example of Eq. (11) is shown in Figure 3(d), where the color denotes the speed, and the arrows display the principal orientation.

The density and velocity distributions for each crowd flow reflect the dynamic proper-ties of the scene. They can provide a motion prior to the targets that are in a particular crowd flow.

Static Properties (semantic words). For a particular scene, there are some constant properties, such as dominant paths, exits, and entrances. We should output these semantic words. They can easily be obtained from the global density distribution (as shown in Figure 3(e)). The global density distribution is similar to the crowd flow density, but instead reflects properties of the whole scene; it can be computed as where is the set of trajectories we have obtained at time t . As shown in Figure 3(e) and (f), after a long time period, the dominant paths of the scene were easily extracted by thresholding the global density distribution.

Additionally, the exits and entrances to the scene are two very interesting proper-ties, known as sinks and sources, respectively. Such scene knowledge can powerfully assist the tracking to deal with the appearance or disappearance of targets. The sinks/sources can be easily detected from the global density distribution D shown in Figure 3(f), the sinks/sources usually occur at regions of great change in the global density distribution after thresholding. Moreover, the changed direction must follow the principal orientation of the crowd flow. Hence, the sinks/sources can be easily found by a gradient search along the principal orientation of each crowd flow, and the results obtained by this method are shown in Figure 3(f).

In summary, with the help of tracking, we are able to learn the following information online: (1) dynamic properties: density distribution D and velocity distribution V of crowd flows; (2) static properties (semantic words): dominant paths, sinks/sources. Such knowledge is very helpful for high-level activity analysis and low-level tracking or classification. In the next section, we will utilize this information to dynamically supervise and improve the tracking results. Knowledge of a scene structure can be of great help to tracking. First, a person in a particular crowd flow will be greatly influenced by it, because he must follow other per-sons in it. The density and velocity distributions can be used to describe this influence and supervise independent tracking. Second, a birth/death probability, which depends on the gradient of the density distribution, is assigned to the targets or measure-ments. This probability can help the tracking deal with the appearance/disappearance of targets, allowing us to maintain correct tracking even while frequent uncertain measurements take place. Consider the state x i , t = ( x i , t , y i , t ,v x i , z mean-shift clustering [Comaniciu and Meer 1999], we estimate its state as The posterior probability p ( x i , t | z i , t ) can be computed by a Bayesian recursion as where  X  is the normalization constant, p ( z i , t | x i , state and their measurement (observation model), and p ( x probability.
 Obviously, the crowd flow will have a great influence on the people who are in it. We can use the density and velocity distribution to describe this influence, and the transition probability of person i in the crowd flow S j ( t ) can be computed as where W is the walking model, which can be a constant velocity model, a second order autoregressive model [Song et al. 2008a] or the  X  X wo feet model X  [Zhao and Shibasaki 2005]. In this research, we utilize a simple second-order autoregressive walking model as where matrices A , B ,and C are of constant ratio, and are obtained by regression with 150 representative sequences. N is the normal distributed random noise. The and their nearest cluster of laser points where  X  p is the constant ratio.

Eq. (16) can be understood very easily. As shown in Figure 5, if an immediate crowd behavior moves in a particular direction, the individuals in it will favor this direction with a high transition probability, and the motion transition will also follow the density and velocity distributions of this crowd flow.

Hence, we can utilize a Particle Filter (PF) [Doucet et al. 2000] to compute Eqs. (14) and (15) and obtain the targets X  state at each time. Most failed tracking in our application was actually caused by uncertain measure-ments. For instance, a new target is often incorrectly initialized due to a false alarm. In addition, merge/split measurements and nondetections due to occlusion often result in breaks in trajectories, because the targets cannot be matched to their measurements. We can easily ameliorate these problems with the help of source/sink knowledge in a scene.

We assigned a death probability P i death to each target and a birth probability P each measurement. If a target with a high death probability cannot find any matching measurement, it can be considered a disappearing target in the scene. Otherwise, it should still be tracked whether or not it has a suitable matching measurement. Similarly, if a measurement with a high birth probability does not associate with any target, we initialize and track it as a new appearing target. Otherwise, it is considered a false alarm. As shown in Figure 3(c), the birth and death probabilities depend on the gradient of the density distribution, and the direction of gradient descent/ascent must follow the principal direction of the crowd flow. Hence, the two probabilities can be computed as where v j is the principal direction of the crowd flow, and eters.

In summary, the tracking benefits from the learned scene knowledge and also pro-vides new results to update this knowledge. Therefore, this mode of cooperation be-tween tracking and learning not only obtains accurate tracking results and scene knowledge, but also ensures that the entire process is completely automatic and online. As illustrated in Figure 2, once accurate tracking results and scene knowledge are ob-tained, they can be used to perform both global and local online abnormality detection. Global abnormality detection can be addressed by tracking, whereas local detection is performed using the learned scene knowledge (dynamic properties). Furthermore, we also consider the learned global scene structure to improve the abnormality detection model further. We utilize the algorithm discussed in Section 4.1 to cluster the obtained tracking results online based on different activity types. The first type of abnormal activity (global detection) can be detected from outlier trajectories of the online clustering. If some clusters contain very few trajectories, their owners are considered to be performing some abnormal activity. An example is shown in Figure 6: at a specific time in a subway station, a large number of people get off a train. Most of them walk along the common path of this subway station, but, in contrast, some people (such as persons 66 and 98) walk along an uncommon path. Their trajectories are difficult to group into any cluster, and these activities are detected by our system as abnormal activity. Another type of abnormal activity (local detection) can be detected via the learned se-mantic scene (velocity distribution) in each inter-cluster. We define the velocity abnor-where a higher energy E v elocity is more likely to be an abnormal activity. Hence, given the velocity distribution V S position p i , t with velocity v i , t , this energy can be computed by where  X  1 is a constant parameter. Once this energy is larger than the threshold, their activities are detected as abnormal.

This can be easily understood. As shown in Figure 6, at a specific time, many people were walking together and going to the same destination, which would become a crowd flow. Usually, people in this crowd flow should follow one another. But in contrast, some individuals (such as person 54) performed quite different motions from others in the crowd, and this activity could be detected as abnormal. Moreover, while normal people are walking in a large and crowded environment, they usually plan to go to a specific exit of the scene, walk on the common road, avoid obstacles, and find the shortest and most comfortable path (as shown in Figure 7). Thus, the learned scene structure (e.g., dominant paths, exits, and entrances) can also help us to detect some abnormal activities.

We assign the scene abnormal energy E scene for each pedestrian to measure her activity, where a higher energy E scene is more likely to be an abnormal one. Given the current position p i , t of pedestrian i by tracking, online learned scene structure map and Q exits/entrances (as shown in Figure 7(a)), it is easy for us to obtain Q planned shown in Figure 7(b)). Hence, a normal person would like to make her motion be more like her planned path, and the E scene can be computed by.
 L t ( x planned trajectories, which depends on the similarity between the person X  X  current trajectory and this planned one. In this research, we utilize the approach of Wang et al. [2006] to measure the similarity of two trajectories. Please refer to it for more details. Once the weights of planned trajectories are very small, we throw them and stop making new path planning for these exits/entrances. Obviously, if this energy is larger than the threshold, their activities are detected as abnormal. We applied our system to a real scene: the lobby of JR subway station, Tokyo (an area of about 60  X  35m). Eight single-row laser scanners (LMS291) produced by SICK were utilized. They were set 10 cm above the ground surface and performed horizontal scanning at a frequency of 37 fps. We utilized a time server to deal with the problem of time synchronization between different sensors, and the calibration was conducted by several control points in a box. For more details about the experimental setting, please refer to Zhao and Shibasaki [2005]. Selected data from between 7:00 am and 8:30 am, which is quite a busy time in Tokyo, were used for the evaluation, and this data contains five clips. In this section, we will present our experimental results and perform a quantitative evaluation and comparison. Figure 8 shows some selected tracking results of our system. The first row contains tracking results, the second contains clustering results, and the third and fourth show the incrementally learned density and velocity distribution maps. From this figure, we can see that people were clearly clustered based on the different crowd flows. In addition, the density distribution map became increasingly clear so as to reveal knowledge of the scene. Furthermore, from the velocity distribution, we can see that people in a crowded place usually walk quite slowly.

As the 1090 frames proceeded, dominant paths and sinks/sources of the scene were obtained, as illustrated in Figure 13. Actually, with an increase in the number of tracking frames, these results can become more accurate.

In some cases, a failed tracking of our system was caused by the highly unreliable measurements (e.g., more than six people were walking together, and the measure-ments were completely merged). In such circumstances, a stronger motion model (e.g., pedestrians X  walking or movement model) for prediction usually plays a more impor-tant role in the overall tracking process. In the future, we will try to enhance the motion model, and consider the social interactions among walking pedestrians to deal with this problem.
 Selected abnormality detection results (without using scene structure information) from our system are shown in Figure 9. The first row shows the tracking results, the second shows the online clustering results, the third contains the incrementally learned motion distribution, and the fourth row shows the abnormality detection results. From this figure, we can see that some suspicious people could be easily detected by our system, such as person 11 and person 111 in frame 600 (what were they doing?), person 67 in frame 762 (walking to an uncommon exit), and persons 263 and 277 in frame 2005 (appearing at an uncommon entrance).

Additionally, we also present the abnormality detection results with scene structure information as discussed in Section 6.3, and they are shown in Figure 10. The first row shows the abnormal energy, where the color shows abnormal energy value, where the darker the greater the value (as shown in the color bar). The abnormality detection results are shown in the second row. From this figure, we can see that some suspicious persons also could be easily detected, such as persons 131, 117, and 60 in frame 50 (walking on the closed road), person 24 in frame 111 (what was she doing?), person 9 in frame 151 (he was not following other persons and walking in a strange path), etc. In order to evaluate the tracking performance of the proposed system, a quantitative comparison was conducted between four methods: Song et al. [2008a] and Cui et al. [2006], a PF-based tracker (no scene learning), and our method.

We made a statistical survey of 3000 continuous frames to evaluate the performance of these methods in a high-density scene. The ground truth was obtained in a semi-automatic manner (trackers and manual labeling). Tracking failures included those where the target was missed, a false location was given, or the targets X  identity was switched, which can be automatically computed from the ground truth. Details of this comparison are illustrated in Figure 11, and the overall success rate of each method is listed in Table I. From Figure 11, we can see that our method exhibits the best performance of the four in high-density scenes, with the scene knowledge providing a performance improvement of about 16%. As illustrated by the tracking results in frame 990, the trajectories obtained by the trackers with no scene learning were quite short and frequently broken. By contrast, with the help of the scene knowledge, our method can easily maintain long-duration, robust tracking. In order to perform a quantitative evaluation of the abnormality detection, we would ordinarily need the ground truth. Obviously, it is hard to say whether a person X  X  activity is abnormal. Thus, we invited three people to label the activity in our data as abnormal or not. One of them has an academic background, and the other two do not have any academic background in this field. At a specific time, if the invited people think the activity of a person is abnormal, based on the trajectories, they will label that person X  X  activity state as 1, and as 0 otherwise. The final ground truth was based on the union of the three people X  X  opinions with its confidence.

We tested our system over 3000 frames, and the ROC curve of our system is shown in Figure 12. In addition, a quantitative comparison was also conducted between our method (using scene structure information and without using it) and some batch-based clustering methods, such as fuzzy K-means and agglomerative clustering. For the two competing algorithms, abnormal activity was detected by finding the outliers of the clusters. The details of this comparison are also shown in Figure 12. From this figure, we can see that the proposed system performs better than the batch-based methods. This is because our system can vary with a change in the situation and detect any sudden abnormal activities in specific frames, which is difficult for the batch-based methods. Besides, with the help of global scene structure information, the abnormality detection results are improved further.
 In this article, we presented a novel online system that can simultaneously perform semantic scene learning, tracking, and abnormality detection in a large, high-density area. The experimental results demonstrated our method X  X  feasibility and robustness. In the future, this work can be extended and improved in the following aspects: (1) Some failed tracking of our system is usually caused by highly unreliable measurements. In such circumstances, a stronger motion model usually plays a more important role in the overall tracking process. Thus, we will try to enhance the motion model, and consider the social interactions among walking pedestrians to deal with this problem. (2) We found that, with an increasing number of clusters, the computation became very large. Hence, decreasing the computational cost and optimizing our system is an important problem. (3) With the laser scanner data, it is difficult to give a single, clear definition of abnormal activity, especially for an unsupervised method. Therefore, a method to scientifically evaluate the detected results is another important issue. (4) The proposed system can easily be extended to intersections for traffic surveillance. In this case, we will encounter different objects, such as pedestrians, bicycles, and cars. Therefore, an object classification module can be added into our system. Obviously, this module can also benefit from tracking and semantic scene learning.

