 Prior works have shown that probabilistic suffix trees (PST) could predict accurately the moving behaviors of objects for prediction-based object tracking sensor networks. However, maintaining PSTs for objects incurs a considerable amount of storage spaces for resource-constrained sensor nodes. In this paper, we derive a distance function between two PSTs and also propose an algorithm to determine the similarity between them. By the distance between PSTs, we propose a clustering algorithm to partition objects with similar moving behaviors into groups. Furthermore, for each group, one PST is selected to predict movements of objects within one group. Experimen-tal results show that our proposed approaches not only effec-tively reduce the storage cost but also provide good prediction accuracy.
 Categories and Subject Descriptors: H.2.8 [Database ap-plications]: Data mining General Terms: Management.
 Keywords: object tracking, group mobility and clustering.
Object tracking is one of the killer applications for wire-less sensor networks. Various energy conservation schemes for OTSN have been extensively studied in the literature. In par-ticular, a predication-based OTSN is shown very energy-efficient by making only those sensor nodes whose sensing regions are likely to contain tracking objects be active, whereas the rest of sensor nodes are put in sleep mode to conserve energy. Obvi-ously, the performance of a predication-based OTSN depends on the accuracy of prediction mechanisms.

Prior works explore a heterogeneous tracking model (abbre-viated as HTM) in which probabilistic suffix trees (PST) are utilized to capture moving patterns of objects [3]. Though HTM has better prediction accuracy, maintaining a PST for each object incurs a huge amount of storage cost. By the ob-servation of group movement behaviors in many creatures, we can exploit such a feature to cluster moving objects with simi-lar moving behaviors into several groups. Then, for each group, we shall select and maintain one representative PST for pre-dicting the movements of objects in the same group. Hence, not only the storage cost is decreased but also the prediction accuracy is preserved.

To realize the concepts above, in this paper, we first de-rive a distance function to measure the similarity of two PSTs. The proposed distance function considers both tree structures and statistical information of PSTs. Then, according to the distance function derived, given a set of PSTs, their similar-ity values are obtained. Based on the similarity values among PSTs, we propose an algorithm to group objects into several groups and guarantee that the objects within a group have similar moving behaviors. To save the storage space of a clus-ter head in each group, we only select one representative PST that is able to accurately predict the movements of objects within the same group. To evaluate the performance of the proposed approaches, we conduct comprehensive experiments and experimental results show that our proposed approaches not only effectively reduce the storage cost but also guarantee the prediction accuracy.

The rest of the paper is organized as follows. In Section 2, the way to capture object moving patterns are presented. The details of clustering objects with similar moving behaviors are described in Section 3. Experimental results are shown in Section 4. Section 5 concludes with this paper.
In this work, we consider a clustering-based sensor network where sensor nodes are organized into several clusters and a cluster head will be elected for each cluster. Each sensor node within a cluster has a unique identification. When detecting an object, a sensor node notifies its cluster head and thus the lo-cation of an object can be represented as a sequence of sensor ids in a cluster head. A cluster head can use such informa-tion to mine object moving patterns for predictions of object movements.

Since the movements of objects have high dependence rela-tionships, a cluster head can adopt a PST to model the moving behavior of an object [3][5]. Specifically, each edge of a PST represents a sensor id which appears in the moving path of an object. A tree node is labeled as r k ...r 2 r 1 can be reached from the traversal path from root  X  r 1  X  r 2  X  ...  X  r k .InaPST, each tree node maintains a conditional table to record the ap-pearing counts and the conditional probabilities of all appeared labels that follow its label. Consider an example PST in Fig-ure 1, where the object frequently travels in area A and area AB (referred a sequential pattern from area A to area B). In addition, the condition table of each node provides statistical information of next movements. For example, the condition table associated with node A reflects that the next movements when the object is in area A are area B (with the probabil-ity being 0.66) and area C (with the probability being 0.33). Consequently, a PST is able to not only capture the moving be-havior of objects but also be utilized for the prediction. Since the main theme of this paper is to cluster similar moving be-haviors of objects, interesting readers could refer to [4] for the construction of PSTs.
In this section, we exploit group mobility for a prediction-based OTSN, which is called a group-based OTSN in this pa-per. Explicitly, a group-based OTSN consists of the following phases: in Phase 1, a cluster head collects movements of ob-jects and constructs PSTs for objects by using the method in [3], in Phase 2, we compute distance values of objects in terms of their PSTs, in Phase 3, by distance values derived in Phase 2, objects with similar moving behaviors are grouped into one group, and at last only one representative PST is maintained for the prediction to save the storage cost for each group in the Phase 4. In the following sections, we describe Phase 2, Phase 3 and Phase 4 in detail.
Asmentionedabove,aPSTisusedtocapturethemoving behavior of an object. To measure the degree of similar moving behaviors among objects, we derive a distance function  X  MSL for PSTs. Inspired by prior works in [2], we first represent a PST into a set of sequences and then formulate the similarity of PSTs through the editing distances between their sets of sequences.

To measure the similarity between two PSTs, both the struc-ture and the statistical information of a PST should be consid-ered. Since the label of a node in a PST is the suffix of the label of its child nodes, a branch in a PST represents a series of fre-quent sequential patterns (represented as sequences of sensor ids). In other words, by extracting a branch in a PST, frequent sequential patterns with the same destination are determined. Such frequent sequential patterns extracted from branches of a PST are referred to as structure information in a PST. As a result, the similarity of two PSTs should take the structure information of PSTs into consideration. Except the structure information of PSTs, we should further consider the statistical information of PSTs. Through statistical information in PSTs, each node can determine its corresponding importance in terms of the probability that indicates how frequent an object travels along this frequent sequential pattern. Thus, when designing a distance function among PSTs, we should give higher weight to a node with higher probability.

Based on the properties above, we propose a distance func-tion  X  MSL which takes the structures of PSTs and the prob-abilities of nodes into account. In order to capture structure similarity of PSTs, we transform a PST into a moving sequence list which is composed of several moving sequences . Formally, a moving sequence of a PST is defined as follows:
Definition 2. Moving Sequence: Given a PST T i ,the j -th moving sequence is defined as L j i =[ TL 1 i,j : p ( TL p ( TL 2 i,j ) , ..., T L i,j : p ( TL i,j )] where TL k i,j node traversing from the root in the j -th branch of the root node and p ( TL k i,j ) is the corresponding probability.
To measure the importance of a moving sequence, the weight of each moving sequence is defined as follows:
Definition 3. Weight of a Moving Sequence: The weight of a moving sequence L j i is formulated as w ( L Consequently, a moving sequence list is defined as follows:
Definition 4. Moving Sequence List: Given a PST T i , the moving sequence list is defined to be L i = &lt;L 1 i L i &gt; ,where n denotes the number of moving sequences and L i denotes the j -th moving sequence.

For example, the moving sequence list in T 1 is &lt; [ A :0 . 5] , [ B : 0 . 375 ,AB :0 . 33] &gt; . Consequently, a moving sequence list de-rived from a PST is able to represent both the structure and the statistical information of a PST. As such, we propose a distance function  X  MSL .GiventwoPSTs T i and T j with their moving sequence lists L i and L j , the distance between two PSTs  X  MSL ( T i ,T j ) is determined by the editing distance be-tween L i and L j ,say ed ( L i [1 ..m ] ,L j [1 ..n ]). The editing dis-tance between L i and L j is determined as the minimal cost of transforming L i into L j via three editing operations: inser-tion , deletion and replacement . To facilitate the presentation, let TL i,m and TL j,n be a pair , L j i [1 ..n ]be L j i with n elements, and L i [1 ..m ]be L i with m moving sequences. Three operations and the corresponding costs are described as follows:
Insertion: We can transform L i [1 ..m ]to L j [1 ..n ]by(1) transforming L i [1 ..m ]to L j [1 ..n  X  1] and then (2) inserting one moving sequence L n j into L j [1 ..n  X  1]. The corresponding cost is the sum of the cost of transforming L i [1 ..m ]to L j and w ( L n j ).

Deletion: We transform L i [1 ..m ]to L j [1 ..n ] by (1) trans-forming L i [1 ..m  X  1] to L j [1 ..n ]and(2) deleting one moving sequence L m i . The corresponding cost is the sum of the cost of transforming L i [1 ..m  X  1] to L j [1 ..n ]and w ( L m i
Replacement: We transform L i [1 ..m ]to L j [1 ..n ]by(1) transforming L i [1 ..m  X  1] to L j [1 ..n  X  1] and (2) replacing a moving sequence L m i to a moving sequence L n j .Thecostof replacing one moving sequence L m i by L n j is the sum of prob-abilities of all elements, which is listed as R ( L m i ,L Figure 3: An execution scenario for the distance of T 1 and T 3 . Only underlined values will be stored in this table. following. The corresponding cost is the sum of the cost of transforming L i [1 ..m  X  1] to L j [1 ..n  X  1] and R ( L
According to the above three operations, we can define the editing distance between two moving sequences lists. Assume that R (  X  ) denotes the cost of replacement operation.
Definition 5. Editing Distance: Given two moving se-quence lists L i and L j , the editing distance is defined as follows: The boundary conditions are as follows: ed ( L i [0] ,L j
By exploiting dynamic programming, Algorithm DP ( D istance of PST s) is proposed to compute the editing distance between two moving sequence lists from the above recurrence relation in a bottom-up manner. Without loss of generality, given two PSTs T 1 and T 2 , the table entry c [ i, j ] represents the minimal cost transforming L 1 [1 ..i ]to L 2 [1 ..j ]. To compute the minimal cost in a bottom-up manner, the c [0 ,j ]and c [ i, 0] for all i and j are determined first and then compute the table entries row by row. For each table entry, three costs should be calculated ac-cording to three editing operations (i.e., insertion, deletion and replacement). Among three costs, each table entry only stores the minimal cost. The algorithmic form of algorithm DP is listed in Algorithm 1. Table 3 shows the execution scenario for Algorithm DP and we can obtain that  X  MSL ( T 1 ,T 2 )=1 . 445. Algorithm 1 DP
As mentioned in Section 2, cluster heads are responsible for tracking objects in their monitored regions. Let active objects are referred to as those objects that are currently in the corre-sponding monitored regions. Consequently, each cluster head maintains a PST for each object that ever stays in its moni-tored region. In order to cluster objects that are currently in a cluster, current locations of active objects should be considered since objects are not always spatially close even if these objects have similar PSTs. Define that object O i is  X   X  close to object O j if the spatial distance of object O i and object O j is smaller than  X  . Our problem can be defined as follows:
Definition 7. Reactive-Grouping Problem: Let the distance function for PSTs be  X  (  X  ). Given a set of objects, the distance threshold  X  t and the spatial proximity threshold  X  we intend to divide objects into groups such that the number of group is minimal and each O i , O j in the same group should satisfy: (i)  X  ( T i ,T j )  X   X  t and (ii) O i is  X  t  X  close to O
In Reactive-Grouping Problem, we divide objects into the minimal number of groups such that only the minimal num-ber of PSTs are preserved, thereby minimizing cost of tracking objects for a cluster head. This problem can be reduced to the problem of finding a minimal clique cover by constructing a graph where each vertex represents an object and an edge between two objects is created if they are  X  t  X  close and the distance of these two PSTs are smaller than  X  t . Therefore, we could group objects by any existing algorithm for fining clique cover in a graph.
After clustering PSTs into groups, one representative PST, denoted as r-PST , is selected for each group. Once selecting an r-PST, we can use this r-PST to r epresent the moving behavior for a group of objects. In order to select an r-PST, there are two factors to be considered: one is the size of an r-PST and the other is the distance between the selected r-PST and other PSTs. Clearly, the smaller size of an r-PST is, the more storage a cluster head can save. Moreover, if the smaller the distance between the r-PST and other PSTs in a group is, the more precise this r-PST can be represented other PSTs. Thus, we must select the r-PST that has smaller size and is very similar to other PSTs in the same group.

For simplicity, the size of PST ( T i ) is represented as the number of tree nodes ( N ( T i )) and the error sum ( ES )isused to quantify which PST should be chosen as the r-PST in a group. Suppose that there are k PSTs in a group. The error sum of PST T i is defined as the sum of the distance between T and other k  X  1 PSTs, denoted by ES ( T i )= k j =1  X  ( T where  X  ( T i ,T i ) = 0. In order to take a balance between tree size and error sum, we can select the r-PST from k PSTs by Obviously, a parameter  X  can be used to give different weights to tree size and error sum. A larger  X  can give larger weight to the number of nodes while the smaller one can give larger weight to the error sum.
In this section, experiments are conducted to evaluate the effectiveness and efficiency of the proposed methods.
For the comparison purpose, we implement HTM [3] and design a group mobility model based on city mobility model [1]. In HTM, there are 16 level-0 cluster head, organized into three levels hierarchy, and 10*10 low-end sensor nodes in each level-0 cluster. In our group mobility model, a logical group pilot is first generated for a group and the objects in a group follow their group pilot according to two parameters: variation period and variation radius. For every variation period, an object will choose a random direction to move the distance of variation radius away from the group pilot. The variation radius of each objects is uniformly distributed from 0 to max VR . The group pilot will repeatedly visit those specified locations by turns.
In our experiments, there are 30 objects and one group pilot for objects to follow. The variation period is set to 3 and max VR is set to 4. The OTSN works for 10000 time units. HTM collects the moving records of objects in the initial 3000 time units. After that, the cluster heads are in the prediction phase. For our method, the distance threshold  X  t =2 . 5, the spatial proximity  X  t =2and  X  =0 . 4.
In this section, we compare the storage cost and prediction accuracy of our proposed method and HTM. Specifically, the average number of tree nodes is defined as Total Tree Nodes which is used to measure the average storage cost. Hit rate of The storage cost of HTM and RG are shown in Figure 4(a). At the 3000-th time unit, the average number of tree nodes of RG significantly decreases because cluster heads cluster ob-jects and preserve only a PST for each group. Clearly, RG outperforms HTM in terms of storage costs. Figure 4(b) shows that RG has slightly lower hit rate of prediction than HTM. However, in the worst case, the hit rate of HTM is only 5% higher than RG. We could conclude that a plenty of storage cost reduction outweighs the slight loss of prediction accuracy.
We now examine the impact of the distance threshold  X  t for distance  X  MSL , and the spatial proximity threshold  X  t .Inor-der to emphasize the storage cost reduction, we introduce the reduction rate, which is defined as Figure 5: The impact of  X  t and  X  t on reduction rate and hit rate.
 age cost can be reduced. In the meantime, we also discuss the hit rate of prediction affected by different parameter settings.
In Figure 5(a), the reduction rate increases when  X  t or  X  increases. With larger  X  t or  X  t , an object is more likely to form a group with other objects. Thus, more storage cost of PSTs can be reduced. Also, it can be seen in Figure 5(b) that the hit rate of prediction decreases when the distance threshold  X  or the spatial proximity threshold  X  t is larger.
In this paper, we explore group mobility of objects to reduce the cost of maintaining PSTs in OTSNs. First, to cluster ob-jects with similar moving behaviors, we first define a distance function between PSTs to distinguish whether the moving be-haviors of objects are similar or not. Furthermore, we proposed Algorithm DP to compute the distance between two PSTs in a dynamic programming manner. Based on the distance be-tween PSTs, we proposed a clustering algorithms RG to group moving objects. In order to select the r-PST for a group, we proposed a method to select the PST which can reduce the storage cost and maintenance good prediction accuracy. Ex-periments were conducted to evaluate the performance of our proposed methods. Experimental results show that the pro-posed methods not only effectively reduce the storage cost but preserve the prediction accuracy.
