 Information extraction (IE) refers to the extraction of structured information from text documents. In recent years, text analytics have become the driv-ing force for many emerging enterprise applications such as compliance and data redaction. In addition, the inclusion of text has also been increasingly im-portant for many traditional enterprise applications such as business intelligence. Not surprisingly, the use of information extraction has dramatically in-creased within the enterprise over the years. While the traditional requirement of extraction quality re-mains critical, enterprise applications pose several two challenges to IE systems:
Traditionally, IE systems have been built from in-dividual extraction components consisting of rules or machine learning models. These individual com-ponents are then connected procedurally in a pro-gramming language such as C++, Perl or Java. Such procedural logic towards IE cannot meet the increas-ing scalability and usability requirements in the en-terprise (Doan et al., 2006; Chiticariu et al., 2010a).
Three decades ago, the database community faced similar scalability and expressivity challenges in accessing structured information. The community addressed these problems by introducing a rela-tional algebra formalism and an associated declar-ative query language SQL. Borrowing ideas from the database community, several systems (Doan and others, 2008; Bohannon and others, 2008; Jain et al., 2009; Krishnamurthy et al., 2008; Wang et al., 2010) have been built in recent years taking an alternative declarative approach to information extraction. In-stead of using procedural logic to implement the ex-traction task, declarative IE systems separate the de-scription of what to extract from how to extract it, allowing the IE developer to build complex extrac-tion programs without worrying about performance considerations.

In this demonstration, we showcase one such declarative IE system called SystemT , designed to address the scalability and usability challenges. We illustrate how SystemT , currently deployed in a multitude of real-world applications and com-mercial products, can be used to develop and maintain IE annotators for enterprise applica-tions. A free version of SystemT is available at Figure 2: An AQL program for a PersonPhone task. 3.1 AQL and Phone annotations, where the latter follows the former within 0 to 5 tokens, and marks the corre-sponding region of text as a PersonPhoneAll annota-tion. The final output PersonPhone is constructed by removing overlapping PersonPhoneAll annotations.
AQL operates over a simple relational data model with three data types: span, tuple, and view. In this data model, a span is a region of text within a doc-ument identified by its  X  X egin X  and  X  X nd X  positions, while a tuple is a list of spans of fixed size. A view is a set of tuples. As can be seen from Figure 2, each AQL rule defines a view. As such, a view is the basic building block in AQL: it consists of a logical description of a set of tuples in terms of the docu-ment text, or the content of other views. The input to the annotator is a special view called Document containing a single tuple with the document text. The AQL annotator tags some views as output views , which specify the annotation types that are the final results of the annotator.

The example in Figure 2 illustrates two of the basic constructs of AQL. The extract statement specifies basic character-level extraction primitives, such as regular expressions or dictionaries (i.e., gazetteers), that are applied directly to the docu-ment, or a region thereof. The select statement is similar to the corresponding SQL statement, but contains an additional consolidate on clause for resolving overlapping annotations, along with an extensive collection of text-specific predicates.
To keep rules compact, AQL also allows a short-hand pattern notation similar to the syntax of the CPSL grammar standard (Appelt and Onyshkevych, 1998). For example, the PersonPhoneAll view in Figure 2 can also be expressed as shown below. Internally, SystemT translates each of these extract pattern statements into one or more select and ex-tract statements.
SystemT has built-in multilingual support in-cluding tokenization, part of speech and gazetteer matching for over 20 languages using IBM Lan-guageWare. Annotator developers can utilize the multilingual support via AQL without having to con-figure or manage any additional resources. In ad-dition, AQL allows user-defined functions in a re-stricted context in order to support operations such as validation or normalization. More details on AQL can be found in the AQL manual (Chiticariu et al., 2010b). 3.2 Algebraic Operators in SystemT SystemT executes AQL rules using graphs of op-erators. These operators are based on an algebraic formalism that is similar to the relational algebra formalism, but with extensions for text processing. Each operator in the algebra implements a single basic atomic IE operation, producing and consum-ing sets of tuples (i.e., views).

Fig. 3 illustrates the dictionary extraction operator in the algebra, which performs character-level dic-tionary matching. A full description of the 12 differ-ent operators of the algebra can be found in (F.Reiss et al., 2008). Three of the operators are listed below.  X  The Extract operator ( E ) performs character- X  The Select operator (  X  ) takes as input a set of  X  The Join operator (  X  X  X  ) takes as input two sets of
Other operators include PartOfSpeech for part-of-speech detection, Consolidate for removing overlapping annotations, Block and Group for grouping together similar annotations occurring within close proximity to each other, as well as ex-pressing more general types of aggregation, Sort for sorting, and Union and Minus for expressing set union and set difference, respectively. Grammar-based IE engines such as (Boguraev, 2003; Cunningham et al., 2000) place rigid restric-tions on the order in which rules can be executed. Such systems that implement the CPSL standard or extensions of it must use a finite state transducer to evaluate each level of the cascade with one or more left to right passes over the entire input token stream. In contrast, SystemT uses a declarative approach based on rules that specify what patterns to extract, as opposed to how to extract them. In a declarative IE system such as SystemT the specification of an annotator is completely separate from its implemen-tation. In particular, the system does not place ex-plicit constraints on the order of rule evaluation, nor does it require that intermediate results of an anno-tator collapse to a fixed-size sequence.

As shown in Fig. 1, the SystemT engine does not execute AQL directly; instead, the SystemT Optimizer compiles AQL into a graph of operators. Given a collection of AQL views, the optimizer gen-erates a large number of different operator graphs, all of which faithfully implement the semantics of the original views. Even though these graphs always produce the same results, the execution strategies that they represent can have very different perfor-mance characteristics. The optimizer incorporates a cost model which, given an operator graph, esti-mates the CPU time required to execute the graph over an average document in the corpus. This cost model allows the optimizer to estimate the cost of each potential execution strategy and to choose the one with the fastest predicted running time.
Fig. 4 presents three possible execution strategies for the PersonPhoneAll rule in Fig. 2. If the opti-mizer estimates that the evaluation cost of Person is much lower than that of Phone , then it can determine that Plan B has the lowest evaluation cost among the three, because Plan B only evaluates Phone in the  X  X ight X  neighborhood for each instance of Per-son . More details of our algorithms for enumerating plans can be found in (F.Reiss et al., 2008).
The optimizer in SystemT chooses the best exe-cution plan from a large number of different algebra graphs available. Depending on the execution plan generated by the optimizer, SystemT may evaluate views out of order, or it may skip evaluating some views entirely. It may share work among views or combine multiple equivalent views together. Even within the context of a single view, the system can choose among several different execution strategies without affecting the semantics of the annotator. This decoupling is possible because of the declar-ative approach in SystemT , where the AQL rules specify only what patterns to extract and not how to extract them. Notice that many of these strategies cannot be implemented using a transducer. In fact, we have formally proven that within this large search space, there generally exists an execution strategy that implements the rule semantics far more effi-ciently than the fastest transducer could (Chiticariu et al., 2010b). This approach also allows for greater rule expressivity, because the rule language is not constrained by the need to compile to a finite state transducer, as in traditional CPSL-based systems. The SystemT Runtime is a compact, small memory footprint, high-performance Java-based runtime en-gine designed to be embedded in a larger system. The runtime engine works in two steps. First, it instantiates the physical operators in the compiled operator graph generated by the optimizer. Second, once the first step has been completed, the runtime feeds documents through the operator graph one at a time, producing annotations.

SystemT exposes a generic Java API for the inte-gration of its runtime environment with other appli-cations. Furthermore, SystemT provides two spe-cific instantiations of the Java API: a UIMA API and a Jaql function that allow the SystemT runtime to be seamlessly embedded in applications using the UIMA analytics framework (UIMA, 2010), or de-ployed in a Hadoop-based environment. The latter allows SystemT to be embedded as a Map job in a map-reduce framework, thus enabling the system to scale up and process large volumes of documents in parallel. 5.1 Memory Consumption Managing memory consumption is very important in information extraction systems. Extracting struc-tured information from unstructured text requires generating and traversing large in-memory data structures, and the size of these structures deter-mines how large a document the system can process with a given amount of memory.

Conventional rule-based IE systems cannot garbage-collect their main-memory data structures because the custom code embedded inside rules can change these structures in arbitrary ways. As a re-sult, the memory footprint of the rule engine grows continuously throughout processing a given docu-ment.

In SystemT , the AQL view definitions clearly specify the data dependencies between rules. When generating an execution plan for an AQL annota-tor, the optimizer generates information about when it is safe to discard a given set of intermediate re-sults. The SystemT Runtime uses this information to implement garbage collection based on reference-counting. This garbage collection significantly re-duces the system X  X  peak memory consumption, al-lowing SystemT to handle much larger documents than conventional IE systems. The SystemT Development Environment assists a developer in the iterative process of developing, testing, debugging and refining AQL rules. Be-sides standard editor features present in any well-respected IDE for programming languages such as syntax highlighting, the Development Environment also provides facilities for visualizing the results of executing the rules over a sample document collec-tion as well as explaining in detail the provenance of any output annotation as the sequence of rules that have been applied in generating that output. As discussed in Section 1, our goal in building Sys-temT was to address the scalability and usability challenges posed by enterprise applications. As such, our evaluation focuses on these two dimen-sions. 7.1 Scalability Table 1 presents a diverse set of enterprise applica-tions currently using SystemT . SystemT has been deployed in both client-side applications with strict memory constraints, as well as on applications on the cloud, where it can process petabytes of data in parallel. The focus on scalability in the design of SystemT is essential for its flexible execution model. First of all, efficient execution plans are generated automatically by the SystemT Optimizer based on sample document collections. This en-sures that the same annotator can be executed effi-ciently for different types of document collections. In fact, our previous experimental study shows that the execution plan generated by the SystemT opti-mizer can be 20 times or more faster than a manu-ally constructed plan (F.Reiss et al., 2008). Further-more, the Runtime Environment of SystemT results in compact memory footprint and allows SystemT to be embedded in applications with strict memory requirements as small as 10MB.

In our recent study over several document col-lections of different sizes, we found that for the same set of extraction tasks, the SystemT through-put is at least an order of magnitude higher than that of a state-of-the-art grammar-based IE system, with much lower memory footprint (Chiticariu et al., 2010b). The high throughput and low memory foot-print of SystemT allows it to satisfy the scalability requirement of enterprise applications. 7.2 Usability Table 2 lists different types of annotators built us-ing SystemT for a wide range of domains. Most, if not all, of these annotators are already deployed in commercial products. The emphasis on usability in the design of SystemT has been critical for its successful deployment in various domains. First of all, the declarative approach taken by SystemT al-lows developers to build complex annotators without worrying about performance. Secondly, the expres-siveness of the AQL language has greatly eased the burden of annotator developers when building com-plex annotators, as complex semantics such as dupli-cate elimination and aggregation can be expressed in a concise fashion (Chiticariu et al., 2010b). Finally, the Development Environment further facilitates an-notator development, where the clean semantics of AQL can be exploited to automatically construct ex-planations of incorrect results to help a developer in identifying specific parts of the annotator responsi-ble for a given mistake. SystemT has been suc-cessfully used by enterprise application developers in building high quality complex annotators, without requiring extensive training or background in natural language processing. This demonstration will present the core function-alities of SystemT . In particular, we shall demon-strate the iterative process of building and debug-ging an annotator in the Development Environment. We will then showcase the execution plan automati-cally generated by the Optimizer based on a sample document collection, and present the output of the Runtime Environment using the execution plan. In our demonstration we will first make use of a simple annotator, as the one shown in Fig. 2, to illustrate the main constructs of AQL. We will then showcase the generic state-of-the-art SystemT Named Enti-ties Annotator Library (Chiticariu et al., 2010c) to illustrate the quality of annotators that can be built in our system.

