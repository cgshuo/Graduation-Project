 Hidden Markov Models (HMMs) assume a generative model for sequential data whereby a sequence of states (or sample path ) is drawn from a Markov chain in a hidden experiment. Each state generates an output symbol from alphabet  X  , and these output symbols constitute the data or observations . A classical problem, solved by the Viterbi algorithm, is to find the most probable sample path given certain observations for a given Markov model. We call this the single path problem ; it is well suited to labeling or tagging a single sequence of data. For example, HMMs have been successfully applied in speech recognition [1], natural language processing [2], and biological sequencing [3]. We introduce two generalizations of the single path problem for performing collective inference on Markov models, motivated by an effort to model bird migration patterns using a large database of static observations. The eBird database hosted by the Cornell Lab of Ornithology contains millions of bird observations from throughout North America, reported by the general public using the eBird web application. 1 Observations report location, date, species and number of birds observed. The eBird data set is very rich; the human eye can easily discern migration patterns from animations showing the observations as they unfold over time on a map of North America. 2 However, the eBird data are static , and they do not explicitly record movement, only the distributions at different points in time. Conclusions about migration patterns are made by the human observer. Our goal is to build a mathematical framework to infer dynamic migration models from the static eBird data. Quantitative migration models are of great scientific and practical import: for example, this problem arose out of an interdisciplinary project at Cornell University to model the possible spread of avian influenza in North America through wild bird migration.
 The migratory behavior for a species of birds can be modeled using a single generative process that independently governs how individual birds fly between locations, giving rise to the following inference problem: a hidden experiment simultaneously draws many independent sample paths from a Markov chain, and the observations reveal aggregate information about the collection of sample paths at each time step, from which the observer attempts to reconstruct the paths. For example, the eBird data estimate the geographical distribution of a species on successive days, but do not track individual birds.
 We discuss two problems within this framework. In the multiple path problem , we assume that exactly M independent sample paths are drawn from the Markov model, and the observations reveal the number of paths that output symbol  X  at time t , for each  X  and t . The observer seeks the most likely collection of paths given the observations. The fractional path problem is a further generalization in which paths are divisible entities. The observations reveal the fraction of paths that output symbol  X  at time t , and the observer X  X  job is to find the most likely (in a sense to be defined later) weighted collection of paths given the observations. Conceptually, the fractional path problem can be derived from the multiple path problem by letting M go to infinity; or it has a probabilistic interpretation in terms of distributions over paths.
 After discussing some preliminaries in section 2, sections 3 and 4 present algorithms for the multiple and fractional path problems, respectively, using network flow techniques on the trellis graph of the Markov model. The multiple path problem in its most general form is NP-hard, but can be solved as an integer program. The special case when output symbols uniquely identify their associated states can be solved efficiently as a flow problem; although the single path problem is trivial in this case, the multiple and fractional path problems remain interesting. The fractional path problem can be solved by linear programming. We also introduce a practical extension to the fractional path problem, including slack variables allowing the solution to deviate slightly from potentially noisy observations. In section 5, we demonstrate our techniques with visualizations for the migration of Archilochus colubris , the Ruby-throated Hummingbird, devoting some attention to a challenging problem we have neglected so far: estimating species distributions from eBird observations. We briefly mention some related work. Caruana et al. [4] and Phillips et al. [5] used machine learning techniques to model bird distributions from observations and environmental features. For problems on sequential data, many variants of HMMs have been proposed [3], and recently, con-ditional random fields (CRFs) have become a popular alternative [6]. Roth and Yih [7] present an integer programming inference framework for CRFs that is similar to our problem formulations. 2.1 Data Model and Notation A Markov model ( V, p,  X  ,  X  ) is a Markov chain with state set V and transition probabilities p ( u, v ) for all u, v  X  V . Each state generates a unique output symbol from alphabet  X  , given by the mapping  X  : V  X   X  . Although some presentations allow each state to output multiple symbols with different emission probabilities, we lose no generality assuming that each state emits a unique symbol  X  to encode a model where state v output multiple symbols, we simply duplicate v for each symbol and encode the emission probabilities into the transitions. Of course,  X  need not be one-to-one. It is output  X  . We assume each model has a distinguished start state s and output symbol start . Let Y = V T be the set of all possible sample paths of length T . We represent a path y  X  X  as a row row y i  X  representing an independent sample path. The transition probabilities induce a distribution for any function f of a random path Y drawn from  X  . Note that Y (boldface) denotes a matrix of M paths, while Y denotes a random path. 2.2 The Trellis Graph and Viterbi as Shortest Path To develop our flow-based algorithms, it is instructive to build upon a shortest-path interpretation of the Viterbi algorithm [7]. In an instance of the single path problem we are given a model ( V, p,  X  ,  X  ) and observations  X  1 , . . . ,  X  T , and we seek the most probable path y given these observations. We problem is conveniently illustrated using the trellis graph of the Markov model (Figure 1). Here, the states are replicated for each time step, and edges connect a state at time t to its possible successors at time t + 1 , labeled with the transition probability. A feasible path must pass through partition V t at step t , so we can prune all edges incident on other partitions, leaving only feasible paths. By of maximum probability becomes the path of minimum cost under this transformation. Thus the Viterbi algorithm finds the shortest feasible path in the trellis using edge lengths c ( u, v ) . In the multiple path problem, M sample paths are drawn from the model and the observations reveal of output symbols at time t . The objective is to find the most probable collection Y that is feasible, probabilities: Then the formal specification of this problem is 3.1 Reduction to the Single Path Problem A naive approach to the multiple path problem reduces it to the single path problem by creating a new and the transition probabilities are given by the product of the element-wise transition probabilities: A state from the product space V M corresponds to an entire column of the matrix Y , and by chang-ing the order of multiplication in (1), we see that the probability of a path in the new model is equal to the probability of the entire collection of paths in the old model. To complete the reduction, we form a new alphabet  X   X  whose symbols represent multisets of size M on  X  . Then the solution to (2) can be found by running the Viterbi algorithm to find the most likely sequence of states from V M that produce output symbols (multisets) A 1 , . . . , A T . The running time is polynomial in | V M | and |  X 
 X  | , but exponential in M . 3.2 Graph Flow Formulation Can we do better than the naive approach? Viewing the cost of a path as the cost of routing one unit of flow along that path in the trellis, a minimum cost collection of M paths is equivalent to a minimum cost flow of M units through the trellis  X  given M paths, we can route one unit along each to get a flow, and we can decompose any flow of M units into paths each carrying a single unit of flow. Thus we can write the optimization problem in (2) as the following flow integer program, with additional constraints that the flow paths generate the correct observations. The decision variable x uv indicates the flow traveling from u to v at time t ; or, the number of sample paths that transition from u to v at time t . (IP) The flow conservation constraints (3) are standard: the flow into v at time t is equal to the flow leaving v at time t + 1 . The observation constraints (4) specify that N t (  X  ) units of flow leave partition V  X  at time t . These also imply that exactly M units of flow pass through each level of the trellis, by summing over all  X  , Without the observation constraints, IP would be an instance of the minimum-cost flow problem [8], which is solvable in polynomial time by a variety of algorithms [9]. However, we cannot hope to encode the observation constraints into the flow framework, due to the following result. Lemma 1. The multiple path problem is NP-hard.
 The proof of Lemma 1 is by reduction from SET COVER, and is omitted. One may use a general purpose integer program solver to solve IP directly; this may be efficient in some cases despite the lack of polynomial time performance guarantees. In the following sections we discuss alternatives that are efficiently solvable. 3.3 An Efficient Special Case In the special case when  X  is one-to-one, the output symbols uniquely identify their generating states, so we may assume that  X  = V , and the output symbol is always the name of the current state. To see how the problem IP simplifies, we now have V u = { u } for all u , so each partition consists of a single state, and the observations completely specify the flow through each node in the trellis: Substituting the new observation constraints (4 0 ) for time t +1 into the RHS of the flow conservation constraints (3) for time t yield the following replacements: This gives an equivalent set of constraints, each of which refers only to variables x t uv for a single t . Hence the problem can be decomposed into T  X  1 disjoint subproblems for t = 1 , . . . , T  X  1 . The t th subproblem IP t is given in Figure 2(a), and illustrated on the trellis in Figure 2(b). State u at time t has a supply of N t ( u ) units of flow coming from the previous step, and we must route N node. Then the problem reduces to finding a minimum cost routing of the supply from time t to meet the demand at time t + 1 , solved separately for all t = 1 , . . . , T  X  1 . The problem IP t an instance of the transportation problem [10], a special case of the minimum-cost flow problem. There are a variety of efficient algorithms to solve both problems [8,9], or one may use a general purpose linear program (LP) solver; any basic solution to the LP relaxation of IP t is guaranteed to be integral [8]. (IP t ) In the fractional path problem, a path is a divisible entity. The observations specify q t (  X  ) , the fraction of paths that output  X  at time t , and the observer chooses  X  ( y ) fractional units of each path y , totaling one unit, such that q t (  X  ) units output  X  at time t . The objective is to maximize Q i.e., q t specifies the marginal distribution over symbols at time t . By taking the logarithm, an equiv-alent objective is to maximize E  X  [log  X  ( Y )] , so we seek the distribution  X  that maximizes the expected log-probability of a path Y drawn from  X  . Conceptually, the fractional path problem arises by letting M  X   X  in the multiple path problem and normalizing to let q t (  X  ) = N t (  X  ) /M specify the fraction of paths that output  X  at time t . Operationally, the fractional path problem is modeled by the LP relaxation of IP, which routes one splittable unit of flow through the trellis. (RELAX) It is easy to see that a unit flow x corresponds to a probability distribution  X  . Given any distribution time t is equal to the probability it leaves v at time t + 1 . Conversely, given a unit flow x , any path decomposition assigning flow  X  ( y ) to each y  X  X  is a probability distribution because the total flow is one. In general, the decomposition is not unique, but any choice yields a distribution  X  with the same objective value. Furthermore, under this correspondence, x satisfies the marginal constraints (5) if and only if  X  has the correct marginals: Finally, we can rewrite the objective function in terms of paths: By switching signs and changing from minimization to maximization, we see that RELAX solves the fractional path problem. This problem is very similar to maximum entropy or minimum cross entropy modeling, but the details are slightly different: such a model would typically find the dis-tribution  X  with the correct marginals that minimizes the cross entropy or Kullback-Leibler di-vergence [11] between  X  and  X  , which, after removing a constant term, reduces to minimizing E  X  [  X  log  X  ( Y )] . Like IP, the RELAX problem also decomposes into subproblems in the case when  X  is one-to-one, but this simplification is incompatible with the slack variables introduced in the following section. 4.1 Incorporating Slack the LP to deviate slightly from these marginals to find a better overall solution. To accomplish this, we add slack variables  X  t u into the marginal constraints (5), and charge for the slack in the objective function. The new marginal constraints are LP trick [8] to model the absolute value term. The slack costs  X  t  X  can be tailored to individual input values; for example, one may want to charge more to deviate from a confident estimate. This will depend on the specific application. We also add the necessary constraints to ensure that the new marginals q 0 t (  X  ) = q t (  X  ) +  X  t  X  form a valid probability distribution for all t . In this section, we demonstrate our techniques by using the fractional path problem to create visual-izations showing likely migration routes of Archilochus colubris , the Ruby-throated Hummingbird, a common bird whose range is relatively well covered by eBird observations. We work in dis-cretized space and time, dividing the map into grid cells and the year into weeks. We must specify the Markov model governing transitions between locations (grid cells) in successive weeks; also, we require estimates q t (  X  ) for the weekly distributions of hummingbirds across locations. Since the actual eBird observations are highly non-uniform in space and time, estimating weekly distribu-tions requires significant inference for locations with few or no observations. In the appendix, we outline one approach based on harmonic energy minimization [12], but we may use any technique that produces weekly distributions q t ( u ) and slack costs  X  t u . Improving these estimates, say, by incorporating important side information such as climate and habitat features, could significantly (locations) and not output symbols  X  i.e.,  X  is one-to-one  X  we cannot use the simplification from section 3.3 because we incorporate slack into the model. 5.1 eBird Data Launched in 2002, eBird is a citizen science project run by the Cornell Lab of Ornithology, lever-aging the data gathering power of the public. On the eBird website, birdwatchers submit checklists of birds they observe, indicating a count for each species, along with the location, date, time and additional information. Our data set consists of the 428 , 648 complete checklists from 1995 3 through 2007 , meaning the reporter listed all species observed. This means we can infer a count of zero, or a negative observation , for any species not listed. Using a land cover map from the United States Geological Survey (USGS), we divide North America into grid cells that are roughly 225 km on a side. All years of data are aggregated into one, and the year is divided into weeks so t = 1 , . . . , 52 represents the week of the year. 5.2 Migration Inference Given weekly distributions q t ( u ) and slack costs  X  t u (see the appendix), it remains to specify the Markov model. We use a simple Gaussian model favoring short flights, letting p ( u, v )  X  sponds to a squared distance cost function. To reduce problem size, we omitted variables x t uv from upper bounds  X  t u  X  q t ( u ) on the slack variables so no single value could increase by more than a factor of two. Our final LP, which was solved using the MOSEK optimization toolbox, had 78 , 521 constraints and 3 , 031 , 116 variables.
 Figure 3 displays the migration paths our model inferred for the four weeks starting on the dates indicated. The top row shows the distribution and paths inferred by the model; grid cells colored between the week shown and the following week, with line width proportional to flow x t uv . In the bottom row, the raw data is given for comparison. White dots indicate negative observations; black squares indicate positive observations, with size proportional to count. Locations with both positive and negative observations appear a charcoal color. The inferred distributions and paths are consistent with both seasonal ranges and written accounts of migration routes. For example, in the summary paragraph on migration from the Archilochus colubris species account in Birds of North America [13], Robinson et al. write  X  X any fly across Gulf of Mexico, but many also follow coastal route. Routes may differ for north-and southbound birds. X  Acknowledgments We are grateful to Daniel Fink, Wesley Hochachka and Steve Kelling from the Cornell Lab of Ornithology for useful discussions. This work was supported in part by ONR Grant N00014-01-1-0968 and by NSF grant CCF-0635028. The views and conclusions herein are those of the authors and do not necessarily represent the official policies or endorsements of these organizations or the US Government.
 References Our goal is to estimate q t ( u ) , the fraction of birds in grid cell u during week t . Given enough observations, we can estimate q t ( u ) using the average number of birds counted per checklist, a quantity we call the rate r t ( u ) . However, even for a bird with good eBird coverage, there are cells with few or no observations during some weeks. To fill these gaps, we use the harmonic energy minimization technique [12] to determine values for empty cells based on neighbors in space and time. This technique uses a graph-based similarity structure, in our case the 3 -dimensional lattice built on points u t , where u t represents cell u during week t . Edges are weighted, with weights representing similarity between points. Point u t is connected to its four grid neighbors in time slice t by edges of unit weight, excluding edges between cells separated by water (specifically, when the line connecting the centers is more than half water). Point u t is also connected to points u t  X  1 and u t +1 with weight 1 / 4 , to achieve some temporal smoothing.
 Harmonic energy minimization learns a function f on the graph; the idea is to match r t ( u ) on points with sufficient data and find values for other points according to the similarity structure. To this end, we designate some boundary points for which the value of f is fixed by the data, while other points are interior points. The value of f at interior point u t is determined by the expected value of the following random experiment: perform a random walk starting from u t , following outgoing edges with probability proportional to their weight. When the walk first hits a boundary point v , terminate and accept the boundary value f ( v t 0 ) . In this way, the values at interior points are a weighted average of nearby boundary values, where  X  X earness X  is interpreted as the absorption probability in an absorbing random walk. We derive a measure of confidence in the value f ( u t ) from the same experiment: let h ( u t ) be the expected number of steps for the random walk from u t to hit the boundary (the hitting time of the boundary set [14]). When h ( u t ) is small, u t is close to the boundary and we are more confident in f ( u t ) .
 Rather than choosing a threshold on the number of observations required to be a boundary point, we create a soft boundary by designating all points u t as interior points, and adding one boundary node to the graph structure for each observation, connected by an edge of unit weight to the cell in which it occurred, with value equal to the number of birds observed. As point u t gains more observations, its behavior approaches that of a hard boundary: with probability approaching one, the the observations. As a conservative measure, each node is also connected to a sink with boundary value 0 , to prevent values from propagating over very long distances.
 we multiply by the land mass of cell u to get an estimate  X  q t ( u ) for the (relative) number of birds  X  0  X  261 chosen in conjunction with the transition costs in section 5.2 so the average cost for a unit of slack is the same as moving 600 km.
