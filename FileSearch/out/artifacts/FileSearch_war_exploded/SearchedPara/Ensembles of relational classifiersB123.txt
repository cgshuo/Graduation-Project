 Christine Preisach  X  Lars Schmidt-Thieme Abstract Relational classification aims at including relations among entities into the classification process, for example taking relations among documents such as common au-thors or citations into account. However, considering more than one relation can further improve classification accuracy. Here we introduce a new approach to make use of sev-eral relations as well as both, relations and local attributes for classification using ensemble methods. To accomplish this, we present a generic relational ensemble model that can use different relational and local classifiers as components. Furthermore, we discuss solutions for several problems concerning relational data such as heterogeneity, sparsity, and multiple relations. Especially the sparsity problem will be discussed in more detail. We introduce a new method called PRNMultiHop that tries to handle this problem. Furthermore we cate-gorize relational methods in a systematic way. Finally, we provide empirical evidence, that our relational ensemble methods outperform existing relational classification methods, even rather complex models such as relational probability trees (RPTs), relational dependency networks (RDNs) and relational Bayesian classifiers (RBCs).
 Keywords Relational data mining  X  Ensemble classification  X  Sparse graphs  X  Relational autocorrelation 1 Introduction Nowadays new technologies allow to publish a vast amount of data, this data needs to be retrieved in a simple and convenient way. In order to facilitate this retrieval, we need to struc-ture and organize the data. One way to do this is to classify it into categories. Usually this is done by considering only local features. In text classification, it has been assumed that entities are independent from each other, however in most cases this assumption does not hold because of the existing relationships among instances. Most data, especially scientific publications, are related through explicit links like citations or in an implicit manner, i.e., for instance by common authorship. These relations could be exploited using relational classification in order to increase classification accuracy. Recently, especially relational methods, which use collective classification (also called collective inference )[ 13 ], i.e., iterative algorithms, which exploit the relational autocorrelation of variables of connected entities, received atten-tion. Here the classes of related entities are used as predictor variables.

But in general, there is not just one relation to consider in relational classification ,but several. In the area of scientific publications an object could be related to other objects by the same author, the same journal or conference and by citations. In literature, multiple rela-tions are combined either by using a set of neighbor class predictor variables per relation in a single local classifier [ 21 , 23 ] or by merging the relations and summing the weights of common links [ 17 ]. Here, we will present a new approach of combining different relations using ensemble classification [ 6 ].

Often one would like to consider not only relations, but also local attributes of objects, such as the textual content (e.g., represented as a bag-of-words) for text document. If such local attributes are to be considered, in literature typically this is accomplished by adding them as predictor variables to the relational classifiers. We, in contrast, combine local attributes with relations using again ensemble classification methods.

Recently ensemble classification aroused interest in the area of Machine Learning [ 3 , 6 , 33 ] due to its ability to reduce variance and bias and consequentially increasing accuracy. How-ever, on our best knowledge it has not been used for the aim of combining several relations.
In this paper we will make the following main contributions: 1. Formulate the relational classification problem and describe how several problems such 2. Introduce our generic relational ensemble model that consists of a local ,a relational 3. Present propositionalization and relational classification methods that use collective 4. Evaluate the presented relational classification methods in systematic way using ensem-2 Related work One of the earliest approaches considering relations among objects was by Chakrabarti et al. [ 4 ], who proposed a probabilistic model for classification of web pages using the content of the classified page, the class labels of linked pages as well as the content of these linked pages. They also used a collective classification algorithm (relaxation labeling) and showed that using the content of a web page and the class labels of linked web pages increases pre-dictive accuracy. In [ 1 ] an similar but more robust approach is discussed. It uses the classes of neighbors for classification of a document. The neighborhood is build by using content similarity ( metric distance ) of text documents. We in contrast build the neighborhood only by considering meta data, hence our model is not restricted to text documents, but is generic. Furthermore, the problem of multiple relations is not handled. The algorithm  X  X ubs and Authorities X  also considers the links to other web pages and [ 14 ] calculates the weights (hubs and authorities) iteratively.

More recent research has been done for instance on relational probability trees [ 23 ], which is a complex learning algorithm taking into account relations among entities and using prob-ability estimation trees [ 26 ], it propositionalizes the data by using aggregation functions during the feature construction. Another complex relational method is the relational depen-dency networks approach [ 21 ], a probabilistic relational model which is a relational extension of dependency networks. This approach expresses the probabilistic dependency of attributes of related instances, it uses collective classification .In[ 22 ] latent group models are intro-duced for relational data, they capture and exploit the hidden structure in the data. The authors showed that discovering and modeling these hidden groups increases accuracy and explains relational autocorrelation. In [ 24 ] a relational Bayesian classifier has been introduced, it uses propositionalization for constructing attributes. Furthermore regression models using link distributions have been introduced in [ 16 ], in this approach propositionalization is applied too. Research has been performed also on simple models like the Probabilistic Relational Neighbor (PRN) classifier [ 17 ] or other simple methods in [ 2 ]. Although most of them use several relations, they did not apply ensemble classification , neither for the combination of multiple relations, nor in order to combine a local classifier with a relational classifier. Moreover, they either do not considering local features or if doing so, they incorporated them additionally as predictor variables to the relational classifier. Macskassy and Provost [ 17 ] too, considered multiple relations, they represented the considered relations in a single graph (merging the relations and summing the weights of the common links) and performed their algorithms only once with this representation.

F X rnkranz [ 8 ]used ensemble classification in the area of hyperlink categorization. Ensem-ble classification methods have been incorporated in order to combine the results of the pre-dictions for each hyperlink of a target page. He showed, that this technique performed as well as a classifier considering only the content of the target page or even better. In contrast to his approach, we do not combine the prediction for each instance of a relation (link) but only for each relation type. In [ 30 ] the authors showed that considering the content located in the region of the hyperlink of a webpage achieved better results than considering the whole content of neighboring pages. Unfortunately the results have not been compared to methods that use only the classes of the neighborhood. He X  and Kushmerick [ 9 ] described a different approach, they extended the iterative algorithm of Neville and Jensen [ 20 ]and used voting to combine local attributes (there called intrinsic) and relational attributes (there called extrinsic) of web services. They showed that with voting one can achieve better results as with a text classifier or a relational classifier that only appends the local attributes to the relational attributes. This is similar to our approach of combining the results of a local and a relational classifier ; however, besides voting , we additionally used a more powerful ensemble classification method, namely stacking and combined multiple relations by using ensemble classification , furthermore we have evaluated our methods on a public dataset. In [ 31 ] random forests, a ensemble method that uses a subset of features to build the nodes in a decision tree, is applied with a ILP-based relational learning approach. The aim is to combine aggregation with selection conditions. 3 Problem formulation Before we formulate the problem of relational classification considering several relations, we define the problem of traditional classification. In traditional classification objects are described as vectors of values of attributes (or variables) A . As we will need to distinguish between objects with eventually identical attributes, we will describe objects by an ID x  X  X and their attributes by a map a : X  X  A , i.e., a ( x ) corresponds to the usual description of an object by its attributes.

For a traditional classification task of objects into possible classes C ,aset X tr  X  X of objects together with their classes c : X tr  X  C is given for training and another set X tst  X  X of objects together with their classes c : X tst  X  C is given for evaluation (with X tr  X  X tst = X  ).Thetaskthenistolearnanattribute-basedclassifiermodel rate is minimal.

In relational classification there is, additionally to the attribute-value data for objects, relational data concerning these objects. In the simplest case, there is a single binary relation R  X  X  X  X between objects under consideration. Classifiers now can make use of additional information about related objects, e.g., their attributes or their classes, if they are known. Since some of the related objects may themselves belong to the test set, collective classifica-tion can be used to derive consistent predictions. To make use of relational information for classification, it must be propositionalized, i.e., converted to suitable attributes. One of the simplest propositionalization is to calculate class frequencies of related objects, i.e., ses (a dot denotes a missing value). We will see more complex propositionalization schemes in Sect. 6 .

In general, there can be more than one relation, relations can hold between more than two objects, and relations can involve further sets of objects, e.g., for classifying books, also authors and journals could be important related objects of a different type. In this case, a binary homogeneous relation must be derived to apply most relational classification methods. 4 Relation engineering There are many issues to be discussed concerning relational data, for instance, how to handle heterogeneity, how multiple relations can be combined and how to cope with sparsity. In literature these problems concerning relational data, to our best knowledge have not been address explicitly. 4.1 Heterogeneity First of all, we present possible views of relational data and its representation. Relational data is usually heterogenous but it can be viewed also in a homogeneous way.

Heterogeneity with respect to relational data, means there exist more than one type of objects, namely a set of target objects x  X  X and one or more sets of other object types O . Instances of these object types can be related, so that one can have different types of relations R 1  X  X  X  O 1 , R 2  X  X  X  O 2 etc. This heterogeneous view can be represented by a directed acyclic graph as depicted in the left part of Fig. 1 .

More complex models are able to handle heterogeneity and do not need to homogenize the data. For instance in [ 21 ] relational data is represented by a heterogenous, directed, unweighted graph with attached attributes, it is not transformed to a homogenous represen-tation because the used algorithm (RDN) supports heterogeneity. During the model building process it is transformed into a model graph, an undirected graph with nodes for each attri-bute value and object type and attached probabilities. In [ 23 ] the data is too, represented in a heterogenous way, the input of the algorithm (RPT) is a directed, unweighted subgraph, that consists of several object types. During the model building the relational data is propo-sitionalized by using aggregation functions in the tree nodes of the probability tree. In [ 24 ] the same data representation is used for RBC and transformed into a homogenous set of attributes.

We will focus on simple models and use the homogeneous view, similar to [ 17 , 18 ]in order to allow the usage of normal classification methods.

In the homogeneous view we have only one object type, such that, there exist a set of target objects x  X  X and relations R  X  X  X  X among these objects. Of course, on a semantic level, we have still different relations.
 In the homogeneous view, relational data is represented by an undirected, weighted Graph G (
X , E ) with a set of nodes X and a set of edges E  X  X  X  X . The edges are annotated with a weight w ,whichis w : E  X  R + 0 . A higher weight indicates that the relation between two nodes is more important. The weight of an edge is equivalent to the number of objects o  X  O , which two target objects have in common (see ( 4 )).

In Fig. 1 , one can see an example graph from the domain of scientific publications that shows the transformation process from a heterogeneous to a homogeneous representation. On the left side, a heterogeneous graph is shown with two node types, the author nodes (A) and the publication nodes (P), the links indicate the relation between an author and a publication. On the right side the corresponding homogeneous view of the graph is depicted, it contains only the publication node type, the edges display the relation sameAuthor and the weights mark the number of authors, that two papers have in common.

Another possibility to homogenize heterogeneous relational data is to use similarity measures. That means, the weight of an edge between two objects x  X  X is equal to the correlation of these objects. The correlation could be for instance calculated by similarity measures like Pearson Correlation or Cosine Similarity, which are often used in the field of Information Retrieval and Recommender Systems. This approach is not used in this paper, however we will further investigate this in future research. 4.2 Multiple relations In relational data there exist often not only one relation, but multiple, the question is, how to combine these relations. One possibility is to unify the relations, which need to be combined, so that the new relation is the unification of multiple relations S = i R i and the weights of the edges of the new graph are w( x , x ) = R edges in the original graphs. This approach is used by Macskassy and Provost [ 17 ] and will be called Relation Unification . The second approach is the one mentioned in the previous section, in [ 23 , 24 ] all the object types are represented in the same graph and then proposi-tionalized and used as attributes in one classifier. We in contrast, consider each relation R i individually and build a graph for each relation. Then perform relational classification like described in Sect. 3 and combine the results with ensemble classification methods, which will be described in Sect. 7 . The main difference of these approaches is that in the Relation Unification approach the relations are combined on the data level, in the second on the model building level and in our approach they are combined on the result level. 4.3 Sparsity As relational methods try to infer the class of a particular object from information about related objects, sparse relations may pose a problem: if there are not many related objects, i.e., neighbors in the graph, such an inference is based on only a few objects and thus may be fragile.

In the extreme case of an isolated object without any neighbors, the relation does not carry any information about the object, and thus one has to resort to non-relational methods such as local classifiers based on attributes or use the prior class distribution.

In case of sparsity, if an object has just a few direct neighbors, one can additionally use objects indirectly linked by longer paths. Using longer paths for inference can be reformu-lated as densification of the original graph, i.e., adding direct edges between only indirectly linked objects and then the use only direct neighbors in the densified graph.

Let the graph ( G , E ) represent the original (sparse) relation and the set of simple paths on ( G , E ) (where G  X  := i  X  N G i is the set of all vertex sequences and | p |:= i for p  X  G i denotes length). By abuse of notation, we will write G  X  as shorthand forthesetofallpaths p  X  G  X  with p 1 = x and p | p | = x .

A graph can be densified by adding edges between objects linked only by a path of a given maximal length k : The process of densifying a sparse graph is illustrated in Fig. 2 . On the left the original (sparse) graph is shown, on the right the densified graph containing additional edges (colored in gray) is depicted.
Ifthegraphcarriesedgeweights w : E  X  R + 0 ,wherelargeweightsdenotemoreimportant edges, densification also has to provide weights for the new edges and eventually updates of the weights of existing edges. Although in general good schemes to derive these weights will depend on the application and the nature of the relation, there are some plausible properties: 1. Weights of edges existing already in the original graph shall be retained, more precisely, 2. Weights of a new edge ( x , x ) shall only depend on the sequence 3. The new weight shall be larger the larger the weights along the paths, the shorter the 4. Weights of new edges always shall be smaller than weights of direct edges in the original
Let us assume that the weights are normalized in the sense that they are in the range of [ 0 , 1 ] and that for each object the weights of all outgoing edges sum to 1. The edge weights will then be asymmetric in general, i.e., w( x , x ) = w( x , x ) . Then the formula has all the properties (i) X (iv).

Two particularities of typical relational data often will badly affect a straight-forward densification as described so far or render it impractical at least.

First, relations often are not equally sparse for all objects, but typically there are some objects well connected to many other objects and some objects with only sparse connections. In many datasets a Zipf-like distribution of the number of neighbors can be observed. In this situation, densification may have two bad effects: it will connect objects with many neigh-bors, so called hubs, to even more objects, probably without great effect on the quality of the classifier for the hub itself. It also will connect many objects with many other objects through a hub, so eventually blurring the influence of specific neighbors. The second effect is taken into account by using normalized weights that limit the influence of a hub. The first effect may be remedied by introducing an upper bound d for the number of neighbors in the original graph that an object may have to qualify for densification: objects with d or less neighbors may get additional edges through densification, objects with more than d edges keep just their original edges.

Second, relations often contain some noise, i.e., spuriously related pairs. Densification even may increase the noise through aggregation and noisy edges may increase the density of the densified graph beyond the necessary. This effect may be counteracted by introducing a lower bound m for the weights allowed in paths used during densification: only paths where all edges, but the first, have a weight of at least m will introduce a new edge in the densified graph, and only such paths will be considered for computing the new weights in ( 6 ). 5 Relational ensemble model Our generic relational ensemble model is composed of three main components, the relational , the local and the ensemble classification component (see Fig. 3 ). The relational ensemble classification process is listed in Algorithm 1. It describes a classification process, which uses all components of the model.
 Algorithm 1 Relational Ensemble Process
There, A r denotes the relational attributes, i.e., the attributes built by using proposition-alization methods on relational information. The individual components of our model are: Relational classification component For the relational classification component, we use the graph representation depicted in the right part of Fig. 1 . For each relation (e.g. sameAuthor , sameJournal or citation ) we build a new graph and apply relational classification methods (to be introduced in Sect. 6 )using collective classification . The input of the relational clas-sification component is a set of instances containing relational attributes. The output of a relational classification algorithm is a probability distribution over the target variable. Local classification component The local classification component uses only local attri-butes. In the domain of scientific publications, the local classifier performs traditional text classification. The data is represented in the manner of bag-of-words , i.e., each document is represented by a feature vector containing an entry for each word, the value of an entry is the weight (e.g. TFIDF ) of a word. Then a machine learning algorithm is applied, the output is a probability distribution over the target variable.
 Ensemble classification component The task of the ensemble classification component is to combine several classifiers in order to increase the classification accuracy. The input of the component is a set of probability distributions over the target variable, originating from the local and relational components. Either a simple ensemble classification algorithm, for instance voting , or a meta classifier, which learns a meta model of the probability distributions provided by the base classifiers can be used. The output of the ensemble classification com-ponent is a probability distribution, too. In our experiments we combine the results of the relational classification component and the local classification component as it is listed in Algorithm 1 . 6 Relational classification methods In literature simple as well as learning relational classification methods are used, some of them using collective classification . 6.1 Collective classificaton Collective classification (also called collective inference ) methods are iterative procedures, which classify related instances simultaneously. Collective classification exploits relational autocorrelation . While relational autocorrelation is an important property of relational data, where the value of an attribute for an instance is highly correlated with the same variable from a related instance [ 12 ]. Collective classification causes the propagation of information in a graph, so that instances with unknown labels, if they are initialized, can be integrated in the classification process. Relational autocorrelation can be computed for instance using CramersV Statistic [ 5 ].

Many studies [ 4 , 13 , 28 ]haveshown,that collective classification may improve the clas-sification accuracy significantly.

We use three types of collective classification procedures. For most relational classifi-cation methods, we apply probabilistic re-estimation , like Macskassy and Provost [ 17 , 18 ], originally introduced by Chakrabarti et al. [ 4 ] under the name relaxation labeling .Inthis algorithm each instance is initialized with a probability distribution (e.g. prior distribution P ( c ) or probability distribution P ( c | A ) (see also ( 1 )) returned by a local classifier ). Then we iteratively classify each instance of the test set using a relational classification method M : A r  X  C in the inner loop of the iterative algorithm, A r denotes the relational attributes, i.e., relational information is propositionalized to suitable attributes. Within this iterative algorithm we use the class membership probabilities of the neighborhood estimated in the previous iteration, whereas the output of the classification algorithm (a probability distribu-tion) is used as input for the next iteration t + 1:
The procedure stops when the algorithm converges or a certain number of iterations is reached. Here the uncertainty is kept and propagated in the graph.

The second collective classification algorithm is a special case of probabilistic re-estimation and is called deterministic re-estimation method, originally introduced by Lu and Getoor [ 16 ] and there called link-based classification . In their approach, the instances are the uncertainty is not considered in this algorithm. Like in probabilistic re-estimation each instance is classified in each iteration and the output of the relational classification algorithm (a certain category) is used as input for the next iteration until convergence or a certain num-ber of iterations is reached. So the only difference between these iterative algorithms is that probabilistic re-estimation considers uncertainty and deterministic re-estimation does not.
The third iterative algorithm called (deterministic) one-shot-estimation is a special case of the second method. It was used in Macskassy and Provost [ 17 ] with the Relational Clas-sifier algorithm. It actually is not a genuine collective classification method, since it does not initialize the unlabeled instances, but uses only the neighbors with known classes for the estimation of the class membership probability and does not re-estimate these probabilities but calculates them only once. As the deterministic re-estimation method, it uses the nominal classes of the neighbors instead of probabilities. 6.2 Propositionalization methods As mentioned in Sect. 3 we use propositionalization methods, sometimes called aggregation functions, in order to convert the relational information into suitable attributes so that we could use classical machine learning methods. In our research, we have analyzed several propositionalization methods, which map the set-valued attributes, in our case classes of the neighbors of the entity under consideration, to an aggregated value. A scientific paper for example, could be related to three other papers, two of them belonging to the class Machine Learning , the other to Databases , these classes build a set-valued attribute, which cannot be handled by normal classification methods. We could aggregate this set using for example, the frequency of occurrence of these classes.

Propositionalization was often applied to relational data in order to  X  X latten X  the data [ 4 , 16 , 20 , 24 ], while in some of these publications not only the classes of the neighbors but also other attributes have been aggregated. Kramer et al. [ 15 ] showed, that propositionaliza-tion may have no negative effect to classification accuracy.

In Sect. 3 we already presented a simple propositionalization method, called Count that captures the frequency of neighbors having the same class (see ( 3 )). This approach was introduced in [ 16 ] to build attributes used in Logistic Regression. Count does not take into account probabilities, i.e., it is not suitable for probabilistic re-estimation ,butfor determin-istic re-estimation , where all the instances are assigned with nominal classes. Furthermore it does not consider the weights of the edges.

Another propositionalization method is weightedAverage , it was introduced by Macskassy and Provost [ 17 ] and used there as a simple classifier called Relational Classifier ( RN ). Instead of only considering the frequency of neighbors with a particular class, it sums up the weights of these neighbors and normalizes it with a factor Z = x  X  R
As Count , it does not incorporate uncertainty and hence is also not suitable for using with probabilistic re-estimation .Weused one-shot-estimation like in the original method.
The PWAM (probabilistic weighted arithmetic mean) is a probabilistic version of Weight-edAverage , it calculates the weighted arithmetic mean of the class membership probabilities of the neighbors of x . This method was also introduced in [ 17 ] and called probabilistic relational classifier (PRN) .
 It can be used with probabilistic re-estimation but not with deterministic re-estimation .In ( 10 ) the weighted geometric mean of the class membership probabilities is used instead of the weighted arithmetic mean, this is the first extension we made of the method described before.

The geometric mean is sometimes a better way to represent probabilities, especially here, where we assume, that the class membership probabilities of the neighbors given the instance x are independent of each other. The second extension is our propositionalization algorithm 2Hop and the generalization of it MultiHop , which additionally considers indirect neighbors at a distance of two respectively multiple hops if particular conditions are fulfilled. In ( 11 ) the MultiHop method is shown:
The conditions, the building of the new edges and the calculation of dense weights have been described in Sect. 4 . Both extensions of PWAM could be used together with probabilistic re-estimation .

The last propositionalization method we present here is the IndirectRVS method. It was introduced in [ 2 ]asthe Indirect RVS Score and used for simple classification. It is based on the relational vector space model [ 2 ] and corresponds to the cosine similarity measure. The cosine similarity of the instance vector x  X  = (w( x , x )) and the so called indirect class vector ic v c = x : c ( x ) = c x  X  is computed with: What this propositionalization method does, is similar to the 2Hop approach, it takes neigh-bors into account at a distance of two hops that belong to a particular class c . The difference to 2Hop is the type of normalization and furthermore it does not consider the direct neigh-borhood but only the neighbors at a distance of two hops, i.e., the graph is not densified by this method. This propositionalization method can be used either with the deterministic re-estimation or the one-shot estimation since it cannot handle probabilities. 6.3 Simple and learning relational classification methods Simple relational classification methods are simple nearest neighbor procedures, which do not learn. Since we aggregate only the classes of the neighbors, we can calculate the class membership probability of an instance x by using one of the propositionalization methods we have described before.
 We have implemented all of the propositionalization methods described above and used them as simple classifiers. We call the classifier using the propositionalization method PWAM , PRN like in [ 17 ], the one using WeightedAverage is called like the original, RN , the classifier using PWGM is called PRNGeometric and PRNMultiHop uses the MultiHop propositionalization. These methods can be used either with or without collective classification method. Which collective classification to use, depends on the propositionalization algorithm.
For relational learning methods we use the propositinalization methods in order to build attributes and use them to learn a model from training data. We have applied PWAM and IndirectRVS together with Logistic Regression.

Moreover we have used a Naive Bayes Classifier based on the approach of [ 4 , 18 ], however, instead of using probabilistic re-estimation ,weuse deterministic re-estimation as collective classification algorithm. We call this algorithm Weighted Naive Bayes . In contrast to the classical Naive Bayes classifier, this approach considers the weights of the links between an instance and its neighbors. Here the attributes of an instance are the classes of its neighbors. The class membership probability for an instance x and class c is computed according to Bayes rule as follows: While P ( c ( R x ) | c ) can be computed as The advantage of Naive Bayes is its simplicity, which is the independence assumption. Even if instances are not independent, Domingos and Pazzani [ 7 ] showed, that Naive Bayes classifiers performed well. However, most Machine Learning algorithms cannot be applied to relational data, because each instance can have a different number of neighbors and many algorithms cannot cope with missing values. Naive Bayes however, supports missing values, so that we can choose the number of attributes as the maximum existing number of neighbors. That means, we can consider the classes of the neighbors individually instead of aggregating them as in the former approaches.

Like for the simple relational methods, we use a collective classification algorithm for each presented relational learning method. First the training instances are initialized and the attributes are computed, then a model is learned. Next, the test instances are initialized, the attributes are computed and the learned model is applied in each iteration to all test instances until the algorithm converges or a certain number of iterations is reached. That means, in contrast to the EM (Expectation Maximization) algorithm, we learn the model only once and perform the iterations only on the test instances, on which the learned model is applied. 6.4 Systematic categorization of methods After presenting these methods, we would like to categorize them according to particular properties we determined. We analyzed the described approaches and detected the following distinguishing properties:  X  Learning ability We distinguish among methods which are able to learn a model from  X  Frequency of estimation Methods could differ in the frequency of estimating the class  X  Handling of unlabeled instances We decern approaches by the way how they handle  X  Representation of class information The class of neighbors can either be represented as
Table 1 shows the categorization of the methods we described before. We had already per-formed the categorization with respect to the learning ability in the last sections. Concerning the other criteria, we see that most of the methods re-estimate the class membership probabil-ity, i.e., the class membership probability for each instance is re-estimated in each iteration by using the classes of neighbors, which have been estimated in the previous iteration. The only method among the methods we have implemented, RN does estimate the class only once, i.e., uses the one-shot estimation approach, this has the disadvantage that updated classes are not considered. The methods RBC and RPT also estimate the the classes only once, both methods do not use collective classification . Hence, these methods do not consider unlabeled instances in the classification process. RDN in contrast uses collective classification , it initial-izes unlabeled data and re-estimates the class membership probability. Weighted Naive Bayes and Logistic Regression using IndirectRVS as propositionalization method applies determin-istic re-estimation as collective classification method that means the class information is represented as a nominal value. Since RBC and RPT do not use collective classification the criterium representation of class information cannot be applied. The methods we described are compound of different modules, the collective classification module, the propositional-ization module and a classification method. And these modules are interchangeable in most cases. 7 Ensemble classification methods In this section, we present two ensemble classification methods we have used in our generic framework. We have decided to use voting ,asimple ensemble classification technique and stacking , a more complex learning method. As mentioned in the introduction, ensemble clas-sification may lead to significant improvement on classification accuracy. This is because uncorrelated errors made by the individual classifiers are removed by the combination of different classifiers [ 6 ]. Ensemble classification reduces variance and bias, moreover, the combination of several classifiers may learn a more expressive concept compared to a single classifier.

First, we sketch briefly simple unweighted voting : After performing the individual clas-sifiers, we receive probability distributions for each classifier K l as output and build the arithmetic mean of the class-membership probabilities for each test instance and class:
The disadvantage of voting is, that voting performs well only if the results of the individual classifiers are similar.

The second ensemble classification method we present here is stacking [ 29 ], also named stacked generalization [ 33 ]. This method uses a meta-classifier to learn the probability dis-tributions of the individual classifiers and predicts the probability distribution of the combi-nation of these classifiers. Similarly to voting , we perform the individual classifiers K l using k-fold cross validation on the training data first, these classifiers are called level-0 classifiers. Then, we need to set up new instances, so called level-1 instances, which contain the class membership probabilities predicted by the individual classifiers and the true label c :
Then, a meta-classifier (we have used Logistic Regression) is learned on the new level-1 training instances and the model is applied to the level-1 test instances using k -fold cross validation.
As mentioned in Sect. 5 , we will use these methods in order to combine several relations, which as far as we know has never been done before with ensemble classification ,andfor one dataset we will additionally combine a local classifier with a relational classifier . 8 Evaluation and experimental results We performed an extensive and systematic evaluation of the discussed methods. Our aim was to find answers to the following main questions: 1. Does densification of relations improve accuracy? 2. Are methods using ensemble classification for the combination of relations more accu-3. Can a local classifier be outperformed by the ensemble of relations and local features? In total we have spent approximately 1,500 CPU hours for the experiments on these datasets. Some of them have been performed on a grid infrastructure. 8.1 Datasets To be comparable to other publications we applied our approach to Cora [ 19 ], a public dataset of scientific papers within the field of Computer Science. Similar to Macskassy and Provost [ 17 ], we have used 4,240 papers from the area of machine learning with 4,012 unique authors. Additionally the dataset contains citations and each publication can be assigned to one of seven categories. In our experiments for Cora we have used two relations, sameAuthor and citation . For this dataset we have not considered content information.

The second dataset is the CompuScience 1 dataset, also from the domain of scientific papers within Computer Science. We have used 147,571 papers with 117,936 unique authors, 9,914 reviewers and 2,833 journals. For each publication, a title and an abstract is available, but citations are not. Thus, we will use the relations sameAuthor , sameReviewer and sameJour-nal . A characteristic of this dataset is, that each publication can be assigned to more than one category out of the 77 categories that we have used (each category belongs to a least 20 instances). That means, we have to cope with the multilabel problem [ 27 ]. We used the One-vs-All (also called One-vs-Rest ) approach, that means, we learn our models for each class (denoting the positive class) against the rest of the classes (denoting the negative class), i.e., have to solve | C | binary classification tasks.
 In Table 2 some properties of the graphs for the different relations for Cora and Compu-Science have been listed. There, we can assess, that CompuScience is a much more complex dataset than Cora , especially the sameJournal relation is very complex, it contains millions of edges. Furthermore, we have observed that the relational autocorrelation is less for the relations of CompuScience than for Cora . As mentioned in Sect. 6 , relational autocorrelation is an important property, which influences the accuracy of the methods we presented. 8.2 Evaluation metrics In this subsection, we describe shortly the evaluation metrics we have used. Similar to most researchers, who worked on the dataset Cora , where the multilabel problem does not exist, we have chosen accuracy as evaluation metric. For the second dataset, where we have to cope with the multilabel problem and solve binary classification tasks, we have decided to use Precision, Recall and F-Measure as evaluation metrics. First, these metrics are calculated per category and then aggregated by using the micro-average approach (see ( 20 )and( 21 )).
TP i (True Positives) are the instances, which are correctly classified as positive concern-ing class i and TN i (True Negatives) are the correctly assigned negative instances regarding class i . Accordingly FP i (False Positives) are the instances, that are classified to be positive, but are not and respectively, FN i (False Negatives) are the instances, which have been wrongly assigned with a negative class. 8.3 Experiments We have performed several experiments: 1. In the first experiment we analyzed the effect of PRNMultiHop on Cora using 2. In the second experiment setting we have performed for both datasets threefold cross 3. In the third experiment setup, we have performed holdout sampling on Cora (10 X 90% 4. For the CompuScience dataset we have performed an additional experiment, using three-Furthermore, we have done some experiments in order to compare stacking and voting , both, in the case of fusing relations and in the case of combining relational and local classifiers. These experiments showed, that stacking is almost always superior to voting . Stacking is used in the second and fourth experiment setting, in the third experiment setting we used voting . Moreover, we could not apply stacking in the second experiment setting for the CompuScience dataset, because of high memory requirements. Regarding relational learn-ing methods that use propositionalization methods, we performed several experiments with diverse classification models like Support Vector Machines, Decision Trees and Linear and Logistic Regression. Due to the good performance and the low computation time, we have decided to use Logistic Regression.

For the Cora dataset, we have combined the relations sameAuthor and citation . The best combination for the CompuScience dataset is to consider all relations, but in the second experiment we have combined just the relations sameAuthor and sameReviewer since the complex methods RBC, RPT and RDN could not be applied to the sameJournal relation because of the complexity of this relation.

Regarding collective classification , the instances in Cora dataset were initialized with the prior, because text has not been considered for this dataset. For CompuScience we initialized the test instances with the results achieved by a text classifier.

We used two types of test protocols: We split the datasets into test and training sets by using stratified threefold cross validation and stratified holdout sampling as mentioned before. The connections, among training and test set are preserved, since this aids the inference process. In the second and third experiment settings we will compare PRN using the Relation Unification approach to PRN using our approach of combining relations with ensemble clas-sification , this is called as from now EPRN , the other relational methods described in Sect. 6 , which use our relation combination approach are too, prefixed with  X  X  X . The complex models RBC, RPT 2 and RDN 3 do not use ensemble classification . They represent each instance as a subgraph containing all its neighbors including several relations. The complex methods RBC, RPT and RDN have been performed using Proximity. 4 Because of the complex Com-puScience dataset, we could not run the methods RPT and RDN on this dataset. All methods we have presented in Sect. 6 and some others are included in our tool, named RelEns , 5 it uses Weka, 6 a machine learning workbench. 8.4 Experimental results In the first experiment we want to elaborate the effect of different parameters on our new method PRNMultiHop . We assume that the weights, the path length, the parameter d (lower bound of neighborhood size) and the sparsity of the relation influences the result of this method. In Table 2 the average number of neighbors for both relations is shown, we see that the citation relation is sparser than the sameAuthor relation. We applied PRNMultiHop with different configurations on the sameAuthor and citation relation. For both methods we chose the number of the neighborhood size d = 3 by validating it on ten percent of the training data. We tried different values for the minimal weight that an edge has to have at least in order to be considered and for the path lengths (number of hops). The results for some of the configurations we performed are listed in Table 3 .

We see that the best results are achieved for the citation relation with the PRN2Hop method, i.e., we consider additionally to the direct neighbors the neighbors at a distance of two hops and we do not apply any restrictions concerning the weights (minimal weight is 1). For the sameAuthor relation we achieve better result when we restrict the approach to neighbors that have a weight of at least three or four and are at a distance of two hops. A smaller minimal weight decreases the accuracy of the approach for both relations, except for higher minimal weights, since they are rare. Increasing the number of hops also decreases the accuracy. Hence, considering neighbor that are to far away or less important, i.e., have a low weight, leads to worse results. For comparison: EPRN achieved an accuracy of 0.7051 for the sameAuthor relation and 0.7952 for the citation relation. We see that taking into account additional neighbors and hence densifing the relation leads to a slight improvement for the sparser citation relation compared to EPRN , but not for the sameAuthor relation, which is denser. For sparser datasets we expect a higher improvement in accuracy. In the following experiments we will only consider PRN2Hop since it achieved better result than PRNMultiHop .

The results of the second experiment for Cora are depicted in Fig. 4 . We have compared our algorithms to the complex methods RBC, RPT and RDN. We have observed that four of our algorithms have achieved a significantly 7 higher accuracy (asterisked bars) than those more complex methods. Furthermore we have noticed, that our extension of EPRN , EPRN2Hop , performed best.

Moreover, we have detected that most of the simple methods achieved higher accuracy than the relational learning methods. Only Logistic Regression using PWAM as proposi-tionalization method is also significantly better than the other listed methods. It seems that methods, which use probabilistic re-estimation tend to achieve higher accuracy, IndirectRVS and ERN in contrast, which uses deterministic re-estimation and one-shot estimation respec-tively, performs worse than the other simple methods. All of our methods performed better than the complex methods RBC, RPT, RDN. Our algorithms seem to profit from the strength of ensemble classification . Moreover they performed better than PRN with the Relation Unification approach.

One interesting point is, to compare only the complex methods in order to capture the reasons for the low accuracy of RPT and RDN. Doing this comparison, one notices that the simplest complex algorithm, RBC, achieves the best result. The poor results achieved by RPT could be due to the fact that it cannot exploit the power of relational autocorrelation because it does not use collective classification . Another reason could be that we applied the algorithm with only one attribute, which is the category of the neighbors of an instance, but Neville and Jensen [ 21 ] showed, that 90% of the features constructed in their algorithm contain the category as an attribute. RDN, which performed better than RPT in [ 21 ], delivered poor results in our experiments although it uses collective classification . To rule out that the number of iterations has been chosen too low we investigated this matter further by analyzing the influence of the numbers of iterations on the results. The experiments have shown that the accuracy does hardly change after 50 iterations.

Additionally to this experiment measuring the accuracy of methods, we would like to pres-ent the measured runtime of them (see Fig. 5 ). This is the time measured for threefold cross validation experiments on both relations, wile the results have been combined by stacking . We see that the simple methods need less time than the learning methods, except PRN2Hop which needs more time because the building of the new edges, the calculation of the weights etc. is done at the moment on the fly, PRN using Relation Unification is of course, more scalable since it has to be performed only once in contrast to our methods that are applied on each relation. When comparing this times to the runtime needed by the complex methods RPT and RDN we see that our methods are much more scalable.
The second experiment setting has been performed on the CompuScience dataset too. The results for CompuScience are depicted in Fig. 6 . As mentioned before, we could apply only one complex method, namely RBC, on this dataset and we could combine just two rela-tions, namely sameAuthor and sameReviewer .Asfor Cora, all methods listed in Fig. 6 have reached a higher accuracy than RBC and again the best result was achieved by EPRN2Hop . Furthermore, the accuracy of EPRN is much higher than the accuracy of PRN ( Relation Unification ). One can notice that ERN also performs much worse than our other methods, this is because it is used together with one-shot estimation and hence, the test instances are not initialized with the results of the local classification . Because of the complexity of this dataset and consequently long computation time and high memory requirements, some of our methods could not be performed. So, the answer to the main question posed in the second experiment setting is that for both datasets the relational methods described in Sect. 6 have performed better than the complex methods RBC, RPT and RDN.

The next experiment uses holdout sampling on Cora in order to compare the relation fusion by ensemble classification to the Relation Unification . Furthermore we want to ana-lyze how the methods perform on different training and test set sizes. We have split the data in training and test sets of different percentage (10 X 90%) and have performed the algo-rithms for each percentage on five randomly chosen splits. We applied both combination approaches to the Cora dataset. Figure 7 shows the accuracy achieved by PRN and Logistic Regression using PWAM as aggregation function on several splits. The solid line represents an algorithm, which uses our fusion approach with ensemble classification (here voting ), the dotted line shows the accuracy of the algorithm, which uses Relation Unification .Both algorithms, EPRN and ELogistic Regression using the PWAM aggregation function have achieved significantly higher accuracy than with Relation Unification . Moreover we observe that the relational learning method achieves poor results when the amount of training data is small. While the performance of the simple relational method is much higher on few training examples.

As mentioned in the previous section, the fourth experiment setting has been applied on CompuScience dataset. Here, we have measured the performance of the algorithm with F-Measure.Theaimofthisexperimentistocomparetheensemblesof relational classification and text classification with pure text classification. We fused first, all relations using stacking and then combined the result with the outcome of a text classifier using stacking as well. As a local classifier , we have chosen a Support Vector Machine using the words of the abstract and title of a paper as attributes of the SVM. Taking additionally the authors and journals as nominal attributes into account did not improve the results. Figure 8 shows the F-Measure of some algorithms, which we have described in Sect. 6 . One can see, that the ensembles of relational classification and text classification always achieve higher F-Measure values than the text classifier (using only local features). The results of EPRN fused with the results of the text classifier are actually significantly better than the results of the other algorithms. The best relational learning algorithm in this experiment in contrast to the experiments on Cora is ELogistic Regression using IndirectRVS as aggregation function. This confirms the hypothesis of Bernstein et al. [ 2 ] that the IndirectRVS is able to achieve better results when the relational autocorrelation is lower.

As consequence of these experiments, we recommend to exploit the relations existing in the data and to densify relations if necessary, in order to improve accuracy. 9 Conclusions and future works We have presented our generic relational ensemble model that includes a new way of com-bining several relations using ensemble classification and considers relational features as well as local features using ensemble classification . In Sect. 8 section we have shown that our approach improves classification accuracy significantly compared to complex relational learning algorithms [ 20 , 23 , 24 ]andtoa local classifier . Furthermore, we have shown that our way of combining relations is significantly better than the Relation Unification approach and in most of the experiments our simple relational method EPRN2Hop performed best.
In future works we plan to do further experiments with other propositionalization methods to improve the performance of relational learning algorithms and evaluate other ensemble classification methods. Furthermore we will apply our new approach PRNMultiHop to other sparser datasets in order to further analyze its properties.
 References Authors Biography
