 1. Introduction
Frequent pattern mining is one of the most important research topics in the area of data mining. In 1994, Agrawal and Srikant transmission, sampling errors, or other factors. 1.1. Uncertain data
We consider two types of uncertain data in this paper. In the first type, each attribute in a transaction is associated with a pollution may record a quantitative interval, instead of a precise value, to indicate the amounts of suspended particulates at the three attributes of a transaction, namely, suspended particulates, sulfur dioxide, and carbon dioxide, denoted as A
A respectively. If the value of an attribute is missing due to a sensor malfunction, the absence is indicated by a or simply as a uniform or normal distribution.
 hibits the following four symptoms: insomnia, anxiety, depression, and panic, denoted as I toms function as items, while the patient records represent transactions. Each diagnosis indicates the chances that those symptoms exist, rather than stating that the patient definitely has or does not have them.

The two types of uncertain data are fundamentally different. Itemset uncertain data can be viewed as a transaction comprised with an uncertain setting.

Mining frequent patterns from uncertain data is not as simple as mining such patterns from precise data. In the latter, a pat-pattern's support in univariate uncertain data is even more complex than in itemset uncertain data for two reasons. First, the able for precise data. We elaborate on the arguments about the downward closure property in Section 3 .
Although a number of methods have been proposed for mining frequent patterns from uncertain data [7 suitable for mining itemset uncertain data. None of them can handle univariate uncertain data. However, discovering frequent
U2 patterns in univariate uncertain data, such as sensor readings, is an important step in analyzing and understanding the data. Therefore, to address the problem, we propose a novel method called the U2P-Miner algorithm for mining frequent U2 pat-form potential frequent U2 patterns. We also develop two acceleration techniques that exclude unimportant patterns to speed up the mining process. The first technique deletes unimportant base intervals; and the second merges such base intervals to form candidate base intervals. 1.2. Key contributions designed to retrieve frequent U2 patterns from univariate uncertain data. Second, we use a base interval as the basic element oped for use with U2P-Miner algorithm can be utilized by other methods. We also provide an objective measure to determine which technique should be adopted in each situation. Fifth, comprehensive experiments are conducted to compare the perfor-tracking methods [2] on synthetic and real datasets. The results demonstrate that the proposed method outperforms the compared methods.
 quantitative data mining methods. In Section 3 , we define some key terms used throughout the paper. We discuss the proposed 2. Literature review
In this section, we review the literature on uncertain data mining methods and quantitative data mining methods. We also consider a number of issues that must be addressed when mining frequent patterns from uncertain data and quantitative data. 2.1. Uncertain data mining
Generally, the methods for mining frequent patterns from uncertain data can be classified as Apriori-based, FP-growth-based, ogy. Subsequently, Chui and Kao [8] proposed a decremental pruning strategy that speeds up the U-Apriori algorithm by estimat-node. The UF-growth algorithm has also been exploited to mine frequent patterns from streams of uncertain data [11] as well third category, Aggarwal et al. [16] conducted a series of experiments on uncertain data and concluded that the H-mine-based algorithm outperformed both the Apriori-based and FP-growth-based algorithms. The H-mine algorithm is similar to the FP-growth, except that it uses a hyperlinked structure instead of a tree structure. A detailed review on these methods can be found in [23] . In addition, Calders et al. [24] proposed sampling items' probabilities to accelerate the mining process. the pattern will occur in all the transactions that contain it: 0.8 4 X 0.62+0.48 X 0.57+0.94 X 0.73+0.63 X 0.98=2.098. If the minimum the frequencies of all items into consideration to determine whether an item is frequent, instead of depending on the frequen-should be considered when counting its support. Later, Calders et al. [26] extended the study in [13] by using a form of the central limit theorem to measure the probability that a given itemset is frequent. In [27] , Muzammal and Raman presented a study on mining uncertain sequential patterns. Frequent patterns of uncertain data are also applied to classification prob-lems in [28,29] .

Although the proposed method exploits the concepts of existential probability and expected support, we deal with a different type of uncertain data. Our proposed method also combines basic elements to form a merged pattern. We discuss this aspect in detail in Section 4 .
 2.2. Quantitative data mining An intuitive way to mine quantitative data is to take each possible value as an item, and then follow the procedures used in whose consequent parts are statistical measures or the aggregates of attributes; and 3) mining under constraints. Readers may refer to [32] for a detailed survey of the above methods.

The proposed method processes data that are originally represented by using intervals and augmented by probability density a different way of counting pattern support. 2.3. Summary
Based on the above discussion, we summarize the characteristics of the main frequent pattern mining methods in Table 1 . The column in bold is the proposed method. We compare the methods in terms of the types of data they deal with, the methodologies they adopt, and the data structures they use during the mining process. In the table, with either precise data or uncertain data, while  X  Data type quantitative data. The candidate generation methodology generates candidate patterns and determines their frequency. The pat-tern growth methodology uses a tree or hyper-structure to enumerate patterns, which is more efficient than the candidate gen-gorithm also uses a tree structure to compress database transactions rather than an array or a linked list, so it can compute expected support efficiently. Note that some applications are not included in this classification, e.g., frequent graph mining methods [33,34] , approaches for mining frequent tree-like patterns [35] , mining frequent movement patterns for a mobile user [36] , and mining web usage data [37] , because they are not related to the proposed method. 3. Preliminaries
In this section, we define six key terms used throughout the paper. We also discuss the relationship between the proposed method and the downward closure property.

De ability density function, which assigns a probability to each value in the interval.

De fi nition 2 . Suppose an attribute A in a transaction T is associated with a quantitative interval I tion P A . The existential probability of an interval I AS tegral of the density over I AS , denoted by ExProb ( I AS
De fi nition 3 . An quantitative interval I of attribute A i with a range from m to n is represented by A one or more non-repeated attributes, each of which is associated with an interval; and a U2 pattern comprised of interval I
I ified by the user. Thus, a frequent U2 pattern represents the intervals where the actual values locate with high probability.
De fi correspond to one of the intervals in Pat . Thus, where | T Pat | denotes the number of transactions in T Pat
De fi nition 5 . A number of values act as lower bounds or upper bounds (or both) for an attribute. Each pair of consecutive bound values forms a base interval . A base interval i with a range from m to n is denoted as { BI
De fi nition 6 . A base interval and its existential probability form a base element .

In Fig. 1 , five values (i.e., 13, 15, 28, 30, and 31) appear as lower bounds and/or upper bounds of A tervals for A 1 :[13, 15], [15, 28], [28, 30], and [30, 31]. If we give [13, 15] the serial number BI { BI probability of BI 1 on A 1 in T 2 is (15  X  13)/(31  X  13)=0.111. The expected support for BI of the occurrences of BI 1 in Fig. 1 . Since BI 1 only occurs once, its expected support is 0.111. In addition, [ BI tern comprised of BI 1 .{ BI 1 , 0.111} means a base element comprised of BI the term partial expected support has three usages. Moreover, the downward closure property does not always hold in univariate may or may not be frequent. For example, if U2 pattern [ I pattern [ I sub , I 2 , I 3 ], where I sub is a sub-interval of I characteristic also differentiates univariate uncertain data mining from existing uncertain and interval data mining methods. 4. The proposed method quent U2 patterns from univariate uncertain data. The algorithm is implemented in two phases. We introduce the base interval scheme in Section 4.1 , and then describe the two phases in detail in Sections 4.2 and 4.3 respectively. Formal algorithms are given in Section 4.4 . 4.1. Using the base interval scheme tern [ A 1 :[15, 28]] is frequent, as its expected support is 13/15+13/18+13/13+13/15=3.456. Therefore, the intervals of each attribute should also be decomposed to find potential frequent U2 patterns. We believe the values that act as lower or upper bounds in the transactions are more meaningful than those that do not act as bounds. Consequently, based on Definition 5 ,we tervals are combined to form a set of U2 patterns, which serve as potential frequent U2 patterns.
There are two considerations underlying our choice of the base interval scheme. On the one hand, the expected support of a expected support of [15, 20] can be derived by (20  X  15)/(28 [ A :[15, 28]], which is precisely the value of A 1 in T 3 and should therefore be considered. The expected support of [ A cannot be calculated directly from that of [ A 1 :[15, 30]] because a transaction containing [ A 30]]. Hence, we use the base interval scheme in our study. 4.2. Constructing a U2P-tree A U2P-tree compresses the transactions of database into a tree structure by decomposing each transaction into base intervals. tribute are recorded on a list. Take the database in Fig. 1 as an example. By inserting T intervals shown in Figs. 3 (a) and 4 (a) respectively. The tree node { A [15, 30]:1.0} occurs once and its partial expected support is equal to 1.0. Next, we insert T be decomposed into [13, 15], [15, 30], and [30, 31] because [15, 30] is a base interval in the current U2P-tree. The resulting tree and list of base intervals are shown in Figs. 3 (b) and 4 (b) respectively. Inserting T on A 1 . Therefore, two tree nodes, namely, { A 1 :[15, 30]:1.0}:(1, 1.0) and { A
The results are shown Figs. 3 (c) and 4 (c) respectively. Similarly, inserting T of A 2 and A 3 respectively. The corresponding tree nodes, { A 82]:0.933}:(1, 0.933), should also be decomposed. In addition, T i.e., { A 1 :[15, 28]:0.867} and { A 1 :[28, 30]:0.133}, as T which is given a serial number.
 the structure allows us to trace the process. 4.3. Enumerating frequent U2 patterns
In this sub-section, we explain how the constructed U2P-tree is used to enumerate frequent U2 patterns. During the mining process, a U2 pattern, whose support must be checked, is formed by a two-level merging technique that selects the attributes, terns containing the final base interval of the last attribute, e.g., BI next attribute is mined.
 ing process using the U2P-tree in Fig. 5 as an example.

The enumeration of frequent U2 patterns begins with BI 11 taining BI 11 , the expected support of U2 pattern [ BI 11 expected support is 0.143+0.133+0.143=0.419, which means [ BI
Next, the U2 pattern [ BI 10 , BI 11 ] is examined. To find this U2 pattern, each tree path containing BI rived from a tree path containing the U2 pattern. In the current case, the expected support of the U2 pattern [ BI (0.857+0.143)+(0.8+0.133)+(0.857+0.143)=2.933, which is still less than the minimum support. Next, the U2 pattern [ BI 9 , BI 10 , BI 11 ] is examined, but it is not frequent either. All U2 patterns containing BI [ BI od can be easily modified to mine U2 patterns comprised of multiple disjunctive intervals.

The next step examines the U2 patterns containing BI 10 except patterns [ BI previously. Following the pointers, the expected support of [ BI is a frequent U2 pattern, and the conditional U2 pattern base of [ BI base . The conditional U2 pattern base is used to construct the conditional U2P-tree of [ BI sponding parent tree path by the existential probability of the base element of the conditional U2P-tree node. The partial expected support of a projected base on a parent tree path is the summation of the partial expected supports of the tree nodes projected base, not an ordinary U2 pattern.) If the occurrence frequency of the conditional U2P-tree node is more than one, it means that at least two parent tree paths share the node. Thus, the partial expected supports computed from those paths are jected base may be different for each parent tree path. For example, the partial expected supports of the projected base [ BI the parent tree paths with prefixes CP 1 , CP 2 , CP 3 , and CP tial expected support is (0.857 X 0.867)+(1.0 X 0867)=1.61. Mining the conditional U2P-tree is the same as mining the original
U2P-tree. Only BI 2 is frequent in the conditional U2P-tree, i.e., [ BI conditional U2P-tree, is not frequent.

After enumerating frequent U2 patterns containing BI 10 , BI tervals of attribute A 3 have been examined. The mining process continues with the base intervals of attribute A the U2 patterns comprised of the base intervals of A 2 is frequent. Finally, the base intervals of attribute A [ BI 2 ], the U2 patterns are not frequent. Thus, only U2 patterns [ BI 4.4. The U2P-Miner algorithm
PatternGrowth , and BuildConditionalTree , as shown in Figs. 8 the tree root are checked to find the node that matches the first base element of the inserted transaction. If a child node is is inserted by calling the same procedure.

The PatternGrowth procedure enumerates frequent U2 patterns by checking the patterns' expected support and constructing con-partial expected support of the projected base in a transaction Tran is represented as PPB.Tran.partial_expected_support . section, we introduce the two acceleration techniques that speed up the mining process. 5. The acceleration techniques
The two acceleration techniques, denoted as U2P.A1 and U2P.A2 respectively, reduce the number of base intervals in each at-form candidate base intervals. 5.1. The U2P.A1 technique
U2P.A1 provides a lower bound threshold T 1 that can be set by the user. The mining process does not consider any base inter-expected support for each one is shown in parentheses. If T
BI , BI 4 , BI 7 , BI 8 , BI 9 , and BI 10 . Thus, the attribute is now made up of three base intervals, i.e., BI the beginning of the mining process. The base intervals whose expected support is above T way for an un-passed base interval to be included in a frequent U2 pattern is if it is combined with a frequent base interval, value of the attribute seldom falls in the interval of low expected support, e.g., BI avoids spending time on mining frequent U2 patterns that are of little value. 5.2. The U2P.A2 technique U2P.A1 may also prune a frequent U2 pattern that only comprises base intervals with low expected support. For instance, in
Fig. 12 , the U2 pattern comprised of BI 2 , BI 3 , and BI kind of frequent U2 pattern. The technique provides a threshold T (as in U2P.A1), U2P.A2 merges such intervals to form U2 patterns that have expected supports higher than T can be thought as complementing U2P.A1. In Fig. 12 ,if T 2 patterns formed by merging un-passed base intervals are processed as follows. The un-passed base intervals of an attribute are decomposed into several groups. Those between two passed base intervals are clustered in one group, e.g., BI tween BI 1 and BI 5 ); and those not enclosed by the two passed base intervals form another group, e.g., BI resulting U2 pattern is calculated when the un-passed base interval is merged. If the expected support does not exceed T passed base interval continues to merge with the second previous consecutive un-passed base interval and checks the expected minate until one of the following conditions is satisfied: 1) a U2 pattern whose expected support exceeds T but the latter does not return anything. Then, the un-passed base interval merges with the next consecutive un-passed base in-tervals. A candidate base interval may be found in the same way. For example, the un-passed base interval BI not exceed T 2 ,[ BI 7 , BI 8 , BI 9 ] is checked. The merging process for BI exceeds T 2 , or there are no other un-passed base intervals with which it can be merged. Next, BI
However, no computation is required because [ BI 7 , BI 8 with the next un-passed base interval to form [ BI 8 , BI
BI are selected. The average expected support is derived by dividing a U2 pattern's expected support by the number of un-passed base intervals in the U2 pattern.
 5.3. Issues related to U2P.A1 and U2P.A2 intervals. For instance, among the base intervals of A 1 , only BI
U2P-tree in Fig. 5 ,[ BI 3 , BI 4 ] should be examined to determine whether it passes T
The second issue is how to implement the mining process for U2P.A1 and U2P.A2. Both techniques use the constructed U2P-procedure is applied to the U2P-tree as usual, but all un-passed base intervals, such as BI under U2P.A1, only passed base intervals are used to form U2 patterns; and under U2P.A2, passed base intervals and merged base intervals are used to form U2 patterns. For instance, if [ BI all U2 patterns containing BI 5 and BI 6 must be checked; however, those that only contain BI
The third issue concerns the choice between using U2P.A1 or U2P.A2 for mining, given that T
For databases in which most un-passed base intervals have expected supports much lower than T However, the first advantage may not be very important in cases where the number of merged base intervals N high compared to the number of passed base intervals N PBI intervals. Therefore, the choice of acceleration technique is based on the ratio R To choose the appropriate technique, we compute the expected support of each base interval to determine N rive R MP by computing the expected supports of U2 patterns comprised of un-passed base intervals to determine N higher than a user-specified threshold (e.g., 0.1), U2P.A2 is chosen because the number of merged base intervals exceeds the threshold; otherwise, U2P.A1 is adopted.

The acceleration techniques can also be applied by other algorithms that use the base interval scheme to retrieve frequent U2 tracking algorithms. 6. The experiments
In this section, we evaluate the performance of the U2P-Miner algorithm on synthetic and real datasets. We modified the above-mentioned algorithms to compare their performance with that of U2P-Miner. The H-mine algorithm constructs an H-struct contain more than two items of an attribute. The modified depth-first backtracking approach also takes every possible combina-first approach.

The experiments were divided into three sets. In the first set, we compared the performance of U2P-Miner with that of the other algorithms under various levels of minimum support and different-size datasets (i.e., the number of transactions in the datasets). In the second set, the two acceleration techniques were evaluated. The above experiments were performed on a syn-thetic dataset. In the third set, we used two real datasets. All the experiments were performed on an IBM compatible PC with an Intel Core i7 CPU (2.67 GHz) and 3 GB main memory, running on Windows XP Professional. The algorithms were implemented ment sets respectively. 6.1. The synthetic and real datasets tions is set at 9, the average length of potential frequent U2 patterns is set at 6, and the number of transactions is set at generated transactions is 23 and the actual average length of the potential frequent U2 patterns is 18. tributes from the DY2009 dataset: atmospheric pressure at the observation stations, atmospheric pressure at sea level, temperature, vapor pressure, and relative humidity. We chose these attributes because the daily minimum and maximum of ated with each interval is set as a normal distribution to simulate the real-world setting.
 lates, sulfur dioxide, and nitrogen dioxide. The data was collected by the Taiwan Environmental Protection Administration and can be downloaded from the EPA website [39] . We selected five indices from the AirQuality dataset, namely, suspended particu-to mine frequent U2 patterns, we modify the dataset to obtain five intervals formed by the daily minimum and maximum values 26,527 transactions in total.
 degree of an attribute to determine how much the transactions overlap. If they overlap a great deal, the number of frequent U2 patterns may be small when the minimum support is low, but a few frequent U2 patterns may still exist when the minimum sup-port is high. In contrast, if the transactions only overlap by a small amount, the number of frequent U2 patterns may be large when the minimum support is low, but few frequent U2 patterns exist when the minimum support is high. Moreover, in cases by a small amount. This is because the number of base intervals that appear frequently will be small if there is a significant show that some base intervals appear frequently, and therefore imply that the transactions overlap a great deal. In the DY2009
Table 2 . 6.2. The experiments with varied minimum support and dataset sizes
The first set of experiments examined the relationships between the runtime and minimum support, as well as the dataset mance differences between the algorithms are much greater than they appear in the figures. To show the exact differences, the runtime savings achieved by using the U2P-Miner algorithm instead of the other three algorithms are shown in Fig. 14 .
The U2P-Miner and modified H-mine algorithms are obviously faster than the modified Apriori and modified depth-first back-tracking algorithms, especially when the minimum support is less than 3%. U2P-Miner performs slightly better than the modified
H-mine algorithm when the minimum support is greater than 4%. However, as the minimum support gets smaller, U2P-Miner form of the transactions, while the H-struct maintains all the transactions. Consequently, the modified H-mine algorithm may need to trace more transactions than the U2P-Miner algorithm to compute the expected support of a U2 pattern. As the number of U2 patterns that must be checked increases, i.e., the minimum support becomes smaller, the impact is more pronounced. In gorithm ranges from 2.83 to 5.92 for different levels of minimum support in the experiments based on the uniform distribution, and 2.68 to 6.96 in the experiments based on the normal distribution. Second, computing the expected support for U2 patterns comprised of base intervals from more than two attributes is more efficient under the U2P-Miner algorithm than under the mod-to compute the partial expected supports of the nodes in the conditional U2P-tree. This means the partial expected support of
H-mine algorithm does not record that information. Therefore, when the modified H-mine algorithm computes the expected sup-each projected base's occurrence in advance. This inevitably increases the time complexity.

In addition, the modified Apriori algorithm outperforms the modified depth-first backtracking algorithm if the minimum sup-quent 2-patterns, i.e., frequent U2 patterns comprised of two attributes, is available to construct a candidate 3-pattern, the modified depth-first backtracking algorithm does not have this information. However, when the minimum support gets smaller, probabilities to the values near the central value of an interval. Therefore, the number of frequent base intervals decreases.
Next, we consider the scalability of the four algorithms with respect to the number of transactions when the minimum support above-mentioned synthetic dataset. The scalability of each algorithm is linear. From the figure, we observe that the U2P-Miner algorithm is the most efficient and the most scalable for mining very large databases. 6.3. The experiments using two acceleration techniques
In this sub-section, we evaluate the two acceleration techniques. The synthetic datasets with uniform and normal distributions for the normal distribution are similar.

The experiment results for U2P.A1 and U2P.A2 are shown in Tables 3 and 4 respectively. To evaluate the effect of using differ-ent values of T 1 (and T 2 ), we use the following rule to set the values of T support is P %, the values of T 1 (and T 2 ) are set at 0.1%, 0.2%, the runtimes under different values of T 1 . The values are highlighted with a gray background. An entry marked by setting is not used. The layout of Table 4 is identical to that of Table 3 .

The results show that when the minimum support is fixed, a lower T the value of T 1 (or T 2 ) is fixed, lower minimum support results in a longer runtime. When the value of T increases a great deal by changing the value of T 1 (or T expected support is less than 0.2%. Therefore, changing the value of T the runtime of U2P.A1 is always less than or equal to the runtime of U2P.A2 if the value of T1 is the same as that of T2.
The advantage of using the acceleration techniques can also be demonstrated by checking the number of U2 patterns that must be examined during the mining process. Table 5 shows the results of applying U2P.A1 to the synthetic dataset with a uni-form distribution. In the table, the left-most column lists the minimum support ( as percentages (  X  w/o  X  means  X  without using acceleration technique examined by U2P.A1, where the number is rounded off to the nearest hundred thousand. The number of U2 patterns examined shows similar tendencies to the runtimes. Lower T 1 values lead to more examinations if the minimum support is fixed. Lower minimum support also leads to more examinations if the value of T U2 patterns must be examined. The results derived by using U2P.A2 are similar to those for U2P.A1.
The U2P.A2 technique provides a mechanism for retrieving frequent U2 patterns containing un-passed base intervals. Table 6 compares the ratio of the increased number of frequent U2 patterns R covered by using U2P.A1. For ease of presentation, Table 6 only shows the data when T The other settings exhibit similar tendencies. The first column in Table 6 lists the minimum support; the second and third fifth columns list the corresponding ratios for the normal distribution setting.
 Based on the results in Table 6 , we draw three conclusions. First, if the R be significant. Second, a significant R MP leads to a significant R intervals have high expected supports. Therefore, fewer additional frequent U2 patterns are retrieved. 6.4. The experiments on the real datasets In this section, we report the experiment results on both real datasets.
 6.4.1. The experiments on the DY2009 dataset
In this section, we present the experiment results on the DY2009 dataset. Fig. 16 (a) compares the performance of the pro-ferences between the methods. The differences between U2P-Miner and the other algorithms are more precise in Fig. 16 (b), which shows the runtime savings. Note that the lines representing the modified Apriori and modified depth-first backtracking gorithms exceed that of U2P-Miner by a substantial margin. In addition, the ratio of the number of transactions traced by the modified H-mine algorithm to the number traced by the U2P-Miner algorithm ranges from 15.98 to 30.77.
Next, we consider the performance of U2Miner and the three compared algorithms when the two acceleration techniques are applied. However, in Fig. 17 , we only compare the U2P-Miner and modified H-mine algorithms. The modified Apriori and mod-ified depth-first algorithms take much longer than the U2P-Miner and modified H-mine algorithms, even when the acceleration reporting the results of using three values for both T 1 and T niques to the modified H-mine algorithm are denoted as H-mine.A1 and H-mine.A2 respectively. Obviously, the U2P-Miner algo-rithm and its two variants outperformed the modified H-mine algorithm and its two variants. In addition, as the value of T vals, the number of additional frequent U2 patterns discovered by U2P.A2 is not significant. In fact, the range of R iment is only 0.6% to 2.1%. For comparison, if we set T 1 celeration techniques are used.
 6.4.2. The experiments on the AirQuality dataset compared algorithms with various levels of minimum support; and Fig. 18 (b) shows the runtime savings. Because the runtimes of the proposed method and the modified H-mine algorithm are much shorter than those of the modified Apriori and modified the ratio of the number of transactions traced by the modified H-mine algorithm to the number traced by the U2P-Miner algo-rithm ranges from 8.34 to 10.00. Fig. 19 shows the results of using the two acceleration techniques with T the proposed method outperforms the modified H-mine algorithm. It is noteworthy that the modified H-mine.A1 algorithm is fas-ter than U2P-Miner when the minimum support is equal to 4% or 5%. However, it is not faster when U2P.A1 and U2P.A2 are ap-plied. The R IFP is also low at the current setting (the range is 0.8% to 4.4%). For comparison, if we set T minimum support, the R IFP ranges from 9.8% to 26.5%. Moreover, frequent U2 patterns with high expected support, such as patterns can still be discovered when the acceleration techniques are applied. 7. Conclusions and future work
We have proposed a novel algorithm called U2P-Miner for mining frequent U2 patterns from univariate uncertain data. The and modified depth-first backtracking algorithms on both synthetic and real datasets.

Although we only discuss attributes represented by the univariate uncertainty model, the proposed method can also used to uncertain attributes and categorical attributes can be mined.

In the future, we plan to integrate frequent U2 patterns whose intervals mostly overlap. We will also focus on seeking other algorithms that perform frequent U2 pattern mining under user constraints and on uncertain data streams. Acknowledgments
The authors are grateful to the anonymous referees for their helpful comments and suggestions. This research was supported in part by the National Science Council of Republic of China under Grant No. NSC 99-2218-E-259-001-.
References
