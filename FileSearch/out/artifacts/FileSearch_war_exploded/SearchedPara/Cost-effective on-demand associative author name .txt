 1. Introduction
Citations (here understood as a set of bibliographic features such as author and coauthor names, work title and pub-multiple name variations ( synonyms ) or when multiple authors have exactly the same name or share the same name var-and the decentralized generation of content (e.g., by means of automatic harvesting).  X 
The name disambiguation task may be formulated as follows. Let C ={ c disambiguation function which is used to partition the set of citations into n sets { a tains (all and ideally only all) the citations in which the i th author appears. bility issues, avoiding the need for comparisons among all citations.

The complexity of dealing with ambiguous names in DLs has led to myriad of methods for name disambiguation citations for which the correct authorship is known. Each example is composed of a set of m features ( f draws its value from a discrete set of labels ( a 1 , a 2 unknown. The disambiguator, which is a function from { f 1 citations in the test set.
 potential of supervised machine learning techniques: hard-to-label citations with highly ambiguous authors. The cost associated with this labeling process thus may render
However, it may be worthwhile annotating at least some examples, provided that this effort will be then rewarded with ness even in the case of limited labeling efforts.

There is a potentially large number of features and authors, and consequently, the number of possible disambiguation with rarely appearing authors.
 ability of examples). Thus, disambiguators must be able to detect unseen/unknown authors, for whom no label was pre-viously specified.
 the examples and, when uncovered, they may reveal important aspects concerning the underlying characteristics of each adopted by associative disambiguators, where the disambiguation function is built from rules of the form X! a &amp; Zaki, 2006 ).
 contributions of this article are highlighted by specific properties of these disambiguators:
EAND, which works in a eager manner, provides the basic foundations for the use of association rules for name disambiguation.

LAND extracts rules from the examples on a demand-driven basis, according to the citation being disambiguated. Thus, suited for ambiguous groups where the popularity distribution of authors is skewed. Further, extracting rules on a relevant to the specific citation being considered.

To limit labeling efforts (which is a major problem in real world scenarios), SLAND extends LAND by employing a self-advantage of the recently included (pseudo-)example.
 the corresponding citation is considered as a new example which is included in the training data. extremely effective, as it will be shown by a systematic set of experiments using citations extracted from the DBLP ators, LAND is able to outperform all of them with gains in terms of macroF examples.
 mental evaluation. Finally, Section 5 concludes the article with some discussion about future work. 2. Related work
Existing name disambiguation methods adopt a wide spectrum of solutions that range from those based on supervised name disambiguation methods. Our main focus, however, is on those methods that have been specifically designed for to the scope of our work.
 based on Support Vector Machines (SVMs). Both methods have been evaluated using two collections, one from the Web (mainly publication lists from homepages), and the other from DBLP.
 collections extracted from the Web.

In Torvik et al. (2005) , the authors propose a probabilistic metric for determining the similarity between MEDLINE uation), which uses coauthor information to measure the distance between two names in the citations. measure for the respective authors. Results expressed in terms of average ranked precision measures, considering real measures.

Huang et al. (2006) present a framework for name disambiguation in which a blocking method first creates candidate by standard SVMs. This method exploits additional sources of evidence, such as information extracted from the headers of papers corresponding to the respective citations obtained from CiteSeer.
 model for collective entity resolution that uses the cooccurrence of the references to entities ( Bhattacharya &amp; Getoor, 2007 ).

Culotta et al. (2007) propose a more generic representation for the author disambiguation problem that considers fea-several methods for increasing the author coreference by gathering additional evidence from the Web.
Cota, Gon X alves, and Laender (2007, 2010) propose a heuristic-based hierarchical clustering method for name disambig-process is successively repeated until no more fusions are possible.

On and Lee (2007) have studied the scalability issue of the disambiguation problem. They examine two state-of-the-art may be successfully applied to name disambiguation in large collections.
 ability distribution of topics with respect to person names as new evidence for name disambiguation.
Kang et al. (2009) explore the use of coauthorship using a Web-based technique that obtains implicit coauthors of the of the pair.
 posed method attempts to find Web documents corresponding to curricula vitae or Web pages containing publications of additional cost of extracting all the needed information from Web documents.
 good effectiveness.

Since name disambiguation is not restricted to a single context, it is worth noting that several other disambiguation on a hierarchical clustering strategy and the second one makes use of social networks. Vu, Masada, Takasu, and Adachi (2007) propose the use of Web directories as a knowledge base to disambiguate personal names in Web search results, whereas Bekkerman and McCallum (2005) present two methods for addressing this same problem, one based on the link clustering. A deeper discussion of these methods, however, are out of the scope of this paper. problems is an opportunity for improvement, and is the target of our study. 3. Associative disambiguation strong associations between bibliographic features ( f 1 , f disambiguators is based on uncovering such associations from the training data, and then building a function { f
X! a 1 ; X! a 2 ; ... ; X! a n , where X # f f 1 ; f 2 ; ... ; f while { coauthor = W . Lin , title = Optimal , title = Sparse } ? a the author a 2 (Chuen-Liang Chen).

In the following discussion we will denote as R an arbitrary rule set. Similarly, we will denote as R is composed of rules of the form X! a i (i.e., rules predicting author a contains all features in X ), and these rules form the rule set R x matching citation x . Obviously, R x a widely used statistic, called confidence ( Agrawal, Imielinski, &amp; Swami, 1993 ) (denoted as h  X X! a of the association between X and a i . The confidence of the rule X! a being the author of citation x , given that X # x .
 an author of citation x is estimated by combining rules in R
X! a i 2R x a ciation between X and a i , which is h  X X! a i  X  . The process of estimating the probability of a starts by summing weighted votes for a i and then averaging the obtained value by the total number of votes for a pressed by the score function s ( a i , x ) shown in Eq. (1) (where r the average confidence of the rules in R x a
The estimated probability of a i being an author of citation x , denoted as ^ p  X  a as shown in Eq. (2) . A higher value of ^ p  X  a i j x  X  indicates a higher likelihood of a with the highest likelihood is finally predicted as the correct author of citation x . Next, we will introduce novel associative name disambiguators: EAND, LAND, and SLAND. We will start by discussing authors. 3.1. Eager Associative Name Disambiguation adopted by EAND, the Eager Associative Name Disambiguator that will be presented in this section. er than or equal to z ).
The number of citations in the training data in which rule X! a frequent if it is supported by at least p min citations in the training data (i.e., p  X X! a may be important for the sake of disambiguation and, therefore, disambiguation effectiveness is seriously harmed when such rules are pruned.
 Algorithm 1. Eager Associative Name Disambiguation.
 Require : Examples in D ; r min , and citation x 2T
Ensure : The predicted author of citation x known as rule explosion). Even worse, most of these rules are useless for the sake of disambiguation. that any of these algorithms can be used (or modified) to enumerate the rules from the training data.
Example. Consider the citations shown in Table 1 . These citations were collected from DBLP and are used as a running are four different authors with the same name  X  X  X . Gupta X  X  (i.e., a training data). There are six citations in the test set (i.e., the last six citations).
Suppose we set r min = 0.20. In this case, according to Eq. (3) , p rules are included in R . One of these rules is:
Suppose we want to predict the correct author of citation c bility of a 1 being the author of citation c 11 is ^ p  X  a thus, a 1 is the predicted author. In fact, a 1 is the correct author of citation c author would predict again author a 1 . However, a 4 turns to be the correct author of citation c occurred because rules predicting author a 4 are not frequent enough for r propose a strategy that addresses this problem. 3.2. Lazy Associative Name Disambiguation
LAND, the Lazy Associative Name Disambiguator to be presented in this section, exploits such information. 3.2.1. On-demand rule generation examples that are most suitable to disambiguate a specific citation.
 Algorithm 2. Lazy Associative Name Disambiguation.
 Require : Examples in D ; r min , and citation x 2T
Ensure : The predicted author of citation x 1: Let L X  f i  X  be the set of examples in D in which feature f 2: D x (; 3: for each feature f i 2 x do 4: D x (D x [L X  f i  X  5: end for 7: for each author a i do 8: R x a 9: Estimate ^ p  X  a i j x  X  , according to Eq. (2) 10: end for 11: Predict author a i such that ^ p  X  a i j c  X  &gt; ^ p  X  a 3.2.2. Pruning with multiple cut-off values the size of the projected training data will be small. For a fixed value of r as p x min , is calculated based on the size of the corresponding projected training data, as shown in Eq. (4) .
The cut-off value applied while considering citation x varies from 1
The main steps of LAND are shown in Algorithm 2 . 3.2.3. Computation complexity LAND efficiently extracts rules from the training data. It is demonstrated in the Theorem 1 : Theorem 1. The complexity of LAND increases polynomially with the number of features in the collection. sible rules that are useful for predicting the author of the citation x is  X  n k  X  X  k  X  and thus, the number of useful rules increases polynomially in n . h
Example. Suppose again that we want to predict the author of citation c jected training data for c 12 ; D c 12 , as shown in Table 2 , contains only two citations, c
L X  venue  X  ICDE  X  X f c 7 ; c 10 g and L X  co author  X  V : Harinarayan  X  X f c
According to Eq. (1) , s ( a 2 , c 12 ) = 0.50 and s ( a 4 only few citations.

An interesting problem occurs when we consider citation c applying Eqs. (1) and (2) , we finally obtain ^ p  X  a 2 j c to be correct, and more training examples are needed in order to perform a more reliable prediction.
Another interesting problem occurs when we consider citation c training data according to c 15 , there is no remaining example (i.e., D address these two problems. 3.3. Self-Training Lazy Associative Name Disambiguation
In this section we propose SLAND, a Self-training Lazy Associative Name Disambiguator that is able to incorporate new of training data and the appearance of unseen ambiguous authors. 3.3.1. Inclusion of additional examples prediction.

Given an arbitrary citation c in the test set, and the most likely authors for c , a dicting a i , as shown in Eq. (5) .

The idea is to only predict a i if D ( c ) P D min , where D 3.3.2. Temporary abstention
Naturally, some predictions are not enough reliable for certain values of D performed, the citation is removed from the queue and included in the training data as a new example. Otherwise, if citations are processed. 3.3.3. Detection of unseen authors an already seen one is controlled by another user-specified parameter, c extracted from D c (which is denoted as c ( c )), is smaller than c example and included in the training data. The main steps of SLAND are shown in Algorithm 3 .
Example. Suppose again that we want to predict the author of citation c of r min is, again, set to 0.20. As discussed in the previous section, ^ p  X  a the end of the queue. For the next citation in the queue, c training data as a new example.

Now, consider the next citation in the queue, c 15 . Also, suppose we set c (i.e., 0 &lt; c min ) and, thus, the appearance of an unseen author is detected. A new label, a and c 15 is included in the training data. The next citation to be processed is c example, a new rule matching citation c 16 is extracted from D ^ p  X  a which was previously abstained. After the inclusion of citation c ^ p  X  a 2 j c 13  X  X  ^ p  X  a 3 j c 13  X  X  0 : 33. Consequently, D ( c disambiguators.
 Algorithm 3. Self-Training LAND.
 Require : Examples in D ; r min ; D min ; c min , and citation x 2T
Ensure : The predicted author of citation x (if the prediction is not abstained) 1: [11:] if c ( x ) P c min then 2: [12:] Create a new label, a k 3: [13:] Predict author a k 4: [14:] Include { x [ a k }in D 5: [15:] else if D ( x ) P D min then 6: [16:] Predict author a i such that ^ p  X  a i j c  X  &gt; ^ p  X  a 7: [17:] Include { x [ a i }in D 8: [18:] else 9: [19:] Place x in the end of the queue 10: [20:] end if 4. Evaluation ambiguators in these collections. 4.1. Collections ambiguous groups).

Table 3 shows more detailed information about the collections and their ambiguous groups. Disambiguation is particu-publications, as pointed out in ( Liming &amp; Lihua, 2005 ). 4.2. Evaluation Metrics ambiguated citations out of all the citations having the target author. F (i.e., 2 pr p  X  r ). Macro-and micro-averaging were applied to F scores were first computed for individual authors and then averaged over all authors. For F decisions for all authors were counted in a joint pool. MacroF 4.3. Baselines
We used the two supervised name disambiguators proposed in ( Han et al., 2004 ) as baselines. The first disambiguator baseline (in order to evaluate scenarios where no training example is available). 4.4. Results
All experiments were performed on a Linux-based PC with an Intel Core 2 Duo 1.83 GHz processor and 2GBytes RAM. All optimum parameters for each ambiguous group. We used a non-parametric implementation for Naive Bayes ( Domingos &amp; Pazzani, 1997 ).
 How effective are associative disambiguators compared with the baselines?
We evaluate the disambiguation effectiveness obtained by different disambiguators using DBLP and BDBComp collec-each group represents the average of the ten runs. Table 4 shows microF on average (with gains of more than 6.3%, compared to Naive Bayes). Disambiguation effectiveness in terms of macroF
The main reason for this impressive disambiguation effectiveness is depicted in Fig. 2 . We selected some ambiguous prolific authors (i.e., authors appearing in more citations) appear first. The y -axis shows microF to disambiguate specific citations. This is because LAND builds the disambiguation function on a demand-driven basis, citation incurs in impressive gains in effectiveness. How the different disambiguators perform with limited labeling efforts? the last line of Table 4 ).
 the DBLP collection, LAND showed a significant improvement (both in terms of microF served in the DBLP collection, a very low effectiveness (specially in terms of macroF porating additional examples.
 How does c min impact the effectiveness of SLAND? We evaluate the effectiveness of SLAND in detecting unseen authors using the BDBComp collection. Differently from the experiment. However, for each fraction of training examples, we varied c ognize an author as already seen, increases for higher values of c are more examples), and (2) there is an increase in the amount of available evidence supporting already seen authors. How does D min impact the effectiveness of SLAND? used in the previous experiment. However, for each fraction of training examples, we varied D are shown in Fig. 5 . As it can be seen, the effectiveness of SLAND decreases when D to consider a prediction as reliable) is set too high (i.e., D too low (i.e., D min &lt; 0.65). On one hand, when lower values of D
D min ), hurting effectiveness. On the other hand, when higher values of D included in the training data. For the DBLP collection, SLAND achieves the best effectiveness when D 0.75 (specially when few training examples are available).
 How effective is SLAND compared with LAND?
We now evaluate how the abilities of SLAND improve its effectiveness when compared to LAND. We, again, perform 5-value associated with each point in each graph is obtained by applying a different combination of c These gains highlight the advantages of self-training.

Improvements obtained using the BDBComp collection are more impressive. As discussed before, this collection contains with additional examples. As a result, improvements provided by SLAND range from 241.6% to 407.1%. Thus, SLAND is not and important information (i.e., unseen authors), being highly practical and effective in a variety of scenarios. How effective is SLAND compared to an unsupervised disambiguator?
We used the DBLP collection to perform a comparison between SLAND ( c of both disambiguators. In this case, a confusion matrix is used to assess the microF disambiguator obtained superior effectiveness on three ambiguous groups, while SLAND was superior in one ambiguous works by detecting unseen authors, and incrementally adding new examples to the training data. Other point worth men-perfoming the unsupervised disambiguator), demonstrating that SLAND is very cost-effective. 5. Conclusions and future work Citeseer, Google Scholar and DBLP.
 uncovers associations between bibliographic features and authors. The proposed disambiguators based on this approach effectiveness of LAND is mainly because it builds disambiguation functions on a demand-driven basis, so that authors Gon X alves, &amp; Laender, 2010 ).
 As future work, we intend to perform experiments with other collections, particularly from fields other than Computer e-mail), obtained from collaborative social networks, or from the topics or categories of the citations. Acknowledgments This research is partially funded by the National Institute of Science and Technology for the Web (InWeb) (MCT/CNPq/ FAPEMIG Grant No. 573871/2008-6), and by the authors X  X  individual research Grants from CAPES, CNPq, and FAPEMIG. References
