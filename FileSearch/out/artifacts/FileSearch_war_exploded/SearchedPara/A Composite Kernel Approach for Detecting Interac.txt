 The web has become a powerful medium for disseminating information about diverse topics, such as political issues and sports tournaments. While people can easily find documents that cover various perspectives of a topic, they often have difficulty assimilating the information in large documents. The problem has motivated the development of several topic mining methods to help readers digest enormous amounts of topic information. For instance, Nallapati et al. [13] and Feng and Allan [5] grouped topic documents into clusters, each of which represents a theme in a topic. The clusters are then connected chrono logically to form a timeline of the topic. Chen and Chen [1] developed a method that summarizes the incidents of a topic X  X  timeline to help readers quickly understand the whole topic. The extracted themes and summaries distill the topic contents clearly; however, readers still need to expend a great deal of time to comprehend the extracted information about unfamiliar topics. 
Basically, a topic is associated with specific times, places, and persons [13]. Thus, discovering the interactions between persons mentioned in topic document can help readers construct the background of the topic and facilitate comprehension. For instance, if readers know the interactions of the key persons in a presidential campaign, they can understand documents about the campaign more easily. Interaction discovery is an active research area in the bioinformatics field. A number of studies [e.g., 15, 18] have investigated the problem of protein-protein interaction (PPI) which focuses on discovering extraction [10]. The first task decomposes medical documents into text segments and identifies the segments that convey interactions between proteins. Then, the second task applies an information extraction algorithm to extract interaction tuples from the identified segments. In this paper, we focus on interaction detection in Chinese topic documents and identify text segments (called interactive segments hereafter) that convey interactions between persons. According to [17], such interactions exemplify types of human behavior that make people consider each other or influence each other. Examples of person interactions include compliments, criticism, collaboration, and competition. The detection latter tries to discover permanent interactions between proteins, such as binding. By contrast, the interactions between persons are dynamic and topic-dependent. For instance, during the 2012 U.S. presidential election, the Democratic candidate, incumbent President Barack Obama often criticized Mitt Romney (the Republican candidate) for his political views. However, in the topic about Obama forming a new cabinet, President Obama broke bread with Mitt Romney at the White House, and even considered offering him a position in the new cabinet. 
To detect interactive segments from topic documents effectively, we model interaction detection as a classification problem. We develop a rich interactive tree structure to represent syntactic, content, an d semantic information in text segments. Furthermore, to identify interactive segments in topic documents, we develop a composite kernel classification method that integrates the tree structure with a bigram kernel to support vector machines (SVM) [7]. The results of experiments demonstrate that the composite kernel classification method is effective in detecting interactive segments. In addition, the proposed rich interactive tree structure and bigram kernel successfully exploits the syntactic structur es, interaction semantics, and content of text segments. Consequently, the method outperforms the tree kernel-based PPI method [15]; the feature-based interaction detection method [2]; and the shortest path-enclosed tree (SPT) detection method [21], which is widely used to identify relations between named entities. Our research is closely related to relation extraction (RE), which was introduced as a part of the template element task in the sixth Message Understanding Conference (MUC-6). The goal of RE is to discover the semantic relations between the following five types of entities in text: persons, organizations, locations, facilities, and geo-supervised classification problem. Given a training corpus containing a set of manually-tagged examples of predefined relations, a supervised classification algorithm is employed to train an RE classifi er to assign (i.e., classify) a relation type to a new text segment (e.g., a sentence). Feature-based approaches [6, 8] and kernel-based approaches [4, 19] are frequently used for RE. Feature-based methods exploit instances of positive and negative relations in a training corpus to identify effective that included lexical tokens, syntactic structures, and semantic entity types, to SVM for relation extraction. In addition, Kambhatla [8] integrated lexical, syntactic, and semantic features of text into a maximum entropy model to extract relations between entities in the Automatic Context Extraction (ACE) datasets 1 . Feature-based methods often have difficulty finding effective features to extract entity relations. To resolve the problem, Collins and Duffy [3] developed a convolution tree kernel (CTK) that computes the similarity between two text segments in terms of the degree of overlap between their constituent parsing trees. A relation type is assigned to a text segment if the segment is similar to instances of the relation type in the training corpus. Moschitti [12] also utilized a CTK in the predicate argument classification task, which convolution tree kernel by using the shortest path-enclosed tree (SPT) structure, which is the sub-tree enclosed by the shortest path linking two entities in a parsing tree. Their experiment results showed that the SPT successfully represents syntactic information in text and therefore achieves a superior relation extraction performance on the ACE dataset. In recent years, a technique that combines CTK with SPT has been applied by many RE methods [20]. 
Our research is also related to the protei n-protein interaction (PPI) detection [14], which focuses on discovering protein interactions mentioned in biomedical literature. In medical research, determining protein interaction pairs is crucial to understanding both the functional role of individual proteins and the organization of the entire biological process. Originally, methods on PPI are feature-based. The methods extract text features from sentences to construct learning models, which are then used to detect sentences that mention protein interactions. For instance, Ono et al. [14] manually defined a set of syntactic rule-based features covering word and part-of-speech patterns to represent complex sentences. Xiao et al. [18] exploited maximum entropy models to combine diverse lexical, syntactic, and semantic features for PPI extraction. However, the above features hardly represent structured and dependency-based syntactic information in a constituent, which is essential for detecting interactions between proteins. To address the issue, several tree-based kernel approaches have been developed. For example, Qian et al. [16] defined a set of hand-crafted heuristics to identify the informative parts of a constituent parsing tree. The identified sub-trees are then examined by a classification model, which assigns a relation type to the proteins mentioned in a text segment. Miyao et al. [11] combined constituent parsing trees with a bag-of-words kernel to improve PPI performance. Recently, Qian and Zhou [15] developed a novel tree-based kernel. In their approach, shortest dependency path between two proteins derived from a dependency parser. Their experiment results show that the tree-based kernel is efficient in PPI detection. Our research differs from RE and PPI, which detect static and permanent relations. In contrast, our research detects interactions between persons, which are dynamic and topic-dependent. Figure 1 shows the proposed interaction detection method, which is comprised of three key components: candidate segment generation , rich interactive tree construction , and composite kernel classification . We regard interaction detection as a classification problem. The candidate segment generation component processes a set of Chinese topic documents to extract text segments (called candidate segments hereafter) that may mention interactions between topic persons. Then, each candidate segment is represented by a rich interactive tree that integrates the syntactic, content, and semantic information extracted from the segment. Finally, the composite kernel classification component combines the rich interactive tree with a bigram kernel for SVM to classify interactive segments. We discuss each component in detail in the following sub-sections. 3.1 Candidate Segment Generation Component For a Chinese topic document d , we first apply the Chinese word segmentation system CKIP AutoTag 2 to decompose the document into a sequence of sentences S = { s 1 ,..., s k }. CKIP also labels the tokens in the sentences that represent a person X  X  name. We observed that the rank-frequency distribution of the labeled person names followed Zipf X  X  law [9], which means that many of them rarely occurred in the topic documents. Low frequency names usually refer to persons that are irrelevant to the topic (e.g., journalists), so they are segment generation component extracts text segments that are likely to mention the pair X  X  interactions from the document. The component processes a set of document sentences S a sequence of sentences, we consider two types of candidate segments, namely, intra-candidate segments and inter-candidate segments . The component then examines the initial sentence and subsequent sentences until it reaches an end sentence that contains the generates an intra-candidate segment; otherwise, it generates an inter-candidate segment. However, if there is a period in the inter-candidate segment, we drop the segment because, than once in an inter-candidate segment, we truncate all the sentences before the last p i ( p j ) topic documents, we obtain a candidate segment set CS = { cs 1 ,..., cs m }. 3.2 Rich Interactive Tree Construction Component the shortest path-enclosed tree (SPT) of the segment enhanced by three operators: branching , pruning , and ornamenting . To facilitate comprehension of the operators, the inter-candidate segment shown in Fig. 2(a), which mentions the interaction between  X   X  X  X  X  (Barack Obama) X  and  X   X  X  X  X  (Mitt Romney) X , serves as an example. (1) RIT branching In [21], the authors show that the SPT is effective in identifying the relation between two entities mentioned in a segment of text. Given a candidate segment, the SPT is the smallest sub-tree of the segment X  X  syntactic parsing tree that links person names p i For instance, in Fig. 2(a),  X   X  X  X  (recruit) X  and the corresponding syntactic constituent are critical for recognizing the interaction between Obama and Romney. However, they are excluded from the SPT, as shown in Fig. 2(b). To include useful segment context information, the branching operator extends the SPT by examining the syntactic structure of the candidate segments. By default, we utilize the SPT as our RIT sapling. However, if the last person name and the verb following it form a verb phrase in the syntactic parsing tree, we treat the verb as a modifier of the last person name and extend the RIT to the end of the verb phrase. As shown in Fig. 2(c), the extended RIT includes richer context information than the SPT. (2) RIT pruning To make the RIT concise and clear, we prune redundant elements via the following procedures. (3) RIT ornamenting Verbs are often good indicators of interactive segments, but not all verbs express person interactions. Highlighting verbs (called interactive verbs hereafter) closely associated with person interactions in an RIT would improve the interaction detection performance. We used the log likelihood ratio (LLR) [9], which is an effective feature selection method, to compile a list of interactive verbs. Given a training dataset comprised of interactive and non-interactive segments, the LLR calculates the likelihood that the occurrence of a verb in the interactive segments is not random. A verb with a large LLR value is closely associated with the interactive segments. We rank the verbs in the training dataset based on their LLR values and select the top 150 to compile the interactive verb list. For each RIT that contains an interactive verb, we the RIT structure (as shown in Fig. 2(e)). 3.3 Composite Kernel Kernel approaches are frequently used in SVM to compute a dot product (i.e., similarity) between instances modeled in a complex feature space. In this study, we employ a composite kernel approach that integrates the convolution tree kernel (CTK) [12] with a bigram kernel to determine the similarity between segments. (1) Convolution Tree Kernel We leverage the convolution tree kernel to capture the syntactic similarity between rich interactive trees. Specifica lly, the convolution tree kernel K CTK counts the number of common sub-trees as the syntactic similarity between two rich interactive trees RIT 1 and RIT 2 as follows:  X  ( n 1 , n 2 ) evaluates the common sub-trees rooted at n 1 and n 2 and is computed recursively as follows: (2) else if both n1 and n2 are pre-terminals (POS tags),  X  ( n 1 , n 2 ) = 1  X   X  ; (3) else calculate  X  (n 1 , n 2 ) recursively as: respect to different sized sub-trees. (2) Bigram Kernel In addition to the syntactic similarity, we consider the content similarity. Since most Chinese keywords are comprised of two characters, we design the following bigram kernel K BK (.), which examines the bigrams in a candidate segment cs and a training segment ts to measure their content similarity as follows: returns 0. As the LLR value of an interactive verb, a bigram X  X  LLR value indicates the weight of bigram associated with interactive or non-interactive segments. Consequently, the value of K BK will be high if the bigram overlap between cs and ts is large, and the overlapping bigrams are discriminative. 
Finally, a composite kernel approach is used to interpolate the convolution tree kernel and the bigram kernel. We exploit polynomial interpolation [21], which integrates the two kernels as follows: where cs denotes a candidate segment, ts is a training segment in the training corpus, and it is the polynomial expansion of kernel ) , (  X   X  K . The parameters d and  X  are the polynomial degree and weight coefficient respectively. 4.1 Experimental Setting To the best of our knowledge, there is no official corpus for person interaction detection. The relations defined in the Automatic Context Extraction (ACE) datasets, such as capital of, are static and irrelevant to person interactions. Therefore, we compiled a data corpus for the performance evaluations, as shown in Table 1. It contains 10 topics related to political events from 2004 to 2012; and each topic consists of 50 Chinese news documents (all longer than 250 words) collected from Yahoo News. As mentioned in Section 3, many of the person names labeled by CKIP rarely occur in topic documents, and low frequency names usually refer to persons that are irrelevant to the evaluated topics. Hence, for each topic, we evaluated the person names whose frequency reached 70% of the total person name frequency in the topic documents. All the evaluated names represent important topic persons. We used the candidate segment generation algo rithm to extract 1754 candidate segments from the topic documents, and two experts labeled 651 of the segments as interactive. The Kappa statistic of the labeling process is 0.834, which means that our data corpus is reliable. 
We use the SVMLight package [7] to implement our composite kernel 0.23 respectively, as suggested in [20, 21]. In addition, we use Moschitti X  X  tree kernel evaluation results, we utilize the leave-one-out cross validation method [9]. The evaluation metrics are the precision rate, reca ll rate, and F1-score [9]. The F1 value is used to determine relative effectiveness of the compared methods. 4.2 Results and Discussion The proposed RIT structure uses three operators, branching , pruning , and ornamenting , to enhance the SPT. In the following, we evaluate the performance of the operators to demonstrate the effectiveness of RIT. Table 2 shows the marginal performances of applying RIT branching, pruning, and ornamenting, denoted as the efficacy of the proposed method, we detail the results of applying our composite kernel classification component (denoted as RIT+BK), which integrates the RIT with the bigram kernel. As shown in the table, only RIT branching (i.e., +RIT branching ) outperforms the SPT. This is because the br anching operator correctly extends useful context information to remedy the context-limited problem of the SPT (see Sec. 3.2). The pruning operator further improves the system performance because it successfully eliminates indiscriminative and redundant RIT elements and thereby helps SVM learn representative syntactic structures of person interactions. The RIT ornamenting operator improves the F1 performance significantly. Moreover, the compiled interactive verbs are highly correlated with person interactions, so tagging them in the RIT structure helps our method discriminate interactive segments. Notably, our composite kernel classification component achieves the best performance. As the bigram kernel examines the content of segments to identify interactive segments, it does not conflict with the RIT, which analyzes syntactic and semantic information in the segments. Consequently, applying them together improves the system performance. In addition to the SPT and the proposed method, we evaluate FISER [2] and SDP-CPT [15]. To ensure the fairness of our evaluation, systems used for comparison are also developed using the SVMLight package [7] and Moschitti X  X  tree kernel toolkit [12]. It has been shown that SPT is an effective relation extraction method [21]. FISER exploits nineteen features that cover parts-of-speech, context and semantic information in text to detect interactive segments in topic documents. SDP-CPT is an effective tree kernel-based PPI method that analyzes the syntactic dependency tree of person interactions. As shown in Table 3, the proposed method significantly outperforms SPT and SDP-CPT. This is because SPT and SDP-CPT only examine the syntactic structures of candidate segments and cannot sense the semantics of person interactions in those segments. By contrast, our method analyzes the semantics (i.e., interactive verbs) and content (i.e., bigrams) of segments to identify person interactions. Hence, its performance is superior to that of SPT and SDP-CPT. It is noteworthy that SPT and SDP-CPT cannot deal with inter-candidate segments effectively. The reason is that the syntactic structure of inter-candidate segments is usually long and complex, and that affects the methods X  detection performance. The proposed method prunes indiscriminative and redundant syntactic constructs in text, so it is effective in detecting inter-candidate segments. SDP-CPT is superior to SPT in terms of intra-candidate segments because the segments are usually short. The corresponding dependency structure is clear that the shortest dependency path of SDP-CPT represents person interactions well. Consequently, it performs better than SPT. FISER also outperforms SPT and SDP-CP T as it incorporates semantic features to distinguish interactive segments. However, FISER ignores the syntactic structures of text, which are effective in extracting the relations between named entities from text as demonstrated in [21]. It is therefore inferior to our method. 
To summarize, the proposed rich interactive tree and bigram kernel approach successfully integrates the syntactic, semantic, and content information in text to identify interactive segments. Hence, it achieves the best precision, recall, and F1 scores among the compared methods, as shown in Table 3. A topic is associated with specific times, places, and persons. Thus, discovering the interactions between the persons would help readers construct the background of the topic and facilitate document comprehension. To this end, we developed a method that combines the rich interactive tree structure and bigram kernel to analyze the syntactic, semantic, and content information in text. It then exploits the derived information to identify interactive segments in topic documents. Our experiment results demonstrate that the proposed method is effective and also outperforms well-known relation extraction and PPI methods. 
In the future, we will investigate the syntactic dependency tree and sentimental information in candidate segments to incorporate further syntactic and semantic information into the rich interactive tree structure. We will also utilize information extraction algorithms to extract interaction tuples from interactive segments and construct an interaction network of topic persons. Acknowledgements. This research was supported by the National Science Council of Taiwan under grant NSC 100-2628-E-002-037-MY3, NSC101-3113-P-001-004, and NSC102-3111-Y-001-012. 
