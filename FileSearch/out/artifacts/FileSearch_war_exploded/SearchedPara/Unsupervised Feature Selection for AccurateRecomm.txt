 Products in today X  X  e-market are described using both visual and textual information. From con-sumer psychology, the visual information has been recognized as an important factor that influences the consumer X  X  decision making and has an important power of persuasion [4]. Furthermore, it is well recognized that the consumer choice is also influenced by the external environment or context such as the time and location [4]. For example, a consumer could express an information need  X  X ontent-Based Image Suggestion X  (CBIS) [4] motivates the modeling of user preferences with respect to visual information under the influence of the context. Therefore, CBIS aims at the sug-gestion of products whose relevance is inferred from the history of users in different contexts on images of the previously consumed products. The domains considered by CBIS are a set of users U = { 1 , 2 ,...,N u } , a set of visual documents V = { v 1 , v 2 ,..., v N v } , and a set of possible con-texts E = { 1 , 2 ,...,N e } . Each v k is an arbitrary descriptor (visual, textual, or categorical) used to represent images or products. In this work, we consider an image as a D -dimensional vector v =( v 1 ,v 2 ,...,v D ) . The visual features may be local such as interest points or global such as color, texture, or shape. The relevance is expressed explicitly on an ordered voting (or rating) scale defined as R = { r 1 ,r 2 ,...,r N r } . For example, the five star scale (i.e. N r = 5) used by Amazon al-lows consumers to give different degrees of appreciation. The history of each user u  X  X  , is defined as Figure 1: The VCC-FMM identifies like-mindedness from similar appreciations on similar images represented in 3-dimensional space. Notice the inter-relation between the number of image clusters and the considered feature subset.
 In literature, the modeling of user preferences has been addressed mainly within collaborative fil-tering (CF) and content-based filtering (CBF) communities. On the one hand, CBF approaches [12] build a separate model of  X  X iked X  and  X  X isliked X  discrete data (word features) from each D u taken individually. On the other hand, CF approaches predict the relevance of a given product for a given user based on the preferences provided by a set of  X  X ike-minded X  (similar tastes) users. The data set by a categorical index. The Aspect model [7] and the flexible mixture model (FMM) [15] are exam-ples of some model-based CF approaches. Recently, the authors in [4] have proposed a statistical model for CBIS which uses both visual and contextual information in modeling user preferences with respect to multidimensional non Gaussian and continuous data. Users with similar preferences are considered in [4] as those who appreciated with similar degrees similar images. Therefore, in-stead of considering products as categorical variables (CF), visual documents are represented by a richer visual information in the form of a vector of visual features (texture, shape, and interest points). The similarity between images and between user preferences is modeled in [4] through a single graphical model which clusters users and images separately into homogeneous groups in a similar way to the flexible mixture model (FMM) [15]. In addition, since image data are generally non-Gaussian [1], class-conditional distributions of visual features are assumed Dirichlet densities. By this way, the like-mindedness in user preferences is captured at the level of visual features. Statistical models for CBIS are useful tools in modeling for many reasons. First, once the model is learned from training data (union of user histories), it can be used to  X  X uggest X  unknown (possibly unrated) images efficiently i.e. few effort is required at the prediction phase. Second, the model can be updated from new data (images or ratings) in an online fashion in order to handle the changes in either image clusters and/or user preferences. Third, model selection approaches can be employed to identify  X  X ithout supervision X  both numbers of user preferences and image clusters (i.e. model order) from the statistical properties of the data. It should be stressed that the unsupervised selection of the model order was not addressed in CF/CBF literature. Indeed, the model order in many well-founded statistical models such as the Aspect model [7] or FMM [15] was set  X  X mpirically X  as a compromise between the model X  X  complexity and the accuracy of prediction, but not from the data. From an  X  X mage collection modeling X  point of view, the work in [4] has focused on modeling user preferences with respect to non-Gaussian image data. However, since CBIS employs generally high-dimensional image descriptors, then the problem of modeling accurately image collections needs to be addressed in order to overcome the curse of dimensionality and provide accurate suggestions. Indeed, the presence of many irrelevant features degrades substantially the performance of the mod-eling and prediction [6] in addition to the increase of the computational complexity. To achieve a better modeling, we consider feature selection and extraction as another  X  X ey issue X  for CBIS. In literature [6], the process of feature selection in mixture models have not received as much attention as in supervised learning. The main reason is the absence of class labels that may guide the selection process [6]. In this paper, we address the issue of feature selection in CBIS through a new generative model which we call Visual Content Context-aware Flexible Mixture Model (VCC-FMM). Due to the problem of the inter-relation between feature subsets and the model order i.e. different feature subsets correspond to different natural groupings of images, we propose to learn the VCC-FMM from unlabeled data using the Minimum Message Length (MML) approach [16]. The next Section details the VCC-FMM model with an integrated feature selection. After that, we discuss the identifi-cation of the model order using the MML approach in Section 3. Experimental results are presented in Section 4. Finally, we conclude this paper by a summary of the work. The data set D used to learn a CBIS system is the union of all user histories i.e. D =  X  u  X  X  D u . From this data set we model both like-mindedness shared by user groups as well as the visual and semantic similarity between images [4]. For that end, we introduce two latent variables z and c to label each observation &lt;u,e, v, r &gt; with information about user classes and image classes, respectively. In order to make predictions on unseen images, we need to model the joint event p ( v, r, u, e )= leads to quantities with a huge number of parameters which are difficult to interpret in terms of the data [4]. To overcome this problem, we make use of some conditional independence assumptions that constitute our statistical approximation of the joint event p ( v, r, u, e ) . These assumptions are illustrated by the graphical representation of the model in figure 2. Let K and M be the number of user classes and images classes respectively, an initial model for CBIS can be derived as [4]: probability to sample a rating for a given user class and image class. All these quantities are modeled from discrete data. On the other hand, image descriptors are high-dimensional, continuous and generally non Gaussian data [1]. Thus, the distribution of class-conditional densities p ( v | c ) should be modeled carefully in order to capture efficiently the added-value of the visual information. In this work, we assume that p ( v | c ) is a Generalized Dirichlet distribution (GDD) which is more appropriate than other distributions such as the Gaussian or Dirichlet distributions in modeling image collections [1]. This distribution has a more general covariance structure and provides multiple shapes. The distribution of the c -th component  X   X  c is given by equation (2). The  X  superscript is used to denote the unknown true GDD distribution. ematical properties of the GDD, we can transform using a geometric transformation the data point v into another data point x =( x 1 ,...,x D ) with independent features without loss of information dence between x l makes the estimation of a GDD very efficient i.e. D estimations of univariate Beta distributions without loss of accuracy. However, even with independent features, the unsupervised identification of image clusters based on high-dimensional descriptors remains a hard problem due to the omnipresence of noisy, redundant and uninformative features [6] that degrade the accuracy of the modeling and prediction. We consider feature selection and extraction as a  X  X ey X  methodology in order to remove that kind of features in our modeling. Since x l are independent, then we can extract  X  X elevant X  features in the representation space X . However, we need some definition of feature X  X  relevance. From figure 1, four well-separated image clusters can be identified from only two relevant features 1 and 2 which are multimodal and influenced by class labels. On the other hand, feature 3 is unimodal (i.e. irrelevant) and can be approximated by a single Beta distribution p ( . |  X  l ) common to all components. This definition of feature X  X  relevance has been motivated in unsupervised learning [2][9]. Let  X  =(  X  1 ,..., X  D ) be a set of missing binary variables denoting the relevance of all features.  X  l is set to 1 when the l -th feature is relevant and 0 otherwise. The  X  X rue X  Beta distribution  X   X  cl can be approximated as [2][9]: By considering each  X  l as Bernoulli variable with parameters p (  X  l =1)= l 1 and p (  X  l =0)= l 2 ( 1 + l 2 =1 ) then, the distribution p ( x l that both models [3] [4] are special cases of VCC-FMM. We denote by  X  A  X  the parameter vector of the multinomial distribution of any discrete variable A conditioned on its parent  X  of VCC-FMM (see figure 2). We have A |  X =  X   X  Multi (1;  X  A  X  ) where  X   X a = p ( A = a |  X =  X  ) and a  X  parameters of the Beta distribution of relevant and irrelevant components, respectively i.e.  X  cl = (  X   X  ,  X  C and  X  cl , X  l . The log-likelihood of a data set of N independent and identically distributed is given by: The maximum likelihood (ML) approach which optimizes equation (5) w.r.t  X  is not appropriate for learning VCC-FMM since both K and M are unknown. In addition, the likelihood increases monotonically with the number of components and favors lower dimensions [5]. To overcome these problems, we define a message length objective [16] for both the estimation of  X  and identification of K and M using MML [9][2]. This objective incorporates in addition to the log-likelihood, a penalty term which encodes the data to penalize complex models as: In equation (6), | I ( X ) | , p ( X ) , and s denote the Fisher information, prior distribution and the to-tal number of parameters, respectively. The Fisher information of a parameter is the expectation mon sense to assume an independence among the different groups of parameters which factor-izes both | I ( X ) | and p ( X ) over the Fisher and prior distribution of different groups of parame-ters, respectively. We approximate the Fisher information of the VCC-FMM from the complete likelihood which assumes the knowledge about the values of hidden variables for each observation similar methodology of [1]. Also, we use the result found in [8] in computing the Fisher information given by | I (  X  A  X  ) | = Np ( X  =  X  ) ability of the parent  X  . The graphical representation of of VCC-FMM does not involve variable ancestors (parents of parents). Therefore, the marginal probabilities p ( X  =  X  ) are simply the pa-rameters of the multinomial distribution of the parent variable. For example, | I (  X  R zc ) | is computed employ the Jeffrey X  X  prior for different groups of parameters. Replacing p ( X ) and I ( X ) in (6), and after discarding the first order terms, the MML objective is given by: with N p =2 D ( M +1)+ K ( N u + N e  X  2) + MK ( N r  X  1) and N Z p = N r + N u + N e  X  3 .For fixed values of K , M and D , the minimization of MML objective with respect to  X  is equivalent to a maximum a posteriori (MAP) estimate with the following improper Dirichlet priors [9]: 3.1 Estimation of parameters We optimize the MML of the data set using the Expectation-Maximization (EM) algorithm in order to estimate the parameters. In the E-step, the joint posterior probabilities of the latent variables given the observations are computed as Q zci = p ( z, c | u ( i ) ,e ( i ) , x ( i ) ,r ( i ) ,  X   X ) : In the M-step, the parameters are updated using the following equations: The parameters of Beta distributions  X  cl and  X  l are updated using the Fisher scoring method based on the first and second order derivatives of the MML objective [1]. The benefits of using feature selection and the contextual information are evaluated by considering two variants: V-FMM and V-GD-FMM in addition the original VCC-FMM given by equation (4). V-FMM does not handle the contextual information and assumes  X  E ze constant for all e  X  X  . On the other hand, feature selection is not considered for V-GD-FMM by setting l 1 =1 and pruning the uninformative components  X  l for l =1 ,...,D . 4.1 Data Set We have collected ratings from 27 subjects who participated in the experiment (i.e. N u =27 ) dur-ing a period of three months. The participating subjects are graduate students in faculty of science. Subjects received periodically (twice a day) a list of three images on which they assign relevance degrees expressed on a five star rating scale (i.e. N r =5 ). We define the context as a combination of two attributes: location L = { in  X  campus, out  X  campus } inferred from the Internet Protocol (IP) address of the subject, and time as T =( weekday, weekend ) i.e N e =4 . A data set D of 13446 ratings is collected ( N = 13446 ). We have used a collection of 4775 (i.e. N v = 4775 ) images col-lected from Washington University [10] and collections of free photographs which we categorized manually into 41 categories. For visual content characterization, we have employed both local and global descriptors. For local descriptors, we use the 128 -dimensional Scale Invariant Feature Trans-form (SIFT) [11] to represent image patches. We employ vector quantization to SIFT descriptors and we build a histogram for each image ( X  X ag of visual words X ). The size of the visual vocabulary is 500 . For global descriptors, we used the color correlogram for image texture representation, and the edge histogram descriptor. Therefore, a visual feature vector is represented in a 540 -dimensional space ( D = 540 ). We measure the accuracy of the prediction by the Mean Absolute Error (MAE) which is the average of the absolute deviation between the actual and predicted ratings. 4.2 First Experiment: Evaluating the influence of model order on the prediction accuracy This experiment tries to investigate the relationship between the assumed model order defined by K and M on the prediction accuracy of VCC-FMM. It should be noticed that the ground truth number of user classes K  X  is not known for our data set D . We run this experiment on a ground truth (artificial) data with known K and M . D GT is sampled from the preferences P 1 and P 2 of two most dissimilar subjects according to Pearson correlation coefficients [14]. We sample ratings for 100 simulated users from the preferences P 1 and P 2 only on images of four image classes. For each user, we generate 80 ratings (  X  20 ratings per context). Therefore, the ground truth model order is K  X  =2 and M  X  =4 . The choice of M  X  is purely motivated by convenience of presentation since similar performance was reported for higher values of M  X  . We learn the VCC-FMM model using one half of D GT for different choices of training and validation data. The model order defined by M =15 and K =15 is used to initialize EM algorithm.
 Figure 3(a) shows that both K and M have been identified correctly on D GT since the lowest MML was reported for the model order defined by M =4 and K =2 . The selection of the best model order is important since it influences the accuracy of the prediction (MAE) as illustrated by Figure 3(b). It should be noticed that the over-estimation of M ( M&gt;M  X  ) leads to more errors than the over-estimation of K ( K&gt;K  X  ). 4.3 Second Experiment: Comparison with state-of-the-art The aim of this experiment is to measure the contribution of the visual information and the user X  X  context in making accurate predictions comparatively with some existing CF approaches. We make comparisons with the Aspect model [7], Pearson Correlation (PCC)[14], Flexible Mixture Model (FMM) [15], and User Rating Profile (URP) [13]. For accurate estimators, we learn the URP model using Gibs sampling. We retained for the previous algorithms, the model order that ensured the lowest MAE. The first five columns of table 1 show the added value provided by the visual information compara-tively with pure CF techniques. For example, the improvement in the rating X  X  prediction reported by V-FMM is 3 . 52% and 1 . 97% comparatively with FMM and URP, respectively. The algorithms (with context information) shown in the last two columns have also improved the accuracy of the predic-tion comparatively with the others (at least 15 . 28% ). This explains the importance of the contextual information on user preferences. Feature selection is also important since VCC-FMM has reported a better accuracy ( 14 . 45% ) than V-GD-FMM. Furthermore, it is reported in figure 4(a) that VCC-FMM is less sensitive to data sparsity (number of ratings per user) than pure CF techniques. Finally, the evolution of the average MAE provided VCC-FMM for different proportions of unrated images remains under &lt; 25% for up to 30% of unrated images as shown in Figure 4(b). We explain the stability of the accuracy of VCC-FMM for data sparsity and new images by the visual information since only cluster representatives need to be rated. This paper has motivated theoretically and empirically the importance of both feature selection and model order identification from unlabeled data as important issues in content-based image sugges-tion. Experiments on collected data showed also the importance of the visual information and the user X  X  context in making accurate suggestions.
 The completion of this research was made possible thanks to Natural Sciences and Engineering Re-search Council of Canada (NSERC), Bell Canada X  X  support through its Bell University Laboratories R&amp;D program and a start-up grant from Concordia University.

