 YOTARO WATANABE, JUNTA MIZUNO, ERIC NICHOLS, KATSUMA NARISAWA, KEITA NABESHIMA, NAOAKI OKAZAKI, and KENTARO INUI, Tohoku University Textual entailment recognition is the task of recognizing entailment relations between a given text pair, Text T and Hypothesis H . The task has attracted the attention of many researchers in recent decades, especially the community of Recognizing Tex-tual Entailment (RTE) [Dagan et al. 2005]. From the third PASCAL RTE challenge (RTE-3), the task has included recognizing not only entailment relations, but also con-tradiction relations [Giampiccolo et al. 2007].

Textual entailment recognition is useful for many information access tasks that depend on natural language processing technologies, and a breakthrough would lead to significant progress in information retrieval, document summarization, and question answering, among other tasks.

The majority of approaches proposed in previous works recognize entailment re-lations between a pair of texts by capturing lexical or structural correspondences. Methods include simple word overlap-based measures [Jijkoun and de Rijke 2005] as well as alignment of syntactic and semantic dependencies [MacCartney et al. 2008; Sammons et al. 2009]. Transformation-based approaches such as [Dagan et al. 2008; Stern et al. 2010, 2011] also capture correspondence between words or phrases. In these approaches, T is rewritten into H using entailment rules (e.g., XacquireY  X  XobtainY ). The application of these transformation rules can be seen as the equiva-lent of performing alignment [Mirkin et al. 2010].
 One of the current trends in the RTE community is logic-based approaches. Bos and Markert [2005, 2006] and Tatu et al. [2006; Tatu and Moldovan 2007] proposed various logic-based approaches where a pair of texts are converted to logical forms and entail-ment is recognized through theorem proving. Other logic-based approaches also have been explored including abductive inference [Ovchinnikova et al. 2011] and inference on Markov-Logic Networks [Garrette et al. 2011]. In order to capture correspondences between different but related expressions in logic-based approaches, a common ap-resources. The use of such axioms can be seen as performing alignment between two expressions. Therefore, in order to realize robust entailment relation recognition, we need to address the alignment problem, which can be seen as the core sub-problem of RTE.

In the alignment problem, since semantic relations must be captured between a diverse range of expressions, multiple high-coverage sources of linguistic and world knowledge are needed. With advances in knowledge acquisition methods, it has be-come easier to construct several types of large-scale knowledge databases such as paraphrases, entailment relations, and the number of available resources has been increasing. Such resources have been utilized in several applications such as infor-mation retrieval and information extraction. The RTE community has also recognized the importance of utilizing large-scale linguistic resources. Previous work on RTE has explored the application of both hand-crafted resources such as WordNet [Fellbaum 1998] and FrameNet [Ruppenhofer et al. 2006] and semi-automatically constructed resources such as VerbOcean [Pantel and Patrick 2004] and DIRT [Lin and Pantel 2001].

On the other hand, RTE research for Asian Languages is not as advanced as for En-glish. NTCIR-9 Recognizing Inference in TExt (RITE) [Shima et al. 2011a] is the first evaluation task of entailment relation recognition technologies in Asian Languages. RITE focuses on three languages: Japanese, Simplified Chinese and Traditional Chi-nese, and a common dataset has been developed for each language. It will form a basis for RTE research in these languages.

Development of linguistic resources in Japanese has also progressed, including the creation of the Japanese WordNet [Bond et al. 2009], knowledge databases which can be extracted from Wikipedia (e.g., hypernym-hyponym relations [Sumida et al. 2008]), allographic databases [Kojima et al. 2010], ALAGIN predicate entailment database [Hashimoto et al. 2009], predicate relation database for RTE [Matsuyoshi et al. 2008], etc. On the other hand, since textual entailment recognition in Japanese does not have a very long history, the performance of these resources in textual entailment recog-nition systems has not been explored sufficiently. Therefore we believe that now is a good time to identify important research issues by exploring the effectiveness of vari-ous resources in Japanese textual entailment recognition.

In this article, we explore what types of currently available linguistic and world knowledge are effective for Japanese textual entailment recognition through experi-ments and error analysis on the NTCIR-9 RITE dataset. To explore the effectiveness of a variety of resource, we developed a semantic relation recognizer which utilizes diverse linguistic and world knowledge to align linguistic units in pairs of texts, and detects entailment relations based on the discovered alignments. The system at first performs various linguistic preprocessing including morphological analysis, depen-dency parsing, predicate-argument structure analysis, sentiment polarity analysis and factuality analysis, and aligns parts in two sentences by utilizing various resources including lexical semantic knowledge such as synonym and antonym, hypernym-hyponym relations, and predicate entailment relations.

Our textual entailment recognition system identifies entailment relations by apply-ing simple rules to the alignments found between a pair of texts. While the trend in textual entailment recognition research has been toward machine learning-based ap-proaches, since the focus of this article is to explore how each resources contributes performance of semantic relation recognition, we feel that our rule-based alignment-driven system offers several advantages for evaluating the effectiveness of existing resources in textual entailment recognition: resources are only applied during the alignment process making the role in textual entailment recognition transparent ;and resources are applied in a modular fashion, meaning that resources can be evaluated and added or removed from the textual entailment recognition system independently of other resources.
 We conduct several experiments to evaluate the contribution of existing resources. First, to establish upper and lower bounds on performance, we compare a base-line system using no external resources in alignment to one using all available re-sources. Next, to evaluate the individual contribution of each resource, we perform ablation testing, quantify the amount of alignments produced, and evaluate the preci-sion and recall of each resource on a subset of data manually annotated with correct alignments.

Our evaluation shows that while many of the resources are useful, poor alignment coverage is a large remaining challenge for textual entailment recognition. In order to increase alignment coverage, we propose an additional method of alignment based on syntactic and semantic similarity that does not require external resources. Eval-uation shows that this method increases the number of correct alignments detected by our system, leading to an increase in precision and recall of entailment relation detection.

This article is organized as follows. We first survey the literature on textual entail-ment recognition, making note of the resources used and their reported effectiveness, and then we describe developments in the resources of linguistic and world knowl-edge that are available for textual entailment recognition in Section 2. Then, we de-scribe our resource-based entailment recognition system: the overview of the system (Section 3), the alignment module (Section 4), the linguistic resources used in our system (Section 5) and the rule-based entailment relation recognition approach (Section 6). In Section 7, we report the experiment results on the RITE development and formal run data, and then discuss the effectiveness of the resources evaluated and the implications for textual entailment recognition performance system in Section 8. Finally we offer conclusions in Section 9. In the English RTE community, use of several resources has been explored: hand-crafted resources such as WordNet [Fellbaum 1998] and FrameNet [Ruppenhofer et al. 2006], and semi-automatically constructed databases including VerbOcean [Pantel and Patrick 2004] and the DIRT database [Lin and Pantel 2001].

WordNet is the most widely used lexical semantic knowledge because the instances of synonym, hypernym-hyponym, antonym, and entailment relations are useful for textual entailment recognition. Many participants in RTE-5 reported that use of Word-Net was effective [Bentivogli et al. 2009]. In addition, some research reported that several similarity measures which can be calculated using WordNet are also effective for textual entailment recognition (e.g., Castillo [2010]). Wikipedia is also a well-used resource for textual entailment recognition. Seventy-five percent of the participants in RTE-5 reported positive effects from using Wikipedia. FrameNet [Ruppenhofer et al. 2006] is a lexical database which can be used to capture relations between events, and it is used for textual entailment recognition in for instance [Ofoghi and Year-wood 2010; Ovchinnikova et al. 2011; Shivhare et al. 2010]. VerbOcean [Pantel and Patrick 2004] is a database of lexical knowledge including synonyms, cause-effect re-lations, and entailment relations, and it was constructed (semi-)automatically from large-scale Web data by exploiting patterns. It is used for textual entailment recogni-tion by, for instance, [Kouylekov et al. 2010; Majumdar and Bhattacharyya 2010]. The DIRT database consists of 12 million entailment rules extracted from newspaper ar-ticles, and it is used in Clark and Harrison [2010] and Stern et al. [2011]. Blake et al. [2010] used YAGO [Suchanek et al. 2008] which is a high-coverage ontology con-structed from WordNet and Wikipedia. Some textual entailment recognition systems combine several resources, for example, Iftene and Moruz [2010], Stern et al. [2011], and Moruz [2011].

Since the coverage of the existing resources is limited, it is necessary to make clear what types of knowledge are still lacking. In the RTE community, some work discusses what types of knowledge are required for textual entailment recognition. Clark et al. [2007] discusses the roles of lexical and world knowledge in textual entailment recog-nition by investigating the RTE-3 dataset. LoBue and Yates [2011] also explored what types of knowledge are required in textual entailment recognition and described types of common sense knowledge which are needed for textual entailment recognition but have not been the focus of research in the field of knowledge acquisition. Sammons et al. [2010] categorized the underlying linguistic phenomena in textual entailment recognition problems, and attempted to annotate the resulting categories in the RTE dataset. Bentivogli et al. [2010] also categorized the type of linguistic phenomena in textual entailment recognition and constructed a corpus of their examples.
Since textual entailment recognition in Japanese does not have a long history, the effectiveness of existing resources has not yet been explored sufficiently. Shibata and Kurohashi [2011] exploits synonym, hyponym-hypernym, and antonym relations extracted from a Japanese dictionary. Shima et al. [2011b] and Akiba et al. [2011] exploited Japanese WordNet [Bond et al. 2009] and ALAGIN hypernym-hyponym re-lations [Sumida et al. 2008] for Japanese textual entailment recognition, and Akiba et al. [2011] also used the ALAGIN cross-script/orthographic variation pair database [Kuroda et al. 2002; Nakamura et al. 2010]. Tsuboi et al. [2011] used the Japanese thesaurus Bunrui-Goi-Hyo [NLRI 1996] and an ontology extracted from Wikipedia [Shibaki 2011]. However, none of these works reported the effectiveness of using each resource quantitatively. In this section, we describe our approach to recognizing textual entailments between texts. We developed a system that recognizes entailments by aligning linguistic units in the texts and using simple rules to analyze the local semantic relations identified by those alignments.

Our goal is to evaluate the effectiveness of existing resources of linguistic and world knowledge, so we designed our system with two desiderata in mind.

Our system satisfies these desiderata by limiting the application of external re-sources to detecting alignments and labeling local semantic relations. Because re-sources are only used to detect and label alignments and alignment detection is a deterministic process that does not mix resources, both desiderata of transparency and modularity are satisfied.
 Our entailment relation recognition approach is based on the following intuitions.
In order to check for relevance between H and T , we detect alignments between their linguistic units. While alignment in English is usually done at the word level, in Japanese, a popular unit of alignment is the phrase-like unit called the chunk . A chunk consists of one or more content words followed by zero or more functional words. Some of the functional words in chunk represent syntactic roles which is useful information for recognizing semantic relations between sentences. In this article, we use the chunk as the unit of alignment.

Figure 1 shows an overview of our entailment relation recognition system. Our sys-tem first conducts various forms of linguistic analysis: morphological analysis using MeCab [Kudo et al. 2004], syntactic parsing using the Japanese dependency parser, CaboCha [Kudo and Matsumoto 2002] and predicate-argument structure analysis [Watanabe et al. 2010] to provide a basis for alignment and semantic relation clas-sification. We also conduct factuality analysis and sentiment analysis. The factuality analyzer is trained using the linguistic resources provided by Matsuyoshi et al. [2008], which focuses on several information including event factuality. In sentiment analysis, we use the evaluative expression dictionary of Kobayashi et al. [2005] and the noun polarity knowledge of Higashiyama et al. [2008]. This information is exploited in the semantic relation recognition phase.

In the Alignment Phase, chunks in T and H are aligned and are labeled with lo-cal semantic relations. As discussed in Section 1, alignment is the most important sub-problem in textual entailment recognition, and a lot of alignment-based textual entailment recognition systems have been developed (see Section 2 for a full survey). Our system perform alignment by utilizing several external resources for linguistic and world knowledge to identify and label local semantic relations between chunks. To overcome the coverage limitations of existing resources, our system also applies align-ment inference , a method we developed to infer the presence of alignments between chunks in T and H without using external resources by analyzing the similarity of syntactic and semantic dependencies between chunks.

Finally, the system recognizes entailment relation between a pair of texts. Entail-ment relation recognition consists of two phases: relevance recognition and relation classification . In the Relevance Recognition Phase, a heuristic is used to identify and weed out pairs of irrelevant texts that are unsuitable as candidates for entailment. In the Relation Recognition Phase, the pairs of texts identified as relevant are classi-fied into entailment and non -entailment based on the semantic relations between chunks that are identified during alignment.

An example of entailment recognition is shown in Figure 2. The expressions  X   X  X  X  X  X  X  X  X   X  X ollagen X  and  X  X  X  X  X  X  X   X  X s effective X  in H and T are aligned based on surface-based similarity. On the other hand, since the expressions  X  X  X   X  X kin beautification X  in H and  X  X  X  X  X  X  X  X  X  X  X  X   X  X aking skin pretty X  in T differ in surface-level, our system utilized several resources to decide whether the two ex-pressions should be aligned or not. From matching entries in our resources,  X  X  X  X   X  X eautiful X  - X  X  X  X   X  X retty X  ,and  X  X  X   X  X eautiful skin X  - X  X  X  X  X  X  X  X  X  X   X  X o beau-tify skin X  , the alignment  X  X  X   X  X kin beautification X  - X  X  X  X  X  X  X  X  X  X  X  X   X  X aking skin pretty X  is supported. Then in the relevance recognition phase, the pair of texts is  X  X elevant X  because all of the chunks in H are aligned. Next, the relation classifier clas-sifies the entailment relation between the pair of texts H and T . The relation between  X  X  X   X  X eauty skin X  and  X  X  X  X  X  X  X  X  X  X  X  X   X  X aking skin pretty X  is decided as  X  X n-tailment X  by the relations of the entries  X  X  X  X   X  X eautiful X  - X  X  X  X   X  X retty X  ,  X  X  X   X  X eautiful skin X  - X  X  X  X  X  X  X  X  X  X   X  X o beautify skin X  . Since the two other alignments  X  X  X  X  X  X  X  X  X  X   X  X ollagen X  and  X  X  X  X  X  X  X   X  X s effective X  have the same expressions, based on compositionality, the system output  X  X ntailment X  for the case.
In the following, we describe the details of our alignment approach in Section 4, the external resources used for alignment in Section 5, and our rule-based entailment relation recognizer in Section 6. In order to recognize textual entailment between a pair of texts, T and H , it is neces-sary to identify which parts of T and H are semantically related. This is done through alignment .

First, we align chunks and label their local semantic relations. The decision to align a pair of chunks in T and H is made by analyzing the content words in the chunks.
We identify alignments based on lexical similarity of without using external re-sources in the surface-based alignment phase and based on semantic relatedness using external resources in the knowledge-based alignment phrase . In surface-based alignment, the head words in the pair of chunks , T x and H x , are converted into dictionary form, and the chunks are aligned if the head word of H x is found in T x .

As the following example shows that  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X o Disney Land X  in H and  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X o Tokyo Disney Land X  in T are aligned because their head words are both  X  X  X  X  X  X  X  X  X  X  X  X   X  X isney Land X  . In other words, the functional word  X   X  X o X  and the modifier word  X  X  X   X  X okyo X  are ignored. (1) H  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  x  X  X  X  X 
The reason of using only head words in the surface-based alignment is to put em-phasis on alignment recall. With this simple approach, we can flexibly align ortho-graphic variants such as named entities such as  X  X  X  X  X  X  X  X  X  X  X  X   X  X isney Land X  and  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X   X  X okyo Disney Land X  .
 Chunks aligned at this phase are labeled as surf ace .
 We use various resources for knowledge as described in Section 5 to determine seman-tic similarity. Each entry in the knowledge consists of two expressions and a semantic relation. The semantic relation is used to label the resulting alignment.
During this alignment phase, a pair of chunks, T x and H y , is aligned if a semantic relation between an expression including the headword of H y and the headword in T x is found in one of the knowledge sources. As with the surface-based alignment, we use only head words. The chunks are matched against the resources using a word-level bi-gram cosine-based similarity measure [Okazaki and Tsujii 2010]. If the cosine simi-larity of a pair of chunks is higher than a particular threshold, then the pair is aligned. In our implementation, the threshold of cosine value is set to 0.7. In the following example,  X  X  X  X  X  X   X  X he ecosystem X  and  X  X  X  X   X  X he environment X  are aligned be-cause the semantic relation,  X  X cosystem -(synonym) -environment X , was found and the cosine-based similarity of each pair of expressions is higher than the threshold. The resulting alignment is labeled synonym . (2) H  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  In spite of using massive amounts of linguistic knowledge, there are many uncov-ered words. In particular, the coverage of domain-specific expressions is poor. For instance, consider  X   X   X  X  X   X   X   X  X  X  X   X  X gricultural chemicals are used in the field. X  and  X  X  X   X  X  X  X  X  X  X  X  X  X   X  X gricultural chemicals are sprayed on the field. X  ,  X   X  X  X  X   X  X sed X  entails  X  X  X  X  X  X   X  X prayed X  but none of our existing knowledge bases contain this relation.

To infer alignments between infrequent expressions, we develop a heuristic that relies on syntactic and semantic dependency similarity measurements between T and H that can be obtained from dependency parsing and predicate argument structure analysis. Our intuition is that predicates which have similar argument structures are likely to be alignments, so we align two chunks T x and H y if they are both predicates and at least two arguments are lexically aligned.

Figure 3 shows an example of alignment inference. First, the chunk pair of  X   X  X   X  X n Japan X  in H and  X  X  X  X   X  X n Japan X  in T and the pair of  X  X  X  X  X  X  X   X  X nfrastructure X  in H and  X  X  X  X  X  X  X   X  X nfrastructure X  in T . Note that both pairs of arguments are aligned in surface-based alignment. Finally,  X  X  X  X  X  X  X  X  X   X  X s satisfied X  in H and  X  X  X  X  X  X  X   X  X s improved X  in T are judged to be semantically similar due to their aligned argument structures.

The above case illustrated the alignment of predicates when many of their argu-ments were aligned. However, there is a case in where predicates are aligned even if they only share one aligned argument. When both predicates have sentiment polarity values, (e.g., the predicates are identified as having positive or negative sentiment), regardless of whether the values are identical or not, the predicates are aligned even if they share only one argument. Also, when both predicates indicate existence or non-existence such as  X  X  X   X  X xist X  or  X  X  X  X   X  X ew X  , the predicates are aligned even if they share only one argument, and its semantic relation is inferred based on the sentiment polarities of its arguments. We manually constructed a list of predicates which indicate existence or non-existence.

Alignments detected in this phase are labeled inf erence . Since large-scale lexical knowledge is absolutely essential to recognizing the semantic relation between words, we use various large-scale lexical resources. These resources are used for knowledge-based alignment as described in Section 4. This section de-scribes how these resources are used. Table I gives an overview of the resources ap-plied by our system, the local semantic relations they identify during alignment, and their size in entries. We use the Japanese WordNet [Bond et al. 2009] to check whether the two words in T and H have hypernym or synonym relations, for example,  X  X  X   X  X ood effect X  - X  X  X   X  X ffect X  .

In addition, we use Wikipedia as a linguistic resource. Wikipedia has a massive amount of information on diverse topics such as sports, history, and so on, and ex-tracting linguistic knowledge from Wikipedia is an important task for NLP. We use hypernym-hyponym relations [Sumida et al. 2008] and synonym relations extracted from Wikipedia. Synonym relations can be extracted automatically from redirect database. Some words are hyper-linked to another word as  X  X edirect X . These words can be considered as synonyms or paraphrases [Shima et al. 2011b].
 To check whether the two predicates are semantically related, we use a database of relations between predicates [Matsuyoshi et al. 2008] and a database of predicate en-tailments [Hashimoto et al. 2009].

The database provided by [Hashimoto et al. 2009] includes not only predicate en-tailment relations but also preconditions (e.g.,  X  X  X  X  X  X   X  X et drunk X  - X  X  X   X  X rink X  ), action-reaction relations (e.g.,  X  X  X  X   X  X orrow X  - X  X  X   X  X end X  ), antonyms, estimated events (e.g.,  X  X  X  X  X  X   X  X eaves are colored X  - X  X  X  X  X  X   X  X eaves fall X  ), and semantically related events (e.g.,  X  X  X   X  X rganize,form X  - X  X  X   X  X irth X  ). The database contains 52,689 predicate pairs which have entailment relations, and 121,508 pairs in total.
Also, the database of Matsuyoshi et al. [2008] includes the following relations: antonym, cause, effect, goal, hyponym, meronym, and near synonym, and contains 32,314 predicate pairs in total. The Japanese Allographic Database [Kojima et al. 2010] is a database used to check al-lographic ambiguity between two expressions, for example,  X  X  X   X  X   X  X xhaust gas X  and  X  X  X  X   X  X xhaust gas X  . The chunks in T and H are aligned and labeled allographic if the content words are allographic variants of each other. Since many temporal expressions appear in the development set of the data, we devel-oped a numerical expression matching module 1 . Our module tries to search whether any of the set of predefined pattern is present before or after the number in both the T and H . If there is one, we normalize the temporal expression based on that. We use following patterns.  X  Year: N  X   X  X he year of N X  is converted to the year range [ N , N ]. The suffixes [ N , N + 9]), for example, 1989  X  X  X   X  X bout 1989 X  is converted to [1984 , 1994].  X  Century: N  X  X  X   X  X th century X  is converted to the year range [100( N  X  1)+1 , 100 N ].
The suffixes  X  X  X   X  X irst half X  ,  X  X  X   X  X econd half X  and some other variations such as  X  X  X   X  X eginning X  reduce the width of the year range. For example, 20  X  X  X  X  X  X   X  X he second half of the 20th century X  is converted to [1951 , 2000].
 Two temporal expressions are aligned if one range subsumes the other. For exam-ple, the range [1951 , 2000] includes [1984 , 1994], so 1989  X  X  X   X  X bout 1989 X  and 20  X  X  X   X  X  X   X  X he second half of the 20th century X  match. Alignments found using tem-poral expression patterns are labeled temporal . We employ a rule-based approach to recognize semantic relation between two text fragments. As described in Section 3, the entailment recognition phase consists of two phases: relevance recognition and relation classification .

In the Relevance Recognition Phase, our goal is to ensure that all of the semantic content in H is reflected in T . So our system uses a heuristic: it checks the alignments between T and H , and returns relevant if all chunks in H are all aligned to some chunk T , and irrelevant otherwise. If the returned relation is irrelevant then the system outputs non-entailment.

In the Relation Classification Phase, our textual entailment recognition system identifies the semantic relation between T and H through composition of the semantic relation labels on all alignments. MacCartney and Manning [2008] proposed a compo-sitional approach for textual entailment recognition in which alignments are assigned one of seven types of basic semantic relations and the composition rules defined by them are used to infer the semantic relation of a given text pair from relations of alignments. Our approach is similar to their approach but simpler: we define only two basic Entailment Semantic Relation Labels . The semantic relation labels assigned during the alignment phase from Section 4 are assigned one of the above labels using the mappings in Table II, which summarizes the resources used, the alignment labels each resource generates, and its corresponding entailment label.

Also, polarity information and factuality information of predicate alignments pro-vide semantic relations. In the evaluative expression dictionary [Kobayashi et al. 2005] and the noun polarity knowledge [Higashiyama et al. 2008], the three type of polarities positive , negative ,and neutral are defined. Polarity information is mapped to opposition (  X  )ifoneofthealigned chunks of predicates has negative and the other chunk has positive or neutral, and normal (+) otherwise.

The factuality analyzer outputs 5 types of factualities: certain+ , certain-(it is cer-tain that event happened (fact) / did not happen (counter-fact)), probable+ , probable-(it is probable that event happened / did not happen) and unknown for each predicate in a sentence. Factuality information is mapped to opposition (  X  ) if one of the chunks of predicates in the alignment has certain-and the other has certain+ ,and normal (+) otherwise. We used the factuality analyzer developed by [Matsuyoshi et al. 2008].
The set of entailment labels are composed together through a multiplication-like operation where normal (+) is treated as positive and opposition (  X  ) is treated as negative:
If the result of composition of the set of entailment labels is normal (+), then our sys-tem identifies an entailment relation between T and H . Otherwise, the system outputs non -entailment . 2 In order to investigate the effectiveness of the resources described in Section 5 for the task of Japanese textual entailment recognition, we conduct several experiments using the Japanese RITE dataset. The dataset is described in Section 7.1.

In the experiments, we first explore how effective use of various types of resources for the textual entailment recognition problem where we conduct ablation tests. Be-cause the coverage of the resources is limited, we need to infer alignments without any resource information. In the next experiment, we explore how the alignment in-ference algorithm described in Section 4 is effective for determining correct alignments without any resources.

Finally, we evaluate performance of alignments supported by the resources or the inference algorithm on the BC development dataset. In order to do so, we annotated the BC development dataset with correct alignments. The RITE Dataset [Shima et al. 2011a] is a multi-lingual dataset constructed as part of the the Recognizing Inference in TExt workshop of entailment relation recognition technologies in Asian Languages. It consists of data for three languages: Japanese, Simplified Chinese, and Traditional Chinese.
 Datasets are composed of T and H pairs of text. The datasets are divided into Binary Class (BC: entailment and non -entailment ) and Multi-Class (MC: for w ard entailment , back w ard entailment , paraphrase , contradiction ,and independence ) subsets. The BC data consists of 500 development examples and 500 formal run examples, and the MC data consists of 440 development examples and 440 formal run examples.

The Japanese BC and MC dataset were developed from Mainichi newspaper arti-cles. An additional dataset, the EXAM dataset, was developed for Japanese from past school entrance exams from the National Center Test for University Admissions and Wikipedia. The exams covers wide range of subjects including Domestic and World History, Politics, Economy, and Modern Society. The data consists of 941 examples (499 development examples and 442 formal run examples).
 For evaluation we used a dataset comprised of the RITE Japanese BC data and the EXAM data. We did not use the MC data on this exploration because contradiction relations are caused by not only antonyms (which can be found by using lexical knowl-edge) but also structural differences, factuality mismatches, number mismatches, and other phenomena which would not be found by lexical resources. See de Marneffe et al. [2012] for discussion. The aim of this experiment is to explore the effectiveness of ex-isting lexical resources for textual entailment recognition problem; we believe that the MC dataset is not appropriate for this experiment. Table III shows the ablation test results on the BC and the EXAM datasets. The col-umn  X  X lignment X  in the tables denotes alignment settings: surface-based similarity measures are used for alignment ( X  X urface X ), linguistic resources are used ( X +Knowl-edge X ),  X   X   X  denotes the resource being removed.

On both the BC and EXAM datasets, precision (Y) and recall (Y) dropped by several percent when Japanese WordNet was removed. We consider these results to reflect the fact that Japanese WordNet is a relatively large-scale resource with a lot of entries, and thus we expect it to be an effective resources. Japanese WordNet supported the following alignment correctly: ex. dev-67:  X  X  X  X  X   X  X rohibit X  - X  X  X  X  X  X   X  X xclude X  , dev-92:  X  X  X   X  X ppear X  - X  X  X  X   X  X ppear X  .

In addition, the Predicate Entailment DB also made a strong contribution on the BC dataset. It supported for instance the following word pair: (ex. 24:  X  X  X   X  X rganize X  - X  X  X   X  X irth X  )
Wikipedia Synonyms made a small contribution to recall on the EXAM dataset, pri-marily through its knowledge of named entities. It supported for instance the follow-ing word pair:  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X odex Justinianus X  - X  X  X  X  X  X  X  X   X  X orpus Juris Civilis X  ,  X  X  X  X  X  X  X  X   X  X ne thousand and One Nights X  - X  X  X  X  X  X  X  X  X  X  X   X  X rabian Nights X  and  X  X  X  X  X  X  X  X  X   X  X slam X  - X  X  X  X  X  X  X   X  X slam X  (notational variant).

On the other hand, the Allographic DB and Predicate Relation DB had comparative little effect on entailment recognition. We consider their lack of effectiveness to be due to their small size: in the magnitude of tens of thousands of entries instead of the hundreds of thousands or millions of more effective resources.

When comparing a baseline system that uses only surface alignment (Surface) to a system using all possible knowledge sources (+Knowledge), we find that recall (Y) increases over both datasets, but that precision (Y) increases for BC and decreases for EXAM. These results show that even the large-scale knowledge resources have their limits for textual entailment recognition. In particular, their lack of coverage is an outstanding problem for increasing textual entailment recognition performance. Next, we explore how the alignment inference is effective for determining correct align-ments without any resources.

The results of applying alignment inference to a system using all available knowl-edge sources on the BC and the EXAM datasets are given in Table IV. Adding align-ment inference greatly improved the precision (Y) and recall (Y) on the BC dataset compared to both the Surface baseline and the +Knowledge system that performed best in ablation testing. For the EXAM dataset, precision (Y) remained constant while recall (Y) nearly doubled. These results show both the limits of existing knowledge sources for alignment and the potential that similarity-based methods which do not rely on external knowledge sources have for improving entailment recognition perfor-mance. The performance of Alignment Inference dropped when sentiment polarity information was removed (w/o sp). In this setting, a pair of chunks are aligned only when they are both predicates and at least two arguments are lexically aligned. This is a stricter alignment setting. These results suggest that sentiment polarity information is effective for alignment inference.

In our previous experiments, we attempted to increase recall of alignments by us-ing surface information, various knowledge sources and the alignment inference algo-rithm. Now the question is what types of examples does the system fail to recognize the correct semantic relation for. In order to answer the question, we explore the alignment performance of each resource and alignment method used, quantifying the number of alignments produced and the precision and recall on gold standard align-ment data. Finally, we analyze the errors produced by the resources and alignment methods.

Table V shows the number of non-unique chunk alignments on the development and the formal run data for each alignment method and knowledge source employed by our system. Surface alignment is the most productive with 2/3 of the total alignments, followed by Japanese WordNet and Alignment Inference, which each produce 12%. These three resources and alignment methods are responsible for more than 90% of the total alignments detected. These alignment counts correlate with the findings of ablation testing where Japanese WordNet was shown to greatly contribute to precision and recall and the positive evaluation results of alignment inference. In the evaluations in Section 7, we explored the effectiveness of the linguistic re-sources and our alignment inference approach for the RTE problem. Here, one of our issues is the performance of alignments. In the following subsections, we first evaluate alignment-level performance for each resource, and then, through error analysis, we explore and discuss underlying subproblems in the RTE task. In order to evaluate the alignment performance of the knowledge sources and align-ment methods we use, we manually annotated the BC development dataset with gold standard chunk-level alignments. The alignment standards used are as follows. be an alignment candidate using the following standards of similarity and relatedness.  X  The two chunks are identical.  X  The content words in T x and H x are similar to the point of being synonym or near synonym ,and T x and H x are judged to have nearly the same content as a whole.  X  The content of T x is judged to be a hyponym of the content of H x .  X  T x and H x are judged to be similar due to derivative expressions or paraphrases.
Figure 4 shows an example of alignment annotations.  X  X  X  X  X  X  X   X  Cardamom  X  and  X  X  X  X  X  X   X  Spices  X  are aligned because cardamom is a hyponym of spice. On the other hand, since there is no corresponding part in H ,  X  X  X   X  to the brain  X  is not aligned.

The evaluation results on gold standard alignment data are given in Table VI. We report both precision and recall for overall performance (where all methods are com-bined); however, we report only precision for each alignment method because our align-ment annotation does not indicate what alignment method should be used for each alignment.

However, while surface-based alignment has high precision, knowledge-based align-ment has low precision. To determine the likely cause, we analyzed the precision for each knowledge source individually. The results are given in Table VII. First, we ob-serve that the precision is poor for all resources except for Wikipedia Synonym. The majority of incorrect alignments produced by Predicate Entailment DB can be traced to entries of the type non -entail relation. These include examples such as  X  X  X   X  X se X  - X  X  X   X  X ake X  and  X  X  X  X   X  X eed X  - X  X  X  X   X  X ave X  that have low levels of relatedness and are thought to be the primary cause. The errors caused by Japanese WordNet are mainly due to inappropriate entries and our inexact alignment approach considering only head words.

Finally, to determine the performance of alignment inference, we compared the re-sults of entailment recognition of the two alignment settings, Surface+Knowledge and Surface+Knowledge+Inference. We found that the alignments from alignment infer-ence was responsible for the following entailment recognition results.

Table VIII shows the impact of alignment inference on textual entailment recognition. Of the 16 incorrect entailment relations, 14 were due to incorrect align-ments, while in the remaining two, the alignments were correct (annotation standard) but their semantic relations were misclassified due to the results of the factuality analyzer.

An example is given below where an alignment between  X  X  X  X   X  X ecided X  and  X  X  X   X  X  X   X  X ake up one X  X  mind X  is inferred. The alignment is correct, however, the system misclassified the semantic relation as  X  X ntailment X  due to the error of the fac-tuality analyzer for the event  X  X  X  X  X  X   X  X ake up his mind X  . The correct factuality of the event is  X  X robable- X  but the output of the factuality analyzer was  X  X ertain+ X . (3) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  We explored the effectiveness of the linguistic resources and the alignment inference approach by evaluating both relation recognition performance and alignment perfor-mance. In this section, we explore remaining problems in textual entailment recogni-tion by exploring errors provided by our system on the BC and the EXAM data.
Most of the errors are due to false negatives of alignments. We show major error types with examples 3 in the following.

The majority of errors are caused by lack of lexical, paraphrase, and verb entailment knowledge. The following examples are misclassified as N (Y is the correct answer) due to lack of lexical knowledge:  X  X  X  X  X  X   X  X onquer X  - X  X  X  X   X  X estroy X  and  X  X  X  X  X  X   X  X ave jurisdiction X  - X  X  X  X  X  X   X  X nify X  .

Also, due to lack of paraphrase and entailment relation knowledge, the aligner pro-vided false negatives:  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X s a counter-inflation measures X  - X  X  X  X  X  X  X  /  X  X  X  X  X  X  /  X  X  X   X  X o curb price increases X   X  X  X  X  X  /  X  X  X  X  X  X   X  X espect for initiative X  - X  X  X  X  X  /  X  X  X  X  X  /  X  X  X  X  X  X  X   X  X xercise their autonomy in their own best X   X  X  X  /  X  X  X  X   X  X apture someone X  X  heart X  - X  X  X  X  X  X   X  X ttract X  .

The dataset used in the Entrance Exam Subtask contains various types of time expressions. As the time expression reasoner of the system has limited rules, it pro-vided many false negatives: e.g. 16  X  X  X   X 16th century X  - X  X  X   X  X he Ming era X  . Also, if there are modifiers on time expressions (e.g., beginning of), it provides 1-to-n alignments, for example, 902  X   X  X n 902 X   X  10  X  X  X  /  X  X  X   X  X n the beginning of 10th century X  . Since the modifier is not aligned to any phrases in T , it causes incorrect entailment relation recognition.
A few examples are incorrectly classified as  X  X ntailment X  due to misclassifications of factuality information. (4) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  In this case, the factuality of the event  X  X  X  X  X  X  X   X   X  X rant the right to vote X   X  must be  X  X ounter-fact X , however, our factuality analyzer mistakenly labeled  X  X act X  to the event. (5) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X   X   X   X  X  X  X  X  X  X  X  X  X  X  In (5),  X  X  X  X  X  X   X  X xamine X  presupposes that the event  X  X  X   X  X rant X  is  X  X ounter-fact (certain-) X , however, the system also misclassified the factuality of this event as  X  X act (certain+) X .

The following examples are instances of  X  X ntailment X  that are misclassified by our system because H contains a specific information not included in T . (6) T  X  X  X  X  X  X  X  1192  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  1185  X  X  X  (7) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  These examples require additional knowledge to infer entailment relations: in (6),  X   X  X  X  X   X  X amakura Shogunate X  was established in Japan, and in (7),  X  X  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  X  X  X  X   X  X avid Livingstone X  lived from 1813 to 1873, that is, during the 19th century.

Some examples requires more complex inference to determine the correct entail-ment relation. (8) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  In order to infer that  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X nly Japan remained until the end X  implies  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X ntervene for a longer period than all the other countries X  , systems are required to recognize  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X ther countries including UK X  corresponds to  X  X  X  X  X  X  X  X  X  X  X  X   X  X K and USA X  and deal with the comparative expression  X  X  X  X  X  X  X  X  X  X  X  X   X   X   X   X  X ompared to the other countries including UK X  .

In the following example, it is difficult to obtain the correct alignment since T de-scribes multiple and more specific events which correspond to one predicate in H . (9) T  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   X  X  X  X  /  X  X  X  X   X  X ade reforms X  in H corresponds to multiple events, and these de-scribes more specific level compared to T . How to deal with these kinds of examples is an open problem. In this article, we explored the effectiveness of the currently available resources for the Japanese textual entailment recognition problem using the NTCIR-9 RITE-1 dataset. For the exploration, we developed a resource-driven entailment relation recognition system which utilizes various resources in alignment, enabling us easily to analyze their effectiveness. In the evaluation, some resources improve performance, including Japanese WordNet and Wikipedia; however, the gain from these resources was lim-ited because there were still many expressions that needed to be aligned but were not covered by any resource. To tackle this poor alignment coverage problem, we developed an alignment inference algorithm which enables us to infer alignments without any linguistic resources. Adding alignment inference to a system using all available knowledge source greatly increased entailment recognition recall on both the BC and EXAM datasets and achieved the same level of precision (on EXAM) and higher (on BC).

In our error analysis, we found the types of errors, including lack of lexical or chunk-level knowledge, factuality misclassification, and complex inference to be among the problems facing textual entailment recognition. Some examples in errors show that it is important to consider background knowledge. Factuality information provides an important clue in the textual entailment recognition problem; however, existing factu-ality analyzers are immature and error-prone. Improving the performance of factuality analysis is an important area of future work. Since our system used in this article uses simple rules based on alignment semantic relations, there are many linguistic phe-nomena which our system could not handle, such as comparatives, quantification, and complex monotonicity. By combining deep approaches which handle such phenomena and large-scale linguistic resources, it may be possible to achieve accurate and robust entailment relation recognition which can be used in real life applications.
