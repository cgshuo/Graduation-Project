 As skyline query effectively retrieves results by utilizing the concept of domination decision support system and visualization and has gained significance in data processing more meaningful results (than  X  X earest neighbour answers X  returned by the usual top-k queries) and more semantically valuable results. Despite the performance improvement provided by a diversity of skyline query algorithms, text-based data have been ignored as these algorithms primarily focused on handling numerical data. In this paper, we present ferences between the characteristics of numerical data and categorical data [11] when data were used as skyline query objects, we quantify the distance [12] between categori-information of XML or ACM Classification System [13]. 
Table 1 shows the position of our current paper (which deals with skyline query for categorical data ) with respect to related works (w hich handle classification and/or numerical data). Among the most relevant works, Ref. [14] focused on skylines with partially-ordered domains, whereas we emphasized on distance functions. Al-though categorical data have been studied for a long time in various contexts, the corresponding similarity measures for categori cal data were data-driven (i.e., different measures for different data sets) [15, 16, 17, 18, 19]. 
The rest of the paper is organized as follows. Next section reviews relative seman-skyline search (CDSS) algorithm. Section 4 shows experiments results conducted on the ACM classification. Finally, conc lusions are presented in Section 5. 2.1 Semantic Distance Function Categorical data consisting of nodes N (that specify keywords) and edges E (that connect nodes x,y  X  N ) can be represented in a tree form T ( N,E ) as a categorical inclu-sion relation . See definitions below. largest number of abstracted levels from the two nodes to their lowest common ab-stract node. Definition 2. The n -level neighbour nodes are the nodes that share a common ab-stract node with a level difference value of n . Example 1. Fig. 1 depicts a tree representation of categorical data in the ACM Com-puting Classification System [13]. The level difference between  X  X rrays X  and  X  X ata lowest common abstract node) are 2 and 1, respectively.  X  X rrays X  and  X  X rees X  are 1-level neighbour nodes (with the common abstract node  X  X ata structures X ),  X  X ata structures X  and  X  X ata encryption X  are also 1-level neighbour nodes (with the common abstract node  X  X ata X ), whereas  X  X rrays X  and  X  X ode breaking X  are 2-level neighbour nodes (with the common abstract node  X  X ata X ).  X 
Based on the above definitions, we observe the following two properties of cate-gorical data: (i) Distances between every pair of nodes can be derived. (ii) The smaller the level difference between the two nodes, the more are their semantic similarity. Example 2. Based on the above properties, distances between any two arbitrary nodes in the ACM Computing Classification System [13] can be derived. Then, we observed that the distance between  X  X ata structures X  and  X  X rrays X  (i.e., level difference of 1) is smaller which means the former pair is semantically more similar than the latter one.  X  In this paper, we define the following distance function for categorical data . Definition 3. Given a categorical tree T ( N,E ), the distance between categorical nodes x,y  X  N can be computed as follows: where z is the common ancestor node for x,y  X  N , n zr is the level difference between z between y &amp; z . Theorem 1. The distance defined in Definition 3 satisfies the following properties: (i) D
WP ( x,z ) &lt; D WP ( x,y ) + D WP ( y,z ) for all x,y,z Example 3. Given Fig. 1, the distance between  X  X rrays X  and  X  X rees X  can be com-puted using Equation (1): D WP ( X  X rrays X ,  X  X rees X ) = 1  X  [2*3 / (1 + 1 + 2*3)] = 0.25. Similarly, D WP ( X  X ode breaking X ,  X  X ES X ) = 1  X  [2*3 / (1 + 1 + 2*3)] = 0.25, D WP ( X  X ata structures X ,  X  X ata encryption X ) = 1  X  [2*2 / (1 + 1 + 2*2)] = 1/3, D formation systems X ) = 1  X  [2*1 / (1 + 1 + 2*1)] = 0.5, and D WP ( X  X rrays X ,  X  X rrays X ) = 1  X  [2*4 / (0 + 0 + 2*4)] = 0.  X 
With Equation (1), the distance between any two categorical nodes is between 0 and 1 inclusive (with 0 indicating two identical nodes and large value indicating dis-relevance between them. This is congruous to other distance functions [20]. 2.2 Improved Distance Function The aforementioned distance is referred as WP because it utilized Wu and Palmer [21]. Despite its advantage of providing reference for categorical data, the WP nodes. For instance, although there are four child nodes (e.g.,  X  X rrays X ,  X  X rees X ) for  X  X ata structures X  and only two child node s (i.e.,  X  X ode breaking X ,  X  X ES X ) for  X  X ata encryption X , D WP ( X  X rrays X ,  X  X rees X ) = 0.25 = D WP ( X  X ode breaking X ,  X  X ES X ). In other words, the WP distance fails to capture information about the number of child or sibling nodes. To overcome such a limitation, we assign different weights based on the number of child or sibling nodes. The resulting distance function is referred as the Extended-Wu and Palmer ( EWP ). See the definition below. Definition 4. Given a categorical tree T ( N,E ), the distance between categorical nodes x,y  X  N can be computed as follows: where z is the common ancestor node for x,y  X  N , w z = 1 + number of child nodes of z , n is the level difference between z &amp; the root, w y = 1 + the number of sibling nodes difference between y &amp; z . Example 4. Given Fig. 1, the EWP distance between  X  X rrays X  and  X  X rees X  can be computed using Equation (2): D EWP ( X  X rrays X ,  X  X rees X ) = 1  X  [2*5*3 / (1 + 5*1 + 2*5*3)] = 1/6. Similarly, D EWP ( X  X ode breaking X ,  X  X ES X ) = 1  X  [2*3*3 / (1 + 3 + In this section, we propose an algorithm called CDSS for categorical data skyline , which uses the above distance functions. In abstract term, the algorithm finds a sky-line set based on (i) the categorical tree T representing categorical data, (ii) a data set vant to the user keyword set K . Once these objects are found, the algorithm then com-putes the relative distance (e.g., using the WP or EWP distance) based on categorical keywords {Q 1 , ..., Q d } and categorical properties of the top-k data objects that are in dimension indicates a categorical keyword. After computing the distance, skyline query algorithms such as NN [1] and BBS [6] can then be applied to get the resulting D respect to the categorical keyword Q i . Example 5. When a user submits a query with keyword set { X  X etrieval X  X , the CDSS algorithm finds top-k data objects (say, top-k papers) relevant to the topic of retrieval. computes the relative distance based on the two given categorical keywords {Q1= X  X rrays X , Q2= X  X ypes of systems X  X  contained in the categorical tree T of cate-gorical data. Then, these top-k data objects (e.g., P1= X  X ata storage X , P2= X  X ash ta-ble X , and P3= X  X quipment X ) are in a two-dimensional data set. Using Equation (2), the CDSS algorithm computes DEWP(Q1,P1)=0.143, DEWP(Q1,P2)=0.25 and DEWP(Q1,P3)=0.7. Similarly, the algorithm computes DEWP(Q2,P1)=0.739, DEWP(Q2,P2)=0.786 and DEWP(Q2,P3)=0.2. See Fig. 1. Based on these distance values, the algorithm computes the distan ce for each categorical keyword: D(Q1) = minj DEWP(Q1,Pj) = 0.143 and D(Q2) = minj DEWP(Q2,Pj) = 0.2, which means P1= X  X ata storage X  is the most relevant paper with respect to category Q1= X  X rrays X  and P3= X  X quipment X  is the most relevant paper with respect to category Q2= X  X ypes of systems X . Afterwards, skyline query algorithms can be applied to these data.  X  The experiment was conducted on WWW 2007-2008 and TODS 2005-2008 papers in the ACM Digital Library [22]. Here, K 1 ={ X  X ODS X ,  X 2005 X ,  X 2006 X ,  X 2007 X ,  X 2008 X  X  and K 2 ={ X  X WW conference X ,  X 2007 X ,  X 2008 X  X  are examples of input keyword sets used for selecting the initial data set of 165 and 300 top-k data objects; q1= {Q 11 = X  X atabase applications X , Q 12 = X  X eterogeneous databases X  X , q2={ X  X ormal lan-guages X ,  X  X nowledge acquisition X  X  and q3={ X  X elational databases X ,  X  X bstracting methods X  X  are examples of categorical keyword sets used in our experiments. 
First, we compared the difference between WP and EWP distances. In Fig. 2, the skyline of data is arranged by the semantic distance computed by BBS [6]. In each experiment, data computed as the skyline were depicted by lines connecting the data points. The results showed that categorical data (which were previously excluded from computation of skyline) can now be applied to skyline query. 
Second, we measured precision ratio (i.e., the ratio of the number of skyline result nodes to the total number of object nodes). Fig. 3 shows that WP returned about 10% of the total data as skyline results, whereas EWP returned about 0.5% to 4%. This indicates the capability of using EWP in retrieving outstandingly accurate results, i.e., effective processing of multi-dimensional data with massive storage. Specifically, a problem associated with the WP distance was related to the shallowness of categorical tree (e.g., maximum depth level is 5 for the ACM Classification System). The average query was undermined. In contrast, EWP successfully improved the distance function. Finally, we evaluated the scalability and dimensionality of the CDSS algorithm. Fig. 4 depicts the comparison associated with an increase in the amount of data, and Fig. 5 illustrates performance changes with respect to dimension growth. Here, we used three different data distribution X  X amely, uniform, correlated and anti-correlated distribution. Previously, skyline queries were operated only for numerical data, and thus could not widens the applicability of skyline to categorical data . The algorithm queries the skyline based on a function that calculates the distance between two nodes for cate-gorical data, by which more semantically meaningful answers can be generated than the top-k results returned by conventional queries. Our experimental results on the ACM Computing Classification System showed that our two proposed distance func-tions X  X P and EWP X  X ed up to 30% and 60% enhancements, respectively. Acknowledgments. This project is partially supported by (i) Basic Science Research Program through the NRF of Korea funded by the MEST(2010-0025366) and (ii) NSERC (Canada). 
