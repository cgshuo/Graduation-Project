 1. Introduction
Delta compression represents a target file T making use of a source file S . The general approach of differencing algorithms for constructing delta files is compressing T by finding common substrings between S and T , and replacing these substrings by a copy reference. The delta file is then encoded as a sequence of elements which are either pointers to an occurrence of the same substring in S , or individual characters that are not part of any common substring. To improve compression perfor-mance, pointers to previously occurring substrings in T are also used. When the delta file is the sequence of differences be-tween a given source file which was chronologically created before the target file we call it a forwards delta file. If the source file was created after the target file, it is called a reverse delta file or a backwards delta file .

Practical applications of delta compression are found in cases where the new information, which is received or generated, is highly similar to information already present. Such applications include distribution of software revisions, incremental file system backups, and archive systems, where using delta techniques is much more efficient than using regular compression tools. For example, incremental backups not only avoid storing files that have not been changed since the previous backup, as  X  well as applying standard file compression, they also save space by differential compression of a file with respect to a similar but not identical version saved in the previous backup.

The classical delta approach is not symmetrical, and the two input files play different roles. This paper introduces the no-can now be source or target. A bidirectional delta file provides concurrent storage and usage of forwards and backwards delta techniques in a single file. When one wishes to go back and forth between versions, bidirectional delta files should be used, providing flexibility, processing time savings, space storage efficiency, and I/O operations reduction. Instead of storing both source and target versions for future usage, the bidirectional delta file together with one of the versions is sufficient. Once the target file is constructed using its previous version and the bidirectional delta file, the source file is no longer needed and can be deleted, thus saving memory storage. In a multiuser environment where successive versions are used simultaneously by different users, a bidirectional delta file can provide upgrades and downgrades for all users in a single, storage saving file.
A practical application for bidirectional delta files is software distribution. When a new revision is released to licensed users, the distributor can make use of bidirectional delta techniques, providing both forwards and backwards deltas in an economical way. Memory resources are not always available on the distributor X  X  computer, thus when software distribution is done on a remote computer, the user should transfer these files and perform the upgrade or downgrade on his personal computer. This paper suggests that the distributor will provide the corresponding bidirectional delta file instead of the for-wards and backwards deltas, so that a single file could be transferred. Since the bidirectional file is usually smaller than the sizes of the forwards and backwards delta files, taken together, using it reduces data traffic and storage resources at both ends. Moreover, I/O operations are also saved by transferring a smaller number of bytes. The bidirectional delta file is espe-cially useful in the case a user regrets an in-place upgrade he just performed, i.e., when the user overwrites the source file with the new target file. Undoing this last update and restoring the previous situation can be achieved by using the same bidirectional file.
 Another connected, yet different application for bidirectional delta files is in the case of installing patches of databases.
When the user wishes to uninstall the patch he just applied, the same bidirectional patch (which is a special delta file) can be used to restore the previous situation of the database.

Generating a delta file of two given files S and T can be done in two typical ways, LCS (Longest Common Subsequence) based algorithms (e.g. Heckel, 1978 ), and edit-distance based algorithms (e.g. Agarwal, Amalapurapu, &amp; Jain, 2003; Tichy, 1984; Weiner, 1973 ). An edit distance oriented delta compressor is introduced in the work of Hunt, Vo, and Tichy (1998) , who compute a delta file by using the reference file as part of the dictionary to LZ-compress the target file. Their results indi-cate that delta compression algorithms based on LZ techniques significantly outperform LCS based algorithms in terms of compression performance. Based on these papers the constructed delta file in this research uses edit distance techniques including insert and copy commands. The already compressed part of the target file is also referenced for better compression.
Ajtai, Burns, Fagin, Long, and Stockmeyer (2002) use a hash table with Karp X  X abin footprints to perform differential com-pression of one file with respect to another, using constant space in addition to that used by both files. Shapira and Storer
Shapira and Storer (2005) study in-place differential file compression. They present a constant factor approximation algo-rithm based on a simple sliding window data compressor for the out-of-place version of this problem, which is known to be NP-Hard. Motivated by the constant bound approximation factor they modify the algorithm so that it is suitable for in-place decoding and present the In-Place Sliding Window Algorithm (IPSW). The advantage of the IPSW approach is sim-plicity and speed, achieves in-place without additional memory, with compression that compares well with existing meth-ods (both in-place and not in-place). Our bidirectional delta file is not necessarily in-place, but minor changes (such as limiting the offset X  X  size) can result in an in-place bidirectional delta version. Shapira (2009) introduces the problem of merg-ing two delta files, also called Compressed Transitive Delta Encoding (CTDE) problem. The problem is to construct a single delta file which has the same effect as two consecutive delta files, by working directly on the compressed forms, without the use of the source file, and in time proportional to the size of the delta files.

Rochkind (1975) introduces the Source Code Control System (SCCS), which is a model where each change made to the soft-ware module is stored as a discrete delta file. To produce the latest version of the source code module, SCCS follows the for-ward delta files from the beginning, applying them as it goes. Revision Control System (RCS) described by Tichy (1982, 1985) was first to use reverse delta files. A reverse delta file describes how to go backwards in the developed history: it produces erating a stored back-patch to undo the effect of forward patching. A back-update file (reverse delta file) is created, in order to allow future access to the previous version of a file, by providing the information necessary to construct the previous ver-sion out of the current version. In Forster (2001) a system with concurrent usage of forwards and backwards delta techniques is presented, which provides an improved method for updating an archive of a computer file to substantially reduce or elim-inate problems and disadvantages associated with archive resources like data storage and data transfer speed. In this paper we take this idea one step forward by merging the forwards and backwards deltas into a single file, in a non-trivial way.
Our paper is constructed as follows. Section 2 introduces the problem of generating an efficient bidirectional delta file, and shows the difficulty of building one by processing the corresponding forwards and backwards deltas directly. Section 3 presents an optimal sub-quadratic time algorithm for constructing a bidirectional delta file using dynamic programming.
To save processing time and reduce memory complexity we suggest a streaming greedy algorithm which is gradually developed. The first attempt algorithm named Aligned _ BD is presented in Section 4 , and its drawbacks are overcome in the algorithm named Non _ aligned _ BD presented in Section 5 . The final algorithm applies ad hoc heuristics to achieve better compression performance. Section 6 presents experimental results showing compression savings of at least 25% over the tra-ditional approach. 2. Problem presentation and optimal solution the backwards delta file of S with respect to T . The delta file (forwards and backwards) can be formed out of three types of items: pointers into the source file, self pointers (pointers copying substrings to the current position in the file from the al-ready scanned portion of the same file), and raw characters. The copies are initially described in the form of ordered pairs, pointers, describes the length of the reoccurring substring, which is the number of its characters. The position component, pos , of a source-file-pointer refers to a copy of the substring starting at position pos in the source file. The off component of a self-pointer means that the substring starting at the position corresponding to the current ordered pair can be copied from off characters before the current position in the decompressed file. A copy from the base file is denoted by the flag bit value
BP (Base Pointer flag bit value), and a self copy from the target file is denoted by OP (Offset Pointer flag bit value), while raw that the copy is from the target file. For example, suppose S is the string abcdxxxdyyz and T is the string yyzzzabcdyyzzz , both used to copy the substring yyz from address 8 of S ,( BP ,0,4) is used to copy the substring abcd from address 0 of S , and ( OP ,9,5) is used to copy the substring yyzzz from the beginning of T , which occurs nine characters before the current position.
A bidirectional delta file is denoted by BD D ( S , T ), which is a two way differencing file. The objective is to construct a single compact file in linear time in the sizes of the input files. The fundamental approach for storage savings in bidirectional delta files is to represent a common substring of S and T using a single copy reference, unlike two independent copies in the for-wards and backwards deltas. As common substrings of S and T can occur in a different order in S than in T , their encoding in the bidirectional delta file requires a precise clarification of the source and target addresses in both S and T , for a total of a 6 component pointer (adding the length and flag bit components to the 4 address components). The encoding of the two indi-vidual pointers that refer to the same common substring in the forwards and backwards delta files use a 3 component poin-ter each (flag bit, address and length). A comparison between the size of the encoding of the pointer to the common substring in the bidirectional delta file as opposed to the sizes of the encodings of both corresponding individual pointers implies an inferiority in efficiency of the 6 component pointer encoding in the bidirectional file (an address component does usually require more bits than the length component). Thus, a more efficient encoding of the common substrings is required which suggests using only a partial set of the common substrings.

A first attempt for solving the problem of choosing the  X  X  X est X  X  set of common substrings of two given files is by looking at the corresponding delta files. Selecting the same common substrings chosen by the differencing algorithm raises difficulties which stem from the fact that the corresponding delta files are not symmetric. Not only do the forwards and backwards del-tas choose different substrings for pointer references, but even if the same substring is represented by a reference, it does not necessarily use an identical pointer to represent such copy. Using the previous example, the forwards delta file used to con-( BP ,8,4) is used to copy the substring dyyz from address 8 in T . Although the substring abcd is represented by pointer ref-common substrings are not necessarily copied from the counter file. Note that the prefix d of dyyz is copied from S in D ( S , T ) using the triplet ( BP ,0,4), but this triplet refers to the occurrence of d at position 3 of S and not the one which occurs in the common substring dyyz at position 7. This example illustrates that choosing the set of common substrings based on an inde-pendent left to right parsing of S and T might result in a small number of short reoccurring substrings, which would impose a non-efficient bidirectional delta file. Rather, what is required is to find regions of the two files that are identical by a parallel scan of the files.

An alignment of given strings S and T is a parsing of both of them according to their common substrings so that the com-mon substrings occur in the same relative order. In other words, a set of substrings is aligned if by writing T below S and drawing straight lines between corresponding matches, no lines cross. The common substrings (contiguous matching char-acters) of an alignment are called blocks. The following figure gives a schematic view of aligned blocks of S and T . Given two strings S and T , the (global) sequence alignment problem is finding an alignment of maximal length. Formally, an alignment with k ordered blocks { b 1 , b 2 , ... , b k } is said to be of maximal length if R
S and T . Note that not all alignments necessarily have the same number of blocks. Instead of referring to the aligned blocks, b (1 6 i 6 k ), one can refer to the contiguous characters between the blocks. These are also known as gaps . Thus, another way to formalize the alignment problem is minimizing the accumulated length of the gaps.

The edit distance problem is another way to measure similarity between two given strings. The original problem was defined as finding the minimum number of insertions, deletions and substitutions in order to transform one string to an-other. In this paper consider character insertions and character deletions only, and focus on uniform costs of the operations involved. Otherwise, the costs are specified in a given scoring matrix . An optimal alignment is an alignment that yields the best edit distance. A gap is the result of the deletion of one or more consecutive characters in one of the strings. Solving the optimal alignment problem of two given strings is discussed in the following section (see Fig. 1 ). 3. Solving the maximum alignment problem using dynamic programming
The edit distance of two strings of sizes n and m , respectively, and the associated optimal alignment, can be computed using dynamic programming in O ( n m ) time and space ( Gusfield, 1997; Smith &amp; Waterman, 1981 ). If there is no need to reconstruct the alignment, O ( n + m ) space suffices. Given S = s bottom-up algorithm for solving the maximum alignment sequence problem, using a matrix A of size ( n +1) ( m + 1). Rows correspond to the characters of S and columns correspond to characters of T . First column cells of the matrix are initialized by i , where i stands for their row index, to indicate i character deletions for converting S to the null string. First row cells are initialized by j , where j refers to their column index, to indicate j character insertions for converting the null string to T .
Each cell A [ i , j ] of matrix A stores the minimum number of operations necessary to transform S [1 i ]to T [1 j ], which is computed by assigning it the value of the minimum between:
The value in the diagonal cell A  X  i 1 ; j 1 in case of a match between s an horizontal gap by referring to cell A  X  i 1 ; j plus 1 (character deletion); a vertical gap by referring to cell A  X  i ; j 1 plus 1 (character insertion).

The number attained in cell A [ n , m ] is the minimum number of operations required in order to transform S into T . A trace-back step determines the actual maximal alignment or multiple maximal alignments that result from this minimum score.
The algorithm presented in Fig. 2 is a first attempt for building a bidirectional delta file using dynamic programming for computing the maximum alignment of the two input files. However, the traditional Max Alignment Algorithm is not exactly suited for what we are looking for. Applying this algorithm on the two strings S = yxxabcd and T = abcdxbcd will produce the table shown in Fig. 3 . The back tracking algorithm traversing the colored cells will reconstruct two longest alignments: abcd as one solution, and x and bcd as another solution (there are other alignments for these strings which are not shown). There is a clear advantage of the first solution over the second one, since it uses a single common substring rather than two in the second solution. However, the traditional algorithm does not distinguish between these two alignments. Our problem is thus modified to finding the maximum alignment which uses the minimum number of blocks, and the algorithm which computes it is shown in Fig. 4 . The difference between this algorithm and the one presented in Fig. 2 is that here a diagonal penalty is applied. Each time an alignment occurs, there is an opening charge. Whenever a match occurs between a character of S ( s and a character of T ( t j ) this condition is verified by checking whether the corresponding former characters do not match. We would rather have that the more important criterion should be the length of the overlap. Only if we have several alternatives with same total length, should one prefer that with minimal number of blocks. That may be achieved by giving only a small diagonal penalty, e.g. 1 n  X  m  X  1 (so the sum of all diagonal penalties is &lt;1). This way the minimum edit distance with minimum number of gaps is attained.

The implementation of the dynamic programming algorithm presented in Fig. 4 , is memory consuming, and suffers from hardware limitations. For example, the dynamic programming table for two files of about 100 K bytes each, requires at least 10 10 bytes (assuming each cell occupies a single byte which is definitely a lower-bound). In order to handle addresses of sizes more than 4 Gbytes, 64-bit OS must be used since a 32-bit OS is limited to 2 of the dynamic programming algorithm applied on this example, the computer must have at least 10 Gbytes of physical memory for storing the dynamic programming table. To overcome the problem we used the fact that the operations of the algorithm are done on neighboring cells; the diagonal cell, the cell to the left and the cell above. Thus only a constant number of rows can be stored in the RAM, and all other rows can be saved on external storage devices. A set of cells are then fetched and dumped from and to the main memory. Saving computational time is achieved by minimizing the number of reloads and dumps and processing the maximum possible number of rows bounded by the size of the RAM. The experiments with the dynamic programming approach, the results of which are given in Section 6 , were only applied on files up to the size of 230 KB, performing dumps and reloads of 1000 rows at a time.

Masek and Paterson (1980) present a sub-quadratic global alignment string comparison algorithm based on the Four Rus-sians paradigm, which divides the dynamic programming table into uniform sized (log n log n ) blocks (here the length of the two strings is O ( n )). Under the conditions of a constant alphabet and discreteness (rational weights for the operations) the time complexity of the algorithm they present is O n 2 log n . Crochemore, Landau, and Ziv-Ukelson (2003) describe a O hn where h denotes the entropy of the strings, being faster than Masek and Paterson X  X  algorithm for compressible strings. In prac-tice, even though encoding is done only once, we suggest applying a streaming greedy linear time heuristic algorithm rather than a dynamic programming approach, even when adapting a sub-quadratic time performance.
 4. Basic greedy bidirectional delta encoding algorithm
Given S = s 1 s 2 s n and T = t 1 t 2 t m , we adapt the notation s [ i , j ] for representing the substring s symmetrically for T . A streaming greedy algorithm for constructing a bidirectional delta file is presented in Fig. 5 . The aligned blocks are found by a synchronized parsing of the strings from left to right. The gaps in both files are encoded using raw characters and self pointers, i.e., pointers copying substrings to the current position in the file from the already scanned por-tion of the same file. It uses the well known algorithm of Lempel X  X iv X  X torer and Syzmanski, LZSS ( Storer &amp; Szymanski, 1982 ) for compressing a single file against itself, using a sliding window.

The algorithm parses the strings trying to keep the pointers to both files synchronized. S and T are scanned in parallel by advancing the pointer to the file that lacks behind. If the position of S precedes the position of T the next common substring is found by searching S for the longest substring that matches the one that starts at the current position j of T . Otherwise, the next common substring is found by searching T for the longest substring that matches the one that starts at the current po-sition i of S . The algorithm uses the CS () method which is applied on two strings, X and Y , and returns an ordered pair, where the first component is the index of the starting position of a substring in Y which matches the longest prefix of X , and the second component is its length. For example, CS ( abcdxxx , xyzabcdyyabcdx ) = (9,5), since the longest occurrence of a prefix of X in the second component string is at its ninth position, and refers to the string abcdx , which consists of five characters. Note that this method is not symmetric, and CS ( X , Y ) is not necessarily equal to CS ( Y , X ).
 The Aligned _ BD algorithm can be implemented in linear time in the sizes of S and T by using a suffix trie for the string
S T $, where $ is a character not belonging to the original alphabet of S and T . Every node a string which is obtained by concatenating, top down, the labels on the edges forming the path from the root to node suffix trie is a compact trie , i.e., each path of single child nodes is collapsed to its starting and ending nodes, with an edge labeled with a string that is a concatenation of all labels on the original path so that each non-leaf node (except the root that might be a single child node) has at least two children. The set of strings associated to its leaves is the set of the suffixes of
S T $. Since the $ character does not occur elsewhere in S or T , each suffix corresponds to a unique leaf. Therefore, a node with descendant nodes that refer to substrings with prefixes from S and T corresponds to common substrings, and the deepest such node corresponding to the longest common substring. This implies that the CS () method can be performed in time pro-portional to the length of the longest common substring of the two input strings which is also a prefix of its first component string. In practice, CS () can be implemented using hashing, having better processing time, at the price of not necessarily locating the longest match.

The Aligned _ BD algorithm uses indices i and j to point to the current location in S and T , respectively, which are both ini-tialized to point to the beginning of the files by assigning them a zero. Assistant indices, i ing position, in S / T , of the next portion of the file to be encoded, and i files, of the common substring found by the CS () method, which is also the ending position in S / T of the next portion of the file to be encoded. The length of the common substring found by the CS () method is compared against a supplied parameter, to justify the use of this aligned block by checking whether the common substring is long enough. If the length is less than the given parameter MinLen, the method CS () is applied on the successive position in S or T . Otherwise, the gaps in both files are encoded by self pointers and raw characters using LZSS, followed by the encoding of the common substring itself. The indices i and j are then advanced together with the assistant indices, i mon substring. When the scan of one of the files ends, the remaining part of the other file is compressed using LZSS and out-put to the bidirectional delta file.

The format of the bidirectional file is composed out of flag bits, aligned pointers, and LZSS items of S and T , which, in turn, include flag bits, self pointers and raw characters. Thus, 3 flag bit values are needed to distinguish between such items in
BD D ( S , T ), for which LZSS items require 2 additional inner flag bit values to differentiate pointers from raw characters. For simplicity we refer to flag bit values 1, 2 and 3, for aligned blocks, LZSS S -items, and LZSS T -items, respectively, and ignore the inner implementation of the LZSS components (since pointers are given as ordered pairs and raw characters are written explicitly). Note that, for example, when a raw character is individually output to the bidirectional delta file, the appropriate inner flag bit value of LZSS is concatenated to the corresponding BD D ( S , T ) flag bit value to differentiate a S raw character from a T raw character. Thus, a raw character is represented using an additional bit value as compared to the representation of a raw character in a single direction delta file. An aligned block is represented by a 1 flag bit value, and followed by a triple ( S add , T add , len ) for referring to the common substring that occurs in S at address S of characters is len . Note that the representation of a common substring in each single direction delta file uses an ordered is used to differentiate a raw character and a pointer, and the other flag bit component is used to differentiate a self pointer and a base pointer. The bidirectional delta file items of the encoded gaps can be put in between the encodings of the corre-sponding common substring in any order (e.g. alternating LZSS S-items and LZSS T-items), as long as they occur in the same order as in LZSS for S and T. For simplicity, LZSS S-items are put before LZSS T-items in each gap.

Consider for example the strings S = xxxabcdefxablmn and T = abcdxyzlmnxxx . Using flag bit values BP and OP as defined in aligned blocks are found by the CS () method, abcd and lmn and are encoded by ( 1 ,3,0,4) and ( 1 ,12,7,3), respectively (flag bit values are highlighted in bold). The gaps between these common substrings (including the gaps at both ends of the xxx . The output bidirectional delta file is therefore: 5. Non-aligned bidirectional delta encoding algorithm The previous section presents the basic greedy construction of a bidirectional delta file. Empirical experiments given in
Section 6 show poor compression performance of the Aligned _ BD algorithm presented in Fig. 5 as compared to the traditional approach of using both forwards and backwards delta files. In this section we suggest two gradually improved versions of the basic algorithm, which have significant preference on the traditional one.

In our last example we discover that the substring xxx , even though being a common substring of S and T , is encoded as indi-vidual characters in both LZSS encodings of the bidirectional delta file. This loss in compression is due to the fact that only aligned common substrings are efficiently encoded. An improved version of the basic greedy bidirectional delta encoding algo-rithm, named Non _ Aligned _ BD , suggests using a regular delta encoding instead of the LZSS encoding used in the Aligned _ BD Algorithm shown in Fig. 5 , where the gaps between the aligned blocks also capture reoccurring substrings in the other file.
As in Fig. 5 , the Non _ Aligned _ BD algorithm is used for constructing a bidirectional delta file for given source and target files S and T , respectively. The files are scanned in parallel by keeping the pointers to both files synchronized the same way as in Fig. 5 . Unlike the LZSS method used in the Aligned _ BD algorithm, here a delta encoding is applied. D ( X , Y ) is used as a delta compression scheme which is applied on the strings X and Y , where X is a substring of the source file S , and Y is a substring of the target file T . This way, also non-aligned blocks are compressed using the help of the opposite file. This comes at the price of having three different formats of items in the delta encoding (pointers to the source file, self pointers, and raw characters) as opposed to only two in the LZSS encoding (self pointers and raw characters). So for example, the Non _ A-ligned _ BD Algorithm replaces the statement BD D  X  S ; T  X  BD D  X  S ; T  X  2 LZSS  X  s  X  i BD D  X  S ; T  X  BD D  X  S ; T  X  2 D  X  s  X  i old ; i new ; T  X  for a S delta item.

Returning to our previous example, the substring xxx of the first gap of S is therefore encoded as ( 2 , BP ,10,3) for copying it bidirectional delta file is therefore:
Fig. 6 a and b are schematic illustrations, which visually represent differences between Aligned _ BD and Non _ aligned _ BD algorithms. The source file S and target file T are presented so that T is drawn below S . Common substrings of S and T have the same texture. In the Aligned _ BD algorithm, only aligned blocks are used as pointers to the other file. The gaps between the aligned blocks are encoded by pointing backwards to previous occurring substrings in the same file. On the other hand, in the Non _ Aligned _ BD algorithm non-aligned blocks are also used as pointers to the counter file. The remaining portions of the gaps in the source and target files are encoded by pointing backwards to previous occurring substrings in the same file.
A final improvement using heuristics is now suggested for controlling the aligned blocks chosen by the CS () function. The following example shows that there are many cases for which the CS () method used in the Aligned _ BD and Non _ aligned _ BD algorithms is inefficient. Let S = abcdxyzlmnxxx and T = xxxabcdefxablmn , which is in fact swapping the roles of S and T in our previous example. In this example, the first common block selected by the CS () function, is xxx , and occurs in opposing ends of the files. As a result, the computed set of the aligned blocks consists of a single common substring ( xxx ). Since the com-pression savings of a bidirectional delta file over conventional delta files are due to using a single copy of the aligned blocks, unlike two independent copies in the forwards and backwards deltas, the resulting bidirectional file may be relatively inef-ficient. Moreover, the remaining items in the bidirectional delta file use more flag bit values than the number of flag bit val-ues used in the items of the forwards and backwards delta files (the bidirectional delta file uses 3 flag bit values to differentiate aligned blocks, S-items and T-items in addition to the flag bit values, which are also used in a regular delta file).
In fact, other aligned blocks could have been selected to better utilize the similarity of the two given files, e.g. abcd and lmn which could have been found if the dynamic programming algorithm of Fig. 4 was applied.
 Although such an example may be quite rare, it emphasizes the loss of choosing aligned blocks which are too far apart.
Our final bidirectional delta encoding algorithm, named Improved _ BD , suggests using heuristics for selecting the aligned blocks by controlling the distance between the corresponding positions in the source and target files, and checking whether it is proportional to its length. More formally, if the factor between the length of the candidate block, and the distance be-tween the last chosen block and the candidate block is less than a supplied constant (empirically chosen as 0.1,0.2, ... ,1.0) the candidate block is ignored, and the search continues at the following position. Otherwise, the block is chosen, and both positions to the files are advanced. 6. Experimental results
This section presents experiments which evaluate the compression savings and processing time performance of a bidirec-tional delta file construction using the four algorithms described in this paper: Dynamic Programming, Aligned _ BD, Non _ A-ligned _ BD and the Improved _ BD algorithm. We first compare the greedy approach algorithms to the traditional one, where all are built around parameters of a simulation delta compressor we programmed. Since the dynamic programming algorithm is not practical for the original set of data files used in the first part of the experiments, we modify the set of files so that only small files are considered. We then apply the dynamic programming algorithm presented in Fig. 4 on the smaller files and compare its compression performance to those of the improved greedy algorithm. 6.1. Greedy bidirectional delta experiments
At first, a simulation LZ based delta encoder was implemented, using pointers to the source file, pointers to the already scanned portion of the target file, and raw characters. The goal of the delta simulation was to provide a tool for further exper-iments, rather than try to modify the existing delta utilities to fit our needs. The format of a delta file was constructed around key parameters of the UNIX gzip utility that uses a window of size 32 K and maximum match length 256.

For our experiments we consider three typical series of consecutive versions of software releases. First, source codes of the GNU GCC compiler collection which includes front ends for C, C++, Objective-C, Fortran, Java, and Ada, as well as libraries for these languages (libstdc++, libgcj, ... ), versions 4.3.3 and 4.4.0, gcc.c, combine.c and parser.c files. Second, the GNU source code of MySQL server, which is a portable multiuser relational database management system, versions 5.0.82 and 5.0.83, sql_select.cc and sql_yacc.cc files. Third, the GNU Emacs text editor source code, versions 22.3 and 23.1, calc.texi file. Table 1 presents the set of software releases that were used in our experiments and their corresponding sizes in bytes.
Our first experiment was used to empirically evaluate the compression performance of our delta simulation against xdelta and zdelta LZ based UNIX utilities, which use the zlib compression library. Fig. 7 presents the size in bytes ( Y -axis) of the output deltas applied to the data files ( X -axis) of Table 1 , where the Y -axis is logarithmic rather than linear axis providing better appearance. As can be seen, the compression performance of our delta algorithm, denoted by Simulated D ( S , T ), con-sistently outperforms xdelta , but is slightly less efficient as compared to zdelta . As the format of our bidirectional delta file was constructed around the key parameters of this delta simulation, the compression results given in Fig. 7 are encouraging, since one can only expect that the compression we achieve here will be improved by using a gzip or zdelta implementation.
The following experiment compares the processing time of encoding and decoding of bidirectional files as opposed to the traditional approach of encoding and decoding two separate files. The top half of Table 2 presents the encoding time perfor-mance, and the bottom half gives the results for decoding, where all figures are given in seconds. Each column corresponds to a different set of source and target file as in Table 1 . The forwards + backwards rows refer to the time taken to construct the forwards delta file, in addition to the time it takes to generate the backwards delta file. The improved _ BD row corresponds to the time taken to construct the bidirectional delta file using the improved version, which is the most time consuming version of all bidirectional delta algorithms. The results show that the encoding running time for regular deltas is superior as com-pared to improved _ BD in most cases. However, encoding is done only once, while decoding can be done over and over. Sur-prisingly, our time performance for decoding are comparable to the general approach despite the fact of dealing with a bigger number of different formats.

Our following and most important experiment was applied in order to show the gain in compression performance of our suggested algorithms as compared to the sizes of the corresponding forwards and backwards deltas. A comparison of aligned _ BD, non _ aligned _ BD , and improved _ BD with the traditional method can be found in Table 3 . The figures are given as a percentage of the sum of the sizes of the forwards and backwards delta files, corresponding to 100%. Thus, results less than 100 indicate an improvement over the traditional approach, while results more than 100 show inferior performance. As can be seen, improved _ BD has compression capability of about 25 X 30% better than the traditional way of using two separate forwards and backwards deltas. As expected, the two preceding constructions of bidirectional delta files are not as good as the improved version, although even the non _ aligned _ BD version is in most cases better than forwards + backwards deltas. 6.2. Dynamic programming bidirectional delta experiments
The dynamic programming algorithm presented in Fig. 4 was applied on data files which are limited to 230 K bytes be-cause of its memory requirements. The algorithm was applied on files which were taken from the gcc-4.3.3 and gcc-4.4.0
GNU software packages. Table 4 presents the source and target files (first and third columns) and their corresponding sizes in bytes (second and fourth columns).

The dynamic programming algorithm is only optimal for choosing the maximal alignment using the minimum number of blocks, but this still does not mean that it would necessarily produce the smallest encoded file, since parsing of the intervals between alignments is also involved. Suppose, for example, that S is abaccababacccab and T is bacccababaccaba . The maximal alignment is the substring ccababacc of nine characters. Note that this is the only maximal alignment and therefore it is also the maximal alignment using the minimum number of blocks. Using a greedy parsing for the remaining parts of the file, S and T would be parsed as aba ccababacc cab and bac ccababacc aba , respectively (the common substring appears in 4 base pointers and a single common substring pointer. While a greedy, left-to-right parsing is S = abaccaba bacccab and
T = bacccab abaccaba , in which the Bidirectional delta file encoding is: ( 3 , BP ,8,7)( 1 ,0,7,8)( 2 , BP ,0,7), using one common substring pointer and two base pointers, which produces a smaller Bidirectional delta file than the file constructed by the optimal alignment. Note that some of the base pointers in the maximal alignment encoding can be replaced by self pointers, which does still require more bits than the greedy encoding.

Table 5 compares the compression performance of the dynamic programming algorithm for computing the maximal alignment with the minimum number of blocks to the greedy and traditional approaches. In all cases the gaps between the aligned blocks are encoded using the same format. The only difference between the greedy algorithm and the dynamic programming one is in the way the aligned blocks are chosen. As can be seen, the dynamic programming algorithm gives better results in most cases. In cases where the dynamic programming approach is worse because of the differences in the encodings of the gaps, its performance is very close to the greedy algorithm. Since, as noted above, the dynamic program-ming approach is impractical for larger files, this experiment is only given to show that the dynamic programming approach is usually a lower bound on the compression performance, however, the greedy approach is a good approximation with rapid running time. 7. Conclusion
In this paper the term of bidirectional delta files is introduced, providing flexibility when going back and forth between versions. Optimal and practical algorithms are suggested and compared to the general approach of using both forwards and backwards delta files. Experiments show a consistent advantage of our bidirectional delta construction that does not only provide storage savings, but does also imply a reduction in the amount of I/O operations in case the deltas are trans-formed over a network (e.g. file system backups or software distribution). Surprisingly, the processing time is comparable to that of the traditional approach even with the more complicated structure of the file. Moreover, one can expect that the compression and processing time performance of our algorithm can only be improved by using a gzip or zdelta implementation.
 References
