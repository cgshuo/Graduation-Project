 Faceted blog distillation aims at retrieving the blogs that are not only relevant to a query but also exhibit an interested facet. In this paper we consider personal and official facets. Personal blogs depict various topics related to the personal experiences of bloggers while official blogs deliver contents with bloggers X  commercial influences. We observe that some terms, such as nouns, usually describe the topics of posts in blogs while other terms, such as pronouns and adverbs, normally reflect the facets of posts. Thus we present a model that estimates the probabilistic distributions of topics and those of facets in posts. It leverages a classifier to separate facet terms from topical terms in the posterior inference. We also observe that the posts from a blog are likely to exhibit the same facet. So we propose another model that constrains the posts from a blog to have the same facet distributions in its generative process. Experimental results using the TREC 2009-2010 queries over the TREC Blogs08 collection show the effectiveness of both models. Our results outperform the best known results for personal and official distillation. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -retrieval models, selection process; Algorithms, Experimentation, Languages Faceted Blog Distillation, Personal and Official Facets To explore information seeking behaviors in blogosphere, TREC 2009 [9] introduced faceted blog distillation that aims at, for a given query q in a blog search context, retrieving the blogs that are relevant to q and exhibit a given facet. In this paper, we are interested in a pair of facets: personal vs. official. Personal blogs are normally written by bloggers to describe various topics related to their personal experiences while official blogs are increasingly written by companies for PR or marketing purposes. A blog (i.e. an RSS feed) is a set of blog posts. We use the term feed to represent a blog and the term post to represent a blog post in a feed.
Existing personal and official blog distillation works are dictionary based [2, 7, 8], heuristic based [4, 11] and clas-sification based [5, 6, 13, 15, 17]. In contrast, we employ topic modeling techniques. We observe that 1) the topics in posts are normally expressed by some terms (called topical terms ), such as nouns, while the facets of posts are normally revealed by other terms (called facet terms ), such as pro-nouns and adverbs; and 2) the facet terms frequently used in personal posts are different from those in official posts. Let us illustrate these two observations with an example.
Example 1. Given a query  X  parenting  X , one excerpt d 1 =  X  I am a big fan of babywearing and so I was elated when I received a Sleepy Wrap to try. I thought it was so cute that it came in a little pouch bag (for storage). Anyway , what exactly is a Sleepy Wrap?  X  and another excerpt d 2 =  X  A coalition of concerned individuals and organizations has started NEPI, the National Effective Parenting Initiative. Its goal is to have every child in our country effectively and humanely raised by parents who receive the best pos-sible parenting education, training and support.  X , d 1 is from a personal post while d 2 comes from an official post. The terms in bold obviously do not show any topics but facets. Specifically, the pronoun  X  I  X  and the interjection  X  Anyway  X  show the personal facet while the adverbs  X  effectively  X  and  X  humanely  X  show the official facet.

Motivated by our observations, we propose two models that calculate the probabilistic distributions of topics and those of the two facets within posts. Moreover, all the exist-ing works indicated above treated posts independently and ignored the facet correlation among all the posts from a feed. We observe that a post from a feed f is likely to exhibit the same facet as other posts from f . It is intuitively reasonable, because all the posts from a feed are usually written by a blogger at different times. To leverage such a correlation, one of the two models constrains all the posts from a feed to have the same facet distribution in its generative process.
This paper has three contributions. 1) Our work is the first study that employs generative models to solve personal and official blog distillation. 2) Our work is the first study that leverages the facet correlation of the posts from a feed into the calculation of their personal and official facets. 3) Experimental results show our models are robust and effec-tive and our best results outperform the best known results for personal and official blog distillation.
Figure 1: The plate notations of JTF and E-JTF.
Various approaches have been proposed to study personal and official blog distillation. The methods in [2, 6, 7, 17] made the assumption that personal (official) posts are likely to have opinionated (factual) contents. They indirectly mea-sured the extents of posts exhibiting the personal (official) facet by measuring those of posts being opinionated (fac-tual). Specifically, the extents of posts being opinionated or factual are calculated either by the opinionated and factual lexicons built by mutual information metric [2, 7] or by var-ious opinionated and factual classifiers [6, 17]. Li et al. [8] built a personal and official lexicon using information gain measure and then used this lexicon to measure the personal and official facets of posts. Heuristics built on parameters, such as the number of occurrences of first person pronouns, are used to calculate the personal and official facets of posts in [4, 11]. Various classifiers are built in [5, 13, 15] to di-rectly categorize posts into personal or official ones. Our work differs from the above existing works in two aspects: 1) unlike the methods in those works, we use the topic mod-eling techniques to compute the facets of posts; and 2) their works treated posts independently while one of our models constrains the posts from a feed to exhibit the same facet.
We now present a j oint t opic f acet model (called JTF) that c omputes the probabilistic distributions of topics and those of facets within posts. Specifically, given a set of feeds with respect to (w.r.t.) a query where each feed is a set of posts, a corpus is formed by pooling the posts from the feeds. In the JTF model, the terms (unigrams) of a post in the corpus are assumed to be generated from a mixture of some latent topics and two latent facets: personal and official.
We first describe JTF X  X  generative process. Let us de-fine some notations for ease of presentation. Let E denote a set of feeds, E = { e 1 ,...,e | E | } where each feed e set of posts. A corpus of posts is formed by pooling the posts from E . Let D denote the corpus, D = { d 1 ,...,d | D | where d i  X  D is a post from a feed e d i  X  E . Let V be the term vocabulary of D . 1 Each post d has N d terms where w d,n denotes the n th term in d . Let W be the set of ob-served terms in D , W = { w d,n | d  X  D ; n = 1 ...N d } . The terms in W act as either topical terms or facet terms. Let  X  = {  X  d,n | d  X  D ; n = 1 ...N d } be the set of the probabil-ities for all the terms in W acting as facet terms. Specifi-cally,  X  d,n is the probability of w d,n acting as a facet term. Let R = { r d,n | d  X  D ; n = 1 ...N d } be the set of the bi-
W e only consider the terms appearing in at least 30 posts, because the average number of posts in the corpus for a query is about 21000. We believe that a term appearing in less than 30 posts can neither show up as a top topical term nor a facet term. nary variables, each of which indicates whether a term in W acts as a topical term or a facet term. Specifically, w acts as a facet (topical) term if r d,n = 1 ( r d,n = 0). Let Z = { z d,n | d  X  D ; n = 1 ...N d } be the set of the topics or the facets assigned to the terms in W . Specifically, z d,n the facet (topic) assignment to w d,n if r d,n = 1 ( r d,n Assume that there are a set of latent topics T and two facets probability of a post d exhibiting the facet f  X  F and the row vector  X  F d is the probabilistic distribution of d exhibiting all the facets F .  X  T = {  X  T d,t } | D | X | T | is the matrix where  X  is the probability of d exhibiting the topic t  X  T and the row vector  X  T d is the probabilistic distribution of d exhibiting all the topics T .  X  F = {  X  F f,v } | F | X | V | is a matrix where the row vector  X  F f is the probabilistic distribution over all the terms in V for the facet f and  X  F f,v is the probability of the term v for f .  X  T = {  X  T t,v } | T | X | V | is a matrix where the row vector  X  t is the probabilistic distribution over all the terms in V for the topic t and  X  T t,v is the probability of the term v for t . Now we present the generative process of the JTF model (see the plate notation in Figure 1(a)). 1. For each facet f  X  F , draw  X  F f  X  Dirichlet (  X  F ); 2. For each topic t  X  T , draw  X  T t  X  Dirichlet (  X  T ); 3. For each post d  X  D , 1) Draw  X  F d  X  Dirichlet (  X  F ); 2) Draw  X  T d  X  Dirichlet (  X  T ); 3) For each term in d , say w d,n ,
In the generative process,  X  d ,n is the probability that con-trols whether the term w d,n in d is generated from a facet or a topic and it is set by a function g (  X  ) (see Step 3.3.i). The-oretically, we should use Beta priors as g (  X  ) in the (unsuper-vised) generative process. The studies [12, 16] proposed two models that compute the topics and the sentiments of posts. In their models, a term is generated from either a topic or a sentiment. So their models set the probability of a term in a post acting as a topic term. Their studies showed that us-ing classifiers in their posterior inferences to calculate these probabilities yields better performance than deriving these probabilities from the adopted Beta priors in their genera-tive processes, because fully unsupervised topic models are unable to separate sentiment terms from topical terms well [16]. In this work, we want to separate topical terms from facet terms and we believe that it is hard to differentiate them in an unsupervised manner either. Thus, we follow their suggestions and build a classifier to automatically cal-culate the set of probabilities  X  for all the terms in W acting as facet terms in the posterior inference, i.e.  X  d,n  X  g ( where sifier. X and  X  correspond to two observable variables in the plate notation of Figure 1(a). To build such a classifier, we resort to the TREC queries and the TREC judgments to col-lect typical topical terms and typical facet terms as training examples. The TREC judgments provide the personal and o fficial feeds w.r.t. the TREC queries. We use query terms as typical topical terms, because query terms always express topical information. We propose a method called STFT to s elect t ypical f acet t erms from the TREC judgments below. 1 . For a TREC query q , partition the personal feeds from 2. Pool the posts from the personal (official) feeds that 3. For each term in P  X  O , conduct the  X  2 test over P and 4. Repeat steps 1 to 3 for each TREC query. 5. Pool the candidates for all TREC queries; for each 6. Rank the candidates in the pool in descending order
The high  X  2 value of a selected typical facet term shows that it has a clear facet inclination. The high number of queries of which a selected typical facet term appears as a candidate exhibits its strong generality. Thus we believe the STFT method can select typical facet terms. For example, a typical personal term and a typical official facet term found by STFT are  X  X eah X  and  X  X ignificantly X  respectively. The classification of topical and facet terms is challenging. Intuitively, typical topical terms tend to be nouns while typ-ical facet terms are normally non-noun terms, such as pro-nouns and adverbs. However, our preliminary experimental results showed that poor performance was obtained if we just used the part-of-speech (POS) of a term to classify it, be-cause there are exceptions. For example, the noun X  X roduct X  can be an official facet term. To accurately separate topi-cal terms from facet terms, we propose to use a term X  X  POS and its contextual POSs as features, because these POSs of a term reflect its syntactic role. The syntactic role of a topical term and that of a facet term are likely to be dif-ferent. Specifically, given a term w d,n in a post d , we first identify the sentence s containing w d,n and then obtain the POS of w d,n , the POSs of 10 preceding terms of w d,n in s (if any) and those of 10 succeeding terms of w d,n in s (if any) as features. 2 This generates a vector of 21 features. Each topical (facet) training example consists of a typical topi-cal (facet) term and a contextual sentence. We use as the contextual sentences the sentences containing at least one of the selected typical topical (facet) terms in the posts of the feeds from the TREC judgments.

After defining the features and collecting the training ex-amples, we build a classifier that determines whether a term in a post acts as a topical term or a facet term. Specifically, given a term w d,n in a post d , if w d,n is classified to be a facet term with a class probability p ( &gt; 0 . 5), the probability of w d,n in d acting as a facet term is equal to p (  X  d,n w d,n is classified to be a topical term with a class probability p ( &gt; 0 . 5), the probability of w d,n in d acting as a facet term is equal to 1  X  p  X  (  X  d,n = 1  X  p  X  ). After we apply the classi-
I n our preliminary experiments, the classification perfor-mance was improved with the increasing of the size of the contextual window (symmetrical at w d,n ) to collect the con-textual POSs. The performance made negligible changes after the size of the window increased beyond 20. fier to all the terms in W , we obtain the set of probabilities  X  = {  X  d,n | d  X  D ; n = 1 ...N d } , each of which indicates the probability of a term in W acting as a facet term. Then we can use  X  as a set of priors in the posterior inference (to be presented in Section 3.2). Note that the classifier does not specify whether a term in a post acts as a personal or an official term. A term X  X  facet is inferred by the JTF model.
The posterior inference predicts the topic (facet) distribu-tions of posts  X  T ( X  F ) and the term distributions of topics (facets)  X  T ( X  F ). In order to infer these four distributions, we need to know the topic and facet assignments Z and the binary variables R for all the terms in W . Specifically, given a term w d,n in a post d , z d,n indicates the facet f (the topic t ) assigned to w d,n if r d = 1 ( r d = 0). We adopt the collapsed Gibbs sampling [3] to estimate the posterior dis-tributions of Z and R . We skip the derivation details and estimate Z and R by the conditional probabilities below. 3  X  where m F f,v and m T t,v are the counts of the occurrences of the specific term v (  X  V ) in W being assigned to the facet f and the topic t , respectively; n F d,f and n T d,t are the counts of the facet f and the topic t being assigned to the terms in d , respectively. The superscript { X }  X  ( d,n ) means the exclusion of the term w d,n . For example, { m F f,v }  X  ( d,n ) is the count of the occurrences of v being assigned to the facet f by exclud-ing w d,n ( w d,n = v ). The same applies to Z  X  ( d,n ) , R W provide some explanations for the two probabilities above. During the iterative sampling, the probability of a term w in a post d being assigned to a facet f (a topic t ) is propor-tional to the product of three items below: 1. The probability of w d,n in a post d acting as a facet 2. The smoothed ratio of the count of the occurrences of 3. The smoothed ratio of the count of the terms in d ex-After the posterior distributions of Z and R are estimated, topic or facet assignments to all the terms in W (indicated by Z and R ), we estimate the count of the occurrences of
F or convenience of presentation, we omit some priors in the conditional probabilities in the paper. The omit-ted priors are  X  F , X  T , X  F , X  T and  X , i.e. P ( X | Y ) = P ( X | Y, X  F , X  T , X  F , X  T ,  X ). v (  X  V ) in W that are assigned to the facet f ,  X  m F f,v the count of the terms in d that are assigned to the facet f ,  X  n F d,f . Then we can estimate the facet distributions of posts  X  F and the term distributions of facets  X  F as follow:  X   X  estimate  X  m T t,v and  X  n T d,t , the topic distributions of posts  X  and the term distributions of topics  X  T in a similar manner.
Given a corpus of posts, D , after the JTF model calculates the facet distribution of posts  X  F and the term distributions of the two latent facets  X  F , we can classify the posts in D into personal or official ones as follows. 1. Given the term distributions for the two latent facets, 2. For each post d  X  D , the probabilistic distribution of We now present an e xtended j oint t opic f acet model called E -JTF. We observe that the posts from a feed are likely to show the same facet. The E-JTF model improves the JTF model by incorporating such an observation into its gener-ative process. Let  X  F = {  X  F e,f } | E | X | F | be the matrix where  X  e,f is the probability of any post in the feed e exhibiting the facet f and the row  X  F e is the probabilistic distribution of any post in e exhibiting all facets. The E-JTF model em-ploys the feed affiliations of posts. Let the feed containing a post d be e d . Now we present the generative process of the E-JTF model (see the plate annotation in Figure 1(b)). 1. For each facet f  X  F , draw  X  F f  X  Dirichlet (  X  F ); 2. For each topic t  X  T , draw  X  T t  X  Dirichlet (  X  T ); 3. For each feed e  X  E , draw  X  F e  X  Dirichlet (  X  F ); 4. For each post d  X  D , 1) Set  X  F d =  X  F e 2) Draw  X  T d  X  Dirichlet (  X  T ); 3) For each term in d , say w d,n ,
The E-JTF model differs from the JTF model in that i t enforces the same probabilistic distribution of exhibit-ing all facets to all the posts from a feed in its generative process (see step 4.1). We still draw a probabilistic dis-tribution of exhibiting all topics for each post, because the posts from a feed are composed by a blogger at different mo-ments and he/she may write about any topic. Intuitively, there may not be topical similarities among all the posts within a feed. The E-JTF model also involves the set of probabilities  X , each of which indicates the probability of a term in W acting as a facet term. We still utilize the classifier g ( Section 3.1). During the posterior inference, we want to obtain the topic distributions of posts  X  T , the facet dis-tributions of feeds  X  F and the term distributions of topics (facets)  X  T ( X  F ). To obtain these four distributions, we need to know the topic or facet assignments Z and the bi-nary variables R for all the terms in W . Again we leave out the derivation details and estimate the posterior distribu-tions of Z and R by the collapsed Gibbs sampling as below.  X  We provide some explanations of the probabilities above. The probability of a term w d,n (= v  X  V ) in a post d being assigned to a topic t has the same interpretation as the JTF mode (see Section 3.2). The probability of a term w d,n in a post d of a feed e d being assigned to a facet f is proportional to the product of three items: 1. The probability of w d,n acting as a facet term,  X  d,n 2. The smoothed ratio of the count of the occurrences of 3. The smoothed ratio of the count of the terms in the The probability of a term w d,n in a post d being assigned to a facet f in the E-JTF model is calculated differently from that in the JTF model. Such probabilities in both models are the products of three items where their items 3 are different. Specifically, the item 3 for the JTF model is the estimated facet distribution within a post d by the terms in d assigned to facets in previous iterations. However, the item 3 for the E-JTF model is the estimated facet distribution within a feed e by the terms in e assigned to facets in previous iterations. Note that the item 3 for the E-JTF model is due to the generative process of the E-JTF model where all the posts from a feed are given the same facet distribution. This results in that the estimated facet distributions of all the posts from a feed are similar.

After finishing sampling Z and R , we can obtain the facet distributions of posts  X  F and the term distributions for the two latent facets  X  F by the same way as the one in the JTF model (see Section 3.2). Then we can classify the posts by the same way as the JTF model (see Section 3.3) by using  X 
F and  X  F from the E-JTF model.
Experimental Setups . We evaluate our models by us-ing 8 TREC 2009 queries and 10 TREC 2010 queries that are required to be searched over the TREC Blogs08 collection. T REC Blogs08 collection is the only collection available for personal and official blog distillation. Each query is asso-ciated with a personal facet and an official facet. Given a query q , a faceted blog distillation method is required to re-trieve two rankings of feeds w.r.t. q , one ranking for each facet. The performance is evaluated by the TREC judg-ments for those queries. We evaluate the JTF and E-JTF models over three TREC baselines of feeds. Specifically, for each query q , we obtain a corpus of posts by pooling all the posts of all the unique feeds from the three TREC baselines w.r.t. q . We denote as TREC query corpus the corpus of posts for q . This produces 18 TREC query corpora. We apply the JTF model and the E-JTF model to a TREC query corpus, respectively. A model is effective and robust if its faceted performance constantly and significantly out-performs those of the three baselines. For both models, we gested in [3]. We set the number of topics | T | = 100 and the number of facets | F | = 2 for each TREC query corpus and run the samplers for both models for 1000 iterations. We employ the mean average precision (MAP), the R-precision (R-pref), the normalized discounted cumulative gain over all positions (NDCG) and the precision at top 10 posts (P10) as the evaluation measures. MAP is most important [10]. The personal (official) MAP measure means the MAP measure in terms of the personal (official) performance. The same applies to R-prec, NDCG and P10 too.

Experimental Evaluation . We first qualitatively eval-uate the JTF and E-JTF models. Specifically, we present the top (most representative) facet terms identified by both models. Due to space limit, we only present the facet terms identified by both models over the TREC query corpus w.r.t. an exemplified query,  X  drug safety  X . Table 1 shows the top facet terms identified by both models. We make bold some terms that are errors. Both models identify the representa-tive personal facet terms that consist of two categorizes: 1) the first person pronouns, such as  X  I  X  and the interjection  X  well  X , and 2) some (simple) verbs, such as X  think  X  and X  like  X  that are frequently used in personal posts. Intuitively, these representative personal facet terms are rarely used in official posts. However,  X  medical  X  is an adjective related to  X  drug safety  X , but our models erroneously identify it as a personal facet term. Both models also identify the representative of-ficial terms. These terms consist of four kinds: 1) some adjectives, such as  X  effective  X ; 2) some adverbs, such as  X  po-tentially  X ; 3) some nouns, such as  X  company  X  and  X  market  X ; and 4) some verbs, such as  X  develop  X  and  X  report  X . Intu-itively, these terms are more likely to be used in official posts than in personal posts. However, both models also identify some terms erroneously, some adjectives, such as  X  pharma-ceutical  X , and some nouns, such as  X  FDA  X . These terms are related to the query, not general official facet terms.
We then evaluate the classifier that determines whether a term in a post acts as a topical term or a facet term. In practice, we use the terms from the TREC queries as the typical topical terms. Since we only have 18 queries, we can only collect 37 typical topical terms. After obtaining these typical topical terms, we collect the contextual sentences for them. Specifically, given a query q , we get all the posts that satisfy the following two conditions: 1) they are from the personal or official feeds w.r.t. q indicated by the TREC judgments; 2) they contain q . The posts satisfying these Table 1: Top Facet Terms Identified by JTF and E-J TF over TREC Query Corpus w.r.t.  X  X rug safety X .

Table 2: Facet and Topical Term Classification. t wo conditions are likely to be relevant to q and the terms of q in such posts are likely to be topical terms. There are about 110K sentences from these selected posts that con-tain at least one term of q as the topical training examples. We employ the proposed STFT method (see Section 3.1). The STFT method selects 1021 typical facet terms. We randomly select about 110K sentences containing these typ-ical facet terms as the facet training examples. We deliber-ately keep the training data balanced. We use the decision tree classifier in the Weka package 4 and conduct a 10-fold cross validation over the training data. Table 2 shows the average classification performance in Precision, Recall and F1-measure. Our classifier can separate topical terms from facet terms with a reasonable accuracy.

Note that we use the query terms as typical topical terms for training, so we build two classifiers and use them in the sequential experiments. Specifically, we test the TREC 2010 queries by using the classifier that is trained over the training examples for the TREC 2009 queries and vice versa.
Now we evaluate the faceted performance of both mod-els. Specifically, we re-rank the feeds from each baseline by addressing their topical relevance to the queries and their extents of exhibiting a facet. This re-ranking process pro-duces two rankings of feeds, one for the personal facet and the other for the official facet. To rank feeds by each model, we first calculate the facet scores of posts in feeds by that model and then aggregate the facet scores of posts to those of feeds. We adopt the method proposed in [5] to obtain the facet scores of feeds. An aggregated score of a feed f , AS k ( f ), combines the IR score of f , IR ( f ) and its facet score where IR ( f ) is provided by the TREC baselines and the pa-rameter  X  is empirically learned in the following manner. The specific value of  X  that optimizes the faceted ranking performance for the TREC 2009 queries are used for the TREC 2010 queries and vice versa. All feeds are ranked in descending order of their aggregated scores.

We also compare both models with the LDA model [1] over the three baselines. Specifically, for each baseline, we use the LDA model to re-rank the feeds from the baseline in descending order of their topical relevance to the TREC queries. Note that the LDA model cannot measure the facets of feeds. It just calculates the IR scores of posts w.r.t. queries. Please refer to [14] for the details of such a cal-culation. Then we aggregate the IR scores of feeds by those of their posts and re-rank the feeds. We set up the LDA model X  X  priors:  X  T = 50 | T | ,  X  T = 0 . 1 as in [3] and | T | = 100. h ttp://www.cs.waikato.ac.nz/ml/weka/
Table 3 shows the faceted performance of the LDA model, the JTF model and the E-JTF model over three TREC base-lines (namely baselines1-3). Several observations are made. First, both the JTF and E-JTF models constantly outper-form the three TREC baselines in the mean faceted perfor-mance, which shows them robust and effective. Second, the JTF model shows significantly better performance than the LDA model in the mean personal performance. It shows de-cent improvements over the LDA model in the mean official MAP, R-prec and NDCG and a slightly deterioration in the mean official P10 performance. Third, the E-JTF model dis-plays significantly better performance than the LDA model in almost all the mean faceted performance except that a slight improvement over the LDA model in the mean offi-cial P10. These two observations show that both models are more effective than the LDA model. Four, the E-JTF model outperforms the JTF model in the mean faceted per-formance. The superiority of the E-JTF model to the JTF model validates the observation that all the posts from a feed are likely to have the same facet.

We also compare our best results achieved by the E-JTF model with the results achieved by the state-of-the-art meth-ods. Specifically, we compare our E-JTF model with the  X  X itFeeds X  X uns [15], the X  X exMIRuns X  X uns [7] and the X  X IOPFT X  runs [5]. All their results are reported by using the same test-ing benchmarks as ours: both TREC 2009 and TREC 2010 queries over the three TREC baselines. We compare our best results obtained by the E-JTF model with their results in terms of both faceted MAP performance. Table 4 shows the comparison of our results with the best-known results ob-tained by the three methods described above. We observe that the E-JTF model consistently and significantly outper-forms all the best-known results in both faceted performance over all three baselines. These improvements demonstrate our E-JTF model is robust and effective.
We proposed two models that discover the topics and the personal and official facets of blog posts. Both mod-els are supplemented by a classifier that separates topical terms from facet terms in posts during the posterior infer-ence. Moreover, we observed and validated an important characteristic for personal and official blog distillation that all the posts from a feed are likely to exhibit the same facet. One of our two models considers such a characteristic in its generative process. We evaluated both models by the TREC 2009 and TREC 2010 queries over the TREC Blogs08 collec-tion. Experimental results demonstrated the effectiveness of both proposed models. The results obtained by our second model outperform the best-known results.

