
Two clustering algorithms that are popular for their sim-plicity and flexibility are K-means [2] and expectation m~LX.-imization (EM) [1]. Both methods have been studied ex-perimentally on many problems and have been used widely in applied settings. Here we review the algorithms briefly, note their key similarities, and show how their differences suggest a more general clustering framework. 
The K-means algorithm represents each class by a cen-troid, which it computes by taking the mean for each at-tribute over all the instances belonging to that class. In geometric terms, this corresponds to finding the center of mass for the cases associated with that class. Data reas-signment involves assigning each instance to the class of the closest centroid. 
In contrast, EM models each class by a probability distri-bution that it extracts from the training data in the class model creation step. If the data are continuous, each class is generally modeled by an n-dimensional Gaussian distribu-tion that consists of a mean and variance for each attribute. In the discrete case, P(aj = vjllck) is extracted for each possible combination of class ck, attribute aj, and attribute value vjt. In both cases, when finding these parameters, the contribution of each instance xl is weighted by P(c~[xi). Data reassignment is done by recalculating P(ck [xi) for each instance xi and class c~ using the new class models. 
Although both of the above clustering algorithms incor-porate iterative optimization, they employ different meth-ods for developing class models. Thus, we can view them as invoking a different supervised learning technique to dis-tinguish among the classes. The two algorithms also differ in how they assign instances to classes: K-means assigns each instance to a single class, whereas EM uses partial as-signment, in that each instance is distributed among the classes. We will refer to the absolute method as the "strict" paradigm and to the partial method as "weighted". 
These observations lead to a general framework for clus-tering that involves selecting a supervised learning algorithm and selecting one of these assignment paradigms. In the context of K-means and EM, this framework immediately suggests some variants. By using the weighted paradigm with the K-means classifier, we obtain a weighted K-means algorithm. Similarly, combining EM's probabilistic classi-fier with the strict paradigm produces a variant in which each instance is assigned entirely to its most probable class. This variant has been explored under the name of "strict-assignment EM", although the partial assignment method is more commonly used. 
Although the classifiers utilized in K-means and EM can be easily modified to operate with either assignment method, other supervised algorithms can require more sophisticated adaptations, as we will see shortly. 
As we have argued, it should be possible to embed any su-pervised learning method within our generalized clustering framework. However, our evaluation has focused on four simple induction algorithms that have limited representa-tional power [6], because the clustering process itself alms to generate the disjoint decision regions that more power-ful supervised methods are designed to produce. Below we 
Another simple induction method, the perceptron algo-rithm [12], also combines evidence from attributes during classification, but uses the expression to assign a test case to the positive (1) or negative (0) class. Each weight w,~ specifies the relative importance of an at-tribute m; taken together, these weights determine a hyper-plane that attempts to separate the two classes. The learn-ing algorithm invokes an error-driven scheme to adjust the weights associated with each attribute. 1 Because a percep-tron can only differentiate between two classes, we employed an ordered list of perceptrons that operates much like a deci-sion list. The algorithm first learns to discriminate between the majority class and others, generating the first percep-tron. Instances in the majority class are removed, and the system trains to distinguish the new majority class from the rest, producing another perceptron. This process continues until one class remains, which is treated as a default. 
Although the perceptron traditionally assumes all-or-none assignment, it seems natural to interpret the scaled differ-ence between the sum and the threshold as a likelihood. The weighted variant multiplies the update for each attribute weight by the weight for each instance, so that an instance with a smaller weight has a smaller effect on learning. To prevent small weights from causing endless oscillations, it triggers an updating cycle through the data only if an in-correctly classified instance has a weight of greater than 0.5, although all instances are used for the actual update. 
In reassignment, the weighted method calculates the dif-ference between the instance value and the threshold, scaled by the sigmoid which produces bounds on the weight size. If an instance were evaluated as being perfectly at the threshold, the func-tion would return 0.5. The factor 5 in the exponent of e distributes the resulting weights over a larger range, so the algorithm will not give a weight close to 0.5 for all instances. 
Otherwise the sigmoid is not tight enough to be useful for a generally small range of values. decision-stump induction (e.g., Holte [4]), which differs from the others in selecting a single attribute to classify instances. 
To this end, it uses the information-theoretic measure where freq(e~, S) is the frequency of class ck in a training set S with ICI classes. If the attribute is continuous, the algorithm orders its observed values and considers splitting between each successive pair, selecting the split with the highest score. The method applies this process recursively to 1For the purposes of this study, we used a learning rate of 0.05 and 50 iterations through the training data, which did well on all our classification tasks. Table 1: Supervised accuracies on four data sets. Promoters 86.0 87.0 76.0 70.0 Iris 49.3 94.7 46.0 93.3 Hayes-Roth 32.3 61.5 79.2 43.1 Glass 84.8 79.0 39.0 97.6 class of its majority population. For example, if a given cluster consists of 30 instances that are actually class A and 10 that are actually class B, all instances in the cluster will be declared members of class A, with an accuracy of 75% for that cluster. This approach loses detail, but it let us evaluate each clustering algorithm against the "correct" clusters. We selected four data sets from the UCI repository -Pro-moters, Iris, Hayes-Roth, and Glass -that involved different numbers of classes (two to seven), different numbers of at-tributes (five to 57), and different attribute types (nominal, continuous, or mixed). Another factor in their selection was that each led to high classification accuracy for one of the supervised methods but (typically) to lower accuracy for the others, as shown with bold font in Table 1. This differen-tiation on supervised training data seemed a prerequisite for testing the predicted correlation between accuracies for supervised learning and clustering. Moreover, remember that our four supervised methods each has restricted representational power that is generally limited to one decision region per class. As a result, the fact that one such method obtains high accuracy in each of these domains suggests that each of their classes maps onto to a single cluster. This lets us assume that the number of classes in each data set corresponds to the number of clus-ters, further increasing the chances of meaningful results. For each data set, we collected a learning curve using ten-fold cross-validation, recording results for each increment of 25 data points. Typically, clustering accuracy ceased to improve early in the curve, although the supervised accuracy often continued to increase. The results we report here all involve accuracy as measured at the last point on each curve. 
Table 2: Unsupervised accuracies for two alternative data assignment paradigms (strict/weighted). Promoters 62.0/77.0 52.0/41.0 49.0/57.0 19.0/26.0 Iris 27.3/51.3 83.3/88.0 26.7/32.0 55.3/53.3 Hayes-Roth 37.7/39.2 30.0/40.0 38.5/38.5 34.6/36.2 Glass 84.8/51.0 44.8/61.9 26.2/34.3 77.1/74.3 Recall that our first hypothesis predicted each supervised method would construct more accurate clusters when com-bined with its preferred data assignment paradigm. The results in Table 2, which shows the classification accura-cies for each method-paradigm combination on the four do-mains, disconfirms this hypothesis. In general, each super-vised algorithm sometimes did better with one assignment scheme and sometimes with the other, depending on the do-main. Both naive Bayes and the prototype learner showed univariate decision trees to operate on unsupervised data and thus generate taxonomy, and, more recently, Langley [611 and Liu et al. [9] have described similar but more sophisti-. cared approaches. The relationship between supervised and unsupervised algorithms for rule learning is more transpar--ent; Martin [10] has reported one approach that adapts su-pervised techniques to construct association rules from unla.-beled data. But again, such research has focused on specific algorithms rather than on general or generative frameworks. 
However, other areas of machine learning have seen a few frameworks of this sort. Langley and Neches [7] developed PRISM, a flexible language for production-system architec-tures that supported many combinations of performance and learning algorithms, and later versions of PRODIGY [14] in-cluded a variety of mechanisms for learning search-control knowledge. For classification problems, Kohavi et al.'s [5] MLC++ supported a broad set of supervised induction al-gorithms that one could invoke with considerable flexibility. The generative abilities of MLC++ are apparent from its use for feature selection and its support for novel combina-tions of existing algorithms. This effort comes closest to our own in spirit, both in its goals and its attempt to provide a flexible software infrastructure for machine learning. 
In this paper, we presented a framework for iterative op-timization approaches to clustering that lets one embed any supervised learning algorithm as a model-construction com-ponent. This approach produces some familiar clustering techniques, like K-means and EM, but it also generates some novel methods that have not appeared in the literature. The framework also let us evaluate some hypotheses about the relation between the resulting clustering methods and their supervised modules, which we tested using both natural and synthetic data. 
Our first hypothesis, that each supervised method had a preferred data assignment scheme with which it produced more accurate clusters, was not borne out the experiments. Clustering practitioners can continue to combine prototype learning with strict assignment (giving K-means) and naive Bayes with weighted assignment (giving EM), but we foumt no evidence that these combinations are superior to the al-ternatives. However, our experiments did support our sec-ond hypothesis by revealing strong correlations between the accuracy of supervised algorithms on natural data sets and the accuracy of iterative optimizers in which they were em-bedded. We augmented these results with experiments on synthetic data, which gave us control over decision regions and separation of clusters. These studies also produced pos-itive correlations between supervised and unsupervised ac-curacy, but failed to reveal an effect of cluster separation. 
Clearly, there remains considerable room for additional research. The framework supports a variety of new clus-tering algorithms, each interesting in its own right but also important for testing further our hypotheses about relations between supervised and unsupervised learning. We shouht also carry out experiments with synthetic data that vary systematically other factors that can affect predictive accu-racy, such as irrelevant features and attribute noise. Finally', we should explore further the role of cluster separation and the reason it had no apparent influence in our studies. 
Although our specific results are intriguing, we attach more importance to the framework itself, which supports 
