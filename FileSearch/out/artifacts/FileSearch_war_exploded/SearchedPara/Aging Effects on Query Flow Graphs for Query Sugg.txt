 World Wide Web content continuously grows in size and importance. Furthermore, users ask Web search engines to satisfy increasingly disparate information needs. New tech-niques and tools are constantly developed aimed at assisting users in the interaction with the Web search engine. Query recommender systems suggesting interesting queries to users are an example of such tools. Most query recommendation techniques are based on the knowledge of the behaviors of past users of the search engine recorded in query logs.
A recent query-log mining approach for query recommen-dation is based on Query Flow Graphs (QFG). In this paper we propose an evaluation of the effects of time on this query recommendation model. As users interests change over time, the knowledge extracted from query logs may suffer an aging effect as new interesting topics appear. In order to validate experimentally this hypothesis, we build different query flow graphs from the queries belonging to a large query log of a real-world search engine. Each query flow graph is built on distinct query log segments. Then, we generate recommen-dations on different sets of queries. Results are assessed both by means of human judgments and by using an automatic evaluator showing that the models inexorably age.
 H.2.8 [ Database Management ]: Database Applications -Data Mining ; H.4.3 [ Information Systems Applica-tions ]: Communications Applications Algorithms Query Flow Graph, Query Suggestion, Topic Drift, Aging Effects, Effectiveness in Query Recommendations
In the last years, all web search engines have started to provide users with query suggestions to help them to quickly satisfy their needs. One of the main difficulties users find when they use a web search engine, is correctly formulat-ing their needs in a short text query. Translating human thoughts into a concise set of keywords is in fact not straight-forward. Doing the opposite, i.e., translating a few keywords back into a human information need is even more difficult. Query recommendation techniques are based on the knowl-edge of the behaviors of past users of the search engine.
A successfully query-log mining approach for generating useful query recommendation based on Query Flow Graphs (QFGs) [2], was recently proposed in [3]. The QFG model aggregates information in a query log by providing a markov-chain representation of the query reformulation process fol-lowed by users trying to satisfy the same information need. This paper aims at extending the QFG model by provid-ing a methodology for dealing efficiently with evolving data. The interests of search engine users change in fact over time. New topics may become bursty popular, while others that focused for some time the attention of crowds can suddenly lose importance. The knowledge extracted from query logs can thus suffer an aging effect, and the models used for rec-ommendation rapidly becoming unable to generate useful and interesting queries.

In order to validate our claims and assess our methodol-ogy, we build different query flow graphs from the queries belonging to a large query log of a real-world search engine, and we analyze the quality of the recommendation models devised from these graphs to show that they inescapably age.

The paper is organized as follows. Section 2 discusses re-lated works, while Section 3 introduces the concept of query flow graph. The data used for the experiments are described in Section 4, while their analysis finalized to the evaluation of aging effects on the recommendation models is discussed in Section 5. Finally, Section 6 draws some conclusions and outlines future work.
Different approaches have been proposed in recent years that use query logs to mine wisdom of the crowds for query suggestion. Bruno et al. in [4] use an association rule mining algorithm to devise query patterns frequently co-occurring in user sessions, and a query relations graph including all the extracted patterns is built. A click-through bipartite graph is then used to identify the concepts (synonym, specializa-tion, generalization, etc.) used to expand the original query. Jones et al. in [6] introduce the notion of query substitu-tion or query rewriting, and propose a solution for sponsored search. Such solution relies on the fact that in about half ses-sions the user modifies a query with another which is closely related. Such pairs of reformulated queries are mined from the log and used for query suggestion. Baeza-Yates et al. [1] use a k-means algorithm to cluster queries by consider-ing both topics and text from clicked URLs. Then the clus-ter most similar to user query is identified, and the queries in the cluster with the highest similarity and attractiveness (i.e. how much the answers of the query have attracted the attention of past users), are suggested.
A Query Flow Graph ( QFG ) is a compact but powerful representation of the information contained in a query log. It has been applied successfully to model user interactions with a web search engine and for a number of practical appli-cations as segmenting physical sessions into logical sessions or query recommendation. In this Section we briefly recall some practical steps to infer a QFG from a query log.
Boldi et al. in [2] define a Query Flow Graph ( QFG ) as a directed graph G = ( V,E,w ) where:
Each query is represented by a single node independently of its frequency, or of the number of distinct users who issued it. The two special nodes s and t capture respectively the beginning and the end of a chain. The Query Flow Graph is built according to the algorithm presented by Boldi et al. in [2].
Our experiments have been conducted on the AOL query log. The AOL data-set contains about 20 million queries issued by about 650 , 000 different users, submitted to the AOL search portal over a period of three months from 1st March, 2006 to 31st May, 2006. To assess the aging effects we conducted several experiments to evaluate the impact of different factors. The log has been split into three different segments . Two of them have been used for training and the third one for testing. The three segments correspond to the three different months of users activities recorded in the query log. We fixed the test set  X  i.e. the set of queries from which we generate recommendations  X  to be the queries submitted in the last month. Table 1 shows the number of nodes and edges of the different graphs corresponding to each query log segment used for training: Table 1: Number of nodes and edges for the data-graphs corresponding to the two different training segments.

It is important to remark that we have not re-trained the classification model for the assignment of weights associated with QFG edges. We reuse the one that has been used in [2] for segmenting users sessions into query chains 1 . Once the QFG has been built, the query recommendation methods are based on the probability of being at a certain node after performing a random walk over a query graph. This ran-dom walk starts at the node corresponding to the query for which we want to generate a suggestion. At each step, the random walker either remains in the same node with a prob-ability  X  , or it follows one of the out-links with probability equal to 1  X   X  ; in the latter case, out-links are followed pro-portionally to w ( i,j ). In all the experiments we computed the stable vector of the random walk on each QFG by using alpha = 0 . 85. Actually, the stable vector is computed ac-cording to a Random Walk with Restart model [8]. Instead of restarting the random walk from a query chosen uniformly at random, we restart the random walk only from a given set of nodes. This is done by using a preference vector v , much in the spirit of the Topic-based PageRank computation [5], defined as follows. Let q 1 ,...,q n be a query chain ( q most recently submitted query). The preference vector v is defined in the following way: v q = 0 for all q /  X  q 1 ,...,q and v q i  X   X  i .  X  is a weighting factor that we set in all of our experiments to be  X  = 0 . 90.
The main goal of this paper is to show that time has some negative effects on the quality of query suggestions gener-ated by QFG-based models. It is also worth remarking that we can safely extend the discussion that follows also to sug-gestion models different from QFG-based ones. As a matter of fact, the presence of  X  bursty  X  [7] topics could require fre-quent model updates whatever model we are using. To val-idate our hypothesis about the aging of QFG-based models we have conducted experiments on models built on the two different segments according to the procedure described in the above section.

In order to assess the various reasons why a QFG-based model ages we have considered, for each segment, two classes of queries, namely F 1 , and F 3 , which respectively corre-spond to queries having a strong decrease and a strong in-crease in frequency. F 1 is the set of the 30 queries that are among the 1,000 most frequent queries in the first month ( M 1 ) but whose frequency has had the greater drop in the last month covered by the query log ( M 3 ). Conversely, F is the set of the 30 queries among the 1,000 most frequent queries in the test log M 3 whose frequency has the greater
We thank the authors of [2] for providing us their model. drop in the first part of the log M 1 . Actually, to make the assessment more significant, we do not include queries that are too similar, and we do not include queries containing domain names within the query string. Figure 1 graphically show where the selected queries for each class fall when we plot the popularity of the top-1000 most frequent queries in M 3 by considering query ids assigned according to frequen-cies in M 1 . Figure 1: Queries in F 3 . The set of top 1,000 queries in M 3 compared with the same set projected on M 1 . Query identifiers are assigned according to frequen-cies in M 3 . The circled area in the plot highlights the zone from where F 3 was drawn.

Some examples of queries in F 1 are:  X  shakira  X ,  X  ameri-canidol  X ,  X  nfl  X . Some other examples of queries in F 3  X  mothers day gift  X ,  X  memorial day  X ,  X  da vinci code  X . The queries are related to particular events in March 2006, for instance singer Shakira in March 2006 released a music al-bum, and in May 2006 the movie adaptation of the popular book  X  X a Vinci Code X  was published.

We selected two distinct sets because we want to assess the effectiveness of recommendations for both new or emerg-ing query topics in the test log (i.e. queries in F 3 ), and for queries that are frequent in the first month but poorly repre-sented (or absent) in the test month (i.e. queries in F 1 first evaluation we perform is a human-based assessment of the quality of query suggestions generated by models trained on the two different segments. From each query in F 1 and F 3 we generated the top 20 recommendations using four dif-ferent sets of QFG-based models: three of them are filtered with different threshold values (0.5, 0.65, and 0.75), one is generated without filtering (threshold 0). Each set consists of QFGs built on either M 1 , or M 2 . The generated recom-mendations were manually evaluated and classified as useful and not useful . We consider useful a recommendation that undoubtedly interprets the possible intent of the user better than the original query.

Table 3 shows the results of the human assessment per-formed by counting, for each query and the three different threshold levels, the number of useful suggestions. We av-eraged the counts over all the queries evaluated. For each training period we show the average number of useful sug-gestion for queries in the three different groups, i.e. F and F 1  X  X  3 .
 From the table we can draw some interesting conclusions. First, the performance of the models built from M 1 M 2 are quite similar (column F 1  X  X  3 ). This might seem filtering threshold Table 3: Model aging statistics varying the model type and the temporal window. Results were man-ually assessed. Best results are represented in bold typeface. a counterexample to the hypothesis that the models age. Actually, by breaking down the overall figure into separate figures for F 1 and F 3 we can observe that for all the queries in F 3 the suggestions built from M 2 are more useful than those built on M 1 . Furthermore, by inspecting some of the suggestions generated for the queries shown in Table 2, it is evident that some of the suggestions are  X  fresher  X  (i.e. more up-to-date) in the case of a model built on M 2 than those obtained on models built on M 1 . This is particularly true for queries in F 3 .

When we performed the assessment of the suggestions we noted a phenomenon regarding the scores computed on the different QFGs by the random walk-based method. Let us consider again the results shown in Table 2 and let us look at the suggestions, with the relative scores, computed for 6 queries (3 queries from F 1 and 3 queries from F M 1 and M 2 . As we go further down the list sorted by score, when the quality of the suggestions starts to degrade, we often observe that the useless suggestions are associated with the same low score values, e.g.  X  regions banking  X ,  X  aol email only  X ,  X  adultactioncamcom  X  are three different (and useless) query suggestions for the query  X  harley davidson  X  whose QFG computed score is always 1394.

From the above observation we make the following hy-pothesis that we will use to derive an automatic evaluation methodology to assess the  X  X sefulness X  of suggestions:
A QFG-based recommender system recommends queries by computing a random walk with restart on the model. At each step, the random walker either remains in the same node with a probability  X  , or it follows one of the out-links with probability equal to 1  X   X  . Out-links are followed pro-portionally to w ( i,j ). Let us suppose the recommender sys-tem start recommending more than k queries sharing the same score for the given query q . On the QFG model it means that the query q has more than k out-links sharing the same probability ( w ( i,j )). Due to the lack of informa-tion the system is not able to assign a priority to the k recommended queries. This is the reason why we consider these recommendations as  X  X seless X . This heuristic considers useful k query recommendations if the suggestions following the top-k recommended queries have equal scores associated with them. Consider again the case of the query  X  X arley davidson X , we have six queries with different scores and then the remaining queries (for which the associated scores are equal) are clearly useless. recommendations are taken from different query sets.
We perform the automatic analysis described above to the 400 most frequent queries in the third month for which recommendations were generated on models built on either M 1 or M 2 . For all the experiments we set k = 3. Table 4 shows that according to this measure of quality filtered mod-els works better than unfiltered ones. The filtering process reduces the  X  X oise X  on the data and generates more precise knowledge on which recommendations are computed. Fur-thermore, the increase is quite independent from the thresh-old level, i.e. by increasing the threshold from 0 . 5 to 0 . 75 the overall quality is, roughly, constant. Table 4: Recommendation statistics obtained by us-ing the automatic evaluation method on a relatively large set of 400 queries drawn from the most fre-quent in the third month.

We further break down the overall results shown in Table 4 to show the number of queries on which the QFG-based model generated a given number of useful suggestions. To highlight more the aging effect we show in Figure 2 the total number of queries having at least a certain number of useful recommendation. For example, the third bucket shows how many queries have at least three useful suggestions. For each bucket, results for M 2 are always better than the ones for M 1 . Furthermore, for Figure 2 we can observe that a model trained on M 2 has a larger percentage of queries for which the number of useful suggestions is at least 4. This confirms our hypothesis that QFG-based recommendation models age.
In this paper we have studied the effect of time on recom-mendations generated using Query Flow Graphs [2] (QFGs). We have shown that the interests of search-engine users change over time and new topics may become popular, while other that focused for some time the attention of the crowds can suddenly loose importance. The knowledge extracted from query logs can thus suffer from an aging effect, and the models used for recommendations becoming unable to generate useful and interesting suggestions. Figure 2: Histogram showing the total number of queries having at least a certain number of useful recommendations. For instance the third bucket shows how many queries have at least three useful suggestions. Results are computed automatically. [1] R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query [2] P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, [3] P. Boldi, F. Bonchi, C. Castillo, D. Donato, and [4] B. M. Fonseca, P. Golgher, B. P X ossas, B. Ribeiro-Neto, [5] T. H. Haveliwala. Topic-sensitive pagerank. In In Proc. [6] R. Jones, B. Rey, O. Madani, and W. Greiner.
 [7] J. Kleinberg. Bursty and hierarchical structure in [8] H. Tong, C. Faloutsos, and J.-Y. Pan. Fast random
