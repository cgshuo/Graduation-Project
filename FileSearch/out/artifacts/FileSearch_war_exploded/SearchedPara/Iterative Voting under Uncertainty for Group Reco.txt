 Group Recommendation Systems (GRS) aim at recommending items that are relevant for the joint interest of a group of users. Voting mechanisms assume that users rate all items in order to identify an item that suits the preferences of all group members. This assump-tion is not feasible in sparse rating scenarios which are common in the recommender systems domain. In this paper we examine an application of voting theory to GRS. We propose a method to ac-curately determine the winning item while using a minimal set of the group members ratings, assuming that the recommender system has probabilistic knowledge about the distribution of users X  ratings of items in the system. Since computing the optimal minimal set of ratings is computationally intractable, we propose two heuristic algorithms that proceed iteratively that aiming atto minimizing the number of required ratings, until identifying a "winning item". Ex-periments with the Netflix data show that the proposed algorithms reduce the required number of ratings for identifying the "winning item" by more than 50%.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Human Factors, Experimentation
Group Recommender Systems (GRS) provide recommendations for groups of users and are applicable for domains where a group of people participate in a single activity. This paper addresses the recommendation of one item, a definite "wining item" (e.g., a TV show) while assuming that the preferences for the items are not known in advance. The necessary preferences are acquired during the recommendation process.

It is impractical to ask all members of the group for their pref-erences for all items. Some studies [3] deal with this challenge by computing the probabilities of the user preferences on candidate items and thus predict a probable winning item. We, on the other hand, assume that the distribution of the preferences of the users over the items is known and thus we compute the minimal set of re-quired references and query the users in order to identify a definite winning item. Unlike critique based GRS system [8], we ask the users to provide ratings of items rather than interactively critiquing critique on preferred features of the items. We propose to use a vot-ing mechanism as it allows users to rank possible items and choose a winning item that reflects their joint preferences. Specifically, we focus on Range voting in which users are asked to assign a rating within a specified range for the items. The ratings for each item are summed, and the item with the highest score is the winner. Range voting is relevant to many existing recommender systems applica-tions where users are asked to rate items within a specified range (e.g., Netflix). The voting mechanism discussed in this paper re-duces the number of user ratings required for reaching an accurate and definite recommendation.

In voting theory, it is possible to determine a winner by specif-ically requesting users for certain preferences rather than for their whole set of preferences. A key question is what partial informa-tion is essential for determining a winner. To cope with this chal-lenge we assume in this paper that the recommender system has probabilistic knowledge about the distribution of the group mem-bers preferences for the candidate items. For instance, in the case of friends wishing to watch a TV show together, the distribution can be inferred by rankings of these TV shows by similar users using collaborative filtering methods as illustrated in Section 6.
Computing the optimal minimal set of queries that are required to determine the winner is computationally intractable due to the combinatorial space of queries orders. Thus we propose two heuris-tic approaches to address this challenge. Both approaches proceed greedily and iteratively by querying a selected user about its rating for of a specific selected items.
Hazon et al. [4] assume predefined probability distribution of the ratings. They show theoretical bounds for the ability to cal-culate the probability of an outcome. However, while they focus on calculating the winning probability for each item, we focus on finding the winner using a minimal amount of queries.

Konczak et al. [6] address the case of partial information, where users do not set the preferences for all the items. They show how to compute the sets of possible winners and necessary winners. These sets determine which items no longer have a chance of win-ning and which are certain to win. We adopt their approach to propose a systematic preference aggregation protocol in which the users do not need to send their entire set of preferences. Walsh [9] surveys the computational complexity of possible and neces-sary winners in various voting rules. Walsh studies this problem by examining weighted or unweighted ratings and bounded or un-bounded items.
We may conclude that previous work in voting theory has ad-dressed voting in systems where users send partial information, but most existing studies and algorithms do not aim at reducing ratings. Furthermore, while most papers in this field propose theoretical analysis of solving a voting problem, we apply it to a realistic do-main and evaluate our algorithms empirically. As for related work in the GRS domain, most systems assume knowledge of the users X  preferences on the items [7] while some studies suggest effective methods to acquire them [5]. To our knowledge, only de Campos [3] is the deals with uncertainties in GRS and estimates the user preferences using Bayesian Netowrks. HeThey then computes an estimated recommended item while we compute a definite winner, i.e. a recommended item that certainly suits the preferences of the group. McCarthy et al. [8] is the only known study that assumes that the users X  preferences are not known. They apply the critique approach using case-based reasoning to acquire user preferences on desired items features, until they can infer the winning item that fits the set of desired features values. Such a system requires analysis and maintenance of items features which is not always feasible.
Let us formalize a voting system with a rating distribution; a distribution of the users X  preferences over the items. Let us refer stands for the lowest value and d max denotes the highest value. User v i  X  X  preferences are represented by a rating function  X  D that assigns a value d l  X  D to every item c j  X  C .
In our model we assume that the recommender system knows the probability distribution of the users X  preference over domain D for each item. Formally: random variable that represents the rating of user v i over the item c j . c j i is distributed according to some Rating Distribu-all the rating distributions of the users X  rating for the items.
Since we use Range voting, we can assume independence be-tween the probability distributions of the user X  X  preferences for the items. While the independence assumption is a naive one, it can be used for approximating the actual probability. Note that the pre-cise probability value is not required if we can still sort the queries correctly according to their informativeness. In closely related do-mains, such as machine learning, a similar naive assumption is known to provide accurate classification although the independence assumption is not always true.

In the example presented in Table 1, we show the rating distribu-tion of three users for two items over a domain of f 1 ; 2 ; 3 the probability that v 1 will assign rating 1 to item c 1
Based on the rating distribution settings, we can determine the winner with some probability. To set a definite winner, the system must disambiguate the accurate users X  rating over the items. For this, we explicitly query the user. q j i represents the query of user v for its rating for item c j . We assume that the user is sincere regarding her response.
 A query has a cost denoted by the function cost : q  X  R . Throughout this paper we assume that the cost is equal for all queries. Fortunately, it may not be necessary to query the users about the whole set of items in order to determine the winner. It is possible to conclude who the winner is from partial information about the users X  ratings [6, 9], although in the worst case each user should submit all its preferences [2]. To guarantee a winner with minimum cost, we proceed in rounds. In each round one user needs to rate one item. Following that, we determine the next query. Thus the total cost is minimized.

To determine whether a partial set of user ratings suffices for set-ting the winner, we use the necessary winner set [6]. The necessary winners set contains the items that win in all complete extensions of the partial preference relations among the items. It is sufficient to generate only the extensions that provide the most optimistic (pos-sible maximum aggregated rating) and pessimistic (possible mini-mum aggregated rating) scenarios. Then, a necessary winner is an item whose minimum aggregated rating is greater than the maxi-mum aggregated rating of all the others.

In Range voting, the pessimistic value (possible minimum) of a item is the lowest bound of the range. The optimistic value (possible maximum) is the upper bound. To formalize , let v set of O i sets. The function pmax A ( c j ; O A ) computes the possible maximum of item c j , based on the preference values of the users:
D EFINITION 2. [Range voting Possible Maximum]
Similarly, we define a function of the possible minimum of an item:
D EFINITION 3. [Range voting Possible Minimum]
Now we can define the necessary winner. For this definition we define the set C t  X  C which contains the items that have been sent by any user after t querying rounds: C t = { c | X  c; d  X  i rating is greater than the maximum aggregated rating of all the oth-ers: D EFINITION 4. [Necessary Winner]
Given a set of users V , a set of items C and probability distri-bution of users X  rating for the items VD , our goal is to determine a querying policy which minimizes the number of ratings that should be provided by the users in order to determine the winner.
This challenge can be represented as a Markovian decision pro-cesses (MDP). An MDP model is a tuple of states, actions, transi-tion function from state to state by an action, and a reward func-tion. In our problem, the states are the possible combinations of the users X  ratings for the items. Every user can assign j values to item c i . If a user has not been assigned any value yet, the current value of the item is unknown. Thus, the combination space is | D | +1) nm , where n is the number of users and m is the number of items. The actions are the possible queries, where a query is sent to a specific user about a single item X  X  value. Thus the queries space is nm . The transition function between two states is affected by the probability distribution of the ratings of the item about which the user has made a query . The reward is the negative query costs. The policy is to determine which query to choose on each iteration.
Dynamic programming methods as Value Iteration or Policy It-eration [1] can compute the optimal queries vector by finding the optimal Policy. . However, these methods grow polynomially in the number of states and actions. In our case the state space itself is ex-ponential and dynamic programming is not suitable for such large settings. Thus, we present in the next sections heuristic approaches that compute the next query greedily.
The information gain approach uses a greedy calculation in order to select the best query. In this approach we calculate the informa-tion gain of each query among the m n possible queries, and choose the query that maximizes the gain. The information gain of a specific query is the difference between the prior probability distribution of the items to win and the posterior distribution of the items given the possible responses to the query. To calculate the distribution of the items to win, we define a winning item as a dis-crete random variable:
D EFINITION 5 (W INNING I TEM ). A Winning Item W C is a discrete random variable over the item set C , where P r ( W C = c is the probability of item c i to win.
 The steps for the calculation of the information gain of each query: 1. Compute the probability of each item to win ( W C ). 2. Calculate the entropy of W C ( H ( W C ) ). 3. For each possible query q j i : a. Calculate the entropy of W C given q j i ( H ( W C j q b. Calculate the information gain achieved by q j i . 4. Select the query that maximizes the information gain.
To compute P r ( W C = c i ) , we sum the probabilities of the cases in which the aggregated rating of c i is greater than the aggregated rating of the other items. Recall that P r ( c is the probability that the aggregated rating of c i is equal to s . Due to the independence of probabilities, the probability of c to win with a aggregated rating s is the product of the probabil-ity that the aggregated rating of c i is s and the aggregated rat-ing of the other items is at most s 1 . To calculate P r ( c s ) , we use a dynamic programming algorithm. P r ( c i = s ) = sented in the first three rows of Table 2 (based on the V D presented in Table 1). For instance, to calculate P r ( c 1 = 6) based on the rat-ings of all the three users (sixth column in line one, 0.236), we use the probabilities that were computed in columns 3 X 5 in the second line. These are the probabilities that c 1 = s for s 2 f 3 ; 4 ; 5
Based on Table 2, it is easy to calculate P r ( c 1 s ) by aggregat-ing the results of the first row, as presented in the fourth row. The probability that a certain item c i is a winner with a certain aggre-with a certain aggregated rating s is presented in the last row of the table. For instance, the probability that c 1 is the winner with a aggregated rating of 5 , is the probability that its aggregated rating is 5 and the aggregated rating of c 2 is at most 5 : 0 : 182 0 : 492 = 0 : 089 . Finally, the probability that a certain item c i culate the probability of c 1 to win in Table 2, we aggregate its prob-ability to win over the possible ratings of s (last line in table 2). In our example P r ( W C = c 1 ) = 0 : 727 . Ties are broken according to the item positions according to an increasing order of all items.
To calculate the information gain ( IG ) of a certain query, we calculate the entropy reduction of W C that is achieved the equation ( H ( W C | c i j = d g )) represents the entropy of W C given the possible values by querying user v i about item c j . The calcula-tion of W C | c i j = d g is processed exactly as described above based
To calculate the weighted average of the entropy we multiply the entropy by the probability of the random variable P r ( c reduced side in the equation). arg max example, querying user v 2 about c 2 generates the maximum infor-mation gain. To conclude, the algorithm iterates until a necessary winner is found.

The complexity of this algorithm is affected by the dynamic programming algorithm that computes the probability that c ability for all items ( m ) and ratings ( n j D j ) for every users ( n ). This is done by going through the possible ratings | ) . This dynamic algorithm is implemented for every possible query of the users over the items ( mn j D j ). Thus the worst case
The highest expected maximum heuristic is based on the explo-ration vs. exploitation tradeoff. As mentioned above, a necessary winner is an item whose possible minimum is greater than the pos-sible maximum of the other items.

We propose a heuristic which chooses its next query by consid-ering the item that has the possible maximum and the user that is expected to maximize the rating of that item. Using this ap-proach, we encourage a breadth exploration over the items since the less information we have about an item X  X  rating the higher pos-sible maximum it has. In addition, we exploit the preferences re-vealed in order: (1) to refrain from querying about items that have been proved as impossible winners (since their possible maximum is less than a minimum of another item); and (2) to further examine an item, that has the highest possible maximum, and might be a necessary winner.

Once the target item of the query is chosen we further choose the user that is to be queried about that item. Here again we choose the user that is expected to maximize the item X  X  rating by com-puting the expected rating using the rating distribution of that item. In particular, the expected rating of c j i based on the rating item c j we choose the user that maximizes the expected rating: arg max i ES ( V D j i ) . This process is repeated until a necessary win-ner is found.

The complexity of this algorithm is polynomial in the number of users, items and domain size. In order to select the item that is to be queried, we compute the possible maximum of each item which is O ( nm ) , to select which user to query we compute the expected rating of the users about the specific item which is O ( n the total complexity is O ( n ( m + | D | )) .
We compared the proposed methods in terms of the number of queries required for finding the necessary winner.
 We evaluated the performance of the (1) Dynamic Information Gain algorithm ( DIG ) and the (2) Expected rating algorithm ( ES ). The baseline for measuring the effectiveness of the proposed meth-ods is a random procedure ( RAN DOM ), in which the next query is randomly selected. We used the Netflix dataset to simulate real-world cases. Netflix provides a training data set of over 100 million ratings on a 1-5 scale as given by 480,000 users.

We extracted 5 different dense rating sub-matrices from Netflix. . Each sub-matrix contains 40 users (the group size) and 40 items for which all actual ratings are known. The selected movie of the group is the one that obtains the maximum sum of ratings. Our goal is to find this movie with a minimum number of queries.
In the Netflix domain, the actual ratings are known but the rat-ing distribution is unknown. Since we are interested in evaluating our algorithm using the rating distribution, we estimated the rating distribution of each user over an item by using simple user-to-user collaborative filtering with Pearson correlation. Collaborative fil-tering is commonly used to estimate a predicted rating by weight-ing the ratings of similar users (neighbours). In our case instead of weighting the ratings into a single predicted rating, we accumulate the neighbours X  weights which fall into each of the rating intervals: ( 1 ; 1 : 5) ; [1 : 5 ; 2 : 5) ; [2 : 5 ; 3 : 5) ; [3 : 5 ; 4 : 5) ; [4 : 5 ; ize the vector to obtain a proper probability distribution.
Figure 1 presents the results obtained for 5 different sub-matrices. The results indicate a clear superiority of ES and DIG on Random. On average, ES requires only 32% of 625 maximum queries to find the wining item and DIG requires 45%. While a random selection of queries requires 91%. From the perspective of interrupting the user, users were required for an average of only 8 items in ES and 11.3 in DIG rather than an average of 22.8 requests in the maximum scenario. This result fits the requirement of min-imizing the number of requests from the perspective of the human interface. The differences were found to be statistically significant with F(2,8)=53.48 and p &lt; 0 : 05 .

Figures 2 and 3 present the effect of the number of items/users where the number of users/items is fixed at 20 on the number of queries required. The results indicate that there is a clear corre-lation between the number of queries and the number of items or users. In all cases, the ES heuristic requires the least number of queries in all cases and the random method requires the largest number of queries.
 The differences were found to be statistically significant with F(2,14)=13.61 and p &lt; 0 : 05 for the number of items and F(2,14)=20.85 and p &lt; 0 : 05 for the number of users.
We presented incremental query-based algorithms to reduce the number of queries required to find the winner item when the proba-bility distribution of the users X  rates is known in advance or can be estimated. The DIG algorithm chooses the query that maximizes the information gain based on the entropy of the probability of the items to win. The ES algorithm selects the item that has the high-est possible maximum rating and queries the user that is expected to maximize the rating of that item. We showed that both methods sig-nificantly outperform a random selection of queries. Specifically, DIG reduced the necessary queries although its computational time complexity was found to be worse. ES was found to be a much more useful approach with negligible additional computational ef-fort. In the future we plan to further develop more anytime algo-rithms that do not necessarily guarantee the winner but guarantee the most likely item under bounded resources. [1] B ELLMAN , R. Dynamic programming treatment of the [2] C ONITZER , V., AND S ANDHOLM , T. Communication [3] DE C AMPOS , L., F ERN X NDEZ -L UNA , J., H UETE , J., [4] H AZON , N., A UMANN , Y., K RAUS , S., AND [5] J AMESON , A. More than the sum of its members: challenges [6] K ONCZAK , K., AND L ANG , J. Voting procedures with [7] M ASTHOFF , J. Group recommender systems: combining [8] M C C ARTHY , K., S ALAM X  , M., C OYLE , L., M C G INTY [9] W ALSH , T. Uncertainty in preference elicitation and
