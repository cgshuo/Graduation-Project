 Security of computer systems is essential to their acceptance and utility. Computer security analysts use intrusion detec-tion systems to assist them in maintaining computer system security. This paper deals with the problem of differenti-ating between masqueraders and the true user of a com-puter terminal. Prior efficient solutions are less suited to real time application, often requiring all training data to be labeled, and do not inherently provide an intuitive idea of what the data model means. Our system, called ADMIT, re-laxes these constraints, by creating user profiles using semi-incremental techniques. It is a real-time intrusion detection system with host-based data collection and processing. Our method also suggests ideas for dealing with concept drift and affords a detection rate as high as 80.3% and a false positive rate as low as 15.3%. 
Security of computer systems is vital to their utility and acceptance. It is maintained by monitoring audit logs. The ever-increasing size of these logs makes it mandatory for network administrators and security analysts to use spe-cific tools, called intrusion detection systems (IDS), to prune down the monitoring activity. According to the 2000 Com-puter Security Institute/FBI computer crime study, 85% of the 538 companies surveyed, reported an intrusion or exploit of their corporate data, with 64% suffering a loss [12]. Thus, IDS are becoming increasingly important. 
For an IDS to be powerful it must run continually, be adaptable to user behavior changes, be fault tolerant (i.e. crashes must not require retraining or re-learning of behav-ior), be impervious to subversion, be scalable, should impose minimal overhead, be configurable, and should show graceful degradation of service[19]. Other challenges to contend with *This work was supported by Pitney Bowes, Inc. tThis work was supported in part by NSF CAREER Award IIS-0092978, and NSF Next Generation Software Program grant EIA-0103708. permission and/or a fee. SIGKDD 02 Edmonton, Alberta, Canada Copyright 2002 ACM 1-58113-567-X/02/0007 ...$5.00. deavors include statistical-based methods such as IDES [5] and EMERALD [15], which create multi-level usage pro-files (i.e., at user or group levels). DuMouchel [6], created contiguous command sequence-based probability transition matrices, which serve as user profiles. Schonlau et al [18] test a variety of statistical methods for building user profiles. Clustering is an unsupervised learning technique, in which data is partitioned into meaningful subgroups called clusters based on some similarity measure. Prior efforts using clus-tering for intrusion detection include those by Portnoy [16] and Zamboni [22]. Portnoy used non-real-time clustering to group unlabeled network data and labeled them based on the assumption that the proportion of network data that is anomalous is very low. Zamboni observed that the dis-tribution of test points to clusters changes significantly at the time of attacks, which can be used as an indicator of anomalous behavior. The work most closely related to ours is that by Lane and 
Brodley [10, 11], who used both instance-based learning [1] (IBL) as well as Hidden Markov Models (HMM) techniques to create user profiles for user command data. Like our method, they too use clustering, however only for model scaling (i.e., limiting the number of sequences representing the user). The IBL approach by Lane [10] provides the ad-vantage that the class of a test point is based on the points most similar to it in the training database, rather than the similarity of all database points, thereby limiting problem complexity. Statistically-based anomaly-detection methods [16] often assume that anomalies form a very small propor-tion of audit data. But an intruder may use such "anoma-lous" sequences repeatedly, so that their frequency becomes high enough frequency to be labeled "normal". However, as the IBL approach is not statistically based, even a single labeled point is useful and using this ploy is futile. At the same time, a coincidence may result in contamination and hence expert supervision is essential. Also, since nearly all computation in IBLs takes place at run time, it is a slow alternative. Also, IBLs do not inherently provide a method of model scaling. 
Most of the IDS efforts, thus far, require substantial train-ing data, which must all be labeled. Also, the more success-ful efforts are less suited to real time application; the experi-
It is our belief that current IDS techniques are not sophis-
ADMIT is a user-profile dependent, temporal sequence clus-
Figure 1: ADMIT's Architecture: Training/Testing count as in Lane [10]. For example, the user sequence given above is converted to the following set of tokens T = {ti : = ps -ef. The notation &lt;n&gt; gives the number of arguments (n) of a command. For instance, the command vi tl.txt is tokenized as vi &lt;1&gt;, while vi t3.txt ~.txt as vi &lt;2&gt;. ProfileManager is the top-level module in ADMIT; it is responsible for the security of a terminal. It has a number of deputies, whose operations it configures, coordinates and decides. ProfileCreator, during training, creates profiles for users authorized to use the terminal. During testing, Pro-fileUpdater updates profiles for those users, while Sequence-
Examiner examines each sequence of tokens of process data and determines if that is characteristic or not, of the user thought to have produced it. Based on the decision, it takes action specified by the ProfileManager. The ProfileCreator and ProfileUpdater both use two sub-modules. FeatureSelector parses the source command data for a user, cleans it up by replacing argument names by num-converts it into tokens as described above. It then converts the token data from each session, into sequences of tokens, whose length is specified by the ProfileManager. Cluster-
Creator converts the input array of sequences into clusters which form the profile of the user they originate from. At startup, the ProfileManager initializes the ProfileCre-ator, ProfileUpdater and SequenceExaminer with various parameters. At training time, the ProfileCreator instructs 
FeatureSelector, as to what data to parse, and how to clean and tokenize it. The FeatureSelector makes sequences out of the tokens, whose length is determined by the ProfileM-anager. Thus, a sequence s, of specified length l, is a list of tokens, occurring contiguously in the same session of audit data, i.e., s E T t, where T is the token alphabet. If the number of commands is less than l, blank tokens are used to right pad the session. The ProfileCreator also initializes ClusterCreator and passes on the clustering algorithm and similarity measure, specified by the ProfileManager, so that the ClusterCreator can con-vert the sequences into clusters which are added to the user profile. Thus, a cluster c, is a collection of sequences off user-initiated command data, such that all its sequences are very similar to others within itself using some similarity measure SimO, but different from those in other clusters. If the clusters have sufficiently high intra-cluster simi-subsequence of tokens that the two sequences have in com-mon. It is polynomially bounded in the length l, i.e. O(/2) [4]. While LCS is a quadratic algorithm in comparison to the exact match-based linear algorithms, it does represent similarity between phase-shifted sequences. For example, for the Sl and s2 from above, LCS is 2, since they both share achieved using edit distance, dot-plots with the length of the longest diagonal corresponding to the similarity between the sequences and other sequence alignment algorithms. Note that all of the proposed metrics produce a similarity mea-sure having a whole value, i.e., Sim : T l x T l --~ [0, l]. This restricts the granularity of differentiation. 3.1 Dynamic Training 
Initial user profiles in ADMIT are mined in the training phase from user commands at their host machine. There are three main steps during training: 1) data pre-processing, 2) clustering user sequences, and 3) cluster refinement. These 
ADMIT collects user audit data, by monitoring the com-
The FeatureSelector parses, cleans and tokenizes the audit 
The FeatureSelector next creates sequences of length l 
Once tokens have been converted into sequences, we next 
K-Means [8] is an often favored clustering algorithm be-calls for a large number of clusters, i.e., the number of clus-ters, k = O(N). Thus, in general n is small and can be neglected. In this case, for the LCS and MCAP similar-ity measures, as 5 = O(1) and 5 = O(/2) respectively, the algorithm has complexity O(12N 2) and O(lN 2) respectively. 
The last step in training phase is refinement of the clusters found above. Although DynamicClustering counters all the basic k-means disadvantages, setting the intra-cluster sim-ilarity r may require experimentation. Also, a cluster may have a lot in common with another, i.e., sequences assigned to it are as close to it as they are to another cluster. There may also be denser sub-clusters within the larger ones. To tackle these problems, we improve the clustering by merging and splitting clusters as follows: 
MergeClusters (r', p~,, S,~): //r' is the inter-cluster similarity threshold 1. For each pair of clusters, ca, c~ inprofile p~,, i  X  j 3. ca = ca U cj //merge clusters 4. Recalculate center for ca 5. p~ = p~ -cj //remove cj from profile 
Split Clusters(r, t~, p~, S,~): //t~ is a splitting threshold support 1. For each cluster ca in profile p~, 3. DynamicClustering(r + 1, cl, p~, S~) 4. p~ = p~, -ca //.remove ca from profile Assume that p~, = {c0,cl,c2} and r' = 2 from above X  Let's see how MergeClusters works X  For instance, using LCS, Sim(co,cl) = Sire(so,s2) = 2. In this case, the two clusters should be merged to get co = {so, sl, s2} and cl will be removed from the profile. Also, the center for co becomes sl. For clusters that have high support SplitClusters calls DynamicClustering to re-cluster them into smaller, higher density clusters. 
In terms of time complexity MergeClusters takes O(Sk 2) time, while SplitClusters takes O(Sknk') time, where k' is the number of resultant clusters after splitting. The split-ting algorithm splits only very large clusters; while it may produce many sparse clusters, we found empirically, that it still increases the probability of finding better clusters X  The main advantage of these two methods are that they are faster than most other splitting and merging algorithms X  
Once ADMIT creates user profiles it can be used to test for masqueraders. Unlike training, the testing must happen in an online manner as user sequences are produced. Testing consists of four main steps: 1) real-time pre-processing, 2) similarity search within the profile, 3) sequence rating, and 4) sequence classification (normal vs. anomalous). These steps are detailed below. 
Capture user-based process data in real time. We use the following user data as an example: *SOF*; vi t4 X txt; vi 
WEIGHTED: The weighted mean of the last rating and the current sequence's similarity. The rating Rj for the jth se-quence is calculated as where Ro = Sim(s~,p~). For example, if o~ = 0.33, then 
Ro =R1 =R2 =R3 =3, and R4 =2.66. In general, it is more sensitive than LAST..a, and one doesn't have to fix n. However, it is hard to choose an optimal weight ratio. 
DECAYED_WEIGI-rrs: A variant of the weighted mean. Instead of using a constant a weight ratio, we vary it according to the sequence number. We thought of diminishing the sensitivity of the system as time passes. Doing this counters the effects of concept drift (i.e., shift in user profiles), which increases as time passes by, giving lesser sensitivity as the sequence id increases. The rating Rj for jth sequence is calculated as 
Here weight varies with sequence id, and is given as Thus o~j is a decaying weight as long as 1 -log(A) &gt; 0 Y 3 As an example, if y = 4100 and z = 7500, then R0 = R1 
R2 = R3 = 3, and R4 = 2.66. :?.2.4 Prediction: Normal vs. Anomalous as either "normal", i.e., true user, or as "anomalous", i.e., a possible masquerader. This classification is based on the rating Rj for a given sequence sc. 
NormalSequences. We use a threshold value on the rating of a sequence to determine if it is normal or not. The lower accept threshold, TACCEPT , is the threshold rating for a sequence, which, if exceeded by the test sequence's rating, causes the system to label that sequence as having originated from the true user. It is generally an empirically selected value. A normal sequence is added to the profile p,, to the cluster it is the closest to. For example, with TACCEPT -~-2.7, for WEIGHTED rating metric (a = 0.33) no alarm will be deemed to be normal; they are assigned to the nearest profile cluster centers are recalculated lazily. 
Anomalous Sequences. An anomalous sequence is one that doesn't pass the TACCEPT threshold (e.g., s~ is anomalous, since Ra = 2.66 &lt; 2.7). This may occur as the result of any one of three phenomena: 1) noise, e.g., from typing errors, randomness, etc., 2) concept drift, e.g., working on a differ-ent project, etc., and 3) masquerader, i.e., the one we want to detect. A lone anomalous sequence is most likely noise. A number of sequences which do not get assigned in near suc-cession suggest a change in the behavior, and are more likely to be an intrusion or concept drift, as compared to evenly distributed anomalous sequences, which are more likely to be noise. The larger the number of anomalous sequences in near succession, the more suspicious the identity of the user. However, these sequences do not have to be contigu-ous, otherwise IDS spoofing, in which harmful commands are inserted between normal commands to confuse the IDS, would be possible. To get a better estimate of the type of 
IDS are evaluated on the basis of accuracy, efficiency and usability [14] according to the following metrics: 1) Detec-tion Rate gives the percentage of OTHER sequences that receives a rating below TACCEPT (or OTHER REJECT). 2) False Positive Rate is the percentage of SELF sequences that the system incorrectly determines to be intrusive, i.e., the percentage of SELF sequences that receive a rating be-low TACCEPT (or 100 -SELF ACCEPT). 3) Time-To-Alarm (TTA) [10] is the expected number of normal sequences be-tween two anomalous sequences. It is a measure of the sys-tem's sensitivity and efficacy in detecting intrusions in real time. 4) Data reduction is a measure of the system's us-ability in terms of reducing the data the network security analyst has to browse through. 
As such, high SELF ACCEPT and OTHER REJECT are desirable, as they indicate a low false positive rate and a high detection rate, i.e., high accuracy. A high TTA indicates that there is considerable time between alarms, which is desirable for SELF since SELF should not raise alarms, but is undesirable for OTHER. 
For our experimental study, we use command stream data collected from nine UNIX users from Purdue University [10] over varying periods of time. The time over which the data for each user was collected is not known, so we use the num-ber of sessions as an indicator of time. Since there were 500 sessions for the user with the fewest sessions, we use the first 500 sessions from each user as our dataset. We further split the data for each user into five overlapping folds (i.e., blocks) of 225 sessions each (i.e., sequence numbers 0-224, 69-293, 138-362, 207-431, 275-499). Each of the folds is used inde-pendently of the others for testing and the results reported are the average over the five folds. 
For training and testing, 'each fold of 225 sessions is fur-ther split into two parts, the first 125 sessions are used for training and the latter 100 for testing. In each fold, for each user, the system creates a profile of SELF by train-ing on 125 sessions of SELF data. It then independently tests the first t sequences of the last 100 sessions of the cor-responding fold, for all users, including SELF, against this profile. Thus, each profile is tested against t SELF sequences and 8 x t OTHER sequences. Unless otherwise indicated, we perform experiments using LCS similarity measure and us-ing the DECAYED_WEIGHTS rating metric with y=6750 and z=7500. The intra-cluster threshold similarity r=3, the se-quence length l=5, the cluster support t~=15, test data size t=250 and inter-cluster threshold r'=2. All the experiments assume that training data is labeled. However, this is not a hard requirement. After clustering the training data it can be labeled easily, with substantial decrease in the work of the security analyst. This relaxes the requirements imposed by other methods, at no addi-tional cost. In the following graphs, we plot the variation in ADMIT's performance as a function of its configuration parameters, generally varied one at a time. 
The accuracies resulting from different sequence lengths varied from user to user. Hence we report tile mean of the readings of all users. We tested the performance for sequence TACCEPT was used for each value of I 1. Also, the intra-cluster threshold similarity was set as r = I -2 to ensure 1Empirically we determined that TACCEPT = 0.55 * I + 0.1 Figure 7: Effect of Intra-cluster Threshold 0 e"--S'~"'"~" x-algorithms. Machine learning, 6(1):37-66, 1991. 
