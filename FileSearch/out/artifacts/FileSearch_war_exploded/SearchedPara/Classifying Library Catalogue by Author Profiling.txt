 This paper presents a novel approach to classifying library records by making use of what we call  X  X uthor profile, X  a representation of an author X  X  expertise along a library clas-sification. Coupled with a string kernel classifier, the idea is shown to bring a significant improvement over a baseline. Categories and Subject Descriptors : H.3 [ Informa-tion Storage and Retrieval ]: Library Automation General Terms : Algorithms Keywords : Author Profiling, String Kernel, SVM, Library Classification
This paper addresses the issue of automatically assigning a library classification to a bibliographic record, which is currently done at the expense of daunting manual efforts. It is therefore not surprising that a significant number of books published in Japan still remain unclassified with NDC, a standard library classification adopted in Japan [2].
Prior literature in this field has been dominated by ap-proaches featuring a straightforward application of SVMs with polynomial kernel, which met with rather limited suc-cess [1, 2]. In this paper, we tackle the issue through the use of a novel idea we call author profiling , which enables us to tap into what might be called a social structure among au-thors, and lends itself to a straightforward integration with a popular machine learning framework such as SVMs.
Given an on-line bibliographic database such as OPAC, the goal of author profiling is to identify areas of expertise that may characterize a given author, say X, by looking at bibliographic records which have X as an author, and those by authors who have one or more books coauthered with X. Behind this idea is a straightforward intuition that if X works with someone whose work mostly concerns a particu-lar area, there is a good chance that X X  X  work relates to that area.

We say that a set of bibliographic records (call them bir form an authorship network of degree one for author X (call it N 1 ( X )) if they are accessible in a single search step using X as a query word, and an authorship network of degree two ( N 2 ( X )) if all of the bir s are two search step away from X. Just to give a flavor of what is happening here, sup-pose that we have a database with three bir s, as shown in Table 1, which are in the same format as those we work Figure 1: A authorship network with a 2-degree ra-dius. Each dashed edge represents a single search step, and a small filled circle a ben, with an initial query at the center. with in the experiments: they start with a title, followed by one or more author names, followed by publisher and date of publication. Suppose that we run a query with au-thor name Doris Lessing , which give you bir s 1 and 2, i.e., N 1 ( Doris Lessing ) = { 1 , 2 } . We may expand this network by further querying with Idries Shah , which appears in bir 2 . The result would be N 2 ( Doris Lessing ) = { 1 , 2 , 2 , 3 Note that N i ( Doris Lessing ) = N 2 ( Doris Lessing ) , i &gt; 2. This is because there is no author left in N 2 that we have not dealt with in the toy database in Table 1.

We create an author profile for X by culling library clas-sification codes from bir s in X X  X  authorship network and reorganize them along a classificatory scheme they use. For the present work, we make use of a hierarchical classifica-tion scheme known as Nippon Decimal Classification (NDC), the Japanese equivalent of U.S. Library of Congress Clas-sification, and create an author profile based on the top level classification of NDC, which contains 10 categories, i.e., general , philosophy , history , social science , natural science , technology/engineering , industry , art/fine art , language , and literature . Shown in Table 2 are profiles for three authors A, B, and C, each of which records how bir s are distributed across relevant categories; A and C have most of their bir s in social science whereas B has bir spread from general to social science.
One of the challenges we face in classifying bir s is that they usually carry little information on what they are about: what they do carry is limited to title, authors, who published them, and how they are published and when. Our response is twofold; first, we look beyond a single bir , find about what area a given author has expertise in, and exploit that information toward classification (this is something we hope 2 Learning How to Learn/ Idries Shah, Doris Lessing -Penguin, 1996.9 3 The Sufis/Idries Shah -Anchor, 1971.1 to accomplish with author profile); and second, as a way of making most of what we have with information poor bir s, we work with string kernel, which allows us to turn any substring from a bir , contiguous or otherwise, into a feature to be used with a classifier such as SVM.

Formally, for two sequences x and x  X  , consisting of char-acters from alphabet A , a string kernel is defined as: where A  X  denotes the Kleene-closure over alphabet A , and  X  s a weight for s . num s ( x ) indicates the count of s in x . In the experiments described below, we worked with a partic-ular alphabet known as  X  X a JP.UTF-8. X 
In sum, our approach amounts to the following: given a bir x , which is a string, we take its potential class H ( x ) to be: H ( x ) = arg max y  X  X  {  X f ( y, A  X  ( x ) , h )+(1  X  A  X  (  X  ) returns a string stripped of an author name, if any, while A + (  X  ) returns a string that corresponds to the author name. f ( y, x, h ) denotes the probability of emitting class label y given x under an SVM h with string kernel, or more precisely, f ( y, x, h ) = P ( y = 1 | h ( x )) = 1 represents the frequency ratio of class y given an author pro-file z . For example, C X  X  profile in Table 2 gives 0.58 for class soc. , so g ( soc , C ) = 0 . 58 . Parameters A and B are deter-mined as described in [3]. As we have 10 categories with which to label bir s, we create an SVM dedicated to identi-fying each of the categories, each trained on data with an equal number of positive and negative instances, i.e., those labeled with a specific category such as gen and phil , and those not. We then run a bir through each of the ten SVMs to determine a category it is mostly likely to fall into. SVMs, along with string kernel, were implemented with kernlab [3].
We created a training corpus for a category specific bi-nary SVM by selecting at random 1,600 bir s from the sec-ond half of what is called Zenkoku Shoshi Mokuroku (ZSM) or  X  X ationwide Library Catalogue X  published in 2006 by the National Diet Library of Japan. We populated each corpus with an equal number of positive and negative bir s, nega-tive bir s being those that do not fall into a target category, and positive bir s those that do. For a testing corpus, we gathered 1,000 bir s randomly from ZSM published in 2006. A care was taken not to have any part of the testing corpus overlap with training data we created for SVMs. An SVM was trained with C = 10. We had the string kernel exam-ine every possible substring of up to 20 characters in length. The decay factor  X  was set to 0.5. So was  X  . In addition, we experimented with various values of radius for authorship network to see how it impacts performance in classification.
The results of the experiments are shown in Table 3. Listed alongside of them are the frequency ratios of bir s with rel-evant categories; bir s labeled with gen , for instance, occur 2.7% of the time in the testing data. r indicates a value for radius; in particular r = 0 means that no use was made of author profile when classifying bir s. Table 3 shows rather clearly that for the most of time, author profiling leads to a significant improvement over a vanilla SVM approach (the numbers represent performance in F1, harmonic mean of precision and recall , given in percentage format). Of partic-ular note is the fact that performance declines as radius r grows (compare r = 2 with r = 4). This is probably because as we expand the authorship network, bir s we get become increasingly disconnected from areas of expertise that the original author is associated with.
To conclude, we set out to examine whether paratextual information such as authorship network helps classifying bir s. This is apparently so, as it led to a significant im-provement when coupled with SVMs. However, applying the present work across diverse library catalogues is defi-nitely something we need to address in the future.
