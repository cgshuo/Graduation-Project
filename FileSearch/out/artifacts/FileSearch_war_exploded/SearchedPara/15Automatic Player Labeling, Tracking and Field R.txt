 Video event mining for understanding, retrieval and search is becoming more and more important in recent years [Xu et al. 2007; Zhang et al. 2005; Peursum et al. 2003]. One of the interesting applications is intelligent sports video summarization and browsing based on semantic analysis, for example, highlight detection, tactics analysis, and player activity analysis. In these applications, an important technology is tracking players and mapping their trajectories into the field model for further scene/action retrieval, activity and tactics analysis. This task is interesting while quite challenging due to many difficulties, such as player occlusion, similar player appearance with low discrimination, varying number of players, abrupt camera motion, player pose variation, various sources of noise, video motion blur, unreliable key-points detection and correspondence, etc.

Player and ball tracking is an important task in sports video analysis. It locates ball and players and finds their moving trajectories in image sequence. Field registration is to find the geometric correspondence between image plane and the standard field model, and map the playfield from an image plane to the standard field model. Once getting players moving trajectories and field registration, the players X  positions in the field, the moving direction and approximate speed, as well as the pass through activity can be easily obtained from the registered field [Yu et al. 2004; Farin et al. 2005]. These cues can facilitate team based line-up and tactics analysis, attack, and defense time distribution analysis [Bebie and Bieri 2000], activity-based scene retrieval [Kim et al. 1998; Watanabe et al. 2004] (such as attack, pass through, etc.), and video content enrichment [Yu et al. 2004], such as virtual content/advertisement insertion. Lots of works have been studied in sports video analysis [Okuma et al. 2004; Sullivan and Carlsson 2006; Nillius et al. 2006; Wang et al. 2004]; several researchers also inves-tigated the specific problem of labeling and tracking of players in TV broadcast videos [Sato and Aggarwal 2005; Choi and Seo 2004]. A review of state-of-the-art tracking algorithms is given in Yilmaz et al. [2006]. Many algorithms have already been pro-posed, such as particle filter [Isard and MacCormick 2001; Okuma et al. 2004], joint probabilistic data association filter (JPDAF) [Bar-Shalom and Fortmann 1998], multi-ple hypothesis tracking (MHT) [Reid 1979], track linking [Perera et al. 2006; Stauffer 2003; Kaucic et al. 2005]. Tracking can be viewed as a data association problem, whose purpose is to recover the correspondence between observations across different frame. Most of data association algorithms like JPDAF and MHT assume one-to-one map-ping between observations. This assumption is often violated when occlusions or false alarms occur. The MCMC data association framework [Oh et al. 2005; Yu and Medioni 2007; Yu et al. 2007] does not assume such mapping scheme, and it is quite suitable for our application in which occlusions often occur in playfield. Choi and Seo [2004] tried to extract color models of the playfield and the team uniforms for semantics analysis. In Sullivan and Carlsson [2006], a clustering-based trajectory matching method was proposed to solve the player tracking in soccer video. In their work, labeling of individ-uals was achieved by supervised classification. Nillius et al. [2006] built a track graph and took the tracking problem as inference in a Bayesian network. In both of these works, a multi-camera system was used to get a stationary, high-resolution and wide-field view of soccer game. This setting ensured a reliable background subtraction can be obtained. In our application, the camera is not fixed, which results in moving back-ground. Thus, we need robust and adaptive background modeling and effective object association technologies. In another aspect, unsupervised player labeling is preferred for its generalization ability. In the aspect of field registration, Watanabe et al. [2004] first binarized the input image plane, and searched the optimal matching from the im-age to the standard field model. Their experimental results seem somewhat accurate, while the matching process needs to search in huge solution space. A 3D reconstruc-tion and enrichment system [Yu et al. 2004] was presented to reconstruct broadcast soccer video and enrich reconstructed video with music and illustrations of the video content. In fact, it faces much challenging because it needs at least six accurate key corresponding points (should not be in the same plane) to get 3D information. Liu et al. [2005] proposed a method for soccer field registration under the condition with or without enough corresponding points. But they did not explain how to locate key points in image planes. Thomas [2007] presented a method for computing the position, orientation and focal length of a camera using image analysis with markings on the pitch, such as arcs and lines, etc. and using multiple images to improve the accuracy. In this article, we detect, label and track multi-players and find mapping from im-age planes to field model and then map their moving trajectories into field model. The player detection is achieved by the dominant color based background subtraction and Haar-like feature-based boosting detection. Combination of foreground extraction and boosting algorithm yields a fast player detector with high detection accuracy. For missing and false detections, we allow to associate observations across inconsecutive frames, and recover the state of target between these frames by linear interpolation. Automatic player labeling is reached by player samples collection and unsupervised player appearance modeling. We can successfully identify two teams X  player and the referee. Player tracking is viewed as data association problem. By defining energy on the global association which penalizes missed detections, false alarms and unfavorable association, we consider all the above problems in a unified framework. Part of miss detections will be remedied, false alarms will be removed and correct correspondence will be generated.

Further, we conduct field registration on the filtered binary image. We apply Hough transform to detect lines and extract their intersection key-points. If there are enough key points ( &gt; = 4), we use direct strategy to estimate the homography mapping matrix. Otherwise, we apply indirect strategy. In direct strategy, we map the extracted key points in image plane to field model and search the optimal mapping. To accelerate the process, we design special fast rejection step to skip the obvious non-reasonable cases. We also apply distance transform to measure the matching error continuously to facilitate search. In cases of no enough key-points, we reconstruct the homography mapping matrix by taking the global motion between adjacent frames as transfer factor.
After getting player trajectories and registered field model, we map players X  moving trajectories into the field model. From that, we can know the position of players in the world coordinate system, and obtain their moving velocities and directions. These information can be further used for team activity analysis and scene/activity retrieval.
Our system framework is illustrated in Figure 1. The whole procedure is a two-pass video scan. In the first scan, we (1) learn video dominant color via accumulated color histograms, and (2) unsupervised learn players X  appearance models over hundreds of player samples collected by a well-trained boosted player detector. In the second scan, which is the testing phase, we first use the dominant color for playfield segmentation and view-type classification. Only the global views [Li et al. 2006] will be processed. We apply a boosting player detector to localize players, in which the segmented playfield is taken as mask. Afterwards, the players are labeled as Team A, Team B, Referee or outlier in terms of prior learned models. We perform data-driven MCMC association to generate players X  trajectories, in which track length, label consistency and motion consistency are used as criterions for associating observations across frames. The dom-inant color and view-type classification results are also used for Hough line detection and intersection key-points extraction. If there are enough key-points, we can direct estimate the homography mapping matrix between image plane and field model. Oth-erwise, we use motion transition between adjacent frames to infer the current mapping matrix. With the homograhy matrix, we can map the players X  trajectories into the field model.

Figure 2 shows an example of the player tracking result (left) and mapping result on the field model (right). At the left, players are tracked and labeled by different color rectangles, the ball is labeled by a red-cross circle [Tong et al. 2007], and a number is assigned to each player at the up-left of the rectangle. On the right, the registered field and players are shown as corresponding color circles. The area covered by the camera is shown in white color.

The differentiation of our work from the work of Farin et al. [2004, 2005] is that (1) in addition to field registration, we present multi-player tracking work; (2) our register method can still work when there is no enough key points, and (3) we apply more fast rejection criterions to accelerate the search procedure. The differentiation from the work of Liu et al. [2005] is that we present the method for getting key points and performing key point correspondence that is a key process in a practical system. Our differentiation from the work of multiple object work [Sullivan and Carlsson 2006; Nillius et al. 2006] is that we present the whole flowchart including detection, labeling, and multi-object tracking method with high accuracy. During tracking, we use motion, player label, trajectory length, etc., constraints to associate multiple players moving trajectories. For automatic player labeling, we are unaware of existing work done with large and numeric evaluation in the sports domain, and we are also unaware of all-day testing on a public database of field registration in soccer video.

The main contributions of our method are (1) robust and accurate player detec-tion achieved by background subtraction and boosted cascade detection; (2) unsu-pervised player appearance modeling, the referee can be reliable identified in ad-dition to two teams players without any manual labeling; (3) efficient global data association for player tracking, which solves the difficulties like tracker coalescence and correspondence maintaining after occlusions; (4) practical field registration al-gorithm that can work with and without enough key points; (5) the employment of distance transform to measure matching error, which enables the error to be con-tinuous and makes the search more stable; (6) proposal of several fast rejection cri-terions, which reduces the search space and achieves near-optimal field registration result. We shared our experimental results of player tracking on a real soccer game at http://www.flickr.com/photos/37625729@N03/3499448484/, and the corresponding field registration and player trajectories mapping results at http://www.flickr.com/photos/ 37625729@N03/3461850457/.

The article is organized as follows: Section 2 describes the dominant color learning and view-type classification. Section 3 presents the boosting based player detection, player labeling and tracking algorithm. Field registration algorithm is presented in Section 4 in detail. Experimental results and analysis are shown in Section 5. Conclu-sions are finally drawn in Section 6. We learn the dominant color of background (corresponds to grass color of playfield) by accumulating HSV color histograms. Then, the playfield is extracted through domi-nant color segmentation, morphological filtering and connect-component analysis. In accordance with the area of playfield and non-field object size within the playfield, we classify each view using a decision tree into one of four predefined view types: global view, medium view, close-up, and out of view (Figure 3). The detailed algorithm is described in our previous work [Li et al. 2006].
 Player detection is achieved by running a boosted cascade of Haar features [Viola and Jones 2001] on global views. We manually labeled about 6000 players as positive sam-ples. These samples are carefully selected in order to capture the appearance variation of players caused by body articulate motion. Negative samples are background patches randomly cropped from soccer and natural images. This scheme enhances the detection accuracy especially in this domain. Some training samples are shown in Figure 4. All these samples are properly scaled to a resolution of 32  X 
A boosted cascade detector is then trained on this sample set. We use a total amount of about 340,000 Haar features for training. In each round, a decision stump is used as weak classifier. By a Gentle Adaboost algorithm, a strong classifier is learned as an additive model of the form H ( c ) = N n = 1 h n ( c ), where h round. To accelerate the training process, we randomly select only a fraction of Haar features for each round training as in Shotton et al. [2006]. This process brings a dramatic speed up in training phase while only small impact on the final detection performance.

In detection phase, playfield segmentation is first used to filter out the background regions. The detector is then scanned across the filtered image regions at multiple scales. From our observation, the average player height is about 70 pixels of global views in MPEG2 video (resolutions: 720  X  576). Therefore, we limit the player size in a range from 32  X  64 to 48  X  96 in our experiments. Multiple detections will usually occur around each player after scanning the image. We merge adjacent detected rectangles and remove possible false responses through clustering to get final detections with proper scale and position. Missed detections and false alarms may occur due to video blur and congregation of players. False alarms will also emerge due to various type of noise such as cameraman and replacement. These detection accuracy can be improved by tracking process through data association. The procedure of detection is illustrated in Figure 5. The task of player labeling is to distinguish players X  identities (Team A, Team B, Referee). Since now, we use word  X  X layer X  indiscriminately to represent both team players and referee when there is no confusion.

To learn the player appearance model, we run the player detector on every 50 frames to collect training samples from the input video. About 500 frames are processed and approximately 1,500 samples are extracted from a half game (45 minutes, 25 fps). We utilize a bag of feature to represent players. This process is illustrated in Figure 6. For each player sample, the background is subtracted by using the dominant color model firstly, and only the upper body region is used for training. A large pool of pixels is then collected from these regions and transformed into CIE-Luv color space. We estimate a Gaussian Mixture Model (GMM) with N components in the space by Expectation-Maximization (EM) [Bilmes 1998] clustering. Centers of these components are named prototypes . The adjacent components with smaller center distance than a certain threshold are then merged together. The resultant merged components are called meta-prototypes . Each player sample is then represented as a histogram by binning all pixels in upper body region into the corresponding meta-prototype.
Then, we learn the appearance model for each identity (Team A, Team B, Referee). A naive clustering on player samples is not enough here. Actually, we manually labeled some samples collected from a real match video, and plotted the first two dimensions of PCA in feature space, as shown in Figure 7. It can be seen that referee samples do not clearly form a cluster in feature space due to their small quantity. A direct clustering may lead them to be absorbed into a nearby cluster. The existing of outliers will also incur an imprecise localization of clusters.

To deal with these problems, we first use EM clustering to estimate K clusters over the meta-prototype histogram of all player samples. K should be large enough to make sure that the referee samples form at least one cluster. Centers of these K clusters are named submodels , which are denoted as textitSM ={ sm we merge adjacent clusters into four clusters by hierarchical clustering. Their centers are named real-models , and formally denoted as RM ={ rm i ing function L assigns each real-model and submodel exactly one label in a label set
LS ={ Team A , Team B , Referee , Outlier } . The first two real-models with the largest size are labeled as Team A and Team B, their corresponding submodels are also la-beled as Team A or B. Then, we compute a minimum average distance (MAD) from other two real-models to the team submodels. Denote samples in a real-model as s 1 , 2 ,..., | rm | . All the submodels labeled as Team A or Team B are denoted as TM { tm j : tm j  X  SM and L ( tm j )  X  { Team A, Team B } , j = where Bd is the Bhattacharyya distance defined as in Okuma et al. [2004]:
The real-model with a larger MAD is labeled as Referee, and the other one is labeled as Outlier. All the submodels labeled as Outlier are discarded and never used for future testing, that is, we only maintain a set of submodels take label from label set LS ={ TeamA , TeamB , Referee } . The samples labeled as outlier usually come from goal-keepers, false detections or regions containing multiple players, etc.
In player-labeling phase, each player sample is represented by its meta-prototype histogram, which is denoted as s . We calculate the Bhattacharyya distance between s and each submodel sm as in formula (2). The sample is assigned the submodel X  X  label with the nearest distance ( k -nearest neighbor, k = 1). 3.3.1. Problem Formulation. We formulate the tracking of multiple players as a data association problem. The whole detection and labeling result over a time period [1 is taken as the observation set, which is denote as Z 1: T time t ,and Z i t be the i th observation at time t . To reduce the computational complexity, we define a neighborhood graph G = ( V , E ) on the observation set, with each node in the graph represents a single observation and edges are defined between neighboring nodes. The neighboring of nodes is defined as: where v max is the maximum speed of targets and T max is the maximum time interval of consecutive observations in a track. A partition of such neighborhood graph can be represented as  X  ={  X  0 , X  1 , X  2 ,..., X  K } , where  X  form  X  k ={  X  k ( t 1 ) , X  k ( t 2 ) ,..., X  k ( t |  X  optimal association can be represented by a partition  X   X  of  X  given observations: The posterior is formulated in a Gibbs distribution form as follows: where C is normalizing constant, T is temperature, U is a potential based on temporal compatibility within a single track, and V is a potential based on spatial compatibility between different tracks.
 The potential U of a track  X  k is formulated as: with U length penalizes a short track, U label favors consistent labeling, and U izes inconsistent motion and long range association. Let T L th be the expected length of tracks, U length is defined as:
It can be seen that all the tracks whose length are shorter than L this term. We define the label of a track to be the most frequently appeared observation label in the track. The label potential U label is defined as: where L is the label of an observation or a track. U l is defined as: where s and d are positive potential. In this term, associating consistent labeled nodes together will be favored, while inconsistent labeling in single track will be pe-nalized. The motion potential U motion is defined as:
This term has the effect of penalizing fast drifting of observations in the track, that is, targets should not move too fast. It also penalize associating observations across long time span, which means targets will be successfully detected in most of the frames, and their observations should be associated into tracks. The potential term V penalizes spatial overlapping between two tracks with the same label: where  X  is the spatial overlap between two observation nodes. This term prevents a single track being split into several overlapping tracks.
 Some good association and bad association examples are illustrated in Figure 8. The length potential term and label potential term have impact on the length of the tracks. Long tracks will always be favored by these terms. So when occlusion occurs, observations of occluded player will be interpolated to complete the whole track in order to reduce the global association energy.

Our target is to find a configuration of associations that globally maximize the poste-rior probability in (5). We achieve this by adopting an MCMC data association strategy. 3.3.2. MCMC Data Association. It is usually impossible to compute the global optimal solution for (5) analytically. We adopt MCMC strategy to explore the solution space, and estimate the optimal solution by a simulated annealing scheme. Given a target distribution  X  (  X  ), the basic idea of MCMC algorithm is to simulate a Markov chain in the state space of  X  , so that the stationary distribution of this chain is Metropolis X  X astings (MH) sampler [Liu 2001] as the MCMC sampler. Our algorithm is shown in Figure 9. The design of moves in MH algorithm is crucial to the correctness and efficiency of Markov chain. Some basic requirements should be fulfilled, such as the chain should be ergodic, aperiodic and reversible. Our move set M consists of six types of moves (shown in Figure 10): M ={ birth , death , extension They are similar to those used in Yu and Medioni [2007]. These moves are grouped into reversible pairs: birth / death pair, extension / reduction pair and split we describe these move pairs and deduce the proposal ratio for them.

We denote current state as  X  = (  X  0 , X  1 , X  2 ,..., X  K ) and proposed state as move. Proposal ratio for each move is denoted as R m , m  X  (1) Birth/Death Move Pairs. The birth/death move consists of adding/removing a track from current state. For birth move, denote proposed state as (  X  , X  associate it to a new track  X  K + 1 . An extension direction flag d is selected u.a.r from di-rection set D = { forward, backward } . Then, we start an association procedure: For each z  X  N d ( z associate it to track  X  K + 1 ,andset z c = z i . Continue the association with probability (0 &lt; X  &lt; 1). Repeat this procedure n times until an association is rejected or no obser-vation can be added. For death move, denote proposed state as We select u.a.r a track  X  k in  X  and remove it. The proposal ratios are given by: where p end is the probability of ending association, p end probability of ending association at tail and head. The values of these probabilities are 1 if no observation can be added or 1  X   X  otherwise. (2) Extension/Reduction Move Pairs. The extension/reduction move consists of ex-tending/reducing a track in one direction. For extension move, denote proposed state as  X  = (  X  d is selected u.a.r from D . Then, we repeat the same association procedure n timesasin birth move on d . For reduction move, denote proposed state as First, a track  X  k is selected u.a.r in  X  . Then a cutting index is selected u.a.r from ... on this direction are removed from the track. The proposal ratios are given by: (3) Split/Merge Move Pairs. The split/merge move consists of splitting a single track or merging two neighboring tracks. For a split move, denote proposed state as (  X  , X  t split with probability p ( move, denote proposed state as  X  = (  X  0 , X  1 , X  2 ,..., X  and  X  j with probability p merge (  X  i , X  j ) from all the pair candidates in intoasingletrack  X  K  X  1 . The proposal ratios are given by: 3.3.3. Data Driven Proposal. The convergence speed of Markov chain depends critically on the design of moves. In order to increase the efficiency of moves, proposals are all driven by the observation data. Let p asso ( z i t 1 , z j neighboring observation nodes z i t 1 and z j t 2 , we define p where  X  is the Dirac function, and U m is defined as in (10). Denote neighboring relation between tracks as  X  m  X   X  n , Then p d ( z i ), p (  X  ( t formulation as follows: The procedure of field registration is shown in Figure 11. It is composed of: (1) Hough line detection, horizontal and vertical line classification, and intersection point extrac-tion; (2) Direct homography matrix estimation including correspondence hypothesis generation and evaluation if there are enough key-points; (3) If there are no enough corresponding key-points, we perform indirect estimation with the homography matrix of previous frame and the global motion transition from the previous frame to current frame. This procedure includes SIFT key-points detection [Lowe 1999], point matching, points-correspondence filtering by RANSAC [Fischler and Bolles 1981] global motion estimation based on the key-points, and homography matrix generation. The soccer field model is shown in Figure 12. We set the field size to be 105m We use not only the real intersection points (intersected by two real lines) in the model, but also the virtual intersection points (intersected by one real line and an extended real line, or intersected by two extended real lines). These virtual intersection points are also key points of the field model, and can be used to calibrate the camera. The horizontal and vertical lines and intersection points are shown in Figure 13. We take the imaging model as a pin-hole model, which related to a 3D point in the world and its 2D image point on the retina. A 3D point with homogeneous coordinate is denoted as P = X , Y , Z , 1 . A 2D point on a retina is p camera, a 3D point P in real world coordinate system and its image corresponding 2D image point p have the following relationship: where K is called the camera intrinsic parameters, including f factors in the image X  X  x and y axis, the principle points ( o the optical axis and the retina, and c is the skew of the image X  X  two axis. R and T are rotation matrix and transition vector, which related to world coordinate system and camera coordinate system, respectively.

The soccer playfield is on a plane, so we define playfield on XOY plane of the world coordinate system, that is, the plane function is Z = 0. Substituting this plane equation into (22), we have:
For convenience, the point on the plane Z = 0 in the world coordinate system is denoted as P = X , Y , 1 . As a result, Eq.(22) can be rewritten in the matrix form as below: where H is a 3  X  3 matrix parameterized in term of intrinsic matrix K and column vector r 0 , r 1 and t . In general, it is called homography matrix between a plane in the world and an image plane.

The matrix H is defined up to a scale factor; therefore, it has eight indepen-dent parameters. In order to determine the eight parameters, at least four point-correspondences between image plane and field model have to be found. Since the field usually does not have obvious point-features, we use the intersections of lines within the playfield to estimate point-correspondence. Note that the intersection points gen-erated by real lines and extension of real lines can be also used to calibrate the camera. 4.3.1. Hough Line Detection and Intersection Points Extraction. We use Hough transform [Thomas 2007] to find lines in the field. We firstly extract the playfield region with dominant color and morphological filtering (shown in Figure 14(a)), then reserve the pixels not consistent with the dominant color within the playfield. To reduce the noise, we remove large blob-like regions (possible players region) with connect-component analysis (Figure 14(b)). After that, we apply Hough transform on the binary image to detect line-marks. Each line is categorized into horizontal or vertical types according to their slant angles (Figure 14(c)). Finally, we obtain the intersection points resulted by any horizontal and vertical lines. Both real and virtual intersection points are considered (Figure 14(d)). 4.3.2. Direct Mapping Matrix Estimation. If there are more than four corresponding points (i.e., at least two horizontal lines and at least two vertical lines) between image plane and the field model, we use direct strategy to estimate the homography matrix. The problem is to determine point pairs X  correspondence. It is difficult to directly assign the corresponding points. We enumerate all possible mapping instances and search the optimal one through error evaluation.
 (1) Mapping Hypothesis Generation. To simplify the mapping procedure, we con-sidered line correspondence instead of point correspondence. The reason for this is twofold: (1) the number of lines is smaller than that of points, thus the possible map-ping is less and (2) once we extract the lines, we can determine their geometric rela-tionship (left/right, up/down). The constraint of the relative geometric relationship also reduces the space of mapping. There are L h = 10 horizontal lines and L lines in the field model. Given m horizontal lines and n vertical lines detected, there which defines a determinative correspondence between detected image lines and field model lines. (2) Hypothesis Evaluation. For each hypothesis, we get a mapping matrix H from the world coordinate to image plane. To evaluate the confidence of each hypothesis, we map the field model with H to image plane and calculate the distance between the mapped image and the actual image. In order to improve the robustness, we use the distance transform map of the Hough line detection image (which decreases the noise). Set the distance map to be D , the pixel sets (lines) generated from field model to image plane by homography matrix (yellow lines in Figure 15(b)). Then, the error is defined as: where N is the total number of non-zero pixels remapped, t maximum error. We search the optimal case as the final best matching. An original image and the remapping line image are shown in Figure 15. (3) Fast Rejection. The search space is huge, which results in much redundant com-putation. If m = 2, n = 2, there are C = 945 possible configurations. If m 9240. The search space is huge if there are many lines (including false alarms lines), and results in wasting much time to find the optimal configuration. Actually, some of hypothesis are obvious impossible and can be fast rejected.

If there are two horizontal lines corresponding to the field model, we can estimate the field model size. In the same way, we also estimate the field model size with any two corresponding vertical lines. If the two estimated size has much difference, this hypothesis will be rejected. For example, two horizontal lines are detected in image plane (blue lines l 1 and l 2 in Figure 16 left), and we assume that they correspond to the top lines in the field model. Because we know both the actual distance between l and l 2 , and the distance of the mapping lines in the model, we can calculate the width of field model, and compare it with the standard size. If there is much difference, the hypothesis will be rejected.

Another fast rejection method is evaluating the homography matrix itself [Farin et al. 2004]. The homography matrix has eight degrees of freedom, but the real-image formation process has only seven. These comprise three for camera position, three for camera rotation, and one for focal-length. The remaining degree can be attributed to nonisotropic scaling, which refers to unequal scaling in horizontal and vertical directions. If we consider the individual steps of the image formation process, we get where f denotes focal-length. Nonisotropic scaling is impossible in the real world. Hence,  X  should be 1, and we can use this condition as a rejection rule. To determine from H, we first compensate the camera principle point ( o at (W/2, H/2) by multiplying an appropriate matrix to be the left side. Furthermore, we simplify the equations by exploiting the fact that we construct the field model on the Z = 0 plane. Consequently, we obtain
Since the rotation matrix { r ij } is known to be orthonormal, we can deduce the two equations
Finally, we get
In this work, we only accept solutions that have 0.5 &lt; X &lt; 4.3.3. Indirect Mapping Matrix Estimation. If the camera focus to the area near midfield, or the image is blur due to abrupt camera motion, it is hard to detect the lines, which results in not enough corresponding points. In this case, we use the camera motion transition to deduce the current homography mapping matrix (their relationship is illustrated in Figure 17). We assume the camera motion between successive frames is linear and continuous, which results in continuous view changes of the focus area in the standard field model. The procedure includes key-point detection, point matching, point correspondence filtering via RANSAC, and global motion estimation.
We assume the global motion model to be perspective model whose transform matrix is also 3  X  3 with eight independent parameters (defined up to a scale factor). The current frame I t can be estimated by its previous frame I transform M t  X  1 (denote field model as F ): Substituting formula (32) into (31), we have Comparing formula (31) and (34), we have (1) SIFT Detection. In key-point detection, we use SIFT feature [Lowe 1999] point to characterize the key points. The SIFT key points are scale, shift and rotation invariable, and have good capability of point matching in some transform range. Each key point is represented by a 128-dimension histogram of gradient orientation. Most points are at audience regions, and some are at players regions in soccer scenes. (2) Key-Point Correspondence between Adjacent Frames. The distance of two points is measured by histogram intersection. For one point, the candidate with the nearest distance is taken as the optimal matching (first candidate). To improve the robustness of matching, we also calculate the second minimum distance (second candidate). If the difference between the first and the second candidate distance is lower than a threshold, it is trustable. (3) Corresponding Points Filtering via RANSAC. There are average 700 pairs of key points. Some of them are noise, parts of them are false matching. It is necessary to filter out the outliers. In this work, we apply Random Sample Consensus (RANSAC) algorithm. The procedure is shown in Figure 18. After filtering out the outliers, we can compute the global camera motion parameters M under a perspective model. (4) Homography Matrix Generation. Set the time-stamp of the current frame to be t , the homography mapping matrix at time t to be H t , , and the motion transition matrix from time t to t + 1tobe M t + 1 , then, we can get the current homography as below: We test our algorithm on FIFA World Cup 2006 MPEG2 videos (image size: 720 576, 25 fps). First, the player detection algorithm (without tracking) is evaluated on two half games: the France vs. Spain and Brazil vs. Japan videos. Then, we give the labeling results and tracking results of our system on three video clips from World Cup 2006. Based on player tracking, we map player trajectories into the standard field model through field registration.
 We randomly select hundreds of frames from two videos (50 X 100 frames interval be-tween adjacent selected frames) and manually labeled each player X  X  position and label as the ground truth. We use three criteria to check if detection is correct, miss or a false alarm: relative distance, cover and overlap, as defined in Leibe et al. [2005]. The criterions are illustrated in Figure 19. The relative distance d normalized distance between the bounding box centers and ground-truth centers (see Figure 19(left)). Cover and overlap measure how much of the annotation rectangle is covered by the detection and vice-versa (see Figure 19(right)). In our detection and tracking experiments, we consider a detection to be correct if d overlap are both above 50%. This is described in the following formula: where, c g , c d are the centers of annotation ground-truth and detection rectangle re-spectively; dist( c g , c d ) is the Euclidean distance of the two points; h height and width of the ground-truth rectangle, s g and s detected rectangle, respectively.

We utilize precision, recall and F-score metric to measure the performance. Denote the counter of correctly detected samples to be # correct, the counter of false alarm to be # false, and counter of missing items to be # miss. Then, the metric of Precision is defined as: Precision = # correct / (# correct + # false), and Recall as: Recall / (# correct + # miss), and accordingly the F-score = 2  X  Recall). The performance of player detection is shown in Table I. The average F-score of two testing videos exceed 90%. These results demonstrate the validity and robustness of our detection method. As declared above, although our detector works well without the playfield mask, the playfield segmentation plays an important role in the algorithm. It not only accelerates the detection speed, but also eliminates the out-field region and reduces false alarms within the playfield, which is of much benefit to later tracking procedure. We also test our labeling module on the same ground truth data. Only correctly detected players are used for evaluation. The confusion matrix of labeling is shown in Table II, in which GT stands for ground truth , INF stands for inferred . R denotes Referee, TA denotes Team A and TB denotes Team B. All the percentages are row-normalized. The labeling accuracy of two teams is much high, while that of referee is lower. In a match video, the counter of referee samples is much smaller than that of two teams. Thus, the training samples may be not enough and the clustering result is not clean, and also the final trained model is not well characterized. One false labeling of referee has much bigger effect to the final performance. These make the accuracy of referee to be lower. Because the ground truth data labeling is very time consuming, we list the experimental results on two matches here. But in reality, we have applied this method on many soccer games with different teams, illumination and boarding style, and get stable and good performance.
 There are several parameters to be set in the tracking module. Parameter selection is an open problem. In our system, these parameters are selected empirically.
As the parameters for the definition of neighboring graph, is set to be 15. The choosing of v max and T max needs some consideration. If the values are too large, the computational cost will be dramatically increased; if the values are too small, long occlusions will cause failure of association.

As the parameters for the definition of the posterior probability, weight of length term, which is set to be 0.3. L th is set to be half the time span between the first frame and the last frame.  X  is the relative weight of labeling term, which is set to be 1. s is set to be 0.1, and d is set to be 0.5, which means an inconsistent labeling association will be penalized much more than the gain of a consistent labeling association.  X  and  X  denote the relative weight of motion term, which are set to be 0.3 and 1.2. The relative weight  X  in potential term V is set to be 2.5.

As the parameters for the definition of the data driven proposal, relative importance between labeling consistency and motion consistency. We set it to be 3.

It is hard to get satisfied result just applying the fixed parameters to general purpose applications without any adjustment. In a specific scenario, the parameters are related to the proposals, the favorite and penalty items, the observation performance (such as detection and labeling results), etc. In our work, besides some default parameters, we tune some parameters according to the detected player result (accuracy, missing and false alarm), the labeling accuracy, player size, moving velocity, and scene complexity, etc. Due to the stability of detection and robustness of player classification result, the tuned parameters can be determined in one game and can be extended to other games. We apply this method to some other games (FIFA, Euro Cup, Asia Cup, etc); the experimental performance is stable and satisfied.

We manually labeled three global view clips. The first clip consists of 100 frames, and the other two clips consist of 250 frames. We test the tracking algorithm on these clips. 60,000 MCMC iterations are used for the first clip and 200,000 iterations for the other two clips, both with 500 iterations as burn-in iteration steps.

Some tracking results are shown in Figure 20. Automatic tracked players are en-closed by rectangles. The red rectangles denote  X  X eam A X , blue denote  X  X eam B X  and yellow denote  X  X eferee X . The ID of player is shown on the top of each rectangle. Note that player ID is assigned globally, and the prior appeared player is not necessarily assigned smaller ID.
 From Figure 20(a), it can be noticed that occlusion occurs between ID12, ID14 and ID18 from frame 40 to frame 70. Our algorithm correctly tracks and classifies them even if ID18 is totally occluded by ID12 in frame 51. Occlusion also occurs between ID8 and ID11 in frame 40, and between ID6 and ID7 in frame 70, which are all correctly handled. In Figure 20(b), ID8 is occluded by ID2 from frame 34 to frame 46. Another occlusion occurs in frame 131. They all successfully recovered.

Figure 20(c) shows the result on the third clip. For ID7 and ID33 in frame 46, a long time occlusion between them occurs later. Because we have set the maximum association interval T max to be 15, this occlusion can not be recovered, and the track of single-player breaks into tracklets ID33 and ID35.

Our tracking algorithm can reach a detection precision of 98.47% and recall of 93.02% on the ground truth of three clips. We also observed that the performance of labeling is significantly improved after tracking. But there still have some false assignments of track id to players. Most of them are due to failure of boosting detection in several consecutive frames caused by video blur, articulate motion of players or long time occlusions.

We manually label two sequences for each player trajectory and its team type to evaluate the tracking performance. The first sequence (seq1) has 100 frames, and the second sequence (seq2) has 115 frames. We uploaded the tracking results at http://www.flickr.com/photos/37625729@N03/3499448484/. We count the tracking per-formance by hit and miss measurements in frame-wise unit. When a player, with con-sistent player-ID and correct player-label, is correctly tracked (located) in one frame, it is hit; when it is missing or false labeled with other player-ID, it is regarded as a miss. The same three criteria used in detection evaluation are also utilized here, but we add another label item. Thus, a track is regarded as a hit if all following four conditions are met: d r &lt; 1, and cover &gt; = 50%, and overlay &gt; = correct (the label along the trajectory is consistent). The count and rate of hit and miss are shown in Table III. There are 24 and 19 player-IDs in clip 1 and 2, respectively. Please note that the number of player-ID is always bigger than the actual number of players in a clip. When the camera pan from left to right and then back from right to left, a player at the image plane boundary area may move out the image plane, and comes back after a while (longer than a certain threshold). We cannot link the two players X  trajectories and merge them together even we correctly label the category and track it. Also, if a player is not at the boundary area of the image plane, but the track algorithm miss it for a long time, when it is detected and tracked, another player-ID will be assigned and another trajectory is generated. In some more complex cases, for example, during a corner ball, many players gather around the goalmouth, it is quite hard to track all players (detection performance may be much bad).

The moving trajectories of seq1 and seq2 are shown in Figures 21(a), and (b). From the figures, we can see that each trajectory is consistent and smooth, but due to much occlusion and cross, the whole environment is complex. In seq1, the players with ID12 (teamA), ID14(teamB) and ID18(teamB) run cross at the low part of the image plane (refer the supplementary video). Their moving direction of ID14 and ID18 is opposite. Their moving trajectories are shown in Figure 21 (c). In another example, we show a complex scene in seq2 (Figure 21(d)). There are three players with ID2(teamA), ID5(teamA) and ID7(teamB), they run to the same direction, but with different speed, and they almost tangle together. In these two exemplar complex cases, the algorithm can well handle and get right results. The cross and occlusion of these players can be observed in our shared video.

The input observation set of the first clip is shown in Figure 22(a). Figure 22(b) shows trajectories generated by tracking algorithm, with totally 24 players enter-ing/leaving the scene. It can be seen that most miss detections have been interpolated by association. Some selected results in France vs. Spain are given in Figure 23. The first column is the frame number. The second column represents the original image planes in the video. Column 3 is the Hough line detection result, in which red represents vertical lines and blue represents horizontal lines. Column 4 is the result of mapping field model to real image. Column 5 is the field registration result. We set the region of the camera focus to be gray and the other regions to be black. In the listed frames, frame 2  X  29 are left field, 120  X  180 are left-middle field, and 1200  X 1250 are right field. The results of frame 2, 13, 26, 120, 163  X  180, and 1200  X  1250 are obtained by direct estimation, the others are obtained by indirect estimation (some corresponding Hough line results are null). The result can be evaluated from two aspects: (1) the inverted mapped (from standard model to image plane) line-overlay image (column 4), and (2) the registered field (column 5). The lines in the field model can be mapped and overlaid on the real image with homography matrix. The overlay ratio between yellow and field lines implies the accuracy. The more overlay, the better accuracy is. On the other hand, the registered field in Column 5 also represents the performance. We can compare it with our subjective estimated results.

In theory, the direct estimation is more accurate than indirect estimation. But a problem exists as there are some falsely or inaccurately detected lines (due to players clutter or arc lines or others) such as in frame 26. The false and inaccurate lines have some bad effects in the final result. Although we perform exhausting search, remind of that the distance map used for error measurement is generated by the distance transform on these lines. The lines are missed in frame 130  X  150 by Hough transform. The reasons are: (1) motion blur resulting in dim lines, (2) some lines are too short and be omitted. But through the motion transition, the registered results are still good. The error accumulates along the time, thus the remapped image of frame 150 is not as good as frame 130. Anyway, we can see that the results of indirect estimation (frame 16 and 130) in real videos are good as well. Based on player tracking and field registration, we can map the players position and trajectories into the standard field model. For a player rectangle in the image plane, we get its center point and map it into the field model. Thus, players X  locations and their movement are well displayed. We list these results of the game FIFA 2006 Spain vs. France in Figure 24. Most of these middle views, left-middle and right-middle views are obtained through motion transition. Each player is labeled by a colored rectangle (color represents different player category) and a number at the up-left of the rectangle. It should be noted that all the labeled players are tracking results which is different from the initial detection results. After tracking, some players with short trajectories are removed. In general, the detection performance at the middle-field is better than other view angles because there are wider space and less occlusion. But on the contrary, the registration performance of the left/right field are better than that of the middle-field for there are more lines and key-points can be extracted for correspondence. A good player trajectory mapping needs not only good player tracking but also good field registration result. So, the final integrated player trajectories mapping is neither better than pure player tracking performance nor better than only field registration performance. But at least, the solution we proposed is feasible and practical and it works well in most time. For more experimental results, please refer to our shared video at http://www.flickr.com/photos/37625729@N03/3461850457/.

From these results, we can see that some visible players are missing. The reasons have: (1) the image is blurring especially during the camera transition (frame 120); (2) the player size is too small to be detected (frame 120), may we need more fine scanning scales in detection; and (3) some players are occluded by other players or line-marks (frame 1000). We run this system on a one-minute video clip (MPEG2 video, 720 the running speed. There are totally 1499 frames, which include 935 global views. In the global views, there are 5 player tracking shots and averagely 7.11 players in each global view. The running time and speed (frame per second, fps) are given in Table IV. The experimental platform is: Intel 2.4-GHz CPU and 2-GB RAM. In this article, we proposed an automatic player trajectory mapping algorithm based on player detection, unsupervised labeling, efficient player tracking and playfield registra-tion in broadcast soccer videos. The detection module combines background modeling and boosting detection. Labeling is achieved through unsupervised player appearance learning. MCMC data association is applied for tracking players. Most of players can be detected and tracked by our method, while some cases such as long occlusions, serious video blur, abrupt camera motion and player tangle may still lead to failure. The field registration module is feasible in real applications. We show the final results in real broadcast videos. The method can be utilized for team tactics and player activity analysis, etc. These modules are practical and proved to be robust and effective, and applicable to real video.

The player detection is simple and effective with the help of field background fil-tering by dominant color. Further, the effective detector collects player samples for color codebook learning of player appearance. The unsupervised clustering procedure is demonstrated to be applicable for many videos with different player appearance. Ac-tually, this module can be also used to detect and recognize announcer scene for news video parsing. Generic multi-object tracking is difficult. So we narrow this problem in soccer videos with robust player detection and player labels. The valid observations including dominant color, accurate player location and labeling and some efficient pro-posals make the tracking procedure workable. The key idea of field registration is to find corresponding key-point pairs between image plane and the standard field model. Actually, it is impossible to always detect enough lines and key-point pairs for motion blur, algorithm limited capability. We proposed a method that can work in all-day con-dition. Considering the running efficiency, we designed several efficient rejections to accelerate the search procedure.

The contributions of this system are: (1) robust and accurate player detection method; (2) automatic player appearance modeling, including two teams X  players and referee, without any manual labeling; (3) efficient global data association for player tracking; and (4) practical field registration algorithm including fast matching and rejection criterions. In a summary, the above solid work make the system to be practical and feasible and can be work in reality.

After having player moving trajectories and mapping homography matrix, we can detect ad retrieve action/activity scenes and analyze team tactics, such as player/ball pass through, etc.

