 The notion of collocation has been widely di s-cussed in the field of language teaching for de c-ades. It has been shown that collocation , a su c-cessive common usage of words in a chain, is important in helping language learners achieve native -like fluency. In the field o f English for Academic Purpose, more and more researchers are also re c ognizing this important feature in academic writing. It is often argued that colloc a-tion can influence the effectiveness of a piece of writing and the lack of such knowledge might cause cumulative loss of precision (Ho w arth, 1998).

Many researchers have discussed the function of collocations in the highly conventionalized and specialized writing used within academia. Research also identified noticeable increases in the quantity and qualit y of collocational usage by native speakers (Howarth, 1998). Granger (1998) reported that learners underuse native -like coll o-cations and overuse atypical word combinations. This disparity in collocation usage between n a-tive and non -native speakers is clear and should receive more attention from the language tec h-nology community.

To tackle such word usage problems, trad i-tional language technology often employs a d a-tabase of the learners' common errors that are manually tagged by teachers or specialists (e.g. Shei and Pain, 2000; Liu, 2002). Such system then identifies errors via string or pattern matc h-ing and offer only pre -stored suggestions. Co m-piling the database is time -consuming and not easily mai n tainable, and the usefulness is limited by the manual col lection of pre -stored sugge s-tions. Therefore, it is beneficial if a system can mainly use untagged data from a corpus contai n-ing co r rect language usages rather than the error -tagged data from a learner corpus. A large corpus of correct language usage s is m ore readily avai l-able and useful than a small labeled corpus of inco r rect language usage s .

For this suggestion task, the large corpus not only provides us with a rich set of common co l-locations but also provides the context within which these colloc a tions appear. Intuitively, we can take account of such context of collocation to generate more suitable suggestions. Contextual information in this sense often entails more li n-guistic clues to provide suggestions within se n-tences or par a graph. However, the conte xtual information is messy and complex and thus has long been overlooked or ignored. To date, most fashionable suggestion methods still rely upon the linguistic comp o nents within collocations as well as the linguistic relationship between mi s-used words and their correct counte r parts (Chang et al., 2008; Liu, 2009). 
In contrast to other research, we employ co n-textual information to automate suggestions for verb -noun lexical collocation. Verb -noun coll o-cations are recognized as presenting the most cha l lenge to students (Howarth, 1996; Liu, 2002). More specif i cally, in this preliminary study we start by focusing on the word choice of verbs in collocations which are considered as the most difficult ones for learners to master (Liu, 2002; Chang, 2008). The exper iment confirms that o ur collocation writing assistant proves the feasibility of using machine learning methods to automatically prompt learners with collocation suggestions in ac a demic writing. This study aims to develo p a web service, Coll o-cation Inspector (shown in Figure 1) that accepts sentences as input and generates the related ca n-didates for learners.

In this paper, we focus on automatically pr o-viding ac a demic collocation suggestions when users are writing up thei r abstracts. After an a b-stract is submitted, the system extracts li n guistic features from the user X  X  text for machine learning model. By using a corpus of published ac a demic texts , we hope to match contextual li n guistic clues from users X  text to help elici t the most rel e-vant suggestions. We now fo r mally state the problem that we are addres s ing:
Problem Statement : Given a sentence S wri t-ten by a learner and a reference corpus RC , our goal is to output a set of most probable sugge s-tion candidates c 1 , c 2 , ... , c m . For this, we train a class i fier MC to map the context (represented as feature set f 1 , f 2 , ..., f n ) of each sentence in RC to the collocation s . At run -time, we predict these collocations for S as suggestions. 2.1 Academic Collocation Checker Trai n-Sentence Parsing and Collocation Extraction: We start by collecting a large number of a b-stracts from the Web to develop a reference co r-pus for collocation suggestion. And we continue to ide n tify collocations in each sentence for the subsequent proce ssing.

Collocation extraction is an essential step in preprocessing data. We only expect to extract the collocation which comprises components having a syntactic relationship with one another. Ho w-ever, this extraction task can be complicated. Take the foll owing scholarly sentence from the reference corpus as an example (exa m ple (1)):
Traditionally, t hrough part -of -speech tagging, we can obtain a tagged sentence as follows (e x-a mple (2)). We can observe that the desired co l-location  X  X ntr o duce method X , conforming to  X  X ERB+NOUN X  relationship, exists within the sentence. However, the distance between these two words is often flexible, not necessarily rigid. Heuristically wri t ing pat terns to extract such verb and noun might not be effective. The patterns between them can be tremendously varied. In addition, some verbs and nouns are adjacent, but they might be inte r vened by clause and thus have no syntactic relation with one another (e .g.  X  X r o-pose model X  in example (3)).
A natural language parser can facilitate the e x-traction of the target type of collocations. Such parser is a program that works out the grammat i-cal structure of sentences, for instance, by ident i-fying which group of words go together or which word is th e subject or object of a verb. In our study, we take advantage of a dependency parser, Stanford Parser , which extracts typed depende n-cies for ce r tain grammatical relations (shown in Figure 2). Within the parsed sentence of example (1), we can notice that t he extracted dependency  X  X obj (introduce -2, method -4) X  meets the crit e-rion.
 Using a Classifier for the Suggestion task: A classifier is a function generally to take a set of attributes as an input and to provide a tagged class as an output. The basic way to build a cla s-sifier is to derive a regression formula from a set of tagged examples. And this trained class i fier can thus make pred i cation and assign a tag to any input data.

The suggestion task in this study will be seen as a classification problem. We treat the colloc a-tion extracted from each sentence as the class tag (see examples in Table 1). Hopefully, the system can learn the rules between tagged class es (i.e. collocations) and example se n tences (i.e. scho l-arly sentences) and can predict which coll o cation is the most appropriate one given attributes e x-tracted from the sentences.

Another advantage of using a classifier to automate suggestion is to provide alternatives with regard to the similar attributes shared by sentences. In Table 1, we can observ e that these co l locations exhibit a similar discourse function and can thus become interchangeable in these sentences. Therefore, based on the outputs along with the probability from the classifier, we can provide more than one ad e quate suggestions. Featu re Selection for Machine Learning: In the final stage of training, we build a statistical machine -learning model. For our task, we can use a s u pervised method to automatically learn the relationship between collocations and exa m-ple se n tences.
 We choose Max imum Entropy (ME) as our trai n-ing algorithm to build a collocation sugge s tion classifier. One advantage of an ME classifier is that in addition to assigning a classific a tion it can provide the probability of each assignment. The ME framework estimates prob abilities based on the principle of making as few assumptions as poss i ble. Such constraints are derived from the training data, expressing relationships b e tween features and outcomes. 
Moreover, an effective feature selection can increase the precision of machine lear n ing. In our study, we employ the context ual feature s which consist of two elements, the head and the ngram of co n text words:
Head : Each collocation comprises two parts, collocate and head. For example, in a given verb -noun collocation, the verb is the collocate as well as the target for which we provide suggestions; the noun serves as the head of collocation and convey the esse n tial meaning of the collocation. We use the head as a feature to condition the classifier to ge n erate candidates relevant to a given head.

Ngram : We use the context words around the target collocation by consider ing the correspon d-ing unigrams and bigrams words within the se n-tence. Moreover, to ensure the rel evance, those co n text words, before and after the punctuation marks enclosing the collocation in question, will be excluded. We use the parsed sentence from previous step (example (2)) to show the extracted context fe a tures 1 (example (4)): 2.2 Automatic Collocation Suggestion at After the ME classifier is automatically trained, the model is used to find out the best collocation suggestion. Figure 3 show s the algorithm of pr o-ducing suggestions for a given sentence. The i n put is a learner X  X  sentence in an abstract, along with an ME model trained from the re f erence corpus. 
In Step (1) of the al gorithm, we parse the se n-tence for data pr e processing. Based on the parser output, we extract the collocation from a given sentence as well as generate fe a tures sets in Step (2) and (3). After that in Step (4), with the trained machine -learning model, we o btain a set of likely collocates with probability as predicted by the ME model. In Step (5), SuggestionFilter singles out the valid coll o cation and returns the best collocation sugge s tion as output in Step (6). For example, if a learner inputs the sentence like Example (5) , the features and output cand i dates are shown in T a ble 2. From an online research database, CiteSeer , we have collected a corpus of 20,306 unique a b-stracts, which contained 95,650 sentences. To train a Maximum Entropy classifier, 46,255 co l-locations are extracted and 790 verbal collocates are identified as tagged classes for collocation suggestions. We tested the cla s sifier on scholarly sentences in place of authentic student writings which were not available at the time of this pilot study. We extracted 364 collocations among 600 randomly selected sentences as the held out test data not overlapping with the training set. To automate the evalu a tion, we blank out the verb collocates within these se n tences and treat these verbs directly as the only correct suggestions in question, although two or more suggestions may be interchangeable or a t least appropriate. In this sense, our evaluation is an underestimate of the perfor m ance of the proposed method.

While evaluating the quality of the sugge s tions provided by our system, we used the mean reci p-rocal rank (MRR) of the first relevant sugge s-tions returned so as to assess whether the sugge s-tion list conta ins an answer and how far up the answer is in the list as a quality me t ric of the sy s -tem output. Ta ble 3 shows that the best MRR of our prototype system is 0.518. The results ind i-cate that on average users could easily find a n-swers (exactly reproduction of the blanked out collocates) in the first two to three ranking of su g gestions. It is very likely th at we get a muc h high er MMR value if we would go through the lists and evaluate each suggestion by hand. Moreover, in Table 3, we can further n o tice that contextual features are quite informative in co m-parison with the baseline feature set co n taining merel y the feature of HEAD. Also t he integrated feature set of HEAD and CON TEXT t o gether achieve s a more satisfactory suggestion result. Many avenues exist for future research that are important for improving the proposed method. For example, we need to carry out the exper i-ment on authentic learners X  texts. We will co n-duct a user study to investigate whether our sy s-tem would i m prove a learner X  X  writing in a real setting. Additionally, adding classifier features based on the translation of mi s used word s in lear n ers X  text could be beneficial (Chang et al., 2008). The translation can help to resolve prev a-lent collocation misuses influenced by a learner's native la n guage. Yet another dire c tion of this research is to investigate if our methodo l ogy is appli cable to other types of collocations, such as AN and PN in addition to VN dealt with in this paper.

In summary, we have presented an unsupe r-vised method for suggesting collocations based on a corpus of abstracts collected from the Web. The method involves selecting features from the refe r ence corpus of the scholarly texts. Then a classifier is automatically trained to determine the most probable collocation candidates with regard to the given context. The preliminary r e-sults show that it is beneficial to us e classifiers for identifying and ranking collocation sugge s-tions based on the context fe a tures. 
