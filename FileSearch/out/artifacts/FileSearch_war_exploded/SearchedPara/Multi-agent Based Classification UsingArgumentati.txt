 Argumentation is concerned with the dialogical reasoning processes required to arrive at a conclusion given two or more a lternative viewpoin ts. The process of multi-agent argumentation is conceptualised as a discussion, about some issue that requires a solution, between a set of software agents with different points of view; where each agent attempts to persuade the others that its point of view, and the consequent solution, is the correct one. In this paper we propose apply-ing argumentation to facilitate classification. In particular, it is argued that one model of argumentation, Arguing from Experience ([24,23]), is well suited to the classification tasks. Arguing from Experience provides a computational model of argument based on inductive reasoning from past experience. The arguments are constructed dynamically using Classification Association Rule Mining (CARM) techniques. The setting is a  X  X ebate;; about how to classify examples; the gen-erated Classification Association Rules (CARs) provide reasons for and against particular classifications.

The proposed model allows a number of agents to draw directly from past examples to find reasons for coming to a decision about the classification of an unseen instance. Agents formulate their arguments in the form of CARs gen-erated from datasets of past examples. Each agent X  X  dataset is considered to encapsulate that agent X  X  experience . The exchange of arguments between agents represents a dialogue which continues until an agent poses an argument for a par-ticular classification that no other agent can refute. The model has been realised in the form of argumentation framework called PISA: Pooling Information from Several Agents . The promoted argumentation-based approach is thus a multi-agent classification technique [5] that offers a number of practical advantages: (i) dynamic generation of classification rules in a just in time manner accord-ing to the requirements of each agent, (ii) easy-to-understand explanations, in the form of dialogues, concerning a particular classification, and (iii) applica-tion to ordinal classification and imbalanced class problems as well as standard classification. The approach also provides for a natural representation of agent  X  X xperience X  as a set of records, and the arguments as CARs. At the same time the advocated approach also preserves the privacy of the information each agent knows , therefore it can be used with sensitive data.

The rest of this paper is organised as fo llows. Section 2 provides an overview of the PISA Framework. Section 3 details the nature of the Classification Asso-ciation Rules (CARs) used in PISA. In Section 4 details and empirical analysis are provided of three different applications of PISA to classification problems: (i) standard classification, (ii) ordinal classification and (iii) the imbalanced class problem. Finally, we conclude with a summary of the main findings and some suggested for further work. The intuition behind PISA is to provide a method whereby agents argue about a classification task. In effect each agent can be viewed as a dynamic classi-fier. The overall process thus leads to a reasoned consensus obtained through argumentation, rather than some other mechanism such as voting (e.g. [2]). It is suggested that this dialogue process increases the acceptability of the out-come to all parties. In this respect PI SAcanbesaidtobeanensemble-like method. Both theoretical and empirical research (e.g. [20]) has demonstrated that a good ensemble is one comprising individual classifiers that are relatively accurate but make their errors on different parts of the input training set. Two of the most-popular ensemble methods are: (i) Bagging [3] and (ii) Boosting [14]. Both techniques rely on varying the data to obtain different training sets for each of the classifiers in the ensemble.

PISA is viewed as a bagging-like multi-agent ensemble, whereby the dataset is equally divided amongst a number of participants corresponding to the number of class values in the dataset. Each participant applies the same set of algorithms to mine CARs supporting their advocated class. To this end, each participant can be said to correspond to a single cla ssifier. The argumentation process by which each participant advances moves to support its proposals corresponds to voting methods by which ensemble techniques assign class labels to input cases. But rather than simple voting, PISA applies an argumentation debate (dia-logue). PISA also differs from Boosting t echniques in that it does not generate a sequence of classifiers; instead the desir ed classification is achieved through the collaborative operation of s everal classifiers. Further more, PISA classifies unseen records by (dynamically) producing a limited number of CARs sufficient to reach a decision without the need to produce the full set of CARs.

The PISA framework comprises three key elements: 1. Participant Agents. A number of Participant Agents, at least one for 2. Chairperson. A neutral mediator agent which administers a variety of tasks 3. Set of CARs. The joint set of CARs exchanged in the course of one PISA Each Participant Agent has its own distinct (tabular) local dataset relating to a classification problem (domain). These agents produce reasons for and against classifications by mining CARs from their datasets using a number of CARM algorithms (Section 3). The antecedent o f every CAR represents a set of reasons for believing the consequent. In other words given a CAR, P  X  c , this should be read as: P are reasons to believe that the case should classify as c .CARs are mined dynamically as required. The dynamic mining provides for four dif-ferent types of move , each encapsulated by a distinct category of CAR. Each Participant Agent can employ any one of the following types of move to gen-erate arguments: (i) Proposing moves, (ii) Attacking moves, and (iii) Refining moves. The different moves available are discussed further below. Note that each of these moves has a set of legal next moves (see Table 1).
 Proposing Moves . There is only one kind of proposing move: 1. Propose Rule: Allows a new CAR, with a confidence higher than a given Attacking Moves . Moves intended to show that a CAR proposed by some other agent should not be considered decisive with respect to the current instance. Two sub-types are available: (i) Distinguish and (ii) Counter Rule, as follows: 2. Distinguish: Allows an agent to add new attributes (premises) to a previ-3. Counter Rule: Similar to Propose Rule but used to cite a classification Refining Moves . Moves that enable a CAR to be refined to meet a counter attack . For the purposes of using PISA as a classifier, one refining move is implemented: 4. Increase Confidence: Allows the addition of new attribute(s) to the Having introduced, in the foregoing, the legal moves in PISA dialogues, the real-isation of these moves is described in this section. The idea is to mine CARs ac-cording to: (i) a desired minimum confidence, (ii) a specified consequent and (iii) a set of candidate attributes for the an tecedent (a subset of the attributes rep-resented by the case under discussion). Standard CARM techniques (e.g.[7,16]) tend to generate the complete set of CARs represented in the input data. PISA on the other hand utilises a just in time approach to CARM, directed at gen-erating particular subsets of CARs, and applied such that each agent mines appropriate CARs as needed. The mining process supports two different forms of dynamic ARM request: 1. Find a subset of rules that conform to a given set of constraints. 2. Distinguish a given rule by adding additional attributes.
 In order to realise the above, each Participant Agent utilises a T-tree [6] to summarise its local dataset. A T-tree is a reverse set enumeration tree structure where nodes are organised using reverse lexicographic ordering, which in turn enables direct indexing according to attribute number; therefore computational efficiency gains are achieved. A further ad vantage, with respect to PISA, is that the reverse ordering dictates that each sub-tree is rooted at a particular class attribute, and so all the attribute sets pertaining to a given class are contained in a single T-tree branch. This means that any one of the identified dynamic CARM requests need be directed at on ly one branch of the tree. This reduces the overall processing co st compared to other prefix tree structures (such as FP-Trees [16]). To further enhance the dynamic generation of CARs a set of algorithms that work directly on T-trees were developed. These algorithms were able to mine CARs satisfying different values of support threshold. At the start of the dialogue each player has an empty T-tree and slowly builds a partial T-tree from their data set, as required, containing only the nodes representing attributes from the case under discussion plus the class attribute. Note that no node pruning, according to some user specified threshold, takes place; except for nodes that have zero support. Two dynamic CAR retrieval algorithms were developed: (i) Algorithm A which finds a rule that conforms to a given set of constraints, and (ii) Algorithm B which distinguishes a given rule by adding additional attributes. Further details of these algorithms can be found in [25]. Arguing from Experience enables PISA agents to undertake a number of different tasks, mainly: 1. Multi-agent Classification : Follows the hypothesis that the described oper-2. Ordinal Classification : Follows the hypothesis that PISA can be successfully 3. Classifying imbalanced data using dynamic coalitions : Follows the hypothesis In this section the above applications of PISA are empirically evaluated. For the evaluation we used a number of real-world datasets drawn from the UCI reposi-tory [4]. Where appropriate continuous v alues were discretis ed into ranges. The chosen datasets (Table 2) display a vari ety of characteristics with respect to number of records ( R ), number of classes ( C ) and number of attributes ( A ). Im-portantly, they include a diverse number of class labels, distributed in a different manner in each dataset (balanced and unbalanced), thus providing the desired variation in the experience assign ed to individual PISA participants. 4.1 Application 1: PISA-Based Classification The first application of PISA is in the context of multi-agent classification based on argumentation. In order to provide an empirical assessment of this application we ran a series of experiments designed t o evaluate the hypothesis that PISA pro-duces at least comparative results to that obtained using traditional classification paradigms. In particular, ensemble classification methods. The results presented throughout this sub-section, unless otherwise noted, were obtained using Ten-fold Cross Validation (TCV). For the purposes of running PISA, each training dataset was equally divided among a number of Participant Agents correspond-ing to the number of classes in the dataset. Then a number of PISA dialogues were executed to classify the cases in the test sets 1 . In order to fully assess its operation, PISA was compared against a range of classification paradigms: .
 1. Decision trees : Both C4.5, as implemented in [15], and the Random Decision 2. CARM : The TFPC (Total From Partial Classification) algorithm [7] was 3. Ensemble classifiers : Table 3 summarises the techniques used. We chose to
For each of the included methods (and PISA) three values were calculated for each dataset: (i) classification error rate , (ii) Balanced Error Rate (BER) using a confusion matrix obtained from each TCV 2 ; and (iii) execution time . These three values then provided the cri teria for assessing and comparing the classification paradigms.
 The results are presented in Table 4. From the table it can be seen that PISA performs consistently well; out performing the other association rule clas-sifier, and giving comparable results to the decision tree methods. Additionally, PISA produced results comparable to those produced by the ensemble methods. Moreover, PISA scored an average overall accuracy of 93.60%, higher than that obtained from any of the other methods tested (e.g. Bagging-RDT (89.48%) and RDT (90.24%)) 3 .

Table 5 shows the BER for each of the given datasets. From the table it can be seen that PISA produced reasonably good results overall, producing the best result in 14 out of the 39 datasets tested.
 Table 6 gives the execution times (in milliseconds) for each of the methods. Note that PISA is not the fastest method. However, the recorded performance is by no means the worst (for instance Decorate runs slower than PISA with respect to the majority of the datasets). Additionally, PISA seems to run faster than Bagging and ADABoost with some datasets. 4.2 Application 2: PISA-Based Ordinal Classification Having established PISA as a classification paradigm, we now explore the appli-cation of PISA to ordinal classification. In this form of multi-class classification the set of class labels is finite and ordered. Whereas traditional classification paradigms commonly assume that the class values are unordered. For many practical applica-tions class labels do exhibit some form of order (e.g. the weather can be cold, mild, warm and hot). Given ordered classes, one is not only concerned to maximise the classification accuracy, but also to mini mise the distances between the actual and the predicted classes. The problem of ordi nal classification is often solved by either multi-class classification or regression methods. However, some new approaches, tailored specifically for ordinal classification, have been introduced in the litera-tures (e.g. [13,22]). PISA can be utilised for ordinal classification by the means of biased agreement . Agents in PISA have the option to agree with CARs suggested by other agents, by not attacking these rules, even if a valid attack is possible. PISA agents can either agree with all the opponents or with a pre-defined set of opponents that match the class order. For instance, in the weather scenario, agents support-ing the decision that the weather is hot, agree with those with the opinion that the weather is warm, and vice versa. Wher eas agents supporting that the weather is cold or mild agree with each other. We refer to the latter form of agreement by the term biased agreement . In which the agents are equipped with a simple list of the class labels that they could agree with (the agreement list ). Here, we have two forms of this mode of agreement: 1. No Attack Biased Agreement (NA-BIA): In which agents consult their 2. Confidence Threshold Bias ed Agreement (CT-BIA): Here, if the To test the hypothesis that the above approach improves the performance of PISA when applied to ordinal classification a series of TCV tests, using a number of datasets from Table 2 which have ordered classes, were conducted. PISA was run using the NA-BIA and CT-BIA strategies, and the results were compared against the use of PISA without any agreement strategy. Additionally, to provide better comparison the Mean Squared Error (MSE) and the Mean Absolute Error (MAE) rates for the included datasets and methods were calculated. [11] notes that little attention has been directed at the evaluation of ordinal classification solutions, and that simple measures, such as accuracy, are not sufficient. In [11] a number of evaluation metrics, for ordinal classification, are compared. As a result MSE is suggested as the best metric when more (smaller) errors are preferred to reduce the number of large errors; while MAE is a good metric if, overall, fewer errors are preferred with more tolerance for large errors. Table 7 provides a summary of the results of the experiments. From the table it can be seen that the NA-BIA produces better results with datasets with ordinal classes. 4.3 Application 3: PISA-Based Solution to the Imbalanced Class Another application of PISA is using dynamic coalitions between different agents to produce better performance in the f ace of imbalanced class problem. It has been observed (e.g.[17]) that class imbal ance (i.e a significant differences in class prior probabilities) may produce an important deterioration of the performance achieved by existing learning and classification systems. This situation is often found in real-world data describing an infrequent but important case (e.g. Table 2. There have been a number of proposed mechanisms for dealing with the class imbalance problem (e.g. [10,21]). [12,17] note a number of different approaches: 1. Changing class distributions: by  X  X psizing X  the small class at random (or 2. At the classifier level by either: manipulating classifiers internally, cost-3. Specially designed ensemble learning methods. 4. Agent-based remedies such as that proposed in [18] where three agents, each In the following we present a refinement of the basic PISA model which en-ables PISA to tackle the imbalance-class problem in multi-class datasets, using Dynamic Coalitions between agents representing the rare classes. Unlike the bi-ased agreement approach (Sub-section 4.2), coalition requires mutual agreement among a number of participants, thus a pre paration step is necessary. However, for the purposes of this paper we assume that the agents representing the rare classes are in coalition from the start of the dialogue, thus eliminating the need for a preparatory step. The agents in a coalition stop attacking each other, and only attack CARs placed by agents outside the coalition. The objective of such coalition is to attempt to remove the agents representing dominant class(es) from the dialogue, or at least for a pre-defined number of rounds. Once the agent in question is removed from the dialogue, the coalition is dismantled and the agents go on attacking each others as in a normal PISA dialogue. In the following we provide experimental analysis of two coalition techniques: 1. Coalition (1) : The coalition is dismantled if the agent supporting the dom-2. Coalition (2) : The coalition is dismantled if the agent supporting the dom-To test the hypothesis that the above approaches improves the performance of PISA when applied to imbalanced class datasets we ran a series of TCV tests using a number of datasets from Table 2, which have imbalanced class distribu-tions. The results were compared against the use of PISA without any coalition strategy. Four measures were used in this comparison: error rate, balanced error rate, time and geometric mean (g-mean) 4 . This last measure was used to quan-tify the classifier performance in the class [1]. Table 8 provides the result of the above experiment. From,the table it can be seen that both coalition techniques boost the performance of PISA, with imbalance-class datasets, with very little additional cost in time, due to the time needed to dismantle the coalitions. The PISA Arguing from Experience Framework has been described. PISA al-lows a collection of agents to conduct a dialogue concerning the classification of an example. The system progresses in a round-by-round manner. During each round agents can elect to propose an argument advocating their own position or attack another agent X  X  position. The arguments are mined and expressed in the form of CARs, which are viewed as generalisations of the individual agent X  X  experience. In the context of classificat ion PISA provides for a  X  X istributed X  classification mechanism that harnesses all the advantages offered by Multi-agent Systems. The effectiveness of PISA is compa rable with that of other classification paradigms. Furthermore the PISA approach to classification can operate with temporally evolving data. We have also demonstrated that PISA can be utilised to produce better performance with imbalanced classes and ordinal classification problems.

