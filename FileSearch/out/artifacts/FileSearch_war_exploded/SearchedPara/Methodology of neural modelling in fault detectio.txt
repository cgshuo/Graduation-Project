 fi 1. Introduction
Recent technical matters are more and more complex, hetero-geneous, dynamic, and of various forms. Industrial systems such as chemical and oil re fi neries, nuclear power and thermal power plants, aircrafts and many others are composed of dedicated hard-ware and software parts. These components are often quite com-plex, thus increasing their potential for failures. When any failure occurs, then the standard solution is to stop a plant, and employ a servicing personnel for repairing every faulty component in the object. Therefore, the problems of reliability, maintainability, survi-vability of technical matters and especially their ability of fault tolerance have become a major concern in the last years. Effectively detecting and adapting to software and hardware faults allow the system to continue working until repairs can be realistically sched-uled. Currently, it is known to be one of the most important issues in advanced control system design and analysis ( Blanke et al., 2006; Caccavale and Villani, 2003; Isermann, 2006; Korbicz et al., 2004; Patton et al., 2000 ).

Fault tolerance in dynamic systems is traditionally achieved using hardware redundancy. This technique is rather straightforward to critical process plants. The most important problems encountered with this approach are an additional cost of the redundant hardware, weight increase, additional space required to accommodate the equipments and usually additional sources of energy such as batteries. On the other hand, analytical or information redundancy is a practical control architectures. The main advantage of this technique is that it improves the capability of fault tolerance by adding fewer extra components and increasing computation power ( Korbicz et al., 2004; Patton et al., 2000 ). The general schematic arrangement appropriate to many active fault tolerant systems has four main components: the system itself (including sensors and actuators), the fault diagnosis unit, the controller and the supervision system (with the control recon fi guration mechanism). Fault diagnosis using analytical or information redundancy is one of the most popular approach in the domain of the process diagnostics. Model-based fault diagnosis makes use of quantitative and/or qualitative models of the supervised object Real-time fault diagnosis systems usually realize each of these three tasks independently. The typical fault diagnosis scheme in practical must for any practical systems. Furthermore, a fault has to be detected avoid more serious consequences.

In recent years, arti fi cial neural networks, especially recurrent ones have attracted considerable research interest in the model-based control and diagnostic systems. On the one hand, results and data from industrial applications con fi rm human safety and economic ef fi ciency of such approaches, but on the other hand, there is still the need to elaborate much more general neural models that might be used for modelling both deterministic and stochastic processes simultaneously. Recurrent neural networks are a class of parametric, nonlinear dynamic models that have found widespread use in fault diagnosis and fault-tolerant control systems, including identi fi cation of dynamic systems and modelling problems ( Korbicz et al., 2004 ). In general, recurrent neural networks can be viewed as universal approximators for spatiotemporal data ( Gupta et al., 2003;
Patan, 2008a ). They can be classi fi ed into two categories ( Korbicz et al., 2004; Patan, 2008b ): globally (totally or partially) recurrent with feedback connections between simple static neurons of differ-ent layers or/and these of the same layer. The second one encom-passes neural structures similar to static feed-forward topologies, however they include dynamic neural units with internal feedback connections. The locally recurrent architecture is basically obtained by introducing dynamic elementary processors into the structure of a feed forward network ( Korbiczetal.,2004;Patanetal.,2008 ).
Numerous examples of the most important strategies for developing dynamic units and locally recurrent topologies and their applications in areas of fault diagnosis can be found e.g. in the papers ( Ayoubi, 1994; Korbicz, 2006; Korbicz et al., 2004; Patan, 2008a; Patan et al., 2008 ) and monograph ( Patan, 2008b ).

Taking into account the current state of the art in the fi of neural model-based fault detection it was stated that it was necessary to develop more advanced neural modelling methods in order to reduce uncertainties caused by various sources. On the other hand, it is well known that it is impossible to entirely eliminate such origins of uncertainties as measuring noise, unknown disturbances and modelling errors. Therefore, there is also the need to elaborate robust fault detection methods by enhancing the robustness of the decision making block. These considerations were the basis for the hypothesis that the proposed methodology for neural modelling of dynamic systems with the use of some parts of the chaos theory, to disturbances and modelling errors.

Chaos together with the theory of relativity and quantum mechanics is considered as one of the three monumental dis-coveries of the twentieth century. In turn, Zadeh (1994) indicates chaos theory as one of the principal constituent of soft computing.
There are a lot of areas where chaos engineering is successfully applied, such as medical diagnostics ( West, 1990 ), control systems ( Fradkov and Evans, 2005 ), communication systems ( Stavroulakis, 2005 ), mechanical systems ( Moon, 2004 ), and many others. More-over, chaos engineering contributes to develop various prototypes of everyday devices (such as washing machines, heaters, and microwaves) raising their ef fi ciency and reliability ( Hirota, 1995;
Moon, 2004 ). Theoretical and experimental studies on applications of chaos engineering in technical diagnostics can be divided into two groups: passive and active approaches. The fi rst group of methods makes full use of nonlinear data analysis, that is fractal analysis, recurrence quanti fi cation analysis, and others ( Bogu Merkisz, 2005; Bi-qiang Du et al., 2008; Nichols et al., 2006;
Tykierko, 2008 ), whereas the second one depends on using chaotic systems in direct way ( Li and Qu, 2007; Song et al., 2009 ).
The rest of the paper is organized as follows. In Section 2 the detailed description of the proposed approach is given. In particular, there are contained investigations on a locally recurrent neural network as a tool for modelling purposes and biphasic hybrid algorithms that are used for tuning adjustable network parameters.
This section includes also a form al description of two procedures proposed for architecture selection as well as the method which is suggested to robust fault detection. Section 3 contains the results of veri fi cation experiments, and the last section is devoted to conclud-ing remarks. 2. Neural model-based fault detection using chaos engineering
The proposed methodology can be viewed as the extension of the most often used model-based fault detection approach, where a neural model is created for faultless state of the system, cf. Korbicz et al. (2004) , Fig. 1 . 6 at p. 22, or Chapter 9 at pp. 333 novelty in this study is the use of chaos theory in the development of fundamental parts of such fault detection architecture. This means that chaos engineering is employed to advance arti fi neural networks and decision blocks of model-based fault detection schemes. The application of chaos theory in this matter is well founded because of two facts. Firstly, neural models with chaotic neurons are able to be much more sensitive to abrupt as well as incipient faults (chaotic systems are very sensitive to even small changes in the initial conditions). Secondly, advanced nonlinear time series analysis methods developed in the background of chaos theory can be used in residual evaluation process. It is reasonable due to the fact that such analysis techniques were elaborated to better understand phenomena related to chaotic systems (in our case residual signal is generated by using chaotic neural network).
The proposed scheme of fault detection is presented in Fig. 1 .There are two main parts: a neural model of the system for residual generation and a decision block for residual evaluation.
As one can see, input (U) and output (Y) process variables are collected by SCADA system. The subset of the most relevant signals is determined by means of extended Hellwig's method applying chaos engineering. Selected input signals  X  U 0  X  are processed by a locally recurrent globally feed forward neural network in order to compute redundant signals  X  Y 0 m  X  which are compared with output signals  X  Y 0  X  registered by SCADA system. A neural model which is composed of chaotic neurons is created using historical data U gathered for nominal conditions of the object. It should be noted here, that hybrid training schemes using chaotic systems are used for adjusting values of parameters of the neural network. The result of the comparison is residual signal (R) which should be equal to zero when there is not any faults (F) in the system or be greater than zero when the faults occur. The residuum has a complex nature due to the different origins of uncertainties corresponding to disturbance (D) and modelling errors. Therefore, the passive robust fault evalua-tion is realized using recurrence quanti fi cation analysis which was initially proposed in the literature for diagnosing chaotic systems.
This technique is used to calculate features (M) of the residuum to be useful in formulation of conditions in the decision block. As a result, the diagnostic signal (S) is generated taking into account values of thresholds identi fi ed for recurrence quanti fi sures. The next subsections in this paper illustrate more detailed backgrounds of the proposed methodology. 2.1. Locally recurrent neural network
As it was mentioned above, in contrast to globally recurrent structures with feedback connections between simple static neu-rons of different layers or/and these of the same layer, locally recurrent networks are similar to static feed forward topologies.
However, they include dynamic neural units with internal feed-back connections. Therefore, it is necessary to de fi ne the formal model of the elementary neural unit with the internal dynamics. 2.1.1. Dynamic neural unit
The authors have proposed the dyn amic neural processor that can be investigated as an extension of two units well practised in the area of fault diagnosis, viz. a dynamic neural unit with an in response fi lter in the activation block ( Ayoubi, 1994; Patan, 2008b ) of the unit is presented in Fig. 2 . The proposed model of the neuron wasthesubjectofnumerousinvestigationsofthe fi rst author of this paper (see e.g. Przysta  X  ka, 2007, 2008 ).

Under consideration its behaviour is described by a few equations. The state in the summing junction is computed using the following equation: k  X  X  X  u ( k ) is the i -th external input of the unit,  X  3 k  X  X  is the feedback state of the neuron. Using the backward shift operator q 1 the activation state of the unit at the discrete time k is formulated as follows: Aq 1  X  2 k  X  X  X  Bq 1  X  1 k  X  X  X  Cq 1  X  A k  X  X  ;  X  2  X  and also the state in the feedback block may be written in the same way Dq 1  X  3 k  X  X  X  Eq 1 yk  X  X  X  Gq 1  X  F k  X  X  :  X  3  X 
Finally, the output of the unit at the discrete time k is obtained from yk  X  X  X  f  X  2 k  X  X  X  b ;  X  4  X  where Aq 1 , Bq 1 , ... , Gq 1 are polynomials of the delay operator q 1 , terms  X  A ,  X  F denote random processes with the mean values  X  A ,  X  F and the variances  X  2 A ,  X  2 F , f is the output function of the neuron, b is a bias.

Such elementary processor possesses two new features when comparing it with other arti fi cial neurons known from the litera-ture. For one thing, the output of the neuron might be stochastic, and for another, the neuron might be only described by determi-chaotic neuron). The fi rst situation can be achieved, if either Cq 1 or Gq 1 to be different from zero. The second one is much more complicated and can be obtained if the output function f to be nonlinear and the feedback block is activated that means, if the polynomial Eq 1 a 0. Nonlinear analysis was realized for this case to prove the complex nature of the neuron. Fig. 3 (a) demonstrates the bifurcation diagram graphed for the constant input signal u  X  k
 X  X  0 : 5 and bifurcation parameter e 0 . This allows a comparison between the periodic and chaotic behaviours of the proposed unit.
It can be observed that Fig. 3 (b) illustrates the contour plot of the largest Lyapunov's exponent of such dynamic neural unit as the relat-ion between the input signal u ( k ) and the refractory parameter e indicates a chaotic character of its behaviour and it is achieved for the following values of parameters: Cq 1  X  0, Dq 1  X  1, systems. 2.1.2. Neural network structure
The structure used in this study is presented in Fig. 4 .Asonecan see, it is composed of three layers. There are simple static neurons with a nonlinear output function in the fi rst layer. The second layer includes non-linear dynamic neur ons with unknown inputs. Such units are obtained by introducing linear dynamic systems into the structure of the neuron as it was shown in the previous section. The last layer consists of simple static units in which the output function is linear. Neural processing in the fi rst and the output layers is the same as it is in feed forward topologies. In layers where dynamics is included more complicated operations are needed.

The output signal of the i -th dynamic layer of a locally recurrent network is computed using a nonlinear or linear transform operator: y k  X  X  X  f i  X  i 2 k  X  X  X  b i :  X  5  X 
Internal states of neurons in the activation block of the i -th layer can be written using the polynomial notation in a vector form:
A q 1  X   X   X  i 2 k  X  X  X  B i  X  q 1  X   X   X  i 1 k  X  X  X  C i  X  q 1  X   X  and also for the feedback block:
D q 1  X   X   X  i 3 k  X  X  X  E i  X  q 1  X   X  y i k  X  X  X  G i  X  q 1  X   X   X  i
An associative input activation of neurons in the i -th layer is given by the following expression:  X  i k  X  X  X  IW i y i 1  X  k  X  X  FW i  X   X  i 3  X  k  X  ;  X  8  X  where IW i is the matrix of external input weights, FW i is the vector of feedback weights,  X  indicates an array multiplication, b is a bias vector, A i q 1 , B i q 1 ; ... ; G i q 1 are vectors with polynomials of the variable q 1 ,  X  i n  X  k  X  denotes the vector with activation or feedback states of neurons in the i -th layer, unknown inputs  X  i A  X  k  X  and  X  i F  X  k  X  are represented by the vector-valued random processes. 2.1.3. Stability analysis of the neural model
Asymptotic stability of a locally recurrent network is guaranteed, if every dynamic neuron in the network is asymptotically stable ( Patan, 2008b ). Two cases are considered in this paper using the
Lyapunov's method: dynamic neurons with linear and nonlinear output functions. Global asymptot ic stability conditions for linear units are determined by means of the following characteristic polynomials:
Aq  X  X  X  q na  X  a 1 q na 1  X   X   X  a na ;  X  9  X 
Dq  X  X  X  q nd  X  d 1 q nd 1  X   X   X  d nd ;  X  10  X 
Hq  X  X  X  Aq  X  X  Dq  X  X  w r  X  h 0 q nh  X  h 1 q nh 1  X   X   X  h nh ;  X  11  X  where nh  X  max deg Aq  X  X  Dq  X  X   X  X  ; deg Bq  X  X  Eq  X  X   X  X  ,anditscoef h  X 
X where j  X  0 ; 1 ; ... ; nh , a k  X  0for k 4 na , d j k  X  0for0 b  X  0for l 4 nb , e j l  X  0for0 4 j l 4 ne .

On the other hand, for nonlinear dynamic neurons (where f  X  x  X  X  tanh  X  x =  X  f  X  ) local asymptotic stability conditions are deter-mined if a nonlinear output function to be linearized for the equilibrium point at the origin. Hence, the characteristic poly-nomials for nonlinear neurons are similar as in the previous one, but
Hq  X  X  X   X  f Aq  X  X  Dq  X  X  w r
A dynamic neural unit is stable if all roots q i of the character-istic polynomials are inside the unit circle. Schur  X  Cohn's algorithm ( Henrici, 1988 ) is used in this paper to decide whether a given polynomial is free of zeros in the closed unit disk. 2.2. Hybrid training scheme
The main purpose of the training process is to minimize an assumed objective function. Due to this reason and also to prevent other troubles such as the stability of a neural model and the local minima problem, a diphase hybrid training scheme is proposed. In this paper, the hybrid training strategy is composed of two parts: global and local optimization algorithms. The global algorithm is run to reach the region near an optimum point by minimizing the combined function:
E  X  X  X  where n s is the number of network outputs, Q is the number of training patterns, p is the number of network parameters, represents a vector with adjustable network parameters, y t ( k ) is the j -th target output at the discrete time k , network parameter at the n -th algorithm step, R ,  X  and  X  black box-type coef fi cients.

The fi rst term in Eq. (14) is the Minkowski-R error, whereas the second one is an additive parameter-depend energy and it is employed in order to prevent over fi tting. In this stage of the training process two kinds of soft computing approaches for global optimization are investigated: evolutionary algorithm (EA) and simulated annealing algorithm (SAA).

Then the solution from the global optimization step is set as an initial point for a local method that is faster and more ef local search. For this purpose, well-known line search, trust-region or conjugate gradient methods can be applied (e.g. steepest descent or quasi-Newton methods). However, taking into account results of experiments obtained in the related study ( Przysta 2007 ), in the current paper it is only realized by minimizing the objective function (14) for  X   X  0 and R  X  2 with the use of the
Levenberg  X  Marquardt rule (LM) in the following form: where the Hessian matrix is approximated by the Jacobian matrix as follows H  X  n  X  X  X  J T  X  n  X  X  J  X  n  X  X  , the regularization factor puted in the same way as it is presented in Hagan and Menhaj (1994) . For the structure proposed by the authors the Jacobian matrix is derived using a numerical differentiation method ( Nocedal and Wright, 2006 ) or a stochastic approximation approach ( Spall, 2003 ).
Therefore, there is no need to have the Jacobian information that is analytically calculated. After both stages of the training process the asymptotic stability of the locall y recurrent neural model must be checked using rules described in the previous section. If any of the dynamic neural units is unstable, the training procedure has to be repeated. 2.2.1. Evolutionary algorithm
Evolutionary algorithms are based on the natural selection process that mimics biological evolution. In order to apply such an optimization technique for training neural models it is neces-sary to de fi ne the following properties of the algorithm ( Deb, 2009 ): the representation of the individuals, the fi tness function, selection and succession methods, crossover and mutation opera-tors. It is assumed, that the number of individuals ( L p population is fi xed at each epoch of the evolutionary process and that individuals are composed of genes representing real numeric values of adjustable network parameters. Note that the chromo-some contains information about synaptic connection weights, parameters of linear dynamic systems for each neuron, and key parameters of its output function. The length of the chromosome is dependent on the complexity of the network structure and equals the length of the vector  X  : chr  X   X  T  X   X  1  X  2  X   X  j  X   X  p :  X  16  X 
The initial population can be generated in different ways, but in this paper it is realized applying Patan's (2008b) method. It guarantees the stability of the neural model at the beginning of the training process. The fi tness value of an individual is computed using the fi tness function which is declared on the basis of the objective function (14) . The best fi tness value for a population is the smallest fi tness value for every individual in the population.
Roulette wheel selection is applied to choose parents for the next generation, whereas succession operations are realized by de the reproduction rules characterized by two parameters: elite number of individuals with the best fi tness values in the current generation that are guaranteed to survive to the next generation.
The second one is the fraction of individuals in the next genera-tion, other than elite children, that are created by crossover.
In view of the fact that the evolutionary algorithm is mainly employed to fi nd initial values of adjustable parameters, it is decided to use a simple heuristic crossover operator. On the basis of two individuals  X  1 and  X  2 , in the case if E  X  1 o E where  X  h is a fraction pointing at the better adapted individual.
Two types of mutation operator are responsible for generating heterogeneous individuals. The fi rst function is known as an uniform mutation and it changes a selected chromosome as follows: where the value of a gene  X  n j is obtained from the random number generator. Each entry of the chromosome has a probability rate r of being mutated. The second operator of this type used herein is a non-uniform mutation. This one changes a selected chromosome in such a way where  X  i is a vector ( p 1) with random process values. The variance of its distribution is determined by the parameters scale ( ) and shrink (  X  2 ) at each epoch. The scale parameter determines the variance at the fi rst generation. The shrink parameter controls how the variance shrinks as generations go by according to the recursive formula  X  n  X   X  n 1 1  X  2 n = m ,where  X  0  X   X  1 is the number of epochs, n is the number of the n -th generation. Different kinds of distributions are usually practiced for the pseudo random number generator. The best examples of them are the uniform distribution U  X  1 ; 1  X  or the Gaussian distribution systems are also applied ( Awrejcewicz and Mosdorf, 2003 ):
H X non's map:
Iked's map:
Mackey  X  Glass's equation: where initial values in Eqs. (20)  X  (22) are set randomly using the uniform distribution U  X  0 ; 1  X  .
 2.2.2. Simulated annealing algorithm
Simulated annealing algorithm imitates the physical process of temperature is slowly lowered to decrease defects and it leads to minimize the system energy. The simulated annealing scheme pro-posed by Ingber (1996) is employed in order to tune network parameters in this paper. This optimization method requires to specify for generating new points for the next iteration. In this paper, the candidate solutions are calculated using the following equation: where the vector  X  n is obtained in the same way as it is done in the evolutionary algorithm, s n is a scale parameter, J J is the maximum norm. Hence, a few different variants of the annealing function can be taken into consideration, for instance: g
N  X  0 ; 1  X  , g g g where the scale parameter can be proportional to the temperature
T or to the limited temperature respectively).

The next important feature of the algorithm is the temperature function, which is necessary to update the temperature schedule.
Three well-practiced rules for temperature reduction are applied in this study: the exponential reduction function t e T n ; T 0  X  X  : T n the exponentiation function t f T n ; T 0  X  X  : T n  X  T 0 = the logarithmic function t b T n ; T 0  X  X  : T n  X  T 0 = log
The last aspect that must be considered is the acceptance function for determining whether a new point is accepted or not.
It is well grounded to use one of the most famous acceptance probability function in the form prob  X  X  X  1 where the derivative of the energy function is de fi ned as
E  X  X  E  X  n  X  X  .
 2.3. Architecture optimization
The optimal structure of a network should be found in order to obtain good training and generalization abilities. This problem is decomposed into two tasks, which are known in the literature as the selection of relevant input variables and the selection of appropriate internal structure of the network. 2.3.1. Relevant input variables selection
It is proposed that the selection of relevant input variables for locally recurrent models can be solved by means of the extended method of Hellwig's coef fi cient of the integral capacity of informa-tion ( Barczak and Biolik, 2003 ). In the classical approach, Hellwig's coef fi cient is calculated as follows:
H  X  where h jk r is the individual capacity of information,  X  coef fi cient representing the relationship between the k -th and j -th relationship between the i -th and j -th potential input variables, r  X  1 ; 2 ; ... ; 2 n s 1 is the number of the r -th combination, L number of variables used in the r -th combination.

Relevant inputs of neural models are those for which the integral capacity of information is maximal. Statistical measures such as
Pearson's correlation coef fi cient, Spearman's and Kendall's rank correlation coef fi cients, or mutual information are usually used to calculate terms  X  jk and  X  ij . The authors have extended this method introducing other measures that are obtained by recurrence quan-ti fi cation analysis. Recurrence quanti fi cation analysis (RQA) has been introduced by Zbilut and Webber (1992) in order to quantify the mentioned structures in recurrence plots ( Eckmann et al.,1987 ). They de fi ned measures of complexity using the recurrence point density and diagonal and vertical line structures in the recurrence plot (RP). Some examples of them are ( Marwan et al., 2007b ): the recurrence rate, the determinism, the divergence, the entropy and the trend.

In the fi rst step two input signals must be embedded in a multi-dimensional space in order to apply any of RQA measures. This is performed by constructing two vectors: z z where i  X  0 ; 1 ; 2 ; ... ; N  X  d 1  X   X  j , d ,  X  j ,  X  k sion and delays, respectively. Recurrence is then de fi ned on the following matrix:
CR  X  nm  X  H  X  J z nj z mk J ;  X  27  X  tion, J J denotes a norm (usually L 2 distance). As one can see, there are three key parameters  X  , d ,  X  that must be determined in order to successfully generate a recurrence plot. The fi rst two parameters are needed in phase space reconstruction from the time series. The reconstruction delay is usually obtained using the mutual information, whereas for the embedding dimension one can make use of the false nearest neighbour analysis ( Li et al., 2006;
Zbilut and Webber, 1992 ). The last parameter is usually declared as  X  5  X  ,where  X  is the standard deviation of the noise in the dataset ( Marwan et al., 2007b; Thiel et al., 2002 ). For recurrence matrix CR different RQA measures are evaluated ( Zbilut and Webber, 1992;
Marwan et al., 2007a ). Generally, RQA diagonal and vertical mea-sures are able to identify bifurcation points, intermittency and laminar states ( Marwan et al., 2007b ). Nevertheless in this paper following measures are employed to de fi ne coef fi cients
Recurrence rate  X  the density of recurrence points in a recurrence plot: rr  X  1
Determinism  X  de fi ned as the percentage of blacks points belonging to a diagonal line of at least length l min : det  X 
Entropy  X  is the Shannon entropy of the frequently distribution of diagonal lines in the plot: ent  X 
Laminarity  X  analogously to det, it is de fi ned as the percentage of black points that belongs to a vertical line of at least length l lam  X 
Trapping time  X  is the mean length of vertical lines: tt  X  in the RP, N l is the total number of diagonal lines. 2.3.2. Internal structure selection
This is a two-step procedure. In the fi rst step, heuristic rules and the systematic-search algorithm are employed to establish an initial structure of the network. It is realized by changing complex-ity of the network during the process of optimization of neural models. This leads to determining the whole set of candidate neural models. To evaluate the quality of neural models the authors have used statistical information criteria ( Konishi and Kitagawa, 2008 ), such as Hannan  X  Quinn's criterion: HQC  X  N ln Q G = N  X  2 p ln ln N  X  X   X  X  ;  X  33  X  Jenkins and Watts' criterion:
JEW  X  Q G N p N 2 p 1 ;  X  34  X  where Q G is the mean absolute percentage error calculates for the test dataset, N is the cardinality of the test dataset. The values of the information criteria are used in order to graph criteria isolines with coordinates p and Q G in a similar way as it is presented in the paper ( Pokropi  X  ska et al., 2006 ). Thanks to this it is easy to neural structure. The other bene fi tofthisapproachisthatitallowsus to compare models of different types, not only neural ones.
In the next step the minimal complexity of the candidate network is found by using one of the two well-known approaches: magnitude-based pruning ( Gupta et al., 2003 ) or optimal brain damage method ( Cun et al., 1990 ). The fi rst technique after the training process eliminates parameters that have the smallest magnitude, however, this plausible idea unfortunately often leads to the elimination of the relevant parameters. Hence, the second method is more often used and provides better results. The key aspect in this strategy is to de fi ne the term saliency corresponding to every parameter that represents their importance in terms of the network output: s  X  1 2 where h kk is the k -th diagonal element of the second-order partial derivatives matrix of the error function (14) and it is approximated by the Jacobian matrix J  X   X  X  . All diagonal elements are derived using a numerical differentiation method. The parameters that have small saliency values after training process can be deleted and afterwards the Levenberg  X  Marquardt based learning proce-dure should be repeated. 2.4. Robust fault detection
Either hard or soft computing methods are used for creating models of processes, but any of these approaches does not guarantee non-measurable disturbances and modelling errors ( Korbicz, 2006 ).
Therefore, there is the need to elaborate robust fault detection methods by enhancing the robustness of the decision making block. proposed to robust fault detection. This makes possible to create ef fi cient fault detection systems to be robust enough to disturbances and modelling errors.

Suppose we have a time series r  X  k  X  N k  X  1 representing the residual signal for which a recurrence plot is created. In the step the phase space has to be reconstructed. This is realized by constructing the vector: r k  X  X  X  rk  X  X  rk  X   X  X   X  rk d 1  X  X   X   X  X  T ;  X  36  X  and the recurrence matrix:
RR  X  ij  X  H  X  J r i  X  X  r j  X  X  J  X  X  ;  X  37  X  along the main diagonal line in the recurrence plot. As it was shown in the previous section that RQA features are then com-puted  X  m  X  k  X  X  rr  X  k  X  det  X  k  X   X   X  . The situations when the fault affects a process are recognized if at least one of these measures exceeds the threshold  X  i . The particular parameters of the analysis such as  X  , d ,  X  ,  X  i can be determined using the expert's knowledge or can be computed applying heuristic/numerical optimization methods. 3. Case studies
The proposed approach was examined in order to prove that chaos engineering can be successfully employed to solve different kinds of problems related to neural modelling and robust fault detection. The description of benchmark examples and the obtained results are presented below. 3.1. Example 1  X  the comparison of diphase training schemes
The fi rst example shows the advantages of the proposed methodology in the context of nonlinear system identi fi cation. This system is deliberately written in the form of a neural network such as shown in Fig. 5 . The hidden layer includes a single neuron with dynamic systems in the activation and feedback blocks. The output layer contains one static neuron. Both output functions of the neurons are assumed to be a hyperbolic tangent function f  X  f  X  1  X  and a linear function f 2 . The disturbance input signal has the nature of the stochastic process with a normal distribution N 0 ; 0 : 1  X  X  . A pseudorandom binary sequence u  X  k  X  3000 order to obtain the response of the system.

The dynamic behaviour of the system was identi fi ed in the following experiment. The initial condition was assumed to be zero, whereas, the probability of change of the signal level at each time-instant was equal to 0.9. The system was simulated to acquire samples that are needed for system identi fi cation. The simulation tion set ( k  X  1501, ... ,2101) as well as the test set ( k
The main problem consisted in modelling the system's behaviour by means of a locally neural structure proposed in Section 2.1.2 .
The structure of the neural model was the same as the structure of the identi fi ed system. In this way, it was possible to compare different training algorithms without taking into consideration the problem of structure selection.

Two hybrid training schemes, EA-LM and SAA-LM, were inves-tigated in order to con fi rm the advantages of the proposed neural network. The convergence of the EA-LM scheme was examined for different types of the mutation operator and different values of the crossover fraction p k . It was decided that the total number of epochs of the EA was equal to 10, whereas the number of iterations of the LM algorithm was set up to 5. A random well-dispersed initial population was achieved applying Patan's method. The fi tness function was declared in the form of (14) with R  X  4and  X  total number of individuals was the same as the number of adjustable network parameters L p  X  p  X  13. The selection of the parents to the next generation was realized using the roulette method. A simple heuristic crossover operator was used in order to return a child that lies on the line containing the two parents in such a way that the distance between the child and the better parent is determined by the user-de fi ned parameter (it was set to 1.1). The number of individuals (the elite count) that were guaran-teed to survive to the next generation was equal 2. The solution obtained from EA was used as the start point for the LM rule. The cost function in this part of the training process was de (14) for R  X  2and  X   X  0.

For each set of the algorithm's features the training process was run 10 times, and afterwards the averaging procedure was affected employing the second-order exponential approximation. Table 1 includes the results obtained for the EA-LM scheme with various types of reproduction operators and with different values of their parameters. In the average sense, the smallest value of the mean absolute percent error (0.95) and standard deviation (0.46) were received using the EA-LM scheme for which the uniform chaotic mutation with H X non's map was used where the probability rate r  X  0.01 and for the crossover probability p k  X  0.6.

Similar trails were also carried out for the SAA  X  LM scheme. In this case, the initial solution, the cost functions of SAA and LM algorithms were obtained in the same manner as in the previous scheme. The sum of iterations of SAA and LM algorithms was chosen in such a way, that the total number of function evaluation was comparable with those obtained in the EA-LM scheme. The acceptance function declared as (24) and used for determining whether a new point would be accepted or not. The convergence of this scheme was examined for different types of the annealing function, various rules of temperature reduction as well as different values of an initial temperature. The averaged test results are combined in Table 2 .

It can be observed that the smallest values of the mean absolute percent error and standard deviation were achieved for the anneal-ing function g 2 N  X   X  n  X  and the temperature reduction function t with T 0  X  1. Besides, it can be stated, that for a small value of the initial temperature, the SAA  X  LM scheme behaves analogously to the
EA-LM scheme with a non-uniform mutation and without a cross-over operation ( p k  X  0). 3.2. Example 2  X  neural modelling of the large-scale industrial object
The next example focuses on the application of the developed methodology for modelling phenomena related to the thermal process of copper recovery from slag. The last part of this process is realized in an electric arc furnace which is presented in Fig. 6 .
A number of physical quantities such as voltages and currents, pressures, fl ows, temperatures are collected by the SCADA system.
Additionally, the SCADA system stores various types of information concerning the analysis of the chemical composition of the slag, the position of electrodes immersed in the slag, etc. The total number of process variables is about 180. A more detailed description of the process is given in Moczulski and Szulim (2004) and in Szulim (2003) as well.

The temperature is one of the most important diagnostic para-meter. Hence, it was decided to create a model corresponding to the temperature of the furnace arch surface between electrodes E1 and E2. Training and test datasets were prepared in the following way. The data were collected by the measurement system within the period of 36 h. Process variables were registered with the sampling interval  X  t  X  1 min. The data were also fi ltered using anti-aliasing fi lter and the result of this was processed with the downsampling procedure. Every signal in the datasets was normalized to a range from 1 to 1. As a result the time series of process variables with the sampling interval  X  t  X  20 min was obtained. The fi rst 1500 samples were used as the training patterns, whereas the next 1236 samples were used as the test examples.

The fi rst step in creating the model was to identify such process variables that had the greatest in fl uence on changes in the value of the temperature. A subset of process variables was fi rstly selected basing on the technical documentation of the plant and taking into account the expert's knowledge (see Table 3 ). It was noted that the direct in fl uence on the dependent variable y could have indepen-dent variables such as heating currents u 1 3 and temperatures u 14 18 . The rest of relevant variables were pointed out using the extended method of Hellwig's coef fi cient of integral capacity of information. Several statistical measures such as mutual informa-tion ( I jk ), nonlinear correlation coef fi cient ( nr jk or Kendall's (  X  jk ) rank correlation coef fi cients were used for representing the relationship between the k -th and j -th input variable. The coef fi cient denoting the relationship between the i -th and j -th potential input variable were computed using
Pearson's correlation coef fi cient ( r ij ), mutual information ( I well as recurrence quanti fi cation analysis measures such as determinism  X  det ij  X  , entropy  X  ent ij  X  , and laminarity selection results are given in Table 4 .

From all the results presented in Table 4 it can be stated that the most often indicated variables that have an impact on the tempera-ture of the furnace roof between the electrodes E1 and E2 are the ( u ) and the water pressure at the outlet of the contact plates ( u
For several variants of the independent variables predictive neural models were created with the prediction horizon of 20, 40 and 60 min. It was decided that the internal structure of the network was fi xed, while the training process was carrying out by means of the
EA-LM scheme. It was enough to apply only four dynamic neurons in the hidden layer with a hyperbolic tangent output function and with the second order of polynomials Aq 1 , Bq 1 , Cq 1 and Eq 1 of the dynamic systems in the activation and feedback blocs. In the global algorithm (EA) the values of parameters of the objective function (14) were declared as R  X  4,  X   X  0.5,  X  0  X  1 : 5, whereas, in the case of the local algorithm (LM), these values were set as R  X  0. The evolutionary algorithm was run for 10 generations with the following options: the population size L p  X  100, genes in the chromo-somes representing real numeric values of adjustable network parameters, roulette-wheel select ion, succession operations via heur-istic crossover (  X  h  X  1 : 1, p k  X  0.8) and the elite count chaotic mutation with H X non's map ( r m  X  0.1). The second part of the training was realized using the Levenberg  X  Marquardt algorithm (10 The accuracy of each model is estimated using two performance measures: ( ) mean absolute percent error and ( )Theil'sU statistics.

When the prediction horizon H  X  1  X  t or H  X  2  X  t it is not so important to have the smallest number of neural inputs. In contrast to this, when the time horizon is relatively long then the number of inputs of neural models has the serious in fl on the prediction results. Another important conclusion is that the extended method of Hellwig's coef fi cient with recurrence quanti-fi cation analysis measures enable to fi nd the smallest set of the independent process variables that can be used to create neural models with satisfying accuracy. As an example of such a model outcome, Fig. 7 presents predicted values of temperatures of the furnace arch surface between electrodes for two prediction hor-izons. It con fi rms the accuracy of the model equipped with the smallest number of independent variables. 3.3. Example 3  X  robust fault detection in industrial systems
The fi nal example in this section deals with the applicability of the methodology for solving the problem of model-based fault detection in industrial systems. The DAMADICS benchmark pro-blem was selected in order to show the effectiveness of the proposed methodology in this kind of problems. The purpose of the DAMADICS project is the development of fault diagnosis methods and techniques for fi nal control elements in the industry environment. The main part of the test problem is the simulator of the valve actuator that can be applied in order to simulate a nominal condition and 19 abnormal events, which are caused by abrupt and incipient faults. The scheme of an electro-pneumatic valve is presented in Fig. 8 , where F is the main pipeline P 1 and P 2 denote the pressures on valve (inlet and outlet), T is the liquid temperature, X is the valve plug displacement and CV is the process control external signal.

Thefaultshavebeenclassi fi ed into four groups: (1) control valve tion, f 3  X  valve or valve seat erosion, f 4  X  increase of valve friction, f external leakage (leaky bushing, covers, and terminals), f leakage (valve tightness), f 7  X  medium evaporation or critical (2) servomotor faults such as f 8  X  twisted servo-motor stem, f servomotor housing or terminal tightness, f 10  X  servomotor dia-phragm perforation, f 11  X  servomotor spring fault; (3) positioner faults such as f 12  X  electro-pneumatic transducer fault, f displacement sensor fault, f 14  X  pressure sensor fault, f spring fault; (4) general faul ts/external faults such as f supply pressure drop, f 17  X  unexpected pressure change across valve, f  X  fully or partly opened bypass valves, f 19  X  fl ow rate sensor fault.
Moreover, in DAMADICS, the real-world data with arti fi cial faults ( f ) was also collected for three valve actuators that were installed in Sugar Factory and Re fi nery Lublin. More detailed descriptions of the DAMADICS problem and the whole dataset are given in Barty et al. (2006); Barty  X  and Syfert (2002) .

The fi rst part of this case study focuses on the fault scenarios that were investigated using the simulation data. In the fi was necessary to create neural models for nominal conditions.
Taking into account the DAMADICS problem documentation it was stated that two relations would be modelled: X  X  g X CV ;
F  X  g
F X ; P 1 ; P 2 ; T 1  X  X  . These relations were identi fi layer and three-layer locally recurrent neural structures with non-linear neurons in the hidden layers and linear neurons in the last layer. The simulation data were divided into two sets with 2000 training and 900 test samples. Each model was tuned by means of the EA-LM scheme. The objective function (14) was declared with (30 epochs) and R  X  2,  X   X  0 for tuning up (15 iterations). The features of the EA were as follows: the population size L genes in the chromosomes representing real numeric values of adjustable network parameters, roulette-wheel selection, succes-sion operations via heuristic crossover (  X  h  X  1 : 1, p k elite count (  X  s  X  1), uniform chaotic mutation with Iked's map ( r  X  0.1). The quality of the models was elaborated in the form of isoline maps and they are presented in Fig. 9 (a) and (b) ( symbolize two-layer and three-layer neural structures, respec-tively). It was concluded that the relation g X could be represented by the neural model no. 32, while the relation g F by the neural model no. 7.

Afterwards, the structures of the selected models were pruned by the optimal brain damage procedure. It allowed for a reduction of 25% of the parameters in the fi rst model and 17% of the parameters in the second one. After pruning procedure, there was needed to retrain neural structures using the LM algorithm (only 10 iterations were executed).

The next step in the design of fault detection system was to apply a robust method for evaluation of residuals. It was realized by means of the method proposed in Section 2.4 . The main problem here was the proper selection of the values of parameters residual attractor in the phase space,  X  i  X  X  that was necessary to calculate a recurrence matrix for the i -th residual signal. It was also needed to fi nd the optimal values of threshold parameters for
RQA measures. This stage of the study was performed applying a simple evolutionary algorithm. The result of the computation is presented in Table 6 . These values were used in the decision block of the fault detection system.

Test data were gathered for each state using the simulator of the valve actuator in order to prove the effectiveness of the proposed approach. It allowed to exam 44 scenarios with different kinds of way, that it was possible to detect almost every fault in the system.
The basic features of fault detection have been described by two performance indices: r td  X  true detection rate and r fd  X  phase are presented in Table 7 .Thefollowingnotationwas proposed:  X  corresponds to a situation that was not investigated, because it is not physically justi fi able; denotes undetectable of the relation g X . On the one hand, as one can see in Table 7 the percentage of false alarms is about 1%. On the other hand, the high rates of correct alarms can be observed for almost all faults. The poorer results of true detection rates were achieved in cases of the medium abrupt fault f 16 as well as incipient faults f 4 , f occurrence.

This can be better explained when t aking into consideration fault detection results which are presented in Figs. 10 and 11 . The initial moment of the fault development i s signed by the black bullet at the time axis. In cases (a) and (b) of Fig. 10 it is possible to observe residuals and corresponding to them binary diagnostic signals obtained for conditions with small and medium abrupt faults. In the second example, the plots of (a) and (b) of Fig. 11 demonstrate the reaction of the fault detection system on two types of incipient faults. It can be seen that the forms of these signals are strongly connected with the values of performance indices. However, taking all results together, it seems r easonable to conclude that the proposed method of residual evaluation can be successfully used to design robust and highly sensitive fault detection systems. This can be also con fi rmed by comparing the obtained results with other Korbicz and Kowal, 2007; Mrugalski et al., 2008; Patan et al., 2008; Puig et al., 2007 ).

The last part of this case study deals with an example that have been investigated using the industrial data. All gathered signals were pre-processed using the decimation procedure. In the next step, process variables were standardized to a range from 1to1and divided into three subsets: training and test datasets with data collected for nominal conditions and test dataset with arti ( Table 8 ).

In order to present some aspects more clearly only the fi of Table 8 is discussed herein in details. Remaining neural models were created in the same way. Due to the small number of process variables, the selection of relevant inputs was not realized. Instead of this, the expert's knowledge and the description of the bench-mark problem were practised. This led to formulating the general relation F Z 1  X  g 1 P 1 Z 1 ; P 2 Z 1 ; T Z 1 ; X Z 1  X  X  line fl ow rate, P 1 Z 1 and P 2 Z 1 denoting the pressures on valve displacement. This relation was identi fi ed by double-layer and three-layer locally recurrent neural networks with nonlinear out-put functions of neurons in the hidden layer and linear output functions of neurons in the output layer. A hybrid algorithm according to the EA-LM scheme used for tuning adjustable net-work parameters. For EA the values of parameters of the fi function (14) were declared as R  X  2,  X   X  0 : 5 ;  X  0  X  1 hand in the case of the local algorithm (LM), these values were set as R  X  2,  X   X  0. The maximum number of epochs in the evolutionary algorithm was equal 10 and the following options were used: the population size L p  X  50, genes in the chromosomes representing real numeric values of adjustable network parameters, roulette-wheel selection, succession operations via heuristic crossover (  X  1 : 1, p k  X  0.6) and the elite count (  X  s  X  1), uniform chaotic mutation with H X non's map ( r m  X  0.1). The total number of itera-tions in the Levenberg  X  Marquardt algorithm was set as 15.
Summary results of the test stage are illustrated in Fig. 12 ( denote double-layer and three-layer structures, respectively).
Among all models that are close to the baseline, for which the criterion HQC is about 4500, the model no. 13 was selected taking into account the principle of economy. The structure of this model is presented in Fig. 13 (a). The next step was to identify the optimal internal structure of the model with the use of the optimal brain damage method. After pruning procedure, the LM algorithm was used in order to retrain the model. As a result of this, the model was created with the smallest mean absolute percent error (MAPE  X  2.7%). Its structure is presented in Fig. 13 (b). It can observe that the smallest values of adjustable parameters were set to 0.
 The other cases from Table 8 were elaborated in the same way.
The obtained results are included in Table 9 . It can be seen, that the values of the MAPE performance measure for each model are smaller than 5%. Plots (a), (d), (c) and (d) in Fig. 14 demonstrate the residual signals which were obtained applying four locally recurrent neural models created with the use of the proposed methodology. The arbitrary threshold of 0.2 was assumed in order to evaluate the residuals. Despite this, it was possible to have the most sensitive residual to the considered faults and hence, there were no false alarms. The neural models of the relations g
The fault f 17 , which was occurred in the valve actuator Z2, was detected using the model of the relation g 3 ,whereasthedetection of the fault f 19 in the actuator Z3 was realized employing the model of the relation g 4 . 4. Conclusion
The paper deals with a new methodology for neural modelling, especially in the context of fault detection. The proposed approach is based on recurrent neural networks and chaos engineering. The novelty in this research depends on that chaos engineering is successfully employed to solve different kinds of problems related to neural modelling and robust fault detection. A new dynamic neural unit is elaborated as an extension of two arti fi cial neurons well practised in the literature, that is, Frasconi  X  Gori or a dynamic neural unit with an in fi nite impulse response
Such elementary neuron has two new features when comparing it with other ones which are often used in the area of fault diagnosis.
Explaining this on an example, stochastic as well as chaotic behaviour can be obtained for the proposed model. In this way, it is possible to design a locally recurrent neural network with complex dynamic neural units for which chaotic or stochastic behaviour can be achieved. For this structure global and local optimization methods are connected together into hybrid training schemes. Chaos engineering is introduced into two global algo-rithms (EA and SAA) in order to improve the ef fi ciency of the tuning procedure. The method of Hellwig's coef fi cient of integral capacity of information is extended by introducing new measures known from chaos theory for denoting the relationship between input variables. This method is suggested to solve the problem of relevant inputs selection. In addition, criteria isolines and a sensitive technique based on optimal brain damage method are used to the suitable architecture of a network. Moreover, the problem of stability analysis of neural models is also considered in this paper. Chaos engineering is also applied to passive robust fault detection. Therefore, recurrence quanti fi cation analysis of residual signals is utilized to robust evaluation of residuals. The main limitation of the method is that the stability of the neural models is actually performed after training procedure and therefore it is sometimes necessary to retrain neural models to eliminate this problem.
The preliminary veri fi cation of the elaborated methodology in modelling tasks was carried out for both simulation and industrial data. The results achieved in this part of investigations demon-strate the capabilities of the approach for creating neural models of strongly nonlinear processes that are mainly realized in large-scale industrial objects. The fundamental veri fi cation was con-ducted for the data made available within DAMADICS benchmark problem. Due to the fact, that fault detection methodology has been tested considering faults associated with the publicly avail-able benchmark, it was possible to compare the obtained results with other methods known from the literature. The results achieved under single faulty scenarios show the good detectability features and they con fi rm that the proposed methodology can be applied not only in abrupt fault detection but also in the case of incipient faults.
 Acknowledgements The research project was partially fi nanced by the Ministry of Science and Higher Education (Poland) granted according to the decision no. N N514 3412 33.
 References
