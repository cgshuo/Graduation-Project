 Summarization systems take a long document as input and generate a concise document as out-put. Several summarization variants exist such as generic, query-based, multi-document and single document, but the basic requirements for summa-rization remain the same. Summaries should con-tain salient information so that the reader will not miss anything from the original document. Also, the reader is not interested in repetitive informa-tion, so summaries should not include redundant information. Finally, summaries should be coher-ent and of high readability.

We introduce a completely unsupervised graph-based summarization using latent drichlet alloca-tion (LDA, Blei and Lafferty (2009)). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the se-mantic relatedness between words and hence the topical coherence of a document. We use topi-cal coherence as a means to ensure the coherence of extractive single-document summaries. Re-mus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account.

Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013). However, in their graph one set of nodes corre-sponds to entities whereas in our graph it corre-sponds to topics. The entity graph has already been used by Parveen and Strube (2015) for sum-marization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense.
We apply our topical graph on the dataset in-troduced by Parveen and Strube (2015). This dataset contains scientific articles from the jour-nal PLOS Medicine 1 . Every PLOS Medicine ar-ticle is accompanied by an editor X  X  summary and an authors X  abstract. We use both as gold sum-maries for evaluation. Results obtained on the PLOS Medicine dataset using the topical graph are as good as using the entity graph and significantly better than several baselines and the graph-based system TextRank (Mihalcea and Tarau, 2004). We use the DUC 2002 dataset to compare our results with state-of-the-art techniques. In contrast to the PLOS Medicine data the DUC 2002 dataset con-tains very small articles. Still, our technique gives comparable results to the state-of-the-art. This shows that our technique is flexible and scalable despite being unsupervised. 2.1 Document Representation A graph-based representation has been used by well known summarization systems such as LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004). The graph used by both is of one mode type where sentences are nodes which are connected by weighted edges. Weights express sentence similarity.

We use a bipartite graph representation of doc-uments (Figure 1). The bipartite graph, G = ( V s , V t , E t,s ) , has two sets of nodes where V s rep-resents sentences and V t topics. The two sets of nodes are connected with edge E t,s , if a word in a sentence s is present in a topic t . If multiple words are present in topic t of sentence s , then the edge weight is the logarithmic sum of probabilities of words in topic t . We normalize the edge weight by dividing them by the length of the sentence. Hence long sentences will not benefit from their lengths. We call the resulting graph topical graph . 2.2 Sentence Ranking The final summary should contain only important sentences. Therefore, we give a score to every sentence in a document to obtain important sen-tences. Following Parveen and Strube (2015) we apply the HITS (Hyperlink Induced Topic Search) (Kleinberg, 1999) algorithm for ranking sentences by importance, since our graph is a bipartite graph. It puts nodes of a graph in two sets: hub nodes and authority nodes .

For the HITS algorithm the rank of nodes needs to be initialized. We initialize the topic rank Rank t 1+ sim ( s i , title ) . The title in the sentence rank is the title of the article. sim ( s i , title ) is the cosine similarity between the sentence s i and the title of the article. After initialization of all nodes in the weighted topical graph, the HITS algorithm is ap-plied to obtain ranks of sentences. 2.3 Coherence Measure Guinaudeau and Strube (2013) represent a docu-ment by the entity graph, a bipartite graph consist-ing of sentence and entity nodes. They perform a one-mode projection on sentence nodes, com-pute the coherence of a document on the basis of the one-mode projections and use the coherence measure for summary coherence rating. Building upon this work, Parveen and Strube (2015) inte-grate this coherence measure to directly generate coherent summaries. Instead of the entity graph we here use the topical graph to incorporate the co-herence measure. Parveen and Strube (2015) use an unweighted projection graph whereas we use a weighted projection graph of a topical graph to compute the coherence. The weighted one mode projection of the topical graph is shown in Figure 1, bottom right.
Equation 1 calculates the outdegree of every sen-tence from the weighted projection graph. How-ever weighted coh ( s i , P ) in Equation 1 is not a normalized value. The normalized coherence value is in Equation 2. Afterwards, we use this coherence value in the optimization phase for the selection of sentences. 2.4 Optimization McDonald (2007) introduces summarization as an optimization task which takes care of importance, redundancy and coherence simultaneously. In this paper, we also propose a model for single doc-ument summarization which is based on integer linear programming (ILP). We consider ranks ob-tained by the HITS algorithm as sentence impor-tance. The weighted coherence measure is cal-culated using Equation 1 and Equation 2. PLOS Medicine articles are very long and contain repeti-tive information, so we have to deal with redun-dancy even in single-document summarization. Therefore we model non-redundancy as topic cov-erage in the final summary: the more topics in a summary, the less redundant the summary will be. The ILP objective function is shown in Equation 3. f i ( X ) is the function which maximizes im-portance, f c ( X ) maximizes coherence, and f t ( Y ) maximizes topic coverage.

X is a variable for sentences which contains boolean variables x i , where 0 &lt; i &lt; n is the num-ber of sentences. Y is a variable for topics which contains boolean variables y j , where 0 &lt; j &lt; m is the number of topics.
Constraints ensure that the system satisfies addi-tional requirements such as summary length:
The final summary should be shorter than the original text and it should also have a length limit (Equation 5). The results on PLOS medicine data (Section 3) are limited to 5 sentences. We have also experimented with multiple lengths. Increas-ing the summary length increases ROUGE scores. DUC 2002 summaries are limited to 100 words.
Equation 6 shows that topics present in sen-tence x i are selected, when sentence x i is selected. Therefore, x i = 1 and T i = T opics x straint holds, because thermore, if sentence x i = 0 , i.e., it is not se-lected, then there must be topics which are al-ready present in selected sentences. Hence, the constraint holds,
Equation 7 constrains the selection of topics. If topic y j = 1 , then at least one sentence containing this topic has been selected. Therefore and the constraint holds. If topic y j = 0 , then sentences containing this topic are not selected, so
P Following Parveen and Strube (2015), we evaluate on the science genre, i.e. PLOS Medicine articles, and on the news genre, i.e. DUC 2002 data. 3.1 Datasets PLOS Medicine articles are considerably longer than DUC 2002 documents. The average num-ber of sentences per document is 154 in PLOS Medicine and 25 in DUC 2002. Benefits of using PLOS Medicine articles for experiments are:  X  They are accompanied by an authors X  abstract.  X  They have a summary written by an editor.  X  They are formatted in XML.  X  They contain explicit full forms of abbrevia-Editor X  X  summaries have a different perspective, writing style and length than authors X  abstracts. We use both as gold summaries for evaluation. Following Parveen and Strube (2015) we re-port the results using editor X  X  summaries and au-thor X  X  abstracts independently. To compare with the state-of-the-art in single-document summa-rization, we also evaluate on DUC 2002 data. 3.2 Experimental Setup We use the XML version of PLOS Medicine ar-ticles. We extract the contents excluding figures, tables and references. Editor X  X  summary and au-thors X  abstract are separated from the content for evaluation. The PLOS Medicine XML provides explicit full forms when abbreviations are intro-duced. We replace abbreviations with their full form in the summary. We then remove non-alphabetical characters. After this we parse ar-ticles using the Stanford parser (Klein and Man-ning, 2003). We perform pronoun resolution using the coreference resolution system by Martschat (2013) 2 . We use gensim to generate the topics. For generating topics we use a dataset contain-ing scientific articles from biology, which con-tains 221,385 documents and about 50 million with topics from a general domain.

The HITS algorithm is applied on the bipar-tite graph for computing sentence importance. We calculate the coherence values of sentences on weighted one-mode projection graphs. The impor-tance and coherence of a sentence is used in the for each sentence. 3.3 Results Results on PLOS Medicine are shown in Tables 1 and 2. We evaluate using ROUGE-SU4 and ROUGE-2 (Lin, 2004). We limit the length of the summaries to five sentences and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same.

We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance (Carbonell and Goldstein, 1998). TextRank is the graph-based system by Mihalcea and Tarau (2004) 5 . Egraph is the entity graph based system by Parveen and Strube (2015). Egraph + Coh. is their system Table 1: PLOS Medicine , editor X  X  summaries which includes a coherence measure, which is cal-culated by using the unweighted projection graph. Egraph + Coh. + Pos. combines the coherence measure and positional information.

Our system outperforms all baselines substan-tially, as shown in Tables 1 (editor X  X  summaries) and 2 (authors X  abstracts). We observe improve-ments in the results when including coherence in the topical graph. We obtain best results with Tgraph + Coh., where the number of topics is 2000. In Tgraph, penalizing coherence mea-sures with positional information lowers ROUGE scores. While including positional information into the entity graph obtains the best results on the PLOS Medicine dataset, positional informa-tion does not appear to be beneficial for the topical graph. Absolute ROUGE scores are higher when using abstracts as gold summaries, because the ab-stracts are shorter than editor X  X  summaries.
We compare results using biology journals (Ta-ble 3) and Wikipedia (Table 4) to generate top-ics. The topical graph is denser when using bi-ology journals compared to the graph generated from Wikipedia. Results using the in-domain bi-ology journals as data to generate topics are better than using general domain Wikipedia data. The scores are highest with 2000 topics. For Bio topic the differences are negligible, however.

We also compare results on DUC 2002 to Table 3: PLOS Medicine , editor X  X  summ., Bio topic Table 4: PLOS Medicine , editor X  X  summ., Wiki topic check against the state-of-the-art on a well-known dataset. Lead performs well on DUC 2002 as shown in Table 5, because important information appears in the initial lines of news articles. DUC 2002 Best is the result reported by the top perform-ing system at DUC 2002. This system actually obtains better results than TextRank (Mihalcea and Tarau, 2004) and the more recent system Uniform-Link (Wan and Xiao, 2010). Our system Tgraph + Coh. performs better than the well known best systems on DUC 2002 and slightly better than Egraph + Coh. However the difference between the results of Tgraph and Egraph are not signifi-cant. In contrast to the entity graph based system, the coherence measure in our system is calculated by using a topic-based weighted projection graph, which is denser and hence more informative. 3.4 Human Coherence Judgements In addition to ROUGE scores, we use human judgements for evaluating the coherence of our summaries. We asked four PhD students in natural language processing to evaluate our summaries on the basis of coherence. We randomly selected ten summaries of scientific articles from three differ-ent systems, TextRank , Lead and Tgraph + Coh. We asked the human judges to rank the summaries according to their coherence. So, the summary Table 5: DUC 2002, single-document summariza-tion which is best in coherence gets rank 1 , second best gets rank 2 , and worst gets rank 3 . We calculated the Kendall concordance coefficient ( W ) (Siegel and Castellan, 1988) to measure the judges X  agree-ment. We obtain W = 0 . 61 , which indicates a relatively high agreement.

To compare the three systems, we take the aver-age over the ranks. The overall rank of TextRank is 2 . 625 , Lead is 1 . 675 and Tgraph + Coh. is 1 . 8 . Lead performs best, because it selects the top five consecutive sentences, which are coherent as the original authors intended them to be. However, the overall ranks of Lead and Tgraph + Coh. are not significantly different, whereas TextRank  X  X  over-all rank is significantly worse than both. Hence, Tgraph + Coh. performs very well in our human judgement coherence experiment. In this paper we introduced the topical graph for single document summarization. We experi-mented with multiple numbers of topics on the sci-entific article dataset. Our system performs well when including the weighted coherence measure in the optimization phase. The results are compa-rable with the entity graph. However, the entity graph is less informative and very sparse as com-pared to the topical graph. Our system does not need annotated training data and, except for the number of topics, no optimization of parameters. Hence, we consider it unsupervised.
 This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. The first au-thor has been supported by a Heidelberg Insti-tute for Theoretical Studies Ph.D. scholarship. This work has been supported by the German Re-search Foundation as part of the Research Training Group  X  X daptive Preparation of Information from Heterogeneous Sources X  (AIPHES) under grant No. GRK 1994/1. We would like to thank our colleagues Sebastian Martschat, Nafise Moosavi, Alex Judea and Mohsen Mesgar who served as hu-man subjects and commented on earlier drafts.
