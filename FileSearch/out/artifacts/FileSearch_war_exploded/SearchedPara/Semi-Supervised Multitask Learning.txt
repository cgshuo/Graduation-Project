 Supervised learning has proven an effective technique for learning a classifier when the quantity of labeled data is large enough to represent a sufficient sample from the true labeling function. Un-fortunately, a generous provision of labeled data is often not available since acquiring the label of a datum is expensive in many applications. A classifier supervised by a limited amount of labeled data is known to generalize poorly even if it produces zero training errors. There has been much recent work on improving the generalization of classifiers based on using information sources be-yond the labeled data. These studies fall into two major categories: (i) semi-supervised learning [9, 12, 15, 10] and (ii) multitask learning (MTL) [3, 1, 13]. The former employs the information from the data manifold, in which the manifold information provided by the usually abundant unla-beled data is exploited, while the latter leverages information from related tasks.
 In this paper we attempt to integrate the benefits offered by semi-supervised learning and MTL, by proposing semi-supervised multitask learning . The semi-supervised MTL framework consists of M semi-supervised classifiers coupled by a joint prior distribution over the parameters of all classifiers. Each classifier provides the solution for a partially labeled data classification task. The solutions for the M tasks are obtained simultaneously under the unified framework.
 Existing semi-supervised algorithms are often not directly amenable to MTL extensions. Transduc-tive algorithms directly operate on labels. Since the label is a local property of the associated data point, information sharing must be performed at the level of data locations, instead of at the task level. The inductive algorithm in [10] employs a data-dependent prior to encode manifold informa-tion. Since the information transferred from related tasks is also often represented by a prior, the two priors will compete and need be balanced; moreover, this precludes a Dirichlet process [6] or its variants to represent the sharing prior across tasks, because the base distribution of a Dirichlet process cannot be dependent on any particular manifold.
 We develop a new semi-supervised formulation, which enjoys several nice properties that make the formulation immediately amenable to an MTL extension. First, the formulation has a parametric classifier built for each task, thus multitask learning can be performed efficiently at the task level, using the parameters of the classifiers. Second, the formulation encodes the manifold information of each task inside the associated likelihood function, sparing the prior for exclusive use by the information from related tasks. Third, the formulation lends itself to a Dirichlet process, allowing the tasks to share information in a complex manner.
 The new semi-supervised formulation is used as a key component of our semi-supervised MTL framework. In the MTL setting, we have M partially labeled data manifolds, each defining a clas-sification task and involving design of a semi-supervised classifier. The M classifiers are designed simultaneously within a unified sharing structure. The key component of the sharing structure is a soft variant of the Dirichlet process (DP), which implements a soft-sharing prior over the parameters of all classifiers. The soft-DP retains the clustering property of DP and yet does not require exact sharing of parameters, which increases flexibility and promotes robustness in information sharing. The new semi-supervised formulation, termed parameterized neighborhood-based classification (PNBC) , represents the class probability of a data point by mixing over all data points in the neigh-borhood, which is formed via Markov random walk over a graph representation of the manifold. 2.1 Neighborhoods Induced by Markov Random Walk Let G = ( X , W ) be a weighted graph such that X = { x 1 , x 2 ,  X  X  X  , x n } is a set of vertices that coincide with the data points in a finite data manifold, and W = [ w ij ] n  X  n is the affinity matrix with the ( i, j ) -th element w ij indicating the immediate affinity between data points x i and x j . We follow A Markov random walk on graph G = ( X , W ) is characterized by a matrix of one-step transition and is given by a ij = w ij P n the probability of transiting from x i to x j in t steps.
 Data point x j is said to be a t -step neighbor of x i if b ij &gt; 0 . The t -step neighborhood of x i , neighborhood depends on the right choice of t . A rule of choosing t is given in [12], based on maximizing the margin of the associated classifier on both labeled and unlabeled data points. The  X  i in specifying w ij represents the step-size (distance traversed in a single step) for x i to reach its immediate neighbor, and we have used a distinct  X  for each data point. Location-dependent step-sizes allow one to account for possible heterogeneities in the data manifold  X  at locations with dense data distributions a small step-size is suitable, while at locations with sparse data distributions a large step-size is appropriate. A simple choice of heterogeneous  X  is to let  X  i be related to the distance between x i and close-by data points, where closeness is measured by Euclidean distance. Such a choice ensures each data point is immediately connected to some neighbors. 2.2 Formulation of the PNBC Classifier y of data point x i , given x i alone (which is a zero-step neighborhood of x i ). The base classifier can be implemented by any parameterized probabilistic classifier. For binary classification with expresses the conditional class probability as where a constant element 1 is assumed to be prefixed to each x (the prefixed x is still denoted as x for notational simplicity), and thus the first element in  X  is a bias term.
 Let p ( y i |N t ( x i ) ,  X  ) denote a neighborhood-based classifier parameterized by  X  , representing the probability of class label y i for x i , given the neighborhood of x i . The PNBC classifier is defined as a mixture where the j -th component is the base classifier applied to ( x j , y i ) and the associated mixing propor-tion is defined by the probability of transiting from x i to x j in t steps. Since the magnitude of b ij automatically determines the contribution of x j to the mixture, we let index j run over the entire X for notational simplicity.
 The utility of unlabeled data in (2) is conspicuous  X  in order for x i to be labeled y i , each neighbor x j must be labeled consistently with y i , with the strength of consistency proportional to b ij ; in such a manner, y i implicitly propagates over the neighborhood of x i . By taking neighborhoods into account, it is possible to obtain an accurate estimate of  X  , based on a small amount of labeled data. The over-fitting problem associated with limited labeled data is ameliorated in the PNBC formulation, through enforcing consistent labeling over each neighborhood.
 Let L X  X  1 , 2 ,  X  X  X  , n } denote the index set of labeled data in X . Assuming the labels are condition-ally independent, we write the neighborhood-conditioned likelihood function p  X  3.1 The sharing prior Suppose we are given M tasks, defined by M partially labeled data sets of labeled data in task m . We consider M PNBC classifiers, parameterized by  X  m , m = 1 ,  X  X  X  , M , with  X  m responsible for task m . The M classifiers are not independent but coupled by a prior joint distribution over their parameters with the conditional distributions in the product defined by tribution with mean  X  l and covariance matrix  X  2 I . As discussed below, the prior in (4) is linked to Dirichlet processes and thus is more general than a parametric prior, as used, for example, in [5]. knowledge indicating how the present task should be learned, based on the experience with a previ-ous task. It is through these normal distributions that information sharing between tasks is enforced. Taking into account the data likelihood, unrelated tasks cannot share since they have dissimilar solu-tions and forcing them to share the same solution will decrease their respective likelihood; whereas, related tasks have close solutions and sharing information helps them to find their solutions and improve their data likelihoods.
 previous tasks available, as is seen from (5) by setting m = 1 . When there are m  X  1 previous tasks, one uses the baseline prior with probability  X   X  + m  X  1 , and uses the prior transferred from each of the m  X  1 previous tasks with probability 1  X  + m  X  1 . The  X  balances the baseline prior and the priors imposed by previous tasks. The role of baseline prior decreases as m increases, which is in agreement with our intuition, since the information from previous tasks increase with m . The formulation in (5) is suggestive of the polya urn representation of a Dirichlet process (DP) [2]. The difference here is that we have used a normal distribution to replace Dirac delta in Dirichlet processes. Since N (  X  m |  X  l ,  X  2 I ) approaches Dirac delta  X  (  X  m  X   X  l ) as  X  2  X  0 , we recover the Dirichlet process in the limit case when limit case when  X  2  X  0 .
 The motivation behind the formulation in (5) is twofold. First, a normal distribution can be regarded as a soft version of the Dirac delta. While the Dirac delta requires two tasks to have exactly the same  X  when sharing occurs, the soft delta only requires sharing tasks to have similar  X   X  X . The soft sharing may therefore be more consistent with situations in practical applications. Second, the normal distribution is analytically more appealing than the Dirac delta and allows simple maximum a posteriori (MAP) solutions. This is an attractive property considering that most classifiers do not have conjugate priors for their parameters and Bayesian learning cannot be performed exactly. Under the sharing prior in (4), the current task is equally influenced by each previous task but is influenced unevenly by future tasks  X  a distant future task has less influence than a near future task. The ordering of the tasks imposed by (4) may in principle affect performance, although we have not found this to be an issue in the experimental results. Alternatively, one may obtain a sharing prior that does not depend on task ordering, by modifying (5) as the full conditionals in (6) is not analytically available, nether is the corresponding posterior joint distribution, which causes technical difficulties in performing MAP estimation. 3.2 Maximum A Posteriori (MAP) Estimation the joint likelihood function over all tasks can be written as where the m -th term in the product is taken from (3), with the superscript m indicating the task random walk is always restricted to the same task (the one where the starting data point belongs) and can never traverse multiple tasks. From (4), (5), and (7), one can write the logarithm of the joint We seek the parameters {  X  1 ,  X  X  X  ,  X  M } that maximize the log-posterior, which is equivalent to si-multaneously maximizing the prior in (4) and the likelihood function in (7). As seen from (5), the prior tends to have similar  X   X  X  across tasks (similar  X   X  X  increase the prior); however sharing between unrelated tasks is discouraged, since each task requires a distinct  X  to make its likelihood large. As a result, to make the prior and the likelihood large at the same time, one must let related tasks have similar  X   X  X . Although any optimization techniques can be applied to maximize the objective function (8), expectation maximization (EM) is particularly suitable, since the objective function involves summations under the logarithmic operation. To conserve space the algorithmic details are omitted here.
 Utilization of the manifold information and the information from related tasks has greatly reduced the hypothesis space. Therefore, point MAP estimation in semi-supervised MTL will not suffer as much from overfitting as in supervised STL. This argument will be supported by the experimental re-sults in Section 4.2, where semi-supervised MTL outperforms both supervised MTL and supervised STL, although the former is based on MAP and the latter two are based on Bayesian learning. With MAP estimation, one obtains the parameters of the base classifier in (1) for each task, which can be employed to predict the class label of any data point in the associated task, regardless of whether the data point has been seen during training. In the special case when predictions are desired only for the unlabeled data points seen during training (transductive learning), one can alternatively employ the PNBC classifier in (2) to perform the predictions. First we consider semi-supervised learning on a single task and establish the competitive perfor-mance of the PNBC in comparison with existing semi-supervised algorithms. Then we demonstrate the performance improvements achieved by semi-supervised MTL, relative to semi-supervised STL and supervised MTL. Throughout this section, the base classifier in (1) is logistic regression. 4.1 Performance of the PNBC on a Single Task Figure 2: Inductive results of the PNBC on Ionosphere. The horizontal axis is the size of X U . The PNBC is evaluated on three benchmark data sets  X  Pima Indians Diabetes Database (PIMA), Wisconsin Diagnostic Breast Cancer (WDBC) data, and Johns Hopkins University Ionosphere database (Ionosphere), which are taken from the UCI machine learning repository [11]. The evalu-ation is performed in comparison to four existing semi-supervised learning algorithms, namely, the transductive SVM [9], the algorithm of Szummer &amp; Jaakkola [12], GRF [15], and Logistic GRF [10]. The performance is evaluated in terms of classification accuracy, defined as the ratio of the number of correctly classified data over the total number of data being tested.
 We consider two testing modes: transductive and inductive. In the transductive mode, the test data mode, the test data are a set of holdout data unseen during training. We follow the same procedures as used in [10] to perform the experiments. Denote by X any of the three benchmark data sets and Y the associated set of class labels. In the transductive mode, we randomly sample X L  X  X and assume the associated class labels Y L are available; the semi-supervised algorithms are trained by X  X  X  L and tested on X \X L . In the inductive mode, we randomly sample two disjoint data subsets X
L  X  X and X U  X  X , and assume the class labels Y L associated with X L are available; the semi-supervised algorithms are trained by X L  X  X  L  X  X  U and tested on 200 data randomly sampled from X \ ( X L  X  X  U ) .
 The comparison results are summarized in Figures 1 and 2, where the results of the PNBC and the algorithm of Szummer &amp; Jaakkola are calculated by us, and the results of remaining algorithms are cited from [10]. The algorithm of Szummer &amp; Jaakkola [12] and the PNBC use  X  i = min j k x i  X  x k / 3 and t = 100 ; learning of the PNBC is based on MAP estimation. Each curve in the figures is a result averaged from T independent trials, with T = 20 for the transductive results and T = 50 for the inductive results. In the inductive case, the comparison is between the proposed algorithm and the Logistic GRF, as the others are transductive algorithms.
 For the PNBC, we can either use the base classifier in (1) or the PNBC classifier in (2) to predict the labels of unlabeled data seen in training (the transductive mode). In the inductive mode, however, representation, therefore we can only employ the base classifier. In the legends of Figures 1 and 2, a suffix  X  X I X  to PNBC indicates that the PNBC classifier in (2) is employed in testing; when no suffix is attached, the base classifier is employed in testing.
 Figures 1 and 2 show that the PNBC outperforms all the competing algorithms in general, regardless of the number of labeled data points. The improvements are particularly significant on PIMA and Ionosphere. As indicated in Figure 1(c), employing manifold information in testing by using (2) can improve classification accuracy in the transductive learning case. The margin of improvements achieved by the PNBC in the inductive learning case is striking and encouraging  X  as indicated by the error bars in Figure 2, the PNBC significantly outperforms Logistic GRF in almost all indi-vidual trials. Figure 2 also shows that the advantage of the PNBC becomes more conspicuous with decreasing amount of labeled data considered during training. 4.2 Performance of the Semi-Supervised MTL Algorithm We compare the proposed semi-supervised MTL against: (a) semi-supervised single-task learning (STL), (b) supervised MTL, (c) supervised STL, (d) supervised pooling; STL refers to designing M classifiers independently, each for the corresponding task, and pooling refers to designing a sin-gle classifier based on the data of all tasks. Since we have evaluated the PNBC in Section 4.1 and established its effectiveness, we will not repeat the evaluation here and employ PNBC as a represen-tative semi-supervised learning algorithm in semi-supervised STL. To replicate the experiments in [13], we employ AUC as the performance measure, where AUC stands for area under the receiver operation characteristic (ROC) curve [7].
 The basic setup of the semi-supervised MTL algorithm is as follows. The tasks are ordered as they are when the data are provided to the experimenter (we have randomly permuted the tasks and found the performance does not change much). A separate t -neighborhood is employed to represent the manifold information (consisting of labeled and unlabeled data points) for each task, where the step-size at each data point is one third of the shortest distance to the remaining points and t is set settings represent the basic intuition of the experimenter; they have not been tuned in any way and therefore do not necessarily represent the best settings for the semi-supervised MTL algorithm. Figure 3: (a) Performance of the semi-supervised MTL algorithm on landmine detection, in com-parison to the remaining five algorithms. (b) The Hinton diagram of between-task similarity when there are 140 labeled data in each task.
 Landmine Detection First we consider the remote sensing problem considered in [13], based on data collected from real landmines. In this problem, there are a total of 29 sets of data, collected from various landmine fields. Each data point is represented by a 9-dimensional feature vector extracted from radar images. The class label is binary (mine or false mine). The data are available at http://www.ee.duke.edu/  X  lcarin/LandmineData.zip.
 Each of the 29 data sets defines a task, in which we aim to find landmines with a minimum number of false alarms. To make the results comparable to those in [13], we follow the authors there and take data sets 1-10 and 16-24 to form 19 tasks. Of the 19 selected data sets, 1-10 are collected at foliated regions and 11-19 are collected at regions that are bare earth or desert. Therefore we expect two dominant clusters of tasks, corresponding to the two different types of ground surface conditions. To replicate the experiments in [13], we perform 100 independent trials, in each of which we ran-domly select a subset of data for which labels are assumed available, train the semi-supervised MTL and semi-supervised STL classifiers, and test the classifiers on the remaining data. The AUC av-eraged over the 19 tasks is presented in Figure 3(a), as a function of the number of labeled data, where each curve represents the mean calculated from the 100 independent trials and the error bars represent the corresponding standard deviations. The results of supervised STL, supervised MTL, and supervised pooling are cited from [13].
 Semi-supervised MTL clearly yields the best results up to 80 labeled data points; after that super-vised MTL catches up but semi-supervised MTL still outperforms the remaining three algorithms by significant margins. In this example semi-supervised MTL seems relatively insensitive to the amount of labeled data; this may be attributed to the doubly enhanced information provided by the data manifold plus the related tasks, which significantly augment the information available in the limited labeled data. The superiority of supervised pooling over supervised STL on this dataset sug-gests that there are significant benefits offered by sharing across the tasks, which partially explains why supervised MTL eventually catches up with semi-supervised MTL.
 We plot in Figure 3(b) the Hinton diagram [8] of the between-task sharing matrix (an average over the 100 trials) found by the semi-supervised MTL when there are 140 labeled data in each task. maximum element is one), which is represented by a square in the Hinton diagram, with a larger square indicating a larger value of the corresponding element. As seen from Figure 3(b), there is a dominant sharing among tasks 1-10 and another dominant sharing among tasks 11-19. Recall from the beginning of the section that data sets 1-10 are from foliated regions and data sets 11-19 are from regions that are bare earth or desert. Therefore, the sharing is in agreement with the similarity between tasks.
 Art Images Retrieval We now consider the problem of art image retrieval [14, 13], in which we have a library of 642 art images and want to retrieve the images based on a user X  X  preference. The preference of each user is available on a subset of images, therefore the objective is to learn the pref-erence of each user based on a subset of training examples. Each image is represented by a vector of features and a user X  X  rating is represented by a binary label (like or dislike). The users X  prefer-ences are collected in a web-based survey, which can be found at http://honolulu.dbs.informatik.uni-muenchen.de:8080/paintings/index.jsp.
 We consider the same 69 users as considered in [13], who each rated more than 100 images. The preference prediction for each user is treated as a task, with the associated set of ground truth data defined by the images rated by the user. These 69 tasks are used in our experiment to evaluate the performance of semi-supervised MTL. Since two users may give different ratings to exactly the same image, pooling the tasks together can lead to multiple labels for the same data point. For this reason, we exclude supervised pooling and semi-supervised pooling in the performance comparison. Figure 4: Performance of the semi-supervised MTL algorithm on art image retrieval, in comparison to the remaining three algorithms.
 Following [13], we perform 50 independent trials, in each of which we randomly select a subset of images rated by each user, train the semi-supervised MTL and semi-supervised STL classifiers, and test the classifiers on the remaining images. The AUC averaged over the 69 tasks is presented in Figure 4, as a function of the number of labeled data (rated images), where each curve represents the mean calculated from the 50 independent trials and the error bars represent the corresponding standard deviations. The results of supervised STL and supervised MTL are cited from [13]. Semi-supervised MTL performs very well, improving upon results of the three other algorithms by significant margins in almost all individual trials (as seen from the error bars). It is noteworthy that the performance improvement achieved by semi-supervised MTL over semi-supervised STL is larger than corresponding improvement achieved by supervised MTL over supervised STL. The greater improvement demonstrates that unlabeled data can be more valuable when used along with multitask learning. The additional utility of unlabeled data can be attributed to its role in helping to find the appropriate sharing between tasks. A framework has been proposed for performing semi-supervised multitask learning (MTL). Recog-nizing that existing semi-supervised algorithms are not conveniently extended to an MTL setting, we have introduced a new semi-supervised formulation to allow a direct MTL extension. We have proposed a soft sharing prior, which allows each task to robustly borrow information from related tasks and is amenable to simple point estimation based on maximum a posteriori . Experimental results have demonstrated the superiority of the new semi-supervised formulation as well as the additional performance improvement offered by semi-supervised MTL. The superior performance of semi-supervised MTL on art image retrieval and landmine detection show that manifold infor-mation and the information from related tasks could play positive and complementary roles in real applications, suggesting that significant benefits can be offered in practice by semi-supervised MTL.
