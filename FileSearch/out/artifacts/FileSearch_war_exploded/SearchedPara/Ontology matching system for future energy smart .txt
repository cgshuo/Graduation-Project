 fi nds complex correspondences by processing expert knowledge from 1. Introduction
The term Smart Grid is nowadays synonymously used for future power systems ( Mc Namara et al., 2013; Rayudu, 2010 ).
The former centralized infrastructure with its unidirectional power fl ow from large power plants via the consumers, turns into a full-meshed topology including bidirectional power fl ows. This raises many challenges in terms of interoperability issues. Thus, numerous Smart Grid devices, possibly from different developers, need to exchange data with each other in order to co-operate over complex control tasks. The main standardization body in the electricity sector, the International Electrotechnical Commission (IEC), has created some standard data models de fi ning semantics of the data that need to be exchanged within this domain.
Unfortunately, a single standard data model has not been de for all Smart Grids. It is worth noting that many contributions in the literature ( Haslhofer and Klas, 2010; O'Leary, 1997 )have concluded that, in practice, it is not always advisable (or even possible) to create a single standard data model that is valid for all the applications within a domain. Therefore, with the aim of achieving interoperability in Smart Grids, it is mandatory to align different data models.

Before aligning the models, these must be expressed in the same modeling language. In this work, data models have been converted into OWL (Web Ontology Language) ontologies ( Bechhofer et al., 2004 ). Originally, ontologies were created in Arti fi cial Intelligence (AI) to produce knowledge base components for intelligent systems ( G X mez-P X rez et al., 2004 ). More recently, ontologies have started to be used in numerous engineering applications ( Abanda et al., 2013; Blomqvist and  X hgren, 2008; Morbach et al., 2007; Wriggers et al., 2007 ). In this study, ontologies have been employed because they represent knowledge by de fi ning logic theories, which enable machines to infer implicit knowledge by means of general reasoning services. These reasoning services are very useful for fi semantic correspondences (alignments) between two data models.
The process of aligning ontologies is known as ontology matching. Most ontology matchers are only able to fi nd equiv-alences between ontology entities ( Euzenat and Shvaiko, 2007 ).
In Smart Grids, however, very few alignments can be expressed as simple equivalences ( Santodomingo et al., 2012 ). For this reason, this paper presents a new ontology matching system that is able to obtain complex alignments between Smart Grid ontologies. This system processes deep domain knowledge from external ontolo-gies (domain ontologies) and uses innovative matching methods.
The remainder of this paper is organized as follows. Section 2 provides a brief overview of the two main standard data models that promote interoperability in Smart Grids: CIM and SCL. Section 3 sets out the fundamentals aspects of Ontology Matching. Section 4 presents the proposed ontology matching system, which comprises a schema-based subsystem ( Section 5 ) and an instance-based subsystem ( Section 6 ). Section 7 is devoted to the tests performed in this study to evaluate the proposed system. Finally, Section 8 concludes the paper and provides an outlook on future work. 2. Interoperability in smart grids This work addresses the main interoperability issue in Smart Grids: interactions between CIM-based and SCL-based systems.
This section presents CIM and SCL data models and discusses their interactions. 2.1. Smart grid data models: CIM and SCL
The Common Information Model ( CIM )isde fi ned in the IEC 61970/ 61968/62325 standard series. It standardizes the semantics to achieve interoperability in a broad range of energy management functionalities, such as: network operations, asset management and electricity markets ( Uslar et al., 2012 ). Hundreds of classes organized in packages are included in this data model. Among all the CIM packages, Wires and Topology packages contain several classes to represent electric power systems. For instance, cim:Substation, cim:VoltageLevel, and cim:Breaker are the CIM classes to represent substations, voltage levels, and circuit breakers, respec-tively. The CIM is currently maintained in UML. In this study, the equivalent CIM OWL ontology has been created by using the
Uml2Owl conversion implemented in the open-source CIMTool. The Substation Con fi guration Language ( SCL )isde fi ned in the
IEC 61850 standard series. It includes the concepts required for con fi guring the automation systems that locally control electric networks. The SCL de fi nes terms to represent automation systems and electric facilities. For instance, scl:tSubstation and scl:tVolta-geLevel are the SCL classes for representing substations and voltage levels, respectively. Meanwhile, circuit breakers are repre-sented in SCL as scl:tConductingEquipment instances that take the value  X  CBR  X  in the attribute scl:type . The SCL is represented in the XML Schema De fi nition (XSD) language. The equivalent SCL OWL ontology has been created in this work with the Xsd2Owl conversion presented in ( Garc X a and Gil, 2007 ). 2.2. Interactions between CIM and SCL
As detailed in ( Falk and Saxton, 2010 ), during the planning and con fi guration of electric networks, engineers of the CIM-based management system must exchange fi les with engineers of the
SCL-based automation system. The problem is that CIM and SCL were developed by different working groups with different requirements and goals. This resulted in the existence of mis-matches hindering the interactions between CIM-based and SCL-based systems. In that way, simple equivalences of terms are not suf fi cient themselves for carrying out these interactions. For instance, CIM and SCL representations of circuit breakers must be aligned by a complex correspondence involving the class cim:Breaker , the class scl:tConductingEquipment , the attri-bute scl:type and the attribute value  X  CBR  X  . 3. Ontology matching
This section de fi nes the concepts that will be used throughout the paper to describe the proposed ontology matching system. For that purpose, the terminology de fi ned in ( Euzenat and Shvaiko, 2007 ) is employed. 3.1. Ontology matching process
Ontology matchers are aimed at fi nding correspondences between entities (classes, properties, instances) of two ontologies o 1 and o 2. In this study, two types of property are considered: object properties (or relationships), which connect two classes or instances, and data properties (or attributes), which connect a class or instance to a data type (e.g., string, integer, etc.) or value.
Typically, ontology matching processes comprise two overall steps: similarity computation and alignment extraction ( Fig. 1 ). In the fi rst step, entities of o 1 and o 2 are compared. For each entity e 1of o 1 and e 2of o 2, a similarity measure s ( e 1, e 2) is calculated. This measure is a function from a pair of entities to a real number expressing the similarity between them ( Euzenat and Shvaiko, 2007 ). In order to work with similarity measures within the range [0  X  1], usually, similarities are normalized with the maximum s ( e 1, e 2) that was calculated. The results obtained in a similarity computation are included in a similarity matrix M containing all the similarity measures between entities of o 1 and entities of o 2. Several similarity computations are proposed in the state of the art. These can be categorized in
Element-based methods , which analyze the entities of the ontol-ogies in isolation (i.e., ignoring their relationships with other entities). In this work, different element-based methods included in the state of the art (such as the string-based comparison proposed in ( Winkler, 1999 )) were used (see Section 5 ).
Structure-based methods , which take the structure of the ontologies (i.e., the relationships between entities) into account. Graph-based matching methods were identi fi ed as the most appropriate structure-based methods for the system proposed in this work (see Section 6.3.3 ). This is because graph-based methods are mature methods that obtain good results in the ontology align-ment evaluations ( Cruz et al., 2011 ). These methods represent ontologies as graphs and compare their nodes (classes or instances) attending to local characteristics (such as attributes or names).
The local similarities s l ( e 1, e 2) obtained from this comparison are then propagated by considering the structure of the graphs in order to obtain the global similarities s g ( e 1, e 2). The main graph-based matching methods proposed in the literature are: the Similarity Flooding ( SF )de fi ned in ( Melnik et al., 2002 ); the Similarity Equation Fixed Point ( SEFP )de fi ned in ( Euzenat and
Valtchev, 2004 ); the Descendant ' s Similarity Inheritance ( DSI )and the Sibling ' s Similarity Contribution ( SSC )de fi ned in ( Cruz and
Sunna, 2008 ); and the Semantic-Neighbourhood Matching ( SNM ) de fi ned in ( Rodr X guez and Egenhofer, 2003 ).

Existing mismatches between ontologies make for dif fi cult use of a single similarity computation. Hence, the fi nal similarity matrix M is usually calculated from the similarity matrices Mi obtained with different similarity computations ( Shvaiko and
Euzenat, 2013 ). Two approaches have been used in this work to combine similarity computations: the ontology-driven combina-tion, which calculates the weights of the matrices Mi by analyzing the ontologies for instance, the combination proposed in ( Juanzi et al., 2009 ), and the quality-driven combination de fi ned in ( Cruz et al., 2009 ), which calculates the weights by analyzing the quality of the similarity matrices Mi .

In the second step ( alignment extraction ), the alignments between ontologies are obtained from the fi nal similarity matrix M .The literature includes two basic techniques to carry out the alignment extraction: threshold-based extraction and mapping-based extraction.
The threshold-based extraction selects the pairs of entities whose normalized similarity is greater than a con fi gurable threshold.
For each pair of entities selected, an equivalence e 1 e 2iscreated.The mapping-based extraction uses mapping algorithms that analyze the similarity matrix M to select the pairs of entities  X  e 1, e 2 equivalent. Therefore, both techniques are only able to obtain equiv-alences between ontology entities. This partially explains why most ontology matchers are not able to obtain complex correspondences. The main mapping algorithms proposed in the literature are: the
Perfect Monogamy ( PM )andthe Stable Marriage ( SM )de fi and Gal, 2007 ); and the Maximum Weight Bipartite Graph ( MWBG ) de fi ned in ( Munkres, 1957 ). 3.2. Matching with background knowledge
Apart from the classi fi cation of similarity computations explained in Section 3.1 of this contribution, ontology matching systems can be categorized also by considering th etypeofinformationtheyusefor aligning ontologies. Hence, ontology matching systems can employ: syntax of the elements included in the ontologies to be aligned, formal semantics of the ontologies to be aligned, or background knowledge from external resources ( Euzenat and Shvaiko, 2007 ).
In their recent review of the state of the art, Shvaiko and Euzenat explain that  X  one source of dif fi culty for matching is that ontologies are designed in a particular context, with some background knowl-edge, which often do not become part of the fi nal ontology speci tion  X  . Thus, the authors point out that  X  matching with background knowledge  X  is one of the most important challenges for ontology matching ( Shvaiko and Euzenat, 2013 ). Several studies have analyzed how to infer background knowledge from external ontologies to improve ontology alignment. Aleksovski explored the in fl different types of background ontologies ( Aleksovski, 2008 ). Mascardi et al. proposed algorithms to exploit upper ontologies (that is, ontologies de fi ning general concepts that are the same across all domains) as background knowledge for ontology matching ( Mascardi fi nd background ontologies in the Semantic Web ( Sabou et al., 2008 ).
In all these contributions, the process of matching with background knowledge comprises two steps: anchoring and deriving relations ( Fig. 2 ).

Anchoring refers to the mapping of entities from the source and target ontologies to entities of the background ontologies. This mapping follows the generic ontology matching process described in Section 3.1 .

Deriving relations is the process of discovering relations between source and target entities by looking for relations between their anchored concepts in the background knowl-edge ( Aleksovski, 2008 ). In the solutions proposed in the state of the art, derived relations are simple correspondences ( equivalence , subsumption ,or disjointness ) between one entity of the source ontology and one entity of the target ontology.
The ontology matching system proposed in our work uses back-ground knowledge to align ontologies in the Smart Grids domain.
However, unlike existing solutions, our system performs the anchoring by mapping instances, previously translated from the source to the target ontology ( d1 1 ), to concepts of domain ontologies. As will be detailed in Section 6 ,thisprocessenablestoautomatically fi complex correspondences relating more than two entities ( Fig. 3 ). 3.3. Ontology alignment evaluation
Starting from 2004, the Ontology Alignment Evaluation Initiative (OAEI) 2 campaign is run every year with the purpose of establishing a consensus for evaluating ontology matching methods. This initia-tive uses two evaluation measurements: compliance measurements and performance measurements. Compliance measurements compute the quality of the output alignments provided by the ontology matchers in comparison with the reference alignments, which comprise all the valid correspondences between the ontolo-gies that have to be aligned. The most common compliance measurements in ontology matching are: Recall , Precision and F-measure ( Euzenat and Shvaiko, 2007 ). Recall measures the ratio of correctly found correspondences (true positives) to the total number of reference alignments; Precision measures the ratio of true positives to the total number of returned correspondences; and F-measure is the harmonic mean of recall and precision. Meanwhile, performance measurements refer to the runtimes (in seconds) of the tests performed with different ontology matchers. 4. Proposed ontology matching system
The ontology matching system proposed in this paper consists of a schema-based subsystem and an instance-based subsystem ( Fig. 4 ).

The schema-based subsystem only uses schema-level input information. It imports the standard ontologies ( o 1 and o 2) and creates the initial alignments ( A 1 ) between them by combining different element-based methods. This sub-system also takes advantage of an electrical and electronic terminology database called electropedia . 3
For its part, the instance-based subsystem takes advantage of instance fi les. It involves an iterative process between the ESODAT data translator presented in ( Santodomingo et al., 2012 )andanexpert system developed in this study, the Domain Expert .Byprocessingthe initial alignments ( A 1 ), ESODAT translates an instance source ontology ( o 1) into the target ontology ( o 2). Given that the alignments do not include all the existing correspondences between ( d 1 1 ). The Domain Expert automatically detects data losses in d1 proposes new alignments ( A 0 ) for improving the translation in the next iteration. In order to do this, the Domain Expert employs its knowledge base previously created from domain ontologies that formally express deep background knowledge about re presentative substation archi-tectures. The iterative process continues until the Domain Expert detects that the translation has not improved from the previous iteration.

It is worth noting that Fig. 4 details the process for fi correspondences required to translate fi les from o 1to o 2. When the correspondences in the opposite direction are required, it is necessary to repeat the process by importing an instance fi coming from the ontology o 2.

Fig. 5 uses the classi fi cation proposed in ( Euzenat and Shvaiko, 2007 ) to summarize the ontology matching methods employed in our schema-based and instance-based subsystems. These methods will be explained in Sections 5 and 6 . 5. Schema-based subsystem
The schema-based subsystem is implemented in the CIMMap-pingBench, which is a stand-alone tool de fi ned in ( Uslar et al., 2008 ). It combines the following matching methods: the linguistic method, the language-based method, the string-based method and the constraint-based method.

In the linguistic method, an equivalent ontology was created from the electropedia terminology database in order to identify words with similar meanings and in different languages. This ontology is used to complete the strings of the entities by adding the de fi nitions given in the electropedia . The extended strings of the entities are then prepared with language-based methods. First, a word stemming algorithm ( Porter, 1980; Tartarus, 1980 ) reduces all the words within the names and descriptions to their root form, and next, a fi le including stop words ( Cornell, 1999 ) is used to out redundant words.

Once the strings of the entities have been prepared, string-based and constraint-based methods are used to compare entities of the ontologies o 1 and o 2. The string-based method compares the strings of the entities using the Jaro-Winkler algorithm ( Winkler, 1999 ). This comparison results in the similarity matrix Mstring , whose elements s -string ( e 1, e 2) give a unitary measure of the similarity between the entities e 1 and e 2. For its part, the constraint-based method compares the attributes of the entities; so it is calculated only for the similarities between classes. This method assumes that two classes can be equivalent (even if their names and descriptions are different) if more than 80% of their attributes are similar. Two attributes a 1 and a 2 are considered 0.9. The calculated similarity in Mconstraint ( s -constraint )is steadily increasing starting at 0 for 0% similar attributes and ending at 1 for 100% similar attributes.

Then, the CIMMappingBench combines the matrices Mstring and Mconstraint to obtain the fi nal similarity matrix M . When the -constraint is greater than 0.8 (that is, the classes have similar sets of attributes) the element s of the similarity matrix M is calculated as the arithmetic mean of s -string and s -constraint. Otherwise, s is simply the s -string value.

Finally, the schema-based subsystem uses a threshold-based extraction method to obtain the initial alignments (equivalences) from the fi nal similarity matrix M . These alignments must be very precise in order to facilitate convergence of the iterative process in the instance-based subsystem. Hence, in this study, the threshold was set in the
CIMMappingBench at 0.85, which is a very restricted value. 6. Instance-based subsystem
The instance-based subsystem comprises two processes: the data translation and the ontology matching process. The data translation is carried out by the ESODAT data translator presented in ( Santodomingo et al., 2012 ). This section focuses on the ontology matching process, which is performed by the expert system developed in this work, the Domain Expert .

Before describing this ontology matching process, it should be noted that the instance-based subsystem fi lters the initial align-ments imported from the schema-based subsystem in the fi rst iteration. This fi ltering process removes equivalences between classes and properties (e.g., between the class cim:VoltageLevel and the property scl:VoltageLevel ). Moreover, when a class is equivalent to two classes of the other ontology, it removes the equivalence with lower similarity. 6.1. Domain ontologies
The Domain Expert creates its knowledge base by importing domain ontologies. This knowledge base enables the Domain
Expert to detect data losses that occur during data translations in order to fi nd new alignments. What follows explains the reasons for creating domain ontologies in Smart Grids and gives an overview of the domain ontologies developed in this work.
CIM and SCL de fi ne classes that can be used to represent electric facilities. However, these standard models do not provide precise de fi nitions for describing a particular type of electric facilities. For instance, CIM includes the class cim:Substation to represent electrical substations, but it does not de fi characteristics of a typical radial substation, e.g.,:  X  it must contain two voltage levels  X  ,  X  one of the voltage levels must contain an electrical busbar  X  , etc. This means that it is possible to create valid
CIM and SCL fi les representing electric facilities that can rarely exist in practice, such as a substation that only consists of one circuit breaker. Consequently, the Domain Expert cannot evaluate data translations by importing the standard CIM and SCL ontolo-gies. Therefore, it is mandatory to create domain ontologies that formally describe how to represent typical electric facilities in CIM and SCL. Given that there are no many types of electric facilities in practise, in a realistic scenario it should be possible to create a database containing all the domain ontologies that are required for representing complete power systems.

In this work, the domain ontologies have been created in OWL and SWRL (Semantic Web Rule Language) ( Horrocks et al., 2004 ) by using the open-source ontology editor Prot X g X  3.4.6. 4 domain ontologies describe how to represent in CIM and SCL representative substation architectures that were considered in the case studies ( Section 7.1 ). The overall structure of such domain ontologies is presented next with a simple example. Fig. 6 shows an extract of the domain ontology that describes how to represent in CIM the H topology (or Type_ 3), which is one of the substation architectures given in the case studies. As can be observed, this extract de fi nes three classes: CIMHSubstation , CIMD 1 and CIME 1.
CIMHSubstation derives from cim:Substation . With the aim of describing the particu larities of H topologies, CIMHSubstation adds two constraints establishing that this class must have exactly one CIMHSubstation-CIMD 1propertyandone CIMHSubstation-CIME1 property. Such object properties derive from cim:VoltageLevel.
Substation , which is the CIM property used to represent the relationships between substations a nd voltage levels. Therefore, the constraints mentioned above establish that H topologies must have two voltage levels.

CIMD 1 and CIME 1 derive from cim:VoltageLevel . These classes de fi ne the particular characteristics of the two voltage levels that must be contained in H topologies. Thus, the de of CIMD 1 and CIME 1 (which, for clarity purposes, are not included in Fig. 6 ) provide detailed descriptions of the bays and conducting equipment (e.g., circuit breakers, and disconnectors) that should be included in these voltage levels. In this way, the domain ontologies created in this work de fi ne all the classes and proper-ties that are required to describe in CIM and in SCL fi ve repre-sentative substation architectures. 6.2. Ontology matching process in the domain expert
Ontology matching processes typically obtain the alignments by importing the standard ontologies that have to be aligned ( Fig. 1 ). Nonetheless, in the Domain Expert , the ontology matching process is carried out by importing an instance fi le d 1 the data translation) and two domain ontologies: the source domain ontology and the target domain ontology ( Fig. 7 ).
The Domain Expert fi rst compares d 1 1 with the source and target domain ontologies by using innovative similarity computa-tions ( Section 6.3 ). As a result of these comparisons, two similarity matrices Ms and Mt are obtained, which establish the similarities between the instances in d 1 1 and the classes in the source and the target domain ontologies, respectively. From Ms and Mt , alignment extraction methods developed in this work ( Section 6.4 ) obtain complex alignments between the standard ontologies. 6.3. Similarity computation
As discussed in Section 3.1 , the similarity computations devel-oped in this study are graph-based matching methods. Section 6.3.1 describes how the Domain Expert creates graphs from d 1 from the domain ontologies. Then, Section 6.3.2 details how these graphs are compared by considering local characteristics of the nodes. Finally, Section 6.3.3 presents the innovative graph-based matching algorithms that propagate the local similarities in order to obtain global similarities. 6.3.1. Knowledge acquisition
The knowledge base created in the Domain Expert comprises three graphs: I , Ds and Dt .The fi rst graph is created from d 1 represent the instances described in the output of the translation, whereas the arcs that connect the nodes represent object properties between the instances. Graphs Ds and Dt are created from the source domain ontology and the target domain ontology, respectively. Their nodes d represent domain ontology classes, whereas the arcs repre-sent object properties between the domain ontology classes.
The following example is used to describe the graphs mentioned above.Intheexample,theobjectiveistoobtainthecorrespon-dences that are required to carry out translations from CIM into SCL. Let us suppose that the instance-based subsystem uses an existing CIM fi le describing an electric facility that consists of a bay ( E1Q 1) containing a circuit breaker ( QA 1). Moreover, let us suppose that the initial alignments found by the schema-based subsystem ( A include the correspondences between cim:IdentifiedObject. name and scl:name and also between cim:Bay and scl:tBay . In that way, the output of the translation d 1 1 contains some SCL terms that are inferred in the data translator (ESODAT) by processing the initial alignments. For example, E 1 Q 1 will be represented in d 1 as an instance of cim:Bay , but also as an instance of scl:tBay Finally, let us suppose that the source domain ontology and the target domain ontology imported in the Domain Expert describe how to represent this type of electric facility in CIM and SCL, respectively. Fig. 8 shows the graphs I and Dt created in this example. In graph I , nodes include following two elements:
Classes represent the classes of the instances in the output of the translation. For example, the node E 1 Q 1 belongs to two classes: cim:Bay and scl:tBay .

Attributes refer to the data properties that appear in the de fi nition of the instance in the output of the translation. For example, the node E 1 Q 1 has the attributes scl:name and Identified Object.name .

Meanwhile, in graph Dt (the same as in graph Ds ) nodes contain the following elements:
Standard Class represents the class of the standard ontology from which the domain ontology class derives. For instance, the domain ontology class SCLBay 1 represents a particular type of bay, so it derives from the standard ontology class scl:tBay
Fixed Value Attributes refer to the constraints in the de of the domain ontology classes that set a speci fi c value for an attribute. For example, in SCL, circuit breakers are represented with scl:tConductingEquipment instances that take the value  X  CBR  X  in the attribute scl:type . Thus, the domain ontology class
SCLBreaker 1 includes the fi xed value attribute scl:type
Reference Attributes are the attributes used to establish relation-ships by reference; that is, relationships between two classes that are related when they take the same value in their reference attributes. No relationships by reference are included in the example. However, in SCL, connections between term-inals and connectivity nodes are represented with relationships by reference based on the reference attributes scl:connec-tivityNode and scl:pathName .

Attributes refer to all the other attributes that appear in the de fi nition of the domain ontology class.

Once the graphs have been created, the Domain Expert com-pares the nodes of graph I with the nodes of graphs Ds and Dt .
These comparisons are performed with the ontology matching methods presented in the following sub-sections. It should be noted that the explanation of these methods is based on the comparison between graph I and a generic graph D . However, as shown in Fig. 7 , this process is carried out for both Ds and Dt . 6.3.2. Local similarities
In order to compare graph I with graph D , the Domain Expert fi give a unitary measurement of the similarity between the nodes i of I and the nodes d of D focusing on their local characteristics.
In this context these characteristics are: name of the correspond-ing standard ontology class; label of the arcs connected to the nodes; and name and value of the attributes included in the nodes.
Hence, the local similarity matrix Ml containing all the similarities l ( i , d ) is obtained in this work as the weighted sum aggregation of Mc , Mr and Ma (1) ,with:
Mc being the matrix containing the similarities s c ( i , d ) between the names of the standard ontology classes related to i and d ,
Mr being the matrix containing the similarities s r ( i , d )between the labels of the arcs (i.e., object properties) connected to i in I and to d in D , and Ma being the matrix containing the similarities s a ( i , d ) between the attributes of i and d .

Ml  X  wc Mc  X  wr Mr  X  wa Ma  X  1  X 
In Mc , s c ( i , d )is1if i belongs to the standard ontology class from which d derives, and is 0, on the contrary. For instance, in
Fig. 8 , the value of s c ( E 1 Q 1, SCLBay 1) is 1, whereas the value of c ( E 1 Q 1, SCLBreaker 1) is 0.

Meanwhile, in Mr , elements s r ( i , d ) are calculated with the expression given in (2) , with: Ri being the set of all the arcs connected to i in I , Rd being the set of all the arcs connected to d in
D , and || being the number of elements contained in a set. For term | Ri \ Rd | is the intersection between the set of arcs connected to E 1 Q 1 and the set of arcs connected to SCLBay 1. These nodes have no arcs in common. Therefore, in this case, | Ri \ Rd ( E 1 Q 1, SCLBay 1)  X  0. r  X  i ; d  X  X j Ri \ Rd j = j Ri [ Rd j X  2  X  fi nally, elements s a ( i , d )of Ma are calculated with the expression given in (3) , with: Ai being the set of attributes included in i , and
Ad being the set of attributes included in d . Following the example presented above, s r ( E 1 Q 1, SCLBay 1)  X  1/1  X  1, because the only
SCL attribute in E 1 Q 1 and SCLBay 1is scl:name . a  X  i ; d  X  X j Ai \ Ad j = j Ai [ Ad j X  3  X 
As stated in Section 3.1 , two main approaches proposed in the state of the art have been considered in this work for combining similarity computations: ontology-driven approach and quality-driven approach. What follows explains why the ontology-driven approach was used in this study to calculate the weights wc , wr and wa in Eq. (1) .

In order to explain this choice, two aspects must be taken into account: (a) in our case, each entity i of I can only be mapped to, at the most, one entity d of D ; and (b) for each node i there is usually more than one node d with the same standard ontology class in D .
The second aspect implies that, typically, in the matrix Mc there will be instances i taking the similarity value 1 for different domain ontology classes d . Considering the fi rst aspect mentioned before, and using the quality parameters de fi ned in ( Cruz et al., 2009 ), it can be concluded that matrix Mc will have usually a low quality. Therefore, in most cases, the weights wc calculated by the quality-driven approach will be very low, or even 0. Despite of its low quality, Mc provides very useful information for carrying out the subsequent analyses ( Section 6.3.3 and Section 6.4 ), because it fi nds which instances and domain ontology classes have the same standard ontology class, i.e., the same type. Hence, in order to take advantage of the information provided by Mc , parameters other than the quality of the similarity matrices should be used for combining similarity computations in this case.

These parameters can be given by analyzing the graphs to be mapped (ontology-driven approach). In particular, the ontology-driven method employed in this study to calculate the weights wc , wr and wa , was the one proposed in ( Juanzi et al., 2009 ). The overall intuition behind this ontology-driven combination can be expressed as follows:  X  the more information about the local characteristics considered in a similarity matrix, the greater the weight assigned to that matrix  X  . As it will be explained next, this method is very useful in our context. Let us suppose that the initial alignments A 1 have more correspondences between classes than between properties and attributes. In this scenario, during the iteration graph I will have more relevant information about classes than about relationships and attributes, and, therefore, Mc will be more useful than Mr and Ma for fi nding the mappings. This perfectly with the ontology-driven method proposed in ( Juanzi et al., 2009 ), as it will assign a greater value to wc than to wr and wa . When in the fi rst iteration the system fi nds many correspon-dences between relationships, in the second iteration the weight wr calculated by the ontology-driven method will grow, because the matrix Mr will provide now more meaningful information.
In that way, the ontology-driven method sets the weights to better combine the similarity matrices at each step of the iterative process. 6.3.3. Global similarities
With the aim of obtaining the global similarities it is necessary to propagate the local similarities by considering the overall structures of the graphs. As discussed in Section 3.1 , existing graph-based matching methods proposed in the literature can be used for this purpose. This section presents two innovative graph-based matching methods developed in this study: Descendants
Similarity Contribution ( DSC ) and the Mixed Similarity Contribution ( MSC ).

The Descendants ' Similarity Contribution ( DSC ) is a new algo-rithm based on the Descendant's Similarity Inheritance algorithm (DSI) proposed in ( Cruz and Sunna, 2008 ). Whereas in DSI, containers propagate their similarities to their children in the graph, in the DSC, children propagate their similarities to their containers. What follows explains how the DSC calculates the global similarity between the instance i and the domain ontology class d . Let path_len_leave ( i ) be the minimum number of arcs between i and the farthest instance contained in i , and path_len_ leave ( d ) be the minimum number of arcs between d and the farthest domain ontology class contained in d . From these values, the DSC calculates the factors n , which is the maximum value of path_len_leave ( i ) and path_len_leave ( d ), and n2 , which is the minimum value of path_len_leave ( i ) and path_len_leave ( d ). Once the factors n and n 2 are obtained, the global similarity is calculated with the expression given in (4) . s g In (4) :
MCP is the main contribution percentage, which is the fraction of the local similarity s l ( i , d ) that will be used in determining the global similarity s g DSC ( i , d ). As in ( Cruz and Sunna, 2008 ), in this study the MCP was set at 0.75.

Si m and Sd m are the set of nodes contained in i (respectively, d ) that have m arcs between them and i (respectively, d ).
MSim is the match-based similarity between two sets of entities; in this case, between Si m and Sd m . As explained in chapter 4 of ( Euzenat and Shvaiko, 2007 ), MSim ( x , y ) is obtained with the expression given in (5) ; with Pairings ( x , y ) being the set of mappings between x and y .

Fig. 9 shows how the DSC obtains the global similarity between the instance E 1 Q 1 and the domain ontology class SCLBay 1. In the example, MSim 1 and MSim 2 measure the similarity between the sets { L 1, QA 1} and { SCLConnectivityNode 1, SCLBreaker 1}, and between the sets { T 1} and { SCLTerminal 1}, respectively. In this case, path_len_leave ( i ) and path_len_leave ( d ) are both equal to 2, because the shortest path that connects T 1 (respectively, SCLTerm-inal1 )to E 1 Q 1(respectively, SCLBay 1) has 2 arcs. Therefore, para-meters n and n 2 are both equal to 2, and, using the expression given in (4) , the weights assigned to MSim 1 and MSim 2 result in 0.167 and 0.083, respectively.

The Mixed Similarity Contribution ( MSC ) combines the simila-rities calculated with the DSI, the SSC (which is also proposed in ( Cruz and Sunna, 2008 )), and the DSC. Thus, the global similarity s g s g
The three methods DSI, SSC and DSC use the same ontology entities to obtain global similarities, so in this case it is not possible to calculate the weights w DSI , w SSC and w DSC the ontologies (graphs). Consequently, the MSC developed in this work employs the quality-driven combination proposed in ( Cruz et al., 2009 ). This means that the weights w DSI , w SSC automatically obtained by analyzing the quality of the similarity matrices M DSI , M SSC and M DSC .
 6.4. Alignment extraction
Once the global similarity matrices between I and Ds (i.e., Ms )and new alignments for the next iteration. The alignment extraction method developed in this study, unlike most existing methods in the literature, is able to fi nd complex semantic correspondences. This method comprises two steps. In the fi rst step, from the global similarities Ms and Mt , an innovative mapping algorithm maps the instances of I to their most similar domain ontology classes in Ds and
Dt ( Section 6.4.1 ). In the second step, from these mappings, the alignment extraction method detects losses that occurred in the translation and proposes new alignments with the aim of avoiding these data losses in the next iteration ( Section 6.4.2 ). 6.4.1. Mapping algorithm
In order to develop a mapping algorithm for the Domain Expert , it is important to consider the following aspects:
Every instance must be mapped to, at the most, one domain ontology class.

Every domain ontology class must be mapped to, at the most, one instance.
 Due to the existence of coverage mismatches ( Euzenat and Shvaiko, 2007 ), the mappings may not be bijective.

The alignments created from the mappings obtained by the mapping algorithm are used in the next iteration for translating an instance fi le.
 Therefore, the mapping algorithm must meet two requirements:
It must establish [0,1]  X  [0,1] mappings (using the notation of ( Melnik et al., 2002 )).

It must be precise; i.e., it should avoid the creation of false mappings, because this could make future translations worse. All the mapping algorithms mentioned in Section 3.1 (i.e., PM,
SM and MWBG) meet the fi rst requirement. As regards the second requirement, the precision of these algorithms can be improved by using a threshold; that is, the mapping algorithm fi rst obtains the mappings, and then it only selects those mappings with a global similarity greater than the threshold.

With the aim of enhancing the performance of the alignment extraction, a new mapping algorithm has been developed in this work: the Hierarchical Mapping ( HM ). The HM is based on the performance tuning detailed in ( Cruz and Sunna, 2008 ). Fig. 10 explains the HM algorithm by using a simple example. The HM starts by comparing the global similarities between the immediate children of the root nodes of I and D . The best possible match for each of the children is determined by the MWBG algorithm. Then the
HM compares only the sub-trees of the mapped nodes. This means that if i has been mapped to d in the previous step, then only the children of i are compared with the children of d .Thisprocessis repeated until the HM reaches the leave nodes. 6.4.2. Creation of complex correspondences
From the mappings between instances and domain ontology classes, the Domain Expert is able to detect data losses that occur during the data translation. In particular, four types of losses have been considered in this study ( Table 1 ). As will be discussed at the end of this sub-section, Table 1 does not provide a comprehensive list containing all the possible data losses that can occur during data translations. On the contrary, these are the losses that can be resolved by the Domain Expert by proposing new alignments.
In future work, the Domain Expert should be able to detect more data losses in order to fi nd more alignments.

For each data loss, the Domain Expert proposes a complex alignment that resolves such a loss in the next iteration. In what follows, the four types of data losses and the corresponding complex alignments are described by using simple examples. Data loss 1  X  missing target class occurs when: The instance i is mapped in Ds to ds and in D tto dt . The instance i does not belong to the standard class of dt .
In this case, the alignment extraction method creates a SWRL alignment that establishes a transformation rule: From the standard class and fi xed value attributes of ds . To the standard class and fi xed value attributes of dt .
For example, let us suppose that the instance QA 1 has been mapped to CIMBreaker 1in Ds and to SCLBreaker1 in Dt . As shown in Fig. 11 , during the translation it was not inferred that the instance QA 1 belongs to scl:tConductingEquipment , which is the standard class of SCLBreaker 1. Therefore, the alignment extrac-tion method creates the SWRL alignment given in (7) . cim :
Breaker  X  ? x  X  -scl : tCondu c tingEquipment  X  ? x  X   X  scl : type  X  ? x ; } CBR }  X   X  7  X 
Data loss 2  X  missing target relationship ( equivalent to source relationship ) occurs when: The instance i is mapped in Ds to ds and in Dt to dt .
The instance i n is mapped in Ds to ds n and in Dt to dt n In Ds there is a relationship rs ( ds , ds n ).
 In Dt there is an equivalent relationship rt ( dt , dt n ).
In the output of the translation, i is not related to i n relationship rt ( i , i n ).

In this case, the alignment extraction creates a SWRL alignment that establishes a transformation rule: From the standard class of ds and the relationship rs . To the relationship rt .

For example, in Fig. 12 , the instance E 1 is mapped to CIMVolta-geLevel 1in Ds and to SCLVoltageLevel 1in Dt . Meanwhile, the instance E 1 V is mapped to CIMVoltage 1in Ds and to SCLVoltage 1 in Dt . Moreover, E 1 is connected to E 1 V with cim:VoltageLevel
BaseVoltage , but not with scl:Voltage , which is the target ontology relationship. Consequently, the alignment extraction method creates the SWRL alignment given in (8) .
Data loss 3  X  missing target relationship ( inverse of source relationship ) occurs when: The instance i is mapped in Ds to ds and in Dt to dt .
The instance i n is mapped in Ds to ds n and in Dt to dt n In Ds there is a relationship rs ( ds , ds n ).
 In Dt there is an inverse relationship rt ( dt n , dt ).
In the output of the translation i n is not related to i by the relationship rt ( i n , i ).

In this case, the alignment extraction method creates a SWRL alignment that establishes a transformation rule: From the standard class of ds and the relationship rs . To the relationship rt , but changing the order of the arguments. For example, in Fig. 13 ,theinstance E 1ismappedto CIMVoltage-Level 1in Ds and to SCLVoltageLevel 1in Dt . Meanwhile, the instance SE 1ismappedto CIMSubstation 1in Ds and to SCLSubstation 1in Dt .Moreover, E 1 is connected to SE 1with cim:VoltageLevel.
Substation ,butnotwith scl:VoltageLevel ,whichisthetarget ontology relationship. Thus, the alignment extraction method creates the SWRL alignment given in (9) .Itshouldbenotedthatin (9) the order of the arguments in scl:VoltageLevel is the opposite to that in cim:VoltageLevel.Substation .
Data loss 4  X  missing target relationship ( source relationship by reference ) occurs when: The instance i is mapped in Ds to ds and in Dt to dt .
The instance i n is mapped in Ds to ds n and in Dt to dt n
In Ds there is a relationship by reference between ds and ds In Dt there is a relationship rt ( dt , dt n ).

In the output of the translation i is not related to i n by the relationship rt ( i , i n ).

In this case, the alignment extraction method creates a SWRL alignment that establishes a transformation rule:
From the standard class of ds and the relationship by reference between ds and ds n .
 To the relationship rt .
 For example, in Fig.14 the instance T 1ismappedto SCLTerminal 1in Ds and to CIMTermina1 in Dt . Meanwhile, the instance L 1ismappedto SCLConnectivityNode 1in Ds and to CIMConnectivityNode 1in Dt. More-over, T 1and L 1 are connected with an relationship by reference based on the attributes scl:connectivitNode and scl:pathName ;but these instances are not connected with the object property Terminal.ConnectivityNode , which is the target ontology rela-tionship. Therefore, the alignment extraction method creates the SWRL alignment given in (10) .Itshouldbestressedthatin (10) ,the relationship by reference between the terminal and the connectivity node in SCL is represented by using the swrlb:string Equal Ignore Case built-in ( Horrocks et al., 2004 ). scl : tTerminal  X  ? x  X   X  scl : connectivityNode  X  ? x ; ? scl : tConnectivityNode  X  ? y  X   X  scl : pathName  X  ? y ; ? swrlb : stringEqualIgnoreCase  X  ? v ; ? v n  X  -cim : Terminal : ConnectivityNode  X  ? x ; ? y  X   X  10  X 
Data losses other than the ones considered in this work might output of the transla tion (i.e., in graph I ), there might not be a relationship by reference that exists in the target domain ontology be necessary to fi nd complex alignments that can only be found by using advanced data analysis and statistics methods. However, such methods require a numerous set of valid instance fi les ( Euzenat and Shvaiko, 2007 ), which are not always available in this context. 6.5. Iterative process
Sections 6.2  X  6.4 detailed how the Domain Expert proposes new alignments at each step of the iterative process. The function whose value indicates that the iterative process has ended should measure the similarity between the output of the translations and the target domain ontology. The measure of this similarity ( obtained from the expression given in (11) .

In (11) : Rt ( dt ) is the set of all the relationships rt of the domain ontology class dt , and s rel ( i , rt ) is the similarity between a relationship rt of dt and the relationships of the instance i . The an instance i n related to i by the relationship rt ( i,i rel ( i , rt ) is 0.5 if the output of the translation does not include or rs ( i n , i ). In any other case, s rel ( i , rt )is0.
The function s TOT is not unitary; this means that it can take values greater than 1. The unitary value s TOT m is obtained by dividing s TOT by the maximum s TOT , which is calculated by setting all the similarities s g ( i , dt ) and s rel ( rt ) at 1. The iterative process stops when s TOT m does not change more than a threshold  X  from the previous iteration. In this study,  X  was set at 0.01. ?? 7. Evaluation
The fi rst objective of the tests performed in this study was to compare the proposed ontology matching system with the Agree-mentMaker ( Cruz et al., 2007 ), which is currently one of the best generic ontology matchers according to the Ontology Alignment
Evaluation Initiative (OAEI) competitions ( Euzenat et al., 2011 ). The second objective was to evaluate the MSC and the HM algorithms developed in this work. Thus, these algorithms were compared against the main graph-based methods and the main mapping algorithms included in the state of the art. 7.1. Case studies
In the case studies, the proposed system had to obtain the alignments for performing bi-directional translations between CIM and SCL of instance fi les representing fi ve substation archi-tectures. Table 2 provides a brief description of these substation ?? ?? architectures, which are: the simple substation ( Simple ) used in ( Santodomingo et al., 2011 ), the radial substation ( Radial ) described in the IEC 61850-6 standard, and three representative substation architectures ( Type_ 1, Type_ 2 and Type_ 3) de the main Spanish electricity companies in ( GSECS-61850, 2010 ). 7.2. Reference alignments
For each case study, a set of reference alignments has been created in this work by using Prot X g X  3.4.6 and Jena programming framework ( Jena, 2013 ). Each set of reference alignments include all the required correspondences for performing bi-directional translations between CIM and SCL for one of the substation architectures presented above. All the sets of reference alignments have been successfully validated in ESODAT, which proved able to make valid data translations for all the substation architectures by importing these reference alignments.

Table 3 describes the reference alignments. For the Simple architecture, all the required correspondences have been expressed in SWRL. However, this is not possible for the rest of the architectures. For the Radial architecture only 90.74% of the correspondences have been expressed in that language. The rest of the correspondences require the de fi nition of new variables in the consequent that have not been included in the antecedent of the transformation rule. Therefore, these had to be represented in Jena
Rule Language by using the makeInstance built-in expression ( Jena, 2013 ). Given that the proposed ontology matching system only creates SWRL rules, in the Radial architecture it will be able to obtain at maximum 90.74% of all the required correspondences.
Table 3 also shows the number of simple equivalences that are included in the reference alignments. As discussed, most of the existing ontology matchers are only able to obtain simple equiv-alences between the ontologies. Consequently, the ratio of equiv-alences determines the maximum percentage of alignments that can be obtained with generic ontology matchers. For instance, only 29.63% of the alignments required for the Radial architecture can be expressed as simple equivalences. 7.3. Results and discussion
This subsection provides a synthesis of the results obtained in the tests. The complete results can be found in the website of the fi rst author. 5 The tests were performed on a 3.16 GHz Intel Core
Duo CPU with 3.23 GB of RAM, running Windows XP. 7.3.1. Comparison with the AgreementMaker
The results obtained in the case studies with the ontology matching system developed in this work were compared to those obtained with the AgreementMaker. In particular, the matcher employed in the case studies was that used by the Agreement-
Maker in the OAEI 2011 ( Cruz et al., 2011 ). During the tests, it was observed that the maximum F-measures obtained with the Agree-mentMaker occurred with its mapping threshold set at 0.7. There-fore, this was the mapping threshold used in the AgreementMaker for the case studies.

Table 4 shows the Recall ( R ), Precision ( P ) and F-measure ( F ) obtained in the case studies with: the schema-based subsystem presented in Section 5 ( S-based system ), the complete ontology matching system proposed in this work using the MSC graph-based method and the HM mapping algorithm ( OM system ), and the AgreementMaker ( AMaker ). As can be seen, the complete ontology matching system developed in this work improved the
F-measures by almost 35% on average compared with the Agree-mentMaker. This is because the proposed system is able to complex correspondences, improving the recall by 40% on average.
Furthermore, due to the fi lter included in the instance-based subsystem, it also improves the precision by 22%.

As regards the performance measurements, the runtime with the AgreementMaker and the schema-based subsystem was close to 1 min; that is, as will be detailed in Section 7.3.2 , almost times faster than with the complete system. However, given that the aligning between CIM and SCL ontologies is required for con fi guring power systems (not for real-time operations), the runtime with the matching system developed in this work is acceptable.

It should be emphasized that the comparison with the Agree-mentMaker is not a competition in equal terms, because due to the
OAEI restrictions, the AgreementMaker does not use speci fi knowledge about the domain. In fact, this is the main contribution of the ontology matching system developed in this work: how to automatically process deep domain knowledge in order to fi semantic correspondences that cannot be found with the best generic ontology matchers.

With the aim of clarifying the scope and limitations of our system, the next three paragraphs will discuss the expected results of this system in a generic OAEI benchmark.

The OAEI benchmark test sets are built around a seed ontology and many variations of it ( Cuenca Brau et al., 2013 ). In that way, ontology matchers must align the seed ontology with all the variations created in the benchmark. It is worth noting that the reference alignments in these benchmarks only include simple correspondences between pairs of entities. Hence, these tests do not assess the ability of a system to fi nd complex correspondences, which is the main feature of our system. Besides, in order to compare ontology matchers in conditions that are equal for all of them, neither background knowledge nor instance fi les can be used in the OAEI benchmarks.

Taking the aforementioned restrictions into account, our ontol-ogy matching system would only be able to use 3 out of its 8 ontology matching methods (see Fig. 5 ). All the matching methods of the instance-based subsystem require instances and domain ontologies. For example, the graph-based methods are used in our system for mapping instances to domain ontology classes. Therefore, these methods would not be used by our system in the OAEI benchmark. As for the matching methods of the schema-based subsystem, only the string-based, language-based, and constraint-based methods would be employed in the benchmark. As explained in Section 5 , these methods are normally enhanced in our system by using the electropedia domain termi-nology dictionary. However, without this speci fi c background knowledge of the electric power system domain, they are rather simple methods that would obtain similar results to those obtained by the edna matcher, which is as a simple edit distance matcher that serves as a baseline in the OAEI evaluation cam-paigns. According to the OAEI report of 2011 ( Euzenat et al. 2011 ), edna obtained an F-measure of 0.51 in one of the benchmarks, whereas the AgreementMaker obtained an F-measure of 0.71.
These results show that when it is not possible to use background knowledge and instance fi les, the best generic ontology matchers outperform our system. Furthermore, generic ontology matchers have improved their performance during the last years. Thus, in the benchmark used in the OAEI 2013 ( Cuenca Brau et al., 2013 ), edna obtained an F-measure of 0.41, whereas the best ontology matchers in those tests  X  YAM  X  X  ( Ngo and Bellahsene, 2013 ) and
CroMatcher ( Guli  X  and Vrdoljak, 2013 )  X  obtained F-measures that were close to 0.9.

In conclusion, we do not have developed a generic ontology matcher that outperforms existing matchers in all cases. On the contrary, we have de fi ned a novel methodology to take advantage of background knowledge ontologies and instance fi les for complex semantic correspondences in a particular domain. Our system and methodology could be reused in other domains, but only by importing domain ontologies and instance fi les of that particular domain. Otherwise, our system would not obtain as good results as existing generic ontology matchers. This suggests that, in principle, it would be possible to enhance our system by adding novel techniques used by the best generic ontology matchers. In particular, these techniques would improve the performance of the domain-independent methods employed in the schema-based subsystem in order to obtain better initial alignments. It should be noted, however, that this enhancement does not seem critical in the particular case of the CIM-SCL aligning. Thus, the tests carried out in this work show that the initial CIM-SCL alignments found by the schema-based subsystem are similar to those found by the AgreementMaker (see Table 4 ). 7.3.2. Evaluation of MSC and HM algorithms
The tests presented in this sub-section compared the results obtained with the proposed system by using different similarity computations and different mapping algorithms in the instance-based subsystem. As explained in Section 6 , the instance-based subsystem uses similarity computations and mapping algorithms for mapping instances to domain ontology classes. In that way, these tests assessed whether the innovative similarity computa-tion (MSC) and mapping algorithm (HM) developed in this work outperformed the main solutions in the state of the art in the speci fi c task of mapping instances to domain ontology classes.
Table 5 shows the F-measures obtained with different similar-ity computations (rows of the table) and different mapping algorithms (columns of the table). The notation used in Table 5 for the similarity computations and the mapping algorithms was explained in Section 3.1 . As can be seen, the best F-measure is obtained by combining the MSC with the HM. Furthermore, this combination obtains good results in terms of performance. Thus, whereas the average runtime in all the possible combinations is 2544.77 s, the runtime in the MSC-HM combination is 303.196 s.
The explanation for these results is detailed as follows. MSC is a simple computation (hence, it obtains good performance measure-ments) that considers all the possible contributions of the asso-ciated nodes (sons, parents and siblings) in the propagation of the local similarities, which explains its good results in terms of compliance measurements. Regarding the mapping algorithm, HM only evaluates the similarities between nodes in the same hierarchical level. Therefore, it provides good results (in both performance and compliance measurements) when the equivalent concepts in both ontologies are represented in the same hierarch-ical level, which occurs in the CIM and SCL aligning.

Additional tests were performed in order to draw broader conclusions about the performance of MSC, HM, and, in general, about the performance of all the matching methods used in this evaluation. In these additional tests, 10% of the hierarchical relationships included in the SCL domain ontology were trans-formed into normal relationships. In that way, we simulated the case in which a number of equivalent concepts are represented in different hierarchical level in the ontologies to be aligned. The tests showed that, after this modi fi cation in the hierarchies of the graphs, the combinations SNM-MWBG and DIS-MWBG outper-formed the MSC-HM combination.

In summary, when the equivalent concepts in both ontologies were in the same hierarchical levels, the combination MSC-HM improved the F-measure by 1.5% compared with existing graph-based matching methods and mapping algorithms. However, when the hierarchies of the graphs were modi fi ed, other combi-nations obtained better compliance measurements. In any case, no major differences were found in the results obtained with different graph-based matching methods. Besides, none of them obtained F-measures greater than 70%. Therefore, as will be explained in Section 8 , other similarity computations different from graph-based matching methods should be used in future work to improve the mapping of instances to domain ontology classes in the instance-based subsystem. 8. Conclusions
In this contribution, an ontology matching system for future energy Smart Grids was presented. This system uses instance and imports deep domain knowledge from external domain ontologies in order to obtain complex alignments that cannot be found with generic ontology matchers. Moreover, it employs innovative graph-based matching methods ( DSC and MSC ) and innovative mapping algorithms ( HM ) that have been developed in this work.

The evaluation of the proposed ontology matching system was based on the main interoperability issue within the scope of Smart
Grids: the alignment of CIM and SCL ontologies. In the tests performed in this study, the system had to obtain the required alignments to perform bi-directional translations between CIM and SCL fi les representing fi ve substation architectures. In these tests, the proposed system outperformed one of the best generic ontology matchers according to the OAEI, the AgreementMaker.
Furthermore, the MSC-HM combination obtained better results than the main graph-based matching methods and the main mapping algorithms included in the state of the art. It is worth noting, however, that we have not developed a generic ontology matching system. Thus, when background knowledge and instance fi les cannot be used, the AgreementMaker and other generic matchers (such as, YAM  X  X  and CroMatcher) obtain better results than our system. Besides, the MSC-HM combination outperforms existing graph-based matching methods and map-ping algorithms only when the equivalent concepts in both ontologies are represented in the same hierarchical level, which occurs in the CIM and SCL aligning.
 Even though the proposed system signi fi cantly improves the
CIM-SCL aligning, it is not able to automatically fi nd all the alignments. During the tests it was observed that the similarity computation was the bottle neck of the matching process; i.e., it does not seem possible to fi nd more alignments from the similar-ity matrices created with the similarity computation. Therefore, in order to improve the ontology matching system, another type of similarity computation different from graph-based methods should be adopted for the system. On this topic, model-based methods, especially the methods based on Description Logics (DL), are a promising research direction. These methods have not been considered in this study because, at the time of developing the ontology matching system, they were not as mature as existing graph-matching algorithms. Nevertheless, future work will ana-lyze in detail how DL-based methods can take advantage of the de fi nitions included in the domain ontologies in order to compare these domain ontologies precisely with the instance fi les imported in the system. Furthermore, additional case studies will be designed with the aim of proving the ability of the system to align other standard ontologies in Smart Grids, or even in other domains.
 Acknowledgment
The authors wish to thank Professor I.F. Cruz from the Uni-versity of Illinois at Chicago, for granting them permission to use the AgreementMaker in this study. This work was supported in part by the Ministry of Education of the Madrid Government under Grant CPI/0349/2008.
 References
