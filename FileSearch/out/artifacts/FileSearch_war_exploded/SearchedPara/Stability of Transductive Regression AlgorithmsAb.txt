 Corinna Cortes corinna@google.com Google Research, 76 Ninth Avenue, New York, NY 10011. Mehryar Mohri mohri@cims.nyu.edu Dmitry Pechyony pechyony@cs.technion.ac.il Technion -Israel Institute of Technology, Haifa 32000, Israel. Ashish Rastogi rastogi@cs.nyu.edu Many learning problems in information extraction, computational biology, natural language processing and other domains can be formulated as transductive inference problems (Vapnik, 1982). In the transduc-tive setting, the learning algorithm receives both a la-beled training set, as in the standard induction setting, and a set of unlabeled test points. The objective is to predict the labels of the test points. No other test points will ever be considered. This setting arises in a variety of applications. Often, the points to label are known but they have not been assigned a label due to the prohibitive cost of labeling. This motivates the use of transductive algorithms which leverage the un-labeled data during training to improve learning per-formance.
 This paper deals with transductive regression, which arises in problems such as predicting the real-valued labels of the nodes of a known graph in computational biology, or the scores associated with known docu-ments in information extraction or search engine tasks. Several algorithms have been devised for the specific setting of transductive regression (Belkin et al., 2004b; Chapelle et al., 1999; Schuurmans &amp; Southey, 2002; Cortes &amp; Mohri, 2007). Several other algorithms in-troduced for transductive classification can be viewed in fact as transductive regression ones as their objec-tive function is based on the squared loss, e.g., (Belkin et al.2004a; 2004b). Cortes and Mohri (2007) also gave explicit VC-dimension generalization bounds for trans-ductive regression that hold for all bounded loss func-tions and coincide with the tight classification bounds of Vapnik (1998) when applied to classification. This paper presents novel algorithm-dependent gen-eralization bounds for transductive regression. Since they are algorithm-specific, these bounds can often be tighter than bounds based on general complexity mea-sures such as the VC-dimension. Our analysis is based on the notion of algorithmic stability.
 In Sec. 2 we give a formal definition of the transductive regression setting and the notion of stability for trans-duction. Our bounds generalize the stability bounds given by Bousquet and Elisseeff (2002) for the in-ductive setting and extend to regression the stability-based transductive classification bounds of (El-Yaniv &amp; Pechyony, 2006). Standard concentration bounds such as McDiarmid X  X  bound (McDiarmid, 1989) can-not be readily applied to the transductive regression setting since the points are not drawn independently but uniformly without replacement from a finite set. Instead, a generalization of McDiarmid X  X  bound that holds for random variables sampled without replace-ment is used, as in (El-Yaniv &amp; Pechyony, 2006). Sec. 3.1 gives a simpler proof of this bound. This concentration bound is used to derive a general transductive regression stability bound in Sec. 3.2. In Sec. 4, we present the stability coefficients for a family of local transductive regression algorithms. The anal-ysis in this section is based on convexity. In Sec. 5, we study the stability of other transductive regression al-gorithms (Belkin et al., 2004a; Wu &amp; Sch  X olkopf, 2007; Zhou et al., 2004; Zhu et al., 2003) based on their closed form solution and propose a modification to the seemingly unstable algorithm that makes them stable and guarantees a non-trivial generalization bound. Fi-nally, Sec. 6 shows the results of experiments with lo-cal transductive regression demonstrating the benefit of our stability bounds for model selection, in partic-ular for determining the radius of the local neighbor-hood used by the algorithm. This provides a partial validation of our bounds and analysis. Let us first describe the transductive learning setting. Assume that a full sample X of m + u examples is given. The learning algorithm further receives the la-bels of a random subset S of X of size m which serves as a training sample. The remaining u unlabeled ex-amples, x m +1 , . . . , x m + u  X  X , serve as test data. We denote by X  X  ( S, T ) a partitioning of X into the training set S and the test set T . The transductive learning problem consists of predicting accurately the labels y m +1 , . . . , y m + u of the test examples, no other test examples will ever be considered (Vapnik, 1998). 1 The specific problems where the labels are real-valued numbers, as in the case studied in this paper, is that of transduction regression . It differs from the standard ( induction ) regression since the learning algorithm is given the unlabeled test examples beforehand and can thus exploit this information to improve performance. We denote by c ( h, x ) the cost of an error of a hypoth-esis h on a point x labeled with y ( x ). The cost func-tion commonly used in regression is the squared loss per, we will assume a squared loss but many of our results generalize to other convex cost functions. The training and test errors of h are respectively b R ( h ) = generalization bounds we derive are based on the no-tion of transductive algorithmic stability.
 Definition 1 (Transduction  X  -stability) . Let L be a transductive learning algorithm and let h denote the hypothesis returned by L for X  X  ( S, T ) and h  X  the hy-pothesis returned for X  X  ( S  X  , T  X  ) . L is said to be uni-formly  X  -stable with respect to the cost function c if there exists  X   X  0 such that for any two partitionings X  X  ( S, T ) and X  X  ( S  X  , T  X  ) that differ in exactly one training (and thus test) point and for all x  X  X , 3.1. Concentration Bound for Sampling Stability-based generalization bounds in the inductive setting are based on McDiarmid X  X  inequality (1989). In the transductive setting, the points are drawn uni-formly without replacement and thus are not indepen-dent. Therefore, McDiarmid X  X  concentration bound cannot be readily used. Instead, a generalization of McDiarmid X  X  bound for sampling without replacement is needed as in El-Yaniv and Pechyony (2006). We will denote by S m 1 a sequence of random vari-ables S 1 , . . . , S m and write S m 1 = x m 1 as a short-hand for the m equalities S i = x i , i = 1 , . . . , m and Theorem 1 ((McDiarmid, 1989), 6.10) . Let S m 1 be a sequence of random variables, each S i taking values in the set X , and assume that a measurable function  X  : X m 7 X  R satisfies:  X  i  X  [1 , m ] ,  X  x i , x  X  i  X  X, The following is a concentration bound for sampling without replacement needed to analyze the general-ization of transductive algorithms.
 Theorem 2. Let x m 1 be a sequence of random vari-ables, sampled from an underlying set X of m + u el-ements without replacement, and let that  X  : X m 7 X  R be a symmetric function such that for all i  X  [1 , m ] and for all x 1 , . . . , x m  X  X and x  X  1 , . . . , x  X  m  X  X , Then,  X   X  &gt; 0 , Pr P For uniform sampling without replacement, the probability terms can be written as: between brackets, we divide the set of permutations { x that do not. If a permutation x  X  m i +1 contains x i we x k = x i . We then match it up with the permutation x permutations contain exactly the same elements, and since the function  X  is symmetric in its arguments, the difference in the value of the function on the permutations is zero.
 In the other case, if a permutation x  X  m i +1 does not contain the element x i , then we simply match it up with the same permutation in { x m i +1 } . The match-ing permutations appearing in the summation are then x spect to x i . The difference in the value of the func-tion  X  in this case can be bounded by c . The num-P with the identity yields that Pr  X   X  E [  X  ]  X   X   X  2 exp  X  2  X  2  X   X  is symmetric in m and u in the sense that selecting one of the sets uniquely determines the other set. The statement of the theorem then follows from a similar the tighter of the two. 3.2. Transductive Stability Bound To obtain a general transductive regression stability bound, we apply the concentration bound of Theo-rem 2 to the random variable  X  ( S ) = R ( h )  X  b R ( h ). To do so, we need to bound E S [  X  ( S )], where S is a ran-dom subset of X of size m , and |  X  ( S )  X   X  ( S  X  ) | where S and S  X  are samples differing by exactly one point. Lemma 1. Let H be a bounded hypothesis set (  X  x  X  X, | h ( x )  X  y ( x ) | X  B ) and L a  X  -stable algorithm re-turning the hypotheses h and h  X  for two training sets S and S of size m each, respectively, differing in exactly one point. Then, Proof. By definition, S and S  X  differ exactly in one point. Let x i  X  S , x m + j  X  S  X  be the points in which the two sets differ. The lemma follows from the obser-vation that for each one of the m  X  1 common labeled points in S and S  X  , and for each one of the u  X  1 common test points in T and T  X  (recall T = X \ S , T  X  = X \ S  X  ), the difference in cost is bounded by  X  , while for x i and x m + j , the difference in cost is bounded by B 2 . Then, it follows that |  X  ( S )  X   X  ( S  X  Lemma 2. Let h be the hypothesis returned by a  X  -stable algorithm L . Then, | E S [  X  ( S )] | X   X  . Proof. By definition of  X  ( S ), its expectation is E S [ c ( h, x m + j )] is the same for all j  X  [1 , u ], and E
S [ c ( h, x i )] the same for all i  X  [1 , m ], for any i E
S  X  [ c ( h  X  , x i )]  X  E S [ c ( h, x i )]. Thus, E S E Theorem 3. Let H be a bounded hypothesis set (  X  x  X  X, | h ( x )  X  y ( x ) | X  B ) and L a  X  -stable algorithm. Let h be the hypothesis returned by L when trained on X  X  ( S, T ) . Then, for any  X  &gt; 0 , with prob. at least 1  X   X  , R ( h )  X  b R ( h )+  X  + 2  X  + Proof. The result follows directly from Theorem 2 and Lemmas 1 and 2.
 This is a general bound that applies to any transduc-tive algorithm. To apply it, the stability coefficient  X  , which depends on m and u , needs to be determined. In the subsequent sections, we derive bounds on  X  for a number of transductive regression algorithms (Cortes &amp; Mohri, 2007; Belkin et al., 2004a; Wu &amp; Sch  X olkopf, 2007; Zhou et al., 2004; Zhu et al., 2003). This section describes and analyzes a general family of local transductive regression algorithms ( LTR ) gen-eralizing the algorithm of Cortes and Mohri (2007). LTR algorithms can be viewed as a generalization of the so-called kernel regularization-based learning al-gorithms to the transductive setting. The objective function that they minimize is of the form: where kk K is the norm in the reproducing kernel Hilbert space (RKHS) with associated kernel K , C  X  0 and C  X   X  0 are trade-off parameters, and e c ( h, x ) = ( h ( x )  X  e y ( x )) 2 is the error of the hypothesis h on the unlabeled point x with respect to a pseudo-target e y . Pseudo-targets are obtained from neighborhood labels y ( x ) by a local weighted average. Neighborhoods can be defined as a ball of radius r around each point in the feature space. We will denote by  X  loc the score-stability coefficient of the local algorithm used, that is the maximal amount by which the two hypotheses differ on an given point, when trained on samples dis-agreeing on one point. This notion is stronger than that of cost-based stability.
 In this section, we use the bounded-labels assumption, that is  X  x  X  S , | y ( x ) | X  M . We also assume that for any x  X  X , K ( x, x )  X   X  2 . We will use the fol-lowing bound based on the reproducing property and the Cauchy-Schwarz inequality valid for any hypothe-sis h  X  H :  X  x  X  X, Lemma 3. Let h be the hypothesis minimizing (3). Assume that for any x  X  X , K ( x, x )  X   X  2 . Then, for any x  X  X , | h ( x ) | X   X M Proof. The proof is a straightforward adaptation of the technique of (Bousquet &amp; Elisseeff, 2002) to LTR al-gorithms. By Eqn. 4, | h ( x ) | X   X  k h k K . Let 0  X  R m + u be the hypothesis assigning label zero to all examples. By definition of h , Using k h k K  X  Since | h ( x ) | X   X M a bound on | h ( x )  X  y ( x ) | X  M (1 +  X  we are in a position to apply Theorem 3 with B = AM , A = 1 +  X  We now derive a bound on the stability coefficient  X  . To do so, the key property we will use is the convexity of h 7 X  c ( h, x ). Note, however, that in the case of e c , the pseudo-targets may depend on the training set S . This dependency matters when we wish to apply convexity with two hypotheses h and h  X  obtained by training on different samples S and S  X  . For convenience, for any two such fixed hypotheses h and h  X  , we extend the definition of e c as follows. For all t  X  [0 , 1], This allows us to use the same convexity property for e c as for c for any two fixed hypotheses h and h  X  , as verified by the following lemma, and does not affect the proofs otherwise.
 Lemma 4. Let h be a hypothesis obtained by training on S and h  X  by training on S  X  . Then, for all t  X  [0 , 1] , Proof. Let e y = e y ( x ) be the pseudo-target value at x when the training set is S and e y  X  = e y  X  ( x ) when the training set is S  X  . For all t  X  [0 , 1], The statement of the lemma follows directly by the convexity of x 7 X  x 2 over real numbers.
 Let h be a hypothesis obtained by training on S and h  X  by training on S  X  . Let  X  = h  X  h . Then, for all x  X  X , | c ( h, x )  X  c ( h  X  , x ) | =  X   X   X  k  X  k K , thus for all x  X  X , Lemma 5. Assume that for all x  X  X , | y ( x ) | X  M . Let S and S  X  be two samples differing by exactly one point. Let h be the hypothesis returned by the algorithm minimizing the objective function F ( h, S ) , h  X  be the hypothesis obtained by minimization of F ( h, S  X  ) and let e y and e y  X  be the corresponding pseudo-targets. Then,
C [ c ( h  X  , x i )  X  c ( h, x i )] /m  X  C  X  [ e c ( h  X  , x  X  2 AM (  X  k  X  k K ( C/m + C  X  /u ) +  X  loc C  X  /u ) . where  X  = h  X   X  h and A = 1 +  X  Proof. Let  X  c ( h i ,  X  y i ) =  X  c ( h, x i ) and  X  c ( h By Lemma 3 and the bounded-labels assumption, | e c ( h  X  i , e y  X  i )  X  e c ( h i , e y i ) | = | e c ( h  X  i , e y  X  i )  X  e c ( h  X  i , e y i ) + e c ( h  X | ( e y  X  i  X  e y i )( e y  X  i + e y i  X  2 h  X  i ) | + | ( h By the score-stability of local estimates, e y  X  ( x i )  X  e y ( x i )  X   X  loc . Thus, Using 6 leads after simplification to the statement of the lemma.
 The proof of the following theorem is based on Lemma 4 and Lemma 5 and is reserved to a longer version of this paper.
 Theorem 4. Assume that for all x  X  X , | y ( x ) | X  M and there exists  X  such that  X  x  X  X , K ( x, x )  X   X  2 . Further, assume that the local estimator has uniform stability coefficient  X  loc . Let A = 1+  X  LTR is uniformly  X  -stable with  X   X  2( AM ) 2  X  2 Our experiments with LTR will demonstrate the benefit of this bound for model selection (Sec. 6). 5.1. Unconstrained Regularization Algorithms In this section, we consider a family of transductive regression algorithms that can be formulated as the following optimization problem: pirical weights (in practice it is often a diagonal ma-trix), y  X  R ( m + u )  X  1 are the target values of the m labeled points together with the pseudo-target values of the u unlabeled points (in some formulations, the pseudo-target value is 0), and h  X  R ( m + u )  X  1 is a col-umn vector whose i th row is the predicted target value for the x i . The closed-form solution of (8) is given by The formulation (8) is quite general and includes as special cases the algorithms of (Belkin et al., 2004a; Wu &amp; Sch  X olkopf, 2007; Zhou et al., 2004; Zhu et al., 2003). We present a general framework for bounding the stability coefficient of these algorithms and then examine the stability coefficient of each of these algo-rithms in turn.
 For a symmetric matrix A  X  R n  X  n we will denote by  X  M ( A ) its largest eigenvalue and  X  m ( A ) its smallest. Then, for any v  X  R n  X  1 ,  X  m ( A ) k v k 2  X k Av k 2  X   X 
M ( A ) k v k 2 . We will also use in the proof of the fol-lowing proposition the fact that for symmetric matri-ces A , B  X  R n  X  n ,  X  M ( AB )  X   X  M ( A )  X  M ( B ). Proposition 1. Let h and h  X  solve (8), under test and training sets that differ exactly in one point and let C , C  X  , y , y  X  be the analogous empirical weight and the target value matrices. Then, k h  X   X  h k 2  X  k y Proof. Let  X  = h  X   X  h and  X  y = y  X   X  y . Let C = ( C  X  1 Q + I ) and C  X  = ( C  X   X  1 Q + I ). By definition, Thus, k  X  k 2  X  Furthermore,  X  m ( C )  X   X  m ( Q )  X  back into Eqn. 10 yields: k  X  k 2  X  Since k h  X   X  h k  X  is bounded by k h  X   X  h k 2 , the propo-sition provides a bound on the score-stability of h for the transductive regression algorithms of Zhou et al. (2004); Wu and Sch  X olkopf (2007); Zhu et al. (2003). For each of these algorithms, the pseudo-targets used are zero. If we make the bounded labels assumption to show that k y  X  y  X  k 2  X  We now examine each algorithm in turn.
 Consistency method ( CM ) In the CM algo-rithm (Zhou et al., 2004), the matrix Q is a normal-that captures affinity between pairs of points in the full sample X . Thus, Q = I  X  D  X  1 / 2 WD  X  1 / 2 , where P j [ W ] i,j . Note that  X  m ( Q ) = 0. Furthermore, ma-trices C and C  X  are identical in CM , both diagonal ma-trices with ( i, i )th entry equal to a positive constant &gt; 0. Thus C  X  1 = C  X  X  X  1 and using Prop. 1, we ob-tain the following bound on the score-stability of the CM algorithm:  X  CM  X  Local learning regularization ( LL  X  Reg ) In the LL  X  Reg algorithm (Wu &amp; Sch  X olkopf, 2007), the regularization matrix Q is ( I  X  A ) T ( I  X  A ), where R captures the local similarity between all pairs of points in X . A is normalized, i.e. each of its rows sum to 1. Let C l , C u &gt; 0 be two positive constants. The matrix C is a diagonal matrix with [ C ] i,i = C l if x i  X  S and C u otherwise. Let C max = max { C l , C u } and C min = min { C l , C u } . Thus, k C  X  X  X  1  X  C  X  1 k  X  rem, its eigenvalues lie in the interval (  X  1 , 1] and  X 
M ( A )  X  1. Thus,  X  m ( Q )  X  0 and  X  M ( Q )  X  4 and we have the following bound on the score-stability of the LL  X  Reg algorithm:  X  LL  X  Reg  X  4  X  Gaussian Mean Fields algorithm GMF (Zhu et al., 2003) is very similar to the LL  X  Reg , and admits ex-actly the same stability coefficient.
 Thus, the stability coefficients of the algorithms of CM , LL  X  Reg , and GMF can be large. Without addi-tional constraints on the matrix Q , these algorithms do not seem to be stable enough for the generalization bound of Theorem 3 to converge. A particular exam-ple of constraint is the condition by Belkin et al. X  X  algorithm (2004a). In the next sec-tion, we give a generalization bound for this algorithm and then describe a general method for making the algorithms just examined stable. 5.2. Stability of Constrained Regularization This subsection analyzes constrained regularization al-gorithms such as the Laplacian-based graph regular-ization algorithm of Belkin et al. (2004a). Given a weighted graph G = ( X, E ) in which edge weights represent the extent of similarity between vertices, the task consists of predicting the vertex labels. The hy-pothesis h returned by the algorithm is solution of the following optimization problem: the graph Laplacian, { y i | i  X  [1 , m ] } are the target values of the m labeled nodes.
 The hypothesis set H in this case can be thought of as a hyperplane in R m + u that is orthogonal to the vector 1  X  R m + u . Maintaining the notation used in (Belkin et al., 2004a), we let P H denote the operator corresponding to the orthogonal projection on H . For a sample S drawn without replacement from X , define I [ I
S ] i,i = 1 if x i  X  S and 0 otherwise. Similarly, let y if x i  X  S and 0 otherwise. The closed-form solution on a training sample S is given by (Belkin et al., 2004a): Theorem 5. Assume that the vertex labels of the graph G = ( X, E ) and the hypothesis h obtained by optimizing Eqn. 11 are both bounded (  X  x, | h ( x ) | X  M and | y ( x ) | X  M for some M &gt; 0 ). Let A = 1 +  X  Then, for any  X  &gt; 0 , with probability at least 1  X   X  , (4  X   X  2 is the second smallest eigenvalue of the Laplacian. Proof. The proof is similar to that of (Belkin et al., 2004a) but uses our general transductive regression bound instead.
 The generalization bound we just presented differs in several respects from that of Belkin et al.(2004a). Our bound explicitly depends on both m and u while theirs shows only a dependency on m . Also, our bound does not depend on the number of times a point is sampled in the training set (parameter t ), thanks to our analysis based on sampling without replacement.
 Contrasting the stability coefficient of Belkin X  X  algo-rithm with the stability coefficient of LTR (Theorem 4), we note that it does not depend on C  X  and  X  loc . This is because unlabeled points do not enter the objec-tive function, and thus C  X  = 0 and e y ( x ) = 0 for all x  X  X . However, the stability does depend on the sec-ond smallest eigenvalue  X  2 and the bound diverges as  X  2 approaches C m . In all our regression experiments, we observed that this algorithm does not perform as well in comparison with LTR . 5.3. Making Seemingly Unstable Algorithms In Sec. 5.2, we saw that imposing additional con-straints on the hypothesis, e.g., h 1 = 0, allowed one to derive non-trivial stability bounds. This idea can be generalized and similar non-trivial stability bounds can be derived for  X  X table X  versions of the algorithms presented in Sec. 5.1 CM , LL  X  Reg , and GMF . Recall that the stability bound in Prop. 1 is inversely propor-tional to the smallest eigenvalue  X  m ( Q ). The main dif-ficulty with using the proposition for these algorithms is that  X  m ( Q ) = 0 in each case. Let v m denote the eigenvector corresponding to  X  m ( Q ) and let  X  2 be the second smallest eigenvalue of Q . One can modify (8) and constrain the solution to be orthogonal to v m by imposing h v m = 0. In the case of (Belkin et al., 2004a), v m = 1 . This modification, motivated by the algorithm of (Belkin et al., 2004a), is equivalent to increasing the smallest eigenvalue to be  X  2 . As an example, by imposing the additional constraint, we can show that the stability coefficient of CM becomes bounded by O ( C/ X  2 ), instead of  X (1). Thus, if C = O (1 /m ) and  X  2 =  X (1), it is bounded by O (1 /m ) and the generalization bound converges as O (1 /m ). 6.1. Model Selection Based on Bound This section reports the results of experiments using our stability-based generalization bound for model se-lection for the LTR algorithm. A crucial parameter of this algorithm is the stability coefficient  X  loc ( r ) of the local algorithm, which computes pseudo-targets e y x based on a ball of radius r around each point. We de-rive an expression for  X  loc ( r ) and show, using extensive experiments with multiple data sets, that the value r  X  minimizing the bound is a remarkably good estimate of the best r for the test error. This demonstrates the benefit of our generalization bound for model selection, avoiding the need for a held-out validation set. The experiments were carried out on several publicly available regression data sets: Boston Housing , Ele-vators and Ailerons 2 . For each of these data sets, we used m = u , inspired by the observation that, all other parameters being fixed, the bound of Theorem 3 is tightest when m = u . The value of the input variables were normalized to have mean zero and variance one. For the Boston Housing data set, the total number of examples was 506. For the Elevators and the Ailerons data set, a random subset of 2000 examples was used. For both of these data sets, other random subsets of 2000 samples led to similar results. The Boston Hous-ing experiments were repeated for 50 random parti-tions, while for the Elevators and the Ailerons data set, the experiments were repeated for 20 random par-titions each. Since the target values for the Elevators and the Ailerons data set were extremely small, they were scaled by a factor 1000 and 100 respectively in a pre-processing step.
 In our experiments, we estimated the pseudo-target of a point x  X   X  T as a weighted average of the la-beled points x  X  N ( x  X  ) in a neighborhood of x  X  . Thus, e y fined in terms of a similarity measure K ( x, x  X  ) cap-tured by a kernel K :  X  x = K ( x, x  X  ). Let m ( r ) be the number of labeled points in N ( x  X  ). Then, it is easy to show that  X  loc  X  4  X  max M / (  X  min m ( r )), where  X  Thus, for a Gaussian kernel with parameter  X  ,  X  loc  X  estimate of m ( r ), the number of samples in a ball of radius r from an unlabeled point x  X  . In our experi-ments, we estimated m ( r ) as the number of samples in a ball of radius r from the origin. Since all fea-tures are normalized to mean zero and variance one, the origin is also the centroid of the set X . We implemented a dual solution of LTR and used Gaus-sian kernels, for which, the parameter  X  was selected using cross-validation on the training set. Experiments were repeated across 36 different pairs of values of ( C, C  X  ). For each pair, we varied the radius r of the neighborhood used to determine estimates from zero to the radius of the ball containing all points. Figure 1(a) shows the mean values of the test MSE of our experiments on the Boston Housing data set for typical values of C and C  X  . Figures 1(b)-(c) show sim-ilar results for the Ailerons and Elevators data sets. For the sake of comparison, we also report results for induction. The relative standard deviations on the MSE are not indicated, but were typically of the order of 10%. LTR generally achieves a significant improve-ment over induction.
 The generalization bound we derived in Eqn. 3 con-sists of the training error and a complexity term that depends on the parameters of the LTR algorithm ( C, C  X  , M, m, u,  X ,  X  loc ,  X  ). Only two terms depend upon the choice of the radius r : b R ( h ) and  X  loc . Thus, keeping all other parameters fixed, the theoretically optimal radius r  X  is the one that minimizes the train-ing error plus the slack term. The figures also include plots of the training error combined with the complex-ity term, appropriately scaled. The empirical mini-mization of the radius r coincides with or is close to r . The optimal r based on test MSE is indicated with error bars. 6.2. Stable Versions of Unstable Algorithms We refer to the stable version of the CM algorithm presented in Sec. 5.1 as CM  X  STABLE . We compared CM and CM  X  STABLE empirically on the same datasets, again using m = u . For the normalized Laplacian we used k -nearest neighbors graphs based on Euclidean distance. The parameters k and C were chosen by five-fold cross-validation over the training set. The experiment was repeated 20 times with random par-titions. The averaged mean-squared errors with stan-dard deviations, are reported in Table 6.2.
 We conclude from this experiment that CM and CM  X  STABLE have the same performance. However, as we showed previously, CM  X  STABLE has a non-trivial risk bound and thus comes with some guarantee. We presented a comprehensive analysis of the stability of transductive regression algorithms with novel gen-eralization bounds for a number of algorithms. Since they are algorithm-dependent, our bounds are often tighter than those based on complexity measures such as the VC-dimension. Our experiments also show the effectiveness of our bounds for model selection and the good performance of LTR algorithms.
 Belkin, M., Matveeva, I., &amp; Niyogi, P. (2004a). Reg-ularization and semi-supervised learning on large graphs. COLT (pp. 624 X 638).
 Belkin, M., Niyogi, P., &amp; Sindhwani, V. (2004b). Man-ifold regularization (Technical Report TR-2004-06). University of Chicago.
 Bousquet, O., &amp; Elisseeff, A. (2002). Stability and generalization. JMLR , 2 , 499 X 526.
 Chapelle, O., Vapnik, V., &amp; Weston, J. (1999). Trans-ductive Inference for Estimating Values of Func-tions. NIPS 12 (pp. 421 X 427).
 Cortes, C., &amp; Mohri, M. (2007). On Transductive Re-gression. NIPS 19 (pp. 305 X 312).
 El-Yaniv, R., &amp; Pechyony, D. (2006). Stable transduc-tive learning. COLT (pp. 35 X 49).
 McDiarmid, C. (1989). On the method of bounded dif-ferences. Surveys in Combinatorics (pp. 148 X 188). Cambridge University Press, Cambridge.
 Schuurmans, D., &amp; Southey, F. (2002). Metric-Based
Methods for Adaptive Model Selection and Regular-ization. Machine Learning , 48 , 51 X 84.
 Vapnik, V. N. (1982). Estimation of dependences based on empirical data . Berlin: Springer.
 Vapnik, V. N. (1998). Statistical learning theory . New York: Wiley-Interscience.
 Wu, M., &amp; Sch  X olkopf, B. (2007). Transductive classi-fication via local learning regularization. AISTATS (pp. 628 X 635).
 Zhou, D., Bousquet, O., Lal, T., Weston, J., &amp;
Sch  X olkopf, B. (2004). Learning with local and global consistency. NIPS 16 (pp. 595 X 602).
 Zhu, X., Ghahramani, Z., &amp; Lafferty, J. (2003). Semi-supervised learning using gaussian fields and har-
