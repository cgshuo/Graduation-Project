 Technion -Israel Institute of Technology , Haifa, Israel. Effective techniques for analyzing streaming data are re-quired in many big data applications and pose new machine learning challenges. One major challenge arises when the underlying source generating the data is not stationary , in which case the concept to be learned changes through time. For example, in prediction tasks, such as fraud detecti on or user preference prediction, the performance of a static pre-dictor that was previously trained, is bound to degrade ov er time, as the nature of fraudulent attacks, or personal prefer -ences is evolving. A reliable detection of such changes can be used to maintain high performance and meaningful anal-yses of data streams. This work is concerned with detection of change in the conte xt of a prediction problem , and pro-poses a detection scheme for online identification of times along the stream in which such changes have occurred. Changes of the prediction task can be caused by changes in the input data, the target concept, or both. One option is to try detecting the change in the data gener ating distrib u-tion, a renowned problem in statistics termed change-point detection ; see Section 1.1 for further discuss ion. However, while a drift in the generating distrib ution may result in a change in the learning problem, this is not a necessity . For example, if a sensor is damaged at some point, yet these changes affect features with a low correlation with the label, or the changes do not affect the decision bound-ary of the predictor , they should be ignored. Detecting these types of irrele vant changes, and consequently initi-ating a new training phase, may degrade the quality of the resulting predictor by unnecessarily shrinking the training set size. Moreo ver, detection of any type of distrib utional change is a challenging task, especially in high dimensional data. Therefore, when high prediction quality is the goal, we adopt the principle of Vapnik ( 1998 ) and propose to solve the problem directly by monitoring the drift in the prediction loss of the underlying predictor rather than the intermediate problem of change-point detection.
 The main idea is to consider concept change only with re-spect to some hypothesis class. This approach enjoys no false detection of changes that are irrele vant to the end task. Using this approach, the sample and computation comple x-ity are conveniently controlled by the choice of the hypoth-esis class. As an example consider the task of predicting the rating of a stream of book reviews of a user, where the genre of the books being reviewed changes with time, and the hypothesis class is restricted to linear predictors with constrained L1 norm. For simplicity of exposition consider using a very small dictionary instead of the L1 norm con-straint. If the dictionary is { bad, good, informati ve } , the change from  X  X antasy X  to  X  X ducational X  books will be easily detected, due to the correlation of the word  X  X nformati ve X  with a good educational book. If the dictionary is { bad, good, kindle } , we won X  X  detect the change of the user to kindle, as kindle is not correlated with the sentiment. How-ever, if we inspect the distri bu tional change in the input we may detect an irrele vant change.
 The idea of focusing on the change in the target concept through the error of the underlying predictor instead of fo-cusing on changes in the stream distrib ution has been pre-viously proposed only in the conte xt of classification; see Section 1.1 for details. Yet, a general-purpose model with theoretical guaranties for any prediction task, be it classifi-cation, regression, clustering etc., has not yet been consid-ered, and is the focus of this work.
 In this paper , we term changes in the prediction loss con-cept drifts and focus on their detection in streaming data. Our definition of a concept drift (see Definition 2 ) slightly deviates from the standard definition, which associates drifts only with changes in the target concept ( Tsymbal , 2004 ), while our terminology links a concept drift also to the learning algorithm and its function class.
 Our main contrib ution is a general approach for detection of change in a prediction problem for different types of concept drifts. Our detection mechanism relies on the idea of random permutations of the examples, which generate multiple train-test splits from the stream. The proposed ap-proach is invariant to the learning problem, specifically to the loss function and to the learning algorithm. We analyze the detection quality of the proposed scheme for different types of changes in the prediction problem, from the sim-plest scenario of an abrupt change to that of a slow noisy gradual change. We also show empirically the success of the permutation-based detection. 1.1. Related Work A closel y related problem to concept drift detection , pur-sued in this paper , is that of change-point detection ; the goal of the first is to detect changes that affect the mapping from the input space to the target concept, while the goal of the latter is to detect changes in the generating distri-butions of the time-series. A great deal of work has been invested in methods for change-point detection; some ref-erence books include ( Basse ville &amp; Nikiforo v , 1993 ; Chen &amp; Gupta , 2012 ), for parametric methods, and ( Brodsk y &amp; Darkho vsky , 1993 ), for non-parametric methods. Change-point detection is associated with homogeneity testing, in which, given two samples, one has to deter-mine whether they were generated by the same distrib u-tion. Many attempts have been made to extend classical statistical tests for homogeneity for detection of change in time-series ( Kifer et al. , 2004 ; Lung-Y ut-Fong et al. , 2011 ). Other methods are based on a predefined parametric model, such as the generating distrib ution ( Basse ville &amp; Nikiforo v , 1993 ; Gustafsson , 1996 ; Lavielle &amp; Teyssiere , 2006 ), au-toregressi ve models ( Takeuchi &amp; Yamanishi , 2006 ), and state-space models ( Moskvina &amp; Zhiglja vsky , 2003 ; Kawa-hara et al. , 2007 ). Their success depends on the compat-ibility of the preassigned model. Nonparametric alterna-tives often rely on the estimation of density functions ( Dasu et al. , 2006 ; Sebasti  X  ao &amp; Gama , 2007 ), which tends to be problematic in high dimensional probl ems. A different di-rection is to directly estimate the density ratio ( Kawahara &amp; Sugiyama , 2012 ; Liu et al. , 2013 ), while Desobry et al. ( 2005 ) propose to segment the series using one-class sup-port vector machine. Vovk et al. ( 2003 ) pursue a related problem: exchangeability of the samples in the stream 1 . The above list is merely a small sample of the numerous attempts at the challenging change-point detection prob-lem. We suggest to evade its comple xity when the goal is to detect concept drift. Existing approaches for detec-tion of a concept-drift are commonly based on some heuris-tic that utilizes the error rate, and draw upon intuition de-rived from learning theory . For example, in Gama et al. ( 2004 ), a change is detected when the error trend increases as the size of the stream grows. Another detection method ( Baena-Garc  X   X a et al. , 2006 ), detects a concept drift once the distance between the classification errors decreases. A third error-based method, compares the accurac y on a re-cent windo w with the ov erall accurac y excluding the recent windo w by applying a test of equal proportion ( Nishida &amp; Yamauchi , 2007 ). Other methods search directly for the  X  X ptimal X  windo w ( Klink enber g &amp; Joachims , 2000 ; Bifet &amp; Gavalda , 2007 ). For example, Klink enber g &amp; Joachims search for a windo w that minimizes the approximate error of an SVM classifier . The advantage of most error-based methods is their simple employment as wrappers to any classification algorithm. A limitation of known detection schemes is that they only treat classification settings un-der the zero-one loss. Theoretical guaranties for existing schemes are also scarce.
 Other approaches for learning in the presence of concept drift don X  X  apply detection but adapt to the change or em-ploy an ensemble of learners. Adaptation methods retrain the learner after a fixed windo w size, or re-weigh instances by appearance recenc y ( Klink enber g , 2003 ; 2004 ). The choice of a proper windo w size balances a tradeof f be-tween adaptation speed and generalization. Some adapta-tion methods are tailored to a specific learning algorithm, such as decision trees, and modify elements of the model when drift is suspected by some heuristic strate gy ( Black &amp; Hickey , 1999 ; Hulten et al. , 2001 ). In ensemble methods, a weighted voting scheme of multiple learners, trained on different windo ws ov er the stream is applied ( Street &amp; Kim , 2001 ; Stanle y , 2003 ; Wang et al. , 2003 ; Kolter &amp; Maloof , 2007 ; Masud et al. , 2009 ). There is no explicit detection of the drift, but initiation of new classifiers. A prediction problem is defined on an input space X , an output space Y , and consists of finding a predictor h : X  X  Y , from some fixed function class H . During the detection process we observ e a sub-sequence Z n { z 1 , z 2 , ..., z n } of independent observ ations emitted from a stochastic process called a stream, where each observ a-tion, z t  X  Z = X  X  Y , is generated by some distri-bution D t ov er Z . Under this definition, even within a single concept, the distrib ution generating different exam-ples may vary. The risk of h  X  H with respect to D t is R
D t ( h ) = E z  X  X  t [  X  ( h, z )] , where  X  ( h, z ) : Y X Y  X  [0 , 1] is a given bounded loss function. We denote the average risk ov er an index set I , not necessarily an ordinal one, by R
I ( h ) = 1 | I | P t  X  I R D t ( h ) , and its empirical estimate by  X  R We would like to detect different types of concept changes. In the following, we formulate different kinds of concept changes, from a sharp abrupt change, to a more realistic noisy change, and finally , a slowly evolving noisy gradual change. For each type of change, we provide a suitable de-tection algorithm and a corresponding statistical guaranty . The presentation begins with the simplest and progresses to the most difficult one. Note that the algorithm for noisy gradual change also detects simpler drift types, and there-fore may be applied as an all-purpose detection scheme. We follow a hypothesis testing paradigm. Our null hypoth-esis H 0 is of equality or proximity of the average true risk on sequential training and test segments. The alternati ve H 1 asserts that there is a substantial difference between the two. Variations of this hypothesis, which are suited to dif-ferent types of concept changes, are presented below. 2.1. Abrupt (noisy) change The first, and most simplistic concept change is an abrupt change, where we assume that within each concept the risk is constant, and between the concepts, due to the concept switch, there is a change in the risk X  X  value. The model includes a parameter  X   X  0 that defines the rate of change to be tested. The threshold  X  serves as a sensiti vity valve, which provides the means to tradeof f small changes in the concept with a growing training size. The top image in Figure 1a shows an abrupt change, while the bottom image presents a deviation that is under the threshold. In the first step of our basic detection scheme the ob-served sub-sequence Z n is divided into a training windo w S ord = Z k 1 , 1 &lt; k &lt; n, and a test windo w S  X  ord If a change is not detected, the test windo w is added to the training windo w and a new test windo w is introduced. De-tection is done by comparing the loss on the test windo w with the loss of multiple test sets of the same size obtained by random shuffling of the examples. This idea is formu-lated in Algorithm 1 . The shuffled train-test partitions of the data are denot ed by ( S, S  X  ) , such that S consists of k elements of Z n , and S  X  is Z n \ S . The predictor A S  X  H is obtained by training algorithm A on a set S . We denote by f the ordered training set.
 In each iteration of Algorithm 1 we compare the risk on the ordered train-test split,  X  R ord =  X  R S  X  U n denotes the uniform distrib ution ov er all possible n k training sets of size k from the sample Z n . The permuta-tion loss may be estimated ov er P  X  n k random parti-tions. The comparison between the losses obtained on the ordered split and the shuffled splits is done by an hypoth-esis test, denoted by  X  X EST X  in Algorithm 1 . The TEST may be done by thresholding the difference between the losses by applying the bound provided next in Theorem 3 , or by applying a permutation test detailed in Section 3 . The intuition behind this scheme is that if no concept change has occurred, the prediction on the ordered split should not deviate too much from that of the shuffled splits, especially if the learning algorithm has algorithmic stabil-ity. An advantage of using shuffled train-test splits ov er other error based schemes, as in ( Gama et al. , 2004 ), is that the training and test sets are disjoint. Therefore, the test error is a valid estimation of the risk. 2 In addition, by using multiple train-test splits we gain a good estimation of the error under the null hypothesis, as well as valuable infor-mation regarding its variation.
 Note that the model presented in this paper assumes tempo-ral independence of the samples. In cases of dependenc y, means to maintain exchangeability of the samples, such as block-wise permutations along with remo ving the initial part of each block, may be applied.
 A generalization of abrupt change is noisy abrupt change , where within each concept the risk may vary up to some rate. These variations are common in most real-life sce-narios, where the process generating the stream has small changes, which affect the risk but should be disregarded. We define these permitted variations as follows.
 Definition 1 (  X  -permitted variations) . A stream seg-ment [ t 1 , t 2 ] is said to have  X  -permitted variations, for some  X   X  0 , with respect to h  X  H , if Figure 1b illustrates an  X  -permitted variation and a noisy abrupt change. A concept change is defined by: Definition 2 (Concept change w.r.t. h  X  H ) . Let I, J be two sequential stream segments with  X  -permitted variati ons w.r.t. h . There is a concept change of size  X  &gt;  X  between I and J if | R J ( h )  X  R I ( h ) | X   X  .
 The null and alternati ve hypotheses for a (noisy) abrupt change are defined as follows. Let I = [1 , k ] and J = [ k + 1 , n ] define the ranges of two consecuti ve stream seg-ments with  X  -permitted variations, corresponding to the training and test set windo ws. Then, The function  X  (  X  )  X  0 depends on the permitted variation and other elements of the algorithm (see Theorem 3 below for further details). Notice that the hypotheses are parame-terized by the prediction function f , which is trained on the training windo w I.
 Our analysis relies on algorithmi c stability ( Bousquet &amp; Elisseef f , 2002 ), which is reviewed in the supplementary material. The following theorem bounds the difference be-tween the risks under the null and alternati ve hypotheses. The proof is provided in the supplementary material. The slack  X  quantifies an area where a change cannot be de-tected, as defined in ( 1 ); it shrinks as the algorithm is more stable and the training and test sets are larger. Theor em 3 (Detection of (noisy) abrupt change) . Define H 0 and H 1 as in ( 1 ). For an algorithm with  X  n = O ( 1 n Algorithm 1: Concept Drift Detection Scheme and any  X   X  (0 , 1) , we have that under H 0 , with probability of at least 1  X   X , Under H 1 , the inverse inequality holds with probability of at least 1  X   X .
 Theorem 3 states a threshold which differentiates between the two h ypotheses with high probabi lity, and may be used for the TEST routine in Algorithm 1 . The role of each ele-ment in the bound is as follows: 1. Test windo w size p = | J | n : the larger the windo w is the better concentration of the empirical risk around the risk and consequently , a tighter bound is obtained. In practice, the windo w size corresponds to the maximum detection de-lay and therefore one should choose it as large as possible while considering the tolerance to detection delay . 2. The significance rate  X  bounds the miss detection and false detection rates, usually set in the range 0 . 01  X  0 . 05 . 3. The hyperparameter  X  denotes the rate of change one wishes to ignore. The output of the test for different values of  X  may be computed after training the predictors once, therefore, detection as a function of  X  can be given instead of a single binary value with no further computational cost. 4. The stability rate  X  n = O ( 1 n ) of the algorithm con-trols the variability of the loss. For a stable algorithm 5. The rate  X  bounds the permitted variations of the risk within an interv al, and can be empirically estimated in ad-vance. As can be expected, in the simplified scenario of an abrupt change (  X  = 0 ), the bound is tighter . 2.2. Gradual drift Another concept drift type is a gradual drift . In many real life problems, the change between two concepts happens gradually . For example, in fraud detection, the characteris-tics of fraudulent actions may have a slow transition phase. Gradual drifts may be modeled by a mixing stage, in which an increasing weight is given to the next concept and a de-creasing one to the prior concept.
 We treat two cases of gradual drift: one which is faster, where the change length is within the test windo w, and another , corresponding to a gradual drift evolving very slowly; see Figure 1c for an illustration. In the first case, there is sufficient difference between the average risk in the test windo w and the previous concept, thus, the abrupt change algorithm may be used. In the second case, the drift is slower, and therefore, the difference between the risks may be insufficient to cross the threshold. When the drift is slow, it is most challenging to detect, however, when it is not detected, it can slowly degrade the quality of the pre-dictor . To treat this drift type we provide a lookahead pro-cedure presented in Algorithm 2 . In this procedure, if the hypothesis test determines that there may be a change, we retain the same training windo w and move to test the next test windo w. This process is continued until a drift is de-tected, the test determines a false-alarm, or the maximum number of lookahead iterations have been reached. We define the null and alternati ve hypotheses for detect-ing slow gradual change as follows. The hypotheses are directly defined for the noisy setting, so all stream seg-ments have  X  -permitted variations w.r.t. f (Definition 1 ). Let m be the size of the test windo w, let I = [1 , k ] be the training windo w and let J q = [ k +( q  X  1) m +1 , k + qm ] , for q = 1 , . . . , M, be the ranges of M test stream segments. The hypotheses at the M  X   X  M lookahead iteration are:
H 0 :  X  q =1 . . . M  X  R I ( f )  X  R J
H 1 :  X  q =1 . . . M  X   X  1 R I ( f )  X  R J Recall that S ord denotes the training set. Denote the q th set by S  X  ord,q = { z t : t  X  J q } . Let  X  R per m,q be the average empirical risk obtained on permutations of [ S ord , S  X  ord,q The following theorem bounds the miss detection and false alarm rates of a gradual drift at iteration M  X   X  M . Theor em 4 (Detection of slow gradual change) . Define H 0 and H 1 as in ( 2 ). For an algorithm with  X  n = O ( 1 n ) , a we have that for any  X   X  (0 , 1) and under H 0 , with probability of at least 1  X   X , Algorithm 2: Slow Gradual Drift Detection Scheme. See Algorithm 1 for detect procedure.
 Under H 1 , with probability of at least 1  X   X , and The proof of the theorem relies on the bounds in Theorem 3 and the union bound. Using Theorems 3 and 4 themselv es as testing procedures, with type-1 and type-2 error guarantees provided by the bounds, may result in conserv ative tests, as the bounds are based on large de viations results. In this section we pro-pose another hypothesis testing procedure for the  X  X EST X  module in Algorithms 1 and 2 . The theorems imply that variability of the loss, encapsulated in the error stability of the algorithm, should be taken into account in the test pro-cedure. In this section, we present a different perspecti ve on these variations using permutation tests ( Good , 2005 ). Permutation tests are a well known methodology in statis-tics to obtain most powerful statistical procedures , and will provide tighter thresholds for the testing procedure. Our test statistic is  X  R ord , the loss ov er the ordered train-test split. To test if a change has taken place, we use a permutation test. The heart of the method is that under the null hypothesis the samples are exchangeable and therefore may be randomly shuffled. According to the null hypothe-sis, the average risk before and after the tested change in-dex k are  X  -close. Under this hypothesis, the samples are
Algorithm 3: TEST(  X  R ord , n  X  R S  X  Procedure for detection scheme approximately exchangeable. Specifically , the more stable the algorithm is and the smaller  X  is, the more the exam-ples are exchangeable. As the size of the training set grows, which emanates when a change is not detected, stability of the learner strengthens and ensures exchangeability . By shuffling the data multiple times we can obtain an esti-mate of the non-parametric distrib ution of the test statistic  X  R ord under the null hypothesis. Recall that the empirical error obtained for the i th shuffled split. If there was a concept drift at time index k , we expect  X  R to be larger than if H 0 was true. The larger value we observ e, the stronger is the evidence against H 0 . There-fore, the achie ved significance level of the procedure is P this testing procedure. Optimally , to get the exact distrib u-tion of the statistic, we would need to examine all possible train-test shuffles, but in practice much less are sufficient. Also note that the train-test procedure of the multiple splits can be straightforw ardly parallelized.
 In the gradual drift detection scheme, at iteration M  X  , M base hypotheses are combined, and therefore, there is a need to correct for multiple comparisons. In Theorem 4 , this is done by the union bound, which is equivalent to the Bonferroni correction in the statistical literature. In the per-mutation test, we use the Benjamini-Hochber g correction ( Benjamini &amp; Hochber g , 1995 ), which is less conserv ative. We compare the performance of our detection algorithm in classification and regression settings with other concept-drift detection methods, and baseline methods. We use syn-thetic data and drifts synthesized in real data, thus control-ling drift points and allowing precis e performance analysis. Detection Algorithms: We denote by PERM and grad-PERM the application of Algorithm 1 and 2 , respecti vely, applied with the testing procedure in Algorithm 3 . In clas-sification problems, we compare PERM X  s detection to three known methods for concept drift detection: DDM ( Gama et al. , 2004 ), early drift detection ( EDDM ) ( Baena-Garc  X   X a et al. , 2006 ), and STEPD ( Nishida &amp; Yamauchi , 2007 ); see Section 1.1 . We also compare the performance with learners with a fixed memory windo w ( Window # , where # is the windo w size), a full memory that trains on all prior examples ( No detection ), and an  X  X ptimal X  detector in hindsight that detects a drift at its onset ( Exact detection ). We set the sensiti vity level of PERM and grad-PERM to  X  = 0 . 01 ,  X  = 0 , the warning and detection thresholds of STEPD to w = 0 . 05 , d = 0 . 01 , and the parameters of EDDM to  X  = 0 . 95 and  X  = 0 . 90 . 4 Performance Measur es: Performance comparisons are done by evaluating detection quality and error rate. A True Positi ve (TP) detection is defined as a detection within a fixed delay range after the precise concept change time. This range is taken to be the size of the windo w in PERM and STEPD. A False Negative (FN) is defined as missing a detection within the delay range, and a False Positi ve (FP), as a detection outside this range or an extra detection in the range. The detection quality is measured both by the Recall = T P/ ( T P + F N ) and Precision = T P/ ( T P + F P ) of the detector . The prediction on a test example is done by a predictor trained on the previous examples. 4.1. Synthetic Data In the following synthetic classification tasks the base al-gorithm was K-Nearest Neighbors ( k = 3) , each stream was randomly repeated 100 times, and P = 100 reshuf-fling splits were used in PERM. The first stream, denoted  X  X ix ed X , represents abrupt drift with label noise. The fea-tures are two boolean ( v, w ) and two numeric ( x, y ) at-tributes; the examples are labeled as positi ve if at least two conditions are met: v, w = 0 , y &lt; 0 . 5 + 0 . 3 sin(3  X x ) . The classification is reversed at each concept change. The second dataset, denoted  X  X ircles X , presents a more chal-lenging concept drift with label noise. We sample data uniformly from the unit square, and label an example as positi ve/negative if it resides inside/outside a moving and dynamically changing circle. We set the initial center and direction of movement at random, and at each concept drift gradually move the center and change the radius. 5 The third, most challenging synthetic dataset, is the rotating  X  X heck erboard X ( Elwell &amp; Polikar , 2011 ), where the exam-ples are sampled uniformly from the unit square and the labels are set by a check erboard with 0.2 tile width. At each concept drift, the check erboard is rotated in an angle of  X / 20 radians. The results on the different streams, each consisting of 10 drifts and concept lengths of 1000 samples, are presented in Figure 2 : rows correspond to datasets and colum ns to performance measures. Both recall and precision of the PERM algorithm are higher than the other methods. The performance difference of the error-noise curves is smaller on the Mixed and Circle datasets. These two problems are not hard, and therefore, while DDM and EDDM encounter many miss detections, their error rate remains low. In the check erboard dataset, the performance of PERM impro ves as the windo w range grows. This can be anticipated be-cause as the test size grows the variations of the error de-creases, which reduces the false detection rate.
 Our last synthetic drift was generated using the Check er-board dataset. In this experiment, a single gradual drift is initiated by increasing the label noise at time-indices [1400 , 1600 , 1800 , 2000] with corresponding noise-rates [0 . 05 , 0 . 1 , 0 . 2 , 0 . 3] . The growing label noise serves as a gradual drift which slowly evolves. The windo w size in PERM, grad-PERM and STEPD was 100 samples. Table 1 shows that grad-PERM obtained the best detection rate. 4.2. User Preference Prediction We compare detection performance on a user preference prediction task defined using the 20-ne ws groups text dataset 6 , consisting of 18 , 846 documents and ov er 75 , 000 features. We apply the TF-IDF weighting scheme on the documents and partition the 20 groups to six subgroups ac-cording to subject as presented in the repository . We define two prediction problems: a binary classification problem of identifying whether a user likes/dislik es the subject, and a regression problem of rating user preference. In all our experiments the time-series is generated by randomly re-ordering all the documents. We use P = 500 , and SVM and SVR with linear kernel as the learning algorithms. 7 We ran two experiments on the classification problem. In the first, after 1000 documents (  X  50 documents from each newsgroup) a concept drift is activated, in which a random third of the binary ratings are switched and the rest remain as in the previous concept. 8 In the second, we use the same concepts but with a gradual drift: after 500 documents from the first concept, sets of 100 documents are added with the first and second concepts respecti vely. Another 500 documents from the second concept follow.
 In the regression problem, the label is initiated randomly to 1  X  10 and a concept drift is activated after 2000 doc-uments. Two types of drifts are considered: (I) the label of all six groups under go a random walk step  X  3 , (II) four groups randomly selected change rating of  X  3 . Scenario (II) is more challenging as the drift is smaller . Performance of PERM is compared only to that of  X  X indow X ,  X  X o de-tection X , and  X  X xact detection X , since DDM, EDDM and STEPD are limited to zero-one classification problems. The results are presented in Tables 2 to 4 . The performance of PERM for regular drift and grad-PERM for gradual drift, are the highest in both classification and regression. We presented a resampling scheme for concept-drift detec-tion with respect to the risk of a learning algorithm. One of the advantages of the method is its applicability to any sta-ble learning algorithm and any bounded loss function cho-sen as the most suitable for the task at hand. For example, weighted loss may be used in a data imbalance scenario. Our detection algorithm outputs time indices of concept changes that form windo ws of adapti ve size, each compris-ing of examples from a single concept. The detection times may be used for initiating a new training phase, as done in our experimental evaluation, but can also be used as a basis for ensemble learners, by providing an informed choice of the training windo ws for the ensemble X  s members. Our experiments show that the proposed scheme is more robust to noise and has better precision and recall rates than existing schemes. There is a bias-v ariance tradeof f in the choice of windo w size in PERM. A larger windo w reduces the variability which increases the accurac y of the test, but causes a detection delay which may increase the error. In future work we plan to implement an online setting for the scheme, in which the learners of the reshuffled samples are preserv ed and updated. While the current algorithm is readily parallelized, this regime should enjoy a favorable computation time.
 This research was partially supported by the ISF under con-tract 890015 and by the Intel Collaborati ve Research Insti-tute for Computational Intelligence (ICRI-CI).
 Baena-Garc  X   X a, M., Campo- X  Avila, J., Fidalgo, R., Bifet, A.,
Gavald  X  a, R., and Morales-Bueno, R. Early drift detec-tion method. In StreamKDD , pp. 77 X 86, 2006.
 Basse ville, M. and Nikiforo v, I. V. Detection of Abrupt Chang es: Theory and Application . Prentice-Hall, 1993. Benjamini, Y. and Hochber g, Y. Controlling the false dis-covery rate: a practical and powerful approach to multi-ple testing. JRSS , pp. 289 X 300, 1995.
 Bifet, A. and Gavalda, R. Learning from time-changing data with adapti ve windo wing. In ICDM , 2007.
 Black, M. and Hickey, R.J. Maintaining the performance of a learned classifier under concept drift. IDA , 1999. Bousquet, O. and Elisseef f, A. Stability and generalization. JMLR , 2:499 X 526, 2002.
 Brodsk y, B.E. and Darkho vsky, B.S. Nonpar ametric meth-ods in change-point problems . Springer , 1993.
 Chen, Jie and Gupta, A Arjun K. Parametric Statistical Chang e Point Analysis: With Applications to Genetics, Medicine , and Finance . Springer , 2012.
 Dasu, T., Krishnan, S., Venkatasubramanian, S., and Yi, K.
An information-theoretic approach to detecting changes in multi-dimensional data streams. In ISCSA , 2006. Desobry , F., Davy, M., and Doncarli, C. An online kernel change detection algorithm. IEEE Trans. Signal Process , 53(8):2961 X 2974, 2005.
 Elwell, R. and Polikar , R. Incremental learning of concept drift in nonstationary environments. IEEE Trans. Neural Netw. , 22(10):1517 X 1531, 2011.
 Gama, J., Medas, P., Castillo, G., and Rodrigues, P. Learning with drift detection. In Advances in Artificial Intellig ence X  X BIA 2004 , pp. 286 X 295. 2004.
 Good, P.I. Permutation, parametric and bootstr ap tests of hypotheses . Springer , 2005.
 Gustafsson, F. The marginalized likelihood ratio test for detecting abrupt changes. IEEE Trans. Autom. Contr ol , 41(1):66 X 78, 1996.
 Hulten, G., Spencer , L., and Domingos, P. Mining time-changing data streams. In KDD , 2001.
 Kawahara, Y. and Sugiyama, M. Sequential change-point detection based on direct density-ratio estimation. Sta-tistical Analysis and Data Mining , 5(2):114 X 127, 2012. Kawahara, Y., Yairi, T., and Machida, K. Change-point detection in time-series data based on subspace identifi-cation. In ICDM , pp. 559 X 564, 2007.
 Kearns, M. and Ron, D. Algorithmic stability and sanity-check bounds for lea ve-one-out cross-v alidation. Neural Computation , 11(6):1427 X 1453, 1999.
 Kifer , D., Ben-Da vid, S., and Gehrk e, J. Detecting change in data streams. In VLDB , pp. 180 X 191, 2004.
 Klink enber g, R. Concept drift and the importance of exam-ples. In Text Mining TAA , pp. 55 X 77, 2003.
 Klink enber g, R. Learning drifting concepts: Example se-lection vs. example weighting. IDA , 8:281 X 300, 2004. Klink enber g, R. and Joachims, T. Detecting concept drift with support vector machines. In ICML , 2000.
 Kolter, J.Z. and Maloof, M.A. Dynamic weighted majority:
An ensemble method for drifting concepts. JMLR , 8: 2755 X 2790, 2007.
 Lavielle, M. and Teyssiere, G. Detection of multiple change-points in multivariate time series. Lithuanian Mathematical Journal , 46(3):287 X 306, 2006.
 Liu, S., Yamada, M., Collier , N., and Sugiyama, M.
Change-point detection in time-series data by relati ve density-ratio estimation. Neural Networks , 2013. Lung-Y ut-Fong, A., L  X  evy-Leduc, C., and Capp  X  e, O. Homo-geneity and change-point detection tests for multi variate data using rank statistics. arXiv:1107.1971 , 2011. Masud, M., Gao, J., Khan, L., Han, J., and Thuraisingham,
B. A multi-partition multi-chunk ensemble technique to classify concept-drifting data streams. In KDD . 2009. Moskvina, V. and Zhiglja vsky, A. An algorithm based on singular spectrum analysis for change-point detection. COMMUN STAT SIMULA T , 32(2):319 X 352, 2003.
 Nishida, K. and Yamauchi, K. Detecting concept drift using statistical testing. In DS , pp. 264 X 269, 2007.
 Sebasti  X  ao, R. and Gama, J. Change detection in learning histograms from data streams. In PAI . Springer , 2007. Stanle y, K.O. Learning concept drift with a committee of decision trees. Informe t  X  ecnico , 2003.
 Street, W. and Kim, Y. A streaming ensemble algorithm (sea) for large-scale classification. In KDD , 2001. Takeuchi, J. and Yamanishi, K. A unifying frame work for detecting outliers and change points from time series. IEEE Trans. Knowl. Data Eng , 18(4):482 X 492, 2006. Tsymbal, A. The problem of concept drift: definitions and related work. Technical report, 2004.
 Vapnik, V.N. Statistical learning theory . Wiley, 1998. Vovk, V., Nouretdino v, I., and Gammerman, A. Testing exchangeability on-line. In ICML , pp. 768 X 775, 2003. Wang, H., Fan, W. Yu, P., and Han, J. Mining concept drift-
