 DONG ZHOU University of Nottingham MARK TRURAN University of Teesside TIM BRAILSFORD University of Nottingham and HELEN ASHMAN University of South Australia 1. INTRODUCTION The distinguishing hallmark of a cross language informatio n retrieval (CLIR) engine is the linguistic disparity between the queries whic h are submitted and the documents which are retrieved. To resolve this disparit y, all CLIR engines are required to incorporate some facility for language tran slation, an obvious requirement if query representations and document represe ntations are to be meaningfully compared. In the past, this translation has of ten been effected using a machine readable bilingual dictionary [Adriani 200 0; Ballesteros and Croft 1998; Jang et al. 1999; Maeda et al. 2000; Liu et al. 2005 ; Gao and Nie 2006].
 is an inherent tendency towards ambiguity . This problem stems from the choice of possible translations. A typical bilingual dicti onary will provide a set of alternative translations for each term within any giv en query. Choos-ing the correct translation of each term is a difficult task, a nd one that can seriously impact the efficiency of any related retrieval fun ctions. The use of co-occurrence information extracted from a representative do cument collection has gone some way to address this shortcoming [Adriani 2000; Ballesteros and Croft 1998; Jang et al. 1999; Maeda et al. 2000; Liu et al. 2005 ; Gao and Nie 2006], but the results published to date are still some dista nce from optimal. the coverage problem. This refers to the limited linguistic scope of bili ngual dictionaries. Certain types of words are not commonly found in this type of resource, and it is these out-of-vocabulary (OOV) terms tha t will cause difficul-ties during automatic translation. A nonexhaustive list of word types that fall into this problem category is as follows:  X  X ompound words  X  X roper names, such as the identifiers attached to persons or organizations  X  X echnical terms, including newly invented words and phras es from specialist disciplines concentrate on complex statistical solutions, but so far pr ogress has been ham-pered by the difficulties inherent in separating genuine OOV translations from noisy terms [Cheng et al. 2004; Zhang and Vines 2004; Zhang et al. 2005; Lu et al. 2007]. 1.1 The Contributions of This Article In this article we present a practical solution for each of pr oblems described above. First, we describe a novel technique for the resoluti on of ambiguity in dictionary-based query translation which considers co-oc currence information as a network susceptible to graph-based analysis. 1 Second, we introduce a new approach to the translation of OOV terms which utilizes a com putationally in-expensive pattern-based processing of mixed language text to generate candi-date translations. Finally, we present an extensive evalua tion of a hybrid cross language retrieval system which incorporates these two tec hniques. 1.2 The Structure of the Article The remainder of the article is organized as follows: Sectio n 2 examines previ-ous work related to query term disambiguation and unknown te rm translation, Section 3 describes a graph-based disambiguation algorith m, Section 4 exam-ines a pattern-based approach to OOV term translation, Sect ion 5 describes the hybridization of these complimentary techniques within a s ingle CLIR system, Sections 6 and 7 document the process we used to evaluate this system, and Section 8 concludes and speculates on work outstanding. 2. RELATED WORK 2.1 Candidate Term Ambiguity Techniques addressing the problem of ambiguity in the conte xt of CLIR have steadily increased in sophistication over time. In the earl y stages of CLIR de-velopment, researchers often used fairly arbitrary rules f or the disambiguation of candidate translations (e.g., selecting the first matchi ng entry in a bilingual dictionary as the final translation). More recently, highly developed techniques exploiting term co-occurrence statistics have been brough t to bear on the prob-lem [Adriani 2000; Ballesteros and Croft 1998; Jang et al. 19 99; Maeda et al. 2000; Liu et al. 2005; Gao and Nie 2006].
 text states that the correct translations of individual que ry terms will tend to co-occur as part of a sublanguage while incorrect translati ons will not. In other words, this approach should be able to determine the most lik ely translation for a given query by examining the pattern of term co-occurre nce within some representative text collection (e.g., the World Wide Web [M aeda et al. 2000] or a monolingual/unlinked corpora [Ballesteros and Croft 1 998; Gao and Nie 2006]). However, there is a problem with this general approa ch. This prob-lem relates to the mutually dependent relationship between each term within a multiple term query. Ideally, for each query term under con sideration, we would like to choose the best translation that is consistent with the transla-tions selected for all remaining query terms. However, this process of inter-term optimization has proved computationally complex for e ven the shortest of queries [Gao and Nie 2006]. A common workaround used by sev eral re-searchers working on this particular problem [Adriani 2000 ; Ballesteros and Croft 1998; Liu et al. 2005; Gao and Nie 2006] involves use of t he following greedy algorithm: 1. Given a source query q  X  Q , for each word in q , acquire the set of all trans-2. For each set T i : For various reasons relating to term independence, the gree dy algorithm de-scribed above is not ideal, and several attempts have been ma de to improve on it. For example, Sperer and Oard [2000] presented a modified P irkola method [Pirkola 1998] called structured translation which used the co-occurrence measurements to assign term weights. In the same vein, Feder ico and Bertoldi [2002] demonstrated a technique which incorporat ed the generated co-occurrence information into a query translation Hidden Markov Model (HMM). Work described by [Gao et al. 2002] refined the greedy a lgorithm by modifying the term similarity measurement applied in step 2 (b). In this step, the similarity between two terms is usually calculated usin g the mutual infor-mation (MI) between two terms x and y as shown below: ity of word x and y co-occurring in a predefined text window. Gao et al. [2002] updated this measure by incorporating the distance factor D ( x , y ), defined as: where  X  is the decay rate and the Dis ( x , y ) is the average distance between x and y in the corpus. The resulting decaying co-occurrence model was evaluated using the TREC-9 test collection [Voorhees an d Harman 2000] and comfortably outperformed the basic MI model (with  X  = 0 . 8 yielding the best results). Three years later, Liu et al. [2005] revisite d the use of mutual information and introduced a maximum coherence model which estimated the translation probabilities of query words from term co-occu rrence statistics by maximizing the overall coherence of the corresponding quer y. Simultaneously, Monz and Dorr [2005] published an algorithm which estimated the translation probabilities using an iterative expectation-maximizati on algorithm based on the co-occurrence statistics between all translation cand idates.
 of research into the usefulness of mutual information by con sidering term co-occurrence as a graph susceptible to recursive analysis. Th is approach was inspired by the current popularity of techniques based on gr aphs induced by implicit relationships between documents or other linguis tic items [Erkan and Radev 2004; Kurland and Lee 2005; Mihalcea and Tarau 2004; Zh ou et al. 2007]. guity shares strong commonalities with research investiga ting the utility of graph-based algorithms for large-scale word sense disambi guation (WSD) [Mi-halcea 2005]. In this particular field, each node within a gra ph structure repre-sents one possible sense of a given word sequence, while the e dges connecting the nodes correspond to semantic dependencies between thos e interpretations (e.g., antonymy, synomy). The process of determining the co rrect sense for a given word sequence exploits these semantic dependencies to calculate the most  X  X mportant X  node, thereby resolving the ambiguous seq uence. 2 most appropriate translation for a given term using recursi ve graph-based analysis based on co-occurrence measures, could be viewed a s a logical ex-tension to this technique, but is actually quite distinct in practical terms. Our technique employs a number of graph centrality measurem ents which are driven by term co-occurrence measurements rather than s emantic depen-dencies. Furthermore, unlike the majority of WSD systems, o ur algorithm is specifically designed for a bilingual text environment. 2.2 Out-of-Vocabulary Terms The problem of unknown terms is fairly widespread in CLIR res earch and has attracted a considerable amount of time and study. Early sol utions advocated the use of domain-specific bilingual dictionaries, which di d deliver greater ac-cess to troublesome technical terms and specialized vocabu laries, but were of-ten fairly narrow in terms of scope [Pirkola 1998]. Later app roaches to the problem adopted the technique of transliteration , which involves identifying similarities in the orthographic structures of two languag es in an attempt to generate rules specifying how certain substrings written i n one language are spelled in another. [AbdulJaleel and Larkey 2003; Buckley e t al. 2000; Kang and Kim 2000; Fujii and Ishikawa 2001; Qu et al. 2003; Virga an d Khudan-pur 2003]. Transliteration is essentially a string matchin g exercise [Pirkola et al. 2002, 2003], which obviously works best when the langu ages involved shared a common alphabet. Transliteration between languag es with dissim-ilar alphabets requires a process known as phonetic mapping . This involves generating rules (using linguistic analysis or statistica l methods) represent-ing the phonetic presentation of the languages involved, th en manipulating these rules to resolve the OOV term. Using this technique, Qu et al. [2003] de-veloped a translation system for Japanese names and words us ing a phonetic English dictionary, and AbdulJaleel and Larkey [2003] deve loped a generative statistical model for the translation of Arabic into Englis h.
 itself with the World Wide Web as a potential repository of tr anslation patterns [Cheng et al. 2004; Lu et al. 2002; Zhang and Vines 2004; Zhang et al. 2005; Cao et al. 2007]. Most of the work in this area is dependent upo n a certain quirk of authorship. When new terms, foreign terms, or prope r nouns are used in multilingual Web text, they are frequently accompanied b y a courtesy trans-lation in the vicinity of the original text. By specifically t argeting these multi-lingual Web pages, then subjecting the text they contain to s tatistical analysis, it is often possible to extract these complementary transla tions [Cheng et al. 2004; Zhang and Vines 2004; Zhang et al. 2005; Cao et al. 2007] . However, there is a drawback. Techniques which address the coverage p roblem using a statistical analysis of mixed-language Web pages have pro ved to be fairly error prone. Studying this problem, Chen and Ma commented th at the use of exclusively statistical methods in this particular cont ext would inevitably result in low precision and low recall, with poor performanc e often related to the misidentification of low-frequency terms [Chen and Ma 20 02]. Proposing a solution, the authors suggested a consideration of linguistic patterns alongside concurrence measures as the possible antidote.
 processing is well established. Researchers working on the problems of nat-ural language processing have frequently used linguistic p atterns to improve ontology generation and knowledge discovery [Iwanska et al . 1999]. Previous experience has demonstrated that even a simple understandi ng of language can often yield useful information. A good example of this st atement in action can be found in Hearst [1992], where the author used just two l exico-syntactic patterns to successfully acquire publication-related hyp onyms from text cor-pora. Hearst used the pattern  X  X uch NounPhrase as { NounPhrase, } * { (or/and) } NounPhrase X  to target sentences such as  X  X orks by such autho rs as Herrick X . Application of this pattern to a text corpus automatically g enerated a list of hyponyms ( X  X uthor X ,  X  X errick X ), providing a low-cost appr oach to knowledge discovery. Further examples illustrating the utility of sy ntactic and linguis-tic patterns can be found in the field of Web mining. For exampl e, Liu et al. [2003] demonstrated a technique for mining a topic specific e Book from the Web using a pattern-based approach (see also Chen et al. [200 5]), and vari-ous other authors have successfully extracted class and ins tance relationships using a similar technique [Cimiano et al. 2004, 2005; Etzion i et al. 2004]. Finally, a fairly contemporary application of patterns is d escribed by Cao et al. [2007], who used a single parenthesis-based template in com bination with various transliterative techniques to extract translatio n candidates. lation technique for unknown terms which combines traditio nal statistical methods with linguistic and punctuative pattern matching. This technique is described in full in Section 4.
 3. CANDIDATE DISAMBIGUATION USING GRAPH THEORY We propose that the co-occurrence of possible translation t erms within a given corpus can be viewed as a graph . In such a graph each translation candi-date of a source query term is represented by a single node. Ed ges drawn between these nodes are weighted according to a particular c o-occurrence mea-surement. Figure 1 illustrates a graph view of the possible t ranslation candi-dates for a sample five term query. In this diagram, translati on candidates for the same query term have been grouped together, and only t he candidates with the highest co-occurrence scorings have been connecte d.
 pus in this way has one particular advantage. It converts sim ple concurrence statistics into a pattern susceptible to various analytica l techniques pioneered in the field of information retrieval. 3.1 Graph Analysis Algorithm The basic algorithm for selecting the best translation amon g a set of possible candidates is as follows: q form a undirected weighted graph: G = &lt; V , W &gt; , where V is the set of vertices representing one translation candidate t i , j to the query term q i , and W is a com-plete set of weighting functions . Hence, every possible pairing of translation candidates has a nonnegative weight attribute, w , which indicates the proba-ble strength of any link potential between the two translati on candidates. The set of weights as a whole can be described as: given by the function: but within this remit there are still two possible approache s, as discussed in section 3.2) to determine Cen ( t i , j ) for every single translation candidate in the graph (this process is discussed in more detail in section 3.3). lation candidate, t i , j , which produces the maximum Centrality Score in the cor-respondent set of translation candidates: 3.2 Weighting Functions In our algorithm, a weight w is added to each edge connecting a pair of nodes in the co-occurrence graph. This weight indicates the  X  X tre ngth X  of the link between the nodes. Two different weighting functions have b een developed for this task, which are called StrengthWeighting (SW) and FixedWeighting (FW) respectively. The SW function produces a undirected, weighted graph, while the FW function produces an unweighted alternative.
 a certain threshold  X  , then the weight between the two terms is equivalent to the similarity score. Otherwise, the weight is set to zero. a certain threshold  X  , then the weight between the two terms is set to one. Otherwise, the weight is set to zero. used here to exclude word pairings with low-frequency count s [Manning and Sch  X  utze 1999]. 3.3 Calculating the Centrality Score Graph-based analysis is essentially a technique for decidi ng the importance of a single node using global information recursively drawn from the entire graph. In our formulation of this approach, which is tailore d to candidate translation selection, the importance of a node within the g raph is described as its centrality . The following subsections describe three different ways o f calculating node centrality. of assessing the centrality of a node within a co-occurrence graph involves calculating the number of edges incident upon that node (i.e ., the indegree measure). In the context of an undirected graph, this measur ement actu-ally equates to a node X  X  degree , since a connecting edge contributes equally to the degree of each connected node. Stated formally, for a u ndirected graph G = ( V , E ), the centrality of a given node V i is defined as: where w ij is the weight assigned to the edge connecting the nodes V i and V j . dicate the strength of the link between two nodes in the co-oc currence graph. Each of these functions will produce a different type of grap h (i.e., the SW function will produce an undirected weighted graph and the FW function will produce an undirected unweighted graph). The precise type o f graph deter-mines the method used to calculate the indegree centrality o f a node. In an undirected unweighted graph, the centrality of a node will b e calculated by a simple count of the number of edges incident upon it, meaning the translation candidate for a given query term with the maximum indegree me asure will be selected as the final translation term. By contrast, in a undi rected weighted graph, the centrality of a node is calculated using node-nod e co-occurrence scores represented by edge weightings. Interestingly, thi s means that the re-sult of determining the centrality of a node using this metho d will be the same as if we had employed the greedy algorithm discussed in secti on 2.1, since the coherence measure (step 2(b) of the algorithm) is identical to the indegree of a node in an undirected weighted graph. This can be demonstrat ed fairly easily. If we calculate the MI similarity measure between two transl ation candidates x and y so that we will arrive at the same result had we calculated the indegr ee for these nodes within an undirected unweighted graph.
 scheme involves centrality calculations based on a random w alk around the graph structure. Up to this point, when calculating node ind egree, we have applied a totally democratic method whereby each edge is con sidered as one  X  X ote X  contributing to that node X  X  centrality score. Howev er, this scheme has a weakness which is exposed when several unwanted translati ons  X  X ote X  for each other, thereby unhelpfully raising their indegree sco rings. Fortunately, this situation can be completely avoided by weighting the  X  X  otes X  bestowed by each edge according to the centrality of the voting nodes. This approach, which is derived from the hyperlink analysis technique know n as PageRank [Brin and Page 1998], is informed by an analysis of a stochast ic procedure that involves a random walk around the graph. The rules for th is  X  X alk X  are as follows X  X eginning at some arbitrary node A in the undirected graph, we move from node A to a randomly chosen node linked to A . This step is contin-ually repeated. If, at any point, there is a lack of node outli nks making further traversal impossible, we jump to a randomly selected node in the graph and continue. As the random walk proceeds, certain nodes in the g raph structure will be visited more often than others, intuitively leading us to the following conclusions: (1) Nodes which are visited frequently during the random wal k are more likely (2) Nodes which are visited frequently during the random wal k are more likely walker model: for the given undirected graph G = ( V , E ), where V denotes a set of nodes and E denotes a set of edges, for a given V i let { V i } IN be a set of nodes that point to it and let { V i } OUT be a set of nodes that V i points to, then, the centrality score of V i is defined as follows: Where d is a dampening factor which integrates the probability of ju mping from one node to another at random (normally set to 0.85) and N is the total number of nodes in the graph. Starting with an arbitrary valu e assigned to every node in the graph, this algorithm is guaranteed to conv erge below a certain threshold. 3 we can reformulate these definitions. Let A be the similarity matrix where rows and columns represent the translation candidates and e ach entry denotes the similarity score between them. Note that the similarity scores between translation candidates for the same query term are initiall y set to zero. Let z be the centrality vector that corresponds to the stationary distribution of A , and let U be a square matrix with all elements being equal to 1 / N . The equation above can be written in the matrix form as mixture of two kernels U and A . A random walker on this Markov chain chooses one of the adjacent states of the current state with p robability d , or jumps to any state in the graph, including the current state, with probability 1  X  d . for calculating the centrality score of a node in an undirect ed graph borrows heavily from Kleinberg X  X  HITS algorithm [Kleinberg 1999]. In this scheme, each translation candidate in the graph is assigned a hub score and an author-ity score. These scores have a recursive and mutually reinforci ng relationship, so that: (1) A strong authority is a node that is pointed at by a high number of nodes (2) A strong hub is a node that points to a high number of nodes with strong date term, t , over the whole collection of candidate terms, T , as: all weights on edges connecting t to other terms t  X  in the graph, multiplied by the hub scores for t  X  . In an exact mirror of this calculation we determine the hub score for a candidate term as the sum of all weights on edge s connecting t to any other terms t  X  in the graph, multiplied by the authority scores for t  X  : tive HITS algorithm [Kleinberg 1999], it can be proven that t hese equations will converge to score functions Hub  X  and Authority  X  (which are nonidenti-callyzero, nonnegative). When this algorithm has converge d, those translation terms with the top hub scores or the top authority scores will be natural choices for providing final translation terms.
 proach to candidate term ambiguity. In the next section we di scuss another technique designed for CLIR which addresses the difficult re solution of OOV terms.
 4. A PATTERN-BASED APPROACH TO OOV TERMS A high-level summary of our approach to unknown terms is as fo llows:  X  X etect the OOV terms in a query.  X  X ubmit these terms to a search engine and cache the results.  X  X pply a set of punctuative and linguistic patterns to the mi xed language text of the cached Web pages.  X  X xtract one or more translation candidates.  X  X elect a final translation for the OOV using any suitable dis ambiguation strategy.
 4.1 OOV Detection The first stage in this process, which involves identifying t he presence of OOV terms in a source language query, is surprisingly difficult. Any query term not found in a bilingual dictionary is, by definition, out of voca bulary. However, this is by no means the end of the matter. To illustrate this po int, assume that we have a three-word query  X  X pen source download X  which we need to translate. Each of these three query terms can no doubt be tra nslated indepen-dently using a bilingual dictionary, as they are very common words. However, the resulting translation, pieced together term by term, is unlikely to provide a meaningful translation of the opening two-term phrase . To make matters worse, even when a phrase is recognized, that phrase may or ma y not be OOV itself.
 with a robust phrase identification stage. Therefore, queri es are first analyzed using a pair of noun phrase recognizers. 4 If there are no phrases found in the query, then the query is translated term by term using a bi lingual dictio-nary, with any term not successfully translated being label ed as an OOV term. If a phrase is identified in the query, and that phrase cannot b e translated by the bilingual dictionary, we search the mixed language We b for possible translations (please refer to the next step for details). If possible translations are found, we treat the text string as an OOV phrase. If no poss ible trans-lations are found, we decompose the phrase into single terms and attempt a word-by-word translation, again using the bilingual dicti onary. Any words not successfully translated at this point are labeled as OOV ter ms. The pattern matching procedure from this point on is then identical whet her we are trying to translate a single OOV term or an OOV phrase. 4.2 Obtaining Mixed-Language Text In the next step of our pattern-based approach to OOV terms, t he unknown term or phrase is submitted to a Web search engine. Our search is configured in such a way as to retrieve documents written in the target tr anslation lan-guage. For example, if an unknown English term is to be transl ated into Chi-nese, then the search will be configured to only retrieve Chin ese Web pages. Configuration of the search is performed using the advanced s earch criteria provided by most major search engines. The top 100 ranked tit les and docu-ment surrogates are cached, and the stored text is parsed to r emove HTML tags and other non-content symbols, thereby creating a raw t ext collection. 4.3 Generation of Patterns The next stage of the process involves generating a set of pun ctuative and lin-guistic patterns that we can apply to the mixed language text . The literature on this subject suggests two different ways to generate thes e patterns. The first approach, as discussed by Hearst, is manual extraction ; examples of the text collection are examined by hand for syntactic and lingu istic relationships, and the patterns that are detected are recorded [Hearst 1992 ]. The second method, as exemplified by the work of Serban et al. [2005], is a utonomous extraction X  X he text is exposed to some application capable of automatically detecting the requisite patterns. Either approach (of a com bination of both) can be used to generate the patterns required for our OOV transla tion technique (see section 6.8 for the specific technique we employed in our English-Chinese cross-language experiment). 4.4 The Pattern Set A typical pattern set will contain a mix of punctuative patte rns and linguistic patterns. We will deal with each type of pattern in turn. Conc rete examples of each pattern, taken from the English-Chinese cross languag e retrieval experi-ment discussed later in this paper (see section 6), are provi ded for illustration in Figure 2. tuation in the cached mixed-language Web pages. There are tw o different types of punctuation patterns: of OOV terms delineated by brackets. This type of pattern inc ludes all of the commonly used bracketing symbols, together with known pare nthetic substi-tutes. Examples 1 and 2 in Figure 2 illustrate the symmetric p attern in an English-Chinese context.
 pairs adjacent to single punctuation marks. This type of pat tern includes all of the common nonparenthetic symbols that organize written te xt, like commas, colons, and full stops. Examples 3-5 in Figure 2 illustrate t he nonsymmetric punctuation pattern in an English-Chinese context.
 headings: in stop lists, commonly used in corpus linguistics. This mea ns that eliminator terms have a low information value and, if extracted as part o f the translation candidate, will almost always decrease the accuracy of the t ranslation. How-ever, one positive aspect of eliminator terms is that they fr equently mark the boundaries between the translation pairing and the rest of t he source docu-ment, and can therefore be used to delineate target translat ions. Example 4 in Figure 2 provides an illustration of an eliminator term in an English-Chinese pattern.
 indicating the relationship between a term (or terms) in one language and a translation in another. Clues of this nature are particular ly valuable to the OOV translation process. This type of pattern includes all c ommonly used explanatory phrases employed by authors writing mixed-lan guage pages. Ex-ample 5 in Figure 2 provides an illustration of a discriminat or phrase within an English-Chinese punctuation pattern. 4.5 Applying the Pattern Set In the next step the raw text collection descibed in section 4 .2 is subjected to the pattern set in order to extract translation candidates. The output of this pattern matching technique is a set of likely translation ca ndidates for the OOV term. Although a final translation for the OOV term can be e xtracted from this set using any reliable disambiguation strategy [Z hou et al. 2007], we chose to perform final candidate selection by joining our pat tern-based OOV translation technique to the graph based disambiguation pr otocol discussed in section 3, thereby creating the hybrid query translation te chnique discussed below. 5. A HYBRID QUERY TRANSLATION TECHNIQUE Our hybrid query translation technique works by linking the two methods dis-cussed above so that the undifferentiated output of the OOV p attern matching process (i.e., the set of all translation candidates derive d using patterns) con-stitutes the input to the graph-based disambiguation algor ithm. A summary of the process chain is as follows: (1) First, the target query is translated using a naive bilin gual dictionary, a (2) Next, the OOV terms and phrases are passed to our pattern m atcher, (3) Next, this entire set of translation candidates is subje cted to the (4) Finally, the fully translated query is passed to the CLIR engine. 6. EVALUATION In the following section we describe a series of cross langua ge retrieval ex-periments designed to evaluate (both in isolation and in com bination) the two translation techniques described above. Our evaluation wi ll focus on the fol-lowing thematically related questions: (1) Is the proposed graph-based method for candidate term di sambiguation (2) How accurate, when compared with manual translations, a re the transla-(3) Is the combination of these two techniques (in the form of a hybridized 6.1 Test Environment The document collections and topic sets used in our experime nt were provided by the 6th NTCIR workshop (2006/7). This workshop was organi zed into two separate stages. In STAGE1 participants were invited to sub mit findings re-lated to bilingual ad hoc search tasks, using a document coll ection consisting of newspaper articles published between 2000 and 2001 (see T able I). STAGE2 provided an opportunity for cross-collection analysis usi ng older collections (NTCIR-3, NTCIR-4, and NTCIR-5), and functioned as a check o n the robust-ness of techniques submitted in STAGE1. STAGE1 reused the to pic sets previ-ously published in relation to NTCIR-3 and NTCIR-4, while ST AGE2 used the original topics sets for the older collections. All of docum ents in the various collections were written in traditional Chinese and used th e BIG5 character encoding method. 6.2 Translation Resources The English-Chinese bilingual dictionary used in our exper iments was pro-vided by the Linguistic Data Consortium. 5 This dictionary contains exactly 110,834 English words with the accompanying Chinese transl ations. It was compiled using various resources including LDC-internal c omponents and the World Wide Web, and provides a useful exemplar of the type of b ilingual dic-tionaries commonly used in CLIR. 6.3 Text Preprocessing The most strenuous part of the text preprocessing stage invo lved character en-coding issues. All of the Chinese documents in our test colle ction were encoded using BIG5, which was designed to represent traditional Chi nese characters. However, our bilingual dictionary was encoded using an alte rnative scheme, GB2312, which is used to represent simplified Chinese charac ters. To pro-vide a unified translation and retrieval environment, we wer e forced to con-vert the encoding of all of the documents in the test collecti on and each entry in the bilingual dictionary to a third encoding, Unicode UTF -8. This was ac-complished using an encoding converter written in the Java p rogramming lan-guage. 6 Following conversion, all of the Chinese documents were pro cessed using a segmentation tool 7 and the English queries were subjected to the Krovetz stemmer and 571 word stop list. 8 Finally, the test collection was in-dexed using the Lemur toolkit. 9 6.4 Description of the Experimental Retrieval Systems In order to investigate the effectiveness of our translatio n techniques and to study the effect of combining them within a single process, w e designed a set of eleven experimental retrieval systems. A description of these systems is as follows: collection using manually translated versions of the Chine se queries provided by the various NTCIR organizing committees. The performanc e of a mono-lingual retrieval system such as this has always been consid ered as an unreachable  X  X pper-bound X  of CLIR as the process of automat ic translation is inherently noisy.
 collection using all the translations provided by the bilin gual dictionary for each query term.
 test collection using only the first translation suggested f or each query term by the bilingual dictionary. Due to the way in which bilingual d ictionaries are usually constructed, the first translation for any word gene rally equates to the most frequent translation for that term according to the Wor ld Wide Web. term were selected using the basic greedy co-occurrence alg orithm described in section 2.1 We used the target document collection to calc ulate the co-occurrence scorings.
 lations were selected using the unweighted co-occurrence m easure described in section 3.3.1 rather than the basic co-occurrence model.
 were selected using the decaying co-occurrence algorithm d escribed by in Section 2.1 translation system known as Babelfish 10 to translate the English queries into Chinese (for previous use see Kraaij [2001]). This system wa s included to pro-vide a strong baseline for the remaining runs.
 document collection using query translations suggested by our analysis of a weighted co-occurrence graph (i.e., we used the SW weighting function). Edges of the graph were weighted using co-occurrence scores deriv ed using the greedy algorithm in section 2.1 Within this framework there are sti ll three permuta-tions in choosing the suitable centrality scores (see secti on 6.6). the collection using query translations suggested by our an alysis of the co-occurrence graph, only this time we used an unweighted graph (i.e., we used the FW weighting function). GW, except that the query terms and phrases that were not reco gnized (i.e., OOV) were first sent to the pattern matcher for translation an d then passed to our disambiguation routine.
 the preceding, only this time we used the unweighted scheme.
 tations related to the choice of topic fields. We labeled retr ieval runs using the Title topic field as T-Runs . Likewise, we labeled retrieval runs using the Description field as D-Runs . Finally, we identified those runs which used a combination of both fields as TD-runs . In total, this yielded a 33 individual retrieval runs (i.e., 11 systems * three field based permutat ions) which are summarized in overview Table II.
 6.5 Retrieval Function All of the retrieval systems ran translated queries against the document col-lections using the Lemur toolkit and the BM25 retrieval func tion. In this func-tion, the relevance of a document to a given query is defined as : where w t is the Robertson/Sparck Jones weight of t , k 1 , b , and k 3 are parame-ters (set to 1.2, 0.75, and 7 respectively), | d | represents document length and a v g | d | stands for average document length. 6.6 Centrality Measures To demonstrate the interchangeability of the various centr ality measurements described in section 3.3, we varied the centrality calculat ions from collection to collection. The results using the NTCIR-6 and NTCIR-3 doc ument collec-tions respectively were achieved using the PageRank-deriv ed random walker model (denoted as PR). A series of retrieval runs using the NT CIR-4 collec-tion shows the retrieval performance when a centrality meas urement based on node authority scoring was employed (denoted as AUTH). The experimen-tal run relates to the NTCIR-5 collection lists the results o btained when node hub scorings are used to determine node centrality (denoted as H UB). A com-parative analysis and overview of the performance of the var ious centrality measurements can be found in section 7.4. 6.7 Parameter Selection One important part of the experiment involved establishing the optimal values for the various parameters discussed above. The following s ection describes how we selected values for  X  (a component of the decaying co-occurrence model) and  X  (an important element in our weighting functions). the decaying rate parameter (denoted  X  ) in the decaying occurrence model can be set at any value between 0.2 and 1.0 with broadly similar re sults, although a setting of 0.8 will marginally outperform the other values in this range [Gao et al. 2002]. To verify these findings, we ran a number of DCOM r uns against the NTCIR-6 test collection, with a spread of settings for th e  X  parameter. As illustrated by Figure 4, the highest mean average precision scorings for the relaxed and rigid runs were obtained when  X  = 0.2, with a sharp drop in MAP thereafter. As a result of this test, we decided to set the val ue of  X  = 0.2 for all subsequent experiments.
 in our weighting functions to exclude word pairings with low co-occurrence scorings. We determined the correct value for this paramete r by running a number of GW runs against the NTCIR-6 test collection, with a spread of set-tings for the  X  parameter. As illustrated by Figure 5, threshold values bel ow zero had no effect on MAP scores in either the rigid or relaxed runs, and the best value for this parameter in terms of mean average precis ion was  X  = 0 . 0. As a result of this test, we decided to set the value of  X  = 0.0 for all subsequent experiments.
 6.8 Generating the Pattern Set As mentioned above, our OOV translation technique relies on the application of punctuative and linguistic patterns. These patterns can be generated in a number of different ways. For this particular experiment, w e used a modified simple machine learning algorithm known as 1R , to infer the rudimentary pat-terns [Witten and Frank 2005]. This computationally inexpe nsive algorithm generates a one-level decision tree expressed in the form of a set of rules that all test one particular input attribute (translation pairs in our case). Input to the algorithm was a list of English names, locations, and tec hnical terms ac-companied by Chinese translations. 11 The output of the algorithm was a set of pattern candidates. These candidates were sorted and ver ified by a bilin-gual individual with a background in linguistics. The total time expended on this verification stage was one hour. A summary of the modified 1R algorithm is provided in Figure 6. For the purposes of pattern acquisit ion, we used the Google search engine throughout. 7. RESULTS AND DISCUSSION The following section is divided into three parts. In the firs t part, we rational-ize the number of experimental systems under consideration using poor initial performance as grounds for exclusion. In the second part we e valuate the ef-fectiveness of the remaining systems using the NTCIR-6 docu ment collection. In the third part we extend this evaluation into the of realm o f cross-collection analysis, using earlier collections NTCIR-3, NTCIR-4, and NTCIR-5.
 CIR organizing committee. These judgments provide two diff erent thresholds of relevance X  X ocuments which are strictly relevant to a que ry (i.e., rigid rele-vance), and documents which are likely to be relevant to a que ry (i.e., relaxed relevance). As shown in the results below, we used both measu res in our eval-uation when reporting NTCIR-6 results, along with mean aver age precision (MAP), recall-precision (R-prec), and recorded precision at ten documents. The results for cross-collection analysis will concentrate on rigid relevance criteria. The Wilcoxon signed-rank test with 95% confidence level was a lso employed to test the statistical significance of the different runs. B old figures in the results tables indicate a statistically significant differ ence in the retrieval per-formance of the labeled run. 7.1 Rationalization of Experimental Systems In the previous section we introduced a large number experim ental retrieval systems. Early experimentation suggested that this rather exhaustive list could be shortened considerably by removing those systems w hich performed poorly when compared with their immediate siblings. Workin g on this premise, in this stage of the experiment we were able to remove four exp erimental sys-tems from further consideration. The following subsection s will provide a ra-tionale for each deletion. ing early result, the performance of retrieval runs using a d ecaying co-occurrence model (DCOM) were largely inferior to those runs using the basic co-occurrence model (COM). The diagram in Figure 7, which co mpares mean average precision scorings obtained for a variety of title and description runs using the NTCIR-6 collection, indicates that COM outperfor ms DCOM in five out six cases. Clearly, there is some disagreement here with the work of Gao et al. [2002], who observed an increase in retrieval effecti veness when a decay-ing factor was introduced to the calculation of mutual infor mation. Although the precise reason for this disagreement is not known at this time, one possible explanation might relate to the various test collections un der scrutiny. Gao X  X  work centered on the TREC test collections, while this study uses materials from an NTCIR corpus. Whatever the underlying reasons, this result led to our first performance-based deletion. We discontinued our e xperimentation with the DCOM retrieval system at this point. demonstrated that the basic co-occurrence model was equiva lent to the weighted indegree measure of centrality in a graph generate d using occurrence data. We also proposed another measure of centrality using t he unweighted indegree measure. We performed an early experiment testing the differences between these two measures, with a legitimate expectation t hat the weighted variant COM would outperform COMUW. Our expectations were b roadly sat-isfied (see Figure 8), although we did record an unusually str ong performance by COMUW when using longer NTCIR-6 queries. However, as this anomaly was not statistically significant (according to the Wilcoxo n signed-rank test with 95% confidence level) and did not persist into cross-col lection analysis, we eventually decided to exclude COMUW from further conside ration. sion related to those systems employing an unweighted graph . As revealed in Figure 9, retrieval runs employing a weighted graph easil y outstripped the counterpart unweighted model, irrespective of the central ity measurement or the type of relevance criteria applied. This seems to confirm that edge weight-ing plays an important role when using graph-based analysis to select a final translation target. For this reason we decided to exclude al l experimental sys-tems that used an unweighted graph from the main results sect ion. 7.2 Main Results (NTCIR-6) Our main experimental results, which describe the performa nce of the remain-ing seven experimental systems runs on the NTCIR-6 document collection, are shown in Tables III and IV. As illustrated by the data, docume nt retrieval with no disambiguation of the candidate translations (ALLT RANS) was the lowest performer in terms of mean average precision. This re sult was not surprising and merely confirms the need for an efficient proce ss for resolv-ing translation ambiguities. The English-Chinese diction ary provided by LDC contains a large number of translation alternatives, there by creating greater scope for ambiguity and translation error. Using the first tr anslation offered by the bilingual dictionary (FIRSTONE) always led to an impr ovement in retrieval effectiveness.
 co-occurrence model (COM), retrieval effectiveness alway s exceeded ALL-TRANS and FIRSTONE. 12 There was a noticeable improvement in retrieval effectiveness when processing longer queries (i.e., D-run s), but a far more mod-est increase for shorter queries (i.e., T-runs).
 equivocal. BFMT faired well against the basic co-occurrenc e model in the Title field and combined field runs, but actually scored worse than C OM when the Description field was used.
 were very promising. Pleasingly, the weighted graph GW outp erformed the basic co-occurrence model and the machine translation meth od in the majority of retrieval runs, with the best scores relating to longer qu eries. It is likely that this bias toward longer queries is an artifact of the gra ph-based disam-biguation approach, with a higher number of query terms havi ng a positive effect via the amount of global information available durin g processing. were excellent. Runs employing the successful weighted co-occurrence graph in partnership with OOV pattern matching (GW+OOV) produced the highest nonmonolingual MAP score across the board, touching a credi table 88.59% of monolingual performance and recording statistically sign ificant improvements over the COM and BFMT baseline systems in every single run. An illustra-tion of these findings is supplied in Figure 10, which gathers together recall-precision plots for the four leading retrieval systems. 7.3 Cross Collection Analysis (NTCIR-3, NTCIR-4, NTCIR-5) Table V shows the results obtained when we repeated all of the retrieval runs described above using document collections and topic sets r eleased by NTCIR in previous years. As shown in the table, our hybrid translat ion technique (GW+OOV) continued to perform well, realizing between 60% a nd 80% of monolingual retrieval performance. While these statistic s may not seem par-ticularly impressive when placed alongside recent work usi ng the TREC doc-ument collections (where cross-language retrieval perfor mance in excess of monolingual performance has been reported [Gao and Nie 2006 ]), this type of intercollection comparison is ultimately misleading. In t he context of the NT-CIR English-Chinese document collections, the norm for mon olingual perfor-mance is much lower than the TREC benchmark, currently withi n the range of 40% to 65% (see Table VI for a collection-by-collection comp arison of the lead-ing systems in NTCIR-6). At the time of writing, the NTCIR col lections seem to offer a more challenging retrieval environment than their T REC counterparts, which are constructed in such a way that even a rudimentary di sambiguation strategy like COM can deliver 90% of monolingual performanc e [Gao and Nie 2006]. Therefore, we are very pleased with the overall perfo rmance of our hy-brid technique, which has achieved some of the highest score s with regards to monolingual performance ever recorded on the NTCIR collect ions without even resorting to query expansion (used by many of our fellow comp etitors [Kwok and Dinstl 2007; Wu et al. 2007]).
 to the non-monolingual runs. As illustrated by Table VII and Figure 11, GW+OOV always exceeded the COM and BFMT baselines by a statis tically significant margin in every single test run, irrespective of the centrality mea-surement we applied. We take this cross-collection perform ance as a whole to be favorable, indicating the stability of our hybrid query t ranslation technique. alies. On several occasions, usually during retrieval runs addressing the Title field, the performance of ALLTRANS approached that of FIRSTO NE, even ex-ceeding it on the NTCIR-4 document collection. We believe th at the influential factor at work in this case is the short length of the queries. This result merely confirms the intuitive assumption that ambiguity has a posit ive relationship with the number of query terms under consideration (i.e., re trieval runs using longer queries will tend to perform worse than shorter queri es).
 casionally performs worse than ALLTRANS or FIRSTONE. Again, this artifact seems to be related to query length. It may be that short queri es do not provide sufficient context for the successful operation of a techniq ue based on simple term-term co-occurrence. Luckily, graph-based methods us ing more sophisti-cated measures of centrality seem to have no such limitation s. 7.4 Comparison of the Various Centrality Measures Table VIII shows a side-by-side comparison of the various ce ntrality measure-ments described in section 3.3 in the context of retrieval ru ns carried out on the NTCIR-6 document collection. As we anticipated, the random walk centrality measure outscored the measurements based on either hubs or a uthorities in the vast majority of cases, while the difference between the MAP scorings for centrality measure HUB and centrality measure AUTH was fair ly marginal. This is probably related to the undirected nature of the co-o ccurrence graph, which unlike its directed cousin will tend towards node equa lity in this sort of analysis.
 NTCIR-5 document collection (see Table IX). However, the re sults we obtained failed to verify random walk as the undisputed centrality me asurement of choice (i.e. retrieval runs using the HUB centrality measur ement performed much stronger on this set of documents than the previous coll ection). A possi-ble conclusion that could be drawn from the results summariz ed in these two tables is that more research with respect to the correct cent rality measure-ment will be necessary in the future. It is likely that this pr ocess will involve trials of a metric which combines the more useful elements of the random walk method in partnership with consideration of graph hubs and a uthorities. 7.5 Translation Success Rate and Error Analysis There were 22, 29, and 40 OOV terms in the NTCIR-3, NTCIR-4, an d NTCIR-5 query sets respectively. 13 Most of these terms were proper nouns or acronyms (see Table X for examples taken from NTCIR-5). Our pattern ma tching algo-rithm, in combination with the graph-based disambiguation protocol, success-fully translated 18, 23, and 28 of the OOV terms, meaning our t ranslations perfectly matched the manual translations provided by the v arious NTCIR committees. In our opinion, an OOV translation success rate of 81.8%, 79.3%, and 70% in return for a meager expenditure of resources empha tically vali-dates the use of linguistics patterns alongside traditiona l statistical analysis. of date. Our method collects all translation candidates fro m the contempora-neous Web. The query terms we worked with are several years ol d. It could be that the persons, organizations, or acronyms which are re ferred to in those query sets are no longer as prominent on the Web as they once we re. This would inevitably have a negative impact on our ability to gen erate appropri-ate translation candidates. Furthermore, extremely well-known English terms are sometimes used directly in Chinese Web pages (i.e., with out an accompany-ing translation). This would obviously have a negative impa ct on our pattern based-translation technique. 7.6 Encoding Issues The last issue to be addressed in this section relates to char acter encoding. As discussed in Section 6.3, all of the documents collections u sed in our experi-ments, together with the bilingual dictionary used for naiv e translation, were converted to UTF-8 to provide a unified translation and retri eval environment. However, this harmonization of character encoding sets, wh ile necessary in terms of experimental design, should be taken into consider ation when evalu-ating our results. We conducted a final retrieval experiment to illustrate this problem. Table XI shows the negative effect of successive tr anscoding of the original NTCIR-5 document collection (BIG5 to GB2312 to UTF -8) on monolin-gual performance in Title field runs. As illustrated, each reencoding of the doc-ument set results in a significant drop in retrieval effectiv eness. Clearly, this issue of character encoding represents a major challenge fo r the CLIR research community X  X  problem which as yet lacks a standard, verified r esponse. 8. CONCLUSIONS In this article we have described a hybrid technique for quer y translation which can be used for English-Chinese CLIR. This hybrid tech nique marries a graph-based model for the resolution of translation ambigu ity with a pattern-based method for the translation of unknown terms. The combi nation of these two techniques performed well on the NTCIR-6 test collectio n, delivering sta-tistically significant improvements over various baseline systems. The robust-ness of this hybridized approach to query translation was co nfirmed during extensive cross-collection analysis using earlier NTCIR d ocument collections. led to some interesting observations. There seems to be a dis tinct difference between NTCIR collections and the TREC alternatives common ly used by re-searchers in this field. Cross-language retrieval performa nces in excess of monolingual performance have frequently been reported by i ndividuals work-ing with the TREC document collections. By contrast, the nor m for cross-language retrieval systems using the NTCIR English-Chines e document col-lections is much lower (usually within the range of 40% to 65% ). Future work is currently being planned that will involve a side-by-side examination of the TREC and NTCIR document sets to investigate this inconsiste ncy.
 Our thanks to the WebTech Group of the University of Nottingh am for many useful discussions.

