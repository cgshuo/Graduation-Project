 Bernardo  X  Avila Pires bpires@ualberta.ca Department of Computing Science University of Alberta Mohammad Ghavamzadeh mohammad.ghavamzadeh@inria.fr Team SequeL INRIA Lille -Nord Europe Csaba Szepesv  X ari szepesva@ualberta.ca Department of Computing Science University of Alberta A common technique to reduce the computational cost of learning a classifier is to define a convex  X  X urrogate loss X , such as the hinge loss in binary classification (e.g., Cortes &amp; Vapnik , 1995 ). Although the compu-tational problem that results may be more amenable to e ffi cient optimization, it is unclear whether minimizing the surrogate loss will still result in a good accuracy. be such that the loss of Lee et al. ( 2004 )tobelower-bounded over the set of  X  X entered X  vectors. The cali-bration function we derive has the same form as that given by Bartlett et al. ( 2006 ) and Steinwart ( 2007 ) for binary classification (up to modifications for cost-sensitivity), meaning that the e ff ort needed to calcu-late a calibration function for multiclass classification is the same as that for a binary classification problem with the same loss.
 Our general-form calibration function also applies to the loss of Lee et al. ( 2004 ) with  X  X otated X  inputs. We show that in K -class classification problems we can apply input transformations to convert a minimization with a sum-to-zero-constraint over vectors in R K into an unconstrained minimization over R K  X  1 . Moreover, we show that a particular case of these rotations is the Simplex Coding studied by Mroueh et al. ( 2012 )(who derived calibration functions for the cases when  X  is the hinge loss and the squared loss). To the best of our knowledge, the only work that has reported sim-ilar analytic expressions for calibration functions in multiclass classification is the one by Mroueh et al. ( 2012 ). As a secondary consequence of one of our re-sults, we show that the calibration function is the same for certain well-known  X  ( s ) and their  X  X runcated X  ver-The remainder of this paper is organized as follows. In Section 2 , we describe the cost-sensitive multiclass classification problem, and present our risk bounds, our general-form calibration function for the surrogate loss of Lee et al. ( 2004 ), along with a few examples of choices of  X  and respective calibration functions. In Section 3 , we present the proof of our core The-orem together with the intermediate results and the sketches of their proofs. The proofs themselves are pre-sented in the supplementary material (Appendix A ) due to space constraints. In Section 4 , we generalize our results to encompass the Simplex Coding losses of Mroueh et al. ( 2012 ). Finally, in Section 5 ,we present a brief overview of the work that provides the foundation and the context for our results. Let ( X, Y ) be jointly distributed random variables tak-ing values in the measurable spaces X and Y ,respec-tively. Let K = { 1 ,...,K } be the label space and fix a measurable function c : X  X  K  X  Y  X  R .The multiclass cost-sensitive classification problem finds a (measurable) mapping g : X  X  K that achieves the define this loss, we first choose some convex function  X  : R  X  R . The expected surrogate loss, or surrogate risk, of h : X  X  C is defined as where the surrogate loss of the balanced score vector t  X  C at x  X  X is defined by 1 Here with a slight abuse of notation, we define c ( x, k )= E [ c ( X, k, Y ) | X = x ] as the expected cost of input-label pair.
 To understand ( 3 ), consider the case when  X  is the hinge loss,  X  ( s )=(1+ s ) + , 2 t  X  C incurs larger loss when either t k or the corresponding label cost is large. Intuitively, minimizing the surrogate loss should push for smaller scores for labels with larger cost (in partic-ular, when  X  is the hinge loss, scores below  X  1 do not incur any cost). As a result, the classifier that selects the label with maximal score should incur a small cost. When the scoring function is a linear function of some weights, the above surrogate loss is convex, and thus, can be used as the basis for designing e ffi cient algo-rithms to minimize the empirical surrogate loss. What remains now is to investigate how choice of  X  af-fects the performance of the surrogate-risk minimizer w.r.t. the true risk. 2.2. Risk Bounds In what follows, we let  X  f ( x ) denote the set of subd-i ff erentials of the convex function f : R  X  R .With a slight abuse of notation, we denote by  X  (0) an ar-bitrary subdi ff erential of  X  at zero . In the rest of the paper, we will assume that  X  satisfies the following two assumptions: Assumption 2.1. The function  X  : R  X  R is convex with  X  X  (0)  X  (0 ,  X  ) .
 Assumption 2.2. inf t  X  C K k =1 c ( X, k )  X  ( t k ) &gt;  X  X  X  almost surely (a.s.).
 The e ff ort needed to verify Assumption 2.2 may change on a case-by-case basis. However, since we are ul-timately interested in not making any assumption Then, under Assumptions 2.1 , 2.2 ,and 2.3 , we have that  X  ( X,  X  ) &gt; 0 holds a.s. for all  X  &gt; 0 ,andforany implies For specific convex functions, this result is easy to in-terpret. For example, for the hinge loss, it is not hard to show that  X   X   X  ( x,  X  ). Further examples are given in Table 1 below.
 Following the argument of Steinwart ( 2007 ), it turns out that Assumption 2.3 allows one to study the rela-tionship between risks by first considering conditional risks. The proof of Theorem 2.1 follows immediately from the  X  X ointwise X  result stated below, which we will prove in Section 3 .
 Theorem 2.2. Let  X  1  X   X  X  X   X   X  K ,K &gt; 0 be non-negative numbers. Consider a maximum selector func-tion f , and also a convex function  X  satisfying As-sumption 2.1 and s.t. For  X   X  0 , define  X  (  X  )=(  X  j Then, for all  X  &gt; 0 and t  X  C ,if all  X  &gt; 0 .
 An equivalent way of stating the conclusion of this theorem is to say that  X  is a calibration function Proof of Theorem 2.1 . We first prove that the bound holds pointwise, i.e. , for any  X  &gt; 0 and any h  X  H ,we have
E [ L  X  ( X, h ( X )) | X ]  X  min  X  c ( X, f  X  h ( X ))  X  min This pointwise bound is the direct application of The-orem 2.2 with t = h ( X ) and  X  k = c ( X, k ). Assump-tion 2.2 ensures that inf t  X  C K k =1  X  k  X  ( t k ) &gt;  X  X  X  in A . We start with an adaptation of Definition 2.7 of Steinwart ( 2007 ) which will give key concepts for our derivations: calibration , and calibration functions . Definition 3.1 (Calibration function, calibration) . Consider a set I and two functions L 1 ,L 2 : I  X  R . We call any positive-valued function  X  :(0 ,  X  )  X  (0 ,  X  ] a calibration function for the pair ( L 1 ,L 2 ) if for all  X  &gt; 0 and i  X  I it holds that
L 2 ( i ) &lt; inf If there exists a calibration function for the pair ( L 1 ,L 2 ) , then L 2 is said to be calibrated w.r.t. L 1 . Calibration means that minimizers of L 2 are also min-imizers of L 1 . As a result, a calibration function ex-presses an upper-bound on the rate of convergence of the target loss ( L 1 ) in terms of the convergence rate of the surrogate loss ( L 2 ).
 Before proceeding, we will make a boundedness as-sumption. We will discuss its suitability when we make our choices of L 1 and L 2 for multiclass classification. For now it su ffi ces to say that if inf i  X  I L 2 ( i )=  X  X  X  , then L 2 has no rate of convergence, but it is still, by definition, calibrated w.r.t. L 1 , regardless of what L 1 is. This case requires a di ff erent treatment of calibra-tion and is beyond the scope of this paper.
 Assumption 3.1. Assume that  X  X  X  &lt; inf An equivalent and useful way to characterize calibra-tion under Assumption 3.1 is as follows: Proposition 3.1. For each  X   X  0 , let and for  X  &gt; 0 , let Under Assumption 3.1 ,itholdsthat L 2 is calibrated w.r.t. L 1 i ff  X  max (  X  ) is positive for all  X  &gt; 0 .Fur-thermore, for any  X  :(0 ,  X  )  X  (0 ,  X  ] s.t. 0 &lt;  X  (  X  )  X   X  max (  X  ) for all  X  &gt; 0 ,  X  is also a calibration function. This proposition is derived from Lemma 2.9 of Stein-wart ( 2007 ) and its proof is included in the appendix for completeness. In what follows, we refer to  X  max as the maximum calibration function . It follows from the second statement in Proposition 3.1 that charac-terizing a calibration function can be done by  X  X ean-ingfully X  lower-bounding, rather than explicitly calcu-lating,  X  max . This is the strategy that we will use to prove Theorem 2.2 .
 the calibration function that is straightforward to cal-culate for di ff erent choices of  X  . Thus, in order to ob-tain a calibration function that is as straightforward to calculate as a binary classification calibration func-tion, we lower-bound  X  max . To do so, we find subsets of C\M (  X  ) where the infimum does not change, and up-per bound the second term in ( 5 ) in a way that parts of this upper-bound cancel out parts of the first term. Before developing our lower-bounds, we state a result that specifies  X  max for the case of K = 2. This re-sult is essentially extracted from Theorem 2 in Bartlett et al. ( 2006 ) (though we added Assumption 3.2 ) and its proof is only included for completeness. The re-sult itself will be used to ensure that the calibration functions we present are positive.
 Lemma 3.3. Let K =2 and  X  be a convex func-tion satisfying Assumption 3.2 and such that  X  X  (0)  X  [0 ,  X  ) . Then for  X  (  X  1 ,  X  2 )=(  X  1 +  X  2 )  X  (0)  X  inf it holds that Moreover,  X  (  X  1 ,  X  2 ) &gt; 0 for all 0  X   X  1 &lt;  X  2 ,i ff ad-ditionally  X  satisfies Assumption 2.1 , i.e. ,  X  X  (0)  X  (0 ,  X  ) .
 It follows from the proof of Lemma 3.3 that while for  X   X   X  2  X   X  1 we have equality in ( 6 ), for  X  &gt;  X  2  X   X  1 we have  X  max (  X  )=  X  (it is trivial to see this case consid-ering the definition of calibration and Proposition 3.1 ). The lemma is important because it gives a closed-form expression for  X  max as a function of (  X  ,  X  1 ,  X  2 ) for many commonly used convex functions  X  satisfying Assump-tions 2.1 and 3.2 for  X  1 ,...,  X  K (cf. the examples in Table 1 ).
 Let us now return to bounding  X  max from below when K  X  2. We start by rewriting the first term in ( 5 ) as an (equal) infimum over a subset of C\M (  X  ). We first prove the results for a non-decreasing function  X  : R  X  R with  X  (0) &gt; 0. Recall that 0  X   X  1  X  ...  X   X  K . For  X  &gt; 0 and t  X  C ,wedefine j  X  =min { j :  X  j  X   X  1  X   X  } and  X   X  t =  X  Lemma 3.4. If  X  : R  X  R is convex and non-decreasing, and  X  1  X   X  X  X   X   X  K ,forall  X  &gt; 0 ,we Sketch of the proof of Lemma 3.5 . The result is triv-ial in case  X  =  X  . In the other case, the argument to prove the lemma is based on the observation that there will be a minimizer of the loss L  X  2 whose coor-dinates all are larger than or equal to s  X  ( i.e. , at the coordinates,  X  is increasing). We show the weaker but su ffi cient statement that for any vector of the form t 1 =  X  X  X  = t j  X  ,s.t. t i  X  0 for i&gt;j  X  ,if t i &lt;s  X  for some i , we can construct another vector t with t 1 =  X  X  X  = t j  X   X  0s.t. s observe that  X  ( t k )=  X  ( t k ) for all k and for all these t , which are clearly in C\M (  X  ). We then use Lemma 3.4 to show the desired result.
 We are now almost ready to connect all these results in order to prove Theorem 2.2 . All that remains is to present the next two lemmas.
 Lemma 3.6. Let  X  1 ,  X  2 be two non-negative numbers and  X  satisfy Assumptions 2.1 and 3.2 . Then we have inf Lemma 3.7. Let 0  X   X  1  X  ...  X   X  K and  X  satisfy Assumptions 2.1 and 3.2 .For  X   X  0 , define  X  (  X  )=(  X  j Then for all  X  &gt; 0 and t  X  C ,italsoholdsthat  X  max (  X  )= inf The essence of the proof of Lemma 3.7 lies in properly manipulating the constraints of the infima involved in the calculations, in order to  X  X eaningfully X  lower-bound  X  max . We conclude this section with the proof of Theorem 2.2 .
 Proof of Theorem 2.2 . The proof follows from Propo-sition 3.1 combined with Lemma 3.7 , and from the observation that  X  (  X  )=  X  (  X  j Lemma 3.3 . From Lemma 3.3 , we have that the cal-ibration function  X  is positive for all  X  &gt; 0. This is because by definition of  X  j Since  X  is a positive lower-bound to  X  max , from Propo-sition 3.1 , it is a calibration function, and thus, we obtain the calibration result for  X  f . All that remains is to see that for all t  X  C and  X  &gt; 0,  X   X  f ( t )  X   X  1 &lt;  X  implies  X  f ( t )  X   X  1 &lt;  X  . Calibration functions are well characterized for convex binary classification losses. Bartlett et al. ( 2006 )fully characterized calibration functions for losses based on convex  X  , in binary cost-insensitive classification. In contrast to our presentation of their main re-sult (Lemma 3.3 ), and also in contrast to our re-sults, Bartlett et al. ( 2006 ) characterize binary classifi-cation calibration even when inf s  X  1  X  ( s )+  X  2  X  (  X  s )=  X  X  X  . A similar construction seems to be harder to deal with in multiclass classification, and, thus, we leave re-laxing Assumption 3.2 for future work.
 The work of Steinwart ( 2007 ) provides a general treat-ment of calibration and calibration functions, and as an example recovers and extends the results of Bartlett et al. ( 2006 ) for the binary cost-sensitive scenario. Proposition 3.1 , which is the starting point of our work on calibration functions for multiclass classification, is a special case of Lemma 2.9 of Steinwart ( 2007 ). Some of the examples of calibration functions in Table 1 were originally presented in Steinwart ( 2007 ).
 For multiclass classification, Tewari &amp; Bartlett ( 2007 ) furthered the work of Zhang ( 2004 ) and showed that the surrogate loss we study in this paper is consis-tent ( i.e. , calibrated) in ordinary multiclass classifica-tion. They presented an asymptotic convergence re-sult, guaranteeing that a minimizer of R  X  ( h )w.r.t. h also minimizes R ( f  X  h ) (an existential proof for a cali-bration function). Liu ( 2007 ) also provided calibration and non-calibration existential proofs. Along these lines, Guruprasad &amp; Agarwal ( 2012 ) investigated con-ditions for the existence of surrogate losses that are calibrated w.r.t. a generalized notion of a true loss that encompasses the cost-sensitive 0-1-like labelling cost. Their results are also proofs of calibration without ex-plicit calculation of calibration functions.
 The work of Chen &amp; Sun ( 2006 ) is the closest in na-ture to our results. However, their results are for or-dinary multiclass classification and the assumptions they make are stronger. They require  X  to be di ff eren-tiable, convex, and increasing with lim s  X  X  X  X   X  ( s )=0 and lim s  X  X  X   X  ( s )=  X  . Moreover, the minimizer of t  X  K k =1  X  k  X  ( t k )mustexistover C . It is possible to show that their Condition (3), which is essential to their main result via Condition (6), is equivalent to assuming that there exist  X   X  1 and  X   X  0 s.t. for all  X  &gt; 0, inf t  X  C  X  (  X  j corresponds to assuming that  X  (  X  )=  X  (  X  j calibration function for ( L  X  f 1 ,L  X  2 ). As a result, verify-ing Condition (6) of Chen &amp; Sun ( 2006 ) is not simpler APPENDIX X  X UPPLEMENTARY MATERIAL respective results are re-stated for ease of reference. Proposition 3.1. For each  X   X  0 , let and for  X  &gt; 0 , let shows that  X  max is indeed a calibration function. for all  X  &gt; 0 ,i  X  I function. Indeed,  X  is positive, and for all i  X  I holds i ff for every I  X  { 1 ,...,K } , we have inf t  X  C : Proof of Proposition 3.2 . For any I  X  { 1 ,...,K } ,wehave Since  X  X  X  &lt;  X  (0) &lt;  X  ,ifthereexists I  X  { 1 ,...,K } s.t. then Conversely, if for all I  X  { 1 ,...,K } we have then, in particular, we have it for I = { 1 ,...,K } , and so Then for it holds that  X   X  M (  X  )= { ( s,  X  s ): s&gt; 0 } ,so Using linear lower bounds for s  X   X  ( s ), s  X   X  (  X  s ) at 0, In particular, this holds for z = 0, so which contradicts ( 7 ), and so 0 /  X   X  X  (0) Proof of Lemma 3.4 . Consider t  X  C\M (  X  ): t j For t  X  C ,let  X   X  t =  X  1 j 0 ,t m = t m for k  X  j  X  and m&gt;j  X  , m = i .Then and so, because  X  is non-decreasing, From this we conclude that Since the equality in the lemma follows.
 otherwise let where s  X  = max { argmin s  X  ( s ) } .Then, for any  X   X  0 , we have  X  and Hence, and the result follows.
 and define Then Therefore, we obtain that lemma can be obtained from the above through Lemma 3.5 . Then for all  X  &gt; 0 and t  X  C ,italsoholdsthat Proof of Lemma 3.7 . We have Given that  X  is non-decreasing, from Lemma 3.4 we get that fying Assumption 2.1 . Then for all  X   X  0 Hence, and our result follows.
 where q k is the k -th row of Q .
 Then, for all  X  &gt; 0 and w  X  R K  X  1 ,itholdsthat implies  X  f Since  X  (  X  )=  X  (  X  j  X  Proposition 4.2. The columns of a simplex-coding matrix C span C . showing that for i = j and for 1  X  i  X  K that for all  X  &gt; 0s.t. j  X  exists,  X  (  X  )=  X   X  (  X  1 ,  X  j calculating  X   X  (  X  1 ,  X  2 )when  X  1 =  X  2 because  X  j and 3.2 are satisfied.
 We have that where So Since  X  (0) = 1,  X   X  (  X  1 ,  X  2 )=  X  2  X   X  1 . and 3.2 are satisfied.
  X  (  X  1 ,  X  2 )=  X   X  (  X  1 ,  X  2 )=  X  2  X   X  1 , from Proposition C.1 . and 3.2 are satisfied.
 di ff erentiable, we know that so and 3.2 are satisfied.
 and, if  X  1 &gt; 0 , then  X   X  (  X  1 ,  X  2 )=(  X  so which implies s  X  = 1 2 ln  X  2  X  The second statement is easy to verify from the above. for a, b &gt; 0 .
 e so which implies s  X  =ln  X  2  X 
