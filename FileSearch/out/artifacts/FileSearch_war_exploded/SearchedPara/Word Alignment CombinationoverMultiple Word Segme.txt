 Word segmentation is the first step prior to word alignment for building statistical machine transl a-t ions (SMT) on language pairs without explicit word boundaries such as Chinese -English. Many works have focused on the improvement of word alignment models. (Brown et al., 1993; Haghighi et al., 2009; Liu et al., 2010) . M ost of the word alignment model s ta ke single word segmentation as input. However , f or languages such as Chinese, it is necessary to segment sentences into appropr i-ate words for word alignment.

A l arge amoun t of work s have stressed the i m-pact of word segmentation on word alignment . Xu et al. (2004), Ma et al. (2007), Ch a ng et al. (200 8 ) , and Chung et al. (2009) tr y to learn word segme n-tation from bilin gually motivated point of view; they use an initial alignment to learn word segme n-tation appropriate for SMT . H owever, the ir pe r-formance is lim ited by the quality of the initial alignment s , and the process es are time -consuming . S ome other methods try to combine multiple word segmentation at SMT decoding step (Xu et al., 2005; Dyer et al., 2008; Zhang et al., 2008; Dyer et al., 2009; Xiao et al., 2010) . D ifferent segment a-tion s are yet independently used for word alig n-ment .

Instead of time -consuming segmentation optim i-zation based on alignment or postpon ing segment a-tion combination late till SMT decoding phase , we try to combine word alignments over multiple monolin gually motivated word segmentation on Chinese -English pair , in order to improve word alignment quality and translation performance for all segmentation s . We introduce a tabular structure called w ord s egmentation n etwork (WSN for short ) to encode multiple segmentations of a Chinese se n-tence , and define skeleton l inks (SL for short) b e-tween spans of WSN and word s of English sentence . The c onfidence score of a SL is defined over multiple segmen tations. O ur combination a l-gorithm picks up potent ial SLs based on their co n-fidence scores similar to Xiang et al. (2010), and then project s each selected SL to l ink in all se g-mentation respectively . Our algorithm is simple, eff i cient, easy to implement, and can effectively improve word alignment quality on all segment a-tions simultane ously, and a lignment errors caused by inappropriate segmentations from single se g-menter can be substantially reduced .

Two questions will be answered in the paper: 1) h ow to define the link confidence over multiple segmentation s in combination algorithm ? 2) A c-cording to Xiang et al. (2010) , t he success of their word alignment combination of different models lies in the complementary information that the candidate alignments contain. In our work, are multiple monolingually motiva ted segmentations complementary enough to improve the alignments? The rest of this paper is structured as follows : WSN will be introduced in section 2. Combination algorithm will be presented in section 3. Exper i-ments of word alignment and SMT will be repo rted in section 4. We propose a new structure called word segment a-tion network (WSN) to encode multiple segment a-tions. Due to space limitation, all definition s are presented by illustration of a running example of a sentence pa ir:  X  X  X  X  X  ( xia -yu -lu -hua ) Road is slippery when rain ing
We first introduce skeleton segmentation . Given two segmentation S 1 and S 2 in Table 1, the word boundaries of their skeleton segmentation is the union of word boundarie s (marked by  X  /  X  ) in S 1 and S 2 .

Table 1 : T he skeleton segmentation of two se g-
The WSN of S 1 and S 2 is shown in Table 2. As is depicted, line 1 and 2 represent words in S 1 an d S 2 respectively, line 3 represents skeleton words . E ach column, or span , comprises a skeleton word and words of S 1 and S 2 with the skeleton word as their morphemes at that position. The number of col u mns of a WSN is equal to the number of skel e-ton words. It should be noted that there may be words covering two or more span s, such as  X   X  X   X  in S 1 , because the word  X   X  X   X  in S 1 is split into two words  X   X   X  and  X   X   X  in S 2 .

The skeleton wor d can be project ed onto word s in the same span in S 1 and S 2 . For clarity, w ords in each segmentation are indexed (1 -based), for e x-ample,  X   X  X   X  in S 1 is indexed by 3 . We use a pr o-jection fu n ction t o denote the index of the word onto which the j -t h skeleton word is projec t-ed in the k -th segmentation, for example, and .

In the next, we define the links between spans of the WSN and English words as skeleton links (SL), the subset of all SLs comprise the skeleton alig n-ment (SA). Figure 1 shows an SA of the example. Figure 1 : An example alignment between WSN in Table 2 and English sentence  X  Road is slippery when rain ing  X  . ( a) skeleton link; ( b) skeleton alignment .

E ach span of the WSN comprises word s f rom different segmentations ( Figure 1a ) , which ind i-cates that the confidence score of a SL can be d e-fined over words in the same span. By projection function, a SL can be projected onto the link for each segmentation. Therefore , the problem of combining wo rd alignment over different segme n-tations can be transformed into the problem of s e-lecting SLs for SA first , and then project the selected SLs on to links for each segmentation r e-spectively .
Given k alignment s over segmentat ions respectively ) , and is the pair of the Chinese WSN and its parallel English se n-tence. S uppose is the SL between the j -th span and i -th English word , is the link between the j -th Chinese word in and . Inspired by Huang (20 09 ) , we define the confidence score of each SL as follows where is the confidence score of the link , defined as w here c -to -e link posterior probability is defined as and I is the length of . E -to -c link posterior pro b-ability ( | ) can be defined similar ly , 
Our alignment combination algorithm is as fo l-lows. 1. Build WSN for Chinese sentence . 2. Compute the confidence score for each SL 3. All SLs in are sorted in descending order 4. Repeat 3 until no more SLs can be included. 5. Map SLs in on each to get k new alig n-
The h euristic in step 3 is similar to Xiang et al. (2010), which avoids adding error -p r one links. We a p ply the similar heuristic again in step 5 in each weights in Eq. (1) and can be tuned in a hand -aligned dataset to maxi m ize word alignment F -score on any with hill climbing algorithm. Probabil ities in Eq. (2) and Eq. ( 3) can be estima t-ed using GIZA . 4.1 Data Our training set contains about 190K Chinese -English sentence pairs from LDC2003E14 corpus. The NIST  X  06 test set is used as our development set and the NIST  X  08 test set is used as our test set. The Chinese portions of all the data are prepr o-cessed by three monolingually motived segmenters respectively. These segmenters differ in either training method or specification , including ICTCLAS (I) 3 , Stanford segmenters with CTB (C) and PKU (P) specifications 4 respectively . We use d a phrase -based MT system similar to (Koehn et al., 2003), and generate d two baseline alignment s u s-ing GIZA++ enhanced by gdf heuristics (Koehn et al., 2003) and a linear discriminative word alig n-ment model (DI WA) (Liu et al., 2010) on training set with the three segmentations respectively . A 5 -gram language model trained from the Xinhua po r-tion of Gigaword corpus was used . The decoding weight s were optimized with Minimum Error Rate Training (MERT) (Och, 2003). W e use d the hand -aligned set of 491 sentence pairs in Haghighi et al. (2009) , the first 250 sentence pairs were used to tune the weight s in Eq. (1), and the other 241 were used to measure the word alignment quality . Note that we adapted the Chinese portio n of th is hand -aligned set to segmentation C . 4.2 Improvement of Word Alignment We first evaluate our combination approach on the hand -aligned set ( on segmentation C ) . Table 3 shows the precision, recall and F -score of baseline alignment s and combined alignmen t s .

A s shown in Table 3 , the combination alig n-ment s outperformed the baseline s (setting C ) in all settings in both GIZA and DIWA. We notice that the higher F -score is mainly due to the higher pr e-cision in GIZA but higher recall in DIWA. In GIZA, the resu lt of C+I and C+P achiev e 8.4% and 9.5% higher F -score respectively , and both of them outperformed C+P+I, we speculat e it is because GIZA favors recall rather than DIWA , i.e. GIZA may contain more bad links than DIWA, which would lead to more unstable F -sc ore if more alignments produced by GIZA are combined , just as the poor precision (69.68%) indicated . However, DIWA favors precision than recall ( this observ a-tion is consistent with Liu et al. (2010)), which may explain that the more diversified segment a-tio ns lead to better results in DIWA.
 Table 3 : Alignment p re cision, recall and F -score. 
Figure 2 gives baseline alignments and co m-bined alignments on two sentence pairs in the trai n ing data . As can be seen, a lignment errors caused by inappropriate segmentations by single segmenter were substantially reduced. For exa m-ple, in the second example , the word  X   X  X  X  X  X  X  X   X  X  X  hksar X  ap pears in segmentation I of the Ch i-nese sentence , which benefit s the generation of the three correct links connecting for words  X   X   X   X  ,  X   X  X  X   X  ,  X   X  X  X  X   X  respect ively in the co m-bined alignment. 4.3 Improvement in MT performance We then evaluate ou r combination approach on the SMT training data on all segmentations. For eff i-ciency, we just use d the first 50 k sentence pairs of the aligned training corpus with the three segme n-tations to build three SMT systems respectively . Table 4 shows the BLEU scor es of baseline s and combined alignment ( C+P+I, and then projected on to C, P, I respectively) . O ur approach achieves improvement over baseline alignments on all se g-mentations consistent ly , without using any lattice decoding techniques as Dyer et al. ( 2009) . The gain of translation performance purely comes from improvements of word alignment on all segment a-tions by our proposed word alignment combination . Table 4: Improvement in BLEU scores . B:B aseline 5 Conclusion W e evaluate d our word alignment combination over three monolingually motivated segmentation s on Chinese -English pair . We showed that the co m-bined alignment significantly outperforms the baseline alignment with both higher F -score and higher BLEU score on all segmentations . Our work also proved the effectiveness of link conf i dence score in combining different word alig n ment mo d-els (Xiang et al., 2010), and extend it to co m bi n e word alignments over different segment a tions .
Xu et al. (2005) and Dyer et al. (2009) combine different segmentations for SMT . T hey aim to achieve better translation but not higher alignment quality of all segment ation s . They combine mu l t i-ple segmentations at SMT decoding step , while we combine segmentation alternatives at word alig n-ment step. We believe that we can further i m prove the performance by combining these two kinds of works. We also believe that combining word alignments over both monolingually motiva t ed and bilingually motivated segmentations ( Ma et al. , 2009 ) can achieve higher performance.

In the future, w e will investigate combining word alignments on language pairs where both languages have no explici t word boundaries such as Chinese -Japanese.
 This work was supported by the National Natural Science Foundation of China under Grant No. 61003112, and the National Fundamental Research Program of China (2010CB327903) . We would like to thank Xiuyi Jia and Shujie Liu for useful discussions and the anonymous reviewers for their constructive comments.

