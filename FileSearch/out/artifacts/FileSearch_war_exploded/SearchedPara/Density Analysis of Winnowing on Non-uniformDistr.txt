 For kinds of reasons, digital documents are copied completely or partially. Web sites are mirrored. Some students plagiarize their homework or papers from the Web. The increasing copies make detecting duplicates among a set of digital documents an important problem.

Full copies of documents can be easily de tected by comparing document check-sums. As to partial copy detection, it is not trivial. Many techniques have been proposed to address the problem, such as [1,2,3,4]. Most of them use the follow-ing idea: Store small sketch of document, i.e. fingerprints of document, so that by comparing the fingerprints between two documents, copies can be identified. In these methods, it is vital for fingerprinting algorithms to select representa-tive fingerprints, because they have to find copies without knowing, in advance, which documents and which parts of document are involved. It is also important for fingerprinting algorithms to have h igh performance, i.e. to select as small fingerprints as possible, if recall that there are usually a great deal of documents to be compared with in a real system.

Among fingerprinting algorithms proposed so far, Winnowing [5] is one of the most efficient. Winnowing is a fingerprinting algorithm based on k-grams and selects some hashes of k-gram as fingerprints of document. Compared with other fingerprinting algorithms, it provides guarantee to detect copies longer than a user predefined length. This makes fingerprints selected by Winnowing representative, and thus makes the detection results more reliable.

In order to measure performance of Winnowing, density , which is defined by (1), is used: where E[  X  ] denotes expectation over distribution of k-grams . The previous den-sity analysis of Winnowing needs uniformly distributed k-grams [5]. But the as-sumption of uniformity seems too strong for real data. Instead, more and more researchers report highly non-uniform distributions [5,6,7,8,9]. The gap leaves behavior of Winnowing unwarranted in real systems and separates theory from reality. From the view of practice, it would be valuable to predict behavior of Winnowing on highly non-uniformly distributed data effectively. Using the pre-diction, copy detection s ystems can be optimized. So the questions whether we can theoretically predict the density of Winnowing on highly non-uniformly dis-tributed data and the above prediction, if any, can work on real data, may be asked. We will answer these questions in this paper. Our contributions are the following:  X  We carry out a careful theoretical study that expands the applicability of  X  We verify the theoretical results with extensive experiments using both ar-
The rest of the paper is organized as follo ws. The next section describes back-ground and related work. In section 3, we provide our theoretical density analysis method of Winnowing. In Section 4, exper imental results which verify the the-oretical findings are given. Section 5 is concludes. Winnowing is a fingerprinting algorithm based on k-grams .A k-gram is a con-tiguous character sequence of length k .Distinct k-grams may overlap, and there are almost as many k-grams as characters in document. Fig. 1(a-c) gives an example.

In Winnowing, there are two user specified parameters, k and t ( k t ), to control the process of fingerprinting. Parameter k is called noise threshold .Any duplicate shorter than k will not be detected. Parameter t is called guarantee threshold . Any duplicate longer than t is guaranteed to be found. Winnowing avoid matching duplicates shorter than noise threshold by considering hashes of k-gram . Many hash functions can be used here, such as MD5 [10]. But the most popular is Rabin X  X  algorithm [11], because of it X  X  computational efficiency. Fig. 1(d) shows hashes of 7-grams in Fig. 1(c), calculated by a hypothetical hash function. To provide the detection guarantee, Winnowing uses the idea of local algorithms , which select fingerprints depending only on the contents of a local window. The local property guarantees that the same fingerprints are selected no matter where window appears. Specifically, in Winnowing, a sliding window of size w is used, where w = t  X  k +1, and window of size w is defined to be w contiguous hashes. As the window starting from the beginning of document slides hash by hash, Winnowing selects the minimum hash in each window (If there are more than one minimum hashes , select the rightmost). This means that, for any contiguous t characters in document, at least one fingerprint is selected, and duplicates containing th em can be detected. Note that the same hash may be selected from adjacent windo ws, only distinct hashes are stored as fingerprints. This process is illustrated in Fig. 1(e-f).

Assume independent and uniformly distributed input k-grams . The density of Winnowing can be associated with w , the size of windows. In this case, the density of Winnowing is 2 w +1 , given that the possibility of multiple minimum hashes appear in a small window can be ignored [5].

Uniform distribution simplifies analysis, but the assumption seems so strong that real data collections ca n seldom satisfy. Instead, many researchers report highly non-uniform distributions of real data. Zipf observed that frequency of occurrence of words in English documents, as a function of the rank when the rank is determined by the above frequency of occurrence, is a power-law function with the exponent close to -1 [7]. According to [8,9], other language and language unit can also be charactered by Zipf X  X  Law. Furthermore, power-law relationship between frequency and rank is observed in data collections consisting of Web pages [5], contents of packets traveling through networks [6], and so on. It seems that, in real data collections, power law phenomenon, which means the distribu-tion is far from uniform, is pervasive. These observations leaves the performance of Winnowing in practice unwarranted. Designers of copy detection system are not sure how Winnowing will behave in their systems.
 In this section, our theoretical density analysis of Winnowing will be given. Now, lets X  introduce Lemma 1 as start.
 Lemma 1. Assume that h 1 ,h 2 ,  X  X  X  ,h n are independent and identically distri-buted random variables, whose sample space are Z , a finite subset of integer. Then P that h i takes the smallest value within sample point in joint sample space Z n .  X  and get the same integer sequence. It is obvious that R is an equivalence relation. So Z n can be divided into equivalence classes E 1 ,E 2 ,  X  X  X  ,E Q by R ,where Q is the number of equivalence classes.
 1 i n and 1 j n ,where | S m , i | and | S m , j | denote cardinality of S m , i and S m , j individually. To prove this, assume By definition of S m , i ,  X  h i must be the smallest integer within  X  h . Exchange  X  h i the above exchange, we get two new sample points  X  h and  X  h .  X  h and  X  h must |
S
Consider the definition of E m and the independent and identically distributed random variables. In any given E m , the probability that each sample point occurs  X  X  X  = P ( S P Theorem 1. Given input hashes h 1 ,h 2 ,  X  X  X  ,h n ,  X  X  X  , if the hashes are indepen-dently and identically distributed, the density of Winnowing is 2 w +1 ,provided that the probability that there are more than one smallest hash among contigu-ous w +1 input hashes is small enough to be ignored.
 Proof. Consider the function FS that maps the position of window, which is defined to be the position of leftmost hash in it, to the position of fingerprint the window selected. We say function FS is monotonic increasing, namely if i&lt;j ,then FS ( i ) FS ( j ). To prove this, consider two cases. If windows W i and W j do not overlap, FS ( i ) is less than the position of any hash in W j .So maximum value of FS ( i )is q ,where q is the position of minimum hash among h ,  X  X  X  ,h i+w  X  1 ; On the contrary, the minimum value of FS ( j )isalso q .This means FS ( i ) FS ( j ). Thus the function FS is monotonic increasing.
Consider an indicator random variable X i that is one iff W i selects a fingerprint which is not selected by any previous window. Consider two contiguous windows W  X  1 and W i . The two windows overlap except the leftmost hash h i  X  1 and the rightmost hash h i+w  X  1 . Consider the position p containing the smallest hash in h  X  1 ,h i ,  X  X  X  ,h i+w  X  1 . There are three cases: a). If p = i  X  1, then W i  X  1 selects it and W i must select another position q , b). If p = i + w  X  1, then W i selects it. Because W i is the first window containing c). If i  X  1 &lt;p&lt;i + w  X  1, both W i  X  1 and W i select it. So W i cannot be the
The first two cases happen with probability P min ( h i  X  1 )and P min ( h i+w  X  1 ), in P than one smallest hash in contiguous w + 1 hashes can be ignored. The above w +1 . Recall that the sum of the expected values is the expected value of the sum, even if the random variables are not independent. Therefore, we get the density. 4.1 Experiments with Artificial Data In this set of experiments, we use artific ial data which are randomly generated hashes. The purpose of the experiments is to verify our method on non-uniformly distributed data in ideal cases.
 In the experiments, normal, exponential and uniform distributions are used. All hashes involved are generated by pseudo-random number generators inde-pendently. Every experiment here is carried out in the following way: Generate hash sequence of length 10 8 ; Perform Winnowing fingerprinting with commonly used window sizes; Repeat 100 times and get the average. The experiment results are shown in Table 1. The first column of the table gives sizes of window used by Winnowing. The second to the fourth columns show relative deviations of ob-served densities from theoretical predictions on uniform, normal and exponential distributions individually. Relative deviations are calculated by: From the table, we can see the deviations are quite small in all cases. Note that, this is true not only on uniform distribution, but also on non-uniform distributions. This result fits our theoretical predictions perfectly, and which in turn implies that performance of Winnowing on non-uniform distributions can be predicted by our method.

According to our theorem, no significa nt performance difference should be observed between uniformly and non-uniformly distributed hashes. In order to verify this conclusion, paired t-tests are conducted. We calculate t-statistics be-tween densities of 100 runs on uniformly distributed hashes and densities of 100 runs on non-uniformly distributed hashes, etc. normally and exponentially distributed hashes. If set significant level to be 0 . 05, the hypotheses that no sig-nificant differences occur can be accepted s afely. (We don X  X  report the calculated t-statistics just for space constraint). 4.2 Experiments with Real Data TDT-5(Topic Detection and Tracking) [13 ] is chosen as test collection in this set of experiments (We also conduct exp eriments on Reuters-21578, Request for Comments (RFC) documents and TDT-4, but don X  X  report the results for space constraint). TDT-5 is used for evaluation of topic detection and tracking. The sources of it include radio and television broadcasts as well as newswire services. TDT-5 is a multilingual collection. We only use all English documents of it, about 600MB in size, for only a simple preprocessor of documents is employed in our experiments.

Before the experiments, we are interested in how k-grams in TDT-5 are dis-tributed. We elaborately co mpute frequency of every k-gram occurring in TDT-5 for distinct k , i.e. 16, 32, 48 and 64; Then sort k-grams according to frequency in monotonically decreasing order; Take the position of a k-gram in the ordered list as it X  X  rank. We plot the frequency-rank relations in log-log scale, as what is showninFig.2(Ifmorethanone k-grams have the same frequency, only the first k-gram and the last k-gram of that frequency in the ordered list are plotted, and the two points are linked by a dashed). From the figure, highly non-uniformly distributed k-grams are observed. The distributions of k-grams vary greatly with different values of k . For all values of k , power law relation between frequency and rank is exhibited. At the same time, one can find that smaller k makes k-gram of the same rank higher frequency. This is because small k tends to make k-grams repeated frequently.

As in previous sectio n, we calculate relative density deviations for different k and different window size. The results are listed in Table 2. From the tables, we find the experimental results agree wi th our theoretical predictions well. Compared with artificial data, relatively large deviations are found. One reason may be the assumption of independent and identical distribution of all k-grams . In real documents, k-grams are not completely independently and identically distributed. For example, there are idioms of language, and there are some rela-tionships and differences among different paragraphs of document.

Another factor that may influence the densities is the tie hashes. This is because in our theorem the probability that tie minimum hashes occur should be small. We count the number of windows, size of w + 1, within which tie minimum hashes are observed. The results are illustrated in Fig. 3. In the figure, we plot rate of window that tie occur as function of window size. From the figure, We find something interesting. First, the rates of tie window increase with increasing window sizes. This may be caused by the rea son that the same tie hashes appear in more windows if window size is large. Another interesting thing is that the rates are sensitive to the value of k .When k increases, the rates are decreased in general. If K&gt; 32, the influence of k is relatively small. The reason may be that larger k makes the probability of tie smaller. These findings suggest something valuable: From the point of tie hashes, small size of window with large k trends to make the theoretical prediction of density precise. In this paper, an improved density analysis method of Winnowing is proposed. The new method removes the strong assumption of uniformly distributed k-grams from the previous. Instead, only identical distribution is required. Using the weaker assumption, our method can be safely used on highly non-uniformly distributed data which seems common in pra ctice. Finally, we report experiments on artificial data and real data. The experiment results verify our theoretical findings.

