 Jialei Wang jl.wang@ntu.edu.sg Peilin Zhao zhao0106@ntu.edu.sg Steven C.H. Hoi chhoi@ntu.edu.sg Online learning algorithms ( Rosenblatt , 1958 ; Crammer et al. , 2006 ; Jin et al. , 2010 ; Zhao et al. , 2011a ; b ) represent a family of fast and simple machine learning techniques, which usually make few statistical assumptions and can be applied to a wide range of applications ( Li et al. , 2012 ). Online learning has been actively studied in machine learning community, in which a variety of online learning algorithms have been proposed, including a number of first-order algorithms such as the well-known Perceptron algo-rithm ( Rosenblatt , 1958 ) and the Passive-Aggressive (PA) algorithms ( Crammer et al. , 2006 ).
 Recent years have seen a surge of stud-ies on the second-order online learning algo-rithms ( Cesa-Bianchi et al. , 2005 ; Dredze et al. , 2008 ; Crammer et al. , 2009b ; Orabona &amp; Crammer , 2010 ; Duchi et al. , 2011 ), which have shown that pa-rameter confidence information can be explored to guide and improve online learning perfor-mance ( Cesa-Bianchi et al. , 2005 ). For example, Confidence-weighted (CW) learning ( Dredze et al. , 2008 ; Crammer et al. , 2009a ) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates ( Dredze et al. , 2008 ). Although CW learning has formal guarantees in the mistake-bound model ( Crammer et al. , 2008 ), it can overfit in certain situations due to its aggressive update rules based upon a separable data assumption. Recently, an improved online algorithm, i.e., Adaptive Regular-ization of Weights (AROW) ( Crammer et al. , 2009b ; Orabona &amp; Crammer , 2010 ), relaxes such separable assumption by employing an adaptive regularization for each training example based upon its current confidence. This regularization comes in the form of minimizing a combination of the Kullback-Leibler divergence between Gaussian distributed weight vectors and a confidence penalty of vectors. Although AROW is able to improve the original CW learning by handling noisy and non-separable cases, it is not the exact corresponding soft extending part of CW (Like PA with PA-I and PA-II). In particu-lar, the directly added loss and confidence regular-ization make AROW lose an important property of Confidence-weighted learning, i.e., Adaptive Margin property. Following the similar idea of soft margin support vector machines, the adaptive margin assigns different margins for different instances via a proba-bility formulation, which enables CW to gain extra efficiency and effectiveness.
 In this work, we extend the confidence-weighted learn-ing for soft margin learning, which makes our Soft Confidence-Weighted (SCW) learning method more robust than the original CW learning when handling noisy and non-separable data, and more effective and efficient than the state-of-the-art AROW algorithm. The rest of this paper is organized as follows. Sec-tion 2 reviews related work. Section 3 proposes the soft confidence-weighted learning method. Section 4 analyzes the mistake bounds and properties of our al-gorithms. Section 5 conducts an extensive set of em-pirical experiments, and Section 6 concludes this work. 2.1. Overview of Online Learning Online learning operates on a sequence of data exam-ples with time stamps. At time step t , the algorithm processes an incoming example x t  X  R d by first pre-the true label y t  X  { X  1 , +1 } is revealed and then the the loss is used to update the weights of the model based on some criterion. Overall, the goal of online learning is to minimize the cumulative mistake over the entire sequence of data examples.
 Our work is closely related to several first and second order online learning algorithms, including Passive-Aggressive (PA) learning ( Crammer et al. , 2006 ), Confidence-Weighted learning ( Dredze et al. , 2008 ), and Adaptive Regularization of Weights learn-ing ( Crammer et al. , 2009b ). Below we review the ba-sics of these algorithms. 2.2. Passive-Aggressive Learning As the state-of-the-art first order online learning al-gorithm, the optimization of Passive-Aggressive (PA) learning is formulated as: w where the loss function is based on the hinge loss:  X  ( w ; ( x t ,y t )) = The above optimization has the closed-form solution: to handle non-separable instances and more robust, a slack variable  X  was introduced into the optimiza-tion ( 1 ) using one of two types of penalty: linear and quadratic, leading to the following two formulations of soft-margin PA algorithms: w t +1 = arg min where C is a parameter to tradeoff between passiveness and aggressiveness. The resulting weight updates to the soft-margin PA algorithms have the same form as that of ( 2 ), but different coefficients  X  t as follows:  X  t = min { C, 2.3. Confidence-Weighted Learning To better exploring the underlying structure between features, the Confidence-Weighted (CW) learning al-gorithm assumes a Gaussian distribution of weights with mean vector  X  R d and covariance matrix  X   X  R d  X  d . The weight distribution is updated by minimizing the Kullback-Leibler divergence between the new weight distribution and the old one while en-suring that the probability of correct classfication is greater than a threshold as follows: ( This optimization problem has a closed-form solution The updating coefficients are calculated as follows:  X  t = max 0 , x lative function of the normal distribution),  X  = 1+  X  2 2 and  X  = 1 +  X  2 . 2.4. Adaptive Regularization of Weights Unlike the original CW learning algorithm, the Adap-tive Regularization Of Weights (AROW) learning introduces adaptive regularization of the prediction function when processing a new instance in each learn-ing step, making it more robust than CW to sudden changes of label noise in the learning tasks. In partic-ular, the optimization of AROW is formulated as: ( is a regularization parameter. The optimization has a closed-form solution similar with CW of ( 3 ), but dif-ferent updating coefficients: In this section we present a new online learning method that aims to address the limitation of the CW and AROW learning. Following the same problem settings of the Confidence-Weighted learning, we assume the weight vector w follows the Gaussian distribution with the mean vector and the covariance matrix  X . Notice that the probability constraint in the CW learning, i.e., Pr w  X  X  ( ,  X ) [ y t ( w x t )  X  0]  X   X  can be rewritten as where  X  =  X   X  1 (  X  ). Further, we introduce a loss func-tion as follows:  X   X  N ( ,  X ); ( x t ,y t ) = max 0 , X  q x  X  It is easy to verify that satisfying the probability con-is equivalent to satisfying  X   X  N ( ,  X ); ( x t ,y t ) = 0. Therefore, the optimization problem of the original CW can be re-written as follows ( The original CW learning method employs a very ag-gressive updating strategy by changing the distribu-tion as much as necessary to satisfy the constraint imposed by the current example. Although it results in the rapid learning effect, it could force to wrongly change the parameters of the distribution dramatically when handling a mislabeled instance. Such undesir-able property makes the original CW algorithm per-forms poorly in many real-world applications with rel-atively large noise.
 To overcome the above limitation of the CW learn-ing problem, we propose a Soft Confidence-Weighted (SCW) learning method, which aims to soften the ag-gressiveness of the CW updating strategy. The idea of the SCW learning is inspired by the variants of PA algorithms (PA-I and PA-II) and the adaptive margin. In particular, we formulate the optimization of SCW for learning the soft-margin classifiers as follows: where C is a parameter to tradeoff the passiveness and aggressiveness. We denoted the above formulation of the Soft Confidence-Weighted algorithm, as  X  X CW-I X  for short. Similar to the variant of PA, we can also modify the above formulation by employing a squared penalty, leading to the second formulation of SCW learning (denoted as  X  X CW-II X  for short): For the optimization of SCW-I, the following proposi-tion gives the closed-form solution.
 Proposition 1. The closed-form solution of the opti-mization problem ( 4 ) is expressed as follows: where the updating coefficients are as follows:  X  t = min { C, max { 0 ,  X  x
T  X  t x t , m t = y t ( t x t ) ,  X  =  X   X  1 (  X  ) ,  X  = 1 +  X  = 1 +  X  2 .
 Similarly, the following proposition gives the closed-form solution to the optimization of SCW-II. Proposition 2. The closed-form solution of the opti-mization problem ( 5 ) is: The updating coefficients are as follows:  X  The detailed proofs of Proposition 1 and 2 can be found in Appendix section. Finally, Algorithm 1 sum-marizes the proposed SCW-I and SCW-II algorithms. We first give an overview about the comparison of the proposed SCW methods with respect to several exist-ing first-order and second-order online learning algo-rithms, followed by the discussions on the nonlinear extension and the bound analysis.
 Algorithm 1 SCW learning algorithms ( SCW ) INPUT: parameters C &gt; 0,  X  &gt; 0.

INITIALIZATION: 0 = (0 ,..., 0)  X  ,  X  0 = I . for t = 1 ,...,T do end for 4.1. Comparison with the existing methods Following the study of AROW, we qualitatively exam-ine the properties of different algorithms in Table 1 . Unlike the previous second-order algorithms, the pro-posed SCW algorithm enjoys all the four salient prop-erties. In particular, SCW improves over the origi-nal CW algorithm by adding the capability to handle the non-separable cases, and improves over AROW by adding the adaptive margin property. To the best of our knowledge, SCW is the first second-order online learning that holds all the four properties. 4.2. Extension to Nonlinear Cases Similar to other linear online learning methods, the proposed SCW learning can be extended to nonlinear cases. The following lemma shows the possibility of extending the proposed SCW algorithms to nonlinear cases using kernel tricks.
 Lemma 1. (Representer Theorem) The mean i and covariance  X  i parameters computed by the soft confidence weight algorithm can be written as linear combinations of the input vectors with coef-vectors, i.e.,  X   X   X   X  The above lemma can be proved by induction similar to the proof in ( Crammer et al. , 2008 ). 4.3. Analysis of the Loss Bound Our analysis begins with the definition of confidence loss, which is used in ( Crammer et al. , 2008 ). The loss is a function of the margin m i normalized by  X  v , i.e.,  X  m i = m i  X  v in ( Crammer et al. , 2008 ) as an upper-bounded loss by:  X  that the loss  X   X  (  X  m ) holds the properties of Lemma 5 in ( Crammer et al. , 2008 ) for SCW-I.
 We have the following loss bound.
 quence for SCW-I. Assume there exist  X  and  X   X  such that for all i for which the algorithm made an update (  X  i &gt; 0) , Then the following bound holds: The above theorem can be proved by applying Lemma 7 and property 6 in Lemma 5 in ( Crammer et al. , 2008 ). If we let  X   X  by choosing an appropriate C , then our mistake num-ber is also bounded by (1 +  X  2 ) 5.1. Datasets and compared algorithms We adopt a variety of datasets from different domains:  X  synthetic data: we generated this data set  X  Digital recognition: we use two benchmarks:  X  Face data: we use the MIT-CBCL face imags 3 .  X  Machine Learning datasets: we randomly choose Table 2 shows the statistics of the list of datasets used. We compare our methods with various online learning algorithms, including Perceptron ( Rosenblatt , 1958 ), PA ( Crammer et al. , 2006 ), ROMMA ( Li &amp; Long , 1999 ) and its aggressive version agg-ROMMA, Second-Order Perceptron ( Cesa-Bianchi et al. , 2005 ), Confi-dence Weighted Learning ( Crammer et al. , 2008 ), Im-proved Ellipsoid Method for Online Learning(IELLIP) ( Yang et al. , 2009 ), AROW ( Crammer et al. , 2009b ), Normal HERD (NHERD) ( Crammer &amp; D.Lee , 2010 ) and NAROW ( Orabona &amp; Crammer , 2010 ). Fol-lowing the similar parameter setting methods in ( Dredze et al. , 2008 ) and ( Crammer et al. , 2009b ). The parameter r in AROW, paramter b in NAROW and parameters C in PA-I, PA-II, NHERD, SCW-I and SCW-II are all determined by cross validation to select the best one from { 2  X  4 , 2  X  3 ,..., 2 3 , 2 parameter  X  in CW, SCW-I and SCW-II are deter-mined by cross validation to select the best one from determined by cross validation to select the best one determined, all the experiments were conducted over 20 random permutations for each dataset. All the re-sults were reported by averaging over these 20 runs. We evaluate the performance by three metrics: (i) on-line cumulative mistake rate, (ii) number of updates (which would be closely related to the potential num-ber of support vectors in kernel extension), and (iii) running time cost. 5.2. Experimental Results Table 3 summarizes the results of our empirical evalu-ation, where we only show margin-based second-order learning algorithms due to space limitation. For a more complete comparison, please refer to our sup-plemental material. The bold elements indicate the best performance with paired t-test at 95% significance level. We can draw several observations as follows. First of all, by examining the overall mistakes, we found that second-order algorithms usually outper-forms first-order algorithms, and margin based algo-rithms usually outperforms non-margin based meth-ods. This shows the efficacy of  X  X arge Margin X  and  X  X onfidence X  properties for learning better classifiers. Second, by examining the original CW algorithm, we found that, it significantly outperforms the first-order algorithms (e.g. Perceptron, ROMMA, and PA al-gorithms) on the synthetic data without noise, but fails to outperform the first-order algorithms on some real-world datasets that often have noisy data. This empirical result verifies the importance of  X  X andling Non-separable X  property in producing robust classi-fiers when dealing with noisy data.
 Further, we found that AROW significantly outper-forms CW in many real-world datasets (except min-ist). However, AROW usually produces considerably more updates and spends more running time than CW. This verifies that the importance of  X  X daptive margin X  property of both CW and SCW to reduce the number of updates as well as the running time.
 Moreover, among all the compared algorithms, SCW often achieves the best or close to the best performance in terms of accuracy, number of updates, and running time cost. Finally, Figure 1 shows the online results of 13 algorithms with respect to varied numbers of samples in online learning process. The results again validate the advantages of SCW in both efficacy and efficiency among all the state-of-the-art algorithms. This paper proposed the Soft Confidence-Weighted (SCW) learning, a new second-order online learning method with state-of-the-art empirical performance. Unlike the existing second-order algorithms, SCW en-joys all the four properties: (i) large margin training, (ii) confidence weighting, (iii) adaptive margin, and (iv) capability of handling non-separable data. Em-pirically, we found the proposed SCW algorithms per-form significantly better than the original CW algo-rithm, and outperform the state-of-the-art AROW al-gorithm for most cases in terms of both accuracy and efficiency. Future work will conduct more in-depth analysis of the mistake bounds and its multi-class ex-tension ( Crammer et al. , 2009a ).
 is easy to see the solution is valid. When  X  timization problem is equivalent to Since P is positive semi-definite (PSD), it can be writ-ten as P =  X  2 to make the optimization with a convex constraint in and  X  simultaneously. But for conve-nient, we will still use  X  instead of  X  2 in the following analysis. The Lagrangian of the above optimization is where  X   X  0 and  X   X  0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables ,  X  and  X  . and C  X   X   X   X  = 0, so  X  = C  X   X   X  C , thus  X   X  [0 ,C ] The KKT conditions for the optimization are: Case 1.  X  6 = 0 As  X  (  X  p x  X  t  X  x t  X  y t x t  X   X  ) = 0 implies (  X  p x y t x t  X   X  ) = 0, the KKT conditions are simplified: Sub-case 1.1.  X  6 = 0 When  X  6 = 0,  X  X  = 0, implies  X  = 0. The KKT condi-tions are simplified as Finally, we have the following: multiplying by x  X  t (left) and x t (right), we get u t = v And  X  p x  X  t  X  x t  X  y t x t = 0 implies  X  can be rearranged as: v 2 t (1+  X  2 )  X  2 +2 m t v t (1+  X  ( m 2 t  X   X  2 v t ). The larger root is then where  X  = m 2 t v 2 t (1 +  X  2 2 ) 2  X  v 2 t (1 +  X  2 )( m If  X   X  (0 ,C ), then  X  = C  X   X   X  (0 ,C ).
 Sub-case 1.2.  X  = 0 C  X   X   X   X  = 0 implies  X  = C . The KKT conditions can be simplified as: We thus have: It is easy to verify that has no solution on [0 , +  X  ) and f  X  (0) =  X   X  2 v t 2  X  v is decreasing on [0 , +  X  ). , which thus implies C  X   X  .
 Case 2.  X  = 0 When  X  = 0, since C  X   X   X   X  = 0,  X  = C , the KKT condtions are simplified as Thus, t +1 = t and  X  t +1 =  X  t ; as a result,  X  p x  X   X   X  N ( ,  X ); ( x t ,y t ) &gt; 0.
 For SCW-II, the Lagrangian of the optimization is where  X   X  0 and  X   X  0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables ,  X  and  X  . and 2 C X   X   X   X   X  = 0, so  X  =  X  +  X  2 C . The KKT conditions for the optimization are: The rest proof is similar to that of SCW-I.
 This work was in part supported by Singapore MOE tier 1 project (RG33/11) and Microsoft Research project (M4060936).

