 Adopting a product line (PL) approach supports companies to foster systematic reuse [1],[2]. However, the transition from single-system development to a PL approach is often non-trivial and costly [3]. PL scoping is an important activity in existing PL engineering processes [2]. Within PL scoping, companies investigate which existing products are potential candidates for a PL. Therefore, they have to identify the com-monality that potential members of the PL share and their variations [4],[5]. Most existing scoping approaches require large upfront investments [6],[7]. Scoping highly depends on the development practices within the organizations, the architecture of the system, and the business domain. In [8] about 16 different scoping approaches and industrial applications have been identified. However, only 6 industrial case studies for these approaches exist. Those approaches aim to deliver a full PL scope while our goal is to deliver a first estimation if further scoping investments are justified. 
According to our experience, small and medium sized companies (SME) would re-quire more lightweight, automated and therefore time and cost-effective approaches highlighted by current research in the agile software engineering domain [7],[9],[10] that emphasis the need for more lightweig ht approaches. However, agile approaches such as the scoping game [7] require the participation of various stakeholders which could also limit its applicability. Within our research we aim at addressing the bes-poke issue by investigating semi-automatic similarity analysis to support PL scoping for configuration-based standard software products. 
In this context we presented a first solution [11], which allows to semi-automatically identify key information on the reuse potential of existing standard software product configurations. Such configurations represent large software prod-ucts such as Enterprise Resource Planning (ERP) systems. These kind of products aim Therefore, standard software products are by their nature highly flexible and confi-gurable software systems. However, the configuration of standard software products is a time consuming non-trivial task, similar to coding in traditional software devel-opment. The goal of our work is to provide a semi-automatic approach to estimate the variability within product configurations. We are aware of the fact that traditional scoping approaches [4],[12] include important activities such as domain assessment and risk analysis and consider product plans or organizational issues. Our automated approach is not meant to replace traditional scoping but to complement it with an initial similarity calculation that could trigger additional scoping measures. We have conducted two industrial case studies in order to validate our approach. Within the first case study we have applied our approach to ERP system customiza-tions for 5 different customers from different industry branches. The second case study has included more than 50 different business intelligence systems. Both case studies aimed at investigating whether the similarity calculation provides correct re-sults and indicates the start of a product line for the products under comparison. In the first case study we have compared the calculated similarity values to a manual estima-tion performed by domain experts. Furthermore, we have evaluated the efficiency of our approach in terms of time savings by comparing the manual estimation to the tool-supported calculation. The second case study focused on the scalability of our approach on large sets of products and the extensibility to handle less standardized configurations. We also have evaluated the integration of domain knowledge by using synonym definitions to identify semantically equivalent settings. 
The results of the case studies suggest that our approach is capable of semi-automatically calculating the similarity between existing standard software product configurations and thus supports a key scoping activity which is the analysis of exist-ing systems. Domain experts clearly indicated that they would benefit from our tool-supported approach compared to manual methods to investigate the reuse potential within a software product portfolio. Apart from time-savings, our approach provides objective results on the similarity between the different products. This helps to pre-vent misjudgments and discussions between engineers, which are not based on facts but potentially false opinions. 
This paper is structured as follows: In Section 2 we present our tool-supported ap-proach that allows semi-automatic product line scoping. Section 3 and 4 present the conducted case studies and the identified results. Section 5 discusses related work and Section 6 concludes the paper with lessons learned and an outlook on future work. 2.1 Conceptual Solution Our approach is focused on standard software products (i.e. customer specific software configurations). These kinds of products are developed and maintained by large soft-ware vendors such as Microsoft or SAP and typically contain a rich set of features. Smaller partner companies sell these products to their customers and configure or extend the product to meet the customers X  needs. This is mainly done by setting values tool-supported product line scoping for configuration-based standard software products in order to support these small partner companies. We foresee a semi-automatic approach where customer-specific product configurations are compared in order to identify commonalities and variations. The variability in our case lies in the differences between the configuration settings of the products under comparison. This means each how it is configured. An analyst can provide additional domain knowledge as input to order to perform a similarity analysis for configuration-based products: 
Step 1: The domain expert selects a set of products for analysis. The selected products are instances of a particular standard product (e.g. ERP system without cus-tomizations) that defines the schema of the available configuration settings. The result of this step is a list of products for further analysis. 
Step 2: In this step the domain expert defines the scope of the analysis. Therefore the relevant configuration settings that should be compared are selected. Many soft-ware products contain settings that do not influence the behavior of the product and from analysis. Moreover, settings can also be grouped if they belong to a logically step 4) grouped settings are only considered similar if all individual setting values are similar. The output of step 2 is a new configuration schema which only includes rele-vant configuration settings and newly defined groups of settings. 
Step 3: The domain expert can define how the similarity between the selected con-figuration settings is calculated. Checking on exact equality of settings might often be too strict. Therefore we support an approach that also allows a more fuzzy compari-son. The domain expert can define so called dictionaries to deal with different naming conventions. A dictionary contains lists of synonyms to identify semantically equal configuration settings (e.g.  X  X evenue X ,  X  X ev. X  and  X  X urnover X ). The domain expert can also provide upper-and lower boundaries for numerical values of settings (e.g. credit card limits between 2900  X   X  3100  X  shall be considered similar). These similarity ranges are defined using mathematical formulas (e.g. a range of 10% around a default value). We not only support defining similarity ranges for specific configuration settings (e.g. credit card limit) but also for global data types (e.g. Floating Point). For example an analyst can decide to round all floating point numbers. The combination of 1.2, 1.4, 0.9 and 1.7 would be transformed to 1,1,1,2. The output of step 3 is a do-main specific definition of similarity for the configuration settings selected in step 2. 
Step 4: In this step the similarity analysis is performed by comparing the configu-ration setting values for the selected products. We compare the configuration values value per setting. We take the most frequent setting value among the selected prod-they are identical or if they are within a similarity range defined in step 3. If there is a domain specific similarity defined for a specific setting (e.g. credit card limit between setting to calculate the similarity value. As an example let us consider the comparison of 4 products with the values true , true , false , true for the setting credit card payment 20%. The results of step 4 are a calculated similarity value for each setting or group of settings and a total similarity value for all products under analysis. 
Step 5: Finally the domain expert can draw conclusions based on the calculated re-sults. The analysis results guide the decision whether to invest in a product line. 2.2 Tool Support We have developed an internally available tool prototype to perform a similarity analy-sis based on configuration settings. The tool supports importing product configurations from multiple source systems, defining similarity evaluation rules, and comparing the we have extended the tool X  X  capability to process different types of configuration settings from XML files and SQL data sources. Setup. The setup of the tool consists of three steps. First the binaries are installed on a Microsoft Windows-based computer. This step requires almost no additional human input. The second step is to configure th e connections to the products under analysis. In case where the products use an SQL database only a connection client is required (ODBC). Furthermore we provide add-ons for non-SQL products to export the confi-gurations to XML, for example QlikView (see case study in section 4). In a final step the product configurations are loaded, either from an SQL data source or XML files. case study. However, if the products under analysis cannot be accessed either by us-ing SQL connections or one of our plugins for XML export, the tool cannot be used out of the box and additional development effort is required. Data Management. Meta data is required to handle product configurations. XML schema definitions are used to describe how product configurations are structured. These schemas are either delivered with the standard software product itself, or deduced from the actual configurations. Moreover, domain knowledge about the advised to compare all products for a specific industry branch. Therefore our tool contains master data about customers and the products in use. Every customer has at least one legal entity. Each legal entity belongs to one or more industry branches (e.g. for one or more business areas (e.g. sales, procurement) and there can be multiple products built for one business area. Each product has at least one configuration. This tailor the analysis scope (e.g. compare all product built for sales in retail industry). 2.3 Limitations A main issue regarding our approach is that in its current form it can only be used for identifying the reuse potential within configuration-based systems (e.g. ERP systems). This means it cannot be applied without modifications in other software domains where the system behavior is not configured. Furthermore, the system behavior may also be influenced by its application data (e.g. the chart of ledger accounts in an ERP system) which is not considered by our approach. We only analyze existing product configurations. This does not reflect all possible product configurations and therefore cannot reveal the complete variability. Each feature has equal influence on the calcu-lated similarity. Currently we do not support weighting of features (e.g. based on their granularity). Focusing on existing product configurations means that we currently do not support other typical product line scoping activities such as planning future prod-ucts as members of the product line. The tool compares the values of each configura-tion setting and calculates the similarity. Th erefore the effort increases with each ad-ditional product under analysis. However, we have conducted a case study on 54 products (see section 4) which can be seen as typical repository size for an SME and the tool was able to finish the calculations within seconds. 3.1 Case Study Setting In order to get insights on our approach we conducted a case study at InsideAx, a small company that is a partner for Microsoft Dynamics AX. Dynamics AX is a busi-ness software solution from Microsoft for medium to large enterprises. Partners, such as InsideAx, configure, customize and sell the ERP product to customers. 
Standard software, such as Dynamics AX has high reuse potential and would there-fore suggest the application of software product lines. However, as partner companies do not own the software product, their influence on the evolution of the system is limited. In fact they have to cope with massive changes within short time periods. This volatile environment and the limited resources of a small company have so far prevented InsideAx to invest in PL engineering. 
At InsideAx employees are basically aware of the benefits of PLs and some even believe that the introduction of PL engineering would be beneficial for their company. However, no detailed analysis of existing product configurations was conducted, which leaves the company in uncertainty about the reuse potential of their software. Furthermore, initial informal discussions among domain experts at InsideAx have indicated that experts might have different opinions on the similarity and thus the reuse potential of particular software products. 
In order to eliminate this uncertainty we analyzed their product configurations with steps regarding the introduction of PL engineering at the company. 3.2 Evaluation Method The goal of this study was to provide first evidence that our approach provides correct similarity calculations. Within a small company we used our approach to calculate the similarity between different product configurations to deliver a first estimation if fur-ther scoping investments are justified. Particularly we were interested in providing initial answers to the following questions: Q1: Will the calculated results indicate the need for introducing a PL approach? Q2: Will the calculated results differ from domain expert estimates? Q3: Will domain experts benefit from knowing the calculated results? 
Steps 1 to 4 were conducted as described in Section 2.1 by one of the authors of this paper, who is also an employee of InsideAx. He first selected five customized products (step 1) which are all derived from the same base product but operating in different industry branches (construction, retail, and manufacturing). He selected the business areas Purchase , Sales , and Inventory Management (i.e. their configuration settings) for comparison as they reflect key business areas (step 2). Next, the domain expert provided similarity ranges (step 3) and the tool calculated a pairwise similarity between the products and the overall similarity value for all three business areas (step 4). 
In parallel three domain experts at InsideAx were asked to estimate the similarity of the mentioned products and business areas. They used a scale from 0% to 100% (0% meaning that there is no overlap and 100% meaning that two products are iden-tical). To support the estimation process, they had full access to the configured prod-ucts, their documentations and requirements. The first expert was an ERP consultant with 3 years experience, the second expert was a data analysis consultant with 4 years experience and the third expert had 2 years experience in developing and customizing ERP products. We then compared the tool-calculated similarity with the domain ex-perts X  estimates. Finally, we discussed these results in a workshop with the domain experts. 3.3 Results The author calculated the similarity for the selected products (P1 to P5) with the help of the tool and spent about 15 minutes in total to perform steps 1 to 4. Table 1 shows the pairwise calculated similarity values for the business activities Sales, Inventory and Purchase. 
For Purchase the pairwise similarity calculations resulted in a similarity range from 40% to 93% (58% on average). In addition to the pairwise comparison the tool similar. The pairwise similarity comparison for Inventory provided a range from 48% to 59% (50% on average). In total 41% of all features are similar. For Sales the pair-wise similarity comparison resulted in a range from 31% to 65%, while the average similarity for Sales is 47%. Within Sales the total similarity rate is 31%. 
Furthermore, we received the estimates of the domain experts. However, one ex-pert was not familiar with all products under analysis and therefore just provided a comparison for those he knew. Table 2 highlights the pairwise similarity estimates. We present the minimum and maximum estimates and the individual estimates for the three domain experts in brackets. 
A comparison between the calculated values and the estimates revealed that the expert X  X  opinion and tool calculations differ significantly with hardly any exact matches. To still enable a meaningful comparison, we defined a 20-percentage point interval around each automatically calculated similarity value as a more relaxed com-parison criterion. For example, if the tool has calculated a 70% similarity, we defined an interval from 60% to 80%. We then counted the number of expert estimates that were within the defined ranges. 
For the business area Purchase, eight out of ten estimates do not differ more than 20 percentage points on the scale form 0% to 100%. However, the two remaining estimates on purchase vary between 30 (P3-P5) and 70 (P4-P5) percentage points. For Inventory only 4 estimates are within the 20-percentage point limit. This leaves 6 estimates which differ significantly (40 percentage points at most). Also for Sales only 4 out of 10 estimates are within the 20-percentage point limit. 
The first domain expert who only provided estimates for 18 out of 30 requested comparisons provided 3 estimates, which were within the corresponding intervals. All of them could be linked to the business area Purchase . Eight estimates were actually lower, leaving seven estimates to be higher than the calculations. The second domain expert performed best. 5 out of 10 estimates were within the corresponding intervals. All of them were within the business area Purchase . 7 out of 10 estimates were within the intervals for the business area Inventory and still 3 out of 10 for Sales were within the given range. 14 estimates were higher than the tool-calculated results. The third domain expert was able to provide three estimates within the given range. Only one estimate for each business area was within the interval. Again, most estimates were too optimistic (17 out of 23). 3.4 Findings Will the calculated results indicate the need for introducing a PL approach? The case study was conducted for customized ERP products. While ERP software is commonly known as Standard-Software, we expected a high reuse potential. Reviewing the cal-culated similarity results, this assumption seems to be somewhat correct. In total, 31% to 41% of the features were similar in all the customized products, regardless of in-dustry branch or business area. A pairwise comparison indicated even higher values. Although we have not defined a clear schema in order to decide which result indicates to introduce a PL, we expected a significantly higher overall similarity value than 50% for each business area. This assumption was based on the published scoping threshold in [6] where 50% is understood as break-even point. However, as we couldn X  X  identify a similarity value higher than 41% we conclude that the results do not clearly indicate the need for introducing a PL approach. 
Will the calculated results differ from domain expert estimates? The results high-light that tool calculations and expert estimates vary strongly. Therefore, we per-formed a more detailed manual analysis of the product configuration settings together with the domain experts. The tool X  X  calcula tions were validated and for selected set-tings the corresponding product configurations were analyzed. Although no overall similarity was calculated manually, the expe rts agreed that the tool X  X  calculations were correct and can be seen as the ground truth for this comparison. Comparing cal-culated and estimated similarity shows that 33% of the estimates were within a 20 % points interval around the calculated results. In general the domain experts estimated a higher similarity than tool calculations re vealed. The discussion with the domain ex-perts in the debriefing session revealed the reasons. In many cases new projects are based on existing customized products from past projects. The domain experts know this and somehow assume that these products show high similarity. However, in reali-ty, these products undergo major changes in most cases and diverge. Table 2 indicates this effect comparing product P1 and product P2, which was initially built based on P1. Although the product has undergone major changes, domain experts still assumed high similarity between the products. In general the domain experts make their esti-mates based on their experience. None of the domain experts performed a detailed comparison of all product configuration settings, which would not have been possible in a reasonable amount of time. 
Will domain experts benefit from knowing the calculated results? Having a differ-ent view on the overall situation might lead to conflicts between domain experts. In the debriefing workshop we told domain experts about the tool results and compared them to their estimates. Most experts did not expect that the products were tailored to individual customer needs to that extent. They liked the fact that they could compare their estimates with the calculated values. They argued that the calculated values pro-vide guidance and support in resolving conflicts between domain experts. 3.5 Threats to Validity Conducting one single case study does not allow computing any statistical signific-ance regarding the correctness of the calculated similarity values, which is a threat to conclusion validity . Discussions with domain experts and a conducted manual analy-sis revealed the appropriateness of the calculated similarity in this case. 
One of the authors used our tool to calculate the similarity values within this study, with the consultants revealed the correctne ss of the input and the configuration. 
Our similarity calculation mechanism was developed for the domain of configura-ble software products. However, our study only focuses on Dynamics AX. This can be seen as a threat to construct validity. Also, we did not utilize the dictionary concept in the first case study. 
The size and the number of products used in our study were limited, which is a threat to external validity . We focus on configuration-based systems and do not pro-vide support for a broader system range. Input from a skilled domain expert, who is familiar with the tool is needed. Not yet investigating the tool X  X  usability in more detail can be seen as threat. 4.1 Case Study Setting The second case study at InsideAx was focused on a product for data analysis and business intelligence. Domain experts at InsideAx use a product named QlikView to build data analysis applications for thei r customers. The process of building these applications contains three key steps. In a first step QlikView extracts, transforms, and loads data from multiple source systems such as ERP systems. A domain expert defines so-called measures in a second step . A measure in QlikViev is a formula to calculate a business relevant value (e.g. contribution margin). In a last step the meas-contribution margin). These analysis result s are used to lead a company and optimize a departments X  work. 
Business intelligence applications such as QlikView are built in tight collaboration with the customers X  decision makers, and therefore are more individual than a stan-dard software product. Still, domain experts at InsideAx believe there is a common set of recurring QlikView measures on most business areas and industry branches. How-ever, no in depth analysis has been conducted so far. 
Within this study we analyzed a set of cu stomer specific products in order to iden-tify similar QlikView measures. The products are characterized by business area and the customers X  industry branch. 4.2 Evaluation Method The goal of this study was to show that our similarity calculation approach works with a larger example (scalability of the approach). Furthermore, the dictionary con-system under analysis does not allow comprehensive manual calculations or estimates in a reasonable amount of time. This is why we did not include domain experts in this case study. We have framed our evaluation goal in three research questions (RQs): Q1: Will the calculated results indicate the need for introducing a PL approach? Q2: Will the dictionary concept influence the calculated results? Q3: Will the approach be scalable to the given problem size? 
In step 1 we selected 54 different products from 12 customers in 6 different indus-try branches. All of these 54 products use the data analysis capabilities of QlikView. In contrast to the first case study these products are not derived from a common base product. Each of these 54 products can be seen as individually developed product. QlikView only defines how measures are created but does not include a predefined list of measures (such as a configuration schema in an ERP system). Therefore we defined an initial dictionary containing synonym lists of measures to allow a domain specific comparison. For example, the measures Profit Margin and Contribution Margin are identical and should therefore be identified as similar during the similarity calculation. The dictionary containing the synonym lists was created by one of the authors of this paper who has 6 years experience in developing business applications. In step 2 we grouped the products by business area (e.g. Sales, Finance, and Project). 
In step 3 we incrementally refined the dictionary while importing product configu-rations into our tool. We assigned newly imported measures to existing synonym lists if they were semantically similar. For example, the imported measure Profit Contribu-tion was added to the synonym list that already contains the measures Profit Margin and Contribution Margin . 
In a next step we performed a similarity analysis on the groups of products built for a specific business area (step 4). The tool identified the number of measures occurring in all products within this group and calculated a similarity value. 4.3 Results In total, we analyzed 54 different products from 12 customers in 6 different industry branches. These products were grouped into 7 business areas. In total all products together contained 930 measures. We defined a dictionary containing 27 synonym lists to group semantically equal measures. 109 measures were highly individual and could not be grouped with others. 
The author spent about 40 minutes to create the initial dictionary (step 1) and 5 mi-nutes to group the products into business areas (step 2). Step 3, the refinement of the synonym lists, took again about 45 minutes. The calculation itself has been performed within seconds (step 4). Table 3 shows the results from the analysis based on the product X  X  business area. The second column shows the number of products per business area. The number of products varies between two for Project up to 17 for Sales . The third column contains the number of customers running a product for this business area. For example there are two customers running a product to analyze Project but 10 customers analyzing Sales . The next column shows the total number of identified measures within the products per business area. For the business area Project , 29 measures were identified while for the business area Sales we found 460 measures. The fifth column shows the number of synonym lists used to group the measures. This means that the comparison of measures can be reduced from the number of measures to the number of synonym instead of 460 measures because they were identified as semantically equal in the dictionary. The last column shows the calculated similarity of all products in the giv-en business area. For the business area Project , the two compared products are 63% similar. This means 63% of identified measures are used in both products. In the business area Sales , only 8% of the identified measures (or their synonyms) are present in all 17 products. In general, the calculated similarity decreases with the number of compared products. 4.4 Findings Will the calculated results indicate the need for introducing a PL approach? Provid-approach is needed and a single-system development approach can also be perused in the future. In case where the calculated results reach the threshold value (see business areas Project and Production in Table 3) only two products were compared. In all other cases the calculated similarity was significantly lower than the desired thre-shold. However, our study also indicates that the different granularity of the products under investigation had a significant impact on the results. For example we found five very specialized Sales applications built for one customer. A way to address this issue could be to merge these specialized appli cations and compare more general applica-lated similarity values, we performed a manual similarity analysis for 6 products with 71 measures from the business area Procurement, which is about 10% of total prod-ucts under analysis. This manual analysis revealed the correctness of the calculations. 
Will the dictionary concept influ ence the calculated results? Solutions developed with QlikView are in general harder to co mpare as less standardization is available. Therefore, we introduced the dictionary concept. We observed that synonym lists provided a predefined set of synonym lists. Therefore many terms were mapped to these synonyms and the reported similarity value was high. With ongoing analysis we refined the set of synonym lists by splitting existing synonym lists into smaller more precise lists. As a result the calculated sim ilarity decreased. This also means that the calculated similarity strongly depends on the analyst X  X  domain knowledge and ability to define adequate synonym lists for domain specific terms. 
Will the approach be scalable to the given problem size? The study has shown that case study where 5 products were compared in 3 business areas we managed to ana-lyze 54 products in 7 business areas. We could not identify any performance problems within this case study as the tool calculated the similarity within seconds. However, consumed a significant amount of time (about 1,5 hours in total). 4.5 Threats to Validity Although the example is larger than the one in the previous case study and we can draw first conclusions regarding the scalability of our approach, we still cannot com-pute any statistical significance regarding the correctness of the calculated results. This can be seen as a threat to conclusion validity . More case studies would be needed The number of products in some of the business areas (such as Production and Project ) was very limited. Manual analysis revealed the correctness of the calcula-tions for a limited set of products in the business area Procurement . 
As one of the authors of this paper was also the developer of the tool similar threats to internal validity as described for the first case study (cf. Section 3.5) apply. Particu-case study. Although the dictionary was built iteratively, which allows for validation and correction, it was created and validated by one person only. not use similarity range definitions. 
As discussed in the first case study, or approach focuses on configuration-based systems. This could mean that it underrepresents external validity . A domain expert our approach in a larger setting, we did not investigate the tool X  X  performance in de-tail. However, we expect the problem size of the second study to be typical for SMEs. Schmid and Schank [6], PuLSE-BEAT is introduced, a tool for supporting the product line scoping approach called PuLSE-Eco presented in [13]. To identify the optimal scope, a product map is used which is a matrix with the product characteristics (fea-tures) on one axis and the products on the other axis. The product characteristics are elicited from stakeholders, existing systems, and the product plan. In our approach, product characteristics (we call them feature definitions) are derived from existing systems. In PuLSE-Eco the benefit analysis step decides what to develop for reuse and what not. Benefit functions describe the benefit of having a certain characteristic and calculate a similarity value to decide what should be inside the scope. 
John [8] describes the CAVE approach. It utilizes existing documentation in order to identify communalities and variability. CAVE foresees the steps; Preparation, Analysis and Validation. In the first step a domain expert selects user documentation for analysis. In the second step a domain expert browses the selected documents and tags elements based on extraction patterns. The results of the second step are product line artifacts that are validated by a group of domain experts. 
Scoping based on source code is presented in de Medeiros et al. [14]. The authors present a tool-based approach containing three modules. The feature identification module receives legacy systems source code and outputs the features composing the legacy system. The similarity comparison module identifies copied source code from legacy systems and calculates the similarity of feature implementations. The third module visualizes the results for domain experts. Duszynski et al. [15] present an approach that analyzes the source code of multiple variants for commonalities to sup-port migration towards a product line. The reuse potential of system parts is assessed using occurrence matrices. Instead of a pair-wise comparison of existing variants, the matrix contains the different elements of th e variants that are compared, the variants and the occurrence of the elements in the variants. The similarity rate is categorized as core (element occurs in all variants), shared (element occurs in some variants), and unique (element occurs in only one variant). In contrast to [14] and [15] we focus on configuration settings of standard software products rather than on source code. In the second case study we calculate similarity of products based on measures defined in these products. We compare formula definitions in this case but do not analyze the source code for similarity. Although many measures realize the same business con-cept (e.g. calculate the contribution margin) the implementation itself greatly differs because the information sources for this measure are different for most of the systems (e.g. different tables from different ERP systems are used to retrieve the input data for the calculation). Code scoping techniques would thus reveal that the implementations of these products are highly different. We presented a tool-supported approach that enables companies to semi-automatically perform a similarity analysis of existing product configurations. We consider it as a lightweight approach wh ich complements existing approaches and supports companies to initially answer the question if a product line approach would suit their needs. The presented solution enables SMEs to estimate the similarity in standard software products. The case studies have shown that our approach can be applied to different types of products (ERP, data analysis) and also scales to a larger number of products. The similarity calculation is automated and reveals quick insight on the existing product portfolio. It can be repeated and refined without major changes on the tool. 
In order to evaluate our approach we have conducted two industrial case studies in the field of business software. Starting a product line from existing solutions is recog-have shown that the tool can be used by domain experts and reveals valuable results. Furthermore the evaluation shows that domain experts give different estimates on the reuse potential that not only differ from the calculated value, but also from one anoth-er. If a company is planning to introduce software product lines they should not rely only on their domain experts estimates, but take (semi-)automatic scoping into con-sideration. Although the calculated results did not clearly indicate the need for intro-ducing a product line approach, it provoked an intense discussion in the company. 
In the second case study we started with a large set of existing products, built for different customers and purpose. In contrast to the first case study these products were less standardized. Therefore we intensively used the dictionary concept and defined many synonym lists to identify semantically equivalent configuration settings. This case study revealed the importance of domain knowledge when performing a scoping analysis. The dictionary concept was proven to be a valuable way to make domain knowledge explicit and reusable for automatic processing. Moreover, the second case study has shown that our approach scales also to a large number of less standardized products. Also, the more products under analysis are domain specific the more do-main knowledge is required. We have learne d that less standardized software products like QlikView in case study two, are harder to compare than strictly standardized software products like the ERP systems in case study one. 
Future work will include extending the tools functionality to implement a more so-phisticated similarity calculation method in order to identify clusters of similar parts. Moreover, we will work on the dictionary concept. The second evaluation has shown that we need to address the different granularity of dictionaries and synonym defini-tions in order to handle products of different granularity for analysis. 
