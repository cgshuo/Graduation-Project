 1. Introduction
In an industrial process, the desired quality of products can be realized by adjusting various process parameters from raw material to finished product. Such a process can be then considered as complex system in which the input variables correspond to the adjustable process parameters, and the output variables to the measurable features representing the product quality. In order to optimize the product quality, it is necessary to build a mathematical model characterizing the relationship between process parameters (input variables) and the quality parameters (output variables). Fig. 1 shows an example of such model in a complex nonwoven process.

Practically, an industrial process is often composed of a great amount of process and quality parameters. Moreover, the number of learning data is very limited due to machine availability and trial cost. In fact, a model dealing with numerous input variables is often too complex for interpreting the obtained results.
In order to reduce the complexity of the model and obtain physically interpretable results, only a small group of the most relevant process parameters should be taken as input variables of the model. During the production, operators adjust these relevant parameters in order to improve product quality. According to the same idea, only the most relevant quality variables are selected as outputs of the model. Therefore, the selection of relevant variables constitutes the first step in the modeling of an industrial process.
Selection of relevant variables (called also feature selection) is an important topic which has made many researchers interesting for reducing the search space and the complexity of the problem to be processed. It has been widely applied to pattern recognition, system modeling and data mining. The definition of the criterion of relevance depends on the specific problems to be solved and then it has different versions in the machine learning literature.
These definitions can be summarized in some sense using a general statement given by Blum and Langley, 1997 .

A variable x is relevant to a target concept c if there exists two examples A and B in the instance space such that A and B differ only in their assignments to x and c ( A ) a c ( B ).
In the existing literature, many research methods have been proposed for selecting relevant variables. Most of them deal with data based classification problems, and the strategy used for evaluating variables and the condition for halting the search are generally defined as the variable X  X  ability to discriminate among classes of learning data ( Pizzi and Pedrycz, 2008 ). The optimal subset of variables corresponds to the case in which the separability between different classes is maximal and data inside each class is as compact as possible.

Of the classification based variable selection methods, most of the existing work has used the supervised learning strategy, i.e. the objective of selection is to improve the classification accuracy or class label predictive accuracy of data samples. Several well-known methods are the decision-tree method ( Sugumaran et al., 2007 ), the nearest-neighbor method ( Li and Lu, 2009 ), the mutual information measure based method ( Liu et al., 2009 ) and the hyperbox generation based method ( Thawonmas and Abe, 1997 ), information-theoretical connectionist network model for remov-ing both irrelevant and redundant variables ( Last et al., 2001 ) and wrapper model ( Maldonado and Weber, 2009 ), which evaluates alternative subsets of variables by running some induction algorithm on the learning data and using the estimated accuracy of the resulting classifier as its metric. There also exists some work on unsupervised variable selection using conditional
Gaussian networks ( Zeng and Cheung, 2009 ) and data clustering techniques ( Bandyopadhyay, 2005 ). Recently, some new variable selection methods have been developed using fuzzy techniques, such as a modified fuzzy decision trees with supervision ( Chang et al., 2010 ), a proposed fuzzy model for input variable selection based on numerical learning data ( Xing et al., 2003 ).
There also exists some work on relevant variable selection in the context of complex nonlinear system modeling. The corre-sponding strategy for evaluating variables is often defined as reaction capacity or tracking capacity of input variables related to output variables. One typical method has been presented in Lin et al., 1998 . It develops two stage fuzzy curves and surfaces from a set of learning data for ranking all input variables and discovering correlations between these variables.

In practice, the performance of these data based variable selection methods is strongly related to the quality and the quantity of data samples and the criteria defined, which may vary from task to task. These methods are not efficient to solve variable selection problems in industrial process modeling because the number of learning data measured from an industrial process is often too limited to constitute a correct statistic distribution.
Moreover, the professional knowledge on products and processes, which often plays a key role in the determination of relevant variables, is not taken into account in these methods. For solving this problem, a selection criterion, called Linear
Global Relevancy (hereafter LGR) criterion, has been initially proposed in our previous papers ( Vroman et al., 2008 ) for selecting relevant input variables (process parameters) related to a specific output variable (quality parameters). Such relevancy criterion combines the sensitivity to experimental data and the conformity of human knowledge using a linear model. In our study, the relevancy of output variables is generally defined according to the analysis of total quality and market. In this paper, the selection criterion for the relevancy of input variables is only discussed. The detailed idea is given as follows:
In order to deal with few numbers of experimental data, the classification based selection criteria is replaced by data sensitiv-ity based criterion, called Numerical Sensibility (hereafter NS) criterion. Instead of measuring the separability between different classes and compactness inside each class, the proposed criterion calculates distances or variations between individual data samples in the input space and the output space, respectively, and evaluates the sensitivity of the variations in the input space to those in the output space. This sensitivity can be considered as a measure of information content included in the set of all input variables and defined according to the two following principles: 1) Input variables are considered as sensitive to experimental data if small variations of input data induce big variations in the output variable. 2) Input variables are considered as insensitive to experimental data if big variations of input data induce small variations in the output variable.

When removing one variable from the set of original input variables, the sensitivity value related to the remaining input variables is calculated and compared with those of the other input variables. The most sensitive input variable corresponds to the case in which the sensitivity value of the remaining variables after its removal is the smallest.

In order to formalize and integrate the expert X  X  knowledge on products and processes in variable selection, a Human Knowledge Conformity (thereafter HKC) criterion is also defined and com-bined into the previous sensitivity criterion. This conformity criterion transforms qualitative and incomplete information on relationship between process and quality parameters into numer-ical values. The combined variable selection criterion is capable of taking into account the two complementary information sources, i.e. numerical data measured on processes and products and related human knowledge obtained from experience.

The above variable selection criterion has been successfully applied to several real industrial problems. However, there exists two main drawbacks in this method 1) This method is very sensitive to noisy data. As it is based on distances between individual data samples, the sensitivity criterion is naturally less robust than classification based variable selection criteria. 2) Like the other variable selection methods, the numerical results obtained from this criterion are not directly inter-pretable and they are only significant for ranking variables. In the list of ranked variables, the difference between two neighboring variables cannot be interpreted. In practice, when the values of a selection criterion for two neighboring variables are very close, they are generally considered as having the same level of relevancy and the order between them is not significant. Contrarily, for two neighboring variables having a big difference in values of selection criterion, their order should be significant. According to this analysis, numerical selection criteria are too sensitive and then mask real physical significance in related results.

Consequently, a Fuzzy Global Relevancy (thereafter FGR) criterion is proposed in order to solve these two drawbacks and further improve the performance of the proposed selection method. This criterion is based on our previous LGR criterion. In the new FGR criterion, both the sensitivity criterion and the conformity criterion are outputs of fuzzy models and their linear combination is replaced by fuzzy rules generated according to the experience of experts. As results of this criterion before defuzzi-fication are fuzzy values, the related selection results are more robust with noisy data and easier for physical interpretation. In fact, the variables corresponding to equal fuzzy values of the selection criterion can be considered as having the same level of relevancy and the difference between all ranked variables is then significant.
 This paper is organized as follows: Section 2 introduces the LGR criterion. Section 3 presents a fuzzy system for generating the
FGR criterion. In Section 4, the two previous criteria are applied to one artificial data set and one analytical function in order to validate its effectiveness and compare with the other variable selection methods. In Section 5, these two relevancy criteria are applied to the case of a nonwoven process modeling. A conclusion is given in Section 6. 2. Linear global relevancy criterion 2.1. Formalization of the relevant variable selection problem
In this paper, for simplicity, the selection of relevant input variables related to one specific output variable and related human knowledge is only studied. The relevancy of input variables related to a set of output variables can be studied by combining all the selection results obtained from individual output variables. The formalization of the input variables selection can be illustrated as follows.

Let m and n be the total number of input variables and the total number of output variables, respectively. The input and output variables are denoted as X= { x 1 , x 2 , y , x m } and Y= { y respectively. The relationship between { x 1 , x 2 , y , x output variable y b can be considered as a nonlinear function f so x , x ( t ) ) is created in which the variables of X X t is aggregated by calculating the average of all values of f ( x 1 , x 2 , y relevant variables if and only if their mean value of 9 f g smallest for all the t sized subsets of input variables in X .
Let X s =( x s 1 , x s 2 , y , x sk , y , x sm ) T and Y s y ) be the input vector and the output vector that correspond to have been normalized to eliminate the scale effects and the learning data set contains z samples. In order to find the relevant inputs for a given output y b , a linear global relevancy criterion
LGR k b (estimated for each input variable x k and related to output variable y l ) is defined as follows:
LGR with k A {1, y , m }, b A {1, y , n }, g 1 and g 2 are two positive coefficients.

The criterion LGR k , b is designed for finding the best compro-mise between the numerical sensitivity of experimental data NS and the human knowledge conformity to experimental data
HKC k , b , respectively. The larger LGR k , b is, the more the input x relevant to the output y b . 2.2. Numerical sensitivity criterion
The criterion of sensitivity for the influence of all input variables X related to the output variable y b is defined by
NS  X  where d ( X i , X j ) is the Euclidean distance between two input and y
Eq. (2) is used for evaluating the variations of the whole set of input variables related to the variation of an output variable y all the pairs of learning data samples. Evidently, NS b varies between 0 and 1. If values of NS b are close to 1, it is considered that small variations of input data can cause big variations in the output space and the input variables are sensitive to experimental data. If the values of NS b are close to 0, it is considered that big variations of input data correspond to small variations in the output space and the input variables are insensitive to experi-mental data.

The criterion NS b can be considered as a measure of information content in the input variables. However, for selecting relevant variables, the information content is evaluated after removing one or a group of input variables. The criterion of sensitivity related to the output variable y b when removing the input variable x k is then defined by
NS  X  where d 0 k  X  X i ; X j  X  X  tion of d ( X i , X j ) on the axis x k .

From Eqs. (2) and (3), 1 4 NS k , b 4 NS b is easily obtained. For a other sensitivity value NS pl after removing related input variable x ( p a k ), it is considered that x k is most insensitive to experimental data because the remaining input variables after removing x k are more sensitive than those after removing any other individual input variable. Contrarily, if the value of NS smaller relative to the other input variables, it is considered that x is the most sensitive to experimental data because the remaining input variables after removing x k are the least sensitive.
In order to conform to the definition of LGR k , b in Eq. (1), i.e. big values of sensitivities correspond to relevant variables and small values of sensitivities to irrelevant variables, Eq. (3) is trans-formed into the following form:
NS  X  1
Evidently, values of NS k , b also vary between 0 and 1. The bigger the value of the sensitivity criterion NS k , b is, the more sensitive the corresponding variable x k is to the experimental data. 2.3. Human knowledge conformity criterion
In Eq. (1), the second element HKC k , b characterizes the degree of coherence between the human knowledge and the variation of experimental data. The human knowledge is collected from the process and product experts in R&amp;D department. This expert knowledge is generally incomplete and varied according to the application cases. A symbolic representation of an expert knowl-edge about the influence of an input variable x k ( x k A an output variable y b ( y l A Y ) can be summarized as follows:
IF x k is increasing THEN y b is increasing : R ( x k , y
IF x k is increasing THEN y b is decreasing : R ( x k , y IF there is no influence of x k on y b : R ( x k , y b )=0 IF there is no human knowledge : R ( x k , y b ) =null
The human knowledge collected from the process and product experts is sometimes quite different from the information extracted from the experimental data of product samples. In practice, the human knowledge is more general than the results obtained from the concrete product samples. So the human knowledge can be used for completing the experimental data.
The human knowledge conformity HKC k , l can then be calcu-lated using the following formula:
As shown in Fig. 2 , 9 I kp 9 and 9 U kp 9 are the lengths of the intervals, which, respectively, correspond to the intersection and union of A kp and A kp+1 (input space), corresponding to C (output space).

Eq. (5) can be interpreted as follows: R p represents the degree of coherence between the human knowledge and the variation of experimental data in the two neighboring intervals C b p and C Its value varies between 0 and 1. If I kp = F and x inf kp  X  1 input data X s  X  X  ( s= 1, y , z ) projected on the axis x when their corresponding output data y b s  X  X  vary from C
In this case, if the human knowledge R ( x k , y b )= 1 ( x influence on y b ), it is considered that this human knowledge is strongly coherent with the data variation trend of x k in the two neighboring intervals C b p and C b p+1 . From Eq. (5), R case) is obtained. If the human knowledge R ( x k , y b )= 1( x negative influence on y b ), then it is considered that this human knowledge is strongly incoherent with the data variation trend of x in the two neighboring intervals C b p and C b p+1 . Then, R obtained from Eq. (5) (the worst case). Similar interpretation can be given to the case of I kp = F and x sup kp  X  1 r x inf x cases is obtained (see Fig. 2 ) and the input data projected on x slightly increasing when their corresponding output data human knowledge is weakly coherent with the data variation of x in C p and C b p+1 . The degree of coherence R p is related to the overlap between the two data sets of x k corresponding to C C b p+1 . The smaller this overlap is, the closer the data variation of x is to a strongly increasing case and the closer the value of R to 1. If R ( x k , y l ) = 1, the human knowledge is incoherent with the data variation of x k and R p =0. The other cases of R p can be interpreted in the same way. If big values are obtained for all R ( p =1, y , t 1), then the value of the criterion HKC k , b and the data variation related to x k is coherent with the human knowledge.
 After computing NS k , b and HKC k , b , the value of the criterion LGR k , b representing the global relevancy of each input x output y b can be determined. Then all the LGR k  X  s ( k =1 be ranked in a descending order. Namely, the input corresponding to the highest value of LGR k , b will be the most relevant input to this output, and so on.

This proposed criterion LGR k , b has been applied successfully in several industrial problems. However, there exist some draw-backs when using the applications.

The coefficients g 1 and g 2 are often difficult to be determined because the precise importance of the data sensitivity NS related to the coherence between human knowledge and experimental data HKC k , b is generally unknown.

Some changes of LGR k , b are not significant because the linear combination of NS k , b and HKC k , b is too sensitive to data variation. If some noises are included in measured experi-mental data, the ranking results will be easily affected.
Significant changes of HKC k , b should be reinforced and interpreted so that differences in the list of the ranked variables can be physically understood.

Based on this analysis, it needs to propose a new selection criterion which is more robust, easier for physical interpretation and capable of treating uncertain and linguistic information related to human knowledge. 3. Fuzzy global relevancy criterion
The FGR criterion for selecting input variables is defined in a similar way with the LGR criterion. In this definition, the fuzzy sensitivity variation of each input variable x k related to the output variable y b is estimated using experimental data. And it is combined with the conformity of human knowledge related to experimental data using fuzzy rules. With this criterion, the noisy data could be effectively filtered and thus a significant order could be obtained in the corresponding results. The general fuzzy criterion of variable selection can be expressed as
A
FGR k , b =f ( FS k , b , HKC k , b ), in which the first element FS Fuzzy Sensitivity (hereafter FS) criterion and the second element
HKC k , b the conformity of human knowledge obtained from judgments of a group of experts using data aggregation.
As shown in Fig. 3 , the fuzzy system for generating the FGR criterion is divided into three categories of fuzzy models: (1) evaluation of FS criterion of each input variable x k related to one output variable y b (fuzzy model M 1 ); (2) estimation of the human knowledge by aggregating the weighted judgments of a panel of experts (fuzzy model M 2 ); (3) aggregation of two previous sources of information (fuzzy model M 3 ). These three categories of models are presented in the following sections, respectively. 3.1. Fuzzy sensitivity criterion
The FS criterion for all the input variables is defined according to the same principle given in Section 1. This principle is transformed into a set of fuzzy rules for building a fuzzy model in which the input data variation D x (distance between two normalized input vectors) and the output data variation D y (distance between two normalized values of one specific output variable) are taken as two input variables, respectively, and the general sensitivity FS as output variable (model M 1 in Fig. 3 ).
Evidently, FS is a function of D x and D y , denoted as FS=M
This fuzzy model includes an interface of fuzzification, a base of fuzzy rules, an inference mechanism and an interface of defuzzification.

The fuzzification procedure aims to uniformly partition each of the two input variables into three fuzzy values: Small ( S ), Medium variable varying from 0 to 1 and composed of five fuzzy values: (illustrated in Fig. 5 ).

According to the experience of production operators on the relationship between process and quality parameters, a set of fuzzy rules are defined in Table 1 .

As the output variable includes fuzzy values, the Mamdani controller ( Mamdani and Assilian, 1975 ; Cao et al., 2001 ) is used for aggregating these fuzzy rules and obtaining defuzzified output values.

Given a specific output variable y l , for any pair of data samples ( X , y and the output data variation d ( y i b , y j b ) are calculated. The corresponding sensitivity in the data pair ( i , j ) related to y denoted as FS b ( i , j ), which can be obtained from this fuzzy model
M , such as FS b ( i , j )=
M of information content of all the input variables in the pair ( i , j ) related to the output y b .

When removing x k from the whole set of input variables, the sensitivity of the remaining input variables in the data pair ( i , j ) related to the output y b can be calculated in Eq. (6)
D FS k ; b  X  i ; j  X  X  M 1  X  D d k  X  X i ; X b  X  ; d  X  y i b ; y
D d  X  X i ; X j  X  X  d  X  X i ; X j  X  d k  X  X i ; X j  X  X  6  X 
The general fuzzy sensitivity criterion FS k , b for all the pairs of data sample when removing the variable x k is defined in Eq. (7)
FS  X  1 =
Evidently, when the value of FS k , b is bigger relative to the other input variables x p  X  X  ( p a k ), then the removing variable x considered as the most sensitive because the remaining variables are less sensitive to experimental data than x k . Contrarily, when the value of FS k , b is smaller relative to the other input variables, then the removing variable x k is considered as the most insensitive because the remaining variables are more sensitive to experimental data than x k .

In order to confirm the NS criterion, the FS criterion FS normalized in [0,1]. In this way, the closer the value of FS the more the input variable x k is sensitive to the output variable y . The closer the value of FS k , b is to 0, the more the input variable x is insensitive to the output variable y b .

Based on the fuzzy sensitivity criterion defined in Eq. (7), an algorithm for selecting the most relevant variables and ranking all
Aggregation of human knowledge with a group of experts the input variables is proposed. This algorithm combines both the forward search and the backward search. The forward search permits to select the most relevant input variables in each step, while the backward search allows to remove the most irrelevant or redundant variables. Two thresholds a 1 and a 2 are defined for such two searches. The principle of this algorithm is illustrated in Fig. 6 . 3.2. Aggregation of knowledge of experts
In Section 2.3, the HKC criterion is based on the knowledge of only one expert. In practice, there often exist several experts having different professional profiles who provide various judg-ments on the relations between the quality and the process parameters. Moreover, for any expert, the confidence of his judgment and his professional competence are often different from the others. In this situation, it is necessary to improve the
HKC criterion by aggregating the weighted human knowledge obtained from a group of experts (panel of experts).

In the existing literature, the cross-impact matrix ( Asan et al., 2004 ) is frequently used for identifying the relevant variables by collecting the knowledge from a group of experts. Based on a structural analysis, this matrix can clarify the direct and indirect impacts among the variables. However, the performance this matrix experts and the degree of confidence of judgment. Consequently, a new criterion is proposed which integrates the level of experts, the degree of confidence and the dissimilarity between the knowledge in the same time. The criterion is presented as follows.
For a set of h experts, the influence of the process parameter x and the quality parameter y l can be represented by a vector ( I , I 2 , y , I h ) T (as shown in Table 2 ). I v corresponds to the knowledge expressed by the expert v using the following ( N ) and Very Negative ( VN ). Cv corresponds to the degree of confidence expressed by the expert v using following linguistic terms: Little Certain (LC) and Certain (C). E v represents the level of the expert v given by the organizer of the knowledge evaluation using the following terms: High , Medium and Low .

The procedure for aggregating knowledge of this group of experts contains three following steps (model M 2 in Fig. 3 ). 3.2.1. Calculation of knowledge dissimilarity between different experts
In practice, the knowledge of experts on the influence of process parameters on quality parameters is often various owing to their different professional background and personal sensitiv-ity. In order to evaluate the performance of experts and fusing their judgments correctly, it needs to calculate the dissimilarities between the knowledge provided by different experts. The procedure of calculation is shown as follows.

First, the knowledge of each expert is transformed into a fuzzy to the triangular membership functions shown in Fig. 7 . Each membership function, denoted as trimf ( x ,[ a t , b t , c represents one type of influence of a process parameter on specific quality parameters.

After removing the knowledge of the expert v , the knowledge provided by the other h 1 experts to the five classes correspond-ing to the previous five fuzzy values is assigned denoting the number of experts in the class t as U tv . The contribution rate of the other experts to the class t after removing expert v , denoted as CR tv , can be calculated by CR tv =U tv / ( h 1). In the corresponding membership function, the area A tv is used to represent the importance weight of the knowledge after removing the expert v and A tv = ( c t a t ) /2 CR tv is obtained.

Then, the gravity center for each of the five classes C v calculated from the linear combination of the contribution rates and experts in the group, denoted as D v , can be calculated as follows: D  X  9 b y C n 9 with C v  X  where b y ( y A {1, y , 5}) is the center of the class (fuzzy value) in which the expert v gives his judgment.

This numerical dissimilarity is then transformed into a linguistic value of the set { Small , Medium , Big }, corresponding, respectively, to the triangular membership functions trimf ( x ,[ 1, 3.2.2. Calculation of weights for the knowledge of experts
At this step, the fuzzy logic is used for determining the weights related to the knowledge of the e xperts. They include information from the calculated dissimilarities, the professional levels of experts and the degrees of confidence. The weights take fuzzy values from corresponding, respectively, to the triangular membership functions The weights w v related to the knowledge of the expert v ( v y , h} ) can be calculated using a set of fuzzy rules generated according to following principles: 1) IF a high level expert has a high degree of confidence and his/her knowledge is close to that of the other experts , THEN the corresponding weight of knowledge is high . 2) IF a low level expert has a low degree of confidence and his/her knowledge is far away from that of the other experts , THEN the corresponding weight of knowledge is not important .
 These two extreme cases lead to the generation of 18 fuzzy rules presented in Table 3 . 3.2.3. Aggregation of knowledge of experts
At this step, the knowledge of experts is aggregated using a linear combination. The normalized weights are calculated by w =w v /sw with sw  X  P h (knowledge of experts) VP , P , 0 , N and VN are then replaced by the numerical values B= [1, 0.5,0, 0.5, 1] T , respectively. Thus, the aggregation of knowledge of experts R ( x k , y l )in Table 1 is recalculated using the following equation:
R  X  x ; y l  X  X  : W T U B : where W  X  X  w 0 v ; v A  X  1 ; h  X  9  X  that there exists no influence. The human knowledge conformity criterion HKC k , b can be calculated from the R ( x k , y
Section 2.3. In most of the cases, the result of aggregation for knowledge of different experts is a real value in the interval [ 1, 1]. Thus, it is more general than the knowledge coming from an individual expert taking values from { 1, 0, 1} only.  X  &gt; 3.3. Combination of fuzzy sensitivity and human knowledge conformity
The two previous criteria, i.e. the fuzzy sensitivity FS k , b human knowledge conformity HKC k , b , are combined in order to more robust for selecting the input variables (Model M 3 in Fig. 3 ). The combination is based on the fuzzy rules presented in Table 4 .
These fuzzy rules are used to build a fuzzy model in which FS and HKC k , b are taken as two input variables and FGR k , b variable. The output variable FGR k , b takes the same membership functions as those of FS k , b (shown in Fig. 5 ). The membership trimf ( x ,[ f , g , g ]), where the parameters e , f , g are defined by e  X  min Obviously, the output variable FGR k , b varies in the range of [0, 1].
The closer the value of FGR k , b is to 1, the more the corresponding variable x k is relevant. 4. Simulation
In this section, the usefulness and effectiveness of previous criteria using an artificial data set and an analytical function are validated. The performance of these proposed criteria has been compared with a classification based hyperbox method ( Thawon-mas and Abe, 1997 ) and Fuzzy Curves and Surfaces (hereafter FCS) method ( Lin et al., 1998 ) . As human knowledge is not available in these simulation examples, the NS and FS are only used as relevancy criteria for ranking input variables. Both the results of
NS and FS are normalized in the interval [0, 1] for calculating relative sensitivity ranks of the input variables. Thus, the closer the sensitivity value is to 1, the more the corresponding input variable is relevant related to the other input variables. Example 1. Iris data set
The well-known Iris data set ( Fisher, 1936 ) consists of 150 data classes. Some of Iris data can be considered as noisy data. The ranking results obtained from the criteria NS and FS are given in Table 5 .

From Table 5 , it is seen that the ranking results of NS (Section 2) and FS (Section 3) criteria are quite different. The most relevant variable for NS is x 1 , which is considered as the most irrelevant variable for FS. Moreover, x 3 is the 2nd relevant variable for FS and the most irrelevant variable for NS. This difference is related to the fact that the fuzzy criterion is more capable of taking into account significant data variation trend and filtering useless data variations.

Table 6 gives the two most relevant inputs obtained by each of the three selection criteria as well as their correct recognition rates for the set of Iris data when applying the fuzzy c-means classifier ( Wang et al., 2004 ) to the two most relevant variables.
From Table 6 , it is noticed that the result of the Abe X  X  hyperbox criterion is the same as that obtained by FS. The correct recognition rate of NS criterion is smaller than those of the two other criteria and the combination of x 3 and x 4 leads to the best classification effect for the set of Iris data. This result means that the fuzzy sensitivity criterion, developed for treating small sets of learning data with strong variation trends, can also be applied to big sets of noisy learning data and obtain the same accuracy as the classical classification based variable selection criteria. However, the NS criterion is efficient for treating small sets of learning data with significant variation trends but inefficient for treating big sets of data with noises or nonsignificant variation trends. Example 2. a complex related nonlinear function y  X  sin  X  6 x 1  X  sin  X  4 x 2  X  X  sin  X  2 x 3  X  sin  X  5 : 4 x where x 1  X  cos  X  e  X  x 8  X   X  , x 2  X  1 x 5  X  x 5  X  cos  X  x  X  x
 X  X  t U D , t = {0,1}, x  X  1 ; 1 ; i  X  1 ; ... ; 4  X 
In this example, ( x 1 , x 8 ), ( x 2 , x 5 ), and ( x 3 , x respectively. d is a random variable uniformly distributed in the interval [ 1, 1]. t is a Boolean value, i.e. t A {0, 1}. For testing the robustness of the selection methods, p% of noises to the learning data of x is introduced. t =1 when a noisy data is generated, otherwise x , y , x 8 are uniformly generated on the interval [ 1, 1] and then they are used for computing the values of the other input variables x , x , x 3 and x 4 as well as the values of the function y .
In order to evaluate the pertinence of a subset of t selected is projected on the sub space of X t and then obtain a new function g ( x , x (2) , y , x ( t ) ) in which all the variables of X t mask the other variables by calculating the mean of original function f ( X ) for the removed variables. { x (1) , x (2) considered as the most relevant variables if and only if the general mean of 9 f g 9 , denoted as ME , is smaller than the other subset of t variables. The smaller the value of ME is, the more the selected input variables are relevant.

Fig. 8 illustrates how ME varies with the number of learning data z for NS and FS when selecting four most relevant input variables. These learning data do not include any noise ( t =0). It is found that both sensitivity criteria lead to small values of ME (between 1.3 and 1.9) and their values are very close when the number of learning data is increased. For small number of learning data, FS leads to better performance (low values of ME ) in the selection of relevant variables.

Fig. 9 shows how ME varies with data noises for 10,000 learning data when selecting four most relevant input variables. It is seen that the performance of NS and FS are similar for small data noises. However, for important data noises, values of ME are quickly increased for NS but FS is relatively robust and less sensitive to data noises. Data noises can be effectively filtered by the fuzzy models.

Table 7 compares the performances of three variable selection criteria, such as NS, FS and FCS. This comparison has been carried out by selecting the four most relevant variables from a small set of learning data without noise ( z =100) and a big set of learning data without noise ( z =10,000).

It is noticed that NS leads to more accurate result and smaller values of ME (0.96) for the big set of learning data (num-ber=10,000). Contrarily, FS leads to better result of variable selection and small value of ME (1.60) for the small set of learning data (number=100). In addition, using the recursive selection algorithm in Fig. 6 , FS can effectively filter the correlations between the variables. Moreover, both NS and FS lead to more accurate results than FCS. The results show that the proposed sensitivity criteria are more efficient than the FCS criteria. In fact, the proposed sensitivity criteria take into account complete information variations included in the whole set of input variables after removing one individual variable, while FCS is based on evaluation of individual variables and pairs of variables.
In Section 4, we have used two previous simulation examples to validate the effectiveness of fuzzy sensitivity (FS) criteria. In
Section 5, we illustrate the procedure of combining the human knowledge using an application example in nonwoven process modeling. 5. Application example
The nonwoven process is a complex industrial process dealing with a great number of process parameters, the nonlinear relationship between process settings and product properties, and the interdependencies between process parameters. More-over, the number of trials is rather limited, due to the cost and time for doing experiments on this process.

In this case, the experimental data have been measured during the design procedure of a fibrous material dedicated to specific liquid absorption. Over 25 data sets are available for analysis.
Eight process parameters related to the cross-lapper and needle-loom are taken as input variables. They include x : in-feed apron speed of cross-lapper ( m/min ), x : delivery apron speed of the cross-lapper ( m/min ), x : production speed ( m/min ), x : stroke frequency ( st/min ), x : penetration depth of needles ( mm ) x : needleloom draft ( % ), x : number of layers , x : stroke density ( st/cm 2 ).
 These parameters are pre-selected by nonwoven experts according to their possible influence on  X  X orosity X . Porosity is one of the main critical structural parameters related to super-absorbent properties of materials and then taken as output variable of the model. The bigger is the porosity, the more important is the capacity of absorption of material.

First, the algorithm in Fig. 6 is applied in order to select the most relevant process parameters and remove the least relevant and redundant ones. The related steps are shown in Table 8 .
Theoretically, these 8 preselected process parameters can be divided into two categories: direct parameters and indirect parameters. The direct parameters can be obtained by taking measures from related sensors or can be regulated directly on the process. The indirect process parameters can be calculated from the values of direct parameters according to some known physical laws. In this case, the variables ( x 6 , x 3 , x 2 ), ( x are related according to the physical relations.

In Table 8 , a direct parameter x 5 : penetration depth of needles and three indirect parameters x 6 : needleloom draft , x 7 layers and x 8 : stroke density , are selected using the proposed algorithm in Fig. 6 .

Next, the human knowledge is integrated in the procedure of selection using the model M 2 in Fig. 3 . The human knowledge is extracted from the predefined questionnaire describing the relation between the identified process parameters and the structural parameter  X  X orosity X .
 This questionnaire is filled by a group of 5 experts shown in Tables 9 and 10 presents the results of the knowledge aggregation procedure.

From Tables 9 and 10 , it is noticed that, for x 5 : penetration depth of needles , the knowledge of Expert 3 has the weakest weight (0.43) because it is evaluated by a low level expert. The knowledge of Expert 2 for x 6 : needleloom draft has a medium weight (0.50) although it is evaluated by a high level expert because of its great dissimilarity (1.00) related to the others.
Moreover, the knowledge of Expert 5 for x 7 : number of layers has also the weakest weight (0.22) because it has both weak confidence and great dissimilarity (1.50) related to the others.
The knowledge of Expert 1 for x 8 : stroke density has also a medium weight (0.50) because of its great dissimilarity (1.00) related to the others and weak confidence. In this way, nonrelevant knowledge of experts can be effectively filtered from this aggregation procedure. According to the final aggregated results of human knowledge, the x 5 : penetration depth of needles ( mm ), x number of layers , x 6 : needleloom draft ( % ) are considered as more important than x 8 : stroke density ( st/cm 2 ).

The ranking results as well as the values of different selection criteria are given in Table 11 and Fig. 10 .

From Table 11 and Fig. 10 , it is found that the parameter x penetration depth of needles is the most relevant for FS but the most irrelevant for NS. This difference is due to the fact that the fuzzy criterion is able to take into account the significant variation trend of learning data (see Fig. 11 ). Physically, this parameter strongly depends on the behavior of fiber, including its mechanical behavior during the needlepunching.
 Porosity (%) Weak 
Moreover, the influence of x 7 : number of layers is quite important (rank 2) according to HKC criterion, but effectively underestimated by NS (rank 3) and FS (rank 4). This difference is mainly due to the weak variation of the learning data of this parameter (see Fig. 12 ).

The parameter x 8 : stroke density is the 2nd most relevant variable for NS and FS but has no important influence (rank 4) according to the human knowledge conformity. Also, x 6 : needle-loom draft is the 3rd most relevant variable for HKC but the most relevant variable for NS. This result shows that the experimental data based selection criteria are limited when the data are measured in a very small range (proximity) (see Figs. 13 and 14 ).
In this case, the integration of human knowledge can effectively improve the selection results.
 Based on the previous selection results, it is concluded that the
FGR criterion provides a good compromise between the experi-mental data analysis and human knowledge judgments, especially when the number of trials is very limited and expensive. This criterion is efficient for evaluating the degree of relevancy of process parameters in the complex processes. 6. Conclusion
This paper presents two relevancy criteria for selecting the most relevant process parameters related to a specific quality parameter. The two proposed criteria combine the degree of relevancy obtained from the experimental data sensitivity (NS and FS criteria) and conformity of human knowledge (HKC criterion) using linear combination (LGR criterion) and fuzzy models (FGR criterion).

The effectiveness of these methods has been validated using an artificial data set, an analytical function and a case study of fibrous material development. The related results show that both criteria can lead to relevant input variables but the FGR criterion is more efficient because it is more robust, less sensitive to measured data noises using fuzzy techniques. Moreover, this fuzzy relevancy criterion is more sensitive to significant data and more efficient for physical interpretation because it can effec-tively filter nonvariation and small range of measuring data. This result is validated even when the number of learning data is small and the data is noisy, which is frequently encountered in industrial modeling problems.

In order to compensate the lack of information from the experimental data, fuzzy techniques have also been applied to integrate the process and product expert X  X  knowledge into the global relevancy criteria. The proposed selection fuzzy system constitutes the first step for solving the problem of industrial process modeling.
 References Porosit X  (%)
