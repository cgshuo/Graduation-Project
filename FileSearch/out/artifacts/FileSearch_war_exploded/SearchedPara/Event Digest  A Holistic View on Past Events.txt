 For a general user, easy access to vast amounts of online informa-tion available on past events has made retrospection much harder. We propose a problem of automatic event digest generation to aid effective and efficient retrospection. For this, in addition to text, a digest should maximize the reportage of time, geolocations, and entities to present a holistic view on the past event of interest.
We propose a novel divergence-based framework that selects ex-cerpts from an initial set of pseudo-relevant documents, such that the overall relevance is maximized, while avoiding redundancy in text, time, geolocations, and named entities, by treating them as independent dimensions of an event. Our method formulates the problem as an Integer Linear Program (ILP) for global inference to diversify across the event dimensions. Relevance and redun-dancy measures are defined based on JS-divergence between inde-pendent query and excerpt models estimated for each event dimen-sion. Elaborate experiments on three real-world datasets are con-ducted to compare our methods against the state-of-the-art from the literature. Using Wikipedia articles as gold standard summaries in our evaluation, we find that the most holistic digest of an event is generated with our method that integrates all event dimensions. We compare all methods using standard Rouge-1, -2, and -SU4 along with Rouge-NP, and a novel weighted variant of Rouge.
  X  Information systems  X  Retrieval tasks and goals; Summa-rization; Probabilistic retrieval models; Information retrieval di-versity; Linking; Event digest; Diversification; Semantic annotations
Today, in this era of digitization, the World Wide Web plays an integral role as an effective and efficient digital medium for pro-viding information on events of global as well as local importance. Large volumes of online news data are generated by media houses and other independent providers as they report eagerly on current events or those that have happened in the past. Contributing to the volume, variety, and velocity of the data, social media is also prov-ing to be a new popular medium of news propagation across the globe. On one hand, this change from traditional print media to publishing online news has given rise to less polarizing and more democratic journalism. On the other hand, from the perspective of a general user, vast amounts of information with a high degree of redundancy have made it difficult to connect the dots and get a holistic understanding on past events with large ramifications.
State-of-the-art vertical news search engines, like Google News, are among the first choices of a general user when seeking infor-mation on past events. However, these search engines are keyword based and retrieve a large ranked list of news articles, all of which are temporally biased to the query issuing time. It is hard for a user to sift through all retrieved news articles so as to get a holistic view on a past event. For such an information need, it would be useful if a system could automatically generate an event digest by extracting text from retrieved news articles. With such a digest given, the user can first get a broader view on the event and then, if desired, refer to individual documents to get necessary details. A concrete example of an event digest is given in Table 1. For further motivation con-sider this scenario: A journalist, Laura Lang, wants to quickly get a holistic view on the event of East Timor X  X  independence, illustrated in Table 1. She uses Google News and issues the keyword query { East , Timor , votes , independence , Indonesia , referendum }. Not to her surprise, she finds that the system retrieves numerous (more than one thousand) news articles published by different news agen-cies. To get a good understanding of the event, she tediously sifts through many articles, most of which contain redundant informa-tion. However, with a concise digest given, she can first get an overview of the event, and then jump into news articles connected to the excerpts in the digest to get necessary details.

One plausible solution to the information overloading problem is to link orthogonal sources of information on past events [20, 22, 25]. With a similar goal, in a recent work [19, 20], we investigated a linking task that leveraged semantic annotations to identify relevant news articles that can be linked to excerpts from Wikipedia articles. We motivate that Wikipedia articles summarize past events by often abstracting from fine-grained details, and on the other hand, online news are published as the events happen and cover all angles with necessary details. Individually, they both fall short in providing a full picture due to context missing from news articles, and fine-grained details omitted from Wikipedia articles. However, connec-tions can facilitate navigation between them and help in getting a larger picture. One drawback of such a linking task is that for an excerpt from Wikipedia that represents an event with long ramifi-cations, like the one in our example, many news articles get linked to it. An event digest in such a case becomes an intermediate level of linking that presents a holistic view . Excerpts from Wikipedia, an abstract view , are connected to excerpts in the digest which are in-turn connected to news articles that give a detailed view as il-lustrated in Figure 2. As other use cases, since event digests are generated with a fixed length, smaller digests can be considered as sneak peaks (snippets) into news articles, retrieved as a search result. Longer digests can be treated as automatically generated reports for deeper analysis of an event X  X  ramifications.
In this paper, we propose to address the following problem: given an event from Wikipedia along with a time interval indicating its occurrence period, automatically generate a digest that presents a holistic view on the event. As input, we consider: 1) an event query that comes with a short textual description, and a time interval in-dicating when the event happened; and 2) a set of textually pseudo-relevant documents retrieved using a standard retrieval model with a keyword query generated from the event description. As output, our goal is to return a diverse set of excerpts from news articles to compose an event digest with its total length under a given length budget such that it presents a holistic view on the event in the query.
Traditional multi-document extractive summarization tasks [4, 12, 14, 16, 18, 21, 31] focus on generating textual summaries from filtered relevant documents such that they are as close as possible to a manually created summary. Unsupervised methods in this realm, consider only text to maximize relevance and reduce redundancy in the generated summaries. However, we define an event to be a joint distribution over independent text , time , geolocation , and en-tity dimensions, indicating the time period, geographic locations, and entities affected by its ramifications. To present a holistic view on an event, we motivate that relevant information along all four di-mensions has to be diversified. For the example in Figure 1, diver-sifying across time will result in information on causality (excerpt 1 and 2), effects during happening (excerpts 3 to 5), and after-math (excerpts 6 to 8) of the event. Similarly, diversifying across ge-olocations will give information on the entire geographical scope, and diversifying across entities will give information on all persons, places, and organizations involved. We refer to such a view as an event digest that contrasts from a traditional notion of a summary. Challenges. Leveraging text, time, geolocation, and entity dimen-sions of an event to automatically generate an event digest becomes a challenge. Further, we note that the event descriptions are ver-bose. Thus, it becomes a challenge to deal with verbosity to select relevant excerpts into the digest.
 Contributions made by this paper are the following: 1) we pro-pose the new problem of event digest creation. 2) We present a novel method that uses a divergence-based framework , and formu-lates the problem as an integer linear program (ILP) to perform global inference for the event digest creation. To the best of our knowledge, we are the first to present a unified method to explicitly diversify across text, time, geolocations, and entities using query modeling approaches. 3) We present an experimental evaluation on three real-world datasets by treating Wikipedia articles central to an event query as a gold standard.
 Organization. In Section 2 we review the literature; Section 3 gives details of our approach. Conducted experiments and their results are described in Section 4. We conclude in Section 5.
We contrast the event digest generation problem defined in this paper from prior works along the following five lines.
 Extractive Summarization focuses on selecting sentences from a single or multiple input documents to create a summary. This line of research has received much attention in the past [4, 12, 14, 16, 18, 21, 31]. It was also investigated at the Document Understanding (DUC) and Text Analysis Conferences (TAC). From various sub-classes of extractive summarization, we identify three that seem to be most related to our task: multi-document summarization , query focused multi-document summarization , and timeline generation . In the realm of unsupervised summarization techniques, MMR [4] stands as the most popular approach that defines an objective func-tion rewarding relevance and penalizing redundancy. McDonald et al. [18] proposed an ILP formulation with a slight change to the original MMR objective function. Litvak and Last [16], and Ried-hammer et al. [21] proposed to use key phrases to summarize news articles and meetings. Gillick et al. [8] maximized the coverage of the salient terms in input documents to generate summaries. How-ever, in the problems investigated by all above mentioned works, there is no notion of a user query. This stands as a difference to our problem where we have to generate a digest for a given event query. Further, we incorporate additional semantics to identify in-formational excerpts for the digest. However, in our approach, we incorporate the formulation given by Riedhammer et al. [21] to de-velop our text-only method.
 Query-Focused Multi-Document Summarization takes into con-sideration a topic that is input as a user query to generate a topic-focused summary. For this task, supervised approaches have re-cently proved to be effective [12, 14, 31]. However, they require labeled data for training. Firstly, these approaches focus on short queries, like TREC adhoc topics used in TAC, whereas in our prob-lem, event queries are verbose textual descriptions of events. Sec-ondly, we present an unsupervised approach that formulates an ILP for event digest generation.
 Timeline Generation as a subclass that focuses on events, has also received attention [1, 5, 28]. The main goal is to generate a time-stamped list of updates as sentences, key phrases, etc., covering different facets of an event. As an early approach, Allan et al. [1] proposed clustering-based approaches on entities and noun phrases to generate a timeline for a given event. Chieu et al. [5] leveraged burstiness as a ranking metric to identify sentences to be included into a timeline. McCreadie et al. [17] proposed an incremental update summarization task and presented supervised methods to address it. Recently, in a different direction, Shahaf et al. [22] ad-dressed the information overloading problem by presenting a map of connected news articles that captures the story development of a given event. Timeline generation and incremental update sum-marization tasks aim at presenting a concise ordered summary of events. This is different from our task in two ways: firstly, we do not focus on the ordering of the excerpts in a digest; and secondly, we focus on generating a holistic view by explicitly diversifying across different dimensions of a past event to aid retrospection. Search Result Diversification problem originally aimed at identi-fying documents from a relevant set that catered to different infor-mation needs of a user query. Further, we look into prior novelty-based strategies to diversify search results. MRR [4] is among the first formulations that penalized documents based on redundancy. This was extended by Zhai et al. [30] for language models and they proposed a risk minimization framework to diversify search results. Wang et al. [26] proposed a mean-variance analysis (MVA) diver-sification objective. A recent work that becomes interesting is pre-sented by Dou et al. [6] as they attempt to diversify across multiple implicit sub topics by treating them as dimensions of the query. All the methods above cater only to text, and extending them to time, geolocations, and entity dimensions is not straightforward. Passage Retrieval tasks have been well studied in the past. Sys-tems retrieving passages have been proven to be effective for IR tasks when the documents are long or contain diverse topics. One popular way to define a passage is based on the document structure [3, 9, 23]. Another example of passages are windows consisting of a fixed number of words. These can be further classified into overlapping [3] or non-overlapping windows [13]. The traditional passage retrieval tasks do not take diversity of the passages into consideration. However, we find that the definitions of the passages to be complementary to our excerpts.
We present our approach to create a concise digest for a given event that presents a holistic view by describing as many aspects as possible. Intuitively, while selecting excerpts from the input doc-uments, if the reportage of time, geolocations, and entities associ-ated with the input event is maximized then a holistic view can be developed. We propose a novel divergence-based framework for event digest creation. Under this framework, our method estimates independent query and excerpt models, and maximizes the rele-vance while avoiding inter-excerpt redundancy based on the KL-divergence between the models. We define an event as a joint dis-tribution over text, time, geolocation, and entity dimensions. Our method extends the divergence-based retrieval framework, and for-mulates a single unified linear problem to perform global inference across the event dimensions. We design an ILP with appropriate binary indicator variables and constraints. We begin by defining our notations and representations.
 Event Query q is derived from a given Wikipedia event that comes with a short textual description and a time interval indicating its occurrence period. We assume that an event is a joint distribution over four independent dimensions: text, time, geolocation, and en-tity. Thus, from a given query we derive the following four parts from the textual description: query-text part q text as a bag of tex-tual terms; query-time part q time as a bag of explicit temporal ex-pressions; query-space part q space as a bag of geolocations; and query-entity part q entity as a bag of entity mentions.
 Excerpt  X  is a single unit of an input document that gives informa-tion on an event. In this work, we fix an excerpt as a single sen-tence, however other definitions may be adopted depending on the application. Analogous to the query, each excerpt has four parts: text  X  text , time  X  time , geolocation  X  space , and entity  X 
In our method, we sometimes use the entire collection as a single coalesced document and refer to its corresponding parts as C C Time dimension is modeled as a two-dimensional space T  X  T , as proposed by Berberich et al. [2]. We normalize a temporal ex-pression to an interval r tb,te s with begin time tb and end time te . Further, each interval is described as a quadruple r tb l where tb l gives the lower bound, and tb u gives the upper bound for the begin time tb of the interval. Analogously, te l and te the bounds for the end time te . A time unit or chronon t indicates the time passed (to pass) since (until) a reference date such as the UNIX epoch. We fix the granularity of a time unit to a single day. Geolocation dimension is modeled using the geodetic system in terms of latitude  X  longitude . A geolocation s is represented by its minimum bounding rectangle (MBR). Each MBR is described as quadruple r tp,lt,bt,rt s , where point p tp,lt q is the top-left cor-ner and p bt,rt q is the bottom-right corner of the MBR. A geolo-cation unit g refers to a geographical point in our two-dimensional grid. Further, we empirically set a minimum resolution resol resol long of the grid to smooth out noisy annotations at a very high granularity (like streets and avenues).
 Entity e refers to a location, person, or organization. Our entity di-mension represents all entities in the YAGO2 [10] knowledge base. We use the YAGO URI of an entity, as its unique identifier while estimating query-and excerpt-entity models.
The divergence-based framework with the independence assump-tion between the dimensions allows us to estimate the correspond-ing query models uniquely. For this, we first expand the original parts of a query (other than text) with the given input set of the documents, thus treating them as pseudo-relevant. Intuitively, by expanding the query parts, we cope with overly specific annota-tions in the original query. We refer to our prior work [20] for more detailed explanation. We estimate the independent query models from corresponding expanded parts as follows.
 Query-Text Model Q text . Query modeling for text is a well-studied problem. The main intuition is that the query-text model should capture the true intent of the query in the text dimension. In our approach, we treat the set of excerpts R in the input docu-ments as pseudo-relevant, and estimate a feedback model. We then combine the feedback model with the empirical query model, esti-mated from q text , to boost salient terms for the event in the query. Since the best way combining is through linear interpolation [29], we define the generative probability of a term W as,
P p W | Q text q  X  p 1  X   X  q  X  P p W | q text q`  X   X   X  A term W is generated from the feedback model with  X  probability and from the original query with p 1  X   X  q probability. Since we use a subset of the available terms, we finally re-normalize as, Query-Time Model Q time can be understood as a probability dis-tribution in our time domain T  X  T that captures the true temporal scope of an input event. We assume that the time part q time query is sampled from Q time . The generative probability of a time unit t from the query-time model Q time is estimated by iterating over all the time intervals r tb,te s P q time as, where 1 p  X q function returns 1 if there is an overlap between a time unit t and interval r tb l ,tb u ,te l ,te u s . If a time unit overlaps with a time interval then we add a probability mass proportional to the inverse of the interval X  X  area in the space. Intuitively, this assigns higher probability to time units that overlap with a layer of spe-cific (smaller area) intervals in q time . For computation of areas and intersections of temporal intervals we refer to [2]. To han-dle near misses [20] perform an additional two-dimensional Gaus-sian smoothing that blurs the boundaries of Q time by spilling some probability mass to adjacent time units. With this, the new genera-tive probability is estimated as, where G  X  denotes a 2-D Gaussian kernel that is defined as, Finally, we re-normalize similar to Equation 2.
 Query-Space Model Q space . Analogous to time, the query-space model is a probability distribution from which the geolocation part of a given query is sampled. It captures the true geographical scope of the event described in the query. The generative probability of a geolocation unit g from the query-space model Q space by iterating over all r tp,lt,bt,rt s P q space is estimated as,
P p g | Q space q  X   X  The 1 p  X q functions indicates an overlap between a space unit l and a MBR r tp,lt,bt,rt s . Since we normalize with the area of the MBR, a geolocation unit gets higher probability if it overlaps with many specific geolocations (MBR with smaller area) in q space of a MBR, |r tp,lt,bt,rt s| can easily be computed as p rt  X  lt ` resol lat q  X p tp  X  bt ` resol long q . To avoid the issue of near misses we estimate  X  P p l | Q Space q with additional Gaussian smoothing as described in Equation 4, and finally re-normalize as per Equation 2. Query-Entity Model Q entity is a probability distribution over our entity space and captures the entities that are salient to the event in a given query. To estimate the Q entity from q entity a similar process as described for the query-text model, by com-bining the empirical entity model with a feedback model estimated from the pseudo-relevant excerpt set R . The generative probability of an entity e is estimated as,
P p e | Q entity q  X  p 1  X   X  q  X  P p e | q entity q`  X   X  where P p e | q entity q and P p e | E entity q are the likelihoods of gen-erating the entity from the original query and pseudo-relevant ex-cerpts  X  P R respectively. We finally re-normalize as in Equation 2. Excerpt Model in each dimension is estimated by following a sim-ilar methodology as for the query modeling. However, we addi-tionally add Dirichlet smoothing [29] to the excerpt models with the collection C as a background model. For the text dimension, the excerpt-text model E text is formally estimated as, where  X  P p W | E text q is computed according to Equation 1 and  X  is set as the average excerpt length of our collection [29]. Similarly, for time, geolocations, and entity models we follow Equation 3, 5, and 6 respectively. However for estimating E time and E space do not employ the Gaussian smoothing (Equation 4) as this tends to introduce additional information into the excerpts artificially.
After estimating necessary query and excerpt models, we next describe our ILP designed for the event digest generation. With our assumptions in mind, we first specify our exact requirements. A digest should portray the following characteristics: i) contain relevant excerpts to a given event query; ii) avoid redundancy; iii) maximize the reportage of the temporal scope, geolocations, iv) length in words should not be more than a given budget L . To design an ILP, we define the following binary indicator vari-ables: S i indicates if a candidate excerpt  X  i is finally selected into the digest; for a given excerpt  X  i , M ij indicates the single most redundant excerpt  X  j that is already selected into the digest; T dicates if there is an overlap with t P Q time ; G ig indicates if there is an overlap with g P Q space ; E ie indicates if there is an overlap with e P Q entity . Using the above definitions, we can now pre-cisely formulate our ILP as illustrated in Algorithm 1. Algorithm 1 ILP to generate an event digest.
 Objective Function can be explained as four parts: text, time, ge-olocation, and entity. In the text part, rel i function computes the relevance between an excerpt  X  i and query q . Each excerpt is pe-nalized with the maximum textual redundancy score red ij with the already selected excerpts into the digest. The parameter  X  balances textual relevance and redundancy estimates.

To explain the rest of the formulation, let us consider the time part in isolation. For each excerpt, the following steps are followed: first, identify the time units that overlap with the given Q ond, weights w it of the time units are summed and assigned as temporal scores. The rest of the parts, i.e., space and entity, are handled similar to time. To specify the global importance of the dimensions, four parameters,  X  ,  X  ,  X  , and  X  are introduced into the objective function. Finally, we normalize the time, geolocations, and entity parts with the size of their corresponding query models denoted as N t , N g , and N e respectively.
 Constraints defined for our ILP are categorized into the four parts corresponding to the objective function. Constraints on text are de-fined on the binary indicator variable M ij . Constraints 1-3 enforce that exactly one excerpt in the digest is selected for consideration as most redundant. Constraint 4 is to ensure that if M ik  X  is most redundant to  X  i and they both are selected into the final digest. Constraints 5, 8, and 11 ensure that each unit in the query model is covered by at least one excerpt in the digest, thus maxi-mizing total coverage of the query units in the digest. Constraints 6, 9, and 12 specify that if an excerpt is selected then overlapping units across the dimensions are covered. For these constraints, we introduce an additional binary variable o ik that indicates if there is an overlap between a k th unit in query with excerpt  X  i model. Fi-nally, constraints 7, 10, and 13 are required as sanity check that a unit can be covered only if an overlapping excerpt is selected. Textual relevance rel between a given query q and excerpt  X  in the objective function is estimated by computing the KL-divergence KLD between their language models, denoted as Q text and E respectively. Formally, this is given as, Textual Redundancy red between any two excerpts can be sim-ply interpreted as the similarity between them. For this, we com-pute the Jensen-Shannon divergence JSD which is the symmetric variant of the KLD and a popularly used distance metric. In this case, lower divergence indicates higher redundancy between the excerpts. Formally, this is defined as, Weights w it , w ig , and w ie specify the importance of the time t , ge-olocation g , and entity unit e respectively for an excerpt  X  our divergence-based framework, we define the weights as the neg-ative KL-divergence between the generative probability of a unit from the query and excerpt models. Formally, we define weights for all dimensions analogous to time as,
For a single dimension considered in isolation, summing over the weights gives the overall divergence between excerpt and query models in that dimension. For example, in the time dimension the divergence KLD p Q time || E i time q can be computed by summing over query time units as  X  t P Q is maximized by globally minimizing the overall divergence of a query with entire digest. However, since the KL-divergence scores are not bounded, we normalize the weights across all excerpts as,
In our divergence framework, the redundancies in time, geolo-cations, and entity dimensions are minimized implicitly by maxi-mizing the coverage of the units in query models. However, at the same time, the relevance of excerpts in these dimensions are also considered. The ILP solver first selects excerpts that cover most important units (receiving high probability in query model) with the lowest divergence scores as indicated by their weights.
Next, we give details on the conducted experiments. For repro-ducibility, we make the experimental data publicly available
We begin by describing our test collections, query set, gold stan-dards, and measures used in the experimental setup.
 Test Collections. We perform experiments on three real-world datasets: 1) The New York Times Annotated Corpus (NYT) with about 2 million news articles published between 1987 and 2007; 2) English Gigaword corpus with about 9 million news articles pub-lished between 1991 and 2010; and 3) ClueWeb12-B13 (CW12) corpus with about 50 million web pages crawled in 2012. We pro-cess the queries in our test set with a standard query likelihood document retrieval model. Top-10 retrieved documents from each dataset are considered pseudo-relevant and input into our methods. http://resources.mpi-inf.mpg.de/d5/eventDigest/ Test Queries are generated from the timeline of modern history in Wikipedia that contains the most prominent news events in the past. We randomly sample 100 events occurring between 1987 and 2007 as test queries. Each query comes with a short textual de-scription and a time interval indicating when the event happened. Further, we automatically annotate each query with time, geoloca-tions, and entities by disambiguating mentions in their descriptions. Gold Standard. We consider a Wikipedia article that describes the specific event in a query as its human-generated or gold standard digest created by Wikipedians. Since these articles on past events are elaborate and cover most of the important aspects, they are apt for evaluating our task. For this, we manually identify Wikipedia articles that are central to an event query.
 Measures. We use the following measures:  X  Rouge-1 , Rouge-2 , and Rouge-SU4 measures [15] are well es-tablished for evaluating method-generated against gold standard (human-generated) summaries.  X  Rouge-NP : We introduce a new measure that takes into con-sideration only the noun phrases overlap. Generally, noun phrases represent the key concepts in a gold standard, and a larger overlap indicates better information coverage in the digest. This is further motivated by Taneva et al. [24] in their experimental evaluation.  X  weighted-Rouge (w-Rouge) : The above rouge measures eval-uate how close a method-generated digest is to the gold standard. However, due to the disparate quantity of text between a method-generated digest and the gold standard, these measures are not in-dicative of the diversity of excerpts in a digest. Thus, we introduce w-Rouge that computes Rouge-1 score of a method-generated di-gest S with each paragraph p of the corresponding gold standard GS . The individual Rouge-1 scores are weighted with the normal-ized length of each paragraph | p | | GS | . To get the final score for a method, we average over all queries q in query set QS . Formally, Additionally, we also report the mean variance ( MV ar ) of the w-Rouge across all the queries. Formally, this is given as, MV ar  X  1 where N is the number of paragraphs in GS . We assume that in a long Wikipedia article, each paragraph describes an aspect of the central event. Thus, a method-generated summary that gives di-verse information should show overlap with more number of para-graphs in the gold standard Wikipedia article. A method that gen-erates a digest that is closer to the gold standard by covering more aspects of the given event should have a higher mean F1 score and mean variance of w-Rouge.
 Implementation. All the methods are implemented in Java. For the temporal annotation, we use Stanford CoreNLP toolkit 3 annotate geolocations, we use an open-source gazetteer-based tool that extracts locations and maps them to the GeoNames 5 knowledge base. For entity annotations, we use the AIDA [11] system. We use the Gurobi ILP solver 6 in our experiments. https://en.wikipedia.org/wiki/Timeline_of_modern_history http://stanfordnlp.github.io/CoreNLP/ https://github.com/geoparser/geolocator http://www.geonames.org/ http://www.gurobi.com
We next describe the different methods that are compared in our experiments. We distinguish three frameworks that use integer lin-ear programs for global inference: 1) maximum marginal relevance [4, 18, 21], 2) coverage-based [7, 8, 27], and 3) divergence-based methods. While the first two are derived from literature as state-of-the-art frameworks for unsupervised methods, the third divergence-based framework is proposed in this paper. We extend the frame-works to incorporate time, geolocations, and entities, and design methods that leverage different combination of the dimensions un-der each framework. All our methods formulate the event digest problem as solvable ILPs.
 Maximum Marginal Relevance [4] is arguably the most popular unsupervised framework for generating document summaries. We compare the following two methods that fall under this framework:  X  Mcd : As first method, we consider the summarizer presented by McDonald et al. [18] that uses an ILP for global inference in summarization. Though they follow the MMR [4] style formula-tion, they make a slight change to the global objective function by introducing linear approximation. This results in candidates being penalized with the average redundancy to the already selected ex-cerpts. Their objective is defined as,
Maximize :  X  We refer to [18] for the full set of constraints. The generalized ILP framework allows us to define the rel and red functions using language modeling methods as described in Equation 8 and 9.  X  Rdh: More recently, Riedhammer et al. [21] propose an ILP formulation that got rid of the linear approximation in the global objective function of Mcd , thus giving an optimal solution. In their formulation, they introduce an additional binary variable M indicate the maximum redundancy of an excerpt to the already se-lected excerpts in the digest. Further, they have additional con-straints that are defined on this variable which leads to efficient convergence to the optimal value. Their global objective function is defined as,
Maximize :  X  We refer to [21] for full set of constraints. Similar to Mcd , we use the definitions for rel and red as given in Equations 8 and 9. Coverage-Based Framework [8] is also popular in the summa-rization community as an unsupervised global inference method. It follows the idea of implicitly reducing the redundancy in the fi-nal summary by maximizing the coverage of textual units. Prior works [7, 27] propose various definitions for such units in context of different tasks. This framework remains state of the art, and ap-proaches have shown to work well in comparison to other unsuper-vised global inference methods. At large, the framework is general enough and can easily be extended to our event dimensions. Their global objective function is defined as, where w i is defined as P p c | Q text q probability of generating a term from query-text model, and C i is a binary indicator variable that marks the occurrence of a term c in an excerpt  X  i . Using this framework, we design the following methods that consider differ-ent subsets of the four event dimensions:  X  Cov-txtEM and Cov-txtQM : As text-only methods, Cov-txt max-imizes the coverage of the salient terms associated with an event. In their original work, Gillick et al. [8] relied heavily on preprocess-ing the documents to be summarized including key-phrase extrac-tion. For this work, we do not do any preprocessing. In contrast, we make use of a query-text model Q text to capture salient textual terms for the event in the query. We motivate that this makes their method more query-focused and stronger as a baseline. To demon-strate the advantage of incorporating a query model, we compare two methods: Cov-txtEM that uses only the empirical terms (after stop words removal), and Cov-txtQM that estimates a query model by expanding the query with terms from the pseudo-relevant docu-ments as shown in Equation 1.  X  Cov-T , Cov-S , Cov-E , Cov-ST , and Cov-EST : In principle, the coverage-based method can easily be extended to time, geoloca-tions, and entity dimensions. In the time dimension, we adapt the objective function in Equation 14, such that it selects excerpts by maximizing the global coverage of all time units  X  P Q time label this method as Cov-T . Similarly, Cov-S , and Cov-E maxi-mize the coverage of geolocation units l P Q space and entities e P Q entity respectively. We motivate that Cov-E method is similar to the original approach proposed by Gillick et al. that maximizes concepts, which in our case are entities. It is not hard to think of methods that maximize a combination of the dimensions in their objective functions. Cov-ST maximizes the coverage of geoloca-tions and time, and Cov-EST additionally combines entities.
In all the above methods, weights w i as in Equation 14, are gen-erative probabilities from query models described in Section 3.2. Divergence-Based Framework , discussed in Section 3, takes into consideration the divergence between query and excerpt models in all the dimensions. We note that the text-only method under this framework is equivalent to Rdh that defines its rel and red func-tions in Equation 13 based on the KL-divergence between corre-sponding text models. We design the following methods:  X  Div-T , Div-S , Div-E , Div-ST , Div-txtST , Div-EST , and Div-txtEST : In Section 3, we present a unified divergence-based frame-work that maximizes the textual relevance and minimizes the re-dundancy across text, time, geolocations, and entities. We label this as the Div-txtEST method. However, one can think of methods that consider only a subset of the dimension. We thus design Div-T , Div-S , Div-E , Div-ST , Div-txtST , and Div-EST methods that lever-age a combination of text ( txt ), time ( T ), space ( S ), and entities ( E ) as indicated by the suffixes in their labels.
 Random. Finally, we consider the Rand method that selects ex-cerpts at uniformly random from the input top-10 pseudo-relevant documents until the length constraint is satisfied.
 Parameters of the methods were tuned by varying one parameter at a time while keeping the others fixed to observe the change in the overall result quality as described in [28]. We have two groups of parameters, first denoted by  X  that balances the relevance rel with redundancy red . Second, that specifies the importance of text, time, geolocations, and entities with parameters,  X  ,  X  ,  X  , and  X  re-spectively. For NYT, Gigaword, and CW12 datasets, we set  X  to 0 . 85 , 0 . 90 , and 0 . 95 respectively. In the second group of param-eters, we tune  X  ,  X  , and  X  while fixing  X   X  1  X  p  X  `  X  `  X  q . We empirically observe that setting the three parameters too high leads to a deterioration of the results. For NYT, Gigaword, and and  X   X  r 0 . 01 , 0 . 30 , 0 . 01 s . Finally, for the query models in Equa-tion 1, 3, 5, and 6, we use settings described in [20].

We compare the quality of event digests generated from the three different datasets. We also compare the variance of weighted-Rouge measure that we propose to highlight the diversification effect of each method.
 Rouge score analysis. Table 1, Table 2, and Table 3 show the re-sults of generating an event digest of length 250 words from NYT, Gigaword, CW12 documents respectively. We compare the digest generated by different methods against Wikipedia articles as gold standards, and report Rouge-1, Rouge-2, Rouge-NP, and Rouge-SU4 scores. We find that across all the three datasets the best qual-ity digest is generated by the Div-txtEST method.

Firstly, we note that the random method Rand already achieves a decent F1 score. Across the three datasets, selecting excerpts randomly from the top-10 input pseudo-relevant NYT and Giga-word news articles generate better digests as compared to CW12 web pages. The text-only methods, Mcd , Rdh , and Cov-txtQM per-form significantly better than Rand , as expected. Among the text-only methods, Rdh and Cov-txtQM show significant improvements over Mcd in terms of Rouge scores. At the same time, Rdh and Cov-txtQM follow different frameworks and prove to have over-all similar performance. However, Cov-txtQM method proves to be better for Gigaword, and CW12 datasets while for NYT, Cov-txtQM gets significantly lower Rouge-2 F1 score. Cov-txtEM that uses only the empirical query terms proves to be the worst text-only method, thus highlighting the advantage of incorporating our query-text model. Next, we look at the methods that extend the cov-erage based framework into the different dimensions. Cov-T and Cov-S do not prove to be effective in any dataset. The Cov-E gets significantly higher score from its contemporary methods consider-ing only time and geolocations. This method gets the highest gain over its contemporaries in the CW12 dataset. However, it always performs significantly worse than the text-only methods as shown in Table 4. The coverage-based methods in the time, geolocations, and entity dimensions get worse scores than the Rand due to rela-tively shorter digest generated. Later in the section, we discuss this in detail. Our proposed divergence-based methods perform bet-ter that the coverage-based methods across all three datasets. This is because Div-T , Div-S , Div-E , Div-ST , and Div-STE always per-form better than the Cov-T , Cov-S , Cov-E , Cov-ST , and Cov-STE methods. Next we analyze the different combinations of dimen-sions in the divergence framework. The text-only method under this framework is equivalent to Rdh that performs significantly bet-ter than Div-T , Div-S , and Div-E . However, different combinations of the time, geolocations, and entities as Div-ST and Div-STE per-form better than the text-only method. Finally, the Div-txtSTE with highest score proves to be the best method for our task. Variance Analysis. From our experiments so far what is clear is that event digests generated by the Div-txtEST method are clos-est to the gold standard Wikipedia articles. However, we perform an extended evaluation using the proposed w-Rouge measure that computes the mean Rouge-1 F1 score with respect to individual paragraphs in the Wikipedia articles. Firstly, we assume that each paragraph describes some aspect of the event. Thus, a larger mean with high variance in the weighted F1 score indicates higher cover-age of the Wikipedia paragraphs, and hence better diversity in the generated digest. As shown in Table 5, all methods get higher mean and variance from Rand across all three datasets. We find that the Div-txtEST method proves to be the method that generates most diversified digest by achieving the highest mean and MVar scores. The next best method is Div-txtST .
 Varying Digest Length. Next we analyze the effect on the quality of the digest by varying the digest length budget . Table 6 compares the Div-txtEST method with the text-only methods, Cov-txtQM and Rdh , in terms of Rouge-2. What we find is that for smaller length budget, Cov-txtQM performs better than other methods. We also find that both Cov-txtQM and Div-txtEST perform better than the Rdh across all the length budgets in Gigaword and CW12 datasets. The poor performance of the Rdh as compared to Cov-txtQM can easily be understood by analyzing their formulation. For very small budget of only 50 words, on average only two excerpts are selected into the digest by all the methods. Rdh first selects the most rel-evant excerpt, and then as the next it selects the one that is least redundant from the first. This causes the Precision to fall and an overall decrease in the F1 score. On the other hand, Cov-txtQM attempts to cover as many important terms with high probability in the Q text to maximize the coverage. This generates a better di-gest for the smaller length budget. However, in the NYT dataset, for larger length budgets, Cov-txtQM suffers due to the lesser re-dundancy in the news articles. Thus, as it tries to maximize term coverage, the Precision falls resulting in lower F1 scores as com-pared to Rdh . The effect of diversifying across time, geolocations, and entities in the Div-txtEST method is evident when the length budget is larger than 100 .
 Discussion. As the first point, we discuss the poor performance of the coverage framework in time, geolocation, and entity dimen-sions. The coverage-based framework selects excerpts such that the maximum number of units (of time, geolocations, or entities) in a given query are covered. The associated weights, as described in Equation 14, denote the importance of the units for a given query, thus forcing the ILP solver to cover more important units first. As a drawback, this framework does not take into consideration the im-portance of the units for the excerpts. This causes selection of ex-cerpts that may not be relevant. Moreover, in the dimensions other than text, excerpts that do not come with explicit annotations are automatically disregarded. Since a single temporal or geographi-cal expression can represent a large time interval (e.g., a century) or geographic area (e.g., a continent) respectively, the coverage of query units are easily maximized by selecting few excerpts. For example, the entire temporal scope of query in Figure 1 is covered by excerpt 8. This causes the Cov-T and Cov-S methods to gener-ate digests with fewer excerpts. Hence, they receive a worse Rouge score than the Rand which simply benefits from generating longer digest. On the other hand, the divergence-based framework addi-tionally regards the importance (higher generative probability) of a unit for the individual excerpts. While generating the digest, the ILP solver first selects excerpts which cover important query units with higher probability, thus lowering the overall divergence of the digest to the query. Moreover, since each excerpt is associated with an independent smoothed model for each dimension, no excerpt is disregarded for digest generation.

Next, we discuss the diversification of excerpts in the digest achieved by each method. We note that Wikipedia articles as gold standard digests are textually larger than the system generated di-gests. We assume that Wikipedia articles cover most aspects of a given event as a query. To get a better insight into the diversification of the excerpts, we compare the methods using w-Rouge, proposed by us. The Div-txtEST gets the highest mean and variance scores, and proves that it achieves the best diversification.

We next discuss the individual dimensions. Text is clearly the most important dimension in all our methods. However, we find that the text-only methods heavily rely on the query modeling tech-niques. Using only the empirical query terms leads to worse per-formance as shown by the Cov-txtEM method. The Cov-E method uses only entities instead of all terms, as motivated by Gillick et al., is not able to beat text-only methods in Rouge-2 scores. Time and geolocations are important indicators of identifying event-related excerpts and work well as a combination. Individually, we run into sparsity problems with very few annotations in excerpts. This is more pronounced in the CW12 dataset. Combination of text, time, and geolocations as the Div-txtST proves to be the second best method in the news datasets where we get comparatively more annotations. This is also due to the fact that every excerpt from a news article is also annotated with the publication date of the source article. Entities are more prominent in the CW12 documents and help to reinforce the text model. However, across all the datasets, combination of all four dimensions proves to be most effective. Gain/Loss analysis. Rouge measures assume that higher n-gram overlap with gold standard implies more relevant excerpts in the digest. Thus, to get insights into the overall quality of digests, we manually identify relevant excerpts (highlighted in green) by refer-ring to their source documents. We look at queries for which Div-txtEST shows the highest gain and worst loss in w-Rouge scores, when compared to the best among the text-only methods.

It achieves the highest gain in w-Rouge from the best text-only method for the query: January 26, 2001: An earthquake hits Gujarat, India, killing al-most 20,000.
 For this query, the best text-only method proves to be Cov-txtQM . Let us compare the digest generated by both methods: We note that the Div-txtEST method selects more relevant excerpts. The Cov-txtQM method maximizes the coverage of the textual terms in the query-text model which leads to selection of irrelevant ex-cerpts that enlist past earthquakes. These are however not selected by Div-txtEST due to their large divergence with query-time and -space models. Thus, due to combined diversification across the time, geolocations, and entities, Div-txtEST generates better qual-ity digest with more relevant excerpts and a wider coverage.
The Div-txtEST method gets the worst loss in w-Rouge from the best text-only method, Cov-txtQM , for query: November 22, 1995: Rosemary West is sentenced to life for killing 10 women and girls, including her daughter and stepdaughter, af-ter the jury returns a guilty verdict at Winchester Crown Court. The trial judge recommends that she should never be released from prison, making her only the second woman in British legal history to be subjected to a whole life tariff (the other is Myra Hindley). Let us compare the digest generated by both methods: Both methods select few relevant excerpts into the digest. How-ever, the text-only method selects excerpts based on term matching that leads to better Rouge scores. Div-txtEST method suffers due to the sparsity of annotations in the event dimensions.
We proposed the problem of generating a digest that presents a holistic view on a given Wikipedia event. We proposed a novel divergence-based framework for selecting excerpts from pseudo-relevant input news articles such that the global divergence between the digest and the query is minimized. The problem was formulated as an ILP for global inference to maximize the overall relevance of the digest to the input event query, while reducing inter-excerpt redundancies in text, time, geolocations, and entity dimensions. In experimental evaluation, we compared several methods, and found that our divergence-based method that considers all dimensions of an event proves to be most appropriate for event digest generation. [1] J. Allan, R. Gupta, and V. Khandelwal. Temporal summaries [2] K. Berberich, S. J. Bedathur, O. Alonso, and G. Weikum. A [3] J. P. Callan. Passage-level evidence in document retrieval. [4] J. Carbonell and J. Goldstein. The use of mmr, [5] H. L. Chieu and Y. K. Lee. Query based event extraction [6] Z. Dou, S. Hu, K. Chen, R. Song, and J. R. Wen.
 [7] E. Filatova. Event-based extractive summarization. ACL [8] D. Gillick and B. Favre. A scalable global model for [9] M. A. Hearst and C. Plaunt. Subtopic structuring for [10] J. Hoffart, F. M. Suchanek, K. Berberich, and G. Weikum. [11] J. Hoffart. Discovering and Disambiguating Named Entities [12] P. Hu, D. H. Ji, H. Wang, and C. Teng. Query-focused [13] M. Kaszkiel and J. Zobel. Effective ranking with arbitrary [14] Y. Li and S. Li. Query-focused multi-document [15] C. Y. Lin. Rouge: A package for automatic evaluation of [16] M. Litvak and M. Last. Graph-based keyword extraction for [17] R. McCreadie, C. Macdonald, and I. Ounis. Incremental [18] R. McDonald. A Study of Global Inference Algorithms in [19] A. Mishra and K. Berberich. Linking Wikipedia Events to [20] A. Mishra and K. Berberich. Leveraging Semantic [21] K. Riedhammer, B. Favre, and D. Hakkani-T X r. Long story [22] D. Shahaf, C. Guestrin, E. Horvitz, J. Leskovec. Effective [23] G. Salton, J. Allan, and C. Buckley. Approaches to passage [24] B. Taneva , G .Weikum. Gem-based entity-knowledge [25] M. Tsagkias, M. de Rijke, and W. Weerkamp. Linking online [26] X. Wang, H. Fang, and C. Zhai. A study of methods for [27] K. Woodsend and M. Lapata. Multiple aspect summarization [28] R. Yan, X. Wan, J. Otterbacher, L. Kong, X. Li, and [29] C. Zhai and J. D. Lafferty. Two-stage language models for [30] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond [31] S. H. Zhong, Y. Liu, B. Li, and J. Long. Query-oriented
