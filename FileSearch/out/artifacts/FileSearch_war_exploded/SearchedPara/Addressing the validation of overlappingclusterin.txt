
Computer Science Departament, Universidad de Oriente, Santiago de Cuba, Cuba Departament d X  X nginyeria Inform X tica i Matem X tiques, Universitat Rovira i Virgili, Tarragona, Spain 1. Introduction
Clustering has been widely investigated due to the wide range of situations where it may be applied: event detection and tracking, novelty detection, summarization, image segmentation, and so on. Cluster-and differences. A clustering is called partitional if each object may only belong to one cluster, other-wise the clustering is called overlapped. Most real-life problems are better modeled using overlapping clustering.

A very important step in the clustering task is that of evaluating the quality of clustering algorithms by means of quality measures. Such measures are divided into external, relative or internal. Internal measures asses the quality of a clustering without any knowledge external to it, opposite to the external measures, which compare the candidate clustering to a gold standard built by human experts. Relative measures take into account multiple runs of a clustering algorithm combining different parameters and selecting one of these runs as the best for obtaining a final score. In this work, we focus on external evaluation measures, specifically on those conceived for evaluating overlapping clusterings.
It is undesirable for an evaluation measure to yield high scores for poor quality clusterings, since that could lead to erroneous comparisons, where poorly performing algorithms may be mistakenly consid-ered to outperform or to be equivalent to better competing algorithms. To evaluate the quality of the external measures, some authors have enunciated sets of conditions, some of them accepted to some extent by the scientific community, which describe desirable behaviors of good evaluation measures.
We take as our starting point the work published by Amig X  et al. [1], who enunciate a set of four desirable conditions in partitional scenarios. They argue that these conditions contain as special cases a variety of other conditions and study a number of evaluation measures, concluding that the sole to fulfill all four conditions is BCubed [2]. They propose the measure Extended BCubed as an extension to BCubed for handling the case of overlapping clusterings. Here, we identify an additional problem that arises when evaluating overlapping clusterings, and enunciate a condition describing the desirable behavior to be followed by evaluation measures in these situations. Upon determining that the Extended BCubed fails to fulfill this new condition, we present CICE-BCubed, an extension which successfully handles the described situation.

This paper is an extension of preliminary results presented in [3]. There, we described the problem that we addressed, presented the new measure and briefly justified its correctness. Here, we extend these results by presenting formal proofs of the new measure X  X  compliance to Amig X  et al. X  X  initial conditions, as well as the new proposed condition. Additionally, for consistency purposes, we analyze several evaluation measures recently introduced and prove that they fail to satisfy the initial Amig X  et al. X  X  conditions. We do so by providing counterexamples where these measures do not show the behavior prescribed by some of the conditions.

The remainder of this paper is organized as follows. In Section 2 we briefly review existing work, focusing on the sets of conditions that have been previously enunciated, as well as the external measures proposed in the literature for validating overlapping clustering. We describe our proposals in Section 3, and, finally, we present our conclusions in Section 4. 2. Previous work
Many widely used quality measures suffer from undesi rable effects, which in turn potentially harm conclusions drawn from comparisons based on them. For instance, the widely used F -measure [4] has been reported to show a tendency towards assigning higher scores to clusterings containing a large number of clusters [5]. In consequence, some authors have devoted a considerable effort to enunciate desirable conditions that all quality measures must fulfill. Meila [6] enunciated twelve properties specif-ically for the Variation Information. Moreover, in [7], a set of five conditions is proposed, which were later extended to seven in [8].

In [1], Amig X  et al. propose a set of four conditions which are proven to cover all the characteristics validated by the previous ones. Each condition is defined by means of a pair of clusterings D 1 and D 2 , where D 1 is argued to be worst than D 2 , upon which a measure satisfying the condition should score D  X  Homogeneity :Let D 1 be a clustering where one cluster G k in the candidate clustering contains ob- X  Completeness :Let D 1 be a clustering where two clusters G 1 and G 2 contain only objects belonging  X  Rag bag :Let D 1 be a clustering where one cluster G clean contains n objects belonging to one class  X  Clusters size versus quantity :Let D be a clustering where one cluster G large contains n +1 objects
Amig X  et al. conducted an exhaustive study on a large number of existing external quality measures taking into account the set of conditions that they proposed, and determined that the sole quality measure that satisfies all four conditions is BCubed F  X  measure [2].

Since BCubed is only suited for evaluating partitional clusterings, they propose an extension for han-dling the overlapping clustering case. The Extended BCubed measure works by counting the pairs of objects that co-occur in the same class or cluster. Like the F -measure, it computes a precision and recall value and merges both values into a sole final score. Extended BCubed precision evaluates the correct-ness of the decisions made by the clustering algorithm of placing pairs of objects together in the same cluster. Extended BCubed recall evaluates the algorithm X  X  capacity of placing together pairs of objects belonging to the same classes.
 The Extended BCubed precision is defined as where U represents the collection, G represents the candidate clustering, C represents the gold standard, and E ( o, C ) is the set of objects co-occurring with o in at least one class of the gold standard. It is Likewise, the Extended BCubed recall is defined as thus, the Extended BCubed precision and recall are merged into
Tuning the  X  parameter, it is possible to allow Extended BCubed precision or recall to weight more on the final score. Commonly, this parameter is set to 0.5, behaving as the harmonic mean between both criteria. Extended BCubed checks the number of times that a pair of objects are placed together in the same clusters and/or classes, while BCubed only takes into account the fact that a pair of objects are place together in at least one cluster and/or class, or not.

Recently, Amig X  et al. proposed Reliability and Sensitivity (R*S for short) [11], a new generalization of Extended BCubed for flexibly handling the evaluation of a number of document organization tasks which, besides document clustering, include document retrieval, filtering, etc. They proved that R*S also fulfills all four conditions. This new measure considers a number of situations not encountered when evaluating document clustering, such as the existence of a ranking. However, for a scenario concerned exclusively with clustering, R*S maintains a behavior very similar to Extended BCubed, except for the fact that R*S evaluates a pair of objects each time it occurs and not only once. By considering the fact that two objects belong to an specific cluster as a relationship r ( o 1 ,o 2 ) , then R*S computes F  X  (as defined in Eq. (3)), redefining the calculation of precision and recall as follows:
As we mentioned before, in their original paper Amig X  et al. conducted an extensive analysis of ex-isting evaluation measures. For the sake of exhaustivity, we now review other external quality measures that have been recently proposed.

Here, we describe these measures in detail and analyze cases where they fail to satisfy several of the conditions proposed by Amig X  et al.

The GFM measure [9] relies on a | G | X | C | -sized contingency table, where and This measure analyzes the candidate clustering taking into account the pairs of objects that belong to the (Eqs (6) X (8), respectively) which represent the probability that a pair of objects belong to more than one successes in a 2-sized sample from a population of size P that contains p successes.
 Finally, the GFM mesaure is defined as follows:
The PCMP measure define the event  X  S  X  C as selecting from a cluster two objects that belong to the same class. The P PM criterion is computed as the probability that  X  S  X  C occurs.
 where P ( G i )= X  n i  X  /  X  n  X  X  X  and P (  X  S  X  C | G i ) is defined as follow:
On the other hand, they define the Class Recall as the probability that an object of a class C j is included in any cluster, and it is defined in Eq. (10). Let N c = j | C j | . The Global Recall is computed in as shown Eq. (11).
 Finally, the PCMP measure (Eq. (12)) merges both criteria in a sole value as follows: The Best Match measure determine for each cluster G i its best representative class C i ,asshownin Eq. (13). Likewise, they determine the most representative cluster for each class (Eq. (14)). They propose Eq. (15) to calculate the distance between clusters. Finally, the Best Match measure computes the distance between G and C in terms of the distances between the best matching class/cluster for each cluster/class, as follows:
The K -Center measure is supported in the distance d ( Center K ( G ) ,C i ) which must satisfy the follow-ing condition:
Computing an optimal Center K ( G ) is an NP-Hard problem [10]. The authors propose a heuristic to deal with this situation. They calculate the K-Center measure computing the Best match measure between Center K ( G ) and Center K ( C ) .
 The M L 2 measure defines the following function for each pair of objects in a clustering as follows:
The user-defined parameters P e and P g represent the notions of extra-cluster and intra-cluster commu-nication, respectively. The probability distribution P C is defined analogously to Eq. (18) for all object pairs on the set of classes of the gold standard. Finally, the M L 2 and M KL measures are computed as the averaged L 2 distance (Eq. (19)) and the Kullback-Leibler divergence (Eq. (20)) between P G and P C , respectively.

In order to assess whether these quality measures satisfy Amig X  et al. X  X  conditions, we defined the sets of clusterings shown in Figs 1 X 5. Here, we focus on showing counterexamples that prove that these measures fail to satisfy one or several conditions. In every case, clustering D 1 is expected to be scored worse than D 2 .

Table 1 shows the scores obtained by each measure on the defined clusterings. Each cell contains a pair of values, reflecting the scores obtained on D 1 and D 2 , respectively, when applying each measure on the clusterings defined for a nalyzing the fulfillment of each condition. Th e cases where D 1 was not scored worse than D 2 , thus failing to satisfy the corresponding condition, are highlighted. Notice that, for measures behaving as similarities, scoring D 1 worse than D 2 is understood as assigning it a lower value, whereas for measures behaving as dissimilarities, scoring D 1 worse than D 2 is understood as assigning it a higher value.

Analyzing the results presented in Table 1, it may be verified that every measure fails to satisfy at least one of the conditions proposed by Amig X  et al. 3. Our proposal
In their original analysis of Extended BCubed, Amig X  et al. point out that it may yield the maximum score for some candidate clusterings that are not identical to the gold standard, as exemplified in Fig. 6. This situation, which also affects R*S, occurs when all the pairs of objects that belong to the same number of clusters also belong to the same number of classes.

Now we enunciate a new condition, which describes the desired behavior that evaluation measures should display in this type of situations.

The Perfect Match condition is trivially satisfiable on partitional clusterings. However, in overlapping scenarios it poses challenges. We focus on modifying Extended BCubed in such a way that it maintains the behavior that makes it satisfy the original conditions while also dealing with this situation. We propose a new external measure called Cluster-Identity-Checking Extended BCubed ( CICE-BCubed for short). Analogous to BCubed, our measure is based on a notion of precision and a notion of recall, which are conveniently combined. CICE-BCubed scores the pairs of objects that co-occur in clusters and/or classes. Despite the more general nature of R*S, we maintain Extended BCubed as the basis for extension because, while fulfilling both of them all four initial conditions and failing both of them on the new condition, they feature analogous behaviors for the particular scenario of clustering.
In order to deal with the Perfect Match condition we introduce the Cluster Identity Index ( CII for short), a factor  X ( o 1 ,o 2 ,A,B ) that yields values in the interval [0, 1]. The CII estimates the degree A , determines the cluster B j  X  B , such that it is the most similar to A 1 and o 1 ,o 2  X  B j :
We propose to use Jaccard X  X  index, as defined on Eq. (21), [12] as the similarity criterion due to the fact that it yields a maximum score for a pair of clusters only if they are identical. However, we can use any other measure that shows this desirable property, e.g. Rand X  X  coefficient or the traditional F -measure.
Let A be a candidate clustering and let B be a gold standard. The CII factor averages the similarity B j , and is defined as follows:
Note that the CII factor only yields the maximum score if each cluster may be mapped to a class which is identical to it. CICE-BCubed precision and recall are defined in Eqs (23) and (24), respectively. and the CICE-BCubed F  X  -measure is defined as
We claim that CICE-BCubed maintains the desirable characteristics of Extended BCubed, whereas the inclusion of the CII factor allows it to also satisfy the Perfect Match condition 1 .Inwhatfollows,we analyze the behavior of CICE-BCubed with respect to all conditions.
 Lemma 1 .Let D c be a candidate clustering, let D g be a gold standard, and let N be the total of objects in the collection. Then the CICE-BCubed precision and CICE-BCubed recall scores for D c can be expressed as a sum of terms with the form  X  X  i p ij o ij ,where and Proof. The CICE-BCubed Precision formula may be reformulated into the one shown in Eq. (26). By applying some arithmetic operations we can express  X  P in terms of the contribution of each pair to the score, as shown in Eq. (27), which is a sum of terms of the aforementioned form. Note that for the pairs ( o i , o j ) that do not co-occur in the same cluster, p ij = 0.
Following a similar reasoning, it may be verified that CICE-BCubed recall behaves in the same man-ner.
 Lemma 2 .Let D c 1 and D c 2 be two candidate clusterings, and let D g be a gold standard. If CICE-BCubed precision and recall yield a higher score for D c 2 than for D c 1 , then CICE-BCubed F  X  obtains a higher score for D c 2 than for D c 1 . Proof. Taking  X  = 1 E ,forsome E  X  N , we can reformulate the CICE-BCubed F  X  equation as When the values of  X  P and  X  R increase, the value of the expression 1 the value of CICE-BCubed F  X  increase.
 Theorem 1 . The CICE-BCubed measure satisfies the Homogeneity condition.
 Proof. We first focus in the CICE-Bcubed precision. By Lemma 1, and
Note that the only pairs of objects yielding different contributions to D 1 and D 2 are those composed by objects belonging to G k . We shall center our attention in the terms corresponding to those pairs. The contribute p ij =0 to CICE-Bcubed precision. Otherwise, they contribute p ij =  X  p ij , since the pairs belong to the same amount of clusters and classes for both clusterings D 1 and D 2 . As a consequence of
The same principle of Lemma 1 is applied to CICE-BCubed recall, so and account when calculating the CII factor, in such a way that for all these pairs  X  ij  X   X  ij . Therefore,  X  P satisfying the Homogeneity condition.
 Theorem 2 . The CICE-BCubed measure satisfies the Completeness condition.
 Proof. The clustering D 1 contains two clusters G 1 and G 2 with objects that belong to the same class, which are merged into one cluster G k  X  D 2 . In consequence, all the objects o i  X  G 1 are scored as  X  i = X  ij ,forsome o j intersections necessary for calculating Jaccard X  X  coefficient are larger for the objects that belong to G k than for those that belong to G 1 and G 2 . Note that all the objects in the collection have the same score Lemma 2, we conclude that CICE-BCubed scores D 1 worse than D 2 , thus satisfying the Completeness condition.
 Theorem 3 . The CICE-BCubed measure satisfies the Rag bag condition.
 Proof. We first compute the global score for the clustering D 1 given by CICE-BCubed precision. Let o n clusters are scored as 1 n 2 . The CICE-BCubed precision is computed as
In the clustering D 2 ,the n objects that belong to G clean are scored with maximum value equal to 1, as
Similarly, for D 1 , the CICE-BCubed recall scores o n as 1 n +1 . The objects that belong to G clean are as belong to G noisy receive 1 n +1 . Finally, we formulate the global score as
This condition is verifiable for n 2 . In these cases, it may always be verified that  X  P D 1 &lt;  X  P D 2 and  X  R D 1 &lt;  X  R D 2 . Applying Lemma 2, we conclude that CICE-BCubed scores D 1 worse than D 2 , thus satisfying the Rag Bag condition.
 Theorem 4 . The CICE-BCubed measure satisfies the Cluster size versus quality condition. Proof. For D 1 , all the objects contained in G large are scored the maximum value, and the others, which belong to unitary classes, are scored as 1 2 by CICE-BCubed precision. The global score is thus On the other hand, the clustering D 2 has an unary cluster, whose single object o u is scored 1 n +1 .The maximum value. Finally, the average for D 2 is computed as
When computing CICE-BCubed recall on D 1 , each object in G large is scored the maximum value and the others are scored 1 4 . The average is computed as to 2-sized clusters are scored the maximum value. Finally the average is computed as
This condition is verifiable for n 3 . In these cases, it may always be verified that  X  P D 1 &lt;  X  P D 2 and  X  R D 1 &lt;  X  R D 2 . Applying Lemma 2, we conclude that CICE-BCubed scores D 1 worse than D 2 , thus satisfying the Rag Bag condition.
 Theorem 5 . The CICE-BCubed measure satisfies the Perfect Match condition.
 Proof. Now, we shall prove that CICE-BCubed precision and recall always yield a maximum score when the candidate clustering is identical to the gold standard. In this context, the CII factor always yields a maximum score because each cluster has a representative class in the gold standard identic to it. Also, all the pairs co-occur in exactly as many clusterings as classes. In consequence, CICE-BCubed precision and recall yield a maximum score for each pair of objects and so does for the clustering, hence CICE-BCubed F  X  yields a maximum score too.

On the other hand, we shall demonstrate using proof by contrapositive, that the fact of obtaining a maximal score of CICE-BCubed precision and recall implies that the candidate clustering is identical to the gold standard. Let A be a candidate clustering and let B a gold standard, such that A is not identical to B . Under this condition, there must be at least one cluster A i  X  A whose best matching class is not identical to it. For object pairs occurring in such cluster A i , the CII will not yield the maximum score, thus preventing CICE-BCubed precision and CICE-BCubed recall, as defined in Eqs (23) and (24), from yielding the maximum score. If CICE-BCubed precision and recall do not yield the maximum score, neither does the CICE-BCubed F  X  -measure. Thus, we have proven that evaluating a candidate clustering which is not identical to the gold standard yields non-maximal CICE-BCubed precision, recall and F  X   X  measure, which, in turn, demonstrates that obtaining maximal CICE-BCubed precision, recall and F  X   X  measure implies that the evaluated candidate clustering is identical to the gold standard. As a consequence, we may conclude that CICE-BCubed F  X  satisfies the perfect match condition.
Summing up, Theorems 1 X 5 describe the behavior of CICE-BCubed, showing that it satisfies all five conditions. It should be pointed out that the time complexity of computing CICE-BCubed is O ( n 3 log n ) , where n is the number of objects contained in the collection. However, since the validation of clustering algorithms is generally performed as an offline task, we consider that this time complexity is affordable given the benefits of relying on more robust evaluation measures. 4. Conclusions
We addressed the validation of overlapping clusterings. We took as a starting point the four condi-tions enunciated by Amig X  et al. as well as the Extended BCubed F  X  measure, the fastest among the two measures reported to satisfy the initial four conditions, and attacked one of the known problems that both face when used for overlapping clusterings, namely that of assigning the maximum score to candidate clusterings that are not identical to the gold standard. We prove that our proposed counterpart, CICE-BCubed F  X  , does handle this situation adequately, while continuing to satisfy the previous four conditions.

Whether this problem is likely to occur frequently in particular collections depends not only on the col-lections themselves, but also on the outputs that clustering algorithms may potentially produce, which is by Amig X  et al. as well as any other set of conditions, do not necessarily enjoy universal acceptation. Because of that, absolute statements regarding whether a particular evaluation measure should be con-sidered better than others may not be appropriate. However, we consider that the existing conditions, as well as the new condition we treated in this paper, do reflect desirable characteristics of clustering evaluation measures, thus supporting the strength of the proposed measures and the convenience of their use.

We have identified several attractive directions for future work, such as studying the behavior of sev-eral sets of conditions proposed in the literature when overlapping scenarios are involved, identifying new conditions stemming from phenomena observed in overlapping clustering that are not observed in partitional environments, etc.
 Acknowledgment
The authors are grateful to Enrique Amig X  of the ETSII, UNED, Spain, for his helpful comments and remarks.
 References
