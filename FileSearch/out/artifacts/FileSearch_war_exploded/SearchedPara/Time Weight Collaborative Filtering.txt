 Collaborative filtering is regarded as one of the most promis-ing recommendation algorithms. The item-based approaches for collaborative filtering identify the similarity between two items by comparing users X  ratings on them. In these ap-proaches, ratings produced at different times are weighted equally. That is to say, changes in user purchase interest are not taken into consideration. For example, an item that was rated recently by a user should have a bigger impact on the prediction of future user behaviour than an item that was rated a long time ago. In this paper, we present a novel algorithm to compute the time weights for different items in a manner that will assign a decreasing weight to old data. More specifically, the users X  purchase habits vary. Even the same user has quite different attitudes towards different items. Our proposed algorithm uses clustering to discriminate between different kinds of items. To each item cluster, we trace each user X  X  purchase interest change and introduce a personalized decay factor according to the user own purchase behaviour. Empirical studies have shown that our new algorithm substantially improves the precision of item-based collaborative filtering without introducing higher order computational complexity.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering ; I.2.6 [ Artificial Intelligence ]: Learning X  Knowledge Acquisition Algorithms, Experimentation, Performance, Human Factors collaborative filtering, item-based approach, time weight Copyright 2005 ACM 1-59593-140-6/05/0010 ... $ 5.00.
Nowadays the amount of information in the world is in-creasing far more quickly than our ability to process it. Collaborative filtering and content-based filtering are two prevailing techniques that help users filter useless informa-tion. Content-based filtering analyses an item X  X  attributes to make recommendation, while collaborative filtering uses historical data on user preferences to predict items that a user might like. To date, collaborative filtering is best known for its use on e-commerce web sites. It has also been widely used in other areas, for example, filtering Usenet News, rec-ommending TV shows and web personalization.

Over the years, various approaches for collaborative fil-tering have been developed. Generally, there are catego-rized into two classes: memory-based algorithms and model-based algorithms [3]. Memory-based algorithms represent the classical trend in collaborative filtering. This type of al-gorithm includes user-based algorithms and item-based algo-rithms. User-based algorithms represent a user as a vector in the item-space [12],while item-based algorithms represent an item as a vector in the user-space [13]. On the other hand, model-based algorithms deploy the data to build a model that is then used for predictions. The aspect model(AM) [7] and the personality diagnosis model(PD) are two popular model-based algorithms. AM is a new probabilistic graph-ical model that combines a Poisson mixture with a latent aspect class model to model users X  purchase behaviour. PD is a different case, as it treats each user in the training set as an individual model. It computes the likelihood for the test user to be in the model of each training user and then uses the training users as the estimators [8]. Contrary to model-based algorithms, memory-based approaches are usu-ally simpler and require less offline computation,performing better when the training data is small [14]. Compared to user-based algorithms, item-based algorithms can dramat-ically improve the scalability of collaborative filtering and provide better quality [13]. Up until now, item-based algo-rithms have been widely used in many applications in the real world, such as at Amazon.com.

Item-based algorithms have achieved success both in re-search and practice. However, in these approaches data col-lection is regarded as static. Ratings produced at different times are weighted equally. That is to say, changes in user purchase interest are not taken into consideration. For ex-ample, a man previously liked thrillers. So he rated The 39 Steps , a thriller released in 1935, the highest score 5 three years ago. But he changes his interests as time goes by. Currently he dislikes thrillers. He rated The Bourne Identity , another thriller released in 2002, the score 2 a month ago. Classic collaborative filtering algorithms sup-pose these two scores have the same weights in predicting the user future preference for thrillers. However, we argue that the target user X  X  recent ratings reflect his / her future preferences more than the old ratings. A good collaborative filtering algorithm should gradually decay the influence of old data and predict the user future preferences precisely. From the perspective of intuition, an item that was rated recently by a user should have a bigger impact on the user X  X  prediction than an item that was rated a long time ago. To address this problem, a simple and popular approach is the use of sliding windows. The approach just uses new data in current sliding window and discards old data. How-ever, this approach can aggravate sparsity. Sparsity is a well-known problem in collaborative filtering. It refers to the fact that most users do not rate many items and hence the user-item rating matrix is very sparse. Using only new data can make this sparsity factor more severe, thereby de-grading the precision of recommendation system. In this paper, we present a novel time weight algorithm. We find appropriate time weights for different items that are rated at different times. The more recent the data is, the more it contributes to predicting the items. More specifically, the users X  purchase habits vary. Some people X  X  interests change with time quickly, while others persist in what they like for a long time. Even the same user has quite different atti-tudes towards different items. Purchase interest in some kinds of items last much longer than other kinds of items. We assume that the same user has the similar preferences and similar purchase interest changes for the similar items. So we use clustering to discriminate between different items. There exists strong relevancy between these items belong-ing to the same cluster. Then to each item cluster, we trace each user X  X  purchase interest change and compute automat-ically a personalized decay factor for each user according to his/her own purchase behaviour.

The remainder of the paper is organized as follows. Sec-tion 2 briefly presents some of the research literature re-lated to collaborative filtering. In section 3, we propose a novel time weight collaborative filtering algorithm and de-scribe different sub-tasks of the algorithm in detail. Section 4 presents our experimental work,providing details of our data set, evaluation metrics, results of different experiments and discussion of the results. In the final section, we make a conclusion and point out directions for future work.
Recommendation systems started attracting major research interest during the early nineties [5]. Since that time, many techniques have been explored in collaborative filtering. Mar-itza L. et al made a comparison of a number of different algorithms, namely memory-based algorithm, dependency-networks algorithm, online learning algorithm and support vector machine and conducted many experiments in [10]. The results from these experiments showed that for a wide range of conditions, memory-based algorithm outperforms support vector machine, dependency-networks and online methods.

In collaborative filtering, the prediction accuracy is a key issue. It influences the prevalence of the recommendation systems to a great extent. So research on collaborative fil-tering is primarily focused on improving this element. Rong Jin et al presented an approach of normalizing ratings of different users to the same scale [9] and an optimization al-gorithm to automatically compute the weights for different items based on rating discrepancies among different users [8]. Chun Zeng et al adopted two techniques: a matrix conver-sion method for similarity measure and an instance selection method [19]. Cai-Nicolas Ziegler et al exploited taxonomic background knowledge for the computation of personalized recommendations [21]. Many model algorithms have also been developed to improve the accuracy of collaborative fil-tering. For example, Thomas Hofman presented a Gaussian probabilistic latent semantic model in [7]. The observed user ratings can be modelled as a mixture of user communities or interest groups. Users are able to participate probabilisti-cally in one or more groups. The user community is denoted by a hidden variable.

Unfortunately, as far as we know, few papers have focused on the temporal feature of ratings in collaborative filter-ing. In [16], the authors proposed that a movie X  X  production year, which reflects the situational environment in which the movie is filmed, might significantly affect target users X  future preferences. Loren Terveen et al defined users X  preferences using their personal history [17]. Kazunari Sugiyama et al explored a type of time-based collaborative filtering with detailed analysis of user X  X  browsing history in one day [15]. Yanchang Zhao et al proposed using decaying function to tackle time series data [20]. However, the recency of ratings has not been studied so far. In fact, with the fast growth of e-commerce, many collaborative filtering applications have been fielded for a long time. For example, in [2], the authors described a TiVo television show collaborative recommenda-tion system which started four years ago. It has currently accumulated approximately 100 million user ratings, some of which are very old. Since the value of these very old rat-ings is questionable, we should seek to develop an algorithm that will decay the influence of these.

Furthermore, recently mining concept-drifting data has received growing interest. Concept-drifting means the con-cept that we try to learn from the data is constantly evolv-ing. This is very similar to the interest-drifting in user pur-chase history. There have been some efforts dedicated to data selection in the environment of concept-drifting [4][18]. In [4], the author pointed out that using old data blindly is not better than  X  X ambling X . In other words, using old data unselectively helps produce a more accurate hypothesis only if there is no concept-drifting and the amount of old data chosen arbitrarily just happen to be right. Our proposed algorithm can select data wisely and trace changes in user purchase interest. This algorithm alleviates the problem of concept-drifting in the situation of collaborative filtering.
The main idea of our time weight algorithm is to find appropriate time weights for items in order that the items rated recently are able to contribute more to the prediction of the recommendation items. Intuitively, we can surmise that recent data corresponds to the latest user purchase in-terest. More recent data should have higher value in the time weighting. In the following sections, we first describe the definition of collaborative filtering algorithms, and then we introduce the time function to item-based collaborative filtering algorithms. Finally, we propose the new algorithm. Collaborative filtering problem can be defined as follows:
Given a database D as a tuple &lt; U i , I j , O ij , T ij U i identifies the i-th user of the system, I j identifies the j-th items of the system, O ij represents the i-th user X  X  opinion on the j-th item and T ij represents producing time of the opinion, find a list of k recommended items for each user U.
The classic item-based collaborative filtering algorithms have two phases: Phase 1 Similarity Computation. There are three main ap-Phase 2 Preference prediction. The prediction of the pref-
As we assumed before, the user purchase interest is sen-sitive to time. The recommendation process should assign a greater level of importance to recent data. So we propose that in the phase of Preference Prediction, each rating is assigned a weight defined by a function f(t) to the time t. That is to say, in our proposed algorithm, the Equation (4) is modified as: where t ic represents the time the user X  X  opinion O ic was produced.

Furthermore, we assume that the time function f(t) is a monotonic decreasing function, which reduces uniformly with time t and the value of the time weight lies in the range (0,1). In other words, all the data contribute to the recom-mendation items, while the most recent data contributes the most. The old data reflects users X  previous preferences. It should have small weights in the prediction of recommenda-tion. In our proposed algorithm, we choose an exponential form for the time function to achieve the goal. The expo-nential time function is widely used in many applications in which it is desirable to gradually discay the history of past behaviour as time goes by [1]. Firstly, we define a half-life parameter T 0 as: That is to say, the weight reduces by 1 / 2 in T 0 days.
Then we define the decay rate  X  as:
The time function is as follows:
From the Equation (8), we can observe that the value of the time function is in the range (0 , 1), and it reduces with time. The more recent the data, the higher the value of the time function is. The exponential function satisfies our needs well. However, there are still other time functions, for example, logistic function. From the Figure (1), we can observe the difference between these two functions. The ex-ponential function reduces at a reducing rate. The gradient of the curve at data point that is close to zero is steeper than data point that is far away from zero. Here, x=0 rep-resents current data. The higher the value of x is, the older the data is. However, to the logistic function, the gradient of the curve at the middle data point is steepest. Obviously, we emphase the user X  X  latest purchase interest and focus on the most recent data. In this case, the exponential function is more suitable. At the same time we analyse the half-life parameter T 0 in detail. Conceptually, the aim of design-ing a half-life parameter is to define the rate of decay of the weight assigned to each data point. From the Equation (6), we can see that T 0 is inveresely proportional to  X  . The lower the value of T 0 , the higher the value of  X  . The higher the value of  X  , the faster old data decays and the lower the importance of the historical information compared to more recent data. The value of parameter T 0 decides the decay rate of old data. From the Figure (2), we can see the dif-ferent curves of time function when the value of parameter T 0 is different. Obviously, we should select different values of parameter T 0 under different circumstances and the se-lection of parameter T 0 is a key issue to the performance of our algorithm. In the real world, the decay rate of old data is decided by how frequently the user purchase inter-est changes. If the user preference for the type of items is consistent, old ratings related to the type of items can help improve accuracy of predicting future preference for the type of items. In this case, we should decay the old data slowly and assign a high value to T 0 . The deviation between time weights is comparatively small. So in predicting future user preference for this type of items, similarity plays a more important role than time weight. Conversely, if the user preference for the type of items changes frequently and dra-matically, we should assign a low value to T 0 . This means that old ratings related to the type of items cannot predict the user future preference for the type of items precisely. These old data should decay as quick as possible. In other words, time weights would contribute more to predicting the future preference compared to when the user preference is consistent. So we should select the appropriate parameter T 0 to precisely predict the user future preference according to the user personalized purchase history.

We need to find the appropriate value of parameter T 0 to precisely predict the user future preference, thereby improv-ing the performance of our proposed algorithm. However, the users X  purchase habits vary. Even the same user has quite different attitudes towards different kinds of items. Purchase interest in some kinds of items last much longer than other kinds of items. Furthermore, it is not feasible interactively providing a corresponding value of parameter Figure 2: the curves of time function using different T T 0 for each user and each items. We assume that the same user has the similar preferences and similar purchase inter-est changes for the similar items. It means to one user, the similar items have the similar decay rates of old data. So we propose to compute the corresponding values of parameter T 0 for each user and each cluster of items according to the user personalized purchase history. To realize the goal, we first use simple K-Means clustering approach to summarize items into different clusters through the rating information [11]. There exists strong relevancy between these items be-longing to the same cluster. Then to each item cluster, we take the leave-one-out approach to compute automatically the personalized value of parameter T 0 . In other words, each time we leave out one item rated by a user from one item cluster. We are then able to use the omitted item to mea-sure how well the user purchase behaviour on the item can be explained. To measure this, we introduce the mean abso-lute error (MAE). MAE is a popular metric in collaborative filtering. It computes the average absolute deviation of rec-ommendations from their true user-specified values. For an item cluster, each user has many ratings for items belonging to this cluster. The MAE can be computed as:
Here N identifies the number of the user X  X  ratings in a cluster p i identifies the predicted rating for the i-th item q i identifies the user X  X  true rating for the i-th item
In our proposed algorithm for each user, the prediction P for each item is parameterized by T 0 . So we use MAE( T 0 emphasize that the MAE is parameterized by T 0 . By min-imizing the value of MAE, we will find optimal parameter T . Formally, the optimization problem is stated as follows:
However, finding the optimal solution to Equation (10) is rather difficult due to the non-concave objective function. We derive an optimization strategy for Equation (10) that uses approximate value. First, we set interactively an up-per bound and a lower bound of parameter T 0 . We then discretize the value of parameter T 0 . At last, we scan all the possible values and select the optimal value assigned to parameter T 0 . By this method, to each item cluster we can approximately compute the personalized optimal value of T for each user. The Figure 3 is an overview of our approach.
Our new time weight collaborative filtering algorithm is based on item-based collaborative filtering. In our proposed algorithm, the prediction of the preference for a given object can be computed by using the sum of the ratings of the user to items weighted by the similarity between different items and the time weight. The input to this algorithm is the N  X  M user-item matrix C, N  X  M user-time matrix T that rep-resents the time users X  opinions on items were produced, a parameter n that specifies the number of item-to-item simi-larities that will be stored for each item, a parameter K that specifies the number of item clusters and a parameter l that denotes the number of recommendation items. If the i-th user has no rating on the j-th item in the system, the values of C ij and T ij are both equal to zero. The output is an N  X  l matrix N that stores the N  X  l recommendation items. In it, every row represents every user. For each user there are l recommendation items. The algorithm is shown in Figure 4.

TimeWeightCollaborativeFiltering (C,T,n,K,l) 1. Matrix M  X  ComputeItemSimilarity(C,n); 2. ItemSimpleKMeans(C,K); 3. for (ClusterNo = 1; ClusterNo &lt; =K; 4. ClusterNo++) { 5. for (UserNo = 1; UserNo &lt; =N; UserNo++) { 6. Array P  X  LearningParameters(C,M,T,n,K,l); } 7. } 8. Matrix N  X  9. PredictRecommendationItems(M,T,P,l); Figure 4: Time Weight Collaborative Filtering Al-gorithm
We have conducted a set of experiments to examine the performance of our new time weight collaborative filtering algorithm. Particularly, we address the following two issues: 1 How does the parameter T 0 influence the prediction ac-2 How is our time weight algorithm compared to the exist-
We use two datasets in our experiments: EachMovie 1 and GroupLens 2 . EachMovie and GroupLens have been the most widely used common datasets in collaborative fil-tering research projects. EachMovie was collected during 18 months where 72,916 users rated 1628 movies [6]. Grou-pLens consisted of 1,000,209 ratings for 3900 movies by 6040 users. The global statistics of these two datasets used in our experiments are showed in Table 1.
 Table 1: characteristics of EachMovie and Grou-pLens Avg. ] of rated Items/User 145.6 20
We alter the training size to be the first 30, 60 or 200 users for training. And we also utilize two protocols, All But One and Given k . In All But One , the newest rated items for each user are used for testing. But in the second protocol, Given k , we select k ratings from each user as the observed ratings and then predict the remaining ratings. By varying the number of training users and the number of given items, we can test our proposed algorithm for different configurations. In all the experiments the number of the nearest neighbours is set to 30. The evaluation metric used in our experiment is the mean absolute error (MAE).
In the first experiment, we vary the parameter T 0 from 10, 20, 50, 100 to 200. The value of  X  is 0.1, 0.05, 0.02, 0.01 and 0.005 respectively. The results of using different con-stant T 0 are demonstrated in Table 2, Table 3 and Figure 5. Since the parameter T 0 controls the decay rate of historical www.research.compaq.com/SRC/eachmovie www.cs.usyd.edu.au/Research/GroupLens/data/million Figure 5: MAE using different T 0 on EachMovie in All But One information, we can see that the parameter T 0 dramatically influences the performance of the algorithm and under differ-ent configurations to obtain the best performance we should assign different values to the parameter T 0 .
 Table 3: MAE using different T 0 on GroupLens in All But One . A smaller value means a better perfor-mance
Another observation is that the approach that the value of parameter T 0 is fixed does not guarantee the improvement of the performance of collaborative filtering and in some cir-cumstances the performance is not good. The experimental results confirm that the users X  purchase habits vary and as-signing the same value of parameter T 0 to different users is inappropriate. In our proposed algorithm, the value of pa-rameter T 0 can be automatically computed according to the user X  X  history of past behaviour. The results show that our new algorithm is always close to the optimal performance for all configurations.
In this experiment, we compare our new time weight algo-rithm to the classic item-based algorithm. The parameter T is automatically computed for different users and different item clusters. The results are presented in Table 4, Table 5 and Figure 6. Obviously, our new algorithm is able to boost the prediction accuracy for all configurations.
 Table 5: MAE using different algorithms on Grou-pLens in All But One . A smaller value means a better performance Figure 6: MAE using different algorithms on Each-Movie in All But One
Classic item-based collaborative filtering X  X  scalability is that it can create the expensive similar items table offline. The offline computation of the similar table is extremely time intensive, with O ( N 2 M ) as worst case. Here, N rep-resents the number of items. M represents the number of users. In our proposed algorithm, the offline computa-tion is even more expensive. Our algorithm needs to com-pute similar items table and the personalized value of pa-rameter T 0 offline. So the offline complexity is equal to O ( N 2 M + NKl + MNKt ). Here K means the number of item clusters. l means the iterative times in clustering items. t means the number of possible values of parameter T . Compared to computing similar items table, comput-ing the personalized value of parameter T 0 has a cheaper computation.

Our proposed algorithm X  X  online complexity is the same as classic item-based algorithm. The online component is just looking up similar items the user X  X  ratings. So our algorithm scales independently of the number of users and items. The algorithm is fast even for extremely large data sets.
In this paper, we present a new time weight collabora-tive filtering algorithm. Unlike the non-time weighted al-gorithms, we utilize a predefined time function for different items. The main idea is to predict prcisely user future pur-chase interest by deploying time weight. The item that was rated recently by a user should have a bigger impact on the user X  X  prediction than an item that was rated long time ago. At the same time we learn users X  rating behavior to find the appropriate personalized parameter for each item cluster. Empirical studies have shown that our new algorithm can definitely improve the precision of item-based collaborative filtering algorithms.

Our further work is to study collaborative filtering algo-rithms on streaming data. This issue brings us a new chal-lenge that data are all contained not in a database ready for random access but are seen once only from online resources.
The work reported in this paper was funded in part by the Australian Research Council -Discovery Project Grant (ARC DP0558879), and computational resources used in this work were provided by the Queensland Parallel Super-computing Foundation (QPSF). [1] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A [2] K. Ali and W. v. Stam. Tivo: making show [3] J. S. Breese, D. Heekerman, and C. Kadic. Empirical [4] W. Fan. Systematic data selection to mine [5] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. [6] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [7] T. Hofmann. Collaborative filtering via gaussian [8] R. Jin, J. Y. Chai, and L. Si. An automatic weighting [9] R. Jin and L. Si. A study of methods for normalizing [10] M. L., C. N., and J. d. J. Perez-Alcazar. A comparison [11] Q. Li and M. Zhou. Research and design of an efficient [12] P. Resnick, N. Iacovou, M. Suchak, P. Bergstorm, and [13] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [14] L. Si and R. Jin. flexible mixture model for [15] K. Sugiyama, K. Hatano, and M. Yoshikawa. Adaptive [16] T. Y. Tang, P. Winoto, and K. C. C. Chan. On the [17] L. Terveen, J. McMackin, B. Amento, and W. Hill. [18] H. Wang, W. Fan, P. S. Yu, and J. Han. Mining [19] C. Zeng, C.-X. Xing, and L.-Z. Zhou. Similarity [20] Y. Zhao, C. Zhang, and S. Zhang. A recent-biased [21] C.-N. Ziegler, G. Lausen, and L. S. Thieme.

