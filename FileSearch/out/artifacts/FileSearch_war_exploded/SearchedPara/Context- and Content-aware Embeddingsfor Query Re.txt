 Search engines represent one of the most popular web ser-vices, visited by more than 85% of internet users on a daily basis. Advertisers are interested in making use of this vast business potential, as very clear intent signal communicated through an issued query allows effective targeting of users. This idea is embodied in a sponsored search model, where each advertiser maintains a list of keywords they deem in-dicative of increased user response rate with regards to their business. According to this targeting model, when a query is issued all advertisers with a matching keyword are en-tered into an auction according to the amount they bid for the query and the winner gets to show their ad. One of the main challenges is the fact that a query may not match many keywords, resulting in lower auction value, lower ad quality, and lost revenue for advertisers and publishers. Possible solution is to expand a query into a set of related queries and use them to increase the number of matched ads, called query rewriting. To this end, we propose rewriting method based on a novel query embedding algorithm, which jointly models query content as well as its context within a search session. As a result, semantically similar queries are mapped into vectors close in the embedding space, which allows ex-pansion of a query via simple K -nearest neighbor search. The method was trained on more than 12 billion sessions, one of the largest corpus reported thus far, and evaluated on both public TREC data set and an in-house sponsored search data set. The results show that the proposed ap-proach significantly outperformed existing state-of-the-art, strongly indicating its benefits and monetization potential. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Information Retrieval; Query Rewriting; Algorithms. Query rewriting; word embeddings.
In recent years targeted advertising has become one of the largest and most lucrative advertising channels. Despite the fact that traditional offline advertising still accounts for the majority of advertising expenditures [34], future potential of this burgeoning field is clearly exemplified by reported ad revenue of over 20 billion dollars in the first half of 2013 in the US alone, combined with a remarkable growth of around 20% on a yearly basis [21]. The size and importance of the online advertising, as well as the interesting open questions that the scale and variety of the targeting tasks bring, has drawn attention of many researchers from both industry and academia, resulting in a number of novel methods and im-provements to the flourishing field [1, 18, 32].

Due to a large diversity of the internet medium, targeted advertising has evolved to encompass many different outlets for the advertisers interested in reaching their target audi-ence. These include behavioral targeting [12] (where users are targeted based on their general browsing behavior), e-mail retargeting [18] (targeting users based on their e-mail interaction patterns), site re-targeting (targeting users based on their historical search queries), to name a few. In this work we consider a task of sponsored search advertising [17, 22], a very popular advertising model that targets users with the most relevant ads by considering an immediate query is-sued by a user. It has become one of the prevalent means of advertising due to a fact that the current query carries a strong signal about an immediate intent of the user, result-ing in a highly effective targeting model [15].

In the sponsored search model each advertiser maintains a list of keywords that they deem relevant to their product (e.g., Nike may maintain a keyword list containing terms such as  X  X unning shoes X  and  X  X thletics X ). In addition to a list of keywords, each advertiser also specifies a monetary bid amount they are willing to pay if their ad is shown and clicked by the user. Then, when a user issues a query in a search engine, the query is compared against each adver-tisers X  keyword list, and all advertisers with the matching keyword are entered into an auction. Finally, according to advertiser X  X  bid amount and the estimated quality and rel-evance of an ad that they wish to show, one advertiser and their corresponding ad are chosen for user targeting. Value of the auction increases when number of matched advertis-ers and their bids are high, which directly results in a better ad quality and higher revenue for both advertisers and pub-lishers (i.e., websites that host the ads).

Due to a large number of queries that the users could possibly issue, a common occurrence is that an exact query match cannot be found, as the advertisers usually cannot cover all relevant queries related to their product or ser-vice. However, even when the exact match does not exist, most often there does exist a non-matching keyword that is still highly related to the query. For example, query  X  X urina one X  and bidded keyword  X  X og food X  are strongly related yet a string match would fail to make the connection, which di-rectly translates into lost revenue. To mitigate this problem, query rewriting is used to expand the original query by pro-viding K related ones for which ads are available, and which can be used instead to qualify advertisers for an auction [9, 23, 40]. In the above example, a query rewriting method can be used to rewrite  X  X urina one X  into related queries such as  X  X og food X ,  X  X at food X ,  X  X urina pro plan X , and others, thus in-creasing likelihood of retrieving more high-quality, relevant ads, likely to be clicked by a user that issued the query.
In this paper we address this critical step in sponsored search, and propose a novel query rewriting algorithm mo-tivated by recent advances in distributed neural language models [14, 30, 31]. We explore and expand upon these ap-proaches for the task of query rewriting, resulting in signif-icant performance improvements over the current state-of-the-art methods. Key contributions are summarized below:
In this section we describe related work in the domains of query rewriting and neural language modeling that moti-vated the approach proposed in this work.
Owing to the importance of query rewriting for the success of query-ad auctions, various algorithms have been proposed in the literature to address this critical step. These include graph-based methods such as Query Flow Graph (QFG) [6, 7] that learn from users X  browsing behavior, as well as meth-ods that exploit syntactical relationships between queries [11, 23]. However, disadvantage of existing solutions is that they mostly do not take into account complex semantic re-lationships between queries, which may lead to suboptimal rewrites. For example, the rewrites typically result in the original queries with added or removed terms, such as  X  X u-rina one X  being rewritten as  X  X urina X  or  X  X urina one pro X . Thus, they are often obvious and have already been consid-ered by the advertisers that targeted the original query, and do not add a significant value to the auction.

We note that query rewriting task is related to the prob-lem of query suggestion, albeit the goals of the two tech-niques are quite different. In the case of query suggestion the objective is to provide users with queries that are im-portant for meeting users X  information needs [2, 7, 39], while in query rewriting the task is to expand query to increase both the number and quality of retrieved ads. We refer an interested reader to [36] for an overview of query log mining approaches as applied to query suggestion task.
In a number of natural language processing (NLP) appli-cations, including information retrieval, part-of-speech tag-ging, chunking, and many others, the specific objective can be generalized to the task of assigning a probability value to a sequence of words. To this end, language models have been developed, defining a mathematical model to capture statistical properties of words and the dependancies among them [3, 27]. Traditionally, language models represent each word as a feature vector using one-hot representation, where a word vector has the same length as the size of a vocabu-lary, and a vector element that corresponds to the observed word is equal to 1, and 0 otherwise. However, this approach often exhibits significant limitations in practical tasks, suf-fering from high dimensionality of the problem and severe data sparsity, resulting in suboptimal performance.
Neural language models have been proposed to address these issues, inducing low-dimensional, distributed embed-dings of words by means of neural networks [4, 13, 38]. Such approaches take advantage of the word order in text documents, explicitly modeling the assumption that closer words in the word sequence are statistically more dependent. Historically, inefficient training of the neural network-based models has been an obstacle to their wider applicability, be-ing proportional to the size of the vocabulary which may grow to several millions in practical tasks. However, this is-sue has been successfully addressed with recent advances in the field, particularly with the development of highly scalable continuous bag-of-words (CBOW) and skip-gram (SG) language models [30, 31] for learning word represen-tations. These powerful, efficient models have shown very promising results in capturing both syntactic and semantic relationships between words in large-scale text corpora, ob-taining state-of-the-art results on a plethora of NLP tasks. More recently, the concept of distributed representations has been extended beyond word representations to sentences and paragraphs [14, 28], relational entities [8, 37], general text-based attributes [26], descriptive text of images [25], nodes in graph structure [33], and other applications going beyond NLP domain for which they were originally proposed.
To address the shortcomings of the existing state-of-the-art methods for query rewriting, we propose to take a rad-ically new approach to this task, motivated by the recent success of distributed language models in NLP applications [31, 38]. In the context of NLP, distributed models are able to learn word representations in a low-dimensional contin-uous vector space using a surrounding context of the word in a sentence, where in the resulting embedding space se-mantically similar words are close to each other [31]. Our objective is to take advantage of this property for the task of query rewriting, and to learn query representations in a low-dimensional space where semantically similar queries would be close. As a result, and in contrast to rewriting meth-ods commonly used in practice, related queries could have a high similarity score even if they do not have any shared terms. Clearly, such approach would allow us to reduce com-plex task of query rewriting to a trivial K -nearest-neighbor search in the new embedding space.

However, application of distributed language models to the task of query rewriting is not an easy endeavour. Find-ing distributed query representation, as opposed to finding word representations, brings very unique challenges quite different from those found in everyday NLP problems. First, there are significant differences between language used in everyday language and web searches [10, 35]. For example, web search users often use summarization when searching for content (e.g., typing  X  X acations Spain X  instead of  X  X acations in Spain X ), thus omitting frequent words. Further, some n-grams that rarely appear in everyday language often appear together in web search [24], and queries are characterized by more spelling mistakes. Moreover, contrary to everyday language where linguistic rules and notions of words and sentences are clearly defined, search queries are composed of terms where there is no existing notion of  X  X entence of queries X  or the surrounding context equivalent to natural language domain.

In this paper we address these issues, and propose three query rewriting methods that bring the state-of-the-art dis-tributed language models closer to the setting of sponsored search: 1) context2vec, where we exploit the fact that user query is recorded with a timestamp, from which we create  X  X uery sentences X  and apply state-of-the-art language model [31]; 2) content2vec, where we propose to learn distributed query vector representations from its content without con-sidering session information, which is equivalent to para-graph2vec method from [28]; and 3) context-content2vec, where we propose to use a novel two-level architecture [14] that jointly models content of queries (i.e., word tokens that form the query) along with the query context (defined as other temporally close queries within a search session). Em-pirical results suggest that the resulting rewrites are highly related to the original queries, while being more diverse than rewrites produced by the current state-of-the-art methods. In addition, using a large data base of query-bids collected for thousands of advertisers, we show that the rewrites pro-duced by the proposed method match the highest percentage of bidded queries, providing a strong positive impact on the overall revenue of both publishers and advertisers.
In addition to search query logs, search engines systemat-ically log a number of other valuable signals that can help better explain and model the user intent. For example, ad clicks and clicks on search results are also recorded, and may provide a supplementary intent signal that can be used to improve query representations. To help exploit these two valuable sources of information, we propose to incorporate both ad clicks and search result clicks into user query ses-sions, and show how the additional signals are seamlessly handled by the proposed models. The benefits of including the ad and search clicks for query rewriting task are clearly confirmed by the empirical results, showing increased rel-evance of query rewrites and higher coverage of advertis-ers X  bid terms. Moreover, in addition to improving query representations, in this way we also learn low-dimensional representations of ad clicks and search clicks in the same embedding space, which opens doors for using the proposed methods on a number of important online tasks, such as query-to-ad matching, query suggestion, and query catego-rization, to name a few.
In this section we describe the proposed methodology for the task of query rewriting in sponsored search. As dis-cussed earlier, the goal is to find queries related to the is-sued one, which would allow us to retrieve relevant ads that were not matched by the original query. To solve this prob-lem, we propose to learn representation of queries in low-dimensional space from historical search logs using neural language models. Query rewriting can then be performed by finding K nearest neighbors of the issued query in the learned embedding space.

More specifically, given a set S of S search sessions obtained from online users, where each session s = ( q ,...,q M s )  X  S is defined as an uninterupted sequence of M s queries, and each query q m = ( w m 1 ,w m 2 ,...w consists of T m words, our objective is to find D -dimensional real-valued representation v q m  X  X  D of each query q m such that semantically similar queries lie nearby in the new space.
We propose three approaches for learning query repre-sentations that address specifics of the web search environ-ment. We first propose context2vec and content2vec meth-ods that consider query context and query content, respec-tively, motivated by previous work on learning word rep-resentations from news articles [30, 31]. We then detail context-content2vec, a two-level architecture for joint mod-eling of both query context and query content, which results in better, more useful query representations.
The context2vec model involves learning low-dimensional representations of queries from search logs by using a notion of a search session as a  X  X entence X  and queries within the session as  X  X ords X , borrowing the terminology from NLP do-main (see Figure 1a). More specifically, context2vec learns query representations using the skip-gram model [31] by maximizing the objective function over the entire set S of search sessions, defined as Probability P ( q m + i | q m ) of observing a neighboring query q m + i given the current query q m is defined using soft-max, where v q and v 0 q are the input and output vector representa-tions of query q , b is defined as length of the context for query sequences, and V is the number of unique queries in the vo-cabulary. From equations (4.1) and (4.2) we can see that context2vec models temporal context of query sequences, where queries with similar contexts (i.e., with similar neigh-boring queries) will have similar vector representations in the projected semantic space.
We propose content2vec method to simultaneously learn vector representations of queries and the words contained within them, motivated by the paragraph2vec algorithm [28]. The content2vec architecture is illustrated in Figure 1b. Training data set was derived from user search logs by disregarding the query timestamps, and consisted of queries q m and their containing words q m = ( w m 1 ,w m 2 ,...w mT During training, query vectors are learned so they predict the words in their content, while word vectors are learned so they predict their context words within the query. More specifically, objective of content2vec is to maximize the log-likelihood over the set S of all query sessions, where c is length of the context for words within the query. The probability P ( w mt | w m,t  X  c : w m,t + c ,q m ) is defined using a soft-max function, where v 0 w mt is the output vector representation of w mt  X  v is averaged vector representation of the context including corresponding q m , defined as where v w is the input vector representation of w . Similarly, the probability P ( q m | w m 1 : w mT m ) is defined as where v 0 q m is the output vector representation of q  X  v m is averaged input vector representation of all the words within the query q m , computed as
Both context2vec and content2vec models have limited modeling power in the light of the available data. This is due to the fact that they are not capable of exploiting all the available query log information as they model only one as-pect of the data at hand (i.e., either make use of the context of queries in search sessions or their content, respectively). To overcome this limitation, we propose a two-layer context-content2vec [14] specifically tailored for the purpose of mod-eling query logs. The two-layer architecture of the proposed model is illustrated in Figure 1c. The upper layer models the temporal context of query sequences in search sessions, based on the assumption that temporally closer queries are statistically more dependent. On the other hand, the bot-tom layer models the content information of word sequences found within queries.

More formally, given S sessions of queries together with their content, objective of the two-layer context-content2vec model is to maximize the log-likelihood of the training data, where  X  weights are hyperparameters that trade off between minimization of the log-likelihood of query sequences (i.e., query context) and the log-likelihood of word sequences (i.e., query content). Denoting frequency of the m th query as K we set the hyperparameters as  X  m = 1 log(1+ K rarely seen queries rely more on content and frequently seen queries more on context.

As can be observed, context-content2vec model combines the two earlier models, using the context2vec model in the upper layer and the content2vec model in the lower layer. Note that the probabilities from equation (4.8) are defined in equations (4.2), (4.4), and (4.6). In order to learn from both contextual and content information, the training data set is a union of context and content training data sets defined previously in sections 4.1 and 4.2.
The models are optimized using stochastic gradient as-cent, suitable for large-scale problems. However, computa-tion of gradients  X  X  in (4.1), (4.3), and (4.8) is proportional to the vocabulary size V , which is computationally expen-sive in practical tasks as V could easily reach hundreds of millions. As an alternative, we used negative sampling ap-proach proposed in [31], which significantly reduces the com-putational complexity.

When the vector representations of all queries are found, we can perform query rewriting in a straightforward man-ner. For a given user query q , we generate K query rewrites using K nearest neighbors (K-NN) of query q in the low-dimensional space with respect to a cosine distance [31].
In this section we describe the considered data set and give empirical evaluation of the proposed rewriting methods. We learned embeddings for more than 45 million queries, using one of the largest search data sets reported so far, comprising over 12 billion sessions collected on the US website of Yahoo Search. The vectors were used to produce query rewrites, evaluated in terms of relevance and ad coverage and com-pared to the state-of-the-art methods from the literature.
For purposes of learning query embeddings from query content, we took 45 million most frequent queries and where q m is the m -th query and ( w m 1 ,w m 2 ,...w mT m the words contained within q m .
Search sessions are defined as uninterrupted sequences of web search activity. Following [16], the session ends when a user is inactive for more than 30 minutes. A new session is initiated with the following search query.

To be able to learn query embeddings from interactions of queries within a search session we created dataset D context { s i ,i = 1 ,...,S } , derived by sessionizing user search logs data into sessions s i , that were in turn represented as a set of queries ordered in time, s i = ( q i 1 ,q i 2 a case of repetitive queries, such as s i = ( q i 1 q ,q i 4 = q i 2 ,q i 5 ), repetitions were de-duplicated to obtain s = ( q i 1 ,q i 2 ,q i 5 ). Finally, search sessions that contained only a single search query were discarded.
In a search session, queries are often accompanied by ad clicks and search link clicks. These events can be used as additional context to improve query representations and spe-cialize them for a specific task. For example, while one of the main goals of query rewriting in sponsored search is to produce relevant alternatives to the original query, an-other important goal is for rewrites to match as many bid terms as possible to increase the auction value. Thus, to pro-duce more commercial query rewrites, we use ad click events within query contexts when learning vector representations.
For this purpose we extend the session data set by adding ad click events to user sessions, where each ad click is uniquely identified by ad identification number. (a) automotive-related ad Figure 2: Examples of most similar queries to select ads The data set D ad = { s i ,i = 1 ,...,S } consists of ses-sions s i comprising both search queries and ad clicks, s queries, and a im refer to ad click events. Moreover, to fur-ther improve learned query representations we also consid-ered adding search link clicks to the user sessions (i.e., clicks that a user made on links given as search results, also re-ferred to as organic results), motivated by the idea behind QFG approach. To this end, we expanded data set D to obtain data set D ad + link = { s i ,i = 1 ,...,S } , formed by further adding link click events l im to search sessions s
Unlike in everyday language, where the most frequent to-kens are articles and prepositions (e.g., a , the , in ), in search data the most frequent tokens are navigational queries, such as google , yahoo , facebook , etc. Due to the fact that over a longer period they occur in a direct neighborhood of ma-jority of other queries, there is a risk that the embedding space will shrink. We have empirically observed this phe-nomenon, and during training the navigational queries tend to pull all other queries towards them, preventing the vectors from spreading further away in the hyperspace.

The authors of [31] suggested to deal with the frequent tokens in news articles by downsampling. This heuristic involved discarding words with probability P ( w i ) = 1  X  f ( w i ) , where f ( w i ) is the frequency of word w i , and  X  is a user-set parameter. However, this approach is not applica-ble in a context of web search which poses quite different re-quirements. In particular, we aim to learn good representa-tions of navigational queries while at the same time prevent them from adversely influencing representation learning for non-navigational queries. To achieve this objective, we pro-pose a one-direction learning rule for navigational queries. In particular, their vectors are being updated by vectors of queries appearing in the context, but are not used to update the vectors of other queries in their context. We identified navigational queries editorially by evaluating the most fre-quent 3 , 000 queries for navigational intent.
Models were trained using a cluster of 9 machines with 256GB of RAM memory and 24 cores. Dimensionality of the embedding space was set to D = 300, context neighborhood size was set to 5 and content neighborhood size was set to 7. Finally, we used negative sampling to speed up the training, and used 10 random samples in each vector update.
We considered the following approaches in our empirical analysis, where each resulted in vector representation for 45 million most frequent queries. 1) word2vec news model was used as a simple baseline. Query vectors were constructed by summing publicly avail-able word vectors for word tokens in a query (whitespace was used as a token separator), trained on Google News data set with English stopwords removed 1 . 2) word2vec search query vectors constructed by sum-ming word vectors for word tokens in a query, trained using D 3) content2vec model (cn2vec) was trained using D content where queries were used as a global context to the containing words, as illustrated in Figure 1b. 4) context2vec model (cx2vec) was trained using D context , as illustrated in Figure 1a. 5) context-content2vec model (cx-cn2vec) used both D content and D context data to train query vectors, leveraging the two-layer architecture from Section 4.3. Since the model learns from both content and context, one of the motivations behind cx-cn2vec is to improve embeddings for queries that were not seen in many sessions. In Table 1 we give several illustrative examples of such tail queries. Unlike cx2vec, cx-cn2vec relies more on content in case of rare queries, and thus provides better rewrites. For example, at the time of creation of our data set the query  X  X phone 6 repair service X  was a tail query, resulting in poor cx2vec rewrites such as  X  X p3attic music X  or  X  X ocial security disability bronx ny X . On the other hand, cx-cn2vec provided more relevant rewrites. https://code.google.com/p/word2vec 6) cx-cn2vec ad model was trained using D context and D ad (i.e., context data with ad clicks added). Training re-sulted in additional 8 . 5 million ad vectors.
 As illustrated in Table 2, we can see that addition of D ad resulted in quite different query rewrites than using a data set without ad clicks. For example, rewrites for query  X  X akeup X  mainly contain terms that are related to tips, tu-torials, and pictures when no ads were used in training. Con-versely, rewrites for the same query when clicks on ads are considered contain more commercial search terms.

In addition, given ad and query vectors in the same em-bedding space, we can easily retrieve similar queries for any given ad. This by-product is extremely useful for suggesting new bid keywords for specific categories of ads (note that in our system ads are categorized into one or more interest categories, such as  X  X ports X  or  X  X ravel X ). As an example, in Figure 2 we show K = 5 , 000 most similar queries to ads in  X  X utomotive X  and  X  X ir travel X  categories. Keywords with higher cosine similarity are shown with larger font sizes. We can observe that the key concepts of the category are well captured with the most similar queries. 7) cx-cn2vec ad+link model was trained using D content and D ad + link (i.e., context data with ad clicks and link clicks added). Training resulted in additional 19 million search link vectors and 8 . 5 million ad vectors. 8) QFG ad+link model was trained using a click-flow graph constructed from D ad + link dataset, with additional 19 million search link vectors and 8 . 5 million ad vectors.
To produce rewrites for out-of-dictionary queries, embed-ding models generated their vectors by summing the existing vectors of word tokens within queries (excluding stopwords). Unlike the embedding methods, QFG could not produce rewrites for queries that were not seen in the graph.
Our evaluation did not include topic models such as LDA [5] or PLSA [19], as earlier research [20] found that these methods perform poorly on short text documents.
In the following two sections we show our main experi-mental results, where we report performance of the com-peting approaches in terms of relevance and ad coverage of query rewrites. We also provide examples of rewrites by cx-cn2vec ad+link method in an online video 2 .
We used editorial judgments of query rewrites to compare query rewriting methods in terms of relevance.

In-house data. The first data set we used is an in-house data set consisting of the query and several rewrites produced by current production system that were graded editorially. The editors were instructed to assign the fol-lowing grades: bad , fair , good , and excellent . In total, the data set includes more than 40 , 000 (query, rewrite, grade) tuples, such as ( X  X fl news X ,  X  X atest nfl news X ,  X  X xcellent X ), ( X  X fl news X ,  X  X fl shooting X ,  X  X air X ), ( X  X fl news X ,  X  X fl rumor X ,  X  X ood X ), ( X  X etro transit X ,  X  X etro pcs X ,  X  X ad X ).

Given a query we ranked the rewrite candidates based on a model X  X  output score and retrieved the top K candidates. Next, we computed the NDCG metric using editorial grades of rewrites as labels (0 for bad, 1 for fair, 2 for good, and 3 for excellent) at values of K ranging from 1 to 20. In Figure 3 we report the results for different models. http://youtu.be/pvfFQSCYhqI
By considering the reported results, several conclusions can be drawn. Regarding models that did not utilize search session data (i.e., word2vec news , word2vec search , and cn2vec), we can see that the word embeddings specifically tailored for search queries perform better than using word embeddings learned using news data. In addition, learning query vec-tors as global context of words using cn2vec leads to slightly better results than directly summing the words. However, all three models performed worse than the QFG ad+link base-line method, which made use of the co-occurrence of queries, ads, and links in search sessions. Query embeddings trained directly on search sessions, i.e. cx2vec, already outperform QFG ad+link . Further improvements were observed when em-beddings were learned from both context and content. Fi-nally, incorporating ad and link click events showed incre-mental boost in relevance. The largest gain was observed when links were added as an additional context.

In addition, in Table 3 we report average similarities of (query, rewrite) pairs in each editorial grade group. It is important to note that scores are comparable only within the same method and not across methods. For conclusive comparison we calculated the level of separation between the groups by p-value of t-test, which tests the hypothesis that the means of two neighboring grades are equal. By compar-ing p-values reported we can quantify which method does the best job of separating the four grade groups. Findings are similar to the ones from Figure 3. Additionally, we find that QFG ad+link method has issues with  X  X ad X  grade group, and that without incorporating search context, the embedding models have similar average scores in  X  X ood X  and  X  X air X  grade groups. As expected, separation improves when embedding models incorporate search context, with the standard devi-ation between the groups reducing even further when ads and links were considered as an additional context.
In the case when one or both queries from the editorial grade list were not found in a model, we generated the vec-tors by summing vectors of query tokens. Bottom part of Ta-ble 3 shows results for such cases. We can observe that sim-ilar conclusion hold even for such out-of-dictionary queries.
TREC data. The second data we used was a publicly available TREC Web Track data set 3 from 2009 to 2013, con-taining a total of 250 queries. Using the competing methods we produced 5 rewrites for each query, and evaluated the re-sult editorially. The editors were given instructions to rate the rewrites in the following way: grade 0 if the rewrite is irrelevant, grade 1 if relevant, and grade 2 if it is excellent. http://trec.nist.gov/
Editorial grades for each method as well as the Leven-shtein distance [29] were averaged and reported in Table 5. We can see that the cx-cn2vec ad+link query embedding method, learned from query content and search session con-text including ad and link clicks, returned the most relevant rewrites and outperformed the baseline QFG method. Once more, learning query embeddings from content of queries on its own was not enough to outperform QFG. Interest-ingly, there was just a small difference between cx2vec and cx-cn2vec models. It can be explained by the fact that cx-cn2vec generally improves rewrites for tail queries, while TREC data set mostly consists of frequent queries.

In addition to providing highly relevant rewrites, cx-cn2vec ad+link showed the highest diversity, a favorable prop-erty for rewrite algorithms. Considering the performance in terms of Levenshtein distance, we can observe that rewrites produced by models which learned from content are less di-verse than the ones produced by approaches that modeled query context during training.

Examples of query rewrites obtained by the competing methods are given in Table 4. As can be seen, there exist significant differences between the rewrites of the competing approaches. As discussed earlier, the content-based model cn2vec is sensitive to cases when the query words appeared in different contexts across the query dictionary. For exam-ple, words  X  X udget X  and  X  X alculator X  from the query  X  X ed-ding budget calculator X  mostly appeared in more general financial contexts. For this reason in the first 5 rewrites we have queries that are not related to wedding. The model that utilized both content and context data cx-cn2vec outputs highly relevant, interesting rewrites that capture a number of meanings and contexts of the original query. The model that considered ads during training cx-cn2vec ad produced more commercial rewrites, referencing stores and sales. We also bolded queries that matched the actual bidterms in the system, discussed in more detail in the following experiment. Examples of query rewrites produced by cx-cn2vec ad+link are shown in an online video 4 . The video mostly covers queries from TREC 2010 data set. http://youtu.be/n5kHKyKQAa8 Table 5: Comparison of query rewrite methods (TREC data) Method Editorial grade Levenshtein dist.

QFG ad+link 1 . 0441 11 . 70 word2vec news 0.9189 10 . 91 word2vec search 0.9492 11 . 32 cn2vec 0.9571 11 . 37 cx2vec 1.1273 13 . 79 cx-cn2vec 1 . 1343 13 . 13 cx-cn2vec ad 1 . 2281 13 . 62 cx-cn2vec ad+link 1.2457 13 . 25
In the previous section we showed the advantage of pro-posed methods in terms of relevance. In this section we eval-uate how beneficial those rewrites are from the ad match-ing perspective. It is of fundamental interest to sponsored search to ensure that the rewrites being provided as alterna-tives to the users X  queries match as many additional relevant bidterms as possible. The percentage of rewrites that match bid terms is defined as coverage . We conducted an off-line experiment to compare query rewriting methods: 1) on an in-house dataset of 2 , 000 editorially selected queries which the editors deemed representative of the query set; and 2) on the TREC data set. For each query in the data sets we generated K = 5 rewrites and look-up bidterms in our current sponsored search demand. We report average cov-erage (relative improvement over QFG) over the entire set of queries for each of the two data sets. Table 6 summarizes the results of our analysis.

To estimate monetary value of each query rewriting method we used two proxy measures. First, for the query rewrites produced by each method we look-up the bid amounts for the queries that were matched in the bidterm database. We report the total sum of these amounts, and refer to this metric as  X  X evenue potential X . In addition, for each rewrite method we calculated effective cost per mille (eCPM). Given a query rewrite q , and an ad a for which q was a bidterm, we calculated eCPM value e qa by multi-plying cost per click (CPC) dollar amount and the click-through rate (CTR) of that (query, ad) pair, computed as number of ad clicks divided by number of ad impressions. Fi-nally, we report the weighted sum of eCPM X  X , P q P a w q e where the weight w q is proportional to the number of times the query appeared in the search logs. Considering the re-sults presented in Table 6, we can see that query embedding models trained using news documents and query content achieved lower average coverage than QFG method. How-ever, QFG was in turn outperformed by the coverage of rewrites produced using query embedding approaches.
Moreover, by taking the results from both experiments into account, it can be concluded that cx-cn2vec ads + links is the best choice as it achieves the highest relevance while maintaining large ad coverage. When link clicks were added on top of ad clicks we observed a large improvement in rel-evance, with ad coverage remaining almost the same.
In this paper we described novel query rewriting methods based on recently proposed neural language models. The methods learn low-dimensional, distributed representations of search queries based on context (context2vec), content (content2vec), or combined context and content (context-content2vec) of the queries within search sessions. To spe-cialize the query rewrites for sponsored search application, we further incorporated ad clicks and search link clicks into the training data. We evaluated the proposed methods us-ing both in-house and publicly available TREC data sets. When compared to the current state-of-the-art approaches, we showed that context-content2vec generates the most rel-evant query rewrites, while at the same time maintains high level of ad coverage. The results clearly indicate significant advantages of context-content2vec over the state-of-the-art query rewrite algorithms, and suggest high monetization po-tential of the query embedding approach to the task of spon-sored search advertising. In our ongoing work, we plan to experiment with more involved search sessionization algo-rithms and navigational query detection algorithms. [1] M. Aly, A. Hatch, V. Josifovski, and V. K. Narayanan. [2] R. Baeza-Yates, C. Hurtado, and M. Mendoza. Query [3] R. Baeza-Yates, B. Ribeiro-Neto, et al. Modern [4] Y. Bengio, H. Schwenk, J.-S. Sen  X ecal, F. Morin, and [5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [6] P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, [7] F. Bonchi, R. Perego, F. Silvestri, H. Vahabi, and [8] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, [9] D. E. Bowman, M. L. Hamrick, T. R. Kohn, R. E. [10] A. Broder. A taxonomy of web search. In ACM Sigir [11] A. Z. Broder, P. Ciccolo, M. Fontoura, E. Gabrilovich, [12] Y. Chen, D. Pavlov, and J. F. Canny. Large-scale [13] R. Collobert, J. Weston, L. Bottou, M. Karlen, [14] N. Djuric, H. Wu, V. Radosavljevic, M. Grbovic, and [15] D. C. Fain and J. O. Pedersen. Sponsored search: A [16] D. Gayo-Avello. A survey on session detection [17] M. Grbovic, N. Djuric, V. Radosavljevic, and [18] M. Grbovic and S. Vucetic. Generating ad targeting [19] T. Hofmann. Probabilistic latent semantic indexing. In [20] L. Hong and B. D. Davison. Empirical study of topic [21] A. K. Jain, L. Hong, and S. Pankanti. Iab internet [22] B. J. Jansen and T. Mullen. Sponsored search: An [23] R. Jones, B. Rey, O. Madani, and W. Greiner.
 [24] F. Keller and M. Lapata. Using the web to obtain [25] R. Kiros, R. Zemel, and R. Salakhutdinov. Multimodal [26] R. Kiros, R. S. Zemel, and R. Salakhutdinov. A [27] V. Lavrenko and W. B. Croft. Relevance based [28] Q. V. Le and T. Mikolov. Distributed representations [29] V. Levenshtein. Binary codes capable of correcting [30] T. Mikolov, K. Chen, G. Corrado, and J. Dean. [31] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and [32] S. Pandey, M. Aly, A. Bagherjeiran, A. Hatch, [33] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: [34] PwC. Global entertainment and media outlook: [35] C. Silverstein, H. Marais, M. Henzinger, and [36] F. Silvestri. Mining query logs: Turning search usage [37] R. Socher, D. Chen, C. D. Manning, and A. Ng. [38] J. Turian, L. Ratinov, and Y. Bengio. Word [39] H. Vahabi, M. Ackerman, D. Loker, R. Baeza-Yates, [40] W. V. Zhang and R. Jones. Comparing click logs and
