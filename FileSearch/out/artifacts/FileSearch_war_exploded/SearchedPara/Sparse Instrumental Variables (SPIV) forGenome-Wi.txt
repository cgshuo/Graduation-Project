 A problem common to both epidemiology and to systems biology is to infer causal relationships between phenotypic measurements (biomarkers) and disease outcomes or quantitative traits. The problem is complicated by the fact that in large bio-medical studies, the number of possible genetic and environmental causes is very large, which makes it impla usible to conduct exhaustive inter-ventional experiments. Moreover, it is generally impossib le to remove the confounding bias due to unmeasured latent variables which influence associations b etween biomarkers and outcomes. Also, in situations when the biomarkers are mRNA transcript level s, the measurements are known to be quite noisy; additionally, the number of unique candidate c auses may exceed the number of obser-vations by several orders of magnitude (the p  X  n problem). A fundamentally important practical task is to reduce the number of possible causes of a trait to a m uch more manageable subset of can-didates for controlled interventions. Developing an effici ent framework for addressing this problem may be fundamental for overcoming bottlenecks in drug devel opment, with possible applications in the validation of biomarkers as causal risk factors, or deve loping proxies for clinical trials. Whether or not causation may be inferred from observational d ata has been a matter of philosophical debate. Pearl [28] argues that causal assumptions cannot be verified unless one makes a recourse to experimental control, and that there is nothing in the pro bability distribution p ( x, y ) which can tell whether a change in x may have an effect on y . Traditional discussions of causality are largely focused on the question of identifiability, i.e. determinin g sets of graph-theoretic conditions when a post-intervention distribution p ( y | do ( x )) may be uniquely determined from a pre-intervention dis-be obtained by statistical estimation, which for common mod els often reduces to solving systems of linear equations. In contrast, from the Bayesian perspecti ve, the causality detection problem may be viewed as that of model selection, where a model M is complicated by the likelihood-equivalence, where for ea ch setting of parameters of one model there may exist a setting of parameters of the other giving ri se to the identical likelihoods. However, unless the priors are chosen in such a way that M may be possible to infer the direction of the arrow. The view t hat the priors of likelihood-equivalent models do not need to be set to ensure the equivalence of the po steriors is in contrast to e.g. [12] (and references therein), but has been defended by MacKay (s ee [21], Section 35).
 In this paper we are leaving aside debates about the nature of causality and focus instead on iden-tifying a set of candidate causes for a large partially obser ved under-determined genetic problem. The approach builds on the instrumental variable methods th at were historically used in epidemi-Specific modeling hypotheses are tested by comparing approx imate marginal likelihoods of the cor-responding direct, reverse, and pleiotropic models with an d without latent confounders, where we follow [21] in allowing for flexible priors. The approach is l argely motivated by the observation that independent variables do not establish a causal relation, w hile strong unconfounded direct depen-dencies retained in the posterior modes even under large spa rseness-inducing penalties may indicate potential causality and suggest candidates for further con trolled experiments. Inference of causal direction of x on y is to some extent simplified if we assume existence of an auxiliary variable g , such that g  X  X  effect on x may only be causal, and g  X  X  effect on y may only be through x . The idea is exploited in instrumental variable methods [3, 2, 29] which typically deal with low-dimensional linear models, where the strengt h of the causal effect may be estimated as w x  X  y = cov( g, y ) / cov( g, x ) . Note also that the hypothesized cause-outcome models such as M appropriate model via likelihood-based tests. Selecting a plausible instrument g may be difficult in some domains; however, in genetic studies it may be possible to exploit as an instrument a measure of genotypic variation. In quantitative genetics, such app lications of instrumental variable methods have been termed Mendelian randomization [15, 34]. In accordance with the requirements of the classic instrumental variable methods, it is assumed that e ffects of the genetic instrument g on the biomarker x are unconfounded, and that effects of the instrument on the o utcome y are mediated only through the biomarker (i.e. there is no pleiotropy ) [17, 35]. The former assumption is grounded in the laws of Mendelian genetics and is satisfied as long as populat ion stratification has been adequately controlled. However, the assumption of no hidden pleiotrop y severely restricts the application of this approach, as most genotypic effects on complex traits are no t sufficiently well understood to exclude argument is limited to biomarkers for which suitable non-pl eiotropic instruments exist, and cannot be easily extended to exploit studies with multiple biomark ers and genome-wide data.
 A more general approach to exploiting genotypic variation t o infer causal relationships between gene transcript levels and quantitative traits has been dev eloped by Schadt et. al. [30] and subse-quently extended (see e.g. [5]). They relax the assumption o f no pleiotropy, but instead compare models with and without pleiotropy by computing standard li kelihood-based scores. After filtering to select a set of gene transcripts { x genotypes have effects on transcript levels x causation, and a pleiotropic model (see Figure 1 left, (i) X (iii) ). The support for these three models is compared by a measure of model fit penalized by complexity: either Akaike X  X  Information Cri-terion (AIC) [30], or the Bayesian Information Criterion (B IC) [5]. Schadt et. al. [30] denote this procedure as the  X  X ikelihood-based causality model select ion X  (LCMS) approach. While the LCMS (iv) Figure 1: Left: (i X  X ii): Causal, reverse, and pleiotropic models of the LCMS approac h [30]; (iv): pleiotropic model with two genetic instruments. Center: Possible arbitrariness of LCMS inference. The histogram shows the difference of the AIC scores for the c ausal and reverse models for a fixed biomarker and outcome, and various choices of loci from pred ictive regions. Right: AIC scores of the causal (top) and reverse (bottom) models for each choi ce of instrument g link the scores for a fixed choice of g model. Biomarker and outcome are liver expressions of Cyp27b1 and plasma HDL measurements for heterogeneous mice. Based on the choice of g and related methods [30, 5] relax the assumption of no hidden pleiotropy of the classic Mendelian randomization method, they have three key limitations. Fir st, effects of loci and biomarkers on out-comes are not modeled jointly, so widely varying inferences are possible depending on the choice of the triads { g and reverse models constructed for a fixed biomarker and outc ome, and for various choices of the genetic instruments from the predictive region. Depending on the choice of instrument g causal or reverse explanations are favored. A second key lim itation is that the LCMS method does not allow for dependencies between multiple biomarkers, me asurement noise, or latent variables (such as unobserved confounders of the biomarker-outcome a ssociations). Thus, for instance, with-out allowance for noise in the biomarker measurements, non-zero conditional mutual information between the underlying biomarker and outcome is causal. Als o, the method is not Bayesian (the BIC score is only a crude approximation to the Bayesian proce dure for model selection). One extension of the classic instrumental variable methods has been proposed by [4], who described graph-theoretic conditions which need to be satisfied in ord er for parameters of edges x be identifiable by solving a system of linear equations; howe ver, they focus on the identifiability For example, their method does not allow for an easy integrat ion of unmeasured confounders with unknown correlations with the intermediate and outcome var iables. Another approach to modeling joint effects of genetic loci and biomarkers (gene expressi ons) was described by [41]. They modeled the expression measurements as three ordered levels, and us ed a biased greedy search over model structures from multiple starting points, to find models wit h high BIC scores. Though applicable for large-scale studies, the approach does not allow for mea surement noise or latent variables (and looses information by using categorical measurements). Th e vast majority of other recent model selection and structure learning methods from machine lear ning literature are also either not easily extended to include latent confounders (e.g. [16], [19], [2 2]), or applicable only for dealing with relatively low-dimensional problems with abundant data (e .g. [33] and references therein). To address the problem of causal discovery in large bio-medi cal studies, we need a unified frame-work for modeling relations between genotypes, biomarkers , and outcomes that is computationally tractable to handle a large number of variables. Our approac h extends LCMS and the instrumental variable methods by the joint modeling of effects of genetic loci and biomarkers, and by allowing for both pleiotropic genotypic effects and latent variables th at generate couplings between biomarkers and confound the biomarker-outcome associations. It relie s on Bayesian modeling of linear associ-ations between the modeled variables, with sparseness-ind ucing priors on the linear weights. The Figure 2: Left: SPIV structure. Filled/clear nodes correspond to observed / latent variables. Right: log Bayes factor of M intermediate  X  Bayesian framework allows prior biological information to be included if available: for instance, cis-acting genotypic effects on transcript levels are like ly to be stronger and less pleiotropic than trans-acting effects on transcript levels. It also offers a rigorous approach to model comparison, and is particularly attractive for addressing under-determin ed genetics problems ( p  X  n ). The method builds on automatic relevance determination approaches (e .g. [20], [25], [37]) and adaptive shrink-analysis in the presence of unobserved confounders, pleiot ropy, and noise.
 Model Parameterization Our sparse instrumental variables model (SPIV) is specified with four classes of variables: gen o-and latent factors z high value (extraneous dimensions will tend to be pruned und er the sparse prior). The latent factors z play two major roles: they represent the shared structure be tween groups of biomarkers, and con-found biomarker-outcome associations. The biomarkers x and outcomes y are specified as hidden effects of genotype on biomarkers and outcome are assumed to be unconfounded. Pleiotropic effects of genotype (effects on outcome that are not mediated throug h the phenotypic biomarkers) are ac-methods [2, 3, 29] by allowing for the pleiotropic links, and also extends the pleiotropic model of Schadt et. al. [30] (Figure 1 left (iii) ) by allowing for multiple instruments and latent variables . and  X  y = y + e N (0 ,  X  structure (accounting for possible couplings of the neighb oring microarray measurements). Prior Distribution tional convenience, the variance components of the diagona l covariances  X  with inverse Gamma priors  X   X  1 ( a biomarker measurements). One way to view the latent confoun ders z is as missing genotypes or environmental covariates, so that prior variances of the la tent factors are peaked at values repre-sentative of the empirical variances of the instruments g . Empirically, the choice of priors on the variance components appears to be relatively unimportant, and other choices may be considered [9]. The considered choice of a sparseness-inducing prior on par ameters W , W of zero-mean Laplace and zero-mean normal distributions L w i (0 ,  X  1 )  X  exp { X   X  1 | w i |} cian L values of  X  different  X  ever, for clarity of this presentation we shall only use a glo bal parameter  X  component with the inverse variance  X  The considered family of priors (2) induces better consiste ncy properties [40] than the commonly used Laplacians [36, 9, 39, 26, 31]. It has also been shown [14 ] that important associations between variables may be recovered even for severely under-determi ned problems ( p  X  n ) common in ge-netics. The SPIV model with p ( w ) defined as in (2) generalizes LASSO and elastic net regressio n [36, 42]. As a special case, it also includes sparse conditio nal factor analysis. Other sparse priors on the weights, such as Student-t ,  X  X pike-and-slab X , or inducing L tractable posteriors even for linear regression [10, 37, 8] , which also motivates the choice (2). Some additional intuition of the influence of the sparse prio r on the causal inference may be gained by numerically comparing the marginal likelihoods of the Ma rkov-equivalent models with and with-out confounders M epidemiology, because while the temporal data may often be a vailable for distinguishing direct and reverse models M Figure 2 shows that when the empirical correlations are stro ng and  X  is a strong preference for a causal model. This is because the alternative model with the confounders will have more parameters, and the weights will need to be lar ger (and therefore more strongly pe-likelihood-equivalence is achieved for w = vw penalize all the weights, which makes the models largely ind istinguishable. Also, as the number of genetic instruments grows, evidence in favor of the causal o r pleiotropic model will be less depen-dent upon the priors on model parameters. For instance, with two genotypic variables that perturb a single transcript, the causal model has three adjustable p arameters, but the pleiotropic model has five (see Figure 1 left, (iv) ). Where several genotypic variables perturb a single transc ript and the causal model fits the data nearly as well as the pleiotropic mo del, the causal model will have higher model will be outweighed by the penalty imposed by several ex tra adjustable parameters. Inference While the choice of prior (2) encourages sparse solutions, it makes exact inference of the posterior parameters p (  X  |D ) analytically intractable. The most efficient approach is ba sed on the maximum-a-posteriori ( MAP ) treatment ([36], [9]), which reduces to solving the optimi zation problem for the joint parameters  X  , where the latent variables have been integrated out. Note t hat the MAP and outcome vectors are only partially observed. Compared t o other approximations of inference approximation allows for an efficient handling of very large networks with multiple instruments and biomarkers, and makes it straightforward to incorporat e latent confounders. Depending on the choice of the global sparseness and grouping hyperparamete rs  X  weights will tend to be sparse, which is also in contrast to th e full inference methods. In high dimen-sions in particular, the parsimony induced by the point-est imates will facilitate structure discovery and interpretations of the findings.
 One way to optimize (3) is by an EM-like algorithm. For exampl e, the fixed-point update for u R g | linking biomarker x i with the vector of instruments g is easily expressed as Figure 3: Top: SPIV for artificial datasets. Left/right plots show typical applications for the high and low observation noise (  X  2 Hinton diagram correspond to the ground truth and the MAP wei ghts U (1 X 18), W (19 X 21), W 27). Bottom: SPIV for a genome-wide study of causal effects on HDL in heter ogeneous stock mice. Left/right plots show maximum a-posteriori weights  X  between the unobserved biomarkers and outcome evaluated fr om the model at  X  joint Gaussian assumption. A cluster of pleiotropic links o n chromosome 1 at about 173 MBP is consistent with biology. The biomarker with the strongest u nconfounded effect on HDL is Cyp27b1 . Transcripts that are most predictive of HDL through their li nks with pleiotropic genetic markers on chrom 1 are Uap1, Rgs5, Apoa2 , and Nr1i3 . Parameters  X  v which for (1) are easily expressed in the closed form. The res t is expressed analogously, and ex-tensions to the partially observed cases are straight-forw ard. Faster (although more heuristic) al-ternatives may be used for speeding up the M-step (e.g. [7]). The hyperparameters may be set by cross-validation, marginalized out by specifying a hype r-prior, or set heuristically based on the produced by pruning irrelevant dimensions, more computati onally-intensive inference methods for the full posterior (such as expectation propagation or MCMC ) may be used in the resulting lower-dimensional model if needed. After fitting SPIV to data, form al hypotheses tests were performed by comparing the marginal likelihoods of the specific models fo r the retained instruments, biomarkers, and target outcomes. These were evaluated by the Laplace app roximation at  X  Artificial data: We applied SPIV to several simulated datasets, and compared specific modeling hypotheses for the biomarkers retained in the posterior mod es. The structures were consistent with the generic SPIV model, with all non-zero weights sampled fr om N (0 , 1) . Figure 3 (top) shows typical results for the high/low observation noise (  X  i,  X  2 consistency of the results for the more important factors. S eparate simulations showed robustness under multiple EM runs and under-or over-estimation of the t rue number of confounders. Sub-sequent testing of the specific modeling hypotheses for the m ost important factors resulted in the correct discrimination of causal and confounded associati ons in  X  86% of cases.
 Genome-wide study of HDL cholesterol in mice: To demonstrate our method for a large-scale density lipoprotein (HDL) cholesterol levels for a mice fro m a heterogeneous stock. The genetic factors influencing HDL in mice have been well explored in bio logy e.g. by Valdar et. al. [38]. The gene expression data was collected and preprocessed by [ 13], who have kindly agreed to share a part of their data. Breeding pairs for the stock were obtain ed at 50 generations after the stock foundation. At each of the 12500 marker loci, genotypes were described by 8-D vectors of expected founder ancestry proportions inferred from the raw marker g enotypes by an HMM-based reconstruc-tion method [23]. Mouse-specific covariates included age an d sex, which were used to augment the set of genetic instruments. The full set of phenotypic bioma rkers consisted of 47429 transcript lev-els, appropriately transformed and cleaned. Available dat a included 260 animals. Before applying our method, we decreased the dimensionality of the genetic f eatures and RNA expressions by using a combination of seven feature (subset) selection methods, based on applications of filters, greedy (step-wise) regression, sequential approximations of the mutual information between the retained set and the outcome of interest, and applications of regress ion methods with LASSO and elastic net (EN) shrinkage priors for the genotypes g , observed biomarkers  X  x , and observed HDL mea-surements  X  y . For the LASSO and EN methods, global hyper-parameters were obtained by 10-fold cross-validation. Note that feature selection is unavoida ble for genome-wide studies using gene ex-pressions as biomarkers. Indeed, the considered case of  X  O (10 5 ) instruments and 47K biomarkers would give rise to &amp; O (10 9 ) interaction weights, which is expensive to analyze or even k eep in memory. After applying subset selection methods, SPIV was t ypically applied to subsets of data with  X  O (10 5 ) loci-biomarker interactions.
 The results of the SPIV analysis of this dataset are shown on F igure 3 (bottom). The bottom left plot shows maximum a-posteriori weights  X  procedure to convergence from 20 random initializations. F or a model with latent variables and about 30 , 000 weights, each run took approximately 10 minutes of executio n time (only weakly optimized Matlab code, simple desktop). The parameters  X  that only a fraction of the variables remains in the posterio r. In this case and for the considered sparseness-inducing priors, no hidden confounders appear to have strong effects on the outcome in the posterior 1 . The spikes of the pleiotropic activations in sex chromosom e 20 and around chromo-some 1 are consistent with the biological knowledge [38]. Th e biomarker with the strongest direct effect on HDL (computed as the mean MAP weight w over multiple runs, where each mean weight exceeds a thresho ld) is the expression of Cyp27b1 (gene responsible for vitamin D metabolism). Knockout of the Cyp27b1 gene in mice has been shown to alter body fat stores [24], which might be expected to affect HDL cholesterol levels. Recently it has also been shown that quantitative trait locus for circul ating vitamin D levels in humans includes a gene that codes for the enzyme that synthesizes cholestero l [1]. A subsequent comparison of 18 specific reverse, pleiotropic, and causal models for Cyp27b1 , HDL, and the whole vector of retained genetic instruments (known to be causal by definition) showe d a slightly stronger evidence in favor of the reverse hypothesis without latent confounders (with the ratio of Laplace approximations of the marginal likelihoods of reverse vs causal models of  X  1 . 95  X  0 . 27 ). This is in contrast to the LCMS where the results are strongly affected by the choice of an instrument (Figure 1 right shows the results for Cyp27b1 , HDL, and the same choice of instruments).
 approximate mutual information I ( x unobserved HDL levels expressed from the model at  X  account not only the strength of the direct effect of x instruments, strengths of the pleiotropic effects, and dep endencies between the instruments. Under the as-if Gaussian assumption, I ( x with the rest expressed analogously. Here  X  ments, w biomarkers, confounders, and genetic instruments respect ively. When the outcome is HDL, the ma-jority of predictive transcripts are fine-mapped to a small r egion on chromosome 1 which includes Uap1, Rgs5 , Apoa2 , and Nr1i3 . The informativeness of these genes about the HDL cholester ol can-not be inferred simply from correlations between the measur ed gene expression and HDL levels; for example, when ranked in accordance to  X  2 (  X  x of 838, 961, 6284, and 65 respectively. The findings are also b iologically plausible and consistent with high-profile biological literature (with association s between Apoa2 and HDL described in [38], and strong links of Rgs5 to a genomic region strongly associated with metabolic trai ts discussed in [5], while Nr1i3 and Uap1 are their neighbors on chromosome 1 within  X  1 M bp ). Note that the couplings are via the links with the pleiotropic genetic mar kers on chromosome 1. Adjusting for sex and age prior to performing feature selection and inference did not significantly change the results. The results reported here appear to be stable for different c hoices of feature selection methods, data adjustments, and algorithm runs. We note, however, that dif ferent results may potentially be obtained based on the choice of animal populations and/or processing of the biomarker (gene expression) measurements. Details of the data collection, microarray p reprocessing, and feature selection, along with the detailed findings for other biomarkers and phenotyp ic outcomes will be made available online. Definitive confirmation of these relationships woul d require gene knock-out experiments. In large-scale genetic and bio-medical studies, we are faci ng a practical task of reducing a huge set of candidate causes of complex traits to a more manageable su bset of candidates where experimen-tal control (such as gene knockout experiments or biomarker alternations) may be performed. SPIV performs the screening of interesting biomarker-phenotyp e and genotype-biomarker-phenotype as-sociations by exploiting the maximum-a-posteriori infere nce in a sparse linear latent variable model. Additional screening is performed by comparing approximat e marginal likelihoods of specific mod-eling hypotheses, including direct, reverse, and pleiotro pic models with and without confounders, which (under the assumption of no  X  X rior equivalence X ) may s erve as an additional test of possible causation [21]. Intuitively, the approach is motivated by t he observation that while independence of variables implies that they are not in a causal relation, a preference for an unconfounded causal model may indicate possible causality and require further c ontrolled experiments.
 Technically, SPIV may be viewed as an extension of LASSO and e lastic net regression which al-lows for latent variables and pleiotropic dependencies. Whi le being particularly attractive for genetic studies, SPIV or its modifications may potentially be applie d for addressing more general structure learning tasks. For example, when applied iteratively, SPI V may be used to guide search over richer model structures (where a greedy search over parent nodes is replaced by a continuous optimiza-tion problem which combines subset selection and regressio n in the presence of latent variables), which may be used for structure learning problems. Other ext ensions of the framework could in-volve hybrid (discrete-and real-valued) outcomes with non linear/nongaussian likelihoods. Also, as mentioned earlier, once sparse representations are prod uced by the MAP inference, it may be possible to utilize more accurate approximations of the inf erence applicable for the induced sparse matrices. A potentially interesting alternative may invol ve a direct estimation of conditional preci-sion matrices with a sparse group penalty. While SPIV attempt s to focus the attention on important biomarkers establishing strong direct associations with t he phenotypes, modeling of the precisions may be used for filtering out unimportant factors (conditionally) independent of the outcome vari-ables. Our future work will involve a direct estimation of th e sparse conditional precision matrix  X  latent variable extensions of the recently proposed graphi cal LASSO and related methods [11, 18]. The key purpose of this paper is to draw attention of the machi ne learning community to the prob-lem of inferring causal relationships between phenotypic m easurements and complex traits (disease risks), which may have tremendous implications in epidemio logy and systems biology. Our specific approach to the problem is inspired by the ideas of instrumen tal variable analysis commonly used in epidemiological studies, which we have extended to prope rly address situations when the ge-netic variables may be direct causes of the hypothesized out comes. The sparse instrumental variable framework (SPIV) overcomes limitations of the likelihood-based LCMS methods often used by ge-neticists, by modeling joint effects of genetic loci and bio markers in the presence of noise and latent variables. The approach is tractable enough to be used in gen etic studies with tens of thousands of variables. It may be used for identifying specific genes asso ciated with phenotypic outcomes, and may have wide applications in identification of biomarkers a s possible targets for interventions, or as proxy endpoints for early-stage clinical trials.
