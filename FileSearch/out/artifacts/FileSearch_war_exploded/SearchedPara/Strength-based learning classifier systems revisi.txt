 1. Introduction Learning classifier systems (LCS), originally proposed by Holland (1976) , belong to a class of machine learning (ML) systems designed to work for both single-step and sequential decision problems. They employ a population of classifiers (usually rules in the traditional production system form) gradu-ally evolving through the use of a reinforcement scheme and a genetic algorithm (GA) based search component ( Holland, 1975 ). Research in the LCS field has mainly focused on the case of sequential decision problems, with XCS ( Wilson, 1995 )  X  the first LCS for which accurate and maximal generalizations were reported  X  being the algorithm studied in the vast majority of cases. Starting in the late 1990s, however, there has been a shift of interest toward applying LCS to single-step decision tasks, such as predictive data mining (DM), which has come to be considered one of the most important application domains for this class of systems ( Barry et al., 2004 ; Lanzi, 2008 ).

Despite the different nature and requirements of single-step classification problems, most of the investigations in the DM area have also relied on XCS-like accuracy-based approaches evolving complete , rather than best action maps (BAM). BAM LCS, on the other hand, have been less popular, although they evolve rulesets that only contain high-rewarded rules  X  or in DM terms, rules that are consistently correct. Thus, BAM LCS provide compact knowledge representations that may be more efficient in large search spaces, characteristic of real-world classification problems ( Bernado  X  -Mansilla and Garrell-Guiu, 2003 ).

Irrespective of the model it evolves, a BAM learner may be either an accuracy-based or a strength-based LCS ( Bernado  X  -
Mansilla and Garrell-Guiu, 2003 ). Although strength-based LCS  X  X  X aturally X  X  evolve BAMs, due to their inherent exploration focus on best-rewarded rules, comparative studies between the two approaches have been sparse ( Bull and Hurst, 2002 ; Bull, 2005 ;
Bull et al., 2007 ). This is partly due to the fact that strength-based fitness has been traditionally associated with poor generalization and performance. Moreover, the focus of existing studies has remained on simplified versions of strength-based systems and theoretical investigations of boundedly difficult artificial pro-blems. While the contribution of such studies in advancing our understanding of LCS is undoubtedly important, there have not been comparative studies between strength and accuracy-based systems specifically focusing on supervised classification tasks and extending the experimental investigation to real-world tasks. Exactly this gap in the literature has motivated our current work. based fitness calculation and aim to uncover its potential as a
BAM learner for single-step classification tasks. Our proposed algorithm, named Strength-based Supervised Learning Classifier
System (SS-LCS) comprises: a. a supervised learning framework for evolving BAMs in super-b. a set of extensions to the traditional strength-based approach
The definition of the SS-LCS algorithm serves as the starting point for our comparison of accuracy and strength-based supervised
LCS, which involves the investigation of several key aspects of such algorithms in the domain of classification problems. The performance, convergence properties, fitness pressure and gen-eralization abilities of the two approaches are analyzed and conclusions are drawn regarding their competitiveness in (i) boundedly difficult artificial problems with multiple classes and various class distributions and (ii) a wide range of real-world classification tasks. Throughout all experiments, the state-of-the-art UCS algorithm ( Orriols-Puig, 2008 ; Orriols-Puig and Bernado  X  -
Mansilla, 2008c ) that is an accuracy-based supervised BAM learner is also included in the comparison, actually serving as a reference point for validating the performance of the proposed SS-
LCS algorithm. The results of our extended experimental investi-gation contribute to a better understanding of the learning dynamics involved in single-step classification problems and reveal the potential of strength-based supervised LCS as real-world DM tools inducing tractable rule-based classification mod-els, even in the presence of highly skewed class distributions. sets the context of our current work, by discussing related work and the issues central in the debate between CAMs and BAMs.
Section 3 presents the SS-LCS algorithm, through a high-level description of its learning components, details our proposed extensions to the traditional strength-based LCS framework and analyzes how these extensions alleviate the problems associated with strength-based fitness. Section 4 studies the behavior and performance of the SS-LCS algorithm, as well as UCS, on three artificial learning tasks, specifically designed to challenge their scalability and generalization abilities, while Section 5 extends our experimental investigation to 26 real-world classification tasks. This work is concluded in Section 6 where we summarize our presented work, restate our contributions and conclusions, and identify future research directions towards a robust and effective classification tool based on SS-LCS. 2. Related work research on sequential decision problems, lately, the LCS commu-nity has shifted a significant part of its efforts towards single-step decision tasks, such as data mining. Actually, attempts to explore the potential of LCS for data mining date back to 1991 with the work of Bonelli and Parodi (1991) , who were the first to investigate the effectiveness of an LCS called NEWBOOLE on three medical classification domains. Holmes and colleagues successfully applied a modified version of NEWBOOLE ( Barry et al., 2004 ) to epidemio-logical databases, showing LCS potential in applications requiring adaptable models of risk. Starting in the late 1990s, and spurred by the introduction of the accuracy-based LCS named XCS by Wilson (1995) , more investigations appeared supporting the claim that
LCS could outperform traditional ML methods in various domains: mining breast cancer data ( Kharbat et al., 2007 ), direct marketing ( Greenyer, 2000 ), clinical research databases ( Holmes and Sager, 2005 ), protein structure prediction ( Bacardit et al., 2008 ), perso-nalizing desktop interfaces ( Shankar and Louis, 2010 ), and several other real-world classification tasks ( Bernado  X  -Mansilla and Garrell-Guiu, 2003 ; Bacardit and Butz, 2007 ; Orriols-Puig et al., 2009b ).
Although most of these investigations have used the reinforce-ment learning approach of XCS, an important  X  X  X eviation X  X  has been reported in the work of Bernado  X  -Mansilla and Garrell-Guiu (2003) who took a radical approach in dealing with the reinforce-ment component. Their  X  X  X Upervised Classifier System (UCS) X  X  ( Orriols-Puig and Bernado  X  -Mansilla, 2008a , 2008c ; Orriols-Puig, 2008 ; Orriols-Puig et al., 2009b ) is an extension of XCS, specifi-cally designed for classification and DM problems. UCS does not employ temporal difference learning for updating classifiers X  accuracies, but rather directly estimates them by using the classifiers X  actual true positive rates.

Exactly because of this supervised approach to the fitness update component, UCS features another important difference compared to XCS: it evolves a BAM instead of a CAM. In DM terms, a BAM contains only the consistently correct rules , i.e., the rules that predict the correct class for every instance they cover, while a CAM includes all consistently accurate rules , regardless of their providing correct predictions or not. Therefore, a CAM includes not only all consistently correct rules, but also all the consistently incorrect rules that predict the wrong class for every instance they cover.
Given the nature of single-step classification problems, though, it is obvious that only consistently correct rules are actually useful and necessary to produce an effective knowledge representation of the task to be learned. Indeed, the very definition of a BAM, points to solutions that are smaller than their corresponding CAMs, for any given classification problem. These observations raise some important questions concerning the advantages of evolving CAMs over BAMs, in terms of the effectiveness, compactness and induc-tion complexity of the resulting models.

More specifically, it is straightf orward that the evolution of a CAM requires greater exploration of the search space, as it also includes regions that are not important for the target classification task, i.e., the regions of the search space wher e consistently incorrect rules reside. This may become severely problematic as the size of the search space increases, that i s exactly the case in real-world applications with high-dimensionality and/or large numbers of classes. However, as Kovacs (2000a) points out, there may also be advantages in keeping track of incorrect rules in a CAM. The existence of such rules may (i) deter the system from re-inventing them, thus improving its exploration process, and (ii) enhance exploit performance by serving as a list of decisions that are harmful, and thus not to be chosen by the system, in certain situations.
Regarding the issues of compactness and evolution complex-ity, the decisive factor is the size of a CAM, which may be up to n times larger than that of a BAM for a classification problem with n classes. Thus, a BAM not only contains a smaller number of rules, but it also requires smaller population sizes and less computa-tional resources to evolve ( Kovacs, 2000a ). Moreover, given the fact that the covering map size has been identified as a factor of complexity for LCS ( Kovacs and Kerber, 2001 ), the evolution of
CAMs may also require more learning iterations and, thus, longer training times.

A final aspect of interest in early literature on the debate between best and complete action maps was the poor generalization of BAM learners  X  traditionally belonging to the strength-based family of LCS and the resulting de gradation of system performance by strong overgeneral  X  X  X uessers X  X  that proliferate in the rule popula-tion. However, it is now recognized that the degree of generalization ability of an LCS is actually dependent on the learner and not the knowledge representation it evolves. 1 A representative example is UCS, which despite being an accuracy-based LCS evolving BAMs, has been proved capable of effective generalization over the search space of correct rulesets ( Bernado  X  -Mansilla and Garrell-Guiu, 2003 ).
Although a more comprehensive discussion of these issues 2 beyond the scope of this paper, an important conclusion may be drawn from the brief comparative analysis of best and complete action maps presented above. In the domain of single-step classification tasks, and given their unique characteristics and requirements, there is both theoretical and empirical evidence that supervised LCS evolving BAMs are an efficient alternative  X  in terms of predictive accuracy, generalization abilities and training times  X  to XCS-like CAM learners.

The above conclusion serves as the motivation for our current work that proposes an alternative to traditional fitness calculation approaches in strength-based LCS, aiming at providing an efficient strength-based learner that  X  X  X aturally X  X  evolves BAMs. Subse-quent sections seek to validate the effectiveness, in terms of generalization and predictive abilities, of the proposed algorithm through (i) a comprehensive discussion of its properties, and (ii) an extended experimental comparison with an accuracy-based counterpart, that is the state-of-the-art UCS learner. 3. The strength-based supervised learning classifier system (SS-LCS) The following is a high level description of the proposed SS-LCS algorithm X  X  learning framework, focusing on the components comprising its execution cycle.

Rule representation . SS-LCS employs a population P of gradually evolving, cooperative classifiers, each encoding a fraction of the problem domain and, thus, collectively forming the overall solu-tion to the target problem. Rules (classifiers) in SS-LCS are represented in the traditional production form of  X  X  X F condition THEN action  X  X  3 and are encoded over the ternary alphabet {0, 1, #}. The symbol # (usually referred to as a  X  X  wildcard  X  X  or a  X  X  do not care  X  X ) allows for generalization in the rule condition part, such that both inputs 11 and 10 are matched by the rule-condition 1#. No generalization occurs in the action part  X  actions are discrete and represented as integer-values.
 Associated with each classifier, there are a number of parameters:
The numerosity num of a classifier that is the number of its copies, usually termed microclassifiers, present in the ruleset;
The niche set size ns that estimates the average size of the correct sets the classifier has participated in;
Thetimestamp ts that stores the time step of the last occurrence of a genetic event in a correct set the classifier has belonged to;
The experience msa of the classifier, that is its number of match set appearances;
The number of the classifier X  X  correct ( tp ) and incorrect decisions ( fp );
A scalar strength value str that estimates the classifier X  X  average reward received per step; and
The fitness F that is based on strength and is a measure of the classifier X  X  (relative) quality or its usefulness in the final solution.

At each discrete time-step t during learning, SS-LCS receives a binary encoded instance vector V t along with its associated class c ( V t -c t ) and follows a cycle of performance , update and discovery component activation, which is presented in algorithmic form in Algorithm 1 and described in more detail in subsequent sections.

Algorithm 1. SS-LCS component activation cycle (at step t ) during training. Fitness calculation details will be provided in Section 3.1 .

RUN TRAINING CYCLE () 1: V t  X  read next data instance 2: initialize empty sets M , C , and ! C 3:  X  X  X  X  X  X  X  X  X  X  X  X START PERFORMANCE COMPONENT] 4: M  X  generate match set out of P using V t 5: if ( M is not empty) then 6: a  X  choose decision out of M 7: C  X  generate correct set out of M using class  X  V t  X  8: ! C  X  M C 9:  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X START UPDATE COMPONENT] 10: for each classifier cl in Cdo 11: cl : ns  X   X  cl : ns cl : msa  X  P cl A C cl : num  X  =  X  cl : msa  X  1  X  12: end for 13: for each classifier cl in Mdo 14: cl : msa  X  cl : msa  X  1 15: UPDATE FITNESS of cl considering C 16: end for 17:  X  X  X  X  X START SEARCH COMPONENT (GA-BASED)] 18: if  X  t  X  P cl A C  X  cl : ts cl : num  X  = P cl A C cl : num  X  4 y 19: for each classifier cl in Cdo 20: cl : ts  X  t 21: end for 22: f cl 1 , cl 2 g  X  apply GA on C 23: insert cl 1 and cl 2 into the population P 24: DELETE RULE FROM POPULATION P 25: end if 26: end if 27:  X  X  X  X  X  X  X  X  X  X  X  X  X ACTIVATE COVERING COMPONENT] 28: if M is empty OR C is empty OR ( a a class  X  V t  X  ) then 29: a n  X  class  X  V t  X  30: cl n  X  generate covering classifier based on V t and a 31: insert cl n into the population P 32: DELETE RULE FROM POPULATION P 33: end if
DELETE RULE FROM POPULATION P 1: while P cl A P cl : num 4 N do 2: cl d  X  choose rule to be deleted out of P 3: remove cl d from the population P 4: end while
Performance component . Upon receipt of a data instance V the system scans the current population of classifiers for those whose condition part matches the input and forms the matching set M . Next, the correct set C is formed, containing all members of
M advocating the correct action c t , while the rest of the classifiers in M  X  the ones predicting classes other than c t  X  are placed in the incorrect set ! C . Finally, an action (classification decision) a is selected among those advocated by rules in M . Depending on the employed inference strategy, action selection may be determinis-tic , with the action advocated by the fittest classifier being selected, or based on a (possibly fitness-proportional) voting process among the classifiers advocating it in M .
 of a data instance is associated with an update of the matching classifiers X  parameters. More specifically: (i) for all classifiers in M , their msa is increased by one; (ii) for all classifiers in C , their ns is updated as the arithmetic average of the sizes of all correct sets they have participated in so far; and (iii) all classifiers in M have their fitness F updated, such that classifiers in C get their fitness values increased, while the ones in ! C decreased. The specifics of the latter update procedure are detailed later on, in Section 3.1 .
 mechanisms: (i) a steady-state niche genetic algorithm and (ii) a covering operator .
 invoked at a rate y GA , approximating the intervals needed for classifier fitnessestosettletostead y-state values. Thus, y GA is defined as a (minimum) threshold on the average time since the last GA invoca-tion of the classifiers in C . The evolutionary process employs parent selection based on tournaments of size t s  X  r 9 C 9 ,with r parent classifiers, selected based o n their fitness, are copied to form two offspring after crossover and mutation operators have been applied to them with probabilities w and m , respectively. checked for subsumption against each of their parents. If either of the parents is sufficiently experienced, precise and more general than the offspring, the latter is not introduced into the population, but the parent X  X  numerosity num is increased by one instead.
If the offspring are not subsumed by either of their parents, they are introduced into the population and deletion is applied, if necessary, in order to maintain a constant population size (at the microclassifier level).
 enough, it is essential that we define  X  X  precision  X  X  in the SS-LCS framework: a classifier cl in SS-LCS is considered precise if its true positive rate ( tp cl = msa cl ) is greater than a threshold value tpr min A  X  0 , 1 , with the actual value of tpr min being usually set close to 1. That is, given our supervised approach, precision is defined in DM terms and is independent of classifier fitness. reported in Kovacs (1999) and tries to even the sizes of the correct sets, by determining a classifiers probability of deletion based on its correct set size estimate ns . Deletion also takes into account the fact that SS-LCS does not assume positive-only or normalized fitness values and, thus, unlike parent selection, is applied on the whole population based on tournaments of size t .

The deletion probability of a classifier is proportional to the average size of the correct sets ns it has participated in and inversely proportional to its micro-fitness, 4 provided that the classifier is sufficiently experienced  X  msa 4 y del  X  , thus protecting newly created classifiers. Given that the system maintains a record of the number of classifier matches per iteration through the dataset, considerably higher deletion probabilities are assigned to classifiers not matching any instances in the training dataset.

M is empty, (ii) the decision produced by the system (based on a non-empty match set M and the employed inference strategy) is incorrect, or (iii) the correct set C is empty. Covering creates a new classifier with an action part equal to the current input X  X  class c t and a condition part matching V t and generalized by inserting # symbols with a given probability P # . Deletion is applied, again, if necessary, to conserve the population size constant after the insertion of the newly created classifier. 3.1. Fitness calculation in SS-LCS: strength-based fitness revisited
This section aims to provide a set of extensions to the traditional strength-based framework that target the problems identified for this class of systems, such as poor generalization ability and the proliferation of strong overgenerals. In this direc-tion, we define our modified strength-based approach to fitness calculation, starting with the simple strength-based LCS frame-work with reward sharing  X  similar to the one defined in NEW-
BOOLE ( Bonelli et al., 1990 ). The strength str cl of classifier cl is updated upon successful classification, according to str cl  X  str where R is the reward apportioned to the system for correctly of the correct set C the classifier has participated in at step t .
A classifier X  X  strength is also updated in case of a misclassifica-tion according to str cl  X  str where ns  X  t  X  cl is the classifier X  X  average correct set size at step t .
Thus, Eq. (2) defines that a classifier X  X  strength upon a misclassi-fication is decreased by p times  X  p Z 1  X  the average (positive) reward it has received so far.

Our next extension is central to the way the SS-LCS algorithm works and concerns the way fitness is calculated from a classi-fier X  X  strength. Our approach resembles the one used in ZCS ( Wilson, 1994 ), in that it tries to estimate the average reward (positive or negative  X  see Eq. (2) ) the classifier has  X  X  X rought X  X  to the system so far per step . Instead of learning this value via a temporal difference approach, though, SS-LCS directly estimates it by calculating the reward rate per step , i.e., by dividing a classifier X  X  strength by its experience msa . Thus, the fitness F  X  t  X  cl of a classifier cl at any given timestep t is calculated according to
F cl  X  num
Notice that Eq. (3) also factors in classifier numerosities ( num which is essential for the reward sharing scheme to effectively distribute reward at the microclassifier level.

Combining Eqs. (1) X (3) , for a classifier with tp cl correct classifications and fp cl misclassifications so far, its fitness F T appearances in match sets may be written as
F where ns cl approximates the size of the correct sets the classifier has been part of so far, T  X  tp cl  X  fp cl is the number of updates of the classifier X  X  parameters, i.e., its number of match set appear-ances msa cl , and num cl is the classifier X  X  numerosity.
The above approximation, of course, presupposes that R = ns effectively estimates the actual reward a classifier has received so far. In practice, given that ns cl is an arithmetic average, R = ns underestimates the actual reward after small correct sets and overestimates it after large ones. Assuming a uniform distribution of these cases and taking into account the deletion pressure towards equally sized correct sets (that decreases the width of this fluctuation), ns cl may be considered an accurate enough estimation on average to allow for a safe use of Eq. (4) in the following discussion. We will return to this issue though, when-ever it is of importance for our arguments and/or examples. Algorithm 2. Fitness calculation component for the SS-LCS algorithm.

UPDATE FITNESS ( cl , C ) 1: if  X  cl A C  X  then 2: cl : tp  X  cl : tp  X  1 3: cl : str  X  cl : str  X  X  R =  X  P cl A C cl : num  X  X  4: else 5: cl : fp  X  cl : fp  X  1 6: cl : str  X  cl : str p  X  R = cl : ns  X  7: end if 8: cl : F  X  cl : num  X  cl : str = cl : msa  X 
To sum up, the fitness update procedure outlined above (that corresponds to the UPDATE FITNESS function in Algorithm 1 )is presented in Algorithm 2 . Therein, strength str is updated each time a classifier belongs to a match set. It is increased upon successful classification by a fraction of the reward R associated with correct decisions (line 3), or, otherwise, decreased by p times the average positive reward the classifier has received so far. The resulting strength str is divided by the classifier X  X  number of matches msa to provide its final fitness value F , after multi-plication by its numerosity num (line 8).

Having defined our proposed approach to fitness calculation, we are ready to discuss two important problems traditionally associated with strength-based fitness and the way SS-LCS circumvents them.

The problem of strong overgenerals . An important problem of strength-based LCS, already identified by Wilson (1995) , is the proliferation of strong overgenerals , stating that under the simple strength-based framework, the system is not able to distinguish between accurate classifiers with moderate payoff and overly general ones having the same payoff on average ( Kovacs, 2000b ). The interaction occurs when an overgeneral rule acts correctly in a high reward state and incorrectly in a low reward state. In the case of SS-LCS, such an over general rule will hopefully not prosper, given (i) the niche-GA that restricts reproductive com-petition to members of the current correct sets only and (ii) the population-level deletion mechanism that tries to even the sizes of the correct sets. However, the high reward the overgeneral rule receives when it is correct may cause it to outweigh an accurate classifier during action selection. This problem is illustrated by the following simple example.

Consider two classifiers cl 1 -a and cl 2 -b , predicting classes a and b respectively. Classifier cl 1 is perfectly accurate, that is, it is always correct when it matches, while cl 2 correctly covers several instances of class b , but also wrongly covers some instances of class a , such that fp cl action selection, at least one of cl 2  X  X  false positives must be a true positive for cl 1 .

Let us examine the simplest case, where there is exactly one instance of this kind. The first time the classifiers compete for action selection over this instance, the worst-case scenario for cl 1 is that both classifiers have had only correct classifications so far and tp cl possible that cl 2  X  X  fitness is larger than that of cl 1 average been part of smaller correct sets  X  ns cl 2 o ns cl F
As soon as our instance of interest (whose class is correctly predicted by cl 1 ,butnot cl 2 ) comes along, though , the classifiers X  fitnesses will be updated, based on the current correct set C
F
F
Thus, as soon as the first false positive of an overgeneral rule comes along, the system will always be able to distinguish it from its accurate competitors for action selection. The precision of this argument, of course, depends on the quality of the estimation that
R = ns cl (when used in the case of misclassifications) provides for the actual reward a classifier has receive d so far. Given our assumptions, though, for a relatively small fluctuation of the correct set values, due to deletion pressure, and a uniform distribution of extreme cases (very large and very small correct sets), we hypothesize that ns will be a sufficiently accurate estimation on average to prevent strong overgenerals from harming system performance. This hypothesis is, in fact, later validated in practice by the results of the experimental part of our investigation ( Section 4 ).
Pressure towards accu rate generalizations . Another problem, tradi-tionally associated with strength-based fitness, that we need to address is the lack of explicit pressure toward accurate general-izations. This is related to Wilson  X  s Generalization Hypothesis ( Wilson, 1995 ), according to which an accuracy-based fitness calculation regime interacts with the niche-GA to produce an evolutionary pressure toward accurate and maximally general classifiers. This process eventually yields niches of the  X  X  X earch space X  X  represented by a minimal number of rules, with th eruleconditionsrepresentinga minimal number of concepts, but it has one important requirement in order to effectively operate in our e xtended strength-based approach: given a precise ( tp cl that is a generalization of cl 1 , 5 larger fitness values should only be steered towards cl 2 (compared to cl 1 ) if it also complies to the system X  X  precision criterion. We will use the following simple example to illustrate that this requirement is met by SS-LCS.
Consider the two classifiers cl 1 and cl 2 mentioned above, with cl being a generalization of cl 1 . Without loss of generality, we may assume that, initially, num cl 1  X  num cl 2 . Whenever cl the same correct set, their strengt h values will be increased by the same amount R = 9 C 9 . However, because cl 2 is a generalization of cl will tend to be part of more correct sets than cl 1 and will, thus, have more reproductive opportunitie s under the niche-GA employed.
Consequently, the number of copies of cl 2 will also tend to grow with respect to those of cl 1 ,or,inotherwords,theratiobetween cl and cl 1  X  X  numerosities will increas e. As a result, the next time cl cl occur in the same correct set, alth ough they will still receive the fraction, as F is proportional to a classifier X  X  numerosity. This will in turn produce through the GA yet more copies of cl 2 relative to cl until eventually cl 2 will displace cl 1 from the population.
This pressure towards generalization exists as long as cl cl are perfectly precise, but might, and perhaps should, be lost if cl loses strength in between its two  X  X  X eetings X  X  with cl 1 . The point at which the system should stop treating the two classifiers as equals during reward apportionment should be ideally con-trolled by the precision threshold tpr min . This, though, requires a reward/fitness sharing scheme that takes into account individual precisions and favors classifiers that comply to the system X  X  precision criterion, similar to the schemes employed in XCS ( Butz and Wilson, 2001 ) and UCS ( Orriols-Puig and Bernado  X  -Mansilla, 2008c ) based on accuracy. Although our study of the SS-
LCS algorithm has proven that, in practice, generalization is effective even without this modification, we consider its imple-mentation and analysis as a future step of great importance. 4. Learning performance of SS-LCS in artificial classification domains 2009a ) to allow for a facet-wise analysis of the studied algorithms and advance the understanding of their working process, with the ultimate goal of designing competent and efficient complex systems.
Although a detailed design decomposition of SS-LCS is beyond the scope of this paper, we followed the approach of analyzing system performance on artificial problems before applying them to real-world tasks. This approach has allowed us to both gain some insight on the SS-LCS algorithm and trace its differences with respect to
UCS, given simple test problems that highlight the difficulties inherent in corresponding real-world problems. 4.1. Experimental setup tion tasks, we begin our analysis with three artificial problems with binary attributes that we consider representative of a wide class of problems from our target real-world domain. The three chosen artificial problems, named parity , decoder and position respectively, are consistent with the characteristics of interest in the targeted domain: parity is a binary class problem, while the last two are multi-class problems, one with a uniform ( decoder ) and the other with a skewed class distribution ( position ). In all cases, we gradually scale the number of classes and, when applicable, the maximum imbalance ratio (i.e., the ratio between the dataset X  X  prevalent and minority class X  number of instances, denoted 9 TIc maj 9 and 9 TIc min 9 respectively), thus defining a collec-tion of problems of increasing difficulty.
 fication and pattern recognition literature as a performance metric, it is of little use in the case of our artificial problems. This is due to the fact that in all reported experiments, all algorithms achieve close to 100% prediction accuracy. Thus , in an effort to quantify the relative performance of the studied algorithms, the percentage of the optimal population achieved was selected for use throughout this
Section as an appropriate performance metric, indicative of the progress of genetic search ( Kovacs and Kerber, 2004 ). Given that in our case, both studied algorithms evolve BAMs, the employed performance metric coincides with the percentage of the best action map %  X  B covered at any point during training, which is monitored for all algorithms at 10-step intervals. As an additional comparison feature, partly indicative of the generalization ability of a system, we also report the number of rules evolved by each algorithm at the end of the training phase. For both metrics ( %  X  B and number of rules), all presented results are averaged over 10 runs (per problem and algorithm) with different random seeds.
 described in Orriols-Puig (2008)  X  we used our own implementations codified in Java 6 and kept the majority of parameter settings fixed for all problems. The only parameter varied was the GA invocation rate y
GA . It was empirically set according to the configuration guidelines, derived in Orriols-Puig et al. (2007) and Orriols-Puig and Bernado  X  -
Mansilla (2008b) for XCS and later shown to be extensible to supervised LCS, for the imbalance bound to be satisfied y
GA  X  k ir  X  8  X  is an arbitrary constant, defining the number of updates of a classifier belonging to a starved niche before it receives a genetic event.
According to Eq. (8) we, thus, set (i) y GA  X  20 for the parity and decoder problems and (ii) y GA  X  max f 20 , 2 ir g for the position problems.

The population size N was set to 25 9  X  B 9 (where 9  X  B 9 of the BAM per problem), while for the rest of the parameters a typical setup, consistent with thos e reported in the literature, was used: w  X  0 : 8, m  X  0 : 04, P #  X  0 : 33, y sub  X  20, y del  X  0 : 25 9 P 9 , n  X  10, tpr min  X  1 10 4 , p  X  10, and R  X  1. Para-meters for UCS had the same values, while additionally: acc 0  X  0 : 999 and b  X  0 : 2. The learning process lasted 100,000 iterations for all sets of problems, i.e. the system was allowed 100,000 cycles of performance, update and discovery component activation, before arriving to the final ruleset to be used for testing. 4.2. The parity binary class problem The first problem, denoted as parity -l , is defined as follows.
Given a binary input string x of length l , the class label parity  X  x  X  is 1 if the number of ones in the input is odd and 0 otherwise. Thus, given input instances of length l , there are always only two possible classes and the required BAM to solve the problem consists of exactly 2 l rules with no generalization ( Table 1 ).
Experiments with the parity function were performed on a series of problems ranging from 3 to 9 input bits and, thus, scaling the size of the BAM from 8 to 512 rules, respectively. Fig. 2 a X  X  depict the results obtained for all algorithms, in terms of the percentage of the BAM (%[B]) achieved throughout the learning process, with the curves being averaged over 10 runs. For the same 10 runs, Table 2 (a) reports the time required to reach 100%[B], that is the earlier iteration for which the full BAM was present in the ruleset of all 10 runs ,while Fig. 1 reports the average number of rules evolved at the end of the learning process.

It is evident that, although both algorithms present similar convergence speed for the first five problems ( parity -[3 X 7]), SS-
LCS appears to scale better to the parity -8 and parity -9 cases. In terms of the time required to obtain the full solution, SS-LCS and
UCS perform equivalently in the smaller-scale problems ( parity -[3 X 7]), while SS-LCS manages to reach 100%[B] in almost half the time (learning iterations) required by UCS in parity -8. In the parity -9 problem, while no algorithm manages to reach 100%[B] in all 10 runs, SS-LCS reaches 98.05%[B], that is the average value achieved by UCS at the end of learning, at 72,400 steps.
Regarding the statistical significance of the observed perfor-mance differences, the application of the Wilcoxon signed-ranks test ( Wilcoxon, 1945 ) on the full data used to produce the curves in Fig. 2 a X  X  reveals that, at a  X  0 : 05, SS-LCS performs significantly better than UCS on all test problems. Thus, when considering performance during the whole training phase , and not just the time to discover the full solution, SS-LCS is the top performing algo-rithm for all problems.

Overall, given the relatively high variance observed in these problems, one may consider both algorithms equivalent in terms of performance, but notice that UCS consistently results in larger models, producing on average 30% more rules than SS-LCS. 4.3. The decoder multi-class problem
The problem, denoted as decoder -l , consists of the n -ary encoding of a binary string of length l decoder  X  x  X  X  where x i is the i th input bit (starting from the leftmost bit) and decoder  X  x  X  is the corresponding class. Given input instances of length l , the number of possible classes is 2 l and the required BAM to solve the problem consists of exactly 2 l rules with no general-ization ( Table 3 ).

Experiments with the decoder function were performed on a series of problems ranging from 3 to 9 input bits and, thus, scaling the number of classes from 8 to 512 respectively. Fig. 2 c X  X  depict the results obtained for all algorithm s, in terms of the percentage of the
BAM (%[B]) achieved throughout the learning process, with the curves being averaged over 10 runs. Table 2 (b) reports the time required to reach 100%[B] (for the same 10 runs), while Fig. 3 reports the average number of rules evolved at the end of the learning process.
It is evident that, although the evolved number of rules is almost the same for both algorithms (differences are less than 20%) regardless of the size of the problem, SS-LCS achieves faster convergence rates and appears to scale better than UCS with the number of classes: as the number of classes increases, SS-LCS manages to reach the full solution (100%[B]) in up to half the time (learning iterations) required by UCS.

Regarding the statistical significance of the observed perfor-mance differences, the application of the Wilcoxon signed-ranks test on the full data used to produce the curves in Fig. 2 c X  X  reveals that, at a  X  0 : 05, SS-LCS performs significantly better than UCS on all test problems. Thus, SS-LCS is the best performing algorithm for all studied problems, also when the full learning curves are taken into account, allowing us to conclude that its superior overall performance is not only due to its steeper convergence in the beginning of the learning process. This might indicate the presence of a trait in the strength-based fitness calculation component that favors a more  X  X  X onsistent X  X  evolution of the BAM by SS-LCS. In order to analyze this observation, it is useful to go back to the definition of the problem  X  according to which all rules in the best action map contain no generalizations  X  and examine it in relation to an issue associated with the evolution of classifiers that is especially relevant in this kind of problem.

Classifiers in LCS can be evolved from two sides ( Butz et al., 2001 ): (i) from overspecificity towards maximal generality (explained by  X  X  X ilson X  X  generalization hypothesis X  X ) and (ii) from overgenerality towards maximal specificity. The second kind of evolution, which is especially relevant in the decoder problem, is mainly attributed to the presence of effective fitness pressure towards accurate classifiers and presupposes that the application of the GA results in pressure towards high fitness classifiers regardless of their generality ( Butz et al., 2004 ).

Specifically in the decoder problem, a classifier cl with g generalizations ( g  X  X  X o not care X  X  bits) matches 2 g instances and predicts the correct class for only one of them. Thus, its true positive rate tpr cl is 1 = 2 g . As we move from the overgeneral side towards the desired level of specificity (no generalizations), every specification in a classifier X  X  condition part results in its coverage being decreased by 50% and its tpr being doubled. This has a different effect on a classifier X  X  fitness in SS-LCS and in UCS, as fitness is dependent on strength and accuracy, respectively, with str cl  X  l  X  1 p  X  2 g 1  X  X  R ns acc cl  X  X  1 = 2 g  X  n  X  10  X  allows for a closer examination of the behavior of the two fitness functions in the decoder problem. Moving along the x -axis from left to right, tpr increases (actually it doubles) with every specification step towards the optimal rule. In both cases, fitness also increases while moving from the overgeneral side towards maximal specificity and, thus, fitness pressure towards accuracy is present and effective.
However, comparing the two plots, one may easily observe that the slope of the curve is steeper, and thus fitness pressure is stronger, in the case of SS-LCS when more specifications are required (first half of the graph), while the opposite is true for the second half of the graph. This explains why SS-LCS achieves a faster convergence rate than UCS as l  X  and thus the number of possible generalizations  X  increases.

Overall, both studied supervised LCS appear well suited for the decoder problem, which as already observed in Bernado  X  -Mansilla and Garrell-Guiu (2003) , can serve as an artificial representation of real-world classification problems where there is a contrary-to-accuracy fitness landscape for CAM learners (like XCS). Such landscapes, where overgeneral classifiers lack any fitness gui-dance towards accuracy, may emerge in classification tasks with large number of classes or with unequal proportions of examples per class. In such cases, SS-LCS may prove a preferable solution than its accuracy-based, CAM or BAM learning, rivals. 4.4. The position unbalanced multi-class problem
Our third problem, denoted as position -l , involves multiple classes and different distributions of examples per class, thus enabling the study of supervised LCS performance when rules with various levels of generality are required to form an effective solution. In other words, the series of position-l problems will serve as a test bed for analyzing the generalization abilities of the studied algorithms, while comparing the effect of the two distinct fitness calculation regimes therein.

The definition of the problem states that for a binary string of length l , its class corresponds to the position of the leftmost bit with value one. If there is no bit with the value one in the input string, then the output class is zero ( Table 4 ).

From the definition of the problem, we may infer that given input instances of length l , the number of possible classes is l  X  1 and the required BAM to solve the problem consists of exactly l  X  1 rules, that is one per available class, with various degrees of generalization  X  however, the BAM also includes two rules with no generalization. Regarding the coverage of the rules, it is worth noting that the most general rule covers half the instances, while the two most specific rules cover only one example each.
Experiments with the position function were performed on a series of problems ranging from 3 to 9 input bits, thus scaling the number of classes from 4 to 10 and the imbalance ratios from 4 to 256 respectively. Fig. 2 e X  X  depict the results obtained for all algorithms, in terms of the percentage of the BAM (%[B]) achieved throughout the learning process, with the curves being averaged over 10 runs. Table 2 (c) reports the time required to reach 100%[B] (for the same 10 runs), while Fig. 5 reports the average number of rules evolved at the end of the learning process. Based on these results, one may easily observe that both algorithms are able to discover the full BAM (achieve 100%[B]) in all cases, while they also evolve rulesets of comparable sizes. However, SS-LCS appears to consistently achieve faster convergence towards the full solution than its rival, especially in the higher complexity problems.
In general, since both algorithms achieve the optimal popula-tion in all cases, it can be argued that they scale well with the number of classes. Moreover, both their generalization mechan-isms (which are structurally similar, with the fitness calculation process being the important difference between the two) effi-ciently explore the search space of BAM rules, regardless of the magnitude of the imbalance ratio.

However, the application of the Wilcoxon signed-ranks test on the full data used to produce the curves in Fig. 2 e X  X  leads to some interesting conclusions. The test reveals that, at a  X  0 : 05, SS-LCS performs better than UCS on all test problems. Thus, SS-LCS is not only the best performing algorithm when the time to reach the full solution is taken into account, but it also achieves the best overall learning performance in all studied problems.

A closer examination of the learning curves (especially in the position -8 and position -9 problems) allows us to make some addi-tional observations regarding the evolution of the BAM. More specifically, Fig. 2 e X  X  reveal that all algorithms learn fast during the first iterations (i.e., achieving 90%[B] in less than 30,000 explore trials), but after that the learn ing curves improve slowly. This suggests that, although the algorit hms demonstrate effective con-vergence, they also encounter difficulties in obtaining (at least) one rule of the BAM. In order to determine this  X  X  X ard to get X  X  rule, we analyzed the corresponding evolved rulesets and traced the times during training when the vario us BAM rules are first created. during learning  X  when the system does not choose the correct decision  X  for the SS-LCS algorithm specifically.
 To sum up, our analysis of the results obtained for SS-LCS and
UCS in the position problems shows that, when facing problems that require the evolution of rules of various generality levels: (i)
SS-LCS scales better with problem size (and thus complexity) than its rival, achieving both the best overall learning performance and the shortest time to discover the full solution for all studied problems; and (ii) both learners evolve comparable rulesets, in terms of their size, wherein the BAM rules are clearly prevalent.
These conclusions provide evidence of the competitiveness of not only the supervised LCS framework in general, but also the
SS-LCS algorithm specifically: our extended strength-based approach is proved, in practice, to not suffer from the poor generalization abilities usually attributed to strength-based LCS, even in the presence of severe class imbalances. 5. Experiments with real-world classification problems
So far, our analysis has focused on artificial problems with known characteristics, designed specifically to get insight into the behavior of the algorithms under different constraints. In this
Section, we continue our investigation by applying both SS-LCS and UCS on a set of real-world problems (26 datasets), in order to test whether our conclusions can be extended to classification problems with unknown complexity factors and bounded achiev-able accuracy rates. Training various algorithms on a wide range of problems will allow us to better estimate problem complexity and, hopefully, identify the types of problems for which our proposed SS-LCS approach is better suited to. 5.1. Target problems and rival algorithms The benchmark datasets employed in this work are listed in
Table 5 and are all readily available from the UCI repository ( Asuncion and Newman, 2010 ), except for the web-activity dataset that was selected from a local repository ( Vavliakis et al., 2010 ).
A major factor for choosing the particular datasets was their affiliation with real-world domains (except for the led dataset which was artificially generated), but also their diverse characteristics. In an effort to study a wide range of problem categories and present the algorithms under comparison with a diverse challenge, we selected datasets that comprise a mixture of nominal and numeric attributes, a wide range of attribute numbers (4 X 69), classes (2 X  24) and imbalance ratios (1 X 84), several dataset sizes (101 X 8124 instances), some cases of missing values, and also a case of noisy data  X  the led dataset was generated with 10% added noise.
The performance metric used throughout Section 5 for algorithm comparisons is the accuracy rate (i.e., the percentage of correct classifications). All algorithms were evaluated using 10-fold stratified cross-validation that provides a decent estimation of a learning algorithm X  X  performance on a given problem and ensures relatively high replicability ( Bouckaert and Frank, 2004 ). In order to evaluate the statistical significance of the measured differences in algorithm ranks, we have used the procedure suggested by Dem  X  sar (2006) for robustly comparing classifiers acro ss multiple datasets. This proce-dure involves the use of the Friedman test ( Friedman, 1937 )to establish the significance of the differences between classifier ranks and, potentially, a post-hoc test t o compare classifiers to each other. In our case, the goal was two-fold, the first being to compare the performance of all algorithms to each other. Thus, the Nemenyi test ( Nemenyi, 1963 ) was selected as the appropriate post-hoc test. A second, more specific, goal was to compare the two studied LCS algorithms, in order to validate our i nitial hypothesis that, equipped with our extensions to the traditional strength-based LCS framework, SS-LCS can exhibit at least similar performance to that of the state-of-the-art UCS algorithm. For this purpose we used the Wilcoxon signed-ranks test ( Wilcoxon, 1945 ) to examine the statistical sig-nificance of the observed performance differences between the two supervised LCS learners and their rivals (all possible pairs).
The rival algorithms against which the two LCS algorithms are compared are: ZeroR, IBk, KStar, Naive Bayes, Logistic Regression, Multi-Layer Perceptron, SRAN, SMO, C4.5 and PART. ZeroR is included in this study to provide a baseline accuracy rate for algorithm comparisons, since it represents the performance of a minimally experienced c lassifier that always predicts the dataset X  X  prevalent class. IBk ( Aha et al., 1991 ) and KStar ( Cleary and Trigg, 1995 ) are instance-based classifiers that use the k  X  X  X losest X  X  points, or nearest neighbors, in the attribute s pace for performin g classification. ThedistancemetricusedistheEuclideandistanceforthecaseofIBk (where k was set to 3) and the entropy measure for KStar. Naive Bayes ( John and Langley, 1995 ) computes conditi onal probability distributions of future observabl es given already observed data and classifies instances based on the value of the class attribute that maximizes the posterior probabilit ycomputedusing Bayes X  theorem.
Logistic Regression refers to a mul tinomial implementation of the well-known algorithm. Mu lti-Layer Perceptrons ( Haykin, 1998 )con-sist of simple processing units (neur ons) massively interconnected to each other and are suitable for bot h, regression and classification tasks. Self-adaptive Resource Allocation Network (SRAN) is a sequen-tial learning algorithm that ide ntifies reduced training data sequences with significant informa tion (to avoid over-training) and produces compact networks using self-regulative control parameters ( Suresh et al., 2010 ). Support Vector Machine (SVM) classifiers ( Boser et al., 1992 ) were trained using the Sequential Minimal Optimization (SMO) algorithm ( Platt, 1999 ). We experimented with polynomial and radial basis function kernels and finally included only the former in the comparison, as the latter performed worse on average. C4.5 is the well-known decision tree induction algorithm developed by
Quinlan (1993) , which builds decision trees from a set of training data using the concept of Informa tion Entropy. Finally, PART ( Frank and Witten, 1998 ) generates a decision list, using the  X  X  X eparate-and-conquer X  X  approach: partial C4.5 decision trees are built in each iteration and the  X  X  X est X  X  leaf is made into a rule.

For all the above algorithms their WEKA implementations ( Witten and Frank, 2005 ) were used, with the exception of SRAN, for which a Matlab implementation was provided by the algo-rithm X  X  author. For all algorithms we employed a modest (grid-search based) tuning phase for selecting the optimum parameter set per problem. 5.2. Implementation issues and parameter setup Given that we have used our own implementations, codified in
Java, for both SS-LCS and UCS, there are number of additional issues that need to be further discussed.

Rule representation . Rules in SS-LCS, as well as in (our imple-mentation of) UCS, follow the traditional production system form of  X  X  X F conditions THEN action  X  X . Given the fact that both algorithms aim at classification tasks, the action part is simply a class label, from the class attribute X  X  set of possible values. On the other hand, the rule condition part consists of a conjunction of predicates that may take various forms, depending on the type of attributes (nominal or numeric) present in the training dataset.
More specifically, for a nominal attribute with possible values in the set X  X f V 1 , ... , V N g , the corresponding condition takes the form x A X sub , where X sub D X . For numeric attributes we employ the interval representation, according to which conditions are of the form y A  X  V low , V high , where V low and V high are real-valued.
Associated with each condition, there is an activation bit responsible for switching the condition on or off through genetic evolution or the built-in generalization process  X  during covering, the activation bit may be switched off, rendering the correspond-ing predicate always true, with probability P # .

Evolved ruleset use . The ruleset evolved by both studied LCS algorithms contains up to M r N classifiers, where N is the (user-defined) maximum allowed number of microclassifiers in the population during training. Despite the built-in subsumption and duplication processes, the final classifier population (but also the population at any point during the training process) may still contain identical classifiers, possibly due to the combined effects of the genetic and covering/generalization operators.

In order to use the final set of rules effectively, a preprocessing step is required, during which the system discards redundant classifiers, keeping only one copy of each rule in the population. The remaining classifiers X  numerosities, of course, are increased by the sum of the numerosities of their deleted copies and their fitness-related parameters are updated accordingly (i.e., set to the values corresponding to their most experienced pre-existing copy). Thereafter, the ruleset may be used as ordered ,with the strongest classifier matching a certain input imposing its decision, or in combination with a (possibly weighted) voting scheme . The former inference strategy was employed in all experi-ments throughout this Section for SS-LCS, while the voting scheme was employed for UCS, consistent with previous studies in the literature.
 (except for the datasets reported in Table 6 ) are: N  X  1000,
P #  X  0 : 33, w  X  0 : 8, m  X  0 : 04, y sub  X  y del  X  y GA , t d  X  0 : 25 9 P 9 , n  X  10, p  X  10, R  X  1, tpr min  X  1 10 0 : 999, b  X  0 : 2 and 100,000 learning iterations.

Table 6 , one can easily observe that most of the available (tunable) parameters were kept constant, while for only a small subset, a modest tuning process was employed. This exploration was mainly guided by the dataset X  X  imbalance ratio and involved tuning the allowed number of microclassifiers ( N ) and the GA invocation rate  X  y GA  X  . The y GA value was approximately selected according to the bound defined by Eq. (8) , while N was configured according to the bound for the minimum population required to guarantee a sufficient initial supply of rules N  X  O  X  n  X  1  X  ir  X  (derived in Orriols-Puig et al., 2007 ) where n is the number of classes and ir is the imbalance ratio of the dataset.
 available (to our knowledge and at the time of running the reported experiments) is the one provided by the ML tool KEEL ( Alcala  X  -Fdez et al., 2009 ). However, given that it is not clear from the KEEL documentation which version of the algorithm is actually implemented, we decided against using this version of
UCS and opted for our own implementation of the algorithm. This implementation is based on the description provided in Orriols-
Puig (2008) and, thus, includes fitness sharing and factors in rule numerosities during fitness calculation. It does not include the  X  X  X n-line adaptation algorithm X  X  described in Orriols-Puig and
Bernado  X  -Mansilla (2008a) , but uses the bounds derived therein to tune the y GA parameter externally. Finally, as already men-tioned, the same rule representation, though different from the one described in Orriols-Puig (2008) , is shared among both studied algorithms. It is worth noting that our UCS implementa-tion achieves results comparable to (and often better than) already published ones on both the artificial and real-world problems used in this study. Thus, we believe that we do not introduce any bias towards the SS-LCS algorithm by employing our own, slightly modified, version of UCS. 5.3. Comparative analysis of results in this study on all target datasets. Along with the accuracy rate, we also report the corresponding algorithm ranks per dataset (superscript next to the accuracy rate), each algorithm X  X  overall average rank (row labeled  X  X  X ank X  X ), as well as its position in the final ranking ( X  X  X os X  X ).

Based on the measured accuracy results, the average rank provides a clear indication of the studied algorithms X  relative performance: a  X  X  X unction-based X  X  cl assifier, namely Logistic Regres-sion, dominates its rivals with an average rank of 4.90, while SS-LCS follows with a minimal difference in overall rank (5.00) and UCS ranks sixth. It is also worth noting that the studied LCS algorithms outrank their  X  X  X ule-based X  X  rivals (C4.5 and PART), achieving a better predictive accuracy on all but 8 test problems.

As far as the relative performance of the two LCS algorithms is concerned, one may easily observe that SS-LCS performs better than UCS in 15 out of the 26 datasets and worse in 7. The cases where SS-LCS outperforms UCS include 7 out of the 8 datasets zoo ), half of the most numerous datasets (datasets with more than 500 instances), 8 out of the 13 non-binary class datasets (datasets with 3 or more classes) and 10 out of the 16 datasets with more than 10 attributes, thus providing further proof that SS-LCS X  X  performance scales well with problem complexity, in terms of these factors.

From the above observations, particularly interesting is the fact that SS-LCS outperforms UCS in the vast majority of datasets with severe imbalances ( ir 4 2). It is well known, though, that the accuracy rate is highly sensitive to skewed class distributions and often fails to quantify the actual error costs involved in corre-sponding real-world applications. Models hardly covering the minority class(es) may appear to perform better than models with balanced coverage of all classes, as all  X  X  X isses X  X  are con-sidered of equal importance ( He and Garcia, 2009 ). In order to determine whether this is the case with SS-LCS, and given that
AUC (Area Under Curve) is a commonly employed evaluation metric for imbalanced classification problems, we further report the corresponding values for our datasets of interest in Table 8 .The reported values correspond to the multi-class AUC (MAUC) as defined by Hand and Till (2001) . That is, they are calculated as the unweighted average of the areas under the precision X  X ecall curves of all possible class combinations per problem. Observing the reported results, one may easily infer that SS-LCS does not only induce models with greater predictive accuracy than that of UCS. It is also able to distinguish between classes effectively even under the presence of highly skewed distri butions, thus confirming our pre-vious findings on the artificial problems (See Section 4.4 ).
Regarding the statistical significance of the measured differ-ences in algorithm ranks, the use of the Friedman test rejects the null hypothesis (at a  X  0 : 01) that all algorithms perform equiva-lently, but the Nemenyi post-hoc test fails to detect any signifi-cant differences except between all algorithms and the  X  X  X aseline X  X 
ZeroR. The Wilcoxon signed-ranks test, though, is more powerful in pairwise comparisons and also allows us to compute the confidence level at which the difference between two algorithms may be considered significant. These confidence levels are reported for SS-LCS and UCS in the last two rows of Table 7 , unless smaller than 80%. A careful examination of the results allows us to conclude that SS-LCS performs better than 6 of its rivals, including UCS, at a level of confidence greater than 90%.
Overall, it is important to note that both LCS algorithms, which evolve rule-based models, perform comparably with the top-performing Log classifier  X  there is no statistically significant difference detected between Log and either of the studied LCS and clearly better than their rule-based rivals (C4.5 and PART).
More specifically, based the Wilcoxon signed-ranks test, SS-LCS outperforms all its rule-based rivals (including UCS) at a con-fidence level greater than 95%. We consider this fact a clear indication that SS-LCS may provide an effective alternative to classification tasks where description is just as important as prediction , or in domains where  X  X  X lack-box X  X  models (such as the ones provided by SMO) or  X  X  X omplex mathematical modes X  X  (Log) are not acceptable. A representative example of this class of problems is presented in Tzima et al. (2011) where Air Quality models that need to be explained to and validated by stake-holders are developed.

In the direction of investigating the  X  X  X escriptive X  X  abilities of LCS, and starting with the more specific goal of comparing the interpret-ability of models produced by di fferent kinds of learners, we performed an additional set of experiments, where only SS-LCS (which was found to be the best performing LCS algorithm in this study), C4.5 and PART were included . The purpose of this additional set of experiments was to compare the legibility of the knowledge representations evolved by the t hree candidates, in terms of the number of rules they induce, and thus, for the sake of simplicity, the  X  X  X valuate-on-training-set X  X  method was used for each of the 26 datasets in Table 5 . For SS-LCS we used exactly the same parameter setup as in the previous experiments (see Section 5.2 ), the  X  X  X ittest rule X  X  inference strategy and a sim ple post-processing step, where only the subset of rules necessary to fully cover the training set was retained in the final model. Table 9 summarizes the results of this set of experiments, reporting along with the number of rules produced per algorithm-dataset pair ( X  X  X R X  X ), also the classification accuracy achieved ( X  X %CC X  X ) in order to ensure that the model sizes are compared at comparable performance levels, in terms of predictive accuracy.

Inspecting the reported results, one may easily observe that there are 14 cases where SS-LCS produces fewer rules than both its rivals (marked by a sign in the  X  X  X esult X  X  column), 7 cases where SS-LCS produces more rules than both its rivals (marked by ) and 5 cases where it produces fewer rules than at least one of its rivals (4 less than C4.5 and 1 less than PART). The Friedman and Nemenyi tests on the reported results detect that both SS-LCS and PART significantly outperform C4.5 at a  X  0 : 05. Additionally, the application of the Wilcoxon signed-ranks test  X  for pairwise comparisons between SS-LCS and its rivals  X  reveals that
SS-LCS outperforms C4.5 at a 93.26% level of confidence, but fails to detect any statistically significant difference between SS-LCS and PART. Given that our approach hardly uses any ruleset reduction techniques and, more importantly, that it clearly outperforms its rule-based rivals in terms of prediction accuracy (see Table 7 ), we consider these results indicative of SS-LCS X  potential to evolve tractable, yet effective, models in supervised classification tasks.

Before closing our discussion, a final comment on execution times is in order. All rivals, and especially C4.5 and PART, are considerably faster than both LCS algorithms. While no explicit comparison of execution times is possible, as our implementa-tions cannot be in any case considered optimized, the time required to train the LCS models even for the larger datasets used in this study was manageable on a regular PC with a 3.2 GHz processor and 3 GBs of RAM: a 10-fold cross-validation run for the largest datasets used in this study took approximately 15 min to complete. 6. Conclusions and further work employed under a supervised learning framework. SS-LCS departs from the reinforcement learning approach to fitness calculation, traditionally used in LCS. It bases its fitness on straightforward
DM-based rule performance metrics, directly estimating a classi-fier X  X  payoff rate per step from its strength value. To alleviate the shortcomings traditionally associated with strength-based LCS,
SS-LCS is also equipped with appropriate extensions to the update component that allow it to present effective generalization abilities in single-step classification tasks.
 includes the well known UCS algorithm, whose competitiveness has already been proven in previous studies. Both algorithms are shown to efficiently evolve accurate generalizations of best action maps, with comparably fast learning convergence and equally legible rulesets  X  in terms of size. However, SS-LCS performs better than UCS in problems where the evolution of rules from the overgeneral side is of interest. The latter kind of evolution is especially relevant in real-world classification problems with large number of classes or unequal proportions of examples per class. problems, are also validated in real world classification tasks, thus revealing the potential of supervised LCS in general, and strength-based ones more specifically, as DM tools. In the corresponding experiments, SS-LCS X  X  overall performance is found comparable to that of well-known ML algorithms and clearly better than that of its rule-based or tree-inducing rivals, including UCS, especially in problems with severe class imbalances. An initial investigation of the  X  X  X escriptive X  X  abilities of SS-LCS reveals that it is capable of inducing, not only predictively accurate, but also highly inter-pretable knowledge representations.

Despite the encouraging results of our present study, several issues deserve further investigation, in order to obtain an efficient
DM tool for difficult classification tasks based on SS-LCS. A first step toward this direction is the improvement of the algorithm X  X  architecture by incorporating a  X  X  X recision-sensitive X  X  fitness shar-ing process. The design and implementation of a more in-depth exploration strategy for the algorithm parameters may also help clarify their effect on system performance. It is also essential to explore options to reduce the time required to produce models, as this is arguably a weak point of the LCS family of algorithms. We plan to pursue this goal from two directions: (i) by implementing a version of the algorithm that exploits its inherently parallel nature and (ii) by investigating ways to reduce the large number of rules maintained during the training process, which constitute a major source of time complexity issues for LCS.
 Acknowledgments
The authors would like to thank Prof. S. Suresh for providing the code for the SRAN algorithm, along with invaluable insights on tuning the algorithm X  X  paramete rs. The first author would like to acknowledge that this work was partially supported by the 03ED735 research project, implemented wi thin the framework of the  X  X  X ein-forcement Programme of Human Research Manpower X  X  (PENED) and cofinanced by National and Community Funds (25% from the Greek Ministry of Development-General Secretariat of Research and Tech-nology and 75% from E.U.-European Social Funding).
 References
