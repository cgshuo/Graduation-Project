 Toolbar navigation logs provide rich data for enhancing in-formation discovery on the Web. The value of this data resides in its scope, which goes beyond that of traditional query-mining data sources, such as search-engine logs. In this paper we present a methodology for extracting relevant association rules for queries, based on historic user naviga-tional data. In addition, we propose a graph-based approach for extracting related queries and URLs for a given query. H.3 [Information Storage and Retrieval] :H.3.3 Infor-mation Search and Retrieval.
 Web Data Mining, Toolbar Data, Association Rules.
Recently, research has started to focus on complex search tasks[5, 8] expressed by a series of queries submitted in a certain time window, which can span up to several months. Complex search tasks (or complex information needs) in-volve multiple aspects that can hardly be addressed in a single web page or search-result page. Subsequent queries issued to satisfy this kind of need are not mere reformula-tions of the initial query. Instead, they are meant to explor e diverse (although related) facets and aspects.
 Historically, a great deal of research has been devoted to information needs that can be satisfied by a single query. Most of the studies in this field aim at increasing the rele-vance of the information retrieved in return to a single quer y regarding a given topic or a task. Here it is important to note that relevance and relatedness are quite diverse con-cepts. To illustrate this point, let us consider the query  X  X ondos in North Beach X  (being North Beach a neighbor-hood in San Francisco). Then consider the two following web pages: www.homefinder.com/CA/San_Francisco/neighborhood/ North_Beach/property_type_condo_unit/ and www.psk12.com/ CountyID_38.html .Mostlikelyahumanassessorwouldjudge the first document (which is a list of condos for sale in North Beach) relevant to the query. On the other hand, the second document (a ranking of elementary schools in San Francisco county) would probably be judged as not directly relevant to the query. Nevertheless, public-school quality might be adeterminantfactorinthedecisiontomovetoaparticu-lar neighborhood. Hence, the second page is not relevant but actually related to the complex task of  X  X uying/renting condos in North Beach X .

Acomplexinformationneedisoftendenotedbytheterm mission [7]. In this context, the concept of logical session (or simply session )referstothesetof actions (queries and URL clicks) that a user performs to fulfill a particular re-search mission. It has been shown that aggregating logical sessions that correspond to closely related missions allow sto discover sets of diverse yet related actions. This type of re -search has been mostly performed on query-log data, whose information regarding the click activity of users is limite dto web pages included in the search-engine results.

In this work we aim at automatically extracting sets of related actions (and subtasks) that correspond to a same complex information need. Related subtasks might not be clear to the user at the beginning of the search activity but they are often discovered during the browsing activity. Bot h user browsing and searching activities are logged by toolba r applications installed in users X  browsers. Therefore, too l-bar logs have the potential to allow the discovery of diverse URLs and queries related to a complex information need. The added value provided by toolbar data to the informa-tion discovery task is that discovered URLs might not even be in the pool of visible results built by the search engine in response to a query.

To extract the actions related to a task, we devise a method-ology for discovering association rules in toolbar data. In addition, we create a graph representation and we develop amethodologyforextractinggroupsofrelatedactions.

Toolbar data and association rules have been previously used to enhance the set of relevant results for a query, or for query reformulation. Fonseca et al. [6] extract associatio n rules from a search-engine query log for query reformulatio n and query expansion. Bilenko et al. [1] is the work clos-est to ours in terms of tracking the browsing behavior after the user departs from the search engine and begins to fol-low an information thread through the Web. However, we believe that the two works above are not directly compa-rable to ours. Fonseca et al. use query-log data, while we analyze a richer dataset, which includes navigation action s and queries submitted to di ff erent search engines. Bilenko et al. consider every single query as the start of a new search trail, thus given a query, they only extract rules regarding the URLs visited after that query, loosing the relation with URLs visited in the same session as results of related querie s.
The main challenge of our work is to find sets of related items in toolbar data. We reformulate this problem as that of extracting sets of closely related actions for a given query q .Formally,wedefineasan action ,anyrequestgenerated by a user after issuing a query q .Theserequestsusually correspond to either a new query or a visit to a URL .This choice has the great advantage of allowing the study of fur-ther problems (e.g., CTR increase or query suggestion).
Ideally, to find highly related actions for a query q ,we would extract the complete set of actions that sequentially follow q ,aggregatingtheavailableinformationacrossallthe sessions containing q .However,thisapproachismadeun-feasible in practice by a number of di ffi culties that are en-countered when applying sequential analysis to toolbar dat a. The main challenge is that a sequence of actions following a query q does not necessarily correspond to a sequence of re-quests made by the user to answer to the same information need expressed by q .Usersmanytimesareperformingsev-eral tasks in parallel, which produces unpredicted context changes in navigation. This quality turns this sequential rule discovery problem into that of mining noisy sequences. In particular, we deal with two main types of spontaneous context changes in sequential toolbar session data: 1. switching between parallel unrelated tasks (e.g. search ing and at the same time browsing a social network site); 2. starting a completely new unrelated search task. Context changes in user sessions arise easily given the mult i-tasking nature of humans, and are facilitated by modern browser functionalities, like tabbed windows. In this sce-nario, session features like referral URL, dwell time and timestamp do not provide su ffi cient information to derive which actions are related to a same information need.
An additional challenge arises, once the problem of finding highly related actions for a query q is solved. This problem is that of grouping sets of related actions for q into coher-ent groups that correspond to a same complex information need. This is a complex task, because q can be a part of one type of complex task or part of a completely di ff erent task, depending on the actions that are related to it in a session.
In summary, we define the scope of our research as that of solving the following two problems: 1. Discover interesting association rules for queries in tool-bar data. 2. Automatically extract sets of related actions for a query .
We present a technique for mining association rules for queries in toolbar data. We focus only on rules that are related to a user information need (i.e., rules whose head is a query). In addition to this, we propose a graph-based representation, which we call the association-rule graph ,and which we use to extract sets of related rules.

For our analysis we assume that only sessions containing aquerycorrespondtosessionsthatexpressaninformation need. We also assume that any user action registered before aqueryisformulatedinasession,isnotconsideredaspart of the information need of the query.

To extract association rules from user browsing activity, we retrieve from toolbar sessions meaningful query  X  action pairs for which timestamp(query) &lt; timestamp(action) .As mentioned earlier, we consider as an action either a URL or anewquery.Thequeryandtheactioninapairdonotneed to be immediately consecutive in a session.
 Interestingness Measures. We introduce the following measures for the importance of the extracted rules:  X  supp(q  X  a ): The support of an association rule is the  X  conf(q  X  a) :Theconfidenceofanassociationruleshows  X  supp(q) :Wedefinethetotalsupportofquery q as:  X  query supp(a) :Additionally,wedefinethe query-support Mining Noisy Association Rules. To visualize and an-alyze the association rules defined above, we abstract them into what we call an association-rule graph .

The relationship between queries and actions, given by query  X  action rules, can be represented in an adjacency matrix L of size N  X  ( N + M ), where N corresponds to the number of unique queries in our dataset and M is all of the possible URLs that can be browsed by a user after submitting a query. Since the rules are of type query  X  action ,wehave( N + M )columns. Thevalueofeach l i,j relationship between any q i ,a j is given by conf( q i  X  a
This type of representation is an analogy of the well-known vector-space model used for documents in Informa-tion Retrieval. Traditionally this model vectorizes each d oc-ument d in the feature space of the terms in the vocabulary of the document collection. Each vector coordinate w d,t is given by the frequency of the term t for document d ,also known as tf .Inourapproachweviewaquery q as an ob-ject, which is composed of all of the possible actions that ca n follow it in any session containing q .Therefore,theweight given for every action a corresponds to the confidence of the joined rule: w q,a = conf ( q  X  a ).

In the document model representation the presence of stop words and very long documents can induce unwanted bias onto the frequencies of each word. To deal with this, com-monly, the well-known tf-idf scaling scheme is introduced. In a similar way, in our current research problem, we empir-ically observe two situations that induce noise in the weigh t or importance of our association rules: 1. Actions with high query supp ( a ) value: This is the case of actions, mainly URLs, that are associated to many di ff erent queries. Actions like these mostly correspond to URLs that are typically visited in most sessions, and are usually not related to the search task. Examples of these URLs are: common web e-mail providers (such as GMail or Yahoo! Mail), social networking sites (such as Facebook), etc. Table 3 shows the most common URLs across queries. These actions are not particular to the input query, and can be considered as noise. We refer to these actions as stop actions in an analogy to stop words in Information Retrieval.
Table 1: Stop actions with highest query support 2. Queries with low supp ( q ) value: These are queries that are very infrequent in the dataset. High-confidence rules that are associated to this type of queries should not be considered as relevant. The reason for this, is that there is not enough data evidence to decide if the resulting asso-ciation rule is interesting. For example, an extreme case is that of queries with only one action and one session, which create a rule with conf ( q  X  a )=1.

To mitigate the e ff ect of noise induced by 1) and 2) we introduce the following normalization function for w q,a : which meets the requirements of penalizing the cases de-fined in 1) and 2). Applying a smoothing function, the re-sulting weights in the normalized adjacency matrix are:
We now present the experimental framework we built to evaluate our model. In the following, we describe how we extracted a large association-rule graph from a toolbar log , and how we used it to gather related actions for queries. As application, we show that our rules have the potential to improve the retrieval of related results in Web Search. Graph generation. We obtain query  X  action pairs from asearch-enginetoolbarlogspanningthreemonthsin2010. The initial dataset consisted of 3 . 8billionpairs. Weremoved all the edges that were not likely to represent interesting association rules. Specifically, we sequentially cut out 1. rules whose head (query) had less than 5 occurrences; 2. top 1% highest-support rules (mostly stop-actions); 3. bottom 50% lowest-weight rules (weak relations); 4. rules whose body (action) had degree greater than 2000. The graph resulting from the first two steps contains 350 million of nodes and 1.5 billion edges. The last steps sub-stantially sparsify the graph and this legitimates the ques-tion whether a lot of useful information is also filtered out. To answer this question we perform our experiments both on the graph obtained after the second step ( Tool 50) and on the graph obtained after the final step ( Tool 50  X  f 2 K ). Extraction of related actions. Nodes that are close to each other in the association-rule graph represent queries and URLs that are frequently accessed together by toolbar users, thus are very likely to be motivated by the same in-formation need. Following this intuition, we gather action s related to a given query by looking at close nodes in the association-rule graph. We experiment with three methods. 1. Weakly connected components. Extracting the weakly connected component containing the input query is not e ff ective, nor on Tool 50, neither on Tool 50  X  f 2 K .The two graphs respectively have a giant component spanning 99 . 99% and 75% of the nodes. This happens because stop actions are still present in the graph, despite the pruning. 2. Selection of top neighbors. Our second method se-lects the top ten neighbors of the input query with high-est weights. The idea comes from previous works on the query-flow graph [2, 3], which used the most frequent re-formulations of a query for recommendation. We call TNU and TNF the methods that respectively extract top-weight neighbors from Tool 50 and from Tool 50  X  f 2 K . 3. Random walk with restart to the query node.
 Inspired by previous work on query recommendation [2, 4], we select as actions related to a query the ten nodes with the largest stationary probabilities in a random walk with restart to the query node. Following [2, 4], we use high self-loop probabilities to make the random walk stay close to the input node. We only apply this last method, which we call RW R ,onthe Tool 50  X  f 2 K graph.
 Relatedness assessment. We tested TNU, TNF, and RWR on a random sample of 250 queries. For every query, each method generated a ranked list of ten related actions. In total, we got 6 201 distinct query-action pairs.
We used editorial judgement to evaluate whether the ob-tained actions were actually related to the input query. The editorial team was composed by 5 people. Each editor was assigned a set of query-action pairs. For each pair, the edi-tor was asked to judge whether the action was very related , partial ly related or not related to the query.

The concept of relatedness was explained as follows:  X  X e-latedness will be based on likelihood of a query to lead to the action (query or URL) due to a task the user was involved in. Rather than simply thinking of a possible connection , please keep in mind that we are considering whether there X  X  alikelycause/e ff ectrelationshipbetweenthequeryandthe action. Ask yourself whether the user is on the same task with the second action as with the original query X . The as-sessors were encouraged to access the content of the URLs or to use a search engine to issue questionable queries. They were also asked to judge as not related the queries or URLs that were unreadable, not understandable, or not valid.
Using the editorial judgements as golden truth, we com-puted the precision p @ n ,for n =1 ,..., 9ofTNU,TNFand RWR. We defined p @ n as the fraction of the actions returned by a method for a given query, which were judged by the ed-itors as (very or partially) related to the query. The averag e precision of TNU, TNF and RWR with respect to editorial evaluation is reported in the third column of Table 2.
TNU is the method with poorest performance. The top action is judged as related for 67% of the test queries, but precision rapidly decreases for increasing n .Thisisdueto the noise contained in the unfiltered graph, where popular stop actions are ubiquitously the top neighbors of any node. TNF, which applies the same algorithm (selection of top-weight neighbors) on the filtered graph, obtains p @1 = 0 . 89 and p @2 = 0 . 79, and outperforms TNU for any value of n .Thustheappliedfiltersfavortheemergenceofclearer semantic connections. However, the best method is RWR, which constantly improves the average p @ n for n  X  3. Ex-ploiting the graph structure, RWR demotes rules that have hight weight due to the noisy nature of toolbar data. Application to Web Search. To show that our method-ology has potential application in Web Search, we analyzed aquerylogprovidedbythesamesearchenginethatowned the toolbar data, and spanning the same time interval. For each query and for each method, we computed the fraction of related URLs that were stored in the query log as viewed ( V Coverage) or clicked ( C Coverage) results for the input query (within the top ten positions).
 Table 3 reports average V coverage (second column) and C coverage (third column) of the three methods. The ma-jority of the results returned by our methods was not found in the query log. Given that our methods achieved good precision with respect to a human-assessed notion of relat-edness, we interpreted this as indication of the fact that th e search engine probably failed to include many related resul ts for the original queries. To obtain further evidence of this , we recomputed the precision of our methods in the scenario where we marked as related to the starting query only the URLs that were respectively viewed or clicked in the log (see fourth and fifth column of Table 2). We got findings simi-lar to those based on editorial evaluation. TFN is the best method for n =1 , 2butRWRisstillthemoststableone, and the one with slowest degrade in precision for increasing n .However,thecrucialpointisthatthefractionofURLs that editors judged as related to the queries is much higher than the fraction of the same URLs that were either viewed or clicked in the query log. This clearly indicates that our methodology may be used to improve the performance of a search engine with respect to retrieval of results related t o the users X  queries.

For each method and for each query, we also computed the fraction of related URLs that were not appearing in the query log within the top ten results of the query, but did instead appear in the top ten results of a query that followed the input query within 1 or 2 hops in a user session. We called this quantity the Click-Through Rate Increase from queries at distance d ( CT RI ). Third and fourth column of Table 3 show the average CT RI for our three methods, at d =1and d =2. Inallthecasesweobtainedanaverage CT RI  X  35%  X  40%. Thus, we believe that the relatedness signal provided by toolbar association rules can be used to push these results that appear later in the search session in more prominent positions of the result set of input query, helping to increase the click-through rate.

We have explored association-rule mining for queries in toolbar data, and we have proposed a graph-based approach for extracting actions related to a query. In future work we will study how to leverage sets of related actions for querie s to satisfy more complex information needs. [1] M. Bilenko and R. W. White. Mining the search trails [2] P. Boldi, F. Bonchi, C. Castillo, D. Donato, and [3] I. Bordino, C. Castillo, D. Donato, and A. Gionis. [4] N. Craswell and M. Szummer. Random walks on the [5] D. Donato, F. Bonchi, T. Chi, and Y. Maarek. Do you [6] B. M. Fonseca, P. B. Golgher, E. S. de Moura, and [7] R. Jones and K. L. Klinkner. Beyond the session [8] A. Kotov, P. N. Bennett, R. W. White, S. T. Dumais,
