 1. Introduction
Cross-Language Information Retrieval (CLIR) has been recognized as an independent research sub-field for more than a decade now. The field has sparked three major evaluation efforts: a Cross-Language
Track at TREC (Text Retrieval Conference) from 1997 to 2002, the Cross-Language Evaluation Forum (CLEF) X  X  X  spin-off from TREC X  X  X overing many European languages, and the NTCIR Asian Language
Evaluation (covering Chinese, Japanese and Korean). 3 These efforts have had significant impact, provid-ing CLIR researchers and system developers with infrastructures for system testing and tuning, and with the opportunity to discuss and compare ideas and approaches. The result has been considerable progress in system design and development and the building up of a consolidated community of researchers around this topic.

A little more than two years ago, we decided that it was time to review and assess the progress that has been made so far and discuss what research and development remains to be done to make CLIR a practical rather than a research-oriented enterprise. We thus organized a workshop at SIGIR 2002 with the goal of developing a roadmap of research still to be undertaken. Presentations focused on the major techniques and accomplishments of the field (e.g. utilization of corpus, dictionary, and machine translation techniques for crossing language barriers, strategies for sense disambiguation and query expansion), with position pa-pers suggesting the directions that research should take in the next half decade ( Gey, Kando, &amp; Peters, 2002 ).

One of the results of the workshop was the decision by the editorial board of Information Processing and Management to produce a reference issue on Cross-Language Information Retrieval. The aim as sta-ted in the Call for Papers was to present a landmark set of research papers which present the most signif-icant research in the field on different aspects of multilingual information access and Cross-Language
Information Retrieval. We received twenty-one submissions in response to this Call covering a wide variety of those areas and arguments that impact on the multilingual information access domain. Seven of these papers, highly representative of the current state-of-the-art, were selected for publication in this special issue.

The rest of this paper is organised as follows. Section 2 present the main areas of discussion and ques-tions addressed at the Workshop, whereas Section 3 focuses specifically on the role that has been played by evaluation campaigns in influencing the direction that CLIR research has taken. In Section 4, we provide an overview of the papers in this volume while Section 5 make proposals for future research directions aimed at the development of fully functional, user friendly multilingual and multimodal retrieval systems. The paper concludes with the ambitious 5-year research plan proposed at the Workshop by James Mayfield and Paul McNamee. 2. CLIR workshop at SIGIR 2002
The workshop was organized in six thematic sessions: Approaches to CLIR described various techniques which have been applied to CLIR in the past, including query translation, pivot languages, and thesauri, with speculation for the future. Strategies for Languages with Little Resources described techniques for lan-guages for which there are few linguistic resources available, with examples from Indonesian, Tamil and
Zulu, and also included a proposal for the standardization of lexical resources for CLIR. The Multimedia session discussed CLIR for image and speech retrieval across languages. User Studies/Interactive presented papers on the role of user interaction in CLIR. A session on Evaluation described the Cross-Language
Information Retrieval evaluations underway in Europe and Japan (CLEF and NTCIR, respectively) and discussed their contribution to CLIR research and development. The final session Building a Roadmap began with a main talk in which a detailed 5-year plan for research was outlined; this was followed by par-ticipant discussion and a review of the entire day of presentations.
At the beginning of the workshop the organizers presented three challenges: 1. Where to get resources for resource-poor languages  X  X  X utside of the most spoken languages of Europe (English, French, German, Italian, Spanish) and Asia (Chinese and Japanese) or the additional official languages of the United Nations (Arabic and Russian), resources in terms of parallel corpora or com-mercial machine translation are very difficult to obtain. In particular, the languages of the Indian sub-continent have received very little attention, while the many local languages and dialects of Africa have been almost totally ignored. 2. Why do we not have a sizeable Web corpus in multiple languages?  X  X  X side from the issues of cost of con-struction and maintaining realistic links (which have taken several years to be addressed by the TREC
Web track for the English languages), we have the complication of English language dominance (approximately 60% of Web pages currently) and low percentage representation beyond the top ten lan-guages, as well as lack of standards for character and font representation for many other languages. Chi-nese has at least two major representations (GB and BIG5) and Japanese three, while for Indian subcontinent languages standards are only beginning to be developed (i.e. each site has its own font and internal character representation). This means that if English is included a ranked list of pages will be dominated by pages in English and many languages will not even make in the top 100 pages found. Work is clearly needed here in order to define suitable criteria for the construction of a valid multilingual
Web corpus for R&amp;D. 3. Why aren  X  t search engines offering CLIR?  X  X  X everal search engines now offer monolingual search in a number of languages coupled with machine translation software to translate pages into English (Alta-
Vista and GOOGLE are prominent examples). Cross-language search would seem to be a natural exten-sion of these offerings. Part of the answer is found in the question of utility X  X  X f users are presented with a ranked list of documents that they cannot read, what is the utility? An exacerbating factor is in the weak-ness of current machine translation software when applied to the pages found.
 Although there was a considerable exchange of ideas on these points, no exhaustive answers were found. The main discussion revolved around the third challenge: why is there still little take-up of the results of the
R&amp;D activity by the relevant application communities? A number of questions were asked: Have we solved the CLIR problem? Have we identified the CLIR problem? Do we need a better understanding of the requirements of real users? What are the strategies for moving forward? In the final section of this paper we will address some of these issues. 3. CLIR evaluation campaigns
At the workshop, there was general agreement on the importance of the role that can be played by eval-uation campaigns in promoting research in system development and in influencing the directions that future research can take. There is a duality between research and evaluation. Good research is validated by evalu-ation and good evaluation environments stimulate further research. Modern information retrieval evaluation began with the first TREC conference ( Harman, 1993 ) and has continued within its subsequent eleven other conferences ( Harman, 2003 ). TREC introduced a number of innovative evaluation ideas and approaches, including results pooling, known-item searching, reciprocal rank evaluation (for evaluation of factoid ques-tion answering), evaluation of interactive retrieval, and scene boundary detection for video. The success of
TREC as an objective forum for evaluation led to the formation of the NTCIR series in Japan ( Kando, 2003 ) and the CLEF campaigns in Europe ( Braschler &amp; Peters, 2004 ). of a set of topics which describe information needs and a collection of documents which are to be searched to identify those documents which satisfy the information needs. The ground truth of evaluation is a set of  X  X  X el-evant X  X  documents for each information need which has been identified by a human judge. Evaluation is then done for each ranking of documents with respect to the topic by the usual computation of recall, precision and other measures. For Cross-Language Information Retrieval evaluation, another factor is intro-duced X  X  X ow well cross-language IR performs with respect to monolingual information retrieval on the same document collection. 3.1. The cross-language track at TREC
Originally designed for (and still mainly focused upon) the English language, TREC expanded into other languages with the implementation of the first Spanish foreign language track in TREC-3. In TREC-3, re-trieval of 25 topics against a Mexican newspaper corpus was tested by four groups. Spanish language re-trieval was evaluated in TREC-3, TREC-4 (another 25 topics for the same Mexican corpus), and TREC-5 (where a European Spanish corpus was used). The TREC-3/4 Spanish collections were used by Ballesteros and Croft in their widely cited paper  X  X  X tatistical Methods for Cross-Language IR X  X  ( Ballesteros &amp; Croft, 1998 ). In TREC-5, a Chinese language track was introduced using both newspaper (People  X  s Daily) and newswire (Xinhua) sources from People  X  s Republic of China, and 25 Chinese topics with an English trans-lation supplied. The TREC-5 corpus was represented with the GB character set of simplified Chinese. The
Chinese monolingual experiments on this collection in TREC-5 and TREC-6 sparked research into the application of Chinese text segmentation to information retrieval using dictionary-based methods and sta-tistical techniques, and simpler overlapping character-bigram segmentation methods were also found to be effective. TREC-6, TREC-7 and TREC-8 introduced the first cross-language tracks, which focused upon
European languages X  X  X irst English, French and German, and later Italian ( Harman et al., 2001 ). Following the TREC-8 conference, the venue for European-language retrieval evaluation moved to Europe with the creation of the Cross-Language Evaluation Forum, and the first CLEF workshop was held in Lisbon in
September 2000. For TREC-9, the CLIR task used Chinese documents from Hong Kong. In distinction from the earlier TREC-5/6 Chinese corpus, these sources were written in the traditional Chinese character set and encoded in BIG5. Following TREC-9 the evaluation of English X  X hinese retrieval moved to the NTCIR Evaluation which is coordinated by the National Institute of Informatics in Japan.
 For the TREC-2001 and TREC-2002 conferences, the cross-language task was a bilingual retrieval of
English topics against Arabic document collections ( Gey &amp; Oard, 2002 ; Oard &amp; Gey, 2003 ). The paper by Xu and Weischedel in this issue demonstrates their experimental research utilizing the evaluation re-sources in Chinese and Arabic developed by the TREC tracks between 2000 and 2002. 3.2. Cross-language system evaluation at NTCIR
NTCIR is a series of evaluation workshops, organised at 18 month intervals and designed to enhance research in information access technologies, including information retrieval, text summarization, question answering and text mining. The first NTCIR was held in 1997 and the fourth series is now under way. In
Asian countries, CLIR between English and native-languages can be critical for international information transfer, at least in an initial stage, and CLIR between languages with completely different structures and origins, such as English and Chinese, or English and Japanese, is a challenging task. There is thus great demand for efficient CLIR technology. For this reason, CLIR has been one of the central interests of
NTCIR from the beginning, and has attracted many international participants. In addition, over this per-iod, personal contacts between the populations of East Asia have dramatically increased and the countries in this region are gradually becoming part of a  X  X  X ultilingual multi-cultural society X  X , in which many people can understand more than one language to some extent in ordinary life, in business and entertainment, but are still not sufficiently fluent to formulate fully expressive queries. NTCIR thus started with Japanese and English bilingual CLIR and has gradually increased the number of document languages.
 In NTCIR-1 ( Kando &amp; Nozue, 1999 ) and NTCIR-2 ( Kando, 2001 ), tests were conducted on English X  Japanese scientific abstracts. More than half of the documents were English X  X apanese paired, but in
NTCIR-2 the correspondence between paired documents was not revealed to participants. Interesting char-acteristics of the document collections were the number of technical terms and the existence of a partially paired corpus with an associated list of bilingual keywords, easily found in non-English speaking countries.
Transliteration of technical terms ( Fujii &amp; Ishikawa, 1999 ) was proposed and corpus-derived lexicons were used by several groups. Corpus-based CLIR proved effective in NTCIR-1 but not in NTCIR-2. However, MRD or MT-based approaches supplemented by corpus-derived lexicons improved search effectiveness.
Pre-and post-translation query expansion and disambiguation, and PRF were used with success. Several enhancements of Okapi were proposed. Some groups tested partial document translation approaches as well. NTCIR-2 also tested on Mandarin Chinese news articles from Taiwan, with traditional Chinese char-acters using BIG5 encoding ( Chen &amp; Chen, 2001 ). 5
NTCIR-3 and NTCIR-4 used multilingual CtJKE (traditional Chinese, Japanese, Korean and English) news articles published in East Asia with CtJKE topics, and Japanese patents with English X  X apanese trans-lation-equivalent paired abstracts with CtCsJKE topics. All language collections are derived from multiple source newspapers and, in NTCIR-4, the size and publication years were well balanced. This change in doc-ument genre was decided in response to social needs, i.e., the recent increased interest in the social and cul-tural behaviour of neighbouring countries in East Asia reported above, and the growing importance of technological information transfer in the business and industrial sectors. Consequently, the handling of named entities, 6 and cultural or local/domestic topics were typical targets for intensive investigation on the news document collections, whereas, the use of technical terms, very long documents, large-scale exactly translated paired corpus, etc., were issues for experiments on the patent collection.

At NTCIR-3, many groups tested monolingual retrieval on every language in the multilingual CJKE col-lections, and compared various language-dependent techniques including segmentation. Only seven groups submitted multilingual CLIR runs and many participants focused on using English topics to search Asian language documents for bilingual CLIR. This was partly because of the availability of translation resources that included English as one of the languages. Different groups experimented with query translation using
MRDs or MT with PRF, translation disambiguation, corpus-based translation, or merging of ranked lists for retrieval from a collection in multiple languages. He and Gao (2003) proposed the  X  X  X ecaying co-occur-rence model X  X  for translation disambiguation. Chen and Gey (2003) adopted a corpus-based translation ap-proach using Web search engines. They also found that a hybrid of query translation and cognate matching between Chinese and Japanese through encoding conversion worked well. Lin and Chen (2003) explored a unique MultiLingual IR (MLIR) strategy for merging ranked lists based on translation difficulties. Sakai,
Koyama, Suzuki, and Manabe (2003) intensively investigated variations of PRF, and Murata, Ma, and Isa-hara (2003) proposed a weighting strategy considering keyword location. Moulinier, Molina-Salgado, and Jackson (2003) and Tomlinson (2003) compared various indexing techniques on CJK, and Luk, Wong, and Kwok (2003) examined the comparative effectiveness of several indexing methods and retrieval models on
Chinese. Such comparative studies have contributed greatly to clearer insights into segmentation and search mechanisms for CJK. For patent retrieval, follow-up studies were conducted in order to compare various conditions on the same implementation ( Iwayama, Fujii, Kando, &amp; Marukawa, 2003 ).

Experiments using the NTCIR test collections are described by Fujita and by Seo et al. in this issue. 3.3. The Cross-Language Evaluation Forum
The Cross-Language Evaluation Forum (CLEF) has just completed its fourth year of independent activ-ity. The move to Europe has made it possible to build on and extend the initial results achieved within
TREC. The multilingual environment provided by Europe has made it easier to add new languages and has stimulated participation. It has also facilitated the organisation of CLEF which is organised on a dis-tributed basis with native-language groups responsible for the creation of test data in each language. Since its beginning, there has been a concerted coordination of efforts and exchange of ideas between CLEF,
NTCIR and the cross-language track at TREC; the aim has been to offer complementary CLIR evaluation activities to the R&amp;D community. The first campaigns of CLEF have had as main goals: to accommodate as many European languages as possible to provide facilities for monolingual system testing and tuning in European languages other than Eng-lish, which was already well covered by TREC to stimulate systems to move from monolingual searching to the implementation of a full multilingual retrieval service to study the emerging needs of both system developers and system users in order to promote the intro-duction of new tasks.

The results have been encouraging in terms of numbers and of impact. Separate tracks to test monolin-gual, bilingual and multilingual systems were provided with the aim of allowing groups to work their way up gradually from mono-to multilingual retrieval. The test collections have continued to grow and the main corpus now consists of comparable news documents from the same time period in ten languages:
Dutch, English, French, Finnish, German, Italian, Portuguese, Russian, Spanish, and Swedish. Participa-tion of both academic and industrial groups, and especially of European groups, has increased rapidly. Additional tracks have been added to supplement the core tracks.

By creating a forum for the comparison of results using different approaches and technologies, CLEF appears to have had a real effect on CLIR research and system development. Over the years, we have seen considerable take-up of ideas and methodologies and sharing of resources among participating groups. By promoting the multilingual track as the main task, groups have been strongly encouraged to extend their systems in order to be able to handle a large number of languages and the various problems involved. All kinds of indexing methods have been tried: the merits of simple stemming have been compared with more complex morphological analysers, and different types of compound splitting have been tested on aggluti-nate languages. For multilingual retrieval, several alternatives for the handling of all the languages exist.
They can be handled simultaneously, or they can be handled one at a time, through a succession of bilin-gual retrieval steps, and then subsequently merged into one, multilingual result. Most groups at CLEF have adopted the second approach. Many experiments aimed at identifying the best merging technique have been made, but so far no clear answer has emerged: the merging of various bilingual results to produce an optimum ranking for multilingual retrieval still remains an unsolved problem. In order to cross the lan-guage barrier between query and target collection, groups have experimented with both query and docu-ment translation, and with combinations of the two. Different kinds of translation resources have been employed: machine translation systems, electronic dictionaries, corpus-based techniques, and the use of pivot languages when no translation resources are available for direct translation between two languages.
Groups have even experimented with methods that use no translation resource but match on character n -grams over languages. CLEF has actively encouraged groups to try out innovative ideas and some very Peters, 2003 ).

Over the years the attention of the CLEF campaigns has gradually shifted from a focus on text retrieval systems and the measurement of document rankings towards the provision of a wider range of tasks.
Increasing attention has been given to issues that interest the end users and their interaction with the sys-tem. For example, the ways in which a system can help the user when formulating a query or the ways in which the results of a search are presented are of great importance in CLIR where it is common to have users retrieving documents in languages with which they are not familiar. The paper by Lo  X  pez-Ostenero et al. in this issue describes a tool to assist the user in query formulation and refinement and in foreign-lan-guage document selection that has been evaluated in the Interactive track at CLEF.

The 2004 campaign offers eight different evaluation tracks, and will include tasks to assess systems for multilingual question answering, for cross-language image retrieval, and for cross-language spoken docu-ment retrieval. The goal is to offer a comprehensive set of tasks covering all major aspects of multilingual, multimedia system performance with particular attention to the needs of the end-user. 3.4. The TIDES surprise language 2003
The major US program which has funded cross-language information search (as well as other language technologies such as information extraction and summarization and machine translation) is the TIDES (Translingual Information Detection Extraction and Summarization) program of DARPA. The goal of
TIDES is to dramatically improve the state of language technology to support the rapid response to new world crises. In the early days of the program the phrase  X  X  X achine translation for a new language in a week X  X  was coined. In 2003 the program developed a test scenario called the  X  X  X IDES Surprise Lan-guage Exercise X  X  to evaluate the rapid response capability of the funded technology. The central idea is the announcement of the  X  surprise  X  language on the first day of an evaluation and by the 30th day all tech-nology is adapted to the new language and evaluated according to standard evaluation metrics. In Spring 2003 this was tested in the following ways: a dry-run exercise for 15 days in March to prepare and identify shortcomings in readiness for the actual exercise during the month of June. The dry-run surprise language was chosen as  X  X  X ebuano X  X  spoken by about 15 million persons in the Philippine nation, the lingua franca of the southern Philippines. The June evaluation language was Hindi, spoken by 200 million persons in India. Each language presented special challenges: Cebuano because of the scarcity of electronic resources and Hindi because of the multiplicity of encodings of its scripted written language found abundantly on the Web. In neither language was a body of aligned parallel text available outside of translations of the Bible.
Printed bilingual dictionaries in both languages were scanned and made available and, for Hindi, an inno-vative Web-based translation utility was set up to allow for online translation of Hindi news stories. By the end of the exercise a great deal had been learned and both translation resources developed, and evaluations had been performed on the fundamental language technologies involved in the TIDES program. More information may be obtained by reading the Special Issues on the Surprise Language Exercise of ACM
Transactions on Asian Language Information Processing ( Oard, 2003 ). 4. CLIR research in this issue
The papers in this special issue of IP&amp;M provide a cross-section of many of the important issues cur-rently being investigated by the CLIR research community, both within and externally to the evaluation programs described in the previous section.
 The first paper by Kazuaki Kishida provides a survey of the principal technical issues in Cross-Language
Information Retrieval, including cognate matching, translation types (query, document, interlingual), dic-tionary-based mapping, disambiguation of multiple translations, machine translation, phrasal translation, parallel and comparable corpus-based methods for probabilistic translation, mining Web resources for translation, merging issues for retrieval against multilingual corpora, use of pivot languages for indirect translation, and language-specific issues such as tokenization and segmentation for Asian languages, stop-word lists, stemming, decompounding, part-of-speech tagging, etc.

When discussing query translation versus document translation, the paper notes the principal disadvan-tage of query translation to be short queries with a few disconnected words without sufficient context for disambiguation, while the principal disadvantage of document translation (where context is not a problem) is the overwhelming cost in terms of computing resources needed to translate large document collections. In the area of dictionary-based mapping from the query language terms to the document language terms, methods of disambiguation using query word pair context, part-of-speech mapping, and reverse translation are discussed. For parallel/comparable corpora, the paper describes algorithms for probabilistic matching between term pairs using maximum likelihood and other estimation techniques as well as statistical ma-chine translation models. Interlingual techniques such as latent semantic indexing also depend upon paral-lel corpora alignment. The paper  X  s examination of merging recognizes that the multilingual merging problem is, in principle, equivalent to the problem of distributed collection retrieval and that many of the techniques developed there apply directly to CLIR.

The remaining papers describe individual experiments, designed to test different aspects of the CLIR par-adigm, using European, Asian and Arabic target language collections. Issues investigated include system architecture, indexing techniques, language modelling, translation resource acquisition and employment, pre-and post-translation query expansion, target query term disambiguation and user X  X ystem interaction.
Techniques proposed have been assessed using TREC, NTCIR and CLEF test data. 4.1. Improving dictionary-based CLIR
Most of the papers in this special issue describe experiments that include the application of dictionary-based translation techniques when mapping correspondences between languages. The paper by Levow, Oard and Resnik identifies the key issues raised when using the simplest form of dictionary-based
CLIR X  X  X achine-readable bilingual term lists X  X  X nd proposes a unified framework for term selection and translation. These authors also study the effects of such techniques on the retrieval effectiveness for lan-guages with different characteristics, using queries in English on document collections in French, mandarin
Chinese, German and Arabic under diverse experimental conditions. Points covered include appropriate methods for indexing and term extraction according to the characteristics of the language, query and doc-ument term expansion, the merits of the structured query approach ( Pirkola, 1998 ), and a general method-ology which can be used to enhance dictionary coverage.

Both the papers by Xu and Weischedel and by Larkey and Connell also utilize and test the effectiveness of bilingual machine-readable dictionaries when applied to the translation part of Cross-Language Infor-mation Retrieval. Of course, as also described by Levow et al., translation ambiguity is a major problem when using dictionary-based techniques. Bilingual dictionaries can often provide multiple translations for the same source language word or phrase. This can occur because of polysemy (e.g. the English word bank as a financial institution or the side of a river) or because the same source word may be expressed in multiple ways in the target language. Since both of these two papers test probabilistic retrieval models, they make the assumption of uniform probability among the translation alternatives. In reality not all transla-tions are equally likely and much work has been done in recent years on improving the choice of best possible translation among alternative choices. This has often been done by looking for translation alter-natives among pairs of adjacent (non-trivial) source language query words within a window (sentence, par-agraph, fixed size segment) of target language documents being retrieved.

The paper  X  X  X mproving Query Translation in English X  X orean Cross-Language Information Retrieval X  X  by Seo, Kim, Rim, and Myaeng extends this research in a new direction by optimizing over all possible combinations of translations of source query terms. This process can be compute-intensive (a query of 10 words can generate 10 20 possible combinations of terms) and hence these authors introduce heuristics to reduce the computational overhead of finding the best possible translation alternative. While their experi-ments are with English to Korean bilingual retrieval, the methodology is general and could be applied to any language pair where translation is being carried out via machine-readable dictionaries.
One of the problems noted by Levow et al. when using dictionaries is asymmetry in term selection for translation and matching and consequent variations in performance. This issue is studied in far more depth with comparative evaluation experiments in the paper by Fujita for term translation between Japanese and
English and vice versa on comparable collections. He attempts to explain the asymmetry from two aspects: query translation quality, and discrepancies between information needs with respect to the actual query for-mulated, and with respect to the contents of the target collection. Fujita describes the use of a bilingual
Japanese X  X nglish dictionary together with a (partially) parallel Japanese X  X nglish collection for pre-trans-lation feedback with positive results. He suggests that a challenging direction for future research would also be to test the use of parallel collections in situations where pivot languages and transitive translation meth-ods are involved. 4.2. Translation resources beyond human-constructed dictionaries
The papers by Xu and Weischedel and by Larkey and Connell primarily concentrate on evaluation of resources used in the translation aspect of Cross-Language Information Retrieval. Both papers demon-strate that use of machine translation in CLIR has moved beyond application of commercial off-the-shelf translation systems to the utilization of state-of-the art statistical machine translation software and models.
In both papers, bilingual lexicons are induced using the GIZA++ system against parallel corpora ( Al-Onai-zan et al., 1999 ), using IBM Model 1 (single word translation) in the case of Xu and Weischedel and IBM Model 4 (more sophisticated bigram dependency translation) by Larkey and Connell.

The paper by Xu and Weischedel utilizes a model of CLIR which incorporates translation into the retrieval process and compares the combination of fixed resources (i.e. a human produced bilingual dictionary) with flexible resources (lexicons derived from bilingual corpora). Their experiments test retrieval effectiveness as a function of dictionary size, showing that beyond a certain threshold, dictionary-based retrieval plateaus, and dictionary-based retrieval improves when supplemented by statistical lexicons. Bilingual retrieval experi-ments are carried out for English queries against Chinese, Arabic and Spanish documents, using collections and relevance judgments from the various TREC evaluations of these languages.

The paper by Larkey and Connell compares a traditional IR approach (as exemplified by the U. Mas-sachusetts INQUERY system) which allows for structured queries to incorporate alternative dictionary translations as synonyms to advanced language model approaches (incorporating relevance models) ap-plied to Cross-Language Information Retrieval. Their experiments are carried out again for English queries against the Arabic or Spanish document collections of TREC. While Xu and Weischedel carry out their experiments without pseudo-relevance (blind) feedback (wishing to have a clean comparison of resource size), Larkey and Connell test their experiments with pseudo-relevance feedback incorporated as an integral part of the process (indeed incorporated into the language model part of the experimentation). The Larkey/ Connell experiments exhibit a result where cross-language retrieval performance (at least where English is the source language) exceeds monolingual performance. 7 They describe how the process of blind feedback can produce this result by raising the performance of a single query from abysmal to excellent, thus impact-ing overall performance. 4.3. Interaction with the user
One of the criticisms frequently made of research in the CLIR domain is that too much attention has been given to questions of retrieval functionality and effectiveness with little regard to the real needs of the end user. Many users of CLIR systems are looking for and retrieving information in languages in which they have little or no competence. This means that they may well need guidance from the system both in formulating or refining their queries and in interpreting the results. Other CLIR system users may be per-fectly capable of understanding results in a number of languages but want to be able to query a number of information sources simultaneously, using a single query. Different user groups demonstrate different behaviours and system design must take this into consideration.

The recognition of these needs has given rise recently to a new line of investigation aimed at studying the most effective means for user X  X ystem interaction. Interesting work in this area has been done by the Clarity project. 8 Clarity has studied CLIR for the so-called low-density languages, those with few translation re-sources. The project has investigated a number of techniques aimed at enabling users to better interact with the CLIR system by presenting and organising cross-language retrieval results in an efficient way ( Petrelli et ing an interactive system which is based on the belief that noun phrases are basic conceptual units and as such can be usefully exploited for both query formulation and refinement and for document selection. The paper claims that a cross-language summarization algorithm based on translations of the noun phrases in a document is much faster and less resource consuming than full machine translation, and provides the user with all the information needed to select relevant documents or choose appropriate translations for the query terms. The problem, as with all experimental work in this field, is that the user studies reported are limited and the results are assessed on the basis of a very small data sample. It is hard and time con-suming work to set up an extensive user study and this is one of the reasons that has constrained research in this area so far. More studies of user behaviour and user needs in the CLIR context are needed in order to design and build systems that are not only efficient but respond to the users  X  expectations. 5. The future of CLIR research
As evidenced in the papers in this volume, CLIR research so far has mainly concentrated on text collec-tions and on a limited set of languages. However, in the discussions at the SIGIR workshop, it was ob-served that CLIR was simply a means to an end X  X  X ccess to information regardless of the language or media in which it is presented X  X  X nd the user is primarily interested in the end result. It was thus felt that there should be more attention given to end-user issues such as results presentation, multilingual question answering, cross-language filtering and summarization and also to the implications of multilingual search-ing in collections in multimedia. Furthermore, there was general agreement that future research in CLIR should focus more specifically on several additional areas: new languages, particularly lesser studied languages, different genres and media, the multilingual Web, fundamental models and unsolved problems. 5.1. CLIR for all languages
Thus far CLIR research and resource development has involved just a small fraction of the nearly 2000 widely spoken languages in the world today. Indeed, only about ten of the top 25 most commonly used languages (see Table 1 ) have been subjected to any kind of consistent CLIR experiments. Not surprisingly, these are also the languages that have the most economic and commercial influence, i.e. a number of Euro-pean languages, certain East Asian languages and Arabic.

In total, no more than fifteen of the world  X  s languages have been subjected to extensive formal evaluation exercises and test corpus development, and most of these are European languages. Indeed, nine of the ele-ven official languages of the European Union are included in the CLEF test suites. such concentration of attention gives these languages an unfair advantage. This issue also has far reaching social implications when we are talking about global access to information. The diversity of the world  X  s lan-guages and cultures gives rise to an enormous wealth of knowledge and ideas. CLIR research should con-tribute to the ensuring the survival of endangered languages not to giving unfair advantages to a chosen few.

We are still a long way from the creation of instruments and methodologies that will make it possible to overcome all language barriers, although the TIDES surprise language exercises described above has been instrumental for the investigation and understanding of many of the problems and difficulties involved ( Oard, 2003 ). Particular obstacles are represented by: font and representation anarchy ( Strassel, Maxwell, &amp; Cieri, 2003 ) the lack of machine-readable resources and NLP tools.

While it is feasible that the first of these problems will be overcome with a gradual acceptance and adop-tion of common globally recognized encoding standards for the representation of information in digital form, the second is more difficult to solve. It will probably be necessary to investigate two directions: (i) proposals for quick and inexpensive ways to create resources and tools for a  X  X  X ew X  X  languages, as in the
TIDES surprise language exercise described above, (ii) language-independent methodologies which can be adopted for all languages, or more likely for groups of languages with the same characteristics. 5.2. Different genres and media
Much of the research work and almost all CLIR evaluations have focused upon news stories as the main genre of study. However, news media have characteristics which may not hold true for other genres: wide use of proper nouns (names and places), of which the names have a brief lifespan in a temporally tagged corpus, association of date stamps, particular style of writing and a rapid evolution of general-purpose vocabulary. Certain features may facilitate access and retrieval, others may hinder it. By contrast, scientific and technical terminology is difficult to locate in standard machine translation resources, but is, when lo-cated, relatively stable (except in rapidly developing research areas such as e-commerce). Although there has been some important CLIR research in domain-specific areas, in particular in the medical and legal domains, 10 much more evaluation work is needed in order to understand which approaches are the most successful. In fact, real-world running applications in domain-specific sectors, even those that contain col-lections in multiple languages, are reluctant to adopt any serious cross-language functionality. Most of those that do adopt strategies that use some kind of controlled vocabulary. This is confirmed by a recent study of digital library projects under the Fifth Framework programme of the European Commission which revealed that while 14 contained collections in multiple languages, only six had implemented cross-language search mechanisms. And five of these used a multilingual controlled vocabulary or thesau-rus. But why did they chose this solution? And was it really the most appropriate?
While it is true that both NTCIR and CLEF have worked to some extent with domain-specific data (sci-entific abstracts and also patents at NTCIR), the collections have only covered a few languages (Japanese, German, and French) while some of the best scientific and mathematical literature is also being published in
Chinese and Russian and important technical literature exists in very many languages. More comparative studies are needed to understand which approaches and techniques are most suitable according to the genre to be handled.
Similarly, it is time that research and evaluation work shifts its focus to collections in diverse media rather than just text, and from assessing system performance only in terms of a list of ranked documents to other equally important issues that affect user satisfaction such as assistance in query formulation and results presentation in appropriate forms, according to the user needs and his/her language competence.
Differently from the IR scenario, a Question Answering (QA) system processes questions formulated into natural language (instead of keyword-based queries) and retrieves answers (instead of documents).
QA is a multi-faceted problem requiring contributions from information retrieval, natural language processing and artificial intelligence. The components of a good QA system thus differ from that of a tra-ditional CLIR system and need to be studied independently. A pilot track for multilingual question answer-ing system evaluation was introduced in CLEF for the first time in 2003 in order to encourage investigation of the issues involved ( Magnini et al., in press ).

The current expansion in collections of digital documents in various media and languages means that there is a growing need for systems able to automatically access the information contained in such doc-uments. However, almost all work in the multimedia area has been on monolingual (generally English) collections. Two years ago CLEF decided to promote research on multilingual multimedia IR systems and two experimental tracks were introduced. So far the cross-language speech track has aimed at eval-uating CLIR systems on noisy automatic transcripts of spoken documents comparing performance against a monolingual baseline. First results show the importance of the translation resources used and also that different indexing units can be give better performance depending on whether bilingual or monolingual retrieval is involved ( Federico &amp; Jones, in press ). Cross-language image retrieval is a very new area for CLIR research. Depending on the collection and on the processing tools available, the re-trieval can be purely caption-based (and thus becomes a particular type of text retrieval) or can be based on a combination of language-dependent (text-based) and language-independent (image-based) features ( Clough &amp; Sanderson, in press ). In our opinion these two sectors represent crucial areas for research in the future and investments are needed in order to be able to create the necessary test collections for serious comparative studies. 5.3. The multilingual Web
Probably, the first application that comes to mind for most people when they think about the potential of CLIR is searching on the WorldWideWeb. It is however notable that cross-language search and retrieval is not a functionality offered by the most widely used Web search engines. We should examine the reasons for this. It was remarked at the workshop that Web search engines do not provide CLIR services because of the poor quality of general-purpose commercial machine translation. But MT is not the only way to go for
CLIR. It seems evident that the CLIR R&amp;D community should now be investigating what would be the most successful technology, or combination of technologies, for CLIR in the dynamic context represented by the Web.
 Table 2 shows the distribution of language use on the Web.
 We note the following:
The Web is predominated by languages of the developed countries. Further, the top 16 languages account for 90.3% of all Web usage and the bottom 23 languages account for 0.93% of all Web pages or less than 1%.
 While English remains the predominant language, its share has been declining over time (a 1999 study by Excite Corp had English Web pages as 72% of the Web at that time).

Hence to prepare a Web corpus for evaluation purposes (if we presume that CLIR researchers will not have the resources to store the entire WWW) we will need to prepare a stratified sample, one which taps the entire collection for less represented languages and randomly samples some fraction of the more repre-sented languages (say those representing at least 1% of Web urls). What the sampling fraction should be for the  X  between  X  languages will require careful thought.

For any representative sample of the Web, we will also encounter font and character set representation problems. The panacea of Unicode representation meets reality with the Web capability of dynamic font downloading, which enables any Web site to choose its own character set and font encoding. Only in West-ern Europe are the ISO standards widely used and accepted.

Finally, there are intellectual property problems associated with creating such a corpus, even for research and evaluation. In the United States a published work (such as a Web page) is automatically copyrighted under the law, even if the copyright is not registered. However, works of the US federal government are considered to be publicly financed and hence their content in the public domain (not copyrightable). For this reason, the TREC Web track uses urls and pages taken from the .gov domain in order to prepare a
Web corpus for research and evaluation purpose. Whether this unrestricted usage by the public will hold for other countries is a matter of some question. CLEF has now begun discussion on the creation of a mul-tilingual comparable Web corpus, by following the TREC example and spidering government sites of a number of European countries for a set of specific sectors such as health, social security, education, etc. but first will need to investigate eventual copyright issues. 5.4. Fundamental CLIR models and outstanding problems
Both Jian-Yun Nie (2002) and Mayfield and McNamee (2002) have suggested that drawbacks of current research in CLIR have stemmed from a haphazard approach to the problem, including the separation of the translation process from the retrieval process, and the difficulty of addressing results merging from monolingual retrieval results for multiple languages. Nie suggested that in a unified approach to CLIR, the translation process and the retrieval process would incorporate (a) the word distribution knowledge in both source and target languages and (b) the uncertainty of translation ( Nie, 2002 ). The paper by Xu and Weischedel in this issue presents a start at a unified model for CLIR which incorporates the translation uncertainty into the retrieval process, but not the word distribution in the target collection, nor the merging problems (their paper deals with bilingual search). Incorporation of word distribution has been suggested as Pirkola  X  s method, which has been used by a number of researchers ( Pirkola, 1998 ). The problem of merg-ing is a special case of the problem of retrieval from distributed collections; an example of experiments made on different merging methodologies for the CLEF collections can be found in Chen and Gey (2004) . 6. A 5 year plan for CLIR research
At the workshop, Mayfield and McNamee (2002) proposed a 5 year plan for CLIR research which cov-ers the following areas: tools, standards, resources (both aligned corpora and bilingual dictionaries as well as multilingual ontologies), multiple modalities and media and Web corpora (see Table 3 ).

This ambitious plan seems to be a good strawman proposal for the next generation of cross-language research. It will require both commitment and funding to become a reality.
 References
