 Abhishek Kumar abhishek@cs.umd.edu Hal Daum  X e III hal@umiacs.umd.edu Multi-task learning is concerned with simultaneously learning multiple prediction tasks that are related to one another ( Caruana , 1997 ; Thrun &amp; Pratt , 1998 ). The hope is that common information relevant to pre-diction can be shared among these tasks and learning them jointly can result in better generalization per-formance than independently learning each task. The key aspect in all multi-task learning methods is the introduction of an inductive bias in the joint hypoth-esis space of all tasks that reflects our prior beliefs about task relatedness structure. Assumptions that task parameters lie close to each other in some ge-ometric sense ( Evgeniou &amp; Pontil , 2004 ), or parame-ters share a common prior ( Yu et al. , 2005 ; Lee et al. , 2007 ; Daum  X e III , 2009 ), or they lie in a low dimen-sional subspace ( Argyriou et al. , 2008a ) or on a mani-fold ( Agarwal et al. , 2010 ) are some examples of intro-ducing an inductive bias in the hope of achieving better generalization. A major challenge in multi-task learn-ing is how to selectively screen the sharing of informa-tion so that unrelated tasks do not end up influencing each other. Sharing information between two unre-lated tasks can worsen the performance of both tasks. This phenomenon is also known as negative transfer . In this paper, we propose a structured prior on the tasks X  weight matrix (whose columns are parameter vectors for individual prediction tasks) that allows for-mation of groups of related tasks with partial overlap among the groups. Two tasks can have full, partial or no overlap, which is determined by number of basis tasks they share. We use the term task to refer to the actual prediction problem. We will use the term task weight or parameter vector to refer to the parameters of the model learned from training data.
 A starting point for our method is the assumption that task parameters lie in a low dimensional sub-space ( Argyriou et al. , 2008a ). This is achieved by imposing a trace-norm constraint on the task weight matrix. However, the low rank assumption does not differentiate between the tasks and assumes that all tasks are related, which may adversely affect the per-formance when there are unrelated tasks in the pool, or some tasks have more in common than others. One way to address this problem is to assume that there are disjoint groups of tasks. Examples of such approaches are ( Jacob et al. , 2008 ; Xue et al. , 2007 ) where tasks are assumed to be clustered and parameters of tasks within a cluster lie close to each other in  X  2 norm sense. Our proposed method does not regularize based on the  X  2 distance between task parameters which can fail to take advantage of negative correlation between the tasks. For example, grouping on the basis of  X  2 dis-tance can put two tasks with parameters w and  X  w in separate clusters and block the sharing of information between them while there is clearly a relation between the tasks, i.e., the span of these two parameter vec-tors is one dimensional sub-space instead of being a two dimensional space. An inductive bias that regu-larizes based on the subspace assumption could have exploited the task relatedness of this sort. We do not assume disjoint groups and allow partial overlap be-tween them.
 Recently, task grouping in the subspace based regular-ization framework was proposed in ( Kang et al. , 2011 ). Tasks are assumed to form disjoint groups and the tasks within each group are assumed to lie in a low di-mensional subspace. The parameters of tasks and the group assignment matrix are both learned using alter-nating style optimization that converges to a local min-imum. However, the subspaces shared by each group do not have any overlap between them, which may not always reflect the true sharing structure since there is often a continuum in the sharing between tasks. One pair of tasks may have more in common than another task pair and we may not be able to take full advan-tage of multi-task learning by putting the two tasks in the second pair in different groups.
 In our model, we assume that task parameters within a group lie in a low dimensional subspace, and allow two tasks from different groups to overlap by having one or more bases in common. This is achieved by as-suming that there exist a small number of latent basis tasks and parameter vector of every observed task is a linear combination of these. If the columns of L denote the parameter vectors of k latent tasks, we model the parameter vector w t of observed task t as w t = Ls t , where s t contain the coefficients of the linear combi-nation. However, each linear combination is assumed to be sparse in the latent bases and the overlap in the sparsity patterns of any two tasks controls the amount of sharing between these. The low dimensional sub-space assumption of ( Argyriou et al. , 2008a ) can also be thought of having a small number of latent basis tasks, however each observed task is determined by a full linear combination of these bases and there is no notion of task groups. To be more clear about the dif-ference, if there are k latent tasks and we pick r (  X  k ) observed tasks arbitrarily, the corresponding weight matrix of these tasks will be of rank r in the model of ( Argyriou et al. , 2008a ). On the other hand, our model allows this matrix to be of rank less than r by imposing sparse structure on the linear combination weights. We validate our approach empirically with two synthetic and four real-world datasets and observe that our method either outperforms or performs as well as the relevant baseline methods of ( Kang et al. , 2011 ; Argyriou et al. , 2008a ). Several methods have been proposed in the literature for the problem of multi-task learning. Most meth-ods work on the assumption that all tasks are re-lated ( Evgeniou &amp; Pontil , 2004 ; Ando &amp; Zhang , 2005 ; Argyriou et al. , 2008a ; Rai &amp; Daum  X e III , 2010 ). This assumption can be violated in many real applications and can degrade the performance. To avoid this, sev-eral methods have been proposed to allow for grouping of the tasks using different notions of grouping. Some methods assume that tasks can be grouped in clusters and parameters of tasks within a cluster are either close to each other in some distance metric or share a common probabilistic prior ( Bakker &amp; Heskes , 2003 ; Jacob et al. , 2008 ; Xue et al. , 2007 ; Zhou et al. , 2011 ). Tasks in different clusters do not interact with one an-other. However, these methods might fail to take ad-vantage of negatively correlated tasks since they can put these in different clusters. A similar idea was used in ( Thrun &amp; O X  X ullivan ), where two tasks are taken to be similar if one X  X  parameters improve performance on the other task.
 Other methods assume that there is one group of re-lated tasks and a small number of outlier tasks that are not related to any task in the pool ( Yu et al. , 2007 ; Chen et al. , 2011 ). There also exist probabilis-tic models which attempt to learn full task covariance matrix and use it in learning of predictor functions ( Zhang &amp; Yeung , 2010b ; a ; Zhang &amp; Schneider , 2010 ; Archambeau et al. , 2011 ). These methods place a ma-trix variate prior on the task matrix W .
 Another common assumption is that task parameters lie in a low dimensional subspace that captures the predictive structure for all the tasks ( Argyriou et al. , 2008a ; Liu et al. , 2009 ). These methods assume that some of features (either in original space, or in a trans-formed space) are inactive for all tasks. This forces all task parameters to lie in a low dimensional subspace. In ( Jalali et al. , 2010 ), this model was refined and fea-tures are assumed to be either active for all tasks, or inactive for most of the tasks. This is done by forcing W to be sum of a group sparse matrix and a sparse matrix, hence predictors no longer lie in a low dimen-sional subspace.
 There exist a few methods that incorporate group-ing structure in the subspace based regulariza-tion ( Argyriou et al. , 2008b ; Kang et al. , 2011 ). In ( Argyriou et al. , 2008b ), tasks in each group share a common linear transformation for feature extraction. It is shown to be equivalent to minimizing the trace-norm of each groups X  weight sub-matrix. The objec-tive is non-convex and it is optimized using stochastic gradient descent. Very similar in spirit is the work of ( Kang et al. , 2011 ), where tasks within a group are assumed to lie in a low dimensional subspace and they minimize the square of trace-norm of each group X  X  weight sub-matrix (instead of trace-norm as in ( Argyriou et al. , 2008b )). The non-convex objec-tive is optimized using mixed integer programming. Both these methods assume that groups are disjoint and tasks are either related (within a group) or totally unrelated (in different groups). This is in contrast to the approach proposed in this paper, where the low dimensional subspace shared by group members is not exclusive to it, and two tasks from different groups are allowed to overlap in one or more bases. Intuitively, this means that some of the latent basis tasks influence more than one group. Recently, ( Passos et al. , 2012 ) posited a mixture of sparse factor analyzers structure on the collection of the task weight vectors. Their model assumes that the tasks form clusters and tasks within each cluster are a sparse combination of a task dictionary specific to that cluster. A nonparametric Bayesian approach is used to learn the number of clus-ters and the task dictionary sizes from the data. The task clusters do not have overlap in task dictionary elements. In this Section, we describe our approach for model-ing task grouping and overlap. We call the proposed approach as GO-MTL for Grouping and Overlap in Multi-Task Learning. Suppose we have T tasks and Z for each task t = 1 , 2 , . . . , T . Let w t represent the weight vector for task indexed by t . These task weight vectors are stacked as columns of a matrix W , which is of size d  X  T , with d being the feature dimension. We assume there are k ( &lt; T ) latent basis tasks and each observed task can be represented as linear com-bination of a subset of these basis tasks. This as-sumption enables us to write the weight matrix W as W = LS , where L is a matrix of size d  X  k with each column representing a latent task, and S is a matrix of size k  X  T containing the weights of linear combination for each task. The predictor w t for task t is given by Ls t , where s t is t  X  X h column of matrix S . We assume the matrix S to be sparse to enforce that each observed task is obtained from only a few of the latent tasks, indexed by the non-zero pattern of the corresponding column of matrix S . The predictive structure of the tasks is captured by the matrix L and the grouping structure is determined by matrix S . For two columns s t , the overlap between the sparsity patterns deter-mines the number of basis tasks they have in common. Tasks that have same sparsity pattern can be seen as belonging to same group , while tasks whose sparsity patterns are orthogonal to each other can be seen as belonging to different groups. The partial sharing of bases allows us to do away with the concept of dis-joint groups, and allows to model tasks which are not as much related as they are with tasks in their own group but which still have something in common. The task that does not share bases with any other task in the pool can be seen as outlier task .
 If s t denotes the sparsity pattern for task t , our learn-ing cost function takes the following form: where L ( , ) is the empirical loss function, || || 1 is entry-wise  X  1 norm of the matrix and || L || F = ( tr ( LL  X  )) 1 / 2 is the Frobenius norm of matrix L . The parameter controls the sparsity in S . The penalty on the Frobenius norm of L regularizes the predictor weights to have low  X  2 norm and avoids overfitting. For a convex empirical loss function, the cost function in Eq. 1 is convex in L for a fixed S , and is convex in S for a fixed L , however, it is not jointly convex. We adopt alternating optimization strategy that converges to a local minimum. For a fixed L , the optimization function can be decomposed in individual problems for s as s t = arg min We use two-metric projection method to opti-mize Eq. 2 , which has superlinear convergence ( Schmidt et al. , 2007 ; Gafni &amp; Bertsekas , 1984 ). For a fixed S , the optimization problem reduces to follow-ing: This problem is convex in L and has a closed form solu-tion for squared loss function, which is commonly used in regression problems. For classification problems, we use logistic loss and optimize it using Newton-Raphson method, which is commonly used to estimate logis-tic regression parameters and is the basis of iterative reweighted least squares algorithm (IRLS) algorithm for logistic regression ( Green , 1984 ). We also experi-mented with steepest gradient descent and found it to work reasonable well on all datasets that we tried. Algorithm 1 outlines the steps and initialization pro-cedure for our approach. We adopt the following strat-egy for initializing L . The individual task parameters Algorithm 1 GO-MTL: Grouping and Overlap for Multi-Task Learning Input:
Z t : Labeled training data for all tasks k : Number of latent tasks
Output: Task predictor matrix W , L and S . 1: Learn individual predictors for each task using only its own data. 2: Let W 0 be the matrix that contains these initial predictors as columns. 3: Compute top-k singular vectors: W 0 = U X V T 4: Initialize L to first k columns of U . while not converged do end while 9: Return outputs: L = L old , S and W = L old S . are learned independently using their own data with-out any sharing, which are then stacked as columns in a weight matrix W 0 . The matrix L is then initial-ized to the top-k left singular vectors of W 0 . These are the directions that capture maximum variance of task parameters in a k -dimensional space. This ini-tialization strategy was observed to be effective in all our experiments. The alternating optimization proce-dure is terminated when there is little change in L or S between two consecutive iterations.
 The parameter k determines the number of latent tasks, which is taken to be less than total number of tasks T . The amount of inductive bias depends on this number. In this respect, it is similar to the  X  X umber of groups X  parameter, G , in ( Kang et al. , 2011 ). If k is very low, it may shrink the hypothesis space too much. On the other hand, if k is very high, the tasks are not forced to share information with each other. When we increased the value of k in the experiments starting from 1, the prediction accuracy improves in the beginning. After a certain value of k , the per-formance becomes stable and the possible decrease in performance due to large k can be controlled by in-creasing the sparsity penalty . More details on this behavior are provided in Sec. 4 .
 It is possible to have an alternative formulation to Eq. 1 where we can do away with parameter k (i.e., make it equal to T ), and instead enforce a low rank penalty on matrix L , weighted by a parameter  X  . This can be done by penalizing the nuclear norm of L , which is the tightest convex lower bound on the rank func-tion in the unit ball of matrices (i.e., matrices with spectral norm less than one). However, there are two disadvantages to this approach: (a) this convex surro-gate is not always guaranteed to produce a low rank solution, and (b) this will result in a non-smooth opti-mization problem for L due to non-smoothness of the nuclear norm. 3.1. Regression: Squared Loss Here, we give details about optimization of the cost function of Eq. 1 for squared loss L ( a, b ) = ( a  X  b ) commonly used in regression problems. Let us denote y t to be a column vector of length N t that contains all the labels for task t . Similarly, let X t be the data matrix of size d  X  N t containing all the samples for task t stacked as columns. The cost function of Eq. 1 can be written as, min For a fixed L , we need the gradient and Hessian of the squared loss function f ( s t ) = 1 N optimize for s t using two-metric projection method. These are given as  X  s and  X  2 s the gradient of Eq. 4 to zero gives This is a linear equation in L . To solve this, we ap-ply vectorization operator on both sides, which simply stacks all columns of a matrix one above another and forms a long vector. Clearly, this is a linear operator and can pass through the summation, and we obtain
X where we have used a property of Kronecker product that vec( AXB ) = ( B  X   X  A )vec( X ). This is in stan-dard form of system of linear equations that is full rank and has a unique solution. It can be solved using LU decomposition or by iterative methods, which are much faster and numerically more stable then solving it using matrix inverse. 3.2. Classification: Logistic Loss We use logistic regression for classification problems, although the proposed method is not tied to any par-ticular loss function. Here, we give details about opti-mizing Eq. 1 for logistic loss function, which is given as L ( y, f ( x )) = log(1 + exp(  X  yf ( x ))), where y  X  { X  1 , 1 } is the true label. Let us denote the logistic function by  X  ( x ) = 1 / (1 + e  X  x ). For a fixed L , we need the gradient and Hessian of the loss function w.r.t. s t to solve using two-metric projection method, which are given by where w t = Ls t is the weight vector for task t . For a fixed S , the objective is again convex in L and we give both gradient update and Newton-Raphson up-date here. For Newton-Raphson update, we use Taylor series ex-pansion up to second order around L , making use of directional first and second derivatives. The step di-rection M is obtained by solving the following system of linear equations:
X where  X  ti =  X  ( w  X  t x ti )(1  X   X  ( w  X  t x ti )). The Newton-Raphson update is then carried out by taking a step in this direction. The step size is computed using Armijo rule.
 Newton-Raphson updates, although more costly to compute, can converge in a smaller number of iter-ations. Gradient updates also seemed to work reason-ably well in the experiments. This can be considerably faster than Newton-Raphson, especially for large prob-lems, since Newton-Raphson involves solving a system of linear equations of size dk multiple times for every iteration of L . We perform extensive empirical evaluation of our ap-proach to gauge its effectiveness. We carry out empir-ical comparisons with following two competing sub-space regularized multi-task learning approaches:  X  No-group MTL ( Argyriou et al. , 2008a ) : All  X  Disjoint-Group MTL (DG-In addition, we also compare with baseline single task learning (STL) , in which tasks are learned indepen-dently. Below, we report results on two synthetic and four real-world datasets. The regularization parame-ter  X  in Eq. 1 is kept fixed at 0 . 1 in all experiments. We expect  X  to depend on the dimensionality of the space and number of examples. Incidentally, all the real-world datasets used in this work have dimension-ality less than 100, for which  X  = 0 . 1 seemed to work well. Of course, it can always be selected using cross-validation. We generate four different random splits (70% train, 30% validation) on the training set for cross-validation of parameter . The search grid was Averaged performance for different splits is reported. 4.1. Synthetic data We use two synthetic datasets to study our approach. First, we use the synthetic data used in ( Kang et al. , 2011 ). 1 This data consists of 20-dimensional feature vectors, three groups of tasks, 15 training points and 50 test points per task. There are 10 tasks in each group whose parameter vectors are identical to each other up to a scaling factor. These parameters are used in the model of linear regression to generate training data. The task groups in this data are disjoint. We generate a second synthetic dataset to simulate overlap in groups. We retain the previous setting of 3 groups and 10 tasks in each group, but now we allow the groups to overlap in one basis. We generate param-eter vectors for 4 latent tasks in 20 dimensions, with each entry drawn i.i.d. from a zero mean and unit variance normal distribution. This is essentially the matrix L in our formulation. We generate the first 10 tasks by linearly combining only first two latent tasks. The coefficients of linear combination are drawn i.i.d. from a normal distribution centered at zero with unit variance. In a similar manner, we generate the next 10 tasks by linearly combining second and third latent tasks. Last 10 task parameters are generated by linear combination of the last two latent tasks. The matrix S in our formulation that contains the coefficients of lin-ear combination, has precisely two non-zero entries in each column for this generative model. We randomly generate 15 training and 50 test points per task, and task parameters are used to generate their real valued labels using a linear regression model. Random Gaus-sian noise with zero mean and 0 . 5 standard deviation is added to the labels.
 The plot of root mean square error (RMSE) with changing k is shown in Fig. 1 and Fig. 2 . We also show the RMSE plot with changing value of pa-rameter G (the number of groups) in the approach of ( Kang et al. , 2011 ). GO-MTL converges to almost same RMSE for all values of k  X  3 for first synthetic data and k  X  4 for the second synthetic data. The performance of ( Kang et al. , 2011 ) is more sensitive to the number of groups parameter ( G ) and starts deteriorating when it is increased or decreased from the true value. The proposed approach outperforms disjoint-group MTL by a significant margin, more so on the second dataset that has overlap in groups. Ta-ble 1 shows the exact RMSE values obtained for these datasets.
 The sparsity patterns recovered by GO-MTL for these two data are shown in Fig. 3 and Fig. 4 . We are able to recover the grouping and overlap structure for most of the tasks in both cases. For the second synthetic data (Fig. 4 ), support of first 10 and last 10 tasks is recovered more precisely than the support of the middle group, where a few tasks (for example, 11th, 15th and 16th task) have non-negligible coefficients not belonging to the true support. The recovery of support was found to be robust to the value of k chosen in the algorithm, as is shown in the figures. We are able to recover the support with same precision for values of k  X  3 for the first data and values of k  X  4 for the second data. 4.2. Real datasets We evaluate the proposed approach on the follow-ing four real-world datasets, two of which are regres-sion tasks and the other two are classification tasks. We treat multi-way classification as multi-task learn-ing problem where each task is the classification of one class from all other classes. To be fair in our comparisons, we evaluate on datasets that are used in ( Argyriou et al. , 2008a ; Kang et al. , 2011 ).  X  Computer Survey data: This regression  X  School data: This regression data has been  X  USPS Digits data: This is a handwritten digits  X  MNIST Digits data: This is another handwrit-For MNIST and USPS datasets, we use the same setup as in ( Kang et al. , 2011 ) where 1000, 500 and 500 sam-ples are used for training, validation and test respec-tively. The results are summarized in Table 1. All multi-task learning approaches are able to outperform single task learning, however on School data, the im-provement is not statistically significant. The pro-posed method is able to outperform both no-group MTL and disjoint-group MTL. We proposed a novel framework for learning grouping and overlap structure in multi-task learning, where pa-rameters of each task group are assumed to lie in a low dimensional subspace. Our approach does not as-sume disjoint grouping structure, and tasks belonging to different groups are allowed to overlap with each other through sharing of one or more latent basis tasks. This is a more realistic assumption since we can have tasks in our pool that are not related enough to be in the same group, but still share some information that can be exploited for better learning. We validated our model on two synthetic and four real datasets, and obtained considerable gains compared to other com-peting approaches for subspace regularized multi-task learning that either do not take grouping structure into account, or assume that tasks in different groups do not interact at all. For future work, we would like to extend the proposed model to learn other types of structured interaction patterns among the tasks, e.g., hierarchies of tasks.

