 1. Introduction Recently many researches have paid attention to content-based image retrieval (CBIR) ( Bimbo, 1999; adapt to the diversity of image contents. However, the selection of appropriate features for CBIR remains largely ad hoc and application dependent ( Datta, Li, &amp; Wang, 2005 ). Many approaches focus on the image contents like color ( Deng, Manjunath, Kenney, Moore, &amp; Shin, 2001; Lu &amp; Chang, 2007; Mojsilovic, Hu,
Taking color content as example, some systems use color features by global color histograms (GCH) to cal-culate the percentages of each predefined color of the image pixels. Some systems combine the color distribu-tion and its associated spatial information. For example, in the work of Yoo et al. (2006) and of Lu and Chang (2007) , the color and its spatial layout within an image are used as features for retrieval.
Besides these low-level features, the perception of contained objects and the spatial patterns held among include pattern recognition, image processing, computational geometry, geographic information systems, diagnostic medical imaging ( El-Naga, Yang, Galatsanos, Nishikawa, &amp; Wernick, 2004 ), and real estate mar-keting ( El-kwae &amp; Kabuka, 1999 ). Images are usually preprocessed, semi-automated or manually ( Petrakis, 2002 ), by the assistance of segmentation or symbol recognition techniques such as the methods proposed by Chen, Pappas, Mojsilovic, and Rogowitz (2005) and Djordjevic and Izquierdo (2007) to recognize and cat-
Gandhi, 2006; Djordjevic &amp; Izquierdo, 2007 ). Then each object is represented by a class symbol or an icon
Object-based retrievals are cornerstones of semantic-based image retrieval systems because usually human beings perceive objects as more semantically meaningful than low-level features of surrounding elements ( Djordjevic &amp; Izquierdo, 2007 ). Although the preprocessing of an image may be time consuming, the proce-dure is performed only once for an image and the result of transforming an original image into a symbolic image has many advantages. Retrievals upon symbolic images are time and storage efficient compared to deal-symbolic images are called symbolic image databases (SIDs).

Basically, there are three types of CBIR by object-level spatial constraints: exact match retrieval, subimage identical to the query image. A retrieved image I db must have the same object set as the query I polynomial time complexity. The common techniques employed by these methods are first extract the spatial features from every two or three objects in an image, and then attain a value, a vector, or a compound struc-itate logarithmic-time searches, which use the representative of the query image as the searching key.
Subimage retrieval allows some unmatched objects exist in the database image, that is, the task of this kind answers ( X  X  X es/no X  X ). Among these approaches, the 2D string model proposed by Chang, Shi, and Yan (1987) affords a simple and compact representation of symbolic images. The indexed objects in an image can be rep-resented by two symbol strings according to their projections along x -axis and y -axis. Besides the object-matching methods, some algorithms ( Chang &amp; Lee, 1991; Guru, Punitha, &amp; Nagabhushan, 2003 ) hash or tain this query image, that is, contain all features of the query image.

Similarity retrieval is the kind of retrieval which allows unmatched objects in both the query image and a query image, hence two images have some common objects and similar spatial arrangements of objects. A sim-images from a SID. The first type of similarity function is the maximum common subimage function which returns the number of objects in the maximum common subimage between the query image and a database image such as method LCS_Clique proposed by Lee, Shan, and Wang (1989) . A common subimage between two symbolic images is defined as that its objects appear in both images and the spatial arrangement of these objects are similar in both images. The LCS_Clique algorithm transforms the matching problem to the max-imal complete subgraph (clique) problem (hence referred to as LCS _ Clique hereafter). This method performs a straightforward and effective approach for similarity retrieval. However, finding the maximum clique in order to calculate the similarity of two images is an NP-hard problem. Hence LCS_Clique is not suitable for a data-base of images having large numbers of contained objects ( Ahmad &amp; Grosky, 2003 ). that come from all corresponding object pairs in both images. The algorithms are such as SIM and Raghavan (1995) and SIM DTC by El-kwae and Kabuka (1999) . If the object symbols are exclusive within an image, the time complexity is quadratic in terms of the number of objects, because the efforts are to accu-because all possible object matching between two images need to be calculated in order to find the maximum accumulated value. If not all possible matching are considered, the randomly or greedily selected associations may lead the results far from optimal. 2D Be-string proposed by Wang (2003) is a variant of 2D string , and this method reduces the computational demands by avoiding the two-dimensional geometry calculations. Instead, two independent one-dimensional of these two 1D results. However, the effectiveness is not verified that some potential inaccuracy may occur.
When the spatial relations between two objects along one axis are the same in the two images whereas those calculations. By a real 2D geometry computation, this pair of objects will be deemed less contribution.
Object attributes can also be used for retrieval as well as object symbols. A well-known model returns the editing distance of two attributed relational graphs (ARG) correspond to two symbolic images as similarity vertices in the corresponding ARG and their relationships are represented as arcs between such vertices. The attributes of objects and the relations between object pairs are the vertex and edge labels, respectively.
The similarity degree is the minimum editing distance from one ARG to the other, and the edit operations needs to search a state-space tree for all promising edit sequences, thus the time complexity is exponential.
Besides, a system designed by Sung and Hu (2006) integrates object text description, object color, object &amp; Elschlager, 1973 ) to perform object matching between two images.

Actually, about the time complexity nature of similarity retrievals, Guan, Chou, and Chen (2000) proved that calculating the similarity degree by finding the maximum common subimage of two given symbolic images is NP-complete. Hence the contribution of the proposed work CPM is the designing of a novel data structure and algorithms to perform the similarity calculation between two symbolic images with more efficiency and effectiveness in real-life datasets, instead of breaking the theoretically worst-case time complexity limit.
In this paper, we propose a new method for similarity retrieval in SIDs. This approach employs a data structure named Common Pattern Directed Acyclic Graph (CP_DAG), therefore the proposed method is named CPM for Common Pattern Method . The main contributions of CPM are: 1. By constructing CP_DAG graphs, in which common spatial patterns are retained, CPM is efficient in prac-tice. We derived a constraint that bounds CPM in polynomial-time complexity for the cases that satisfy a prerequisite. From the experimental results, we found that the prerequisite is satisfied by almost all the observed cases. 2. CPM outperforms LCS_Clique method up to 30-fold speed-up on average. For images with larger numbers of objects, the efficiency gain is even more significant (up to one million fold). It also achieves efficiency improvements over SIM R ,SIM DTC , and 2D Be-string for most situations under a synthetic dataset, and it is 8 X 10 times faster on average under an existing dataset. 3. CPM considers the attributes of objects as well as the spatial similarity formed by the common objects.
These object attributes include object color and object size, which can be extended to consider more other object descriptions, by using the same CP_DAG graphs. From the experimental results, CPM achieves higher or compatible retrieval qualities with stable and acceptable efficiency when the number of objects and the symbol duplication rates increase, compared with the aforementioned methods.

The rest of this article is structured as follows. We first describe the 2D string approach and four compared methods briefly in the next section. In Section 3 , the proposed method is presented with the analysis of time complexity. Section 4 presents the results of the conducted experiments with a synthetic dataset and a well-known image database. The conclusion is stated in the last section. 2. Background and related work of similarity retrieval 2.1. 2D Strings 2D string is a remarkable data structure for spatial reasoning, and its definitions and notations are widely 1990 ), and 2D Be-string ( Wang, 2003 ). Since the proposed method CPM is an extension and improvement of
LCS_Clique, the fundamental facts about 2D strings need to be introduced as the building blocks. Fig. 1 depicts an original image and its corresponding symbolic image. There are seven recognized objects in this image and their centroids locate in one of the 4  X  4 positions.

For simplicity of description, we represent a 2D string by a = a ( A )&gt; x _ rank ( B ), and if object A is to the north of object B then y _ rank ( A )&gt; y _ rank ( B ).
Example 1. The 2D string of images in Fig. 2 ais a = ABEDHCF . For object E in image f an object can be considered as one plus the number of x -positions with object projections before this object. between them in the x -axis projection. The analogous properties are also held along y -axis.
Let A be the symbol assigned to an object with x -rank a and y -rank b , we can denote this object by in two images in terms of ranks as Definition 1 .

Definition 1. (type-i similarity)Let [ A ,( x 1 , y 1 )] and [ B ,( x [ B ,( a 2 , b 2 )] two objects in f 2 . Also let D x = x as follows: type-0 : D x D a P 0 and D y D b P 0. type-1 : X  X  D x D a &gt;0or D x = D a = 0 X  X  and  X  X  D y D b type-2 : D x = D a and D y = D b .

Example 2. Consider object A and object D of both images in Fig. 2 , they can be denoted as [ A ,(1,4)], image f 1 , which equals the difference of the two corresponding objects in image f of y -ranks of these two objects (3 X 4) in f 1 equals the difference in f the type-2 checking (and also type-1 and type-0 ).
 the meaning of type-i similarity easier, we say that type-1 criterion depicts two object pairs in both images possessing the same directional relations. The directions include north, north-west, west, south-west, south, south-east, east, and north-east. As an example of Fig. 2 , object D is north-west of object H in both images. differ within one direction. Another example of Fig. 2 , object A is south-west of object E in f identical but the rank differences must also be the same. Hence the two E-D pairs in f type-1 similarity is the most commonly used criterion ( Petrakis et al., 2002 ). 2.2. LCS_Clique
This method, based on 2D strings and proposed by Lee et al. (1989) , defines the similarity degree of two images as the number of objects in the maximum common subimage. The objects in the common subimage of two symbolic images also form a common subsequence between the two corresponding 2D strings.
Definition 2. (common subimage of type-i ) Let S be a subset of objects in image f in f 2 . Then S and T are type-i ( i = 0, 1, 2) common subimage of f
S to T such that: 1. For every object O i in S , the symbol of O i equals the symbol of g ( O 2. For any object pair O i and O j in S , O i and O j in f respectively.

Example 3. Consider objects A , B (choose [ B ,(3,1)] in f form a type-1 common subimage of f 1 and f 2 .

LCS_Clique determines the maximum common subimage of two symbolic images by constructing a type-i graph and finds the maximum clique of this graph. Given two 2D strings a = a symbolic images f 1 and f 2 , respectively, a match entry  X  object b j in f 2 if a i = b j ( a i and b j with the same class symbol). The steps of this algorithm are: Step 1: For each match entry  X  i , j , make a vertex ( i , j ) in this graph.
 type -i rank checking defined in Definition 1 . Step 3: A common subsequence is a set of vertices in which each pair of vertices has an edge between them. The longest common subsequence is the clique of the graph.

Example 4. Fig. 3 shows the match table and the constructed type-1 graph of the two images in Fig. 2 . There find four maximal cliques ( ABD , ADH , BED , EDH ) each with three vertices. Pattern ABD depicts that these three objects possess the similar spatial relations in both images and they form the common subimage of three objects. The sequence ABD is also the common subsequence of two 2D strings a = AB ED HCF and b = CAB ED FHB . The similarity degree of these two symbolic images is 3, which is the number of vertices in the maximal clique.
 possible matching of object a i in f 1 and object b j in f such a graph. Also notice that all the match entries are included in such a graph as vertices. 2.3. SIM R and SIM DTC
Another similarity-based retrieval method SIM R was proposed by Gudivada and Raghavan (1995) . The similarity degree of a database image with respect to a query image is obtained by calculating the closeness between two edge lists of these two images. An edge is represented by a pair of objects and the angle of are ( A , B ,300 ), ( A , C ,330 ), and ( B , C ,45 ). To compare a database image I to find the corresponding edge e j of I db for each edge e
Example 5. Consider Fig. 4 with f 3 as query image and f 4 and three corresponding edge pairs, and their contributions (1 + cos h exclusion is released (multiple objects with the same symbol are allowed), we need to compute the similarities under all the mapping methods in order to find the maximal similarity as the final answer.
An extension method SIM DTC by El-kwae and Kabuka (1999) assesses similarity between two images by three factors: the directional relations as in SIM R , the number of common objects between two images, and angle (RCA) was introduced to obtain a more accurate assessment of spatial similarity with rotation invariance. 2.4. 2D Be-string 2D Be-string ( Wang, 2003 ) processes two one-dimensional strings separately and combines the results into the 2D similarity. In this method, an object is represented by its minimum bounding rectangle (MBR) with four boundary symbols: the begin boundaries and the end boundaries along x -and y -axis, respectively. To make the according to their coordinates. A dummy symbol is inserted between each two consecutive boundary symbols unless the coordinates of two boundary symbols are identical. Hence an image with n objects has two 1D strings each with about 4 n symbols along two axes. To calculate the x -axis one-dimensional longest common subsequence (1D LCS) between two images, a modified dynamic-programming method is employed which needs to compute about 16 mn cells, where m and n are the numbers of objects of two images. The x -axis time complexity of this method is quadratic in terms of the number of objects in the images, and the compu-tational work include sorting four 1D strings (two axes for two images) and performing two separate table calculations for two axes. 3. The proposed method
The proposed method CPM uses object-level spatial patterns and object attributes (object color and size) as features to discriminate images. The main theme of CPM is to represent a clique in LCS_Clique algorithm with a path in CP _ DAG (recall that a clique in an LCS_Clique graph is a common spatial pattern between two images). CPM is a dynamic-programming-based method, and its key is the usage of CP _ DAG graphs to  X  X  X emember X  X  previous results (smaller patterns). When adding another vertex, the path is expanded only if the new vertex passes the type-i spatial checking. Before introducing CPM algorithm, the construction pro-of CPM is only the number of objects in the maximal common subimage as that of LCS_Clique. We will explain the actual similarity function of CPM after the construction part is introduced. 3.1. The construction of CP_DAG graphs
A CP_DAG is a directed graph that contains common spatial patterns as its paths. CP_DAG graphs can be interpreted as follows. A vertex stands for a possible matching of two common objects in both images. Besides, apathwith n vertices corresponds to n objects in both images with the similar spatial layout. For example, the of B ) in both f 1 and f 2 of Fig. 2 .

Given two symbolic images f 1 and f 2 with n 1 and n 2 objects, respectively and the two corresponding 2D table. Fig. 5 shows the constructed CP _ DAG graphs in the comparison of images f and steps of constructing CP _ DAG ( i , j ) are as follows: j = 1) on the match table. The examples are CP _ DAG (1,2) in Fig. 5 aand CP _ DAG (6,1) in Fig. 5 g. entry  X  k , h in the left upper part ( k &lt; i and h &lt; j ) is  X  X  X ype-i checked X  X  with  X 
For example, when constructing CP _ DAG (4,5) in Fig. 5 e,  X   X  4,5 . At this time, CP _ DAG (3,4), CP _ DAG (2,3), and CP _ DAG (1,2) are already constructed. This step is to verify whether  X  i , j can be added to the built patterns to grow the patterns by one more object  X  expandable patterns for  X  i , j . Then Temp _ DAG ( k , h ) is merged into CP _ DAG ( i , j )toadd  X  (the processes of making and merging Temp _ DAG ( k , h ) will be explained later). the largest spatial patterns concerning match entry  X  i , j
In summary, CP _ DAG ( i , j ) is made of  X  i , j and the discovered patterns that can be grown by  X  including them (by merging Temp _ DAG ( k , h )), for each built CP _ DAG ( k , h ), k &lt; i and h &lt; j . 3.1.1. Making Temp_DAG (k,h)
Each path in Temp _ DAG ( k , h ) for  X  i , j is a spatial pattern that can be joined with  X  making Temp _ DAG ( k , h ) from CP _ DAG ( k , h ) is to obtain the expandable patterns with respect to  X  proper  X  X  X ondensing X  X , if the condensed path has more than one vertex. We first do type-i checking with  X  tices originally on p x to make them as path p y . Hence the length of p lowed by some processing examples in Examples 6 and 7 .

Hence only four vertices are in Temp _ DAG ( k , h ) as depicted in Fig. 7 b. When investigating path p p are given a new path identifier, say p 5 , and only two arcs left: from ( k , h )to v intermediate result is as shown in Fig. 7 c. The same rule applied to paths p
Fig. 7 d. Path p 3 is not remained since it coincides with path p vertices except ( k , h ) are on path p 4 , this path is not in Temp _ DAG ( k , h ).
Example 7. Consider the process of making Temp _ DAG (4,5) from CP _ DAG (4,5) with respect to  X  steps are shown in Fig. 7 e X  X . At first we perform type-1 checking on the vertices of CP _ DAG (4,5) with  X  north-west of object H in Fig. 2 a, whereas object B (the third symbol in the 2D string of f ing p 3 , only arc from (4,5) to (1,2) with a new path id p from (4,5) to (3,4) with a new path id p 6 as in Fig. 7 h. 3.1.2. Merge Temp_DAG (k,h) into CP_DAG (i,j)
Since each path in Temp _ DAG ( k , h ) is a pattern ready to join with  X  DAG ( k , h ). The algorithm of merging Temp _ DAG ( k , h ) into CP _ DAG ( i , j )isasin Fig. 8 : arc from ( i , j )to( k , h ) is always added in both case.

Example 8. Fig. 9 a is a singleton Temp _ DAG (1,2) merged into CP _ DAG (2,3), an arc is added with a brand p from vertex (4,5) to (3,4). Fig. 9 c, which continues Fig. 9 b, shows how Temp _ DAG (2,3) is merged into labeled p 4 from (4,5) to (2,3), this final result is the same as in Fig. 5 e. 3.1.3. Properties of CP_DAG
We now conclude the properties of CP _ DAG graphs, and we will prove them in Section 3.3 (the statements below refer to Figs. 2, 3a, and 5 ): 1. CP _ DAG s are multi -graphs . Multiple arcs may exist between a pair of vertices.
A vertex ( i , j ) is a matching of object a i in f 1 and object b object symbol and vertex ( i , j ) is labeled this symbol. 3. An arc from vertex ( a , b ) to vertex ( c , d )ina CP _ DAG depicts that match entry  X  part of match entry  X  c , d on the match table, i.e., a &lt; c and b &lt; d , and  X  with  X  c , d . As an example, consider CP _ DAG (5,7) in Fig. 5 f. Vertex (5,7) with symbol H has an arc to vertex (4,5) with symbol D because in Fig. 3 a  X  4,5 locates in the upper left part of match entry  X  5 &lt; 7), and in Fig. 2 object D is north-west of object H in both f type-1 checking ). subimage with n objects of two symbolic images, i.e., these n objects form the similar spatial pattern in both images. type-i graph of LCS_Clique. 3.2. CPM algorithm
The CPM Algorithm is shown in Fig. 10 , and the whole process of calculating the similarity degree of two symbolic images is called a comparison .

Example 9. The eight type-1 CP_DAG graphs in Fig. 5 are produced in the comparison of images f vertices. These paths correspond to four 3-object common patterns ABD , BED , ADH , and EDH between f pattern ABD is first visit vertex (4,5) in Fig. 5 e, and move forward by the arc with label p then to vertex (1,2). The three vertices in this path is thus the pattern ABD .

The algorithm of making CP _ DAG ( i , j ) is shown in Fig. 11 , and the corresponding statements are presented in Section 3.1 . 3.3. Proofs of Theorems
Lemma 1. When constructing CP _ DAG(i,j), only the match entries  X  the match table (k &lt; i and h &lt; j) can appear in CP _ DAG(i,j).

Proof. Before proving this lemma, we need to recall some important facts previously stated. Firstly, a match entry  X  i , j is a matching of object a i in f 1 and object b  X  or the same column as  X  i , j cannot be type-i similar with  X  two objects in f 2 or one object in f 2 is matching two objects in f same horizontal positions and a k is north of a i ), and b to case 2, which cannot be true. Case 4 is symmetric to case 1, thus we only need to keep case 1. h Lemma 2. For an arc from vertex (i,j) to vertex (k,h) in a CP _ DAG, we have k &lt; i and h &lt; j. h &lt; j . h Theorem 1. CP _ DAG is acyclic.
 anti-symmetric property holds and no cycle exist. h
Theorem 2. A path in CP _ DAG(i,j) corresponds to a common subsequence between two 2D strings a b b 2 ... b j , which is also a common spatial pattern between the two images.

Proof. We prove this theorem by mathematical inductions on the lengths of the paths, and we start from a path with two vertices (one arc). Recall that when Temp _ DAG ( k , h ) is a singleton and  X  vertex ( i , j ) to vertex ( k , h ). Since  X  k , h and  X  with v vertices, these v objects constitute a common subsequence of v symbols. This means that all the v match entries in a path p x are mutually type -i similar. Now we add an arc also labeled p tices constitute a common subsequence accordingly, which also forms a common spatial pattern of v +1 objects. h 3.4. Time complexity analysis of CPM algorithm
Given two 2D strings a = a 1 a 2 ... a n 1 and b = b 1 b 2
The maximal number of vertices in a CP _ DAG is also n because the labels of all vertices do not duplicate within a CP _ DAG . Besides, the time needed for the two processes in making CP _ DAG ( i , j ), mak-the number of paths in CP _ DAG ( k , h ). As a consequence, the number of paths dominates the efficiencies of the construction of a CP _ DAG . From the constructing process of a CP _ DAG , the amount of paths in a the bound of the maximal amount of paths in a CP _ DAG under a prerequisite.
 amount of paths in this graph is bounded by n(n 1)/2, where n is the number of vertices in CP _ DAG(i,j). arc. h
For examples of single arcs, consider the arcs in Fig. 5 f except that from vertex (5,7) to vertex (4,5). The arcs from (4,5) to (3,4) in p 5 and from (4,5) to (1,2) in p and ( k , h ) depicts that the 2-object pattern a i a k in f CP _ DAG .

The discussion below is based on the assumption that all the CP _ DAG graphs satisfy Theorem 3 . The max-imal number of vertices in a Temp _ DAG ( k , h )is n (the number of match entries), and n is also the maximal ing with the n vertices and rebuild the n ( n 1)/2 paths at most, thus takes time complexity n  X  n ( n 1)/ 2=O( n 3 ). The time to perform process Merge is also proportional to the number of paths, which is also case, its time complexity is O( n 4 ).

In summary, we conclude that if the constructed CP _ DAG s satisfy Theorem 3 , the efficiency of calculating the similarity between two images will be bounded by polynomial-time complexity. The time complexity of no greater than the product of the numbers of objects in both images. The result of the stage 1 experiment in next section will show that Theorem 3 is satisfied in general. 3.5. The similarity function of CPM algorithm
In the model of 2D strings and its extensions, an object matches another object if they belong to the same the query image has only red balls. In view of this, the similarity degree between two objects a defined in CPM as: where SIM m ( a i , b j ) is the similarity of the m th attribute of object a perimeter, and roundness. And w m is the corresponding weight of the m th attribute. For example, consider two attributes color and size: where w s and w c are the weights of size and color, respectively. Notice that in the similarity function of
Now the value of CP _ DAG ( i , j ) is modified from the vertex number of the longest path to the maximal sim-vertices (matched object pairs) on this path. Since a path corresponds to a common spatial pattern, the way of spatial relations but also the object attributes. Therefore, the semantic information of the object symbol, object layout, and object attributes are integrated in the CP_DAG graphs.

Example 10. If the similarities of the match entries in Fig. 3 a are: (  X  (  X  4,5 ,0.5), (  X  5,7 ,0.2), (  X  6,1 ,0.8), and (  X  7,6 ,0.8), then the similarity degree of images f is contributed by the common pattern ABD from path p 1 in CP _ DAG (4,5) of Fig. 5 e. In this example, the similarity degrees of the other three patterns are 1.4 ( BED ), 1.0 ( EDH ) and 1.2 ( ADH ). 4. Experiments
We choose the compared methods which perform similarity retrievals based on object-level spatial rela-tions. Besides, these methods are also with the originality on the design of their similarity functions. We designed three stages of experiments to identify the efficiency and effectiveness of the proposed method
CPM. Experiments in stage 1 and stage 2 use a synthetic dataset and experiments in stage 3 employ an image Theorem 3 is generally satisfied by most comparisons. The average comparison time of the five methods,
LCS_Clique, SIM R ,SIM DTC , 2D Be-string, and CPM are recorded in stage 2 for observing the efficiencies of these methods. In stage 3, the retrieval qualities of these five methods are compared. 4.1. Experimental setup
These five methods were implemented in C++ languages and were run on a Pentium 4 (1.8 GHz) with 376 MB RAM running Windows XP . The synthetic dataset consists of 1000 symbolic images, and each boundaries), and colors. These images are equally divided into five groups from G1 to G5. To observe how the number of objects in an image can affect the performance of image comparisons, the number of objects is increased stepwise from 10 objects in the images of each group. The location of each object in an image is generated randomly within an 800  X  600 image area.

The images within each group are further divided into four subgroups. In subgroup 1, the class symbols are exclusive in the same image. In subgroup 2, 20% of the objects have the duplicated class symbols within an image. The distribution of symbol duplication is also random. As a consequence, an image may have 20% of objects with symbol  X  A  X  whereas another image has two symbols  X  A  X  and  X  B  X  with each symbol duplicated by 10%. The intention of designing symbol duplication is to simulate the real-world behaviors of SIDs since cient method should have stable comparison time instead of drastic changes. The symbol duplication rates of subgroup 3 and 4 are 40% and 60%, respectively.

In these experiments every image is taken as the query image in turn to be compared with all the images in the same subgroup including itself. Therefore, 1275 comparisons are performed for each subgroup to obtain average values. Self-comparison is included because it happens frequently in image retrievals that some images are very similar to or even the same as the query image.

The dataset for stage 3 is the image database used in Simplicity System ( Wang et al., 2001 ) and is available in the web site http://wang.ist.psu.edu/docs/related/ . This dataset consists of 1000 images which are equally divided into 10 groups. The main themes of these ten groups are aborigines, beaches, ancient buildings, buses, dinosaurs, elephants, flowers, horses, mountains, and foods in the dish, respectively. Each image is prepro-cessed by us by a software-aided method with human intervention to recognize the symbol, position, size, and color of each object. The number of objects in an image varies from 5 to 24 with average 13.2, and the symbol duplication rate in an image varies from 0% to 82% with average 37%. 4.2. Results of experiments in stage 1 The purpose of this stage of experiments is to verify whether and how Theorem 3 is satisfied by the of vertices in a CP_DAG, hence the number of paths is expressed as a function of the number of vertices in a CP_DAG. The value domain P ( Path ) is divided into six intervals, which are, in the asymptotic order,
P 6 n ( n 1)/2, n ( n 1)/2 &lt; P 6 n 2 , n 2 &lt; P 6 n 3
CP_DAG with the known numbers of vertices n and paths P , the counter of the corresponding interval will satisfies the first interval along the asymptotic order of the intervals.

The proposed method CPM is applied with type-0 criterion for it is the loosest condition among the three From the recorded data, all the CP _ DAGs produced by the 20 subgroups are in the intervals of
P 6 n ( n 1)/2 except those by the subgroup 4 of G5 (denoted as G5-4, with 30 objects and symbol duplica-tion rate 60%). To observe more possibilities, we also produced images with more symbol duplication rates (80%) and more objects (35). Table 1 shows the behaviors of the cases from G1-1 till G5-4 and two extreme cases, notice that they are all not above the interval P 6 n
The numbers in row 1 are the percentages per CP_DAG that lies in the interval P &lt; n ( n 1)/2 (satisfy The-the intervals n ( n 1)/2 &lt; P 6 n 2 and n 2 &lt; P 6 n 3 out of 100 constructed CP _ DAG s that lies in the interval n ( n-1)/2 &lt; P 6 n symbol duplication rate 60% (G5-4).

The data in Table 1 show that the probability to produce a  X  X  X omplicated X  X  CP_DAG is relatively low even when the symbol duplication rate is high. We also produce images that all objects are with the same class sym-bol. For an image of this kind with 14 objects to compare with itself, a complicated CP_DAG is found with P n 3.4 , where n equals 96 in this CP_DAG. However, this is an extreme case and is rare in real databases.
All the produced CP _ DAG s, from the results of this set of experiments, are polynomial in terms of the ver-tices of a CP_DAG, hence also polynomial in terms of the contained objects of images, because the maximum number of vertices in a CP_DAG is quadratic in terms of the image objects. 4.3. Results of experiments in stage 2 The purpose of stage 2 is to compare the efficiencies of LCS_Clique, SIM the proposed method CPM. The same dataset as in stage 1 is applied. The average comparison time for each subgroup is obtained by averaging the 1275 comparisons. The similarity criteria of LCS_Clique and CPM are matching. From the data in Table 2 we can see that when the numbers of objects are not greater than 10 (images of G1), the average comparison time of these five methods are all below 4 ms, no matter how the sym-bols duplicate. However, the average comparison time of LCS_Clique rises rapidly after G2. Therefore the values of G5 of LCS_Clique are not recorded here because its rising trend is obvious enough from the data of the first four groups.

SIM R and SIM DTC are efficient for the subgroups with low symbol duplications (observe only the columns of 0% and 20% of all the groups). However, for higher levels of symbol duplications, their efficiency degrades such that they are only better than LCS_Clique. The reason is that for images with higher symbol duplica-tions, the numbers of all possible matching are also larger. The average comparison time of 2D Be-string is stably dependent on the number of objects only. The reason is that 2D Be-string performs two 1D geometry computations instead of real 2D computations. But because of the necessary processing work, the comparison time is longer than those of other methods in the subgroups with low symbol duplication rates (0% and 20%).
Most important, the average comparison time of CPM rises steadily under increasing number of objects and symbol duplication rates, not like LCS_Clique, SIM R , and SIM 4.4. Results of experiments in stage 3
The purpose of this stage of experiments is to compare the retrieval effectiveness of the five methods. We used three different measures in this stage: R norm measure ( Bollman, Jochum, Reiner, Weissmann, &amp; Zuse, retrieval rate (RR) ( Qiu, 2003 ), and average ranking percentile ( Swain &amp; Ballard, 1991; Qiu, 2003 ).
For these five methods, each image is used as a query in turn to be compared with all the images. A ranked of the images by an expert. Fig. 12 shows the top 20 images ranked by the expert and retrieved by the five methods for taking image 106 as query. The objects extracted from image 106 include three main buildings, five groups of people, sky, ocean, and beach.
 1.0, the higher values are for higher retrieval qualities. R the list produced by domain expert; S is the number of image pairs that are in the opposite order as those in the list of domain expert; and S  X  max is maximum possible number of S The average R norm values are calculated by applying the five methods. The results are shown in Table 3 .2D independent 1D similarities. The R norm values of SIM R and SIM que. We can see that CPM has the highest average R norm value
The last column of Table 3 is the average comparison time in milliseconds of the five methods. This con-these five methods with 8 X 30-fold speed up on average. The average comparison time of SIM are over ten times of CPM because for images with larger scale of symbol duplications their efficiency degrade drastically as depicted in Table 2 .

Retrieval rate (RR) is also known as precision ( Qiu, 2003 ). For a given query image I the ratio of the retrieved images that come from the same group as I 1.0 (100%) if all the top five retrieved images are in the same group as the query. Let image p the top five retrieved images, and also let S ( p i )=1if p retrieval rate of each query is defined as:
Table 4 shows the number of queries of each RR value for the five methods. We can see that for CPM, 760 queries (out of 1000) have an RR of 100%, 133 queries have an RR of 80%, 47 queries have an RR of 60%, 44 queries have an RR of 40%, and 12 queries of 12%. If we only look at the numbers in the column of 100%,
SIM R is better than other methods. But for the column of 80% CPM is better. We further define Exp (expec-exp value of LCS_Clique is 754  X  100% + 122  X  80% + 61  X  60% + 53  X  40% + 10  X  20% = 911.4. It can be seen that the Exps values, except that of 2D Be-string, are very close, and CPM has the highest value.
The third measure is average ranking percentile. Assume a query image Q ( i ) is compared with all the data-size of the database). The average ranking percentile (see Table 5 ) is defined as: We also let each image in the database (with 1000 images) to be query in turn. For LCS_Clique method, AP = 99.89%; for SIM R method, AP = 94.93%; for SIM DTC method, AP = 94.79%; for 2D Be-string method,
AP = 98.85%; for CPM method, AP = 99.92%. Hence for the average ranking percentile measure, CPM out-performs other compared methods. 5. Conclusion and future work
In this paper, we have proposed a new method CPM incorporating a new data structure CP _ DAG for sim-common objects and the spatial relations among these objects, and the semantic similar patterns are conveyed in the induced CP _ DAG graphs. The CP _ DAG graphs are constructed in a succinct way that the numbers of of objects for almost all the observed cases. The building rules and characteristics of CP _ DAG graphs have also been introduced and proved. Three stages of experiments are conducted to compare the proposed method with four existing algorithms. From the results of the recorded measures under the synthetic dataset, CPM has stable efficiency as the number of objects and the symbol duplication rates increase. By tested with a well-known image database, CPM is the most efficient on average and has compatible effectiveness with the well-known compared methods. We noted that the similarity measures of the symbol classes and the relative positions are fuzzy concepts. Thus the future work of our research is to study the hierarchical structure of object classes and the fuzzy measurements of the similarity degrees of attributes and spatial relationships. References
