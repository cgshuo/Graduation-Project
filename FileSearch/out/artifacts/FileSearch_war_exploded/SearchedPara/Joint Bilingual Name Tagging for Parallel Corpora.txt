 Traditional isolated monolingual name taggers tend to yield in-consistent results across two languages. In this paper, we pro-pose two novel approaches to jointly and consistently extract names from parallel corpora. The first approach uses standard linear-chain Conditional Random Fields (CRFs) as the learning frame-work, incorporating cross-lingual features propagated between two languages. The second approach is based on a joint CRFs model to jointly decode sentence pairs, incorporating bilingual factors based on word alignment. Experiments on Chinese-English parallel cor-pora demonstrated that the proposed methods significantly outper-formed monolingual name taggers, were robust to automatic align-ment noise and achieved state-of-the-art performance. With only 20% of the training data, our proposed methods can already achieve better performance compared to the baseline learned from the whole training set. 1 H.4 [ Information Systems ]: Information Systems Applications-Miscellaneous Bilingual, name tagging, joint CRFs
Effective extracting and aligning names from bilingual data is an important task to various natural language processing (NLP) and information access applications, such as name pair and translation template mining [7], statistical word alignment [6], machine trans-lation (MT) [8], cross-lingual information extraction [16], cross-
All of the resources and open source programs developed in this paper are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/cuny_jointtagger.tar.gz lingual information retrieval [4] and cross-lingual question answer-ing [15]. This is a challenging task because it requires both name tagging from two languages and alignment to be handled correctly. However, traditional name tagging approaches for single languages (e.g. [10]) cannot address this requirement because they were all built on data and resources which are specific to each language without using any cross-lingual features. In addition, due to sep-arate decoding processes and word alignment errors, the results on parallel data may not be consistent across languages, even if monolingual name tagging systems achieved state-of-the-art per-formance on each language. Previous methods on bilingual lexicon acquisition cannot address this problem either because they relied on frequency of words appearing in bilingual corpora [18]. But many names are often domain specific and new names are created frequently so they cannot be found in existing bilingual gazetteers.
Fortunately, each language-specific tagger has its own advan-tages and disadvantages, and the features and resources from two languages are often complementary for parallel data. Since the par-allel data sets for English and Chinese are easier for us to obtain and understand, we choose the pair of English and Chinese as an example language pair, with three types of names: persons (PER), organizations (ORG) and geo-political entities (GPE). On one side, English features can help Chinese name tagging in various ways. (1) Due to its efficient symbolic system [3], Chinese texts often in-clude ambiguous name abbreviations which can also be interpreted as common words. However, they appear as full names in English translation which are much easier to detect, such as organization name:  X   X   X  ( Asian Development Bank)" and GPE names:  X   X  (Tianjin) ",  X   X  (Taiwan) ". (2) English features can help fix Chinese word segmentation errors. For example, it X  X  difficult to segment a sequence of local names  X   X   X   X   X   X   X   X   X   X   X  " because it in-cludes some common words such as  X   X   X  / nine rooms " and  X   X  / shed ". But its English translation is based on pronunciation:  X  Jiu-jianpeng village of Pingyi county of Shandong province ", which clearly indicates three GPE names:  X   X   X   X   X  /Jiujianpeng vil-lage ",  X   X   X   X  /Pingyi county " and  X   X   X   X  /Shandong province ". (3) Chinese nested organizations are often translated into simpler abbreviations in English and thus easier to identify, e.g. X   X   X   X   X   X   X   X   X  / Hong Kong Shanghai Huifeng Bank " is translated into  X  HSBC " in English.

On the other hand, Chinese features can help English name tag-ging: (1) name identification: It X  X  easy to identify X   X   X   X   X   X   X   X   X   X   X   X   X  /Guizhou Mao -tai Distillery ( Group ) Company " as an organization name in Chinese, but in English  X  X uizhou Mao" can be mistakenly tagged as a person because of its capitalization feature and the incorrect tokenization between  X  X ao" and  X  X ai". (2) n ame classification: In English it X  X  often difficult to disambiguate organization from facility, while the Chinese contexts often use dif-ferent prepositions or verbs to indicate correct name types.
Based on the above motivations, we develop the first new model based on linear-chain CRFs by projecting features from one lan-guage to the other using word alignment. However, in this frame-work, the knowledge from two languages is implicitly transferred on feature-level instead of label-level. Therefore, the tagged name pairs are not guaranteed to be consistent. For example, in the fol-lowing sentence,  X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X   X  ) / Xinhua News Agency, Hangzhou, September 2nd, by reporters Haixiong Shen and Xiquan Shen " , the Chinese baseline tagger mis-takenly labeled  X   X   X   X   X   X   X  /Haixiong Shen Xiquan Shen " as one single name. Cross-lingual features cannot fix this error be-cause both of its name type and boundary match the two names in English  X  Haixiong Shen " and  X  Xiquan Shen ". We propose the sec-ond model based on joint CRFs which not only incorporates both monolingual and cross-lingual features, but also conduct decoding for two languages simultaneously so that the labeling of two sides can mutually enhance each other. For the above example, the joint CRFs can split the Chinese name into two:  X   X   X   X  /Haixiong Shen " and  X   X   X   X  /Xiquan Shen ".
Some recent work has explored name tagging for parallel data. [13] presented a sequence of cost models to learn name translation pairs. This approach greatly relies on language-specific informa-tion such as repeated strings from both languages and capitalization clues. [9] proposed an approach to extract bilingual name pairs. Their method extracted names from each language first, and then computed the cost scores based on name tagging, name transliter-ation and word translation to rank candidate name pairs. [5] ex-tended their ranking method by incorporating bilingual alignment, bilingual type re-assignment and monolingual candidate certainty. [11] described a joint inference model to improve entity extraction and translation. All of these previous approaches can still be con-sidered as adding a post-processing step after two isolated name taggers. In contrast, our proposed joint CRFs approach integrates name tagging and alignment into one single unified model.
To the best of our knowledge, there was no previous work that we can directly compare to because they all used different data sets or definitions of name types. The approach described in [5] is the clos-est to our method of linear-chain CRFs using cross-lingual features, but there are some fundamental differences between their work and ours in the following aspects. (1) [5] was a two-step method. They added a post-processing step after two isolated name taggers. Their method extracted names from each language with monolin-gual name tagging first, and then computed the linking score to align name pairs. Therefore, in their approach, Chinese-English name pair lists with translation or transliteration confidence values are required to compute the linking scores. In contrast our pro-posed joint CRFs approach naturally integrates name tagging and bilingual alignment into one decoding process and does not require any translation and transliteration components to discover the map-pings betweens names from different languages. (2) The proposed learning methods are different. (3) They used manual alignment during testing, while we evaluate on both manual alignment and automatic alignment.
The input of a bilingual name tagger is aligned (manually or au-tomatically) parallel sentence pairs in two languages (Chinese and English in this paper). We apply the Stanford word segmenter [2] with Peking University standard to segment Chinese sentences. For Figure 1: Example of a parallel sentence pair. Solid lines rep-r esent alignments between names, while dashed lines denote other alignments example, for the parallel sentence pair demonstrated in Figure 1, our system should extract name pairs that appear in two sentences, such as the organization name pair of (  X   X  , Asian Development Bank).

A natural approach is to consider each side of a sentence pair in isolation, and solve the sequence labeling problem on each side using linear-chain CRFs. And during post-processing, we can re-move all of those name pairs that are mis-aligned in boundaries or labeled with different types.
 We adopt the linear-chain CRFs [12] as our learning method. In linear-chain CRFs, given an input sequence x , the conditional distribution of the output label sequence y is defined as: where f k is a feature function,  X  k is its weight, and Z ( malization function factor.

To cast name tagging as a sequence labeling problem, the BIO tagging scheme is applied as our label alphabet. BIO stands for: B-X , token at the beginning of a name; I-X , token within a name; and O , token out of any name, where X denotes the name type. We used a publicly available toolkit MALLET [19] as the implementation of the linear-chain CRFs in our experiments.

Table 1 summarizes the features for the baseline, where we as-sume the i -th token is the token in the current step.
The baseline approach described above neglects the dependency between aligned sentences. Given the hypothesis that the context of sentences pair can help disambiguation and reduce errors mutually, we present a new approach which still takes linear-chain CRFs as the learning framework, but exploits cross-lingual contexts based on alignments.
 Chinese-English sentence pair; y c = ( y c, 1 ...y c,L ) and be the corresponding output label sequences. The subscripts c and e denote Chinese and English respectively. In Chinese each x is a word, while in English each x e,j represents a token. We use A = { ( i, j ) } to denote the set of Chinese-English alignments, an alignment ( i, j ) indicates a Chinese word x c,i is aligned to an En-glish token x e,j . For simplicity we take Chinese side as an exam-ple, the hidden variables y c is not only conditioned on x c conditioned on x e and its alignment A . The conditional probability of y c can be extended as: where A [ i ] represents the indices of English tokens which are aligned to the i -th Chinese word. This still follows the linear-chain struc-ture in which we need to build one model for each language. The distinction from the baseline approach is that, with an English se-quence x e and its alignment A , we can propagate the context from English to Chinese according to its alignment, and vice versa. There-fore, not only is the output from two languages more accurate, but the entity pair detection performance is improved consequently as well. Ideally, we can generate arbitrary variants from the feature same feature set as in Section 3, but aggregate features of x its corresponding English tokens as observed features.
Although the approach in section 4 already takes into account of the dependencies between sentence pair, it requires separate models for two languages, and the prediction from one side cannot directly influence the assignment of the other, because the inference is on implicit feature level rather than the label level. In this section, we propose a bilingual CRFs framework which jointly models the bilingual sentence pair by utilizing their alignments.

We define conditional probability of output y c and y e jointly as:
This distribution is factorized by three cliques of factors: {  X  are potentials of Chinese linear-chain factors, {  X  e } are potentials of English linear-chain factors, and {  X  a } are potentials of bilin-gual factors. Factors in each clique share the same feature set and weights. Z ( x ) is the normalization factor which sums over poten-tials of all possible assignments of y c and y e .
Similar to monolingual name tagging, for any sentence in each language we define factors over all pairs of consecutive variables ( y t  X  1 , y t ), which enables the model to capture the dependency be-tween consecutive variables. The potential function of monolingual factors  X  c and  X  e is defined as where f k is a binary feature function and  X  k is the corresponding real-valued weight.
The label of a Chinese word is often highly correlated with its aligned English token, and vice versa. For instance, in the exam-ple in Figure 1, the Chinese word  X   X   X   X  and its English coun-terpart  X  Asian Development Bank  X  should be both labeled as or-ganizations. In order to model the correlation between the labels of aligned word-tokens, we introduce factors that link output vari-ables in two languages based on alignments. For alignment ( i, j ) in which Chinese word x c,i is aligned to English token x e,j a bilingual factor over y c,i and y e,j . This factor template bridges two monolingual linear chains, and makes it possible to propagate information across two sentences. The potential function of bilin-gual factors  X  a is defined as:
This allows us to design arbitrary binary features based on both and x e . A simple feature function for the above example is: If this feature attains high weight, the aligned word-token pair is likely to represent an organization entity given the English token is  X  Bank  X .

Figure 2 illustrates the factor graph representation of the model for the example in Figure 1. In this figure, white circles represent hidden variables y c and y e , gray circles represent observed sen-tence pair. Theoretically the factors can be linked to the whole observed sequences, for simplicity we only show the link to those at the same step.
Since cycles are introduced by bilingual factors, typical infer-ence algorithms for marginal probability and MAP such as Forward-backward and Viterbi algorithms cannot be exploited, and the exact inference is intractable in general. In this work we use an efficient loopy belief propagation method named Tree-Based Reparameter-ization (TRP) [17, 20] to perform approximate inference on the loopy graph. Figure 2: Graphical representation of bilingual CRFs model. S quares represent factors over input and output variables, for simplicity, the links between bilingual factors and input vari-ables are not shown.

Given a set of training data { ( x ( i ) , y ( i ) ) } N i =1  X  = {  X  k } are estimated using maximum likelihood estimation (MLE). The log-likelihood of the training set is calculated as: To avoid over-fitting we introduce Gaussian prior |  X  | 2 ization term to L  X  . Then the partial derivative of the log-likelihood with respect to parameter  X  k is: where F k ( x ( i ) , y ( i ) ) denotes the count of feature f instance. The first term is the empirical count of  X  k , and the sec-ond term is the expected count of  X  k under the model distribution. Given the gradient, optimization algorithms such as L-BFGS can be applied to maximize the log-likelihood. In this work we used MALLET [19] to implement the inference and learning process.
Given such a framework, the remaining challenge is to design features for both monolingual and bilingual factors. There are vari-ous possible ways to define cross-lingual features in this joint model. For instance, one possibility is to define them based on some con-junctions of the observed values from two languages, but such fea-tures require very large of training data and thus suffer from data sparsity. In our framework, each feature is defined as a conjunction of assignment and features from the input sequence; therefore we only need to design features of the input sequence. We use the fea-tures presented in Section 3 for monolingual factors. The features for the proposed bilingual factors are based on the combination of the monolingual features from the corresponding words/tokens. For instance, given a bilingual factor over x c,i and x e,j ment ( i, j ) , the sets of monolingual features from x c,i merged as features to form the factor. In this way, both monolingual features and cross-lingual transferred features are incorporated in a uniformed manner.

We asked four bilingual speakers to manually annotate the Par-allel Treebank, which contains 288 Chinese-English parallel doc-uments aligned at token level manually. The manual annotations were reviewed and adjudicated/corrected with several additional passes to form the final ground-truth. 230 documents are randomly selected for training, and the remaining 58 documents are used for blind test. Some statistics about this bilingual data set are given in Table 2. The last column (Bilingual Pairs) of the table shows the number of name pairs detected with manual alignment. Since the translation is not exactly literal, some names in one language may have no correspondences in the other. As a result, the number of name pairs may be slightly smaller than the number of names in each language.

A name pair in output is considered as correct if and only if both names in two languages are correct and have the same name type. The scores are computed using bilingual sentence pairs and name pairs, which are detected according to token-based alignment.
Table 3 shows the proposed approaches (with both manual align-ment and automatic alignment [14] 2 ) dramatically outperformed the baseline on all name types, at 99.9% confidence level according to Wilcoxon Matched-Pairs Signed-Ranks Test. The joint model achieved even better performance than single human annotator on person names with manual alignment; and the top F-score with au-tomatic alignment for organization names. This indicates that our proposed models are robust to alignment noise so that they can be effectively applied to bilingual parallel data with automatic align-ment, and avoid the necessity of costly manual alignment.
Figure 3 shows the overall performance of our models when they are learned from different size of training data. In order to bal-ance the small size of training data and test data, we randomly se-lected half of the test set (29 documents) for test. We can see that with only 20% of the training data, each of our proposed meth-ods (with manual alignment or automatic alignment) can already achieve better performance compared to the baseline learned from 100% training data. In particular, when using 20% training data, the joint CRFs model obtained 12.1% higher F-score with man-ual alignment and 10.1% higher F-score with automatic alignment over the baseline. As the training size increases, the proposed ap-proaches consistently outperformed the baseline.
In this paper we developed two novel bilingual name tagging methods incorporating cross-lingual features to jointly extract names
W e applied GIZA++ 2.0 toolkit to produce automatic word align-ment; default parameter setting for training, 5 iterations of IBM model 1, 3 ,4 and HMM alignment model were performed respec-tively; the alignment f-measure was 56.7% Table 3: Performance (%) on bilingual data set (the bold F -scores are significantly better than the baseline; while the scores marked with * are the best for each type).
 f rom bilingual data which significantly outperformed high-quality single-language name taggers, and achieved state-of-the-art perfor-mance.

Although our experiments were conducted on the Chinese-English name tagging task, we believe our proposed models are generally applicable for other NLP tasks (e.g. POS tagging and chunking) in other language pairs which contain complementary linguistic fea-tures. Currently the labeled monolingual data is widely available while manual annotations for parallel data remain highly expen-sive. Therefore in the future we are interested in exploring semi-supervised learning algorithms for joint bilingual name tagging.
This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement No. W911NF-09-2-0053, the U.S. NSF Grants IIS-0953149 and IIS-1144111 and the U.S. DARPA BOLT program. The views and conclusions contained in this docu-ment are those of the authors and should not be interpreted as repre-senting the official policies, either expressed or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on. [1] P. F. Brown, P. V. deSouza, R. L. Mercer, V. J. D. Pietra, and [2] P.-C. Chang, M. Galley, and C. D. Manning. Optimizing [3] Y. R. Chao. The efficiency of the chinese language. In Proc. [4] H.-H. Chen, S.-J. Huang, Y.-W. Ding, and S.-C. Tsai. Proper [5] Y. Chen, C. Zong, and K.-Y. Su. On jointly recognizing and [6] Y. Deng and Y. Gao. Guiding Statistical Word Alignment [7] D. Feng, Y. Lv, and M. Zhou. A new approach for [8] U. Hermjakob, K. Knight, and H. D. III. Name translation in [9] F. Huang and S. Vogel. Improved named entity translation [10] H. Ji and R. Grishman. Analysis and repair of name tagger [11] H. Ji and R. Grishman. Collaborative entity extraction and [12] J. D. Lafferty, A. McCallum, and F. C. N. Pereira. [13] R. C. Moore. Learning translations of named-entity phrases [14] F. J. Och and H. Ney. Improved statistical alignment models. [15] K. Parton and K. McKeown. Mt error detection for [16] M. Snover, X. Li, W.-P. Lin, Z. Chen, S. Tamang, M. Ge, [17] C. A. Sutton, A. McCallum, and K. Rohanimanesh. Dynamic [18] K. Tsuji. Automatic extraction of translational [19] A. K. McCallum. Mallet: A machine learning for language [20] M. J. Wainwright, T. Jaakkola, and A. S. Willsky. Tree-based
