 It is commonly believed that query logs from Web search are a gold mine for search business, because they reflect user-s X  preference over Web pages presented by search engines, so a lot of studies based on query logs have been carried out in the last few years. In this study, we assume that t-wo queries are relevant to each other when they have same clicked page in their result lists, and we also consider the queries X  topics of user X  X  need. Thus, we propose a Two-Stage SimRank (called TSS in this paper) algorithm based on SimRank and some clustering algorithms to compute the similarity among queries, and then use it to discover rele-vant terms for query expansion, considering the information of topics and the global relationships of queries concurrently, with a query log collected by a practical search engine.
Experimental results on two TREC test collections show that our approach can discover qualified terms effectively and improve retrieval performance.
 Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Query Reformulation General Terms: Algorithms, Experimentation.
 Keywords: Search Engine, Query Expansion, Query Logs.
In general, most web search engines discover relevant doc-uments for a query. Unfortunately, queries which are sub-mitted to search engines always contain very few keywords or phrases, and people often use different words to describe con-cepts in their queries from which is used to describe the same concepts in documents by authors. To solve this problem, query expansion (QE) approaches [7, 10, 8] have been wide-ly used, which focus on generating new queries by adding words to the original query.

In this paper, we focus on query expansion (QE) based on the recent history of data in query logs, and present a novel approach to select good terms for it. In general, we look into association and similar patterns at the level of terms through analyzing the relations of terms inside a query log in a real search engine, and treat them as candi-date terms. We try to generate a historical query-click graph which records the clicks generated by URLs when a user in-put a query. The query-click graph is a weighted bi-partite graph [4], with queries on one side and URLs on the other one. Then, a term-relationship graph which is obtained by several transformations from the query-click graph could re-flect the direct connections of the terms in query logs. Our term selecting approach is based on the notion of SimRank [6], which can compute similarity between any two terms in the term-relationship graph. However, in our case, we need to extend SimRank to take into account the weights of the edges in graphs [3]. In addition, queries in query log are clus-tered by the similarity scores, and we propose a Two-Stage SimRank (TSS) algorithm by considering the information of categories and the global relationships of queries concur-rently. Finally, term pairs have the higher TSS similarity scores are thought to be more useful for QE.

In next section, we discuss how we construct the query-click graph and term-relationship graph from query logs. Section 3 describes our Two-Stage SimRank algorithm and the candidate terms selecting process of our query expansion strategy. Section 4 contains the experimental results, as well as a discussion of those results and the last section is a conclusion.
Query-click graph (also known as query-document graph) is introduced by [3], which is a weighted bi-partite graph. The nodes in the one set represent queries and the nodes in the other set represent URLs which appear in query logs. An edge appears between a query q and a URL u if a user has issued the query and clicked on the URL in the list of results. Let G QC = { V QC ; E QC } be a bi-partite graph such that V QC = { v q ; u v } = Q  X  U and E QC = { v qu } = Q where Q is a set of all queries in query logs and U is a set of URLs clicked for those queries. Let ! ( e qu ) be a weighting function for an edge e qu  X  E QC , for this instance, it is the number of clicks for a query q on a URL u . Specifically, the query-click graph is constructed by the process which Figure 1 shows.
Fi gure 2: Term-Relationship Graph Construction Although the query-click graph can reflect all queries, URLs and the connections between them in query logs, then we can discover knowledge at the level of queries.
But in this paper, we propose to use query logs for query expansion at the level of terms through analyzing the rela-tions inside queries. Thus we need a term-level graph which we called term-relationship graph, is a weighted and direct-ed graph. We model terms and relationships as a graph G
T = { V T ; E T } , where nodes in V T = { v t } represent terms inside query logs and edges in E T = { e t } represent rela-tionships between terms. The weight of edge ! ( e ij ) which is the number of co-occurrence represents association degree between two terms i and j .

The term-relationship graph can be obtained by two trans-formations from the query-click graph (See Figure 2): (1) Query nodes substitution. (2) URL nodes elimination. Specif-ically, in the elimination process, for every term node pair ( v 1 ; v t 2 ) and every URL node v u , if there are two edges from v t 1 to v u and from v t 2 to v u concurrently, then add the weight of edge e t 1 t 2 in G T to c ( v t 1 ; v t 2 ; v u
SimRank [4] is a method for computing object similarities, applicable in any domain with object-to-object relationship-s, that measures similarity of the structural context in which objects occur, based on their relationships with other object-s. Unfortunately, because of the weight on graph edges, the naive SimRank fails to properly identify term similarities in our application, so we need to extend SimRank to take into account the weights of the edges in graphs.

In general, in order to utilize the edge weights in the com-putation of similarity scores. We first normalize the in-edge weights for every node v t in the term-relationship graph by following the next equation:
And then, we can incorporate the normalized weight into the SimRank equations as Equation 3 and 4, which named Normalized Weight SimRank (NWS)[9].
 Table 1: Data statistics of Robust-04 and Gov-2
N W ST ( I i ( v a ) ; I j ( v b )) = ! ( I i ( v a )  X  v a ) ! ( I j ( v b )  X  v b ) N W S ( I Query Clustering Obviously, there is a common assumption that in most case the original queries users submitted always have one or more topics of users X  need, so we consider that a global term min-ing in whole query log set may cause noise and topic drift. Therefore, we compute the similarly scores for each query pair in the full query-click graph (Section 3.1), and then clus-ter all queries in K topic groups. Specifically, the clustering algorithm and the value of K may have many strategies in practice, and the strategy we choose will be show in detail in Section 4.3.

After clustering, we can obtain one full query-click graph and several sub graph of query-click. After several trans-formations have been described in Subsection 2.2, the main and sub term-relationship graphs are obtained finally. Interpolation of Similarity Finally, considering the topics, for any term t in query q , we can find a group which describes the same main topic with q , and then mining several related terms to t by NWS algorithm. Unfortunately, because of the scale of the sub graph, the term t maybe haven X  X  appeared in it, so we do not neglect the global similarly and combine group and global similarly as the follow: where is a constant between 0 and 1, gives the weight of group similarly in the final similarly, and its setting will be showed in detail in Section 4.4.
For any given query q = w 1 :::w i 1 w i w i +1 :::w n , our ap-proach will iterate through all terms w i and try to find sim-ilar terms in the query log for each of them. For each w i the approach selects candidate terms and do query expan-sion by following four steps: (1) We classify query q into several group, and obtain the sub term-relationship graphs. (2) If there is a node of t i in the global term-relationship graph, then consider every terms t j with T SS ( v i ; v j as a candidate term. (3) Remain only the top M expansion candidate terms t j sorted by their T SS ( v i ; v j ). (4) Join all remaining candidate terms in the original query, and then ret rieval using the new query. In the follow sections, the method above is called TSSE (Two-Stage SimRank based Expansion).
Our experiments are based on the query log distributed by AOL, containing 36,389,567 records, 10,154,742 distinct queries and 657,426 users. Most of them are in English and sampled during three month, including an anonymous user-id, a query, a timestamp, and the clicked results (for each result, the position on the result page is also provided).
The evaluation is done using two standard TREC collec-tions: Robust-04 and Gov-2, with the details in Table 1. In particular, we treat all topic titles as queries and neglect their description.
In order to evaluate the effectiveness of our method, we use three methods as the baselines for comparison. (1) The Language Model was implemented by the Indri toolkit [1], in which the Dirichlet smoothing prior was set to 1500 empirically [5], and this method is denoted by LM-Dir. (2) A Relevance-Based Language Model was also imple-mented by the Indri, which is one of the PRF expansion approaches, based on the method by Lavrenko and Croft [7] and denoted by RM. (3) The expansion method only based on Normalized Weight SimRank is denoted by NWSE (details in Subsection 3.1). The parameter d m (the maximum number of in-edges) is set to 500 empirically [9].
For creating the term-relationship graph, we creat the query-click graph first, which contains approximately 4 mil-lion query nodes and 2 million clicked URL nodes.
Before the term-relationships X  construction, let X  X  discuss how to cluster the queries by the query-click graph. We comput queries X  similarity scores by NWS (details in sub-section 3.1) first, and then use the K-means clustering al-gorithm with these scores to cluster all the queries into K groups. The intent of query clustering is to group them ac-cording to the topics which just meet the users X  need, so we investigate the Open Directory Project (ODP) which is the largest, most comprehensive human-edited directory of the Web [2], and set K to 15 (the number of top-level topics in ODP). Finally, we train a SVM model according to the K groups, therefore, for each new query, it can be divided into one of the fifteen groups and we will use this information to compute the TSS scores.

Now we have obtained one full query-click graph and sev-eral sub graphs of query-click, after several transformations have been described in Subsection 2.2, the full and sub term-relationship graphs are also obtained finally, containing 413, 013 term nodes.

According to the description in Subsection 3.3, we can discover candidate terms with importance degrees (TSS s-cores) for every new query, and expand the original query. The candidate terms and the original query terms are com-bined using  X # weight  X  operator and  X # combine  X  operator Fi gure 3: MAP performance of all query expansion approach when M=30 implemented by the Indri [1], and Equation 6 is implemented by creating an Indri-query of the form: where Q ori is the original query and is free parameter which determines the weight given to the original query. For now, we work out a complete strategy for selecting expansion terms and creating the final query. In the following passages, the expansion approach above will be named TSSE, and we will focus on its performance in ad-hoc retrieval.
Before doing some detail testing, Figure 3 shows the re-sults of assigning different on two TREC collections, when M (the number of candidate terms remained) is set to 30 and (in Equation 5) is set to 0.5 empirically. As it can be seen in Figure 3, the RM method perform well when the val-ue of is set to 0 : 3 for Robust-04 and 0 : 6 for Gov-2. On the other hand, the TSSE method performs the best on MAP indicator when is set to 0 : 6 for both two TREC collection. Finally, we set the parameter to optimal values above for each of methods.

Similarly, let X  X  discuss the parameter for interpolation in the TSS algorithm now. Figure 4 shows that how the influences the retrieval performance, when M is also set to 30 and is set to 0 : 6. We find clearly that the queries work best when parameter is equal to 0 : 4 for Robust-04 and Fi gure 4: MAP performance of TSSE approach when =0.6 M eth. MA P NWS E 0. 262 0 .269 0. 265 0 .265 0. 256 0. 243 TS SE 0. 268 0 .273 0. 271 0 .266 0. 261 0. 249 NWS E 0. 282 0 .285 0. 284 0 .285 0. 282 0. 273 TS SE 0. 283 0 .286 0. 286 0 .285 0. 281 0. 276 0 : 5 for Gov-2 respectively, so the value is fixed in the detail testing.

We propose to use MAP and precision at top 10 (P@10) to measure retrieval effectiveness for all experiments. Finally, after several ad-hoc retrieval testing on two TREC standard collections, we list Table 2 and Table 3 to show the results.
In this paper, we have explored the AOL query log as a resource for query expansion. We generated a weighted bi-partite query-click graph, with queries on one side and URLs on the other, and then, clustered queries in several sub graphs. After that we obtained term-relationship graphs by several transformations from the full and sub query-click graphs respectively. Finally, a new method have been pro-posed for mining quality expansion terms from query log. Our algorithm named Two-Stage SimRank was based on a revised SimRank algorithm, and we measured the impor-tance of expansion terms according to their TSS scores with the terms in the original queries. In the last section, our ex-periments showed that the expansion terms extracted from AOL query log were better than those extracted from the feedback documents, using a relevance-based language mod-eling method, on the two different TREC collections. This work is supported by grant from the Natural Sci-Me th. Pre cision@10 NW SE 0.4 32 0. 437 0.4 32 0. 433 0 .427 0. 418 TSS E 0.4 31 0. 444 0.4 40 0. 440 0 .434 0. 421 NW SE 0.4 88 0. 502 0.4 92 0. 488 0 .492 0. 482 TSS E 0.4 92 0. 502 0.5 05 0. 493 0 .492 0. 484 enc e Foundation of China (No.60673039 and 60973068), the National High Tech Research and Development Plan of Chi-na (No.2006AA01Z151), National Social Science Foundation of China (No.08BTQ025), the Project Sponsored by the Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry and The Re-search Fund for the Doctoral Program of Higher Education (No.20090041110002). [1] Indri toolkit. http://www.lemurproject.org/indri.php. [2] Open directory project (odp). http://www.dmoz.org/. [3] I. Antonellis, H. G. Molina, and C. C. Chang. [4] P. Boldi, F. Bonchi, and C. Castillo. Query [5] B. Croft, D. Metzler, and T. Strohman. Search [6] G. Jeh and J. Widom. Simrank: A measure of [7] V. Lavrenko and W. B. Croft. Relevance-based [8] K. S. Lee, W. B. Croft, and J. Allan. A cluster-based [9] Y. L. Ma, H. F. Lin, and S. Jin. A revised simrank [10] T. Tao and C. X. Zhai. Regularized estimation of
