 1. Introduction
Biomedical literature has been playing a central role in the research activities of all biologists. The growing amount of scientific discoveries in genomics and related biomedical disciplines have led to a corresponding growth in the amount of literature information. Because of its daunting size and complexity, there have been increasing efforts devoted to integrate this huge resource for biologists to digest quickly.
Understanding gene functions is fundamental to biomedical research, and one fundamental task that bio-medical researchers often have to perform is to find and summarize all the knowledge about a particular gene from the literature, a problem that we call gene summarization.

Because of the importance of genes, there has been much manual effort on constructing an informative summary of a gene based on literature information. For example, FlyBase (one of the model organism genome database) provides a text summary for each Drosophila gene, including
DNA sequence, functional description, mutant information etc. Compressing and arranging all the knowledge from a huge amount of literature into different aspects enable biologists to quickly understand the target gene.
However, such gene summaries are currently generated by manually extracting information from literature, which is extremely labor-intensive and cannot keep up with the rapid growth of the literature information. As the growing amount of scientific discoveries in genomics and related biomedical disciplines, automatic sum-marization of gene descriptions in multiple aspects from biomedical literature has become an urgent task.
One characteristic of an informative gene summary is that the summary should ideally consists of sentences that cover several important semantic aspects such as sequence information, mutant phenotype, and gene product. That is, the summary is semi-structured. For example, Fig. 1 shows a sample gene summary in Fly-
Base retrieved in 2005. Here we see that the summary consists of sentences covering the following aspects of a gene: (1) gene products (GP); (2) expression location (EL); (3) sequence information (SI); (4) wild-type func-tion and phenotypic information (WFPI); (5) mutant phenotype (MP); and (6) genetical interaction (GI), as annotated. We thus propose to frame the gene summarization problem as to automatically generate a semi-structured summary consisting of sentences covering these six aspects of a gene. Such a summary not only is supporting evidence in the literature.

Most existing work on automatic text summarization has focused on news summarization and the gener-ated summary is generally unstructured, consisting of a list of sentences. The existing summarization methods are thus inadequate for generating a semi-structured summary. In this paper, we present a study of methods for automatically generating semi-structured gene summaries from biomedical literature. Although our studies mainly focus in the biomedical literature domain, the approaches we proposed are generally applicable to semi-structured summarization in other applications, such as product reviews. Under the assumption that we have some training sentences for each aspect, generalizing our methods for applying to other applications is very straightforward.

We propose a two-stage approach to generate such a summary for a given gene, in which we would first retrieve articles about a gene and then extract sentences for each of six specified semantic aspects. While the first stage can be implemented using any standard information retrieval techniques, a standard IR tech-nique generally cannot handle gene name variations well. We address this issue through adding some heuristic methods on top of regular keyword matching. For the second stage, we leverage some existing training resources and propose several different methods to learn from the training data and extract sentences in each semantic aspect.

We evaluate the proposed methods using a test set with 20 randomly selected genes. Experiment results show that the proposed methods are potentially useful in automatically generating informative semi-structured gene summaries from biomedical literature and outperform general purpose summarization methods. Among our proposed methods, although vector space model generally performs comparably with most probabilistic approaches, the probabilistic model with gene context analysis is the best by most of the evaluation metrics.

With the proposed methods, we would be able to generate summaries such as those in FlyBase automat-ically. The generated summaries would allow biologists to more easily keep track of new discoveries recently occurring in the literature. Compared with the currently available GeneRIF not only are generated automatically, but also can organize information into aspects. The proposed methods can also be exploited to generate candidate summaries to assist a human expert in curating resources such as FlyBase.

The remainder of this paper is organized as follows. Section 2 discusses the related work. We present the proposed summarization method in Section 3 , followed by a detailed discussion of sentence extraction meth-ods in Section 4 . The evaluation results are discussed in Section 5 . We discuss the generality of the proposed approaches in Section 6 and conclude our study in Section 7 . 2. Related work
To the best of our knowledge, this is the first attempt to automatically generate a structured summary of a gene from biomedical literature. Although, automatic text summarization has been extensively studied before has explicitly defined semantic aspects, whereas most news summaries are simply a list of extracted sentences also consider the special characteristics of the biomedical literature.
 Our work is very much related to the recent work on summarizing/clustering search results ( Kummamuru, 1996 ), Grouper ( Zamir &amp; Etzioni, 1999 ). Clustering web search results was studied in Zeng, He, Chen, Ma, and Ma (2004) , which attempts to organize the search results of each query into clusters labeled with key phrases. Their work tries to discover the latent clusters of ad hoc retrieval results, which does not predefine a structure. Differently, we are generating semi-structured summaries to satisfy people X  X  specific information needs which are well defined ( i.e ., aspects). Therefore, we have fixed semantic meaning in each dimension and aim at generating a sentence-based summary whereas existing work leaves the definition of each dimension open and relies on clustering algorithms to discover meaningful dimensions.

A problem closely related to ours was addressed in the Genomics Track in the Text REtrieval Conference (TREC) 2003 ( Hersh &amp; Bhupatiraju, 2003 ), where the task was to generate descriptions about genes from
MedLine records. The major difference between this task and ours is that the generated descriptions do not organize the information into clearly defined aspects. In contrast, we define six reasonable aspects of genes and propose new methods for selecting sentences for specific aspects.

Most existing studies of biomedical literature mining focus on automated information extraction, using nat-ural language processing techniques to identify relevant phrases and relations in text, such as protein X  X rotein kay &amp; Feldman, 2003 for reviews of these works). The information we extract is at the sentence level, which allows us to cover many different aspects of a gene and extract information in a more robust manner.
Our work was initially published in the Proceedings of Pacific Symposium of Biocomputing 2006 ( Ling et al., 2006 ). This previous work has been significantly extended here with several new probabilistic approaches for sentence extraction and a comprehensive evaluation of all the methods for generating a semi-structured summary. 3. Automatic gene summarization 3.1. Overview The proposed automatic gene summarization system mainly consists of two components: a Keyword
Retrieval module that retrieves sentences about a target gene, and an Information Extraction module that extracts retrieved sentences to summarize the target gene. The Information Extraction module itself consists of two components, one for training data generation, and the other for sentence extraction. The whole system is illustrated in Fig. 2 . 3.2. Keyword retrieval module
First, to identify documents that may contain useful information for the target gene, we use a dictionary-based keyword retrieval approach to retrieve all documents containing any synonym of the target gene. 3.2.1. Gene synonym set (SynSet) construction
Gene synonyms are very common in biomedical literature. It is important to consider all the synonyms of a target gene when searching for relevant documents about the gene. We used the synonym list for fly genes pro-vided by BioCreAtIvE 2003 Task 1B ( Hirschman, Colosimo, Morgan, &amp; Yeh, 2005 ) and extended it by adding names or functional information of proteins encoded by each gene from FlyBase X  X  annotation. In the end, we constructed a set of synonyms and protein names (called SynSet here) for each known Drosophila gene. Because of variations in gene name spelling, we use a special tokenizer for both MedLine abstracts and Syn-
Set entries, to normalize the gene name. The tokenizer converts the input text into a sequence of tokens, where each token is either a sequence of lowercase letters or a sequence of numbers. White spaces and all other sym-bols are treated as token delimiters. For instance, the different synonyms for gene cAMP dependent protein kinase 2 ,  X  X  X KA C2 X  X ,  X  X  X ka C2 X  X , and  X  X  X ka-C2 X  X , are all normalized to the same token sequence  X  X  X ka c 2 X  X  to allow them to match each other. A MedLine abstract is considered as being relevant only if it matches the token sequence of a synonym exactly . 3.2.2. Synonym filtering
Some gene synonyms are ambiguous, for example, the gene name  X  X  X KA X  X  is also a chemical term with a different meaning. In these situations, a document containing the synonym with an alternative meaning would be retrieved. Our strategy of alleviating this problem is based on the observations that (1) the longer or full name of a gene is often unambiguous; (2) when a gene X  X  short abbreviation is mentioned in a document, its full or longer name is often present as well. Therefore, we force all retrieved documents to contain at least one synonym of the target gene that is at least 5-character long. 3.3. Information extraction module
The information extraction module extracts sentences containing useful factual information about the tar-get gene from the documents returned by the keyword retrieval module. To ensure the precision of extraction, we only consider sentences containing the target gene, which are further organized into the six general aspects listed in Table 1 , which we believe are important for gene summaries.

Our main idea for sentence extraction is to leverage the existing training resources (such as FlyBase) to learn a model for each semantic aspect and use such models to categorize the top ranked sentences into appro-priate semantic aspects. 3.3.1. Training data generation
To help identify informative sentences related to each aspect, we construct a training data set consisting of uted data pages, and the references of each gene in FlyBase.

The  X  X  X ummary X  X  paragraph : FlyBase curators have compressed all the relevant information about a gene into a short paragraph, the text Summary in the FlyBase report. This paragraph contains good example sen-tences for each aspect of a gene. A typical paragraph contains information related to gene product, sequence text summaries, we decompose each paragraph into our six aspects with non-relevant sentences discarded.
However, since these sentences are automatically generated by filling the information in FlyBase databases into a common template, they are not good examples of typical sentences that appear in real literature. For bit X  X ,  X  X  X romote X  X  and  X  X  X nhance X  X . In the  X  X  X ummary X  X  paragraph, it is always described using the template  X  X  X t interacts genetically with ... X  X . Thus we also want to obtain good examples of original sentences from the literature.
 The  X  X  X ttributed data X  X  report : One resource of original sentences is the  X  X  X ttributed data X  X  report for each
Drosophila gene provided by FlyBase. For some attributes such as  X  X  X olecular data X  X ,  X  X  X henotypic info X  X  and  X  X  X ild-type function X  X , the original sentences from literature are listed. These sentences seem to be good complements of the training data from the  X  X  X ummary X  X  paragraph. In our system, we collect the sentences from  X  X  X henotypic info X  X  and  X  X  X ild-type function X  X  as training sentences for the aspect WFPI . reports only list the noun phrases related to the target gene, but do not show any complete sentences. In order to find the patterns of sentences containing such information, we exploit the links to the corresponding refer-ences given in the  X  X  X ttributed data X  X  reports to find the PubMed ID of the reference. We then look for occur-the abstract of the reference. We add the sentence containing both the item and the target gene to our training training data. 3.3.2. Sentence extraction
Our general idea for sentence extraction is the following: We first exploit any proposed method (see Section 4 ) to compute the relevance score S for each sentence X  X spect pair. To ensure reliable association between sen-tences and aspects, for each sentence, we rank all the aspects based on S and keep only the top two aspects.
The rationale behind it is that a sentence may contain more than one aspect of a gene. For instance, a sentence describing the mutant phenotype of a gene may have information about the molecular function of this gene. Therefore we empirically only consider the two most dominant aspects of information in a sentence.
To generate a structured, aspect-based summary, for each aspect, we rank all the kept sentences according to S and pick the top-k sentences. Such an aspect-based summary is similar to the  X  X  X ttributed data X  X  report in FlyBase.

It is clear that among all the components in the proposed gene summarization method, the main challenge a sentence w.r.t. a semantic dimension. In the following section, we present several different methods for solv-ing this problem. 4. Sentence extraction methods
As discussed in the previous section, our general idea for sentence extraction is to first compute aspect mod-els based on training data, then compute the relevance score of each sentence with respect to each aspect, and finally extract sentences for each aspect of the target gene. We present different methods for modeling term usages based on the training data and scoring sentences for each semantic aspect: vector space model and probabilistic language model. We now discuss each in detail. 4.1. Vector space model
We can use the vector space model and cosine similarity function from information retrieval to assign a relevance score to each sentence w.r.t. each aspect. Specifically, For each aspect, we construct a corresponding term vector V c using the training sentences for the aspect. Following a commonly used information retrieval heuristic, we define the weight of a term t i in the aspect term vector for aspect j as w
TF i , j is the term frequency, i.e. , the number of times term t
IDF i is the inverse document frequency. IDF i is computed as IDF of documents in our document collection, and n i is the number of documents containing term t reflects the usage of different words in sentences describing the corresponding aspect.

Similarly, for each sentence we can construct a sentence term vector V being the number of times a term occurs in the sentence. The aspect relevance score is then the cosine of the angle between the aspect term vector and the sentence term vector: S = cos( V 4.2. Probabilistic methods: language modeling approaches
Alternatively, we may also use language models to score a sentence for each aspect. Specifically, different language modeling approaches can be used to estimate a language model for each aspect. Then to compute the relevance score S between each sentence X  X spect pair, we can use the negative KL-divergence function to measure the similarity between the retrieved sentence and the aspect language model.
 where h s , h m represents the language model of the sentence and the aspect respectively.

Note that using KL-divergence for scoring is equivalent to using the Naive Bayes classifier to classify a sen-tence into a semantic aspect as the entropy term in the KL-divergence formula does not affect ranking of aspects whereas the cross entropy term is equivalent to the log-likelihood of the sentence given a model. compute p ( w j h m ). One simple method for estimating the aspect language model could be based on the relative word frequency in the training data of each aspect smoothed by the word frequency of the whole collection.
That is, we can simply compute the aspect language model by p  X  w j h vocabulary of the training collection and test collection. We denote this method as the baseline language model method (baseLM).

The baseline language model method can be further improved in several ways. First, common English words and those domain/gene-specific words in the training data are both generally noise when we try to extract the language models of specific information. For example, in our task, the words like  X  X  X ene, protein, biology, experiment X  X  are not informative words for any aspect. Clearly, the above simple language model esti-mation can not filter out this kind of noise. Hence, we propose two more sophisticated generative probabilistic mixture models to remove the noise and expect to extract more general and robust language models for mod-(CTM) proposed in Zhai, Velivelli, and Yuk (2004) , which intends to extract the discriminative aspect models by taking into consideration the hidden background model of the whole collection. The second one is a variant of the contextual probabilistic latent semantic analysis (CPLSA) model proposed in Mei and Zhai (2006) , ing sentences.

As mixture models, both approaches explicitly distinguish a common background model that characterizes common information over a collection of documents from special topic models that characterize topic-specific information in the text. They also distinguish between different topic models that characterize different infor-mation in different context. These approaches involve common background model as well as multiple topic-specific models. The underlying basic idea is to treat the words as observations from a mixture model where the component models are the topic-specific word distributions and the background word distributions across different document collections. The expectation maximization (EM) algorithm is used to estimate the topic-specific models which people are mostly interested in. In our task, we aim to apply these mixture model meth-ods to obtain the aspect-specific word distributions p ( w j h a local maximum of the data likelihood.

In our experiments, we use multiple trials to improve the local maximum we obtain. In the following, we discuss each approach in detail, and give corresponding EM updating formulas. 4.2.1. Discriminative aspect model
In order to remove from the estimated aspect models the noise of the background words over the whole collection of the training data, thus also make the estimated models more discriminative, we adopt the cross-collection mixture model (CTM) proposed in Zhai et al. (2004) . Fig. 3 illustrates the idea of explicitly distinguishing common background model that characterizes common words across all aspects from special aspect models that characterize aspect-specific information. By filtering the background model from the aspect models, we expect to extract more discriminative language models that can effectively differentiate word usages of different aspects.

The training data for each aspect i is collected as sub-collection C m sub-collections for m aspects, respectively. Let h 1 , ... , h distributions) and h B be a background model for the whole collection C . A document d is regarded as a sample of the following mixture model where w is a word, d 2 C i , k B is the mixing weight of the background model h collection C is where c ( w , d ) is the count of word w in document d .

According to the EM algorithm, the following iterative updating formulas are used to estimate all the parameters. { z d , w } is a hidden variable and p ( z d , w by the aspect model i .
The estimated h i can then be assumed to be our semantic aspect models for scoring retrieved sentences. 4.2.2. Generalizable aspect model
In the above models, we only take into consideration the word usage for each aspect. However, as the train-ing sentences are prepared from a sampled set of genes, they also contain gene-specific information which we want to avoid when summarizing genes that are different from this training set. For example, sentences about a gene which encodes transcription factor usually contain many terms about transcription, like  X  X  X NA bind-ing, regulation, transcriptional X  X . The desirable language model extracted to represent each aspect should be general and gene-independent, thus can be used to summarize any new gene.

However, in previous methods, there is no mechanism to filter out this gene-specific information from the aspect language model. Recall that each training sentence has two features: it is about a gene and it is asso-ciated with an aspect. In previous models, we only considered the association between each training sentence and its relevant aspect, but ignored the information that each training sentence is originally from a specific gene. The specific semantic aspect and the specific gene can both be regarded as indicating a  X  X  X ontext X  X  to which the sentence belongs. In this sense, the models presented in the previous subsection can consider only mation ( i.e. , aspects and genes). We thus adopt the contextual probabilistic model (CPLSA) proposed in Mei and Zhai (2006) to address both the aspect context and the gene context when estimating the aspect models. In see it achieves better performance than the methods presented in the previous subsection.

Specifically, by modeling a training sentence in the context of all sentences about the same aspect, we can extract aspect language models. On the other hand, by modeling sentences in the context of all sentences about the same gene, we can model the gene-specific information and distinguish it from the aspect language models. This model intends to make the aspect models more general and applicable to arbitrary genes.
In our task, each document is associated with two types of contexts: the gene g which it describes and the responding language model represents the word distribution of this context. Our goal is to extract the lan-guage models associated with the aspect contexts but not the gene contexts. The details of contextual theme analysis and the original CPLSA model can be found in Mei and Zhai (2006) .

Fig. 4 illustrates the idea for modeling two types of context information, i.e. , aspects and genes. In this model, we assume that document d (with context features C follows: (1) Choose a view v i from a context according to the view distribution p ( v from the language model h i of the view v i . That is, p d represents the m aspect models we are interested to extract, and h the n gene-specific language models we want to filter out. The log-likelihood of the whole collection is
The parameters are the view selection probability p ( v i The mixture model can be fit to a contextualized collection C using a maximum likelihood estimator. The
EM algorithm can be used to estimate the parameters by the following updating formulas, where { z hidden variable and p ( z w , i , d = 1) indicates that the word w in document d is generated by model h
The estimated h i ( i =1,2, ... , m ) can then be assumed to be our semantic aspect models for scoring retrieved sentences. 5. Evaluation experiments 5.1. Experiment setup
We retrieve 22092 MedLine abstracts as our document collection using the keyword  X  X  X rosophila X  X . We use the Lemur Toolkit 3 to implement the summarizers we proposed. As explained in Section 3.3.1 , we use the sub-collection which consists of 20% genes in FlyBase for model training purpose. It contains 7391 sentences in total.

The first stage of keyword retrieval is very straightforward, and can be implemented using standard infor-mation retrieval techniques. To handle gene name variations and improve the accuracy of retrieval, we apply a heuristic method on top of regular keyword matching. Methods developed for this stage are intuitive and stan-dard as a general retrieval task on genomic literature, thus we would not present a formal evaluation here. Instead, we focus the evaluation on the second stage, i.e. , sentence extraction, which is more challenging.
In our experiments, we compare the performance of different summarizers, by means of extracting sentences from the same set of sentences retrieved for each target gene. 5.1.1. Gold standard
Since the semi-structured literature summarization is a novel problem, there is no existing gold standard. It is very difficult to create a large judgment set manually. In our experiments, we randomly select 20 genes from
FlyBase for evaluation. For each gene, we ask two experts to assign each candidate sentence to at most two most relevant aspects separately. Then the sentences that are decided as relevant to a certain aspect are col-lected as the judgment for this gene in this corresponding aspect. There is no constraint on the length of the gold standard summary. These two sets of 20 multiple aspect based summaries are used as the gold stan-dard for our experiments, based on which all summaries generated by the different approaches are evaluated. 5.1.2. Evaluation metrics
ROUGE is an evaluation package suggested by DUC 4 and commonly used ( Sun et al., 2005 ) to automat-ically evaluate both single-document summarization and multi-document summarization systems ( Lin &amp;
Hovy, 2003; Lin, 2004 ). It provides a suite of evaluation metrics to measure the similarity between system gen-erated summaries and the judgments in several ways, such as n -gram overlapping, longest common subse-quence and skip-bigram co-occurrence, instead of simple matching/non-matching. This is especially desirable for gene summarization because the sentences retrieved for a gene are from multiple papers, thus there are usually multiple sentences which are very similar to each other in terms of covering some aspects of the gene. All these sentences are reasonable to be selected for a summary. Among all the evaluation metrics in ROUGE, ROUGE-N (models n -gram co-occurrence, N = 1,2,3) and ROUGE-W-1.2 generally perform well in evaluating single-document summarization according to Lin and Hovy (2003) and Lin (2004) . We eval-uate our system with all the metrics provided by ROUGE, and report ROUGE-1, ROUGE-2, ROUGE-3 and
ROUGE-W-1.2. 5.1.3. The baselines
Since there is no existing system for semi-structured summarization, we select several general purpose summarization systems as the baselines to be compared with our methods. MEAD available summarization toolkit which accommodates both extractive multi-document summarization and single-document summarization ( Radev et al., 2003 ). Three baseline summarizers are provided by MEAD: random extraction  X  the summarizer extracting sentences randomly, lead-based extraction  X  the summarizer extracting sentences from the front of each document, and Mead-Single  X  a featured single document summa-rization system which integrates text features such as keywords, sentence length, sentence position, and cluster centroids. We use the default setting of the MEAD toolkit. In all these three systems, we pool all the sentences retrieved by the Retrieval Module for each gene as a single document. These general purpose summarization methods are reasonable baselines to evaluate our system, and denoted as RAND, LEAD, MEAD respectively in our experiments.

In addition to the three runs for the above baselines, we run four experiments to evaluate our proposed methods in sentence extraction as follows: Run 1 (VSM): use the vector space model proposed in Section 4.1 .
 Run 2 (baseLM): use the simple language modeling approach presented in Section 4.2 .
 Run 3 (DAM): use the discriminative aspect model proposed in Section 4.2.1 .

Run 4 (GAM): use the generalizable aspect model proposed in Section 4.2.2 . 5.2. Comparison of sentence extraction methods
Using ROUGE, We evaluate the result summaries on six aspects and two gold standards separately, then take the average score over the six aspects and two standards as the final evaluation. Table 3 summarizes the averaged Average _ R score for all evaluated methods on sentence extraction. We vary the length of summaries for each aspect among 1, 5, 10 and 15 sentences. Note that as we did not finely tune the parameters for the four proposed methods, the results for them are not necessarily their optimal results. The default selection of parameters are presented in Table 2 unless otherwise specified.
 From Table 3 , we make a number of observations as the following: Comparison among baseline methods :
Among the three baseline methods, MEAD performs significantly better than RAND and LEAD. This is not surprising, since MEAD is a featured document summarization system which integrates many text features, whereas the other two simply extract sentences randomly or from the front of each document. The advantages of MEAD over the other two methods decreases when the summary grows longer. This is because the evalu-ation on very long summaries will be affected by the unavoidably redundancy within the summary, thus the evaluation might not reliably reflect the effectiveness of the methods.
 Baseline methods vs. proposed methods :
By most metrics, our proposed methods perform better than the baseline methods. We also observe that, the evaluation result of metric ROUGE-1 is inconsistent with the others especially when the summary length increases ( i.e. P 10 sentences). Only in this case, the best baseline approach MEAD achieves better score than our proposed methods. In this case, the other two baseline methods (RAND,LEAD) also show exceptionally high scores. This is because ROUGE-1 only measures the coverage of unigrams.
In the standard summary, the common background words, like  X  X  X ene, protein, Drosophila X  X , occur very frequently, most of which appear alone ( i.e ., not associated in an n -gram phrase). When the generated summary length increases, the matching of these common background words will affect the evaluation scores significantly. However, in terms of other metrics like ROUGE-2, ROUGE-3, the common back-ground words are less effective because they measure bigram/trigram co-occurrences. Under these met-rics, MEAD could not achieve higher score than our proposed methods. We also observe consistent result by ROUGE-4. The outperforming of language models and the vector space model over baseline approaches indicate that our proposed methods are useful for automatically generating semi-structured gene summaries from biomedical literature, while the general purpose summarizers do not serve this pur-pose very well.

Generally speaking, a reasonably short summary ( e.g. , five sentences for each aspect of a gene) is enough to capture the key information of a gene and is preferred. Long summaries usually carry redundant infor-mation. By investigating the scores over different summary length, we also noticed that the advantage of our proposed methods over baseline methods are most significant when the summary is short. The main reason is that, unlike MEAD, we do not consider any redundancy removal in sentence selection. The longer the summary is, the more the result will be affected by the redundancy between the sentences picked by our methods. It also suggests a direction for our future work to develop techniques on remov-ing redundancy in generating a semi-structured summary.
 Probabilistic language model vs. vector space model :
Vector space model performs slightly better than language models only when the generated summary is very short ( i.e. , one-sentence summary). In fact, this is not surprising because we used a simple implemen-tation of vector space model without document length normalization. It favors longer sentences. Indeed, we observed that the sentences picked by this model are longer than those picked by the others. Thus when the number of sentence is small, it has a higher chance to cover more words in the gold standard summary, especially unigrams, which makes it achieve slightly higher ROUGE-1 score since the reported Average _ R score favors high recall. However, when investigating N -grams instead of single terms, long sentences do not necessarily have high recall. That is why when ROUGE-2, 3 are used, VSM is not the best. Also when the result summary length increases, this outperforming disappears and vector space model is beaten by language models with larger margin.
 Baseline language model vs. discriminative aspect model :
The discriminative aspect model (DAM) only performs better than the simple baseline language model (baseLM) when the length of the summary is five sentences. These two methods seem quite comparable.
From this evaluation, it is unclear to see which one applies better in our task. Further studies in comparing more elaborate vector space models and optimized discriminative aspect model on this summarization task may provide more insight.
 Generalizable aspect model vs. other probabilistic language models :
The generalizable aspect model (GAM) is the most sophisticated method among the three probabilistic lan-guage model approaches and the only one which takes into consideration the gene labels of training sen-tences. With all evaluation metrics, it performs the best among the proposed language models as expected. GAM also outperforms all the other summarization methods with most evaluation metrics. The only exceptions are that it has lower ROUGE-1 score (1) than the vector space model when generating sin-gle-sentence summaries; (2) than the baseline MEAD when generating 10-and 15-sentence summaries. The reasons are already discussed above. According to the evaluation, the generalizable aspect model based on contextual probabilistic analysis appears to be a very promising approach for our semi-structured gene summarization task.

In Table 4 , we show a sample structured summary generated for the well-studied gene Abl by collecting the best sentence ranked by the vector space model for each aspect. In this summary, all the extracted sentences are quite informative as judged by biologists. For comparison, the human-generated FlyBase summary of the same gene is in Fig. 1 . 6. Discussion
Although our study is focused on a specific semi-structured text summarization problem ( i.e ., summarizing gene information), the problem setup and the proposed methods are general and applicable to other instances of the problem.

Gene summarization is one of the many cases where an ideal summary should have some structure and the summary sentences should be grouped according to this structure. For example, a very common information need is to find opinions about products from the Web. A summary with positive opinions separated from neg-ative opinions would be much more useful than one with the opinions mixed. Also, the products in the same an informative summary about products should ideally separate sentences into these different dimensions. subtopics; correspondingly, a semi-structured summary with summary sentences selected for each subtopic would often be desirable.

As a general setup, our problem definition involves the following elements: (1) A set of documents to be summarized. (2) A set of aspects to define the structure of the summary. (3) Training sentences for each aspect.
Clearly, this setup can be applied to other instances of the semi-structured summarization problem provided that we can collect training sentences for each aspect. Indeed, such a problem setup is most useful for domains where the definition of aspects is natural ( e.g. , in product summarization) and we may easily obtain training aspects can be predefined in the domain.

Given that a problem fits to this general setup, all our proposed methods, including the general two-stage strategy and specific sentence extraction methods for the second stage, can be applied. Although the problem can also be cast as a sentence classification problem on top of a  X  X  X lat summarization X  X  problem, this strategy would not allow us to focus on the desired aspects and the summary can easily be biased toward any domi-nating aspect. In our approach, we ensure the coverage of each aspect through decomposing the summariza-tion task into aspect-specific summarization tasks.

Naturally, for any specific problem, various kinds of heuristics can be exploited to further improve perfor-mance for both stages. For example, we have exploited gene synonym resources to improve the retrieval per-formance in the first stage for gene summarization. 7. Conclusion and future work
In this paper, we studied a novel problem in biomedical text mining: automatic generation of semi-structured gene summaries. We developed a system which employed information retrieval and information extraction techniques to automatically summarize information about genes from PubMed abstracts. We proposed several representative methods for solving the problem and used our system to investigate which computational strategies would be most suitable for our problem. The methods were tested on 20 randomly selected genes, and evaluated by ROUGE.

The results show that the two generic methods proposed, i.e. , vector space model and probabilistic models, are both very effective for sentence extraction. The fact that our proposed methods outperform the baseline general-purpose summarizers indicates that the general-purpose summarizers are not very effective for gene summarization, and considering the special characteristics of the gene summarization problem ( i.e. , different semantic aspects) is important for improving summarization performance. Specifically, the generalizable aspect model (GAM) based on contextual probabilistic analysis performs the best in most cases, and appears as a very promising approach for this task.
 We realized that one obvious limitation of our approach was its dependence on the high-quality data in
FlyBase. To address this issue, we will in the future incorporate more training data from databases of other model organisms and resources such as GeneRIF in Entrez Gene. We believe the mixture of data from differ-ent resources will reduce the domain bias and help build a general tool for gene summarization. Also, the six structured aspects defined in this work are not the only possible ones; the proposed methods can easily gene-rate new aspects given corresponding training sets.

We have not considered the removal of redundant information in generated summaries. To further improve our system, we will develop techniques to integrate other text features for redundancy removal.
The general problem of generating semi-structured summaries represents a new research direction in text summarization. Although our approaches are proposed for gene summarization, they are general and can also be applied to other semi-structured summarization problems, such as automated summariza-tion of product reviews or blog articles in multiple aspects. Further improving our approaches and devel-oping new general methods for semi-structured summarization are all very interesting future research directions.
 Acknowledgments
The National Science Foundation (NSF) supported this research through Award 0425852 in the Frontiers in Integrative Biological Research (FIBR) program, for BeeSpace  X  An Interactive Environment for Analyz-ing Nature and Nurture in Societal Roles ( http://www.beespace.uiuc.edu ). The work is also supported in part by an NSF ITR Grant 0428472. We thank Todd Littell for his help to integrate this work into the BeeSpace system and many helpful discussions. References
