 Wolfgang Minker and Samir Bennacef (University of Ulm and Vecsys) Dordrecht: Kluwer Academic Publishers (Kluwer international series in engineering and computer science), 2004, ix+93 pp [originally published in French as Parole et dialogue homme-machine , Editions Eyrolles/ CNRS Editions, 2001]; hardbound, ISBN 1-4020-8036-0, $95.00,  X 61.00, C 87.00; e-book, ISBN 1-4020-8037-9, $95.00, 61.00, C 87.00 Two long-standing research goals in natural language processing are (1) to develop effec-tive natural language interfaces to databases and (2) to develop theories about the con-struction of such systems that generalize be-yond any one system X  X  application domain. This book is a brief (93 pages!) presentation of one such theory within the context of human X  X achine spoken dialog.

After describing the authors X  approach to natural language understanding via the use of semantic case grammars for parsing phrases within a spoken utterance, the book provides an overview of the different types of modeling needed for spoken dialog. The authors properly make a distinction between task and dialog in modeling while noting how the two are frequently blurred together for pragmatic reasons. In regards to dialog modeling, which is the core topic of the book, they distinguish among three classes of mod-els: (1) structural models, (2) plan-oriented models, and (3) logic models. The bulk of the presentation is on structural models re-presented as dialog grammars, but unfortu-nately the authors X  critique of the various types of models is rather superficial.

The authors then present a description of their dialog model for information-request dialogs. Their model is based on an analy-sis of multiple corpora, both spoken and written, that primarily emphasize travel in-formation of various types. The model is presented as a dialog grammar (i.e., it is a structural model), and a brief description of a system architecture and algorithms for task execution and the dialog manager are provided.

While the topic under discussion and the approach taken by the authors is of interest, the overall presentation is unsatisfying for various reasons. Besides the lack of a serious analysis of the trade-offs among the various types of dialog models, the critique and justification of their own model through a careful evaluation is unfortunately also lack-ing. The authors do present an annotation of a complete 15-utterance dialog from one of their corpora, but that is inadequate to enable a reader to come to an informed judgment about the scientific validity of the proposed model.

In conclusion, given its excessive brevity on key issues, its cost ($95), the fact that it is a translation from a French version of the book published in 2001, and the fact that the results from the book have apparently never appeared in any type of journal publication, I cannot justify recommending this book for personal ownership. It might be helpful as a quick introduction to dialog modeling, particularly in regards to grammatical ap-proaches, but that X  X  about it. X  Ronnie W.
 Sandra K  X  ubler (University of T  X  ubingen) Amsterdam: John Benjamins (Natural language processing series, edited by Ruslan Mitkov, volume 7), 2004, viii+294 pp; hardbound, ISBN 90-272-4991-1, $138.00, and 1-58811-590-9,  X  115.00 This monograph, based on Sandra K  X  ubler X  X  Ph.D. thesis, introduces the reader to research at the intersection of data-driven parsing and memory-based learning. Compared to other approaches to parsing, including knowledge-based methods, memory-based parsing takes the provocative standpoint that new struc-tures can be parsed by analogical reason-ing over stored structures, rather than by abstracted rules. All that the approach needs is parsed example sentences stored in mem-ory and a similarity function to find candidate nearest-neighbor sentences that can act as the basis for the analogical-reasoning step.

K  X  ubler begins with a walk past the known approaches in the field to partial and full memory-based parsing. As for partial parsing (constituent chunking and basic grammatical-relation assignment such as subject-verb re-lations), the work of Daelemans, Veenstra, Buchholz, Tjong Kim Sang, and others using memory-based learning is summarized, as well as Krymolowski, Argamon, and Dagan X  X  work on memory-based sequence learning. K  X  ubler then proceeds to review Streiter, whose memory-based parser is an example of a more holistic, sentence-oriented approach which, in contrast to the aforementioned approaches, needs a more complex similar-ity metric to compute the distance between a complete new sentence and stored parsed sentences. A separate chapter is devoted to data-oriented parsing, which uses probabi-listic machinery and extensive back-off from larger to smaller substructures, instead of a single similarity function; in particular, two nonprobabilistic variants by Bod and De Pauw are close cousins of the other memory-based approaches.

The heart of the book is the T  X  uSBL (T  X  ubing-en Similarity-Based Learning) memory-based parser, which implements a similarity-based approach that, analogous to Streiter X  X  ap-proach, attempts to fully parse complete sen-tences by analogy, as rapidly as possible. K  X  ubler X  X  solution is original. While a naive approach based on a similarity between full sentences would be able to correctly parse only a few sentences very close to sentences in memory, K  X  ubler introduces at least two smart generalization enhancements. One is that the T  X  uSBL parser has more than one sim-ilarity metric. When a new sentence is parsed, it is first analyzed at the levels of part-of-speech tags and base constituents. If no reli-able nearest neighbors matching on the word level can be found in memory, the other levels act as back-offs on which to measure similar-ity. The second enhancement is that the search for nearest neighbors is extended by allowing them to have a word or constituent too many or too few or to be longer but contain a good matching subtree. T  X  uSBL X  X  similarity metric, or rather its case-based reasoning function, is actually aware of the internal structure of the nearest-neighbor trees and the partial syntac-tic structure of new sentences.

T  X  uSBL is put to the test on the NEGRA-formatted T  X  uBa-DS treebank of spontaneous speech in specific domains (hotel reser-vations, business appointments, and travel scheduling), gathered in the context of the VERBMOBIL project. K  X  ubler makes the cred-more interesting challenge to parsing meth-ods than nonspontaneous, professionally au-thored texts in a (similarly) closed domain, such as the Wall Street Journal Penn Treebank. An excellent point is made on the limita-tions of the standard PARSEVAL evaluation X  X  focus on syntactic chunking and labeling; arguably, the correctness of the parser in assigning functional labels to grammatical re-lations is at least as interesting as an eval-uation metric. From the reported results we learn that T  X  uSBL does a good job; it attains a PA R S E VA L F -score of about 85 on the spon-taneous speech corpus. We also learn that the back-off part of T  X  uSBL performs as well as the whole T  X  uSBL system in PARSEVAL terms. This underlines the point that parsing based on matching on smaller, local struc-tures, as is done by most other memory-based methods, performs at least on par with more holistic methods. However, T  X  uSBL X  X  holistic memory-based core is more reliable in as-signing correct functional tags to correctly identified grammatical relations. Computational Linguistics Volume 31, Number 3
In sum, the book offers a comprehensive and well-illustrated overview of the area of memory-based parsing, makes all the right methodological points, and describes a system that performs a complex task in a refreshingly simple and smart way. X  Antal van den Bosch, Tilburg University Chu-Ren Huang and
Winfried Lenders (editors) (Institute of Linguistics, Academia Sinica, and University of Bonn) Taipei: Institute of Linguistics, Academia
Sinica (Language and linguistics monograph series B, Frontiers in linguistics I), 2004, viii+207 pp; paperbound, ISBN 957-01-7610-5
This volume consists of the plenary lectures and two workshop panels from the 19th International Conference on Computational
Linguistics (Taipei, 2002), complementing the already-published conference proceedings.

The contents of the volume are as follows:  X  X omputational Linguistics and Beyond:
An Introduction, X  by Chu-Ren Huang andWinfriedLenders  X  X rameNet and Representing the Link between Semantic and Syntactic Relations, X  by Charles J. Fillmore, Josef
Ruppenhofer, and Collin F. Baker  X  X omputational Studies of Language Evolution, X  by William S.-Y. Yang,
Jinyun Ke, and James W. Minett  X  X ew Chances for Deep Linguistic
Processing, X  by Hans Uszkoreit  X  X he Roles of Natural Language and XML in the Semantic Web, X  by Graham Wilcock, Paul Buitelaar, Antonio Pareja-Lora, Barrett Bryant,
Jimmy Lin, and Nancy Ide  X  X hinese Language Processing at the Dawn of the 21st Century, X  by Benjamin K. T X  X ou
Ant  X  onio Branco, Tony McEnery, and Ruslan Mitkov (editors) (Universidade de Lisboa, Lancaster
University, and University of Wolverhampton) Amsterdam and Philadelphia: John
Benjamins (Current studies in linguistic theory), 2005, x+449 pp; hardbound, ISBN 90-272-4777-3 and 1-58811-621-2,  X  120.00, $144.00
This volume contains revised and extended versions of 20 papers chosen from among those presented at the 2002 Discourse Anaph-ora and Anaphora Resolution Colloquium in Lisbon.

The contents of the volume are as follows:  X  X  Sequenced Model of Anaphora and
Ellipsis Resolution, X  by Shalom Lappin  X  X ow to Deal with Wicked Anaphora, X  by
Dan Cristea and Oana-Diana Postolache  X  X  Machine Learning Approach to Preference Strategies for Anaphor
Resolution, X  by Roland Stuckardt  X  X ecomposing Discourse, X  by Joel Tetreault  X  X  Lightweight Approach to Coreference
Resolution for Named Entities in Text, X  by Marin Dimitrov, Kalina Bontcheva,
Hamish Cunningham, and Diana Maynard  X  X  Unified Treatment of Spanish se , X  by
Randy Sharp  X  X inding and Beyond: Issues in Backward Anaphora, X  by Eric Reuland and Sergey
Avrutin  X  X odelling Referential Choice in Discourse: A Cognitive Calculative Approach and a Neural Network Approach, X  by Andr  X  e
Gr  X  uning and Andrej A. Kibrik  X  X egrees of Indirectness: Two Types of
Implicit Referents and Their Retrieval via Unaccounted Pronouns, X  by Francis
Cornish  X  X ronominal Interpretation and the Syntax-Discourse Interface: Real-Time Comprehension and Neurological
Properties, X  by Maria Mercedes Pi  X  nango and Petra Burkhardt  X  X op-Down and Bottom-Up Effects on the Interpretation of Weak Object Pronouns in Greek, X  by Stavroula-Thaleia
Kousta  X  X ifferent Forms Have Different Referential
Properties: Implications for the Notion of  X  X alience, X  X  by Elsi Kaiser 420  X  X eferential Accessibility and Anaphor Resolution: The Case of the French Hybrid Demonstrative Pronoun celui-ci/celle-ci , X  by
Marion Fossard and Franc  X ois Rigalleau  X  X he Predicate-Argument Structure of Discourse Connectives: A Corpus-Based Study, X  by Cassandre Creswell, Katherin Forbes, Eleni Miltsakaki, Rashmi Prasad,
Aravind Joshi, and Bonnie Webber  X  X ombining Centering-Based Models of Salience and Information Structure for Resolving Intersentential Pronominal
Anaphora, X  by Costanza Navarretta  X  X ronouns without NP Antecedents: How Do We Know When a Pronoun Is Referential? X  by Jeanette Gundel, Nancy
Hedberg, and Ron Zacharski  X  X yntactic Form and Discourse Accessibility, X  by Gregory Ward and
Andrew Kehler  X  X oreference and Anaphoric Relations of Demonstrative Noun Phrases in Multilingual Corpus, X  by Renata Vieira, Susanne Salmon-Alt, and Caroline
Gasperin  X  X naphoric Demonstratives: Dealing with the Hard Cases, X  by Marco Rocha  X  X ocus, Activation, and This -Noun Phrases:
An Empirical Study, X  by Massimo Poesio and Natalia N. Modjeska
 Chris Fox and Shalom Lappin (University of Essex and Kings College, London) Oxford: Blackwell Publishing, 2005, xv+192 pp; hardbound, ISBN 0-631-23375-6, $74.95,  X 50.00; paperbound, ISBN 0-631-23376-8, $39.95,  X 19.99 Intensional logic (IL) and its application to natural language, which the present mono-graph addresses, was first developed by Richard Montague in the late 1960s (e.g., Montague 1970a, 1970b). Through the ef-forts of (especially) Barbara Partee (e.g., Partee 1975, 1976), and Richmond Thomason, who edited the posthumous collection of Montague X  X  works (Thomason 1974), this be-came the main framework for those who as-pired to a formal semantic theory for natural language, and these included computational linguists as early as Jerry Hobbs in the late 1970s (e.g., Hobbs and Rosenschein 1977). In fact, until the advent of the current interest in statistical linguistics with its own conception of what semantics is, IL, or some variant of it, was perhaps the main theory of semantics within computational linguistics generally. And within current computational semantics it still is.

But over the years, philosophers, linguists, and computational linguists have noted a va-riety of shortcomings in Montague X  X  version of IL. Montague defined intensions as func-tions from possible worlds to extensions in that world. But this had the effect of mak-ing logically equivalent expressions have the same intension, thus leading to the problem of  X  X ogical omniscience X  (believing/knowing all the logical consequences of what is be-lieved/known). Montague had based his IL on Church X  X  simple theory of types (Church 1940), supplemented with intensions of each type. But this implies that each natural lan-guage item accepts only arguments of some one fixed type. However, this is not true for natural language, where conjunctions, verbs, and pretty much any functional term that accepts arguments at all can accept argu-ments of different types. (For example, and can accept arguments that are of the sentence type, of the verb phrase type, of the adjective type, etc.; and indeed, it can accept arguments of differing types in its different argument places.) Much study has gone into techniques for changing types of arguments so as to ac-commodate this phenomenon. One result of this has been to make the semantic struc-ture of all complex items be binary X  X  con-sequence that seems otherwise to be without justification. And finally, Montague X  X  version of IL is higher order, allowing quantification over entities and functions of any level. This results in the system not having a recursively enumerable set of theorems, and there has al-ways been a desire to have a more restricted system for representing natural language.

The present monograph addresses all these problematic issues. It develops a fine-grained account of intensions from which an account of a first-order property theory is extracted. A  X  X olymorphic X  type structure is devel-oped and the resulting system is claimed  X  X o permit us to achieve expressive power com-parable to a higher-order system like IL while remaining within the formal limits of a first-order system. X 
Although there are many quite difficult concepts introduced in this monograph, in the main it is very clearly written. If the claims made by the authors for their new in-tensional language are borne out by further research, then this is a very important addi-tion to the literature on the foundations of se-mantics for natural language. X  Francis Jeffry Pelletier, Simon Fraser University References Church, Alonzo. 1940. A formulation of the simple theory of types. Journal of Symbolic Logic , 5:56 X 68.
 Hobbs, Jerry and Stanley Rosenschein. 1977. Making computational sense of Montague X  X  intensional logic. Artificial Intelligence , 9:287 X 306.
 Montague, Richard. 1970a. English as a formal language. In Bruno Visentini et al., editor, Linguaggi nella Societ` a e nella
Tecnica . Edizioni di Comunit ` a, Milan, pages 189 X 224.
 Montague, Richard. 1970b. Universal grammar. Theoria , 36:373 X 398.
 Partee, Barbara. 1975. Montague grammar and transformational grammar. Linguistic Inquiry , 6:203 X 300.
 Partee, Barbara. 1976. Montague Grammar .
 Academic Press, NY.
 Thomason, Richmond, editor. 1974. Formal Philosophy: Selected papers of Richard Montague . Yale University Press, New
Haven.
 Clifford Nass and Scott Brave (Stanford University) Cambridge, MA: The MIT Press, 2005, xix+296 pp; hardbound, ISBN 0-262-14092-6, $32.50 Spoken dialogue systems have received in-creased interest because they are potentially much more natural and powerful methods of communicating with machines than are current graphics-based interfaces. Wired for Speech presents basic research in the psycho-logical and sociological aspects of voice syn-thesis and recognition. Its major lesson is that people attribute human characteristics to spo-ken dialogue systems for reasons related to human evolution. But although it contains in-teresting basic research, the book is mainly aimed at giving technological or marketing advice to those seeking to use voice interfaces when creating commercial applications.

The book is oriented around a series of simple experiments designed to show just how pervasive psychological and social influ-ences can be on the opinions and behaviors of people confronted with voice interfaces. Each chapter describes a basic research hypothesis, introduces an experiment to test it, and dis-cusses its implications for designing voice in-terfaces: gender, personality, accent, ethnicity, emotion, number of distinct voices, use of  X  X  X  by the system, voices in concert with faces, mixed synthetic and recorded voices, context, and the effects of errors in human X  X omputer cooperation.

Although Wired for Speech is very accessi-ble, especially to the non-scientist, it is writ-ten with an unusual bibliography style for an academic book: All references and details are given in a notes section at the end of the book, making up one third of the content. This narrative exposition style will probably not satisfy either type of reader: Scientists will be frustrated at the imprecision in argumen-tation, lack of detail in the book itself, and continually having to refer to the notes. The lack of detail also prevents the book from serving as a reference work. Meanwhile those needing advice when implementing voice interfaces will be puzzled at references to Chomsky, Grice, and Zemlin. Thus the book seems to suffer from not knowing its audi-ence well, which is odd as this is precisely the lesson that the book tries to impart.

Another complaint from the scientific point of view is the obsession this particular book has with casting every experimental result as advice for the business and marketing side of voice interfaces, typically concentrat-ing on Web-based e-marketing examples such as buying books on line. Most of the experi-ments have sample sizes of between 40 and 50, but the authors seem ready to invite multi-billion-dollar businesses to immediately base their deployed systems on these results.

Finally, and fundamentally, this book repre-sents research on psychology and sociology, and the impact of these approaches on the interactions between people and machines. It contains very little linguistic content (for instance, text-to-speech system (TTSs) are de-scribed only in terms of their ability to mod-ify pitch, pitch range, volume, etc.) and some of the linguistic detail is wrong, such as the discussion on dialects in the chapter on accent, race, and ethnicity, as well as lexical alignment.

Wired for Speech may hold a strong place in the literature on practical advice for human X  computer interaction, but computational linguistics readers should get this book only if they want to do research on implementations of spoken dialogue systems and be aware of potential complications when designing experiments that will use such systems. X  Charles Callaway, University of Edinburgh M. Lothaire (pseud.) Cambridge, UK: Cambridge University Press (Encyclopedia of mathematics and its applications, volume 105), 2005, xv+610 pp; hardbound, ISBN 0-521-84802-4, $125.00 Applied Combinatorics on Words is a coherently built sequence of chapters on the applications of formal languages and automata theory, particularly finite state. The term word in the title refers to what often is called a string (or ordered sequence) of symbols (from a finite set). Combinatorics are the operations over
Computational Linguistics Volume 32, Number 3 such strings and sets thereof, including algo-rithms for, for example, recognition, manip-ulation, combination, and matching of such strings. The name Lothaire is a nom de plume for a group of authors.

The book is meant primarily for mathemat-ics and computer science students and schol-ars. As the authors note in the preface to the book, the book does not present formal lan-guage and automata theory, and the reader is referred to other, more suitable books. What the book does provide is a mathematical (al-beit limited) viewpoint on (formal) language processing: It contains many of the standard finite-state models, their representations, al-gorithms, and statistical enrichments as of-ten employed in morphological processing, speech recognition, bioinformatics (applica-tions on biological sequences), mathematics, theoretical physics, and number theory.

Basically, there are two chapters on topics related to computational linguistics:  X  X ym-bolic natural language processing X  (by E.
Laporte) and  X  X tatistical natural language processing X  (by M. Mohri). The term nat-ural language processing in both chapters refers largely to processing at the (sub)word level (morphological processing and speech recog-nition, respectively). The chapter by Mohri on statistical NLP constitutes an elegant in-troduction to the mathematical formulation of weighted automata (using semirings) and their application within speech recognition, and is highly recommended for the com-putational linguistics student and scholar.
Unfortunately, the book contains little to nothing about higher-level linguistic process-ing (symbolic or statistical) as it has been practiced in the computational linguistics community over the last decade, e.g., statis-tical parsing, statistical machine translation, and other applications. Seen from a wide computer science perspective, the book may serve as a quick reference for standard math-ematical definitions and algorithms on finite-state automata and their many applications.
In short, this book could be of some inter-est to a reader seeking a well-formulated but dense overview of some of the major appli-cations of weighted finite-state automata. X  Khalil Sima X  X n, Institute for Logic, Language and
Computation, University of Amsterdam
 Hermann Helbig (FernUniversit  X  at Hagen) Springer (Cognitive technologies series, edited by Dov Gabbay and J  X  org Siekmann), 2006, xviii+646 pp. and CD-ROM; ISBN 3-540-24461-1,  X  96.25 This book is an extended description of a knowledge representation formalism, mul-tilayered extended semantic networks (or MultiNets), used by the author and his col-leagues for the semantic representation of natural language. The level of detail means that this is not an easy or introductory read; the book will be most useful for other re-searchers engaged in reconciling knowledge representation and natural language, espe-cially those looking to compare representa-tional devices for dealing with a range of semantic phenomena.

Since the book principally sets out to document what MultiNets are, a brief de-scription is in order. An ordinary semantic network consists of a set of concepts and a set of binary relations between concepts (e.g., kind of , part of ), often represented as a directed graph. MultiNets build on ordinary semantic networks via extension, layering, and encapsulation.
 Using the machinery of MultiNets, the author illustrates a variety of semantic phenomena, including comparative constructions, spatial and temporal relations, intensional and ex-tensional forms of negation, modalities, car-dinality and plurality, and relations between situations.

Philosophically, the book espouses a  X  X eaning as use X  approach to the semantics of MultiNets, rather than a model-theoretic one. While this is an attractive position, the chapter on question answering and inference is too brief to provide much insight about the intended use of MultiNets. This sometimes makes it hard to determine what particular MultiNets are supposed to mean, or how the meaning of one relates to and differs from that of another. The discussion of intensional and extensional negation is a case in point, where pairings of different German sentences (with English translations) and MultiNet diagrams do not always elucidate the dis-tinctions being drawn. The presentation would have benefited from explanation of how different parts of the representations target different aspects of the situation being described.

The technical core of the book is an ad-mirably comprehensive description of each of the 120 or so relations and functions used by MultiNets, drawn from what is clearly very detailed system documentation. But much of the text surrounding this core also reads like hyperlinked system documenta-tion, with a welter of forward and backward references to other sections throughout. This makes it hard for the uninitiated to work their way into understanding what Multi-Nets are about, and stronger editorial direc-tion in the first part of the book could have made it shorter, more self-contained, and easier to follow. X  Dick Crouch, Palo Alto Re-search Center Computational Linguistics Volume 32, Number 4 Archibald Putt (pseudonym)
Hoboken, NJ: IEEE Press and John Wiley &amp; Sons, 2006, x+171 pp; hardbound,
ISBN 0-471-71422-4, $24.95  X  Evaluating ideas: ...Studies reveal that the prestige of the author or coauthors is the first measure of the value of a [scholarly] publi-cation, quite independent of any new ideas the publication may contain. After writing a paper, it is worthwhile to find a prestigious person who is willing to become a coauthor. ...In addition, ...there is yet another way to measure a paper X  X  value without trying to read and understand it. That method is to see how many subsequent papers refer back to it. ...The use of these evaluation methods has led to the Law Governing the Value of
Technical Publications: The value of a technical article, when first published, is proportional to the sum of the prestige of its authors, but its ultimate value is proportional to the number of references to it. It should be noted that this law refers to the value of a paper to its authors, as opposed to any value it may also have to the technical community. X  X  pp. 141 X 142.
 S. A. Koval X  St. Petersburg: St. Petersburg University Press, 2005, 151 pp; paperbound, ISBN 5-288-03731-0 This book X  X  stated goal is to suggest ways to optimize the incorporation of linguistic knowledge about morphology into computer systems. The book is composed of two quite different parts. Part I (roughly half of the book) defines computational linguistics as a field. Part II presents a clear introduction to computational morphology, primarily us-ing examples from Russian. In addition to basal concepts, this part presents a history of morphological analysis systems for Russian; various implementation options for practical systems; an inventory of phenomena that, al-though important for descriptive and theo-retical morphology, have traditionally been less important in computational applications; and ongoing areas of research. The final chap-ter argues that a core, general-purpose model for Russian morphology is needed, and that its development should be largely driven by linguistic research. In the Afterword, the au-thor emphasizes his belief that approaching computational morphology as  X  X  linguistic, not a technical discipline X  is the most  X  X ruit-ful X  approach, because the real object of re-search is language, not computer systems (p. 131). The book seems most suited to lin-guists or students of linguistics who are unac-quainted with computational morphology. X  Marjorie McShane, University of Maryland at Baltimore County

Pierre M. Nugues (Lund University)
Springer (Cognitive technologies series, edited by Dov Gabbay and J  X  org Siekmann), 2006, xx+513 pp; hardbound, ISBN 978-3-540-25031-9, $109.00,  X  90.90
This comprehensive NLP textbook is strongly algorithm-oriented and designed for talented computer programmers who might or might not be linguists. The book occupies a mar-ket niche in between that of Jurafsky and
Martin (2008) and my own humble effort (Covington 1994); it resembles the latter in ap-proach and the former in scope. Perhaps more than either of those, Nugues X  X  book is also useful to working professionals as a hand-book of techniques and algorithms.

Everything is here X  X verything, that is, ex-cept speech synthesis and recognition; pho-netics receives only a four-page summary.
Those wanting to start an NLP course by cov-ering phonetics in some depth should con-sider Coleman (2005) as well as Jurafsky and Martin (2008).

After a brief overview, Nugues covers cor-pus linguistics, markup languages, text sta-tistics, morphology, part-of-speech tagging (two ways), parsing (several ways), seman-tics, and discourse.  X  X eat X  and  X  X cruffy X  approaches are deftly interleaved and com-pared. Unification-based grammar, event se-mantics, and tools such as WordNet and the Penn Treebank are covered in some de-tail. The syntax section includes dependency grammar and even the very recent work of
Nivre (2006), as well as partial parsing and statistical approaches. Many important algo-rithms are presented ready to run, or nearly so, as Prolog or Perl code. If, for example, you want to build a Cocke X  X asami X  X ounger parser, this is the place to look for directions. Explanations are lucid and to-the-point.
Here is an example. Nugues is discussing the fact that, if you sample a corpus for n -grams, some will not occur in your sample at all, but it would be a mistake to consider the unseen ones to be infinitely rare (frequency 0). Thus the counts need to be adjusted:
The formula follows, but the reader ap-proaches it equipped with the unforgettable image of someone shaving excess material off the peaks and bulges of a histogram and spreading it into the valleys.
 opinion, too much for one semester; it must be used selectively. If nothing is skipped, then besides getting a thorough course in natural language processing (except phonetics), the student is expected to learn both Perl and
Prolog along the way, aided by a 50-page Pro-log handbook in Appendix A. My experience isthatPrologisveryhardtolearnonthe fly; in fact, extensive experience with other languages may be a disadvantage because
Prolog is so different. Nonetheless, all the in-formation needed to learn Prolog is here. Perl is treated more casually because it lends itself much more easily to incremental learning.
 page 31, automata is used as singular. On page 69, the treatment of RTF, T E X, and L A T E Xisso short that the student will come away largely unaware of what each of them is actually de-signed for. This is not pernicious, however, as the student will realize that he or she is inadequately informed.
 and well-written book, and I plan to recom-mend it to my students as well as using it myself as a handbook. X  Michael A. Covington, The University of Georgia References Coleman, John. 2005. Introducing Speech and Covington, Michael A. 1994. Natural Jurafsky, Daniel, and James H. Martin. 2008. Nivre, Joakim. 2006. Inductive Dependency Computational Linguistics Volume 33, Number 4 Language and the Learning Curve: A New Theory of Syntactic Development
Anat Ninio (Hebrew University of Jerusalem)
Oxford University Press, 2006, xiv+206 pp; hardbound, ISBN 0-19-929981-1/ 978-0-19-929981-2,  X 55.00; paperbound,
ISBN 0-19-929982-X / 978-0-19-929982-9,  X 24.95
Ninio proposes a provocative theory of early syntactic development. According to her the-ory, children do not create any abstract rep-resentation of language in the form of rules or schemas, nor do they develop any sys-tematic linking rules between syntax and semantics. Instead, they learn a lexicalist syn-tax. Syntactic development consists of learn-ing, for each individual word, the potential predicate X  X rgument relations and their ap-propriate syntactic realizations. Semantic va-lency (the potential semantic relations of a word with other items) and syntactic valency (the ways to express those relations in sen-tences) are learned for each word separately.
The syntactic structure of a sentence is pro-jected from the lexical valency of words by re-cursively applying a single binary operation,
Merge, which combines the Head (the predi-cate word) to its Dependent (the argument).
Ninio argues that the elimination of the abstract rules from the process of syntactic development is supported by evidence from child language research. Examination of the learning curves (i.e., performance vs. experi-ence) for different syntactic patterns shows no sudden change in children X  X  productiv-ity with a particular syntactic pattern, or in their ability to generalize that pattern to novel items. At the same time, learning a syntac-tic pattern speeds up with experience. The learning curves have an accelerating nonlin-ear shape, which suggests that the acquired item-specific syntactic forms facilitate the ac-quisition of the same syntactic form for new items. Ninio suggests that, even though the knowledge of syntax is item-specific, lexical items are not isolated. Instead, they are in-terconnected via transfer , the ability to extend what has been learned in one context to new contexts by analogy. The notion of transfer is supposed to explain children X  X  nonlinear learning curve, as well as their ability to gen-eralize their lexical knowledge to novel items. However, the details of this central mech-anism are left unspecified: it is not clear how and under which constraints the trans-fer between two items can take place. More-over, one expects that the interplay be-tween the item-specific knowledge and the transfer of learning be used to explain some well-studied stages of language learning in children, including imitation, (over)generali-zation, and recovery from making overgen-eralization errors. (This so-called U-shaped learning curve is quite distinct from the non-linear learning curve that gives the book its title.)
Another radical proposal by Ninio is that semantic similarity plays no role in early syn-tactic development. More specifically, trans-fer of learning, and therefore generalization, is based solely on a similarity of form. The de-velopmental evidence provided for this claim is intriguing. For example, in the priming experiments where training on a large set of verbs that appear in transitive sentences helps to elicit transitive usages from chil-dren on novel nonce verbs, the semantic sim-ilarity between the training and the testing verbs does not affect the rate of generaliza-tion. However, there are many studies show-ing that both children and adults use some kind of mapping between form and mean-ing in comprehension tasks. For example, preferential-looking studies show that infants choose one novel action over another based on the form of the sentence introducing the action (e.g., Naigles 1990; Fisher 2002). Sim-ilarly, adult subjects predict certain semantic properties for the arguments of a novel verb based on the form of the sentence the verb appears in (e.g., Gleitman 1990; Kako 2006). In the absence of any abstract rules, these findings can be explained only through a gen-eralization mechanism that takes into account both syntactic and semantic similarity.

Despite the vagueness of some of the suggested mechanisms and occasional in-sufficient analysis, Ninio X  X  book presents a thought-provoking account of syntactic de-velopment that can be of especial interest to the computational linguistics community. Its proposed view of syntax could be val-idated through computational modeling. If 602 it turns out that the proposed theory is in-deed compatible with empirical data, the underlying ideas could be directly applied to the representation and use of syntactic knowledge in different computational lin-guistic applications. X  Afra Alishahi, Univer-sity of Toronto References
Fisher, C. 2002. Structural limits on verb mapping: The role of abstract structure in 2.5-year-olds X  interpretations of novel verbs. Developmental Science , 5(1):55 X 64.

Gleitman, L. 1990. The structural sources of verb meanings. Language Acquisition , 1:135 X 176.

Kako, E. 2006. Thematic role properties of subjects and objects. Cognition , 101:1 X 42.
Naigles, L. 1990. Children use syntax to learn verb meanings. Journal of Child Language , 17:357 X 374.
 Advances in Natural Multimodal Dialogue Systems
Jan van Kuppevelt, Laila Dybkj X r, and Niels Ole Bernsen (editors) (University of Southern Denmark)
Springer (Text, speech, and language technology series, edited by Nancy Ide and Jean V  X  eronis, volume 30), 2005, ix+373 pp; hardbound,
ISBN 978-1-4020-3032-4, $179.00  X  X he chapters in this book jointly contribute to what we shall call the field of natural and multimodal interactive systems engi-neering. This is not yet a well-established field of research and commercial develop-ment but, rather, an emerging one in all as-pects. It brings together, in a process that, arguably, was bound to happen, contribu-tors from many different, and often far more established, fields of research and industrial development. To mention but a few, these in-clude speech technology, computer graphics, and computer vision. The field X  X  rapid ex-pansion seems driven by a shared vision of the potential of new interactive modalities of information representation and exchange for radically transforming the world of computer systems, networks, devices, applications, and so on, from the GUI (graphical user interface) paradigm into something which will enable a far deeper and much more intuitive and natural integration of computer systems into people X  X  work and lives. and detailed picture of where natural and multimodal interactive systems engineering stands today. The book is based on select-ed presentations made at the International
Workshop on Natural, Intelligent, and Ef-fective Interaction in Multimodal Dialogue
Systems held in Copenhagen, Denmark, in 2002 and sponsored by the European CLASS project. CLASS was initiated on the request of the European Commission with the pur-pose of supporting and stimulating collab-oration among Human Language Technology (HLT) projects as well as between HLT projects and relevant projects outside Europe.
The purpose of the workshop was to bring together researchers from academia and in-dustry to discuss innovative approaches and challenges in natural and multimodal interac-tive systems engineering. X  X  From the editors X  preface
The contents of the volume are as follows:  X  X atural and multimodal interactivity  X  X ocial dialogue with embodied  X  X  first experiment in engagement for  X  X ORM X  by Craig H. Martell  X  X n the relationships among speech,  X  X nalysing multimodal communication X  by  X  X o oral messages help visual search? X   X  X eometric and statistical approaches to
Computational Linguistics Volume 33, Number 4  X  X he psychology and technology of talking heads: Applications in language learning X  by Dominic W. Massaro  X  X ffective interaction with talking animated agents in dialogue systems X  by Bj  X  orn
Granstr  X  om and David House  X  X ontrolling the gaze of conversational agents X  by Dirk Heylen, Ivo van Es,
Anton Nijholt, and Betsy van Dijk  X  X IND: A context-based multimodal interpretation framework in conversational systems X  by Joyce Y. Chai, Shimei Pan, and Michelle X. Zhou  X  X  general purpose architecture for intelligent tutoring systems X  by Brady Clark, Oliver Lemon, Alexander Gruenstein, Elizabeth Owen Bratt, John Fry, Stanley Peters, Heather Pon-Barry, Karl Schultz, Zack Thomsen-Gray, and Pucktada
Treeratpituk  X  X IAMM X  X  multimodal dialogue system using haptics X  by Norbert Reithinger, Dirk Fedeler, Ashwani Kumar, Christoph Lauer, Elsa Pecourt, and
Laurent Romary  X  X daptive human X  X omputer dialogue X  by Sorin Dusan and James Flanagan  X  X achine learning approaches to human dialogue modelling X  by Yorick Wilks,
Nick Webb, Andrea Setzer, Mark Hepple, and Roberta Catizone Evaluation of Text and Speech Systems
Laila Dybkj X r, Holmer Hemsen, and Wolfgang Minker (editors) (University of Southern Denmark and University of Ulm)
Springer (Text, speech, and language technology series, edited by Nancy Ide and Jean V  X  eronis, volume 37), 2007, xxiii+288 pp; hardbound,
ISBN 978-1-4020-5815-4, $149.00  X  X his book has its point of departure in courses held at the Tenth European Lan-guage and Speech Network (ELSNET) Sum-mer School on Language and Speech
Communication which took place at NISLab in Odense, Denmark, in July 2002. The topic of the summer school was  X  X valuation and
Assessment of Text and Speech Systems. X   X  X ine (groups of) lecturers contributed to the summer school with courses on evalua-tion of a range of important aspects of text and speech systems, including speaker rec-ognition, speech synthesis, talking animated interface agents, part-of-speech tagging and parsing technologies, machine translation, question-answering and information retriev-al systems, spoken dialogue systems, lan-guage resources, and methods and formats for the representation and annotation of language resources. Eight of these (groups of) lecturers agreed to contribute a chapter to the present book. Since we wanted to keep all the aspects covered by the summer school, an additional author was invited to address the area of speaker recognition and to add speech recognition, which we felt was important to include in the book. Although the point of departure for the book was the ELSNET summer school held in 2002, the decision to make a book was made considerably later. Thus the work on the chapters was only initiated in 2004. First drafts were submitted and reviewed in 2005 and final versions were ready in 2006. X  X  From the editors X  preface The contents of the volume are as follows:  X  X peech and speaker recognition evaluation X  by Sadaoki Furui  X  X valuation of speech synthesis X  by
Nick Campbell  X  X odelling and evaluating verbal and non-verbal communication in talking animated interface agents X  by Bj  X  orn
Granstr  X  om and David House  X  X valuating part-of-speech tagging and parsing X  by Patrick Paroubek  X  X eneral principles of user-oriented evaluation X  by Margaret King  X  X n overview of evaluation methods in TREC ad hoc information retrieval and TREC question answering X  by Simone Teufel  X  X poken dialogue systems evaluation X  by Niels Ole Bernsen, Laila Dybkj X r, and Wolfgang Minker  X  X inguistic resources, development, and evaluation of text and speech systems X  by Christopher Cieri  X  X owards international standards for language resources X  by Nancy Ide and Laurent Romary 604 Text Entry Systems: Mobility, Accessibility, Universality I. Scott MacKenzie and
Kumiko Tanaka-Ishii (editors) (York University, Toronto and University of Tokyo) San Francisco: Morgan Kaufmann Publishers, 2007, x+332 pp; paperbound,
ISBN 978-0-12-373591-1, $49.95,  X 28.99,  X  41.95  X  X dvances in technology have helped create a connected world, and this is none more apparent than in the area of text entry. The growing popularity and success of textual communication has inspired a variety of text entry systems, modalities, and users. There is a text entry system that will meet the needs of all kinds of users X  X  teen sending an
IM with her phone, a businessman checking e-mail on his blackberry, or a visually im-paired woman using a Braille keyboard on her PDA. The capabilities and modalities of text entry are widespread and evolving.  X  Text Entry Systems is a guidebook on the details and foundations of text entry methods, the effectiveness of current modes of text entry, advances in technology, and the creation of new systems. Authorita-tive researchers from the fields of HCI, handwriting recognition, speech recognition, computational linguistics, natural language processing, universal access, industrial de-sign, cognitive science, and image process-ing all provide their expertise. They address the wide reach of this technology, including design for various languages and accommo-dations for those with special physical condi-tions, using specific examples and offering solutions. X  X  From the publisher X  X  announcement
Books listed below that are marked with a  X  have been selected for review in a future issue, and reviewers have been assigned to each.

Authors and publishers who wish their publications to be considered for review in
Computational Linguistics should send a copy to the book review editor, Graeme Hirst,
Department of Computer Science, Univer-sity of Toronto, Toronto, Ontario, Canada
M5S 3G4. All relevant books received will be listed, but not all can be reviewed. Technical reports (other than dissertations) will not be listed or reviewed. Authors should be aware that some publishers will not send books for review (even when instructed to do so); authors wishing to enquire as to whether their book has been received for review may contact the book review editor.
 book reviewers for the journal should contact the book review editor, outlining their qualifications, by e-mail at gh@cs.toronto.edu or at the address above.

Words and Intelligence II: Essays in Honor of Yorick Wilks
Khurshid Ahmad, Christopher Brewster, and Mark Stevenson (editors) (Trinity College, Dublin and University of Sheffield) Springer (Text, Speech and Language
Technology series, edited by Nancy Ide and Jean V  X  eronis, volume 36), 2007, xiv+279 pp; hardbound, ISBN 978-1-4020-5832-5, $139.00
The Categorization of Spatial Entities in Language and Cognition
Michel Aurnague, Maya Hickmann, and Laure Vieu (CNRS X  X niversit  X  e de Toulouse X  X e Mirail, CNRS X  X niversit  X  edeParisVIII,and CNRS X  X niversit  X  e Paul Sabatier,
Toulouse III) John Benjamins Publishing (Human Cognitive Processing series, edited by Marcelo Dascal et al., volume 20), 2007, viii+371 pp; hardbound, ISBN 978-90-272-2374-6, $144.00,  X  120.00 Semi-Supervised Learning
Olivier Chapelle, Bernhard Sch  X  olkopf, and Alexander Zien (Max Planck Institute for Biological Cybernetics, T  X  ubingen)
The MIT Press, 2007, xiii+506 pp; hardbound, ISBN 978-0-262-03358-9, $50.00,  X 32.95 Computational Linguistics Volume 33, Number 4 Chomsky X  X  Universal Grammar: An Introduction
V.J. Cook and Mark Newson (University of Newcastle upon Tyne and E  X  otv  X  os University)
Blackwell Publishing, 2007, vii+326 pp; hardbound, ISBN 978-1-4051-1186-7, $89.95; paperbound, ISBN 978-1-4051-1187-4, $39.95 Corpus Linguistics 25 Years on
Ronberta Facchinetti (editor) (University of Verona)
Rodopi (Language and Computers: Studies in practical linguistics, edited by Christian
Mair et al., volume 62), 2007, v+385 pp; hardbound, ISBN 978-90-420-2195-2,  X  80.00  X  Errors and Intelligence in Computer-Assisted Language Learning: Parsers and Pedagogues
Trude Heift and Mathias Schulze (Simon Fraser University and University of Waterloo)
Routledge (Routledge series in computer-assisted language learning, edited by
Carol Chappelle), 2007, xviii+283 pp; hardbound, ISBN 978-0-415-36191-0, $115.00 Word Frequency and Lexical Diffusion
Betty S. Phillips (Indiana State University)
Palgrave Macmillan (Palgrave studies in language history and language change, edited by Charles Jones), 2007, xiv+252 pp; hardbound, ISBN 978-1-4039-3232-7, $80.00 Prosodic Orientation in English Conversation Beatrice Szczepek Reed (University of Nottingham) Palgrave Macmillan, 2006, xiv+331 pp; hardbound, ISBN 978-0-230-00872-4, $80.00 Language, Discourse, and Social Psychology Ann Weatherall, Bernadette M. Watson, and Cindy Gallois (Victoria University of Wellington and University of Queensland) Palgrave Macmillan (Palgrave advances in linguistics, edited by Christopher N.
 Candlin), 2007, xvii+309 pp; hardbound, ISBN 978-1-4039-9594-0, $90.00; paperbound, ISBN 978-1-4039-9595-7, $34.95 Contrastive Linguistics: History, philosophy, and methodology Pan Wenguo and Tham Wai Mun (East China Normal University and Nanyang Technological University) Continuum, 2007, xii+287 pp; hardbound, ISBN 978-0-8264-8634-9,  X 85.00, $150.00 On the Syntactic Composition of Manner and Motion Maria Luisa Zubizarreta and Eunjeong Oh (University of Southern California and Korea University) The MIT Press, 2007, xi+228 pp; paperbound, ISBN 978-0-262-74029-6, $32.00,  X 19.95
