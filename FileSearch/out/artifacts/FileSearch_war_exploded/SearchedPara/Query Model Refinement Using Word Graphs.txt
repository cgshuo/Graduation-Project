 Pseudo relevance feedback method is an effective method for query model refinement. Most existi ng pseudo relevance feedback methods only take into considera tion the term distribution of the feedback documents, but omit the te rm X  X  context information. This paper presents a graph-based met hod to improve query models, in which a word graph is construc ted to encode terms and their co-occurrence dependencies within the feedback documents. Using a random walk, the weight of each term in the graph can be determined in a context-dependent ma nner, i.e. the weight of a term is strongly dependent on the weights of the connected context terms. Our experimental results on four TREC collections show that our proposed approach is more effective than the existing state-of-the-art approaches. Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Retrieval models; Relevance feedback General Terms: Algorithms Keywords: Query model, Smoothing, Random walk model, Feedback, Term dependency. Information retrieval (IR) using sta tistical language models [5, 8,11] has attracted much attention in recent years. The estimation of query language models and document langua ge models is a key issue, which strongly impacts retrieval eff ectiveness. It is well known that the document model should be sm oothed. Query model smoothing has also been used recently since queries are short and many relevant terms may be missing from them. 
A common method used to smooth query models is to exploit relevant documents. Pseudo releva nce feedback[9, 10, 11] is one such representative way. Another common approach is to exploit relationships between terms: relate d terms are added into the model. Different types of term relationshi ps have been exploited [1,3], including knowledge-based and cor pus-based term relationships. 
In general, most query mode l smoothing approaches focus on introducing new terms according to the following two principles: (1) They should have a high frequency of occurrence within the (pseudo) relevant documents or passages; (2 ) They should have a strong term relationship with the original query terms. Both principles seem reasonable and should be used toge ther. However, most approaches on query language model smoothing us es one of them. This creates limitations to the methods. On one hand, the methods using the first principle, e.g. model-based feedback methods [11], consider terms to be independent, and only rely on the term distribution among the pseudo feedback documents to sm ooth the query model. However, the term independence assumption is not true in reality. On the other hand, the methods that only consider general term relationships [1,3] Blindly exploiting global term re lationships creates a danger of query drift. Some previous studies have trie d to combine the two principles. The combination of local and global context analyses [10] is such an example. Pseudo-relevance feedback has also been used in combination with query expansion using term relationships in [4, 10]. However, we notice that the two expansion principles are still used separately, i.e., expansion te rms are suggested separately using each of the principles and both sets of terms are used to enhance the query model. complementary and they act in the query expansion process together. means that, for a query, a set of terms can be suggested according to the pseudo feedback documents. In order to accurately estimate their weight, the context information such as the surrounding terms should be taken into considerati on. Term relationships within feedback documents can be very he lpful to improve query model in a context-dependent manner. This is the basic idea that we exploit in this paper. 
The idea will be implemented using a word graph: the words from the pseudo feedback documents and their related terms are used as nodes in the graph, and term relationships as their edges. An iterative random walk process will be performed on the word graph: the weight of a term in the expanded query model will be determined by the probability it receives after the random walk process. A higher probability for a term means that it is highly context. 
Our approach has the following advantages: (1) It can incorporate the pseudo feedback a nd term relationship methods into a unified framework naturally. The word graph in our approach can exploit the rich information with the feedback documents, including both the relevant terms and accurate term dependencies. Compared to the traditional approaches ba sed on pseudo feedback documents only, our method can accurately estimate the score of each term by consider its context information. Compared to the approaches using global term relationships, our met hod can avoid the danger of query drift by using the query related local information. (2) The iterative algorithm gradually propagates the score of a term to those other terms that are directly or indirectly linked to it. Compared to a query expansion approach using a se t of direct term relationships, this iterative propagation can result in a higher coverage of related terms. It can also lead to a more reasonable term weighting dependent on the query context. 
We carry out experiments on f our TREC datasets and our results demonstrate that the proposed word graph-based method can outperform the existing state-of-the-art approaches. In this section, we propose a new query model refinement approach: random walk smoothi ng method which exploits the expanded terms and term relati onships based on the feedback documents. For each query, we construct a word graph based on the feedback documents: the vertices are words, and the edges encode term co-occurrence relationships. The score of each vertex will propagate to the vertices which are linked to by it. The importance of a vertex is determ ined based on the votes that are cast for it as well as the score of the voting vertices. The algorithm's starting state corresponds to the initial query model, and then the score propagation algorithm is run iteratively to re-weight the vertices. Finally, the random walk algorithm will converge and the score of each vertex will become stable. The query model can then be estimated based on the stabilized scores. We will call this model RW-FB (R andom Walk FeedBack) model. 
We will describe our method to construct a graph in the next section. Let us now assume that we have such a graph and present some details about the graph-base d random work algorithm. It is similar to the method used in [2, 6, 7], but our graph is constructed in a different way. correspond to the words, and the weight of an edge score of a vertex i v is defined as follows: where f t ( v i ) is the score of vertex i v at step t , initial score of vertex i v ; (0,1)  X   X  represents the weight of the initial score; (, ) j i wv v is the weight of the edge linking v ; () i In v is the set of vertices that point to vertex Out v is the set of vertices that are pointed to by vertex above formulation is similar to the PageRank [2] model. However, we notice an important differe nce with PageRank: The updating algorithm uses 0 () i f v instead of a uniform jumping probability 1/N. This guarantees that the new model after each step of random walk will not deviate much from the initial model. Therefore, the initial query terms will end up havi ng relatively high scores after the random walk, and through the score propagation, the terms which the query terms link to will also obtain high scores. 
The score of each vertex is recalculated iteratively until convergence or the number of iterations reaches a predefined threshold (e.g. 10 in our experiment ). In practice, a few iterations will be enough. The process stops when the change in f ( V smaller than a predefined threshold (e.g. 10 -6 ). The change c is computed as follows: The construction of the word gra ph is an important factor that influences performance, where both the selection of the vertices to be included in the graph and the weighting of the edges are essential. In this paper, we propose a new type of word graph based on feedback documents, which can fully utilize the helpful information contained within th em, including both the relevant terms and their dependencies. This section will introduce the proposed word graph construction method. 
Firstly, we obtain the top ranked N documents to form a document set () F d with an initial retrieval method. Secondly, we extract all the words from the feedback documents, which become the vertices of the word graph. Thirdly, we extract the word co-occurrence dependencies fro m the feedback documents in order to weight the edges. 
V is the set of terms occurring in this document set () F d . The weight of each edge in the word graph is computed by the following formula: where , ab are words, ( , ) wab represents the strength of the relationship between a and b , and (, , ) i co a b d represents the number of times that , ab co-occur within a sliding window (i.e. 10) within document i d . 
However, formula 3 does not consider the useful IDF information. A term which has high document frequency will co-occur with many other terms a nd thus obtain a high score. But this does not mean that the term has a strong relationship with the order to correctly weight the importance of a term, we use the following formula to compute the transition probability between two terms: N is the number of documen ts in the collection; df(c) is the document frequency of the word w; and (Re f (a ) 0.5) + is a slightly smoothed DF , which will restrict the values to an order of magnitude. It acts to decrease the value of ( | ) Pab is high. The above method to compute the weight of the edge does not take into account the weight of each feedback document. Co-occurrences in different documen ts all contribute the same. In order to take the weights of the feedback documents into consideration, we define another method to compute the weight of the edge, which assumes the co-occurrences in different documents will have different effects. We will call this model WRW-FB (Weighted RW-FB ) model. where ( ) i f d represent the weight of document d, which can be obtained from the initial retrieval model. And we make a normalization of ( ) i f d to [0, 1] as follows: In this section, we will evaluate the quality of our RW-FB and compare it to the state-of-the-a rt methods. The first model we compare is the mixture model ( Mix-FB ) proposed in [10]. Its effectiveness represents the current state of the art feedback method. This model also uses feedback documents, but only obtains a term distribution, to smooth the original query model. 
The second model we compare is another graph-based random walk query model ( RW-C ), in which the term relationship is set to their mutual information. The process of the random walk algorithm in RW-C is the same as that in RW-FB. RW-C is indeed similar to the QMWG model in [7], which also exploits a word graph constructed from the whole document collection. In addition, we will evaluate the performance of an improved RW-FB model  X  the weighted RW-FB or WRW-FB, which considers the weight of the retrieved document. 
We implemented our new feedback model on top of the Lemur toolkit 1 . We first use the basic KL-divergence method with Dirichlet smoothing without feedback to retrieve 3,000 documents for each query. Then, we select the top N documents (several values of N will be tested) as feedback documents to update the query model, and use the KL-divergence method again to perform a second round retrieval on the first set of 3,000 documents. When updating the query model, we truncate the es timated query model by keeping only the 100 strongest terms and by ignoring all terms having a probability less than 0.0001. We evaluate the proposed method on four representative TREC data sets: AP (Associated Pre ss news 1988-90), LA (LA Times), SJMN (San Jose Mercury News 1991) and WT2G (TREC8 small web collection). We used the title field of a query/topic description to simulate short keyw ord queries in our experiments. In all experiments, both the que ries and documents are stemmed (Krovetz stemmer), and stopwords are removed. 
In all our experiments, the cuto ff of relevant documents is set as 1000. We use two performan ce measures: M ean Average Precision (MAP) and Precision at top 10 documents (P@10). In table 3, we compare the performance of RW-FB and Mix-FB with three different numbers of f eedback documents: 5, 10, and 20. 1 http://www.lemurproject.org/ Mix-FB [7] has two major para meters to tune, one for the background noise in the mixture model and the other for the interpolation weight. We fix the noise parameter to be 0.9, and tune the interpolation weight parameter to get the optimal performance of pseudo-feedback. For RW-FB, we tune the main parameter get the optimal result. 
The evaluation results in table 3 show a direct comparison between RW-FB and Mix-FB. We can see that RW-FB can outperform Mix-FB o n different data collections when using different numbers of feedback doc uments, which indicates that the improvement is not very sensitive to the number of documents used for feedback. The word graph in RW-FB can be considered as a local word graph based on feedback documents while RW-C features a global word graph similar to the QMWG mode l in [7]. Table 1 shows that RW-FB can outperform RW-C consis tently and significantly, which indicate local word graph is more effective than global word graph. A possible explanation to our expe rimental result is that a word graph based on a feedback documen t set will have less noise than that based on the whole document collection. 
Table 1: Comparing RW-FB with RW-C. Top 10 documents Data RW-C (QMWG) RW-FB AP88~90 p@10 0.4475 0.4657(+4.07%**) LA p@10 0.2837 0.3000(+5.75%**) SJMN p@10 0.3160 0.3415(+8.07%***) WT2G p@10 0.4460 0.4980(+11.66%***) The above experimental results are based on the RW-FB methods which do not consider the weight of feedback documents. The following section tests the effectiveness of a weighted RW-FB method ( WRW-FB ), which takes the weights of the documents into consideration as shown in equation 5. From table 2 we can see that WRW-FB has a consistently higher performance than RW-FB (except P@10 for WT2G). These resu lts show that the weight of each document is useful when estimating term co-occurrence dependency .
 Table 2: Comparing WRW-FB with RW-FB. Top 10 documents are selected as feedback document. Data RW-FB WRW-FB LA p@10 0.3000 0.3031(+1.03%) The parameter  X  controls the weight of the initial query model during the iterations. In this secti on, we examine the sensitivity of performance to the parameter  X  , and throughout this series of experiments, the size of the sliding window is fixed at 10. retrieval performance. From it, we can see that setting  X  to 0.1 or 0.2 usually yields the best retrieval performance across all the test collections regardless of th e number of feedback documents. This shows the optimal setting of this parameter is relatively stable across different data sets , and the retrieval performance is not very sensitive to  X  if it is set in the range of 0.1~0.3. In this paper, we proposed a graph-based query model smoothing method, which can leverage th e pseudo relevance feedback method with word relationships in a unified framework. The query-specific local word graph based on the feedback documents can better capture the term di stribution and useful term co-occurrence relationships than a global word graph. The random walk process to determine the final query model turns out to work well. The method has been evaluate d on four test collections. In comparisons with the existing query model smoothing methods such as the model-based feedback model Mixture Feedback model (Mix-FB) and RW-C show that our method is more effective. The work can be further improved in several ways. 1) Extending the method with other ki nd of term relationships, such as those featured in other semantic resources such as WordNet or Wikipedia. 2) We can dete rmine domain-specific term relationships: a different set of term relationships will be learnt for a specific domain. Then only the te rm relationships in the domain of the given query will be incorporated into the word graph, as in personalized Pagerank. This will bring less noise in the query model than using the global relations. This work was supported by the National Science Foundation of China (Grants No.60736044, 60773027, 90920010), as well as 863 Hi-Tech Research and Development Program of China (Grants No. 2008AA01Z145, 2006AA010108). [1] J. Bai, D, Song, P. Bruza, J. Nie, G. Cao. 2007. Query [2] S. Brin and L. Page. 1998. Th e anatomy of a large-scale [3] G. Cao, J. Nie, J. Bai. 2005. In tegrating word relationships into [4] G. Cao, J. Nie, J. Gao, S. Robertson. 2008. Selecting Good [5] J. Lafferty and C. Zhai. 2001. Document language models, [6] R. Mihalcea and P. Tarau. 2004. TextRank  X  bringing order [7] Q. Mei, D. Zhang, C. Zhai . 2008. A General Optimization [8] J. Ponte and W. B. Croft. 1998. A language modeling approach [9] J. J. Rocchio. 1971. Relevan ce feedback in information [10] J. Xu, W.B. Croft. 1996. Quer y expansion using local and [11] C. Zhai and J. Lafferty. 2001. Model-based feedback in the 
