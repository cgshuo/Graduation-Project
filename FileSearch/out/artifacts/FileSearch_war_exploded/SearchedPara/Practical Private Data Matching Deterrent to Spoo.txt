 Private data matching between the data sets of two poten-tially distrusted parties has a wide range of applications. However, existing solutions have substantial weaknesses and do not meet the needs of many practical application scenar-ios. In particular, practical private data matching applica-tions often require discouraging the matching parties from spoofing their private inputs. In this paper, we address this challenge by forcing the matching parties to  X  X scrow X  the data they use for matching to an auditorial agent, and in the  X  X fter-the-fact X  period, they undertake the liability to attest the genuineness of the escrowed data.
 H.4 [ Information Systems Applications ]: Miscellaneous; H.2.8 [ Information Systems ]: Database Management X  Database Applications General Terms: Security Keywords: Data privacy, Secure multi-party computation.
Private data matching considers the scenarios that two parties each having a set of data objects wish to determine the objects common to their data sets, while without re-vealing any additional information to each other. Private data matching could be either symmetric in the sense that both parties are interested in the matching result, or asym-metric in that one party gets the matching result and the other party is only interested to assist its counterpart for matching.

In general, private data matching belongs to the secure multi-party computation problems, where two parties with respective private inputs x and y compute a function f ( x, y ) in such a way that each of them learns nothing other than the value of f ( x, y ). However, private data matching in prac-tice needs to address issues beyond the scope of secure multi-party computation. More specifically, given x and y secure multi-party computation concerns with the way f ( x, y )is computed that does not reveal x and y , whereas practical private data matching needs to additionally guarantee that the two matching parties X  private inputs x and y are gen-uine , i.e., x and y are indeed the data owned by the two parties. As a result, while sharing certain generic properties of secure multi-party computation, private data matching in practice has an extra dimension to consider, i.e., to prevent the matching parties from spoofing their private inputs.
A weakness of many existing works on private matching such as [1, 5, 7] is that they assume the two matching parties follow semi-honest behaviors [6], which, among others, stipu-lates that the matching parties do not spoof their private in-puts. This appears to be too strong an assumption for many data matching applications. The reference [8] gave several protocols to address input spoofing by the two matching parties, but it has changed the implication of private data matching in the sense that data objects of equal values as well as originating from the same users are matched (private data matching by definition actually refers to matching data objects of equal values).
We propose an  X  X fter the fact X  detection approach to de-ter the matching parties from spoofing their inputs. More specifically, we assume an auditing mechanism within our system that takes the responsibility for overseeing the data matching transactions: the matching parties may share a single auditorial agent or each matching party (or a group of matching parties) has an independent auditorial agent based on, e.g., administrative domains. For simplicity, we assume all parties have a single auditorial agent in the se-quel. In the process of data matching, each matching party  X  X scrows X  the data objects it uses for matching to the au-ditorial agent, i.e., the party encrypts its data objects using the public key of the auditorial agent, and submits the en-crypted data together with the transcript components for matching. As a result, the receiving matching party gets a data escrow that can be opened by the auditorial agent. In a later  X  X fter the fact X  detection phase either under the demand of the other party or to go through certain regular oversight formalities, a party is liable to attest the genuine-ness of its  X  X scrowed X  data objects to the auditorial agent.
A challenge in this approach is to enable a party to con-vince the other party that the same data objects are used in escrow and for matching, while without revealing extra information. Our basic idea is as follows. Suppose a data object m is used by a party for matching. The matching transcript includes two main components: the first compo-nent is h m = m e used for data matching, where e is a ran-dom number; the second is C m =( c 1 = m ( PK ) r ,c 2 = g serving as the escrow of m ,where PK is the public key (El-Gamal encryption) of the auditorial agent, and r is another random number. We then use a zero-knowledge proof of knowledge (e.g., [2, 3, 4]) to show that h m and c m 1 contain the same data object m .

Adversarial model . We assume malicious matching parties in our system. A malicious party can act in arbitrary ways, e.g., it can submit a spoof query by adding bogus data to its private input, or terminate a protocol prematurely at any point of execution.

System setup . Each of the two matching parties Al-ice and Bob has a key pair for a standard digital signa-ture algorithm. The matching parties need to sign the  X  X s-crowed X  data to show their irrefutable involvement. We de-note SIGN A (.) (resp. SIGN B (.)) the signing by Alice (resp. Bob). The auditorial agent has a public-private key pair y = g x (mod p ) ,x that corresponds to AlGamal encryp-tion, where p =2 q + 1 is a large prime ( q is also a prime), and g  X  QR p with QR p denoting the subgroup of quadratic residues in Z  X  p of order q . The system also decides on a cryptographic hash function H : { 0 , 1 }  X   X  QR p .
The protocol . For limit of space, we only present the protocol for asymmetric private data matching, where Alice eventually gets the matching result. The protocol is out-lined below, where Alice has a genuine data set DS A = { a 1 ,a 2 , ..., a N A } of N A data objects, and Bob has a genuine data set DS B = { b 1 ,b 2 , ..., b N B } of N B data objects. We use NPoK { (  X  ): y = g  X  } to denote the non-interactive  X  X ero-knowledge Proof of Knowledge of a value  X  such that y = g holds X , following the notations in [4].  X  X fter the fact X  detection . In the  X  X fter the fact X  detection step, a matching party is required to attest the genuineness of the data objects it escrowed in matching. Let us suppose the auditorial agent gets { ( c i 1 ,c i 2 1 ..N A } and  X  A from Bob, and asks Alice for attestation. The auditorial agent first checks whether  X  A is a valid signature on { ( c i 1 ,c i 2 ): i =1 ..N A } . Upon determining that the data are indeed from Alice, the auditorial agent decrypts each ( c key x . Since the  X  X scrowed data X  h a i is a hash value, Alice is required to surrender the original data object a i together with the proof that vouches for the genuineness of a i .The auditorial agent checks whether h a i = H ( a i ) and whether the proof supports that a i is indeed a genuine data object.
Deterrent to spoofing attack . Our method of data es-crow together with the zero-knowledge proof of knowledge forces the matching parties to correctly  X  X scrow X  the data they use in matching to the auditorial agent. As a conse-quence, if a matching party spoofs its input, it cannot pro-duce to the auditorial agent valid proofs for the bogus data objects. Depending on applications, failure to present cor-rect attestation proofs for the data objects it uses in match-ing, a party may face compromise of reputation or punitive legal actions. We thus believe that leaving the evidence at the auditorial agent for future spoofing investigation should be a sufficient deterrent to spoofing attacks.
