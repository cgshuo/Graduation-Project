
Selecting the best items to display for a given user visit (i. e., page view) from an available set is a fundamental problem in applications like web search, online advertising and conte nt publishing. For instance, items are documents for web searc h, ads for online advertising and articles for content publish ing. Typically, the goal is to maximize a readily available yield met-ric that acts as a proxy for long-term success, click-rate (C TR) is often used in practice. If the CTR of items are known, one could maximize clicks by simply displaying high CTR items to user visits. Of course, CTR X  X  are unknown and estimated from data obtained through a sequential process. Multi-arm ed bandit schemes provide an attractive and tractable framewo rk to construct such sequential processes in an optimal fashio n ([1], [2], [3]). Originally motivated by problems in a gambl ing scenario, these schemes construct sequential designs to pl ay different arms of a slot machine with the goal of maximizing the expected total reward for the gambler. By now, multi-armed bandit schemes have found wide applicability in diver se web search [7] and online advertising [8]. However, existin g solutions to the  X  X tandard X  bandit problem that assumes a fix ed set of arms with no delayed feedback are sub-optimal for our application scenario. We propose a new set of schemes that significantly outperform the standard bandit solutions and have wider applicability.

Motivating application: We consider maximizing total clicks on a content module published by Yahoo! The module is a panel with several slots, where each slot displays an editorially programmed item (story) selected from a conten t pool of several items. For simplicity, we focus on maximizin g clicks on the most prominent slot of the module that obtains a large fraction of clicks. More precisely, we construct sche mes that select an item from the available pool for every user vis it to maximize overall CTR.

In this paper, we primarily focus on explore/exploit method s that quickly converge to the most popular item (item with highest CTR at any point in time). In Section IV-C, we discuss an extension to personalized recommendation based on user clusters. Bandit solutions for general machine-learning m odels are beyond the scope of this paper.

We now discuss the system constraints and characteristics o f our application that violate assumptions underlying stand ard bandit solutions, but are typical in the context of content publishing on the web. The standard bandit problem considers a fixed set of arms (items), each of which is assumed to have an unknown but fixed reward (CTR). After pulling an arm (showing an item to a user visit), one immediately obtains an observation (click or no click) that reduces uncertainty about the reward (CTR) distribution of the arm. The goal is to find a sequential scheme that maximizes the expected total clicks after a certain number of arm pulls. However, in our application, we have:  X  Dynamic set of items : Items usually have short lifetimes  X  Non-stationary CTR : As shown in [9], the CTR of  X  Batch Serving : Click and view observations are delayed A. Problem Definition
Throughout, index i and t denote item and time interval (we used 5 minute intervals) respectively. Let p unobserved time-varying CTR of item i at time t , N the total number of user visits (i.e., page views), and I dynamic, hence the suffix t on I . If p optimal solution is to serve all N estimated by showing item i to some visits. We assume N are known (usually obtained through a forecasting model).
Serving scheme: A serving scheme (also called policy )  X  is an algorithm that, for each interval t , decides what fraction of user visits should be allocated to each item based on all data observed before t . Let x  X  number) of user visits that  X  allocates to item i in interval t , where P are different from standard multi-armed bandit ones where feedback is assumed instantaneous and item states change af ter each user visit. We drop superscript  X  and subscript they are clear from the context.

Observation: We observe c  X  user visits to item i in interval t ; c  X  Following [9], we assume c  X  has also been validated for our application. We note that it is straightforward to replace Poisson with Binomial . Let (also called reward ) over T intervals (typically, a few months) obtained through scheme  X  .

Definition 1: Oracle optimal scheme: Assume an oracle that knows p ( t = arg max i p it
Definition 2: Regret: The regret of scheme  X  is the differ-ence between the oracle optimal reward and its reward; i.e., E [ R (  X  + , T )]  X  E [ R (  X , T )] .

Definition 3: Bayes optimal scheme: Assume a prior dis-tribution P over p ing scheme  X   X  is Bayes optimal under P if E max  X  E P [ R (  X , T )] , where E P denote expectation computed under P .
 Our goal is to find a Bayes optimal scheme. Note that even Bayes optimal schemes have non-zero regrets, because they need to explore items to estimate item CTR X  X , while the oracl e optimal scheme does not explore at all.
 B. Related Work and Our Contributions
There is a rich literature on the bandit problem; a proper review of this area is not possible here. The standard armed bandit assumes the arms are static over time. Although lifetime constraints can be modeled through restless bandi ts infeasible (PSPACE-complete [13]) for even modest-scale a p-plications. Recently in Machine Learning, Chakrabarti et a l. [14] introduced mortal bandits where they study regret (defi ned differently from ours) bounds for dynamic arms. They work in a model agnostic framework and do not exploit an available predictive distribution as we do through a Bayesian model. Several bandit schemes for non-stationary reward distribu tion have been proposed. For instance, Slivkins and Upfal [15] reported a study of restless bandits with reward following a Brownian motion; this however, does not apply to our setting . Adversarial bandit schemes [16] also assume non-stationar ity; the solutions are however sub-optimal in our scenario as we shall see in Section IV. While delayed outcomes [17] and parallel bandits [18] (which select multiple items but each one is picked at most once in one action) have been studied in the literature, to the best of our knowledge, bandit schemes tha t provide a batch serving plan have not been carefully analyze d before.

It is important to note that most of the known optimality where regret is defined based on the  X  X ptimal scheme X  that plays the single best arm at all times . Our setting is very different where arms have short lifetimes of non-zero rewar ds and different start times (common in many web applications, e.g., news, advertising, etc.). Thus, we define regret based on the oracle optimal scheme that plays the best available arm at each individual time point; the best available arms at different time points may be different. Playing the single b est arm (which has a short period of non-zero reward) at all times would perform poorly in our setting. Optimality bounds for o ur regret definition are generally unknown and a challenging ar ea for future research.

Our approach: Our goal is to find effective solutions to real-world explore/exploit problems. Deriving theoret ically optimal regret bounds with large sample size is not the focus of this paper. As we shall show in Section IV, schemes with opti-mal regret bounds may have poor empirical performance due to inappropriate assumptions and large constants associat ed with regret bounds. Our approach is to appropriately model the characteristics of our application, develop Bayes opti mal solutions in simplified scenarios and near-optimal solutio ns to the general case by appropriate approximations, and then empirically evaluate a large number of schemes using real log data and finally conduct live experiments in the target application that serves real users.

Our contributions: We provide an extensive study of batch schemes in a multi-armed bandit framework for applications with dynamic item pools, non-stationary reward distributi ons and delayed feedback (common in web applications). (1) We propose two novel classes of bandit schemes: (a) schemes that are developed from first principles in a Bayesian framework, and (b) schemes that are adaptations of standard bandit meth -ods. (2) We show the effectiveness of our solutions through extensive evaluation on simulated and real data obtained fr om a content publishing application, and also results from live Such live experiments are important to validate applicabil ity of bandit schemes, but rarely reported in the literature. (3 ) We show that our Bayesian solution is both computationally effi -cient and better than other other schemes in our experiments . Such an empirical comparison between Bayesian and non-Bayesian schemes on a real application has not been reported before. (4) We show the empirical characteristics of a varie ty of schemes (in Section IV-B), explaining the reasons behind the strength and weakness of each scheme.

In this section, we describe our Bayesian solution with approximations that ensure computational feasibility. We de-velop our Bayesian solution in stages, beginning with optim al solutions for simple scenarios that assume a fixed set of item s. This is followed by our near-optimal solution to the general case similar to an index policy (solving a K -dimensional problem through K one-dimensional ones).

Basics: To simplify notations, here we consider a single item and drop index i . The item CTR in interval t p  X  P (  X  t ) , where vector  X  t is the state or parameter of the distribution. After we serve the item x clicks, we obtain the posterior (updated prior) at time 1 , p emphasize that  X  write  X  a stationary CTR (dynamic models will be discussed later).
Gamma-Poisson model (GP): Following [9], we assume, at time t , the prior distribution P (  X  mean  X  user visits with the item and get c count distribution is ( c conjugacy, P (  X   X  (respectively) observed so far. When computing the fractio n of user visits to be allocated to the item in interval t , item state  X  we have not observed c obtained with an allocation of x
One-step lookahead: We consider the optimal scheme with only one remaining interval (call this interval 1 ). That is, we want to find x clicks: subject to P to see that the maximum is attained if we assign 100% visits to the item with the highest expected CTR; i.e, x if E [ p i  X  1 ] = max i E [ p i 1 ] , and x i 1 = 0 otherwise. A. 2  X  2 Case: Two Items, Two Intervals
Next simplified case where we can efficiently find the optimal solution is the 2  X  2 case, i.e., we have two items and two remaining intervals. In fact, the two-armed case hav e been studied in the literature before (e.g., [21], [22]) but under different assumptions. Let us also assume we know the CTR of one item without any uncertainty. We use 0 and 1 as time indices for the two intervals. Since there are only two items , we simplify our notations.  X  N 0 , N 1 : number of user visits at time 0 and 1.  X  q 0 , q 1 : CTR of the certain item at time 0 and 1.  X  p 0  X  P (  X  0 ) , p 1  X  P (  X  1 ) are CTR distributions of the  X  x , x 1 are the fractions of user visits allocated to the  X  c , a random variable, denotes the number of clicks that  X  Let  X  p 0 = E [ p 0 ] and  X  p 1 ( x, c ) = E [ p 1 | x, c ]
The current state  X  of c , hence random. Also, the decision x 1 is a function of To emphasize this, we write x all such functions. Our goal is to find x  X  [0 , 1] and x that maximize the expected total number of clicks in the two intervals given by Since q the expectation term. That is, we find x and x Note that Gain ( x, x of clicks between: (a) a scheme that distributes user visits be-tween two items ( xN item at time 0 and 1) and (b) a scheme that always serves the certain item. Intuitively, it quantifies the gain obtain ed by exploring the uncertain item that could be potentially better than the certain one.

Proposition 1: Given  X  where Gain ( x ) = Gain ( x,  X 
Note that  X  p p  X  ) / (  X  + xN 0 ) for Gamma) are functions of  X  0 ( = [  X ,  X  ] for Gamma), the tail expectation E with respect to the marginal distribution of c appears since interval 1 is the last interval and from the one-step lookahe ad case, when the gain is maximized, x 1 depending on whether  X  p
Optimal solution: max ber of clicks in the 2  X  2 case. For a given class of distribution P , the optimal x can be obtained numerically. For computa-tional efficiency, we use a Normal approximation.

Normal approximation: Assume  X  p Normal. Note that here we only approximate the posterior ( p 1 | x, c ) Gamma. Let  X  2 for the Gamma distribution. By a derivation using iterated expectations with respect to distributions ( c | p obtain: Using the Normal approximation, the tail expectation is ob-tained in closed form and given below.

Proposition 2: Let  X  and  X  denote the density and distri-bution functions of the standard normal.

Gain ( x,  X  0 , q 0 , q 1 , N 0 , N 1 )  X  N 0 x ( X  p 0  X  q
The Normal approximation makes Gain ( x ) a differentiable function with some nice properties. Figure 1(a) shows three Gain functions with three different prior means. In particu lar, it can be shown that Gain ( x ) has at most one minimum and at most one maximum (excluding the boundaries). It can also dx 2 Gain ( x ) &lt; 0 optimal solution is x = 0 , x  X  or 1.

Proposition 3: Let x  X  denote the optimal solution to the normal approximation. The time complexity of finding solu-tion x such that | x  X  x  X  | &lt;  X  is O (log 1 / X  ) .
Properties of the gain function: We note some interesting properties of the gain function as shown in Figure 1. In parti c-ular, Figure 1(b) shows the optimal amount of exploration as a function of uncertainty (small  X  means high uncertainty) for different mean values of the uncertain item. Contrary to wha t one might expect, we note that the amount of exploration is not monotonically decreasing as uncertainty goes down (i.e .,  X  goes up); we in fact should not explore too much when the degree of uncertainty is too high (i.e., small  X  ). The scheme is cautious and does not allocate too many observations to item s that have high degree of uncertainty.
 B. K  X  2 Case: K Items, 2 Intervals
We now consider the case of K items (without distinguish-ing between certain and uncertain ones), but still use two intervals. The optimal solution to this problem can be define d exactly (details omitted), but solving for it is computatio nally hard. Thus, we apply the Lagrange relaxation technique to fin d a near optimal solution. Although the Lagrange relaxation [ 2] is well-known, the application to our problem is novel.
Recall that p use vectors:  X  [ c item i at time t  X  { 0 , 1 } , and c of clicks item i obtained at time 0 . Our goal is the obtain and x the two intervals. When we make this decision,  X  and  X  vector of numbers, but x x = [ x 0 , x 1 ] Now, the expected total number of clicks is Our goal is to find
R  X  (  X  0 , N 0 , N 1 ) = max
Lagrange relaxation: To make the above optimization computationally feasible, we relax the constraints on inte rval 1. Instead of requiring P  X  , we only require P optimization problem becomes: Next, we define the value function V as: where q regulatory conditions, We now state two important properties of the V function that simplifies computation.

Proposition 4: Convexity: V (  X  in ( q 0 , q 1 ) .

Since V is convex in ( q convex optimization tools can be used to find the minimum solution. However, we need to compute V efficiently given ( q property stated below.

Proposition 5: Separability: V (  X  X where Gain is defined in Proposition 1.

Due to separability, the V function can be computed by maximization (over x independent maximization reduces to the gain maximization discussed in Section II-A and can be solved efficiently. Thus , we are able to solve a joint maximization (over x problem in a K -dimensional space through K independent one dimensional optimization. This decoupling is similar in spirit to Gittins (1979) index policy calculation.

Near optimal solution: To compute the fraction of user visits allocated to each item i in the coming interval (in-terval 0), we use a standard convex optimizer to compute min q solution. Then, is the fraction to be given to item i . Note that the Lan-grange relaxation technique was first applied by [2] to bandi t problems. Studies of several related (but different) probl ems suggest that Lagrange relaxation usually provides near opt imal solutions as [11] noted  X  X  developing body of empirical evidence testifies to the strong performance of Whittle X  X  in dex [Lagrange-relaxation based] policies. X  C. General Solution We now describe the solution to the general case.

Dynamic set of items: We extend the near-optimal solution for the K  X  2 case to a dynamic set of items with multiple future intervals. Now, the set I can be incorporated in our framework by marginalizing over the value function. Here, we assume a deterministic ease of exposition. I and e ( i )  X  0 , called live items which start before the current time t = 0 . Let T = max the live item having the longest remaining lifetime. Let I the set of items i with 1  X  s ( i )  X  T , called future items . Let T ( i ) = min { T, e ( i ) } .

We note that, after we apply Lagrange relaxation, the modified formulae), but computational complexity increase s exponentially in the number of intervals. For efficiency, we propose to approximate the multi-interval case by only con-sidering two stages for each item i : The first interval of the exploitation stage. These two stages correspond to and t = 1 in the K  X  2 case, respectively. It is important to note that the two-stage approximate is only used to compute the sampling plan for interval t = 0 ; here we do not decide to actually do pure exploitation for t = 1 , ..., T ( i ) we would consider t = max { 1 , s ( i ) } as the exploration stage for item i and compute the sampling plan for it based on the data observed at t = 0 and before.
 After this two-stage approximation, the objective functio n V (in Proposition 5) becomes: We apply standard convex minimization techniques to find q  X  and q  X  the above Gain function (on the 2nd line) with q q = q  X  1 is the fraction of user visits to be given to item the next time interval. We now explain the V function:  X  Live items vs. future items : Live items I 0 (on the 2nd  X  Lagrange multipliers : q 0 and q 1 are used to ensure the  X  State :  X  i 0 represents our current belief about the CTR of
Dynamic Gamma-Poisson (DGP): We incorporate non-stationarity into our solution by using time-series models to update the distribution of item CTR over time. In general, an y model that estimates the predictive distribution of CTR acc u-rately can be plugged into our Bayesian solution. Following [9], we use the Dynamic Gamma-Poisson model. Assume CTR p temporal variation in CTR by giving more weight to recent data. One simple way is to down-weight the effective sample size  X  after each interval, i.e., the prior at t is centered around the posterior mean at t  X  1 with variance obtained by inflating the posterior variance at t  X  1 (the variance depends on the effective sample size) through a  X  X iscounting X  factor w [23]. More specifically, after observing c clicks and v views for item i at time t , the prior at time t is p where w  X  (0 , 1] is a pre-specified discount factor, tuned on training data. Incorporating the DGP model into the solutio n to the 2  X  2 case is straightforward. When computing the Gain function, we down-weight  X  and  X  for the second interval by w . Specifically, in the Normal approximation, we redefine:
BayesGeneral and Bayes2  X  2 : We call the above general solution the BayesGeneral scheme, which requires solving a two-dimensional convex, non-differentiable minimizati on problem (for q the minimization needs high precision, which leads to long execution time. To achieve better efficiency, we consider the following approximation and call the resulting scheme Bayes2  X  2 . We approximate q that has the highest estimated CTR max find the optimal solution to each x intuition is that we compare each item i with the best item i  X  using the 2  X  2 case assuming we are certain about the CTR of i  X  . Since P fraction allocated to item i as  X  x parameter. Also, since comparing i  X  to itself is not appropriate (which makes x to be max { 1  X  P that the performance of Bayes2  X  2 is close to BayesGeneral . We note that  X  is tuned based on simulations, and we find the performance of Bayes2  X  2 to be not very sensitive to the setting of  X  .

In this section, we adapt two existing schemes from the standard multi-armed bandit literature (popular in Machin e Learning) to our scenario and describe baseline methods which are empirically compared in Section IV. For ease of exposition, let  X  p
B-UCB1: UCB1 [3] is a popular scheme designed for one-at-a-time serving  X  it serves an incoming page view with item i that has the highest priority ; the item priorities are updated after each feedback that is assumed to be instantaneous. The priority for item i is given by  X  p total number of views given to item i so far and n = P This does not work in our scenario. We modify this scheme as follows.  X  To incorporate non-stationary CTR, we use the DGP  X  To adapt to time-varying I t , we replace the n with  X  For batch serving, we propose a hypothetical run tech-
Putting pieces together, we sequentially go through each of the N N , we hypothetically give the k th page view to item i  X  that has the highest priority: Let m number of views that have been given to item i so far (before k ) updated during the hypothetical run, n where Var ( i ) =  X  p m t . Thus, we set x UCB1 or B-UCB1. We note that the tuned version uniformly outperforms the untuned version in our experiments. Thus, w e only report the former.

B-POKER: The POKER scheme [24] is similar to UCB1 but has a different priority function. Let K = |I loss of generality, assume  X  p to our setting by following the B-UCB1 procedure, and only replace the priority function with where  X  = ( X  p the tail probability is computed by assuming p m
Baseline schemes:  X  -Greedy is a simple scheme that, for each interval, allocates a fixed fraction  X  of user visits to explore all live items uniformly, and gives the rest of traffi c to the item having the highest estimated CTR. SoftMax is another simple scheme that sets x tuning parameter. Exp3 [16] is designed for adversarial, non-stationary reward distributions. Let G total number of  X  X djusted X  clicks that item i has received so far. Let  X   X  (0 , 1] and  X  &gt; 0 be two tuning parameters. For each time interval t , we (1) give item i fraction x user visits at time t , where x r i receives c comparison purposes, we also include non-batch UCB1 and POKER, called WTA-UCB1 and WTA-POKER , where WTA stands for  X  X inner takes all X , which means we allocate entir e priority value.

In this section, we report on a series of extensive empirical evaluation for the proposed serving schemes. We start by eva l-20 live items to choose from at any point in time, we then evaluate hypothetical scenarios where number of live items range from 10 to 1000 followed by analysis that demonstrates the benefit of applying multi-armed bandit schemes on user segments. This is followed by results obtained from bucket tests conducted on small random fraction of traffic from the actual system.
 A. Comparative Analysis
Real application scenario: We study performance in our current application scenario that has a set of roughly items in each 5-minute interval. To setup the experiment, we spectively, and estimated the ground truth CTR of each item in each interval through a loess fit with bandwidth selected to minimize the autocorrelations in the residuals as propos ed a random bucket , which is a set of users, to whom we show every live item with an equal number of user visits. The bucke t was setup to be large enough to reliably estimate the CTR of every live item in every time interval. This kind of randomized data is very different from regular log data collected from a system that runs some serving method, which causes serving bias in data. To evaluate the performance of schemes under different traffic conditions, we set N  X  a values. Here, N the data in time interval t . The number of clicks c at time t for an allocation volume N  X  scheme is simulated from Poisson ( p CTR is unobservable, each scheme only obtains the clicks). All schemes except Exp3 use the posterior mean estimate from the DGP model to estimate the non-stationary CTR from the observed clicks; the Bayesian schemes, B-UCB1 (where n the effective sample size from the model that is equivalent to knowing the variance), WTA-UCB1, B-POKER, WTA-POKER also use the variance estimate from the model. We set aside first-month X  X  data to determine the tuning paramet ers for schemes (if they have some), and test all schemes on the remaining three months. To tune the parameters for a scheme, we tried a number (10-20) of parameter settings; for each of the settings, we ran a simulation over the first-month data, and then pick the setting that gives the best performance. Figure 2(a) shows the percentage regret of each scheme as number of user visits per interval). The percentage regret o f a is the oracle optimal scheme assuming the ground truth is completely known. We note that Opt may pick different items across intervals and provides a stronger notion of regret th an the ones used in standard bandit problems (pick a single best item for all intervals, see [16] for more details).

Hypothetical scenario: Several hypothetical scenarios were created by varying the number of live items in an interval. For each scenario, we fix the traffic volume to 1000 views per interval, the lifetime of each item is sampled from Poisson with mean 20 intervals, and the ground-truth CTR of each item is sampled from Gamma with mean and variance esti-mated from the real application data. Figure 2(b) shows the percentage regret of each scheme as a function of number of is synthetically generated, the regret numbers may not matc h those in Figure 2(a).

Summary of Results : We summarize the results from our experiments. (1) BayesGeneral and Bayes2  X  2 are uniformly better than all other schemes; differences in performance g et larger with increasing data sparseness. Note that the more computationally efficient Bayes2  X  2 (with tuned  X  ) closely approximates BayesGeneral. (2) Batch schemes (B-UCB1 and B-POKER) generally have better performance than their non-batch versions respectively, especially when the numb er of user visits per interval is large. However, with extreme data sparseness, WTA-POKER outperforms B-POKER. (3)  X  -Greedy schemes generally provide reasonable performance, but the right  X  depends on the application. (4) Exp3 usually has the worst performance probably because it was designed for the adversarial setting; SoftMax on the other hand provides reasonable performance with a carefully tuned temperature  X  confirmed by experiments on several additional datasets wit h several replications on each.
 B. Scheme characterization
We now provide more intuition on the  X  X xplore/exploit X  properties of each scheme, this also helps us understand why Bayesian schemes perform better than others. Note that a scheme that is too impatient would allocate more user visits to the item with highest posterior mean too quickly and is likely to lose clicks. On the other hand, a scheme that is too cautious in allocating large fraction of user visits to the h igher posterior mean items may be too slow to react to opportunitie s. To quantify this delicate difference between explore/expl oit properties of bandit schemes, we characterize a bandit sche me having the highest estimated CTR (estimated by the scheme) the EMP (estimated most popular) item. Note that different schemes may pick different EMP items at the same time point. Let n to item i at time t . Let p time t , and p  X  i = 1 is the EMP item determined by the scheme for any point in time. We define the following three metrics to characteriz e a scheme:  X  Non-EMP regret:
Figure 3(a) shows EMP regret vs. non-EMP regret for each scheme. We ran three simulations (thus, three points) for ea ch scheme with the numbers of items per interval being 20, 100 and 1000. The simulation setup is the same as that of the bottom left corner. Figure 3(b) shows EMP regret vs. fractio n of EMP display for each scheme. Good schemes are at the bottom right corner. Observe that: (1) The Bayesian scheme is among the best in both plots; even when the number of items is large, its performance is still good. (2) Non-batch schemes (WTA-UCB1 and WTA-POKER) usually are not able to identify the best items because they only show a single item for each time interval; when item lifetimes are only observations to identify good items before the items retire . (3) B-UCB1 has low EMP regret, indicating its capability of identifying good items with much error; however, it usually explores more than necessary. (4) The three  X  -greedy schemes have very similar characteristics. Their fractions of EMP display are fixed at 1  X   X  . Their non-EMP regrets are large due to complete randomization. As the number of items gets SoftMax is quite competitive especially when the number of items is small; however its overall performance is significa ntly worse than the Bayesian scheme for all simulation settings. Moreover, we found this scheme to be overly sensitive to the temperature parameter that has to be tweaked carefully. C. Segmentation Analysis
We now demonstrate performance of our schemes for per-sonalized recommendations by running them separately on user segments created based on user features, which include s age, gender, geo-location and browse behavior (search hist ory, evaluated but found to be weakly predictive. Each item was hand labelled and assigned to one of the C content categories. Using large amount of retrospective data, we generated user segments as follows. Let y no-click) of user u on item i at time t , and x user features (browse behavior is dynamic, hence the suffix t ). Then, we fit a logistic regression model y factors for category k ; and c ( i ) denote the category of item Using the estimated  X  x cluster these projections and select 5 user segments (cluster) after careful analysis. The segments were also analyzed and interpreted by editors who program stories in our application. We note that segmentation provides better interpretabilit y for editors than the regression model in order to program target ed content items. In Figure 4, we show the CTR lift (relative to t he oracle optimal scheme without segmentation) for each schem e. We note that the maximum achievable lift is about 13% . The Bayesian scheme is uniformly better than all other schemes and provides positive lift for all traffic volumes. B-UCB1 an d  X  -greedy perform reasonably well for large traffic volumes, b ut they breakdown when traffic volume gets small. Surprisingly , SoftMax does not perform well in this experiment. This is because we used a single tuned temperature  X  for all the segments. Since  X  is sensitive to the scale of item CTR X  X  and the segments have very different item CTR distributions, a single  X  value for all segments leads to bad performance. D. Bucket Test Results
We now report results of experiments that were conducted on a fraction of live traffic on a major internet portal.
Experimental setup: To setup an experiment, we create a number of equal-sized random samples, called buckets, of in the user X  X  web browser by the website. We exclude users who do not accept cookies from our experiment; the size of this user population is relatively small and does not affect the validity of our experiments. In each bucket, we run a different serving scheme and compare the performance of multiple schemes over the same time period. In this study, we consider three schemes, Bayes2  X  2, B-UCB1 and  X  -greedy, and use the overall CTR of a bucket over a two-week period as our performance measure for all methods. Ideally, we would like a scheme to have full control over all the traffic in its allocated bucket. However, because of concerns regardi ng user experience being hurt through excessive exploration s ince we were testing several schemes simultaneously (e.g., havi ng undesired side-effects like attrition), each scheme was on ly allowed a maximum of 15% of the bucket to explore at any given time; i.e., the remaining 85% of the bucket has to show the current EMP as determined by the scheme. We call 15% the explore traffic and the remaining 85% the exploit traffic , and report the performance of the two parts separately. Both Bayes2  X  2 and B-UCB1 assign 85% of views to the item having the highest estimated CTR and allocate the remaining 15% using the scheme but after incorporating feedback from 85% views that have already been allocated to the highest-CT R item. For  X  -greedy, we use 15% to explore every available item randomly. For confidentiality reasons, we do not disclose th e actual CTRs of the buckets and only report CTR lift relative to a bucket that serves every available item randomly.
Experimental result: Table I shows the results. In this experimental setup, all there schemes have almost the same CTR lift in the exploit traffic. However, in the explore traffi c, it is clear that Bayes2  X  2 is significantly better than B-UCB1, which is significantly better than random. With roughly 270 views per 5-minute interval to explore roughly 20 items, all schemes can easily find the current best item, but Bayes2 finds it more economically. Figure 5 shows the same results but on a daily basis. The Bayes2  X  2 dominate others uniformly across days in the explore bucket.

We proposed several sequential schemes for systems with dynamic item pools, item lifetime constraints, non-statio nary reward distributions and delayed feedback. Our schemes wer e rigorously evaluated on an actual content publishing appli -cation. We find Bayesian solutions in the presence of an accurate predictive model outperform adaptations of stand ard bandit schemes. Sequential schemes proposed in this paper are applicable in a variety of web applications and the resul ts obtained shows our Bayesian schemes can be potentially applied to several high-dimensional problems. For instanc e, in web search, one is confronted with the problem of selecting the top-k documents for every individual query. One can apply information retrieval and other offline models based o n features like Page-rank, anchor-text to narrow down the lis t of relevant documents for a query to a small set. One can then use the techniques proposed in this paper to converge to the best documents for a given query in an economical way. Similar comments apply to advertising where one has to match the best ads to a given query (or web page). For each query, the sample size available is small and effective exploration becomes important for good performance. One can also use statistical models based on covariates to initi alize the CTR priors, this helps in faster convergence. Generaliz ing our methods to optimally select the top-k instead of top-another challenging research problem which we are currentl y investigating. In fact, the top-k problem ( k &gt; 1 ) is no longer a bandit problem but a control problem for which optimal solutions are harder to construct.

