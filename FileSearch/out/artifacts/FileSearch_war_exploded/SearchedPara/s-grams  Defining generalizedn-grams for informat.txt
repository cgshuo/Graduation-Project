 1. Introduction s -gram matching is an approximate string matching technique, where the text strings compared are decom-puted by comparing their s -gram sets. The idea dates back to Shannon X  X  Mathematical Theory of
Communication (1948) and it has in earlier literature also been referred to as n -grams (e.g. Pfeiffer, Poersch, matching technique. In this technique the s -grams are formed of both adjacent and non-adjacent characters of the text strings and classified into sets for computing the similarity. The name s -gram comes from the word skip and points to the idea that a number of characters are skipped when the substrings ( s -grams) are formed. ing cross-lingual spelling and monolingual morphological variants.

In the literature, the terminology used for referring to n -grams and s -grams has varied. In this paper, the the adjacent and non-adjacent s -grams. Thus n -grams are a special case of s -grams, where zero characters are skipped when the substrings are formed. Di-grams are conventional n -grams where the substrings X  length is length n and skip-length k will be referred as s n , k -grams. n -gram matching is a widely used technique both within IR and outside (e.g. Downie &amp; Nelson, 2000;
Ullman, 1977; Zobel &amp; Dart, 1996 ). Ukkonen (1992) gives a formal definition to n -grams. However, the clas-gent definitions both for s -grams and their classified similarity comparison. We do this firstly by formalizing so far, our work suggests that new empirical work be done.

The rest of the paper is organized as follows. Approximate string matching techniques and the use of s -grams in IR are discussed in Section 2 . In Section 3 s -grams are presented in more detail and an example application of the s -gram matching technique is given. Section 4 discusses prior formalizations of n -grams discussion and conclusions. 2. Approximate string matching techniques in IR
Approximate string matching techniques are based on the expectation that two strings that have similar strings of characters will have similar meaning and should therefore be regarded as being equivalent ( Robert-both natural morphological word form variation and variation due to e.g. typing errors or OCR (optical char-acter recognition) errors occur in databases. Recognizing such word form variants as occurrences of the same string is essential as different forms of a word represent the same concept and are therefore equal from the standpoint of users X  requests ( Pirkola et al., 2002 ).

Cross-lingual spelling variation is a type of word form variation occurring between languages. Especially related languages often share a number of words that have the same origin (e.g. Latin based words) and only differ due to the orthographical differences between the languages. Proper names and technical terms are typ-ical examples of words where cross-lingual spelling variation occurs (e.g. Brussels in Finnish is Bryssel).
Approximate string matching can be used in cross-language information retrieval (CLIR) to recognize cross-lingual spelling variants as equivalents. In CLIR, a source language query is typically translated into the target language with machine-readable dictionaries. The general translation dictionaries often do not cover most proper names and technical terms, which therefore remain untranslatable in queries. They can neverthe-less often be recognized as similar by approximate string matching, and therefore translated. This has a posi-tive effect on query translation as proper names and technical terms often are important query keys ( Pirkola et al., 2002 ).

The approximate similarity between strings can be measured with different methods. Here, Soundex and its variant Phonix, Edit distance (ED), Longest common subsequence (LCS) and the s -gram technique will be discussed. Soundex is an early phonetic matching scheme of Odell and Russell from 1918 ( Hall &amp; Dowling, based on comparing the phonetic similarity of strings are language dependent techniques. Soundex and
Phonix were developed for the English language but can be modified for other languages ( Pfeiffer et al., 1996 ). They use phonetic codes based on grouping similar sounding letters together. Strings sharing the same to provide context for the phonetic codes. Especially Soundex makes quite commonly the error of transform-ing dissimilar-sounding strings into the same code, and Pfeiffer et al. (1996) found both Soundex and Phonix clearly inferior to n -grams in proper name matching. Zobel and Dart (1996) tested various string similarity techniques for phonetic matching and found that an edit distance variant Editex that uses the letter-groupings of Soundex outperformed both Soundex and Phonix.

Edit distances (ED) are distance measures, which count the minimal number of single character instertions, deletions and replacements needed to transform one string to another. Different operations can be assigned different costs, depending on their likelihood ( Navarro, 2001 ). ED is sometimes referred to as Damerau X 
Levenstein metric as Damerau and Levenstein developed the metric separately during the 1960 X  X . Damerau developed an early edit distance measure for handling spelling errors, which accepts a difference of one inser-tion, deletion, replacement or transposition of a character in the strings compared ( Damerau, 1964 ). Pfeiffer et al. (1996) and Zobel and Dart (1996) studied different approximate string matching techniques in name matching and ED was tested in both studies. While both found that combining evidence from different string matching techniques was the best solution, the results concerning the individual techniques and specially ED and n -grams diverged: Pfeiffer et al. (1996) found n -grams clearly a better technique than the ED, whereas Zobel and Dart (1996) reported that ED outperformed n -grams.

LCS is a string matching technique that measures the length of the longest pairing of characters that can be (1997) found LCS to be the best method for matching historical word form variants (compared to di-and tri-grams). They nevertheless concluded that di-grams would be the method of choice in an operational system due to LCS X  X  high demand on computational time. Keskustalo et al. (2003) compared s -grams to different length n -grams, ED and LCS in matching cross-lingual spelling variants and found that, where ED often out-performs the adjacent n -grams, the classified s -grams performed better than ED for all the six language pairs studied. LCS was always inferior to s -grams and ED.

The modern applications of the n -gram matching in IR are discussed in, e.g., Grossman and Frieder (2004) and in Robertson and Willett (1998) . The n -gram matching, and its generalization s -gram matching, are lan-guage independent techniques and can therefore be easily applied to all languages in which the strings consist of space-or punctuation-delimited sequences of characters ( Robertson &amp; Willett, 1998 ). Grossman and Frie-der (2004) point to n -gram applications in handling OCR errors, spelling error correction, text compression, authorship detection, and discuss applications in traditional text retrieval at some length. The present article has its focus on s -gram matching in information retrieval (IR) and above all in cross-language information retrieval (CLIR) and therefore mainly IR research is discussed. Results from several studies ( Pfeiffer et al., approximate string matching technique in IR and CLIR and therefore an extensive discussion of other approximate matching techniques is not provided here.

Biological and genetic IR are application areas of s -grams, where the strings compared can be thousands of characters long and therefore higher value of n may be used ( Altschul, Gish, Miller, Myers, &amp; Lipman, 1990;
Bishop &amp; Thompson, 1984; Miller, Gurd, &amp; Brass, 1999 ). Califano and Rigoutsos (1993) proposed a s method for matching molecule biological sequences. For large values of n and k (e.g., n &gt; 10) the proposed method led to serious efficiency problems due to the size of the index needed for retrieval. Similar problems are faced when word-spanning n -grams are used for indexing document collections instead of word-based indexing ( McNamee &amp; Mayfield, 2004 ): When the strings decomposed to n -grams are long (queries, docu-ments) and the number of unique n -grams in any collection is bounded by j R j of an alphabet R , the index size grows rapidly with n . The value of n appropriate for n -gram based indexing varies with the language considered. The optimal value of n for European languages is between 4 and 5 comings of the programs used for recognizing word boundaries, di-gram based indexing has been popular ( Chen, He, Xu, Gey, &amp; Meggs, 1997 ) and index size is not a problem.

The definitions given for n -grams in the present article hold for these applications. The approaches are nev-ertheless different: in n -gram based indexing the value of n needs to be set high enough to ensure the discrim-inating power of the indexing features ( n -grams). In the present article the n -grams are seen as a word level string similarity measure used before a query is matched against a document collection. The problems with long text passages and high values of n are not addressed with length, as the average word length is well under s -grams special features have for the index size is discussed in more detail in Section 6 . 3. s -grams 3.1. s-gram basics
The classified s -gram technique was introduced as a solution for monolingual morphological and cross-lin-gual spelling variation problems in IR ( Pirkola et al., 2002 ) and its performance has been tested with several grams are divided into categories (classes) on the basis of the number of the skipped characters and only the s -grams belonging to the same class are compared to each other. Skip-gram class indicates the skip length used when generating a set of s -grams belonging to a class. Two or more skip-gram classes may also be com-bined into more general skip-gram classes ( Pirkola et al., 2002; Keskustalo et al., 2003 ). The character com-bination index (CCI) then indicates the set of all the skip-gram classes to be formed from a string. Different combinations of skipped characters can be used. For example the CCI { { 0},{1,2}} means that two skip-gram classes are formed from a string: one with conventional n -grams formed of adjacent characters and one with s -grams formed both by skipping one and two characters. An example of forming the skip-gram classes is given alo et al., 2003 ), e.g., for skip-gram class {0,1}, the spanning length is one.

Different skip-gram classes carry forward different evidence from their host string and s -grams can there-fore be tuned to handle different phenomena by adjusting the skip-gram classes. Keskustalo et al. (2003) gives a good presentation on how the skip-gram classes relate to different variation in strings from the cross-lingual deletions and substitutions, or their two-character combinations. For example transforming Swedish variant to use only skip-gram classes with spanning length of two or less when matching cross-lingual spelling vari-ants. Also spelling errors typically involve character substitution, insertion, deletion and reversal errors and their combinations ( Ullman, 1977 ). The spanning length of s -grams can be restricted to two or less again, as Zamora, Pollock, and Zamora (1981) have reported that most of the misspelled strings in text databases only contain a single error.
 It is common to use padding spaces in the beginning and in the end of the strings when forming s -grams. gram set. For conventional n -grams it is common to use a padding of n 1 characters ( Robertson &amp; Willett, 1998 ). For s -grams a padding that varies together with the length of the substring ( n ) and the number of the skipped characters can be used. In accordance with these rules, the set of padded s ferent types of padding spaces for conventional di-grams, tri-grams and s -di-grams, and found that using pad-ding spaces both in the beginning and the end of the words gave the best results. However, leaving out the padding spaces can help down-weighting the derivational suffixes and prefixes, when handling morphological variation or cross-lingual spelling variants in inflected forms. For example, the use of the beginning padding only has been found beneficial for Finnish, which is an inflectionally complex suffix language ( Pirkola et al., 2002 ). 3.2. Motivating example
The typical dictionary-based query translation approach to CLIR has a downside in the constant need for updating the dictionaries and in that different dictionaries are needed for each language pair. These features can make the approach costly and replacing it by cheaper, language independent techniques would be desir-able. Between closely related languages that share a high number of cross-lingual spelling variants, approxi-mate string matching techniques can be used for a simpler, fuzzy query translation technique. A fuzzy s -gram query translation between the Scandinavian languages Norwegian and Swedish is explored here to give an example of a s -gram matching application. 1 Norwegian and Swedish are closely related languages that share a high number of cross-lingual spelling variants: around 90% of the vocabularies of the languages are similar 1997 ). This provides a good basis for fuzzy translation.

Our fuzzy query translation experiment was done using adjacent di-grams and classified s -di-grams for translating Norwegian search topics to Swedish. The goal was to, with fuzzy techniques, reach translation quality sufficient to enable effective searching of a Swedish document collection and competitive with the dic-tionary translation. s -grams were formed with two different character combination indices: s -gram1 X  X  with
CCI { { 0},{0,1},{1,2}} and s -gram2 X  X  with CCI { { 0},{1,2}}. Only the better performing s -gram1 X  X  are dis-cussed in the following. The fuzzy translation was compared to dictionary-based query translation and to monolingual Swedish IR. Also a Norwegian baseline query was formed to see how much the fuzzy translation improves the results compared to no translation at all.
 A typical CLIR test setting with the search topics and test collection from Cross-Language Evaluation
Forum (CLEF) 2003 was used. The CLEF X 03 environment includes document collections and a set of 60 search topics in several languages, including Swedish ( Peters, 2003 ). The Swedish document collection con-tains 142819 news wire articles from the Swedish news agency TT published in 1994 X 1995. As the Norwegian search topics were not included in the CLEF test environment, the English test topics were translated to Nor-wegian by a native Norwegian-speaker. The document collection and the search topics were not morpholog-ically preprocessed for the fuzzy translation X  X he words were used in the inflected word forms in which they appeared in text. The collection and the topics were nevertheless normalized for the dictionary-based transla-tion and monolingual IR, to ensure hard baselines. The stop words, as well as the duplicates of words appear-ing in identical word forms, were removed from the search topics. Finally, six of the search topics did not have any relevant documents in the Swedish document collection and were therefore removed from the topics. The tests were run with the remaining 54 topics.

Test queries were formed from the words of the title and description fields of the test topics (on average 7.5 words after duplicates were removed). The fuzzy translation was done by translating the Norwegian topics into Swedish by matching the n -or s -grams of the topic words against the Swedish document collection X  X  index words X  n -or s -grams. The three best matches were selected as translations for each word. For the dictionary translation, the GlobalDix dictionary by Kielikone Ltd. was used. All the translations for each topic word were selected to the query and the queries were structured according to the Pirkola method ( Pirkola, 1998 ).
The Norwegian and Swedish baseline queries were formed directly from the Norwegian and Swedish topics X  words. The performance of the translation techniques was measured by interpolated mean average precision using the Wilcoxon signed ranks test.
 The results are presented in Table 2 and in Fig. 1 . The statistical significance levels are given in the table. The s -grams achieved on average 80% of the dictionary baseline X  X  performance and 62% of the monolingual
Swedish baselines performance. The differences in the techniques X  average precisions are statistically signifi-cant ( Table 2 ). Still, 80% of dictionary baselines performance is a result that shows that s -gram translation is a promising and interesting query translation technique in CLIR between related languages. Especially so, when the language dependent dictionary translation setting requires two morphological analyzers (Norwe-gian and Swedish) and a translation dictionary to function, while the s -gram translation only needs a (lan-guage independent) program for producing the s -grams. When comparing the precision at the higher ranks, i.e., among the 20 and the 50 first retrieved documents (The document cut-off value (DCV) at 20 and 50 retrieved documents) and at the 10% recall level, the differences between the translation techniques are not statistically significant. These documents placed at the top of the result list are the most important ones from the practical user perspective.

The s -grams clearly outperformed the Norwegian baseline, with an average precision statistically signifi-cantly better than that of the Norwegian baseline ( Table 2 ). The high percentual difference in performance suggests that the difference also has practical significance. It can be seen from Fig. 1 that the s -gram tech-nique X  X  precision-recall curve settles clearly above the n -gram technique X  X  curve at recall levels 10 X 70 and always clearly above the Norwegian baseline (nobase). The difference in the s -and n -gram techniques X  average lation technique for words missing from dictionaries that combines n -grams to statistical rewriting rules).
Therefore, it can be concluded that the s -gram translation is a promising technique in query translation between closely related languages.
 4. Formalizations of n -grams and their proximity functions
We begin by briefly reviewing the basic concepts of formal languages. We follow the conventions of Hop-croft, Motwani, and Ullman (2001) . Then we define n -grams by following the conventions of Ukkonen (1992) .
Finally we give two proximity functions for strings based on their n -gram overlap. The first one is the L ric originally defined for n -grams by Ukkonen (1992) and the second one is Jaccard X  X  similarity function, which is very often used in IR experiments involving n -grams. 4.1. Basic concepts of formal languages
We define an alphabet R as a finite, non-empty set of symbols. A string is a finite sequence of symbols from is also the empty string which does not contain any symbols. Note that an empty string can be chosen from any alphabet. The length j w j of a string w is the number of positions for symbols in the string. For instance j abba j = 4 and j j = 0. A string v = b 1 b 2 ... b m b b If R is an alphabet we denote R k a set of strings over R whose length is k . For example, if R ={ a , b }, then
R strings over an alphabet R is denoted R * . In other words, R * = R
For strings v and w , their concatenation vw is a string, which first has all the symbols of v in order of their appearance in v and then all the symbols in w in order of their appearance in w . Thus, the concatenation of strings v = abba and w = babba is vw = abbababba . 4.2. Definitions for n-grams
As we saw in previous sections, comparing two strings by calculating the overlap of their common sub-strings of certain length has a wide range of applications in IR. Now we are ready to give formal definitions for n -grams and their selected proximity functions.

Let R be a finite alphabet. An n -gram is any string w 2 R ba and bb . To be able to derive proximity functions between strings based on their n -gram overlap we need the following definition of string X  X  n -gram profile ( Ukkonen, 1992 ).

Definition 1. Let w = a 1 a 2 ... a m 2 R * and let x 2 R vector G n ( w )=( G ( w )[ x ]), x 2 R n .

Now, the distance of the strings can be defined as the L 1 tance) of the difference of their n -gram profiles ( Ukkonen, 1992 ).
 Definition 2. Let v , w 2 R * and n 2 N  X  . The n -gram distance between v and w is
Example 1. Let R ={ a , b } and v = abba , w = babba 2 R * . Their di-gram profiles, listed in lexicographical order of the di-grams, are (0,1,1,1) and (0,1,2,1). Thus, their di-gram distance D the di-grams of strings v and w and all di-grams over alphabet R ={ a , b }.

The n -gram distance is pseudo metric ( Ukkonen, 1992 ), i.e., for all v , w , x 2 R * : (1) D n ( v , w ) P 0 (non-negativity), (2) D n ( v , w )= D n ( w , v ) (symmetry) and (3) D n ( v , w ) 6 D n ( v , x )+ D n ( x , w ) (triangle inequality).
 w = aaba ). Ukkonen (1992) lists also other properties of the n -gram distance which are here omitted.
Another approach to n -gram based string proximity is to calculate similarity between two strings instead of distance as in Eq. (1) . Indeed, Keskustalo et al. (2003), Pirkola et al. (2002) and Toivonen et al. (2005) used
Jaccard X  X  formula based similarity function for s -grams. In order to formalize Jaccard X  X  formula for s -gram similarity we first define it for ordinary n -grams X  X ut based on n -gram profiles rather than n -gram sets. In its basic form, Jaccard X  X  formula for measuring the similarity between two sets A and B is written as if A and B do not share common elements, then A \ B = ; and J ( A , B )=0.

Since in set theory the duplicate occurrences of any element in the set are discarded, the Jaccard X  X  formula n -gram profile of Definition 1 we need a binary n -gram profile : follows:
The binary n -gram profile of w is the binary vector B n ( w )=( B ( w )[ x ]), x 2 R
With the binary n -gram profile of w the Jaccard X  X  formula based n -gram similarity function takes the fol-lowing form.

Definition 4. Let v and w be non-empty strings from R * and n 2 N and w is
Example 2. Let R ={ a , b }and v = abba , w = babba 2 R * . Now binary di-gram profiles of v and w , listed in lexicographical order of the di-grams, are (0,1,1,1) and (0,1,1,1). Thus their Jaccard X  X  di-gram similarity
J ( v , w ) = 1 and therefore the strings v and w are treated as equal (cf. Example 1 ).

As we mentioned in the previous section, it is common in IR applications to use padding spaces around the strings to get the symbols in the beginning and the end of the strings properly represented in the string com-parison. It was also mentioned that it is common to use n 1 padding spaces around the strings. Next we show how the padded n -gram comparison of the strings can be performed. For this purpose we assume a spe-cial padding symbol ] . For example, in text retrieval applications ] could be thought as a regular space character.
 strings v and w based on their n -gram overlap with, say, n 1 padding spaces in both the beginning and the end of the strings is performed as follows. Let p be a special string consisting only n 1 padding symbols, i.e.,
D ( pvp , pwp ) and J n ( pvp , pwp ) do the job. This follows from the fact that R both v and w plus those n -grams which begin or end n 1 or less padding spaces (because ] 2 R ). If padding is used only in the beginning of the strings, the comparison is performed with D uation where padding is used only in the end of the strings is handled correspondingly. 5. Formalizations of s -grams and their proximity functions
We shall now generalize the definition of n -grams by allowing skips between the symbols of the string w from which the n -gram is formed, i.e., the definition is generalized for s -grams. While Keskustalo et al. (2003) only consider s -grams of length of two, our definitions are for s -grams of any length. We also show how we get n -grams as special a case of our s -gram definition. 5.1. Definitions for s-grams
For simplicity we require that the skips in the s -grams are systematical , i.e., (1) each skip has equal length and (2) the skips are performed in each character position. With gram length of 2 and skip of 1 the s of w = abbababba are ab , ba , bb , aa , bb , ab , and ba .

Definition 5. Let w = a 1 a 2 ... a m 2 R * , n 2 N  X  be a gram length, k 2 N a skip length and let x 2 R total number of s n , k -gram occurrences of x in w . The s x 2 R n .
 Now, the s n , k -gram based L 1 norm is defined as for n -grams:
Definition 6. Let v , w be strings from R * , n 2 N  X  be a gram length and k 2 N a skip length. The s distance between v and w is
Example 3. Let R ={ a , b } be an alphabet and v = aabab , w = babab strings from R * . Their s listed in lexicographical order of the s 2,1 -grams, are (1,1,0,1) and (1,0,0,2). Thus, their s
D 2,1 ( v , w ) = 2. Note that their di-gram distance defined in Eq. (1) would be 1. Table 4 lists the s strings v and w and all s 2,1 -grams over alphabet R ={ a , b }.

Note that Eq. (1) is a special case of Eq. (4) , because D the following theorem shows that distance D n , k is a pseudo metric. The theorem is easy to prove and the proof is thus omitted.

Theorem 1. For all v,w,x 2 R * , (1) D n,k (v,w) P 0 (non-negativity), (2) D n,k (v,w) = D n,k (w,v) (symmetry) and (3) D n,k (v,w) 6 D n,k (v,x) + D n,k (x,w) (triangle inequality).

Thus also distance D n , k is pseudo metric. It is not metric, because D example for s 2,1 -grams of strings v = aaba and w = aaab ).

Because, Keskustalo et al. (2003), Pirkola et al. (2002) and Toivonen et al. (2005) used Jaccard X  X  similarity point of view to s -gram based string proximity using the concept of similarity instead of distance.
The definition of Jaccard X  X  similarity function for s -gram based string matching is analogous to that of n -grams. First, we need to define the binary s -gram profile :
Definition 7. Let w 2 R * , n 2 N  X  be a gram length and k 2 N a skip length of the s -grams. Let B the occurrences of string x in w as follows:
The binary s n , k -gram profile of w is the binary vector B mula takes the following form.

Definition 8. Let v and w be non-empty strings from R * , n 2 N Jaccard X  X  s -gram similarity between v and w is
Example 4. Let R ={ a , b } be an alphabet and v = aabab , w = babab strings from R * . Their binary s would also be 2/3.

Note that Eq. (3) is a special case of Eq. (5) , because J
As with n -grams, it is also common with s -grams to use padding spaces around the strings to get the sym-bols in the beginning and the end properly represented in string comparison. The approach illustrated in the be noted that with s -grams it is common to use ( k + 1)( n 1) padding spaces around the strings instead of n 1 (i.e, the length of the padding string p is ( k + 1)( n 1)). 5.2. Skip-gram classes and their proximity functions
Pirkola et al. (2002) and Keskustalo et al. (2003) found that the s -gram matching performance is improved each skip-gram class is computed separately. The evidence from the different skip-gram classes is then com-bined for the comparison of the strings. Therefore, we will now begin the formulation skip-gram classes and their proximity functions.
 Definition 9. The skip-gram class of skip lengths, or shortly skip-gram class, is a set C 2 P  X  N ). Character of length n in certain skip-gram class C we will simply write s
Definition 10. Let w 2 R * , C 2 P  X  N  X  a skip-gram class and x 2 R gram class profile of w is the vector G C ( w )=( G C ( w )[ x ]), x 2 R The next definition gives the L 1 norm for skip-gram classes: gram class distance between v and w is
Example 5. Let R ={ a , b } be an alphabet and v = aabab , w = babab strings from R * . Their s class profiles, listed in lexicographical order of the s 2,0 their s 2,{0,1} -skip-gram class distance D 2,{0,1} ( v , w )=4.

Note that we can calculate Eq. (4) with Eq. (6) , because D
Especially n -gram distance of Eq. (1) between strings v and w is given by D
According to the following theorem also skip-gram class distance is a pseudo metric. Again, the proof is obvious and thus omitted.

Theorem 2. For all v,w,x 2 R * , (1) D n,C (v,w) P 0 (non-negativity), (2) D n,C (v,w) = D n,C (w,v) (symmetry) and (3) D n,C (v,w) 6 D n,C (v,x) + D n,C (x,w) (triangle inequality).

Next we want to derive the Jaccard X  X  similarity function for gram class based string matching analogous to previous Jaccard X  X  formulas. Again, this requires us to define a binary skip-gram class profile .
Definition 12. Let w 2 R * , and C 2 P  X  N  X  a skip-gram class and x 2 R
The binary skip-gram class profile of w is the binary vector B
The Jaccard X  X  formula based s -gram similarity using binary gram-class profiles of strings can now be defined like Jaccard X  X  similarities earlier.

Definition 13. Let v and w be non-empty strings from R * , n 2 N class. The Jaccard X  X  skip-gram class similarity between v and w is
Example 6. Let R ={ a , b } be an alphabet and v = aabab , w = babab strings from R * . Their binary s gram class profiles, listed in lexicographical order of the s
Thus, their s 2,{0,1} -skip-gram class similarity is J 2,{0,1} gram class similarity, strings v and w are equal. This is a notable difference to the L w calculated in Example 5 .

Note again that we can calculate Eq. (5) with Eq. (7) , because J
Especially n -gram similarity of Eq. (3) between strings v and w is given by J
Finally, we define a proximity functions for strings based on their total s -gram overlap in given set of skip-gram classes specified by a CCI.
 5.3. CCI-based string proximity
In Pirkola et al. (2002) and Keskustalo et al. (2003) , the final similarity function for s -grams was based on the Character Combination Index (CCI) and an extension of Jaccard X  X  formula. The idea was to calcu-late the Jaccard similarity in each skip-gram class and then to combine the similaries in a novel way to an overall similarity function. In this section, we shall continue our approach from preceeding sections by, firstly, defining a distance function for two strings based on their s -gram profiles and the given CCI, and secondly, binarizing these profiles and defining (precisely) the Jaccard style similarity function for the same situation. As we shall see though some examples, the two functions may give quite different results. This is due to the distance function counting each occurrence of any s -gram and the similarity func-tion only counting one, because it is set oriented. Only the latter has so far been experimentally tested in the case of s -grams.

Definition 14. Let v and w be strings in R * and C 2 P  X  P  X  N  X  X  a character combination index. The distances, i.e., Example 7. Let R ={ a , b } be an alphabet, v = abbababba , w = baabaaba strings from R * and
C  X ff 0 ; 1 g ; f 2 gg a CCI. To calculate the distance D are for string vG 2,{0,1} ( v ) = (1,5,5,4) and G 2,{2} ( v ) = (2,1,1,2), and for string wG
G 2,{2} ( w ) = (3,0,0,2). Thus,
The advantage of using average distance in the above definition is that the CCI distance remains as a definition gives a proximity function loosely on based Jaccard X  X  formula that is used by Pirkola et al. (2002) and Keskustalo et al. (2003) for skip-gram class based string comparison.

Definition 15. Let v and w be non-empty strings over an alphabet R , n 2 N and C 2 P  X  P  X  N  X  X  a CCI. The similarity S n ; C  X  v ; w  X  of v and w with regard to CCI C is Example 8. Let R ={ a , b } be an alphabet, v = abbababba , w = baabaaba strings from R * and
C  X ff 0 ; 1 g ; f 2 gg a CCI. To calculate the similarity S profiles. The profiles, listed in lexicographical order of the s -grams, for string v are B
B 2,{2} ( v ) = (1,1,1,1), and for string w are B 2,{0,1} ( w ) = (1,1,1,0), B
We gave the similarity function of Eq. (9) by convention, following Pirkola et al. (2002) and Keskustalo et al. (2003) . However, this choice for similarity function for CCI based string matching is not the most intu-itive one. Therefore, we propose a new, simpler similarity function calculated as an average of the skip-gram classes of the CCI, in the spirit of Eq. (8) .
 Definition 16. Let v and w be non-empty strings from R * and C 2 P  X  P  X  N  X  X  a character combination index. The similarity S 0 n ; C  X  v ; w  X  of v and w with regard to CCI C is
The similarities given by the Eqs. (9) and (10) are not far apart but nevertheless different as the reader may find through the simple example constructed with strings aabba and bbab and a CCI C  X ff 0 g ; f 1 gg .
We end this section by noting that following equalities hold between the CCI based string proximity func-tions and s -gram proximity functions. Let v and w be strings over an alphabet R , n 2 N k 2 N a skip length. Then evaluated by using Eqs. (8) X (10) only. 6. Discussion and conclusions n -grams have been used widely and successfully for approximate string matching in many areas. Recently,
Pirkola et al. (2002) devised a novel classified s -gram matching technique, where di-grams are formed of both adjacent and non-adjacent characters. s -grams have proved successful in approximate string matching across language boundaries X  X specially in matching proper names and technical terminology. While n -grams have kustalo et al., 2003 ) lacks a stringent definition. In this paper, we have given precise definitions both for s -grams and their distance/similarity comparison.

Following established practices in the literature ( Ukkonen, 1992 ) we first presented the n -gram profiles of strings and then their distance measure, the L 1 metric. This is a well established distance measure, and takes into account both the kinds of n -grams two strings contain, and their number. Based on this we also defined binary n -gram profiles and the Jaccard similarity measure, which has been popular in IR experiments. As pointed out, this similarity measure is weaker than the L the counts of each n -gram in the strings to be compared.

Turning to s -grams, we provided novel definitions of s -gram profiles and extended the L for them. We gave definitions for simple s -gram profiles and distances and progressively extended them to skip-gram classes and collections of skip-gram classes (as specified by the CCI). The s -gram profiles were also reduced in each case to binary profiles in order to precisely define the (extended) Jaccard similarity functions for s -grams in each case. Again, as pointed out, the extended L the corresponding Jaccard similarity measures because the Jaccard measures are insensitive to the counts of each n -gram in the strings to be compared. Interestingly, the L in IR experiments based on s -grams. Their greater strength in measuring string proximity suggests their poten-tial for IR experiments, which are planned for in our forthcoming research.

Pirkola et al. (2002) only considered s -di-grams, which entails one skipping possibility between the two characters. Our definitions were for general s -grams with multiple skipping positions and constant skip length.
Unfortunately, at the sub-word character string level, we do not know of text retrieval applications of s grams for n &gt;2.

Finally, we showed that n -gram similarity/distance computations are special cases of our generalized def-initions. In fact, all s -gram and n -gram distance computations may be carried out by Eq. (8) and their Jaccard similarities by Eq. (9) or Eq. (10) .
 The size of the n -gram index has been pointed out as a critical factor in their application ( Califano &amp;
Rigoutsos, 1993; McNamee &amp; Mayfield, 2004 ), where the determining factors are the size of the symbol sequence). In our case, a further complication arises from the skip-gram classes as each class requires its own profile. However, in the present problem area, focussing on s -grams for mono-lingual and cross-language word matching, the symbol set R typically has less than 30 symbols, the gram length typically is 2 and the
CCI C contains 2 X 3 classes. With such values the s -gram profile size per keyword  X  X j C jj R 2 KB per keyword which is very reasonable. Recall that the keyword index takes, for each keyword, the key-word length and the address list length, which is governed by address specificity, address length, and the data-base size (word count).

At a more general level, our strong belief is that popular proximity measures need precise definitions. This fosters an understanding of their relative strengths (e.g. the L measure) and their consistent implementation and application. Our definitions were developed in a bottom-up manner, only assuming character strings (based on some alphabet) and elementary mathematical concepts. Acknowledgements
This study was funded in part by Department of Information Studies, University of Tampere, TISE (Tam-pere Graduate School for Information Science and Engineering), and Academy of Finland under the Grant # 1209960.
 References
