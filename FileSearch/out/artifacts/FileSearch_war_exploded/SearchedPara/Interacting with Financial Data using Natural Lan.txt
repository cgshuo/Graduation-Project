 Financial and economic data are typically available in the form of tables and comprise mostly of monetary amounts, numeric and other domain-specific fields. They can be very hard to search and they are often made available out of context, or in forms which cannot be integrated with systems where text is required, such as voice-enabled devices.
This work presents a novel system that enables both ex-perts in the finance domain and non-expert users to search fi-nancial data with both keyword and natural language queries. Our system answers the queries with an automatically gen-erated textual description using Natural Language Genera-tion (NLG). The answers are further enriched with derived information, not explicitly asked in the user query, to pro-vide the context of the answer. The system is designed to be flexible in order to accommodate new use cases without significant development effort, thus allowing fast integration of new datasets.
  X  Computing methodologies  X  Natural language gen-eration;  X  Information systems  X  Query intent;
Financial data, such as macro-economic indicator time se-ries for countries, information about mergers and acquisition (M&amp;A) deals between companies, or stock price time series, is typically stored in relational databases, requiring domain expertise to search and retrieve. For example, a financial analyst who is familiar with a particular database will be able to locate the information he or she is seeking quickly. However, for users who lack the necessary familiarity with the databases, it may be difficult and time-consuming to obtain the information they are looking for.

The retrieval of specific data points (e.g., India GDP 2010) may be useful for responding to a very specific information many types of well-formed English questions like  X  X hina X  X  CO2 emissions between 2009 and 2013 X  or  X  X hat is the GDP of India in 2010? X  without complex linguistic processing. In addition, we have designed the system with the aim to be flexible and easily adaptable to different use cases, ranging from retrieving specific points from a time series of financial data to ranking entities or computing correlations, by sup-plying different configurations to the system. The output of the system has been integrated in Thomson Reuters Eikon, a platform for financial analysis.

The automatically generated textual description of an-swers enables the system to be used in desktop or smaller devices, where expressing the answer in a textual form can provide a succinct summary of multiple diagrams and charts, or in settings where text is required (e.g., in speech-enabled devices, where the answer can be spoken back to the user). To the best of our knowledge, this is the first system com-bining natural language search and NLG for financial data. Keyword-Based Search Systems for Databases.
 The BANKS system [1] enables keyword search and naviga-tion in structured and semi-structured datasets. The system performs an in-memory graph search and ranks answers by relevance and the a priori  X  X restige X , inspired by PageRank. The FRISK system [15] uses a dynamic programming-based method for query segmentation and presents the possible in-terpretations so that users can select the one that is closest to the original intention. Discover [7] uses a greedy execu-tion plan over a graph structure to provide efficient search over relational data without knowledge of the schema. The Spark system [12] assembles matching tuples from differ-ent tables together according to relationships such that the tuples are collectively relevant. Keymantic [2] and Key-word++ [5] also belong to this family of systems.
 Natural Language Interfaces to Databases (NLI).
 NLI systems convert user queries to the query language used by the underlying database. For example, both DBSemSX-plorer [3] and DEANNA [21] systems translate a user query into a SPARQL query which is then processed by a triple store. TR Discover [19] is a general-purpose and domain-adaptable NLI for querying linked data. It uses a feature-based grammar to parse a natural language question into its first order predicate logic representation (FOL). The FOL of a question is further transformed into a SPARQL or SQL query to retrieve answers from a knowledge graph.

Question Answering Systems. Our system also relates to question answering, for which several systems have been produced, for example [8][22][10], the top-performing system entries [13][6][18] at the final (2007) open-domain QA factoid track of TREC, or IBM X  X  Watson [4].

Natural Language Generation (NLG). Natural Lan-guage Generation has a long tradition in natural language processing [16]. More recently, statistical approaches where the text generation is informed by statistical properties of training corpora have been suggested [9].

Our system is different from keyword-based search sys-tems for databases in the sense that we decouple the search process from a specific database technology by using a search engine instead. Compared to NLI systems, we avoid the ex-pensive query execution on databases or knowledge graphs, possibly involving joins or graph traversals. Perhaps the systems that most closely resembles the present work are 3) a document identifier, and 4) the caption, which is an array of constant strings and data values. When the Answer Generation module applies a template to a dataset, a virtual document is generated for each database record, comprising the named fields from the template, the document identifier and the caption field.

Since the templates control the format and data of the documents, the design of a template can be guided by the application requirements. For example, when developing an application about time-series of financial macro-economic in-dicators, where users can query for year ranges, two different design choices may be to create a separate virtual document per time-series point, or to aggregate k -year ranges of time-series points and present to the users precomputed results about trends and changes. In this work, we have precom-puted the values for all 5 and 10 year intervals between 1960 and 2015 to speed up online query processing.
Queries in financial search applications tend to be short and contain abbreviations or codes. While we can directly use the caption field of virtual documents to match against user queries, we have built a Query Understanding module that can extract entities relevant to the application in order to perform structured search more effectively. The query understanding module processes a query as follows.

Entity tagging. First, we identify entities in the query string. The type of entities depend on the application requirements. In the case of macro-economic indicators, we identify countries (e.g., US or United States), regions (e.g., South Asia), groups of countries (e.g., OECD), macro-economic indicators and their abbreviations (e.g., Gross na-tional income, or GNI). In the case of merger and acquisition deals, we also identify companies, names of financial advi-sors such as investment banks, dates, industry sectors. We tag entities using a regular expression tagger, a trie-based tagger and a scalable n-gram tagger [14].

Intent generation and ranking. Next, from the set of all identified entities, we generate sets of non-overlapping entities, which we call intents. An intent I is a set of entities. For each intent I , we first apply a set of regular expressions to identify entities which have been tagged wrongly and re-move them. In our setting, tagging errors occur where a to-ken could be a 2-letter country code or not (e.g., the country code IN or the preposition in ).

We also disambiguate entities when the presence of one entity can be used to disambiguate the tagged entities for another sequence of tokens. For example, there is more than one indicator for gross domestic product (GDP), which is expressed in different units, such as  X  X urrent US$ X , or  X  X on-stant 2005 US$ X . We consider the indicator units to be a distinct entity type and use them to disambiguate indicator entities tagged in queries.
 a score associated with entity e adjusted by the prevalence of each identified entity, a measure, based on web counts, of how likely is one definition of an entity over another one with the same surface form, | I | is the number of entities in I and c is the number of tokens not covered by any of the entities in I . The role of (1 + c ) and | I | in the denominator is to decrease the score of intents which consist of many entities with poor coverage of the query. The output of the query understanding module is a ranked list of intents. associated with larger changes ( skyrocket,plummet ). This stands in contrast to previous work (cf. [17]) which found verb choice to be largely idiosyncratic when analyzing a much smaller data sample. In the template example be-low, verb of motion is selected statistically based on the rate of change.
We have applied our system to two datasets. The first dataset consists of macro-economic indicator data from the World Bank 3 . There are 1,319 indicators with a time frame from 1960 to 2015. For the macro-economic indi-cator dataset, the system processes queries requesting the indicator values for a specific country and year or range of years, the top ranked country according to an indicator for a region or group of countries (e.g., OECD), as well as the correlation between the indicator values for a given coun-try. To this end, we created 2 answer generation and 36 answer rendering templates. The second dataset comprises more than 200K records about company M&amp;A deals sam-pled from a proprietary database. For the M&amp;A dataset, the system processes queries comprising company names, as well as queries for deals in a country, an industry sector, or their combinations for a given year, for which we prepared 4 answer generation and 15 answer rendering templates.
In this work, we have introduced a system that enables users to search financial data robustly using both keyword and natural language queries, and returns the answer in the form of an automatically generated textual description, en-riched with additional derived information about the con-text of the answer. The textual description of the answers enables us to use the system both in desktop or smaller de-vices, including speech-enabled devices, where text may be the only way to deliver the answer. Moreover, the system was designed to be flexible and domain-adaptable, by using a template-based answer generation engine to convert data to virtual documents, which are indexed by a search engine, and a configurable mapping of user intents to query plans. We thank Albert Lojko, Alex Tyrell, Sidd Shenoy, Rohit Mittal and Jessica Tran from Thomson Reuters F&amp;R, and Khalid Al-Kofahi from Thomson Reuters R&amp;D for their sup-port and discussions. This work received financial support by Thomson Reuters Global Resources. http://data.worldbank.org/
