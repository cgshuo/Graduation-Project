 Extractive summarization techniques aim at select-ing a subset of sentences from a corpus which can be a representative of the original corpus in the target summary space. Extensive work has been done on extractive summarization aimed at maximizing the information coverage of the summary with respect to the original corpus and accuracies have been re-ported in terms of ROUGE score. But, if a sentence is heavily dependent on its previous context in the original corpus, placing it in the summary in a dif-ferent context can render a wrong inference to the reader of the summary.

The main intuition behind our approach begins with a crucial question about the linguistic nature of a text. Is text a bag of words every time? Psycholin-guistic studies suggest that local coherence plays a vital role in inference formation while reading a text (McKoon and Ratcliff, 1992). Local coher-ence is undoubtedly necessary for global coherence and has received considerable attention in Compu-tational Linguistics. ((Marcu, 2000), (Foltz et al., 1998), (Althaus et al., 2004), (Karamanis et al., 2004)). Linguistically, every sentence is uttered not in isolation but within a context in a given discourse. To make a coherent reading, sentences use various discourse connectives that bind one sentence with another. A set of such structurally related sentences forms a Locally Coherent Discourse Unit (hereafter referred to as LDU) . In the current work, we suggest that it is important to leverage this structural coher-ence to improve the comprehensibility of the gener-ated summary. It should be noted that the concept of LDU is different from the elementary discourse units (EDUs) as discussed in Rhetorical Structure Theory(Mann and Thompson, 1988). RST is inter-ested in describing the structure of a text in terms of relations that hold between parts of text. Any part of the text such as nuclear discourse clauses, satel-lite discourse clauses can be treated as elementary discourse units. In contrast, with LDUs, we are in-terested in identifying which sequence of sentences make up one extractable unit that has to be taken together for an extractive summarization task. The most recent works on extractive summarization can be generalized into three steps given below:-1. Creating an intermediate representation for the 2. Using the intermediate representation to assign 3. Selecting a set of sentences which maximizes During this process, a sentence is severed from its original context in the corpus and is eventually placed in a different context. If the level of depen-dence of the sentence on its context is high, then it has a higher chance to deliver an erroneous reading, when placed out of context. To understand the issue, look at the below sentences in a summary.
 A resultant summary which contains the above two sentences one after another, can be a topically relevant summary. Both talk about  X  X aroque style X ,  X  X rt X , X  X entury X  etc and could possibly be optimal candidates for the target summary. Nevertheless, it invokes an incomprehensible reading for a human reader because the subject of the second sentence is  X  X heir ruler X  whose anaphora is not resolved in the context. Hence it is important that we do not consider a document as mere sequence of sentences or bag of words but rather as a series of LDUs. In spite of all attempts for developing abstractive summarization techniques to mimic the human way of summarizing a text, extractive techniques still stand out as more reliable for practical purposes. So it is inevitable to enhance the extractive summariza-tion techniques along the dimensions of readabil-ity, coherence and comprehensibility. The problem of extractive summarization can be formulated as a function maximization problem in the space of all candidate summaries as follows.
 S  X   X  argmax S  X  V F ( S ) subject to where F is an objective function, S  X  is the summary which maximizes F with an adopted optimization method, S is a candidate summary, c i is the cost of selecting a sentence i into summary, b is the upper bound on the total cost and V is the set of total num-ber of sentences in the corpus.

The current work is inspired by two of the previ-ous works namely (Lin and Bilmes, 2011) and G-Flow (Christensen et al., 2013). Lin &amp; Bilmes ob-served that if the objective function to score candi-date summaries is monotone sub-modular , a greedy approach can ensure the approximation of the sum-mary at the global maximum by a factor of 0.632 as follows.

F (  X  S )  X  (1  X  1 /e )  X  F ( S opt )  X  0 . 632  X  F ( S opt where  X  S is the summary obtained from monotone sub-modular function F and S opt is the summary at the global maximum of F.

G-Flow aimed at generating coherent summaries by constructing a sentence-level discourse graph for the entire corpus and the information from the graph is utilized to quantify the coherence of candidate summaries. In a short summary space, the sentences which structurally depend on other sentences are not encouraged. So the summaries are more compre-hensible than those produced by the systems which blindly aim at achieving maximum content cover-age. The need to create a discourse graph can be a big hurdle to scale the summarizer to large data sets. Also the scoring function of G-Flow is not mono-tone sub-modular and cannot guarantee the approx-imation of optimum summary as per the relation 2. The space of current work is to establish a scheme for comprehensible summarization with a monotone sub-modular objective function . Within the scope of this paper, when we say comprehensibility we mean how much relevant structural context does each sentence have for better conveyability of the dis-course intended by the summary .
In the current work, we try to assign a score for each sentence based on its level of contextual inde-pendence (discussed in subsequent sections). The particular score is combined as a linear component in the candidate summary scoring function of Lin and Bilmes (Lin and Bilmes, 2011) to score sen-tences. While adding the third component, mono-tone sub-modularity of the scoring function is not disturbed since the contextual independence of indi-vidual sentences is constant with respect to a given corpus. We observed an improvement in system-generated summary in terms of human evaluation for comprehensibility while maintaining a reason-able level of content coverage in terms of ROUGE score.
 We framed a comprehensibility index to represent the level of comprehensibility of a system generated summary using contextual independence score of in-dividual sentences. Comprehensibility index for the generated summary is the average contextual in-dependence score of a sentence in the summary . We verified, through human evaluators, whether the comprehensibility index is actually representative of the human comprehensibility. Identification of locally coherent discourse unit (LDU) and combining the information to create a comprehensible summary is a novel problem which is not attempted by any of the previous works in the field of natural language processing to the best of our knowledge. Barzilay and Lapata(Barzilay and Lapata, 2008) attempt to measure the global coherence in terms of local coherence which is measured in terms of entity role switch while G-Flow(Christensen et al., 2013) came up with a metric to measure the coherence of the generated summary with respect to a corpus level discourse graph. Still, these two works are not directly relevant to local dis-course unit identification per se.
 Substantial work has been done on extractive sum-marization which tries to achieve a proper con-tent coverage while reducing the redundancy. Ap-proaches include the use of Maximum Marginal Rel-evance (Carbonell and Goldstein, 1998), Centroid-based Summarization (Radev et al., 2002), Summa-rization through Keyphrase Extraction (Qazvinian et al., 2010) and Formulation as Minimum Dominat-ing Set problem (Shen and Li, 2010), Graph cen-trality to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analy-sis include generative topic models (Haghighi and Vanderwende, 2009), (Celikyilmaz and Hakkani-Tur, 2010), (Li et al., 2011b) and Discriminative models (Aker et al., 2010), ILP2 (Galanis et al., 2012) Joint Optimization of the Importance and Di-versity of summary X  X  sentences (Woodsend and La-pata, 2012), Language Model based scoring func-tion (Takamura and Okumura, 2009) as a maxi-mum concept coverage problem with knapsack con-straint(MCKP) (Wong et al., 2008). Lin and Bilmes formulated summarization as a sub-modular func-tion maximization problem in the possible set of candidate summaries with due respect to the sum-mary space constraint (Lin and Bilmes, 2011). Identifying whether a sentence is contextually in-dependent or not is an important step in our ap-proach to summarization. By Contextual Indepen-dence of a sentence, we mean that the sentence can be globally understood even when the sentences pre-ceding/following it are not available to the reader . Contextual dependence, signifies only the structural dependence of a sentence in a local discourse con-text, not the topical dependence. Topical coherence can be captured by other parameters of optimization function used for generating summary. Take a look at the below example. 1. But it never continued after the first world war. 2. The Prime Minister of France reached Delhi In sentence 1, it is almost impossible to make full sense of the sentence unless the anaphor  X  X t X  is re-solved.  X  X ut X  reveals a contrast relation with the previous unmentioned sentence and therefore highly contextually dependent. Whereas a sentence like 2 can safely stand alone and convey a meaningful in-formation even if sufficient context is not revealed. In our current work, an attempt has been made to quantify this contextual independence of a sentence in terms of surface level, generic features which are described in subsection 4.1. Based on these fea-tures we arrived at a quantified score that denotes the probability of a sentence to be contextually in-dependent. 4.1 LDU identification for measuring Any sentence can be identified to have a contextual dependence with another sentence based on some syntactic cues that trigger the discourse coherence. For example, a pronoun in the subject or object po-sition of a clause in a sentence can more likely be an anaphora to a previous sentence. But extraction of such granular features and clause boundaries re-quires syntactic parsed output of every sentence in a document which is an overhead for the summa-rization system. Therefore, we have modelled the contextual independence identification of every sen-tence in a document as a sequence labelling prob-lem using surface level features such as such as POS labels, unigram/bigram sequences of discourse con-nectives learnt across 3 windows of W words each. For any given sentence, we maximally take the first 3 W words and divide them into three windows and compute the six features mentioned in Table 1 from each window.

Each of the six features signals contextual depen-dence. Computing these features along three win-dows of W words each is intended to statistically generalize that the features are located and com-puted across different clauses in a sentence. For instance, if a pronoun in one clause is resolved in the subsequent clause within the same sentence, one can safely conclude that the sentence is contextu-ally independent. Instead of explicitly identifying the clause boundary and verifying if the anaphora is resolved within the sentence, one can generalize that if the first window does not begin with a pronoun and total number of pronouns is greater than the to-tal number of Named Entities in the 3 W word group, it is more likely to be resolved within the same sen-tence as an anaphora or cataphora. As another il-lustration, take for example determiners such as the modifying a noun as a part of prepositional phrase such as the people from London ; the determiner  X  X he X  in this phrase does not create any contextual depen-dence. This knowledge can be learnt by tracking whether the definite determiner in one window is followed by the presence of preposition in the be-ginning of another window. Thus the count of each of the features mentioned in Table 1 and the W word window boundaries are both crucial to classify a sen-tence as contextually dependent/independent. W is varied experimentally and empirically fixed as 5.
Every locally coherent discourse unit is made up of one contextually independent sentence followed by a sequence of contextually dependent sentences and hence CRF(Lafferty et al., 2001) sequence la-belling algorithm is used for learning the LDUs and in turn the sequence of LDUs in an input document. The features used for contextual independence esti-mation are shown in Table 1.
 The model predicts the probability of contextual in-dependence of a sentence which is later used in the scoring function. The contextual dependencies in-clude anaphors/referents, discourse connectives and determiners. The common POS tags or sequence of POS tags that signal such discourse functions are identified to be PRP, CC, DT, WP, RB, IN, TO. The reason for the choice of the features listed out in Ta-ble 1 is explained below:
DConnect and CC -Typically, a structural con-nection between one sentence to the next is triggered by conjunctions such as also, nevertheless, however, but , discourse connectives such as for instance, in addition, according to . These connectives usually occur at the beginning of a sentence and the features attempt to capture that in the first window.
PRPcount and NECount -Number of Pronouns and the named Entities in a 15 word group. Their relative counts together with the fact of whether they occur in initial positions of first window helps in classification
WhCount -Question words in an interrogative sentence is a marker of contextual dependency Using the above features we are able to model the identification of contextual independence without resorting to the overhead associated with full syn-tactic parsing. 4.2 Leveraging Contextual Independence The contextual independence score of a sentence can be useful in two ways. One is to add the score as a bias term in the candidate summary scoring function and another is to exploit the same score for calculat-ing the comprehensibility index. 4.2.1 Adding a bias term in candidate
Lin and Bilmes suggested a scoring function which contains weighted linear components to cap-ture content coverage and topical diversity of the summary (Lin and Bilmes, 2011). The scoring func-tion is given below.
 F is a monotone sub-modular function which guar-antees the approximation of optimum summary by a factor of 0.632 using a greedy approach. The con-textual independence of a sentence is added as a bias to the scoring function to enable the selection of contextually independent candidate sentences in the generated summary. The new scoring function is given below : F ( S ) = L 1 ( S ) +  X  1  X  R 1 ( S ) +  X  2  X  CI ( S ) (4) Here L 1 ( S ) , R 1 ( S ) and CI ( S ) are given by equa-tions 5, 6 and 7 respectively, where L 1 ( S ) is the coverage function, w i,j is the TF-IDF cosine similarity between sentences i and j, V is the set of all sentences in the corpus, S is the set of sentences in a candidate summary,  X  is a learned parameter.
 where R 1 ( S ) is the diversity function, N is the total no. of documents in the corpus, P 1 ,P 2 ,....P k are sentence clusters formed out of applying k-means clustering on the set of sentences in the corpus with TF-IDF cosine similarity as the similarity metric. where CI ( s ) probability of a sentence s being con-textually independent which is obtained from the CRF model in the section 4.1.
 As per the model created in section 4.1, the con-textual independence of a sentence is a constant and adding it as linear component will not disturb the monotone sub-modularity of sentence scoring function used by Lin and Bilmes (Lin and Bilmes, 4.2.2 Framing a metric for measuring the
A summary S having high CI(S) in equation 7 contains more number of Contextually Independent sentences. Therefore CI(S) represents the potential of a summary to render sufficient context for the sen-tences , such that the reader can grasp the same con-textual interpretation from the summary sentence as is conveyed in the actual corpus, without ever read-ing the full corpus. The scope of the context is cap-tured by means of Local Discourse Unit to which the sentence belongs in the original corpus . Instead of adding CI(S) in equation 3 directly in the scor-ing function, it can be utilised to frame a compre-hensibility index to quantify how much a summary generated by any summarization system is compre-hensible to the reader.
 where Compreh(S) is the comprehensibility index, CI(S) is the contextual independence in equation 7, N is the number of sentences in the summary S. We have to separately evaluate the accuracy of LDU identification, improvement of comprehensibility of system-generated summary when Contextual Inde-pendence is used as a bias term in summarization process and how much reliable the comprehensibil-ity index is, as a metric to estimate the comprehen-sibility of the summary. 5.1 LDU Identification
For LDU identification model creation, we have taken a corpus containing narrative documents com-prising of 2900 sentences. Two Computational Lin-guistics students were involved in annotation of the sentences in the corpus as either contextually depen-of 0.703 (substantial agreement) between them. We extracted the features mentioned in Table 1 and cre-cross validation. The average precision (P), recall (R), F-score and Accuracy (Acc) were measured for different training sets and the results are shown in Table 2. The positive classification represents the contextual independence of a sentence. 5.2 CI(S) as a bias term in the scoring function Table 4: Preference of summary based on compre-hensibility
By adding the CI(S) as a bias term in the scor-ing function in equation 3 to form 4, the system is constrained to choose the sentences which exhibit better contextual independence. Thus the equation 3 loses its flexibility in achieving maximum content coverage by the addition of CI(S) as a bias term. dataset. The results for content coverage in terms of ROUGE-1 scores are given in Table 3.

The proportional decline in content coverage in terms of ROUGE score is tolerable as shown in the table 3. We have reordered the sentences in sum-maries generated by our system and summaries gen-erated by Lin and Bilmes (Lin and Bilmes, 2011) implementation using the reordering system pro-posed by Li et al(Li et al., 2011a). Four students of Computational Linguistics participated in our eval-uation experiment where we conveyed them what we mean by comprehensibility of a summary as de-fined in section 1. For each corpus in the dataset, they were made to read the documents in the corpus and asked choose the more comprehensible of the two summaries generated by our system and Lin &amp; was chosen overwhelmingly more number of times as shown in table 4. 5.3 Evaluation of Comprehensibility Index To evaluate the comprehensibility index, we have taken into consideration, the summaries generated by Lin&amp; Bilmes (Li et al., 2011a) and G-Flow sys-tems(Christensen et al., 2013) for each of the cor-pus in DUC-2004 dataset. The four linguists par-ticipated in another evaluation experiment where we conveyed them about comprehensibility judgement like in previous experiment. For each corpus in the dataset, they were made to choose the more com-prehensible of the two summaries generated by G-Flow and Lin &amp; Bilmes provided in a random order. For the evaluation of the comprehensibility index given by equation 8, we define the accuracy of Com-prehensibility Index as the percentage of times the Compreh(S) value was greater for summaries which are chosen by humans unambiguously. The details are provided in table 5. While considering both the experiments involving human evaluators, the agree-ment between the evaluators was 0.79 in terms of Cohen X  X  kappa measure(Viera et al., 2005). Consid-ering the subjective nature of annotation, we believe Table 5: Comprehensibility Index Evaluation De-tails this is a reasonably good measure of how informa-tive the human judgements were. LDU is identified currently by checking the contex-tual dependency of the current sentence with only the previous sentence. By using Recurrent Neural Networks this contextual dependency can be learnt beyond the preceding one sentence boundary. Com-prehensibility index estimation can be improved by incorporating more information regarding topical context along with local discourse context.

