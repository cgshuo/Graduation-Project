 Statistical machine translation (SMT) systems, re-quire parallel corpora of sentences and their transla-tions, called bitexts , which are often not sufficiently large. However, for many closely-related languages, SMT can be carried out even with small bitexts by exploring relations below the word level.

Closely-related languages such as Macedonian and Bulgarian exhibit a large overlap in their vo-cabulary and strong syntactic and lexical similari-ties. Spelling conventions in such related languages can still be different, and they may diverge more substantially at the level of morphology. However, the differences often constitute consistent regulari-ties that can be generalized when translating.
The language similarities and the regularities in morphological variation and spelling motivate the use of character-level translation models, which were applied to translation (Vilar et al., 2007; Tiede-mann, 2009a) and transliteration (Matthews, 2007).
Certainly, translation cannot be adequately mod-eled as simple transliteration, even for closely-related languages. However, the strength of phrase-based SMT (Koehn et al., 2003) is that it can support rather large sequences (phrases) that capture transla-tions of entire chunks. This makes it possible to in-clude mappings that go far beyond the edit-distance-based string operations usually modeled in translit-eration. Table 1 shows how character-level phrase tables can cover mappings spanning over multi-word units. Thus, character-level phrase-based SMT mod-els combine the generality of character-by-character transliteration and lexical mappings of larger units that could possibly refer to morphemes, words or phrases, as well as to various combinations thereof. We treat sentences as sequences of characters in-stead of words, as shown in Figure 1. Due to the reduced vocabulary, we can use higher-order mod-els, which is necessary in order to avoid the genera-tion of non-word sequences. In our case, we opted for a 10-character language model and a maximum phrase length of 10 (based on initial experiments).
However, word alignment models are not fit for character-level SMT, where the vocabulary shrinks.
Statistical word alignment models heavily rely on context-independent lexical translation parameters and, therefore, are unable to properly distinguish character mapping differences in various contexts. The alignment models used in the transliteration lit-erature have the same problem as they are usually based on edit distance operations and finite-state au-tomata without contextual history (Jiampojamarn et al., 2007; Damper et al., 2005; Ristad and Yiani-los, 1998). We, thus, transformed the input to se-quences of character n -grams as suggested by Tiede-mann (2012); examples are shown in Figure 1. This artificially increases the vocabulary as shown in Ta-ble 2, making standard alignment models and their lexical translation parameters more expressive.
It turns out that bigrams constitute a good com-promise between generality and contextual speci-ficity, which yields useful character alignments with good performance in terms of phrase-based transla-tion. In our experiments, we used GIZA++ (Och and Ney, 2003) with standard settings and the grow-diagonal-final-and heuristics to symmetrize the fi-nal IBM-model-4-based Viterbi alignments (Brown et al., 1993). The phrases were extracted and scored using the Moses training tools (Koehn et al., 2007). 1
We tuned the parameters of the log-linear SMT model using minimum error rate training (Och, 2003), optimizing BLEU (Papineni et al., 2002). Since BLEU over matching character sequences does not make much sense, especially if the k -gram size is limited to small values of k (usually, 4 or less), we post-processed n -best lists in each tuning step to calculate the usual word-based BLEU score. We also built a character-level SMT system for word-level transliteration, which we trained on a list of automatically extracted pairs of likely cognates. 3.1 Cognate Extraction Classic NLP approaches to cognate extraction look for words with similar spelling that co-occur in par-allel sentences (Kondrak et al., 2003). Since our Macedonian-Bulgarian bitext (MK X  X G) was small, we further used a MK X  X N and an EN X  X G bitext.
First, we induced IBM-model-4 word alignments for MK X  X N and EN X  X G, from which we extracted four conditional lexical translation probabilities: Pr( m | e ) and Pr( e | m ) for MK X  X N, and Pr( b | e ) and Pr( e | b ) for EN X  X G, where m , e , and b stand for a Macedonian, an English, and a Bulgarian word.
Then, following (Callison-Burch et al., 2006; Wu and Wang, 2007; Utiyama and Isahara, 2007), we induced conditional lexical translation probabilities as Pr( m | b ) = P e Pr( m | e ) Pr( e | b ) , where Pr( m | e ) and Pr( e | b ) are estimated using maximum likeli-hood from MK X  X N and EN X  X G word alignments.

Then, we induced translation probability estima-tions for the reverse direction Pr( b | m ) and we cal-culated the quantity Piv( m, b ) = Pr( m | b ) Pr( b | m ) . We calculated a similar quantity Dir( m, b ) , where the probabilities Pr( m | b ) and Pr( b | m ) are estimated using maximum likelihood from the MK X  X G bitext directly. Finally, we calculated the similarity score S ( m, b ) = Piv( m, b )+Dir( m, b )+2  X  LCSR( m, b ) , where LCSR is the longest common subsequence of two strings, divided by the length of the longer one.
The score S ( m, b ) is high for words that are likely to be cognates, i.e., that (i) have high probability of being mutual translations, which is expressed by the first two terms in the summation, and (ii) have sim-ilar spelling, as expressed by the last term. Here we give equal weight to Dir( m, b ) and Piv( m, b ) ; we also give equal weights to the translational similar-ity (the sum of the first two terms) and to the spelling similarity (twice LCSR).
We excluded all words of length less than three, as well as all Macedonian-Bulgarian word pairs ( m, b ) for which Piv( m, b ) + Dir( m, b ) &lt; 0 . 01 , and those for which LCSR( m, b ) was below 0.58, a value found by Kondrak et al. (2003) to work well for a number of European language pairs.

Finally, using S ( m, b ) , we induced a weighted bi-partite graph, and we performed a greedy approxi-mation to the maximum weighted bipartite matching in that graph using competitive linking (Melamed, 2000), to produce the final list of cognate pairs.
Note that the above-described cognate extraction algorithm has three important components: (1) or-thographic, based on LCSR, (2) semantic, based on word alignments and pivoting over English, and (3) competitive linking. The orthographic compo-nent is essential when looking for cognates since they must have similar spelling by definition, while the semantic component prevents the extraction of false friends like vreden , which means  X  X aluable X  in Macedonian but  X  X armful X  in Bulgarian. Finally, competitive linking helps prevent issues related to word inflection that cannot be handled using the se-mantic component alone. 3.2 Transliteration Training For each pair in the list of cognate pairs, we added spaces between any two adjacent letters for both words, and we further appended special start and end characters. We split the resulting list into training, development and testing parts and we trained and tuned a character-level Macedonian-Bulgarian phrase-based monotone SMT system sim-ilar to that in (Finch and Sumita, 2008; Tiedemann and Nabende, 2009; Nakov and Ng, 2009; Nakov and Ng, 2012). The system used a character-level Bulgarian language model trained on words. We set the maximum phrase length and the language model order to 10, and we tuned the system using MERT. 3.3 Transliteration Lattice Generation Given a Macedonian sentence, we generated a lat-tice where each input Macedonian word of length three or longer was augmented with Bulgarian al-ternatives: n -best transliterations generated by the above character-level Macedonian-Bulgarian SMT system (after the characters were concatenated to form a word and the special symbols were removed).
In the lattice, we assigned the original Macedo-nian word the weight of 1; for the alternatives, we assigned scores between 0 and 1 that were the sum of the translation model probabilities of generating each alternative (the sum was needed since some op-tions appeared multiple times in the n -best list). For our experiments, we used translated movie sub-titles from the OPUS corpus (Tiedemann, 2009b). For Macedonian-Bulgarian there were only about 102,000 aligned sentences containing approximately 1.3 million tokens altogether. There was substan-tially more monolingual data available for Bulgar-ian: about 16 million sentences containing ca. 136 million tokens.

However, this data was noisy. Thus, we realigned the corpus using hunalign and we removed some Bulgarian files that were misclassified as Macedo-nian and vice versa, using a BLEU-filter. Fur-thermore, we also removed sentence pairs contain-ing language-specific characters on the wrong side. From the remaining data we selected 10,000 sen-tence pairs (roughly 128,000 words) for develop-ment and another 10,000 (ca. 125,000 words) for testing; we used the rest for training.
 The evaluation results are summarized in Table 3.
Transliteration. The top rows of Table 3 show the results for Macedonian-Bulgarian transliteration. First, we can see that the BLEU score for the original Macedonian testset evaluated against the Bulgarian reference is 10.74, which is quite high and reflects the similarity between the two languages. The next line (t1) shows that many differences between Mace-donian and Bulgarian stem from mere differences in orthography: we mapped the six letters in the Mace-donian alphabet that do not exist in the Bulgarian al-phabet to corresponding Bulgarian letters and letter sequences, gaining over 1.3 BLEU points. The fol-lowing line (t2) shows the results using the sophis-ticated transliteration described in Section 3, which takes two kinds of context into account: (1) word-internal letter context, and (2) sentence-level word context. We generated a lattice for each Macedonian test sentence, which included the original Mace-donian words and the 1-best 2 Bulgarian transliter-ation option from the character-level transliteration model. We then decoded the lattice using a Bulgar-ian language model; this increased BLEU to 22.74.
Word-level translation. Naturally, lattice-based transliteration cannot really compete against stan-dard word-level translation (w1), which is better by 8 BLEU points. Still, as line (w2) shows, using the 1-best transliteration lattice as an input to (w1) yields 3 consistent improvement over (w1) for four evaluation metrics: BLEU (Papineni et al., 2002), NIST v. 13, TER (Snover et al., 2006) v. 0.7.25, and METEOR (Lavie and Denkowski, 2009) v. 1.3. The baseline system is also signifi-cantly better than the on-line version of Apertium (http://www.apertium.org/), a shallow transfer-rule-based MT system that is optimized for closely-related languages (accessed on 2012/05/02). Here, Apertium suffers badly from a large number of un-known words in our testset (ca. 15%).

Character-level translation. Moving down to the next group of experiments in Table 3, we can see that standard character-level SMT (c1), i.e., simply treating characters as separate words, per-forms significantly better than word-level SMT. Us-ing bigram-based character alignments yields fur-ther improvement of +0.43 BLEU.
System combination. Since word-level and character-level models have different strengths and weaknesses, we further tried to combine them. We used MEMT, a state-of-the-art Multi-Engine Machine Translation system (Heafield and Lavie, 2010), to combine the outputs of (c3) with the out-put of (w1) and of (w2). Both combinations im-proved over the individual systems, but (w1)+(c2) performed better, by +0.6 BLEU points over (c2). Combining word-level and phrase-level SMT.
 Finally, we also combined (w1) with (c3) in a more direct way: by merging their phrase tables. First, we split the phrases in the word-level phrase tables of (w1) to characters as in character-level models. Then, we generated four versions of each phrase pair: with/without  X   X  at the beginning/end of the phrase. Finally, we merged these phrase pairs with those in the phrase table of (c3), adding two ex-tra features indicating each phrase pair X  X  origin: the first/second feature is 1 if the pair came from the first/second table, and 0.5 otherwise. This combina-tion outperformed MEMT, probably because it ex-pands the search space of the SMT system more di-rectly. We further tried scoring with two language models in the process of translation, character-based and word-based, but we did not get consistent im-provements. Finally, we experimented with a 1-best character-level lattice input that encodes the same options and weights as for (w2). This yielded our best overall BLEU score of 33.94, which is +2.84 BLEU points of absolute improvement over the (w1) baseline, and +1.23 BLEU points over (c2). 4 We have explored several combinations of character-and word-level translation models for translating between closely-related languages with scarce re-sources. In future work, we want to use such a model for pivot-based translations from the resource-poor language (Macedonian) to other languages (such as English) via the related language (Bulgarian). The research is partially supported by the EU ICT PSP project LetsMT!, grant number 250456.
