 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining General Terms: Algorithms, Experimentation Keywords: Weblogs, Online-Communities, Time-sensitive Clustering
In the past few years, weblogs, or blogs as they are more commonly known, have emerged as an important type of Web page. Though blogs started out as online diaries, easy-to-use blogging tools (Blogger [4], LiveJournal [18] etc.) have led to an explosion in their number, and blogs have evolved into an important medium for online content. Several mil-lion blogs are currently in existence. Typically, a blog is a Web page comprised of a sequence of dated entries.
Some characteristics make blogs different from other Web pages. First, each blog is usually maintained and updated by one person (called the blogger ). Hence, blogs are per-sonal, representing the interests, opinions and interactions of one blogger. Second, blogs are updated regularly with new entries; hence they contain rapidly evolving content, as compared to regular websites that do not change much Copyright 2006 ACM 1-59593-433-3/06/0011 ... $ 5.00. over time. Third, each entry in a blog has an associated time stamp, unlike regular webpages. Also, bloggers inter-act with each other by linking to each other X  X  entries in their own entries, thus forming online communities. Within these communities, bloggers engage in discussions over certain is-sues, through entries in their blogs. These discussions, or stories in the blogosphere exist for a while and then die out.
Because of the increasing number of blogs and their unique characteristics, developing techniques for searching and min-ing blogs has become important. Several commercial web-sites like Blogpulse [5], Technorati [27], and Google Blog Search [25] are now available to mine and analyze blog con-tent. These websites provide services such as searching blogs based on query keywords, ranking of blogs according to pop-ularity, and identifying trends in keywords seen in the blogo-sphere. The research community has also begun to focus on blogs, and publications include studies on blog communities, and information diffusion through the blogosphere.
One important problem that has not yet been addressed in mining the blogosphere is to extract cohesive discussions from blog communities as time goes on, on any given sub-ject or issue. In this work, we introduce this problem of story mining and propose a time-sensitive and community-sensitive model to group blog entries into stories, while lever-aging distinct characteristics of blogs like entry time-stamps and community structure. We also propose a Modified Time-sensitive Dirichlet Process and use that in our model.
To group blog entries into stories, we use a probabilistic graphical model. The story is treated as a latent variable while the entry content, time-stamps, and inter-blog links are the observed variables. Our model does not require spec-ifying the number of stories. The number of stories can be potentially infinite and is discovered by the model. Entries are first clustered by community and content. In each such cluster, the timestamps of entries are then used when group-ing entries, so that newer entries are less likely to be grouped with older entries, since two entries with similar content but with wide separation in time are likely to be different stories. Once stories have been discovered, the most recent ones can be considered the hot stories .

Mining stories and hot stories from blogs has useful prac-tical applications. It can help us see what issues are of inter-est to various domains and communities. Also, blog analyt-ics are becoming an important tool for marketing research since blogs often contain frank unsolicited information about products. Discussions discovered through story mining can be processed to derive market intelligence [7].
As an example, consider discussions on the blogosphere about the Apple iPod. Stories discussed would include the introduction of the iPod, and later that of the iPod Mini. In September of 2005, the hot story would have been the announcement of the iPod Nano. Or consider discussions about hurricanes in the Atlantic. Stories would include Hur-ricanes Dennis and Emily in July 2005, Katrina in August 2005, and in mid-September 2005, Hurricane Rita would have been the hot story. In this work, we wish to identify such stories and hot stories.

We summarize the contributions of this paper as follows: 1. We propose a two-stage model to cluster blog entries 2. Our model provides a community-based clustering by 3. We propose a Modified Time-sensitive Dirichlet Pro-
The rest of the paper is organized as follows. Section 2 discusses related work. Section 3 discusses the nature of the blogosphere, and how we approach the problem of discovering stories. Section 4 describes our proposed model. Section 5 presents experimental studies on real-world blog data and shows our model to be very effective in finding interesting communities and stories. We offer concluding remarks in Section 6.
We present related work here in four parts: 1) blog mining research, 2) use of probabilistic graphical models for content and relation analysis, 3) temporal mining, and 4) Web search result clustering.
Since blogs are a new area of research, there has been relatively limited academic work in this area. The flow of information through blogs has been studied by Adar et al. [2] and Gruhl et al. [8]. Kumar et al. [15] studied the formation of communities, and their bursty evolution. Tseng et al. in [28] used tomographic clustering to form and visualize communities in the blogosphere. Both Kumar et al. [15] and Tseng et al. [28] used the link structure between blog entries to discover communities. In contrast, Ishida[11] discovered latent communities based on similarity in content of various blogs, without considering links.

To the best of our knowledge, there is no work in the literature that discovers stories while exploiting the unique characteristics of the blog medium.
Probabilistic models have become popular for text analy-sis. Often each topic is modeled as a probability distribution over words, and a document is viewed as a probabilistic mix-ture over these topics. The probability of generating word w i in a given document is then given by: where z i is a latent variable indicating the topic from which the w i is drawn and T is the number of topics. P ( w i | is the probability of w i given topic j and P ( z i = j )gives the prior probability of topic j .

In probabilistic Latent Semantic Analysis (PLSA) [9], top-ics are modeled as multinomial distributions over words, and documents are assumed to be generated from multiple top-ics. In Latent Dirichlet Analysis (LDA) [3], a distribution over topics is sampled from a Dirichlet distribution for each document. Each word is sampled from a multinomial dis-tribution over words specific to the sampled topic. For D documents about T topics containing W words, we can rep-resent P ( w | z )usingasetof T multinomial distributions  X  over the W words such that P ( w | z = j )=  X  w j ,and P ( z ) with a set of D multinomial distributions  X  over T topics, such that for a word in document d , P ( z = j )=  X  d j .
Recently, the Author-Topic (AT) model [20] extended LDA to incorporate authorship information and the authors of [22] further extended the AT model to the Author-Recipient-Topic (ART) model, specifically for email, by regarding the sender-receiver pair as an additional variable.

Latent structure or groups have been discovered through pairwise relational data in the stochastic Blockstructures model [24], by modeling relations between entities proba-bilistically . A relation holds between a pair of entities with a probability that depends only on the group assignment of the entities. In [13], a non-parametric process was used to select the number of groups. The Group-Topic model [30] extends the Blockstructures model [24] to include attributes on the relations.

However, these models are not suitable for extracting sto-ries from blogs, since they do not consider time and com-munity structure along with the content, all of which are important characteristics of blogs. We propose a two-stage method that first groups blog entries into clusters corre-sponding to blogger communities and then extracts stories, using a combination of content and time stamps. Also, in our model, the number of stories need not be specified.
Recently, there has been some work on temporal mining for text streams. In [14], text streams are converted to tem-poral frequency data for discovering burstiness in the stream. The authors of [23] studied the evolution of themes (prob-ability distributions over words) in a stream of documents. Other works, such as by Ma et al. [21], look for temporal trends in a text stream.

In contrast, our work is concerned with discovering coher-ent groups of documents (blog entries) while incorporating time. Additionally, the community structure is also used.
Clustering methods have been used to group Web search results into groups to allow for better organization and easy navigation. Several clustering engines have been proposed and implemented. The Scatter/Gather system [6] was an early method. Grouper [31] performs clustering using a phrase-based algorithm called Suffix Tree Clustering. Vivisimo [29] is a commercial service that returns clustered Web search results, but uses an unpublished proprietary technique. Other systems include iBoogie [10], and Lingo [17]. The authors of [32] tackle the problem as a salient phrase ranking problem and use learning to discover the ranking, while Kumar et al. [16] presented a graph theoretic approach to the problem. Blogs have unique characteristics, which makes it impor-tant to develop specialized techniques that can utilize these characteristics so as to create meaningful and useful stories.
In this section, we discuss the motivation for mining sto-ries from blogs, the issues involved, and our approach for addressing the problem.
The blogosphere is comprised of a large number of blog-gers regularly updating their blogs with new entries. (Figure 1 shows a sample blog entry.) Since a blog usually cor-responds to an individual who has certain topics of inter-est, the blog is likely to contain entries about those topics. Also, bloggers read other blogs about these topics and is-sues. Bloggers, in their entries, also link to and write about entries in these other blogs, thus creating a conversation in the blogosphere. These bloggers, with their shared inter-ests, conversing over various topics and issues form online communities.

When mining the blogosphere for stories, the communiity structure can be very useful. A community in the blogo-sphere corresponds not only to a topic, but also to a partic-ular viewpoint on the topic. For example, viewed based on content analysis alone, all blogs about politics may appear similar. However, since a political blogger is more likely to link to blogs that match his/her political viewpoint, the communities formed would correspond to a specific politi-cal ideology or viewpoint. This has been validated by [1]. Hence, uncovering and utilizing the community structure can be useful for better mining of coherent stories. As an-other example, consider discussions in the blogosphere about Apple Computer X  X  move to the Intel platform. We may find technology-oriented bloggers who would view this news from a different perspective than perhaps bloggers interested in Apple X  X  stock price. Again, the community structure can help differentiate these stories.
 Before we proceed, we elaborate on our notion of a story . A story is comprised of a set of blog entries that are about a specific issue and that reflect a discussion in the blogosphere. Several stories may be retrieved from a blog database, for some query keywords.

Entries are usually triggered by online or offline events, and stories thus reflect events in the real world such as a news item, a new book or product, or a political or cultural event. Entries in a story have a time-stamp and stories have a time duration. Time can thus be useful in differentiating stories. Two blog entries that have similar content but which were written far apart in time were likely triggered by differ-ent events and thus should be part of different stories. For instance, two entries about the launch of the iPod written far apart in time probably deal with different models of the iPod. Thus it is important to take time-stamps of entries into consideration when clustering entries into stories.
Based on the above understa nding of the blogosphere, we have developed a two-stage Content-Community-Time (CCT) story extraction model to discover stories from a blog database, given some query keywords. Entries relevant to the keywords are retrieved, and then grouped into stories based on their content, time-stamps, and community struc-ture. Here, we give only an overview of our approach, but we go into a detailed description in Section 4.
The community structure is first uncovered as follows. We construct a Community Graph where nodes correspond to the set of entries. We consider a blog entry A to have a link toablogentry B if the blogger of A had hyperlinked to any entry in the blog that B belongs to, within the T days before posting entry A . We do this because this reveals that A  X  X  blogger had an interest in B  X  X  blog at the time of writing entry A . (We assume that the interests of a blogger remain consistent for T days). In this work, we set T to be 30 days. Also, if two entries come from the same blog, we consider them to be linked. We consider links to be directionless since we are interested in community structure, not the flow of information.
In the first stage of the CCT model, we consider content and community structure, and perform a coarse clustering. The set of retrieved entries is divided into Community-Topic clusters (CT-clusters) such that the entries in one cluster are from a group of bloggers that are likely to have a similar interest in the concerned topics, and who may discuss these issues online. (A related notion of Topic-Communities was introduced in [26] in the context of email.) In this model, the number of CT-clusters is determined based on the data, and does not have to be specified. This is very useful since the true number of CT-clusters for any query is unknown. The second stage of the model discovers stories in each CT-cluster. Here content is considered again, but so as to create a finer clustering. Also entry time-stamps are used to assist clustering. Again, as for CT-clusters, the number of stories does not need to be specified.
In this section, we detail our Content-Community-Time (CCT) model and techniques for mining stories from blogs. In Section 4.1, we define some terms and set up notation. Section 4.2 describes the preprocessing performed. Sections 4.3, 4.4, and 4.5 then detail the process of extracting stories basedonsomekeywords.
We formally define here some terms and notions that we use throughout this paper.

Definition 1. (Blog): A Blog is a Webpage comprising of a sequence of dated entries , which has an associated RSS (Really Simple Syndication) feed. A blog is usually written by an individual who is called the blogger .
 Definition 2. (Community Graph): A Community Graph is a graph with nodes corresponding to a set of en-tries, and edges depicting an interest relationship between the bloggers of the two entries.

Definition 3. (Community-Topic Cluster): A Com-munity Topic Cluster (CT-cluster) is a set of blog entries generated by a community of bloggers that write about a topic of mutual interest, such as about politics, technology, or pop music, and link to each other X  X  entries.

Definition 4. (Story): :A Story is a set of blog entries that are about a specific issue and that reflect a discussion in blogspace between members of an online community.
A blog database consists of blog entries e i .Eachentry e has associated with it a blog b ( e i ), and a time-stamp t ( e and a document d ( e i ). The time-stamp t ( e i )isthetimeat which the document d ( e i ) was posted at blog b ( e i ). Also associated with each entry is a set of hyperlinks embedded in the document.

When extracting stories, let n be the number of entries retrieved from the blog database for grouping into stories. For a set of n blog entries, we construct a Community-Graph G that contains n nodes, each corresponding to an entry, and each edge g ij denotes a link between entry e i and entry e
The Community-Topic cluster that an entry e i belongs to is denoted by z ( e i ), while the story it belongs to is denoted by s ( e i ). We use z to denote an n -dimensional vector con-taining z ( e i ) for each of n entries e i . Similarly, s is a vector of stories s ( e i )foreach e i .Also, z  X  i and s  X  i denote z and s excluding z ( e i )and s ( e i ) respectively. We use n j the number of entries in a CT-cluster or story j . Let the number of unique words be V .Thewordsina CT-cluster i are given by a multinomial distribution  X  i over the V words, such that the probability of seeing a word w in cluster j is  X  j ( v ). Similarly,  X  j represents a multinomial distribution over V words for a story j .
 There are some parameters for the model. We use  X  z and
Symbol Meaning d ( e i ) content of e i z ( e i ) CT cluster that e i belongs to s ( e i ) story that e i belongs to  X  s to denote the concentration parameters for clustering into CT-clusters and stories, respectively. Hyperparameters  X  and  X  s control the multinomial distributions  X  and  X  , while hyperparameter  X  controls the distribution of links between clusters. These parameters will be explained along with the model.
Entries from blogs are crawled from the Web and stored locally. The content of each entry is then processed to remove stop words, and stemming is performed using the Porter stemmer.

Then, to allow retrieval of entries based on query key-words, an inverted index is created and the contents of all the entries are inserted into this inverted index. In this work, we used the Apache Lucene [19] library, a standard open-source text search-engine for indexing the text. Along with the content, the entry date, the url, and the corresponding blog url are all stored in the index.

To allow construction of the Community Graph, for each entry we create a list of blogs hyperlinked in the correspond-ing blog within the T days before the entry itself. This linked-blogs list is also stored in the index so it can be re-trieved along with the entries.
The process of extracting stories begins with the user pro-viding some query keywords. Based on these keywords, the Lucene index is queried to retrieve the top n relevant entries. The entry date, associated blog url, and the linked-blogs list.
We now construct the Community Graph, which repre-sents the community structure. The graph G has n nodes, one for each entry. An edge g ij exists between nodes e i e if b ( e j ) exists in the linked-blogs list of e i or b ( e in the linked-blogs list of e j . The constructed graph is di-rectionless. The Community Graph is used to incorporate community structure while finding CT-clusters.
We next use the set of retrieved entries, their content, and the associated community structure (represented by the graph) to group the entries into Community-Topic clusters.
A probabilistic model is used to do the clustering. Given entry documents d ( e 1 ) , ..., d ( e n ) and the Community Graph G , we cluster the entries. The cluster of an entry e i is de-noted by the latent variable z ( e i ). Gibbs sampling is used to compute the cluster labels based on an inference equation. For the inference, we need to find the probability that an entry e i belongs to cluster j , given cluster memberships for all entries except e i , the contents of all entries including e and the graph G .

This can be broken down into three terms. The first term sets the prior probability for z ( e i ) based only on the cluster memberships of all other entries. The second term is the probability of generating the document d ( e i )fromcluster j based on the other documents in cluster j .Thethird term gives the probability of graph G being generated given the cluster memberships of all entries. We can write the inference equation as:
P ( z ( e i )= j | z  X  i ,d ( e 1 ) , ..., d ( e n ) ,G ) where z is the vector of cluster assignments for all entries, and z  X  i is the vector of cluster assignments for all entries except e i .

We discuss in the following sections how each of the terms in the above equation are computed.
The first term on the right hand side of equation 1 gives the probability of an entry e i being assigned to cluster j given the cluster assignments of all other entries. We set this probability based on a Chinese Restaurant Process (CRP). A Chinese Restaurant Process is a clustering mechanism that allows the number of clusters to be potentially infinite. This is quite useful for our purposes since the true number of CT-clusters is unknown and hard to preset.

In a Chinese Restaurant Process (CRP), the probability of a new object belonging to an existing group is directly proportional to the number of objects of that group seen previously. Also, the object may belong to a new group with some probability which is controlled by a concentration parameter . In this way, the number of groups formed is selected automatically by the model, and may grow with the number of objects. Using the CRP for our scenario, we can write where n j is the number of entries already assigned to cluster j ,and  X  z is the concentration parameter .

Note that in the above equation, the probability of entry e being in cluster j is conditioned on only the entries seen before it. However, it is known that CRP is exchangeable, meaning that the indices of e i can be permuted without affecting the probabilities of z ,andsowecantreat e i as the last object to be drawn from the CRP.

Thus, we can get P ( z ( e i )= j | z  X  i ), the first term in equa-tion 1 by assuming that all other entries have already been seen.
The second term in equation 1 incorporates the entry con-tent by giving the probability of the content in entry e i generated from cluster j , given the content of all other en-tries in cluster j .

Each entry document d ( e i ) is represented by a bag of words from the vocabulary containing V words. We assume that each CT-cluster j is represented by a multinomial dis-tribution  X  j over the vocabulary. The probability for entry d ( e i ) being generated from cluster j is then where e i ( v ) is the count of word v in the content of entry e ,and  X  j ( v ) gives the probability that word v is generated from cluster j . We can avoid sampling  X  by integrating it out, and using a Dirichlet multinomial to represent clusters.
P ( d ( e i ) | d ( e k )  X  z ( e k )= j )= Z tion which is derived from a base prior Dirichlet distribution. It can be shown that equation 4 can be written as: P ( d ( e i ) | d ( e k )  X  z ( e k )= j )= where f v is the count of word v in d ( e k )  X  z ( e k )= j , X ()is the gamma function and  X  z is a hyperparameter.
The third term in equation 1 is designed to incorporate the blogger community structure such that intra-cluster linking is much less frequent than inter-cluster linking. We assume that each edge in G is generated independently, and the probability that there exists a link g ij , depends on z ( e and z ( e j ), the CT-clusters corresponding to e i and e
Given the vector of cluster assignments z , the probability of generating the graph G, given all cluster memberships is given by where a and b range over all clusters,  X  ab is the probability that there is an edge between an entry in cluster a and an entry in cluster b , m ab is the number of edges between en-tries in a and b ,and m ab is the number of pairs of entries in clusters a and b respectively that do not have a link be-tween them. We can integrate out  X  in equation 7 using a symmetric Beta prior over every  X  ab .Then where  X  is a hyperparameter that controls the Beta prior.
Now we can substitute equations 2, 5, and 7 into equation 1 and infer the cluster memberships z ( e i ) for any entry given the cluster memberships of all other entries. We initialize clustering by arbitarily assigning a cluster to each entry, say by putting all entries in the same cluster.

A single Gibbs sampling iteration consists of looping through i =1 , ..., n and sampling z ( e i ), in turn, using equation 1, based on the current cluster memberships of all other entries. Then for each entry, the cluster with the highest probabil-ity is assigned as the new cluster for the entry. The Gibbs sampling iteration is then repeated using the new cluster memberships. After running several iterations of the Gibbs sampler, we get cluster memberships z ( e i ) for each entry e
In the next stage, we consider the entry content and time to further divide each CT-cluster into stories. As in the last stage, a probabilistic model is used to do the clustering. Given entry documents d ( e 1 ) , ..., d ( e n ) and their correspond-ing timestamps t ( e i ), we cluster the entries into stories. The story to which an entry e i belongs is denoted by the latent variable s ( e i ). Gibbs sampling is used to compute the story labels based on an inference equation that incorporates time and content.

We can find the probability that an entry e i belongs to story j , given story memberships for all entries except e the contents of all entries including e i , and the time-stamps of all entries. This can be broken down into two terms. The first term sets the prior probability for s ( e i ) based only on the story memberships of all other entries, and the time-stamps of all entries. The second term is the probability of generating the document d ( e i ) from story j basedonthe other documents in cluster j . We can write the inference equation as follows.

P ( s ( e i )= j | s  X  i ,d ( e 1 ) , ..., d ( e n ) ,t ) where s  X  i is the vector of cluster assignments for all entries except e i ,and t is the vector of time-stamps for all entries.
The first term on the right hand side of equation 8 gives the probability of an entry e i being assigned to story j given the story assignments of all other entries, and the time-stamps of all entries.
 For this, we propose a Modified Time-sensitive Dirichlet Process model (based on [12]), where the probability of entry e belonging to story j given the history of story assignent by where  X  s is a concentration parameter, and the function w ( t, j ) gives the weight of a story j at time t . We define function w ( t, j )below.

A Time-sensitive Dirichlet Process is similar to the Chi-nese Restaurant Process, but also incorporates time while assigning clusters. For a new object, the probability of joining an existing group depends on the members of the groups and their age, while it may create a new group with some probability (controlled by the concentration parame-ter). The influence of existing groups decays with the age of members in the group. However, this model is not exchange-able, and we cannot treat any object as the last object to be seen. The first term in equation 8, P ( s ( e i = j ) | s  X  given by
P ( s ( e i )= j | s  X  i ,t ) In prior work, the authors of [12] proposed a Time-sensitive Dirichlet Process model where the probability of entry e i longing to story j given the history, would be given by
However this model has a limitation. The first term in the denominator in the RHS of equation 11, varies significantly since it is very data dependent. The probability of a new cluster is then very different for each term in equation 10, but we would like the possibility of creating new clusters to be uniform. Thus, we proposed equation 9 where probability of being assigned a new cluster is same for all terms.
Now, the weight function w ( t, j ) used above is defined such that the the influence of a story decays with the age of its member entries. It is given by where k ( t ) is a kernel that controls the decay of influence influence of an cluster. The weight decays with time and so a new entry is less likely to join a much older story. We can use a kernel that causes exponential decay of the influence of an entry [12], as follows: where  X  is a decay parameter.
The second term in equation 8 gives the probability of seeing the content in entry e i being generated from story j , given the content of all other entries in story j . Similar to the last stage, we can write P ( d ( e i ) | d ( e k )  X  s ( e k )= j )= where f v is the count of phrase v in d ( e k )  X  s ( e k the gamma function and  X  s is a hyperparameter.
Now we can substitute equations 10 and 13 into equation 8 and infer the story s ( e i ) for all entries using Gibbs sam-pling as performed in Section 4.4.4. After running several iterations of the Gibbs sampler, we get story assignments s ( e i ) for each entry e i .
At the end of this stage, for each entry in each CT-cluster, we have assigned a story label. We are interested in extract-ing interesting stories from the blogosphere. The importance of a story can be in some sense measured by the number of entries in it. For instance, many stories might have just a single entry. Such a story is unlikely to reflect an important event or happening, and is likely to be a personal musing on the subject by a blogger. We thus select the stories that contain several entries.

Since each entry has an associated time-stamp, the time and duration of the story can be determined. Once we have extracted the stories, we can find hot stories by seeking those that are recent.
We implemented the proposed CCT model and used it for mining stories from the blogosphere. For this purpose, we crawled the Web and collected over a million blog entries.
We used the model for several query keywords and stud-ied the results. Since no ground truth is available for these blogs, and the relevance and quality of results may be sub-jective, it is not practically feasible to give a quantitative evaluation of results. Instead, we demonstrate the effective-ness of our model and its various aspects through several case studies.

In the case studies, we show stories discovered using the proposed model, describe the Community-Topic clusters formed, and how they correspond to actual blogger communities. Also we show story extraction differs when performed using the following two alternative models.
 Time-Insensitive Story Extraction
To understand the utility of timestamps in extracting sto-ries, we experimented with a model that replaces the Time-sensitive Dirichlet process in the second stage of the CCT model with a Chinese Restaurant Process. This makes the story clustering insensitive to time.

Our testbed is described in Section 5.1, selection of model parameters is discussed in Section 5.2, and several case stud-ies are presented in Section 5.3.
 One-Stage Story Extraction
It is possible to perform the story extraction by combin-ing community structure, content, and time, for clustering together in one stage. The inference equation for such clus-tering would be
P ( s ( e i )= j | s  X  i ,d ( e 1 ) , ..., d ( e n ) ,G ) where the first term would be computed using the Time-sensitive Dirichlet process as in equation 10, the second term would be given by equation 13, and the third term would be given by equation 7. The inference can then proceed by Gibbs sampling as in Section 4.4.4.
We prepared a blog database for use as a testbed for our studies. The blog database contained over 1 million entries along with timestamps, the corresponding blog url, and em-bedded hyperlinks to other blogs.
The blog database was constructed by crawling the blogo-sphere for over 10 months, from December 2004 to Septem-ber 2005. The crawling was started from a small set of handpicked blogs, and continued along the out-links from these blogs. For our purpose, blogs are webpages that have an associated RSS stream. For over 2 , 000 blogs, new en-tries were retrieved on a daily basis. Also, we stored all blog entries linked to from any of these 2 , 000 blogs.
Time-stamps for blog entries may be available from the corresponding RSS feed. However, for many blogs, the time-stamp is missing or malformed in the RSS feed. For these, we recovered the time-stamp s by examining the HTML files or the URL. Several hand-crafted regular expressions were used to extract dates in a variety of date formats, and some XPath expressions were used to look for dates in certain locations in the documents. For this work, we consider time at the granularity of dates.
In the CCT model, there are six parameters that control the various factors in finding community-topics and queries. These parameters are:  X  z : Hyperparam for Dirichlet distribution for CT clusters  X  s : Hyperparam for Dirichlet distribution for stories  X  z : Concentration param for Chinese Restaurant Process  X  s : Concentration param for Time-Sesitive Dirichlet Model  X  : Hyperparam for Beta prior for community structure  X  : Entry weight decay param
These parameters must be tuned in accordance with the ourobjectives. Forinstance,  X  z for the first stage must be such that the clustering is coarse, since at this stage we want to find only the broad community-topics and not the indi-vidual stories. In contrast, for discovering stories,  X  s be such that finer clustering is done so as to find the individ-ual stories. The concentration parameters  X  z and  X  s should be such that there is a small probability of an entry being assigned to a new cluster. The decay parameter  X  must be set to appropriately control the decay of weight of an en-try decays with time. The effect of community structure on clustering is controlled by  X  .

We tuned these parameters based on a user study, where the community-topics and stories obtained with various pa-rameters were examined manually to evaluate the quality of results. The best parameters were thus chosen and used.
For the hyperparameters  X  z and  X  s ,weusedthevalues 0 . 1 and 50 respectively. The concentration parameters  X  and  X  s were chosen to be 2 and 0 . 01 respectively. The value for parameter  X  was chosen to be 10, and that for the decay parameters  X  was taken to be 0 . 5.

For the Time-Insensitive story-extraction model, we used the same parameters, except that the concentration param-eter for CRP in the second stage was set to be 2. When experimenting with the One-Stage story extraction model, we set  X  s to be 50,  X  s ,tobe0 . 01,  X  to be 0 . 5, and  X  to be 10.
In this section, we present three case studies of story mining using the proposed CCT model. The query key-words used for the three case studies are  X  X sunami X ,  X  X ndia China X , and  X  X ony X . For each, we use the top 200 blog en-tries for grouping into Community-Topic clusters and sto-ries.

The three case studies demonstrate different aspects of our story-mining model. 1. The  X  X sunami X  query (Section 5.3.1) shows CT-clusters 2. The  X  X ndia China X  case study (Section 5.3.2) demon-3. The  X  X ony X  case study (Section 5.3.3) shows stories For the  X  X sunami X  keyword, we found two CT-clusters. We represent them in Table 2 by the top 5 most frequent words in each cluster (excluding the query word itself). A closer inspection of the content of the entries in each CT-cluster show that the CT-cluster 1 contains entries that talk about the tsunami disaster, while entries in CT-cluster 2 provide videos and images relating to the tsunami. CT-cluster 2 contains few entries but gets separated into a sepa-rate cluster since it is distinct from other discussions about the tsunami.

We now look at CT-cluster 1 in greater detail. In the story extraction phase, sever al stories were extracted from this cluster. We examined a few stories. The top 5 most frequent words for these stories are listed in Table 3.
We examine manually the content of entries in each of these stories.

Story 1 contains entries about the Katrina hurricane that compare the devastation caused to that of the South Asian tsunami. The entries are dated around late August and early September 2005. A few days after the Katrina hurricane, the enormity of the disaster became apparent, and there were frequent comparisons with the tsunami of a few months ago. Story 2 contains entries dated late December 2004 through February 2005 that talk about the tsunami soon after it hap-pened. Entries talk about the disaster, and about donation and relief efforts.
 Story 3 occurred in July 2005. An earthquake near the Nicobar island in the Indian Ocean, the same region where the December 2004 tsunami originated, caused fears of an-other tsunami, and a tsunami warning was announced. These entries discuss this event. The content of these entries is ac-tually similar to the content of the entries about the tsunami, but they get separated into different stories because of the influence of time-stamps.

Entries in Story 4, which talk about donations to the tsunami relief efforts, are dated in early January. These entries, however, do not discuss the devastation caused and the details of the tsunami itself, and are hence distinct from Story 2.

Story 5 contains entries dated around August/September 2005 which look at the tsunami relief efforts months after the tsunami. The donations raised and the success of certain relief programs are discussed.

In CT-cluster 2, each of the entries gets assigned to a different story. An examination of their content shows that though they are similar at a coarse level, the distinctness of the entries means that each of the entries corresponds to a different story.
 Table 4: Stories in  X  X sunami X  CT-clusters 1 when timestamps not used Hot Story Detection
From the stories discovered above, we can discover the hot stories. At the time this dataset was collected and stored, September 2005, the hot stories related to the tsunami were 1) comparisons with the Katrina hurricane disaster, and 2) an evaluation of tsunami relief efforts. Table 8: Stories in  X  X ndia China X  CT-cluster 1 Table 9: Stories in  X  X ndia China X  CT-cluster 3 Time-Insensitive Story Mining Table 4 shows some stories discovered using the Time-Insensitive story-mining model. It is notable here that the stories are rather spread out in time. Stories 1 and 4 (from Table 3) can be seen combined into one story (Story 1), which is clearly undesirable.
 Story Clustering Using Only Time
It is worth noting at this point that a clustering based solely on time-stamps and not on content (i.e. by discov-ering story boundaries along the time axis), would also not give satisfactory results. For instance, in this case study, Stories 1 and 5 occur during overlapping time durations. Examination of content is important for differentiating the two. We performed story mining with the query words  X  X ndia China X  in order to discover interesting stories relating to the two countries. We found three CT-clusters, which are representedinTable5bythetop5mostfrequentwordsin each cluster (excluding the query words themselves). We examine closely the Community-Topic clusters retrieved. Table 6 shows some of the blogs in the community corre-sponding to CT-cluster 1. Checking these blogs shows they indeed form a community. The authors of these blogs post entries relating to India, and regularly comment on and link to each other X  X  entries. Similarly, the blogs in CT-cluster 2 (shown in Table 7) form a community of economics bloggers, who write about Indian and Chinese economies. The third CT-cluster contains blogs that are not connected to the first two communities.
 Stories are extracted from these CT-clusters. Table 8 and Table 9 show some interesting stories seen in CT-clusters 1 and 3 (represented by the top 5 most frequent words).
In CT-cluster 1, the we see a story that involves bloggers discussing an article about India and China that appeared in Business Week magazine. A story about the Business Week article was also seen in CT-cluster 3. This demonstrates that different communities can discuss the same stories. A user can browse these stories about the same issue in different communities and get different perspectives.
 Table 10: Stories for  X  X ndia China X  with one-phase mining
Other stories seen in Tables 8 and 9 include a discussion of India X  X  and China X  X  energy needs, and disucssions on the growth in their industrial sector and services outsourcing businesses.
 One-Stage Story Mining In Table 10, we show some stories obtained using the One-Stage story-mining model for the  X  X ndia China X  query. We see here that the story related to the Business Week ar-ticle appears only once, since similar stories from the two communities have been combined into one. The user thus loses the advantage of reading the story from two different perspectives.

Also, by not finding CT-clusters first, we would not have discovered the communities of bloggers that we found with the CCT model. Thus, the advantage of the CCT model is apparent. For the  X  X ony X  case study, the system discovered three CT-clusters. We represent them in Table 11 by the top 5 most frequent words in each cluster. Here CT-cluster 1 con-tains most of the entries retrieved. We will examine this cluster in greater detail below. On examining CT-cluster 2, we find that it contains corresponds to a community inter-ested in High-Definition Television, and entries in this CT-cluster discuss Sony products from that perspective. CT-cluster 3 corresponds to the community around the Infos-yncworld website.
 We now examine a few of the stories in CT-cluster 1. These stories are shown in Table 12 represented by the top 5 most frequent words. Story 1 contains entries discussing the agreement between Sony and Apple Computers to sell songs at the iTunes music store (ITM). These entries are dated around the second week of September 2005 when this was announced. Story 2 contains entries that review the Sony Cyber Shot camera when a new version was released around late July, 2005. Story 3 contains entries that discuss the launch of the Sony Ericsson w800i phone in March 2005. Hot Story Detection
Here again, we can identify a hot story. In September 2005 (when the dataset was collected), Sony had just announced an agreement with Apple, which was the hot story relating to Sony at that time.
The above case studies demonstrate that the CCT model can indeed mine stories and hot stories successfully. The stories found can be seen to correspond to real events, such as the Katrina hurricane or Sony-Apple tie-up. The CT-clusters found can be seen to correspond to actual online communities, like the community of Indian bloggers. We also saw that the same story may be detected in different communities, like we saw with the story about the Business Week article, thus allowing the user to see different per-spectives on the story. Using a one-stage approach to story mining may allow finding stories, but we lose the ability to find the communities where these discussions are occurring, and to differentiate between them. Also, we saw that the use of time-stamps indeed does help to better find stories by differentiating better based on when they occurred.
Blogs have emerged as an important form of Web content, making it important to develop techniques to mine content from the blogosphere. Though similar to other Web con-tent in some ways, blogs have unique characteristics which must be considered and exploited while analyzing informa-tion from the blogosphere.
 In this work, we presented the Content-Community-Time Story Extraction model to extract stories from the blogs. The model incorporates the content of blog entries, their time-stamps, and the community structure to find stories. To study and evaluate our model, we implemented a system and used it for a database of over a million blog entries from the Web. We presented case studies to demonstrate that the proposed model is successful in finding interesting stories from blogs.
