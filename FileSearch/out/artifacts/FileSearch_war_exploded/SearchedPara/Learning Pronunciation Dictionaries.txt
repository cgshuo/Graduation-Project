 The const ruction of speech-to-speech translation systems is difficult, complex, and prohibitively ex -pensive for all but handfu l of major langua ges. De -veloping systems for new languages is a highly skilled job requiring considerable effort, as is the process of training people to acquire the necessary technical knowledge.

Ideally, a native speaker of a (minor) languag e  X  with the right tools  X  should be able to develop a speech system with little or no technical knowl -edge of speech recognition, machine translation, dialog management, or speech synthes is. Rapid de -velopment of machine translation, for example, is the goal of (Lavie et al ., 2003). Similarly , com -bined developmen t of speech recognition and speech synthesis is the stated goal of (Engelbrecht and Schul tz, 2005). 
Here we concentrate on lexicon creation for synthesis and recognition tasks, with the affiliated problem of letter-to-sound rule inference. Two central questions of dictionary building are: what letter-to-sound rule representation lends itself well to incremental learning?  X  and which words should be presented to the user, in what orde r? 
In this paper we investigate various approaches to the word ordering problem, including an active learning algorithm. An  X  X ctive learner X  is a class of machine learning algorithms that choose the or -der in which it is exposed to training example s (Auer, 2000). This is valuabl e when there isn't a pre-existing set of training data and when the cost of acquiring such data is high. When humans are adding dictionary entries the time and accuracy de -pends on the selected word (shor t words are easier than long; familiar are easier than unfamiliar), and on how quickly the learner's error rate drops (long words are more informa tive than short ). Also, mindful that no answe r key exists for new lan -guages  X  and that humans easily become impatient  X  we would like to know when a langua ge's letter to sound rule system is, say, 90% complete. This turns out to be surpr ising elusive to pin dow n.
The next section outlines our working assump -tions and issues we seek to address. Section 3 de -scribes our LTS learning framewo rk, an elabora -tion of (Davel and Barnard, 2003). The learning behavior on multiple test languages is documen ted in Section 4, followed in Section 5 by a compari -son of sever al word selection strategies. In designing language technology developmen t tools we find it helpfu l to envision our target user, whom may be characterized as  X  X on-technical. X  Such a person speaks, reads, and writes the target langu age, is able to enumerate the character set of that language, distinguish punctuation from whitespace, numerals, and regula r letters or graphemes, and specify if the language distin -guishes upper and lower casing. When presented with the pronunciation of a word (as a synthesized wavefile), the user can say wheth er it is right or wrong. In addition, such a person has basic com -puter fluency, can record sound files, and can navi -gate the HTM L interface of our software tools. If these latter requirement s present a barrier then we assume the availability of a field agent to config -ure the comp uter, famil iarize the user, plus trans -late the English instructions, if nece ssary.
Ideally, our target user need not have explicit knowledge of their own langu age's phoneme set, nor even be aware that a word can be transcribed as a sequence of phonemes (differently from let -ters). The ability to reliably discover a workable phon eme set from an unlabeled corpus of speech is not yet at hand, howe ver. Instead we elicit a lan -guage's phoneme set during an initialization stage by presen ting exampl es of IPA wavefiles (Wells and House, 1995). 
Currently, pronunci ations are spelled out using a romanized phonet ic alphabet. Following the rec -ommen dation of (Dave l and Barnard, 2005) a can -didate pronunc iation is accompanied with a wave -file generated from a phoneme-concatenation syn -thesizer. Wher e possible, more than one pronunci -ation is generated for each word presented, under that assumption that it is easier for a listener to se -lect from among a small number of choic es than correct a wron g predi ction. 2.1 Four Que stions to Addre ss 1. What is our measur e of success? Ultimately, 2. For a given langua ge, how many words (let -3. Can the asymptote of the LTS system be esti -4. Which words should be presented to the user, A wide variety of approa ches have been applied to the probl em of letter-to-sound rule induction. Due to simplicity of representation and ease of manipu -lation, our LTS rule learner follows the Default &amp; Refine algorithm of Davel (Davel and Barnard, 2004). In this framewo rk, each letter c is assigned a default production p 1 -p 2 ... denoting the sequence of zero or more phoneme s most often associated with that letter. Any exceptions to a letter's default rule is explained in terms of the surrounding con -text of letters. The default rules have a conte xt width of one (the letter itself), while each addition -al letter increases the width of the context window. For examp le, if we are considering the first occur -rence of 's' in the word basics, the conte xt win -dows are as listed in Table 1. By convention, the underscore character denotes the predicted posi -tion, while the hash represents word termination. Table 1 . Letter contex ts for the first 's' in basics . In this position there are 20 possible expla natory contexts. The order in which they are visited de -fines an algorithm's search strategy. In the class of algorithms knows as  X  X ynamically expand ing con -text (DEC) X , contexts are considered top-down as depicted in Table 1. Within one row, some algo -rithms follow a fixed order (e.g. center, left, right). Another variant tallies the instances of producti ons associated with a candid ate context and chooses the one with the largest count. For example, in Spani sh the letter 'c' may generate K (65% ), or TH when followed by e or i (32%), or CH when fol -lowed by h (3%). These are organized by frequen -cy into a  X  X ule chain. X  If desired, rules 2 and 3 in this example can be condensed into 'c'  X  TH /_{i,e}, but in general are left separated for sake of simplicity.

In our variant, before adding a new rule all pos -sible conte xts of all lengths are considered when selecting the best one. Thus the rule chains do not obey a strict order of expand ing windows, though shorter contexts generally precede longer ones in the rule chains.

One limitation of our representation is that it does not suppo rt gaps in the letter context. Consid -er the word pairs tom/tome, top/tope, tot/tote. A CART tree can represent this pattern with the rule: tice, the inability to skip letters is not a handicap. 3.1 Multiple Pronun ciation Predictions Given a word, finding the predicted pronunci ation is easy. Rule chains are indexed by the letter to be predicted, and possible contexts are scanned start -ing from the most specific until a match is found. Conti nuing our example , the first letter in the Spani sh word ciento fails rule 4, fails rule 3, then matches rule 2 to yield TH. For additional pronun -ciations the search continues until anoth er match is found: here, the default rule 'c'  X  K /_. This proce -dure is akin to predicting from progressively smoothe r models. In a complex language such as English, a ten letter word can readily generate dozens of alternate pronunci ations , necessitating an orde ring policy to keep the total manageable. English is notorious for having a highly irregular spelling system. Conversely, Spanish is admired for its simpl icity. Mos t others lie somew here in be -tween. To estimate how many words need to be seen in order to acquire 90% coverage of a lan -guage's LTS rules, it helps to have a quantitative measure. In this section we offer a perplexity-based measu re of LTS regula rity and present mea -suremen ts of several langua ges with varying cor -pus size. These measurements establish, surpris -ingly, that a rule system's perpl exity increases without bound as the number of training words in -creases. This holds true whether the language is simple or complex. In response, we resort to a heuristic measure for positioning languages on a scale of relative difficulty. 4.1 A Test Suite of Seven Lang uages Our test suite consists of pronunciation dictionar -ies from seven langua ges, with English considered under two manifestations.

English . Version 0.6d of CMU-DICT , consi d -ered without stress (39 phones) and with two level stress marking (58 phones ). German . The Celex dictionary of 321k entries (Burnage, 1990). Dutch . The Fonilex dictionary of 218k entries (Mertens and Vercammen, 1998). Fonilex defines an ab -stract phono logical level from which specific di -alects are specified. We tested on the  X  X tandard X  dialect. Afrikaans . A 37k dictionary develop ed lo -cally. Afrikaans is a language of South Africa and is a recent derivative of Dutch. Italian . A 410k dictionary distributed as part of a free Festival-based Italian synthesizer (Cosi, 2000). Spanish . Generated by applying a set of hand written rules to a 52k lexicon. The LTS rules are a part of the standard Festival Spani sh distribution. Telugu . An 8k locally developed dictionary. In its native or -thography, this language of India possess a highly regular syllabic writing system. We've adopted a version of the Itrans-3 transliteration scheme (Kishore 2003) in which sequences of two to four English letters map onto Telugu phonemes. 4.2 Perplexity as a Measu re of Difficulty A useful way of considering letter to sound pro -duction is as a Marko v process in which the gener -ator passes through a sequence of states (letters), each probabilistically emitting observa tion sym -bols (phonemes ) before transitioning to the next state (following letter). For a letter c , the unpre -dictability of phoneme emission is its entropy the average number of output symbols generated by a letter. The product ion perplexity of the char -acter set is the sum of each individual letter's per -plexity weighted by its unigram probability p c . Conti nuing with our Spanis h exampl e, the letter 'c' emits the observation symbols (K, TH, CH) with a probability distribution of (.651, .321, .028), for a perplexity of 2.105. This computa tion applies when each letter is assigned a single probabilistic state. The process of LTS rule discover y effective -ly splits the state 'c' into four context-defined sub -states: (-,c,-), (-,c,i), (-,c,e), (-,c,h). Each of these states emits only a single symbol. Rule addition is therefore an entropy reduction process; when the rule set is comple te the letter-to-sound system has a perpl exity of 1, i.e. it is perfe ctly pr edictable.
The  X  X rice paid X  for perfect predictability is a complex set of rule chains. To measure rule com -plexity we again associate a single state with each letter. But, instead of phonemes, the rules are the emission symbols. Thus the letter 'c' emits the symbols (K/_, TH/_i, TH/_e, CH/_h) with a distri -butio n of (.651, .236, .085, .028), for a perplexity of 2.534 . Applying equat ion (1) to the full set of rules defines the LTS system 's average perplexity. 4.3 Emp irical Mea surements In the Default &amp; Refine representation, the rule chain for each letter is is initialized with its most probably production. Additional context-depen -dent rules are append ed to cover additional letter productions, with the rule offering the great est in -cremental coverage being added first. (Ties are broken in an implemen tation-dependent way.)
Figure 1 uses Spanis h to illustrate a characteris -tic pattern: the increase in coverage as rules are added one at a time. Since the figure of merit is letter-based, the upper curve (% letters correct) in -creases monotoni cally, while the middle curve (% words correct) can plateau or decrease briefly. 
In the lower curve of Figure 1 the growth proce -dure is constrained such that all width 1 rules are added before width 2 rules, which in turn must be exhausted before width 3 rules are considered. This constraint leads to its distinctive scalloped shape. The upper limit of the W=1 region shows the performance of the unaid ed default rules (68% words correct).
 Figure 1 . Coverage of Spanish (52k corpus ) as a function of rule size. For the lower curve, W indi -cates the rule context windo w width. The middle (blue) curve tracks near-opti mal performance im -provement with the introduction of new rules. For more complex langua ges the majority of rules have a context width in the range of 3 to 6. This is seen in Figure 2 for English, Dutch, Afrikaans , and Italian. Howe ver, a larger rule set does not mean that the average conte xt width is greater. In Table 2, below, compar e Italian to Dutch.
 Table 2 . Numb er of LTS rules for five language and their average context width.
 Figure 2 . Distribution of LTS rules by context window width for four languages : English, Dutch , Afrikaans, and Italian.
 Beyond a window width of 7, rule growth tapers off considerably. In this region most new rules serve to identify particular words of irregular spelling, as it is uncom mon for long rules to gener -alize beyond a single instance. Thus when training a smoothed LTS rule system it is fair to ignore contexts larger than 7, as is done for example in the Festival synthesis system (Black, 1998).
Figure 2 contrasts four langua ges with training data of around 40k words, but says nothing of how rule sets grow as the corpu s size increases. Figure 3 summarizes measu rements taken on eight encod -ings of seven languages (English twice, with and without stress marking), tested from a range of 100 words to over 100,000. Words were subsampled from each alphabetized lexicon at equal spacings. The results are interesting, and for us, unexpe cted. Figure 3 . Rule system growth as the corpus size is increased, for seven languages. From top to bot -tom: English (twice), Dutch, German, Afrikaans, Italian, Telugu, Spanish. The Telugu lexicon uses an Itrans-3 encodi ng into roman characters, not the native script, which is a nearly perfect syllabic transcription. The context window has a maximum width of 9 in these experiments.
 Within this experimental range none of the lan -guages reach an asymptotic limit, though some hint at slowed growth near the upper end. A straight line on a log-log graph is characteristic of geometric growth, to which a power law function cult languages the growth rates (power exponent b ) vary between 0.5 and 0.9, as summarized in Ta -ble 3. The language with the fastest growth is En -glish, followed, not by Dutch, but Italian. Italian is nonet heless the simple r of these two, as indicated by the smaller multiplicative factor a .
 Table 3 . Parameters a and b for the power law fit y=ax b +c to the growth of LTS system si ze. It would be good if a tight ceiling could be estimat -ed from partial data in orde r to know (and report to the lexicon builder) that with n rules defined the system is m percent comple te. However, this trend of geometr ic growth suggests that asking  X  X ow many letter-to-sound rules does a given language have? X  is an ill-posed ques tion. In light of this, two questions are worth asking. First, is the geometric trend particular to our rule representation? And second, is  X  X otal number of rules X  the right measur e of LTS complexity? To answer the first question we repeated the experi -ments with the CART tree builde r available from the Festival speech synthes is toolkit. As it turns out  X  see Table 4  X  a compari son of contextual rules and node counts for Italian demo nstrate that a CART tree representation also exhibi ts geometric growth with respect to lexicon size.
 Table 4 . A comparison of rule system growth for Italian as the corpus size is increased. CART tree nodes (i.e. questions) are the element comparable to LTS rules used in letter conte xt chains. The fit -ted parameters to the CART data are a =2.29 and b =0.765. This compar es to a =2.16 and b =0.69. If geometr ic growth and lack of an obvious asymp -tote is not particular to expanding context rule chains, then what of the measure? The measure proposed in Section 4.2 is average chain perplexi -ty. The hypothesis is that a system close to satura -tion will still add new rules, but that the average perplexity levels off. Instead, the data shows little sign of saturation (Figure 4). In contrast, the aver -age perplexity of the letter-to-phoneme distribu -tions remai ns level with corpu s size (Figure 5). Figure 4 . Growth of average rule perplexity as a function of lexicon size. Except for Spanis h and Telugu, the average rule system perplexity not only grows, but grows at an accelerating rate. Figure 5 . Growth of average letter-to-phoneme production perplexity as a function of lexicon size. Consi dering these observations we've resorted to the following heuristic to measure language com -plexity: a) fix the window width to 5, b) measure the average rule perpl exity at lexicon sizes of 10k, 20k, and 40k, then c) take the average of these three values. Fixing the window width to 5 is somewha t arbitrary, but is intended to prevent the system from learning an unbounded suite of excep -tions. Available values are contained in Table 5. Table 5 . Perplexity measures for six languages. The third (rightmost) column is the ratio of the second divided by the first. A purely phonetic sys -tem has a heuristic perplexity of one.
 From these meas uremen ts we conclude, for exam -ple, that Dutch and German are equall y difficult , that English is 3 times more complex than either of these, and that English is 40 times more complex than Spanish. A selection strategy is a method for choos ing an ordered list of words from a lexicon. It may be based on an estimate of expected maximum return, or be as simple as random selection. A good strate -gy should enable rapid learning, avoid repetition, be robust , and not overtax the human ver ifier. 
This section compares competing selection strategies on a single lexicon. We've chosen a 10k Italian lexicon as a problem of intermediate diffi -culty, and focus on early stage learning. To pro -vide a useful frame of reference, Figure 6 shows the results of running 5000 experiments in which the word sequence has been chosen randomly. The x-axis is number of letters examined.
 Figure 6 . Random sampling of Italian 10k corpu s. Figure 7 compares average random performance to four deterministic strategies. They are: alphabeti -cal word ordering, revers e alphabetical, alphabeti -cal sorted by word length (group s of single charac -ter words first, followed by two character words, etc.), and a greedy ngram search. Of the first three, rever se alphabetical performs best because it intro -duces a greater variety of ngrams more quickly than the others. Yet, all of these three are substan -tially worse than random. Notice that grouping words from short to long degrades performan ce. This implies that strategies tuned to the needs of humans will incur a machine learning penalty. Figure 7 . Compar ison of three simple word order -ings to the average random curve , as well as greedy ngram search. It might be expected that selecting words contain -ing the most popular ngrams first would out-per -forms random, but as is seen in Figure 7, greedy selection closely tracks the random curve. This leads us to investigate active leaning algorithms, which we treat as variants of ngram selection. 5.1 Algorithm Description 5.2 Active Learner Performance Figure 8 displays the performance of our active learner on the Italian 10k corpus, show n as the blue curve. For the first 500 characters encoun -tered, the active learner's performance is almost everywhere better than average random, typically one half to one standard deviation above this refer -ence level.

Two other references are shown. Immediately above the active learner curve is  X  X racle X  word se -lection. The Oracle has access to the final LTS sys -tem and selects words that maximal ly increases coverage of the known rules. The topmost curve is for a  X  X erfect Oracle. X  This represents an even more unrealistic situation in which each letter of each word carries with it information about the correspond ing production rule. For example, that 'g' yields /F/ 10% of the time, when followed by the letter 'h' (as in  X  X augh X ) . Carrying compl ete in -formation with each letter allows the LTS system to be constructed directly and without mistake. In contrast, the non-perfect oracle makes mistakes sequencing rules in each letter's rule chain. This decreases perfo rman ce.
 Figure 8 . From top to bottom: a perfect Oracle, a word selection Oracle, our active learner, and av -erage random performan ce. The perfect Oracle de -marcates (impossibly high) optimal performance, while Oracle word selection suggests near-opti -mality. For comparison, standard deviation error bars are added to the random curve.
 Encour agingly , the active learning algorithm strad -dles the range in between average random (the baseline) and Oracle word selection (near-optima l -ity). Less favorable is the non-monotoni city of the perform ance curve; for example, when the number of letters examined is 135, and 210. Analysis shows that these drops occur when a new letter-to-sound produc tion is encountered but more than one context offers an equally likely expla nation. Faced with a tie, the LTS learner sometimes chooses incor rectly. Not being aware of this mis -take it does not seek out correcting words. Flat plateaus occur when additional words (containing the next most popular ngrams) do not conta in pre -viously unseen letter-to-sound productions. While this work does not definitively answ er the question of  X  X ow may words to learn the rules, X  we have developed ways of characterizing lan -guage complexity, which can guide developers. We've devised a word selection strategy that ap -pears to perform better than the (surprisingly high) standard set by randomly selection. Furth er im -provements are possible by incorpo rating knowl -edge of word alignment and rule sequencing er -rors. By design, our strategy is biased towards short words over long, thereby being  X  X ice X  to lex -icon develope rs  X  our original objective. 
