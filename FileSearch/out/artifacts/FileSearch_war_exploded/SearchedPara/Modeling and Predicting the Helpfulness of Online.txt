
Online reviews provide a valuable resource for potential customers to make purchase decisions. However, the sheer volume of available reviews as well as the large variations in the review quality present a big impediment to the effec-tive use of the reviews, as the most helpful reviews may be buried in the large amount of low quality reviews. The goal of this paper is to develop models and algorithms for pre-dicting the helpfulness of reviews, which provides the basis for discovering the most helpful reviews for given products. We first show that the helpfulness of a review depends on three important factors: the reviewer X  X  expertise, the writ-ing style of the review, and the timeliness of the review. Based on the analysis of those factors, we present a nonlin-ear regression model for helpfulness prediction. Our empir-ical study on the IMDB movie reviews dataset demonstrates that the proposed approach is highly effective.
The increasing impact of the I nternet has dramatically changed the way that people shop for goods. More and more people are now gravitating to reading products re-views prior to making purchasing decisions. Such reviews have become an indispensable component of e-commerce Websites such as Amazon (http://www.amzon.com), and they are also available through dedicated Web-sites such as CNET (http://www.cnet.com) and IMDB (http://www.imdb.com). While reading reviews can help the potential customers make informed decisions, in many cases the large quantity of reviews available for a product can be overwhelming and actually impede the customers X  ability to evaluate the product. This is further aggravated by the fact that the quality of the online reviews tends to be very uneven, ranging from excellent detailed opinions to simple repetition of product specifications to (in the worst case) pure spams. As a consequence, potential consumers have to sift through a large number of reviews in order to form an unbiased judgment regarding the product.

To alleviate this problem, many Websites are now al-lowing readers of a review to indicate whether they think that review is helpful by voting for or against it, and a tally (or score) is provided in the form of  X  100 out of 150 peo-ple found the following review helpful  X . The reviews can be sorted according to their helpfulness using those scores. Although this is certainly an improvement in the right di-rection, there are still important issues to be addressed. For example,  X  For newly posted reviews, most likely no vote or only  X  Presenting the reviews ranked by their user-voted help- X  In some cases, reviews can be incorrectly labeled as In these scenarios, it will be highly desirable to have a way to predict the helpfulness of the given reviews. The pre-dicted helpfulness scores can then be used to address the above problems either directly or indirectly, by combining with existing user votes (if there is any).

This paper is concerned with the problem of automat-ically evaluating the helpfulness of reviews and conse-quently identifying the most helpful reviews for a particular product. Previous research on review mining has focused on answering questions like  X  What do people think of the product?  X  [3, 16, 18],  X  How would users X  evaluation affect the sales of a certain product?  X  [1, 5, 11], and  X  How to un-derstand and summarize the reviews with minimum human efforts?  X  [7, 20], but few explicitly consider the problem of evaluating the quality of reviews, which is significantly different from the well-studied problem of sentiment classi-fication and opinion extraction.

In this paper, we take a principled approach to tackling this important problem by developing a novel model for predicting helpfulness of reviews. The model is based on a thorough analysis of some major factors that may affect the helpfulness of a review, including the areas of exper-tise of the reviewer, the writing styles, the timeliness of the reviews, the length of the reviews, etc. We provide a de-tailed analysis of those factors and explain their effects on the helpfulness of reviews. We then develop a non-linear regression model that takes all important factors into con-sideration, serving as a basis for helpfulness prediction. Ex-tensive experiments were conducted on the IMDB dataset, demonstrating the effectiveness of the proposed approach.
To make our discussions and results more concrete, in this paper we use movie reviews in the past two years (2006-2007) collected from the IMDB Website as a case study. However, our approach is general enough to be eas-ily adapted to handling other types of online reviews.
To summarize, we make the following contributions in this paper.  X  We carefully analyze the possible factors that might  X  We develop a mathematical model that is able to cap- X  We conduct extensive experiments on a movie dataset
The rest of the paper is organized as follows. In Sec-tion 2, we define the prediction problem, and provide a detailed analysis of the major factors that affect the help-fulness of reviews. In Section 3, we propose a regression model based on radial basis functions. Experimental results are presented in Section 4. Section 5 provides a review of related work. Section 6 concludes this paper and discusses directions for future work.
In this section, we first formally define the problem of helpfulness prediction, and then analyze the factors that may affect the helpfulness of a review, which will provide the basis for the proposal of the model in the next section.
The goal of this research is to develop a model that can accurately predict the helpfulness of a review. For a given review, its  X  X elpfulness X  H is defined as the expected frac-tion of people who will find the review helpful. That is, H is a number falling in the range [0 , 1] , and greater values of H imply higher helpfulness.

As in any prediction tasks, the prediction model will be obtained based on available training data, which consist of reviews and related product information. Let the set of re-viewers (authors of the reviews) concerned be U ,thesetof movies be M , the set of reviews be D , then each review can be represented as a quadruple R =( u, d, m, t ) ,where u  X  X  denotes the reviewer, d  X  X  represents the review, m  X  X  represents the movie for which the review is writ-ten, and t indicates the number of days elapsed from the movie release to the time the review is published. For each movie in M , assume that the genres it falls in are also avail-able.

The helpfulness of a review in the training data can be approximated by the tally attached to that review, which takes the form of  X  x out of y people found the following review helpful  X . That is, H = x y . As an effective indi-cator of the public opinions, this evaluation metric has also been widely adopted in previous product review helpfulness studies [19]. To maintain the robustness of the prediction model, in this study, we only consider reviews with at least 10 votes, i.e., y  X  10 .
In order to develop an effective model for helpfulness prediction, we must carefully analyze the important fac-tors that may affect a review X  X  helpfulness rating. To this end, we have examined the reviews on several popular Web-sites, including CNET, Amazon, and IMDB, and conducted preliminary experiments to evaluate the various factors in-volved. Our efforts reveal that the following are among the most important factors. 1. Reviewer Expertise : Product reviews often involve 2. Writing Style : Due to the large variation of the re-
Figure 1. An example of review helpfulness vs. time of review. 3. Timeliness : In addition to the available review con-We have also considered other possible factors that may af-fect the helpfulness values, e.g., length of the review, po-larity of the review, the average rating of all reviews on the movie, etc. However, none of them shows clear correlation with the value of helpfulness, and the detailed examination is available elsewhere [12]. Other factors, such as server-side weblogs indicating how many users read but did not respond to the helpfulness ques tion, might also facilitate the prediction. However, they are not considered in our study due to the data availability issue.
Based on the observations from the previous section, we propose a model that accounts for these three important fac-tors. Once trained, this model can be used for predicting the helpfulness of a given review. In the following discussions, we will use the IMDB movie data as a case study, although the model can be easily applied to other types of review data.

Since radial basis functions (RBF) are used in the model-ing of both the expertise factor and the writing style factor (in the next subsection), a brief introduction of RBF is in order. After that, we will analyze how to model each factor mentioned in the previous section, and then present the non-linear regression model with all those factors incorporated, followed by a description of the training algorithm.
Function approximation is an important component to solving prediction problems defined over both continuous and discrete spaces. A powerful function approximator will not only accurately represent a value for a state it has ex-perienced, but also generalize values to nearby states it has not experienced before. The most common type of approx-imator is the linear approximator. It has the benefit of being straightforward and involving lower computational cost, but it is obviously unreliable if the true relation between the in-puts and the output is nonlinear. One then has to rely on non-linear approximators, such as RBF.

Radial basis functions have the advantage of being much simpler than other popular function approximators, such as multilayer perceptron neural networks, but still serving as a universal function approximator. They are generally used when local properties of the functional relationship needs to be captured, as is the case in the modeling of reviewer expertise and writing style. Due to its high flexibility, ra-dial basis functions have been widely used in many areas, including finance and image processing [2].

A radial basis function is a real-valued function whose value depends only on the distance of the input vector x from some center point  X  . In the most general form, the RBF  X  ( x |  X  ,  X  )= f ( x  X   X  ) T  X   X  1 ( x  X   X  ) ,where f is the function used (Gaussian, Cauchy, etc.) and  X  is the met-ric. The term ( x  X   X  ) T  X   X  1 ( x  X   X  ) represents the distance between the input x and the center  X  in the metric defined by  X  . Here, we choose the distance metric to be Euclidean. In this case,  X  =  X  2 I for some scalar radius  X  . Hence,
The function f can take various forms. In this study, we choose the commonly used Gaussian RBF: f ( y )= e  X  y , of the RBF. Intuitively, the further away x is from the center  X  , the smaller the function value is, and the function peaks at the center when x =  X  . In addition, the value of the spread  X  determines the  X  X ightness X  of the RBF, i.e., how fast the function value falls off when the input x gets further away from the center.

Multiple RBFs can be combined to build up function ap-proximations of the form where the approximation function g ( x ) is represented as a weighted sum of k radial basis functions, each with a differ-ent center  X  i , a metric  X  i , and a weight a i . Such function approximation models are sometimes referred to in the lit-erature as radial basis function networks. Figure 2 shows an example of using 3 radial basis functions to approximate a function. In this example, one would like to fit a func-tion to the scattered data points. Although in our model for helpfulness prediction, we will deal with multi-dimensional input, for illustration purpose, this example deals with one-dimensional input. The fitted function represented by the solid line can be obtained by taking the weighted sum of the three individual RBFs. Fitting the data with the function in-volves determining the centers and spreads of the RBFs as well as the weight of each RBF.
As discussed in Section 2, the helpfulness of a review depends in part on the level of expertise of the reviewer on the product (movie) concerned. For example, for a given reviewer, if his past reviews on a certain set of movies (de-noted by A ) are rated very high while his reviews on some other movies (denoted by B ) are very low, then we have reasons to expect that a new review by this reviewer will be considered more helpful if the movie concerned is more similar to the movies in A than to those in B .

In order to quantify the  X  X imilarity X , we first need to choose the right features to represent each movie. To this end, we use the genres provided by IMDB to represent each movie. As an example, the movie Casino Royale is la-beled by IMDB as  X  X ction X ,  X  X dventure X , and  X  X hriller X , which can be used to represent the movie for our purpose.
Figure 2. Using radial basis functions for function approximation. The solid line repre-sents the fitted function, and the three RBFs are plotted with dotted lines.
 Formally, each movie is represented by a m -dimensional vector x =( x 1 ,x 2 ,...,x m ) ,where m is the number of different genres available for all movies. Each dimension corresponds to one genre, and x i (1  X  i  X  m ) takes the value of 1 l , if the movie belongs to the corresponding genre (where l is the number of genres the movie falls into), and 0 otherwise. Note that due to the normalization factor l ,
The next step is to measure the similarity of a given movie to movies that have been reviewed by the same re-viewer, and relate this measure to the helpfulness score. We choose to approximate the relationship using RBFs. If we were to predict the helpfulness of a review based solely on the reviewer expertise factor, then we would fit the follow-ing regression model on the training data. where  X  H 1 is the estimated helpfulness score, x is the feature vector representing the movie, k 1 is the number of centers in the RBF network,  X  i and  X  i are the center and spread of the i -th RBF respectively, and u i is the weight of the i -th RBF.

Since we represent each movie using a feature vector based on its genres, each center can be considered as corre-sponding to one  X  X luster X  of movies that are similar to each other in terms of their genres. The helpfulness of a given movie is thus the weighted sum of the distance between the movie to those centers. In this way, the reviewer X  X  expertise on different clusters of movies can be naturally captured in that similar movies will have similar distances to the centers and therefore have similar helpfulness scores.
A previous study [19] has shown that the linguistic style can be a very good indicator of the utility of the review. In fact, shallow syntactical features like part-of-speech pro-vide more predicting powers than deeper features at the lex-ical level. Thus, we choose to label the part-of-speech of the words contained in the reviews with a fixed set of tags using LingPipe 1 , a suite of Java libraries for the linguistic analysis of natural language.

For each review, we parse it using the LingPipe tag-ger, and count the number of words with each tag. Those counts are further normalized by dividing them with the word count of the review. The resulting numbers form a vector, denoted by y , with each number corresponding to one dimension. This vector y is used as a representation of the review for the purpose of modeling writing styles.
We again use a radial basis function network to model the relationship bet ween the feature vector y and the help-fulness of the review, with each RBF explaining part of the functional relationship, and the weights indicating the con-tribution of each RBF. Formally, if we were to predict the helpfulness solely based on the writing style, the regression model we would like to use is where  X  H 2 is the estimated helpfulness, v i ,  X  i ,and  X  weight, center, and the spread of the i -th RBF respectively, and k 2 is the number of RBFs.

Of course, the writing style is only one of the factors affecting the helpfulness of a review. Therefore, the model in Equation 4 will be combined with other factors in the complete model we propose.
Our analysis in Section 2 has shown that there is a strong correlation between the helpfulness of a review and when it is published. Having observed the trend for a large number of movies, we hypothesize that the helpfulness of a movie review is subject to exponen tial decay with respect to time. Therefore, we propose the following model for movie re-views if the prediction of helpfulness were to be done only based on the timeliness: where  X  H 3 is the estimated helpfulness, t 0 is the release time of the movie, t is the time when the review is published, and  X  and d are parameters in the model to be estimated. Intuitively,  X  controls the rate of decay in the helpfulness as we move further away in time from the movie release.
Now that we have built the regression model for each in-dividual factor, we are ready to propose the complete model that incorporates all of the above factors. The idea is to consider the helpfulness score a weighted sum of the three individual models, as shown below: where p , q ,and r are the weights of the three components. Note that the above equation can be further simplified, as the weights p , q ,and r can be  X  X bsorbed X  by the individ-ual components. For example, p k 1 i =1 u i  X  ( x |  X  i be rewritten as k 1 i =1 u i  X  ( x |  X  i , X  i ) ,where u i r w = r  X  e d . Therefore, the model can be written in a more concise form: where the notations u i and v i are overloaded for the sake of brevity, with them actually referring to u i and v i as defined above.

The model given in Equation 6 makes it possible to cap-ture all of the factors discussed in this section, with the tion X  of each factor to the helpfulness score.
We now develop the algorithm that can be used to es-timate the model parameters based on the training data (movie reviews). Assume that the training data consists of N reviews, and for each review j (1  X  j  X  N ) , x j , y j t can be obtained, as well as the true helpfulness score H j The set of parameters in the model include 1. the weights { u i } k 1 i =1 , { v i } k 2 i =1 ,and w ; 4. the decay rate  X  .
 The values of k 1 and k 2 are supplied by the user.
The goal of training is to estimate the parameters such that the sum of squared error (SSE) between the true values and the model output values is minimized, i.e., we would like to minimize where  X  = H j  X   X  H j . The optimization can be done through the method of steepest descent. By computing the partial derivatives of Equation 7, we can apply the following rules to iteratively update the values of the parameters as follows.
Let {  X  u ,  X  v ,  X  w ... } be the user-defined learning rate for parameters { u i , v i , w ... } in the model. 1. For the weights, we have 2. For the centers, we have 3. For the spreads, let  X  = 1  X  2 ,and  X  = 1  X  2 , and we have 4. Finally, for the decay rate  X  ,wehave
Recall that in modeling the reviewer expertise as de-scribed in Section 3.2, we rely on the genres of the movies the reviewer has commented and the corresponding help-fulness scores. This requires sufficient past reviews of the reviewer in order to achieve meaningful results. In reality, some reviewers may have written only a few or no reviews, or the reviews a reviewer has written may not be present due to data availability issues. We therefore make the distinc-tion between prolific reviewers and non-prolific reviewers and revise the model correspondingly. We call a reviewer a prolific reviewer if the number of reviews authored by him/her in the data set exceeds a certain threshold T ,and non-prolific otherwise. For prolific users, we simply use the model described in Section 3.5, whereas for non-prolific ones, we need to drop the first term regarding reviewer ex-pertise in the model, as we do not have sufficient grounds to make meaningful inference in that regard. In that case, the model becomes
Note that since the above model does not involve any in-formation regarding individual reviewers, a common model can be trained for all of the non-prolific reviewers. The parameter estimation can be done using the update formu-lae presented in Section 3.6. It is worth pointing out that the distinction between prolific and non-prolific reviewers is due to data availability; we do not assume that the re-views written by prolific reviewers are more helpful than those written by non-prolific reviewers.
We conducted extensive experiments on the IMDB data set to evaluate the effectiveness of the proposed prediction model and study the behavior of the model as we change the user-tunable parameters.
The movie review data set was obtained from the pub-licly accessible IMDB Website. Specifically, we collected the reviews for 504 movies released in the United States during the period from January 6, 2006 to November 21, 2007. We intentionally selected the time that is not very close to the present time in the hope that the voting of help-fulness has stabilized, as less and less reviews are expected to appear as time increases across the whole time span. To model reviewer expertise, we also collected the genre la-bels for each movie. In total, 94 , 919 reviews were col-lected, and the number of rev iew entries collected for each movie ranges from 2 , 152 (for Superman Returns [2006]) to 2 (for Absolute Wilson [2006]). Those reviews were posted by 56,588 different reviewers. Note that we only collected reviews posted by reviewers from the US as it helps to en-sure the consistency in the release time (it is common for a movie to be released on different dates in different coun-tries). The total number of genres involved are 27.
Figure 3. The distribution properties of the data
Figure 3(a) and (b) show the distributions of the number of reviews available for movies, and the number of movies per genre respectively. To ensure the robustness of the pre-diction model, we only use the reviews with at least 10 votes. Also, for the purpose of training and testing, only the reviews with a helpfulness score available (i.e., reviews with a label of the form  X  x out of y people found this re-view helpful  X ) are used. The number of such movie reviews is 22,819. The movie information (genres for each movie) and the review data are indexed using Apache Lucene 2 .For each review, its feature vectors are obtained as described in Section 3, and we use 10-fold cross validation to evaluate our approach.
We evaluate the effectiveness of the proposed model us-ing two metrics as we anticipate that the model will be used in different ways. First, the model can be used to predict the helpfulness of reviews directly, so we would like to measure the deviation of the predicted value from the true value. We call this a prediction problem. Second, the model can be also used to help retrieve only those reviews that are consid-ered helpful, i.e., the reviews having a predicted helpfulness higher than a certain threshold. We call this a classification (or retrieval) problem.

Two metrics, which were used in previous literatures [19, 5], are adopted to evaluate the predication accuracy in those two scenarios respectively, namely, the Mean Squared Error (MSE) (for the prediction problem) and the F-measure (for the classification problem). Specifically, for each review in the test set, we make a prediction for its helpfulness and compute the squared deviation between the predicated value and the true helpfulness. MSE is defined as the sum of all the deviations divided by the total number of predictions. That is, where n is the number of reviews in the test set. Note that lower MSE values indicate higher prediction accuracy. To measure the performance using F-measure, we consider a review as helpful if its helpfulness score is greater than a given threshold  X  . In our experiments, we set  X  =0 . 5 .
In the prediction model, there are several user-chosen pa-rameters that provide the flexibility to fine tune the model for optimal performance. They include the threshold T to separate prolific users and non-prolific users, the number of RBFs in the RBF network k 1 and k 2 , and a threshold  X  de-termining whether a review is helpful. We now study how the choice of these parameter va lues affects the prediction accuracy. 4.3.1 Effect of T Recall that in Section 3, we use a threshold T to distinguish a prolific reviewer from a non-prolific reviewer, based on how many reviews in the data are authored by that reviewer. We train different models for the two types of reviewers as discussedinSection3.

With fixed values of k 1 and k 2 ( k 1 =3 ,and k 2 =10 ), we vary T , and observe the changes in accuracy. Similar trends can be observed for other values of k 1 and k 2 .As shown in Table 1, as T increases from 10 to 30 , the pre-diction performance improves in both F-measure (for the classification problem) and MSE (for the prediction prob-lem) , and at T =30 , it achieves the best accuracy with F-measure=0.7116 and MSE=0.0332. This implies that accu-mulating more reviews for a given author allows our model to better capture the effects that influence the helpfulness, which leads to more accurate predictions. In addition, the accuracy for prolific reviewers is much superior to that for non-prolific reviewers across different values of T , indicat-ing the effectiveness of the  X  X eviewer expertise X  factor in the model for prolific reviewers. 4.3.2 Effects of k 1 and k 2 We then vary the values of k 1 and k 2 , with T fixed at 30, to study how the number of RBFs affects the prediction accu-racy on prolific reviewers. We do not consider non-prolific reviewers in this experiment as the features describing re-viewer expertise are not available for non-prolific reviewers, and thus k 1 is not required for the corresponding model. The effect of k 2 is similar on the two types of reviewers, and therefore only the results on the prolific reviewers are presented here.
Table 1. Effect of T . N and P refer to non-prolific and prolific reviewers respectively.

We first vary the value of k 1 , and observe from Figure 4(a) and (b) that there is a large improvement in accuracy when k 1 increases from 1 to 2, and the model achieves its best performance with k 1 =3 . This implies that introduc-ing multiple components to ana lyze the reviewer expertise can greatly improve the prediction accurary. However, af-ter k 1 past a thresold, the accuracy tends to decrease. This might be due to over-fitting the training data with more RBFs. Nonetheless, the accuracy remains stable for a wide range of k 1 values, indicating the insensitivity of the model with respect to the choice of k 1 values. It is also worth not-ing that the trend in accuracy remains the same regardless of the choice of k 2 .
Similarly, we fix the values of T and k 1 ,andvary k 2 from 1 to 12 . As shown in Figure 5 (a) and (b), there is also an optimal choice of k 2 , which is 10. Similar to the case of k , the accuracy remains quite stable over a wide range of k , which again demonstrates that the model is not sensitive to the choice of parameter values. 4.3.3 Effect of  X  In classifying a review as helpful or not helpful, we use a threshold  X  . Figure 6 shows the effect of the value of  X  on the accuracy. Clearly, smaller  X  values tend to lead to better accuracy. This is as expected, because a larger  X  means less reviews can be classified as helpful, and is therefore more restrictive, making accurate cl assifications more difficult.
In our study, three factors that may affect the review helpfulness are considered, and we propose a non-linear re-gression model to incorporate them into one model. Here, we study how the three factors affect the prediction of help-fulness individually. That is, how would the model perform if we choose to use only one of the factors for prediction? In Section 3, we discussed three models (Equations 3, 4, and 5) corresponding to the three factors. For the experi-ments, we train the three individual models as presented in Section 3 with the corresponding feature vectors and mea-sure the accuracy of each one. In particular, we let k 1 and k 2 =10 in this experiment, and the results are shown in Table 2.

Apparently, considering the timeliness factor only yields the best results in both MSE and F-measure among the three factors. This coincides with our intuition that a timely re-view can be very helpful for customers to evaluate the prod-uct of interest. Only considering the writing style gives the worst performance of the three, implying that it has less pre-dictive power compared with reviewer expertise and timeli-ness. Note that the results obtained by considering only one factor are not as good as considering all the factors together.
To demonstrate the effectiveness of our proposed model, we compare it against a baseline model that use linear re-gression (LR). For each review, we obtain the feature vec-tors ( x , y ,t ) corresponding to each factor in the same way as described in Section 3 and concatenate them together to form one vector r . Then the linear regression model can be written as  X  H l =  X  T r + b ,where  X  is the coefficient vector and b is the intercept. This model can be fit to the training data using standard linear least squares method. We con-ducted a series of experiments with different T values and compare the performance of the LR model with our pro-posed method. As shown in Figure 7, it is clear that our proposed method is much more accurate than the LR model for both prolific and non-prolific reviewers.
With the rapid growth of online reviews, automatic re-view mining has attracted a lot of research attention. Early work in this area was primarily focused on determining the
Figure 7. Comparison with linear regression model semantic orientation of reviews. Among them, some of the studies attempt to learn a positive/negative classifier at the document level [16, 15], while others work at a finer level and use words as the classification subject [18].

Pushing further from the explicit two-class classification problem, Liu et al. [7] build a framework to compare con-sumer opinions of competing products using multiple fea-ture dimensions. Liu et al. [11] assume that sentiment consists of multiple hidden aspects, and use a probability model to quantitatively measure the relationship between sentiment aspects and reviews.

Our method departs from classic review mining ap-proaches in that, ultimately, we want to examine the im-portance of these opinions, which is a new and important research problem. In some sense , determining the sentiment and helpfulness of reviews a re orthogonal to each other and could be modeled independently. One recent work that is closely related to our study attempts to examine the eco-nomic impact of the online reviews [5]. That approach mainly focuses on quantifying the extent of which the tex-tual content, especially the subjectivity of each review, af-fects product sales on a market such as Amazon, while our method aims to build a more fundamental model for review helpfulness prediction. Another relevant study in this field analyzes spams that exist in online reviews [8]. In partic-ular, their work presents a categorization of review spams, and proposes some novel strategies to detect different types of spams. Our work can be considered complimentary to that work in that the spam filtering model can be used as a preprocessing step in our approach.
Identifying the quality of Web documents has received a lot of attention, particular ly because of its application to search engines. PageRank and HITS are two popular link-based ranking algorithms to determine the importance of web pages [10, 14]. The HITS algorithm is based on the observation that a good hub usually points to good au-thorities and a good authority usually points to good hubs. The Pagerank algorithm doesn X  X  distinguish hub and author-ity pages. Instead, it estimates the importance of the web page X  X  neighbours, and the authority of the page is con-sidered proportional to this value. Motivated by this idea, various algorithms have been proposed to discover the au-thorities or leaders in the Web domain [9, 17, 13].
Note that our approach is different from above methods in that we use semantic inform ation of web document rather than link structures for evaluating the helpfulness of online reviews.
In this paper, we have considered the important prob-lem of predicting the helpfulness of reviews. We provided a detailed analysis of the major factors affecting the help-fulness of a review, and proposed a nonlinear model based on radial basis functions for helpfulness prediction. Exten-sive experiments on the IMDB data set have confirmed the effectiveness of the proposed model.

Our study in this paper has focused on the movie re-views, but our approach is general enough to be easily adapted to other domains as well. For example, if we would like to handle product reviews on Amazon or CNET, we can simply replace the genres of movies with the categories of products, and the writing style and timeliness can still be modeled in the similar way as described in Section 3.
This study presents the first step in modeling the help-fulness of reviews. For future work, we plan to study the related ranking problem, i.e., how do we rank the reviews based on the helpfulness? One way to do this is to rank the reviews based on their predicted helpfulness, but we can also develop a model to directly predict the set of most help-ful reviews. Another possible direction for future work is to incorporate existing votes as an indicator of the future help-fulness, and build an adaptive model which can automat-ically update the predication value of helpfulness as new reviews come in. Besides, we also plan to incorporate col-laborative filtering methods, such as [6], to help build a per-sonalized helpfulness prediction model.

