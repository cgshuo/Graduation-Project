 1. Introduction
Information retrieval systems (IRSs) that are wildly used in many applications, such as search engines, are overwhelmed by the explosion of data. To efficiently search vast amounts of data, an inverted file is query consists of keyword terms. To retrieve information, the query evaluation engine reads and decom-ence) corresponding posting lists to obtain a candidate set of relevant documents.
Moffat, 1995 ). This is because the total time of transferring a compressed posting list and subsequently can be achieved. In addition, we observe that the d -gap compression approach can result in good compres-sion if the document identifiers in the posting lists are clustered.

The query processing time in a large-scale IRS is dominated by the time needed to read and decompress processingtime growswith thetotal encodedsize ofthecorrespondingposting lists. This isbecause thedisk pression approach are on a bit-by-bit basis. If we can reduce the total encoded size of the corresponding posting lists without increasing decompression times, a shorter query processing time can be obtained.
A document identifier assignment (DIA) can make the document identifiers in the posting lists evenly dis-the d -gap compression approach without increasing the complexity of decoding process, hence reduce the query processing time. In this paper, we consider the problem of finding an optimal DIA to minimize
DIAproblem,thatisknowntobeNP-complete viaareductiontotherectilinear traveling salesman problem (TSP), is a generalization of the problems solved by Olken and Rotem (1986) , Shieh, Chen, Shann, and mization problem can be effectively solved by the well-known TSP heuristic algorithms. The greedy nearest neighbor (Greedy-NN) algorithm performs the best on average, but its high complexity discourages its use in modern large-scale IRSs.

In this paper, we propose a fast heuristic, called partition-based document identifier assignment (PBDIA) algorithm, to find a good DIA that can make the document identifiers in the posting lists for frequently used query terms more clustered. This can greatly improve the compression efficiency of the posting lists ical case in a real-world IRS, the experimental results show that the PBDIA algorithm can yield a compet-itive performance versus the Greedy-NN for the DIA problem. The experimental results also show that the DIA problem has significant advantages for both long queries and parallel information retrieval (IR).
The remainder of this paper is organized as follows. Section 2 describes the inverted index and explains why a DIA can affect the storage space required and change query performance. Section 3 derives a cost model for the DIA problem, and presents how to use the well-known TSP heuristic algorithms to solve this optimization problem. In Section 4, we propose a fast PBDIA algorithm. We show the experimental results in Section 5. Finally, Section 6 presents our conclusion. 2. General framework form where id i is the identifier of the document that contains t , and frequency f decompression of posting lists is hence required during query processing.

Zipf(1949) observedthatthesetoffrequentlyusedtermsissmall.AccordingtoZipf  X  slaw,95%ofwords eachqueryterm.ThispaperrestrictsattentiontoinvertedfilesideonlyandinvestigatestheDIAproblemto improve the efficiency of an inverted file and the overall IR performance.

The d -gap compression approach ( Moffat &amp; Zobel, 1992; Witten et al., 1999 ), the most popular ap-codingmethod.Manycodingmethods,suchas c coding( Elias,1975 ),Golombcoding( Golomb,1966;Wit-tions. The more accurately the estimate, the greater the compression can be achieved.
One common characteristic of coding methods used in the d -gap compression approach is that small d -gap values can be coded more economically than large ones. If we can shrink the d -gap values, the com-pression ratio and query performance can be improved. Consider a document collection of six documents shown in Fig. 2 (a). Each document contains one or more terms. For example, the document d terms 1 and 2, document d 2 contains term 2, etc. In Fig. 2 (b) and (c), the notation d
II denotes that the document identifier j is assigned to the document d compression for the given coding method without increasing the complexity of decoding process, hence improve query throughput by reducing both the retrieval and decompression times of posting lists. This lem, and then derive a method to find a good DIA to shorten average query processing time when the probability distribution of query terms is given. 3. Document identifier assignment problem and its algorithm
The DIA problem is the problem of assigning document identifiers to a set of documents in an inverted query terms is given. In this section, we first formalize the problem, and then show how to use the well-known greedy nearest neighbor (Greedy-NN) algorithm to solve this problem. 3.1. Problem mathematical formulation
Let D ={ d 1 , d 2 , ... , d N } be a collection of N documents to be indexed, and p :{ d
Let f t be the total number of documents in which term t appears and d taining term t , then the posting list of the term t can be represented as IL
Without loss of generality, we assume that p  X  d t  X  1  X   X  &lt; p  X  d
C which requires C ( x ) bits to encode a d -gap x . The size of a posting list IL expressed as in a query: X t = 1 if term t appears in a query and X t = 0 otherwise. The query processing time Time posting list processing includes (1) retrieval time Time R
Time Comp .Sincethedocumentidentifiercomparisontimeisrelativelysmall(about10%ofqueryprocessing time) and does not change with different DIAs, the query processing time in this paper is defined only as The average query processing time AvgTime QP is the expected value of Time
IL for the term t appearing in a query grows with the size of the posting list IL Substituting Eq. (4) into Eq. (3) , we obtain We thus define the objective function Cost( p ) to reflect the average query processing time AvgTime
TheobjectiveofthisresearchistofindaDIA p : D ! {1,2,3, ... , N }suchthatCost( p )isminimal.Thisopti-mization problem is called the DIA problem, and it is reduced to the simple DIA (SDIA) problem if the value of p t for each term t is set to 1. The SDIA problem is the problem of finding a DIA to minimize
DIA problem is also a NP-complete problem. 3.2. Solving DIA problem via the well-known Greedy-NN algorithm
The research works of Shieh et al. (2003) and Gelbukh et al. (2003) indicated that finding the near-opti-malsolution forthe SDIA problem can berecast as the traveling salesman problem(TSP),andalso showed that heuristic algorithms for the TSP can be applied to the SDIA problem to find a near-optimal DIA.
Compared with those well-known TSP heuristic algorithms, such as insertion heuristic algorithm and span-ningtreebased algorithm, Shieh etal.(2003) showedthattheGreedy-NN algorithm performsbetterforthe
SDIAproblemonaverage.InSection3.2.1,weshowhowtosolvetheSDIA problem usingtheGreedy-NN algorithm.Then, inSection3.2.2,weshowhowtotransform theDIA problemintotheSDIA problem, and explain why the Greedy-NN algorithm can provide better performance than the other TSP heuristic algo-rithms for the DIA problem. 3.2.1. Solving SDIA problem via Greedy-NN algorithm Shieh et al. (2003) showed that the SDIA problem can be solved by using TSP heuristic algorithms.
Given a collection of N documents, a document similarity graph (DSG) can be constructed. In a DSG, each vertex represents a document, and the weight on an edge between two vertices represents the similarity of thesetwocorresponding documents. Thesimilarity Sim( d i , d where T ( d i ) and T ( d j ) denote the set of terms appearing in d section operator. Hence, the similarity between two documents is the number of common terms appearing in both documents. The DSG for the example documents in Fig. 2 (a) is shown in Fig. 3 . A TSP heuristic algorithm can then be used to find apath of the DSG visitingeach vertexexactly oncewith maximalsum of compression approach can be reduced. Shieh et al. (2003) showed that the Greedy-NN algorithm ( Fig. 4 ) can provide excellent performance for the SDIA problem.

We now show how to obtain a DIA for the DSG described in Fig. 3 using the Greedy-NN algorithm, where V ={ d 1 , d 2 , d 3 , d 4 , d 5 , d 6 }. In Step 1, we pick d its adjacent edges is maximal (=10). In Step 2, we have V since d 6 is the vertex v in V 0 such that the edge ( v , v
V 0 ={ d 1 , d 2 , d 3 , d 5 }. Repeat Steps 3 and 4 as needed, we can then sequentially pick d and d 5 as v 6 . Hence, we have a TSP path: { d 4 , d 6 , d d ! 4, d 4 ! 1, d 5 ! 6, d 6 ! 2}. 3.2.2. Transforming DIA problem into SDIA problem
We use a matrix A to represent the input document collection, in which a row corresponds to a term and a column corresponds to a document. The entry A i , j is a 1 if term i appears in document d
The SDIA problem is to determine whether there exists a permutation of the columns of A that results in a matrix B such that where C is a coding method which requires C ( x ) bits to encode a d -gap x , n is the number of terms, f mine whether there exists a permutation of the columns of A that results in a matrix B such that where p i is the probability of a term i appearing in a query and k whether there exists a permutation of columns of A such that the mean encoded size needed to read and decompress a posting list during query processing is less than k To show how to transform the DIA problem into the SDIA problem, we use the document collection in struct a new matrix A 0 for the SDIA problem by duplicating each row of matrix A in a certain number
A , the row of matrix A corresponding to term i is duplicated m rows( A 0 ) denotes the number of rows of matrix A 0 . The rows( A m i = rows( A 0 )  X  p i is an integer for every i . In this example, we let rows( A the optimal solution of matrix A 0 for the SDIA problem is also the optimal solution of matrix A for the
DIA problem when the probabilities p 1 = 0.2, p 2 = 0.3, p
Using the same approach, it is obvious that one can transform any instance A of the DIA problem into an instance A 0 of the SDIA problem such that the optimal solution of matrix A also the optimal solution of matrix A for the DIA problem when the probabilities p Greedy-NN algorithm performs the best for the SDIA problem on average, one can show that the Greedy-
NN algorithm can provide better performance than the other TSP heuristic algorithms for the DIA prob-lem. Therefore, the DIA problem can be solved using the Greedy-NN algorithm described in Fig. 4 , if the similarity Sim( d i , d j ) between two documents d i and d where the probability of a term t appearing in a query is known to be p Although the Greedy-NN algorithm is very simple to implement, it is not very applicable to large-scale
IRSs due to its high complexity. Given a collection of N documents and n distinct terms, the number of to construct a DSG for the Greedy-NN algorithm is O( N 2  X  n ). An algorithm with lower complexity yet still generates satisfactory results should be developed. 4. Partition-based document identifier assignment algorithm
Since the DIA problem is an NP-complete problem, the effort in search for an effective low-complexity method is needed. Although the Greedy-NN algorithm can be used to solve the DIA problem, its complex-propose an efficient partition-based document identifier assignment (PBDIA) algorithm for the DIA problem. 4.1. Generating an optimal DIA for a single query term the d -gap technique, we can obtain f t d -gap values: d -gap which requires C ( x ) bits to encode a d -gap x . We want to know which d -gap probability distribution d -gap probability distribution can minimize subject to and where k is the largest document identifier in the posting list IL ched LLRUN coding. For these coding methods, we can use dynamic programming technique ( Bellman &amp;
Dreyfus, 1962 ) and find that minimizing Eq. (11) should meet two requirements: (1) maximize the number of d -gap values of 1; and (2) minimize the largest document identifier, i.e., k , in the posting list IL posting list IL t can be achieved.

According to the above observation, we propose the simple partition-based document identifier assign-ment (SPBDIA) algorithm to generate optimal DIAs for a given query term t . The SPBDIA algorithm con-sists of a partitioning procedure, an ordering procedure, and a document identifier assignment procedure.
The partitioning procedure divides the given documents into two partitions in terms of query term t : one partition P ( t ) consists of documents containing query term t ; the other partition P ( t
Finally, the document identifier assignment procedure generates an appropriate DIA for the ordered par-ment identifiers, while the documents in partition P ( t 0 The SPBDIA algorithm is illustrated in the following example.

Example. There is a collection of 500 documents, among which 300 documents contain query term t . After 301 X 500 to the 200 documents in partition P ( t 0 ).

Documents in a partition can be arbitrarily assigned identifiers within the given range, hence the number of possible DIAs for the above Example is 300!  X  200!. Each of the 300!  X  200! DIAs satisfies the two requirements for minimizing Eq. (11) , and hence gives both the best posting list compression and fastest query speed for query term t . The SPBDIA algorithm is simple, and its complexity is O( N ). 4.2. Efficient partition-based document identifier assignment algorithm for DIA problem
In a real-world IRS, a few frequently used query terms constitute a large portion of all term occurrences lows thosefrequentlyused queryterms tohavebetterpostinglistcompression can resultin reduced average query processing time. Based on the SPBDIA algorithm, an efficient partition-based document identifier assignment (PBDIA) algorithm for the DIA problem can be developed.

Like the SPBDIA algorithm, the PBDIA algorithm also partitions the document set, orders these par-titions, and then assigns document identifiers. The flowchart of the PBDIA algorithm is shown in Fig. 6 .
The partitioning and ordering procedures of the PBDIA algorithm iterate n times given that there are n query terms. Then, the document identifier assignment procedure is performed as the last step of the
PBDIA algorithm. Terms that are queried more frequently should take higher priority in document parti-tioning and partition ordering. Let the most frequently queried term be assigned rank 1, the second most frequently queried term rank 2, and so on. We use t rank i titioning and ordering procedures of the PBDIA algorithm should proceed by considering t t
Both the PBDIA partitioning and ordering procedures are invoked once per iteration. The PBDIA par-the SPBDIA partitioning procedure. The PBDIA ordering procedure then assigns each newly generated partition a partition order. Each partition P in the PBDIA algorithm hence can be uniquely identified by an iteration number i and a partition order j , and we use the notation P partition of the i th iteration. For example, the notation P in an input document collection. In the following, we describe in detail the partitioning, ordering, and document identifier assignment procedures of the PBDIA algorithm. 4.2.1. PBDIA partition procedure tioning procedure invoked in the i th iteration divides each partition P f P
P term t rank i . Since P i 1, j is nonempty, at least one of the two partitions P empty for j =1,2, ... , k .
 4.2.2. PBDIA ordering procedure partition pairs generated by PBDIA partitioning procedure in iteration i . Let j P nonempty partitions of the above partitions. The PBDIA ordering procedure invoked in the i th iteration
Now let us consider the ordering of partition pair f P i 1 ; k
Next we consider the ordering of partition pairs f P i 1 ; j the next largest partition order to be assigned be s . Since PBDIA ordering procedure orders f P
P 4.2.3. PBDIA document identifier assignment procedure Thedocumentidentifier assignment procedure,the last stepof PBDIAalgorithm, isstraightforward. Let
P
To obtain a good DIA, the partitions must be properly ordered. We explain why the PBDIA ordering procedure is proper: Note that the PBDIA ordering procedure always assigns consecutive partition orders to two nonempty partitions of a partition pair. This makes documents in the same partition in iteration i remain in the same or neighboring partitions in iteration i + 1. According to the PBDIA document consecutiveor atleastadjacent document identifiers. Thatis, once theorderof partitionsisgeneratedatthe end of iteration i , the compression performance for the posting list of t ing list of t rank1 has the best compression, then that of t rithm considers the t rank1 first, then t rank2 , and so on, in its iterations.
O( N ). Since the PBDIA algorithm iterates for n times, the total number of comparisons for the PBDIA algorithm is O( N  X  n ). Compared with the Greedy-NN algorithm, this complexity of PBDIA algorithm is distinctively low. This advantage brings the PBDIA algorithm a dark side, of course. Although the
PBDIA algorithm targets on improving the compression efficiency for the frequently used query terms, of the assorted query terms are very unbalanced. And this imbalance nature makes the PBDIA algorithm achieve very good query performance. In Section 5, we compare the search performance of the Greedy-NN and PBDIA algorithms for real-life document collections. 5. Experiments
This section describes our experiments for evaluating the different DIA algorithms. Experiments were conducted on real-life document collections, and the average query processing time and the stor-age requirement for each DIA algorithm were measured. We also investigated the DIA problem in parallel IR. 5.1. Document collections and queries
Three document collections were used in the experiments. Their statistics are listed in Table 2 . In this collections FBIS (Foreign Broadcast Information Service) and LAT (LA Times) are disk 5 of the man, 1997 ). The collection TREC includes the FBIS and LAT.

We followedthemethod ( Moffat &amp;Zobel,1996 ) toevaluateperformancewithrandomqueries. Foreach document collection, 300documents wererandomlyselectedtogenerate aqueryset. Aquerywasgenerated the document were folded to lower case, and stop words such as  X  X  X he X  X  and  X  X  X his X  X  were eliminated. The number of terms per query ranged from 1 to 65. For example, a query containing 5 terms may be  X  X  X nverted lection that was relevant to the query. We also made the generated query set for each document collection query q ; (2) The terms per query distribution followed the shifted negative binomial distribution the distribution of generated queries closely resemble the distribution of real queries ( Wolfram, 1992;
Xie &amp; O  X  Hallaron, 2002 ). 5.2. Experimental results InSection5.2.1,wefirstpresenttheactual timestakenbytheGreedy-NNandthePBDIAalgorithms.In ent the compression performance of different DIA algorithms. Finally, we study the DIA problem in par-allel IR in Section 5.2.4.
The inverted files of the three test collections were constructed according to the DIAs generated by dif-ferent DIA algorithms. We tested four different DIA algorithms:  X  X  X andom X  X ,  X  X  X efault X  X ,  X  X  X reedy-NN X  X , and  X  X  X BDIA X  X . The Random algorithm means that the document in a collection is randomly assigned doc-umentidentifier.TheDefaultalgorithm meansthatthe document inacollection isassigned document iden-tifier in chronological order. The Greedy-NN and PBDIA algorithms were described in Sections 3.2 and lomb coding ( Golomb, 1966; Witten et al., 1999 ), skewed Golomb coding ( Teuhola, 1978 ), batched
LLRUN coding ( Fraenkel &amp; Klein, 1985 ), and unique-order interpolative coding method ( Cheng, Shann, &amp;Chung, 2004 ).Forthefollowingexperiments,theparameter b foreachpostinglistinGolombcodingwas polative coding was set to 4 ( Cheng et al., 2004 ).

All experiments were run on an Intel P4 2.4 GHz PC with 512 MB DDR memory running Linux operating system 2.4.12. The hard disk was 40 GB, and the data transfer rate was 25 MB/s. Intervening processes and disk activities were minimized during experimentation. 5.2.1. Time taken by Greedy-NN and PBDIA algorithms
In Table 3 , the performance in terms of completion time is shown. The times reported are the actual times taken by the algorithms to generate a DIA for the given document collection that has been inverted. the document collection, nor the time needed to rebuild an inverted file with a new DIA.
Table 3 showsthat the PBDIA algorithm is much faster than the Greedy-NN algorithm. This factmakes the PBDIA algorithm viable for use in large-scale IRSs. Such a fast DIA algorithm can be very useful for situations such as 1. Dynamically changing probability distribution of query terms, and 2. Dynamically changing document collection. 5.2.2. Query performance of different DIA algorithms
In Table 4 , the average query processing time (AvgTime QP and decode an identifier during query processing (AvgBPI QP rithm (Imp)weremeasured accordingtoEq. (6) .Foreach documentcollection, the generatedqueryset was divided into three subsets: the short query set, the medium-length query set, and the long query set. The number of terms per query for the short, medium-length, and long query sets range from 1 to 8, 9 to 20, and 21 to 65, respectively.

All decoding mechanisms were optimized, including: 1. Replaced subroutines with macros. 2. Replaced calls to the log function with fast bit shifts. 3. Careful choice for compiler optimization flags. 4. Implementation used 32-bit integers, as that is the internal register size of the Intel P4 CPU.
Furthermore, the Huffman code of batched LLRUN coding was implemented with canonical prefix a document identifier only required tens of nanoseconds.

The experimental results are shown in Tables 4 and 5 . Key findings are: 1. Table 4 shows that the query performance of the Default algorithm can be 10% faster than the Random algorithm. This indicates that the Default algorithm already captures some clustering nature, thus can serve as a rigid baseline in comparison with other fine-tuned algorithms. 2. Comparing Tables 4 and 5 , one should observe that AvgTime ifies Eq. (4) in Section 3.1, and explains why a good DIA can result in better compression and reduced query processing time. 3. From Table 5 , one should observe that both the Greedy-NN and PBDIA algorithms can result in better compression of posting lists for all tested coding methods except Golomb coding. This indicates that the
Greedy-NN and PBDIA algorithms can improve the cache efficiency if a posting list cache is implemented. 4. Table 4 shows that both the Greedy-NN and PBDIA algorithms can reduce average query processing time for all tested coding methods except Golomb coding. And the query speedup differences between the Greedy-NN and PBDIA algorithms were only 3% on average. Considering the algorithm complex-ity, the PBDIA algorithm is a good choice for the DIA problem. 5. From Table 4 , one should observe that Golomb coding cannot benefit much from the Greedy-NN and
PBDIA algorithms in terms of query performance. This is because Golomb coding assumes that the d -result and the query processing time of Golomb coding are independent of d -gap distribution. 6. From Table 4 , one should observe that the query speedup obtained by the PBDIA algorithm becomes higher as the query length increases. This is because that, as the number of query terms increases, more frequently used query terms are likely to be included, resulting in more advantage due to the PBDIA algorithm. 7. Table4 showsthatboth c codingandunique-orderinterpolativecodingarerecommendedforreal-world
IRSs due to their fast query throughputs. In addition, compared with the other tested coding methods, these two coding methods benefit more from the PBDIA algorithm. We conclude that the PBDIA algo-rithm is viable for use in real-world IRSs. 8. Table 4 shows that the PBDIA algorithm can reduce average query processing time by up to 20% for an inverted file in which the document identifiers in a posting list are sorted in ascending order. To allow extremely fast processing of conjunctive queries and ranked queries using the same index, most IRSs inusetoday adopttheskippedinvertedfiles( Moffat&amp;Zobel,1996 )ortheblockedinvertedfiles( Moffat,
Therefore, the PBDIA algorithm can also be applied to those inverted files, and reduce the time needed widely used in modern large-scale IRSs, we believe that the PBDIA algorithm can contribute in real-world IRSs. 5.2.3. Compression performance of different DIA algorithms tifier (BPI), defined as follows:
To reduce average query processing time, both the Greedy-NN and PBDIA algorithms target on improving the compression efficiency for the frequently used query terms. However, this is at the cost of sacrificing the compression efficiency for the less frequently used query terms. We need to know how much space overhead is needed to trade for this speed advantage. Results in Table 6 shows that the Greedy-NN and PBDIA algorithms can speed up query processing with very little or no storage overhead. 5.2.4. DIA in parallel IR
This subsection investigates the DIA problem in an IRS that runs on a cluster of workstations. Assum-query processing time is shortened. Ma, Chen, and Chung (2002) indicated that near-ideal speedup on query processingcan beobtainedifaninvertedfileispartitionedusingthe interleavingpartitioning scheme.
Forsuchapartitioning,DIAplaysacrucialroleinloadbalancing.ThePDBIAalgorithmcanbeappliedto aid the interleaving partitioning scheme to yield better load balancing.

Table 7 shows the performance of parallel query processing using interleaving partitioning scheme with eitherthe Default algorithm or thePBDIAalgorithm.Themetricisthe speedup relative tosequentialquery processing with Default algorithm. Experiments were conducted on the TREC collection. The sub-file on each workstation was compressed using the unique-order interpolative coding method. The parallel query processing time was defined as max[ T 1 , T 2 , ... , T k decompress the (partial) posting lists for the query terms on the i th workstation. Note that T include the document identifier comparison time (the reason being the same as described in Section 3.1).
The experimental results show that the interleaving partitioning scheme can yield near-ideal speedups, as reported in Ma et al. (2002) . In addition, using the PBDIA algorithm to enhance the clustering property speedups. Hence the DIA problem should deserve much attention in parallel IR. 6. Conclusion
In this paper, we study the DIA-based query optimization techniques for an IRS in which the inverted generating a good DIA to reduce average query processing time.

The PBDIA algorithm can efficiently assign consecutive document identifiers to the documents contain-small, and results in better compression for popular coding methods without increasing the complexity of decoding processes. This can result in reduced query processing time.

Experimental results show that the PBDIA algorithm can reduce the average query processing time by upto 20%. We also pointout thatthe DIA problem has vital effects onthe performance of longqueries and parallel IR. Compared with the well-known Greedy-NN algorithm, the PBDIA algorithm is much faster and yields very competitive performance for the DIA problem. This fact should make the PBDIA algo-rithm viable for use in modern large-scale inverted file-based IRSs.
 Acknowledgements This work was supported by National Science Council, ROC: NSC93-2213-E-009-025. References
