 A comprehensive understanding of user X  X  item selection be-havior is not only essential to many scientific disciplines, but also has a profound business impact on online recommenda-tion. Recent researches have discovered that user X  X  favorites can be divided into 2 categories: long-term and short-term. User X  X  item selection behavior is a mixed decision of her long and short-term favorites. In this paper, we propose a unified model, namely S tates T ransition p A ir-wise R anking Model (STAR), to address users X  favorites mining for sequential-set recommendation. Our method utilizes a transition graph for collaborative filtering that accounts for mining user X  X  short-term favorites, jointed with a generative topic model for ex-pressing user X  X  long-term favorites. Furthermore, a user X  X  specific prior is introduced into our unified model for better modeling personalization. Technically, we develop a pair-wise ranking loss function for parameters learning. Empiri-cally, we measure the effectiveness of our method using two real-world datasets and the results show that our method outperforms state-of-the-art methods.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Information Filtering Models Recommender Systems, Sequential Data, Personalized
The ability of Recommender Systems (RS) to predict con-nections between users and items makes them an important tool for web users, e.g., movies (Netflix), products (Ama-zon), restaurants (Yelp), etc. Overall, user X  X  favorites can c  X  be expressed either explicitly, such as by ratings, or implic-itly by her clicked or purchased history. Traditional meth-ods [2, 5] in Recommender Systems usually focus on mining global patterns by analyzing the entire history in a chaotic order. However, in real-world applications, items purchased by a user come in a sequence. Sequential data recommenda-tion problem [4, 7] has attracted more and more attention in recent years. In this paper, we deal with top-N recom-mendation problem under the setting where sequential data with implicit feedback is given per user. Common examples include 1) an online music website where users frequently select songs in their favor; 2) an online shop where user-s constantly buy books or CDs. In these applications, the target is to mine user X  X  favorites, so as to recommend items that she might want to listen/purchase in her next visit.
In general, user X  X  item purchased sequence can be viewed as a states transition process, in which user X  X  latent favorites are treated as hidden states. The user X  X  next action can be predicted based on her previous actions. Recently, a variety of methods have been proposed, e.g., Yang et.al,[6] proposed a modified sequential Matrix Factorization model for min-ing user X  X  short-term favorites. Rendle et al.[3] firstly put forward a unified model, embedding both Markov Chains and Matrix Factorization, to provide the next point of in-terest (POI) recommendation. However, these methods can not fully express a user X  X  item selection behavior, since they merely capture user X  X  sequential dependent favorites (short-term favorites), while ignore user X  X  sequential independent favorites (long-term favorites). More comprehensive analysis and strategies should be carried out. To date, representing user X  X  item selection behavior with good interpretability is still an open problem.

In summary, the major challenges of this work lie in: 1) How to effectively model and predict user X  X  long and short-term favorites simultaneously: Basically, user X  X  item selection behavior is a mixed decision of her long and short-term favorites. Some special models should be considered to effectively capture the characteristics of dif-ferent favorites patterns. 2) How to properly express user X  X  personalization: Due to the reason that different users may have different favorites distribution, a personalized item recommendation is an enabling mechanism to overcome information overload occurred and to really meet user X  X  individualized favorites. In this paper, we propose a unified model, namely S tates T ransition p A ir-wise R anking Model (STAR), to address users X  favorites mining for sequential-set recommendation. Our method collaboratively combines a transition graph with a generative semantic model: 1) users X  long-term favorites (hobbies) are seized as topics which can be effectively gener-ated by Latent Dirichlet Allocation (LDA); 2) users X  short-term favorites (ad-hoc interest) are captured by a transition matrix in Markov Chains (MC). A unified states transition matrix is learnt as a trade-off strategy for effectively model-ing the user X  X  item selection behavior. Furthermore, a user X  X  specific prior is introduced into our unified model to dis-tinguish personalized favorites. Technically, we develop a pair-wise ranking loss function for parameters learning and derive inference to obtain better performance. Experimental results show that our proposal outperforms state-of-the-art methods. In a word, our contributions can be summarized as follows:
Let U = { u 1 ,u 2 ,...,u | U | } be a set of users, and W = { w 1 ,w 2 ,...,w | W | } denote a set of items. For each user u , the purchased history H u is known: H u := ( H u 1 ,H u 2 ,...,H with H u t  X  W . And the purchased history of all users is to recommend items to a user the next time she visits the shop. Note that we deal not with absolute time points, but with relative ones regarding a user, e.g., the first, second, etc. The item recommendation task can be formalized in creating a personal ranking over all pairs of items for user u in her next visit. With this ranking, we recommend top-N items W re to the user. Figure 1: Top-N recommendation will be based on the scores under the candidates.
In this paper, we express a general item selection process through a unified model for sequential set recommendation. According to Figure 1, imagine we have recorded a target user X  X  (e.g., Alice) purchased history H u := ( H u 1 ,...,H with H u t  X  W , we find that she usually purchased love theme movies like  X  X itanic X  and  X  X one with the Wind X . But recently she bought some tickets of  X  X he Hobbit: The Desolation of Smaug X . Thus, instead of recommending some movies in her favor, it is also promising to give another style movies such as  X  X he Lord of the Rings X  to her. Figure 2: A unified model for recommendation. Where  X  u , X , X , X  are four hyper-parameters
As shown in Figure 2, we elaborate above case with our unified model. The light blue box represents a generative semantic model, in which user X  X  general taste is expressed by topics. A multinomial distribution  X  is over the laten-t topics to model the prior distribution of a target user u . And each latent topic z has a multinomial distribution  X  z over the item set, which represents the relevance of items to the topic. On the other hand, the light green box stands for a hidden Markov model, in which user X  X  purchased record can be viewed as a Markov Chain, and her recent favorites can be captured by the hidden states c . Then the recom-mended items will be generated based on the probability of the unified model. Similar to the idea of Topics and Syntax Model [1], we treat all the topics in LDA as a special hidden state (e.g., c=1), so that the state transition matrix  X  can be learned as a trade-off selective strategy for the unified model. Furthermore, due to the reason that different user-s may have different favorites distribution, a user X  X  specific prior (e.g.,  X  u ) is introduced into our unified model so as to distinguish personalized favorites.

The total likelihood can be represented as a condition-al probability of hyper-parameters  X  u , X , X , X  . And here we write the user X  X  event corpus as follows:
We then use the probability as the final score of each item for the ranking measure. The probability is given as follows: where I I I is an indicator variable which equals to 1 if the argument is true. We introduce a pair-wise log-loss function for parameters adaptation. where r denotes the ranking,  X  r ij = r i  X  r j denotes the dif-ference of observed ranking (ground-truth) in validation set. Note that smaller ranking means more relevant. The scalar  X  is a free parameter which designates a target margin val-ue. f = P ( w i | H u )  X  P ( w j | H u ) denotes the difference of the Algorithm 1 STAR Algorithm 1: Initialize the parameters and set  X  u equally for all users. 2: for outeriter in (0 ,maxouteriter ) do 3: for each user u in U do 4: Sample  X  from a Dirichlet(  X  u ) prior. 5: end for 6: for inneriter in (0 ,maxinneriter ) do 7: Use MCMC for sampling. 8: Calculate the distribution of each z and c . 9: end for 11: for each user u in U do 12: Calculate the transition probability  X  u . 13: Calculate items X  probability for recommendation. 14: Random select i  X  FalsePositive , j  X  FalseNegative . 15: Minimize the loss function and update the hyper pa-16: end for 17: end for 18: Rerun MCMC on testing set, recommend W re to target users. prediction scores. Our main process is shown in Algorithm 1. We apply a detailed inference for the proposed algorithm. Based on Algorithm 1, we use Markov Chain Monte Carlo (MCMC) to perform full Bayesian inference in this model. We firstly derive topic assignment z t . Given items w , the state assignments c , other topic assignments z  X  t , and the hyper-parameters, each z t is drawn from: where n z t w t denotes the number of items in topic z t that are the same as w t , n z t  X  represents the total number of items in topic z t . We have obtained these conditional distributions by using the conjugate of the Dirichlet and multinomial dis-tributions to integrate out the parameters  X  ,  X  . Similarly, each c t is drawn from: where n c t  X  denotes the total number of items in state c n t is the number of transitions from state c t  X  1 to c t . C denotes the total number of states. We then calculate the item distribution  X  z w t ,  X  c w t as follows:
For each user, the transition probability  X  c t  X  1 u is given by where n u stands for a transition counter only for user u . Based on equation (2) and (3), the partial derivative of the parameter  X  u on the loss function is given by where  X  u k represents the prior for k th topic. Finally, the up-dating strategy is given by follows through Stochastic Gra-dient Descent(SGD) algorithm. where l stands for a learning rate. Two real-world datasets used here are MovieLens 1 and Douban 2 . MovieLens is widely used in related work. Douban is a real-world dataset crawled from a publicly available web-site. Both datasets have users X  sequential behavior history. For experiments, we obtain 1,000,209 observations from 6040 users and 3900 items in MovieLens, 2,152,962 observation-s from 6000 users and 14648 items in Douban. For each dataset, we mark of the last 10% items of each user as the test set to evaluate the recommendation accuracy of differ-ent methods. And we use the rest as train dataset and 10% of train dataset as validation to fit the models.

We evaluate the accuracy of different methods with four traditional metrics, namely precision( Pre ), recall( Rec ), mean average precision( MAP ) and normalized discounted cumu-lative gain( NDCG ). Here we consider top-N(i.e.,10, 15, 20) recommendation.

To validate the effectiveness of our model, we implement the following baselines for comparison, namely User-based kNN(k=50), LDA, FPMC[3], HMM[4], NSTAR( X  X  X  is short for Non-personalized, where users share a common prior).
Quality: Table 1 shows the quality of evaluation metrics on the two datasets for different methods respectively. We discover that our proposed methods, which take advantage of both the LDA and MC, are superior to any single model of LDA or MC, because the global patterns of items and the first-order markov property have been captured as the tran-sition matrix in our model. Additionally, Both FPMC[3] and our method work pretty well in MAP and NDCG on the two sequential datasets since we all consider designing a ranking loss function directly. Furthermore, STAR also surpasses NSTAR with the fact that learning a personalized http://grouplens.org/datasets/movielens/ http://www.douban.com prior for distinct users is beneficial to modeling users X  per-sonalized favorites. In a word, our model could give a better explanation for the general item selection process and thus move a step closer to persuasive recommendations. Figure 3: The Number of States and Topics Analysis
Topics and States Analysis: We fix the number of s-tates/topics at 10, and vary the number of topics T /states C from 10 to 30 respectively. The evaluation metrics results on the MovieLens are plotted in Figure 3(a) and (b) respective-ly. We can see in 3(a) that the recommendation performance remains relatively stable when varying the value of T . It can be shown in 3(b) clearly that the performance consistently decreases as the number of states increases. Furthermore, it is shown that both MAP and NDCG have shaken greater than Pre as well as Rec with the mutative number of topics.
User X  X  Personalized Favorites Study: Figure 4 shows the transition matrices of a pair randomly selected users in MovieLens (we denote as user i,j ). Each row/column de-notes a hidden state of the unified model. Brighter colors indicate high probability. We can draw that the item se-lection of user i usually depends on her long-term favorites (e.g., c =1, a special hidden state for topics in LDA, occupies a high percentage.), while user j would also like to follow her short-term favorites (e.g., large values in diagonal elements, indicating that the user probably selects items based on her recent favorites).
In this paper, we try to model user X  X  item selection behav-ior and address the recommendation task on sequential data. Specifically, we present a transition graph for collaborative filtering that accounts for mining user X  X  short-term favorites, jointed with a generative topic model for expressing user X  X  long-term favorites. A personalized prior is introduced so as to express users X  distinct favorites. The results show that our method outperforms state-of-the-art methods.
This work was supported in part by National Natural Sci-ence Foundation of China (Grant No. 61170127).
