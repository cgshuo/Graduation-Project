 Suicide is a major concern in society. Despite of great attention paid by the community with very substantive medico-legal impli-cations, there has been no satisfying method that can reliably pre-dict the future attempted or completed suicide. We present an in-tegrated machine learning framework to tackle this challenge. Our proposed framework consists of a novel feature extraction scheme, an embedded feature selection process, a set of risk classifiers and finally, a risk calibration procedure. For temporal feature extrac-tion, we cast the patient X  X  clinical history into a temporal image to which a bank of one-side filters are applied. The responses are then partly transformed into mid-level features and then selected in ` -norm framework under the extreme value theory. A set of prob-abilistic ordinal risk classifiers are then applied to compute the risk probabilities and further re-rank the features. Finally, the predicted risks are calibrated. Together with our Australian partner, we per-form comprehensive study on data collected for the mental health cohort, and the experiments validate that our proposed framework outperforms risk assessment instruments by medical practitioners. J.3 [ Life and Medical Sciences ]: Health; I.6.5 [ Simulation and Modelling ]: Model Development medical data analysis, suicide, risk modelling, risk prediction, one-side convolutional kernels, filter bank, machine learning
Suicide is widely considered as a major problem in mental and public health, and is a main cause of death. WHO estimates that worldwide, suicide accounts for nearly 2% of deaths by 2000 [2]. Although there is a decreasing trend in the number of suicide-classified deaths in Australia, there is no decline in the suicidal ideation or attempts [11]. In a 2007 national survey, 2.9% of the population had suicidal ideation, and 0.4% had attempted suicide [8]. This poses grave challenges for mental health service providers, and the open question is how to improve early detection of suicide and prevention.

Mandatory practice in health services is to perform risk assess-ments, serving as one of the gate-keeper indicators in triage to de-termine nature of care. Such assessments have medico-legal con-sequences. However, the reliability and validation of suicide risk assessments is not well understood in terms of predictive power, and remains a controversial issue in risk management (e.g., see [18, 10]).
 Figure 1: Clinical events represented as a temporal image, which is convoluted with one-sided filter bank.

We ask a bold question: Can we predict suicides automatically, given mental history, risk assessments and clinical intervention data? We aim to predict the probabilities within a given future period of sentinel events: low-risk, moderate-risk and high-risk events. Low-risk events implies no detected suicide risks, moderate-risk events are self-injuries that do not lead to fatal consequences, and high-risk events are those with fatal results. The convention is that if several events occur within the same period, the highest sever-ity is considered. The cohort under study is from Barwon Mental Health, Drugs and Alcohol Services, the only provider in the re-gion of 350,000 people in the central western region of Victoria in South-eastern Australia.

We depart from the standard medical practice of considering a small set of risk factors and limited risk levels based on expert knowledge (e.g., see [4]). We exploit large medical datasets, gen-erating thousands of potential signals from multiple sources. We then employ machine learning to automatically select strong and re-liable risk factors of future attempts or suicide. The goal is then to develop an automated tool that: (i) provides objective measures of risk factors quantifying uncertainties; (ii) detects risk patterns from the patient history; and (iii) computes probabilities of outcomes . Key modelling considerations are transparency in modelling deci-sions and interpretability in results.

The problem is highly challenging (e.g., see [16]). Documented risk factors, such as those used in risk assessments may not cor-relate well with future outcomes. High risk events are rare and irregular. The data is aggregated from different sources, is incom-plete (e.g., people reported dead without any noticeable history) and contains a significant noise (e.g., service providers under pres-sure might enter  X  X unk X  data to meet protocol requirements). The data is severely imbalanced. Time scales for event evolution can be very different, ranging from days to decades.

Our proposed framework implements three key concepts to tackle these challenges: automated scale-invariant feature generation and selection from big data, subsequent ordinal risk classification and finally, risk calibration to account for data imbalance. For feature extraction, we offer a novel conceptual view in which a patient X  X  medical record is cast as a temporal image, features vs time, on which an one-sided filter bank can be applied (see Fig. 1 for an illustration and Sec. 3.1 for details). The extracted feature set is temporally sensitive and takes into account time sensitive nature of varied medical event evolutions. The feature pool is then pruned by a supervised procedure that penalises features that are weakly indicative of future attempts in a ` 1 -norm framework, under the ex-treme value theory [6] (Sec. 3.2). A set of ordinal classifiers are designed to further re-rank and select surviving features, simulta-neously computing probabilities of risk levels within a window of time (Sec. 3.3). Finally, the predicted risks are calibrated to meet operational requirements (Sec. 3.4).

To the best our knowledge, this is the first comprehensive data mining type of work for this important domain: Our database con-tains more than 10 , 000 mental patients, with more than 25 , 000 risk assessments. We consider up to 10 , 000 extracted signals and a series of ordinal classifiers. Significantly, we show that using this data, our method X  X  prediction outperforms the risk assessment instrument used by medical practitioners (Sec. 4).

The significance of our framework is that it is agnostic to disease type -given mixed type data comprising demography, clinical his-tory (emergency attendances, admissions and diagnostic coding), and risk assessment instruments -questions with ordinal ratings, our framework automatically extracts the most relevant features and builds risk prediction classifiers. This allows us to easily apply the proposed framework across disease domains.
The Barwon Health hosts a data warehouse in which electronic medical records are pooled. We are mainly interested in data on emergency department presentations and admissions to the gen-eral hospital. For emergency attendances (ED), there are 42 K + recorded mental cases for 8 K + patients in the period of 2005 X  2012. For hospital admissions (HA), there are approximately 67 K recorded mental cases in the period of 1995 X 2012. The number of recorded emergency attendances and admissions has been increas-ing over the year, e.g., from 7,068 admissions in 2009 to 8,143 in 2010 and 8,956 in 2012.

The most important piece of information is the diagnostic coding for any episodes. Each ED record contains only one main code, but an admission is typically associated with multiple codes, some of which reflects mental status. The diagnosis coding conforms with Figure 2: Some data distributions: (Top) codes suggesting at-tempts; (Bottom left) words in assessment notes; and (Bottom right) interval between risk assessments in weeks. Best viewed in colour. the latest classification scheme, the ICD-10 1 . This is a hierarchy of diseases covering almost all known conditions. The codes start with a letter followed by several digits where the digits placed later in the sequence indicate more specific conditions. For example, in-juries to the head are classified into 10 groups, from S00 to S09 . The group S01 would mean  X  X pen wound of head X , the subgroup S011 means the  X  X ound in the eyelid and periocular area X . Some ICD codes can be readily interpreted as suicide attempts, for exam-ple, the code R4581 refers to suicide attempt or ideation. However, other codes must require expert interpretation about severity of in-cidents. Fig. 2 (top) depicts the distribution of codes which are associated with suicide risks.

Another feature of mental health data held at Barwon Health is that it contains suicide risk assessments for every mental patient un-der its management. The local clinical protocol requires a suicide risk assessment on admission, and then after every 91 days during the care episode, and finally on discharge. The assessment instru-ment used by Barwon Health was developed in-house in 1999. It has ordinal assessments for 18 items covering all mental aspects such as suicidal ideation, stressors, substance abuse, family sup-port and psychiatric service history. See Fig. 2 (bottom left) for examples of keywords noted by the assessment staff.

The system recorded approximately 25 K assessments on 10 K patients in the period of 2009-2012. The majority of patients have only one assessment (62%), followed by two assessments (17%), but there are about 3% patients who have more than 10 assess-ments. For those with more than one assessments, the time between two successive assessments are: 30% within one week, 64% within 3 months (Fig. 2 (bottom right)).

Three other assessment tools are also required by the Australian government: the HoNOS (Health of the Nation Outcome Scales), the LSP (Life Skills Profile) and the BASIS-32 (Behaviour and Symptom Identification Scale). These provide different perspec-tives on the mental health of a patient. However, it appears that they are incomplete and noisy and thus our early experiments on these instruments did not result in positive findings.

We focus our study on those patients who have had a least one event prior to a risk assessment. The dataset then has 7 , 746 pa-tients and 17 , 771 assessments. For each patient, we collect age, gender, spoken language, country of birth, religion, occupation, marital status, indigenous status, and the postcodes over time. Among International Statistical Classification of Diseases and Related Health Problems 10th Revision, available at: http://apps.who.int/classifications/icd10/browse/2010/en Horizon (day ) 14 30 60 90 180 C 1 16,985 16,525 15,952 15,471 14,490 C 2 536 836 1,174 1,440 19,29 C 3 250 410 645 8,60 1,352 Suicide 7 24 32 41 63
Table 1: Outcome class distribution following risk assessments. patients considered, 48 . 7% are male and 48 . 6% are under 35 of age at the time of assessing.

The risk assessments are the evaluation points from which future prediction is required. Future outcomes are broadly classified into three levels of risk, based on expert at Barwon Health: class C refers to low-risk outcomes, class C 2 refers to moderate-risk (non-deadly attempts), and class C 3 the high-risk (deadly outcomes). The classes are assigned using a look-up table from the diagnosis coded events. The convention is that among all events occurring within the prediction period, the class of the highest risk is cho-sen. For example, the ICD-10 coded event S51 (open wound of forearm) is moderate-risk, while S11 (open wound of neck) would be considered as high-risk. Typically the completed suicides are rare, and the class distributions are imbalanced. For example, for 2-week period following the risk assessment, there are only 7 sui-cides among 250 lethal attempts ( 1 . 4% ), and 536 moderate-risk attempts ( 3 . 0% ). Further class distributions are summarised in Ta-ble 1.
After data pooling, we obtain a temporal medical database where each patient has multiple time-indexed records. Each record spec-ifies a particular event such as risk assessment, moving home, ad-mission, diagnosis, lab test, or medicine prescription. In general, the data characteristics can be summarised as follows: We note that similar observations have also been partly stated in [21], and these characteristics are common for other medical ser-vices as well.

The suicide risk analysis has been mostly carried out in the tra-ditional medical research (e.g., see [4]), and it is well recognised that it is very hard to predict the actual suicidal outcomes (e.g., see [16]). The common feature in these studies is that the risk fac-tors are manually designed based on expert knowledge, and thus each study can only handle a handful of such factors. The risk assessment instrument developed and practiced at Barwon Health, for example, is composed of 18 items. In data mining and machine learning, the problem of suicide risk prediction has largely been overlooked. Recent work of [17] proposes a Bayesian nonpara-metric approach to suicide attempt modelling. The main idea is to represent each patient by a set of binary features discovered from the data. However, the study has limited value in practice since it mainly involves interviews and does not contain real outcomes but ideation, which is known to be weakly associated with real attempts and suicide.
Our ultimate goal is to predict attempts and associated lethality in the future, often at the point of risk assessments. We describe an integrated predictive framework which has the following com-ponents: 1. Temporal feature extraction: Most of the features are tem-2. Feature selection using a surrogate task of detecting attempts 3. Risk classification given the observed history. This is the 4. Risk calibration for translating the probability of risk in to The second and third components are placed within the bootstrap-ping framework [5, 3, 15][3] for better stability and predictive per-formance.
Our problem is to construct a set of sensible features at a partic-ular time in the patient history. It is desirable that the feature pool has a good coverage and is highly informative for the risk predic-tion tasks at multiple time-scales. In other words, the feature set should be insensitive to scales. The main conceptual insight is that much of the clinical records can be represented as a sparse tempo-ral image , where at any given point of time, we can only look back to the recorded history. The key concept we introduce here is the one-sided filter bank 2 for detecting temporal features.
Data includes demography, detailed clinical history and risk as-sessments. Clinical history includes a series of admissions and emergency visits. Each admission typically contains a subset of ICD diagnosis codes, procedure codes, diagnosis-related groups and discharge medications. To deal with the plethora of ICD codes, we preprocess to separate the rare codes, which we consider as one observation type.
This is somewhat analogous to the concept of filter-bank in signal processing and computer vision.
Let t be the time point of interest, H be the maximum history length. Let v i ( t ) be the observation of the event of type i at time t and let there be D event types. If the event is not observed in the data, then v i ( t ) = 0 , otherwise, it is a real value if it is some measure, or 1 if it is an occurrence 3 . An event for an ICD code is the presence or absence of code. For demography, some events are fixed over time (like gender); for postcodes, we consider an event if a change of postcode has occurred; and for age, we discretise into bands, that is an event is recorded when the age reaches a particular band at the assessment time. For continuing events such as treat-ment episodes, v i ( t ) is the duration given that the entire episodes are in the history. Then a representation of the patient history is as depicted in Fig. 1.
Different events have different resolutions in time -an attempted suicide is time critical, whereas a Type I diabetic ICD code is not. To accommodate events having different time scales of evolution, we consider a multiscale temporal filter bank. For each event type i , we have a set of K filters over varying timescale. Each filter essentially evaluates the strength of the event type at that scale. Let K k  X  R H +1 be the k -th one-sided filter (or kernel), the k -th feature evaluated at t for event i is where K k ( h ) is the convolution kernel evaluated at h . One useful kernel is the truncated Gaussian where K k ( h ) &gt; 0 for h  X  0 and 0 otherwise. The hyper-parameter  X  defines the effective width of the kernel, i.e., the response drops drastically as h goes beyond  X  k . The behaviour is similar to the uniform kernel with specified width  X  k This kernel counts the normalised number of events falling within a given period of time.
 partly captures the temporal structure in the patient history. How-ever, the nature of event aggregation using the kernels does not re-veal temporal changes within the  X  X edical image X , for example the rise and fall of stress over time. We propose a simple way to do this by dividing the image into temporal fragments. Each fragment is then evaluated through filter responses and all fragment responses are concatenated. Indeed this can be captured using the same ker-nels as above but with a shifting operation, i.e., the convolution in Eq. (1) is modified as follows where s k denotes the delay from which the kernel operation has effect.

Finally, the design of filter bank is characterised by a set of pairs (  X  k ,s k ) . In this particular suicide application, we choose the pairs
If an event is missing, it may due to the fact that nothing happens, or it is not recorded, or the time t is in the future. (in months). That is, the history H = 24 months is considered. At the current evaluation point, three kernel widths are 0 . 5 , 1 and 3 months reflecting the short-term scales of the mental risks. The delays of 3 , 6 and 12 months are designed to capture the medium-term progression of the mental state and comorbidities.
Given several risk factors, we need to find a compact subset that best explains suicide outcomes. Since suicides are rare, we look at the suicide attempts as the first approximation . Thus we are con-cerned with the setting where there are binary outcome of a suicide attempt) y  X  { 0 , 1 } , given the features. We choose the Gener-alised Linear Model (GLM) framework [13] with the complemen-tary log-log link function, which is essentially the application of the Extreme Value Distribution (the Gumbel distribution) [6]. This link function is motivated by the fact that suicide attempts are at the extreme end of the risk spectrum.

Let  X  ( f ) = u 0 + P i u i f i be the mean risk, where u are feature weights. The probability of an suicide attempt is given as The model estimation and the feature selection can be carried out simultaneously by maximising the ` 1 -regularised log-likelihood on training data D where  X  1 &gt; 0 are regularisation parameters. In general, larger  X  would lead to sparser models (e.g., many features are not selected). This setting is essentially a variant of the lasso (the original prob-lem was linear regression [19]). The output of this step is the list of features with non-zeros weights.
Here we describe a set of models to deal with the ordinal na-ture of the suicide outcomes. Our goal is not only to come up with high performing classifiers but also to offer a reasonable interpre-tation of modelling choices. In particular, we assume that the ob-served outcomes are the discretised version of underlying random risks x  X  R m . The probabilistic models are natural to estimate the probability of a particular risk class being observed. Let L be the number of discrete levels of lethality, in which level 1 refers to the normal state where no risk can be observed, and level L refers to the most fatal state or even death. The outcomes are regressed against the feature vector f evaluated at the time t . k -NN makes no assumption about the underlying random risk, but it is based on the foundation that patients with similar recent history would assume similar risk in the near future. To this end, for each patient at any evaluation point t , we choose k similar history fragments from other patients with known outcomes and compute class probabilities of the outcomes in that neighbourhood. That is P ( r d = l | f d ) = 1 k P p  X  N ( d ) 1 [ r p = l ] , where N ( d ) is the k -nearest neighbourhood of data d .
We assume that the underlying random risk is normally distributed, and resembles the lethality level l  X  1 , i.e., we treat the discrete lev-els as real values and x = r  X  X  (  X  ( f ) , X  ) . The distribution mean is modelled as a linear function of features:  X  ( f ) = w However, since we are mainly interested in the probabilities of the discrete outcomes, we need a way to convert from the continuous distributions N (  X  ( f ) , X  ) . We employ the following transforms normalising constant. The standard deviation  X  can be estimated from the set e d = r d  X   X  ( f d ) d  X  X  on the training data D .
This model assumes that the discrete outcomes r are generated from the one-dimensional underlying random risk x  X  R as follows [12] where  X  1  X   X  2  X  ... X  L  X  1 are thresholds. This essentially says that the discrete outcome is a coarse version of the real-valued risk. Here the risk spectrum is the real line divided into intervals, each of which determines the corresponding outcome. In the form of probability distribution we have where F (  X  l | f ) is the cumulative distribution evaluated at  X  Choosing the form of F (  X  l | f ) is usually the matter of practi-cal convenience since x is unobserved and we do not know the true underlying distribution. For example, assume that the mean risk functional is linear in features, i.e.,  X  ( f ) = w 0 tic distribution F (  X  l | f ) = [1 + exp (  X  (  X  l  X   X  ( f )))] interesting interpretation: i.e., the log odds at the split level l is proportional to the risk factors. Another distribution is the Gumbel family studied in Sec. 3.2, and this can provide an interpretable model in terms of extremal risks.
This leaves a question of how to estimate F (  X  | f ) and the creasing sequence, we enforce this monotonicity by using for l = 2 , 3 ,...,L  X  1 , where  X  l  X  R , which is unconstrained. More details are left until Sec. 3.3.6.
Cumulative models assume a single risk variable that can explain the ordinal outcomes. This assumption is quite limited and does not address the nature of the risk progression -for some patients, the risk may not reach a certain level immediately. It may, alternatively, start from a normal condition, and then progress upward. This sug-gests a stagewise model of outcomes: The next outcome level may be attained only if the lower levels have not been attained [1, 20].
Since there are several stages, we need not assume that there is only one underlying risk variable. Instead, the risks can be multi-dimensional , i.e., x  X  R L  X  1 and each stage l  X  { 1 , 2 ,..,L  X  1 } assumes their own underlying risk variable x l  X  R . The stagewise process can be formalised as follows Here, the transition from level l to level l + 1 is signified by the event that the risk value passes through the level-specific threshold  X  . The probability that the outcome is the lowest is then where F 1 (  X  1 ) is the level-1 cumulative distribution. If the condition x  X   X  1 does not hold, then we consider level 2 This process continues until some level has been accepted, or we must accept the last level L . Thus the probability of having the highest level of risk, given all the lower levels have not been ac-cepted, is
Note that the probabilities above are conditional . The marginal probability of selecting a particular discrete outcome is P ( r = l ) = With the choice F l (  X  l ) as a logistic distribution and the linear risk functional  X  ( f ) = w 0 f we have a nice interpretation i.e., the log odds of the probability of choosing the next level, given the fact that all previous levels have failed, is proportional to the risk factors f .

At this point, we are left with two choices: (i) using the same dis-1 } , or (ii) using level-specific distributions. The later choice has more parameters, and thus more flexible.
While the stagewise models greatly relax the assumption of the underlying random risks, the stagewise risk progression process is at best an approximation to the true process. Here we relax the as-sumption even further: (i) Outcomes are individual choices that are independent of other choices, (ii) An outcome is observed because it is the most likely choice among all choices given the situation.
Like the stagewise models, we assume that the underlying risk are multidimensional, i.e., x  X  R L , one dimension for a pos-sible outcome. An outcome is observed if its underlying risk is the largest among all other underlying risks, i.e., r = l if x max m 6 = l { x m } . It has been proved that under the Gumbel distri-bution, this decision rule leads to the standard multinomial model P ( r = l | f )  X  exp (  X  l ( f )) [14]. Let  X   X  l ( f ) =  X  this simplifies to
The probabilistic models, except for the k -NNs, are estimated by maximising penalised likelihood over the training data D
L ( w ,  X  ) = 1 where  X  are thresholds in the cumulative and stagewise models. The role of the ` 1 -penalty is to further select strongest features for the predictive task. For the cumulative and stagewise models, we fix the first threshold  X  1 = 0 and learn the others. For ease of interpretation, we employ the simple linear functional  X  ( f ) = w 0 + w 0 f if parameters are shared among all levels or  X  l w 0 l + w 0 l f otherwise. For the multinomial model, we simply fix  X  ( f ) = 0 .
Let us now consider a specific situation at Barwon Health, where the outcomes are broadly classified into three levels of risk: class C 1 refers to low-risk outcomes, class C 2 refers to non-deadly at-tempts, and class C 3 the most deadly outcomes. Once trained, the classifiers described above produce the probabilities of future risk classes P ( r | f ) . However, there are two major problems with this setting. First, for everyday practice, it may create significant cognitive load for physicians to reason in terms of numerical prob-abilities. Second, the data collected here is highly imbalanced: For three-month horizon, only 8 . 1% data points belong to the class C and 4 . 8% belong to C 3 (Sec. 2.1, Table 1). This leads unavoidable bias in estimation which is unfavourable towards the most impor-tant class, the C 3 .

To mitigate the problems, we employ a simple calibration that first translates the risk class probabilities into a single, interpretable risk index , and derives a rule to assign the risk classes, in a manner similar to the cumulative model (Sec. 3.3.3). This translates into the following procedure: 1. Estimate the risk index, which is the expected risk, on each 2. For each test point j , predict the test classes by using the
One potential problem with the pipeline we have just described is the instability of the model, especially the selected features, due to the data sampling. That is, a different data collection scheme may produce an entirely different model, leading to the interpretation problem and high variance in the classifiers. To achieve stability and potentially boost the prediction performance, we draw from the existing literature of bootstrapping [5], including bagging [3] and stability selection [15]. The overall training loop is as follows: 1. For each bootstrap b = 1 , 2 ,...,B 2. For every training data point, compute the averaged class 3. Estimate the decision thresholds  X  low and  X  high (Sec. 3.4). 4. Collect statistics for every feature: (i) the mean feature weights , The Step 1(a) is essentially the well-known procedure called  X  X am-pling the majority class X  for handing the class imbalance problem, but we are not aware of the use within the context of bootstrapping. Thus at the end of the training phase, we have collection of B clas-sifiers and a list of stable and predictive features, as well as the fully specified class-assignment rule.

At test time, the class probability is estimated as in Step 2, and the class assignment is carried out using procedure in Sec. 3.4.
For robustness we consider items (e.g., codes) with more than 100 occurrences and are in the top 2 , 000 most popular items of a given type. Other items that do not satisfy these conditions are considered rare events. Such rare events, though statistically less important individually, are critical in identifying risks if combined. We empirically find that using diagnostic features at level 3 in the ICD-10 hierarchy gave the best result as they appears to balance generality and specificity. Whenever appropriate, we also map di-agnostic codes into the mental health grouping scheme known as MHDG 4 .
 We implement several kernel types and report here the results for Gaussian kernel filters, as they seem to work better than others (but similar to uniform kernels). Filter responses are then normalised into the range [0 , 1] before transformed by the sqrt ( f ) operators. We then apply feature selection described in Sec. 3.2 with control parameter:  X  1 = 3  X  10  X  4 unless specified otherwise. For cumu-lative and stagewise classifiers (Sec. 3.3.3 and Sec. 3.3.4), logistic distributions for the underlying random risks are used. The number of bootstrap is set as B = 100 . The decision thresholds used in the class assignment rule in Sec. 3.4 are set at the 78 th percentile and the 93 th percentile, respectively.

We use 10 -fold cross-validation in the patient space , that is, the set of unique patients is divided in to subsets of equal size. Models are trained on data for 9 subsets and tested on the other. The results are reported for all validation subsets combined. Note that this can be a stronger test than the cross-validation in the data space because it removes any potential patient-specific correlation (also known as random-effects ).

We employ several performance measures: For general model fitting, the likelihood evaluated on validation sets provide a mea-sure of how the model generalises to unseen data. For each out-come class, we use recall R  X  the portion of groundtruth class that is correctly identified; the precision P  X  the portion of identified
MHDG stands for Mental Health Diagnosis Group. The mapping is available at http://www.health.gov.au class that is actually correct; and the F-score  X  their harmonic mean F 1 = 2 RP/ ( R + P ) .
We first evaluate the predictive power of the mandatory risk as-sessments being performed by Barwon Health. Using the over-all assessment (risk ratings of 3 and 4 are high-risk, 2 moderate-risk, and ratings of 1 and 0 are low-risk), the performance on the high-risk class for 3 month horizons is quite poor: R = 8 . 1% , P = 12 . 9% , F 1 = 10 . 0% . There are 14 suicide cases ( 34% ) detected from the C 2 and C 3 assignments. Tab. 2 lists more de-tails. Machine learning algorithms significantly outperform the mental health professionals to a large margin. For moderate-risk prediction, the F 1 -score by machines ranges from 20 . 4% to 22 . 6% , which are 31%  X  45% improvement over the score by clinicians. The differentials are even better for the high-risk class: the im-provement are between 164% to 212% . In terms of suicide detec-tion, the machine detects 29  X  32 cases, which are more than twice the number detected by human ( 14 cases).

The practical significance of the difference is remarkable. As-suming for simplicity that the management cost, on average, is similar for both the moderate and high risk cases, then the total cost when predicting by human is 3 , 445 resource units. There are 1 , 535 cases are misclassified as low-risk (they are false nega-tive, and thus left untreated). The machine algorithms typically cost slightly higher than human but with less false negatives. For exam-ple, the stagewise model with shared parameters (Sec. 3.3.4) leads to 3 , 890 resource units ( 13% higher than those by clinicians), but with 1 , 148 false negatives ( 25% lower than those by clinicians). The significance may be amplified when considering that the so-cial cost for false negatives is much more serious than hospital re-sources.
Excepts for the k -NN classifiers which do not have built-in selec-tion mechanism, all other classifiers are capable of fine-tuning the features selected from the previous step (Sec. 3.2).Under the ` norm regularisation schemes within the bootstrap framework, only few percents of strong and stable features are kept.
 wise models (with shared parameters) do not distinguish the pa-rameters between classes, and thus we have a single list of features at the end of the training phase. Tab. 3 presents top 20 features ordered by their importance (see Sec. 3.5), as produced by the cu-mulative model (Sec. 3.3.3). Predictive features include: Recent emergency visits, recent high-risk attempts ( C 3 ), moderate-risk at-tempts ( C 2 &amp; self-poisoning) within 12 months, recent history of mental problems and of drug abuse, socioeconomic problems (pen-sioner, frequent home moving). Although these risk factors are known [7, 4], our discovered factors are more precise in timing. Class-specific features. Class-specific models such as the stage-wise model with class-specific parameters and the multinomial model can offer re-ranking of features for C 2 and C 3 separately. Tabs. 4 list top-ranked class-specific features for C 2 and C 3 , respectively, under the stagewise models. A noticeable aspect is the strong asso-ciation between prior C 3 attempts with future C 3 outcomes.
We have proposed an integrated computational framework for suicide risk prediction. The framework has three components: tem-poral feature extraction, an ensemble loop for feature selection and ordinal classifiers, and risk calibration. The key innovative aspect of the paper lies in its representation of the patient clinical his-tory as a temporal event image, from which time-dependent fea-tures are generated by applying a bank of multiscale one-sided convolutional filters. Risk-bearing features are then selected by training an extreme-value classifier equipped with ` 1 -norm regu-larisations. Using the proposed framework, we have presented a thorough study on a cohort of mental health patients from a large regional hospital. The results demonstrate that the framework out-performs risk assessment instruments by medical practitioners in terms of predictive power.

This project started with the goal of predicting suicide. How-ever, we soon realised that this was an impossible task due to the rarity of suicide while there are many possible risk factors, none of which are really strong. This difficulty actually resembles the long-standing conjecture in the mental health literature [11, 9]. While the existing literature focuses instead in predicting suicide attempts, for practitioners the high-risk attempts are those we should pay ex-tra attention to. And thus one of the contributions of this study is the separation of the attempts into those moderate-risk ( C high-risk ( C 3 ).

As the time of this writing, the deployment is on-going. Since the data is readily available through Barwon Health X  X  warehousing, a real-time clinician support system can be readily implemented with very minimal cost. There is no need for special hardware/software. As the cohort is relatively small by current machine learning stan-dards, the feature extraction and model training are relatively fast. Our prototype implementation on a standard PC using SQL Sever and Perl typically takes a couple of minutes to extract features for models (Sec. 3.3.3). The Gaussian kernel width  X  k and the delay s about 10 thousands patients. The same amount of time is needed for model building in Matlab, while prediction is unnoticeable by users. The model needs to be retrained periodically as new data flowing in, e.g., every month. The front-end that interacts with clinicians is being developed  X  this will offer easy browsing of risk history (through the predictive and stable risk factors which have been discovered by our models), alerting risk and predicting future outcomes.

The main challenge faced in deploying the solution would be earning trust from clinicians in their daily work-flow. We anticipate that the initial resistance will be significant as the implication of taking the advice from the machine is profound for professionals. The next phase of this research is consulting with physicians and psychologists on how to best present the results and explain the reasoning behind the prediction. Another issue is the interaction between the physicians and the system: If the physicians modify their treatment strategy based on the machine prediction, then the outcome will be altered, leading to the poorer match between the actual outcome and the predicted.

The framework introduced in this paper is generalisable as the information extracted from the data warehousing is standardised, e.g., using the ICD-10 coding system and Mental Health Diagno-sis Group mapping, and the models make no use of local expertise (such as risk assessments). The main limitation is that the research is based on the cohort at Barwon Health alone, and thus local char-acteristics of the population and the practice may bias the predic-tion. Finally, the pipeline of feature extraction, selection and clas-sifier is in fact general and thus can readily be applicable for many types of risks with very minimal effort. This has been validated on a series of other predictive problems: The risk of hospitalisa-tion in diabetes, COPD, mental health, heart failure, heart attack and pneumonia, and of mortality in cancers, all at Barwon Health demonstrating the versatility.
 We thank Ross Arblaster and Ann Larkins for helping data col-lections, Paul Cohen for providing management support for the project, and the three reviewers for helpful comments. [1] T. Amemiya. Qualitative response models. Annals of [2] B. Bondy, A. Buettner, and P. Zill. Genetics of suicide. [3] Leo Breiman. Bagging predictors. Machine Learning , [4] G.K. Brown, A.T. Beck, R.A. Steer, and J.R. Grisham. Risk [5] B. Efron and R. Tibshirani. Bootstrap methods for standard [6] EJ Gumbel. Statistical of extremes . Columbia University [7] Keith Hawton, Daniel Zahl, and Rosamund Weatherall.
 [8] A.K. Johnston, J.E. Pirkis, and P.M. Burgess. Suicidal [9] M. Large and O. Nielssen. Suicide is preventable but not [10] M. Large, C. Ryan, and O. Nielssen. The validity and utility [11] M.M. Large and O.B. Nielssen. Suicide in Australia: [12] P. McCullagh. Regression models for ordinal data. Journal of model without parameter sharing (Sec. 3.3.4). The Gaussian kernel width  X  k and the delay s k are measured in months; Sel. Pr. = selection probability. MHDG = Mental Health Diagnosis Group. [13] P. McCullagh and J.A. Nelder. Generalized linear models . [14] D. McFadden. Conditional logit analysis of qualitative choice [15] N. Meinshausen and P. B X hlmann. Stability selection. [16] G.E. Murphy. The prediction of suicide: Why is it so [17] F. Ruiz, I. Valera, C. Blanco, and F. Perez-Cruz. Bayesian [18] C. Ryan, O. Nielssen, M. Paton, and M. Large. Clinical [19] R. Tibshirani. Regression shrinkage and selection via the [20] G. Tutz. Sequential models in categorical regression. [21] F. Wang, N. Lee, J. Hu, J. Sun, and S. Ebadollahi. Towards
