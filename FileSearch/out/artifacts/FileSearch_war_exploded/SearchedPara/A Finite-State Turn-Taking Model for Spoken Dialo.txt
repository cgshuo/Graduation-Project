 Turn-taking, the process by which participants in a conversation alternate speech and silence, is an es-sential component of spoken interaction. In order to lead productive conversations, people need not only know what to say but also when to say it. Decades of research on Conversation Analysis and psycholin-guistics (Duncan, 1972; Sacks et al., 1974; Ore-str  X  om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking be-havior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is of-ten reduced to ad hoc rules only based on very low level features. This simplistic approach leads to in-efficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005).
Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, prac-tical model of turn-taking behavior that builds upon previous work on finite-state models of the conver-sational floor. Because of its simplicity and gener-ality, this model can be applied to many turn-taking phenomena. At the same time, being grounded in decision theory, it lends itself well to data-driven op-timization. We illustrate our approach by applying the model to a specific turn-taking task: end-of-turn detection. 2.1 6-state finite state models of turn-taking In the 1960 X  X  and early 1970 X  X , several researchers proposed models to explain the rhythmic turn-taking patterns in human conversation. In particular, Jaffe and Feldstein (1970) studied the mean duration of pauses, switching pauses (when a different speaker takes the floor), simultaneous speech, and (single-speaker) vocalizations in recorded dyadic conversa-tions. Based on their observation that these dura-tions follow exponential distributions, they proposed first-order Markov models to capture the alterna-tion of speech and silence in dialog. Their initial model had four states: only participant A is speak-ing; only participant B is speaking; both participants are speaking; and neither participant is speaking. However, such a model fails to distinguish switch-ing pauses from A to B from switching pauses from B to A. Based on this observation, they extend their model to a six-state model which they found to bet-ter fit their data than the four-state model. Around the same time, Brady (1969) developed a very sim-ilar six-state model. He trained the parameters on a recorded conversation and compared the generated conversations to the original real one along several dimensions (pause and speech segment durations, overlaps, etc), finding that his model generally pro-duced a good fit of the data. 2.2 Finite-State Models for Control While Jaffe, Feldstein and Brady were primarily concerned with the analysis of human-human con-versations, more recently, several researchers have proposed finite-state machines to control conversa-tional agents. For instance, Cassell et al. (2001) model the conversational state of an embodied real estate agent as a 5-state machine. Two states indi-cate whether a user is present or not, whereas the other three indicate who holds the floor between the user and the agent, or whether the floor is open. Floor conflicts are not captured by this machine and are presumably resolved through simple rules (e.g. when the user speaks, the agent yields the floor).
Kronild (2006) proposes a much more complex model, based on Harel statecharts, which are an ex-tension of finite-state machines for modeling and vi-sualizing abstract control (Harel, 1987).

Thorisson X  X  Ymir architecture (Thorisson, 2002) is an attempt to model the cognitive processes in-volved in conversation. It features dialog states, cap-turing, for example, who has the floor, and rules that govern the transition from one state to another based on  X  X oolean conditions of perceptual features X .
All these models are deterministic. At any point in time, the agent knows who owns the floor and uses fixed rules to take appropriate actions. These ap-proaches assume 1) that the system can obtain per-fectly reliable information on the state of the world, and 2) that the state itself is unambiguous. 3.1 Extending the 6-state model for control Our model, the Finite-State Turn-Taking Machine (FSTTM), uses the same six states as Jaffe and Feldstein: USER and SY STEM represent states where one and only one of the participants claims the floor, FREE S and FREE U states where no participant claims the floor (following, resp., a SY STEM and USER state), and BOTH S and BOTH U states where both participants claim the floor (following, resp. a SY STEM and USER state). However, we apply this model to the control of a conversational agent, with a goal similar to that of Cassel, Thorisson, and Kronild. One important distinction is that we define the states in terms of the participants X  intentions and obligations (in the sense of Traum and Allen (1994)) rather than the surface level observation of speech vs silence. For example, the state is USER when the user has the obligation to speak (to respond to a system question) or the in-tention to speak, while at the same time, the system does not hold the floor. This does not necessarily mean that the user is speaking, for example at pauses during a user utterance.

As can be seen in Figure 1, not all transitions are valid. First, there is no direct transition between any of the intermediate states (the two FREE states and two BOTH states). The assumption is that to go from any of these state to another, the model will first go to either SY STEM or USER . This is an approximation as there might be cases where, for example, both the system and user start speaking at the exact same time, going from a FREE state to a BOTH state. However these cases are rare enough that they can be approximated using a tran-sition through either SY STEM or USER . Sec-ond, because intermediate states are conditioned on who had the floor previously, not all valid transitions are bidirectional. For example, there is no transi-tion from SY STEM to BOTH U . We associate pairs of user/system actions to each transition. The four possible actions are G rab the floor, R elease the floor, W ait while not claiming the floor, and K eep the floor. For example, transition from SY STEM to
FREE S corresponds to the user waiting silently and the system releasing the floor at the end of a prompt, noted ( R,W ) (we always note the system action first and user action second).

This representation allows us to formalize a wide variety of turn-taking phenomena in a unified frame-work. Specifically, there are 4 types of 2-step transi-tions from a single-floor-holder state ( SY STEM or USER ) to another (or the same) single-floor-holder state, which represent typical turn-taking phenom-ena: Turn transitions with gap are the most common Turn transitions with overlap happen when a par-Failed interruptions happen when a participant Time outs start like transitions with gap but the in-
While all the transitions above were described as deterministic, the actual state of the model is not fully observable. Specifically, while the system knows whether its claiming the floor or not, it can only believe with some degree of uncertainty that the user does so. The system X  X  knowledge of its own claim to the floor splits the state space into two dis-joint subsets. When the system claims the floor, the state can be SY STEM , BOTH S , or BOTH U ) . When the system does not claim the floor, the state can be USER , FREE U , or FREE S ) . In either case, the system needs to recognize the user X  X  in-tention (i.e. whether the user claims to the floor or not) to maintain a probability distribution over the three states. Since the distinction between the two BOTH states (resp. the two FREE states) is based on past history that can be known with a high level of certainty, the uncertainty in state distribution is fully characterized by the probability that the user is claiming the floor, which will have to be estimated from observations, as we will see below. 3.2 Cost of Turn-Taking Actions The problem we are facing is that of choosing the best system action given the system X  X  belief about the current state of the model. That is achieved by applying the probabilistic decision theory principle of selecting the action with lowest expected cost. The actions available to the system are the four de-scribed above ( G , R , K , W ), although not all actions are available in all states. In fact, as can be seen in Table 1, there are always only two actions available in each state, depending on whether the system is claiming the floor or not.
 Each action in each state has a particular cost. While there are many possible ways of defining these costs, we propose a simple cost structure that derives from the principles laid out in Sacks et al. (1974): From this general principle, we derive three rules to drive the design of a cost matrix: 1. The cost of an action that resolves either a gap 2. The cost of an action that creates unwanted gap 3. The cost of an action that maintains a gap or The resulting cost matrix is shown in Table 1, where  X  C S is the cost of interrupting a system prompt  X  C O (  X  ) is the cost of remaining in an overlap  X  C U is the cost of grabbing the floor when the  X  C G (  X  ) is the cost of remaining in a gap that is
This cost structure makes a number of simplifying assumptions and there are many other possible cost matrices. For example, the cost of interrupting the user might vary depending on what has already been said in the utterance, so does the cost of interrupt-ing a system prompt. A more principled approach to setting the costs would be to estimate from per-ceptual experiments or user studies what the impact of remaining in gap or overlap is compared to that of a cut-in or false interruption. However, as a first approximation, the proposed cost structure offers a simple way to take into account some of the con-straints of interaction. 3.3 Decision Theoretic Action Selection Given the state space and the cost matrix given above, the optimal decision at any point in time is the one that yields the lowest expected cost, where the expected cost of action A is: where  X  is the set of states, O are the observable features of the world, and C ( A,S ) is the cost of ac-tion A in state S , from the cost matrix in Table 1. In addition to the cost matrix X  four constants, which we will consider as parameters of the model, it is thus necessary to estimate P ( s = S | O ) , which as seen above amounts to estimate the probability that the user is claiming the floor. Key to applying the FSTTM to a practical turn-taking problem is thus the construction of accurate estimates of the proba-bilities P ( s = S | O ) .  X  ) 0 -- X  ) 0 --4.1 Problem formalization In our FSTTM formalism, endpointing is the prob-lem of selecting between the Wait and the Grab ac-tions during a user utterance. We make the simplify-ing assumption that, once a user utterance has been detected, the only states with non-zero probability are USER and FREE U . While this does not cap-ture cases where the system erroneously detects user speech (because there is, for example, background noise), it represents a working first approximation of the problem.
 The main issue is to estimate the probability P ( s = FREE P ( F | O P ( U | O tures at time t . Given that probability, the expected cost of grabbing the floor is: Similarly, the expected cost of waiting is: The system endpoints whenever the expected cost of grabbing the floor becomes higher than that of waiting.

We consider two separate cases for computing both P ( F | O t ) and C G (  X  ) : when a pause has been detected by the voice activity detector (VAD), and when no pause has been detected (yet). In the fol-lowing sections, we provide details on the approxi-mations and estimation methods for these two cases. 4.2 At pauses If a pause has been detected by the VAD, we set the cost of waiting in the FREE U state to be pro-portional to the duration of the pause so far. If the user has released the floor, the duration of the current pause corresponds to the time spent in the FREE U state, i.e.  X  in the cost matrix of Table 1. In this case, we set C G (  X  ) = C p rule 3 from section 3.2.

We decompose the observations at time t , O t , into observations available at the start of the pause ( O ), and observations made during the pause. With only audio information available, the only information available during the pause is its duration so far, i.e.  X  . Specifically, we know that d  X   X  , where d is the total duration of the pause (with d =  X  at the end of a turn 1 ). Consequently, P ( F | O t ) can be rewritten using Bayes rule as where P ( F | O ) is the probability that the user re-leased the floor without any knowledge of the dura-tion of the pause, and P ( d  X   X  | O ) is the probability that the pause will last at least  X  ms. We further de-compose P ( d  X   X  | O ) into P ( d  X   X  | O ) = P ( d  X   X ,U | O ) + P ( d  X   X ,F | O ) Consequently, P ( F | O t ) is a function of P ( F | O and P ( d  X   X  | O,U ) . We estimate P ( F | O ) by step-wise logistic regression on a training set of pauses labeled for finality (whether the pause is turn-final or turn-internal), using a wide range of features avail-able from various components of the dialog system. Based on the well established observation that pause durations follow an exponential distribution (Jaffe and Feldstein, 1970; Lennes and Anttila, 2002; Raux et al., 2008), P ( d  X   X  | O,U ) is a function of mean pause duration, computed on the training set. 4.3 In speech In some cases, it is not necessary to wait for the VAD to detect a pause to know with high confidence that the user has released the floor. For example, after a simple yes/no question, if the user says  X  X ES X , they are very likely to have released the floor, regardless of how long they remain silent afterwards. In order to exploit this fact and improve the responsiveness of the system in these highly predictable cases, we use a separate model to compute the expected costs of waiting and grabbing the floor before any pause is detected by the VAD (specifically, whenever the du-ration of the current pause is between 0 and 200 ms). In this case, we set the cost of waiting to a constant C P ( F | O duced by the ASR during a user utterance. We use the same set of features as above. 5.1 Corpus and Features We evaluated the effectiveness of the FSTTM on an actual deployed spoken dialog system. The sys-tem provides bus schedule information for a mid-size North American city. It is actually used by the general public and therefore constantly operates and collects data. In order to train the various proba-bility estimation models and evaluate the approach in batch, we first collected a corpus of 586 dialogs between May 4, and May 14, 2008 (the  X 2008 cor-pus X ).

All of the features we used can be automatically extracted at runtime, and most of them were readily available in the system. They include dialog state in-formation, turn-taking features, such as whether the current user utterance is a barge-in, and semantic information derived from the dialog state and par-tial recognition hypotheses provided by the speech recognizer. Dialog state is abstracted to three high-level states, which correspond to the type of system prompt directly preceding the user utterance: Open question ( X  X hat can I do for you? X ); Closed ques-tion (e.g.  X  X here do you want to go? X ); and Confir-mation (e.g.  X  X oing to the airport. Is this correct? X ).
To capture lexical cues correlated with the end of turns, we created a new feature called the boundary LM score. To compute it, we used previously col-lected data to train dialog-state-dependent statistical language models to estimate the probability that the hypothesis is complete. Boundary LM score is de-fined as the ratio of the log likelihood of the hypoth-esis being complete by that of the hypothesis being incomplete. 5.2 Estimating P ( F | O We trained two logistic regression models using stepwise regression and 10-fold cross-validation for evaluation. The first model, whose performance is given in Table 2, estimates P ( F | O ) at pauses. The model is unable to improve classification accu-racy over the majority baseline for each state, how-ever, the statistically significant improvement in av-erage log likelihood indicates that the probability estimates are improved by using the features. The most informative feature in all three states was the boundary LM score introduced in section 5.1. Other selected features included the average number of words per user utterance so far and whether the cur-rent utterance is a barge-in (for the Open and Closed question states), as well as whether the partial hy-pothesis contained a confirmation marker such as  X  X ES X  or  X  X URE X  (for the Confirmation state).
The second model performs the same regression, this time on all partial hypotheses received during speech segments. As seen in the  X  X  X  columns in Ta-ble 2, classification error was significantly reduced and the gain in average log likelihood were larger than at pauses, particularly for the  X  X losed ques-tion X  and  X  X onfirmation X  states. Again, boundary LM score was the most informative feature. The duration of the pause at the end of the partial hy-pothesis (between 0 and 200 ms) also proved well correlated with finality. 5.3 Batch Evaluation of the FSTTM We performed two batch evaluations of the FSTTM. The first one aims at comparing in-pause-FSTTM with a fixed-threshold baseline as well as previous data-driven endpointing methods proposed in Ferrer et al. (2003) (reimplemented by us) and Raux et al. (2008). This evaluation was done on the corpus used in Raux et al. (2008) (the  X 2007 corpus X ). As seen in Figure 2 (a), the FSTTM outperforms all other ap-proaches (albeit only slightly compared to Ferrer et al.), improving over the fixed threshold baseline by up to 29 . 5% .

Second, we compared the anytime-FSTTM with in-pause-FSTTM and a fixed-threshold baseline (for reference) on the more recent 2008 corpus (since the 2007 corpus did not contain all necessary features for anytime-FSTTM). We set C p to either 0 , leading to an endpointer that never end-points during speech (in-pause-FSTTM), or 1000 (anytime-FSTTM). In both cases, we vary C U to compute the latency / cut-in rate trade-off curve. The results are shown in Figure 2 (b). Anytime-FSTTM endpointing is consistently better than in-pause-FSTTM. For example, at a cut-in rate of 5% , anytime-FSTTM yields latencies that are on average 17% shorter than in-pause-FSTTM, and 40% shorter than the baseline. Additionally, we found that, in anytime-FSTTM, 30 to 40% of the turns are end-pointed before the pause is detected by the VAD. 5.4 Live Evaluation To confirm the results of the batch evaluation, we implemented our FSTTM model in the deployed system a let it run for ten days using either FSTTM or a fixed threshold for endpointing, resulting in a corpus of 171 FSTTM and 148 control dialogs. For FSTTM, we set C p C correspond to a cut-in rate of 6 . 3% and an average latency of 320 ms. For the control condition, we set the fixed endpointing threshold to 555 ms, which also corresponded to about 6 . 3% cut-ins.

Figure 3 shows the average latency and cut-in rate for both conditions. The FSTTM improves over the baseline on all metrics, reducing average latency by 193 ms ( p &lt; 0 . 05 ), cut-in rate by 1 . 5% (although this result is not statistically significant). Both batch and live evaluation results confirm the effectiveness of the FSTTM approach in improv-ing system responsiveness. This approach signif-icantly reduced endpointing latency over previous approaches. Boundary LM score got the highest weight in the regression, indicating that in a domain such as telephone-based information access, lexical cues are very informative for endpointing. The fact that boundary LMs can be computed without any hu-man transcription effort (since they are trained on ASR output) makes them all the more appealing.
Essentially, the FSTTM provides a simple, unified model of turn-taking that lends itself to data-driven optimization. While we discussed specific cost structures and probability estimation techniques, the framework X  X  flexibility opens it to other choices at many levels. By formalizing the overall turn-taking process in a probabilistic, decision-theoretic frame-work, the FSTTM extends and generalizes previous classification-based approaches to endpointing such as those proposed by Sato et al. (2002), Ferrer et al. (2003), Takeuchi et al. (2004), and our previous work (Raux et al., 2008).

Possible extensions of the approach include data-driven cost matrices to relax some of the assump-tions introduced in section 3.2, as well as more com-plex state structures to handle, for example, multi-party conversations.

Finally, we plan to investigate more principled ap-proaches, such as Partially Observable Markov De-cision Processes or Dynamic Bayesian Networks, to model the different sources of uncertainty (detection errors and inherent ambiguity) and track the state distribution over time. Raux (2009) provides more details on all aspects of the approach and its possi-ble extensions. In this paper, motivated by existing finite-state mod-els of turn-taking in dyadic conversations, we pro-pose the Finite-State Turn-Taking Machine, an ap-proach to turn-taking that relies on three core ele-ments: a non-deterministic finite-state machine that captures the conversational floor; a cost matrix that models the impact of different system actions in dif-ferent states; and a decision-theoretic action selec-tion mechanism. We describe the application of the FSTTM to the key turn-taking phenomenon of end-of-turn detection. Evaluation both offline and by applying the FSTTM to a deployed spoken dialog system system showed that it performs significantly better than a fixed-threshold baseline.
 This work is supported by the US National Science Foundation under grant number 0208835. Any opin-ions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF. We would like to thank Alan Black for his many comments and advice.
