 Social-networking sites have started to offer tools that suggest  X  X uests X  who should be invited to user-defined social events (e.g., birthday parties, networking events). The problem of how to rec-ommend people to events is similar to the more traditional (recom-mender system) problem of how to recommend events (items) to people (users). Yet, upon Foursquare data of  X  X ho visits what X  in the city of London, we show that a state-of-the-art recommender system does not perform well -mainly because of data sparsity. To fix this problem, we add domain knowledge to the recommendation process. From the complex system literature in human mobility, we learn two insights: 1) there are special individuals (often called power users) who visit many places; and 2) individuals go to a venue not only because they like it but also because they are close-by. We model these insights into two simple models and learn that: 1) simply recommending power users works better than random but is far from producing the best recommendations; 2) an item-based recommender system produces accurate recommendations; and 3) recommending places that are closest to a user X  X  geographic center of interest produces recommendations that are as accurate as, if not more accurate than, item-based recommender X  X . This last result has practical implications as it offers guidelines for designing location-based recommender systems and for partly addressing cold-start situations.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms Advertisements, Mobile, Social Marketing  X 
This work was done while visiting the Computer Laboratory of the University of Cambridge.

Social media sites have been recently testing features that return lists of people ( X  X uests X ) users might want to consider inviting to their events (e.g., law firm parties, birthday parties, PR  X  X  club in-vitations) [5]. Guests are selected based on relevance to the event and to the other fellow guests.

The problem of predicting relevant  X  X uests X  for venues or events has thus started to receive attention on the Web but has not been fully explored on mobile-social media platforms such as Foursquare, as discussed in Section 6 on  X  X elated Work X . One way of recom-mending venues to people is to use existing Web-based collabora-tive filtering algorithms. In Section 2, we show that such algorithms are not effective, mainly because of data sparsity: a venue is visited, on average, by very few users. Therefore, we propose two simple techniques for  X  X ecommending guests X  that are reasonably accurate and scalable, and whose recommendations are easy to explain. In so doing, we make two main contributions:
Before placing this work in the context of relevant literature (Sec-tion 6) and concluding (Section 7), we discuss some open questions (Section 5), including that of when our models do not work (and, consequently, where future work should go). To begin with, we state our research problem.

Problem Statement: Given a venue (e.g., Italian restaurant), select individuals who are likely to visit it.

This simple problem, if solved, might enable a variety of ap-plications, which include target advertising, commercial property evaluation, and social marketing (as we shall discuss in Section 5).
The problem might be formulated in simple  X  X ecommender sys-tem X  terms -that is, it is the problem of how to recommend venues (items) to people (users). One way of solving it is to run a state-of-the-art matrix factorization algorithm on the inverted venue-by-people matrix (whose value m ij is 1, if user j checked-in in venue i ; 0 otherwise) and obtain, for each venue, a list of people who a million US one-dollar bills as a proxy measure and analyzed their mo vements as they were passed around over five years [2]. They found many short movements and occasional longer ones. Similar patterns were found by Gonzalez et al . who studied the trajectories of 100,000 mobile phone users tracked for six months [7]. These researchers found that people are regular, in that, the vast majority of them move around over a very short distance (from 5 to 10km) and make regular trips to the same few destinations such as work and home on a daily basis (70 percent of the time they were found in their two most frequently visited locations); people occasionally make longer trips when they, for example, go on vacation. More recently, Cheng et al. analyzed the movement of Foursquare users across venues and found similar patterns: a mixture of short, ran-dom movements with occasional long jumps. As such, the vast majority of users had a small radius of gyration -typically less than 10 miles [3].
 Considering Geographic Closeness. To sum up, upon different types of movement (derived from dollar bills, mobile phones, and mobile social-networking applications), researchers in different dis-ciplines have independently concluded that people rarely stray from familiar areas -they travel to a limited number of nearby locations and, consequently, short-range movements are more frequent than long-range ones (i.e., the frequency distribution of distance is ex-ponentially distributed). This is also the case in our London data: Figure 2 plots the probability of one X  X  traveling a certain distance for different venue categories. The distributions (for different cate-gories) are very skewed and all fit the same distribution: where d ui is the distance between the user X  X  ( u  X  X ) center of geo-graphic interest -which is center of mass or barycenter computed considering the locations where the user has previously checked-in -and the venue i . Interestingly, different venue categories are associated with different  X  , and the higher  X  , the less distance mat-ters in one X  X  choice when visiting a venue. Table 3 reports the  X   X  X  for the different categories. The highest  X  (2.22) is associated with venues in the category  X  X ravel X : those include train stations and bus stations, and it makes sense that people travel farther when go-ing to places of limited supply (e.g., not all neighborhoods have a train station). The lowest  X   X  X  are registered for venues in the cat-egories  X  X ightlife X  and  X  X ome/work/etc. X . That is, one X  X  center of geographic interest revolves around home and work locations, and when going to bars, one goes to nearby ones.
 Considering Power Users. Another conclusion from the literature is that not all mobile users are equally mobile. Individuals display significant regularity, yet, when compared to each other, there are few users who travel a lot, while the vast majority have limited travel activity. By framing the problem probabilistically, expres-sion (1) is able to account for those special (power) users. It does so with p go in expression (2), which reflects the extent to which one is a power user or not.
The model in expression (1) has only considered whether one user is close or not and whether is a power user or not; but the model has not taken into account personal preferences. To fix that, we need to compute p ( like | go ) -we need to compute the extent to which a user visits venues that are predictable from his/her past visits/likes. However, to do so, we need a way to measures a user X  X  like s. Since our data is sparse (Section 2), we measure likes not Figure 2: Probability of one X  X  traveling a certain distance acr oss different types of venues (best seen in color).
 Table 3: Why People Visit Different Types of Venues. The higher  X  , the more one travels farther than usual to reach the venue in that category. based on similarity among users but among venues. That is, we use an item -based collaborative filtering [21], which has been found to work well in such situations:  X  X nlike traditional collaborative filtering, the algorithm also performs well with limited user data, producing high-quality recommendations based on as few as two or three items. X  [15]. Rather than matching the user to other sim-ilar users, item-to-item collaborative filtering matches each of the user X  X  venues with similar venues. A common way of computing the similarity between two venues is to compute the cosine similar-ity between two binary vectors: each vector reflects a venue, and a vector X  X  i th position reflects whether the i th user visited the venue or not. Upon a so-constructed venue similarity table, the algorithm finds, for each user, the venues similar to the ones previously vis-ited by the user.

We apply the item-based collaborative filtering algorithm on the user -by-venue matrix and obtain a rating l ui for each user u and venue i . Figure 3 shows the distribution of the predicted ratings. Upon these ratings, we compute p ( like = l ui | go ) , which is the fraction of venues i visited by u that have predicted ratings l p ( like = l ui | go ) = #venues visited by user u with rating l
Having users X  whereabouts and preferences at hand, we now need to predict which users are likely to be at a certain venue. We do so using a Naive Bayesian model, a Bayesian model, and a linear regression.
 Naive Bayesian modeling. One simple way of modeling all the three factors together is to compute p ( go | like, close ) using Bayes X  Law: For each pair (user, venue) , we compute p close with expression (3) and p like with (4); and for each user, we compute p go with (2). The importance of venue i for user u is then proportional to the above p ( go | like, close ) , and we call it rank u,i .
 Bayesian modeling. The previous model assumes that whereabouts and preferences are independent. This might well be not the case: those addicted to luxury goods will often be found near Bond Street (a major shopping street in the West End of London with many high price fashion shops). Here preference and whereabout go hand in hand. To go beyond independence, we could model jointly the two attributes: where: p Linear Regression. Another approach for combining preferences and whereabouts is to run a linear regression: where I  X  X  are normalized values of whereabouts and preferences: I tion of distance is very skewed), and I like is l ui . The product I close  X  I like controls for interaction effects between whereabouts and preferences.
The goal of this work is to predict which users are more likely to visit a given venue. To ascertain the effectiveness of our pro-posed techniques at meeting this goal, we need to select a desirable metric, measure it, and interpret those measurements. We execute these three steps next.
 Metric. We need to find a measure that reflects the extent to which the predicted users for a venue are those who actually visited the venue. One such measure is called percentile-ranking [10]. The percentile-ranking rank u,i of user u for venue i ranges from 0% to 100%: it is 0%, if user u is first in venue i  X  X  recommendation list; it is 100%, if the user is last. Percentile-ranks have the advantage over absolute ranks of being independent of the number of users. Our quality measure is then the total average percentile-ranking: where gone u,i is a flag that reflects whether user u was in venue i : it is 0, if u was not there; otherwise, it is 1. The lower rank for a list, the better the list X  X  quality. For random predictions, the expected value for rank u,j is 50% (averaging infinite placements of users for a venue returns the middle position of the list). There-fore, rank &lt; 5 0% indicates an algorithm better than random. To ease illustration, we covert percentile ranking into ranking accu-racy, which is 1, if the percentile ranking is 0% (best); and it is 0, if the percentile ranking is 50% (random):
Accurac y would be 0 for a random predictor (baseline), and would be 1 for an ideal (oracle) predictor.
 Execution. To measure the ranking accuracy, we run a 10-fold cross validation. That is, we divide the dataset into 10 segments, we take one segment s at a time, consider it to be the testing set, and go through the following steps: 1. For each venue in the training set (the venues in all segments other than s ), associate it with the users who visited that venue. 2. Train the model using the venues (and corresponding visitors) in the training set. 3. Use the trained model to then infer a rank list of users who are likely to go to each venue in the testing set (the venues in s ).
We finally compare the users predicted for each venue to those who actually visited it (those who are in the ground truth). Results. Figure 4 reports the ranking precisions for the individ-ual components of the Bayesian models (first three bars in each venue category) and for the overall models (Naive in the fourth bar, Bayesian in the fifth, and Linear Regression in the sixth). Starting from the first bar in each category ( p go ), one sees that recommend-ing power users works better than random (accuracy is always well above zero): the more so for shops (.38) than for arts&amp;entertainment venues (.24). Considering only nearby places (second bar in each set) returns more accurate rankings -again, more for shops (.60) than for arts&amp;entertainment venues (.38). However, if one con-sider only past user preferences (third bar p like ) , then accuracy is mendation list). comparable to that of recommendations based on proximity (sec-ond and third bars do not differ much). This suggests that the simple concept of geographic distance is as important as that of the user X  X  taste in all venue categories. It also suggests that, by only knowing where a user usually hangs out (without any infor-mation on the user X  X  taste), one can produce reasonable recommen-dations (ideal for cold start situations). If we then combine these previous elements in a Naive Bayesian model, results do not im-prove; on the contrary, they are worse than those offered by sim-ple geographic proximity for venues in the categories  X  X ood X  and  X  X rts&amp;entertainment X . That might be because the model treats its components as though they were completely independent. How-ever, on average, the Pearson correlation coefficients  X  between each pairs of components are small:  X  ( p go , p like ) = . 13 , the fifth bar in each set, one registers improvements with the tradi-tional Bayesian model (in which dependencies are model). Another common reason for which Naive Bayesian does not work well in certain situations is that the addition of redundant components and arbitrary discretization of the random variables skew the learning process, and that seems to be the case here. Indeed, the linear re-gression (last bar) -which just models taste, whereabouts, and in-teractions between the two -works best in all categories. As one would expect, for categories characterized by less data sparsity and periodic patterns (e.g., education buildings), the models perform extremely well (accuracy above .90): the performance tend to be comparable to, if not better than, those registered in Web applica-tions. Putting Results into Context. For the case of recommending shows on set top boxes, Hu et al. had 17K of unique programs (roughly 2  X  our number of venues) and 32M non-zero ratings ( 140  X  ours). In that context of less sparsity, they managed to achieve a ranking accuracy as good as .80 (upon learning from 200 distinct factors). Thus our results with the linear regression (always above .50 and above .60 for categories such as  X  X hops X  and  X  X arks X  and  X  X ravel X ) are comparable to those reported in the literature in far more favorable contexts ( 140  X  less sparsity). Also, the percentile rankings are expected to slightly improve in more  X  X ealistic X  situa-tions. To see why, consider that our data has been collected within a limited time window; by contrast, if one were to crawl the entire Foursquare history, then the resulting data would be still sparse but less so, and, as such, the prediction results would improve, as we have already registered with the category  X  X ducational X  venues for which the accuracy was above . 90 .
 When It Does not Work. When putting forward new predictive models, one often tends to focus on favorable situations in which predictions are best. Next, we briefly focus on the opposite case -we focus on situations in which prediction are worst. The idea be-hind this exercise is to find out which aspects future models should consider to increase accuracy. To this end, we run a qualitative study. For each venue i , we compute four predictability and unpre-dictability measures upon the following quantities: gone ui reflects whether user u visited venue i ; the geographic decay con-stant  X  taken from Table 3; the predicted rating l ui for user u and venue i ; and the distance d ui between u  X  X  geographic center of in-terest and venue i . More specifically, upon these quantities, for each venue i , we compute:
Geo Predictability. The higher it is, the more the venue X  X  visitors
Geo Unpredictability. The higher it is, the less its visitors are which are based on visitors X  geographic closeness (rows) and likes (columns).
Like Predictability. The higher it is, the more its visitors are pre-
Like Unpredictability. The higher it is, the less its visitors are
We create four tables that contain the top -10 venues ranked by each of those four measures and ask three coders (three London-ers with diverse background -architect, barrister, and medical doc-tor) to build predictability boxes of the kind in Figure 5(a). For them, that translated into ordering venue categories that are pre-dicted (hard to predict) by geographic distance based on the table ranked by P i geo (by U i geo ), and categories that are predicted (hard to predict) by user preferences based on the table ranked by P (by U i like ). We consider only the answers for which two out of three coders or all three have independently agreed. In Figures 5(b) and 5(c), word size is proportional to the coders X  agreement. For all venue categories (Figure 5(b)), the unpredictable venues (pre-dicted neither by closeness nor by taste) are train stations. That is because train stations are often far from where one hangs out and do not reflect a specific taste in, say, music, bars, clubs, or food. By contrast, local parks and outdoor activities are predictable ei-ther by closeness or by taste, suggesting that people prefer their local parks over bigger parks (they stay close), and that residents of the same area tend to be like-minded (a tendency often called  X  X e-ographic sorting X  [1]). Closeness is more informative for predict-ing visits to coffee shops (one tends to go to local coffee shops); while user taste is more informative for cinemas in central Lon-don areas, where diversified choice of movies motivates visitors to travel farther than usual. For the specific category  X  X uildings X  (Fig-ure 5(c)), the unpredictable venues (predicted neither by closeness nor by taste) are companies such as IBM, Procter&amp;Gamble, Sam-sung whose headquarters are in suburban areas where people with diverse background work but do not hangout, not least because of limited supply of amenities. By contrast, the behavior of employees (mostly interaction designers) of Sony, eBay, Telehouse working in central areas like Soho is predictable either by closeness or by taste. Finally, closeness is more informative for predicting visits to mosques and churches (one tends to go to local religious venues); while user taste is more informative for visitors of university (e.g., UCL X  X , Birkbeck X  X ) facilities in central areas. From these qualita-tive results, one can extrapolate two key insights: 1. Predictable situations are those in which people: a) stay close 2. By contrast, unpredictable situations are those in which peo-Future work should go into models that are able to simultaneously account for these (at times) conflicting situations.
 Applications. The practical implications of this work go beyond traditional applications of recommender systems:
Target Advertising. The first step when promoting new nightclubs,
Commercial Property Evaluation . This is the process of identify-
Social Marketing . Social marketing can be defined as a research-Scalability. The two main parts of this work -which model where-abouts and preferences -are highly scalable:
Whereabout Part. This requires to know a geographic point for
Preference Part. This translates into item-based collaborative fil-
The problem of recommending events has been initially tackled on the Web. In this context, researchers have mainly worked on de-tecting and tracking events [11, 13]. They initially considered how textual content evolves over time and left out network effects. Zhu and Sasha then started to model social interactions and topic evolu-tions by treating these two elements separately [26]. More recently, Lin et al. built a model that considers these two elements simulta-neously and showed that it worked upon two very different types of data -Twitter and DBLP [14]. After detecting events, one can then recommend them. That is what Daly and Geyer et al. did: they built a system that recommends events in an internal event man-agement service and proposed a new way of recommending events to new users [4]. Before that, Minkov et al. had run large user studies in which they evaluated the effectiveness of different strate-gies for recommending academic talks [16]. They found that, in a situation of limited data sparsity, collaborative filtering approaches work better than content-based ones. The recommendation process generally relies on user ratings but has also been enriched by social networks at times. A case in point is Golbeck et al. who built a recommender system that integrates social networks to offer well-informed movie recommendations [6].
 Hence past work on recommending events has mostly gone into Web platforms, while mobile ones have been investigated only re-cently. Takeuchi and Sugimoto proposed a system that recom-mends shops based on past visited locations, and found item-based collaborative filtering to work reasonably well [23]. Ricci and Nguyen proposed a system that recommend nearby restaurants using a critique-based model [20]. More recently, for major mobile social-networking services, Scellato et al. studied their geographic properties at scale and suggested that these properties could well inform venue rec-ommendation in large cities [22]. Upon mobile phone data in the metropolitan area of Boston, Quercia et al. studied strategies for recommending large-scale events (e.g., concerts, baseball matches) and showed how different types of events require different recom-mendation strategies [19].

Shifting attention from recommending events to recommending people, one sees that most of the work has again gone into Web platforms. Within an enterprise social network, Guy et al. pro-posed ways to recommend people a user is not likely to know but might be interested in [9]. Few months ago, Facebook launched a new feature called  X  X uggested guests X  [5]: this returns a list of people (three at the time) a user might want to consider inviting to their event, and the list is compiled based on relevance to the event and to the people who are attending. Since work on recom-mending people for events has just started on the Web, it comes as no surprise that little work about it has gone into mobile social-networking platforms.
We have studied different strategies for recommending  X  X uests X  for real-world venues and, not surprisingly, found that results are best not only for venues with considerable historical data (e.g., ed-ucational institutions) but also for venues that are visited regularly (e.g., work locations). For other types of venues such as restaurants and bars, geographic closeness plays a very important role. Com-bining user preferences and geographic closeness has the expected result of offering more accurate recommendations, and that result can be achieved by using very simple models -Bayesian or linear regression. Being simple, these models not only are scalable and cost efficient but also produce recommendations that are easy to ex-plain. The main criticism for the new Facebook  X  X uggested guests X  feature has been that it  X  X oes not offer. . . any sort of context X  [5]. Our recommendations -which depend on whether one has visited similar locations or whether one often hangs out in certain neigh-borhoods -are likely to be easier to explain than those produced by black-box approaches. In the future, we will work in this direction: on how to recommend  X  X uests X  in ways that are easy to explain and that increase serendipitous encounters [25].
 Acknowledgments. We thank Tamas Jambor for his help on the Implicit SDV algorithm and his valuable insights, and the reviewers for their constructive comments. This work was funded by RCUK through the Horizon Digital Economy Research grant (EP/G065802/1) and by the Spanish Economy and Competitiveness Ministry through the HIPERGRAPH project (TIN2009-14560-C03-01). [1] B. Bishop. The Big Sort: Why the Clustering of Like-Minded [2] Brockmann, L. Hufnagel, and T. Geisel. The scaling laws of [3] Z. Cheng, J. Caverlee, K. Lee, and D. Z. Sui. Exploring [4] E. M. Daly and W. Geyer. Effective event discovery: using [5] B. Darwell. Facebook tests  X  X uggested guests X  for events. In [6] J. Golbeck. Trust and nuanced profile similarity in online [7] M. C. Gonzalez, C. A. Hidalgo, and A.-L. Barabasi.
 [8] S. Grier and C. A. Bryant. Social marketing in public health. [9] I. Guy, S. Ur, I. Ronen, A. Perer, and M. Jacovi. Do you want [10] Y. Hu, Y. Koren, and C. Volinsky. Collaborative Filtering for [11] A. Ihler, J. Hutchins, and P. Smyth. Adaptive event detection [12] K. L. Keller. Branding perspectives on social marketing. [13] J. Kleinberg. Bursty and hierarchical structure in streams. In [14] C. X. Lin, B. Zhao, Q. Mei, and J. Han. PET: a statistical [15] G. Linden, B. Smith, and J. York. Amazon.com [16] E. Minkov, B. Charrow, J. Ledlie, S. Teller, and T. Jaakkola. [17] A. Plant, J. A. Montoya, H. Rotblatt, P. R. Kerndt, K. L. [18] D. Quercia, H. Askham, and J. Crowcroft. TweetLDA: [19] D. Quercia, N. Lathia, F. Calabrese, G. D. Lorenzo, and [20] F. Ricci and Q. N. Nguyen. Acquiring and Revising [21] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based [22] S. Scellato, A. Noulas, R. Lambiotte, and C. Mascolo. [23] Y. Takeuchi and M. Sugimoto. CityVoyager: An Outdoor [24] D. C. Walsh, R. E. Rudd, B. A. Moeykens, and T. W.
 [25] Y. C. Zhang, D. O. S X aghdha, D. Quercia, and T. Jambor. [26] D. Zhou, X. Ji, H. Zha, and C. L. Giles. Topic evolution and
