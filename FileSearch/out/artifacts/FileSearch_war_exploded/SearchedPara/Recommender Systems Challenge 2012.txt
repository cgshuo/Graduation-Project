 The Recommender System Challenge 2012 invited partici-pants to work on two tracks with real-world datasets and to submit their contributions that would be related to spe-cific problem contexts. First of all, it asked participants to develop new algorithms and to compare them to other al-gorithms in given settings; in addition, it asked participants to explore with new recommendation methods, services, as well as added-value services related to recommendation. D.2.8 [ Software Engineering ]: Metrics -complexity mea-sures, performance measures; H.3.3 [ Information Storage and Retrieval ]: Information search and retrieval -infor-mation filtering, relevance feedback; H.3.4 [ Information Technology and Systems Applications ]: Decision sup-port; H.3.5 [ Online Information Services ]: Data Shar-ing; H.5.1 [ Multimedia Information Systems ]: Evalua-tion/methodology Algorithms, Design, Experimentation, Human Factors, Measurement Recommender Systems, dataset, challenge, competition, context-aware, scientific paper recommendation able, with information related to concepts from the world of cinema, e.g. single movies, movie universes (such as the world of Harry Potter movies), upcoming details (trailers, teasers, news, etc).

At the end of the challenge, a live evaluation session took place during which participants demonstrated how al-gorithms trained on offline data where evaluated online, on real users. The aim of this track was to find the right audi-ence for a given movie. This movie has not necessarily been released already (as it might be in production), so the over-all goal is to generate a large impact on the recommended item in terms of interaction in the social networks of those users to whom the movies are recommended. The aim of the hands on session was to expose participants into the types of information that they would be expecting to handle when working on such systems, as well as bring them in direct contact with the technical team of a deployed service where recommendation is core.
This track focused on recommendations to users about scientific papers that they might be interested in, using a data set that comes from the Mendeley system 1 . The aim was to share recommendation approaches and discuss issues like:
Submissions used the already published Mendeley dataset [2] which came out after the 1st DataTEL Challenge of the 2010 Workshop on Recommender Systems in Technology Enhanced Learning (RecSysTEL) [3]. The Track asked par-ticipants to use and evaluate their approaches in an off-line manner, as well as invited them to propose their approaches for relevant services, navigational interfaces, visualizations of recommendations etc. Thus it welcomed submissions that combined the data set with the Mendeley API 2 .

During the interactive part of the workshop, participants had the opportunity to discuss with the Mendeley technical team about ways in which their ideas and proposals could be incorporated into a large-scale real-world system like Mende-ley, and get insight into the way that such systems are being maintained and extended in the industry. The Recommender Systems Challenge 2012 took place on September 13 th , 2012, as a full day workshop that included sessions both focusing on algorithmic evaluations as well as hands-on experience with real datasets, APIs, recommender systems software and systems.
The involvement of Nikos Manouselis has been carried out with European Commission funding support and, more specifically, the FP7 agINFRA project 3 . http://www.mendeley.com http://dev.mendeley.com http://www.aginfra.eu
