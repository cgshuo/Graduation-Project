 In many computer aided diagnosis applications, the goal is to detect potentially malignant t umors and lesions in medical images (CT scans, X-ray, MRI etc). In a n almost universal paradigm for CAD algorithms, this problem is addressed by a 3 stage system: id entification of potentially unhealthy candidate, and labeling of each candidate ( e.g. as normal or diseased) by a classifier. The training out tumors. Then, candidate ROIs (with associated computed features) are marked positive if they are sufficiently close to a radiologist mark, and negative ot herwise. Many CAD datasets have fewer than 1-10% positive candidates. In the CAD literature, stan dard machine learning algorithms X  X uch as support vector machines (SVM), and Fisher X  X  linear discriminant  X  X ave been employed to train the classifier. In Section 2 we show that CAD data is better mod eled in the multiple instance learning (MIL) framework, and subsequently present a novel convex-h ull-based MIL algorithm. In Section 3 we provide experimental evidence from two different CAD pro blems to show that the proposed algorithm is significantly faster than other MIL algorithms , and more accurate when compared to other MIL algorithms and to traditional classifiers. Furthe r X  X lthough this is not the main focus of our paper X  X n traditional benchmarks for MIL, our algorithm is again shown to be competitive with the current state-of-the-art. We conclude with a descripti on of the relationship to previous work, review of our contributions, and directions for future rese arch in Section 4. dates) are drawn identically and independently from an underlying X  X hough unknown X  X istribution. This property is clearly violated in a CAD dataset, due to spa tial adjacency of the regions identi-fied by a candidate generator, both the features and the class labels of several adjacent candidates (training instances) are highly correlated. First, becaus e the candidate generators for CAD problems are trying to identify potentially suspicious regions, the y tend to produce many candidates that are spatially close to each other; since these often refer to reg ions that are physically adjacent in an image, the class labels for these candidates are also highly correlated. Second, because candidates are labelled positive if they are within some pre-determine d distance from a radiologist mark, mul-tiple positive candidates could correspond with the same (p ositive) radiologist mark on the image. happen to be near a mark, thereby introducing an asymmetric l abeling error in the training data. In MIL terminology from previous literature, a  X  X ag X  may con tain many observation instances of the same underlying entity, and every training bag is provid ed a class label ( e.g. positive or nega-every bag. This corresponds perfectly with the the appropri ate measure of accuracy for evaluating ing malignant structure (radiologist mark) is correctly hi ghlighted to the radiologist, the malignant as the ability to detect at least one candidate that points to a malignant region. Furthermore, w e would like to classify every sample that is distant from radi ologist mark as negative, this is easily accomplished by considering each negative candidate as a ba g. Therefore, it would appear that MIL algorithms should outperform traditional classifiers on CA D datasets.
 Unfortunately, in practice, most of the conventional MIL al gorithms are computationally quite in-efficient, and some of them have problems with local minima. I n CAD we typically have several thousand mostly negative candidates (instances), and a few hundred positive bags; existing MIL algorithms are simply unable to handle such large datasets d ue to time or memory requirements. Notation: Let the i -th bag of class j be represented by the matrix B i the bag i in class j with l = 1 , . . . , m i The vector e represent a vector with all its elements one. 2.1 Key idea: Relaxation of MIL via Convex-Hulls The original MIL problem requires at least one of the samples in a bag to be correctly labeled by the toy example. This relaxation, (first introduced in [1]) elim inates the combinatorial nature of the MIL problem, allowing algorithms that are more computationall y efficient. As mentioned above, we will consider that a bag B i any convex combination of points of B i vector containing the coefficients of the convex combinatio n that defines the representative point of bag i in class j . Let r be the total number of representative points, i.e. r = r total number of convex hull coefficients corresponding to th e representative points in class j , i.e.  X  j = P Where  X  = {  X  is a vector containing all the  X  i function,  X  :  X  ( n +1)  X  X  X  is a regularization function on the hyperplane coefficients [2] and  X  is a regularization function on the convex combination coeffic ients  X  i E,  X  ,  X  and  X  , (1) will lead to MIL versions of several well-known classifi cation algorithms. Figure 1: A toy example illustrating the proposed approach. Positive and negative classes are repre-sented by blue circles and red diamonds respectively. Cyan p olyhedrons represent the convex hulls for the three positives bags, the points chosen by our algori thm to represent each bag is shown by blue stars. The magenta line represents the linear hyperpla ne obtained by our algorithm and the black line represents the hyperplane for the SVM. As an example, we derive a special case of the algorithm for th e Fisher X  X  Discriminant, because this choice (FD) brings us some algorithmic as well as computatio nal advantages. 2.2 Convex-Hull MIL for Fisher X  X  Linear Discriminant Setting  X  = 1 , E (  X  ) = k  X  k 2 version of the quadratic programming algorithm for Fisher X  s Linear Discriminant [4]. The number of variables to be optimized in (2) is r + n +1+  X  : this is computationally infeasible when This substitution eliminates the variables  X ,  X  from the problem and also the corresponding r equality constraints in (2). Effectively, this results in the MIL ver sion of the traditional FD algorithm. As in some algorithmic advantages as well (For more informatio n on the equivalence between the single instance learning versions of (2) and (3) see [4]). Thus, the optimization problem reduces to: where S is the mean for class j . X dimensional space such that the row of X i in class j where i = { 1 , . . . , r 2.3 Alternate Optimization for Convex-Hull MIL Fisher X  X  Di scriminant The proposed mathematical program (3) can be solved used an e fficient Alternate Optimization (AO) algorithm [5]. In the AO setting the main optimization p roblem is subdivided in two smaller or easier subproblems that depend on disjoints subsets of th e original variables. When  X ( w ) and  X (  X  ) are strongly convex functions, both the original objective function and the two subproblems (for optimizing  X  and w ) in (3) are strongly convex, meaning that the algorithm conv erges to a global minimizer [6]. For computational efficiency, in the r emainder of the paper we will use the regularizers  X ( w ) =  X  k w k 2 efficient AO algorithm for solving the mathematical program (3) is described below.
 Sub Problem 1: Fix  X  =  X   X  : When we fix  X  =  X   X  , the problem becomes, which is the formulation for the Fisher X  X  Discriminant. Sin ce S matrices, it is guaranteed to be at least positive semidefini te and thus the problem in (4) is convex. For datasets with r &gt;&gt; n , i.e. the number of bags is much greater than the number of dim en-sionality, S the number of constraints is proportional to the number of ba gs, eliminating  X  and  X  leaves us with computational advantages when dealing with datasets with r &gt;&gt; n .
 Sub Problem 2: Fix w = w  X  : When we fix w = w  X  , the problem becomes where  X  S containing the r vector with its nonzero elements set to B i P P matrices, it is positive semidefinite and thus the problem in (5) is convex. Unlike sub problem 1 the positive definiteness of  X  S complexity of (5) is O ( n X  2 ) .
 As it was mentioned before, in CAD applications, a bag is defin ed as a set of candidates that are cation is considered negative in the training data, therefo re the concept of bag for negative examples does not make any practical sense in this scenario. Moreover , since ground truth is only available on The learned classifier labels (ie classifies) individual ins tances -the bag information for positive examples is only used to help learn a better classifier from th e training data. Hence, the problem in (5) can be simplified to account for these practical observat ions resulting in an optimization problem with O ( n X  2 2.4 CH-FD: An Algorithm for Learning Convex Hull Representa tion of Multiple Instances The nonlinear version of the proposed algorithm can be obtai ned by first transforming the original datapoints to a kernel space spanned by all datapoints throu gh a kernel operator, i.e. K :  X  n  X  X  X   X   X  and then by optimizing (4) and (5) in this new space. Ideally  X   X  is set to  X  . However when  X  is large, for computational reasons we can use the technique pr esented in [7] to limit the number of datapoints spanning this new space. This corresponds to con straining w to lie in a subspace of the kernel space. For the experiments in section 3.1 , we compare four techniqu es: naive Fisher X  X  Discriminnat (FD), CH-FD, EM-DD [8], IDAPR [9]. For IDAPR and EM-DD we used the Ma tlab implementation of these algorithms also used in [10]. In both experiments we us ed the linear version of our algorithm. Hence the only parameter that requires tuning is  X  which is tuned to optimize the 10-fold Patient tested on the sequestered test data. The resulting Receiver Operating Characteristics (ROC) plots are obtained by trying different values of the parameters (  X ,  X  ) for IDAPR, and by thresholding the corresponding output for each of the EM-DD, FD and CH-FD. 3.1 Two CAD Datasets: Pulmonary Embolism &amp; Colon Cancer Dete ction Next, we present the problems that mainly motivated this wor k. Pulmonary embolism (PE), a po-tentially life-threatening condition, is a result of under lying venous thromboembolic disease. An early and accurate diagnosis is the key to survival. Compute d tomography angiography (CTA) has emerged as an accurate diagnostic tool for PE, and However, t here are hundreds of CT slices in each CTA study and manual reading is laborious, time consuming an d complicated by various PE look-alikes. Several CAD systems are being developed to assist ra diologists to detect and characterize emboli [11], [12]. At four different hospitals (two North Am erican sites and two European sites), we collected 72 cases with 242 PE bags comprised of 1069 posit ive candidates marked by expert chest radiologists. The cases were randomly divided into tw o sets: training (48 cases with 173 PE bags and 3655 candidates) and testing (24 cases with 69 PE bag s and 1857 candidates). The test group was sequestered and only used to evaluate the performa nce of the final system. A combined total of 70 features are extracted for each candidate.
 Colorectal cancer is the third most common cancer in both men and women. It is estimated that in 2004, nearly 147,000 cases of colon and rectal cancer will be diagnosed in the US, and more than 56,730 people would die from colon cancer [13]. CT colonogra phy is emerging as a new procedure to help in early detection of colon polyps. However, reading through a large CT dataset, which typically consists of two CT series of the patient in prone an d supine positions, each with several hundred slices, is time-consuming. Colon CAD [14] can play a critical role to help the radiologist avoid the missing of colon polyps. Most polyps, therefore, a re represented by two candidates; one obtained from the prone view and the other one from the supine view. Moreover, for large polyps, a typical candidate generation algorithm generates severa l candidates across the polyp surface. The database of high-resolution CT images used in this study wer e obtained from seven different sites across US, Europe and Asia. The 188 patients were randomly pa rtitioned into two groups, training comprised of: 65 cases with 127 volumes, 50 polyps bags (179 p ositive candidates) were identified in this set with a total number of 6569 negative candidates an d testing comprised of 123 patients with 237 volumes, a total of 103 polyp bags (232 positive cand idates) were identified in this set with a total number of 12752 negative candidates. The test gr oup was sequestered and only used to evaluate the performance of the final system. A total of 75 fea tures are extracted for each candidate. The resulting Receiver Operating Characteristics (ROC) cu rves are displayed in Figure 2. Although for the PE dataset Figure 2 (left) IDAPR crosses over CH-FD an d is more sensitive than CH-FD for extremely high number of false positives, Table 1 show that C H-FD is more accurate than all other methods over the entire space (AUC). Note that CAD performan ce is only valid in the clinically acceptable range, &lt; 10 fp/patient for PE, &lt; 5 fp/volume for Colon (generally there are 2 volumes per patient). In the region of clinical interest (AUC-RCI), Table 1 shows that CH-FD significantly outperforms all other methods.
 Table 1: Comparison of 3 MIL and one traditional algorithms: Computation time, AUC, and nor-malized AUC in the region of clinical interest for PE and Colo n test data Execution times for all the methods tested are shown in Table 1. As expected, the computational cost is the cheapest for the traditional non-MIL based FD. Am ong MIL algorithms, for the PE data, CH-FD was roughly 2-times and 9-times as fast than IAPR and EM DD respectively, and for the much larger colon dataset was roughly 85-times and 2000-tim es faster, respectively(see Table 1). 3.2 Experiments on Benchmark Datasets We compare CH-FD with several state-of-the-art MIL algorit hms on 5 benchmark MIL datasets: 2 Musk datasets [9] and 3 Image Annotation datasets [15]. Eac h of these datasets contain both positive and negative bags. CH-FD (and MICA) use just the pos itive bag information and ignore the negative bag information, in effect, treating each negativ e instance as a separate bag. All the other MIL algorithms use both the positive and negative bag inform ation.
 molecules. Each feature vector has 166 features. The goal is to differentiate molecules that smell  X  X usky X  from the rest of the molecules. Approximately half o f the molecules are known to smell musky. There are two musk datasets. MUSK1 contains 92 molecu les with a total of 476 instances. MUSK2 contains 102 molecules with a total of 6598 instances. 72 of the molecules are shared between two datasets but MUSK2 dataset contain more instanc es for the shared molecules. The Image Annotation data is composed of three different cat egories, namely Tiger , Elephant , Fox . Each dataset has 100 positive bags and 100 negative bags.
 (RBF) kernel K ( x the datapoints in MUSK1 dataset and a subset of the datapoint s in MUSK2 dataset (one tenth of the original training set is randomly selected for this purp ose). The width of the kernel function and  X  are tuned over a discrete set of five values each to optimize th e 10-fold Cross Validation performance. For the Image Annotation data we use the linear version of our algorithm. We follow the benchmark experiment design and report average accurac y of 10 runs of 10-fold Cross Validation Table 2: Average accuracy on Benchmark Datasets. The number in parenthesis represents the rela-tive rank of each of the algorithms (performance-wise) in th e corresponding dataset table. Iterated Discriminant APR (IAPR), Diverse Density ( DD) [16], Expectation-Maximization Diverse Density (EM-DD) [8], Maximum Bag Margin Formulatio n of SVM (mi-SVM, MI-SVM) [15], Multi Instance Neural Networks (MI-NN) [17] are the te chniques considered in this experiment for comparison purposes. Results for mi-SVM, MI-SVM and EM-DD are taken from [15].
 Table 2 shows that CH-FD is comparable to other techniques on all datasets, even though it ignores the negative bag information. Furthermore, CH-FD appears t o be the most stable of the algorithms, at least on these 5 datasets, achieving the most consistent p erformance as indicated by the  X  X ver-age Rank X  column. We believe that this stable behavior of our algorithm is due in part because it converges to global solutions avoiding the local minima pro blem. Relationship to previous literature on MIL: The Multiple Instance Learning problem described in in this paper to represent each bag is similar in nature to the one presented in [1]. However in contrast with [1] and many other approaches in the literatur e [9, 15, 17] our formulation leads to a strongly convex minimization problem that converges to a un ique minimizer. Since our algorithm considers each negative instance as an individual bag, it is complexity is square proportional to the number of positive instances only which makes it scalable to large datasets with large number of negative examples.
 Principal contributions of the paper: This paper makes three principal contributions. First, we have identified the need for multiple-instance learning in C AD applications and described the spa-Second, building on an intuitive convex-relaxation of the o riginal MIL problem, this paper presents a new approach to multiple-instance learning. In particula r, we dramatically improve the run time classified) with infinite but continuous sets of constraints (at least one convex combination of the ing convexity in the objective function of the training algo rithm alleviates the problems of local maxima that occurs in some of the previous MIL algorithms, an d often improves the classification accuracy on many practical datasets. Third, we present a pra ctical implementation of this idea in the form of a simple but efficient alternate-optimization al gorithm for Convex Hull based Fisher X  X  Discriminant. In our benchmark experiments, the resulting algorithm achieves accuracy that is com-of magnitude speed ups were observed).
 Related work: Note that as the distance between candidate ROI increases, t he correlations between their features and labels decreases. In another study, we mo del the spatial-correlation among neigh-boring samples. Thus we jointly classify entire batches of c orrelated samples both during training and testing. Instead of classifying each sample independen tly, we use this spatial information along with the features of each candidate to simultaneously class ify all the candidate ROIs for a single patient/volume in a joint operation [18].

