 1. Introduction
With rapid development of Internet technology, professionals in a community of practice can commu-nicate with each other via the Internet regardless of geographical distance. The virtual community enabled by the World Wide Web (WWW) facilitates knowledge sharing and creation for communities of practice. If knowledge objects reside in an organizational information system, the managerial authority can direct the knowledge sharing process including organization knowledge categorization. However, a virtual commu-nity with people from different organizations usually lacks such managerial authority. Therefore, the knowledge sharing process in a virtual community needs more technical support to deal with the asynchro-nous addition of knowledge objects and maintain a consistent knowledge structure.

In general, there are two types of knowledge: explicit and tacit knowledge. Knowledge creation and transfer is a spiral process of interactions between explicit and tacit knowledge through socialization, exter-nalization, combination, and internalization ( Nonaka, 1994 ). Organizational knowledge creation may start from the individual level via the collective (group) level to the organizational level, and sometimes reach out to the inter-organizational level. The inter-organizational learning process facilitated by a virtual commu-nity information system constructs distributed explicit knowledge, and weaves the social networks to con-nect tacit knowledge owned by individuals across organizations. Knowledge objects can be text or hypertext to archive explicit knowledge. In the Internet era, explicit knowledge exists generally in hypertexts on the Web or texts on the Intranet, which we view them as documents in this study. In order to shorten the learning cycle, an individual can exploit the experience of others to enlarge his or her experiences, which can be carried out by sharing explicit knowledge on the Internet. Besides, well-structured knowledge objects reveal the relationship among knowledge, and reduce information overloading on knowledge sharing and creation ( Chou &amp; Lin, 1998 ; Paolucci, 1998 ).
 Learning in virtual communities can be facilitated by the transactive memory system ( Lin &amp; Lin, 2001 ).
A transactive memory system consists of three components: knowledge map, social network, and mne-monic functions. A knowledge map is represented by knowledge objects and their dependencies. A social network is formulated by individuals, their relationship, and the strength of the relationship. Mnemonic functions include knowledge allocation, social network updating, knowledge maintenance, and collabora-tive knowledge retrieval ( Lin &amp; Lin, 2001 ). Therefore, it is important to develop the knowledge map man-agement system to organize knowledge objects in order to facilitate learning in virtual communities.
This study proposes the framework of knowledge map management system to perform knowledge nav-igation, search, and advisory learning, and develops knowledge map creation and maintenance methods to facilitate knowledge map management. We demonstrate knowledge map creation and maintenance meth-ods in two communities: the teachers  X  professional community, called SCTNet ( http://sctnet.edu.tw )and the thesis repository at the National Central Library.

Section 2 introduces existing related techniques used for knowledge map management. In Section 3, we propose the framework of the knowledge map system and elaborate its operations. The knowledge map creation and maintenance functions with the information retrieval and clustering techniques is explained in Sections 4 and 5, respectively. In Section 6, we evaluate the performance of these knowledge map man-agement functions. Section 7 concludes this study. 2. Existing techniques used for knowledge map management
A knowledge map has been viewed by various perspectives in literatures emphasizing decision-making, education, or information retrieval. For decision-making, a knowledge map is a method designed not only to elicit the knowledge that a decision maker faces, but also to combine probabilities associated with var-the relation of casual or influent relationship of decision-making. Meanwhile, knowledge map creation for the education domain emphasizes knowledge taxonomy. In the teaching X  X earning process, a teacher teaches learners what knowledge is and how knowledge relates one to another. Much research in the education do-map ( Chou &amp; Lin, 1998 ; Paolucci, 1998 ). In the information retrieval and text mining fields, a knowledge map denotes the document category with concept hierarchy ( Sebastiani, 2002 ; Steinbach, Karypis, &amp;
Kumar, 2000 ). The term concept map, sometimes, is used with knowledge map interchangeably in a variety of domains. In practice, for example, a concept map tool for educational applications, called Mindmapper ( http://www.mindmapper.com ) can construct knowledge structure of a subject domain; for the knowledge management application, Semiomap ( http://www.semio.com ) can connect concepts extracted from organi-zational documents. Although Semiomap also generates knowledge structure from document sets as the proposed system in this study does, it is encapsulated as a proprietary system. This study presents a system-atic way to incrementally update the knowledge structure while Semiomap lacks of such capability. In this research, a knowledge map is defined as a concept hierarchy characterizing the taxonomy of documents contributed by members of a community of practice. These concepts are denoted by key terms elicited from documents. The links of various concepts retrieved by community members indicate the learning paths which can be used for guiding others  X  knowledge acquisition processes. In fact, in a knowledge map, doc-ument categories are built explicitly to represent concept hierarchy, and learning paths, traversed implicitly, are associated with the specific problem solving process.

To handle documents uploaded incrementally without pre-specified categories, we need techniques from information retrieval and document clustering to create and maintain the structure of these documents. In this study, since those communities of practices we can access use Chinese, the information retrieval tech-niques should be capable of extracting keywords from Chinese documents. The following subsections over-view these available techniques. 2.1. Information retrieval Information retrieval techniques can be used for extracting essential concepts representing documents.
Since documents implicitly denote unstructured or semi-structured text, information retrieval has been developed for transforming unstructured text to structured data over twenty years. Although the informa-tion retrieval development of western languages has gradually matured, the research of information retrie-val from Chinese documents still has many difficulties in morphological, syntactic, and semantic levels ( Wong &amp; Li, 1998 ). To transform unstructured Chinese document to structured data for eliciting key terms, techniques such as word segmentation , text indexing , and term weighting have been adopted.
Word segmentation is used for eliciting words from the text. In English text, words are separated by spaces or terminators, such as comma, quotation mark, period, et cetera. However, in Chinese text, a word can be composed of more than one Chinese character, and there are no specific terminators to enclose char-acters as a word. For example, in the sentence  X  X  X he teacher is telling the story of discovering DNA  X  s struc-ture in 1953. X  X  each word is separated by spaces before and after it. In the translation of this sentence to
Chinese, 1953 . The word,  X  X   X  X , six Chinese characters, represents  X  X  X NA X  X , an acronym to denote Deoxyribose Nucleic Acid. To generate accurate ton, 1989 ; Wu &amp; Tseng, 1993 ). Prior research of word segmentation is summarized into three categories: dictionary , linguistic , and statistical approaches.

The dictionary approach is known to utilize the dictionary to match the lexicons of sentences in each article. The major advantages of this approach are its execution efficiency and ease to implement. Some systems are still using this approach, especially when lexicons in the target articles do not consist of new words ( Chien, 1997 ; Li &amp; Xing, 1998 ).
 The linguistic approach uses semantic knowledge bases, heuristics, or rules to extract lexicons ( Wu &amp;
Tseng, 1995 ). The Chinese knowledge information processing (CKIP) project in Academia Sinica proposes the Chinese parser to facilitate word segmentation and provides not only the functionality of word segmen-tation but also the morphological information of each word ( http://ckip.iis.sinica.edu.tw/CKIP/ ).
In statistics, a word segment is determined by calculating the mutual information (MI) of two constit-uent characters called fragments. The higher the MI value of two fragments is, the higher inclination these two fragments are going to be treated as a word ( Yang, Yen, Yung, &amp; Chung, 1998 ). MI is defined as where f ( c i ) and f ( c j ) denote the occurrence frequency of character c the frequency of the two consecutive characters c i and c
Yang and his coauthors  X  research ( Yang et al., 1998 ), two algorithms are proposed. One employs the nature of a priori knowledge to allocate segmented words by iteratively calculating the MI of each bi-gram, tri-gram, and n -gram. The other is to calculate the MI of each bi-gram only once, and to find the proper seg-ment points at the whole sentence according to the MI distribution. Chien (1997) defines another mutual information function, named AE, which is the same as Jarcard similarity. For example, the AE value of word  X  X   X  X  (calculator) can be calculated as AE  X  z characters ( ) of the word. y denotes the frequency of the two right characters ( ) of the word. and z denotes the frequency of the word ( ). Context dependency (CD) is employed to judge whether a lex-icon is a keyword or not.

The mutual information-based approaches have to access the whole document set in order to calculate the frequency of all possible lexicons. Therefore, an effective text indexing method and efficient data struc-of-text symbol that would not appear anywhere else, we can guarantee that any semi-infinite string is not a prefix of another. Hence, semi-infinite strings can be unambiguously identified by their starting position.
Searching for a pattern simply becomes searching for a prefix in any of the semi-infinite strings. These sistrings can be indexed in the tree structure named PAT-Tree, which is developed by Gonnet and
Baeza-Yates (1992) from Morrison  X  s PATRICIA algorithm (1968) to index a continuous data stream and locate every possible position of a prefix in the stream. Using this data structure to index the full-text of a document, all possible character strings, including their frequency counts in the document, can be retrieved and updated in a very efficient way without storing every character string with arbitrary length ( Chien, 1997 ).

After the word segmentation and text indexing phases, the next step is to assign weights to word seg-ments (terms) to represent their importance to represent the main concepts of documents. This weight assignment process is known as feature selection in machine learning, or the term-weighting system in an information retrieval system. The term-weighting system calculates the term occurrence in a document as a measure to assess the importance of the term to represent the document. In the information retrieval research, the fully weighted system tf log  X  N = n  X  = the term-weighting systems, where tf denotes term frequency, N is total number of documents in the corpus, and n is number of documents to which a term is assigned ( Salton &amp; Buckley, 1988 ). 2.2. Document clustering
The recent research in information science has tended to facilitate the tasks of automatic document cat-egorization. However, the clustering task is more challenging than document categorization since there are no pre-existing categories created by human experts. The clustering task has a higher degree of freedom; that is, not only assigning decisions but also decisions about how many clusters to create and what kinds of documents to assign to each cluster ( Roussinov &amp; Chen, 1999 ). The process of document clustering con-sists of two major tasks: document representation and clustering . Document representation adopts the vector space model, where a document is represented as a multidimensional vector and each dimension corre-sponds to a unique term from the document ( Salton &amp; Buckley, 1975 ).

Clustering techniques conventionally can be categorized into three types: partitioning , hierarchical , and hybrid approaches ( Kaufman &amp; Rousseeuw, 1990 ). In the partitioning approach, objects are viewed as points distributing in a hyperspace, and given the number of clusters, the seed (centroid) points for their clusters. Many algorithms such as k -means, PAM, CLARA, and FANNY are developed in this manner ( Kaufman &amp; Rousseeuw, 1990, pp. 38 X 44 ). In the agglomeration approach, the clustering process starts with forming each data point as its own cluster, and gradually merges clusters until all points have been grouped together as a big cluster. The entire grouping history is preserved, so that the user can choose the level of clustering that works best for the application. The common methods include AGNES, DIANA, CURE, and CHAMELEON ( Kaufman &amp; Rousseeuw, 1990, pp. 44 X 48 ).
 Two-stage clustering is a hybrid approach combining the partitioning and hierarchical clustering ( Punj &amp;
Stewart, 1983 ). If the initial parameters of the partitioning clustering are not generated randomly, it will perform better than hierarchical clustering. Besides, they also conclude that the k -means clustering tech-nique has better noise tolerance and the performance is independent from the abnormal instances and the difference of the distance measurement.

The above algorithms need to assess the similarity between objects in order to group objects with similar characteristics. Similarity assessment is defined as inner production of vector, similarity  X  J ; K  X  X 
P i  X  1 d ji d ki , where document J and K are measured by the inner production of m terms ( Biru, EI-Hamdou-chi, Rees, &amp; Willett, 1989 ).
 Recently neural network clustering techniques, such as Kohonen neural network (i.e., Self-Organizing
Map, SOM) and density-based clustering, such as CLIGUE, are gaining popularity as ways to deal with large quantity data with high noise ( Agrawal, Gehrke, Gunopulos, &amp; Raghavan, 1998 ; Kohonen et al., 2000 ; Merkl &amp; Rauber, 1999 ; Yang &amp; Lee, 1999 ). 3. The architecture of knowledge map management system In this study, we propose the architecture of the knowledge map management system as shown in Fig. 1 .
A knowledge map management system facilitates knowledge navigation, knowledge seeking, and advisory learning. Knowledge acquisition is navigated by browsing documents with concept hierarchies. By doing so, a knowledge seeker can thoroughly understand the inter-document relationship, and efficiently locate documents. A learning adviser recommends documents to learners by analyzing the document access his-tory to generalize the common access pattern. These main components are described as follows. (1) The knowledge map navigator is used for guiding knowledge browsing according to knowledge map (2) The knowledge seeker is used for retrieving documents from the document base to answer users  X  (3) The learning adviser is responsible for recommending documents according to the learning history (4) The learning history analyzer facilitates the learning adviser by using sequential pattern analysis tech-(5) The knowledge map manager is the kernel of the knowledge map management system. The knowledge 3.1. Knowledge navigation
In a community of practice, knowledge is the most important capital existing in dialogues and publica-tions. Learning in the profession community occurs while sharing knowledge among members. Well-orga-nized knowledge structure will help knowledge seekers retrieve the knowledge they need. The knowledge map creation method automatically clusters documents to generate the knowledge map in the hierarchical structure. Sometimes, users may not accurately specify key terms to represent knowledge they are search-ing, so that it is difficult for them to give keywords to start the search. By using the knowledge navigation function, knowledge seekers may traverse the knowledge map level-by-level, and they can thoroughly understand the concept hierarchy existing in the community. The knowledge navigation function brings users a macro view of knowledge structure in the community to guide the document retrieval. 3.2. Knowledge seeker
The knowledge navigation is a macro view to understand the overall knowledge structure of the profes-sional community, and knowledge seeking with the search engine is a micro view to allocate the target doc-uments. The knowledge seeking with knowledge navigation takes advantage of the efficiency of the search engine and also represents the searching results with the knowledge map. Therefore, the knowledge seekers not only efficiently retrieve documents but also the structure of concepts.
 3.3. Learning adviser
In a community of practice, the most interesting characteristic is collaboration. Via collaboration, the professional community aggregates more intellectual capitals than a single enterprise. The learning adviser exerts collaborative document retrieval to exploit past knowledge activities to shorten the individual learn-ing cycle. With analysis of the document retrieval history of members with similar problem solving back-ground, we can generalize the common knowledge retrieval path as the learning history to a specific task.
The knowledge navigation function together with the learning adviser greatly helps the knowledge sharing in the community. When a learner explores the knowledge map, the knowledge map management system will advise the learner to retrieve certain documents based on the analysis of the individual knowledge re-trieval history and learning history in previous tasks. 3.4. Knowledge map manager
The role of knowledge map manager is responsible for coordinating the knowledge map navigation, knowledge seeking, and learning recommendation with user  X  s requests. The design of knowledge map man-ager is depicted in Fig. 2 . The knowledge map manager uses information retrieval techniques to transform the unstructured documents to the structured data, and applies data mining techniques to discover the rela-tionships among documents. These techniques include text indexing, keyword extraction, term-weighting, document clustering and sequential pattern analysis. The first three techniques are responsible for the data transformation and play the role as document representation. (1) Text indexing . Unstructured documents are first indexed in PAT-tree to avoid re-scanning the (2) Keyword extraction . In this stage, a hybrid keyword extraction method is employed. The combination (3) Term weighting . Keywords representing each document are identified by the term-weighting system, (4) Clustering . Clustering techniques are used for specifying document relationships based on features to
A knowledge manager of the community of practice takes charge of the knowledge map management system with three main tasks: the knowledge map creation , knowledge map maintenance ,and the collabora-tive knowledge retrieval as shown in Fig. 1 . The collaborative knowledge retrieval exploits the learning his-tory analyzer to generate common knowledge retrieval patterns. We introduce the procedures of knowledge map creation and maintenance in the next sections. However, due to insufficient knowledge access history data to conduct the experiment, we will examine the learning history analyzer in future research. 4. Knowledge map creation and maintenance 4.1. Knowledge map creation
In a virtual community where people came from different organizations and shared knowledge autono-mously, it is difficult to pre-define knowledge structure in terms of concept hierarchy, and then assign doc-uments to specific categories properly. Instead of this top-down approach, the bottom-up knowledge structure discovery method is required to cluster documents. Hierarchical clustering expresses the hierarchi-cal relationships of documents with a binary tree, but relationships in the concept hierarchy are not always divided into two sub-clusters. In order to identify relationships among concepts extracted from knowledge artifacts, this study adopts the two-stage clustering approach as the core technique. In the first stage, the preliminary binary hierarchical relationships are explored by the hierarchical clustering approach. From the preliminary structure, we determine the number of clusters to replace the binary structure. In the second stage, the k -means clustering is employed to physically partition documents into the number of clusters determined in the first stage. These two stages of clustering are performed iteratively as illustrated in
Fig. 3 . 4.1.1. Stage 1 (hierarchical clustering)
We first apply hierarchical clustering to obtain the hierarchical relationship of documents. The binary structure is the nature of the hierarchical clustering method and the binary knowledge structure limitedly supports the knowledge navigation activities because of the tremendous complex category structure. The complexity of the binary structure generated from the hierarchical clustering can be reduced by choosing a cutting threshold to determine the number of clusters in order to perform the physical partitioning with k -means clustering in the second stage. But how many clusters should be chosen? In this study, the optimal number of clusters is determined by the Silhouette Coefficient (SC) ( Kaufman &amp; Rousseeuw, 1990 ). The be the average dissimilarity of i to all other objects of cluster A . For any cluster C different from A , let the smallest among them is selected and denoted as b ( i ) = min obtained by combining a ( i ) and b ( i ) as follows: Thus, we can choose the best number of clusters from the clustering results with the highest Silhouette
Coefficient. Experience with the Silhouette Coefficient has led us to a rather subjective interpretation, which is summarized in Table 1 . 4.1.2. Stage 2 (k-means clustering)
In general, the k -means clustering method obtains much better performance than hierarchical clustering in most cases, but its performance depends on the number of clusters and initial seeds. After obtaining ini-tial seeds and determining the number of clusters from the hierarchical clustering results in stage 1, we then use the k -means clustering method to physically partition the document set starting with these initial seeds.
To construct the knowledge map with hierarchical relationship among concepts, the structure discovery procedure should be performed iteratively between stages 1 and 2 in each layer. If documents in a cluster belong to one concept, these documents are similar, and their distances are relatively small; that is, the be the dissimilarity of o i to o j . The disjoint of cluster A , defined as calculates the average distance within cluster A , where N denotes the total number of objects in cluster A .
The smaller the value of D A , the more similar documents of cluster A . 4.2. Knowledge map maintenance
Members of a virtual community contribute documents continuously, and the knowledge map of the community may vary dynamically. Therefore, how to index the new incoming documents in the existing knowledge map is very important, especially in the autonomously virtual community, which lacks mana-gerial authority. The knowledge map maintenance function is designed to keep the knowledge map up to date, so that users can precisely access documents from their categories. Besides, it also reduces the com-putational cost and prevents re-clustering the existing documents whenever we classify few incoming doc-uments. Besides considering the computational cost, we also account for the knowledge seekers  X  cognitive loadings. People tend to get used to a given knowledge structure; meanwhile, a large degree of structure change may confuse knowledge seekers  X  existing knowledge maps. Therefore, we exploit an incremental knowledge map maintenance approach to modify categories in a small range of knowledge map instead of re-clustering the whole knowledge map. The incremental knowledge map maintenance approach will greatly reduce the knowledge seekers  X  cognitive loadings.

The major steps of the knowledge map maintenance approach are depicted in Fig. 4 . When a new doc-ument is added into the knowledge map, the first step is to represent the document with the vector space test, are used to examine the need to perform cluster decomposition, cluster merging, and cluster re-clus-tering. The detailed steps are described in the following subsections. 4.2.1. Document and cluster representation
A cluster resulting from the knowledge map creation is represented by the vector space model, and the centroid vector of a cluster is the average of vector values of objects in the cluster. An incoming document is represented with the vector space model, and it is classified into a cluster by calculating the distance be-tween the document vector and cluster centroid vector. In the vector space model, the vector value denotes the occurrence of keywords in a document, and the cluster  X  s centroid vector denotes the average occurrence of keywords within the cluster. In this step, both the new documents and existing clusters are transformed into the vector space representation with the same dimensions. Thus, we can compare the similarity in key-words between a new document and the existing clusters. 4.2.2. Document classification
In this step, we classify a new document into the existing clusters by comparing with the document vector and cluster centroid vector. With the Euclidean distance calculation of the two vectors, we obtain the distance between the document and the cluster. The document is inserted into the cluster that has the short-est distance.

After the incoming document is classified into the closest cluster, the within cluster disjoint test is per-formed. The within cluster disjoint is defined as the average distance between documents within a cluster. If documents within a cluster are similar, the distance between documents is relatively small, which results in documents within the cluster is significantly low, the cluster is split into sub-clusters. 4.2.3. Cluster decomposition to decompose the cluster, and the number of clusters is determined by Silhouette Coefficient. We need to decide where to mount these new clusters after discarding the original cluster, and this leads to the next step, cluster merging. 4.2.4. Cluster merging
We compare the similarity of these new clusters generated in the cluster decomposition phase with the existing clusters. If the distance between a new cluster and an existing cluster is equal to or less than the disjoint threshold a , these two clusters are merged into a single cluster. The merged clusters may originally belong to different super clusters, which are the candidate locations to mount the new merged clusters.
For example, the distance between the existing cluster C 1 threshold a , so that they can be merged into the same cluster C super clusters C S 1 and C S 2, respectively. After the merging action, we can choose two locations, C C
S 2 , to be the mounting point of the new cluster C new . In deciding the mounting point, we compare the distance of the new cluster centroid vector C new with the original super cluster centroid vector C C
S 2 , and the closest super cluster will be chosen as the mounting point. 4.2.5. Re-clustering
As mentioned above, SC is used for determining the number of clusters. After inserting a new document, we test SCs of those super clusters wherein resides the new document or induced new clusters from cluster decomposition and emerging. Comparing the super cluster  X  s original SC with the new SC, if the SC  X  s curate after updating the cluster structure. Therefore, we should perform the re-clustering function to restructure the knowledge map under the super cluster. If the SC  X  s decreasing rate is equal to or less than tering action is needed.

A re-clustering knowledge map follows the creation procedure wherein the original knowledge structure under the given super cluster is demolished, and documents within that super cluster are re-clustered. 5. Evaluation of the knowledge map creation In Chinese information retrieval research, few standard test corpuses exist as evaluation benchmarks.
Thus, we adopt the evaluation method proposed by Roussinov and Chen (1999) , which conducts experi-ments to evaluate the outcomes by invited subjects. In this study, we use two document sets obtained from two communities of practice to evaluate the quality of the knowledge map creation. One document set con-tains 254 natural science documents (NSD) (419,196 Chinese characters) for teachers in the teachers  X  pro-fessional community, SCTNet. The other document set contains 281 thesis abstracts in information management (TAIM) (267,288 Chinese characters) from Taiwan  X  s National Central Library. After a knowledge map is created, experiments are conducted to evaluate the resulting categories. Sixteen domain experts, eight for each document set, are asked to modify the hierarchical categories generated from the document set along with viewing these documents. 5.1. Evaluation criteria
The performance of the knowledge map creation method is evaluated by the degree of experts  X  modifi-cation from the automated clustering measured by precision and recall. As we know that precision and re-call are widely used as relevancy measures for information retrieval ( Salton &amp; Buckley, 1988 ). Precision measures the percentage of relevant documents in relation to the number of documents retrieved. Recall measures the percentage of the total relevant documents retrieved by the query. In this study, we view a query as a category designation, and adopt precision and recall measures to evaluate how accurate the knowledge map creation method complies with domain experts in assigning documents to specific catego-ries. M denotes the set of documents allocated to a category by a domain expert, and A denotes the set of documents assigned to a category by the knowledge map creation method. N uments in A , N M denotes the number of documents in M , and N both in A and M . For each category of the modified knowledge map, the precision and recall are defined by the knowledge map creation method which are also designated to that category by a domain expert. Re-call denotes the percentage of documents designated to a category by a domain expert, which are also as-signed to that category by the knowledge map creation method. The whole knowledge map  X  s precision and recall are calculated by averaging the values of precision and recall respectively from all categories of the modified knowledge map. 5.2. Experimental design
The knowledge maps generated from NSD and TAIM documents are evaluated by two teams of domain experts in the same experimental settings. NSD knowledge maps are evaluated by eight elementary school teachers; TAIM knowledge maps are evaluated by eight graduate students major in information systems.
Although the Silhouette Coefficient can be employed to choose the number of clusters, we do not expect to use a large number of clusters to express the hierarchical relationship among concepts. Therefore, three different knowledge maps for each document set are created by three structuring strategies. The first strat-egy, called  X  X  X eep X  X , picks the number of clusters between 1 and 10 per layer which has the largest Silhouette
Coefficient. We expect to obtain a smaller number of clusters in each layer and the concept hierarchical tree looks deep. The second strategy, called  X  X  X ide X  X , chooses number of cluster between 10 and 20 per layer which has the largest Silhouette Coefficient. We expect to obtain a larger number of clusters in each layer, and the concept hierarchical tree looks wide. The third strategy, called  X  X  X ix X  X , chooses the number of clus-ters ranging from 1 to 20 per layer which has the largest Silhouette Coefficient.

Each expert spends 40 min on one section to finish modifying one knowledge map generated by one strategy (deep, wide, or mix), and the cooperation between experts is not allowed. We designed a Web inter-face for subjects to modify the knowledge map on desktop computers. By referring to the printed document abstracts, an expert verified and then modified the knowledge map on the Web. There is a 10 min break between two sections. Meanwhile, domain experts return reference materials at the end of each section to prevent the influence from the previous session. It takes about 2 h to finish three sections  X  evaluation.
The differences of knowledge maps before and after domain experts  X  modification were analyzed to evaluate the performance of the proposed mechanisms. 5.3. Evaluation results The precision and recall of the NSD and TAIM document sets are shown in Tables 2 and 3 , respectively.
We found that the precision and recall in these experiments are very high (91 X 93%); however, among dif-ferent experts the modified knowledge maps vary greatly. It is insightful to investigate the consensus of ex-perts by modifying precision and recall measures to reflect the consensus of knowledge maps. The revised precision and recall for each cluster (category) of the modified knowledge map are defined as respectively, where A denotes the set of documents in a category designated by the knowledge map creation method, U i denotes the set of documents in a category designated by both the knowledge map creation method and domain expert i , N A denotes the number of documents in A , N of distinct documents from U i [ U 2 [[ U n ,and N U from U i \ U 2 \\ U n .

The revised precision denotes the percentage of the documents in a category assigned by the knowledge map creation method which are also jointly designated by n domain experts. The revised recall denotes the percentage of the distinct documents in a category designated n domain experts which are also jointly as-signed to that category by the knowledge map creation method. The whole knowledge map  X  s revised pre-cision and recall are calculated by averaging the revised precision and recall from all categories of the modified knowledge map.

From experiments, we obtain revised precision 0.61 for wide, 0.59 for deep, and 0.60 for mix knowledge maps in the NSD document set; 0.79 for wide, 0.75 for deep, and 0.72 for mix knowledge maps in the
TAIM document set. We also obtain revised recall 0.72 for wide, 0.73 for deep, and 0.68 for mix knowledge maps in the NSD document set; 0.66 for wide, 0.60 for deep, and 0.58 for mix knowledge maps in the TAIM document set.
 From these evaluation results of revised precision and recall, the common consensus evaluation of the
NSD and TAIM document sets is lower than those using original precision and recall measures. It implies that the bottom-up knowledge map discovery method enacts a high degree of freedom in category alloca-tion, and therefore, presents difficulties in reaching consensus in categorization viewed by individual do-main experts.

One-way ANOVA test was conducted to test if three types of knowledge maps (wide, deep, and mix) resulted in significant differences measured in precision and recall. The result shows that no significant dif-ference exists between these three types of knowledge maps either in the NSD or TAIM document sets. In summary, the knowledge map creation function with different structuring strategies can achieve effective performance measured in precision and recall. 6. Evaluation of the knowledge map maintenance
We analyze the knowledge map maintenance performance by applying the cross-validation method to evaluate the real world data from NSD and TAIM document sets. For each document set, each time we randomly select the two-thirds of documents to create the initial knowledge map, and then insert the rest of the one-third documents into the knowledge map, and then evaluate the updated knowledge maps. After rotating three times, we calculate the average performance measured in purity, diversity, specificity, and structure adaptation index. 6.1. Evaluation criteria
The performance of knowledge map maintenance is evaluated by four criteria: purity , diversity , specific-terion is unique to this study in evaluating hierarchical knowledge structure. These four criteria are defined as follows.

Purity indicates the degree of similarity within each category after documents are inserted incrementally into the existing document set. Purity is defined as where N U i denotes the total number of documents in the updated cluster i , n U of documents that belong to the same category in the updated cluster i ,and N denotes the total number of documents in all clusters.

Diversity indicates the variety of categories correctly updated by new documents. It is represented by the ratio of correctly updated categories over the original category set; that is, Diversity  X  the number of original category, and t U denotes the number of true categories covered by the updated categories.

Specificity indicates the precision of assigning new documents to the corresponding categories. It is de-noted by the ratio of correctly updated categories covered by the updated categories; that is, Specificity  X  t U categories covered by the updated categories.

This study aims to discover the hierarchical relationship among documents. However, three criteria aforementioned do not reflect the structural change between original and updated knowledge maps. There-fore, we design the structure adaptation indicator (SAI) to express the structural change. SAI is defined as l denotes the level number in the concept hierarchy. At the root node, l is 1, and as the layer descends, the level number increments. A leaf node has level number L . N level l in the original knowledge map, and N U l denotes the number of clusters containing in level l in the updated knowledge map. The parameter 1 log l grants a higher SAI value to the structural difference in the upper layers. The smaller the SAI value is the less the structure changes. 6.2. Evaluation results
The performance of knowledge map maintenance function for the NSD and TAIM document sets with disjoint threshold a = 0.84 and SC threshold b = 10% are evaluated, and the results are shown in Table 4 .
In purity, diversity, and specificity criteria, the results of incremental knowledge map maintenance are all above 65% which is acceptable in practice. The re-clustering function is activated four times out of 85 doc-ument insertions, and 16 out of 254 documents on average are re-categorized in the NSD document set. The re-clustering function is activated two times out of 94 document insertions, and 13 out of 281 documents are re-categorized in the TAIM document set.

Due to the characteristic of incremental reallocation, the knowledge map refined by the knowledge map maintenance function may differ from that created by the one-shot knowledge map creation function measured by the SAI. However, it is a tradeoff between the knowledge map quality and computational complexity. In the knowledge map management for communities of practice, it is desirable to have an effi-cient knowledge map maintenance method to deal with the incremental document insertion. The knowledge map maintenance approach achieves acceptable purity, diversity, and specificity, and the re-clustering action, which is computationally costly, is rarely triggered. In summary, the incremental knowledge map updating process utilizing the knowledge map maintenance function can be performed on a real time basis. The need to periodically re-cluster the document set depends on the frequency of document insertion. 7. Conclusions and future research
This paper proposes a knowledge map management system to facilitate explicit knowledge sharing activ-ities in communities of practice. We have developed knowledge map creation and maintenance techniques to keep document categories up-to-date in this study. The knowledge map creation function employs the automatic categorization technique to discover the knowledge structure of documents in a virtual commu-nity. The knowledge map maintenance function updates knowledge structure efficiently. Beyond knowledge structure management, collaborative knowledge retrieval can be further developed by generalizing docu-ment retrieval patterns from individual knowledge access histories. Although the system is demonstrated for processing Chinese documents, the knowledge map creation and maintenance process is also applicable to documents with other languages by switching the keyword extraction methods. Technically, this study has developed the following unique techniques: (1) This study has enabled the automated determination of cluster number using Silhouette Coefficient. (2) This study has adopted the state-of-the-art two-stage clustering procedure iteratively to generate hier-(3) This study has invented the method to allow the incremental update of knowledge maps. (4) This study has linked information retrieval and text mining techniques to streamline the flow from (5) This study has proposed additional new criteria, called structural adaptation indicator, to capture
Major findings from the evaluation of the proposed knowledge map creation and maintenance functions are summarized as follows. In evaluating the knowledge map creation performance, eight elementary school teachers revised the natural science teaching materials in a teachers  X  virtual community; eight grad-uate students majoring in information systems revised the knowledge maps generated from thesis abstracts from universities in Taiwan. From evaluation results, individual experts generally accepted the document categories created by the knowledge map creation method. However, constituent documents of categories in the knowledge map modified by different experts are quite different due to individual differences in their own knowledge structures. People tend to classify knowledge in their own knowledge structures based on their cognitive styles, which may explain why different people prefer different knowledge maps ( Pask &amp;
Scott, 1972 ; Witkin, Moore, Goodenough, &amp; Cox, 1977 ). This research shows the needs to enable personal knowledge maps in communities of practice to fit accurately to individual knowledge structures. The incremental knowledge map maintenance approach utilizes the within cluster disjoint and Silhouette
Coefficient tests to maintain up-to-date knowledge maps. The experimental results demonstrate its compe-tency measured in purity, diversity, specificity, and structure adaptation. Thus, the knowledge map main-tenance approach is acceptable in considering the balance among the cognition loading, knowledge map quality, and computation complexity of modifying knowledge structure.
We recommend that this line of research be continued. Specifically, we recommend new study in the fol-lowing areas: (1) The analysis of documents using information retrieval methods in this research does not employ any (2) The learning advisory techniques can be implemented in the future to discover the dynamic relation-References
