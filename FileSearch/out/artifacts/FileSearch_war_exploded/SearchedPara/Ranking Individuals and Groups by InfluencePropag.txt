 Ranking the centrality (or importance) of nodes within a graph is a fundamental problem in network analysis. Recently, the o nline social networking sites, such as Facebook and MySpace, provide users with a platform to make people connected. Learning and mining on these large-scale social networks attract attentions of many researchers in the literature [1]. I n retrospect, Freeman [2] reviewed and evaluated the methods about centralit y measures, and categorized them into three conceptual foundations: degree, betweenness, and closeness. Accompanied with eigenvector centrality (EVC) propos ed by Bonacich [3], these four measures dominate the empirical usage. The first three methods measure the centrality by simply calculating the edge degree or th e mean or fraction of geodesic paths [4], and treat every node equally. In this paper, we focus on EVC, which ranks the centrality of a node v by considering the centra lity of nodes that surround v .
In the literature, most of link analysis approaches focus on the link structures and ignore the intrinsic characteristics of nodes over a graph. However, in many networks, nodes also contain important information, such as the page content in a web graph. Simply overlooking these predefined importance may facilitate the usage of link spam. We believe the intrinsic characteristics of nodes also affect link-based ranking significantly.

The main contributions of this work are summarized below. First, we discuss the problems with the current EVC approaches, for example, PageRank, which ignores the intrinsic impacts of nodes on the ranking. Second, we propose a new Influence Propagation model, called IP m odel, which propagates the user-defined importance over nodes in a graph by random walking. We allow users to specify decay functions to control how the influence propagates over nodes. It is worth noting that most of EVC approaches only use an exponential function, that is not proper in many cases which we will address later. Third, we give algorithms to rank an individual node and all nodes in a graph efficiently. Fourth, we discuss how to rank a group (a set of nodes) regarding the centrality using both inner and outer structural information.

The remainder of the paper is organized as follows. Section 2 gives the mo-tivation of our work. Section 3 discuss our new influence propagation model, and ranking algorithms for individual nodes and groups. We conducted exten-sive performance studies and report our findings in Section 4. The related work is given in Section 5 and we conclude in Section 6. The notations used in this paper are summarized in Table 1. In this section, first, we discuss our motivation to propose a new influence model, and explain why PageRank is not applicable in some cases. Second, we give our intuitions on how to rank the centrality for a set of nodes.
 Why Not PageRank: As a typical variant of EVC [3], PageRank [5] models the behavior of a random surfer, who clicks some hyperlink in the current page with probability c , and periodically jumps to a random page because  X  X ets bored X  with probability (1  X  c ). Let T be a transition matrix for a directed graph. For the p -th row and q -thcolumnelementof T , T p,q =0if( p, q ) /  X  E ,and T p,q = w ( p, q ) / i  X  O ( p ) w ( p, i )otherwise,where w ( p, q ) is the weight of edge ( p, q ). The matrix form of PageRank can be written below.

Here, U corresponds to the distribution vector of web pages that a random surfer periodically jumps to and U = 1 holds. Based on Eq. (1), PageRank scores can be iteratively computed by R k = cR k  X  1 T +(1  X  c ) U .Thesolution R is a steady probability distribution with R = 1, and decided by T and U only.
It is important to note that the initial importance R 0 of all nodes in PageRank are ignored (refer to Eq. (1)). In other words, R 0 is not propagated in PageRank. As shown in Fig. 1, for the graph shown in Fig. 1(a), the PageRank scores for a, b, c, d, and e are 0.149, 0.1, 0.223, 0.243, and 0.174, respectively, regardless any given initial importance R 0 . However, in many real applications, the initial importance R 0 plays a significant role and greatly influences the resulting R .
In addition, simply applying the PageRank to measure centrality in general may result in unexpected results, beca use PageRank is originally designed to bring order to the web graph. For examp le, to model the  X  X ord-of-mouth X  effect in social networks [6] where people are likely to be influenced by their friends, the behavior of  X  X andom jumping X  used in PageRank is not reasonable, since the influence only occurs between two directly connected persons.

Motivated by propagating the initial predefined importance of nodes and ran-domly jumping, we claim that PageRank is not applicable for link-based ranking in all possible cases. In this paper, we propose a more general and customizable model for link-based ranking. We pro pose a new Influence Propagation (IP) model and IPRank to rank nodes and groups, based on their structural contexts in the graph and predefined importance.
 Group Ranking: In this paper, a group is a set of nodes in a graph. We categorize group centrality measures into two types. The first type exploits the inner information of a group. Two simple approaches to rank a group are either to sum or to average the centrality sco res of nodes in group. However, summing is obviously problematic because larger groups tend to obtain higher scores. Averaging is unacceptable in some cases where a group with only one but high-score node beats another group with a large number of nodes. The second type employs the information outside a group. [7] analyzed this problem and proposed a measure based on the number of nodes outside a group that are connected to members of this group. More explicitly, let C be a group, N ( C )bethesetofall nodes that are not in C , but are neighbors of a member in C . [7] normalizes and the graph. Clearly, this method measures group centrality from the view of nodes outside this group. However, given two large groups A and B where | A | &gt; | B | , making larger groups have a higher degree centrality more easily. Moreover, this method ignores the centralit y scores of nodes in groups.

In this work, we investigate how to combine the inner and outer structural context of a specific group. Some intuitions are given below. Consider Fig. 2. First, regarding the outer structural context, Group 2 should have a higher score than Graph 1, because Group 2 is with a larger span of neighbors. This intuition is drown from real-world networks such as friendship network, where a group with more contacts outside this group have a higher ranking. Second, regarding the inner structure of a group, both Group 2 and Group 3 have the same outside neighbors, but the inner structure of Group 3 is more compact and cohesive, so Group 3 is with a higher score than Group 2. In our influence propagation model, we consider every node has its own in-fluence that needs to be propagated. This influence represents the predefined importance of a node, such as content, st atus, or preference. We consider a di-rected edge-weighted graph G ( V, E ), where V and E are the sets of nodes and edges respectively. Every node in V has attributes to describe its properties, and the attributes of a node can be used to indicate which groups the node belongs to. We use M A ( a ) to denote the belonging of the node a to a group A ,andcall it membership degree .Let Z be a vector to represent the predefined importance of nodes in G based on the attributes, and every element in Z is non-negative.
The influence propagates following random walk [8]. Like the existing work [9,6,10,11], in our approach, influence p ropagation is a process that the in-coming influence from in-neighbors of a node a to the node a itself at time t propagates to the out-neighbors of the node a with transition probability and decay effected at next time ( t + 1). Regarding decay, we introduce a discrete decay function f ( k ) to describe the retained influence on the k -thstepdur-ing the propagation with decay, where k  X  X  1 , 2 , ..., K } and K is the maxi-mum propagation steps. The most prevalent decay function used in PageRank is f ( k )= c k where 0 &lt;c&lt; 1. Generally, f ( k ) is a non-increasing function that satisfies f ( k ) &lt; 1 and smaller f ( k ) results in smaller maximum steps k . We allow users to configure f ( k ) into other forms such as linear function to adapt different situations. To help assessing the maximum propagation steps K , a user needs to specify a threshold h that satisfies the following condition. which also defines the condition of convergence. According to the definition, we show a proposition to describe the influe nce propagation on a random walk path with cycles permitted, and define IPRank scores in Definition 1.
 Proposition 3.1: For a random path p = v 0 ,v 1 , ..., v k that starts at time 0, the influence Z (0) propagating from v 0 to v k is Proof Sketch: Let X  X  analyze the case of one-step propagation. For an edge v i ,v j ,theinfluence Z ( j ) propagating from v i is can be viewed as a sequence of one-step propagations, Eq. (3) holds. Definition 1. The IPRank score of a node in a graph is measured by the influ-ence of this node and the influence propagated in from other nodes. Like PageRank, the assumption behind IPRank is that, more influence a node receives, more important this node is. Ho wever, our IPRank i s more general than the mutual enforcement based rankings. First, the initial importance Z of nodes will be taken into consideration. Z is propagated in our method and influences IPRank scores. Reconsider Fig. 1(a). We show that IPRank scores are different corresponding to different Z as shown in Fig. 1(b). Second, we allow users to specify a decay function. 3.1 IPRanking Nodes The key to compute IPRank score R ( v ) of a node v is how we collect the influence propagated in from other nodes. Noting that after a propagation over k steps, the influence will be so small that it can be ignored. Therefore, we only need to collect random walk paths that reach the node v within k steps. A possible method is by random walk backwards, where the random surfer walks reversely along links starting from v and traverses nodes recursively. All nodes traversed can be viewed as the starting points of such random paths, whose probability can be assessed by Proposition 3.1.

Consider the node a in the graph G in Fig. 1(a) and suppose k =1.Sincewe reverse all edges and traverse b and e starting from the node a , two random walk paths on G that reach the node a in one step are collected. We summarize the recursive procedure IPRank-One in Algorithm 1, which computes IPRank score of the given node a . Furthermore, supposing the average size of out-neighbors Algorithm 1. IPRank-One ( G , v , Z , T , K ) in graph G is d , Algorithm 1 needs to traverse k i =1 d i nodes and thus collects the same number of random walk paths. The time complexity of IPRank-One is O ( d k ) and acceptable for querying IPRa nk scores for one or a few nodes. But it is obviously inefficient when we need to compute IPRank scores of all nodes in a graph. Based on our observations, random walk paths generated by IPRank queries of differen t nodes contain the shared segments, which can be reused to save computational cost. Fo r example, influence propagation along path a, b, a, c and a, b, a are both computed on IPRank queries for node c and a , but they contain the same segment a, b, a .

We develop an algorithm to compute IPRank for all nodes in matrix form that works as follows. We call it IPRank-All , which is motivated by our IP model, where different nodes propagate their influe nce with different steps. The initial influence of all nodes is stored in a row vector Z . In the first step, all nodes propagate influence to its out-neighbors with decay factor f (1). Let us consider the influence received by a node. Suppose that in-neighbor set of a node v is I ( v ), such as v ,weget Z 1 = f (1)  X  ZT in matrix form. In the s econd step, according to our IP model, all elements in Z 1 will propagate to its out-neighbors and the influence vector received on the second step is Z 2 = f (2)  X  ZT 2 . Analogously, the influence vector received on the k -th step can be comput ed iteratively by Recall Definition 1, IPRank vector obtained within k stepsisasfollows. Eq. (4) and Eq. (5) form the main computation of IPRank-All algorithm. Let X k = ZT k , Z k can be computed iteratively by applying Z k = f ( k ) Algorithm 2. IPRank-All ( G , Z , T , h ) f ( k )  X  X k  X  1 T . So time complexity of IPRank-All algorithm is O ( KNd ), where d is the average in-degree and N is the graph size. When it is specific to the most popular decay function f ( k )= c k ,weget Hence, R k can be computed iteratively if the decay function is exponential. Eq. (6) implies a mutual reinforcement of importance like PageRank does. How-ever, when f ( k ) is not exponential, we cannot compute R k iteratively using Eq. (6). In this case, the efficient way to obtain R k is to compute all Z k itera-tively by Eq. (4) and sum them up. The algorithm for IPRank-All is given in Algorithm 2. While the IPRank in Eq. (4) and Eq. (5) propagates one step of all nodes at a time, Algorithm 2 propagates all steps of one node.
 Some useful propositions about IPRank computing are given below.
 Proposition 3.2: The convergence rate of IPRank scores R k is decided by the decay function f ( k ) .
 Proof Sketch: According to Eq. 5, R k  X  R k  X  1 = f ( k )  X  Z  X  T k . Since each row of T is normalized to one unless all elements in this row are zero, T k  X | V | is tenable. Proposition 3.2 holds.
 Proposition 3.3: When f ( k )= c k , IPRank is an extension of PageRank in fact, and also a variant of eigenvector centrality (EVC) measure. Proof Sketch: Letting Z =(1  X  c ) U in Eq. (6), we get PageRank as shown inEq.(1).When k  X  X  X  , R k = R k  X  1 , and therefore R = c  X  RT + Z . Suppose that X is a | V | -by-| V | matrix with non-zero values only on the diagonal that satisfies RX = Z ,weget R = R ( T  X  c )+ RX = R ( T  X  c + X ). Therefore, R is an eigenvector of ( T  X  c + X ). 3.2 IPRanking Groups As a set of nodes, the group X  X  structural context consists of links from both the outside and inside. If we view a group as a big node and apply IPRank on it, we simply get the group centrality measured from the outside of this group, which says  X  group centrality is the influence propagated in from nodes outside this group  X .
Formally, if we use Z ( u, v ) to represent the influence Z ( u ) propagating from node u to node v (no matter via how many steps), we rank a group A from the viewpoint of the outside structure.

M A ( v ) is the membership degree. On the other hand, if nodes in the group are more connected to each other, this group should have a higher centrality. We do not use the simple approaches such as summing and averaging, because they ignore the link information between individual nodes in a group. To reduce the effect of the group size, individual nodes with a high centrality should play a more important role, especially when they are highly connected. IP model is also effective to help rank groups from the viewpoint of the inner structure, by propagating the influence of these high-s core individuals via links. That is,
Finally we combine rankings from outer and inner structural context together to rank groups in graph G ( V, E ), as shown below.

Ranking groups in a graph G is an extension of our IPRank algorithms. The basic idea of our IPRank algorithms is t o collect influence propagated in from other nodes. In brief, we show three st eps to perform group ranking in a graph G . (i) Set the centrality score R ( v ) of a node v as initial influence Z ( v ). (ii) Propagate influence via links by our IPR ank algorithm. (iii) Rank groups by IPRank scores and the membersh ip degree according to Eq. (9). We report our experimental results to confirm the effectiven ess of our IPRank on both individual and group levels. We comp are IPRank with other four centrality measures on accuracy, and we use various synthetic datasets and a large real co-authorship network from DBLP. All algorithms were implemented in Java, and all experiments were run on a machine with a 2.8 GHz CPU.
 IPRank Vs. Others: A Case Study : In this experiment we evaluate the results produced by IPRank and other centrality measures based on degree, betweenness, closeness, and eigenvector . The comparison was performed on the small graph shown in Fig. 1(a). Note that for each centrality measure, there are many variants, so we adopt the definition from Wikipedia [12]. For graph the number of shortest paths from s to t and  X  st ( a ) is the number of such paths that pass through node a . Closeness centrality is a little complex, because the shortest path between two nodes may not exist on directed gr aphs. So we adopt the definition in [13] where the closeness centrality C C ( a )= t  X  V 2  X  d ( a,t ) ,in which d ( a, t ) is the shortest distance from node a to t and d ( a, t )=  X  if it is unreachable. Finally, we use PageRank in [5] to measure eigenvector centrality .
To make the results comparable, we nor malize centrality s cores of different measures to be one and show them in Table 2(a). For IPRank, we set the pre-degree centrality is similar to EVC but only considers directed neighbors. For betweenness and closeness centrality, they base on shortest distance and empha-size on the  X  X restige X  rather than  X  X opularity X  of a node. Thus, C B ( c ) &lt;C B ( b ) and C C ( b ) = 0 is not compliant to the human intuition of ranking that is mainly based on popularity. In IPRank, we set a higher predefined importance on b , which contributes to a and makes R ( a ) &gt;R ( e ) finally, to be contrary of PageR-ank. Moreover, we show different norma lized IPRank scores in Table 2(b) while Z ( b ) increases step by step. Increasing predefined importance of a node generally results in a higher IPRank score of this node.

Decay functions also influence IPRank scores significantly. For example, based 0 . 2for k  X  3and f ( k )=0for k  X  4, and alter decay function from f ( k )=0 . 7 k Results on DBLP Co-Authorship Network: We use the author information of the entire DBLP 1 conference papers (a total of 745,593) to build a large co-authorship network. This network consists of 534,058 authors (nodes), 1,589,343 co-author relationships (edges). There are 2,644 different conferences, and an author is associated with a vector showing how many papers he/she contributes to conferences. The maximum number of co-authors is 361 by Philip S. Yu and nearly 54.3% authors appear once in DBLP. We set the number of co-authors as theedgeweight.Aconferenceservesasa group, and membership degree between author a and conference C is decided by the ratio of a publishing in C .IPRank algorithm follows a human intuition: if author a and author b have the same number of co-authors but a  X  X  co-authors are more important, according to our IP model, a receives more influence from neighbors and earns a higher centrality compared with b . Besides, we consider the decay of influence propagation via co-authorships should be not exponential, since an author means a lot to his co-authors but little to other authors away from several hops. In this experiment, we set decay function f ( k )=1  X  0 . 3 k for k  X  3and f ( k )=0if k  X  4.
To illustrate the necessity of predefined importance, first we consider every author is equal important and show the corresponding top-10 authors and con-ferences in Table 3(a). Some authors rank high only because they have lots of co-authors, and larger co nferences result in higher rankings. Second, we bias the ranking to a special area by predefining importance for authors. In Table 3(b), the authors published papers in KDD are given a higher predefined impor-tance and shortly we obtain top-10 centrality ranking of authors and conferences in the Knowledge Discovery and Data Mining area. Third, we bias IPRank to WWW area by giving higher predefined importance to authors who published in WWW, and show results in Table 3(c). We can see IPRank with predefined importance produces reasonable results. Experiments display that IPRank-All only takes 0.91 second to complete all three iterations.
 Efficiency and Convergence Rate: PageRank does not provide ways to com-pute the score of only one node. In contrast, IPRank-One can do this without accuracy loss, and an advantage is that if we only need to obtain IPRank scores of a few nodes, IPRank-One is more effici ent than IPRank-All. We execute ex-periments on a random graph with 1M nodes and 3M edges. IPRank-All takes 3.65s to perform all iterations, whereas IPRank-One only needs 0.01s to respond IPRank query for one node. IPRank-A ll+ provides a more accurate measure than IPRank-All when the decay of som e large predefined importance needs more iterations. Algorithms show that IPRank-One and IPRank-All+ are all based on traverse of nodes that reach the target node within K steps. Fig. 3(a) shows time cost of such a traverse increases rapidly when K increases. We rec-ommend IPRank-One for IPRank query of a few nodes and IPRank-All+ for more accurate IPRanking.

IPRank-All is suitable for most of cases. We set | E | / | V | =5andletthe graph size | V | increase. Time cost of each IPRan k-All iteration increases near linearly and looks acceptable, as shown i n Fig. 3(b). We test the convergence rate of IPRank-All on DBLP co-authorship network with decay f ( k )=0 . 7 k . The precision of iteration k is defined by averaging R k ( a ) /R ( a ) for every node a . Fig. 3(c) shows that after 10 iterations, the error of precision is below 0.01. Historically, measuring the centrality of nodes (or individuals) in a network has been widely studied. Freeman [2] revie wed and categorized these methods into three conceptual foundations: degree, betweenness, and closeness. Accompanied with eigenvector centrality (EVC) propos ed by Bonacich [3], these four measures dominate the empirical usage of centr ality. A recent summary can be found in [4]. Besides, Tong et al. [14] proposed cTrack to find central objects in a skewed time-evolving bipartite graph, based on random walk with restart.

In recent years, the trend o f exploiting structural context becomes prevalent in network analysis. The crucial intuition behind this trend is that  X  individuals relatively closer in a network are more likely to have the similar characters  X . A typical example is PageRank [5], where the page importance is flowing and mu-tual reinforced along hyperlinks. Other examples and applications were explored in recent works such as [10,11,15]. [15] analyzed the propagation of trust and distrust on large networks consisting o f people. [11] used a few labeled exam-ples to discriminate irrelevant results by computing proximity from the relevant nodes. Gyongyi et al. discovered other good pages by propagating the trust of a small set of good pages [10].
Other studies that applied predefined importance to their measures include [16] and [17]. [16] modified PageRank to be topic-sensitive by assigning im-portance scores for each pages with respect to a particular topic. [17] assigned PageRank scores to each page, and measured the similarity between web pages by propagating their own similarity and receiving similarities from other pages. On the other hand, most of works use exponential decay simply and there are few studies on applying user-defined decay functions in random walking. Perhaps the most explicit study on decay function is [18], which discussed three decay (or damping) functions on link-based ranking and showed a linear approximation to PageRank. We are the first to introduce predefined importance and decay function into EVC under a well-established intuitive model.

We categorize group centrality measures into two types, which exploit the inner and outer information of a group respectively. Approaches that sum or average centrality scores of individuals in this group belong to the first type. As an example of the second type, [7] ranked group C by the nodes that are not in C , but are neighbors to a member in C . Besides, there are some studies on quasi-cliques [13,19], which can be viewed as a special kind of groups. In this paper, we proposed an new influence propagation model to propagate user-defined importance on nodes to others along random walk paths with user control by allowing users to define decay functions. We propose new algorithms to measure the centrality of individuals and groups according to the user X  X  view. We tested our approaches using large real dataset from DBLP, and confirmed the effectiveness and efficiency of our approaches.
 Acknowledgement: The work was supported in part by grants of the Research Grants Council of the Hong Kong SAR, China No. 419109, and National Nature Science Foundation of China No. 70871068, 70890083 and 60873017.

