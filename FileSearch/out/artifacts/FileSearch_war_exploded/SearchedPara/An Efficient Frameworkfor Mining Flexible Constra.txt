 Mining patterns under various kinds of constraints is a key point to get inter-active and successful KDD processes. There is a large collection of constraints which are useful for the user and the latter needs an independent tool to tackle various and flexible queries. The outstandingly useful constraint of frequency is often used in practice. Furthermore, we have efficient algorithms to extract patterns satisfying it. Nevertheless, in the context of constraint-based mining, supplementary constraints like interestingness measures or syntactic constraints have to be added to achieve relevant and desired patterns. The number of ele-mentary constraints and their combinations is too important to build a particular solver dedicated to each constraint. These observations are sound motivations to design and implement a general solver which is able to mine, in a flexible way, patterns checking various and meaningful constraints.
 huge size of the search space which has to be explored (it exponentially increases according to the number of features of the data). Classical algorithms are based on pruning properties in order to reduce the search space. But, unfortunately, these properties are deeply linked to the constraints and many constraints (e.g., average [13], variance [10], growth rate [6]) have been studied individually [1]. Section 2.2 overviews the main classes of constraints and recalls that efficient algorithms are devoted to some of these classes. Several approaches [16, 2] are based on condensed representations of frequent patterns which are easier to mine. We will see that our work uses this approach but without limitation to the classical classes of constraints. The paradigm of inductive databases [8] proposes to handle constraints by reusing existing algorithms (for instance, a complex constraint is decomposed into several constraints having suitable properties like monotonicity). However, the decomposition and the optimization of constraints remain non-trivial tasks [5]. To the best of our knowledge, there is no existing framework presenting at the same time flexibility and effective computation. mine patterns under a constraint specified by the user as a simple parameter. We think that this framework brings three meaningful contributions. First, it allows a large set of constraints: the constraints are described by combinations of SQL -like aggregate primitives and syntactic primitives (see Section 3.1). This formal-ism deals with the most usual constraints (e.g., monotonous, anti-monotonous and convertible ones) and allows to define more original new constraints (e.g., the area constraint which is on the core of our running example). Furthermore, this formalism also enables to combine constraints with boolean operators. Sec-ond, thanks to an automatic process to compute lower and upper bounds of a constraint on an interval and a general pruning operator , the constraint is pushed in the extraction step. Finally, we provide an algorithm called Music ( M ining with a U ser-S pecif I ed C onstraint) which allows the practical use of this frame-work. Music guarantees an efficient pruning to offer short run-time answers and facilitate the iterative process of KDD. We developed a prototype to implement this algorithm.
 sic notations and related work. A running example (i.e., the area constraint) shows the common difficulties of constraint-based mining and the key ideas of our framework. Section 3 depicts the set of constraints that we address, details the theoretical framework and defines the pruning operator. Section 4 indicates how to use it by providing the Music algorithm. Finally, Section 5 presents experimental results showing the efficiency of Music on various constraints. 2.1 Notation Let us first introduce the basic notations. A transactional dataset D is a triplet (
A , O ,R ) where A is a set of attributes, O is a set of objects and R  X  X  X O is a binary relation between the attributes and the objects. ( a, o )  X  R expresses that the object o has the attribute a (see for instance Table 1 where A,...,F denote the attributes and o 1 ,...,o 6 denote the objects). A pattern X is a subset of attributes.
 D and checking a predicate q . The minimal frequency constraint is likely the most usual one (the frequency of a pattern X is the number of objects in D that contain X , i.e. count ( X )  X   X  where  X  is a threshold). Many algorithms since [1] efficiently mine this constraint by using closure or free (or key) patterns [3, 14]. 2.2 Related Work Many works have been done with various complex constraints (e.g., average [13], variance [10], growth rate [6]) providing particular approaches. More gen-erally, we can distinguish several classes of constraints. A well-known class of constraints is based on monotonicity . A constraint q is anti-monotone (resp. monotone) according to the specialization of the attributes if whenever X  X  Y then q ( Y )  X  q ( X )(resp. q ( X )  X  q ( Y )). For instance, the minimal frequency constraint is anti-monotonous. In this case, the search space can be efficiently pruned by a general level-wise algorithm [12]. Another class is the convertible constraints. Such a constraint uses an ordering relation on the attributes in order to obtain properties of monotonicity on the prefixes [15] (typically, the minimal average constraint q 8 is convertible, see Section 3.1 for its exact definition). Let us note that Wang et al. introduce in [18] a method dedicated to the aggregate constraints (e.g. the minimal frequency constraint or the average q 8 ). Unfortunately, the combination of constraints may require again a particular algorithm. For example, a conjunction of two convertible constraints may lead to a no convertible constraint, and a particular algorithm has to been developed. So, several approaches attempt to overcome these difficulties. The inductive databases framework [8] proposes to decompose complex constraints into several constraints having good properties like monotonicity. This approach needs to apply non-trivial reformulations and optimizations of constraints [5]. Introduced in [10], the concept of witness provides properties to simultaneously prune pat-terns under different kinds of constraints. Nevertheless, this approach does not propose a method to automatically obtain witnesses. Thus, instead of building a particular algorithm to mine patterns, a particular algorithm to find witnesses is needed. By exploiting equivalence classes (i.e., a set of patterns having the same outcome with respect to the constraint), condensed representations [4] enable powerful pruning criteria during the extraction which greatly improve the effi-ciency of algorithms [3, 14]. But only few works exploit the equivalence classes with monotonous and anti-monotonous classes [2] or other constraints [9, 16]. Our work follows this approach but it addresses a much more general set of constraints (see Section 3.1). 2.3 Problem Statement and Key Idea of Our Framework Let us come back on the example given by Table 1. Assume that we are interested in all subsets of A having an area greater than 4 i.e. count ( X )  X  length ( X )  X  4 (where length is the cardinality of the pattern). Recently, [7] have dedicated efficient approaches to only mine the closed patterns that check this constraint. The constraint of area is difficult because it is neither monotone ( area ( A )  X  4 but area ( ABF ) &lt; 4), nor anti-monotone ( area ( B ) &lt; 4 but area ( AB )  X  4), nor convertible (no ordering relation exists). None decomposition of this constraint benefits from the properties of these classes of constraints. Thus, the practical approach is to mine all patterns with their own frequency and then to post-process them by checking the constraint on each pattern. Unfortunately, this method fails with large datasets due to a too much number of candidate patterns. characteristics of the constraint to present our pruning strategy of the search space. The main idea is based on the definition of lower and upper bounds of the constraint on an interval, the latter after allows the pruning. We can notice that if X  X  Z  X  Y , the area of the pattern Z can be bounded by that if count ( Y )  X  length ( X )  X  4, the area of the pattern Z is larger than 4 and Z checks the constraint. In this example, with X = AB and Y = ABCD , the area of count ( ABCD )  X  length ( AB ) is equal to 4 and the patterns AB , ABC , ABD , ABCD have an area larger than 4. Thus, it is not necessary to check the con-straint for these four patterns. Similarly, when count ( X )  X  length ( Y ) is strictly smaller than 4, the area of the pattern Z ( X  X  Z  X  Y ) is inevitably smaller than 4. In these two cases, the interval [ X, Y ] can be pruned for this constraint. Also, the patterns AB , ABC , ABD and ABCD , which are included between AB and ABCD , satisfy the constraint. Instead of outputting these four patterns, it is more judicious to only output the corresponding interval [ AB, ABCD ]. This one can be seen as a condensed representation of the patterns with respect to the constraint. This idea -mining a representation of the constrained patterns -is generalized in the next section to a large set of constraints. 3.1 The Set of Constraints Our work deals with the set of constraints Q recursively defined by Table 2. Examples of constraints of Q are given at the end of this section. We claim that Q defines a very large set of constraints.
 the objects O ) i.e. the powerset 2 A (resp. the powerset 2 O ). The set of constraints Q is based on three spaces: the booleans B (i.e., true or false ), the positive reals + and the patterns of L = L A  X  X  O . In addition to the classical operators of these domains, the function count denotes the frequency of a pattern, and length its cardinality. Given a function val : A X  X  X  + , we extend it to a pattern X and note X.val the set { val ( a ) | a  X  X } . This kind of function is used with the usual SQL -like primitives sum , min and max . For instance, sum ( X.val ) is the sum of val of each attribute of X . Finally, f is the intensive function i.e. f ( O )= { a  X  X | X  o  X  O, ( a, o )  X  R } ,and g is the extensive function i.e. g ( A )= { o  X  X | X  a  X  A, ( a, o )  X  R } . We give now some examples of constraints belonging to Q and highlighting the generality of our framework. sufficient conditions to prune the search space. 3.2 Bounding a Constraint on an Interval This section indicates how to automatically compute lower and upper bounds of a constraint of Q on an interval without enumerating each pattern included in the interval. These bounds will be used by the pruning operator (see Section 3.3). noted [ X, Y ]) corresponds to the set { Z  X  X  A | X  X  Z  X  Y } . In our run-ning example dealing with the area constraint, Section 2.3 has shown that count ( Y )  X  length ( X )and count ( X )  X  length ( Y ) are respectively a lower bound and an upper bound of the constraint for the patterns included in the inter-val [ X, Y ]. At a higher level, one can also notice that  X  Z  X  [ X, Y ], we have to false &lt; true . Thus, the area constraint is bounded on the interval. Those bounds only depend on the patterns X and Y and their definitions are the same for any interval [ X, Y ].
 two operators denoted and (see Table 3). Starting from q and [ X, Y ], the recursive application of these operators leads to compute one boolean with (noted q X, Y ) and one boolean with (noted q X, Y ). Property 1 will show that q X, Y (resp. q X, Y ) is a lower bound (resp. an upper bound) of the interval [ X, Y ]for q . In other words, these operators enable to automatically compute lower and upper bounds of [ X, Y ]for q . This result stems from the properties of increasing and decreasing functions. In Table 3, the general notation E i designates one space among B , + or L and E i the associated expressions (for instance, the set of constraints Q for the booleans B ). Several operators given in Table 2 must be split into several operators of Table 3. For instance, the equality e 1 = e 2 is decomposed to ( e 1  X  e 2 )  X  ( e 1  X  e 2 ). In Table 3, the functions are grouped by monotonous properties according to their variables. For instance, the operators  X  , / and \ are increasing functions according to the first variable and decreasing functions according to the second variable. 4 X, Y = count ( X )  X  length ( X ) X, Y  X  4 X, Y = count ( X ) X, Y  X  length ( X ) X, Y  X  4= count ( X X, Y )  X  length ( X X, Y )  X  4= count ( Y )  X  length ( X )  X  4. Symmetrically, count ( X )  X  length ( X )  X  4 X, Y is equal to count ( X )  X  length ( Y )  X  4.
 Property 1 (bounds of an interval). Let q be a constraint, q and q are respectively a lower bound and an upper bound of q i.e. given an interval [ X, Y ] and a pattern Z included in it, we have q X, Y  X  q ( Z )  X  q X, Y . upper bounding operators (due to space limitation the proof is not given here, see [17]). Contrary to most frameworks, these top-level operators allow us to directly use constraints containing conjunctions or disjunctions of other con-straints. Besides, they compute quite accurate bounds. In the particular case of monotonous constraints, these bounds are even exact . They have other mean-ingful properties (linearity or duality) which are not developed here (details in [17]). 3.3 Pruning Operator In this section, we define an operator, starting from a constraint q , which provides a condition to safely prune or not an interval. As for the area constraint, there are two different strategies to prune an interval [ X, Y ] by using the bounds of q . If a lower bound of q on [ X, Y ] is equal to true (i.e., the lower bound checks q ), all the patterns included in [ X, Y ] check q because they are all greater than true . We say that we positively prune the patterns of [ X, Y ]. Conversely, we can negatively prune [ X, Y ] when an upper bound is false because all the patterns of [ X, Y ]donotcheck q . Note that witnesses [10] already exploit these two kinds of pruning. We define now the pruning condition for q and the pruning operator. Definition 1 (pruning operator). Let q be a constraint, the pruning condition for q , denoted by [ q ] , is equal to q  X  X  q . [ ] is called the pruning operator. the positive pruning, and  X  q to the negative one. For instance, the pruning condition for the area constraint on an interval [ X, Y ]is( count ( Y )  X  length ( X )  X  4)  X  ( count ( X )  X  length ( Y ) &lt; 4). This conjunction corresponds to the two cases allowing us to prune intervals (see Section 2.3).
 Theorem 1. Let q be a constraint and [ X, Y ] an interval, if [ q ] X, Y is true , then all the patterns included in [ X, Y ] have the same value for q . value of any pattern of [ X, Y ] by checking only one pattern. Thereby, [ X, Y ]can be pruned without having to check the constraint on whole patterns of [ X, Y ]. Section 4 details how to prune the search space with the pruning condition. not give the greatest lower (resp. the least upper) bound. However, in practice, the pruning operator often provides powerful pruning (see Section 5). Music ( M ining with a U ser-S pecif I ed C onstraint) is a level-wise algorithm which takes advantage of the pruning operator to efficiently mine constrained patterns and get a representation of these patterns. It takes one constraint q belonging to Q as input and one additional anti-monotonous constraint q AM to benefit from the usual pruning of level-wise algorithm [1] (line 4). The com-pleteness with respect to q is ensured by sticking true for q AM . Music returns in output all the intervals containing the patterns checking q  X  q AM . Music is based on tree key steps: the creating of the generators similar to one used in [1] (line 14), the evaluation of candidates by scanning the dataset in order to compute the extension of patterns (line 3), and finally the testing candidates (lines 7-12). Its main originality is that the  X  X ested candidates X  are different from generators and they are intervals instead of patterns.
 erator (i.e., a free pattern or an additionnal candidate) and the right one, its closure (i.e., a closed pattern). The closed patterns are exactly the fixed points of the closure operator h = f  X  g . An important property on the extension stems from the closure: g ( X )= g ( h ( X )). Moreover, as the closure operator is exten-sive, any pattern is a subset of its closure and the interval [ X, h ( X )] has always a sense. The pruning condition is pushed into the core of the mining by applying it on the intervals defined above. Such an approach enables a powerful pruning criterion during the extraction thanks to the use of an anti-monotonous con-straint based on the freeness [3] (line 4). If an interval [ X, h ( X )] satisfies the pruning condition, all the patterns in [ X, h ( X )] are definitively pruned. Other-wise, some patterns of [ X, h ( X )] are added as additional candidates to repeat the same process on shorter intervals (line 11). The computation of the ex-tension for each pattern (line 3) is sufficient to deduce the values of all the primitives given by Table 2 even if they depend on the dataset like g or count . In particular, the frequency of a pattern X is length ( g ( X )) and the closure of X is computed with f ( g ( X )). Note that the additionnal candidates have a low cost because they belong to [ X, h ( X )] and their extension is equal to g ( h ( X )).
 correction of Music (see [17] for a formal proof). All the patterns are comprise between a free pattern and its closure. As Music covers all the free patterns, all the intervals [ X, h ( X )] are checked by the pruning condition. There are two cases. First, if the pruning condition is true, all the patterns included in [ X, h ( X )] are checked. Otherwise, the patterns included in [ X, h ( X )] are enumerated level by level until that the interval between it and its closure can be pruned (that always arises because [ q ] X, X = true ). Thus, the whole search space is covered. The aim of our experiments is to measure the run-time benefit brought by our framework on various constraints (i.e., constraints q 1 ,...,q 14 defined in Sec-tion 3.1). All the tests were performed on a 700 GHz Pentium III processor with Linux and 1Go of RAM memory. The used dataset is the version of mushroom coming from the FIMI repository 1 . The constraints using numeric values were applied on attribute values (noted val ) randomly generated within the range [1,100]. We compare our algorithm with an Apriori -like approach (i.e., mining all patterns according to q AM and using a filter to select patterns checking q ). ing to q 1 ,...,q 14 . With the constraint q 1 , Music has no additional candidates and its behavior is similar than [3]. That shows the abilities of Music towards usual constraints. The best performances are achieved by the constraints q 3 , q 4 , q , q 9 and q 10 because the number of additional candidates in these cases is very low. On the other hand, the three worst performances (i.e., q 2 , q 5 and q 8 )are obtained with the constraints including length . It is interesting to observe that the run-time performances are independent of the complexity of the constraint (i.e., the number of combinations). For instance, a very complex constraint such as q 10 is quickly mined and a conjunction of constraint such as q 2  X  q 3 has bet-ter results than q 2 alone. This fact can be explained with the improvement of the selectivity of the constraint. Additional results are given in [17]. The good behavior of Music with complex constraints allows the user to ask a broad set of queries and to mine constrained patterns which were intractable until now. In this paper, we have proposed a new and general framework to efficiently mine patterns under constraints based on SQL -like and syntactic primitives. This framework deals with boolean combinations of the usual constraints and allows to define new complex constraints. The efficiency of the approach relies on the pruning of the search space on intervals which are took into account by a general pruning operator. Starting from this approach, Music algorithm mines soundly and completely patterns under a primitive-based constraint given by the user as a simple parameter. The experimental results show that Music clearly out-performs Apriori with all constraints. New tough constraints can be mined in large datasets. We think that our algebraisation is an important step towards the integration of the constraint-based mining in database systems.
 the generality of our framework, we would like also to know if other primi-tives used to define constraints should be useful to achieve successful KDD pro-cesses from real world data set. We think that our ongoing work on geographical datasets is a good way to test new expressive queries specified by a geographer expert and the usefulness of the primitives.
 Acknowledgements. This work has been partially founded by the ACI  X  Bingo  X .
