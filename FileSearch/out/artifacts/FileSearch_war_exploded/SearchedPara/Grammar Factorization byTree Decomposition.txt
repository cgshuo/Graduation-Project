 University of Rochester tems. We show that any polynomial-time algorithm for this problem would imply an improved approximation algorithm for the well-studied treewidth problem on general graphs. 1. Introduction
In this article, we describe meta-algorithms for parsing: algorithms for finding the optimal parsing algorithm for a given grammar, with the constraint that rules in the grammar are considered independently of one another. In order to have a common representation for our algorithms to work with, we represent parsing algorithms as weighted deduction systems (Shieber, Schabes, and Pereira 1995; Goodman 1999;
Nederhof 2003). Weighted deduction systems consist of axioms and rules for building items or partial results. Items are identified by square brackets, with their weights written to the left. Figure 1 shows a rule for deducing a new item when parsing a context free grammar (CFG) with the rule S  X  AB . The item below the line, called the consequent , can be derived if the two items above the line, called the antecedents , have been derived. Items have types, corresponding to grammar nonterminals in this example, and variables , whose values range over positions in the string to be parsed.
We restrict ourselves to items containing position variables directly as arguments; no other functions or operations are allowed to apply to variables. The consequent X  X  weight is the product of the weights of the two antecedents and the rule weight w the notation is the fact that we take the maximum weight over all derivations of the same item. Thus, the weighted deduction system corresponds to the Viterbi or max-product algorithm for parsing. Applications of the same weighted deduction system with other semirings are also possible (Goodman 1999).
 ations of variables in the system X  X  deduction rules. If the total number of instantiations is M ,parsingis O ( M ) if there are no cyclic dependencies among instantiations, or, w 0 w 1 w 2 :[ S , x 0 , x 2 ] variables range over positions in the input string. In order to determine complexity in the length n of the input string, it is sufficient to count the number of unique position variables in each rule. If all rules have at most k position variables, M = O ( n we will explore methods for minimizing k , the largest number of position variables in any rule, among equivalent deduction systems. These methods directly minimize the parsing complexity of the resulting deduction system. Although we will assume no cyclic dependencies among rule instantiations for the majority of the article, we will discuss the cyclic case in Section 2.2.
 by decomposing the computation into two or more new rules, each having a smaller number of variables than the original rule. We refer to this process as factorization .One straightforward example of rule factorization is the binarization of a CFG, as shown in
Figure 2. Given a deduction rule for a CFG rule with r nonterminals on the righthand rule X  X  righthand side has been recognized. This type of rule factorization produces an O ( n 3 ) parser for any input CFG.
 Satta (1999), which reduces the complexity of parsing for bilexicalized CFGs from marked with lexical heads as shown in Figure 3a. Here items with type C indicate position x 1 , headed by the word at position h . The item [ D , m the weight assigned by the grammar to a bilexical dependency headed by the word at a) w b) w 1 w 2 :[ X , x 0 , x 2 ] 232 a) w w 1 w 2 :[ C , x 0 , h , x 2 ] b) w w 2 :[ H , h , x 1 , x 2 ] position h with the word at position m as a modifier. The deduction rule is broken into two steps, one which includes the weight for the bilexical grammar rule, and another which identifies the boundaries of the new constituent, as shown in Figure 3b. The hook trick has also been applied to Tree Adjoining Grammar (TAG; Eisner and Satta 2000), and has been generalized to improve the complexity of machine translation decoding under synchronous context-free grammars (SCFGs) with an n -gram language model (Huang, Zhang, and Gildea 2005).
 monolingual CFGs, SCFGs cannot always be binarized; depending on the permutation between nonterminals in the two languages, it may or may not be possible to reduce the rank, or number of nonterminals on the righthand side, of a rule. Algorithms for finding the optimal rank reduction of a specific rule are given by Zhang and Gildea (2007). The complexity of synchronous parsing for a rule of rank r is O ( n improves parsing complexity.
 (LCFRS), which generalize CFG, TAG, and SCFG to define a rewriting system where nonterminals may have arbitrary fan-out , which indicates the number of continuous spans that a nonterminal accounts for in the string (Vijay-Shankar, Weir, and Joshi 1987).
Recent work has examined the problem of factorization of LCFRS rules in order to as factorization with the goal of directly minimizing the parsing complexity of the new grammar (Gildea 2010).
 independently. Individual rules are replaced with an equivalent set of new rules, which must derive the same set of consequent items as the original rule given the same an-tecedent items. While new intermediate items of distinct types may be produced, the set of items and weights derived by the original weighted deduction system is unchanged.
This definition of factorization is broad enough to include all of the previous examples, but does not include, for example, the fold/unfold operation applied to grammars by
Johnson (2007) and Eisner and Blatz (2007). Rule factorization corresponds to the unfold operation of fold/unfold.
 most efficient equivalent system is undecidable; this follows from the fact that it is un-decidable whether a CFG generates the set of all strings (Bar-Hillel, Perles, and Shamir 1961), and would therefore be recognizable in constant time. Whereas the fold/unfold operation of Johnson (2007) and Eisner and Blatz (2007) specifies a narrower class of grammar transformations, no general algorithms are known for identifying an optimal series of transformations in this setting. Considering input rules independently allows us to provide algorithms for optimal factorization.
 tive parsing systems in order to minimize computational complexity. We show how to apply the graph-theoretic property of treewidth to the factorization problem, and examine the question of whether efficient algorithms exist for optimizing the parsing complexity of general parsing systems in this framework. In particular, we show that the existence of a polynomial time algorithm for optimizing the parsing complexity of general LCFRS rules would imply an improved approximation algorithm for the well-studied problem of treewidth of general graphs. 2. Treewidth and Rule Factorization
In this section, we introduce the graph-theoretic property known as treewidth, and show how it can be applied to rule factorization.
 vertices at each node. We define the nodes of this tree T to be the set I , and its edges to be the set F . The subset of V associated with node i of T is denoted by X decomposition is therefore defined as a pair ( { X i | i  X  is a subset of V , and tree T has the following properties:
The treewidth of a tree decomposition ( { X i } , T )ismax graph is the minimum treewidth over all tree decompositions: tion achieving the minimum possible treewidth as being optimal.
 has treewidth = 1; a graph consisting of one large cycle has treewidth = 2, and a fully connected graph of n vertices has treewidth = n  X  1. Low treewidth indicates some tree-like structure in the graph, as shown by the example with treewidth = 2inFigure4.As an example of the running intersection property, note that the vertex N appears in three adjacent nodes of the tree decomposition. Finding the treewidth of a graph is an NP-complete problem (Arnborg, Corneil, and Proskurowski 1987). However, given a graph of n vertices and treewidth k , a simple algorithm finds the optimal tree decomposition in time O ( n k + 2 ) (Arnborg, Corneil, and Proskurowski 1987), and a variety of approxima-tion algorithms and heuristics are known for the treewidth problem (Bodlaender et al. 1995; Amir 2001; Feige, Hajiaghayi, and Lee 2005). Furthermore, for fixed k ,optimaltree decompositions can be computed in linear time (Bodlaender 1996). 234 call a dependency graph , and searching for tree decompositions of this graph. For a rule r having n variables V = { v i | i  X  X  1, ... , n }} , m antecedent items A and consequent C ,let V ( A i )  X  V be the variables appearing in antecedent A be the variables appearing in the consequent. The dependency graph representation of theruleis G r = ( V , E = S : A each variable in the rule, and connect any two vertices that appear together in the same antecedent, or that appear together in the consequent.
 cerning parsing complexity: Theorem 1
Given a deduction rule r for parsing where the input string is referenced only through position variables appearing as arguments of antecedent and consequent items, the opti-mal complexity of any factorization of rule r is O ( n tw ( G graph derived from r .
 Proof
One consequence of the definition of a tree decomposition is that, for any clique appear-ing in the original graph G r , there must exist a node in the tree decomposition T which contains all the vertices in the clique. We use this fact to show that there is a one-to-one correspondence between tree decompositions of a rule X  X  dependency graph G factorizations of the rule.
 the same set of consequent items from a given set of antecedent items as the original decomposition T must have a node X c such that V ( C )  X  X the root of T . The original deduction rule can be factorized into a new set of rules, one nodes X i have a new partial result as a consequent, consisting of the variables X where X j is X i  X  X  neighbor on the path to the root node X factorized rule set yields the same result as the original rule, namely, the semiring sum over all variable values of the semiring product of the antecedents X  weights. The tree structure of T corresponds to a factorization of this semiring expression. For example, if we represent the CFG rule of Figure 2a with the generalized semiring expression: the factorization of this expression corresponding to the binarized rule is where semiring operations  X  and  X  have been interchanged as allowed by the depen-dency graph for this rule.
 decomposition T must contain at least one node which includes all variables V ( A
We can choose one such node and multiply in the weight of A tree decomposition guarantees that each variable has a consistent value at each point where it is referenced in the factorization.
 tree decomposition of the graph G r . We consider the tree decomposition with a set X for each new rule r i , consisting of all variables used in r by the producer/consumer relation over intermediate results in the rule factorization.
Each antecedent of the original rule must appear in some new rule in the factorization, as must the consequent of the original rule. Therefore, all edges in the original rule X  X  dependency graph G r appear in some tree node X i . Any variable that appears in two intersection property of the tree decomposition ( { X i } when viewed as a tree of sets of variables, has the properties that make it a valid tree decomposition of G r .
 rule factorizations and tree decompositions. 2.1 Computational Complexity
Factorization produces, for each input rule having m antecedents, at most m rules, each containing at most the same number of nonterminals and the same number of variables as the input rule. Hence, the size of the new factorized grammar is O ( and we avoid any possibility of an exponential increase in grammar size. Tighter bounds can be achieved for specific classes of input grammars.
 exponential in the size of the input rules. However, optimal factorization is generally feasible whenever parsing with the unfactorized grammar is feasible. This is because, for an input rule with variables, parsing is O ( n ) in the sentence length n .The treewidth of this rule is at most  X  1, and can be computed in time O ( expect n to be greater than . One may also wish to accept only rules having treewidth k and disregard the remainder, for example, when factorizing rules automatically 236 extracted from word-aligned bitext (Wellington, Waxmonsky, and Melamed 2006;
Huang et al. 2009) or from dependency treebanks (Kuhlmann and Nivre 2006; Gildea 2010). In this setting, the rules having treewidth k can be identified in time O ( the simple algorithm of Arnborg, Corneil, and Proskurowski (1987), (where again is the number of variables in the input rules), or in time O ( ) using the algorithm of
Bodlaender (1996). 2.2 Cyclic Dependencies
Although this article primarily addresses the case where there are no cyclic dependen-cies between rule instantiations, we note here that our techniques carry over to the cyclic case under certain conditions. If there are cycles in the rule dependencies, but the semiring meets Knuth X  X  (1977) definition of a superior function, parsing takes time
O ( M log M ), where M is the number of rule instantiations, and the extra log M term accounts for maintaining an agenda as a priority queue (Nederhof 2003). Cycles in the rule dependencies may arise, for example, from chains of unary productions in a
CFG; the properties of superior functions guarantee that unbounded chains need not be considered. The max-product semiring used in Viterbi parsing has this property, assuming that all rule weights are less than one, whereas for exact computation with the sum-product semiring, unbounded chains must be considered. As in the acyclic case, M = O ( n k ) for parsing problems where rules have at most k variables. Under the assumption of superior functions, parsing takes time O ( n algorithm. In this setting, as in the acyclic case, minimizing k with tree decomposition minimizes parsing complexity. 2. 3Related Applications of Treewidth
The technique of using treewidth to minimize complexity has been applied to constraint satisfaction (Dechter and Pearl 1989), graphical models in machine learning (Jensen,
Lauritzen, and Olesen 1990; Shafer and Shenoy 1990), and query optimization for databases (Chekuri and Rajaraman 1997). Our formulation of parsing is most closely related to logic programming; in this area treewidth has been applied to limit complex-ity in settings where either the deduction rules or the input database of ground facts have fixed treewidth (Flum, Frick, and Grohe 2002). Whereas Flum, Frick, and Grohe (2002) apply treewidth to nonrecursive datalog programs, our parsing programs have unbounded recursion, as the depth of the parse tree is not fixed in advance. Our results for parsing can be seen as a consequence of the fact that, even in the case of unbounded recursion, the complexity of (unweighted) datalog programs is linear in the number of possible rule instantiations (McAllester 2002). 3. Examples of Treewidth for Parsing
In this section, we show how a few well-known parsing algorithms can be derived automatically by finding the optimal tree decomposition of a dependency graph. factor graph representation based on that of Kschischang, Frey, and Loeliger (2001) for
Markov Random Fields. Our graphs have three types of nodes: variables, antecedents, and consequents. Each antecedent node is connected to the variables it contains, and represents the antecedent X  X  weight as a function of those variables. Antecedent nodes are analogous to the factor nodes of Kschischang, Frey, and Loeliger (2001), and consequent nodes are a new feature of this representation. We can think of consequents as factors with weight = 1; they do not affect the weights computed, but serve to guarantee that the consequent of the original rule can be found in one node of the tree decomposition. We refer to both antecedent and consequent nodes as factor nodes. Re-placing each factor node with a clique over its neighbor variables yields the dependency graph G r defined earlier. We represent variables with circles, antecedents with squares labeled with the antecedent X  X  weight, and consequents with diamonds labeled c .An example factor graph for the simple CFG rule of Figure 1 is shown in Figure 5. 3.1 CFG Binarization
Figure 6a shows the factor graph derived from the monolingual CFG rule with four children in Figure 2a. The dependency graph obtained by replacing each factor with a clique of size 2 (a single edge) is a graph with one large cycle, shown in Figure 6b.
Finding the optimal tree decomposition yields a tree with nodes of size 3, for each i , shown in Figure 6c. Each node in this tree decomposition corresponds to one of the factored deduction rules in Figure 2b. Thus, the tree decomposition shows us how 238 equivalent to converting to Chomsky Normal Form. 3.2 The Hook Trick
The deduction rule for bilexicalized parsing shown in Figure 3a translates into the factor graph shown in Figure 7a. Factor nodes are created for the two existing constituents from the chart, with the first extending from position x 0 second from x 1 to x 2 . Both factor nodes are connected not only to the start and end points, but also to the constituent X  X  head word, h for the first constituent and m for the second (we show the construction of a left-headed constituent in the figure). An additional factor is connected only to h and m to represent the bilexicalized rule weight, expressed as a function of h and m , which is multiplied with the weight of the two existing constituents to derive the weight of the new constituent. The new constituent is represented by a consequent node at the top of the graph X  X he variables that will be relevant for its further combination with other constituents are its end points x and its head word h .
 ure 7b. If we compute the optimal tree decomposition for this graph, shown in Figure 7c, each of the two nodes corresponds to one of the factored rules in Figure 3b. The largest node of the tree decomposition has four variables, giving the O ( n and Satta (1999). 3.3 SCFG Parsing Strategies
SCFGs generalize CFGs to generate two strings with isomorphic hierarchical structure simultaneously, and have become widely used as statistical models of machine transla-tion (Galley et al. 2004; Chiang 2007). We write SCFG rules as productions with one lefthand side nonterminal and two righthand side strings. Nonterminals in the two strings are linked with superscript indices; symbols with the same index must be further rewritten synchronously. For example, is a rule with four children and no reordering, whereas expresses a more complex reordering. In general, we can take indices in the first righthand-side string to be consecutive, and associate a permutation  X  with the second string. If we use X i for 0  X  i  X  n as a set of variables over nonterminal symbols (for example, X 1 and X 2 may both stand for nonterminal A ), we can write rules in the general form: guages of string pairs generated by a synchronous grammar can be arranged in an infinite hierarchy, with each rank  X  4 producing languages not possible with grammars restricted to smaller rules (Aho and Ullman 1972). For any grammar with maximum rank r , converting each rule into a single deduction rule yields an O ( n algorithm, because there are r + 1 boundary variables in each language. More efficient parsing algorithms are often possible for specific permutations, and, by Theorem 1, the best algorithm for a permutation can be found by computing the minimum-treewidth tree decomposition of the graph derived from the SCFG deduction rule for a specific permutation. For example, for the non-binarizable rule of Equation (2), the resulting factor graph is shown in Figure 8a, where variables x 0 , ... , x in one language of the synchronous grammar, and y 0 , ... , y language. The optimal tree decomposition for this rule is shown in Figure 8c. For this permutation, the optimal parsing algorithm takes time O ( n in the tree decomposition of Figure 8c includes eight position variables. This result is intermediate between the O ( n 6 ) for binarizable SCFGs, also known as Inversion Trans-duction Grammars (Wu 1997), and the O ( n 10 ) that we would achieve by recognizing the rule in a single deduction step.
 number of nonterminals r in an SCFG rule grows, the parsing complexity grows as lengths.
 to long CFG rules results in a deduction system equivalent to a binarized CFG, the individual deduction steps in the best parsing strategy for an SCFG rule do not in general correspond to SCFG rules. This is because the intermediate results may include more than one span in each language. These intermediate deduction steps do, however, correspond to LCFRS rules. We now turn to examine LCFRS in more detail. 240 4. LCFRS Parsing Strategies
LCFRS provides a generalization of a number of widely used formalisms in natural language processing, including CFG, TAG, SCFG, and synchronous TAG. LCFRS has also been used to model non-projective dependency grammars, and the LCFRS rules extracted from dependency treebanks can be quite complex (Kuhlmann and Satta 2009), making factorization important. Similarly, LCFRS can model translation relations beyond the power of SCFG (Melamed, Satta, and Wellington 2004), and grammars extracted from word-aligned bilingual corpora can also be quite complex (Wellington,
Waxmonsky, and Melamed 2006). An algorithm for factorization of LCFRS rules is presented by Gildea (2010), exploiting specific properties of LCFRS. The tree decompo-sition method achieves the same results without requiring analysis specific to LCFRS.
In this section, we examine the complexity of rule factorization for general LCFRS grammars.

NP-complete. This follows from the NP-completeness of treewidth using the following construction: Given a graph, create a deduction rule with a variable for each vertex in the graph and an antecedent for each edge, containing the two variables associated with the edge X  X  endpoints. The graphs produced by LCFRS grammar rules, however, have certain properties which may make more efficient factorization algorithms possible. We first define LCFRS precisely before examining the properties of these graphs. symbols, V N is a set of nonterminal symbols, P is a set of productions, and S distinguished start symbol. Associated with each nonterminal B is a fan-out  X  ( B ), which tells how many continuous spans B covers. Productions p  X  where A , B 1 , ... , B r  X  V N ,and g is a function and non-erasing , which means that if we write the tuple of strings t 1 , ... , t  X  ( A ) on the righthand side contains each variable s the lefthand side exactly once, and may also contain terminals from V generating a string from an LCFRS grammar can be thought of as first choosing, top-down, a production to expand each nonterminal, and then, bottom X  X p, applying the functions associated with each production to build the string. As an example, the CFG corresponds to the following grammar in LCFRS notation: productions X  functions contain just one string. As CFG is equivalent to LCFRS with fan-out = 1, SCFG and TAG can be represented as LCFRS with fan-out = 2. Higher values of fan-out allow strictly more powerful grammars (Rambow and Satta 1999). Polynomial-time parsing is possible for any fixed LCFRS grammar, but the degree of the polynomial depends on the grammar. Parsing general LCFRS grammars, where the grammar is considered part of the input, is NP-complete (Satta 1992). 4.1 Graphs Derived from LCFRS Rules
Given an LCFRS rule as defined previously, a weighted deduction rule for a bottom X  up parser can be derived by creating an antecedent for each righthand nonterminal, a consequent for the lefthand side, and variables for all the boundaries of the non-terminals in the rule. A nonterminal of fan-out f has 2 f boundaries. Each boundary 242 variable will occur exactly twice in the deduction rule: either in two antecedents, if two nonterminals on the rule X  X  righthand side are adjacent, or once in an antecedent and once in the consequent, if the variable indicates a boundary of any segment of the rule X  X  lefthand side.
 of the dependency graph may be arbitrarily large, due to the unbounded fan-out of
LCFRS nonterminals. However, each vertex appears in only two cliques, because each boundary variable in the rule is shared by exactly two nonterminals. In the remainder of this section, we consider whether the problem of finding the optimal tree decomposition of this restricted set of graphs is also NP-complete, or whether efficient algorithms may be possible in the LCFRS setting. 4.2 Approximation of Treewidth for General Graphs We will show that an efficient algorithm for finding the factorization of an arbitrary
LCFRS production that optimizes parsing complexity would imply the existence of an algorithm for treewidth that returns a result within a factor of 4  X  ( G ) of the optimum, where  X  ( G ) is the maximum degree of the input graph. Although such an approxima-tion algorithm may be possible, it would require progress in fundamental problems in graph theory.

We wish to construct a new graph G = ( V , E )from G in such a way that tw ( G ) = tw ( G ) and every vertex in G has even degree. This can be accomplished by doubling the graph X  X  edges in the manner shown in Figure 9. To double the edges, for every edge include every edge in the original graph G in G . Now, every vertex v in G has degree = 2, if it is a newly created vertex, or twice the degree of v in G otherwise, and therefore decomposition of G can be adapted to a tree decomposition of G by adding a node node can be attached to a node containing u and v ; because u and v are connected by an edge in G , such a node must exist in G  X  X  tree decomposition. The vertex  X  e will not occur anywhere else in the tree decomposition, and the occurrences of u and v still form a connected subtree. For each edge e = ( u , v )in G , the tree decomposition must have a is already a node in the tree decomposition containing u and v , whereas if e is an edge to a newly added vertex in G , one of the newly added nodes in the tree decomposition will contain its endpoints. We constructed the new tree decomposition by adding nodes of size 3. Therefore, as long as the treewidth of G was at least 3, tw ( G ) the other direction, because G is a subgraph of G , any tree decomposition of G forms a valid tree decomposition of G after removing the vertices in G tw ( G ). Therefore, path visiting every edge exactly once, beginning and ending at the same vertex. Let  X  =  X  1 , ... ,  X  n be the sequence of vertices along such a tour, with  X  the sequence  X  contains repeated elements. Let  X  i , i  X  X  times we have visited  X  i on the i th step of the tour:  X 
We now construct an LCFRS production P with | V | righthand side nonterminals from the Eulerian tour:
Eulerian tour. The fan-out of the lefthand side nonterminal X is one, and the lefthand side is constructed by concatenating the spans of each nonterminal in the order specified by the Eulerian tour.
 This tour results in the following LCFRS production:
P the technique of Section 2. G has n + 1 vertices, corresponding to the beginning and 244 end points of the nonterminals in P . The edges in G are formed by adding a clique for each nonterminal in P connecting all its beginning and end points, that is, for a nonterminal of fan-out f . We must include a clique for X , the lefthand side of the production. However, because the righthand side of the production begins and ends with the same nonterminal, the vertices for the beginning and end points of X are already connected, so the lefthand side does not affect the graph structure for the entire production. By Theorem 1, the optimal parsing complexity of P is tw ( G ) + 1. corresponds to a vertex in G , and every vertex in G corresponds to a clique in G .
We can identify vertices in G with unordered pairs of vertices example production P ex is shown in Figure 11.
 tion T of G by simply replacing each vertex in each node of T with both corresponding vertices in G .If T witnesses a tree decomposition of optimal width k = tw ( G ), each node in T will produce a node of size at most 2 k in T . For any vertex v in G ,one node in T must contain the clique corresponding to v in G . Each vertex must be found in a contiguous subtree of T , and these subtrees all include the node containing the clique for v . The occurrences of v in T are the union of these contiguous subtrees, which must itself form a contiguous subtree. Furthermore, each edge ( u , v )in G corresponds to some vertex in G ,so u and v must occur together in some node of T . Combining these two properties, we see that T is a valid tree decomposition of G . From the construction, if SOL is the treewidth of T , we are guaranteed that tree decomposition T of G by simply replacing each occurrence of vertex v in a node
Each vertex { v , w } occurs in a contiguous subtree of T because v and w occurred in contiguous subtrees of T , and had to co-occur in at least one node of T . Each edge in G comes from a clique for some vertex v in G , so the edge has both its endpoints in any node of T corresponding to a node of T that contained v .Thus T is a valid tree decomposition of G . We expand each node in the tree decomposition by at most the maximum degree of the graph  X  ( G ), and therefore strategy of an arbitrary LCFRS rule. Consider the following algorithm for finding a tree decomposition of an input graph G : Equation (7). Putting these together: and using Equations (4) and (5) to relate our result to the original graph G , This last inequality proves the main result of this section Theorem 2
An algorithm for finding the optimal parsing strategy of an arbitrary LCFRS production would imply a 4  X  ( G ) approximation algorithm for treewidth.
 lem. The best-known result is the O ( log k ) approximation result of Feige, Hajiaghayi, although polynomial-time factorization of LCFRS rules to optimize parsing complexity may be possible, it would require progress on general algorithms for treewidth. 5. Conclusion
We have demonstrated that a number of techniques used for specific parsing prob-lems can be found algorithmically from declarative specifications of the grammar.
Our method involves finding the optimal tree decomposition of a graph, which is in general an NP-complete problem. However, the relation to tree decomposition allows us to exploit existing algorithms for this problem, such as the linear time algorithm of Bodlaender (1996) for graphs of bounded treewidth. In practice, grammar rules are 246 typically small, and finding the tree decomposition is not computationally expensive, and in fact is trivial in comparison to the original parsing problem. Given the special structure of the graphs derived from LCFRS productions, however, we have explored whether finding optimal tree decompositions of these graphs, and therefore optimal parsing strategies for LCFRS productions, is also NP-complete. Although a polynomial time algorithm for this problem would not necessarily imply that P = NP , it would require progress on fundamental, well-studied problems in graph theory. Therefore, it does not seem possible to exploit the special structure of graphs derived from LCFRS productions.
 Acknowledgments References
