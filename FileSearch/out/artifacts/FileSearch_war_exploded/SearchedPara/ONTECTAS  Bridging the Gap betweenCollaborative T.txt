 Ontologies organize information in content management systems and are the core building blocks of the emerging Semantic Web. Substantial work has been done in extracting ontologies automatically from large repositories like text cor-pora, databases, and the web. This paper focuses on collaborative social tagging systems (CTSs) such as Del.icio.us (for t agging bookmarks), Flickr (for tagging photos), IMDb (for tagging movies), LibraryThing (for tagging books) and Ci-teULike (for tagging publications). These systems permit users to tag and share resources (documents, photos, videos, etc.). Our goal is to create a generic on-tology of the tags from a CTS. By ontology, we mean a set of concepts from a domain, represented by the tags, and their ( is-a and has-a ) relationships.
Learning an ontology from a CTS can help make the CTS more useful. For example, browsing an ontology of tags from a CTS can help users better refine their queries, either to find more items by using a more general term or to find fewer items by using a more specific term. This is especially important in a CTS since the resources are typically labeled by a small, sparse, set of tags  X  so discovering content in CTSs by simple keyword search is much harder than in document and web search. Another application of domain specific ontology builders is to enhance search engines with ontologies. E.g., the prototype Clever Search system [15] merges words and their word senses in the general ontology, WordNet 1 , and returns more relevant result items to the user.
In principle, we could use a general purpose ontology such as WordNet to browse a CTS; there are two disadvantages. First, tags in CTSs are not based on a fixed vocabulary but constantly evolve. Thus, one cannot expect WordNet (or similar systems) to capture the vocabulary in a dynamic CTS, e.g.,  X  X ac OS X X . Secondly, as we demonstrate in Section 7, even when terms corresponding to tags in a CTS are present in WordNet, in many cases, valid is-a relationships between them that are found by our algorithm are missing in WordNet. This mirrors a similar finding for the ontology extracted from Wikipedia using YAGO [25]; using a combination of WordNet and Wikipedia found significantly more ontological relationships (including is-a ) that were absent in WordNet.

This paper studies the following problem: given a collaborative tagging system consisting of users, resources (also called items), and tags assigned by users to items, extract an ontology consisting of tags in the CTS and is-a and has-a rela-tionships between the tags. We consider has-a relationships in addition to is-a : indeed, is-a and has-a relationships are among those most used in ontologies with rich relationsh ips, such as WordNet.

Our algorithm for ontology extraction from CTSs is predicated on the hy-pothesis that tags assigned to a resource by a group of users tend to contain both child and parent tags. We have conducted experiments to validate this assumption in the full version of our paper[20]. A possible explanation for this phenomenon is that different users may use tags at different levels of abstraction (from an underlying ontology in their mind); thus tags for the same item may include more abstract or more specific terms as an aggregation effect of various tagging behaviors. We leverage this hypothesis using association rules [1] and lexico-syntactic patterns to find relati onships between tags. Our approach ac-counts for bi-grams (which can affect the precision of detected relationships), multi-word tags, and also infer non-trivial is-a relationships fro m detected ones. We make the following contributions:  X  We propose (Sections 4 through 6) an algorithm for ontology extraction from  X  We demonstrate via a comprehensive set of experiments on four real datasets Section 2 discusses related work. Section 3 formalizes the problem studied in this paper. Section 8 concludes and discusses future work. Some other works have studied extracting ontologies from CTSs. Some ap-proaches [16,18,2] match CTS tags to concepts in general purpose ontologies such as WordNet, resulting in a graph of tags. However, because CTSs are ad-hoc and use terms dynamically, general purpose ontologies miss many terms as well as edges (i.e., relationships). For example, our experiments show that WordNet misses more than 25% of correct edges between concepts extracted from Del.icio.us, even when both parent and child concepts are in WordNet .
Schmitz [23] constructs weighted graphs based on conditional probabilities between pairs of tags. His algorithm cannot identify the exact relationship (e.g., is-a and has-a ) between terms  X  it simply says they are related, not how. By contrast, our algorithm pinpoints is-a and has-a relationships between terms.
Heymann and Garcia-Molina [10] create an ontology by vectorizing the tags and finding the cosine similarity between tags. However, their method puts every tag from the similarity matrix into the taxonomy which causes many erroneous edges. Their work lacks an evaluation.

Schmitz et al. [22] use association rule mining to build a tree of related tags from a CTS; however, they do not explain how the edges are built or what types of relationships they model. We explain this in depth and also use lexico-syntactic patterns and a search eng ine to detect accurate is-a and has-a relationships. [24] extends [22] and [10] by considering the tag X  X  context. Barla and Bielikov  X  a[3] consider tag context similarly to [24].
 The DAG algorithm [5] distinguishes be tween subjective and objective tags. After calculating feature vectors for each objective tag, DAG places tags with higher entropy in higher levels of abstr action. Like many other previous works, DAG does not determine the type of relationship between concepts.

Lin et al. [19] build a subsumption graph from the folksonomy and use a random walk to sort tags by generality ranking. They put tags in the taxonomy based on support and confidence between candidate nodes from the graph. They only consider a single sense for each tag, which leads to missed relationships. The authors claim building transactions for tags associated to items by specific users will lead to the best taxonomy because it preserves most of the information. In contrast, we found that user information does not improve taxonomy quality.
K  X  orner et al. [14] categorize users by the kind of tags they use. They show that excluding some users can reduce noise and improve precision. This improvement is orthogonal to the contribution we make in this paper and is applicable in our context as well. We leave adapting ONTECTAS to this as future work.

Hearst [9] defines a set of patterns that indicate is-a relationships between words in text documents. [4,6] find patterns for detecting has-a relationships from text corpora. To our knowledge, our work is the first to extend the lexico-syntactic patterns to find relationships of any type between tags in CTSs.
In sum, in contrast to previous works on ontology extraction from CTSs, our method is capable of detecting both has-a and is-a relationships and explicitly identifying each. Our multi-stage algorithm also extracts high quality relation-ships between multi-word tags. A collaborative tagging system [22] is a 4-tuple C =( U, T, I, Y )where U is a set of users, T is the set of tags used by the users, I is the set of items (resources) to which tags are assigned by users, and Y , the set of tag assignments, is a ternary relation on tags, users, and items, i.e., Y  X  U  X  T  X  I .

Specific CTSs may vary in detail from our definition above, e.g., IMDb does not have user information. We can model such CTSs by dropping U and defin-ing Y  X  T  X  I as a binary relation. CTSs such as [11] allow users to declare their own is-a relationships. User-supplied is-a relationships can augment those automatically extracted but cannot supplant them because of the scale.
This paper studies how to efficiently extract is-a and has-a relationships between tags in a given CTS. The output ontology consists tag1, tag2, label tuples where tag1 is the super class and label is either is-a or has-a . 2 E.g., the tuple OS, Windows, is-a indicates that Windows a kind of OS. Algorithm 1. ONTECTAS Our ONTECTAS algorithm for ontology extraction (Algorithm 1) consists of six phases. First, data is preprocessed and cleaned. Next, we extract candidate tag tuples via association rule mining using forward and reverse confidence. We then remove tuples corresponding to bigrams. Next, we detect headwords of multi-word tags and use this to infer additional is-a relationships. We then use lexico-syntactic patterns to extract additional is-a and has-a relationships. Finally, we leverage pairs of tags sharing a common child in the extracted ontology to infer additional is-a relationships. The next three sections describe the phases. 4.1 Preprocessing The preprocessing step is primarily a cleaning step. It takes as input a CTS and performs the following tasks: (1) Any user information is projected away; we found looking at transactions at the level of group of users was most effective in ontology extraction. (2) Words with non-English characters are removed from the input data using the same method as in [5]. This adequately removed non-English words from all of our datasets. (3) Basic stemming: singular nouns are substituted for their plural forms. (4) Si nce tags occurring very infrequently are not statistically reliable, we remove d tags or items that occurred fewer than 5 times. This threshold was determined empirically. (5) Verbs and verb phrases are removed by applying the Stanford parser 3 to each tag. This prunes tags that are used for organizing but convey no meaning about the item being tagged [7]. 4.2. Detecting Potential Relationships Using Association Rules Adapting tagged data to market basket analysis requires defining how to build transactions from tags, which in turn requires defining  X  X o-occurrence X . We ex-plored three different definitions of co-occurrence. Empirically, we determined that the most effective co-occurrence definition is the following: Tags t and t co-occur if both were used to tag the same i tem (by possibly different users). The frequency of { t, t } equals the number of distinct items which were assigned both tags t and t . Our careful study of the best definition of co-occurrence [20] allows us to more optimally use association rules than previous approaches, e.g., [23].
We use the FP-tree association rule mining algorithm [8] to extract frequent tag sets 4 and interesting rules from the set of transactions. The support of a tag set X is the proportion of transactions containing tag set X and the confidence of a rule is defined as confidence( X  X  Y ) = support( X  X  Y ) / support( X )  X  i.e., the proportion of transactions in which X and Y occur together among those in which X appears. In this paper, we refer to the well-known definition of confidence as forward confidence (FC). We also introduce a new notion, reverse confidence (RC) as follows: reverse confidence( X  X  Y ) := support( X  X  Y ) / support( Y ).
We assume tags assigned by users tend to contain both a term in the ontology and another term that has relationship w ith it. Therefore, if two keywords co-occur frequently, they are likely to be related. We use support to filter sets of tags with a cardinality of two. However, po pular unrelated terms may occur together frequently, so we use confidence to remove tuples containing unrelated tags. Because terms which co-occur with high confidence are sometimes synonyms Algorithm 2. Association Rule Tuple Detection (e.g.,  X  X s X  and  X  X perating system X ), we use confidence in the reverse direction to ensure that terms are related with is-a or has-a relationships. Different values for min support and min conf. can drastically change the size of the ontology; in our experiments these values were chosen empirically. At the end of this step, we have not yet classified the relationships into is-a and has-a . 4.3 Pruning Edges between Bi-gram Elements In this phase, bi-gram tuples which are common phrases are automatically pruned using a search engine. Usually bi-grams are compound nouns in the form of  X  X djective + noun X  (e.g., free software) or  X  X oun + noun X  (e.g., web browser). Bi-grams do not contain is-a or has-a relationships but sometimes are incorrectly detected as edges of an o ntology since they co-occur frequently.
Finding bigrams by using a search engine [26,12,17] has not previously been applied to extracting relationships between CTS tags. ONTECTAS sends two keyword queries to a search engine for each relationship tuple (Algorithm 3). The queries are the quoted permutations of the terms in the tuple. If the ratio of the number of results returned for the two queries is larger than a threshold, the terms in the relationship tuple are regarded as bi-grams. E.g., if the relationship tuple is software, free , the queries are  X  X ree software X  and  X  X oftware free X . Since the ratio is higher than the threshold for this tuple, it is detected as a bi-gram and pruned. We experimentally found that the optimal threshold for detecting bi-grams is between 50 and 100. Because words in text documents have Zipfian distribution, [12] suggests using a logarithmic transformation of returned result counts. We found that the logarithmic transformation is also more accurate in de tecting bi-grams. 4.4 Detecting Headwords in Multi-word Tags Since many CTS tags are multi-word tags in form of compound phrases such as  X  X cience-fiction X  and  X  X bject-oriented-data-model X , we use h eadword detection Algorithm 3. Bi-gram Filtering to extract additional is-a relationships (Algorithm 4). First, the Stanford parser detects the headwords for each phrase. A headword is a phrase X  X  grammatically most important word; it determines the phrase X  X  syntactic type. We then extract an is-a relationship for each multi-word tag by putting the headword as the parent of the whole phrase. E.g., we can infer  X  X bject-oriented data model X  is-a  X  X odel X . In this phase, more candidate tuples are produced by using either whole phrases or their headwords as the tags in tuples.
 Algorithm 4. Headword Detection Finally, we analyze occurrences of lexi co-syntactic patterns to detecting is-a and has-a relationships. Due to data sparsity, lexico-syntactic patterns do not occur frequently enough to accurately detect re lationships between terms [21]. Hence, we build on [13] and query the web for more occurrences of the patterns.
The core of our lexico-syntactic search is shown in lines 3-6 of Algorithm 5: given two tags and a pattern, we generate two keyword queries by considering Algorithm 5. is-a Relationship Detection the two possible permutations of the tags in the pattern. E.g., given ( X  X uman X ,  X  X ody X ,  X  X  X  X ), the two generated queries will be  X  X uman X  X  body X  and  X  X ody X  X  human X . Then, the ratios for both forward and reverse occurrences direction are calculated. It is clear that given any set of patterns for any relationship, this algorithm can be applied. We use the following patterns from [9] to identify is-a relationships: (1) Pattern 1: NP 1 such as NP 2 ; (2) Pattern 2: NP 1 including NP 2 ; (3) Pattern 3: NP 1 especially NP 2 .

Our has-a relationships are supersets of meronymy (part-of relationships), and are not limited to the physical per spective. We consider two noun phrases NP 1 and NP 2 to have a has-a relationship (with NP 1 as the parent) if one of the following statements is true: (1) NP 2 is a part of NP 1 . E.g.,  X  X ody X  is a part of  X  X uman X ; or (2) NP 1 has/have NP 2 . E.g.,  X  X uman X  has  X  X ind X  and  X  X oogle X  has  X  X oogleMaps X ; or (3) NP 1 may have NP 2 . E.g.,  X  X uman X  may have  X  X isease X .

From the existing lexico-syntactic patterns mentioned in the literature such as [4,6], we use three following patterns to detect has-a relationships:(1) Pattern 1: NP 1  X  X  NP 2 ; (2) Pattern 2: NP 2 of the NP 1 ; (3) Pattern 3: NP 2 of NP 1 .
While patterns 1 and 2 are among the most common English patterns [6], pattern 3 is not. However, pattern 3 can be used to detect has-a relationship between tags such as the tuple Coffee, Caffeine .

All patterns for a relationship are fed into a search engine. If the largest ratio of a pattern is above a threshold, that tuple is labeled with the corresponding relationship and added to the ontology. Algorithm 5 shows the is-a detection algorithm. The has-a algorithm is similar, but requires that pattern 1 and one of patterns 2 and 3 are above the threshold. Both thresholds were found experimentally. In our experiments, the is-a threshold was 7 and has-a threshold ranged from 20 to 50. Examining the ontology built thus far reveals an interesting property when pairs of tags share the same child. Consider the following example: the ontology may contain  X  X iction  X  urban-fantasy X  and  X  X antasy  X  urban-fantasy X , where  X  X ic-tion X  and  X  X antasy X  are both parents for  X  X rban-fantasy X  w.r.t. the is-a rela-tionship. 5 However, the is-a relationship between  X  X iction X  and  X  X antasy X  may be missing. One possible reason for this is that people tend to use the more spe-cific tags leading to  X  X iction  X  urban-fantasy X  and  X  X antasy  X  urban-fantasy X , so that  X  X iction  X  fantasy X  does not occur above th e relatively high threshold needed to avoid noise.

Hence we have the following hypothesis: in a co-parent structure it is more likely than usual that the two parents are in an is-a relationship. Hence, we include the following additional step (Algorithm 6) to ONTECTAS: for such co-parent pairs, we re-examine the pair X  X  confidences under a lower threshold and extract candidate tuples for an is-a relationship.
 Algorithm 6. Co Parent Pruning
As a final step of the ONTECTAS algorithm, following standard practice in ontology extraction algorithms, if the graph of relationships is disconnected, we add a generic  X  X ntity X  root node and make it the parent of all orphan nodes. 7.1 Datasets and Assumptions Our experiments used four real datasets: Del.icio.us (a social bookmarking web service), IMDb (the Internet Movie Database), LibraryThing (for tagging books) and CiteULike (a service for storing, organizing, and sharing scholarly papers). Table 1 shows the characteristics of the datasets. User information is not avail-able in the IMDb dataset, so competing algorithms were unable to create on-tologies from it.
 To show that general purpose ontologies are insufficient, we validated that WordNet misses many relationships between terms even when it contains both terms . To show this, we evaluated a sample ontology (from Del.icio.us) both manually and by using all parent-child senses (meanings) in WordNet. We lim-ited our experiments to relationships where both parent and child term exist in WordNet. This gives WordNet an advantage since many tags do not appear in WordNet at all. In this case, we found WordNet is missing 26.9% of manually validated relationships discovered by ONTECTAS. For example, WordNet con-tains 3 senses for  X  X ython X , but none of these senses is related to programming; as a result,  X  X rogramming  X  python X  is missing in WordNet.

Since our approach is successful, it is clear that our hypothesis that agroup of users tend to tag items with both parent and child tags is validated. The full version of this paper [20] shows detailed experiments which validate this empirically. We discuss our results, beginning with has-a relationship detection. 7.2 Evaluation of ONTECTAS in Detecting has-a Relationships Table 2 shows the precision of ONTECTAS in detecting has-a relationships. None of the other competing algorithms address has-a relationships from CTSs. Table 2 only reports precision for ONTECTAS, the first algorithm to detect has-a from CTS data.

One challenge in detecting has-a relationships was that pattern-based search engine queries such as  X  X uman X  X  middle X  and  X  X iddle of human X  are frequently part of phrases such as  X  X uman X  X  middle finger X  and  X  X iddle of human history X . Clearly, there is room for improvement in ONTECTAS X  precision in has-a de-tection, which we plan to address in future work. 7.3 Evaluation of ONTECTAS in Detecting is-a Relationships Inthefollowing,wefocuson is-a relationships. All competing algorithms do not distinguish between is-a and other relationships such as synonyms, whereas we clearly isolate is-a relationships. We lump all other relationships into any and compare the performance of ONTECTAS on is-a with that of other algorithms on is-a and any , giving them an advantage, since in this evaluation, we do not give credit to ONTECTAS for correctly finding has-a relationships. We use the following standard performance measures: (1) Precision: We consider the precision of ONTECTAS on is-a with that of other algorithms on is-a + any . Precision for both is the number of correct edges over the number of all edges. (2) Maximum depth and average depth of the is-a taxonomy. (3) Average number of children. A higher value of the last two measures implies richer ontology is extracted. In addition, following [19], we compare all algorithms with a gold standard to see how they fare in trying to recreate manually-curated ontologies.
For depth and breadth metrics, we calculate these metrics on an ontology with only correct relationships to ensure algorithms cannot earn an artificially and unfairly high score on these by finding many incorrect relationships!
Absolute recall for ontology extraction from a large CTS is very hard to measure. Instead, we propose a new metric: relative recall . Relative recall for an algorithm is the number of valid is-a relationships found by the algorithm divided by the total number of valid is-a relationships found by all algorithms. 7.4 Comparing ONTECTAS to Other Algorithms We compare ONTECTAS with the four algorithms from Section 2: 1) the algo-rithm from [19] (abbreviated  X  X FZ X ) 2) the DAG algorithm [5] ( X  X AG-ALG X ) 3) Schmitz X  X  algorithm [23] ( X  X chmitz X ), and 4) Barla and Bielikov  X  a X  X  algorithm [3] ( X  X B X ). Since these algorithms cannot process the IMDb dataset due to the lack of user information, we only compare them on Del.icio.us, LibraryThing, and CiteULike.

To have a fair comparison, we implemented the above algorithms as closely as possible to the way their authors had implemented them; we used the param-eters that were described in the papers and contacted the authors for additional information about how to make their algorithms as competitive as possible.
Validating the edges manually required that each algorithm output a small number of edges. To do so, we put another threshold on the number of times a tag, an item, or a user must occur in ord er to be considered. To be fair, we used the same threshold to ensure that each algorithm output fewer than 150 edges.
Figure 1(a) shows the algorithms X  precision for both is-a relationships (the lower bars) and any relationships (the higher bars); for is-a relationships, the precision of ONTECTAS is 0.50 for Del.icio.us, 0.48 for LibraryThing and 0.29 for CiteULike. ONTECTAS outperforms the precision of all other algorithms on all datasets. We also compare our precision on is-a with that on is-a + any for the other algoritms since they do not distinguish is-a from non-is-a .Eventhen ONTECTAS outperforms the other algorithms in del.icio.us and CiteULike. On LibraryThing, the performance is close to the winner.
 Figure 1(b) compares the algorithms X  relative recall for is-a relationships. ONTECTAS is the best performer for all three datasets. One reason for DAG-ALG X  X  bad relative recall is that it detected many popular tags such as  X  X eb X  and  X  X oftware X  as subjective tags, and pruned them before discovering the edges. BB had relatively low precision and r ecall in CiteULike because it detected many relationships with the tag  X  X o-tag X , which is a popular tag rather than an ontological tag. ONTECTAS performs the best for relative recall for any relationships [20].
Figures 1(c) and 1(d) measure the depth of the validated ontology detected by each algorithm for both is-a (lower bars) and any relationships (higher bars). These measures quantify the richness of the ontology. If there are multiple paths from the root to a node n , the depth is the longest path. Because the other algorithms find just any relationship between elements in an ontology, rather determining the types of relationships, like ONTECTAS does, we measure both the is-a relationships and any relationships found. We do not consider has-a since no other algorithms detect it. Notice that this gives an advantage to the competing algorithms. For the depth metrics, other algorithms usually find a long chain with combination of synonyms and is-a relationships. Since ONTEC-TAS detects mostly is-a or has-a (and not synonyms), maximum depth for any relationship in ONTECTAS is close to maximum depth of is-a relationship because in general of chains containing is-a and has-a are rare.

For is-a relationships, ONTECTAS has the highest maximum depth for two out of three datasets. In the full version of the paper [20], we show that the average number of children is similar to the average depth. For the average number of children, ONTECTAS has the best performance for CiteULike, is roughly tied for Library thing, and is second best for Del.icio.us.
 Even when competing algor ithms are given credit for any relationships and ONTECTAS only for finding is-a , ONTECTAS performs fairly well. This is because there are so many is-a relationships detected as compared to the other relationship types.

For all of the depth/child ren metrics, we note that all algorithms perform markedly better using our preprocessing step of removing verb phrases .Thisstep helped a lot in removing non-ontological tags such as  X  X o-read X  in the Del.icio.us dataset. By applying this to all algorithms, we have improved all algorithms X  performance, not just ONTECTAS X  X . Figure 1 also shows that most of the algorithms performed better on most measures for the Deli.icio.us and Library-Thing datasets than on CiteULike. This validates the fact that the tags in these datasets are of better quality than the ones in CiteULike. This shows that we can compare different CTSs on the quality of tagging actions, using an ontology creation algorithm.

In summary, ONTECTAS outperforms the four other algorithms on precision and relative recall for is-a relationships, and does wel l on the structural metrics of maximum depth, average depth and average number of children. 7.5 Comparing with a Gold Standard Following [19], we compared how the algorithms extracted is-a relationships against a  X  X old standard X  ontology  X  the concept hierarchy from the Open Directory Project (ODP) 6 . To judge precision, recall, and F-measure, we use the lexical and taxonomic metrics from [19]. The lexical metrics measure how well the algorithms did in recreating the concepts , and the taxonomic metrics show how well the algorithms did in recreating the structure . Notice that comparing with a static ontology considered as gold standard has its problems since it may miss important concepts and relationships and a good algorithm that finds concepts and relationshi ps manually verified to be c orrect may get penalized unfairly. We will return to this point. The full version of this paper [20] shows the formal definitions of the measures and the detailed results. Due to space limitations, we only cover the highlights in this paper.
 We looked at the 25 highest-level con cepts common across t he five algorithms. Table 3 shows the results. Bolded entr ies represent the best performance.
ONTECTAS has the second highest overa ll lexical recall and f-measure, which shows that it did well at finding the desired concepts. While DAG had the highest lexical precision and f-mea sure, and BB had the highest lexical recall, they both did very poorly on taxonomic precision, leading to a low taxonomic f-measure.
LFZ had a very good lexical precision; how ever, this is achieved by reporting a very small number of correct concepts . ONTECTAS is superior to LFZ in terms of all three taxonomic measures.

Because the 25 highest level common concepts were very uneven in size, we performed an analysis of the 6 largest subtrees  X  otherwise algorithms would be testing against subtrees that were only one or two concepts large. When we considered only the 6 larg est subtrees, ONTECTAS had the best lexical and taxonomic f-measure.

Comparing to a gold standard shows how well algorithms do against a man-ually created ontology. But since a gold standard ontology is static, this metric may unfairly penalize algorithms that g enuinely find correct concepts and rela-tionships. E.g.,  X  X ialect X  and  X  X oftware is-a technology X  is incorrect according to this standard. Thus, comparing algorithms should take into account other components discussed above as well. We proposed an algorithm (ONTECTAS) for building ontologies of keywords from collaborative tagging systems. ONTECTAS uses association rule mining, bi-gram pruning, exploiting pairs of tags with the same child, and lexico-syntactic patterns to detect relationships between tags. We also provided a thorough anal-ysis of ONTECTAS and how it compares to other algorithms. Some of the important open problems include detecting spam users, improving accuracy of ontology extraction via supervised learning and by means of incorporation of part-of-speech detection. Our ongoing work addresses some of these.
