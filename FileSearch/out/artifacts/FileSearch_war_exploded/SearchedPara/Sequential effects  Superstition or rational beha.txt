 One common error human subjects make in statistical inferen ce is that they detect hidden patterns and causes in what are genuinely random data. Superstitious behavior, or the inappropriate linking of stimuli or actions with consequences, can often arise in s uch situations, something also observed in non-human subjects [1, 2]. One common example in psycholo gy experiments is that despite a randomized experimental design, which deliberately de-co rrelate stimuli from trial to trial, subjects pick up transient patterns such as runs of repetitions and alternations , and their responses are fa-cilitated when a stimulus continues to follow a local patter n, and impeded when such a pattern is violated [3]. It has been observed in numerous experiments [ 3 X 5], that subjects respond more accu-rately and rapidly if a trial is consistent with the recent pa ttern (e.g. AAAA followed by A , BABA followed by B ), than if it is inconsistent (e.g. AAAA followed by B , BABA followed by A ). This sequential effect is more prominent when the preceding run has lasted longer. F igure 1a shows re-action time (RT) data from one such experiment [5]. Error rat es follow a similar pattern, reflecting a true expectancy-based effect, rather than a shift in RT-ac curacy trade-off.
 whether explicitly or implicitly. They readily respond whe n a subsequent stimulus extends the local pattern, and are  X  X urprised X  and respond less rapidly and ac curately when a subsequent stimulus violates the pattern. When such local patterns persist longe r, the subjects have greater confidence in Figure 1: Bayesian modeling of sequential effects. (a) Medi an reaction time (RT) from Cho et al from a large  X  X  X  using button-presses. Along the abscissa ar e all possible four-trial sub-sequences, in terms of repetitions ( R ) and alternations ( A ). Each sequence, read from top to bottom, proceeds from the earliest stimulus progressively toward the presen t stimulus. As the effects were symmetric across the two stimulus types, A and B , each bin contains data from a pair of conditions (e.g. RRAR can be AAABB or BBBAA ). RT was fastest when a pattern is reinforced ( RRR followed by R , or AAA followed by A ); it is slowest when an  X  X stablished X  pattern is violated ( RRR followed by A , or AAA followed by R ). (b) Assuming RT decreases with predicted stimulus probab ility (i.e. RT increases with 1  X  P ( x much weaker sequential effects in the second half (blue: 720 simulated trials) than in the first half 840 trials) and second half (blue: 720 trials). Inset shows p rior over  X  used; the same prior was also used for the FBM in (b).  X  = . 77 . (d) Sequential effects in behavioral data were equally str ong in Green dashed line shows a linear transformation from the DBM prediction in probability space of (c) into the RT space. The fit is very good given the errorbars ( SEM) in the data. the pattern, and are therefore more surprised and more stron gly affected when the pattern is violated. While such a strategy seems plausible, it is also sub-optimal . The experimental design consists of randomized stimuli, thus all runs of repetitions or alterna tions are spurious, and any behavioral ten-dencies driven by such patterns are useless. However, compa red to artificial experimental settings, truly random sequential events may be rare in the natural env ironment, where the laws of physics and biology dictate that both external entities and the observe r X  X  viewpoint undergo continuous transfor-timescales. The brain may be primed to extract such statisti cal regularities, leading to what appears to be superstitious behavior in an artificially randomized e xperimental setting.
 In section 2, we use Bayesian probability theory to build for mally rigorous models for predicting actual behavior. Our analyses imply that subjects assume st atistical contingencies in the task to persist over several trials but non-stationary on a longer time-scale, as opposed to being unknown but fixed throughout the experiment. We are also interested in unders tanding how the computations necessary for prediction and learning can be implemented by the neural hardware. In section 3, we show that the Bayes-optimal learning and prediction algori thm is well approximated by a linear filter that weighs past observations exponentially, a computatio nally simpler algorithm that also seems to fit human behavior. Such an exponential linear filter can be im plemented by standard models of neuronal dynamics. We derive an explicit relationship betw een the assumed rate of change in the world and the time constant of the optimal exponential linea r filter. Finally, in section 4, we will show that meta-learning about the rate of change in the world can be implemented by stochastic gradient descent, and compare this algorithm with exact Bay esian learning. One simple internal model that subjects may have about the na ture of the stimulus sequence in a 2-alternative forced choice (2AFC) task is that the statist ical contingencies in the task remain fixed throughout the experiment. Specifically, they may believe t hat the experiment is designed such that there is a fixed probability  X  , throughout the experiment, of encountering a repetition ( x any given trial t (thus probability 1  X   X  of seeing an alternation x model for the FBM.  X   X  [0 , 1] , x variables. (b) Graphical model for the DBM.  X  sume the prior p variables. (c) Grayscale shows the evolution of posterior p robability mass over  X  for FBM (darker color indicate concentration of mass), given the sequence o f truly random ( P ( x data (blue dots). The mean of the distribution, in cyan, is al so the predicted stimulus probability: and predictive probability P ( x repetitions or alternations. about the task over the time course of the experiment is the ap propriate value of  X  . We call this the Fixed Belief Model (FBM). Bayes X  Rule tells us how to compute the posterior: where r observations ( x the mean of this posterior distribution: P ( x A more complex internal model that subjects may entertain is that the relative frequency of repeti-tion (versus alternation) can undergo discrete changes at u nsignaled times during the experimental session, such that repetitions are more prominent at times, and alternation more prominent at other times. We call this the Dynamic Belief Model (DBM), in which  X  on  X  distribution p be drawn from a Bernoulli process with rate parameter  X  the mean of the iterative prior, P ( x Figures 2a;b illustrate the two graphical models. Figures 2 c;d demonstrate how the two models re-spond differently to the exact same sequence of truly random binary observations (  X  = . 5 ). While inference in FBM leads to less variable and more accurate est imate of the underlying bias as the number of samples increases, inference in DBM is perpetuall y driven by local transients. Relat-ing back to the experimental data, we plot the probability of not observing the current stimulus for each type of 5-stimulus sequences in Figure 1 for (b) FBM and ( c) DBM, since RT is known to lengthen with reduced stimulus expectancy. Comparing the fi rst half of a simulated experimental session (red) with the second half (blue), matched to the num ber of trials for each subject, we see of the experimental data (Figure 1d) shows that sequential e ffects also persist in human behavior, confirming that Bayesian prediction based on a (Markovian) c hangeable world can account for be-havioral data, while that based on a fixed world cannot. In Fig ure 1d, the green dashed line shows that a linear transformation of the DBM sequential effect (f rom Figure 1c) is quite a good fit of the (shorter RT) for repetition trials. This is easily captured by the DBM by assuming p skewed toward repetitions (see Figure 1c inset). The same sk ewed prior cannot produce a bias in the FBM, however, because the prior only figures into Bayesian in ference once at the outset, and is very quickly overwhelmed by the accumulating observations. a Figure 3: Exponential discounting a good descriptive and no rmative model. (a) For each of the six subjects, we regressed RR on repetition trials against p ast observations, RT  X  C + b b recent repetition trials should increase expectation of re petition and decrease RR, and recent alter-nation should decrease expectation of repetition and incre ase RR on a repetition trial. Separately we and 1 to repetitions). The two sets of coefficients did not differ s ignificantly and were averaged togther (red: average across subjects, error bars: SEM). Bl ue line shows the best exponential fit to these coefficients. (b) We regressed P different values of  X  , we repeat the process in (b) and obtain the best exponential decay parameter  X  (blue). Optimal  X  closely tracks the 2 / 3 rule for a large range of values of  X  .  X  is . 57 in (a), so  X  = . 77 was used to generate (b). (d) Both the optimal exponential fit (red) and the 2 / 3 rule (blue) approxiate the true Bayesian P smaller values of  X  , the fit is even better; for larger  X  , the exponential approximation deteriorates ( x t = 1 boundary) is approximately linear. While Bayes X  Rule tells us in theory what the computations oug ht to be, the neural hardware may only implement a simpler approximation. One potential appr oximation is suggested by related work showing that monkeys X  choices, when tracking reward contin gencies that change at unsignaled times, depend linearly on previous observations that are di scounted approximately exponentially larities, much like the kind we hypothesize to be engaged ina dvertently in sequential effects. First, we regressed the subjects X  reward rate (RR) against past observations and saw that the linear coefficients decay approximately exponentially into the pa st (Figure 3a). We define reward rate as mean accuracy/mean RT, averaged across subjects; we thus ta ke into account both effects in RT and accuracy as a function of past experiences. We next examined whether there is also an element of exponential discounting embedded in the DBM inference algo rithm. Linear regression of the pre-dictive probability P lates positively with accuracy and negatively with RT) agai nst previous observations x yields coefficients that also decay exponentially into the p ast (Figure 3b): P Linear exponential filtering thus appears to be both a good de scriptive model of behavior, and a good normative model approximating Bayesian inference.
 particular how the rate of decay relates to the assumed rate o f change in the world (parameterized by  X  ). We first note that the linear exponential filter has an equiv alent iterative form: We then note that the nonlinear Bayesian update rule can also be written as: where K value h K forms and assuming h P distribution. We verified numerically (data not shown) that this mean approximation is quite good for a large range of  X  (though it gets progressively worse when  X   X  1 , probably because the equilibrium assumptions deviate farther from reality as changes become increasingly rare).
 Notably, our calculations imply  X   X  2 result in longer integration time window, whereas faster ch anges should result in shorter memory. Figure 3c shows that the best numerically obtained  X  (by fitting an exponential to the linear regres-ulated data in Figure 3b are in fact obtained by assuming  X  = . 77 , hence the remarkably good fit between data and model. Figure 3d shows that reconstructed P linear exponential filter (red) and the 2 / 3 rule (blue) both track the true Bayesian P In the previous section, we saw that exact Bayesian inferenc e for the DBM is a good model of be-well. To compare which of the two better explains the data, we need a more detailed account of how stimulus history-dependent probabilities translate into reaction times. A growing body of psycho-logical [7] and physiological data [8] support the notion th at some form of evidence integration up to a fixed threshold underlies binary perceptual decision ma king, which both optimizes an accuracy-RT trade-off [9] and seems to be implemented in some form by co rtical neurons [8]. The idealized, continuous-time version of this, the drift-diffusion mode l (DDM), has a well characterized mean stopping time [10], T time fluctuation, and z is the distance between the starting point and decision boun dary. The vertical axis for the DDM is in units of log posterior ratio log P ( s 0 | x t ) the starting point to log b is approximately linear in b (Figure 3e inset), so that the new distance to the boundary is approxi-the relevant range. We therefore have T time is linear in the bias b , in units of probability.
 This linear relationship between RT and b was already born out by the good fit between sequential effects in behavioral data and for the DBM in Figure 1d. To exa mine this more closely, we run the exact Bayesian DBM algorithm and the linear exponential filt er on the actual sequences of stimuli observed by the subjects, and plot median RT against predict ed stimulus probabilities. In Figure 3e, we see that for both exact Bayesian (red) and exponential (bl ue) algorithms, RT X  X  decrease on repe-nation trials when predicted probability for repetition in crease (and therefore predicted probability for alternation decrease). For both Bayesian inference and linear exponential filtering, the relation-ship between RT and stimulus probability is approximately l inear. The linear fit in fact appears better for the exponential algorithm than exact Bayesian in ference, which, conditioned on the DDM being an appropriate model for binary decision making, impl ies that the former may be a better model of sequential adaptation than exact Bayesian inferen ce. Further experimentation is underway to examine this prediction more carefully.
 Another implication of the SPRT or DDM formulation of percep tual decision-making is that incor-rect prior bias, such as due to sequential effects in a random ized stimulus sequence, induces a net cost in accuracy (even though the RT effects wash out due to th e linear dependence on prior bias). The error rate with a bias x monotonically with bias in either direction. This is a quant itative characterization of our claim that extrageneous prior bias, such as due to sequential effects, induces suboptimality in decision-making. Figure 4: Meta-learning about the rate of change. (a) Graphi cal model for exact Bayesian learning. timesteps, averaged over 30 sessions of simulated data, eac h set generated from different true values shown). (c) Stochastic gradient descent with a learning rat e of . 01 produce estimates of  X  (thick lines, width denotes SEM) that converge to the true values of  X  (dashed lines). Initial estimate of  X  , Marginal posterior distributions over  X  (top panel) and  X  probability mass is color-coded: brighter color is more mas s. So far, we have seen that exponential discounting of the past not only approximates exact Bayesian inference, but fits human behavioral data. We now note that it has the additional appealing property of being equivalent to standard models of neuronal dynamics . This is because the iterative form neuronal models, which have been used extensively to model p erceptual decision-making on a rela-for the temporal credit assignment problem of relating outc omes to states or actions that were re-sponsible for them. Here, we provided the computational rationale for this exponential discounting the past  X  it approximates Bayesian inference under DBM-lik e assumptions.
 Viewed as a leaky-integrating neuronal process, the parame ters of Equation 1 have the following  X P t  X  1 as the leaky recurrent term. Equation 1 suggests that neuron s utilizing a standard form of integration dynamics can implement near-optimal Bayesi an prediction under the non-stationary question to ask next is how neurons can learn to set the weights appropriately. We first note that x is a sample from the distribution P ( x Equation 1, with dependence on a single parameter  X  , learning about near-optimal predictions can potentially be achieved based on estimating the value of  X  via the stochastic samples x We implement a stochastic gradient descent algorithm, in wh ich  X   X  is adjusted incrementally on each trial in the direction of the gradient, which should bring  X   X  closer to the true  X  . where  X   X   X   X  SEM estimated from 50 sessions of learning). A key challenge for future work is to c larify whether For comparison, we also implement the exact Bayesian learni ng algorithm, which augments the DBM architecture by representing  X  as a hidden variable instead of a fixed known parameter: Figure 4a illustrates this augmented model graphically. Fi gure 4b shows the evolution of the mean from each of four different true values of  X  , the mean value of  X  under the posterior distribution tends toward the true  X  over time. The prior we assume for  X  is a beta distribution ( Beta (17 , 3) , shown in the inset of Figure 4b).
 Compared to exact Bayesian learning, stochastic gradient d escent has a similar learning rate. But approximation for  X  is under-estimated for larger  X  . For data that were generated from a fixed Bernoulli process with rate . 5 , an equivalently appropriate model is the DBM with  X  =0  X  stochastic gradient descent produced estimates of  X  (thick red line) that converge to 0 on the order of 50000 trials (details not shown). Figure 4d shows that the posteri or inference about  X  and  X  distinct phases when true  X  = 0 and there is no correlation between one timestep and the next . There is an initial phase where marginal posterior mass for  X  tends toward high values of  X  , while marginal posterior mass for  X  equally valid generative model for completely randomized s equence of inputs. However, this joint state is somehow unstable, and  X  tends toward 0 while  X  is because as inferred  X  gets smaller, there is almost no information about  X  thus the marginal posterior over  X  each data point.  X  can only decrease slowly because so little information abou t the hidden variables is obtained from each data point. For instance, it is very dif ficult to infer from what is believed to be an essentially random sequence whether the underlying Bernoulli rate really tends to change once every 1.15 trials or 1.16 trials. This may explain why su bjects show no diminished sequential effects over the course of a few hundred trials (Figure 1d). Wh ile the stochastic gradient results demonstrate that, in principle, the correct values of  X  can be learned via the sequence of binary observations x implement the stochastic gradient algorithm or an alternat ive learning algorithm . Humans and other animals constantly have to adapt their beha vioral strategies in response to chang-ing environments: growth or shrinkage in food supplies, dev elopment of new threats and opportuni-ties, gross changes in weather patterns, etc. Accurate trac king of such changes allow the animals to adapt their behavior in a timely fashion. Subjects have been observed to readily alter their behavioral such behavior is sub-optimal for certain behavioral experi ments, which interleave stimuli randomly or pseudo-randomly, it is appropriate for environments in w hich changes do take place on a slow timescale. It has been observed, in tasks where statistical contingencies undergo occasional and unsignaled changes, that monkeys weigh past observations l inearly but with decaying coefficients (into the past) in choosing between options [6]. We showed th at human subjects behave very simi-larly in 2AFC tasks with randomized design, and that such dis counting gives rise to the frequently observed sequential effects found in such tasks [5]. We show ed that such exponential discounting ap-proximates optimal Bayesian inference under assumptions of statistical non-s tationarity, and derived an analytical, approximate relationship between the param eters of the optimal linear exponential fil-ter and the statistical assumptions about the environment. We also showed how such computations can be implemented by leaky integrating neuronal dynamics, and how the optimal tuning of the leaky integration process can be achieved without explicit representation of probabilities. Our work provides a normative account of why exponential discounting is observed in both sta-tionary and non-stationary environments, and how it may be implemented neurally. The relevant neural mechanisms seem to be engaged both in tasks when the en vironmental contingencies are truly changing at unsignaled times, and also in tasks in whic h the underlying statistics are station-ary but chance patterns masquerade as changing statistics ( as seen in sequential effects). This work bridges and generalizes previous descriptive accounts of behavioral choice under non-stationary task conditions [6], as well as mechanistic models of how neuronal dynamics give rise to trial-to-trial in-teractions such as priming or sequential effects [5, 13, 18 X  20]. Based the relationship we derived between the rate of behavioral discounting and the subjects  X  implicit assumptions about the rate of environmental changes, we were able to  X  X everse-engineer X  the subjects X  internal assumptions. Sub-jects appear to assume  X  = . 77 , or changing about once every four trials. This may have impl ications for understanding why working memory has the observed capac ity of 4-7 items. In a recent human fMRI study [22], subjects appeared to have d ifferent learning rates in two phases of slower and faster changes, but notably the first phase cont ained no changes, while the second phase contained frequent ones. This is a potential confound , as it has been observed that adaptive responses change significantly upon the first switch but then settle into a more stable regime [23]. It types of temporal patterns [24]. In the context of our model, it may imply that there is sequential A related issue is that brain needs not to have explicit repre sentation of the rate of environmental changes, which are implicitly encoded in the  X  X eakiness X  of neuronal integration over time. This is consistent with the observation of sequential effects even when subjects are explicitly told that the stimuli are random [4]. An alternative explanation is that s ubjects do not have complete faith in the experimenter X  X  instructions [25]. Further work is needed t o clarify these issues.
 We used both a computationally optimal Bayesian learning al gorithm, and a simpler stochastic gra-dient descent algorithm, to learn the rate of change (1- X  ). Both algorithms were especially slow at learning the case when  X  =0 , which corresponds to truly randomized inputs. This implie s that com-hypothesis space that contains many possible models of stat istical regularity, which can change over time. This is consistent with previous work [26] showing tha t discerning  X  X andomness X  from binary observations may require surprisingly many samples, when s tatistical regularities are presumed to change over time. Although this earlier work used a differen t model for what kind of statistical regularities are allowed, and how they change over time (tem porally causal and Markovian in ours, cult to discriminate a truly randomized sequence, which by c hance would contain runs of repetitions and alternations, from one that has changing biases for repetitions and alternations over time.
