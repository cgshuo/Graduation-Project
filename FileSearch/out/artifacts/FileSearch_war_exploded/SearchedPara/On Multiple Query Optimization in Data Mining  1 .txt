 Multiple Query Optimization (MQO) [10] is a database research area which focuses on optimizing a set of queries together by executing their common subexpressions once in order to save execution time. The main tasks in MQO are common subexpres-sion identification and global execution plan construction. When common subexpres-sions have been identified, they can be executed just once and materialized for all the queries, instead of being executed once for each query. A specific type of a query is a Data Mining Query (DMQ) [7], describing a data mining task. It defines constraints on the data to be mined and constraints on the patterns to be discovered. DMQs are submitted for execution to a Knowledge Discovery Management System KDDMS [7], which is a DBMS extended with data mining functions. Traditional KDDMSs execute DMQs serially and do not try to share any common subexpressions. 
DMQs are often processed in batches of 10-100 queries. Such queries may show many similarities about data or pattern constraints. If they are executed serially, it is likely that many I/O operations are wasted because the same database blocks may be required by multiple DMQs. If I/O steps of different DMQs were integrated and per-formed once, then we would be able to decrease the overall execution cost of the whole batch. Traditional MQO methods are not applicable to DMQs. DMQs perform huge database scans, which cannot and should not be materialized. Moreover, DMQs usually have high memory requirements that make it difficult to dynamically materialize intermediate results. One of the methods we proposed to process batches of DMQs is Apriori Common Counting (ACC), focused on frequent itemset discovery queries [1]. ACC is based on Apriori algorithm [2], it integrates the phases of support counting for candidate itemsets  X  candidate hash trees for multiple DMQs are loaded into memory together and then the database is scanned once. Basic ACC [11] assumes that all DMQs fit in memory, which is not the common case, at least for initial Apriori iterations. If the memory can hold only a subset of all DMQs, then it is necessary to schedule the DMQs into subsets, called phases [12]. The way such scheduling is done determines the overall cost of batched DMQs execution. To solve the scheduling problem, in [12] we proposed an  X  X nitial X  heuristic algorithm, called CCRecursive . To the best of our knowledge, apart from the ACC method discussed in this paper, the only other multiple query processing scheme for frequent pattern discovery is Mine Merge, presented in one of our previous papers [13]. In contrast to ACC, Mine Merge is independent of a particular frequent itemset mining algorithm. However, it was proven very sensitive to data distribution and less predictable than ACC. A MQO technique based on similar ideas as ACC has been proposed in the context of induc-tive logic programming, where similar querie s were combined into query packs [4]. 
Somewhat related to the problem of multiple data mining query optimization is re-using results of previous queries to answer a new query, which can be interpreted as optimizing processing of a sequence of queries independently submitted to the sys-tem. Methods falling into that category ar e: incremental mining [5], caching interme-diate query results [9], and reusing materialized results of previous queries provided that syntactic differences between the queries satisfy certain conditions [3] [8]. Data mining query . A data mining query is a tuple DMQ = ( R, a,  X  ,  X  ,  X  ), where R is a relation, a is an attribute of R ,  X  is a condition involving the attributes of R ,  X  is a condition involving discovered patterns,  X  is the min. support threshold. The result of the DMQ is a set of patterns discovered in  X  a  X   X  , satisfying  X  , and having support  X   X  . Problem statement. Given a set of data mining queries DMQ = { dmq 1 , dmq 2 , ... , l ating such an algorithm to execute DMQ which has the lowest I/O cost. formulas for DMQ , i.e., a set of selection formulas on the attribute a of the relation R such that for each i , j we have  X  si R  X   X  sj R =  X  , and for each i there exist integers a , ( V , E ) as to a data sharing graph for the set of data mining queries DMQ if and only if V = DMQ  X  S , E = {( dmq i , s j ) | dmq j  X  DMQ , s j  X  S ,  X   X  i R  X   X  sj R  X   X  }. Example . Consider the following example of a data sharing graph. Given a database represent DMQs and boxes represent distinct selection formulas. Apriori Common Counting (Fig. 2). ACC executes a set of data mining queries by integrating their I/O operations. First, for each data mining query we build a separate hash tree for 1-candidates. Next, for each distinct data selection formula we scan its corresponding database partition and we count candidates for all the data mining queries that contain the formula. Such a step is performed for 2-candidates, 3-candidates, etc. Notice that if a given distinct data selection formula is shared by many data mining queries, then its corresponding database partition is read only once. The basic ACC algorithm assumes that memory is unlimited and therefore the candi-date hash trees for all DMQs can completely fit in memory. If, however, the memory is limited, ACC execution must be partitioned into multiple phases , so that in each phase only a subset of DMQs is processed. In such a case, the key question to answer is: which data mining queries from the set should be executed together in one phase and which data mining queries can be executed in different phases? We will refer to the task of data mining queries partitioning as to data mining query scheduling . 
There are several issues to be addressed when scheduling data mining queries. First of all, it is obvious that the number of data mining queries which can be included in the same phase is restricted by the actual memory size. Memory requirements of individual data mining queries are determined by sizes of their candidate hash trees, which in turn are dependent on underlying data characteristics and on candidate sizes. Since the sizes of candidate hash trees change between Apriori iterations, the scheduling should be performed at the beginning of every iteration, not only before data mining query set execution starts. 
Another observation concerns the nature of ACC. Scheduling of DMQs should be based on inter-query similarities. Querie s which operate on separate database partitions should be performed in separate phases, while queries which operate on significantly overlapping database partitions could benefit from being executed in the same phase. To measure the level of  X  X verlapping X  we can use cost estimation features of existing cost-based query optimizers. 
A scheduling algorithm requires that sizes of candidate hash trees are known in advance. They can be estimated in two ways. We can find an upper bound for the number of candidates knowing the number of frequent itemsets from the previous Apriori iteration. Unfortunately, typical upper bounds are far from actual sizes of the candidate hash trees. Another approach is to first generate all the candidate hash trees, measure their sizes, save them to disk, schedule the data mining queries, and then load the required trees from disk. This method introduces the cost of materialization. The CCAgglomerative algorithm first transforms the data sharing graph into a gain graph , which contains (1) vertices being the original data mining queries and (2) two-vertex edges whose weights describe gains that can be reached by executing the con-nected queries in the same phase. Due to the restricted size of this paper we skip the algorithm of gain graph generation. A sample gain graph for the earlier discussed set of data mining queries is shown in Fig. 3. For example, putting the data mining queries dmq 1 and dmq 2 in the same phase will allow us to save 9000 I/O cost units. 
An initial schedule is created by putting each data mining query into a separate phase. Next, the algorithm processes the ed ges sorted with respect to the decreasing weights. For each edge, the algorithm tr ies to combine phases containing the connected data mining queries into one phase. If the total size of all the data mining queries in such phase does not exceed the memory size, the original phases are replaced with the new one. Otherwise the algorithm simply ignores the edge and continues. The CCAgglomerative algorithm is shown on Fig. 4. We performed several experiments using the MSWeb dataset from the UCI KDD Archive [6]. The experiments were conducted on a PC AMD Duron 1.2 GHz with 256 MB of RAM. The datasets resided in flat files on a local disk. Memory was intentionally restricted to 10kB-50kB. Each experiment was repeated 100 times. rithm, by the CCAgglomerative algorithm, by the CCRecursive algorithm, and by a random algorithm (which randomly builds phases from queries). CCAgglomerative has outperformed the other heuristic approach and achieved a very good accuracy. For example, for the set of 10 data mining queries, the CCAgglomerative algorithm misses the optimal solution by only 1.5%. Fig. 6 presents execution times for the optimal scheduling algorithm, CCRecursive , and CCAgglomerative (the execution time for CCAgglomerative includes the time required to build the gain graph). Notice that the optimal algorithm needed ca. 1000s to schedule 12 data mining queries, CCRecursive showed exponential execution time, while CCAgglomerative (polyno-mial wrt. the number of queries) still needed just about 0.0001s even for 15 queries. The paper addressed the problem of optimizing sets of multiple data mining queries. We showed that in order to apply Apriori Common Counting in a restricted memory system, it is required to schedule data mining queries into separate phases. The way such scheduling is performed influences the overall cost of executing the set of data mining queries. We presented the new heuristic scheduling algorithm, called CCAg-glomerative which significantly outperforms the other existing approach, CCRecur-sive , yet it provides a very good accuracy. 
