
We present a classification algorithm built on our adap-tation of the Generalized Lotka-Volterra model, well-known in mathematical ecology. The training algorithm itself con-sists only of computing several scalars, per each training vector, using a single global user parameter and then solv-ing a linear system of equations. Construction of the system matrix is driven by our model and based on kernel func-tions. The model allows an interesting point of view of ker-nels X  role in the inductive learning process. We describe the model through axiomatic postulates. Finally, we present the results of the preliminary validation experiments.
Classification has been employed in many of the prob-lems of the new information/data intensive age. Together with clustering and regression, classification has become a key component of data mining. Examples of classifica-tion problems span different disciplines and domains, like signal/image processing, as in the case of handwritten digit recognition [4], bioinformatics and genomics, as in the case of accurate breast cancer diagnosis [9], and many more.
Being such a relevant topic, classification has enjoyed intensive research in development of faster and more accu-rate algorithms. One of the industry-standard algorithms of today is the Support Vector Machines (SVM) algorithm [6]. SVM is based on the machine learning framework, also referred to as the inductive learning or statistical learning framework. More specifically classification algorithms are referred to as supervised machine learning algorithms. Such algorithms are based on the learn-from-examples methodol-ogy; these algorithms start with examples from every class in the given problem/dataset, and proceed to induce the classification function that can classify any new object it is faced with. The induction process is often times based on some inductive principle/framework, such as the Struc-tural Risk Minimization principle [13]. When evaluating such algorithms, the two keys performance dimensions are the accuracy on unseen objects (generalization) and speed (time complexity + parameterization).

In this paper we present a supervised inductive (classi-fication) algorithm, with the inductive principle based on the Generalized Lotka-Volterra model. The Generalized Lotka-Volterra (GLV) model, proposed independently by Alfred Lotka and Vito Volterra in mid 1920 X  X , was designed to explain the period-to-period changes in the biodensi-ties of several interacting biological species [8, 14]. The GLV is formulated as a system of N first-order non-linear difference or differential equations, depending on whether it is a continuous or discrete-time model. Each equation represents the change in the biodensity of one of the N modeled species. The flexibility of the GLV model is in its applicability to different types of interaction dynamics, such as predation, competition (for resources), and mutual-ism/cooperation.

As it turns out, the GLV model and its underlying prin-ciples are suitable for modeling inductive machine learning as well. Indeed, we can argue that the inductive process is based on competition and cooperation. Induction is a pro-cess of reaching a consensus after weighing the different specifics about the problem. Likewise, machine learning is the process of reaching a consensus after consulting with all the training examples that represent the specific patterns in the problem. It makes sense then that some training vectors might compete because they lobby, so to speak, for differ-ent classification of similar patterns, while others cooperate because they lobby for the identical classification of similar patterns.

Besides the proposed framework, we also present the al-gorithm that is based on it, which we call Interaction Mod-eling Based Learning or IMBL. The algorithm essentially consists of computing the interaction strength coefficients and finding the solution to our model X  X  convergence prob-lem. The solution reveals the parameters of the decision function.

We start in the next section with a bare-bones descrip-tion of the training algorithm. This allows us to put the most relevant information out first. After that, we present our model and all theoretical/heuristic considerations that went into constructing the training algorithm. This section shall address all questions the reader might have about the algorithm, especially since the fist section only presents the steps of the algorithm. Here we also present the decision function. Lastly, we present the results of our accuracy and running time benchmarking experiments in comparison with the Support Vector Machines algorithm.
The classification induction problem is commonly de-fined as follows: given a set of training input vectors X = { x i  X  R n | i = 1 , . . . , N } and a set of training out-put scalars, i.e. class labels, Y = { y i  X  X  1 , . . . , k }| i = 1 , . . . , N } ; find the decision function f (  X  ) : x  X  x  X  is an unclassified input vector, and  X  y is our estimation of x  X  X   X  X rue X , or  X  X referred X , output. In the framework of ma-chine learning, the training algorithm is said to  X  X hoose X  this decision function from the set of decision functions F = { f ( x,  X  ) |  X   X   X  } by computing/inducing the vector  X  , which uniquely parameterizes the decision function f .
At the core of our algorithm is the following linear sys-tem: where M is a full-rank N  X  N matrix, and A is a N  X  1 vector. The system is solved for A , which corresponds to the aforementioned parameter vector  X  . Matrix M , which we call our interaction matrix , is defined later in the paper.
The system (1) represents the convergence of an induc-tion model that is based on principles similar to those of the Generalized Lotka-Volterra (GLV) model, namely princi-ples of interaction and interdependence between the entities of the model. Commonly, the entities in GLV models are biological species and the model is used to describe their biodensities. In our context, the entities are the individual training vectors, and classes are the specific groupings of these entities. With some core postulates we show how the GLV model can be used in the machine learning framework to describe the induction properties of the training exam-ples.

The system (1) represents the convergence of our GLV induction model. Next we present the core postulates that motivate the use of the GLV model for inductive learning. After that we will introduce the elements of the interaction matrix and explain their relevance, as well as discuss the convergence properties of the model.
The full discrete-time GLV model is formally defined as: i = 1 , . . . , N, where  X  ( i ) t , in the biological context, is the biodensity of the i th species during period t . The model contains fixed constants b i and r i , known as the  X  X er capita growth rate X  and the  X  X oefficient of within-species interaction X , respec-tively. These specify the rate of free growth from period-to-period and the rate at which the biodensity reaches its intrinsic limit, known as its carrying capacity, due to com-petition for resources by members of the species. that describes the effect of inter-species interactions on bio-densities of all species. The constants a i,j specify the sign and strength of interactions between every pair of species.
In our machine-learning context, the quantity  X  ( i ) t is what we call the partially-learned classification confidence of i th training vector at discrete induction step t . The clas-sification confidence measures the strength of a vector X  X  membership in some class  X  the greater it is, the more con-fident we are that the vector belongs to this class. Through-out the paper we sometimes refer to this quantity as simply the confidence of an input vector. The classification confi-dence of a training vector measures the strength of the vec-tor X  X  membership in its  X  X rue X , as per training data, class. Classification confidences are the parameters of the deci-sion function and, by way of that, the states of our model. Hence, the convergence of the model signals the culmina-tion of induction, whereby the classification confidences are considered to be fully learned . This leads to the first core postulate. Postulate 2.1 Define a sequence n  X  ( i ) t o of partially-learned confidences for i th training vector. The fully-learned classification confidence  X  ( i ) is found at the con-vergence limit of this sequence:
Postulate 2.1 states that  X  ( i ) , i.e. the fully-learned con-fidence for x i , is found at the convergence limit of the se-quence n  X  ( i ) t o . In turn, the convergence limit is found at the convergence of the model (2).

The use of the system of recurrence equations to derive each induction step is motivated by the following postulate. Postulate 2.2 Sequence n  X  ( i ) t o is formulated as a recur-rence equation: where A t  X  1 = n  X  ( i ) t  X  1 | i = 1 , . . . , N o is the vector of partially-learned classification confidences at step t  X  1 , and g i ( A t  X  1 , X, Y )  X  R is the recurrence formula for i training vector. Note that there are N recurrence equations, used simultaneously to update the confidences in parallel.
Next, we present the postulate that makes the link be-tween the fully-learned classification confidences of the training input vectors and the classification decision func-tion. We first define confidence of some given vector x  X  under the assumption that it belongs to class with label c . The postulate describes how the vector in question.
 Postulate 2.3 Define a function h c : R N  X  R n N  X  Z + N R n  X  R for each class label c , such that where A = {  X  ( i ) | i = 1 , . . . , N } is the vector of fully-learned classification confidences.

Then, the predicted class of x  X  is chosen by comparing the predicted classification confidences for all class labels:
Thus, the predicted class of vector x  X  is the one with the highest predicted confidence  X  the class that is predicted to be the best fit for x  X  .
Next, we present the postulates that motivate the choice of the GLV model for the system of recurrence equa-tions in Postulate 2.2. The model is based on two prin-ciples. The first is logistic growth , characterized by near-exponential growth when the classification confidences are small, switching to decay as the confidences pass some mid-point, called the point of inflection, allowing convergence of the confidences to finite limits.

In our context, logistic growth is explained with the fol-lowing postulate.
 Postulate 2.4 (Maximal overfitting/self limitation)  X  i, t :  X  m &gt; 0 :
The maximal overfitting postulate 2.4 states that the slope of the recurrence function is proportional to the inflec-tion point m minus the previous confidence  X  ( i ) t  X  1 . Thus, if confidence at the previous induction step was much smaller than m , the direction and rate of confidence change is pos-itive and proportionally high. By contrast, if the previous confidence is above m , the next induced confidence will be lower. Essentially, this postulate describes how each train-ing vector can attain its full potential confidence, if it were completely independent and free of interference from other vectors. Consisting of this principle alone, the model cre-ates conditions for maximal overfitting, because each confi-dence is induced in isolation relying on the training vector alone, as if it were its own class. In the full GLV model (2), the inflection point m is inversely proportional to the coef-ficient r i . A larger r i causes the inflection point to occur sooner (smaller m ), with the vector X  X  classification confi-dence converging to a smaller value. Coefficient r i can thus be used to control how quickly each vector limits the growth of its own classification confidence. As we shall see later, this has profound effect on the stability of the model.
The second principle of our framework is the regulariza-tion of learning, achieved by adding interactions between the confidences of the training vectors, which relates the induction of each vector X  X  confidence to the induction of all other vectors X  confidences, thus moderating the maximal overfitting principle. The following two postulates motivate positive and negative interactions between the confidences of input vectors.
 Postulate 2.5 (Inter-class competition/negative interaction)
Inter-class competition is the mutually negative interac-tion between vectors of opposing classes. The motivation for it is that being more confident that patterns in a part of the space belong to a certain class implies that we are less confident that these patterns belong to another class, whose members vectors might be situated near or around that part of the space.
 Postulate 2.6 (Intra-class cooperation/positive interaction)
By contrast, postulate 2.6 states that vectors from the same class have mutually positive effects on the growths of each other X  X  confidences, justified by the shared classifica-tion and also as a way to counteract the effect of inter-class competition from vectors of other classes.

Both positive and negative interaction effects are mod-eled via the term P N j =1 sign of the coefficient a i,j specifies if the interaction is intra-class cooperation ( a i,j &gt; 0 ) or inter-class competition ( a i,j &lt; 0 ), while its magnitude quantifies the strength of the interaction  X  the extent of vector x j  X  X  (or more correctly its classification confidence X  X ) impact on the classification confidence of vector x i .
Before we discuss the convergence and equilibrium con-ditions of our model, it is convenient to switch from the discrete-time recurrence model to a continuous-time differ-ential model. Conceptually, this switch means that induc-tion takes place continuously, rather than at discrete steps. To model this continuous, instantaneous-time induction, a system of differential equations takes the place of the sys-tem of recurrence equations: dt where  X  i is a function of time. This is a system of lin-ear first-order differential-equations. The joint convergence limit, or equilibrium, is found by setting the right-hand side to 0, and finding the roots [10].

However, that would include solutions, where some  X  i  X  X  are 0 1 , due to the single term  X  i outside the parenthesized term. However, since the induction outcome with any fully-learned confidence equal to 0 is not preferred, we can focus our attention only on the parenthesized term, solving the following equation:
This results in the linear system of equations, introduced in the beginning of this section (1): where A = {  X  i | i = 1 , . . . , N } . In order to define the in-teraction matrix M , we split the interaction coefficients a into sign and strength factors  X  i,j and s i,j , respectively: where  X  i,j is equal to 1 when y i = y j (vectors are in the same class), and  X  1 when y i 6 = y j (vectors are in different classes), and s i,j  X  (0 , 1) .

Solving (1) attains what is known in population ecology as the  X  X ommunity equilibrium X , whereby all species coex-ist together in an equilibrium. In our context, the solution precludes only non-zero fully-learned confidences.
To make sure that a unique solution does exist, we need only ascertain that the determinant of M is non-zero. How-ever, it is also important that the community equilibrium is stable, so as to be certain that the induction will indeed con-verge every time to the point where the classification confi-dences become fully trained (c.f. Postulate 2.1).
A key theorem on systems of differential equations states that an equilibrium is stable if and only if all eigenvalues of the Jacobian of the right hand side of (7), evaluated at the roots of the system, have negative real parts [7]. It is a matter of simple exercise to find that this Jacobian is equal to  X  DM , where D is a diagonal matrix with D i,i =  X   X  i and where  X   X  i  X  X  are the roots of the system (1). We rephrase this requirement to say that all eigenvalues of matrix DM need to have strictly positive real parts. We shall return to this point in the next section.
In this section, we address the formulation and computa-tion of the coefficients of the interaction matrix. First, let us start with the coefficients of interaction strength s i,j sign of interaction is given by  X  i,j , and its simple formula-tion was given earlier.

We present two different formulations for the interaction strengths: a simple one, as well as a more elaborate one, which addresses some inherent model weaknesses. In the experimental results section we refer to these formulations as IMBL I (simple) and IMBL II (elaborate).
The simple formulation makes the interaction strength between two vectors equal to the similarity between them, defined as some distance metric in the vector space. The premise for this is that more similar vectors should experi-ence more interaction and have stronger effect on induction of each other X  X  confidences. More similarity means more extensive sharing of patterns between vectors. For vectors of the same class, this further cements our confidence that these shared patterns belong to their common class. For vectors of different classes, on the other hand, more simi-larity suggests that stronger competition should take place, since the patterns shared by the vectors cannot belong to both classes at the same time.

In order to allow arbitrary levels of non-linearity and ca-pacity of pattern recognition, similarities are computed with Radial Basis Function(RBF) kernels. The RBF kernel is de-fined below.

Thus, under the simple formulation of IBML I, the inter-action strengths are equal to the RBF function.
Note that this simple formulation has two consequences for the matrix. The first is that all off-diagonal terms are less than 1, and the second is that matrix M is symmetric,
Exploring this rather straightforward interaction matrix and the resultant classifier, we came across several  X  X ide-effects X  of the model, which allow sub-optimal classifica-tion performance. The model allows entire classes to out-compete each other, especially under small  X   X  X , completely disrupting any parity between the classes. This occurs when data are unbalanced, as when one class is less spread-out or bigger than the other, which occurs in most real prob-lems. Vectors of a class that is less spread-out or bigger en-joy stronger intra-class cooperations than vectors of more spread-out or smaller classes. As a result, their classifica-tion confidences are allowed to reach higher limits, which in turn causes the confidences of vectors from more spread-out or smaller classes to suffer. As  X  is reduced, and interac-tions begin to play a larger role in the outcome of induction, the  X  X tronger X  class with less spread or more members will take over the pattern space around the other  X  X eaker X  class. In order to alleviate this side-effect, we introduce a heuristic that modifies the simple formulation.

The idea we employ is the use of a unique  X  for the intra-class cooperations of each class. Classes that are com-paratively more spread-out or smaller should use compara-tively smaller  X   X  X  for their vectors X  intra-class cooperation strengths, in order to compensate for them being fewer and further-apart.

In order to achieve this, we first compute the average squared Euclidean distance for each class, defined as where N c is the number of vectors in class c .

We can use these average distances to find  X   X  X  that equal-ize the  X  X verage X  RBF kernel outputs for each class, defined as
We use the single user-supplied  X  to be the unique  X  c of the class with the largest D c , and then find the  X  c  X  X  of all other classes with the following simple equation: .
 We should note that even in the elaborate formulation IMBL II, the interaction strength coefficients used for inter-class competition still use the one user-provided  X  , as with IMBL I. This is so that the interaction matrix M can re-main symmetric. The coefficients for intra-class coopera-tion, however, are defined as:
This formulation naturally involves more CPU cycles than the simpler formulation, namely for computing (12) and solving (14). As with IMBL I, matrix M is still sym-metric with off-diagonal entries less than 1.
 This brings us to r i  X  X  or the diagonal terms of matrix M . As we mentioned earlier, the greater this coefficient is, the quicker the classification confidence reaches its conver-gence limit. The choice of this coefficient is motivated by two different concerns. The first concern is ensuring that the system is solvable and the model equilibrium is stable. The second concern is finding the most time efficient imple-mentation of the algorithm.

In the previous section we mentioned that the equilib-rium is stable if and only if all eigenvalues of matrix DM have positive real parts. Furthermore, the determinant of M needed to be non-zero for the system to be solvable. Both of these requirements are satisfied if we can force M to be symmetric (which it is) and strictly diagonally dominant . Strictly diagonally dominant matrices are ma-trices whose diagonal entries are greater than the sums of magnitudes of remaining entries in the corresponding rows: agonally dominant for any  X  , we set all diagonal terms M to N  X  1 , since for small  X   X  X  the magnitudes of off-diagonal values tend to 1 .

The properties of strictly diagonally dominant matrices we are interested in are: a) that strictly diagonally dominant matrices are non-singular, or with non-zero determinants, due to the Levy X  X esplanques theorem [12], and b) sym-metric diagonally dominant matrices with real non-negative diagonal entries are positive-semidefinite. The property a) is important because it guarantees that M is invertible and a solution to our system exists. Furthermore, by b), M is positive-semidefinite, and, therefore, all eigenvalues of M are greater than or equal to 0. But, from property a) we know that all eigenvalues of M are non-zero, since the de-terminant, equal to the product of all eigenvalues, is non-zero, leading all eigenvalues of M to be strictly greater than 0. This means that M is positive-definite.

If M is a strictly diagonally dominant matrix, then it is easy to show that DM is likewise, since multiplying each entry of a row by the same value does not change the fact that the diagonal is the most dominant entry in the row. Since DM is not symmetric however, we cannot state that it is positive-semidefinite. However, even if the symmetry condition is not satisfied, the real parts of strictly diago-nally dominant matrices are non-negative, due to the Ger-shgorin circle theorem [2]. Finally, since matrix D and M are invertible, their product, DM must also be invert-ible and, therefore, with non-zero determinant and non-zero eigenvalues. Therefore, the eigenvalues of DM must have strictly positive real parts, which satisfies the necessary and sufficient conditions for stability of our system X  X  equilib-rium, for any  X  .

Besides this theoretical consideration, the fact that M is symmetric and positive-definite carries an important prac-tical benefit for solving the system. Namely, the faster Cholesky decomposition algorithm can be used instead of the twice slower LU decomposition, which we would have had to employ if M were not symmetric or non positive-definite.
Once the system (1) has been solved and the learned con-fidences have been found, we use them to predict the class of a new vector x  X  . As postulate 2.3 shows, in order to pre-dict its class, we must first find the predicted confidences of x , for each class in the data.

The complete approach would be to add x  X  and its as-sumed class to the training data, and relearn the confidences of all vectors (original training vectors plus x  X  ), following which x  X   X  X  fully-learned confidence can be used as the pre-dicted confidence in question. A more efficient approach however is to keep all the fully-learned training confidences fixed, which is justifiable if we note that they are in a stable equilibrium  X  the state that is most robust under perturba-tions. With this in mind, we present the recurrence equation for learned confidences for x  X  , under assumption that it belongs to class c : [  X  where  X   X  j | c , and s  X  j | c are the identical to  X  i,j except that vector x i is replaced with x  X  , and the class y replaced with the assumed class c .

In a sense, the above equation does not have any mod-eled interaction, since  X  i  X  X  are constant values at this point. All it exhibits is logistic growth, where the constant term P bound on the differences between all the predicted confidences is this summation term. Consequently, we can define the predicted confidence of x  X  for each assumed class as this summation:
For this paper we carried out extensive accuracy and time-benchmarking experiments of the IMBL algorithm. As the standard for both of these performance benchmarks, we used the well-known Support Vector Machines algo-rithm for classification. The implementation we used was the fast and robust LIBSVM library, written by Chih-Wei Hsu and Chih-Jen Lin [5].

IMBL was implemented by ourselves, with a call to the powerful LAPACK library [1] for the Cholesky decompo-sition block routine. The routine is quoted to have O ( n time complexity, which is twice faster than the LU decom-position routines. Considering that all routines for con-structing the interaction matrix are quadratic at worse, it is fair to judge our algorithm to be cubic at worst. Natu-rally, analytical comparison of this time complexity to the time complexity of SVM is made difficult by the fact that of LIBSVM we know only the time complexity of a sin-gle iteration  X  O ( N n ) , but the total time is compounded by a variable number of iterations that the algorithm must take to solve the dual problem. With each dataset and each SVM parameter pair (gamma, C), the training algorithm can take a very different number of iterations to complete. The machine we used was a 64bit Fedora Core 6 running on a Quad-Core AMD Opteron 2212 (2.01GHz each) with 4GB RAM.

We perform several experiments and report the optimal accuracy and running-time. The data used in this paper were previously used in a paper by Meyer et al. [11]. In total there are 21 binary datasets, most made available in the UCI ma-chine learning database [3]. The datasets are summarized in Table 1. Their download links can be found in [11].
The experiments we performed were simple 5-fold cross-validation experiments, with changing user parame-ters. It simply came down to an automated batch of ex-periments trying all parameters from some set of parameter values/pairs. Each parameter set has a clearly defined range and step size.

For SVM, we performed a two-dimensional grid search with a parameter set for RBF  X  (or gamma as it is called in LIBSVM) and a parameter set for parameter C . For IMBL, on the other hand, we only had to perform a single line search for the optimal  X  . Naturally, this is a key strength of our algorithm, allowing a simpler/faster model selection process.

To illustrate this point, we performed model selection ex-periments for both algorithms with equal step sizes. For IMBL, the  X  ranged from 2  X  6 to 2 6 with the powers in-creasing in steps of 0 . 2 , which resulted in 61 different val-ues. For SVM we used this same set of 61 values for both C and gamma, resulting in 3600 parameter pairs. The highest cross-validation accuracies, found after the grid (for SVM) and line (for IMBL) searches, are reported in Table 2.
As the table shows, on 8 datasets ( sonar , promotergene , threenorm , breastcancer , twonorm , titanic , spirals , ringnorm ) one or the other IMBL formulation is either more accurate than SVM (at least judging by CV experiments) or is almost identical to it (  X  0 . 2% difference). On further 5 datasets ( monks3 , circle , hepatitis , chess , heart1 ) IMBL is within 2% of SVM X  X  results. The datasets where IMBL is much worse than SVM (more than 7% difference) are the tictactoe , cards , liver , ionosphere sets. Table 2. Top cross-validation accuracies for SVM and IMBL I and II.
 Table 3 lists the running times for the above experiments. By dealing with just one optimal parameter, IMBL can complete the model selection phase significantly faster than SVM and similar algorithms with more extensive parame-terization. However, it would be interesting to see if there is any relationship between IMBL X  X  relative speed advantage and SVM X  X  relative accuracy advantage. On Figure 1 we present the scatter plot of accuracy difference ratios versus running time difference ratios. The plot shows that the rela-tive accuracy of IMBL is inversely correlated with its speed  X  finding the optimal parameter with IMBL takes the least time, as compared with SVM, for datasets on which it per-forms worst.

We would like to find out if trying only 61 values for  X  is
Table 3. Running time (in hour:min:sec) for completion of the entire model selection run (going through all parameter choices/pairs).
 enough to ensure the optimal accuracy for each dataset, or if we should try many more values in between. To answer this question we ran IMBL I and IMBL II with  X  ranging from 2  X  6 to 2 6 , with the powers increasing in steps of 0 . 005 . This results in 2401 values. We wanted to find out if the differences in optimal accuracies with the increased search precision would be high or negligible. In Table 4 we report the optimal accuracies for IMBL I and IMBL II with the new parameter range. As the table shows, the optimal re-sults results have improved. However, the changes are not significant, and comparisons with SVM X  X  results have not been significantly altered.

In addition to timing the entire model selection phase, we also wanted to compare the running times of individual CV experiments. We measured the running time of each individual CV experiment in CPU clock ticks, for SVM, IMBL I and IMBL II. In Table 5 we report the maximum, minimum and median CPU clock ticks for each problem.
On 9 datasets, either IMBL I or IMBL II, but not both together, had better median running time than SVM, while on another 3 datasets, it was a very close call (+/-5 ticks).
Let us revisit the two inductive principles introduces ear-lier: maximal overfitting and interactions. Maximal overfit-
Figure 1. Plot of accuracy difference ra-tio, ( Acc SV M  X  Acc IMBL ) /Acc SV M , versus running time accuracy ratio, ( T ime SV M  X 
T ime IMBL ) /T ime SV M . A higher accuracy dif-ference ratio shows worse performance for
IMBL compared to SVM, while a higher run-ning time difference ratio shows faster run-ning time for IMBL compared to SVM. ting represents the extreme case of infinite capacity, where each vector is completely isolated from the rest of the train-ing data and is seen as its own class. Each vector is respon-sible for its own confidence, and it will ensure the maxi-mum confidence, regardless of how unrepresentative it is of the general distribution. Under the the maximal overfitting principle, IMBL behaves similarly to how other kernel algo-rithms like SVM, RBF networks, Least-squares and others behave when their capacity is pushed to the extreme. In this case, the system matrices of all these algorithms are usually the identity matrices.

Plugging in community interactions moderates the in-duction process by tying the classification confidence of each vector to other vectors in the dataset. This averages the impact of local patterns on the decision function and in-hibits unrepresentative patterns from significantly affecting the classification confidences of other similar patterns. On the other hand, too much interaction runs the risk of com-pletely whitewashing the relevance of some local patterns, which are essential for good generalization.

This balancing act is controlled by the  X  parameter. A large  X  sets maximal overfitting (cf. postulate 2.4) as the main effective inductive principle of the model by reduc-ing the interaction effect. This benefits outliers due to their  X  X ifficult X  locations and can be the cause of poor general-ization.

Conversely, a small  X  increases the visibility of vectors to each other, which increases the association and inter-dependence between the confidences. As a result, con-fidences are affected to a greater extent by general pat-Table 4. Top cross-validation accuracies for
IMBL I and IMBL II, with the updated parame-ter range.
 terns, with the more drastically unrepresentative vectors be-ing dominated and forced to have ineffective confidences at convergence. According to statistical learning theory, more inter-dependence and association between the vec-tors is preferred to more individualistic learning, because it makes induction more robust and less sensitive to noise and outliers. In summary, the  X  parameter combines capac-ity control and overfitting control by moderating how ef-fectively the model weeds out outliers and noise, which, if left unmanaged, can degrade the conditioning of the system matrix.

Figure 2 shows a two-dimensional toy example of  X   X  X  ef-fect on outliers and local patterns. A large  X  , Figure 2(a), ensures that all three outliers of the cross-marks class have high enough confidence that unlabeled data around them are classified as cross-marks , while a smaller  X  allows the data to force the three outliers to become ineffectual in the con-text of classifying unlabeled data.
The main benefit of using a dynamic learning model is that the fully trained decision function is obtained from the stable steady-state of the model, since at this point the pa-rameters of the decision function attain their equilibrium values. The choice of recurrence equation models is impor-
Figure 2. Example of the implicit control of overfitting with  X  . tant, due to the relatively simple computation of the steady-state. The second feature of our work is the modification of the model with coefficients based on spatial relationships between the observations. Because learning is not based on artificially specified criteria and constraints, but rather on an intuitive juxtaposition of interactions and vectors X  effect on themselves, the issue of overfitting is handled  X  X mplicitly X .
The experiments show that IMBL has potential for use by outperforming such a robust and powerful algorithm as SVM. While IMBL may not be able to challenge SVM on accuracy in general, there are cases when IMBL can be a useful addition to a classification toolset, especially considering its reduced parameterization. As pertaining to comparison of running times between IMBL and SVM, it needs to be noted that our implementation used a third party Cholesky decomposition routine, which has a general in-terface function that wastes CPU cycles on error checking, function argument validation, etc. It is possible that a cus-tom made decomposition routine would reduce the running time of our algorithm even further.

The viability of multi-class classification is inherent to the algorithm. This is due to the fact that class labels are used only to determine the signs of interactions. For each vector, there is either its own class or other classes. In a way, this idea is reminiscent of one-against-all schemes for multi-class classification. The size of the linear system is not affected by the number of classes. Furthermore, we have not noticed any apparent increase in the complexity of the linear system due to added class labels. The decision function, on the other hand, is affected by the number of class labels, as more classes require more comparisons of predicted confidences.

There are several directions of improvement and exten-sion that promise a more accurate and efficient algorithm. Currently, the main focus of our work is updating and ex-tending the formulas for computing the spatially-dependent interaction coefficients, with emphasis on primarily accu-racy, while keeping algorithmic complexity increase to a minimum.

