 Image reranking, which aims at enhancing the quality of keyword-based image search with the help of image features, recently has become attractive in image search communi-ty. A major challenging in this task is that image X  X  visual features do not always well reflect image X  X  semantic mean-ing. Thus, reranking methods only depending on visual fea-tures cannot guarantee to obtain good results. In addition, it is well known that the visual features of an image have strong/weak correlations with its surrounding text. Thus, it is expected that a model considering both visual features and its surrounding text can perform better than those on-ly considering visual features. Motivated by this, in this paper, we propose the HAFSRerank X  X eterogenous Auto-matic Feedback Semi-supervised Reranking method which makes use of both visual and textual features simultaneous-ly during reranking. Specifically, in HAFSRerank, a multi-graph is firstly constructed in which each node represent-ing an image includes visual and textual features, and the parallel edges between them are weighted by intra-modal similarity and inter-modal similarity. A heterogenous com-plete graph is further derived from the multigraph. Then, an automatic feedback graph-based semi-supervised learn-ing method is proposed to propagate the reranking scores on the complete graph, which can make use of the inter-modal similarity to update the weights of heterogenous graph auto-matically. Finally, the result of the semi-supervised learning is used to rerank the images. The experimental results show that HAFSRerank is superior or highly competitive to some state-of-the-art graph-based reranking methods. Moreover, the proposed reranking algorithm can be well interpreted by Bayesian theory, and does not require complex search mod-els for special queries and any additional input from users.
Corresponding author.  X 
This research was partially supported by NSFC (61173068, 61103151).
 Figure 1: Six images from Google Images for the query  X  X orres 2013 X .
 H.3.3 [ Information Search and Retrieval ]: Retrieval models; I.2.6 [ Artificial Intelligence ]: Learning Design, Algorithms, Experimentation Image Reranking; Automatic Feedback; Graph-based Semi-supervised Learning; Image Search; Heterogenous Graph
With the popularity of photo-sharing applications and so-cial network site(SNS), the amount of digital images avail-able on the web has grown dramatically in recent years. This has brought a new challenge to image search: how to effec-tively search so large number of web images which has at-tracted more and more researchers [26]. Although different image search engines have been proposed; most of them still depend on the associated textual features, such as surround-ing text, anchor text, etc. Since the textual features contain much noisy and the visual features are neglected, the search results are usually unsatisfying. For example, irrelevant im-ages are returned on the top positions. As shown in Fig. 1, the results of the query  X  X orres 2013 X , apparently there are some images which the user is not interested in. To tack-le such difficulties, visual reranking is proposed to improve the text-based search result and has attracted substantial research interests [13, 8, 5, 21, 27, 29, 9]. Up to now, many research works have been carried out on this topic, which can be broadly classified into three categories, i.e., learning to rank based approach [13, 9], classification based approach [12, 5, 27], and graph based approach [21, 28, 29].
Among them, graph-based methods have drawn increasing attention recently and have already shown promising results on image and video search[8, 29]. In such methods, a graph is firstly constructed in which images or video shots are rep-resented as nodes and edges are weighted by their visual sim-ilarity; then some algorithm is performed on this graph to get the new ranking score. Graph-based approaches are usu-ally based on the assumption of ranking score consistency, i.e., neighboring nodes (visually similar images or video shot-s) in the graph should have close ranking scores. Random walk and semi-supervised learning are two main frameworks for the graph-based reranking method. For example, in [8], Hus et al. apply random walk reranking on the similarity graph; in [29], Zhang et al. use a semi-supervised learning method. However, these graph-based reranking methods on-ly exploit the visual features. Some literatures have shown that the methods solely using one kind of features for image reranking cannot achieve satisfying performance. Therefore, some graph-based image reranking methods fusing multiple features have been proposed recently [22, 18, 25]. However, in these methods, visual features and textual features are used mutually, e.g., in [18], Tan et al. construct a graph for each type of feature and then fuse the result of each graph as the final result. Apparently, such methods neglect the fact that there are strong/weak correlations between the textual feature and visual feature.

In this paper, we present a graph-based semi-supervised reranking method X  X AFSRerank, which considers visual and textual features simultaneously during reranking. Besides the intra-modal similarity, we introduce the inter-modal sim-ilarity which is heterogenous and reflects the relationship between visual features and textual features. First, a het-erogenous complete graph is constructed in which both vi-sual features and textual features are embedded. Then we use an automatic feedback semi-supervised learning method with a regularizer to propagate the ranking score. Finally, the result of the semi-supervised learning is used to rerank the images. In HAFSRerank, visual features and textual features in the graph are ranked simultaneously, and the re-lationship between the visual features and textual features can be utilized during the reranking process. HAFSRerank is based on the assumption that visual features and textual features are the representations of the image from differen-t views and their semantic meanings are correlated. That is to say, the visual features and textual features are only different aspects/descriptions of the same image in differen-t space and the ranking score should be correlated to some extent. For example, in Fig. 2, both visual features and text features describe the meaning of  X  X occer X , which shows the consistency of visual features and textual features in high level semantic space. Thus, a user interested in images as-sociated with text  X  X occer X  will be also interested in images with visual features of  X  X occer X .

The contributions of this paper include: Figure 2: This figure shows that visual features and textual features are consistent in semantic space.
The rest of this paper is organized as follows. Section 2 reviews the related work, e.g., unimodal/multi-modal fu-sion and semi-supervised learning. Section 3 details the proposed graph-based semi-supervised reranking approach X  HAFSRerank. Section 4 reports and analyzes the experi-mental results. Finally, section 5 concludes this paper.
Most reranking methods [8, 27, 4, 30] adopt unimodal fea-tures, e.g., textual or visual features for reranking. In this diagram, it is a natural idea to rerank the text based retrieval results by using visual features. For example, in [6], Fergus et al. present an approach that can learn an object category by utilizing the raw output of image search engines which can be further used to rerank the image search results. Cui et al. [5] first categorize a query image into one of several redefined intention categories; then, use a specific similarity measure to combine image features for reranking. Hse et al. [7] propose an IB reranking method, based on a rigorous Information Bottleneck principle. Tian et al. [20] formulate the video search reranking problem in the Bayesian frame-work. Jing and Baluja [11] cast the reranking problem into the task of identifying authority nodes on an inferred visual similarity graph. In [14], Lu et al. propose to filter out the most probable irrelevant images using deep contexts, then use a graph reranking approach to solve the problem. In-stead of using visual features for reranking, some methods have tried to make use of text information for the reranking task. For instance, Taneva et al. [19] use the textual fea-tures (keyphrases) extracted from the Wikipedia to rerank images.

Although these methods mentioned above have obtained some progress; the results of reranking methods based on only visual/text features are unsatisfying. Thus, many re-searchers have exploited multimodal features to enhance the reranking results [17, 28, 18, 24, 25]. Snoek et al. [17] con-catenate the features from different modalities to form a (e) The reranked image list single feature vector. Such scheme to deal with the multi-modal information is known as X  X arly fusion X . Some methods use other methods to make use of multimodal information which is known as  X  late fusion X . For example, in [28], Yao et al. propose a Co-reranking model for image search which couples two random walks over textual and visual modali-ty mutually and then fuses the results. In [18], Tan et al. exploit video and image reranking task based on the agree-ment among multiple modalities to guide data fusion. In [24], Wang et al. describe a method to retrieve images with specified object class labels by exploiting established online knowledge resources (Wikipedia pages for the text features; Flickr and Caltech data sets for the image features). Al-though these methods, e.g.,  X  X arly fusion X  or  X  X ate fusion X  have considered the multimodal property of data; they ne-glect a fact that visual features and textual features are the representations of the image from different views and mul-timodal features have strong/weak relationship or are con-sistent to some extent in a high semantic space. Thus, it is expected that a model can obtain better performance if it considers these features simultaneously and makes use of the relationship between them during reranking. Recently, Wang et al. [25] have explored such idea and proposed a random walk based approach for the reranking task.
Semi-supervised learning falls between unsupervised learn-ing (without any labeled training data) and supervised learn-ing (with completely labeled training data). By leveraging unlabeled data with certain assumptions, semi-supervised learning methods are expected to have better performance than those only working on labeled training data. Many d-ifferent semi-supervised learning algorithms have been pro-posed, e.g., EM with generative mixture models [15], co-training [3], self-training [16] and graph-based methods [34]. Extensive reviews of existing methods can be found in [1, 35]. Recently, some researchers [18, 29, 10] have tried to exploit semi-supervised learning to rerank image search re-sults. In [29], Zhang et al. present a semi-supervised learn-ing reranking framework based on Ranking SVM with a new similarity measure algorithm named SM-PCA, which is re-lying on Principle Component Analysis. In [10], Ji et al. propose a novel system scheme based on semi-supervised Locality Preserving Projections (LPP) and Ranking SVM. Tan et al. [18] used semi-supervised learning and random walk for video and image reranking tasks. In this section we propose the HAFSRerank approach X  Heterogenous Automatic Feedback Semi-supervised Rerank-ing which is shown in Fig. 3. First, we show how to construc-t the complete heterogenous graph. Then, we introduce the graph-based semi-supervised learning method developed on regularization framework with the automatic feedback pro-cedure. Finally, we summarize the HAFSRerank algorithm in Algorithm 2 .
As stated in [34], graph construction is more of an art than science. Thus, one of the main problems in graph-based semi-supervised learning techniques is how to construct an appropriate graph. In order to propagate the ranking score considering visual and textual features simultaneously, we first construct a multigraph in which each node contains both textual and visual features.
 Given a query q i ,asetof N images { I 1 ,I 2 ,I 3 ..., I returned by the image search engine. For each image I i ,it is represented by its visual feature v i and textual feature t We model the graph of images as a multigraph G =( V,E ) where V = { I i | i =1 , 2 , ..., N } is the set of the nodes and E is the set of parallel edges. As shown in Fig. 3(b), each node in the multigraph contains visual and textual features. Note that a dashed line represents multiple parallel edges between two nodes, which reflect not only the intra-modal relation, i.e., visual-visual and textual-textual, but also the inter-modal relation, i.e., visual-textual and textual-visual. With intra-modal and inter-modal relations, we can simulta-neously use the the visual and textual features to propagate the ranking score.

The edge weights of the graph determine the relationship of the nodes which can be derived from some similarity met-rics. To set the weights, firstly we need to calculate the intra-modal similarity and the inter-modal similarity.
Intra-modal Similarity. To calculate the intra-modal similarity, we consider three different similarity metrics: In-verse Euclidean Distance, Cosine Similarity and Histogram Intersection. Let p, q be two points of n -dimension space, these similarity metrics are defined as:
Let s ( t i ,t j ) represent text-modal similarity and s ( v vision-modal similarity where t i , t j are the textual feature vectors of image I i and I j ,and v i , v j are the visual feature vectors of image I i and I j . Then, the intra-modal similarities can be defined as:
Inter-modal Similarity. To measure the inter-modal similarity between two images, we leverage the intra-modal similarities. Let s ( t i ,v j ) represent the textual-visual inter-modal similarity, the similarity between t i and v j can be defined as: where  X  is trade-off parameter and c ( t i ,v i ) is the inter-modal consistency which measures the agreement/consistency of visual feature and textual feature in image I i which is can be calculated according to the ranking score of I i .Inthis paper, it is defined as: where f ( t i )and f ( v i ) are the textual and visual ranking scores of image I i , respectively;  X  is a scaling parameter. The closer the rank scores of t i and v i , the more consistent of inter-modal of the visual and textual features. From Eq. 6, we can see that inter-modal similarity is proportional to inter-modal consistency and the intra-modal similarity. Based on these definitions, a heterogenous complete graph G
C is then derived from the multigraph G . Specifically, each node I i in G is expanded into two new nodes, i.e., the textual node t i and the visual node v i . In addition, a new edge is added between t i and v i . For example, as shown in Fig. 3(c), the circles represent the visual features and the triangles are the textual features. Then, the similarity matrix of G C is defined as: where S tt ,S vv are the intra-modal similarity matrices and S tv ,S vt are the inter-modal similarity matrices.
In this subsection, we propose an automatic feedback semi-supervised learning approach based on the heterogenous com-plete graph, which is formulated as a regularization frame-work [31]. Different from [31], our method is with automat-ic feedback, which can update weights of the heterogenous graph automatically. In this semi-supervised learning ap-proach, the score is formulated as follows: f  X  = arg min where f =[ f t ,f v ] is the regularized ranking score vector of the nodes in G C which we intend to find and y =[ y t ,y v is the initial ranking score vector of the nodes which the method to calculate will be given in section 3.3, and D is a diagonal matrix with all ( i, i )-elements equal to the sum of the i -th row of S . The first term of the right-hand side in the objective function is the smoothness constraint, which enforces the score consistency where given two images I i and I j ,theirscores f ( i )and f ( j ) should be similar if the value of S i,j is high. The second term is a regularization term, which means f  X  should not change too much from the initial score y . The trade-off between these two competing terms is controlled by parameter  X  (0 &lt; X &lt; 1).
Differentiating the right side of Eq. 9 with respect to f , we have the following optimal vectorial function f  X  trix of S and I is the identity matrix of the same size with L .

Although the closed form is achieved; from the perspective of practical cases, an iterative solution is more preferable, which is shown as follows: where f (0) = y and t is the iteration number.

Based on the works in [31, 22], the relationship between the closed form and iterative form can be proven. According to Eq. 11, we have
Since 0 &lt; X &lt; 1 and all eigenvalues of L are in [  X  1 , 1], we can get t  X  X  X  f ( t ) = lim t  X  X  X  (  X L )
Note that, in Eq. 13, the constant 1  X   X  does not affect the ranking score; Thus, we have
For the purpose of making use of the inter-modal similari-ty to propagate the ranking score, we use f  X  to update the similarity matrix S and the normalized Laplacian matrix L . This procedure can automatically update the weights of the graph G C and we call it automatic feedback (AF). Note Algorithm 1 Automatic Feedback Algorithm Input: Ranking score f  X  ( t ), best AP value apbest . for i =1  X  N do end for
Calculate ap with CurrentRankingScore ; if apbest  X  X  X  1OR ap  X  apbest then ; else end if Update initial ranking score y = f  X  ( t ); Update the inter-modal similarity in S with f  X  ( t );
Update Laplacian matrix with L = I  X  D  X  1 2 SD  X  1 2 ; that the AF is different from the pseudo relevance feedback (PRF) which is usually to regard the top ranked images in the initial result as the relevant ones. In other words, we call it positive feedback that makes the results better; other-wise, negative feedback 1 . In implementation, the evaluation metric average precision(AP) can be used to determine the effect of the feedback. For instance, if the value of AP is less than the best value of AP of some query, the feedback is negative; otherwise, positive. To control the effect of the negative feedback, we can use the early stopping strategy. The AF algorithm is summarized in Algorithm 1 .

After the automatic feedback process, we have the final f ; then, we can get the ranking scores of textual and visual image I i , we use the following scheme which combines f  X  where  X  is a trade-off parameter.
Another problem that we need to further consider is how to initialize the ranking scores including both textual and visual ranking scores.

Initializing Textual Scores . In general, as most popu-lar image search engines are built on textual features to get the initial ranked list, we consider the following strategies to initialize the textual ranking scores [35]:
Note the concepts of positive feedback and negative feed-back are different from the concepts in the Control Theory and the effects on the results of the system are opposite. Algorithm 2 HAFSRerank X  X eterogenous Automatic Feed-back Semi-supervised Reranking Input: Images with surrounding texts and initial rank re-turned by the image search engine.
 Output: The reranking scores of images Construct a multigraph G ; Construct heterogenous complete graph G C from G ; Initialize similarity matrix S ; Initialize Laplacian matrix L = I  X  D  X  1 2 SD  X  1 2 ; Initialize t =0, f (0) = y , initial rank score y ;
Initialize apbest =  X  1; while not convergent do end while for i =1  X  N do end for
Initializing Visual Scores . Considering HAFSRerank is semi-supervised learning based approach, here we use two strategies to initialize the visual scores. After the textual and visual score vector are initialized, they can be concatenated into the ranking score vector following the formula described in section 3.2.

To further show the process of HAFSRerank clearly, we summarize it in Algorithm 2 .
In this subsection, based on the work in [32, 22, 20], we further present a Bayesian interpretation for the proposed algorithm, which shows why HAFSRerank can work on the heterogenous graph from another point of view.

The ranking score list can be viewed as a random variable; then, reranking can be interpreted as a process to derive the most probable score list given the visual and textual fea-tures as well as the initial scores. Let p ( f | v,t )denotethe conditional prior probability of f and p ( y | v,t,f ) be the con-ditional probability of y given v,t,f . From the probabilistic perspective, reranking is to derive the optimum f  X  with the maximum log posterior probability which can be formulated as:
According to the Bayes X  theorem, the posterior is propor-tional to the product of the conditional prior probability and the likelihood, i.e.,
Assuming that the visual features and textual features ( v,t ) is conditional independent of the initial score y given the score vector f ,wehave
According to the product rule of probability, we then have the following equation
From Eqs. 22 &amp; 23, we get
Substituting Eq. 24 into Eq. 21, we can obtain
T hen, the log of MAP estimation can be formulated as
As described in section 3.1, the heterogenous graph G C is a complete undirected graph which can be interpreted as a Markov random field; therefore, we can formulate the conditional prior p ( f | v,t )as where Z is a normalization constant and E i,j ( f,v,t )isthe energy function.

According to the local consistency assumption that if sam-ples have similar features their corresponding ranking scores should be close, the energy can be defined as:
Substituting Eq. 28 into Eq. 27, we obtain the conditional prior p ( f | v,t )= 1 The conditional likelihood p ( y | f )isfurthergivenby where Z is a normalization constant and  X  is a trade-off parameter.

Replacing the conditional prior and conditional likelihood in Eq. 26 with Eqs. 29 &amp; 30, the MAP estimator Eq. 26 finally becomes f  X  = arg min which is identical to Eq. 9.
 Table 1: The property of the dataset by group.

In this section, we demonstrate the effectiveness of our proposed HAFSRerank method by experiments on the pub-licly available  X  X eb Queries X  dataset [12].
The  X  X eb Queries X  dataset contains 353 queries in which for 80% of queries there are more than 200 images; totally there are 71478 images in the dataset.

To allow a more detailed evaluation, we follow [12, 25] and choose three groups of queries with different behavior on the search engine:
The fraction of relevant images averaged over the queries in each group, which gives an indication of the difficulty to rerank queries in each group, is shown in Table 1.
To compute the visual features of images, OpponentSIFT feature with dense sampling [23] is extracted from the images and then clustered together into a codebook of 400 visual words. Thus, on the visual feature, each image is represented as a bag of visual words. In addition to the visual features, Gibbs LDA [2] is used to get the textual features from the alternative text associated to the images in the dataset. 50 latent topics of the texts are got by the Gibbs LDA. A BoW representation is also computed for the textual features.
In the dataset, each image to each query has been manual-ly labeled on a scale of 0-1: (0)  X  X rrelevant X  and (1)  X  X elevan-t X . The performance is measured by the widely used Average Precision (AP). The Mean Average Precision (MAP) [12] is adopted as the overall performance metric, which is also a popular metric in information retrieval.
To demonstrate the effectiveness of HAFSRerank, we com-pare it with several state-of-the-art graph-based methods in-cluding Random Walk reranking [8], Co-reranking [28], M-rank [33], Joint-rerank [25]. For all approaches, we select the best result for comparison.

In the experiments, the cosine similarity is used to mea-sure the intra-modal similarity, the textual and visual scores are initialized with R and STS strategies, respectively. The weighing factor  X  in Eq. 9 is set to the rule-of-thumb value 0.85. The parameter  X  in Eq. 7 and  X  in Eq. 15 is selected by cross-validation method. For simplicity, we set  X  in Eq.6 to the same value as  X  in Eq. 15 in the experiments. More details about the parameter sensitivity of HAFSRerank are given in section 4.3. Table 2: MAP values of different reranking methods on three groups X  X P, HP and All.
 The experimental results are summarized in Table 2. The Baseline gives the performance of the text-based search re-sults. RW-T is the method of random walking with the tex-tual features and RW-V is the method of random walking with visual features. Among these method, RW-T is only based on textual features for reranking; RW-V and MRank only use visual features for reranking; Co-reranking, Joint-rerank and HAFSRerank are based on both the visual and textual features.

From Table 2, we can find that RW-T based on textual features still slightly outperforms the baseline on the HP group and ALL group. This shows that the textual features are helpful for reranking. In addition, we can also see that RW-T is worse than Baseline on the LP group. The main reason is that the textual features contain more noise in LP than other groups. RW-V and Mrank based on the visual features both outperform the baseline and RW-T on all three groups. This demonstrates the effectiveness of the visual reranking concepts. HAFSRerank and Joint-rerank which make use of the multi-modal features all outperform the RW-T, RW-V and Mrank which use the single-modal features on all three groups. Note that Co-reranking is better than RW-V in LP and ALL groups. This proves that multi-modal methods are more effective than unimodal methods.
Among the three multi-modal methods, HAFSRerank out-performs Co-reranking and Joint-rerank on the HP and AL-L groups. It is also better than Co-reranking on LP. Since these graph-based methods have the same textual and visu-al features, the results demonstrate the effectiveness of the assumption that the visual and textual features are seman-tically consistent to some extent, which is the basic assump-tion of HAFSRerank.

We can also notice that HAFSRerank is slightly worse than  X  X oint-rerank X  on LP group. We think the main reason is that noisy images in LP group make the feedback neg-ative which have a bad influence on the results. Although we exploit the  X  X arly stopping X  strategy to minimize such influence, the bad influence of the negative feedback still ex-ists. However, the overall performance of our method is still better than Joint-rerank.
 From Table 2, we can find that the performance of HAF-SRerank varies on LP and HP groups which means that the quality of search engine result may affect its performance. To show this, we plot the AP X  X  of all queries in LP and HP in Fig. 4 and 5, respectively. From Fig. 4, we can find HAF-SRerank obtains significant improvements on most queries in LP, such as Query 227:  X  X omics page X  , Query 11:  X  X lan metro paris X  , Query 44:  X  X ogo chelsea X  , Query 339:  X  X lipart X  , etc. However, there are five queries on which HAFSRerank works worse that Baseline, e.g., Query 300:  X  X sg jersey X  ,
Figure 4: AP values on all queries in LP group. Figure 5: AP values on all queries in HP group.
 Query 311:  X  X hampions league X  , Query 84:  X  X esus rio X  ,etc. From Fig. 5, we can see HAFSRerank improves the ranking results on all queries in HP. Especially, HAFSRerank per-forms much better than Baseline on some queries, such as Query 16:  X  X ogo olympique marseille X  , Query 77:  X  X oscow basilica X  , Query 40:  X  X pain flag X  ,etc.
 To further show the visual results of different methods, Fig. 8 shows the top 7 images of reranking results returned by different methods on the queries  X  X us X  including Base-line, RW-T, RW-V, Co-reranking, Mrank, Joint-rerank and HAFSRerank. From this figure, we can also find that HAF-SRerank achieves the best reranking list.

Generally, HAFSRerank works well on this dataset. This result also confirms that the heterogenous graph which re-flect the assumption of the semantic consistency of visual and textual features and the automatic feedback are effec-tive in propagating the ranking score.
In this section, we analyze the influences of different sim-ilarity metric methods described in section 3.1, the strate-gy of initializing the ranking score described in section 3.3. Then, we investigate the sensitivity of HAFSRerank on two parameters, i.e., the score fusion parameter  X  in Eq. 7 and the scaling parameter  X  in Eq. 15. Finally, we analyze the convergence of HAFSRerank. 1) Intra-modal Similarity Metric
We discuss three different intra-modal similarity metrics in section 3.1, i.e., Inverse Euclidean Distance (IED), Cosine Similarity (CS), Histogram Intersection (HI). Table 3: MAP X  X  of HAFSRerank with different intra-modal similarity metrics.

The results are shown in Table 3 in which the rows are the metrics for visual features and the columns for textual features, respectively. From Table 3, we can see that 2) Initial Score Strategy
As presented in section 3.3, different strategies can be used to initialize ranking scores including textual and visu-al scores. To investigate their impacts on the performance of HAFSRerank, we show the results of different combina-tions in Table 4. Note that cosine similarity is used as the intra-modal similarity metric. From this table, we have the following observations. 3) Analysis of parameters  X  and  X 
To evaluate the sensitivity of HAFSRerank on parameters, e.g.,  X  and  X  , we show the MAP X  X  of HAFSRerank with different values of these parameters in Fig. 6 where  X  ranges from0to1and  X  from 0.1 to 10. From Fig. 6, we can find that Table 4: MAP X  X  of HAFSRerank with different ini-tial score strategies.
 Figure 6: MAP X  X  of HAFSRerank with different val-ues of parameters  X  and  X  . 4) Convergence Analysis
The stop condition of outer loop in HAFSRerank is set as f ( t )  X  f ( t ) pre  X  , and the stop condition of the automatic feedback is set as ap ( t )  X  apbest  X  ,where is set to 1 . 0 e  X  13. Fig. 7 shows the average number of feedbacks under different parameters on each query that HAFSRerank takes to satisfy the stop condition. We can see that on most queries it takes about 6 to 8 feedbacks to converge.
Based on assumptions that semantic meanings of different modalities of images are consistent to some extent and differ-ent modalities have some relationship, this paper proposes a novel method for image reranking X  X AFSRerank by ex-ploiting heterogeneous automatic feedback semi-supervised learning with visual and textual features simultaneously to explore the semantic consistency of visual features and tex-tual features. A heterogenous graph is constructed to con-tain both the textual and visual features. Then a graph-based semi-supervised learning is exploited to propagate the ranking scores. In the meanwhile, to make use of the inter-modal similarity, we design the automatic feedback algorith-m to update weights of the heterogeneous graph. As shown in this paper, HAFSRerank is simple; moreover, it does not require any additional input from users or a big log da-ta. The experiments conducted on the Web Queries dataset have demonstrated the effectiveness of HAFSRerank. The experimental results show that the semantic consistency and automatic feedback can make a difference to reranking and improve the results of reranking.

However, we have noticed that the existing side-effect of the negative feedback. In the future, we will try to design a more accurate algorithm to control the negative feedback and study the new methods to construct the heterogenous graph. In addition, how to measure the inter-modal simi-larity appropriately is also the other problem to be further considered. Our proposed framework can be extended to other applications such as image annotation and tweet rec-ommendation, etc.
The authors thank the anonymous reviewers for their valu-able comments and suggestions to improve the quality of this paper. [1] M. Belkin, I. Matveeva, and P. Niyogi. Regularization [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] A. Blum and T. Mitchell. Combining labeled and [4] Z.Cao,T.Qin,T.-Y.Liu,M.-F.Tsai,andH.Li.
 [5] J.Cui,F.Wen,andX.Tang.Realtimegoogleand [6] R. Fergus, L. Fei-Fei, P. Perona, and A. Zisserman. [7] W. H. Hsu, L. S. Kennedy, and S.-F. Chang. Video [8] W. H. Hsu, L. S. Kennedy, and S.-F. Chang. Video [9] V. Jain and M. Varma. Learning to re-rank: [10] Z. Ji, Y. Yu, Y. Su, and Y. Pang. Image search [11] Y. Jing and S. Baluja. Visualrank: applying pagerank [12] J. Krapac, M. Allan, J. Verbeek, and F. Jurie. [13] W.-H. Lin, R. Jin, and A. Hauptmann. Web image [14] J. Lu, J. Zhou, J. Wang, T. Mei, X.-S. Hua, and S. Li. [15] K. P. Nigam. Using unlabeled data to improve text [16] E. Riloff, J. Wiebe, and T. Wilson. Learning [17] C. G. M. Snoek, M. Worring, J.-M. Geusebroek, D. C. [18] H.-K. Tan and C.-W. Ngo. Fusing heterogeneous Joint-rerank. (g) The result of HAFSRerank [19] B. Taneva, M. Kacimi, and G. Weikum. Finding [20] X. Tian, L. Yang, J. Wang, Y. Yang, X. Wu, and [21] X. Tian, L. Yang, X. Wu, and X.-S. Hua. Visual [22] H. Tong, J. He, M. Li, C. Zhang, and W.-Y. Ma. [23] K. E. A. van de Sande, T. Gevers, and C. G. M. [24] G. Wang and D. Forsyth. Object image retrieval by [25] G. Wang and X.-S. Xu. Joint-rerank: a novel method [26] X.-S. Xu, Y. Jiang, L. Peng, X. Xue, and Z.-H. Zhou. [27] L. Yang and A. Hanjalic. Supervised reranking for web [28] T. Yao, T. Mei, and C.-W. Ngo. Co-reranking by [29] J. Zhang, P. Jing, Z. Ji, and Y. Su. Image search [30] L. Zhang, T. Mei, Y. Liu, D. Tao, and H.-Q. Zhou. [31] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and [32] D. Zhou and B. Sch  X  olkopf. A regularization framework [33] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and [34] X. Zhu. Semi-supervised learning with graphs .PhD [35] X. Zhu. Semi-supervised learning literature survey.
