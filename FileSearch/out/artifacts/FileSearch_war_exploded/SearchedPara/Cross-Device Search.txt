 Ownership and use of multiple devices such as desktop com-puters, smartphones, and tablets is increasing rapidly. Search is popular and people often perform search tasks that span device boundaries. Understanding how these devices are used and how people transition between them during infor-mation seeking is essential in developing search support for a multi-device world. In this paper, we study search across devices and propose models to predict aspects of cross-device search transitions. We characterize multi-device search across four device types, including aspects of search behavior on each device (e.g., topics of interest) and characteristics of de-vice transitions. Building on the characterization, we learn models to predict various aspects of cross-device search, in-cluding the next device used for search. This enables many applications. For example, accurately forecasting the device used for the next query lets search engines proactively re-trieve device-appropriate content (e.g., short documents for smartphones), while knowledge of the current device com-bined with device-specific topical interest models may assist in better query-sense disambiguation.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  search process; selection process Cross-device search; Multi-device user; Game console search
Cross-device search is an important emerging domain. The number of people who own and use multiple devices such as desktop computers, smartphones, and tablets has increased rapidly [6]. Search across multiple devices by an individ-ual has become a common usage pattern since people can query search providers almost anytime and from anywhere [34]. In addition, the functional boundaries between dif-ferent computing devices have become blurred. For exam-ple, gaming console users can now conduct Web searches directly from consoles and use applications previously only found on other devices. Figure 1 presents an example of a single user X  X  search activity across four types of device (desk-top or laptop computer (referred to as  X  X C X  in this paper), smartphone, tablet, and gaming console) within a single day. This example is drawn from the logs of a large commercial search engine used in our analysis, but query text is replaced with similar alternatives to preserve anonymity. According to our analysis, described later in the paper, at least 5% of searchers are multi-device users, with queries from such searchers accounting for 16% of search volume on the engine studied (i.e., such searchers are highly engaged). Better sup-port for these multi-device searchers is therefore important both for the research community and for search providers.
Despite its importance, supporting cross-device search is a challenging task. From the example presented in Figure 1 we can observe different topical patterns and different tem-poral patterns. For this searcher on this day, the PC and the gaming console are used in the morning (perhaps when they are at home), and smartphone and tablet are used in the evening (when they may be at work or commuting). The morning activity involves planning future events and staying updated on events in social and news media. In the evening, we also observe a longer-running search task between smart-phone and tablet for dining related topics; the topic and the mobile nature of the devices used suggest that the searcher may not be at home. Recent work has shown that the nature of the current location can be estimated using geolocation data [20]. Figure 1 also suggests some predictability in usage patterns. Aside from the time of day that the devices are utilized, gaming console usage precedes PC usage in both instances. We refer to these switches as cross-device tran-sitions . All that being said, this represents only one user X  X  (fictionalized) search behavior on one day. Improving the experience for all searchers as they transition between de-vices requires a better understanding of multi-device usage patterns over many searchers and queries. We present such an analysis as part of the research described in this paper.
Multi-device behavior has been studied in the human fac-tors community [7, 17], but without an emphasis on search. Search on different devices has also been studied separately with a variety of datasets [13, 14, 29]. However, the transi-tions between devices were not analyzed. Wang et al. [34] examined cross-device task continuation, but only from PC to smartphone and for a particular definition of search task. We examine a more general scenario, with up to four device types, and target a broader set of prediction tasks including switch detection and the identification of target devices.
The main contributions of our research are:
Relevant related work falls into the following three areas: (1) large-scale log analysis of search behavior; (2) studies of user behavior, especially characterizations of that behavior, on desktop and mobile, and; (3) user behavior across multi-ple devices, including their use in domains beyond search.
Behavioral logs from search engines are valuable in un-derstanding how people search in naturalistic settings. Re-search has focused on the use of automated methods to an-alyze and predict aspects of search behavior for individual queries [30] and search sessions [2, 35] using logs. Qualitative studies have sought a deeper understanding of the nature and motivations underlying online searching [18]. Other re-search has focused on tasks that extend over time, but have not considered different devices [1, 19, 22, 23].

Studies of search in mobile settings have examined the characteristics of queries issued from mobile devices, analyz-ing behavior along different dimensions such as geographic location and search interfaces [3, 36]. Others have studied mobile search intent and the effect of contextual factors on behavior. Church and Smith [5] studied mobile search, fo-cusing on their underlying intents, topics, and the impact of contexts such as location and time. Teevan et al. [33] showed that local searches are influenced by geography, time, and social context. Smaller scale studies of online behavior have considered other devices such as tablets [25], and mobile de-vice usage rationales [26, 31].

Research on comparing and contrasting search behavior on multiple devices is also relevant [13, 14, 21]. Kamvar and Baluja [13] describe a large-scale study of search patterns be-tween phones, personal digital assistants, and conventional computers and examine the search queries and their cate-gories as well as other aspects of their interaction such as query input speeds and clickthrough. Kamvar et al. [14] presented a log-based comparison of search patterns on dif-ferent devices (computers and mobile). They showed that search usage is more focused on mobile than on computer, but behavior on high-end phones resembles computer-based search. Li et al. [21] studied good abandonment of search results on desktop and mobile (where users do not click but are still satisfied) and showed that it is significantly higher in mobile settings. Song et al. [29] compared search be-havior on three different platforms X  X esktop, mobile, and tablet X  X nd developed specialized rankers for each platform separately.

Wang et al. [34] examined cross-device search tasks ini-tiated on a desktop computer and resuming soon thereafter on a mobile device. They performed a detailed analysis on topics and transition times for these tasks and showed, for example, that interdevice time varied by time of day. They developed models to accurately predict task continuation from PC to mobile. We address a more general scenario, with up to four device types, and predict key aspects of cross-device search that were not addressed in [34], including whether a person will switch devices and their next device.
There has been other research on multi-device use in do-mains beyond search. Studies have shown that user activi-ties tend to span multiple devices [2] and frustrating experi-ences on mobile devices will drive users to complete tasks on conventional computers [16]. Karlson et al. [17] analyzed the usage log of desktops and mobile phones from a user study and showed that there is little support for carrying over tasks between devices. Kane et al. [15] studied Web browsing us-age patterns across devices. Their results indicated sharing browsing information between devices could help improve the effectiveness of browsing on mobile devices. Dearman and Pierce [7] conducted an interview study of multiple de-vice use and showed that current support is inadequate.
The research described in this paper is the first to study cross-device search in a general sense. It also extends pre-vious work in a number of ways. First, we focus on multi-device usage during Web search across four device types, in-cluding search on gaming consoles. Previous studies on mo-bile, desktop, and tablet search have focused on devices inde-pendently, and not considered cross-device searching within users (i.e., the same user transitioning between devices over time, as seen in Figure 1). Second, we study key aspects of multi-device usage such as differences in topical interests and usage patterns on these devices. Third, we character-ize aspects of the transitions between devices, which is an activity where search engines could help directly. Finally, we implement classifiers to predict aspects of cross-device search, demonstrating that this can be accurately forecast using a range of features. Foreknowledge of the next device (especially coupled with task-continuation prediction [1, 34]) can help the search engine select device-appropriate content, feeding into methods to help people search over time [8, 24]
We analyzed sampled search logs from a large commer-cial search engine, over a period of several months. Our goal was to understand search behavior across devices along different dimensions, including time and topic. We con-sider queries on four types of device: PC (desktop or lap-top computers, which were indistinguishable in our logs), smartphones, tablets, and gaming consoles. Our dataset comprises 2,271,142,893 records from the United States En-glish language locale (en-US) market, representing queries from 33,221,253 users. We map searchers across devices us-ing unique identifiers obtained from those who queried when signed into the engine (for most searchers, sign-in happened automatically), allowing us to identify the same searcher as they moved across devices. We retained only records with non-empty queries, filtering abnormal records (such as those from bot traffic) and further eliminated records with-out query classification information (labeling the type and optionally the query type/topic (e.g., navigational) with pro-prietary classifiers, discussed more later).

Our filtering methods reduced the number of smartphone records, since a significant proportion were missing meta in-formation (e.g., user identifiers). We are still able to reliably track users who were signed in on all devices (the default for most users), allowing us to analyze transitions between de-vices over time. While the sample of smartphone users is sufficient to justify analysis, the relative proportions of each device type are likely not representative of general multi-device behavior, independent of search engine. The numbers reported here primarily document the sample sizes used for our analyses, and the multi-device usage seen here repre-sents a lower bound on actual multi-device usage. Table 1 presents the final query counts from this filtered dataset is-sued on each of the four devices considered in our study.
Of the 33 million unique users in our primary dataset, 1.68 million (5.04%) were observed using more than one device. These users are extremely active searchers; their queries comprise over 16% of the total search volume in our dataset (see Table 1). Understanding and supporting these users X  search activity is therefore of critical importance to search providers. Delving into the specifics of observed de-vice usage, Table 2 presents the number of users associated with each type of device, as well as the number of users associated with each combination of device type.

As we can see, the most common device is PC, accounting for roughly 95% of search volume, and most users (95.0%) are associated with a single device. A significant fraction of people use two devices and a small percentage (less than 0.01%) are s searching on all four devices. The most common device pairings are PC-smartphone and PC-tablet, reflecting the still-central role of personal computers in search.
We begin by focusing on how searchers X  content interests differ among the four device types. Understanding the topics of interest on each device can help establish interest priors to pre-fetch appropriate content or personalization during  X  X old start X  scenarios [28]. To do this, we analyzed the dis-tribution of query topics in the dataset. We classified each query using proprietary classifiers (used by the search engine in determining if support such as instant answers should ap-pear on the result page and characterizing query type for the search engine), corresponding to around 50 query categories. A query could belong to multiple categories. The categories were then grouped by the authors into fifteen higher-level topics, including Movies and TV , Music , and Celebrities .
Figure 2 displays the differences in topical interest be-tween devices, by using the pointwise mutual information (PMI) between P (topic | device) and P (topic), calculated as topic popularity on a particular device, with negative values indicating a decrease in popularity. Since the PC contained most query volume, it was most similar to the background model. The most prominent change is the sharp increase in gaming related queries on gaming consoles. Also apparent in Figure 1 is the increase in food-related queries on mobile devices associated with dining (as in Figure 1).
Rather than assuming a static view of topical interests aggregated over time, we were also interested in how they
Figure 2: Topic probability lift (PMI) by device. varied temporally. The queries were partitioned by device and hour of day, taking counts of the number of queries in each partition. The counts were then normalized by the total number of queries across partitions, resulting in a per-device topic distribution over time. We could then investi-gate how the topic distribution changed over the day. We calculated the PMI divergence of P (topic | device, hour) from P (topic | device). Figure 3 shows how topics with large abso-lute PMI divergence shift throughout the day. For each de-vice we plot only the top three topics, in descending order by largest absolute PMI lift throughout the day. Distributions for gaming console is least smooth given data sparseness.
Across the four sub-figures, we observe some noteworthy trends. First, interest in food and adult content appear to be inversely related for three of the four devices: search-ing for adult material is common at night and less common during the work day, food searching exhibits the opposite trend. We notice two peaks of interest for food related queries, one around lunch hour and another around din-ner time. Querying for gaming related activities (including social media games from facebook.com and zynga.com) is popular on PC and tablet late at night, with interest in gaming on tablets exceeding expectations for most of the day. Halvey et al. [11] studied temporal dynamics in topical interests on early smartphones. However, they used a differ-ent content classification and studied Web surfing not Web search, making direct comparisons with this work difficult.
It is clear that there are significant variations in interests across devices and time, and that both (and their interac-tion) need to be considered by search engines when support-ing search on different devices. The analysis can also help generate features for the device identification aspects of the later prediction tasks. However, we focus on cross-device behavior, especially device transitions. This is a critical and defining activity in cross-device search and one that needs better support, for a range of information tasks [7, 17].
We now describe the characteristics of device transitions.
We define a transition as a pair of consecutive queries issued on the same or different device. Cross-device transi-tions include a device change between consecutive queries. To improve the likelihood that the transitions are meaning-Figure 3: Topic probability lift (pointwise mutual information) by device type and hour of day. ful, we limit consideration to transitions with delay times of three hours or less between consecutive queries. Previ-ous work [34] used a six hour threshold, but had a simpler switching scenario (single device pair, single direction). To begin, we computed the maximum likelihood estimates for device transitions as a Markov graph, conditioned on the previous device, which are the empirically observed tran-sition probabilities. Figure 4 shows the probability of the transitions, as percentages, given the previous device.
We can see from the figure that the majority of transi-tions are self-transitions, meaning that the user is likely to continue using the same device. This seems reasonable as searchers are known to search in bursts (as search sessions [35]) and may be unlikely to change device mid-session (al-though as we show later, cross-device transition delays are also often short). The transition analysis becomes more in-teresting if we remove self-transitions and only consider tran-sitions between different devices. That is, only cases where the first query in the transition is on one device and the sec-ond query is on a different device. This allows us to generate the modified Markov graph shown in Figure 5.

Figure 5 shows that although most transition mass leads to PC devices (and very little leads to gaming console de-vices), there is also evidence of significant interplay between particular pairs of devices. Specifically, we can observe that PC-smartphone and PC-tablet exhibit a close relationship, with transitions between those devices (in both directions) Figure 5: Cross-device transition probabilities (%). being particularly common. Our earlier statistics (in Table 2) suggested that these pairs were most likely to be used by the same searchers, but here we show more direct evi-dence of interaction between them. More work is needed on understanding the nature of the search tasks that people pursue before and after these transitions, perhaps via quali-tative user studies, e.g., rapid switches from smartphone to PC may be indicative of a dissatisfying mobile search expe-rience, as has been suggested in a non-search setting [16].
We make some progress in understanding task continua-tion by examining the relationship between the immediately preceding query topic and the device used for the next query. Figure 6 shows that while to-PC transitions continue to dominate, certain topics indicate a shift in next-device prob-ability. The proportions in the figure should be compared to the overall likelihood of transitions into the devices, in-dependent of preceding topic (i.e., PC: 63.9%, Smartphone: 11.2%, Tablet: 24.6%, Console: 0.3%, all shown at the top of Figure 6). It is clear from the figure that the PC dominates given the strong prior. However, there are cases where other devices become more evident depending on the preceding topic. For example, for Events and Nightlife -related previ-ous queries, the likelihood of using a gaming console next increases by an extraordinary 870% over the background. Similarly, searches for Celebrities -related content signifies an increased likelihood of using a tablet device for the next query (a 34% increase over the background), perhaps signi-fying that searchers are actively engaged in leisure pursuits.
We also analyzed the temporal relationship between the previous hour and next device that was used. We focus on the previous hour and not the current hour for two rea-sons. First, focusing on current hour simply gives propor-tions reflective of the background device proportions in most cases, and does not produce informative results. More im-portantly, any system aiming to predict device transitions (see Section 4) may benefit from exploitable patterns link-ing past query times to future device choices. Inspecting our results, we find that PC usage is most likely during the workday, when the previous query was issued between 7AM to 5PM. Transitions to tablets and smartphones are most likely when searching in the early morning and late evening (perhaps signifying commuting activities), and transition to Figure 6: Prev. topic to current device proportions. a gaming console reaches its peak probability between 12AM and 4AM; late-night gaming practices are well known [9].
The variations in future device usage given previous topic and query appear promising for the prediction task described later. Before considering that task, we also examine the time between queries, referred to as the transition delay , since a regressor to predict transition delay may also have util-ity, e.g., in determining the amount of time that the engine has to proactively work on the searcher X  X  behalf or employ crowdworkers to help with an ongoing search task [32].
To study transition delays, we examine all transitions (in-cluding self-transitions, which are the majority and take al-most no time) and cross-device transitions. As we will show in Section 4.2, the transition delay time (DT) has strong predictive value for whether a device switch occurred. Fig-ure 7 depicts the proportion of delay times for all transitions and all cross-device transitions (times in seconds from 0 to 10,800 (3 hrs)) on a log-log plot. A spike occurs for all transi-tions at a delay time of approximately five minutes, perhaps associated with session termination [12]. In general, cross-device transitions take longer on average, although the dis-tributions are heavily skewed, with many short delay times (especially for the  X  X ll transitions X  set) and long tails. We now focus on predicting transitions between devices. Using features such as those outlined in the previous section, including the searcher X  X  previous device, query times, and transition history, we perform three prediction tasks: 1. Predict the next device that a person will search from. 2. Predict whether a device switch has occurred between Figure 7: Delay time for all and cross-device transi-tions. Log-log plot is used to highlight differences. 3. Predict the next device given a switch. This could
We predict device transitions using three datasets derived from our primary search log dataset described earlier. From these queries, we created a set of device-device transition data, which was then used to create three datasets of fea-tures for training and testing. The first dataset ( X  X ain X ) contained both same-and cross-device transitions. The sec-ond dataset ( X  X alanced X ) consisted of an equal 50-50 mix of same-device and cross-device transitions, used in predicting whether or not a change in device would occur during a tran-sition. The final dataset ( X  X ross-Device Only X ), comprised only instances where the next device did not equal the pre-vious device and the user had at minimum 200 transitions observed in the historical dataset (from which user specific transition statistics were computed). For all three datasets, 250,000 instances were selected at random for five-fold cross-validation. It should be noted that sampling was done with respect to filtered transitions rather than with respect to users or queries, so the final datasets do not necessarily re-flect user and device type proportions reported earlier. A set of 177 features were used for training and testing. These include features for the previous device used, proba-bilities of device-type usage, and device-pair transition prob-abilities for the current user and globally. Other features such as the previous query topic and the previous hour are directly informed by the analysis presented in the previous section. For historical features, a separate dataset from pre-vious months was used to compute the feature statistics, allowing for no overlap between historical data and train-ing/test data.
 Table 3 lists the features used, with counts for each type. A count of  X  X 4 X  denotes four features of that type. Some of the features, such as the Previous Query Local Hour Flag , are represented using one-hot binary vectors, hence creat-ing twenty-four binary flags for that single feature (one per hour). The features are as follows. The Previous Device Flag is a one-hot binary representation of which device was used for the previous query. The Query Length feature denotes the length of the previous query (in characters). The Previ-ous Query Local Hour Flag records the hour when the pre-vious query was issued. The Previous (and Current) Query Topic Flags are sets of fifteen binary flags showing which topics are assigned to the query, as measured by the top-ical classifiers discussed in Section 3.2. The Global Device Probabilities record how often queries were issued from each device type across all users. Similarly, the Global Device-Device Transition Probabilities give the likelihood of tran-sitions between each device-type pair (such as PC-to-PC and Tablet-to-Smartphone transitions). The Global Cross-Device Transition Probabilities are similar, but limited to the probabilities for cross-device transitions (thus the nor-malization of the probabilities differs). The Global Device Avg. Transition Delay measures the average delay between queries conditioned on the previous device type. The Global Device-Device Avg. Transition Delay measures the average delay time between device-type pairs.

We also have several user specific features and variants of the above. The Number of Historical User Samples fea-ture denotes how many transitions were previously seen for a given user, and the Number of Historical User Cross-Device Samples feature is similar, but restricted to cross-device transitions. The User Device Probabilities , User Device-Device Transition Probabilities , User Cross-Device Transi-tion Probabilities , User Device Avg. Transition Delay and User Device-Device Avg. Transition Delay features are all similar to their global counterparts, but are instead com-puted on a per user basis. The User Cross-Device Desti-nation Device Probabilities features measure the probability that a certain device will be the destination of a transi-tion, regardless of the origin device, given that it differs from the destination device. Lastly, The User IsDeviceDominant Flags record which of the four device types is the histori-cally dominate destination device, and the User IsCrossDe-viceDominant Flags are analogous, but restricted to cross-device transitions. There is some feature overlap, with some features derivable from others. We use L1 regularization to prune unnecessary and redundant features.

All Stats features in Table 3 are computed from the non-overlapping historical data. We further group the features into sets to measure their effect on predictive accuracy. The baseline feature set consists of the previous device type only. The query length feature gives the number of characters in the previous query, and previous hour gives the hour of day when the previous query was issued. Topical features are grouped by previous and current query and the user tran-sition features are partitioned into six groups, outlined in Table 4. The full list of groupings are given in the ablation results of Table 7 and are discussed in Section 4.2.
Using these datasets, we performed multi-class classifi-cation to forecast different aspects of cross-device search given the previous device and other contextual features re-lated to the previous query and user history. We evaluated an L1-regularized Logistic Regression model [4] and a Gra-dient Boosting Tree ensemble [10] through five-fold cross-validation, using the Scikit-learn package for Python [27]. Since the primary objective of this study is to demonstrate the feasibility of developing accurate predictive models of cross-device searching (and not to develop new machine learn-ing algorithms), we limited our evaluation to two represen-tative classes of learning methods. We compared their per-formance against three baselines: (1) Most Frequent Label, which predicts the most common class label in the training dataset, (2) Uniform Guessing, which predicts class labels uniformly at random, and (3) Stratified Guessing, which predicts class labels randomly, while respecting the observed global class label proportions encountered during training.
For the task of predicting the next device, both models show significant improvements over the baseline methods, with over 98% accuracy, and high average precision, recall and F1-score. The metrics shown represent weighted (by class proportion) averages of per class scores, uniformly av-eraged across folds 1 . Table 5 presents the results. Examin-ing the feature contributions (not shown for this dataset), we found that conditioning on the previous device produces the accuracy observed (98.3%), so that the previous device state is the strongest feature for next device prediction, and extra features do not improve performance.
Our next task was to predict whether or not a user switched devices between queries. This is a non-trivially important task in some scenarios, such as when a new query is issued without corresponding device-type information (as was the case for many records excluded from our dataset). To per-form the prediction, we trained our classification models on the balanced transition dataset, where transition instances were equally split among the  X  X ame-device X  and  X  X ifferent-device X  class labels. In addition to the features given in Tables 3 and 4, we considered an additional feature for this task, the transition delay time, which is the elapsed time between two consecutive queries. We evaluated the effect of adding this feature to the existing historical features.
The classification results for predicting whether a device switch will occur are given in Table 6. Predictive accuracy is significantly increased over the baseline methods, indicat-ing the existence of exploitable non-randomness in device transition behavior. Table 7 demonstrates the effect of dif-ferent feature sets on classification accuracy, including the use of current query features. The greatest gains are seen when adding user-specific historical transition features (U1-U6) and the transition delay time feature (see Figure 7).
Given a classifier capable of predicting whether or not a cross-device transition occurred, the next step is to de-velop a classifier that predicts the next device for cases when it differs from the previous device. In practice the classi-fiers could be chained, but we do not do that here since we wanted to limit interaction effects. The task of predicting the next device given it differs from the previous device is more difficult than predicting the next device in general, since a learner cannot simply predict the class label of the previous device (as is normally the case). Table 8 demon-strates the increased difficulty of this task, with all meth-ods (except uniform random guessing) suffering decreased performance compared to the next-device prediction task from Table 5. However, the feature-based methods continue to significantly outperform the baselines. Surprisingly, the previous device still produced the strongest signal when pre-dicting the future device, apparent in the ablation results of Table 9. This held even though the next device and previ-ous device were guaranteed to differ. Other features, such as previous topics (PT) and global transition stats (G), had no effect on performance, despite proving useful when pre-dicting the occurrence of a device switch. User transition statistics led to significant increases in performance in com-bination with the other features, but also on their own (as Baseline+U1-6). Thus, strong, exploitable patterns emerge for searchers when switching to new devices. learner implementation and class label imbalance, tends to produce precision -recall scores near or equal to accuracy.
Overall, we observe significant improvements over base-lines, with gains in predictive accuracy of over 25% for all three classification tasks evaluated. The previous device and searchers X  own transition histories were the primary factors in the prediction. These results are important as they clearly demonstrate successful prediction of various aspects of cross-device search (the first time this has been accomplished), but also that high accuracy can be achieved with compact models comprising only a few key features. Compactness is important for large-scale deployment in search engines.
We showed that there are variations in interests across the four different device types and that multi-device searchers were fairly common (5% of users) and generated a signif-icant amount of search engine traffic (16%). Of particular interest were the transitions between devices (many of which are more or less immediate, as shown in Figure 7), which provides insight into the context within which devices are used. For example, smartphone/tablet and PC appear to frequently be used consecutively, and more work is needed to understand device interplay (e.g., are there tasks or sce-narios for which a device switch should be recommended?) and how best to support it from a search perspective.
If the search system is expected to work proactively, the ability to predict the device that a searcher will use for their next query is important in determining what type of in-formation to seek on the searcher X  X  behalf. Different de-vices have different display, bandwidth, and interaction con-straints, as well as differences in the type of information that people are interested in on each device (as demonstrated in Section 3.2). This information could be coupled with data about cross-session search tasks and searchers X  long-term in-terests [1, 19] to model their interests and intentions. An additional component that would be welcome in this model is the anticipated time until next query (i.e., the transition delay), which could help guide system assistance decisions.
With that goal in mind, we attempted to predict the time until the next query. Our efforts at this regression task were met with limited success, even when using predictions from the classification models and device-device transition time statistics as features. Neither of the regression models tested (Lasso Regression and Gradient Boosting Trees Re-gression) significantly improved performance over the base-lines of guessing the mean and median delay times. Trans-forming the task into a three-way classification task (classes = { delay less than 30 seconds, delay between 30 secs. and 10 mins., delay greater than 10 mins. } ) was more promising, with significant improvements of approximately 10 percent-age points over the best baseline method, but accuracy was still below 50% (results not shown given space constraints). There are some limitations that we should acknowledge. First, since the study is log-based, we do not have insight about searchers X  rationales for moving between devices or the context of the transitions, which is important for, say, understanding why some device pairings are more tightly coupled than others. Follow-up qualitative studies in the search context are needed to understand: (1) how people transition between devices (both physically and practically), and (2) criteria that they use to select a particular device if multiple devices are accessible in a particular location (e.g., searcher is at home with access to all of their devices). Sec-ond, our prediction tasks focused on query-query transitions, however there are other scenarios that should be explored, e.g., predicting the device used for the next search session . Finally, the dataset used for our analysis is proprietary and cannot be shared publically given privacy considerations. Researchers seeking to perform similar studies should con-sider the need to represent users, their devices, and their inter-device transitions when designing logging mechanisms.
We considered three important prediction tasks where we see significant improvements over the three baselines: (1) predict next device, (2) predict if a device switch occurred, and (3) predict next device given that a device switch oc-curred. The predict-next-device classifier (#1) was highly accurate, although primarily because people frequently stay on the same device. The device prediction task (#3) relies on foreknowledge of a device switch, which could be provided by a device switch classifier (#2). We assessed #2 and #3 separately, and we need to study chaining them together.
We introduced cross-device search and drew several data-supported conclusions about search across devices. We show that people use different devices to search for different con-tent, and time of day interacts with device to affect content sought. Exploitable patterns emerge for device transitions (especially from historic user features), with previous device signaling the next device, even when the devices differ .
We analyzed device-specific and temporal aspects of cross-device search, and were able to successfully predict the next device from which a searcher will query, even on datasets limited to cross-device transitions. For two of the prediction tasks (i.e., predict next device and predict next device given switch), predictive accuracy, recall and precision exceeded 90% with a fairly compact feature set. The remaining task (predict device switch) also saw significant gains in accu-racy over the baselines, approaching 80% given all features. We will continue work in this important emerging area, fo-cused on developing more accurate predictive models, in-cluding further investigating delay time prediction. We will also integrate these models into search systems, enabling capabilities such as proactively locating device-appropriate information in advance of anticipated device transitions.
