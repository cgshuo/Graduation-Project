 Aggre gation is an essential component of man y nat-ural language generation systems (Reiter and Dale, 2000). The task captures a mechanism for mer g-ing together two or more linguistic structures into a single sentence. Aggre gated texts tend to be more concise, coherent, and more readable overall (Dalia-nis, 1999; Cheng and Mellish, 2000). Compare, for example, sentence (2) in Table 1 and its non-aggre gated counterpart in sentences (1a) X (1d) . The dif ference between the fluent aggre gated sentence and its abrupt and redundant alternati ve is striking.
The benefits of aggre gation go beyond making texts less stilted and repetiti ve. Researchers in psy-cholinguistics have sho wn that by eliminating re-(1) a. Holocomb had an incompletion in the (2) After tw o incompletions in the first quar -Table 1: Aggre gation example (in boldf ace) from a corpus of football summaries dundanc y, aggre gation facilitates text comprehen-sion and recall (see Yeung (1999) and the references therein). Furthermore, Di Eugenio et al. (2005) demonstrate that aggre gation can impro ve learning in the conte xt of an intelligent tutoring application.
In existing generation systems, aggre gation typi-cally comprises two processes: semantic grouping and sentence structuring (W ilkinson, 1995). The first process involv es partitioning semantic content (usually the output of a content selection compo-nent) into disjoint sets, each corresponding to a sin-gle sentence. The second process is concerned with syntactic or lexical decisions that affect the realiza-tion of an aggre gated sentence.

To date, this task has involv ed human analysis of a domain-rele vant corpus and manual development of aggre gation rules (Dalianis, 1999; Sha w, 1998). The corpus analysis and kno wledge engineering work in such an approach is substantial, prohibiti vely so in lar ge domains. But since corpus data is already used in building aggre gation components, an appealing alternati ve is to try and learn the rules of semantic grouping directly from the data. Clearly , this would greatly reduce the human effort involv ed and ease porting generation systems to new domains.

In this paper , we present an automatic method for performing the semantic grouping task. We address the follo wing problem: given an aligned parallel cor -pus of sentences and their underlying semantic rep-resentations, how can we learn grouping constraints automatically? In our case the semantic content cor -responds to entries from a database; howe ver, our algorithm could be also applied to other representa-tions such as propositions or sentence plans.
We formalize semantic grouping as a set parti-tioning problem, where each partition corresponds to a sentence. The strength of our approach lies in its ability to capture global partitioning constraints by performing collecti ve inference over local pair -wise assignments. This design allo ws us to inte-grate important constraints developed in symbolic approaches into an automatic aggre gation frame-work. At a local level, pairwise constraints cap-ture the semantic compatibility between pairs of database entries. For example, if two entries share multiple attrib utes, then the y are lik ely to be aggre-gated. Local constraints are learned using a binary classifier that considers all pairwise combinations attested in our corpus. At a global level, we search for a semantic grouping that maximally agrees with the pairwise preferences while simultaneously sat-isfying constraints on the partitioning as a whole. Global constraints, for instance, could pre vent the creation of overly long sentences, and, in general, control the compression rate achie ved during aggre-gation. We encode the global inference task as an inte ger linear program (ILP) that can be solv ed us-ing standard optimization tools.

We evaluate our approach in a sports domain rep-resented by lar ge real-w orld databases containing a wealth of interrelated facts. Our aggre gation al-gorithm model achie ves an 11% F-score increase on grouping entry pairs over a greedy clustering-based model which does not utilize global informa-tion for the partitioning task. Furthermore, these re-sults demonstrate that aggre gation is amenable to an automatic treatment that does not require human in-volv ement.

In the follo wing section, we pro vide an overvie w of existing work on aggre gation. Then, we define the learning task and introduce our approach to content grouping. Ne xt, we present our experimental frame-work and data. We conclude the paper by presenting and discussing our results. Due to its importance in producing coherent and flu-ent text, aggre gation has been extensi vely studied in the text generation community . 1 Typically , semantic grouping and sentence structuring are interlea ved in one step, thus enabling the aggre gation component to operate over a rich feature space. The common assumption is that other parts of the generation sys-tem are already in place during aggre gation, and thus the aggre gation component has access to discourse, syntactic, and lexical constraints.

The interplay of dif ferent constraints is usually captured by a set of hand-crafted rules that guide the aggre gation process (Scott and de Souza, 1990; Ho vy, 1990; Dalianis, 1999; Sha w, 1998). Al-ternati vely , these rules can be learned from a cor -pus. For instance, Walk er et al. (2001) propose an overgenerate-and-r ank approach to aggre gation within the conte xt of a spok en dialog application. Their system relies on a preference function for se-lecting an appropriate aggre gation among multiple alternati ves and assumes access to a lar ge feature space expressing syntactic and pragmatic features of the input representations. The preference function is learned from a corpus of candidate aggre gations mark ed with human ratings. Another approach is put forw ard by Cheng and Mellish (2000) who use a ge-netic algorithm in combination with a hand-crafted preference function to opportunistically find a text that satisfies aggre gation and planning constraints.
Our approach dif fers from pre vious work in two important respects. First, our ultimate goal is a gen-eration system which can be entirely induced from a parallel corpus of sentences and their correspond-ing database entries. This means that our generator will operate over more impo verished representations than are traditionally assumed. For example we do 1 ( Passing (Cundif f 22/37 237 6.4 1 1)) 2 ( Inter ception (Lindell 1 52 1)) 3 ( Passing (Bledsoe 17/34 104 3.1 0 0)) 4 ( Passing (Carter 15/32 116 3.6 1 0)) 5 ( Rushing (Hambrick 13 33 2.5 10 1)) 6 ( Fumbles (Bledsoe 2 2 0 0 0)) This fragment will give rise to 6 sentences in the final text. not presume to kno w all possible ways in which our database entries can be lexicalized, nor do we pre-sume to kno w which semantic or discourse relations exist between dif ferent entries. In this frame work, aggre gation is the task of grouping semantic content without making any decisions about sentence struc-ture or its surf ace realization. Second, we stri ve for an approach to the aggre gation problem which is as domain-and representation-ind epe ndent as possible. We formulate aggre gation as a supervised partition-ing task , where the goal is to find a clustering of input items that maximizes a global utility func-tion. The input to the model consists of a set E of database entries selected by a content planner . The output of the model is a partition S = { S nonempty subsets such that each element of E ap-pears in exactly one subset. 2 In the conte xt of aggre-gation, each partition represents entries that should be verbalized in the same sentence. An example of a partitioning is illustrated in the right side of Table 2 where eight entries are partitioned into six clusters.
We assume access to a relational database where each entry has a type and a set of attrib utes as-sociated with it. Table 2 (left) sho ws an ex-cerpt of the database we used for our experiments. The aggre gated text in Table 2 (right) contains en-tries of five types: Passing , Interception , Kicking , Rushing , and Fumbles . Entries of type Passing have six attrib utes  X  PLAYER , CP/AT , YDS , AVG , TD , INT , entries of type Interception have four attrib utes, and so on. We assume the existence of a non-empty set of at-trib utes that we can use for meaningful comparison between entities of dif ferent types. In the example abo ve, types Passing and Rushing share the at-trib utes PLAYER , AVG (short for average), TD (short for touchdo wn) and YDS (short for yards). These are indicated in boldf ace in Table 2. In Section 4.1, we discuss how a set of shared attrib utes can be deter -mined for a given database.

Our training data consists of entry sets with a kno wn partitioning. During testing, our task is to infer a partitioning for an unseen set of entries. Our model is inspired by research on text aggre-gation in the natural language generation commu-nity (Cheng and Mellish, 2000; Sha w, 1998). A common theme across dif ferent approaches is the notion of similarity  X  content elements described in the same sentence should be related to each other in some meaningful way to achie ve conciseness and coherence. Consider for instance the first cluster in Table 2. Here, we have two entries of the same type (i.e., Passing ). Furthermore, the entries share the same values for the attrib utes YDS and TD (i.e., 237 and 1). On the other hand, clusters 5 and 6 have no attrib utes in common. This observ ation moti-vates modeling aggre gation as a binary classification task: given a pair of entries, predict their aggre ga-tion status based on the similarity of their attrib utes. Assuming a perfect classifier , pairwise assignments will be consistent with each other and will therefore yield a valid partitioning.

In reality , howe ver, this approach may produce globally inconsistent decisions since it treats each pair of entries in isolation. Moreo ver, a pairwise classification model cannot express general con-straints regarding the partitioning as a whole. For example, we may want to constrain the size of the generated partitions and the compression rate of the document, or the comple xity of the generated sen-tences.

To address these requirements, our approach re-lies on global inference. Given the pairwise predic-tions of a local classifier , our model finds a glob-ally optimal assignment that satisfies partitioning-level constraints. The computational challenge lies in the comple xity of such a model: we need to find an optimal partition in an exponentially lar ge search space. Our approach is based on an Inte ger Linear Programming (ILP) formulation which can be effec-tively solv ed using standard optimization tools. ILP models have been successfully applied in several natural language processing tasks, including relation extraction (Roth and Yih, 2004), semantic role label-ing (Pun yakanok et al., 2004) and the generation of route directions (Marciniak and Strube, 2005).
In the follo wing section, we introduce our local pairwise model and afterw ard we present our global model for partitioning. 4.1 Lear ning Pairwise Similarity Our goal is to determine whether two database en-tries should be aggre gated given the similarity of their shared attrib utes. We generate the training data by considering all pairs  X  e is the set of all entries attested in a given document. An entry pair forms a positi ve instance if its mem-bers belong to the same partition in the training data. For example, we will generate 8  X  7 pairs for the eight entries from the document in Ta-ble 2. From these, only two pairs constitute positi ve instances, i.e., clusters 1 and 2. All other pairs form negati ve instances.

The computation of pairwise similarity is based on the attrib ute set A = { A two entries in the pair . As discussed in Section 3, the same attrib utes can characterize multiple entry types, and thus form a valid basis for entry compari-son. The shared attrib ute set A could be identified in man y ways. For example, using domain kno wledge or by selecting attrib utes that appear across multiple types. In our experiments, we follo w the second ap-proach: we order attrib utes by the number of entry types in which the y appear , and select the top five 3 .
A pair of entries is represented by a binary fea-ture vector { x whether two entries have the same value for at-trib ute i . The feature vector is further expanded by conjucti ve features that explicitly represent overlap in values of multiple attrib utes up to size k . The parameter k controls the cardinality of the maximal conjuncti ve set and is optimized on the development set.

To illustrate our feature generation process, con-sider the pair ( Passing (Quinc y Carter 15/32 116 3.6 1 0)) and ( Rushing (Troy Hambrick 13 33 2.5 10 1)) from Table 2. Assuming A = { Player , Yds , TD } and k = 2 , the similarity between the two en-tries will be expressed by six features, three rep-resenting overlap in indi vidual attrib utes and three representing overlap when considering pairs of at-trib utes. The resulting feature vector has the form  X  0 , 0 , 1 , 0 , 0 , 0  X  .

Once we define a mapping from database entries to features, we emplo y a machine learning algorithm to induce a classifier on the feature vectors generated from the training documents. In our experiments, we used a publicly available maximum entrop y classi-fier 4 for this task. 4.2 Partitioning with ILP Given the pairwise predictions of the local classifier , we wish to find a valid global partitioning for the entries in a single document. We thus model the in-teraction between all pairwise aggre gation decisions as an optimization problem.

Let c  X  e classifier). Our goal is to find an assignment that maximizes the sum of pairwise scores and forms a valid partitioning. We represent an assignment us-ing a set of indicator variables x to 1 if  X  e i , e j  X  is aggre gated, and 0 otherwise. The score of a global assignment is the sum of its pair -wise scores:
Our inference task is solv ed by maximizing the overall score of pairs in a given document: argmax X subject to:
We augment this basic formulation with two types of constraints. The first type of constraint ensures that pairwise assignments lead to a consistent parti-tioning, while the second type expresses global con-straints on partitioning.
 Transiti vity Constraints We place constraints that enforce transiti vity in the label assignment: if x A pairwise assignment that satisfies this constraint defines an equi valence relation, and thus yields a unique partitioning of input entries (Cormen et al., 1992).

We implement transiti vity constraints by intro-ducing for every triple e inequality of the follo wing form:
If both x x be either 1 or 0.
 Global Constraints We also want to consider global document properties that influence aggre ga-tion. For example, documents with man y database entries are lik ely to exhibit dif ferent compression rates during aggre gation when compared to docu-ments that contain only a few.

Our first global constraint controls the number of aggre gated sentences in the document. This is achie ved by limiting the number of entry pairs with positi ve labels for each document:
Notice that the number m is not kno wn in ad-vance. Ho we ver, we can estimate this parameter from our development data by considering docu-ments of similar size (as measured by the number of corresponding entry pairs.) For example, texts with thousand entry pairs contain on average 70 pos-itive labels, while documents with 200 pairs have around 20 positi ve labels. Therefore, we set m sep-arately for every document by taking the average number of positi ve labels observ ed in the develop-ment data for the document size in question.
The second set of constraints controls the length of the generated sentences. We expect that there is an upper limit on the number of pairs that can be clustered together . This restriction can be expressed in the follo wing form:
This constraint ensures that there can be at most k positi vely labeled pairs for any entry e corpus, for instance, at most nine entries can be aggre gated in a sentence. Again k is estimated from the development data by taking into account the average number of positi vely labeled pairs for every entry type (see Table 2). We therefore indirectly capture the fact that some entry types (e.g., Passing ) are more lik ely to be aggre gated than others (e.g., Kicking ).
 Solving the ILP In general, solving an inte ger lin-ear program is NP-hard (Cormen et al., 1992). For-tunately , there exist several strate gies for solving ILPs. In our study , we emplo yed lp solve , an ef-ficient Mix ed Inte ger Programming solv er 5 which implements the Branch-and-Bound algorithm. We generate and solv e an ILP for every document we wish to aggre gate. Documents of average size (ap-proximately 350 entry pairs) tak e under 30 minutes on a 450 MHz Pentium III machine. The model presented in the pre vious section was evaluated in the conte xt of generating summary re-ports for American football games. In this section we describe the corpus used in our experiments, our procedure for estimating the parameters of our mod-els, and the baseline method used for comparison with our approach.
 Data For training and testing our algorithm, we emplo yed a corpus of football game summaries col-lected by Barzilay and Lapata (2005). The corpus contains 468 game summaries from the official site of the American National Football League 6 (NFL). Each summary has an associated database contain-ing statistics about indi vidual players and events. In total, the corpus contains 73,400 database entries, 7.1% of which are verbalized; each entry is charac-terized by a type and a set of attrib utes (see Table 2). Database entries are automatically aligned with their corresponding sentences in the game summaries by a procedure that considers anchor overlap between entity attrib utes and sentence tok ens. Although the alignment procedure is relati vely accurate, there is una voidably some noise in the data.

The distrib ution of database entries per sentence is sho wn in Figure 1. As can be seen, most aggre-gated sentences correspond to two or three database entries. Each game summary contained 14.3 entries and 9.1 sentences on average. The training and test data were generated as described in Section 4.1. We used 96,434 instances (300 summaries) for training, 59,082 instances (68 summaries) for testing, and 53,776 instances (100 summaries) for development purposes.
 Parameter Estimation As explained in Section 4, we infer a partitioning over a set of database en-tries in a two-stage process. We first determine how lik ely all entry pairs are to be aggre gated using a lo-cal classifier , and then infer a valid global partition-ing for all entries. The set of shared attrib utes A consists of five features that capture overlap in play-ers, time (measured by game quarters), action type, outcome type, and number of yards. The maximum cardinality of the set of conjuncti ve features is five. Figure 1: Distrib ution of aggre gated sentences in the NFL corpus Ov erall, our local classifier used 28 features, includ-ing 23 conjuncti ve ones. The maximum entrop y classifier was trained for 100 iterations. The global constraints for our ILP models are parametrized (see equations (5) and (6)) by m and k which are esti-mated separately for every test document. The val-ues of m ranged from 2 to 130 and for k from 2 to 9. Baseline Clustering is a natural baseline model for our partitioning problem. In our experiments, we a emplo y a single-link agglomerati ve clustering al-gorithm that uses the scores returned by the maxi-mum entrop y classifier as a pairwise distance mea-sure. Initially , the algorithm creates a separate clus-ter for each sentence. During each iteration, the two closest clusters are mer ged. Again, we do not kno w in adv ance the appropriate number of clusters for a given document. This number is estimated from the training data by averaging the number of sentences in documents of the same size.
 Ev aluation Measur es We evaluate the perfor -mance of the ILP and clustering models by mea-suring F-score over pairwise label assignments. We compute F-score indi vidually for each document and report the average. In addition, we compute partition accurac y in order to determine how man y sentence-level aggre gations our model predicts correctly . Table 3: Results on pairwise label assignment (pre-cision, recall, and F-score are averaged over doc-uments); comparison between clustering and ILP models Our results are summarized in Table 3. As can be seen, the ILP model outperforms the clustering model by a wide mar gin (11.9% F-score). The two methods yield comparable recall; howe ver, the clus-tering model lags considerably behind as far as pre-cision is concerned (the dif ference is 24.5 %). 7
Precision is more important than recall in the con-text of our aggre gation application. Incorrect aggre-gations may have detrimental effects on the coher -ence of the generated text. Choosing not to aggre-gate may result in some what repetiti ve texts; how-ever, the semantic content of the underlying text re-mains intact. In the case of wrong aggre gations, we may group together facts that are not compatible, and even introduce implications that are false.
We also consider how well our model performs when evaluated on total partition accurac y. Here, we are examining the partitioning as a whole and ask the follo wing question: how man y clusters of size 1, 2 . . . n did the algorithm get right? This eval-uation measure is stricter than F-score which is com-Figure 2: Partition accurac y for sentences of dif fer -ent size puted over pairwise label assignments. The partition accurac y for entry groups of varying size is sho wn in Figure 2. As can be seen, in all cases the ILP outper -forms the clustering baseline. Both models are fairly accurate at identifying singletons, i.e., database en-tries which are not aggre gated. Performance is natu-rally worse when considering lar ger clusters. Inter -estingly , the dif ference between the two models be-comes more pronounced for partition sizes 4 and 5 (see Figure 2). The ILP X  s accurac y increases by 24% for size 4 and 8% for size 5.

These results empirically validate the impor -tance of global inference for the partitioning task. Our formulation allo ws us to incorporate important document-le vel constraints as well as consistenc y constraints which cannot be easily represented in a vanilla clustering model. In this paper we have presented a novel data-dri ven method for aggre gation in the conte xt of natural lan-guage generation. A key aspect of our approach is the use of global inference for finding aggre gations that are maximally consistent and coherent. We have formulated our inference problem as an inte ger lin-ear program and sho wn experimentally that it out-performs a baseline clustering model by a wide mar -gin. Be yond generation, the approach holds promise for other NLP tasks requiring the accurate partition-ing of items into equi valence classes (e.g., corefer -ence resolution).
Currently , semantic grouping is carried out in our model sequentially . First, a local classifier learns the similarity of entity pairs and then ILP is em-plo yed to infer a valid partitioning. Although such a model has adv antages in the face of sparse data (re-call that we used a relati vely small training corpus of 300 documents) and deli vers good performance, it effecti vely decouples learning from inference. An appealing future direction lies in inte grating learning and inference in a unified global frame work. Such a frame work would allo w us to incorporate global constraints directly into the learning process.
Another important issue, not addressed in this work, is the interaction of our aggre gation method with content selection and surf ace realization. Using an ILP formulation may be an adv antage here since we could use feedback (in the form of constraints) from other components and kno wle gde sources (e.g., discourse relations) to impro ve aggre gation or in-deed the generation pipeline as a whole (Marciniak and Strube, 2005).

