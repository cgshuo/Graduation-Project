 Previous information extraction (IE) systems are typically orga-nized as a pipeline architecture of separated stages which make independent local decisions. When the data grows beyond some certain size, the extracted facts become inter-dependent and thus we can take advantage of information redundancy to conduct rea-soning across documents and improve the performance of IE. We describe a joint inference approach based on information network structure to conduct cross-fact reasoning with an integer linear pro-gramming framework. Without using any additional labeled data this new method obtained 13.7%-24.4% user browsing cost reduc-tion over a state-of-the-art IE system which extracts various types of facts independently.
 I.2.7 [ Natural Language Processing ]: Text analysis; H.3.4 [ Systems and Software ]: Information networks, Question-answering (fact retrieval) systems Algorithms Information extraction, global reasoning, Integer Linear Program-ming
One of the initial goals for Information Extraction (IE) was to create a knowledge base from the entire input corpus, such as a profile or a series of activities about any entity, and allow fur-ther logical reasoning on the knowledge base. Unfortunately the knowledge base constructed from a typical IE pipeline often con-tains lots of erroneous and conflicting facts. Interestingly, when the data grows beyond some certain size, the extracted facts become inter-dependent and thus we can take advantage of information redundancy to conduct reasoning across documents and improve the performance of IE. Some recent work conducted inference to achieve extraction consistency across documents [4], entities [3], relations [11, 6] and events [7].

In this paper we propose to apply the new structure called "In-formation Networks" to conduct more complete and robust infer-ence. An Information Network (InfoNet) is a heterogeneous net-work that includes a set of  X  X nformation graphs" G = G i ( V where V i is the collection of entity nodes, and E i is the collec-tion of edges linking one entity to the other, labeled by relation or event attributes, such as  X  X ember_of" and  X  X amily". This struc-tured networked representation characterizes a dense graph of rela-tions/events among all entities provides a strong graph theoretical framework to enable effective inference and propagation. From the InfoNet point of view, it X  X  clear that most previous inference work addressed partial structures, such as the inferences between repeated nodes/links [4], a pair of nodes [3], or a pair of links [7]. The goal of this paper is to develop a uniformed global inference framework across all of the nodes and links in the entire InfoNet.
When a user distills knowledge from the IE output, coherent facts are preferred because they include fewer conceptual gaps and thus require fewer inferences and less prior knowledge to under-stand [9]. Based on this intuition, we propose the following hy-pothesis: if an extracted fact is more consistent with other facts to tell a coherent story, it X  X  more likely to be correct. For example, Figure 1 depicts a partial InfoNet connecting inter-dependent re-lations. The solid lines present correct relations, while dash lines indicate incorrect relations. From this figure, we can observe that contradictions may happen due to the relational dependencies, for instance, George W. Bush is detected as the member of both Repub-lican Party and Hamas , while these two organizations are located in different countries ( United States of America vs. Hamas ). Based on one possible global constraint that an organization and its mem-bers are unlikely to locate in different countries, we can determine that George W. Bush is unlikely to be a member of Hamas .
We propose a joint inference method based on cross-fact con-straints in InfoNets to approach this goal. We gather together IE results from a large collection of documents, and then impose con-straints in an integer linear programming framework to reach global optimization. The inference knowledge includes constraints among all kinds of IE stages. To demonstrate the power and generality of this approach, we evaluate it for two distinct relation types: mem-bership and family relations. The effectiveness of this framework is demonstrated by substantially improving the performance of both relation types.
Some recent IE research has raised much interest in global infer-ence [8, 4, 1, 2, 12, 7, 10, 3] based on integer linear programming, heuristic rules or Markov Logic. In this paper, we extend the idea of global inference to the cross-document paradigm for enhancing IE performance. We also leverage relational constraints among all kinds of facts on diverse levels through a new information network representation. In addition, we have generalized the constraints to various categories, so that in the future one only needs to material-ize these categories to new types of facts.
We define a new cross-document IE task on top of the terminolo-gies specified in the NIST ACE program. ACE defined 7 types of entities (persons, geo-political entities, locations, organizations, fa-cilities, vehicles and weapons), 18 types of relations (e.g.,  X  X  town some 50 miles south of Salzburg" indicates a  X  X ocated" relation.); and 33 distinct types of relatively dynamic events (e.g.,  X  X arry Diller on Wednesday quit as chief of Vivendi Universal Entertain-ment." indicates a  X  X ersonnel-start" event). We extend the ACE ter-minology from single document to cross-document setting as fol-lows: Given a collection of source documents, our cross-document IE system should produce a networked knowledge base including unique (i.e. redundancy must be removed) facts.

We apply a state-of-the-art English ACE single-document IE sys-tem [4] as our baseline to extract facts from individual documents. This IE system includes Hidden Markov Model based name tag-ging, and Maximum Entropy based nominal mention tagging, en-tity coreference resolution, time expression extraction and normal-ization, relation extraction and event extraction , incorporating di-verse lexical, syntactic, semantic and ontological knowledge. Fi-nally a cross-document entity linking component based on graph clustering is applied to aggregate facts from different documents. Each component produces reliable confidence values.
In this section, we will discuss the dependency and constraints of the IE outputs in detail, then present a novel cross-document global reasoning approach to enhance IE performance, based on Integer Linear Programming.
We explore typical constraints to be defined across various types of facts. Usually there are heterogeneous relations and events ex-isting among entities, as well as complex interaction patterns. We summarize the constraints on a more abstract level so that one can design domain-specific constraints with the map. Let L i denote a unique relation or event linking two entities A and B .Inthispa-per we consider pairwise and triangle dependency relations among various types of entities and link types, as depicted in Figure 2. Figure 2: Dependency Constraints among Entities, Relations and Events
We compute pointwise mutual information (PMI) to automati-cally estimate the pairwise dependency between any two types of links from ACE2005 training data: where p ( L i ) and p ( L j ) are the frequency of L i and tively, and p ( L i ,L j ) is the co-occurence frequency of and L j ( A, B ) , for any two entities A and B .

Similarly, we apply a multivariate generalization form of PMI [13], total correlation, to the triangle dependency: for any two entities A and B or three entities A , B and C in Figure 2.

If the PMI value is lower than a certain threshold (in our exper-iment we used -2.0 for pairwise and -3.0 for triangle), the links are considered as incompatible and used as a constraint for global inference.

In total we learned 34 pairwise constraints and 16 triangle con-straints. Some constraint examples are listed in Table 1. For ex-ample, Ariel Sharon and Mahmoud Abbas are frequently involved in Contact.Meet events, so they are unlikely to be members of the same organization according to the pairwise constraint. If Osama bin Laden and George W. Bush are involved in a Conflict event with high confidence, then they are unlikely to be the members of the same organization according to the triangle-entity constraint. If Washington and Iraq are involved in a Transport event, then any member of Washington is unlikely to be located in Iraq according to the triangle-link constraint.
Motivated by the intuition that facts are often dependent on each other, we consider the global inference as an optimization prob-lem of all local predication confidence values, using the constraints automatically learned from the above PMI method as hard rules. These hard rules or constraints are designed to guarantee that the facts extracted from different documents are consistent with each other, hence weak predications which violate constraints can be fil-tered out.

First of all, we shall introduce the objective of our optimization problem. Assume we have a set of local outputs, R = { r i inter-dependent relations and events, each output r i is associated with a number of entities r i,j with local confidence values where p i,j  X  (0 , 1] .

From cross-document point of view, a reliable output should have high local confidence value as well as high global frequency. A correct fact may appear rarely within a single document but often appears frequently across documents. In contrast, an invalid fact often has low-frequency, simply because some entities accidentally co-occur in mis-leading contexts. We incorporate this hypothesis into a Integer Linear Programming framework by solving the fol-lowing optimization problem:
Where x i is a binary value: 1 indicates r i is selected in the final output and 0 indicates r i is removed.  X  determines to which extent we penalize low confidence values. If  X  equals 0 then any confi-dence value should be considered equally as 1 ,since p 0 =1 definition. As  X  grows, it gives more penalty to lower confidence values; a special case is  X  equals 1 ,where p  X  equals p itself.
In this section we present the results of applying this joint infer-ence method to improve cross-document information extraction.
We use the data set from the DARPA GALE distillation task, which contains 381,588 newswire documents, for our experiment. The baseline IE system extracted 18,386 person entities, 21,621 geo-political entities and 18,792 organization entities. Without loss of generality, we ask human annotators to evaluate the quality of all of the 1128 Family relations and 2854 Member_of relations (in-cluding ORG-Aff.Employment, ORG-Aff.Membership defined in ACE).

It X  X  important to measure how well a system performs at ex-tracting facts across documents accurately. However, it X  X  time-consuming to manually extract all possible facts from a large col-lection of documents, and thus it X  X  difficult to measure recall. To solve this problem, we apply the Browsing Cost metric defined in [5] to evaluate cross-document IE performance:
Browsing Cost (i) = the number of incorrect or redundant facts that a user must examine before finding i correct facts. In our experiment, we consider a fact as a link L i ( A , is judged as correct if and only if both A and B have correct bound-aries and entity types and L i has correct relation or event type.
Figure 3 and 4 demonstrate the browsing costs. Compared to the baseline, on average our approach resulted in a 13.7% user brows-ing effort reduction for Family relations and a 24.4% user browsing effort reduction for Member_of relations.
Figure 3: Browsing cost comparison of Member_of relation.
Figure 5 depicts the correctness of the removal operations (i.e. the number of unique facts are removed corectly/incorrectly) for Family relation, varying the parameter  X  of the objective function. Although our method mistakenly removed a few correct facts, it successfully removed many more incorrect instances using any pa-rameter. For example, it removed the Family relation between  X  Jack Straw "and X  Tony Blair " because they were involved in the Business relation ( X  Jack Straw " was in  X  Tony Blair " X  X  Cabinet). It occasion-ally removed a few correct relations involving two person entities with multiple types of relations. For example,  X  Mohammed Bakir Al-hakim "and X  Abdul Aziz Al-hakim " are family members as well as colleagues in the Iraqi government. Clearly overall the rewards of using joint inference significantly outweigh the risks. Figure 5: Removal curve of Family relation w.r.t parameter
In order to evaluate the impact of each constraint, we also con-ducted experiments using each constraint independently in the ILP model with  X  =20 for Family relation. The results are presented in Table 2.
 Table 2: Impact of different types of constraints on Family re-lation.
Most previous IE research considered various types of relations and events independent of each other, and focused on individual predictions using local information. As a result, it X  X  inevitable that contradictory facts can be extracted and the incorrect ones must then be removed in an effective way. We incorporated the inter-dependencies among various types of facts as latent constraints in an information network based inference framework using integer linear programming. Such joint inference analysis allowed us to incorporate information from a much wider context, going across documents and fact types, and utilize deeper semantic inferences to significantly enhance the extraction performance. In the future we are interested in applying statistical relational learning algorithms to capture more implicit constraints and soft inference rules. Fi-nally in this paper we assumed that the constraints are relatively static, however, some facts may change over time (e.g. a person X  X  employment or residence relation). Therefore we are also inter-ested in extending our joint inference framework to capture tempo-ral constraints.
This work was supported in part by the U.S. Army Research Lab-oratory under Cooperative Agreement No. W911NF-09-2-0053 (NS-CTA), the U.S. NSF CAREER Award under Grant IIS-0953149 and PSC-CUNY Research Program. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government. The U.S. Government is au-thorized to reproduce and distribute reprints for Government pur-poses notwithstanding any copyright notation here on. [1] N. Chambers and D. Jurafsky. Jointly combining implicit [2] P. Gupta and H. Ji. Predicting unknown time arguments [3] Y. Hong, J. Zhang, B. Ma, J. Yao, G. Zhou, and Q. Zhu. [4] H. Ji and R. Grishman. Refining event extraction through [5] H. Ji, R. Grishman, Z. Chen, and P. Gupta. Cross-document [6] H. Ji, D. Westbrook, and R. Grishman. Using semantic [7] S. Liao and R. Grishman. Using document level cross-event [8] A. Mccallum. Information extraction, data mining and joint [9] D. S. McNamara. Reading both high-coherence and [10] H. Poon and L. Vanderwende. Joint inference for knowledge [11] D. Roth and W. tau Yih. A linear programming formulation [12] M. Tatu and M. Srikanth. Experiments with reasoning for [13] Van de Cruys Tim. Two Multivariate Generalizations of
