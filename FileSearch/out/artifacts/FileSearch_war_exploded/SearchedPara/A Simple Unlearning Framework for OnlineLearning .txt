 Online learning is a machine learning setup where the learning algorithm needs to learn from and make predictions on streaming data efficiently and effectively [ 3 , 4 , 9 ]. The setup enjoys many potential applications, such as predicting the weather, customer preferences, or stock prices [ 16 ].
 rithm (PA) [ 3 ], the confidence weighted algorithm (CW) [ 4 ] and the adaptive regularization of weight algorithm (AROW) [ 9 ], are designed under the assump-tion that the target function to be learned is fixed. In many applications, how-ever, change in the underlying environment can result in change of the target function (concept) as time goes by. That is, the concept can be drifting [ 17 ] instead of fixed. For example, the best popular-cloth predictor (concept) is con-difficulty for traditional online learning algorithms and are studied by two fami-lies of works. One family of works focuses on the detection of concept drift from on the data distribution and set up an alert threshold to reliably detect concept drift. The other family tries to construct learning models from selected instances of the data stream, with the hope that such instances match the drifting concept better [ 2 , 13 ]. The simplest approach of this family is to use a sliding window to capture the newest instances for learning [ 13 ]. While the two kinds both deal with concept-drifting data, it is not fully clear on how they could be combined to improve the learning performance and will be the main focus of this work. In particular, we propose a framework on top of existing online learning algo-rithms to improve the learning performance under concept drifts. The framework detects the possible concept drift by checking whether forgetting some older data may be helpful, where the detection is motivated by the confidence terms used in modern online learning algorithms. Then, it conducts forgetting by unlearn-ing older data from the current model. By greedily repeating the detection and unlearning steps along with online learning, the framework effectively results in a dynamic sliding window that can suit different concept drifts. We design con-crete approaches of the framework based on PA [ 3 ], AROW [ 9 ] and CW [ 4 ]. Our empirical results demonstrate that the framework can reach better accuracy on artificial and real-world data. The results justify the usefulness of the framework. The paper is organized as follows. Section 2 establishes the setup and lists related online learning algorithms. Section 3 introduces the proposed framework. Section 4 discusses the experimental results and Sect. 5 concludes the paper. In this paper, we consider the online learning problem for binary classification. In each round of this problem, the learning algorithm observes a coming instance and predicts its label to be +1 or  X  1. After the prediction, the true label is revealed and the algorithm can then take the new instance-label pair to improve its internal prediction model. The goal of the algorithm is to make as few pre-diction errors as possible.
 We shall denote the instance-label pair in round t as ( x { 1 , 2 ,...,T } .Each x t  X  R n represents the instance (feature vector) and y { +1 ,  X  1 } indicates the label. The prediction in the t -th round is denoted as  X  y and the error refers to the zero-one loss 01 ( y t ,  X  y t y = X  y t , and 0 otherwise.
 In this work, we consider the linear model for online learning, where some linear weight vector w t  X  R n is maintained within round t and  X  y with  X  denoting an inner product. The linear model generally enjoys efficiency in online learning and is often the focus of study in many online learning works [ 3 , 4 , 9 , 14 ]. For the linear model, improving would then mean updating from w to w t +1 , and we denote the difference as  X  w t = w t +1 different online learning algorithms is then to design a proper update function Algorithm 1. The linear model for online learning for online learning is shown in Algorithm 1 ,whereweassume w vector for simplicity.
 is the Passive-Aggressive algorithm (PA) [ 3 ]. PA calculates the signed margin of the labeled instance by y t ( w t  X  x t ), which indicates how confident the pre-diction  X  y t = sign( w t  X  x t ) was. PA then aims to adjust the weights w closest w t +1 (passive) in terms of the Euclidean distance, such that the hinge loss h ( w ;( y t , x t )) = max(0 , 1  X  y t ( w  X  x t )) is decreased to (aggressive). The aim leads to the following Update ( w t of considering a single weight vector w t , the algorithm considers the weight distribution , modeled as a Gaussian distribution with mean w  X  . During each Update for CW, both w t and  X  t are taken into account, and updated to w t +1 and  X  t +1 . The updating step adjusts ( w zero-one loss under the new Gaussian distribution is smaller than some (1 (aggressive).
 [ 9 ], which improves CW by including more regularization. In particular, the updating step of AROW solves an unconstrained optimization problem that calculates ( w t +1 , X  t +1 )by The first term is exactly the KL divergence that the passive part of CW consid-ers; the second term embeds the aggressive part of CW with the squared hinge loss (similar to PA); the third term represents the confidence on x generally grow as more instances have been observed. In particular, the confi-dence term represents how different x t is from the current estimate of  X  .The confidence term acts as a regularization term to make the learning algorithm more robust. In this work, we set the parameters  X  1 and  X  as the original paper suggests [ 9 ]. One special property of the three algorithms above, which is also shared by many algorithms for the linear model of online learning, is that  X  w scaled version of y t x t , as can be seen in ( 1 ) for PA. Then, by having w the zero vector, each w t is simply a linear combination y x work.
 The three representative algorithms introduced above do not specifically focus on concept-drifting data. For example, when concept drift happens, being passive like the algorithms do may easily lead to slow adaptation to the latest concept. Next, we illustrate more on what we mean by concept drift in online learning. [ 16 ] defines concept drift to mean the change of  X  X roperty X  within the data. Some major types of concept drifts that will be considered here are abrupt concept drift, gradual concept drift and virtual concept drift. The first two entail the change of the relation between instances and labels. Denote the relation as the ideal target function f such that y t = f ( x t ) + noise, means that the ideal target function can change from f to a very different one like (  X  f ) at some round t to some different f between rounds t 1 and t 2 .
 Virtual concept drift , unlike the other two, is generally a consequence of the change of some hidden context within the data [ 6 ]. The change effectively causes the distribution of x t to vary. While the target function that characterizes the relation between x t and y t may stay the same for virtual concept drift, the change of distribution places different importance on different parts of the feature space for the algorithm to digest.
 Two families of methods in the literature focus on dealing with concept-method (DDM) that tracks the trend of the zero-one loss to calculate the drift level. When the drift level reaches an alert threshold, the method claims to detect the concept drift and resets the internal model. While the idea of DDM is sim-ple, it generally cannot detect gradual concept drift effectively. [ 1 ]thusproposes the early drift detection method (EDDM) to cope with gradual concept drift, where the distribution of errors instead of the trend is estimated for detection. Some other popular detection criteria include the estimated accuracy difference between an all-data model and a recent-data model [ 12 ], and the estimated per-formance difference between models built from different chunks of data [ 15 ]. Generally, similar to [ 5 ], after detecting the concept drift, the methods above reset the internal model. That is, all knowledge about the data received before detection are effectively forgotten. Nevertheless, forgetting all data before the detection may not be the best strategy for gradual concept drift (where the ear-lier data may be somewhat helpful) and virtual concept drift (where the earlier data still hint the target function).
 The other family [ 2 , 13 ] makes the internal model adaptive to the concept drift by training the model with selected instances only. The selected instances are often within a sliding window, which matches the fact that the latest instances should best reflect the current concept. Most of the state-of-the-art methods consider dynamic sliding windows. For instance, [ 13 ] takes the leave-one-out error estimate of the support vector machine to design a method that computes the best dynamic sliding window for minimizing the leave-one-out error. [ 2 ]proposes a general dynamic sliding window method by maintaining a sliding window such that the  X  X ead X  and  X  X ail X  sub-windows are of little statistical difference. The sliding-window methods naturally trace concept drifts well, especially gradual concept drifts. Nevertheless, calculating a good dynamic sliding window is often computationally intensive. It is thus difficult to apply the methods within this family to real-world online learning scenario where efficiency is highly demanded. resetting the internal model may not lead to the best learning performance under concept drifts; sliding-windows methods are usually effective, but are at the expense of computation. We aim to design a different framework for better online learning performance under the concept drift. Our framework will include a simple detection scheme and directly exploits the detection scheme to efficiently determine a dynamic sliding window. In addition, the framework can be flexibly coupled with existing online learning algorithms with linear models. The idea of our proposed unlearning framework is simple. Between steps 5 and 6 of Algorithm 1 , we add a procedure UnlearningTest to check if forgetting some older instance can be beneficial for learning. In particular, the decision of  X  X eneficial X  is done by comparing a regularized objective function before and after the forgetting, where the regularized objective function mimics that being used by AROW. If forgetting is beneficial, a new w t +1 (and its accompanying  X  t +1 in the case of CW or AROW) replaces the original w t +1 two issues in describing the framework concretely: what the regularized objective function and unlearning step are, and which  X  X lder X  instance to check? We will clarify the issues in the next subsections. 3.1 Unlearning Test Denote ( x k ,y k ), k  X  X  1 , 2 ,  X  X  X  ,t  X  1 } as the selected instance for ingTest . Recall that in round t ,each w t is simply a linear combination of the sibly 0) footprint within w t +1 if we record  X  w k along with the online learning process. Then, one straightforward step to unlearn ( x k ,y w The  X  t +1 accompanying w t +1 can also be calculated similarly by recording  X  X  along with the online learning process.
 and w t +1 represents the original weight vector. Our task is to pick the better one for online learning with concept drift. A simple idea is to just compare their loss, such as the squared hinge loss used by AROW. That is, unlearning is conducted if and only if We can even make the condition more strict by inserting a parameter  X  that controls the demanded reduction of loss from the original weight vector. That is, unlearning is conducted if and only if Then,  X  =0 . 0 makes unlearning happen only if w t +1 is fully correct on ( x in terms of the hinge loss, and the original online learning algorithms are using  X &lt; 0.
 In our study, we find that only using 2 h as the decision objective makes the unlearning procedure rather unstable. Motivated by AROW, we thus decide to add two terms to the decision objective. One is the confidence term used by AROW, and the other is the usual squared length of w . The first term regular-izes against unwanted update of  X  , much like AROW does. The second term regularizes against unwanted update of w to a long vector, much like the usual ridge regression regularization. That is, given ( x t ,y t and conduct unlearning if and only if obj( w t +1 , X  t +1 parameters  X  and  X  balances the influence of each term.
 The final missing component is how to specify  X  and  X  . To avoid making the framework overly complicated, we only consider using those parameters to balance the numerical range of the terms. In particular, we let  X  be the average of for  X   X  X  1 , 2 ,...,t } so  X  x T larly, we let  X  be the average of The details of UnlearningTest is listed in Algorithm 2 . 3.2 Instance for Unlearning Test Unlearning is completed by the unlearning test at a certain selected instance ( x ,y k ). But how to determine the k from all previous processed instances? We proposed three possible unlearning strategies to deciding the instance ( x Algorithm 2. Unlearning test for some instance ( x k ,y k Forwarding-Removing: Traditional sliding window technique tries to main-tain a window that keeps the recent accessed examples, and drops the oldest instance according to some set of rules [ 2 ]. Here, the unlearning test is substi-tuted for the rules. Forward-removing considers ( x t  X  L window size L as the as the selected instance for unlearning test. The strategy is illustrated by Fig. 1 , where the older instances are at the right-hand-side of the data stream. After updating on x t is done, the unlearning test examines the red instance x t  X  L .
 stable and will be used to demonstrate this strategy in Sect. 4 .
 Queue-Removing: Instead of considering the instance that is L rounds away, this strategy selects the oldest one within the current model w the current model w t +1 is a combination of some updated parts  X  w updated instance ( x i ,y i ). We record those  X  w i like a data list, as illustrated in Fig. 2 . Take w t +1 as a queue, unlearning test will be executed at the red updated part  X  w 1 , which is the oldest updated instance in model. As ( x removed from w t , the size of the queue can change dynamically, resulting in a dynamic sliding window effectively. Selecting-Removing: Above strategies both select one particular instance under different structure. However, those strategies neither consider all can-didates in their window nor find out the best unlearned weight w instances and take the instance that can decrease obj the most as the instance to be unlearned. We take these three unlearning strategies in Sect. 3 with PA [ 3 ], AROW [ 9 ]and CW [ 4 ]. In those algorithms, we set a = 1.0,  X  = 0.0001 in CW and r = 0.1 in AROW. The parameter  X  in unlearning test is individually selected from { 0 . 1 , 0 . 2 ,..., 0 . 9 } due to the different properties on these algorithms. All ten synthetic data sets contain different concept drifts described in Table 1 . The first eight data sets are used by [ 5 ]. Because most of them are about abrupt concept drift, we construct two more data sets, LINES and MULTI-LINES, whose drifting type is gradual. The target function of LINES is changed by shifting and rotating gradually in 2D, and MULTILINES is a d dimensional version defined in [ 8 ].
 Previous works [ 1 , 5 ] assume every concept contains a fixed number of instances, and examine on small size data sets. Here we construct these arti-ficial data sets with three differences to make the data sets more realistic. First, the number and the timing of concept drifts are randomly assigned and all drift events are recorded so that we could simulate a perfect drifting detection, Concept-removing, which resets w t +1 immediately after a concept drift hap-pens. We take Concept-removing as an upper bound benchmark for using the ideal drifting information. Second, at least 1,000,000 instances are generated in each data set for the robustness. Finally, we inject noise made by flipping binary labels under different probabilities to check the robustness of the pro-posed framework. All artificial data sets are generated under different flipping level within { 0 . 00 , 0 . 05 ,  X  X  X  , 0 . 30 } .
 improve the accuracy. Two evaluation criteria are considered, mance and cumulative classification accuracy . A smaller average rank (along with standard deviation) indicates that an higher classification accuracy per-formed among compared methods. 4.1 Results and Discussion In addition to the three proposed strategies within the framework, and the ideal Concept-removing strategy, we also compare the proposed framework with EDDM [ 1 ]. Our experimental results are summarized in following tables with dif-ferent control variables. Table 2 compares all unlearning strategies under three kinds of concept-drifting data. Table 3 compares the relation between different unlearning strategies and each online learning algorithm individually. Table 4 evaluates the influence on the best unlearning strategy with different noise level. The individual accuracy performances for each data set are recorded in Table 5 . ideal Concept-removing strategy performs very well for abrupt drifting and vir-tual drifting, as expected. But the immediate resetting cannot work for grad-ual drifting data, and the ideal detection is not realistic anyway. Our proposed framework, on the other hand, performs well on all kinds of data when using Queue-removing.
 side, Queue-removing preforms the best ranking on average in four unlearning strategies. Note that Selecting-removing is worse than Queue-removing, which indicates that overly searching for the  X  X est X  instance to unlearn is not necessary. On the algorithm sides, a significant ranking gap between Concept-removing and the others is presented in AROW. All four unlearning strategies show the smaller ranking than original AROW. For the other two algorithms, only Queue-removing and EDDM gets smaller ranking on PA. But almost all unlearning approaches do not have great advantage in CW. The cause of non-improving is their individual updating rules, which does not consider confidence term in PA and squared hinge-loss in CW. We study Queue-removing more in Table 4 , which shows the ranking perfor-mance under different noise levels. From lowest to highest bias, Concept-removing is still the best in three strategies but Queue-removing shows its effectiveness in all noise levels. When the noise becomes larger, Queue-removing is closer to the ideal Concept-removing strategy.
 Table 5 explains whether unlearning framework reflects the significant differ-ence from original algorithms. We conducted the t -test experiment by its cumu-lative classification accuracy at each data set 30 times for all artificial data and directly evaluated two real data, MNIST 1 and ELEC2 2 . For two real data, we directly compare the accuracy performance with EDDM and Queue-removing. The t -test is evaluated in three different strategies. Queue-removing shows better accuracy than no-unlearning, and those p-value(N-Q) are mostly smaller than 0.01, which indicates the performance gap is significant enough. Concept-removing reveal the upper bound accuracy and the nearly 0 on p-value(Q-C) comparing with the Queue-removing in all data sets except for CIRCLES. MNIST [ 11 ] is a handwritten digits data. Although it is not a concept-drifting data, we test whether our unlearning framework will deteriorate the classifying performance. We use one versus one to evaluate 45 binary classifications for those digits under online learning scenario. To handle all classifications quickly, we scale each image by 25 % and take its pixel as feature. Because MNIST data does not contain significant drifting and the nearly same accuracies are presented, it implies our unlearning framework can work well in the normal data set. ELEC2 [ 7 ] is the collection of the electricity price. Those prices are affected by demand and supply of the market, and the labels identify the changing prices related to a moving average. It is a widely used for concept-drifting. We predict the current price rises or falls by its all 8 features. The result shows that Queue-removing preforms better than no-unlearning and EDDM. We present an unlearning framework on top of PA-based online algorithms to improve the learning performance under different kinds of concept-drifting data. This framework is simple yet effective. In particular, the queue-removing strat-egy, which is the best-performing one, results in a dynamic sliding window on the mistaken data and dynamically unlearns based on a simple unlearning test as the drift detection. Future work includes more sophisticated ways to balance between loss and regularization for the unlearning test.

