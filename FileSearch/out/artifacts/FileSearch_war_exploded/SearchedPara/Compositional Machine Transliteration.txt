 A. KUMARAN Microsoft Research India and MITESH M. KHAPRA and PUSHPAK BHATTACHARYYA Indian Institute of Technology Bombay 1. INTRODUCTION Machine transliteration is an important problem in an increasingly multilin-gual world, for its critical role in many downstream application systems, such as machine translation (MT) and crosslingual information retrieval (CLIR) sys-tems. Proper names form an open set in any language, and they are shown to grow with the size of the corpora. 1 Names form a significant fraction of the user query terms, and handling them correctly correlates highly with the retrieval performance of the IR engine [Mandl and Womser-Hacker 2004]. In standard crosslingual evaluation datasets names are very prominent 2 and they affect the retrieval quality significantly [Mandl and Womser-Hacker 2005; Udupa et al. 2009; Xu and Weischedel 2005]. More importantly, the standard resources (such as bilingual dictionaries) do not include name transliterations except for a small set of popular names, and keeping them updated continually is, in general, not an economically viable option. The statistical dictionaries, on the other hand, may not contain the transliterations as names are not frequent enough to provide sufficient statistical evidence during alignment. 3 Hence, the transliteration systems to rewrite the names in the target language are criti-cally important in crosslingual scenarios. The importance of the transliteration problem is recognized well by the research community over the last couple of decades as evidenced by the increasing prominence for this topic in the research scope and publications of many machine translation, information retrieval, natural language processing, and comput ational linguistics conferences. The standard pair-wise transliteration systems are thoroughly researched and the approaches and performances are well published in research literature. tems as a composition of multiple transliteration systems to achieve translit-eration functionality or to enhance the transliteration quality between a given pair of languages. We propose two distinct forms of composition: serial and parallel. In serial compositional systems, the transliteration systems are com-bined serially; that is, transliteration functionality between two languages X &amp; Z may be created by combining transliteration engine X  X  YandY  X  Z. Such compositions may be useful for situations where no parallel data exists between two languages X &amp; Z, but sufficient parallel names data may exist between X &amp; Y and Y &amp; Z. Such partial availability of pair-wise data is common in many situations, where one central language dominates many languages of a country or a region. For example, there are 22 constitutionally recognized languages in India, but it is more likely that parallel names data might exist between Hindi and a foreign language, say, Russian, than between any other Indian language and Russian. In such situations, a transliteration system between Kannada, an Indian language, and Russian may be created by composing two transliter-ation modules, one between Kannada and Hindi, and the other between Hindi and Russian. Such compositions, if successful quality-wise, may alleviate the need for developing and maintaining parallel names corpora between many language pairs, and leverage the existing resources whenever possible, indicat-ing a less resource intensive approach to develop transliteration functionality among a group of languages.
 dence from multiple transliteration paths in parallel in order to develop a good quality transliteration system between a pair of languages. While it is gener-ally accepted that the transliteration quality of data-driven approaches grows with more data, typically the quality p lateaus, accruing only marginal ben-efit after certain size of the training co rpora. In parallel compositional sys-tems, we explore if transliteration quality between X &amp; Z could be improved by leveraging evidences from multiple transliteration paths between X &amp; Z. Such systems could be very useful when data is available between many dif-ferent pairs among a set of n languages. Again, such situations naturally exist in many multicultural and multilingual societies, such as India and the Euro-pean Union. For example, parallel names data exists between many language pairs of the Indian subcontinent as most states enforce a three-language policy where all government records, such as ce nsus data, telephone directories, rail-way database, etc., exist in English, Hindi, and one of the regional languages. Similarly, many countries publish their parliamentary proceedings in multiple languages as mandated by legislative processes.
 among a group of languages, and in this article our specific contributions are: (1) proposing the idea of compositionality of transliteration functionality, in (2) composing serially two transliteration systems, namely X  X  YandY  X  Z X  (3) improving the quality of an existing X  X  Z transliteration system through (4) demonstrating the effectiveness of different compositional transliteration Indian subcontinent, specifically English, Hindi, Kannada, and Marathi, be-tween which parallel names corpora are available. We believe that such com-positional transliteration functionality may be useful for many regions of the world, where common information access is necessary for political, social, cul-tural, or economic reasons.
 1.1 Related Work Current models for transliteration can be classified as grapheme-based, phoneme-based, and hybrid models. Grapheme-based models, such as source channel model [Lee and Choi 1998], maximum entropy model [Goto et al. 2003], conditional random fields [Veeravalli et al. 2008], and decision trees [Kang and Choi 2000] treat transliteration as an orthographic process and try to map the source language graphemes directly to the target language graphemes. Phoneme-based models, such as the ones based on weighted finite state trans-ducers [Knight and Graehl 1997] and extended Markov window [Jung et al. 2000] treat transliteration as a phonetic process rather than an orthographic process. Under such frameworks, transliteration is treated as a conversion from source grapheme to source phoneme followed by a conversion from source phoneme to target grapheme. Hybrid models either use a combination of a grapheme-based model and a phoneme-based model [Stalls and Knight 1998] or capture the correspondence between source graphemes and source phonemes to produce target language graphemes [Oh and Choi 2002].
 of languages, there existed no consistent way of comparing these algorithms as the results were mostly reported on di fferent datasets using different met-rics. In this context, the shared task on machine transliteration in the recently concluded NEWS 2009 workshop [Li et al. 2009] was a successful attempt at calibrating different machine transliteration systems using common datasets and common metrics for a variety of language pairs. A study of various sys-tems submitted to the workshop shows that grapheme-based approaches per-form better than or at par with phoneme-based approaches, while requiring no specialized linguistic resources. In fact some of the best performing systems in the workshop were primarily grapheme-based systems [Jansche and Sproat 2009; Jiampojamarn et al. 2009; Oh et al. 2009]. Further, combining any of the grapheme-based engines with pre-processing modules such as word-origin detection were shown to enhance the performance of the system [Oh and Choi 2002]. While previous research addressed combining evidence from multiple systems [Oh et al. 2009], to the best of our knowledge, ours is the first attempt at combining transliteration evidence from multiple languages.
 of them addressed the issue of performing transliteration in a resource-scarce scenario, as there was an implicit assumption of availability of data between a pair of languages. In particular, we address a methodology to develop translit-eration functionality between a pair of languages when no direct data exists between them. Some work on similar lines has been done in machine trans-lation [Wu and Wang 2007] wherein an intermediate bridge language (say Y) is used to fill the data void that exists between a given language pair (say X and Z). In fact, recently it has been shown that the accuracy of a X  X  ZMa-chine Translation system can be i mproved by using additional X  X  Ydata provided Z and Y share some common vocabulary and cognates [Nakov and Ng 2009]. Similar work has also been done for transitive CLIR [Ballesteros 2000; Lehtokangas et al. 2008] where it was shown that employing a third language as an interlingua between the source and target languages is a vi-able means of performing CLR between languages for which no bilingual dictio-nary is available. Specifically, Lehtokangas et al. [2008] automatically trans-lated source language queries into a target language using an intermediate (or pivot) language and showed that such transitive translations were able to achieve 85 X 93% of the direct translation performance. Similarly, Gollins and Sanderson [Gollins and Sanderson 2001] proposed an approach called triangu-lated transitive translation which assumed the presence of two pivot languages for transitive CLIR. They showed that taking an intersection of the transla-tions produced through two pivot languages can help to eliminate the noise introduced by each pivot language independently. The serial compositional ap-proach described in this article can be seen as an application of the transitive CLIR idea to the domain of machine transliteration. Similarly, the parallel compositional approach can be seen as a means of eliminating noise by tak-ing multiple transliteration paths (as in the case of the triangulated transitive translation approach [Gollins and Sanderson 2001]). 1.2 Organization This article is organized in the following manner. This section introduces the concept of compositional transliteration. This section also outlines the state of the art in transliteration systems research and related work in machine trans-lation scenarios. Section 2 outlines a language-independent orthography-based state of the art transliteration system that is used for all our experiments sub-sequently in this article. Section 3 defines a measure that correlates well with the ease of transliteration between a given pair of languages. Section 4 in-troduces serial composition of transliteration systems and shows how a prac-tical transliteration functionality may be developed between two languages. Section 5 introduces parallel composition of transliteration systems for combin-ing evidence from multiple transliteration paths to improve the quality of the transliteration between a given pair of languages. Section 6 demonstrate effec-tiveness of such compositional systems in a typical usage scenario: crosslingual information retrieval. Finally, Section 7 concludes the article, outlining our future work. 1.3 Notation Used Throughout the article, we represent each language by its language code as described in Table I, and use the following convention to refer to a specific lan-guage or a transliteration system between a pair of languages: L 1 -L 2 means a system for transliterating words from language L 1 to language L 2 . For exam-ple, by En-Hi we mean a transliteration system from English to Hindi. 2. A GENERIC TRANSLITERATION SYSTEM In this section, we outline the development of a language-neutral translitera-tion system that is to be used for all subsequent transliteration experiments. 2.1 A Generic Transliteration Engine between English and Indian Languages First we set out to design a generic transliteration engine, so as to have a common system that can be used for establishing the baseline performance and the relative performance of various compositional transliteration alternatives. In addition we imposed a quality requirement that such a system work well across a wide variety of language pairs.
 2009 shared task revealed that while the systems using phonetic information require additional linguistic resources, they perform only marginally better than purely orthographic systems. Further, among various machine learning techniques used for transliteration (using orthography or phonology), the con-ditional random fields-based approach was the most popular among those par-ticipants in the first quartile. Hence, we decided to adopt a conditional random fields-based approach using purely orthographic features. In addition, since the Indian languages share many characteristics among them, such as distinct orthographic representation for different variations X  X spirated or unaspirated, voiced or voiceless, etc. X  X f many consonants, we introduced a word origin de-tection module to identify specifically Indian origin names. Use of such clas-sifiers allowed us to train a specific CRF-based transliteration engine for In-dian origin names, and thus scoring a better quality transliteration. All other names are transliterated through an engine that is trained on non-Indian ori-gin names.
 gine, with a name origin detection module as a pre-processor (see Figure 1). The details of the subsystems are provided below. [Lafferty et al. 2001] are undirected graphical models used for labeling sequential data. Under this model, the conditional probability distribution of the target word given the source word is given by where, CRF++, 4 an open source implementation of CRF, was used for training and fur-ther transliterating the names. GIZA++ 5 [Och and Ney 2003], a freely available implementation of the IBM alignment models [Brown et al. 1993] was used to get character level alignments for the name pairs in the parallel names train-ing corpora. Under this alignment, each character in the source word is aligned to zero or more characters in the corre sponding target word. The following features are then generated using this character-aligned data (here e i and h i form the i -th aligned pair of characters form the source word and target word, respectively):  X  h i and e j such that i  X  2  X  j  X  i +2  X  h i and source character bigrams ( { e i  X  1 , e i } or { e i , e i +1 } )  X  h i , h i  X  1 and e j such that i  X  2  X  j  X  i +2  X  h i , h i  X  1 and source character bigrams  X  h i , h i  X  1 and source character trigrams experimenting with various configurations and yet applicable for a wide variety of language pairs. Further, this model may be trained only based on a training set of name pairs from the respective languages, without relying on any special linguistic tools or resources. While our experiments and analyses are confined to English and a set of Indian languages, it would be interesting to explore how it may scale for handling ideographic languages (such as, Chinese) or Semitic languages (such as Arabic and Hebrew). transliteration between English and Indian languages, specifically due to the difference in phonology between English and languages in the Indian subcon-tinent. While this is true in most transliteration systems, they play a crucial role in Indic names, as many variations for consonants typically exist in Indic language phonology.
 ample of letter d .When d appears in a name of Western origin (e.g., Daniel , Hudson , Alfred ) and is not followed by the letter h , it invariably gets translit-erated as Hindi letter , whereas, if it appears in a name of Indic origin (e.g., Devendra , Indore , Jharkhand ) then it is equally likely to be transliterated as or . This shows that the decision is influenced by the origin of the word. Since the datasets (namely, Hindi, Kannada, Russian, and Tamil) for the NEWS 2009 shared task consisted of a mix of Indic and Western names, it made sense to train separate models for words of Indic origin and words of Western origin. arated based on their origin. We first manually classified a random subset of the training set into of Indic origin names and Others. Two n -gram lan-guage models were built, for each of the already classified names of Indic origin and another for others. Each of the remaining names in the training corpora were split into a sequence of characters and the probability of such sequences using the two language models was constructed. Based on the computed probability, we classify all the name pairs in the training set as Indic names or others. 2.2 NEWS 2009 Transliteration Shared Task: Data and Systems In the transliteration shared task conducted as a part of the ACL NEWS 2009 workshop [Li et al. 2009], 28 academic and industry groups from around the world participated in eight diverse language pairs. The shared task published between 6,000 and 30,000 name pairs in various languages as training corpus, and the performances of systems on a common test corpora of approximately 1,000 names in each language pair were published, highlighting the effect of various transliteration approaches on quality in different language pairs. For all our experiments in this section, we used only the training data published by the NEWS 2009 workshop (namely, approximately 6,000 name pairs in En-Ru, 8,000 name pairs in each of En-Ta and En-Ka, and 10,000 name pairs in En-Hi), and the test data for producing our results.
 training corpus, and were manually annotated as Indian or Other. These 3,000 names were then divided into four non-overlapping folds. A four-fold valida-tion was performed using this data. In each case, we used three folds (i.e., 2,250 names) as training data for deriving language models and the remaining fourth fold as test data. The average accuracy over the four folds was 97% that is, the test words were classified into Indic and Other origin names with an accuracy of approximately 97%. The above classifier was then again trained using the entire 3,000 names and was then applied on the entire data to yield reasonably well classified data that is used for training two distinct CRF-based modules for transliterating Indic and other names.
 2.3 Transliteration Quality and Comparison with NEWS 2009 Participants In this section we compare our experimental results on four language pairs (specifically, En-Hi, En-Ka, En-Ta, and En-Ru) with that of the participating systems of the NEWS 2009 transliteration task. We used only the same train-ing and test data that were released for NEWS 2009 Machine Transliteration Shared Task [Li et al. 2009], and hence the output were for standard runs, in NEWS 2009 parlance (that is, no extra data other than what was released for NEWS 2009 shared task, or no other linguistic tools or resources were used). The top 10 transliteration candidates for each word were generated, and eval-uated. The performance of our system is shown with the three standard mea-sures as defined in Li et al. [2009]. Specifically, the Word Accuracy in Top-1 (ACC-1), Fuzziness in Top-1 ( F -score) and Mean Reciprocal Rank (MRR). As can be seen in Table II, our system was comparable to the best of the systems in the NEWS shared task and would have been in the top quarter, in terms of ranking. We also want to highlight that the best system in NEWS 2009 [Jiampojamarn et al. 2009] used an online discriminative training sequence prediction algorithm using many-to-many alignments between the target and source. The Margin Infused Relaxed Algorithm (MIRA) [Crammer and Singer 2001] was used for learning the weights of the discriminative model. The sec-ond best system [Oh et al. 2009] in NEWS 2009 used a multi-engine approach wherein the outputs of multiple engines (Maximum Entropy Model, Condi-tional Random Fields and MIRA) were combined using different re-ranking functions. 3. TRANSLITERABILITY AND TRANSLITERATION PERFORMANCE In this section, we explore quantification of the ease of transliteration between a given language pair and using such knowledge for appropriate selection of language pairs for the composition of transliteration functionalities, and the selection of appropriate intermediate language for composition. 3.1 Language, Phonology, Orthography, and Ease of Transliteration In general, transliteration between a pair of languages is a nontrivial task, as the phonemic set of the two languages are rarely the same, and the mapping between phonemes and graphemes in respective languages is rarely one-to-one. However, many languages share a largely overlapping phoneme set (per-haps due to the geographic proximity or due to common evolution) and share many orthographic and/or phonological phenomenon. On one extreme, specific languages pairs have near-equal phonemes and an almost one-to-one mapping between their character sets, such as Hindi and Urdu [Malik et al. 2008], two languages from the Indian sub-continent. Other language pairs share simi-lar but unequal phoneme sets, but similar orthography possibly due to com-mon evolution, such as Hindi and Kannada, two languages from the Indian subcontinent, with many phonological f eatures borrowed from Sanskrit. This suggests that if we were to arrange language pairs on an axis according to the ease of transliterability between them then we would get a spectrum as shown in Figure 2. At one end of the spectrum would be language pairs like Hindi-Urdu, and at the other end would be a hypothetical pair of languages where every character of one could map to every character of the other, with most language pairs somewhere in between the two extremes.
 with the transliteration performance of a generic system for a given language pair, which in some sense would capture the ease of transliterability between them. First, we enumerate desirable qualities for such a measure: (1) rely purely on orthographic features of the languages only (and hence, eas-(2) capture and weigh the inherent ambiguity in transliteration at the char-(3) weigh the ambiguous transitions for a given character, according to the sure that we call Weighted AVerage Entropy ( WAVE ), as given in Equation 2. Note that WAVE will depend upon the n -gram that is being used as the unit of source and target language names, specifically, unigram, bigram, or trigrams. Hence, we term the measures as WAVE 1 , WAVE 2 or WAVE 3 , depending on whether uni-, bi-, or tri-grams were used for computing the measure. where, Mappings ( i ) = Set of target language uni-, bi-, or tri-grams that i can map to source characters unigram frequencies are computed based on the parallel names corpora outlined in Section 4.2, indicating that the unigram a is nearly 150 times more frequent than the unigram x in English names. Clearly, captur-ing the ambiguities of a will be more beneficial than capturing the ambiguities of x .The f requency ( i ) term in Equation 2 captures this and ensures that the un-igram a is weighed more than unigram x . In Table IV, some sample unigrams of the source language and the target unigrams that they map on to are shown; the numbers in brackets indicate the number of times a particular mapping was observed in the parallel names corpora detailed in Section 4.2. While both c and p have the same fanout of 2, the unigram c has higher entropy than the unigram p as the distribution of the fanout is much more dispersed than that of the unigram c .The Entropy ( i ) term in Equation 2 captures this informa-tion and ensures that c is weighed more than p . Hence, we maintain that the measure captures the importance of ha ndling specific characters in the source language and the inherent ambiguity in character mappings between the languages.
 with a small corpus. In Figure 3, we plot the WAVE 1 measures computed with 10 different samples of a 2,000 paralle l names corpus (a randomly selected subset of the 15,000 corpus) and the entire 15,000 parallel names corpus for various language pairs. The x-axis represents the WAVE 1 measure calculated from the 15,000 corpus and the y-axis represents a box and whisker plot based on the quartiles calculated from the 10 different samples of the 2,000 data. As can be seen the measures are highly corre lated, suggesting that even a small corpus may be sufficient to capture the WAVE n-gram measures.
 mum achieved quality of transliteration (for approximately 15,000 of training corpus) for the language pairs listed earlier. The x-axis plots the logarithm of the WAVE measure, and the y-axis the transliteration quality. We observe that as the WAVE measure increases the transliteration accuracy drops nearly linearly with logarithm of WAVE measure. In Figure 4, we present only the cor-relation between the WAVE measures and the transliteration quality achieved with a 15,000 training corpora. The two points in the top left corner in each of the plots represent transliteration between Hindi and Marathi languages that share the same orthography and have large one-to-one character mappings be-tween them. Significantly (as shown in Figure 4), we observe that different WAVE n-gram measures have similar effect on the transliteration quality, sug-gesting that even the unigram based WAVE measure captures the transliter-ability fairly accurately. Hence, for all subsequent experimentation, we used WAVE 1 , as the unigram measure captures a ny correlation as accurately as other WAVE n-gram measures.
 measure as more easily transliterable, and hence can be a candidate for either the first or the second component of any co mpositional transliteration systems involving one of these languages. Specific compositional transliteration experi-ments through an intermediate language and their performances are explored in the next section. 4. SERIAL COMPOSITIONAL TRANSLITERATION SYSTEMS In this section, we address one of the configurations of the compositional transliteration systems X  X erial transliterations systems. Specifically, we ex-plore the question  X  X s it possible to develop a practical machine transliteration system between X and Z, by composing two intermediate X  X  YandY  X  Zma-chine transliteration systems? X  The utility of the compositional methodology is indicated by how close the performance of such a compositional transliteration system is to that of a direct transliteration system between X and Z . 4.1 Serial Compositional Methodology It is a well-known fact that transliteration is lossy, and hence it is expected that the composition of the two transliteration systems is only bound to have lower quality than that of each of the individual systems X  X  YandY  X  Z, as well as that of a direct system X  X  Z. We carry out a series of compo-sitional experiments among a set of languages, to measure and quantify the expected drop in the accuracy of such compositional transliteration systems with respect to the baseline direct system. We train two baseline CRF based transliteration systems (as outlined in Section 2), between the languages X and Y, and between the languages Y and Z, using appropriate parallel names cor-pora between them. For testing, each name in language X was provided as an input into X  X  Y transliteration system, and the top 10 candidate strings in language Y produced by the system were further given as an input into sys-tem Y  X  Z. The outputs of this system were merged and re-ranked by their probability scores. Finally, the top 10 of the merged outputs were output as the compositional system output.

To establish a baseline, the same CRF based transliteration system (outlined in Section 2) was trained with a 15,000 name pairs corpora between the lan-guages X  X  Z. The performance of this system provides a baseline for a direct system between X and Z. The same test set used in the previous compositional systems testing was used for the baseline performance measurement in the di-rect system. As before, to avoid any bias, we made sure that there is no overlap between this test set and the training set for the direct system as well. The top 10 outputs were produced as the direct system output for comparison.
Additionally, we used the WAVE 1 measure to effectively select the transi-tion language between a given pair of languages. Given two languages X and Z, we chose a language that is easily transliterable to one of X or Z. The following experiments include both positive and negative examples for such transitions. 4.2 Data for Compositional Transliteration Systems In this section, we detail the parallel names corpus that were used be-tween English and a set of Indian languages for deriving correlation between WAVE n-gram metric and the transliteration performance between them. First, our transliteration experiments with the generic engine indicated that the quality of the transliteration increases continuously with data, but becomes asymptotic as the data size approaches 15,000 (see Figure 5) in all language pairs. Hence, we decided to use approximately 15,000 of parallel names cor-pora between English and the Indic languages (namely, Hindi, Kannada, and Marathi), in all our subsequent experiments. While the NEWS 2009 training corpus ranged from 6,000 to 10,000 parallel names, we enhanced this training corpus in each language pair of interest (specifically, En-Hi, En-Ta, and En-Ka) to 15,000 by adding more data of similar characteristics (such as name origin, domain, length of the name strings, etc.), taken from the same source as the original NEWS 2009 data. 6 For other language pairs (such as En-Ma) that were not part of the NEWS shared task, we created 15,000 parallel names cor-pora. We kept the test set in each of the languages the same as the standard NEWS 2009 test set. To avoid any bias, it was made sure that there is no over-lap between the test set with the training sets of each of the X  X  YandY  X  Z systems. 4.3 Transliteration Performance of the Serial Compositional Systems Table V details the experiments and the results of both the baseline direct systems and the compositional transliteration systems, in several sets of lan-guages. All experiments list the thre e quality measures, namely, Accuracy (ACC-1), Mean Reciprocal Rank (MRR) and the Mean F -Score ( F -Score) of both the direct and the compositional systems. For every experiment, a baseline system between the two languages (marked as X-Z) and the serial composi-tional system through an intermediate language (marked as X-Y-Z) are pro-vided. Finally, the change in the quality metric between the baseline direct and the compositional system, with respect to the quality of the baseline sys-tem, is also provided for every experiment.
 system (i.e., X  X  Y) will propagate to the second stage (i.e., Y  X  Z), leading to a considerable loss in the overall accuracy of the compositional system (i.e., X  X  Y  X  Z). However, as we observe in Table V, the relative drop in the accuracy is less than 10%. For example, the baselin e accuracy (ACC-1) of En-Ka baseline system is 0.368, where as the accuracy of the compositional En-Ma-Ka system is 0.347, a drop of a little more than 5%. The drop in mean reciprocal rank is under 12% and the drop in F -score is under 3%. The last system, namely the Ka-En-Hi, was chosen to illustrate the impact of a wrong choice of the intermediate language and is discussed specifically in Section 4.5. 4.4 Error Analysis in Serial Compositional Systems The results shown in Table V contradict our basic intuition of massive degrada-tion and perhaps indicate that the two systems are not independent. To identify the reasons for the better than expected performance, we performed an error analysis of the output of each of the components of the serial compositional transliteration systems, to isolate the errors introduced at each stage. produce results according to the benchmarked quality (with respect to the gen-eration of correct and inco rrect transliterated strings in language Y). If the output of Stage 1 is correct, then we exp ect Stage 2 to produce results accord-ing to the benchmarked quality of Stage 2 (i.e., Y  X  Z) system. On the other hand, when Stage 1 produces incorrect transliterations, we expect the Stage 2 system to produce completely erroneous output, as input itself was incorrect. Contrary to our intuition, we find that many of the erroneous strings in lan-guage Y were actually getting corrected in Y  X  Z transliteration system, as shown by many examples in Table VI. For example, in the fourth example in Table VI, the Kannada string ( sumitomo ) gets incorrectly transliterated as (sumitomo) instead of (sumithomo) ; however, for the second stage transliteration even this erroneous representation generates the correct English string (sumitomo) . This interesting observation suggests that even though the input to the Y  X  Z system is an erroneous input in language Y from X  X  Y system, it still contains enough information for the Y  X  Zsystem to generate the correct output in language Z. However, note that this is possible only if the bridge language has richer orthographic inventory than the target language. For example, if we use a language such as Arabic, which drops all vowels, as the intermediate language, then we will not be able to recover the correct transliteration in the target la nguage. In each of the successful bridge systems (that is, those with a relative performance drop of less than 10%) pre-sented in Table V, the bridge language has, in general, richer orthographic inventory than the target language.
 2, we performed an exhaustive error ana lysis in five different compositional transliteration systems. In each of the systems, we hand created a set of ap-proximately 1,000 three-way parallel test names to calibrate the quality at every stage of the compositional X  X  YandY  X  Z transliteration systems. In this three-way parallel set, for a given name in X, we created the correct equivalent names in languages Y and Z, so we could verify the correctness of the transliterations at each stage of the compositional transliteration system. The results are provided in the Tables VII through XI, where the rows rep-resent the performance of the Stage 1 system, and the columns represent the performance of the Stage 2 system. In each row, we segregated the correct and incorrect transliteration outputs from the X  X  Y system (in the rows) and ver-ified for each of the input (correct or incorrect) whether the Y  X  Z produced correct output or not. Hence, in Table VII, for example, the X  X  Ysystem produced 41% correct transliterations (i.e., 21.5% + 19.5%) and 59% incorrect transliterations (i.e., 11.8% + 47.1%). This is in line with the expected quality of the X  X  Y system. The first row corresponds to the correct and incorrect transliteration by the Y  X  Z system, in line with the transliteration quality of the Y  X  Z system, as the inputs were correct strings in language Y. While we expected the second row to produce incorrect transliterations nearly for all inputs (as the input itself was an incorrect transliteration in language Y), we find upto 25% of the erroneous strings in language Y were getting transliter-ated correctly in language Z (for example, about 11.8% among the wrong 59% input strings were getting corrected in Table VII).

We see the same phenomenon in each of the Tables VII through XI, indicating that some amount of information is captured even in the wrong transliterations in Stage 1 to result in the correct transliteration output by Stage 2. 4.5 Impact of WAVE Measure on Transliteration Quality In all these experiments (except the last Ka-En-Hi system) the intermediate language in the serial compositional transliteration system was chosen to be one that is easily transliterable from the source language or to the target lan-guage (i.e., low WAVE 1 scores). Table XII reports the WAVE scores of the two stages of the compositional system as well as the the WAVE score of the direct system. For example, the first row of Table XII discusses the case when Hindi was used as the intermediate language for English to Kannada transliteration. The first stage of this compositional system was an English to Hindi translit-eration system and the second stage was a Hindi to Kannada transliteration system. The WAVE 1 score of the direct system (i.e., English to Kannada) was 1.52 whereas the WAVE 1 scores for the first and second stages (i.e., English to Hindi and Hindi to Kannada, respectively) were 1.34 and 0.93, respectively. scores of the intermediate systems were generally smaller than that of the direct system, and the drop in accuracy of each of these compositional sys-tems was less than 10% when compared to the direct system. 7 The last row of Table XII shows that the WAVE 1 score of the direct system (0.78) was much less than the WAVE 1 scores of the intermediate systems (1.11 and 1.34). Cor-respondingly, Table V shows that in this case the drop in accuracy was much higher (42.3%). An empirical conclusion that we draw is that the constituent WAVE 1 measures, surrogates for transliterability, may suggest successful candidate pairs and may flag inappropriate candidate pairs for compositional systems. 4.6 Effect of Vowels in the Transliteration A closer error analysis revealed that vowels play a crucial role in the transliter-ation experiments as in nearly all the transliteration systems, approximately 60% of the errors were due to the incorre ctly transliterated vowels. We thus performed some oracle experiments to quantify the impact of correct translit-eration of vowels on Overall transliteration quality. First, using a given X  X  Y transliteration system, we generated transliterations in language Y for about 1,000 names in language X. The resulting quality of transliteration (indicated as ACC-1 without vowel Oracle in Tabl e XIII) was in line with the expected quality of the X  X  Y system. Next, we compared the output strings and the gold set, after ignoring all the vowel and combining matras from the generated transliteration strings in language Y and the gold reference set, presented as ACC-1 with vowel Oracle in Table XIII). Equ ivalently, we can say, that the con-sonants are provided by the X  X  Y system, and the vowels are inserted by an Oracle.
 provement in transliteration quality may be achieved by handling vowels cor-rectly in the transliteration between English and Indian languages and among Indian languages. This opens up a significant future research opportunity. 5. PARALLEL COMPOSITIONAL TRANSLITERATION SYSTEMS In this section, we address the parallel compositional transliterations systems, specifically, combining transliteration evidence from multiple transliteration paths. Our objective here is to explore the question  X  X s it possible to combine evidence from multiple transliteration paths to enhance the quality of a direct transliteration system between X and Z? X . The usefulness of such a composi-tional system is indicated by how much above the performance of such a system is to that of a direct transliteration system between X and Z . Any improve-ment in transliteration quality may be very useful in going beyond the plateau for a given language pair. 5.1 Parallel Compositional Methodology In this section, we explore if data is available between X and multiple lan-guages, then is it possible to improve the accuracy of the X  X  Zsystemby capturing transliteration evidence from multiple languages. Specifically, we explore whether the information captured by a direct X  X  Zsystemmaybe enhanced with a serial X  X  Y  X  Z system, if we have data between all the lan-guages. We evaluate this hypothesis by employing the following methodology, assuming that we have sufficient (  X  15,000, as detailed in Section 4.2) pair-wise parallel names corpora between X, Y, and Z. First we train a X  X  Zsystem,us-ing the direct parallel names corpora between X and Z. This system is called Direct System . Next, we build a serially composed transliteration system using the following two components: First, a X  X  Y transliteration system, using the 15,000 data available between X and Y, and, second a fuzzy transliteration sys-tem Y  X  Z that is trained using a training set that pairs the top-k outputs of the above trained X  X  Y system in language Y for a given string in language X, with the reference string in language Z corresponding to the string in language X. We call this system a Fuzzy System as it utilizes top-k (possibly incorrect) output in the intermediate language Y. We believe that even an incorrect out-put may contain sufficient information not captured in the direct system as evidenced by the error analysis in Section 4.4. We combine the evidence from these two systems X  X irect and fuzzy X  X or a given transliteration task between X and Z as follows: we merge the top-k outputs from the direct system, with the top-k outputs from the fuzzy system, using the following weighted average measure, and re-rank the results based on the above calculated scores. Note that the above formulation of combining the output of two systems is similar to that used by [Al-Onaizan and Knight 2001] for combining the output of a grapheme based system with a phoneme based system. A similar strategy was also used by Zhou et al. [2008] to re-rank the candidate transliterations by taking a weighted sum of the score assigned by a transliteration engine and the nor-malized hit-count obtained for a candidate transliteration using a Web search engine.
 5.2 Results of Parallel Compositional Methodology We employed the above strategy and tested parallel compositional methodol-ogy for combining transliteration for four language pairs and the quality of the results using the previously mentioned metrics X  X amely, Accuracy (ACC-1), Mean Reciprocal Rank (MRR) and Mean F -Score ( F -Score) X  X re shown in Table XIV. In each of the experiments, the metrics for four systems are reported X  X he direct (line 1) and fuzzy (line 2) components of the parallel com-positional systems, and the overall quality once combined (line 3). The quality of the direct system (line 1) provides the baseline for the corresponding parallel compositional transliteration system. The  X  parameter is set to 0.4 for the first two systems and to 0.6 for the last two systems (as explained in Section 5.3).
It is surprising that there is an increase in the ACC-1, up to 8%, from the direct X  X  Z system, by combining evidence from fuzzy X  X  Y  X  Zsystem. Such improvement in transliteration quality suggests that combining evidence using parallel composition of transliteration engine may be productive, and may help go above the quality plateau achieved in direct systems. 5.3 Effect of Varying  X  To study the effect of lambda on the quality of the composite system, we varied it from 0 to 1. A value of zero means only the fuzzy system X  X  output was used and a value of 1 means only the direct system X  X  output was used. Figure 6 shows a plot of the accuracies obtained for different values of  X  .Weobserve that in each case, the best performance was obtained when  X  was between 0.4 and 0.6. Further, the optimum value of  X  depended on the quality of the direct system and the fuzzy system. Typically, if the quality of the direct system was better than the quality of the fuzzy system then the best results were obtained for  X  =0 . 6 (i.e., when more weight was given to the output of the direct system). An example of this is the compositional system obtained by combining the Ka-En direct system with the Ka-Hi-En compositional system. On the other hand, if the quality of the fuzzy system was better than the quality of the direct system then the best results were obtained for  X  =0 . 4(i.e.,when more weight was given to the output of the fuzzy system). An example of this is the compositional system obtained by combining the Hi-En direct system with the Hi-Ma-En compositional system. 6. EFFECTIVENESS OF COMPOSITIONAL TRANSLITERATION IN A In this section, we demonstrate the effectiveness of our compositional translit-eration system on a downstream application, namely, a Crosslingual Informa-tion Retrieval (CLIR) system. We outline a standard state-of-the-art CLIR sys-tem for crosslingual document retrieva l from a standard test collection. We specify the experimental set up and report the performance of the CLIR system integrated with compositional transliteration system, compared with a base-line integrated with a direct transliteration system. 6.1 CLIR System We used a CLIR system that has been fielded for FIRE 8 2008 shared task for the CLIR experiments. Briefly, this CLIR system translates a given Hindi query ( q s ) into English ( q t ) using a probabilistic translation lexicon: where, Similarity of the translated query an d a target document is measured using a Kullback-Leibler divergence-based approach for scoring and ranking the docu-ments, as follows: where, Details of our CLIR system are available in Udupa et al. [2008]. This system was the best performing CLIR system between Hindi and English, with a MAP score of 0.4526, among a field of eight participants in FIRE 2008. 6.2 Training and Test Document Sets for CLIR Experiments The standard document collection used for FIRE 2008 shared task was used for all our CLIR experiments. While the FIRE 2008 collection included documents in both English and multiple Indian languages, we used only Hindi to English portion of the FIRE 2008 CLIR experiments. The target document collection consists of 125,638 news articles in Indian English, from The Telegraph (Cal-cutta edition), gathered over a period of four years between 2004 and 2007. We used Hindi as the language of the query, specifically the topics 26-75 from the FIRE 2008 collection. All the three fields (title, description, and narration) of the topics were used for the retrieval, as this setting would include all names in the query; note that names are the ones that are handled poorly by CLIR systems, and best helped by transliteration modules. Since the collection and topics are from previous years, their re levance judgements were also available as a reference for automatic evaluation. We used only the textual content of the documents for indexing and indexed only non-empty documents. The stop words are removed from the text while indexing and the words were stemmed using Porter Stemmer [Porter 1980]. 6.3 Linguistic Resources Used for the CLIR System We used primarily the statistical dictionaries generated by training statis-tical word alignment models on an existing Hindi-English parallel corpora (  X  100,000 parallel sentences between English and Hindi, consisting of about 70,000 words in English vocabulary and about 50,000 words in Hindi vocabu-lary), using the GIZA++ [Och and Ney 2003] tool. We used five iterations of IBM Model 1 and 5 iterations of HMM, retaining only the top four translations of every source word, along with their probability measures. 6.4 Integrating Machine Transliteration Systems in CLIR As with any CLIR system that uses translation lexicon, we faced the problem of out-of-vocabulary (OOV) query terms that need to be transliterated, as they are typically proper names in the target language. First, for comparison, we used the above mentioned CLIR system with no transliteration engine and mea-sured the crosslingual retrieval perfo rmance. Clearly, the OOV terms would not be converted into target language, and hence contribute nothing to the re-trieval performance. Second, we integrated a direct machine transliteration system between Hindi and English, which is expected to provide the correct transliterated strings in English, only in line with its transliteration perfor-mance. We report this performance as the baseline direct transliteration sys-tem performance. Third, we integrate, instead of a direct system, a set of serial compositional transliteration systems between Hindi and English, transition-ing through different intermediate languages, namely Marathi and Kannada, and reported the CLIR performance for each of the compositional path. Finally, we integrate a parallel compositional transliteration system, through Marathi as an intermediate language, where the results are combined with  X  =0 . 4, the best value as outlined in Section 5.3 for Hi-Ma-En system, and the CLIR performance measured and reported. 6.5 CLIR with Transliteration Systems Evaluation The results of the above experiments a re given in Table XV. The current focus of these experiments is to answer the question of whether the compositional machine transliteration systems used to transliterate the OOV words in Hindi queries to English (by stepping through an intermediate language X  X arathi or Kannada) performs at par with a direct transliteration system.
 grated with different transliteration engines X  X oth direct and compositional X  perform on the standard FIRE 2008 data set. For these experiments, we used top-n ( n =1 , 5 , and 10) output of the integrated transliteration engine, and the results are reported separately. The following guide specifies the systems reported. (1) Baseline. The baseline CLIR system with no transliteration engine inte-(2) D-Hi-En. The baseline CLIR system, integrated with a direct machine (3) S-Hi-Ka-En. The baseline CLIR system, integrated with a serial composi-(4) S-Hi-Ma-En. The baseline CLIR system, integrated with a serial composi-(5) P-Hi-Ma-En. The baseline CLIR system, integrated with a parallel compo-transliteration system (D-Hi-En) gives better results over a CLIR system with no transliteration functionality. Significantly, we observe that most of the com-positional transliteration system perform on par or better than the direct sys-tem at each output level. While the choice of the transition language and the compositional methodology has an influence on CLIR system between a given pair of languages, the on par results indicate that the compositional transliteration systems can be effectively employed in practical downstream applications. Two-tailed paired t -tests were performed to check whether the improvements in the MAP scores obtained by using the Direct, Serial and Par-allel transliteration systems were statistically significant. The results marked with stars (**) in the 5th column of Table XV were found to be statistically sig-nificant with a confidence of 95% (p = 0.05). We observe that the improvements obtained by using the top five and top 10 transliterations were statistically sig-nificant. Also, the statistically significant results suggest that top five output produces the best improvement in the MAP scores, as expected in CLIR-type applications.
 systems showed that in some cases the compositional system does produce a better transliteration thereby leading to a better MAP. As an illustration, consider the query containing the OOV name { Ganguly } and the cor-responding transliterations generated by the different systems as presented in Table XVI. The direct D-Hi-En system generated was unable to generate the correct transliteration in the top five results whereas the serial S-Hi-Ma-En system and the parallel and P-Hi-Ma-En system were able to produce the correct transliteration in the top five re sults thereby resulting in an improve-ment in MAP for this sample query. We also observe that as more number of top-n transliterations are added, the resulting MAP scores decreases slightly, perhaps due to the noise added by the wrong transliterations during query translation. 7. CONCLUSIONS AND FUTURE RESEARCH DIRECTIONS In this article, we introduced the idea of compositional transliteration systems, where multiple transliteration components were composed, either to provide new transliteration functionality, or to enhance the existing transliteration quality, between a given pair of languages. Specifically, we proposed two dis-tinct configurations X  X erial and parallel X  X or compositional systems. The se-rial compositional transliteration systems chained individual transliteration components in a serial manner, to enable creation of transliteration functional-ity for a given pair of languages with no parallel names corpora between them. Specifically, a transliteration system X  X  Z may be created, by composing X  X  YandY  X  Z transliteration components serially. Next, we explored the parallel compositional transliteration systems, which aggregated the translit-eration evidence from multiple transliteration paths to improve the quality of a given transliteration system. Specifically, the quality of transliteration of X  X  Z system may be improved by combining evidence from X  X  Y  X  Z systems.
 ation (which we termed as transliterability between a given ordered language pair. We show how such a measure may help in designing serial compositional systems with minimal loss of quality. Further, such measure might help identi-fying appropriate languages between which parallel corpora needs to be devel-oped, thereby paving way for a less resource intensive approaches for providing transliteration functionality among a set of n languages.
 hensive set of experiments among English and three Indian languages, namely, Hindi, Marathi, and Kannada. We conducted an extensive set of experiments to quantify any change in the transliteration accuracy between a given pair of languages. First, we showed empirica lly that, quality-wise, the serial com-positional systems do not degrade drastically, compared with baseline direct transliteration systems: The relative drop in accuracy of appropriately de-signed compositional systems is less than  X  10% of that of the corresponding direct systems, in general. Second, we p erformed an extensive stage-wise error analysis of the compositional systems, and identified that significant fraction of errors (  X  25%) caused by the first stage transliteration system of the compo-sition is getting corrected by the second stage transliteration system, provid-ing an insight into the benefits of composition of transliteration components. Based on this insight, we designed parallel compositional transliteration sys-tems, that combined evidence from a se rial compositional system to a direct system, to improve the quality of the direct system. Empirically, we showed that there is a improvement of up to  X  8% in transliteration accuracy achieved by this methodology, over the direct transliteration systems. While the compo-sitional methodology uses multiple datasets, each component may participate in many compositional systems thereby amortizing the development cost. In addition they may enable transliteration functionalities that may not be pos-sible with the existing datasets or improve transliteration quality above and beyond direct systems.

Finally, we showed that such compositional transliteration systems X  X oth serial and parallel X  X ay be used in practical situations effectively. We showed that a CLIR system working on the standard FIRE 2008 test collection between Hindi and English is helped by the integration of the compositional transliter-ation systems significantly, showing up to  X  8% improvement in MAP scores over the same CLIR system with no transliteration component. More signif-icantly, these improvements are in-par with, and sometimes better than, the same CLIR system that had been integrated with a direct transliteration sys-tem between Hindi and English, thus establishing the practicality of using compositional transliteration systems. 7.1 Future Research Avenues Transliteration is an important research area for downstream applications such as CLIR or MT. However, there are many situations in which translit-eration functionality needs to be developed among a set of languages, for polit-ical, social, or economic reasons. Compositional systems provide a viable and practical solution in resource-scarce situations.

We plan to pursue the compositional transliteration functionality in several directions: First, we plan to expand the set of languages to explore the scala-bility of the compositional approaches for a diverse set of languages. Second, given a set of n languages, we would like to explore a principled way of select-ing language pairs among the n languages, between which the transliteration corpus may be developed in order to balance the resource requirement and the transliteration accuracy. Finally, we would like to explore complex com-positional approaches involving more transliteration components arranged in more complex topologies.

Compositional systems may provide an effective way of enabling transliter-ation functionality among a group of languages, by reducing the need for de-veloping resources in all combinations of languages, or using more effectively the available parallel corpora between languages. Ultimately, such approaches may help in reducing the digital divide that exist in many resource-poor parts of the world.
 We thank the NEWS 2009 organizers for the transliteration datasets and the FIRE 2008 organizers for the CLIR datasets. We thank K Saravanan for his help in setting up and performing the CLIR experiments. Finally, we thank the anonymous reviewers for their thorough and diligent review comments which have improved the quality of this article significantly.

