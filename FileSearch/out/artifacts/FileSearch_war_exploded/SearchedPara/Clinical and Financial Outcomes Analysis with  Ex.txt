 Existing patient records are a valuable resource fo r automated outcomes analysis and knowledge discovery. However , key clinical data in these records is typically recorde d in unstructured form as free text and images, and most structured c linical information is poorly organized. Time-consuming i nterpretation and analysis is required to convert these records i nto structured clinical data. Thus, only a tiny fraction of this r esource is utilized. We present REMIND, a Bayesian Framework for Reliabl e Extraction and Meaningful Inference from Nonstructu red Data. REMIND integrates and blends the structured and uns tructured clinical data in patient records to automatically c reated high-quality structured clinical data. This structuring allows existing patient records to be mined for quality assurance, regulatory compliance, and to relate financial and clinical fa ctors. We demonstrate REMIND on two medical applications: (a) Extract  X  X ecurrence X , the key outcome for measuring treatme nt effectiveness, for colon cancer patients (ii) Extra ct key diagnoses and complications for acute myocardial infarction ( heart attack) patients, and demonstrate the impact of these clini cal factors on financial outcomes. H.2.8 [Database Management]: Database Applications -Data Mining. Data Mining, Temporal Reasoning, Bayes Nets, HMMs. Hospitals collect vast amounts of electronic inform ation during their daily operations, as they treat and bill pati ents. These records are a valuable source for outcomes analysis, knowle dge discovery, and evaluating the quality of patient care. However , they are underutilized because of the difficulty of analyzin g the clinical information in existing hospital patient records. T his is illustrated in the example below. Early detection of breast cancer is one of the lead ing issues in healthcare. The standards of care demand that physi cians inform women who are at risk for breast cancer (typically those over 40), that they need to undergo an annual screening mammo gram. This applies to all women seen at the hospital (e.g., a doctor X  X  visit for high fever). Physician compliance with this guideli ne is an important measure of hospital quality. It is quite simple to query the database to gather all hospital records of women over age 40, and then to check how many of them have had a mammogram. This fraction, however, is rarely meaningful for measuring compliance. For instance, a woman may have already had a mammogram at another hospita l, or might reject the physician X  X  advice. For others, a differ ent examination may be medically indicated. This information is typ ically present in unstructured form, namely, as free text in transcribed doctors X  dictations. The common way to measure compliance wi th this guideline is for a medically qualified person to re ad these patient records, and determine if the physician has informe d the patient about a mammogram, and has documented why it was no t done. Given that this very basic information cannot be de termined, it is not surprising that more complex questions about pa tient care cannot be answered. For instance, it is difficult t o tell (without reading the radiologist X  X  report) which mammograms have abnormal findings, and of these patients, which hav e been correctly followed-up (with further imaging exams o r biopsy), and if positive, whether the patient was correctly trea ted for cancer. The fundamental problem addressed by this research is the lack of structured clinical data to support outcomes and qu ality analysis. Section 2 describes the  X  X ata gap X  in hospital pati ent records, its impact on KDD, and presents an abstraction of this problem into inference from multiple data sources. In Section 3 we describe REMIND (for Reliable Extraction and Meaningful Infe rence from Non-structured Data), a Bayesian reasoning framewor k that combines all available data in a principled fashion over time . REMIND uses easily available domain knowledge to co mbine information available from multiple sources at diff erent times, to overcome the inherently unreliable data in patient records. We demonstrate REMIND on two different medical applica tions. Section 4 provides results on many experiments for inferring the value of recurrence , a complex outcomes variable for cancer patients. First we demonstrate the value of incorpo rating temporal inference into classification: REMIND X  X  performance is superior to that of many classification and text mining meth ods. We also show that REMIND improves performance by incorporat ing information from multiple data sources (structured and unstructured) into the inference process, and that it is possible to incorporate the results of mining algorithms into R EMIND to learn domain knowledge parameters automatically. In Section 5, we present some preliminary results for using REMIN D on patients admitted to the ICU with a diagnosis of ac ute myocardial infarction (AMI or heart attack). By using REMIND f or the extraction, the hospital can obtain a more accurate picture of the impact of clinical conditions and complications on financial outcomes. We briefly review the rich body of relate d work in Section 6. Section 7 summarizes our approach and co nclusions. The breast cancer scenario shows that hospitals do collect some basic patient information in structured form, for e xample, in billing, insurance, lab, and pharmacy databases. Ho wever, most of the key clinical information is stored in unstructu red form: as free text in admission slips, progress notes, radiology reports, cardiologist findings, etc., as images in various i maging studies (X-Ray, MR, CT, etc.), and possibly even as wavefor ms. This data requires medical interpretation and analysis before it can be used. Figure 1 illustrates the difficulty of getting high -quality structured clinical data in a usable form. Given this  X  X ata Ga p X , there are two possible routes for measuring quality and outco mes. (i) If analysis must be supported by the power of numbers (i.e., over many patient records), only the simplest of measure s can be computed, based upon already-collected patient data . As we shall see in Section 5, even this rudimentary analysis ca n be unreliable. (ii) If the analysis needs highly accurate or compl ex data, medically qualified personnel must manually extract this from patient charts. Obviously, this is feasible only fo r a small number of patients. For instance, hospitals must manually review only 75 patient charts monthly to comply with reporting req uirements for JCAHO [11], the regulatory body for US hospitals. At present there is no solution that allows for acc uracy in the context of large numbers of patient records by comb ining both structured and unstructured data . At first glance, it may seem difficult to believe t hat electronic clinical repositories (illustrated by the cloud in Figure 1) are so poorly organized to be unusable. However, for a phy sician, free text dictations are the most efficient way to docum ent patient history and the complexities of an individual case. Further, other physicians can understand these notes when treating the patient. Thus, the  X  X ata Gap X  does not hinder the practice o f medicine. From a knowledge discovery point of view, it is fru strating that existing patient data cannot be mined. Despite ongo ing efforts {SNOMED}, there are no uniformly accepted standards t hat are universally used. The gold standard for the medical analysis and discovery is based on prospective data that is carefully collected in clinical trials. Any retrospective analysis of hospital records requires manual review of charts, or time-consuming data collection efforts to capture structured data. The reality is that the merest fraction of existing patient data is used fo r KDD activities. REMIND aims to  X  X ill this data gap X  by automaticall y creating high quality structured clinical data from existing patient records. In some sense, this can be viewed as  X  data discovery  X  rather than knowledge discovery. However, once the structured d ata is created, it leads to new knowledge, often by a simp le inspection of the structured data, or via first-order correlat ions. We provide two examples of simple knowledge discovery below. (1) In previous work [25][26], we analyzed treatmen t of colon cancer patients in the first 6-9 months (that is wh en proper application of chemotherapy guidelines can improve survival by 20 percentage points [8]). By extracting process an d guideline information we discovered a key bottleneck in the t reatment of patients. The hospital has since changed the way th ese patients are treated; which is estimated to save up to 5 lives e very year. (2) Analyzing the original structured data used in our experiments in Section 5, may lead to the mistaken impression t hat diabetes (as a complication) has little impact on heart attack o utcomes. (This is due to errors in coding diagnoses and complications .) After REMIND has automatically extracted the clinical dat a, a simple inspection reveals that diabetic AMI X  X  have much hi gher costs and lengths-of-stay than non-diabetic AMI X  X . Based on t his the hospital can begin specialized programs to treat di abetic AMI X  X . The RODS [29] (Real-time Outbreak and Disease Surve illance) system was commissioned at the last Winter Olympics in an effort to detect a bio-terrorism event by analyzing emerge ncy room patient records. Extracting structured information from the existing patient records can further help in this d etection task. Further once the structured clinical data has been extracted from the hospital records, that data itself can be mined . For instance, a large database of cancer patients for whom the outc ome is correctly extracted can be mined to determine the r isk factors and the impact of treatment variations (in that hospita l) on outcome. To summarize, we believe that the  X  X ata Gap X  in Fig ure 1, is the key bottleneck that prevents mining of hospital pat ient records. The REMIND framework uses easily available domain k nowledge to combine information from all available data to a utomatically create high-quality structured clinical databases. Data about real-world systems, particularly those w ith a high cost of failure, are often collected in multiple  X  data sources . X  The collected data may be stored in a structured format , such as tables in a relational database (i.e., in a structured data source), or as free text or images (i.e., in an unstructured data source). Often, critical process information is stored only in an u nstructured format; and occasionally may not be recorded reliab ly by any source. The performance task is to fill the  X  X ata G ap X , i.e., infer the values of key process variables as they change over time from the available data, using easily available domain k nowledge. We need to consider several issues. Each source may begin collecting data at a different time, and may record data at arbitrary points in time, not at evenly spaced time intervals . Data sources may have differing degrees of reliability. The stru ctured data sources are typically missing critical information (hence the need for combining information from all sources in the f irst place), and may also contain errors. The information in unstruc tured sources, such as free text, may be reliable when read (and u nderstood) by a human expert. However, information extracted by a c omputer from the same source (e.g., via natural language pr ocessing of the free text) may be unreliable; typically due to unce rtainties in the extraction, and sometimes due to errors/imprecision in the original free text. Furthermore, some information may be una vailable, because it is never recorded in electronic form. An d, finally, only approximate domain knowledge may be (easily) availa ble. This problem of inference from multiple data source s may be tackled in several different ways. One approach is to improve methods of data collection. Another is to develop b etter methods for extracting information from unstructured data. A third is to use very accurate domain knowledge (either from a domai n expert, or learning it from labeled data). REMIND is different , and yet complementary to the above, as better data collecti on / extraction, and improved domain knowledge will only improve our results. Our approach to inference with this data is to mode l the data as arising from a generative process, and combine prio r knowledge about this process with observations for a specific patient using Bayesian techniques. Patient data is collected in a hospital at arbitrary points in time, and these sampling instan ts vary from patient to patient. Hence, we model the processes o f progression of patients X  diseases and the collection of this da ta as continuous time processes that may be sampled at arbitrary ins tants. We consider a model wherein a patient has a state (for the disease of interest), and observations about the state and rel ated variables are stored in and may be collected from various data re positories. Let S be a continuous time random process taking values in  X  that represents the state of the system; note that S may be a combination of multiple variables. Let T ={t 1 , t 2 t &lt;t i+1 , be the n  X  X imes of interest when S has to be inferred. Let S refer to the sample of S at time t i  X  T . Note that T and n can vary for different realizations of the process. Let V be the set of variables that depend upon S . Let O be set of all (probabilistic) observations for all variables, v  X  V . Let O i be the set of all observations  X  X ssigned X  to t all observations about variables, v  X  V that are relevant for this time-step t i . Similarly, let O i (v) be the set of observations for variable v  X  X ssigned X  to t i . Let seq be a random variable in  X  n ; i.e., each realization of seq is a specific (legal) sequence &lt; S 1 , S 2 , .. S n &gt;. In the case when we are interested only in the valu e of a variable at a point in time (e.g., in the AMI example, we si mply wish to know if the patient really had an AMI), our goal is to estimate: When we wish to track the patient X  X  progress over t ime (e.g., for colon cancer recurrence), our goal is to estimate t he most likely state sequence, seq MAP , the maximum a-posteriori estimate of seq given O . We view S as a continuous time Markov process from which we observe non-uniform samples. Our implementation of REMIND assumes that S is a stationary Markov process, whereas variables, v  X  V that depend on S have conditional distributions (on the parent variable) that are non-stationary. However, our framework can be extended to handle even non-stationary Marko v processes. REMIND X  X  3-step process that estimates the distribu tion of the variable of interest V MAP (or seq MAP ) is summarized below. Our goal is to extract and combine information from all data sources. (1) Extraction step: information about the variables, v  X  V , is extracted from the data sources, and converted into a uniform representation, called probabilistic observations . These play the same role as likelihood findings in standard Bayesi an reasoning. Every observation o  X  O is assumed to be potentially incorrect. (2) Combination step: each observation is assigned to one time of interest, t i  X  T . Then each state, S i is estimated from O (3) Inference step: the inferences are propagated across time. In this step we produce probabilistic observations, o sources . Each o i is drawn entirely from a single piece of information in a data source (e.g., from a phrase i n a sentence, or a row in a database), and hence is assumed to be in herently undependable (either due to errors in the data or i n the extraction process). An observation o i is of the form &lt; NAME , DATE , DIST &gt; where NAME is an observed variable v  X  V , DATE is the date of the observation, and DIST defines a distribution over all possible values that can be taken by NAME given the observation. REMIND currently does extraction from 2 types of da ta sources. REMIND communicates with all databases using SQL. R EMIND is implemented in Java, and its built-in interface to relational databases (JDBC) allows uniform access to data in d ifferent DBMS. The results of executing a query on the datab ase, for instance, retrieving a lab test result, can be expr essed as another probabilistic observation; the DIST can encapsulate any combination of the inherent error associated with t he test (some tests need to be repeated to determine their accura cy), the uncertainty about threshold value (if reported as a qualitative result), or the likelihood of an error in the datab ase. Note that a null result of executing a query can also generate an element, for instance, about a procedure not being performed on a patient. Here the DIST can capture the likelihood that the procedure was performed at another institution. Notice that, in the above examples, uncertainty ari ses because the observation is drawn just once from a single data s ource. Repeated observations of the same variable, for exa mple, the same test repeated a week later, or confirmation in the doctors X  notes about a procedure, can change DIST , the a posteriori distribution for any variable. The REMIND interface partitions a document into sec tions based upon knowledge about the structure of the document. Observations, such as document date, can be extract ed from the structured sections (e.g., headers or footers). Eac h unstructured section is converted into a stream of tokens, via a standard lexical parser (JFlex, a Java implementation of FLEX). The tokens are then gathered into sentences (terminated by EOS tok en). Phrase-spotting Rules : We extract information from the token stream via phrase spotting, a simple and easy-to-im plement method from computational linguistics. Phrase spott ing is about as simple as it sounds! A phrase-spotting rule is a pplied within a single sentence. A rule encodes the knowledge that when a pattern is found in the document, then the extraction syste m should create a new observation (which is then used by the reason ing engine). The pattern in a rule is specified in a rudimentary phrase description language that allows a user to define p atterns of co-occurrence of words in a sentence. It can also enco de compound rules wherein one part of the pattern to be matched is the pattern of another rule. Moreover, it allows for encoding s ynonyms so that only one rule has to be written for all the sy nonyms of a particular word. When a rule is matched, then an ob servation is created for the specified variable with the specifi ed distribution e.g., a rule whose pattern is  X  X vidence X  &amp;  X  X ecurre nce X  and whose action is  X  X ecurrent (true, 0.8, false, 0.2) X  gener ates an observation stating that the value of the variable  X  X ecurrent X  is  X  X rue X  with probability 0.8 and  X  X alse X  with probab ility 0.2. These observations generated from the data sources are meant to encode the a posteriori distribution of a variable given the section of the data source that they are extracted from, an d are subsequently converted into likelihood findings for computation in the Bayesian Network. The primary focus of our interest is estimating wha t happened to the system across the duration of interest. Hence, a natural abstraction of the problem is to look for the best estimate of the sequence of system states across time, and the maxi mum a posteriori (MAP) estimate is one that maximizes the probabili ty of picking the correct sequence. Hence, given the o bservations that we have extracted, we would like to estimate t he a posteriori probability of each legal state sequence and pick t he best. This can be done in two steps, the first of which is com bination of observations at a fixed point in time and the propa gation of these inferences across time. We use a Markov Model to estimate the evolution of the patient X  X  state. As the observations about patients are space d non-uniformly across time, the standard discrete-time Markov appr oximations are not necessarily justifiable. In order to overco me this shortcoming, we model the process of evolution of t he patient state as a continuous-time Markov process from whic h we get to observe non-uniform samples. More specifically, the parameters we need to model are the dwell time in each state a nd the transition rates from each state to every other. In our current implementation, we consider the state to be a stati onary Markov process whereas the other variables that depend on it can have conditional distributions that are non-stationary. Our framework, however, can be modified to handle even the case of non-stationary state processes. Each piece of information that is extracted in the previous step is in the form of an a posteriori probability of a variable given the small context that it is extracted from. We can thu s have multiple such assertions from different parts of the same so urce and from different sources at any given instant in time. All the assertions about a variable at a given point in time are combi ned into one assertion in a straightforward manner by using Baye s X  theorem (under the assumption that the observations are ind ependent given the variable) as follows: We model the relationships between the set of all v ariables of interest using a Bayesian Network, which is used to infer the posterior distributions of all the variables at a g iven point in time given all the information at that time. For inferen ce across time, we may now use a standard dynamic programming based approach (e.g. the Viterbi algorithm, see [24] for details). Because we model the state process as being Markov, we have the following equation that connects the a posteriori probability of a sequence of samples of the state process given all the observations to the temporally local a posteriori probability of the state given all observations at each time instant. The experiments described in this section demonstra te various aspects of REMIND. First, by comparing REMIND with traditional classification and text mining algorith ms we show that incorporating temporal constraints can improve clas sification performance. Further, we show that REMIND combines structured and unstructured data, and that REMIND X  X  performance improves as additional data sources are available. Finally, we show that data mining algorithms can be  X  X lugged-into X  REMIND, to automatically learn the domain kno wledge used by REMIND. We begin by describing the medical application and the data. Colon cancer patients are grouped into 4 stages, su ch that each group is homogeneous in respect of survival [1][27] . Our study focuses on Stage III cancer patients: roughly 50% o f Stage III patients survive. (Most Stage I and II patients sur vive, and virtually all Stage IV patients do not.) The key ou tcomes variable for colon cancer is not death from cancer, but in f act, recurrence of cancer ; i.e., the cancer is cured and then returns. Becau se Stage III recurrence is almost invariably fatal, the key measure of performance is time to recurrence ; i.e., in how many patients did the cancer return, and for those, how long were the y disease free. We study 344 Stage III colon cancer patients at CCO , a cancer care hospital in Sudbury, Canada. The source of structured patient data is OPIS, an oncology patient relational databa se [4]. OPIS contains data about patient demographics, staging, diagnosis date, and administration of drugs. However, OPIS contains no reliable information about recurrence, the most important ou tcome. The principal source of unstructured patient data is doctors X  dictations. CCO began storing data in OPIS from 198 8, and began transcribing dictations in 1994. Our data is based on a snapshot of both data source s taken in January 2001. We restrict our study to patients for whom at least one dictation has been stored. The earliest and lat est a patient in our study began treatment was 1985 and November 200 0 respectively. Patients averaged 10.8 dictations, wi th a maximum of 53 dictations. 18 patients had just 1 dictation, and 54 patients had 3 or fewer dictations. (As indicated earlier, T and n vary for different  X  X ealizations of the process X , i.e., pati ents.) Domain knowledge (DK) for REMIND is fairly simple: Identify state S . Here S is a single variable,  X  X isease-state. X  Since the only transition of interest is from 0 (cured) t o 1 (recurrent), we define the legal sequences as 0* (disease-free) or 0*1* (recurrent). Our goal is to document the patient state as diagno sed by the doctor, i.e., to infer when the doctor diagnosed th e patient as recurrent. (Note the distinction between State and Stage.) Identify V , and the data sources from which they may be extracted . The variables drawn from doctors X  dictations are  X  X ecurrence X  and  X  X EA X  (a test result documented in the notes, and used as a marker for recurrence). OPIS X  X  DB-Che mo table provides information about chemotherapy treatment a nd its intent OPIS X  X  DB-Recur table provides information about re currence in cases where the hospital recorded this information.
 Identify extraction DK . 17 simple phrase spotting rules are used to extract information from the text, in addition t o 2 compound rules to detect negation and imprecision. SQL queri es detect the presence of chemotherapy and/or recurrence in OPIS.
 Define times of interest, T and assign observations to each time. days). Any observations between visits are assigned to the next visit. Recurrence diagnoses typically occur during visits (or are documented only at a patient visit, which amounts t o the same). Identify local dependencies . A simple Bayesian network between S and V is used to infer the posterior distribution s of S We model 5 variables of interest for every patient visit, namely assertions about recurrence, the patient X  X  CEA (if the test was performed), patient chemotherapy and if given, the intent of the chemotherapy, and the disease state. The conditiona l distributions in this network were assigned in consultation with domain experts. The network is replicated for each time in stant of interest with the state at a t being the  X  X ause X  of the stat e at t+1. Determine dwell times and transition probabilities . The medical literature provides survival curves for col on cancer patients [8]. We approximated these by an exponenti ally decaying curve (we could easily have used the actual curve a nd interpolated, but this was most convenient to imple ment). REMIND X  X  output is a sequence of the form 0* or 0*1 * (where  X 0 X  corresponds to not recurrent, and  X 1 X  to recurr ent). We assess performance in two ways: A. Patient classification: for accuracy of classifi cation of final B. Patient visit classification: classification acc uracy for each A related measure to [B] is Sequence prediction: if the patient recurred, how accurately did we estimate the date o f recurrence? The performance of REMIND is assessed with respect to  X  X round truth X   X  the classification made by a colon cancer specialist after reviewing the entire patient record for each patien t (a process that took the doctor about 3 months). 40% of these patie nts (138) were randomly chosen to be in the  X  training set . X  We reviewed the notes on half the training set to arrive at 17 gene ric text extraction rules, and then ran REMIND on the other half of the training set to adjust potential gross errors in the conditional probabilities in the model (both in consultation with a domain exper t). However, we refrained from any fine-tuning of the rules. For example, all phrase rules asserted observations with the same pr obability. After making all such adjustments, we ran the syste m over the remaining 60% (206) patients, using different combi nations of data sources and domain knowledge. Execution time w as not an issue: for all 206 of the test patients (i.e., exec uting all 3 steps for every test set patient), REMIND took less than 60 s econds total on a Pentium III 800 MHz laptop (most of the 60 sec onds was spent in disk access time to read the dictations). REMIND initially produced 7 classification errors o n the training set. However, on further review, we found that 2 of these were not classification errors, but in fact misclassificatio ns by our specialist (i.e., our specialist had overlooked a couple of fa ctors in patient history while determining ground truth  X  not uncomm on when a physician has to wade through a large patient recor d to get an accurate summary of the patient history). The resul ts presented herein are after correcting the ground truth for th ese mistakes. We have not yet done such an analysis for the Test Set . We also ran experiments on the data with classifica tion algorithms from Na X ve Bayes (NB)[20], k-Nearest Neighbor ( k -NN)[20], and Support Vector Machines (SVM)[3], and also with RAINBOW, a bag-of-words text-mining system[19]. REMIND X  X  use of a  X  training set  X  is different from the way any of these systems would use a training set. REMIND curr ently does no learning or model training. Instead the  X  X rainin g set X  is used to verify the phrase spotting rules and deal with any gross errors in the conditional probabilities  X  a largely manual pr ocess (except, see Section 4.6). Whereas, for any of the above aut omated systems we can easily run multiple trials, e.g., a 10-fold cross-validation, this is not feasible for REMIND. The do main knowledge (DK) has been developed on the training s et (40% of the patients), and cannot be  X  X orgotten X  and re-dev eloped for multiple runs (at least, not without considerable e ffort). To ensure like comparisons, all algorithms are trained and te sted on the exact same train/test splits used for REMIND. This first set of experiments compares REMIND with various mining algorithms. Whereas REMIND can perform infer ence directly from text documents and a database, most c lassifiers need the data to be in a standard attribute vector repre sentation. For this first set of experiments we restrict ourselves just to unstructured data: all labeling is done based solely on the doct ors X  dictations. There are (at least) two potential ways to label pa tient visits and patients from documents. One is to use the entire d ocument as input to the classifier (as we do with the bag-of-w ords text miner). Another alternative is to use natural language proc essing methods to extract features from each document, and label t he visit (or patient) based on these features. As traditional cl assification algorithms accept only fixed length feature vectors , we converted the observations from text that are used by REMIND into a vector that encodes how many times each pattern of interes t occurred in the document. The classifiers are trained on the 15 06 visits for the 138 patients in the training set. Table 1 shows cla ssification results with false positives, false negatives and e rror rates for the 2181 patient visits in the test set. 480 of the 218 1 visits are positive (recurrent). As expected in data of this complexity, 1-nearest n eighbor performs poorly, but stabilizes quickly for k&gt;=3. O n the other hand, we were initially pleasantly surprised by RAI NBOW X  X  performance. Doctors typically state diagnoses as n egations ( X  X here is NO evidence of metastatic cancer X ), and bag-of-words loses this information (either removing negations a s stop words or losing word position data). On inspection we found that many supplementary words, (e.g.,  X  X alliative X ) including many not in our phrase spotting rules were used for document di scrimination. (RAINBOW is marginally better with stop words, and those are the results reported.) Table 1 shows that REMIND X  X  performance is superior to the other systems. Note that the observations provided to REMIND after phrase spotting have the same information as the 68-feature vector provided to all the classification algorithm s (except RAINBOW). The additional information for REMIND is the Bayesian network, the temporal constraints imposed by the legal state sequences, and the dwell time and transitiona l probabilities derived from the survival curves in medical literat ure. We also used these algorithms to classify the patie nt as recurrent or not (i.e., final state=1?) based upon just the t ext data. For the classification algorithms we tried voting schemes b ased upon all visits, or just the final visit  X  the best performa nce was with a single 68-feature vector for each patient, produced by adding the 68-feature vectors for each visit. Similarly, for R AINBOW, we present the performance with one large document per patient, produced by concatenating all the documents for tha t patient. REMIND X  X  results for classifying visits came from t he same run that produced the visit classification. The state l abel of the final state was REMIND X  X  classification for each patient. As before we trained on the 138 patients in the train set. Table 2 shows the classification results on the 206 test set patients , of whom 58 are recurrent. Here we present only the best results for k -nearest neighbor (as in Table 1, performance is fairly similar for values o f k , except k =1). RAINBOW X  X  performance degrades in comparison to vis it classification. This reason for this may be that mo st recurrent patients typically have initial visits where they a re not recurrent. Thus, when we concatenate all dictations the set of words that help identify non-recurrent visits may be less usef ul in identifying non-recurrent patients. (Also there are only 138 tr aining patients Algorithm FP FN Errors Error % Na X ve Bayes 50 231 281 12.9 
SVM 32 273 305 14.0 1-NN 661 131 792 36.3 3-NN 67 284 351 16.1 5-NN 54 281 335 15.4 7-NN 33 294 327 15.0 9-NN 27 307 334 15.3 RAINBOW 126 166 292 13.4 REMIND 102 40 142 6.5 Algorithm FP FN Errors Error % Na X ve Bayes 19 3 22 10.7 
SVM 6 17 23 11.2 3-NN 2 26 28 15.6 BOW 23 18 41 19.9 
REMIND 5 10 15 7.3 comes from the Na X ve Bayes classifier built upon th e phrase-spotting feature vector used by REMIND. One of the motivating factors for REMIND is that cr itical information is often recorded redundantly in patien t records. For example, any of these observations can influence pr obability of concluding recurrence: statements in the dictations about recurrence, pain, or side-effects; structured clini cal data about chemotherapy drugs (might be for another cancer) or procedures (colonoscopy or surgery), billing information about referral to specialist, etc. Table 3 details the results for i nferring the patient visit classification, from different data sources. Table 3:Row 1 is the same as the REMIND entry in Ta ble 1; only the text documents are used as patient data. Table 3:Row 2 shows that adding in chemotherapy information from the Me dication database reduces the number of errors by 5. Finally adding information from OPIS X  X  own table for tracking recu rrence gets the best performance on the test data: almost 96% a ccuracy. Table 4 shows that REMIND X  X  performance for classif ying patient visits also improves as additional data sources are provided. The final rows in Tables 3 and 4 represent the best results for REMIND (or indeed any algorithm) on the 206 test se t patients. OPIS X  X  own DB-Recur table is supposed to track pati ent outcome. Table 5 shows how REMIND X  X  classification is signif icantly superior to the structured data recorded in OPIS. Table 5:Row 1 shows the results of 3 months of pain staking chart review by a cancer specialist. A glance at Table 5: Row 3 confirms the need for this effort  X  OPIS X  X  own DB-Recur tabl e, which is supposed to track this crucial outcome, is filled i n correctly for just 62% of the recurrent patients (37/58). If REMI ND X  X  classification were used (thus saving the manual ch art review), the number of total errors in OPIS would reduce from 23 to 10. We note here that at least 4 of our classification errors were unavoidable. In these cases, the specialist X  X  decla ration was based on paper records (doctors X  handwritten notes from p atient visits before 1994, which is when CCO began transcribing d ictations). We also assess REMIND X  X  accuracy for sequence predi ction. Table 5:Row 2 shows that REMIND correctly classifie s 54/58 recurrent patients. Figure 2 displays histograms th at provide the distribution of errors in the time of recurrence fo r patients that were actually recurrent and declared recurrent by R EMIND. The X-axis is the number of visits that our prediction missed by ( X 3E X  is  X 3 visits early X , and  X 2L X  is  X 2 visits late). F or 42 recurrent patients (out of 54) REMIND predicts the exact time of recurrence. Including correct predictions for 142/1 46 non-recurrent patients, REMIND predicts 89.3% of the pa tient sequences with complete accuracy. For the REMIND results shown above, all the domain knowledge (DK) has been manually derived. Notably, REMIND X  X  e xtraction from unstructured text is based upon phrase spottin g domain knowledge that is provided by physicians (and verif ied on the training set). However, RAINBOW X  X  better-than-expec ted performance in classifying visits (see Table 1) pro vides an opportunity to automatically mine the dictations in the training set to learn the phrase extraction DK used by REMIND. In these experiments, instead of using phrase spott ing to generate probabilistic observations for REMIND, we simply us e the RAINBOW X  X  classification of the patient visit as th e only probabilistic observation for that visit. Table 6 s hows preliminary results of plugging RAINBOW into the REMIND framewo rk for the 206 test patients. Algorithm Data Used FP FN Errors Error % BOW Text only 23 18 41 19.9 REMIND Text + DB 5 9 14 6.8 REMIND Text + DB 6 4 10 4.9 Truth 58 0 148 0 0 0 REMIND 60 6 146 4 4% 7% 
DB-Recur 37 1 169 22 &lt;1% 35% Table 6: Row 1 is identical to the RAINBOW results in Table 2 (i.e., using just bag of words to classify patients ). Row (2) shows that using REMIND X  X  temporal reasoning over these o bservations significantly reduces the errors by a factor of alm ost 2. (This is consistent with the observations in Tables 1 and 2, which show that incorporating temporal constraints significant ly improves classification. Now using REMIND we can also incorp orate the structured clinical data into the classification. T able 6:Row (3) shows that adding this information further reduces errors by about one-third. Although our preliminary results are not quite as good as the best REMIND results (replicated in Table 6:R ow 4, from Table 4), this is an exciting area of research that is worthy of further exploration. Table 7 shows similar results for classifying patient visits. In this section we present preliminary results on a n AMI (Acute Myocardial Infarction) cohort. AMI (or heart attack ) is one of the leading causes of sudden death in the Western world , and is the focus of many quality initiatives. Though we have 1 000 patient records available, these results are reported on ju st 52 patients (the total number for whom the ground truth is know n). In these set of experiments, we compare REMIND X  X  ac curacy in generating clinical diagnoses against the diagnoses assigned by the coders in the hospital X  X  billing department. We also show that by using REMIND X  X  code, (at least for this small sa mple) the hospital can get a much better idea of the impact o f clinical factors on financial outcomes. The patient cohort is selected randomly from over 1 000 patients admitted to the Intensive Care Unit (ICU) of the Un iversity of Pittsburgh Medical Center (UPMC) in 2001, whose pri ncipal billing diagnosis was 410.xx: this corresponds to a clinical diagnosis of acute myocardial infarction (AMI). Thi s billing diagnosis is assigned by coders in the hospital bil ling department after manually reviewing the patient chart (after d ischarge) to bill the patient X  X  insurance company. (These are coded u sing an internationally accepted standard for diagnoses, th e ICD-9 codes.) The Medical ARchival System (MARS) at UPMC is the s ource of all patient data. S tructured patient data from MARS includes patient demographic information (age, sex), length of stay in the ICU, all ICD-9 diagnoses codes, procedure codes, la b and pharmacy data. MARS also has unstructured doctors X  dictations including the discharge slip, progress notes from a ll doctors X  visits in the ICU, and cardiologists X  reports based on EKG waveforms. A physician manually reviewed the 52 patient charts to answer 3 specific questions: 1. Diagnosis: Did the patient really have an AMI? I t was 2. Co-morbidities: Did the patient have any related condition 3. Process: Of the diabetic AMI X  X , how many were tr eated The diagnosis of AMI was established according to t he MONICA [30] criteria (International Consensus Conference on Monitoring of Trends and Determinant of Cardiovascular Disease , Augsburg 1995). Variables taken into consideration included the presence or absence of changes typical of AMI in three categori es: clinical (symptoms that fit into the category of  X  X ardiac pa in X ), biochemical (increases in levels of enzymes in bloo d reflecting myocardial injury) and electrocardiographic (wave f orms of abnormal electrical activity diagnostic of myocardi al infarction). In each of these categories, changes were classifie d as abnormal, equivocal and normal, depending on strictly identif ied criteria. The final diagnosis was arrived at according to th e preponderance of the combined evidence from the three categories, as defined by the MONICA criteria. Note that arriving at this d iagnosis involves extracting and combining information from structured (lab) and unstructured (patient history, EKG report s) data sources. Similarly, the diagnosis of diabetes mellitus (DM) was established by combining information from lab and pharmacy reco rds, with corroborating evidence from the patient history. We developed and verified phrase spotting rules and the MONICA criterion on 25 patients. Then REMIND was ru n on the remaining 27 patients. Because there was no signifi cant difference in REMIND X  X  performance, all experimental results a re presented on the entire data set. Table 8 compares the hospital billing codes with Gr ound Truth, and also REMIND with ground truth for diagnosis of AMI and Diabetes Mellitus (DM). Whereas the diagnostic accu racy of the coded information is only 83% for AMI and 90% for D M, results based on REMIND are much closer to Ground Truth (90 % and 95%, respectively). Thus, of the 52 patients coded as AMI, only 43 actually fit the MONICA criteria for AMI (Defini te, Probable or Possible). In comparison, REMIND correctly iden tifies 8 of the 9 patients with No AMI. Of the 52 patients, 19 had diabetes, based on the Ground Truth. REMIND makes only one d iagnostic error, compared to 5 in the coded information. Next we compare the impact of incorrect coding on t wo key financial outcomes: Length of Stay (LOS) and Charge s. LOS Algorithm Data Used FP FN Errors Error % REMIND Text + DB 61 55 116 5.3 
REMIND Text + DB 51 41 92 4.2 derived from coded information in all 52 patients c oded, as having an AMI is about 0.5 days less than the Groun d Truth. (This is because 9 patients who actually don X  X  have an AMI, but have been incorrectly coded as having an AMI, are i ncluded in computing the Average LOS) Table 9 shows that using the diagnosis extracted by REMIND achieves much greater accuracy, being only 0.1 days off the truth. Similarly, code d information leads to an underestimation of charges incurred in AMI patients by about $5000, whereas REMIND is only off by ~ $15 00. The errors in coded information regarding AMI and D M compound the underestimation of both LOS and Charge s in diabetics with AMI. Thus, coded information would lead to the conclusion that LOS for diabetics was 0.6 days less than for non-diabetics, and charges incurred were lower by ~$26, 000. In actual fact (Ground Truth), diabetics stayed an average of ~4.5 days longer , and incurred an additional ~$15,000 in extra charges. REMIND was much closer to Ground Truth, correctly i dentifying that diabetics both stayed longer (by ~5 days), and incurred higher charges (by ~$21,000) (In addition to the above, RE MIND enabled the identification of patients with diabete s who achieved good, moderate, or fair control of their blood suga rs during their hospital stay and in the immediate peri-event perio d of the AMI.) Table 10 demonstrates the value of REMIND in correc tly identifying specific diagnostic categories of patie nts for outcomes research. They also show the hazards of plotting c ost-saving strategies and resource allocations based on electr onically coded information. For instance, the results for LOS and Charges based on the coded information would lead to the conclusi on that patients with diabetes do not pose a problem with L OS or Charges, and that no specific resource allocations need be made for the care of diabetics with AMI. Ground Truth r evealed exactly the opposite. This establishes the utility of REMIND, which paralleled Ground Truth, in correctly identif ying and analyzing outcomes in a large cohort. Our work draws heavily on earlier work on Bayesian networks and graphical models (see [12] for an overview). He re we briefly list some temporal reasoning methods in medicine (s ee [6] for a extensive bibliography) that are similar to REMIND in some aspects. Ngo et al [23] describe a temporal probabi listic reasoning method via context-sensitive model construction. Be llazi et al [2] describe a system that uses a Dynamic Bayesian Netw ork to analyze the blood glucose level of a patient over a time interval. Kayaalp et al [15] use structured information to pr edict probabilities of survival for ICU patients. Other r elated research [10][14][16] deals with representing temporal data and enforcing temporal integrity. Clearly, far superior methods to phrase spotting ma y be used to extract information from free text. Our research fo cus is the combination of extracted evidence, which is why we used a simple method. Clearly, using any of a standard par t-of-speech tagger, better natural language parsing methods, or augmenting the aliases with a lexical reference [7] should imp rove performance. Taira et al [28] have done research on automatic structuring of radiology reports (which is of direc t relevance for the illustrative example in Section 1). REMIND is i mplemented so that other extraction (and reasoning) methods ca n be easily plugged into REMIND (see Section 4.6). REMIND can clearly benefit from using better Natura l Language Processing methods [17] than phrase spotting. Of di rect relevance is the analysis of doctors X  dictations by Chapman [ 5] which identifies the 7 most common uses of negation in do ctors X  dictations. Augmenting our aliases with a general l exical reference [7] or a medical language dictionary (SNOMED) shoul d improve performance. Furthermore text-mining research to id entify relevant documents[22] may help eliminate irrelevan t documents that are mixed in with doctors X  dictations. DISCOTEX [21], like REMIND, extracts information fr om text, and integrates it via data mining. DISCOTEX focuses on learning rules, whereas REMIND uses domain knowledge for dat a mining. REMIND exploits the inherent redundancy in medical patient records. Despite the presence of incorrect observat ions, by performing inference over the entire set of observa tions and combining them with the domain knowledge (DK), REMI ND can reach the correct conclusion. In our implementation, the parameters of the model were obtained from domain experts. Section 4.6 shows that we can mine the training set to learn the extraction knowledge to r eplace the phrase spotting DK used by REMIND. It should also be possi ble to mine the training data set to automatically learn other DK: for instance, the conditional probabilities in the Bayesian netwo rk [9], its structure, and the dwell times and transitional pro babilities. The manual process of acquiring DK is not particula rly time-consuming. We have investigated the sensitivity of REMIND X  X  performance with respect to model parameters (e.g., by varying the confidences attached to text extraction rules, and by performing rule ablation experiments). REMIND is re latively insensitive to the exact parameter values indicatin g that these can be acquired relatively easily. We anticipate 2-4 we eks for each new application. This time will further reduce as w e gain more experience, and develop tools to help verify and le arn new DK. Furthermore, once the DK is acquired it can be used repeatedly at the same hospital without additional effort. For in stance, the UPMC study gives us access to 3000 patient records for AMI alone, for just the last 2 years. Once we build a s tructured database for 3000 AMI patients, not only can it be used for outcomes and quality analysis at UPMC, it can be fu rther mined to learn patterns about variations in treatment, an d their impact. Outcomes Patient-type CODERS Truth REMIND (days) Non-
Charges The real bottleneck for REMIND is not the DK  X  the architecture is designed so that core REMIND functionality and D K can be transferred to different hospitals. Interfacing to patient records in different hospital IT systems (some are home grown) is arduous. The two applications test different aspects of REMI ND. For colon cancer, our task is to determine when the doctor di agnosed recurrence  X  not when the patient actually recurred , or could have been diagnosed, but to identify the time the doctor diagnosed recurrence (treatment can only begin after diagnosi s). For AMI, our task is to find the correct diagnosis from inde pendent clinical factors, and in fact, to correct any errors in codi ng the diagnosis. In conclusion, we have proposed a general framework for performing Bayesian inference on random processes t hat are sampled at arbitrary time instants by integrating i nformation from structured and unstructured data sources. We have a lso demonstrated a successful application of REMIND for extracting structured information for stage III colon cancer p atients and for AMI patients. [1] Beahrs, O.H., Henson, D.E., Hutter, R.V.P.,Kennedy, B.J. [2] Bellazzi, R., Larizza, C., De Nicolao, G., Riva, A. , Stefanelli, [3] Burges, C.J.C., A tutorial on support vector machin es for [4] Cancer Care Ontario. OPIS, The Oncology Patient [5] Chapman, W., Bridewell W., Hanbury P., Cooper, G., [6] Combi, C., Shahar, Y. Temporal Reasoning and Tempor al [7] Fellbaum, C., WordNet: An Electronic Lexical Databa se. [8] Fleming, I.D., Cooper, J.S.,Henson, D.E., Hutter, R .V.P., [9] Heckerman, D. A tutorial on learning with Bayesian [10] Horn, W., Miksch, S., Egghart, G., Popow, C., Paky, F. [11] Joint Commission on Accreditation of Healthcare [12] Jensen, F.V. An introduction to Bayesian Networks. UCL [13] Johnson, D.B., Taira, R.K, Zhou, W., Goldin, J.G., Aberle, [14] Kahn, M., Fagan, L., Tu, S. Extensions to the Time-Oriented [15] Kayaalp, M., Cooper, G. F., Clermont, G. Predicting ICU [16] Larizza, C., Moglia, A., Stefanelli, M. M-HTP: A Sy stem for [17] Manning, C.D., Schutze, H. Foundations of Statistic al [18] McCallum, A., Freitag, D., Pereira, F. Maximum Entr opy [19] McCallum, A.K., BOW: A toolkit for statistical lang uage [20] Mitchell, T., Machine Learning. McGraw Hill, 1997. [21] Nahm, U.Y., Mooney, R.J. A Mutual Beneficial Integr ation [22] Nigam, K., McCallum, A., Thrun, S., Mitchell, T. Le arning [23] Ngo, L., Haddawy, P., Krieger, R.A., Helwig, J. Eff icient [24] Rabiner, R.L. A Tutorial on Hidden Markov Models an d [25] Rao, R. B., Towell, G.G., Miller, M., Schmuecking, I., [26] Rao, R.B, Sandilya, S, Niculescu R, Germond C., Geo l A, [27] Sobin, L.H., Wittekind, C., TNM Classification of m alignant [28] Taira, R., Soderland, S.,Jakobovits, R, Automatic S tructuring [29] Tsui F-C, et al . Data, Network, and Application: Technical [30] Tunstall-Pedoe H., The World Health Organization 
