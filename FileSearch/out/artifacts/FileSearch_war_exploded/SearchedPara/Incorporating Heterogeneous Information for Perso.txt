 A social tagging system provides users an effective way to collaboratively annotate and organize items with their own tags. A social tagging system contains heterogeneous in-formation like users X  tagging behaviors, social networks, tag semantics and item profiles. All the heterogeneous infor-mation helps alleviate the cold start problem due to data sparsity. In this paper, we model a social tagging system as a multi-type graph. To learn the weights of different types of nodes and edges, we propose an optimization frame-work, called OptRank. OptRank can be characterized as fol-lows:(1) Edges and nodes are represented by features. Dif-ferent types of edges and nodes have different set of features. (2) OptRank learns the best feature weights by maximizing the average AUC (Area Under the ROC Curve) of the tag recommender. We conducted experiments on two publicly available datasets, i.e., Delicious and Last.fm. Experimen-tal results show that: (1) OptRank outperforms the existing graph based methods when only &lt; user, tag, item &gt; relation is available. (2) OptRank successfully improves the results by incorporating social network, tag semantics and item pro-files.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Information Filtering, Retrieval Models, Selection Process Algorithms Recommender System, Social Tagging System
In social tagging systems, users can annotate and organize items with their own tags for future search and sharing. For e xample, users can annotate and share Web pages in Deli-cious 1 . Besides Delicious, there are many other social tag-ging system like Last.fm 2 and YouTube 3 in entertainment domain and CiteULike 4 in the research domain.

Personalized tag recommendation is the key part of a so-cial tagging system. When a user wants to annotate an item, the user may have his/her own vocabulary to organize items. Personalized tag recommendation tries to find the tags that can precisely describe the item with the user X  X  vocabulary.
A social tagging system, as shown in Figure 1, contains heterogeneous information and can be modeled as a graph: While the inter-relation has been well studied in previous work [4, 5, 12, 13, 16, 17], few work tries to incorporate all the intra-relation into a unified model. Incorporating the intra-relation may solve the cold start problem due to data sparsity. Users in a social network may influence each other by sharing some annotated items. Semantically related tags may co-occur to describe an item. Items that have similar contents may be annotated with the same tag.

When a user u wants to annotate an item i , the recom-mended tags should meet two requirements: (1) Highly rele-vant to user u because users have their own way to organize items. (2) Highly relevant to item i because tags should pre-cisely describe the item. To rank the tags, we can perform h ttp://delicious.com http://www.last.fm http://www.youtube.com http://www.citeulike.org a random walk with restart at user u a nd item i to assign each tag a visiting probability, which is used as the ranking score. Only tags that are both relevant to u and i can get high scores. However, two problems arise when the random walk is performed on the multi-type graph:
To solve the above two problems, we propose an optimiza-tion framework called OptRank. OptRank can be charac-terized as follows:
Although graph based methods have been studied in the field of personalized tag recommendation by many researchers [4, 5, 17], most of them belong to the unsupervised approach, in which the edge weights and restart probabilities of u and i are empirically assigned. Inspired by the recent development of semi-supervised learning [3] and graph-based learning [1], we are able to turn the existing unsupervised graph-based methods into supervised methods. More specifically, we ex-tend the supervised random walk proposed in [1] for link prediction into the setting of personalized tag recommenda-tion. This paper has two major differences from [1] : (1) The graph in our setting contains different types of edges, each of them has their own set of features and the corresponding feature weights are learned separately. (2) Since we have two nodes for restart, we further introduce node features.
To summarize, our contributions are as follows:
The remainder of this paper is organized as follows. The problem we addressed is formulated in Section 2. Graph model and random walk with restart are introduced in Sec-tion 3. Our optimization framework OptRank is introduced in Section3. Experimental study is described in Section 5. Related work is introduced in Section 6. We conclude the paper and discuss the future work in Section 7. Personalized Tag Recommendation . Given a user u and an item i , personalized tag recommendation tries to find tags to describe or classify the item i precisely according to u  X  X  vocabulary. Inter-relations and intra-relations among users, items and tags are considered, which makes the graph as a multi-type graph (as shown in Figure 1).

Highly ranked tags should be relevant to both u and i . To achieve this goal, a random walk with restart is performed on the multi-type graph with restart at user u and item i . Only tags that are both near to u and item i can get a high visiting probability. Formally, the random walk with restart is performed according to the following equation:  X   X  where The transition matrix A a nd the preference vector q w ill be introduced in detail in Section 3.
 Optimization Framework To get a good ranking by fol-lowing Equation 1, the transition matrix A a nd the prefer-ence vector q n eed to be carefully assigned. Thus we develop an optimization framework called OptRank.

Given a user u and an item i for personalized tag rec-ommendation, suppose u has finally annotated i with tags ( t , t 2 , ...t k ), these tags are defined to be positive tags, de-noted by P T . The rest tags are defined to be negative tags, denoted by NT . In other words, the whole tag set T is divided into two parts, i.e. T = P T  X  NT .

A good ranking function defined by Equation 1 should rank all the positive tags higher than the negative tags. For a randomly picked positive tag t 1 and a negative tag t 2 a good ranking function has a high probability of ranking t higher than t 2 . This is the idea of AUC (Area Under the ROC Curve) metric. Formally, AUC is defined by the following equation: where I ( x ) is 1 when x &gt; 0. Otherwise I ( x ) is 0.
Our goal is to find the best transition matrix A a nd the preference vector q t o maximize the AUC . To achieve this, edges are represented by features X and nodes u and i are represented by features Y . To better illustrate the idea, we can assume the adjacency matrix A only contains edges of the same type. A with different types of edges will be in-troduced in Section 3.1.
According to the above representation, the transition ma-trix A a nd the adjacency matrix A can be rewritten to A (  X  ) means they are respectively decided by parameters  X  and  X  . Since the random walk is defined by A (  X  ) and q (  X  ) ac-cording to Equation 1, we know that p can be rewritten to p (  X  ,  X  ), which means the final ranking scores are parameter-ized by  X  and  X  . However, to make the following formulae more clear, we will not rewrite the above notations with parameters  X  and  X  .

With edges and nodes parameterized by  X  and  X  , we give a formal description of our optimization framework. Given a user u and an item i for tag recommendation and the positive tag set, the optimization problem is
However, the above equation only considers a single train-ing instance. When m instances { &lt; u k , i k , P T k &gt; } considered, the cost function J (  X  ,  X  ) is defined as the average AUC : max where NT k = T  X  P T k .

The optimization framework OptRank and its solution will be introduced in Section 4.
Before introducing the optimization problem, we first in-troduce more details about Equation 1. Section 3.1 intro-duces the transition matrix. Section 3.2 describes the pref-erence vector. Section 3.3 introduces more intuitions and details of the random walk with restart. Transition matrix stores the graph structure information. Before defining the transition matrix, we first introduce how to construct a graph from a social tagging system. The graph shown in Figure 1 is constructed with three steps: (1) Users, tags and items are mapped as the nodes. (2) All the
N odes are allowed to have more than one feature, so Y U and Y I are still in bold to represent vectors. binary relations, i.e., social network, tag semantic related-ness and item content similarities are mapped to edges. (3) For ternary relation &lt;user , tag , item&gt; where three nodes are involved, binary relations can be derived by projections on each dimension. For example, suppose we have &lt;u, t, i&gt; ( u  X  U , t  X  T , i  X  I ), &lt;i, t&gt; can be derived by projecting on the user dimention. &lt;i, t&gt; is described by the feature which is the times of i annotated with t .

Now we define the adjacency matrix. Let G denote the whole graph as shown in Figure 1 and A denote its adja-cency matrix. Let G MN ( M, N  X  X  U, T, I } ) denote the each sub-graph made up by relation &lt;m , n&gt; ( m  X  M, n  X  N ) and A MN denote its adjacency matrix. We have G = G MN and A is composed of sub-matrices A MN :
Recall that edges are represented by features. In Sec-tion 2, the edge feature set is denoted by X and the feature weights is denoted by  X  . Since different types of edges have different features and feature weights. We have X = { X MN | M, N  X  X  U, T, I }} and  X  = {  X  MN | M, N  X  X  U, T, I }} . Given an edge &lt;m , n&gt;  X  X  M, N } , A MN ( m , n ) is defined by Note that X MN ( m, n ) is a vector and X MN is an array of three dimensions. In this paper, f edge : R  X  R + is the sigmoid function:
Transition matrix A i s obtained by normalizing each col-umn of A : where D U , D T and D I are diagonal matrices. The i -th entry in the diagonal of D U is the out-degree of the i -th user. For u  X  U , we have D
T and D I are defined in the same way. Following this definition, each column of A will be normalized to sum to 1.
Given a user u and an item i for tag recommendation, probability at u and i . As introduced in Section 2, User u and item i are respectively represented by feature vector Y
U = (1) and Y I = (1). Let  X  = {  X  U ,  X  I } denote the feature weights. Node weight q M ( m ) ( M  X  X  U, I } , m  X  { u, i } ) is computed by The other entries of q U and q I are all set to 0. f node R + is the sigmoid function in this paper: Figure 2: The random walker restart at u 1 a nd i 1 in no more than 2-hops
The preference vector q T = ( q T U , 0 T , q T I ) is obtained by normalizing q T = ( q T U , 0 , q T I ) to sum to 1: where D q is the summation of each entry in q U and q I . Formally, D  X  1 q is defined as the following equation: Equation 11 ensures that q s ums to 1.
In this section, we introduce more intuitions of the random walk with restart for personalized tag recommendation.
As we introduced in Section 2, the random walker can fre-quently restart at u and i to rank the tags. We illustrate this idea with an example shown in Figure 2. In Figure 2, we want to recommend tags for user u 1 to annotate i 1 , so the random walker restarts frequently from u 1 and i 1 . The edges indicate how the random walker jumps from node to node. u 1 has the history that she/he has annotated i 2 be-fore. i 1 has the history that it has been annotated by u Besides annotation relation, u 2 is a friend of u 1 , i 3 ilar contents with i 1 , and t 4 has high semantic relatedness with t 1 . Now we discuss how the random walker behaves in no more than two hops from u 1 and i 1 :
Now we introduce another intuition behind the random walk. With the transition matrix A d efined by Equation 7, we can rewrite Equation 1 as follows: p U = (1  X   X  )( A U U p U + A U T p T + A U I p I ) +  X  q where A M N = A MN D  X  1 N ( M, N  X  X  U, T, I } ). A M N p  X  X  U, T, I } ) means that p N is spread to its neighbor nodes through the transition matrix A M N .

First we discuss the extreme case that  X  equals to 0. Tak-ing p T as an example, p T receives scores from p U through A
T U , p T through A T T and p I through A T I . For t  X  T , p ( t ) will have a high score if t has highly ranked user neigh-bors, tag neighbors and item neighbors. The same rule ap-plies to p U and p I . In other words, users, tags and items re-inforce each other iteratively until a stable state is reached. However, there is no personalized information considered. Given a user u and an item i for tag recommendation, when  X  is greater than 0, the random walker will restart at u and i . Besides reinforcement rule, p U , p T and p I are also influ-enced by the distance from u and i . Nodes that are near to u and i will get a higher ranking.
In this section, we focus on how to find the best feature weights to achieve an optimal random walk with restart. Section 4.1 describes the objective function for optimiza-tion. Section 4.2 introduces how to solve the optimization problem. Section 4.3 introduces the derivatives of the ran-dom walk with respect to the feature weights, which belongs to the details in solving the optimization problem.
As we introduced in Section 2, we want to maximize the average AUC of the tag recommender according to Equa-tion 3. To convert this problem into a minimization prob-lem, we can rewrite Equation 2 to an equivalent form: This equation tells us that to maximize AUC is equivalent to minimize propose an equivalent minimization problem of Equation 3: min Since J (  X  ,  X  ) is not differentiable, we can use the sigmoid function with parameter  X  as a differentiable approximation: The bigger the  X  is, the smaller the approximate error is. However, when  X  is big, the steep gradient will cause a nu-merical problem.  X  is empirically assigned. Now we have a new objective function: m in
We use gradient descent to solve the optimization prob-lem. The basic idea of gradient descent is to find the di-rection (gradient) that the objective function drops down and make a small step towards the direction to update  X  and  X  . However, the cost function defined in Equation 19 requires to sum up all the training instances to perform one update, which is too costly. So we update  X  and  X  based on each training instance, which is called stochastic gradient descent. The algorithm is shown in Algorithm 1.
 Algorithm 1: S tochastic Gradient Descent 1 t=0; 2 initialize  X  (0) and  X  (0) ; 3 while J (  X  ,  X  ) has not converged do 4 R andomly shuffle the m training instances; 7 t = t + 1; where J k (  X  ,  X  ) is the cost based on the k -th instance: Learning rate lr decides the step size towards the drop-ping direction. The random shuffle at Line 4 is required by stochastic descent for convergence. The updating rules for  X  and  X  are shown in Lines 5 and 6. We will discuss how following.  X  X  k (  X  ,  X  )  X  X  k (  X  ,  X  ) According to Equation 18, we can derive that  X  X  (  X  ji ) / X  X  =  X S (  X  ji )(1  X  S (  X  ji )). The remaining question is how to in the next section.
In this section, we will discuss how to compute the deriva-tives of the random walk. Suppose p T = ( p T U , p T T , p want to compute  X  p / X   X  and  X  p / X   X  . The basic idea is that we can derive a similar iterative way to compute derivatives from the definition of random walk.
 Derivatives with respect to  X  . Since  X  p / X   X  is composed of  X  p / X   X  MN ( M, N  X  X  U, T, I } ), without loss of generality, we introduce how to compute  X  p / X   X  UU . Taking the deriva-tives with respect to  X  UU on both sides of the Equations 13, 14, 15, we can get  X  p T  X  p I Following the same rule, we can compute the derivatives with respect to any  X  MN ( M, N  X  X  U, T, I } ), which all lead to the same form with the above three equations. To better illustrate the connections between computing p and com-puting  X  p / X   X  MN , we can rewrite the above three equations with  X  UU replaced by  X  MN in the matrix form:  X   X   X  where A i s the transition matrix defined in the original random walk. Comparing the above equation with Equa-tion 1 for computing p , we can find two differences: (1) p is replaced by  X  p / X   X  MN . (2) The last term on the right side is totally changed. However, only the first term (1  X   X  ) A  X  p /  X   X  MN decides whether Equation 26 will converge to a stable state. More details about the convergence are discussed in the appendix.

The last detail is how to compute  X  A /  X   X  MN . Without loss of generality, we discuss how to compute  X  A /  X   X  Recall that A i s composed of sub-matrices { A M N | M, N  X  { U, T, I }} and not all A M N are related with  X   X  UU . Accord-ing to Equation 7, only A U U , A T U and A I U can be influ-enced by  X  UU . So we only need to compute  X  A U U / X   X  UU we can get Each entry of A UU is defined according to Equation 5. For u , u 2  X  U , we have Each entry in the diagonal of D  X  1 U is the out-degree of a user. According to Equation 8, for u  X  U , the derivative is So far we have explained how to compute  X  A U U / X   X  UU . The same process can be used for computing  X  A T U / X   X  UU and Derivatives with respect to  X  . Computing  X  p / X   X  is analogous to computing  X  p / X   X  . Since  X  p / X   X  is composed of  X  p / X   X  M ( M  X  X  U, I } ), without loss of generality, we first focus on how to compute  X  p /  X   X  U . Taking the partial derivatives with respect to  X  U on both sides of Equations 13, 14 and 15, we can get Following the same rule,  X  p / X   X  I can also be obtained. Re-placing  X  I with  X  M ( M  X  X  U, I } ), we can rewrite the above three equations to a single equation in the matrix form: From the above equation, we can see that computing  X  p / X   X  also has the same form with Equation 1. More details on the convergence will be discussed in the appendix. The last detail is how to compute  X  q /  X   X  M ( M  X  X  U, I } ). Without loss of generality, suppose M is U, according to Equation 11, we have Each entry of q U is defined according to Equation 9. For u  X  U , we have When f node is the sigmoid function, we know that df node Equation 12 and the derivative is So far we have described how to compute  X  q /  X   X  U . The same process can be performed to compute  X  q /  X   X  I
To sum up, we have introduced how to compute  X  p / X   X  and  X  p / X   X  , which can be summarized by Algorithm 2.
We test OptRank on two publicly available datasets 6 : De-licious and Last.fm, which are published by [2] as bench-marks. Delicious contains 437593 posts involving 1867 users, 40678 tags, 69223 items, 15328 user relations, 197438 tag relations and 151971 item relations. All types of intra-relations we studied are included in Delicious. Posts are represented by &lt;user , tag , item&gt; . Last.fm contains 24164 posts involving 1892 users, 9749 tags, 12523 items and 25434 h ttp://www.grouplens.org/node/462 Algorithm 2: D erivatives of the random walk user relations. Last.fm is a smaller dataset and only user re-l ations are available. We introduce each type of relation and its features as follows.
 Inter-relation . For edge &lt;m , n&gt; ( m  X  M  X  n  X  N  X  M, N  X  { U, T, I } X  M 6 = N ), the feature vector X MN ( m, n ) = ( the times of m co-occurred with n in the posts ). For example, times of u co-occurred with t in the posts ), which means the times of t used by u . In our experiments, we use the same A MN and A NM are both decided by  X  MN and  X  MN .
 User Relation . User relations are formed by the social net-work. Each relation is bi-direction and binary weighted. To find the strength of a user relation, we check their items and tags in common. More formally, user u can be represented by an item vector A IU ( , u ) and a tag vector A T U ( , u ). Each entry of A IU and A T U is re-weighted by TF-IDF. Users and items can be viewed as documents and words in the infor-mation retrieval. Let e A MN ( M, N  X  X  U, T, I } ) denote the A
MN re-weighted by TF-IDF. For edge &lt;u 1 , u 2 &gt; ( u U ), the feature vector X UU ( u 1 , u 2 ) = [cos( e A T U ( , u 2 )), cos( e A IU ( , u 1 ), e A IU ( , u 2 ))] Tag Relation . Tag semantic relatedness is computed with the help of Wikipedia 7 . To be more specific, 47% tags are article titles in Wikipedia. Articles link to each other by anchor texts. Semantic relatedness of tag pairs can be in-ferred from the the number of links between article pairs. We use WikipediaMiner [10], which is an off-the-shelf tool, to calculate semantic relatedness. Only tag pairs that have semantic relatedness larger than 0.25 are retained. To refine the edge weights, tags are also represented by user vectors and item vectors. We perform the same TF-IDF weighting technique to A UT and A IT . Let e A UT and e A IT denote the TF-IDF weighted matrix. For edge ( t 1 , t 2 ) ( t 1 , t 2 h ttp://www.wikipedia.org feature X T T ( t 1 , t 2 ) = [semantic relatedness, cos( e A UT ( , t 2 )), cos( e A IT ( , t 1 ), e A IT ( , t 2 ))]. Item Relation . We calculate item similarities based on Web page titles in Delicious. A title is a vector of words with TF-IDF weighting on each entry. Besides content similari-ties, we refine edge weight with TF-IDF weighted e A UI and e A
T I . For &lt;i 1 , i 2 &gt; ( i 1 , i 2  X  I ), X II ( i 1 cos( e A UI ( , i 1 ), e A UI ( , i 2 )), cos( e A T I ( , i
Like logistic regression, we add a constant feature 1 to each feature set X MN and all the features are normalized to have mean 0 and standard deviation 1.
Since OptRank is an extension of existing graph-based methods, we want to prove two points: (1) OptRank out-performs existing graph-based methods when only &lt;user , tag , item&gt; is available. (2) OptRank further improves the performance by incorporating social networks, tag semantic relatedness, item content similarities. we choose two graph based methods as our baselines.
 Random Walk with Restart . Random Walk with Restart, called RWR for short, is the unsupervised version of Op-tRank. RWR performs on the graph defined by &lt;user , tag , item&gt; . The weight of the edge &lt;m , n&gt; ( m  X  M  X  n  X  N  X  M, N  X  X  U, T, I } X  M 6 = N ) is the times of m co-occurred with n in the posts. Given a user u and an item i for tag recommendation, when the random walker decides to restart, it has the probability of 0.5 to restart at u and 0.5 to restart at i . RWR has been adopted in [6] to incor-porate social networks, but the different types of edges are normalized empirically and are hard to reproduce. FolkRank . FolkRank is a state-of-the-art graph-based al-gorithm. The graph is defined in the same way with RWR. FolkRank can be summarized as three steps: (1) Calculate a global PageRank score p global for each node. (2) Calculate a personalized PageRank score p pref with special preference to u and i for each node. (3) Calculate FolkRank score as the wins and loses between the personalized PageRank p pref and the global PageRank p global , i.e., score = p pref  X  p In our experiments, we set the damping factor to 0.7, which achieves the best performance for FolkRank. In our experi-ments, FolkRank is denoted by  X  X R X .

We are aware that there are many methods based on ten-sor factorization[12, 13, 15]. However, tensor factorization needs to learn a low rank approximation vector for each user, item and tag. In OptRank, a user can even not exist in the training set but can still get recommendation if she/he has neighbors in the test set. OptRank only needs about 3000 training instances to reach its best performance. However, tensor factorization would fail with such a small training set, which is unfair. For this reason, we did not choose these methods as baselines. Performance Measurements . We use average precision, precision-recall curve and average AUC (Area under the ROC Curve) to measure the performance. We are aware that the optimal of AUC is not necessarily the optimal of average precision/recall. To trade-off between best AUC and best precision, we choose the model that has both high AUC and precision in the cross validation set. Then the model is evaluated on the test set. AUC T raining/Cross Validation/Test Set . Posts are aggre-gated into records &lt;u , i , PT &gt; ( u  X  U , i  X  I ). For each dataset, we randomly picked 5000, 3000, and 3000 records as the training set, cross validation set, and test set.  X  and learning rate .  X  in Equation 18 controls the error of approximating I ( x ). The bigger  X  is, the smaller the approx-imate error is. However, when  X  gets too big, the derivative at x = 0 will also get too steep and will cause a numeric problem. When  X  gets too small, minimizing J (  X  ,  X  ) would fail to maximize AUC. From Equations 21 and 22, we can know that the summation of the derivatives is divided by | P T k || NT k | . Since large dataset has big | P T k || NT use a big  X  . In our experiments,  X  is 10 9 in Delicious and 10 6 in Last.fm. Learning rate lr is strongly related to  X  . When lr gets too big, stochastic gradient descent would fail to converge. lr is set to 10 in both datasets.
 Restart Probability  X  .  X  controls how frequently the random walker chooses to restart. We evaluate how AUC and precision change by differing  X  from 0.2 to 0.8 in Deli-cious. The results are shown in Figure 3. OptRank was run on the inter-relation formed by &lt;user , tag , item&gt; . When precision and AUC are both considered,  X   X  [0.6, 0.8] seems to be a good choice. Finally, we set  X  to 0.7. Results on Delicious . Results on Delicious are shown in Table 1 and Figure 4. FR denote FolkRank. OptRank Edge, O ptRank Node and OptRank EN denote OptRank with only e dge features enabled, only node features enabled , and both features enabled, respectively. Firstly, we compare the algo-rithms that are only performed on inter-relations formed by &lt;user , tag , item&gt; . Since RWR always performs better than FR, we only compare OptRank with RWR in the following. When only edge features are enabled, OptRank Edge has c omparable performance with RWR. This indicates that the original transition matrix of RWR and FR is nearly opti-mal. When only node features are enabled, OptRank Node l earns the best weights for u and i , which improves the top-1 precision by 3.3% compared with RWR. This indicates the original node weight is not optimal. When edge features and node features are both enabled, OptRank EN futher im-p roves the top-1 precision by 2.4% based on OptRank Node. F rom Figure 4 we can know that the OptRank EN outper-f orms RWR at top-5 but the advantage disappears at top-10. However, since a user usually annotates an item with less than 5 tags, top-5 performance is considered more impor-tant than top-10 performance. In terms of AUC, FolkRank Algorithm P@1 P@2 P@3 AUC FR 0.219 0.180 0.163 0.6851 RWR 0.233 0.197 0.179 0.9812 OptRank Edge 0.234 0.194 0.171 0.9851 OptRank Node 0.266 0.204 0.179 0.9833 OptRank EN 0.290 0.239 0.201 0.9862 OptRank U 0.297 0.247 0.215 0.9862 OptRank T 0.302 0.245 0.213 0.9862 OptRank I 0.303 0.242 0.210 0.9863
OptRank UTI 0.316 0.262 0.223 0.9869 has relatively poor performance, worse than the precision. I n contrast, RWR has a much better average AUC. This is probably because FolkRank is an empirically designed algo-rithm and relies too much on the global information. We can see that a high precision does not indicate a high AUC.
Now we discuss how OptRank performs when extra user relations, tag relations and item relations exist. When each type of relation is considered separately, OptRank U, Op-t Rank T and OptRank I improve the top-1 precision by a round 1% based on OptRank EN, which is not very signifi-c ant compared with previous improvement. However, as we can see from Figure 4, the top-10 performance of OptRank I i s significantly improved compared with OptRank EN. Since O ptRank U, OptRank T and OptRank I are comparable, o nly OptRank I is shown in Figure 4. When all the rela-t ions are combined, we can see that OptRank UTI achieves t he best performance at all top-k performance. In terms of AUC, OptRank UTI also achieves the best performance. R esults on Last.fm . The results are shown in Figure 5 and Table 2. The results are significantly better than the results on Delicious. This can be explained in terms of data spar-sity. When only inter-relations are considered, a post can be viewed as an entry in the three-dimension array spanned by users, tags and items. 1 . 05  X  10 (  X  7) and 0 . 83  X  10 of the entries in Last.fm and Delicious are known, respec-tively. Thus Last.fm is less sparse and more predictable than Delicious. In Last.fm, all algorithms have comparable performance at top-10. So we mainly focus on the top-5 performance in this experiment and this is reasonable since users usually annotate an item within 5 tags. From Figure 5 we can know that FolkRank and RWR have comparable per-formances in term of precision, which is different from the results on Delicious. When node features and edge features are both considered, OptRank EN improves P@1, P@2 and P @3 by 1.2%, 1.5%, 1.5% respectively compared with FR and RWR. Although Last.fm is less sparse than Delicious, when the social network is combined, OptRank U success-f ully improves the top-1 precision by 3.7% compared with the two baselines. In terms of AUC, empirically designed FR still falls behind other methods. OptRank U achieves t he highest AUC.

To sum up, we have two conclusions from the experiments: (1) When only &lt;user , tag , item&gt; is available, OptRank outperforms RWR and FolkRank. (2) OptRank successfully combined extra relations to improve the performance. Now we discuss some details about the training process. Since Delicious is bigger and takes more time, the training size and running time are reported according to Delicious. Over-fitting Issues . Over-fitting does not seem to be a problem in our model since we only have 18 parame-ters when all the relations are combined 8 . OptRank UTI a chieves nearly the same top-1 precision in the cross valida-tion set and test set.
 Training Size . The training size is really small compared with tensor factorization. OptRank EN achieves its best p erformance when 600 training instances are passed. Op-tRank UTI achieves its best performance when 1200 train-i ng instances are passed.
 Running Time . The experiments were conducted on a sin-gle PC with a 2-core 3.2GHz CPU and 2G main memory. We implemented the algorithm in Matlab with full vectorization. When all the relations are combined, each training instance takes nearly 3.5 seconds. Prediction takes around 0.1 sec-onds per instance and most of the time is spent on computing the gradients. Training with 5000 instances would take 4.8 hours at most. However, all the algorithms in our experi-ments achieve their best performance within 2000 training instances.
There are mainly three approaches for personalized rec-ommendation in social tagging systems: (1) Graph-based approach [4, 5, 17]. (2) Tensor decomposition [12, 13, 15]. The annotation relation is modeled as a cube with many
E ach inter relation has 2 parameters, user relation has 3 parameters, tag relation and item relation has 4 parameters, respectively. unknown entries. After performing tensor decomposition, w e can predict the unknown entries by low-rank approxi-mations. (3) User/Item based collaborative filtering [8, 11, 18]. The original user-item matrix is extended by includ-ing tag information so that we can apply user/item based collaborative filtering methods.

Besides annotation behaviors, user space, tag space and item space have also been explored. [9] has studied trust networks and proposed a factor analysis approach based on probabilistic matrix factorization. [6] incorporates social net-work for item recommendation, but fails to improve the per-formance significantly. [14] links social tags from Flickr into WordNet. [7] introduces item taxonomies into recommender systems.

This paper is mainly inspired by two recent work on graph-based learning [1] and semi-supervised learning [3]. [1] pro-poses supervised random walks to learn the edge weights for link prediction in homogenous graph. This paper ex-tends [1] with multi-type edges and nodes. [3] has proposed similar idea to learn edge weights and node weights with an inductive learning framework in homogenous graph. Since a recommender should have the ability to predict for future events, our framework is different from [3] in that ours be-longs to transductive learning.
In this paper, we propose an optimization-based graph method for personalized tag recommendation. To allevi-ate data sparsity, different sources of information are incor-porated into the optimization framework. There are some problems unsolved for future work: (1) Reducing the graph size. Since the random walker frequently restarts at u and i , nodes that are far away from u and i may be cut without influencing the final ranking. (2) Comparing with tensor factorization methods under a suitable experiment setting. (3) More features can be explored to further improve the results, such as the temporal factors.
This work was supported in part by National Basic Re-search Program of China (973 Program) under Grant No. 2011CB302206, and National Natural Science Foundation of China under Grant No. 60833003. [1] L. Backstrom and J. Leskovec. Supervised random [2] I. Cantador, P. Brusilovsky, and T. Kuflik. Workshop [3] B. Gao, T.-Y. Liu, W. Wei, T. Wang, and H. Li. [4] Z. Guan, J. Bu, Q. Mei, C. Chen, and C. Wang. [5] R. J  X  aschke, L. B. Marinho, A. Hotho, [6] I. Konstas, V. Stathopoulos, and J. M. Jose. On social [7] H. Liang, Y. Xu, Y. Li, and R. Nayak. Personalized [8] H. Liang, Y. Xu, Y. Li, R. Nayak, and X. Tao. [9] H. Ma, T. C. Zhou, M. R. Lyu, and I. King.
 [10] D. Milne. An Open-Source Toolkit for Mining [11] J. Peng, D. D. Zeng, H. Zhao, and F.-y. Wang. [12] S. Rendle, L. B. Marinho, A. Nanopoulos, and [13] S. Rendle and L. Schmidt-Thieme. Pairwise [14] B. Sigurbj  X  ornsson and R. van Zwol. Flickr tag [15] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. [16] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. [17] H. Yildirim and M. S. Krishnamoorthy. A random [18] Y. Zhen, W.-J. Li, and D.-Y. Yeung. Tagicofi: tag We prove the convergence of Equations 26 and 33. Both the equations can be rewritten to a more general form: w here 0  X   X ,  X   X  1, A i s a transition matrix with each col-umn summing to 1 and q can be any vector with the same dimension of p . Suppose p (0) =  X  , we have p (1) =  X  A  X  +  X  q , p ( 2) = (  X  A ) 2  X  +  X  A  X  q +  X  q , ..., p ( n ) P transition matrix A a re in [-1, 1], we have lim n  X  X  X  (  X  A ) 0 a nd lim n  X  X  X  converges to p  X  = ( I  X   X  A )  X  1  X  q .
