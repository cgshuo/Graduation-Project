 Amjad Mahmood * 1. Introduction
The phenomenal growth of the world wide web (WWW) is moving us towards distributed and highly interconnected peak hours, continue to be a common problem while accessing popular web sites. Object replication in a distributed web server system is a well-known technique to improve the system performance (e.g. latency which is a measure of how long it takes to get response from a server, hop counts which is number of hops a TCP/IP packet should make to reach its destination, etc.). On the other hand, maintaining a large number of copies of an object can be a bottleneck, especially in the presence of a large number of updates. It has been shown that deciding how many replicas to create and where to place them on a cluster of web servers to meet a performance goal is an NP-hard problem (Karlsson &amp; Karamanolis, 2004; ristics that are designed for certain systems and work loads.

There have been a number of studies on replication of web contents. Wolfson, Jajodia, and Huang (1997) proposed an adaptive data replication algorithm which can dynamically replicate an object to minimize the network traffic due to  X  X  X ead X  and  X  X  X rite X  operations. The proposed algorithm works on a logical tree structure and requires that communication traverses mance of their algorithm for general network topology is not clear. Bestavros (1995) formulated the problem as a constraint-maximization problem and the solution was obtained by using Lagrange multiplier theorem. The solution, however, does not greedy algorithms, a static and a dynamic one, for replicating objects in a network of web servers arranged in a tree-like structure. The static algorithm assumes that there is a central server that has a copy of each object and a central node determines the number and location of replicas to minimize a cost function. The dynamic version of the algorithm relies on the usage statistics collected at each server/site.

Hedfdaya and Mirdad (1997) presented a dynamic replication protocol for the web, referred to as the Web Wave. It is a dis-tributed protocol that places cache copies of immutable documents on the routing tree that connects the cached documents burdens the routers with the task of maintaining replica locations and interpreting requests for Web objects. Mahmood (2005) andMahmood andHomeed(2007) proposeda seriesofalgorithmsforobjectreplicationindistributed webserversystems.The studied by Kalpakis, Dasgupta, and Wolfson (2001) . Xu and Bhuyan (2005) proposed a three-stage mechanism to replicate ob-jects to satisfy clients X  X oSrequirementsina contentdeliverynetwork(CDN) environment. Inthe first phase, objectreplication mance. Object replication problem in hierarchical and transparent web proxies has been investigated by Jia, Li, Du, and Cao (2005) . They proposed algorithms for two cases: when the proxies have unlimited storage capacities and when the proxies have limited storage capacities. They showed through a simulation study that the proposed algorithms out-perform the stan-dard web caching algorithm. A polynomial time greedy algorithm with backtracking to dynamically replicate objects at the appropriate sites to minimize a cost function is presented by Mahmood (2007) . Due to successful application of meta-heuris-solve object replication problem. Loukopoulos and Ahmad (2004) proposed a genetic algorithm for object replication in a dis-tributed web server system to minimize read and write costs. Mahmood and Homeed (2005) proposed a hybrid tabu search algorithm to determine the number of replicas and their placement in a distributed web server system to minimize latency. move is an atomic change, which transforms the current solution into one of its neighboring solutions.
Since PSO was first introduced to optimize various continuous functions by Eberhart and Kennedy (1995) and Kennedy and Eberhart (1995), it has been successfully applied to a wide range of optimization problems such as power and voltage control, neural network training, task assignment, and permutation flowshop sequencing problem. Following to the success-
Gencylmaz, 2006 ), this paper aims at employing PSO algorithm in solving the object replication problem. We present a discrete hybrid PSO-based algorithm for object replication problem. The proposed algorithm is based on particle swarm opti-mization and tabu search algorithm. The algorithm makes full use of the strong global search ability of PSO and the strong local search ability of tabu search to obtain high quality solution. We show through a simulation study that the hybrid PSO produces high quality solutions as compared to the solutions obtained with genetic algorithm (GA), simple PSO, tabu search, and random placement algorithm.
 presents the proposed hybrid approach. Simulation results are presented in Section 4 followed by conclusions in Section 5. 2. Formulation of object replication problem
We consider a distributed web server system comprising of M sites, with each site having its own processing power, memory and storage media. Let s i be the storage capacity of site i ,(1
The M sites of the system are interconnected by a communication network. A link between two sites i and j (if it exists) (communication cost may be interpreted as latency, hop count, etc.). If two sites are not directly connected by a communi-
C ( i , j ) =C ( j , i ) and is known a priori. Let there be N objects denoted by O (1 6 k 6 N ) and is measured in simple data units. Let r ik and w a certain time period T (we use subscript k to denote object O the target server.

We also assume that each object O k has a primary copy in the network that cannot be deallocated or removed. The site holding the primary copy of object O k is denoted by P k . Each primary site P scheme, denoted by RS k , for each object O k (i.e. set of sites on which object k is replicated). We use RS = {RS to denote replication schemes of all the objects. Furthermore, each site i stores primary site P each object O k . The S ik is the site for which the read requests from i for object O
Note that S ik =P k if the primary site is the closest site and S for an object is served locally (if a replica of that object is available locally) or it is forwarded to the S request. For simplicity reasons, we assume that updates on object O the object to its primary site P k which afterwards broadcasts it to every site that has a replica of O see ( Kalpakis et al., 2001 ).

If X is an M N matrix whose entry x ik = 1 if object k is stored at site i and x subject to certain constraints. That is, we want to the replication scheme RS , denoted by R ( RS ) and W(RS ), respectively, are given by: The cumulative cost ( TC ) due to all reads and writes is given by: That is In terms of replication matrix X as defined before, the cumulative cost is now defined as:
Eq. (8) shows that if a replica of the requested object is available locally (i.e. x wise the requested object is accessed from the site that incurs minimum cost. Also, the write cost for each object O sum of the cost of writing the object at the primary site, P replica of the object. 3. Hybrid PSO for object replication problem
PSO is a population-based algorithm proposed by Eberhart and Kennedy (1995) which models the social behavior of birds optimization tool. In a PSO-based system, multiple potential solutions coexist and collaborate simultaneously. Each candi-flying experiences of its own and those of its companions. Tracking and memorizing the best position encountered build the particle X  X  experience . The PSO system attempts to balance exploration and exploitation by combining local search methods (through self experience) and global search methods (through neighboring experience). It has been shown that a hybrid strategy that embeds a local optimizer such as hill-climbing in between the iterations of PSO can improve the performance mulated in Section 2. The proposed algorithm starts with an initial population of Swarm_size particles where each particle mination condition (e.g. number of iterations) is satisfied. During each iteration, the particle individual best and swarm X  X  apply an adjustment algorithm on each particle. When the algorithm terminates, the best particle is returned as a solution. the following subsections. 3.1. Particle representation and initial solution
One of the key issues in designing a successful PSO algorithm is the representation step, i.e. finding a suitable mapping between the problem solution and PSO particles. In order to construct a direct relationship between the problem domain and the PSO particles for the object replication problem, we let each p th particle at iteration t , denoted by X solution using a bit vector of MN dimension i.e. X t p  X  X  x t k th object, where ger not less than x , or, formally, d x e X  min f n 2 Z j n x g .
 As an example, Fig. 2 shows a mapping between one possible replication scheme of three objects on three sites (i.e. N =3,
M = 3) to a particle X t p of MN dimension in the PSO domain. Note that x t replicated on site two (i.e.  X  X  j 1  X  mod M  X  1  X  X  X  2 1  X  mod3  X  1 . Similarly, x t site three and so on.

The initial population of Swarm_size particles is constructed randomly as follows. For each dimension of a particle, a bin-ary value of 0 or 1 is assigned with a probability of 0.5. That is,
However, a particle generated in this manner may not represent a feasible solution. Therefore, we apply an Adjustment ensure that the storage constraint (3) is also satisfied we proceed as follow: For each site i ,if
Then for each j ,if x pj = 1, we calculate the increase in the cost function if x is equivalent to removing the object from site i ).
 where increase in the cost function due to removal of an object from a site. The complete procedure is given in Fig. 3 . 3.2. Fitness evaluation and particle vector modification value to each particle.
 v t , using the following equation: where c 1 and c 2 are cognitive coefficients and r 1 and r t 1, respectively. The value of dimension j of particle p is updated using the following equation: where q is a random number in the interval (0, 1) and s is a sigmoid function (Kennedy &amp; Eberhart, 1995 ) defined as: 3.3. Hybrid strategy
PSO has a strong global search ability, but as a stochastic search algorithm, cannot guarantee to converge to the global optimal solution at the end. Therefore, we combine a simple tabu search algorithm (Glover, 1990 ) with PSO to get a new hybrid optimization algorithm. Tabu search is applied to each particle, in turn, with an attempt to determine a better solu-space of all feasible solutions by a sequence of moves. A move is an atomic change, which transforms the current solution into one of its neighboring solutions. Associated with each move is a move value , which represents the change in the objec-cedure is repeated for maxtry number of iterations which is generally kept to a small number. The complete tabu search algorithm is given in Fig. 4 . 4. Simulation results
Comparing the performance of the proposed algorithm to the optimal solution obtained by exhaustive search would have been the best way to illustrate the merits of our algorithm. Exhaustive search though is able to provide the optimum solu-we compare the performance of the proposed hybrid PSO (HPSO) with simple tabu search (TS), genetic algorithm ( Loukopo-the same coding scheme and fitness function as used by PSO and the HPSO. It has been shown in many studies that random placement algorithm provides the worst quality solutions ( Loukopoulos &amp; Ahmad, 2004; Mahmood, 2007; Mahmood &amp;
Homeed, 2005 ), it can be considered as an  X  X  X pper bound X  placement method in a sense that an efficient replica placement method should always be better than the random placement. Therefore, we used random placement algorithm to obtain the baseline values of the cost function and use the percentage savings over the random placement algorithm in the cost func-tion (TC) as a measure of performance.

The test data used in our simulation incorporates the characteristics of generic web system in terms of number of servers, number of objects and read/write costs. Briefly, we used networks of 10 X 150 nodes. The network structures were generated as follows: The link costs were uniformly distributed between 1 and 10, which effectively represents the number of hops a wari, 2004; Zipf, 1949 ). The minimum and maximum object sizes were 2 KB and 7 MB, respectively. The total number of ob-jects to be replicated was varied from 50 to 450. The primary site for each object was chosen randomly. In all the that servers have diverse enough storage capacities, the capacity of a server was set randomly between 25% and 90% of the total size of all the objects.

Consistent with a number of other studies on PSO, the parameters for PSO and HPSO were set as follows: The number of particles were set between 50 and 100 depending on the particle dimension. The acceleration coefficients were taken as c = c 2 = 2. The updates velocities r 1 and r 2 were generated randomly between 0 and 1 where value of w was set to 1/ (2 ln2). The maximum number of iterations for tabu search was set to 10. Other parameters for tabu search were set as described in Mahmood and Homeed (2005) . The parameters for GA were the same as used by Loukopoulos and Ahmad ness function is the main source providing the guidance for targeting the optimal solution and is also most time consuming component for both algorithms, the performance is evaluated as the minimum cost obtained when the testing algorithms have run for a specified number of fitness evaluations. Moreover, both HPSO and GA are stochastic algorithms and each inde-pendent run of the same algorithm on a particular testing problem may yield a different result, thus we calculated the aver-age cost for 15 independent runs of each algorithm for every problem instance.

First, we assessed the performance of the HPSO as compared to GA, PSO and tabu search by varying the number of sites different parameters for each network size. It can be observed that the HPSO outperforms GA, PSO and TS in terms of solution read/write requests, together with more storage capacity to be used for replication. The HPSO explores and balances these thereby reducing the read cost which makes up a major portion of the cost value. In the second set of experiments, we inves-intensive objects are replicated, adding more storage space results to only marginal performance improvements. Similar trend was seen when number of objects were increased while keeping other parameters constant. Fig. 9 shows the effect of increasing number of objects for a network of 100 sites and Fig. 10 shows the overall performance of all the algorithms sults that the HPSO achieves better results (on average) as compared to GA, PSO, and TS.

It is evident from the results that HPSO successfully obtained high quality solutions to realist size problems. Moreover, the proposed algorithm can scale up to solve even larger size problems by reducing the particle X  X  dimension, which is the product of number of objects and number of servers. The number of objects can be reduced by grouping the objects that have high probability of being accessed together and replicating each group as a unit of replication. Mahmood and Homeed (2007) proposed an elegant method to group objects that have high probability of being accessed together. To study the perfor-mance of the proposed algorithm when groups rather than individual objects are replicated, we collected a real web-trace HTML pages and 127 image files. We grouped the objects using the object grouping algorithm proposed in Mahmood and
Homeed (2007) . The total number of groups generated by the algorithm was 139, significantly less than the total number of objects. We replicated the object groups using our simulator to evaluate the relative performance of the replication the relative performance of the algorithms. The proposed algorithm consistently obtained better quality solutions as com-pared to other algorithms. 5. Conclusions
Object replication on a distributed web server system is a promising technique to improve system performance. However, one needs to determine the number of replicas and their locations in the network that minimizes the objective function. In this paper, we addressed the object replication problem and developed a cost model which is applicable to large distributed systems. We formulated the object replication problem as a 0 X 1 optimization problem subject to storage and primary copy constraints. We designed a hybrid object replication algorithm makes full use of the strong global search ability of PSO and constantly outperforms the GA, TS, and PSO in terms of solution quality.
 References
