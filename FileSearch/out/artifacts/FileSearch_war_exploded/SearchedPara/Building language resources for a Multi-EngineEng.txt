 Rachel Edita On  X  ate Roxas  X  Allan Borra  X  Charibeth Ko Cheng  X  Nathalie Rose Lim  X  Ethel Chuajoy Ong  X  Michelle Wendy Tan Abstract In this paper, we present the building of various language resources for a multi-engine bi-directional English-Filipino Machine Translation (MT) system. Since linguistics information on Philippine languages are available, but as of yet, the focus has been on theoretical linguistics and little is done on the computational aspects of these languages, attempts are reported here on the manual construction of these language resources such as the grammar, lexicon, morphological information, and the corpora which were literally built from almost non-existent digital forms. Due to the inherent difficulties of manual construction, we also discuss our experiments on various technologies for automatic extraction of these resources to handle the intricacies of the Filipino language, designed with the intention of using them for the MT system. To implement the different MT engines and to ensure the improvement of translation quality, other language tools (such as the morphological analyzer and generator, and the part of speech tagger) were developed. Keywords Corpora  X  Language resources  X  Language tools  X  Lexicon  X  Machine translation  X  Morphology 1 Introduction The multi-engine machine translation project is the development of computer software that performs machine (or automatic) translation (MT) of English texts to Filipino, and vice versa. Natural language translation is a very complex task. Its automation presents more issues and difficulties in addressing, in particular, translation quality. During the past 50 years of research on machine translation involving various languages, different paradigms and methods have been suggested and employed to improve translation quality. The issue is: how effective is an approach in capturing the features of natural languages and the translation phenomena between these two languages so that translation quality can be considered at par with the translation of human experts? It has been shown in previous researches that this cannot be achieved by a single MT paradigm. Hence, the multi-engine MT research team attempts to integrate the various MT paradigms so as to draw a synergy out of the strengths of these paradigms. The current MT system outputs the MT engines respective generated translations and presents them to the user.

The English-Filipino MT system is a combination of the rule-based and corpus-based approaches. Rule-based MT builds a database of rules for language representation and translation from linguists and other experts; while corpus-based MT automatically learns such information from sample text translations. Two corpus-based approaches are considered: example-based and template-based. To implement these paradigms, language resources are built, such as the bilingual English-Filipino lexicon (or electronic dictionary), Filipino grammar, translation rules and annotated corpora. The corpus-based approaches require a part-of-speech tagged corpus. The MT paradigms will also use the morphological analyzer and generator to extract root words from texts.

Our project considers various approaches in capturing natural languages and their intrinsic features and characteristics, and automating the processes involved in the representation and translation of natural languages. The approach considers the effective representation of both the English and Filipino languages, and their translation. In all the components of the MT system, both the rule-based and the corpus-based approaches are considered. The rule-based approach generally requires capturing the rules of the language processes through the expertise of linguists; while the corpus-based approach automatically learns these processes from a corpus (or collection) of examples fed into the system.

One of the major challenges is in building of language resources such as the lexical and morphological information, lexicon, grammar, corpora, and translation from almost non-existent digital forms. Linguistics information on Philippine languages are available, but as of yet, the focus has been on theoretical linguistics and little is done on the computational aspects of these languages. Computational issues involving Philippine languages, in particular Filipino, are considered in this study. Some of these issues include the complex verbal morphology of the language, free word order of sentences, and focus of the sentence. 2 Lexical and morphological information The Philippines is an archipelago of more than 7,100 islands, with over 100 languages. The 1935 Constitution Article XIV, Section 3 states that  X ...Congress shall make necessary steps towards the development of a national language which will be based on one of the existing native languages... X  due to the advocacy of then Philippine President Manuel L. Quezon for the development of a national language that will unite the whole country. Two years later, Tagalog was recommended as the basis of the national language, which was later officially called Pilipino . In the 1987 Constitution, Article XIV, Section 6, states that  X  X he National language of the Philippines is Filipino. As it evolves, it shall be further developed and enriched on the basis of existing Philippine and other languages. X 
The Filipino alphabet consists of the Pilipino ABAKADA, which is composed of 20 letters, and another 8 letters (C F J N  X  Q V X Z) for the assimilation of borrowed words. Because of the confusion in the variations in spelling of Filipino words, especially those assimilated from other languages, the Commission on the Filipino Language ( 2000 ) standardized the Filipino writing system. Unfortunately, revisions on these guidelines are still expected to be made. Such spelling confusions cause difficulties in the representation of these words in the lexicon (as discussed in Sect. 3 ).
Words in documents are formed from root words, and these root words are the only ones that are represented in the lexicon. The extraction of root words, together with its morphological categories, is called morphological analysis (MA), and the generation from root words is called morphological generation (MG). Two general approaches to these morphological processes are the rule-based and example-based approaches. As with the MT systems, the rule-based approach requires the capturing of the morphological phenomena through the expertise of a human linguist, and transforming them into rules that can be represented in a computer. Since the Filipino language has very complex word morphology, the rule-based approach can be complemented by the example-based approach. The example-based approach automatically extracts morphological behavior from examples fed into the system. All the MT components will require a morphological analyzer and generator because different English words may be translated to the same Tagalog root with different attached affixes.
 Much of the work in Philippine linguistics focused on the Tagalog language (De Guzman 1978 ). Tagalog language exhibits complex morphological phenomena, which include concatenative behavior such as prefixation and suffixation, and non-concatenative behavior such as infixation and reduplication (either partial or full). Tagalog is also an agglutinative language, where for instance, prefixes may be successively combined. Research on computational morphology has been predom-inantly on concatenative morphology and on finite-state models of morphotactics (Koskenniemi 1983 ). Although attempts were made to handle non-concatenative phenomena, it has been on a limited capacity only (Beesley et al. 2000 ; Santiago 1991 ; Bonus 2004 ).

We experimented on a rule-based MA using Optimality Theory (OT), since OT has been proven effective in generating non-concatenative phonology. The method was tested on 1,600 Tagalog verb forms (having 3 X 7 syllables) from 50 Tagalog roots which exhibit both concatenative and non-concatenative morphology, and the results show a 96% accuracy of producing the correct underlying forms given the surface forms of the test data. The 4% error is attributed to d-r alteration, an example of which is in the word lakaran , which is from the root word lakad and suffix -an , but d is changed to r . Unfortunately, computation time is quite a slow process, since OT uses an exhaustive search in the analysis wherein all candidate analyses are computed, and erroneous ones are later eliminated through constraints and rules (Fortes-Galvan 2006 ).

To augment the rule-based MA, we also experimented on an example-based MA by extending the WordFrame model (Wincentowski 2002 ) from a seven-way split representation of morphological re-write rules from word pairs of a morphed word and its corresponding root. In the WordFrame model, the seven-way split re-write rules composed of the canonical prefix/beginning, point-of-prefixation, common prefix substrings, internal vowel change, common suffix substring, point-of-suffixation, and canonical suffix/ending. We introduce an additional two-way split to the representation wherein the non-concatenative Tagalog morphological behaviors such as infixation and reduplication are modeled separately. Infixation, partial and full reduplication are improperly modeled in the WordFrame model as point-of-prefixation as shown in the words ( hin)-intay which should have been modeled as the word hintay with infix  X  in-,( hi-) hintay ( -in ) with partial redupli-cation of the first syllable, and salu-salo with full reduplication of the word salo and alteration of character o to u. Words with an infix within a prefix are also modeled as point-of-prefixation as in the word ( hini-) hintay which should be represented as infix  X  in in partial reduplicated syllable hi-. Although the revised WordFrame model correctly represents the re-write rules for the words with such morphological behavior, it is still not capable of fully modeling Filipino morphology since some occurrences of reduplication are still represented as point-of-suffixation for various locations of the longest common substring. There are also some problems in handling the occurrence of several partial or whole-word reduplications within a word. Despite these problems, the training of the algorithm that learns these re-write rules from 40,276 Filipino word pairs derived 90% accuracy when applied to an MA. The complexity of creating a better model would be costly but it would ensure an increase in performance and reduced number of rules. Also, a better generalization of the rules would significantly help reduce the number of rules and better model the language for smaller set of examples (Cheng and See 2006 ). 3 The lexicon The lexicon (or dictionary) is a collection of source words with the corresponding translation in the target language, and their features (such as part-of-speech tag, sample sentences, and semantic information). The base lexicon for the Multi-engine MT project is the dictionary of the Commission on the Filipino Language (CFL) of the Philippine government, which contains approximately 10,000 English source words with a total of about 25,000 Filipino meanings. Since the dictionary was from CFL, the spelling convention that was used by the current electronic lexicon is based on the standardized guidelines and rules of the CFL. Unfortunately, there are other conventions in various academic institutions and there is an added confusion in the variations in spelling of Filipino words because of the assimilated from other languages such as Spanish (e.g., spellings of the Filipino word for congregation are konggregasyon and kongregasyon ). Other conventions which have been formalized are integrated into the lexicon such that all possible spellings of a particular word are stored in the lexicon and marked with the particular guideline used.
Each English entry in the lexicon contains the POS tag of the word and the corresponding Filipino meaning, with co-occurring word information, and other English features or attributes (e.g., other acceptable spellings or synset id based from WordNet) for proper translation. For instance, connectors (or pandikit ) such as ang , ng and sa have various interpretations depending on its context, whether sentence or phrasal context. For instance, the Filipino sa can be translated to to or at in English depending on the context, and mula sa is translated to from . Semantic features address the problem of ambiguity since many words have many-to-many relationships and determining the proper translation is vital.

Since languages are in the process of evolution, it is imperative that the project provides some way to be able to determine and capture new words and probably new meanings of words in the languages considered in this study. New terms can be added into the base lexicon through automatic lexicon extraction from documents on English and Filipino. New lexicon terms are automatically learned from sample documents. Two approaches have been experimented on using non-parallel documents (non-translations of each other) and parallel documents (translations of each other). For the use of the non-parallel comparable (that is, non-parallel but within the same domain) corpora, we derive 50% accuracy of extraction of translation terms of the source word to its equivalent target word using a corpora within the same domain with 381,553 English and 92,610 Tagalog terms, with 4,817 and 3,421 distinct root words, respectively (Tiu 2004 ). An improvement introduced in this study involves the use of clustering algorithm to group together similar senses of a word. One of the contributions of this research is the combination of the word context extraction (Rapp 1999 ) with the clustering technique (Pantel 2003 ) and other clues like the part of speech tags in the source corpora. Other researches only concentrated on context extraction while others on clustering techniques only. This research first extracts the contexts of the source word, clusters them into their most similar sense, and then ranks the output through the assistance of the target corpora. The initial F-measure for the 50 high frequency words and 50 low frequency words calculated was 0.07. And the ranked F X -Measure was calculated to be 0.11, showing an improvement of .04. It was shown that the algorithm performs on a satisfactory level. Other errors are attributed to several factors such as the quality of corpora, preprocessing errors, and the inclusion of some function words in the target corpora.

Lexicon extraction is more difficult using non-parallel texts, so we also considered the use of parallel English-Filipino corpora in the automatic lexicon extraction (Lim et al. 2006 ). This research revolves around the assumption that co-occurring words (i.e., words that appear together) in a language would most probably appear together even in a different language. Thus, a probabilistic approach is used to determine candidate translations of English and Filipino words. Since there are several words not included in the base lexicon (referred to as unknown words), translations of a term X  X  co-occurring word cannot be found, thus minimizing the possibility of generating a high score (based from probabilistic computation) to allow for a possible candidate translation pair. The system was trained on an English corpus with 31,618 tagged and 7,627 untagged words, and a parallel Filipino corpus with 34,588 tagged and 4,127 untagged words. The tagging was done by automatic English and Tagalog taggers, respectively, and the tags were not verified by an expert linguist. Because of these other sources of errors, the system only achieved 57% accuracy.

We have derived further improvements to the lexicon extraction algorithm through several aspects. The most important of these improvements is the use of a seed lexicon in the preprocessing phase. We claim that introducing the seed lexicon X  X  properties to the whole process early produces better similarity measurement results, since most of the  X  X oise X  are temporarily  X  X ilenced X . In this way, we ensure that only the necessary features are made available during the extraction process. Another major difference of the new scheme is its candidate word translation evaluation where in a multi-pass procedure is performed. Rather than performing a single pass on each word pair, we perform iterative similarity measurements on each word pair as the bilingual dictionary is updated. This is to further solidify the hold of top performing candidate translations on their initial positions. The argument is that, if a candidate translation does not change its similarity measurement over multiple iterations relative to newly introduced candidates, then it must be the most correct translation. Since the search is exhaustive in nature, the accuracy is higher, but then computation time is more. 4 The Filipino grammar The Filipino grammar was defined manually by formalizing observable conceptual rules and patterns of the language upon consultation with linguists, and specified using the lexical functional grammar (LFG) formalism. The main building block of LFG is the context free grammar which handles the syntax level of the language and the additional semantic actions that capture the semantic categories of words in the sentence such as subject and object. To illustrate, the top-level grammar rule for a sentence is defined using the LFG rule as follows: IC::=NP (  X  SUBJ=  X  )VP(  X  =  X  ) which is read as IC (or an independent clause) is defined as a NP (or noun phrase) followed by a VP (or verb phrase) and the semantic information from noun phrase will be the SUBJ (or subject) of the sentence.

One of the major challenges of the Filipino language is its free word order in sentence formation. Due to its free word order nature, one sentence in English can be translated to various sentences in Filipino. For instance, the English sentence The man bought an umbrella from the store can be translated into many different Filipino sentences while maintaining the semantics of the original English sentence, five of which are as follows:
Bumili ang lalaki ng payong sa tindahan. The man bought the umbrella Bumili ng payong ang lalaki sa tindahan.
 Bumili sa tindahan ng payong ang lalaki.
 Ang lalaki ay bumili ng payong sa tindahan.
 Ang lalaki ay bumili sa tindahan ng payong.
 Also, the construction of the sentence depends on the focus of the sentence. Considering the same English sentence The man bought an umbrella from the store , some of the possible translations in Filipino with varying foci would be as follows:
Bumili ang lalaki ng payong sa tindahan. The man bought the umbrella Binili ng lalaki ang payong sa tindahan.
 Binilhan ng lalaki ng paying ang tindahan.

The foci in these Tagalog sentences are the man, the umbrella and the store, respectively. To add, within phrases, the Filipino language also exhibits the free word order phenomenon such as the rearranging of the adjective and its noun. For instance, the phrase ang magandang bulaklak ( the beautiful flower ) can be written as ang bulaklak na maganda . Some adverbial phrases can also be placed at different places in a sentence. For instance, the sentence Ako ay umalis sa bahay kanina ( I left the house earlier ) can be written as: Ako ay umalis kanina sa bahay.
 Kanina ako umalis sa bahay.

Because of this free-word order phenomenon in Filipino sentences, there are problems in capturing the rules for the Filipino language to be able to represent all the possible combinations that the language provides. This means that the number of production rules for the Filipino grammar representation to a great extent, is more than its English counterpart. Also, because of this, the translation mapping from source language to target language, that is English to Filipino, and vice versa, also poses problems of one-to-many and many-to-one relationships, respectively.
Also, unlike the English language, Filipino grammar rules do not always revolve around the verb. To illustrate, the sentence Ang sundalo , tatlo ang asawa ( The soldier has three spouses ) does not contain any verb. In another instance, Si Pedro sinuntok si Juan ( Pedro punched Juan ) and Si Pedro sinuntok ni Juan ( Pedro was punched by Juan ) use the same grammar rule, however, the markers (not the verb) si and ni determine whether the sentence is in active or passive voice.

To add, morphological information play a crucial role in the accurate extraction of information from the surface form words, since it also determines the focus of the sentence and the over-all semantics of what is being analyzed. For example, the sentences Nilusob ng sundalo ang kampo ng NPA and Linusob ng sundalo ang kampo ng NPA , the translation would be The soldiers attacked the camp of the NPA or The soldiers sieged the camp of the NPA . Here, the word lusob may be translated differently (due to severity) depending on the affix.

Semantic information in the lexicon and the use of grammar formalisms for natural languages such as LFG are crucial in the effective capturing of relevant information for proper translation. For example, the sentences Nagpaluto ako ng spageti sa Nanay ko (I asked my mother to cook spaghetti for me), Nagpainom ako ng gamot sa anak ko ( I gave medicine to my child rather than I asked my child to drink medicine for me ), and Nagpainom ako ng beer sa kaibigan ko ( I treated by friends to beer rather than I asked my friends to drink beer for me ) have the same grammar, but the beneficiaries are different and the interpretations are different based on the relationship of the action and the object. 5 Corpora Our work requires both parallel English-Filipino corpora and mono-lingual corpora. The example-based MT engines require parallel English-Filipino corpora, while components of the system such as the part of speech Filipino tagger only requires Filipino corpora. We have built bilingual parallel English-Filipino corpora which consist of 207,000 words, and currently half of the Filipino documents are manually POS tagged and verified by linguists, and about 4,000 words in the mono-lingual Filipino corpus. Because of the nature of Filipino sentences wherein the semantics of the words greatly influence the semantics of the sentence, a careful analysis of the Filipino input sentence requires a specific tag rather than just a general tag. For instance, the verb and its affix determine the benefactors, as in the nagpainom and nagpaluto examples in the previous section. The number of arguments of some words is also non-deterministic such that for one word, the context of a word determines the number of arguments in the sentence, as in Nagpaluto ako sa Nanay ko ng spageti ( I asked my mother to cook spaghetti for me ) where ng spageti can be absent from the sentence.

To address the need of building a reliable Filipino corpora and yet minimizing the need for manual encoding, automatic methods for corpora creation are explored. AutoCor is our method for the automatic acquisition and classification of corpora of documents in closely related languages (Dimalen 2004 ). It is an extension and enhancement of CorpusBuilder, a system that automatically builds specific minority language corpora from a closed corpus (Ghani et al. 2001 ). We address a problem with the Tagalog corpus generated by CorpusBuilder which contains documents in other closely-related languages to Tagalog and not Tagalog documents alone. We used the query generation method odds ratio which was reported to produce best results in CorpusBuilder, and introduced the concept of common word pruning to the language models of closely related languages, which was found to improve the precision of the system. The method was implemented in PHP and PERL &amp; tested on 3 most closely related languages in the Philippines, namely: Bicolano, Cebuano, and Tagalog (Fortunato 1993 ). Each of the target languages was tested for query lengths 1 X 5, with 100 generated queries per query length, both with and without common word pruning. Results show that common word pruning improved the precision of the system (Bicolano: with 52.96% highest improvement at query length 4, Cebuano: with 18.00% highest improvement at query length 1, Tagalog: with 19.78% highest improvement at query length 2).

We developed the Filipino tagset with 9 general POS tags, 60 specific POS tags and 5 other tags (for punctuation and currency symbols), based on the Penn Treebank tagset which contains 36 POS tags and 12 other tags (Marcus et al. 1993 ). We identified tags for nouns, pronouns, determiners, adjectives, conjunctions, verbs, adverbs, cardinal number, and punctuation marks. One of the main differences in the tagset of English is the tag for the word ay which is literally translated to is in English. In the sentence Ako ay kumakain ( I am eating ), the Tagalog ay is not considered as a verb but as a lexical marker since it only signifies that the sentence is in the form subject + ay + predicate and is not in the natural order. The natural rendition of this sentence is Kumakain ako which is of the form predicate + subject . Also, singular and plural personal pronouns have distinct tags, while gender in Tagalog pronouns such as siya ( he or she ) is not captured. Interjections are also tagged in Tagalog. The English if which is translated to kung in Tagalog is tagged as a conditional adverb rather than a conjunction.

While our linguists are manually tagging our corpora, we attempted to build automatic POS taggers as well. The example-based tagger requires a large corpus where words are associated with the corresponding part of speech tags, while the rule-based tagger based on Brill X  X  tagger (Brill 1992 ) also learns tagging rules from examples. Initial tagging can be done through our template-based Tagalog tagger (Rabo 2004 ) since accuracy of this tagger is only 83% for general tags and 77% for specific tags, and verification of tags are done manually so that tags can be confidently considered correct. 6 Translation rules Transfer rules devised for the rule-based MT engine is based on the LFG specification of the two languages and are bi-directional. It consists of mappings of devised schematas which are primarily composed of semantic representations from one language to the other, and vice-versa. For instance, the translation of the Filipino sentence Tumakbo siya ( He ran ) used two translation rules 5 and 6 to translate the verb and the pronoun, respectively, which has a one-to-one correspondence, though the order has been interchanged.

In contrast to the rule-based MT which requires building the rules by hand, the corpus-based MT system automatically learns how translation is done through examples found in a corpus of translated documents. The system can incrementally learn when new translated documents are added into the knowledge-base, thus, any changes to the language can also be accommodated through the updates on the example translations. This means it can handle translation of documents from various domains. The principle of garbage-in-garbage-out applies here; if the example translations are faulty, the learned rules will also be faulty. That is why, although human linguists do not have to specify and come up with the translation rules, the linguist will have to first verify the translated documents and consequently, the learned rules, for accuracy. Unfortunately, the rules that were learned by our systems are still not readable and understandable to expert linguists and have to be translated into a form that would be comprehensible to them.
It is not only the quality of the collection of translations that affects the overall performance of the system, but also the quantity. The collection of translations has to be comprehensive so that the translation system produced will be able to translate as much sentences as possible. The challenge here is coming up with the quantity of examples that is sufficient for accurate translation of documents.

With more data, a new problem arises when the knowledge-base grows so large that access to it and search for applicable rules during translation requires tremendous amount of access time and to an extreme becomes difficult. Exponential growth of the knowledge-base may also happen due to the free word order nature of Filipino sentence construction, such that one English sentence can be translated to several Filipino sentences. When all these combinations are part of the translation examples, a translation rule will be learned and extracted by the system for each combination, thus, causing growth of the knowledge-base. Thus, algorithms that perform generalization of rules are considered to remove specificity of translation rules extracted and thus, reduce the size of the rule knowledge-base.

For our example-based MT system, transfer rules are learned using the general framework used by (Probst 2002 ) and David (Chiang 2005 ), which has three steps: seed rule generation, compositionality, and generalization. In seed rule generation, seed rules that define the token sequence, expressed as a combination of POS tags and possibly constant words, token constraints and alignment scheme of a translation pair are generated. Compositionality infers rules of higher syntactic structure, that is, constituent labels are deduced by using the longest adjacent POS tags found in both the English and Filipino rule. The system groups together similar rules and generalizes it to encompass a wider range of unseen examples. The major contribution of this work is the use of the longest common substring of POS tags instead of using a parser based on a grammar specification of the language. So, an English sentence with POS sequence det noun verb prep det noun and Filipino counterpart with sequence verb det noun prep noun will lead to a compositional rule X1  X  det noun , therefore replacing all occurrences of det noun with X1. Similar extracted compositionality rules are grouped together and are combined to form new rules which are applicable to a wider set of sentences. Generalization of attributes is based on the seeded version space learning (Probst 2002 ); however, it is updated due to the removal of a parser. Another basis of similarity amongst compositionality rules are the co-occurring tags found in the sentences these compositionality rules are used. A window of two tags, meaning the two tags before and after a selected tag, is applied and compositionality rules with similar windows are generalized accordingly. This type of generalization is termed as functional generalization, or generalizing the functionality or usage of the compositionality rules. An example of this would be det noun and det adj noun , which are known to humans as noun phrases and are also generalized accordingly by our system. Based on empirical tests, it can be observed that English to Filipino translations had a higher score than its Filipino to English counterparts, which is due to the low accuracy of the Filipino tagger as compared with the English tagger. This means that a learned functional rule in Filipino will be applicable to smaller group of sentence structures as compared to a functional rule in English. For disambiguation, we used semantic information that was derived from WordNet2.1 (Miller et al. 1998 ) for the words in the corpus used, and adopted to correct Filipino meanings. In general, we have achieved 68% accuracy of translated sentences when all other information in morphology, lexicon and tagging are correct. The 32% error can be attributed to lack of information in the lexicon for possible disambiguation by the semantic analyzer (Alcantara et al. 2006 ).

Another way to capture trends in the example translations is through templates and chunks, so instead of rules, templates and chunks are saved into the knowledge-base. Sentence templates are used for translation, and when no appropriate templates are available, phrase translation chunks are used for the construction of the translations. We adopted the machine learning techniques to implement the similarity template learning algorithm performed by (Cicekli and Gu  X  venir 2001 ), and introduced template refinement and derivation of templates from previously learned chunks. To improve translation quality, new chunk alignment and splitting algorithms are introduced into the training process while a flexible template and chunk-matching scheme is established for translation. In training, strict chunk alignment with splitting (SCAS) is followed to ensure that all tokens in a chunk of one language are correctly aligned with the corresponding chunk in the other language. To illustrate, an input English sentence The pretty Sampaguita is the national flower will be translated to Marikit na Sampaguita ay ang pambansang bulaklak , which should have been the correct translated sentence Ang marikit na Sampaguita ay ang pambansang bulaklak . Since, the templates and chunks learned by the system and used for this given input English sentence are X is Y  X  X ay Y and chunks the pretty Sampaguita  X  marikit na Sampaguita ,Z  X  ang Z, and the national flower  X  ang pambasang bulaklak , the phrase The pretty Sampaguita was translated to Marikit na Sampaguita using the first chunk.

Test results show that SCAS instead of loose chunk alignment wherein correspondences are not required improves quality of learned input. To add, experiments on the filtering of commonly occurring words between the two languages (as well as noise words, which are words in one language which does not have a correspondence in the other language) produces better templates thereby improving overall quality, and reduces word and sentence error rates by as much as half during translation. Test results show an accuracy of up to 96% in the testing of a translation corpus. Our results show possible extensions on a more stringent match disambiguation procedure, an algorithm that accepts chunks with empty contents, a feasible chunk refinement method, more comprehensive linguistic resources, or an approach to Cicekli X  X  difference template learning algorithm (Go et al. 2006 ). This is used during the template extraction phase, to ensure that the system does not learn templates whose fixed elements contain only common or noise words, e.g., The X  X  Ang X. This also prevents the system from learning long chunks for X, which would be very difficult to use during translation.
 7 Summary Manual and automatic creation of language resources are explored for lexical and morphological knowledge bases, lexicons, grammar, corpora and translation rules. The accuracy of the language translation is largely dependent on the comprehen-siveness and correctness of the language resources for Filipino and for English-Filipino translation, thus, great pains are exerted to build as much as we can as accurately as we can. But, we are a long way off our target. For example, in an automatic lexicon extraction study conducted by Rapp ( 1999 ) from non-parallel texts, the corpus used had as much as 163 million words, which were taken from German and English newspapers articles. To date, the multi-engine MT project has built the corpus for Filipino of 207,000 words, but only half of the tags so far are verified by expert linguists.
 Interdependence of language resources is also a major problem in this study. Take for instance, the part-of-speech tagger for Filipino which uses a stemmer requires a lexicon. Due to the minimal resources position, excluding the lexicon in the part-of-speech tagger architecture caused many errors in the final analysis of the tags generated for testing documents.

Efforts are made in the building of language resources for the implementation of a Multi-Engine English-Filipino machine translation system, from almost non-existent digital forms. We consider here the computational aspects of these languages since there are already sufficient materials that address the theoretical aspects. We address both manual and automatic constructions of these language resources, problems associated with these and the solutions provided.
 References
