 Human communications in real world situations interlace multiple topics which are related to each other in conversational contexts. This fact sug-gests that a dialog system should be also capable of conducting multi-topic conversations with users to provide them a more natural interaction with the system. However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task. Although some multi-task dialog systems have been proposed (Lin et al., 1999; Ikeda et al., 2008; Celikyilmaz et al., 2011), they have aimed at just choosing the most proba-ble one for each input from the sub-systems, each of which is independently operated from others.
To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers (Nakata et al., 2002; Lagus and Kuusisto, 2002; Adams and Martell, 2008) have considered this dialog topic identification as a sep-arate sub-problem of dialog management and at-tempted to solve it with text categorization ap-proaches for the recognized utterances in a given turn. The major obstacle to the success of these approaches results from the differences between written texts and spoken utterances. In most text categorization tasks, the proper category for each textual unit can be assigned based only on its own content. However, the dialog topic at each turn can be determined not only by the user X  X  inten-tions captured from the given utterances, but also by the system X  X  decisions for dialog management purposes. Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related ex-pressions explicitly in their utterances.

The other direction of dialog topic tracking ap-proaches made use of external knowledge sources including domain models (Roy and Subramaniam, 2006), heuristics (Young et al., 2007), and agen-das (Bohus and Rudnicky, 2003; Lee et al., 2008). These knowledge-based methods have an advan-tage of dealing with system-initiative dialogs, be-cause dialog flows can be controlled by the sys-tem based on given resources. However, this as-pect can limit the flexibility to handle the user X  X  responses which are contradictory to the system X  X  suggestions. Moreover, these approaches face cost problems for building a sufficient amount of re-sources to cover broad states of complex dialogs, because these resources should be manually pre-pared by human experts for each specific domain.
In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building re-sources. Composite kernels have been success-fully applied to improve the performances in other NLP problems (Zhao and Grishman, 2005; Zhang et al., 2006) by integrating multiple individual ker-nels, which aim to overcome the errors occurring at one level by information from other levels. Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context. Figure 1: Examples of dialog topic tracking on Singapore tour guide dialogs Dialog topic tracking can be considered as a clas-sification problem to detect topic transitions. The most probable pair of topics at just before and after each turn is predicted by the following classifier: f ( x t ) = ( y t  X  1 , y t ) , where x t contains the input features obtained at a turn t , y t  X  C , and C is a closed set of topic categories. If a topic transition occurs at t , y t should be different from y t  X  1 . Oth-erwise, both y t and y t  X  1 have the same value.
Figure 1 shows an example of dialog topic tracking in a given dialog fragment on Singapore tour guide domain between a tourist and a guide. This conversation is divided into three segments, since f detects three topic transitions at t 1 , t 4 and t . Then, a topic sequence of  X  X ttraction X ,  X  X rans-portation X , and  X  X ood X  is obtained from the results. The classifier f can be built on the training exam-ples annotated with topic labels using supervised machine learning techniques. Although some fun-damental features extracted from the utterances mentioned at a given turn or in a certain number of previous turns can be used for training the model, this information obtained solely from an ongoing dialog is not sufficient to identify not only user-initiative, but also system-initiative topic transi-tions.

To overcome this limitation, we propose to leverage on Wikipedia as an external knowledge source that can be obtained without significant effort toward building resources for topic track-ing. Recently, some researchers (Wilcock, 2012; Breuing et al., 2011) have shown the feasibility of using Wikipedia knowledge to build dialog sys-tems. While each of these studies mainly focuses only on a single type of information including cat-egory relatedness or hyperlink connectedness, this work aims at incorporating various knowledge ob-tained from Wikipedia into the model using a com-posite kernel method.

Our composite kernel consists of two different kernels: a history sequence kernel and a domain context tree kernel. Both represent the current di-alog context at a given turn with a set of relevant Wikipedia paragraphs which are selected based on the cosine similarity between the term vectors of the recently mentioned utterances and each para-graph in the Wikipedia collection as follows: where x is the input, p i is the i -th paragraph in the Wikipedia collection,  X  ( p i ) is the term vector extracted from p i . The term vector for the input x ,  X  ( x ) , is computed by accumulating the weights in the previous turns as follows: where  X  i = the utterance mentioned in a turn t , tf idf ( w i , u t ) is the product of term frequency of a word w i in u t and inverse document frequency of w i ,  X  is a decay factor for giving more importance to more recent turns, | W | is the size of word dictionary, and h is the number of previous turns considered as dialog history features.

After computing this relatedness between the current dialog context and every paragraph in the Wikipedia collection, two kernel structures are constructed using the information obtained from the highly-ranked paragraphs in the Wikipedia. 3.1 History Sequence Kernel The first structure to be constructed for our com-posite kernel is a sequence of the most similar paragraph IDs of each turn from the beginning of the session to the current turn. Formally, the se-quence S at a given turn t is defined as: where s j = argmax i ( sim ( x j , p i )) .
Since our hypothesis is that the more similar the dialog histories of the two inputs are, the more similar aspects of topic transtions occur for them, we propose a sub-sequence kernel (Lodhi et al., 2002) to map the data into a new feature space de-fined based on the similarity of each pair of history sequences as follows: K s ( S 1 , S 2 ) = where A is a finite set of paragraph IDs, S is a fi-nite sequence of paragraph IDs, u is a subsequence of S , S [ j ] is the subsequence with the i -th charac-ters  X  i  X  j , l ( i ) is the length of the subsequence, and  X   X  (0 , 1) is a decay factor. 3.2 Domain Context Tree Kernel The other kernel incorporates more various types of domain knowledge obtained from Wikipedia into the feature space. In this method, each in-stance is encoded in a tree structure constructed following the rules in Figure 2. The root node of a tree has few children, each of which is a subtree rooted at each paragraph node in: where  X  is a threshold value to select the relevant paragraphs. Each subtree consists of a set of fea-tures from a given paragraph in the Wikipedia col-lection in a hierarchical structure. Figure 3 shows an example of a constructed tree.

Since this constructed tree structure represents semantic, discourse, and structural information extracted from the similar Wikipedia paragraphs to each given instance, we can explore these more enriched features to build the topic tracking model using a subset tree kernel (Collins and Duffy, 2002) which computes the similarity between each pair of trees in the feature space as follows: where N T is the set of T  X  X  nodes,  X  ( n 1 , n 2 ) = P 1 iff the i -th tree fragment occurs with root at node n and 0 otherwise. 3.3 Kernel Composition In this work, a composite kernel is defined by com-bining the individual kernels including history se-quence and domain context tree kernels, as well as Figure 2: Rules for constructing a domain context tree from Wikipedia: PAR, ART, SEC, and CAT are acronyms for paragraph, article, section, and category, respectively
Figure 3: An example of domain context tree the linear kernel between the vectors representing fundamental features extracted from the utterances themselves and the results of linguistic preproces-sors. The composition is performed by linear com-bination as follows:
K ( x 1 , x 2 ) =  X   X  K l ( V 1 , V 2 ) +  X   X  K s ( S 1 , S where V i , S i , and T i are the feature vector, his-tory sequence, and domain context tree of x i , re-spectively, K l is the linear kernel computed by in-ner product of the vectors,  X  ,  X  , and  X  are coeffi-cients for linear combination of three kernels, and  X  +  X  +  X  = 1 . To demonstrate the effectiveness of our proposed kernel method for dialog topic tracking, we per-formed experiments on the Singapore tour guide dialogs which consists of 35 dialog sessions col-lected from real human-human mixed initiative conversations related to Singapore between guides and tourists. All the recorded dialogs with the total length of 21 hours were manually transcribed, then these transcribed dialogs with 19,651 utterances were manually annotated with the following nine topic categories: Opening, Closing, Itinerary, Ac-commodation, Attraction, Food, Transportation, Shopping, and Other.

Since we aim at developing the system which acts as a guide communicating with tourist users, an instance for both training and prediction of topic transition was created for each turn of tourists. The annotation of an instance is a pair of previous and current topics, and the actual number of labels occurred in the dataset is 65.

For each instance, the term vector was gener-ated from the utterances in current user turn, previ-ous system turn, and history turns within the win-dow sizes h = 10 . Then, the history sequence and tree context structures for our composite kernel were constructed based on 3,155 articles related to Singapore collected from Wikipedia database dump as of February 2013. For the linear ker-nel baseline, we used the following features: n-gram words, previous system actions, and current user acts which were manually annotated. Finally, 8,318 instances were used for training the model. We trained the SVM models using ing five different combinations of kernels: K l only, K l with P as features, K l + K s , K l + K t , and K l + K s + K t . The threshold value  X  for selecting P was 0.5, and the combinations of kernels were performed with the same  X  ,  X  , or  X  coefficient values for all sub-kernels. All the evaluations were done in five-fold cross validation to the man-ual annotations with two different metrics: one is accuracy of the predicted topic label for every turn, and the other is precision/recall/F-measure for each event of topic transition occurred either in the answer or the predicted result.

Table 1 compares the performances of the five combinations of kernels. When just the para-graph IDs were included as additional features, it failed to improve the performances from the baseline without any external features. However, our proposed kernels using history sequences and domain context trees achieved significant perfor-mances improvements for both evaluation metrics. While the history sequence kernel enhanced the coverage of the model to detect topic transitions, K l 62.45 42.77 24.77 31.37 K l + P 62.44 42.76 24.77 31.37 K l + K s 67.19 39.94 40.59 40.26 K l + K t 68.54 45.55 35.69 40.02 All 69.98 44.82 39.83 42.18 Figure 4: Error distibutions of topic transitions: FN and FP denotes false negative and false posi-tive respectively. USR and SYS in the parentheses indicate the initiativity of the transitions. the domain context tree kernel contributed to pro-duce more precise outputs. Finally, the model combining all the kernels outperformed the base-line by 7.53% in turn-level accuracy and 10.81% in transition-level F-measure.

The error distributions in Figure 4 indicate that these performance improvements were achieved by resolving the errors not only on user-initiative topic transitions, but also on system-initiative cases, which implies the effectiveness of the struc-tured knowledge from Wikipedia to track the top-ics in mixed-initiative dialogs. This paper presented a composite kernel approach for dialog topic tracking. This approach aimed to represent various types of domain knowledge ob-tained from Wikipedia as two structures: history sequences and domain context trees; then incor-porate them into the model with kernel methods. Experimental results show that the proposed ap-proaches helped to improve the topic tracking per-formances in mixed-initiative human-human di-alogs with respect to the baseline model.
