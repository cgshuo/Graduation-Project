 1. Introduction other classification methods [27,39] .
 without calculating every case.
 based on a vector space model proposed in [31] . It offers a balanced global result. In this sequel study, we prove that this measure satisfies a formal similarity metric definition. followed by similarity measures in CBR. Section 5 shows experimental results. Section 6 concludes the article. 2. Formal concept analysis information system. We introduce basic definitions and ideas of FCA below [11] .
De called the objects and the elements of M are called the attributes of the context. ( g , m ) in a relation I with an attribute m and is read as  X  the object g has the attribute m association between object and its attributes below.

De fi nition 2. For a set A p G of objects, A  X  is defined as A defined as B  X  :={ g  X  G | gIm for all m  X  B }.

De fi nition 3. A formal concept of the formal context ( G , M , I ) is a pair ( A , B ) with A and B the intent of the formal concept ( A , B ). B G ; M
De fi nition 4. If ( A 1 , B 1 ) and ( A 2 , B 2 ) are formal concepts of the formal context (or ( A 2 , B 2 ) is a superconcept of ( A 1 , B 1 )), provided that A denoted by B G ; M ; I  X  X  and is called the concept lattice of the formal context ( G , M , I ).
Theorem 1. (The Basic Theorem on Concept Lattice) [11] Let T be an index set and, for every t complete lattice in which infimum and supremum are given by:
A complete lattice V is isomorphic to B G ; M ; I  X  X  , denoted byV such that  X   X  G  X  X  is supremum-dense in V,  X   X  M  X  X  is infimum-dense in V and gIm is equivalent to The mappings  X   X  g and  X   X  m in Theorem 1 indicate how a formal context can be identified in a concept lattice.
De fi nition 5. For an object g  X  G we write g  X  instead of { g { g  X 
G | gIm } is theattribute extentof theattribute m . Retaining the symbols used in Theorem 1 ,wewrite and  X  m for the attribute concept ( m  X  , m  X  X  ).
 to build a knowledge base. 3. Related works case retrieval in case-based classification. 3.1. Knowledge representation and its algorithm in FCA construction.
 object intent. Note that its time complexity is OG 2 M jj B
Godin et al. next proposed the incremental algorithm to update a concept lattice using O (2 concepts. Shuqun et al. resolved this issue [51] .Yuanetal. [53] improved Godin's algorithm to Oln 2 G complexity is OG 2 M jj B .
 will be modified by creating a new formal concept with new intent. The time complexity is O semilattices. 3.2. Similarity measures in FCA construction ( A , B )and( C , D ) in a formal concept, the local similarity measure, s with the formal concept weight specified by the user. formal concept, the Jaccard index ( s Jac ), Sorenesen coefficient ( s and previous cases in a knowledge base in a binary relation form. 3.3. Knowledge structure in case-based classi fi cation case-based classification.
 lattice form.
 Tartakovski et al. improved similarity measure into generalized case representation [8] .
In addition to these benefits, FCA gives incremental structure to facilitate a dynamic knowledge base. 3.4. Case retrieval in case-based classi fi cation described as follows. same group of problem descriptions [5,56] . 4. Our proposed case-based classi fi cation in CBR and a proposed theorem 4.1. Algorithms for knowledge construction described in intent form (or attribute concept) according to Definition 5 . referred to intent h  X  . We give ( X i , Y i ) as node i , the formal concept i in concept lattice the set of cases (extent), X p G , and Y is the set of attributes (intent), Y Algorithm 1. Algorithm for adding the new data into concept lattice.
If h  X  equals intent Y i , then { h } should also equal X
ReplaceNode function in Algorithm 2 ). This situation is now considered the new formal concept ({ h }, h
We can add a new formal concept with ({ h }, h  X  ) that is a subconcept of the formal concept ( X ( X , Y situation will check both the parent and child of a formal concept ( X Algorithm 2. Function is referred by Algorithm 1 .
 lattice in Fig. 2 (b). Similarly, we add object 5 into the concept lattice. The result is shown in Fig. 2 (c). 4.2. An appearance-based concept similarity measure [23,36] as shown in Theorem 2 . Let C P be a formal concept of formal context ( G , M , I ) representing a pair ( E problem descriptions and solution shared by those cases. A new problem is defined as C retrieved case(s), and I N is a set of new problem descriptions provided by the user. Initially E E defined as Sim ( C N , C P ). The closer the value of Sim ( C
De fi nition 6. [31] Given a formal concept of a previous case C formal context ( G , M , I ), the concept similarity measure is defined as where N is the total number of formal concepts, Fa u , Fa and Fc v , Fc k and Fc l are the frequencies of cases v , k and l , respectively, { v , k , l } Theorem 2. Sim ( C N , C P ) is the degree of similarity between the formal concepts C if Sim ( C N , C P ) satisfies the following conditions [ 36 ]: 1. 0  X  Sim ( C N , C P )  X  1. 2. Sim ( C N , C P )=1 if C N = C P . 3. Sim ( C N , C P )= Sim ( C P , C N ). 4. Sim ( C N , C O )  X  Sim ( C P , C N ) and Sim ( C N , C Proof. Suppose C P =( E P , I P ), C N =( E N , I N ) and C (1) 0  X  Sim ( C N , C P )  X  1. This condition has the following cases: (i) C Case 1. C N = C P  X  [( E P = E N ) and ( I P = I N )]. Hence, | E
Case 2. C N  X  C P =  X   X  [ E P  X  E N =  X  and I P  X  I N =  X  0  X  0  X  X  X  0 : Case 3. C N  X  C P  X  X  X   X  [ E P  X  E N  X  X  X  or I P  X  I N  X  X  X  ]. For this case, we give | E | I |=| I N |= q then r  X  p and s  X  q . Thus, from Definition 6 , we have Sim C In summary, the first condition certainly guarantees 0  X  Sim ( C (2) Sim ( C N , C P )=1 if C P = C N .
 This condition is a special case ( Case 1 ) of the first condition. Hence, this condition guarantees that C (3) Sim ( C N , C P )= Sim ( C P , C N ).
 C theory satisfies the commutative property i.e., E P  X  E N satisfies the commutative property. Thus, this condition satisfies the symmetry property. (4) Suppose C N p C P C O . We have E N p E P E O and/or I 1) Sim ( C N , C O )  X  Sim ( C P , C N ) and 2) Sim ( C N , C O )  X  Sim ( C O , C N ). Shortly, we define Consider that Sim ( C N , C O )  X  Sim ( C P , C N )or Sim ( C From Eq. (6) , we can conclude that Sim ( C N , C O )  X  Sim ( C considering directly matching with binary relation. 4.3. An illustrative example of case-based classi fi cation Suppose our case-based classification contains the cases shown in Fig. 2 (c). Also, assume that the new problem ( C described { b , c , d }. 4.3.1. Retrieve initially compute  X  i  X  I N log N Fa We can thus use these values to compute the similarity between C be retrieved for solving new problem.
 4.3.2. Reuse and revise powerful that it can utilize to knowledge base ostensibly. 4.3.3. Retain 5. Experiment results concept lattice.
 algorithm can complement the nature of hierarchical data very well as demonstrated later in this section.
For environment of our implementation, we used the Toshiba Portege M600 notebook with an Intel(R) Core(TM) 2 Duo version 6.0.1. 5.1. Retrieval performance data structure better than a non-hierarchical data structure.
 improve by computing only related sublattices.
 5.2. Incremental knowledge performance
Our proposed algorithm for an incremental concept lattice is as shown in Algorithm 1 . The steps from lines 2 precedent knowledge base. Next, the best case time occurs when h function takes about NewNode jj B . Thus, the best case of our proposed algorithm is O other hand, the worst-case time is O B  X  NewNode jj B  X  NewNode quadratic function, although for others, the polynomial function is the worst-case. would infer that each case in the data set is an independent case different number of their concepts as shown in Table 3 . 5.3. Performance comparison with other methods as the Hayes-Roth data set.
 confirms that our algorithm performs well on a large hierarchical data set. 6. Conclusion classifier gives the best accuracy for hierarchical data.
 Acknowledgments helpful comments and suggestions of the reviewers, which have improved the presentation.
References
