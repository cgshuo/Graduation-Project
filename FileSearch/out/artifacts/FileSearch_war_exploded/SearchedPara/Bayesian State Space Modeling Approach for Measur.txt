
Analysis of Point of Sales (POS) data is an important research area of marketing science and knowledge discov-ery, which may enable marketing managers to attain the ef-fective marketing activities. To measure the effectiveness of marketing activities and baseline sales, we develop the multivariate time series modeling method in the framework of a general state space model. A multivariate Poisson model and a multivariate correlated auto-regressive model are used for a system model and an observation model. The Bayesian approach via Markov Chain Monte Carlo (MCMC) algorithm is employed for estimating model pa-rameters. To evaluate the goodness of the estimated mod-els, the Bayesian predictive information criterion is utilized. The proposed model is evaluated with its application to ac-tual POS data.
Analysis of Point of Sales (POS) data is an important re-search area of marketing science and knowledge discovery, which may enable marketing managers to attain the effec-tive marketing activities. Marketing activities include, for example, temporary price cuts, display promotions, point of purchase, advertising catalogs and so on. There is a number of studies that investigated the relationship between market-ing activities and their effects on increasing sales [1, 2, 3, 4].
Since the effectiveness of these marketing activities strictly relies on accurate forecasts of the daily demand for each item being sold at a retail store, the prediction of daily sales through the analysis of POS data is valuable to assist marketing managers. The prediction of daily sales is also important for inventory management, manpower planning and management strategies. Therefore, there has been con-siderable effort expended in establishing excellent statistical techniques for analyzing the POS data [5, 6, 7, 8, 9].
A detection of baseline sales, which measure the amount of unit sales in the absence of a promotion, is also important to assess the profitability and effectiveness of marketing ac-tivities [10, 11]. [12] developed a descriptive model of how promotions can impact baseline sales over time. In addition to marketing activities, daily sales are affected by several factors, including economic condition, the day of the week, weather conditions and special events. It is therefore ben-eficial to construct a statistical methodology that allows us to predict daily and baseline sales of individual items by considering specific factors.

The main aim of this paper is to develop the multivariate time series modeling method in the framework of a general state space model [13]. One can consider the use of the stan-dard regression technique. Compared with the regression technique, however, an advantage of the proposed method is it can incorporate prior information that characterizes the dynamic behavior of daily sales. For example, it can es-timate the long term trend of baseline sales. Furthermore, Shapiro-Wilk normality test rejected the null hypotheses of the normality of our dataset, which is one the most essential assumption of the standard regression technique.

The general state space model is constructed by speci-fying two stochastic components: a system equation, and an observation equation [14]. In this paper, the multi-variate Poisson model and the multivariate correlated auto-regressive model are used for these two equations.
Since the likelihood function depends on the high-dimensional integrals, an implementation of the maximum likelihood method is very difficult. In such a case, the Bayesian approach via the Markov Chain Monte Carlo (MCMC) algorithm is useful for estimating model param-eters. It allows us to estimate the models easily because model parameter inference can be done without evaluating the likelihood function. After estimating model parame-ters, we have to determine the best fitting model from a set of candidate models. To evaluate the goodness of the estimated models, we employed the Bayesian predictive in-formation criterion [15]. The proposed model is evaluated with its application to actual POS data. The results indicate that the proposed method extract useful information.
A general state space model [13] enables us to conduct nonlinear and non-Gaussian state space modeling. Gener-ally, the general state space model is described by the fol-lowing system:
Observation equation : y t  X  f ( y t | F t ,h t , ..., h 1
System equation : h t  X  f ( h t | F t  X  1 ,h t  X  1 , ..., h for t =1 , 2 ..., n , where n denotes the sample size. A se-a state variable h t is unobserved. F t denotes the history of the information sequence up to time t , ( y t | F t ,h of y t given F t ,h t , ..., h 1 and of h t given F t  X  1 respectively.

In this research, we focus on a set of p times series data for daily unit sales of a certain kind of items y jt ( j = 1 , ..., p ) . Items would be a packed lunch, a sandwich, a tea beverage, coffee and so on.

Daily sales of products are generally affected by several factors, including the day of the week, weather, price pro-motion, display promotion and advertisement. To describe the daily unit sales y jt , we assume that y jt follows a Poisson distribution with the parameter  X  jt  X  effect, the weekly effect, the rain effect, the price promotion effect, the display promotion effect and the advertisement effect, respectively. Definitions of each variable are given as follows: Note that this model can easily incorporate other marketing-mix variables. Due to the availability of a dataset used in this paper, we considered only these five variables.
The coefficients  X  j =(  X  j 1 , ...,  X  j 5 ) are the unknown parameters to be estimated. Therefore, the daily unit sales are modeled as the conditional distribution given particu-lar specifications of the marketing-mix variables. Figure 1 shows the time series of daily unit sales for each item to be analyzed and the actual values of w jt , r jt , p jt , d jt
In this paper, we assume that the state variable, the base-line sales effect for the j th item, h jt follows a q -th order trend model given by where  X  jt  X  N (0 , X  jj ) is a Gaussian white noise sequence. For q =1 , it is locally constant and becomes a well-known random walk model, h jt = h j,t  X  1 +  X  jt .For q =2 and q =3 , the model becomes h jt =2 h j,t  X  1  X  h j,t  X  2 +  X  h details can be found in [14].

It is natural to consider that the daily unit sales are mutu-ally dependent on each other. A particularly useful form for considering this phenomenon is to introduce the correlation between the noises  X  jt and  X  kt :
Summarizing the above specification leads to the follow-ing observation equation and the system equation: mal density of h t =( h 1 t , ..., h pt ) with variance matrix  X  . For q =1 , the mean is h t  X  1 . A five dimensional vector x jt =( w jt ,r jt ,p jt ,d jt ,a jt ) includes the information on the weekly effect, the rain effect, the price promotion effect, the display promotion effect and advertisement effect.
One problem with state and parameter estimation is how to evaluate the likelihood function, which depends upon high-dimensional integrals:
L ( D n |  X  ,X n )= = = where D n = { y 1 , ..., y n } , y t =( y 1 t , ..., y pt set of observed data, X n = { x t ; t =1 , ..., n } , x t ( x 1 t , ..., x pt ) includes the information on the weekly ef-fect, the rain effect, the price promotion effect, the dis-play promotion effect, and advertisement effect for each item, and  X  =(  X  , vec( X )) is unknown parameter vec-tor. The conditional density functions f ( y jt | h jt ; tion equation and the system equation, respectively. In such a case Bayesian estimation techniques that usually imple-ment the MCMC algorithm allows us to handle the estima-tion problem very easily.
In this section, a Bayesian approach via the MCMC algorithm is developed. Thanks to advances in com-puter technology, MCMC techniques have become the stan-dard computational tools for Bayesian inference with high-dimensional posterior distributions. We can easily construct a MCMC sampler so that its stationary distribution is equal to the posterior distribution of model parameters given data and prior distribution of parameters. After a certain period, a generated realization of MCMC sample can be treated as a dependent sample from the posterior distribution. For more details on the MCMC method, we refer to [16, 17, 18].
As well as  X  , we regard the state vector h = ( h 1 , ...., h n ) as model parameters. An inference on the pa-rameters is then conducted by producing a sample from the posterior distribution  X  (  X  , h | D n ,X n )  X   X  (  X  )
In this paper, we assume prior independence of the pa-rameters  X  (  X  )=  X  (  X  )  X  ( X ) ,  X  (  X  )= 5 l =1  X  (  X  l posing the variance matrix  X  as a product of the variance and the matrix of correlations:  X = RCR , where R =( r ij ) is a diagonal variance matrix and C =( c ij ) is the correla-tion matrix [19], we conduct the Bayesian inference on  X  .
We now formulate a prior distribution on r ii ( i = of the elements { r ii ; i =1 , ..., p } are independently and identically distributed, we place a gamma prior with param-eters a and b on the diagonal entries of  X  :  X  (  X  ii )= which implies  X  ( r ii )=  X  (  X  ii ) To make the prior uninformative, we shall take a =10  X  10 and b =10  X  10 , respectively. For the prior distributions U [0 , 100] and U [  X  1 , 1] are employed.

In this paper, we also simply update each of the elements of the parameter vector and the latent volatility one at a time to sample from the posterior density. The algorithm is sum-marized as follows.
 Sampling algorithm: Step 1. Initialize  X  and h .
 Step 3. Sample  X  l from  X  l |  X   X   X  l , h ,D n . Step 4. Sample r ii from r ii |  X   X  r ii , h ,D n . Step 5. Sample c ij from c ij |  X   X  c ij , h ,D n . Step 6. Repeat Step 2  X  Step 5 for sufficient iterations.
Here h  X  h t denotes the rest of the h vector other than h The Metropolis-Hastings (MH) algorithm [20] is utilized to implement steps 2  X  5 by making a proposal draw from a random walk sampler. In our application, with regard to r , we are also able to directly sample from the conditional posterior densities of since our priors on these elements are conjugate.

Consider the case q =1 , the conditional density function conditional posterior density function of h t is  X  (  X   X   X   X   X   X   X   X   X   X   X   X   X   X  At the k -th iteration, we make a candidate draw of h ( k +1) using the Gaussian proposal density function p ( h t | h ( k ) centered at the current value h ( k ) t with the variance matrix  X  I p , where I p is the p -dimensional unit diagonal matrix. We then accept a candidate draw with the probability  X  = min 1 ,
The remaining conditional posterior density functions are given as follows  X  ( r  X  ( c As well as step 2, steps 3  X  5 are also implemented by using the MH algorithm. The outcomes from the MH algo-rithm can be regarded as a sample from the posterior density function after a burn-in period.

The remained problem is how to evaluate the goodness of the estimated model. In the next section, we consider the Bayesian model selection from a predictive point of view.
Suppose the independent observations D n = { y 1 , ..., y n } are generated from an unknown true dis-tribution G ( D n | X n ) having the probability density G (  X | X n ) . In practical situations it is difficult to obtain precise information on G (  X | X n ) from a finite number of observations. We therefore used the statistical model (2) as an approximating model. In this section, we assess the closeness of the estimated model to the true model from a predictive point of view.

Taking a Bayesian look at the information theoretic ap-proach, [15] and [21] considered maximizing the posterior mean of the expected log-likelihood = log L ( Z n |  X  ,X n )  X  (  X  | D n ,X n ) d  X  dG ( Z n | where Z n = { z 1 , ..., z n } is the unseen observation gener-ated from a true model G ( Z n | X n ) . The posterior density function  X  (  X  | D n ,X n ) is given by The best predictive distribution is chosen by maximizing the posterior mean of the expected log-likelihood among different statistical models.

The posterior mean of the expected log-likelihood de-pends on the unknown true model. Therefore, the problem is how to estimate the posterior mean of the expected log-likelihood accurately. A natural estimator of the posterior mean of the expected log-likelihood is the posterior mean of the log-likelihood,
It is well known that the posterior mean of the log-likelihood  X   X  generally provides a positive bias as an esti-mator of the posterior mean of the expected log-likelihood  X  . The reason is that the same data are used both to con-struct the posterior distributions and to evaluate the poste-rior mean of the expected log-likelihood.

Under some regularity conditions, [15] evaluated the asymptotic bias of the posterior mean of the log-likelihood as follows: n  X  b  X  E  X  | D  X  log { L ( D n |  X   X  n ,X n )  X  (  X   X  n ) } +tr J  X  1 n ( where  X   X  n = argmax  X   X  (  X  | y n ) is the posterior mode, and the matrices I n (  X  ) and J n (  X  ) are respectively given by with  X  n ( y t ,  X  ) = log f ( y t | F t  X  1 , x t ,  X  ) + log  X  (
Consider a situation, in which the prior is assumed to be dominated by the likelihood as n increases, or in other words, log  X  (  X  )= O (1) . Furthermore, assume that the specified parametric models contain the true model (or are close to the true model). In this case, as shown by [21], the posterior mean of the log-likelihood minus the posterior mean of the expected log-likelihood is approximated by half of the dimension of  X  . We also have the following approx-imation formula: tr { J  X  1 n ( X   X  n ) I n ( X   X  n ) } X  dim Under this special case, [15] showed that the asymptotic bias estimate n  X  b can be further simplified by the dimension of  X  .

Estimating the asymptotic bias of the posterior mean of the log-likelihood as an estimate of its expected log-likelihood by the dimension of  X  , the bias corrected pos-terior mean of the log-likelihood is given by  X   X   X  m/n .We then obtain a tailor-made version of the Bayesian predictive information criterion (BPIC; [15]):
BPIC =  X  2 n  X  ( X   X   X  m/n ) =  X  2 We can choose the predictive distribution that minimizes the Bayesian predictive information criterion, BPIC. [22] em-ployed BPIC for the evaluation of several stochastic volatil-ity models.

As an alternative criterion derived in the above frame-work, [21] proposed the deviance information criterion, DIC. From theoretical aspect, it is pointed out that the model chosen by DIC is more complex than that with BPIC and overfits the observed data [15, 23]. We therefore use BPIC.
In this section, we apply the proposed models to an anal-ysis of daily sales of the following 10 food items; cold bev-erages, coffee, tea beverages, cup noodle, rice balls, sand-wiches, packed lunches (type1), packed lunches (type2), jelly and yogurt. Information on daily unit sales for each item and on the daily marketing promotion, the executions of display promotion and price promotion, were available. The method presented was applied to data for the period of 1 July 2002 to 31 July 2002. Figure 1 shows the time series of daily unit sales.

Since the number of observations is small ( n =31 ), we fitted the proposed model with the order q =1 , 2 , 3 and 4. In our application, the total number of MCMC iterations is chosen to be 2,000. The first 1,000 iterations of MCMC chains were discarded as an initial burn-in period. Then, further simulations were performed. All inferences were derived using the remained 1,000 samples.

Table 3 reports the BPIC scores for each of q -th order trend models. The computing time to generate 10 itera-tions for each of the models is also reported. We performed the calculations based on Microsoft Windows XP, Pentium-R 2.0 GHz, running R. BPIC (6) preferred the third order trend model. Due to the limited data, in this analysis, BPIC placed importance on the penalty term. We therefore would like to the possibility that the BPIC perfers the higher order trend models if the data size were larger.

Figure 2 shows the fluctuations in the posterior means of baseline sales for each item. Note that the distributional range is different from Figure 1 Using 1,000 draws for each of the parameters, we calculated the posterior means of the correlation matrix C =( c ij ) We also calculated the poste-rior means and the 95% confidence intervals for the rest of the parameters. The 95% confidence intervals are estimated using the 2.5th and 97.5th percentiles of the posterior sam-ples. These quantities are reported in Tables 1 and 2.
The estimated coefficients of the weekly effect indicate that the daily sales of jelly are affected by the weekly effect. One of the reasons might be that a lot of children buy it on the weekend. With regard to the rain effect, the estimated coefficients of Coffee, Rice ball and Yogurt are above 10. The daily sales of these items therefore are affected by the weather.

We next discuss the effects of marketing promotion ac-tivities. The estimated coefficients of the price promotion effect reveal that the daily sales of packed lunch (type2) in-creases significantly when the price is cut. This indicates that a 10% price cut increases the  X  X xpected X  daily sales of 10 ( 104 . 57  X  0 . 1 ) units of type 2 packed lunches under the assumption that the remained conditions are constant. The estimated coefficients also indicate that consumer respond to the discounted cold beverages and coffee. With regard to the display promotion effect, the estimated coefficients of rice balls, packed lunches (type1), jelly and yogurt are above 10. Although the cost of the display promotion can be regarded as nearly zero for the retail store, it might be infor-mative to execute the effective display promotion. The esti-mated coefficients of the advertisement effect indicate that the daily sales of tea beverage, jelly and yogurt are affected by the advertisement effect. The estimated coefficients of sandwich also indicate that the daily sales of sandwich can not be increased even if the marketing manager execute the price cut, display promotion and advertisement.

A Gaussian graphical model [27] allows the descrip-tion of dependencies between stochastic variables. We now consider an undirected graph G =( h ,E ) with a set of p random variables h =( h 1 , ..., h p ) and a set of edges E = { e ij ; i =1 , ..., p, j &lt; i } where e ij is set to be one if vertices between h i and h j are included in G and set to be zero if vertices between h i and h j are not included in G . A focus of interest is the edge set E . It is well known that two variables are conditionally independent given a set of remaining variables if and only if a corresponding partial correlation vanishes [24, 25, 26].

We therefore calculated posterior means of pairwise par-tial correlation coefficients P = p ij . Figure 4 shows a graph based on the estimated posterior means of the pairwise par-tial correlation matrix. We separated the posterior means of the partial correlation coefficients into three groups, in-dicated by S , I and N . Here S = { e ij ; p ij  X   X  1 } consists of large values of posterior means of the pairwise partial correlations, and hence the corresponding edge sets e ij in-dicate a strong relationship between the daily sales of items i and j . The second group N = { e ij ; p ij  X   X  2 } consists of small values of posterior means of the pairwise partial correlations and corresponding edge set implies a weak re-lationship between the daily sales of these two items. The minate value of the posterior means of the pairwise partial correlations. In this paper, we shall specify the significant levels  X  2 =0 . 35 and  X  1 =0 . 60 .

It suggests that packed lunches (type1) and packed lunches (type2) have a strong relationship. The correspond-ing posterior means of the correlation is negative. There-fore, the baseline sales of the one item are in inverse pro-portion to that of the other item. This is useful information because if we focus only on the posterior means of the cor-relation matrix, we could conclude that the relationship is very weak. Figure 4 also indicates the very weak relation-ship between the baseline sales of the two items and tea beverages. It is suspected that there were a lot of customers who bought tea only because it was summer. Figure 4 also indicates the strong relationship between jelly and yogurt. Figure 4 shows that the posterior mean of the partial correla-tion coefficient for packed lunches (type1) and yogurt has a high score. Therefore it would be good to place yogurt next to packed lunches (type1), because the baseline sales these two items have a strong relationship. The reason might be that there are a lot of people who buy the packed lunches (type1) and the yogurt together. The extracted information from POS data would be useful for the management of mar-keting activities.

This paper considered the problem of identifying un-observed baseline sales, marketing promotion effects and other specific effects using POS data. We attempted to iden-tify the dependency of daily sales by estimating these unob-served factors. In the framework of a general state space model, we developed the multivariate time series modeling method that allows us to predict daily and baseline sales of individual items by considering specific factors. We em-ployed the multivariate Poisson and the multivariate corre-lated auto-regressive models that are used for the system equation and observation equation, respectively. Since the likelihood function depends on the high-dimensional in-tegrals, the Bayesian approach via the MCMC method is employed for estimating model parameters. To determine the best fitting model from a set of candidate models, the Bayesian predictive information criterion is utilized. Fitting the proposed model to POS data, interesting and practically important results are obtained. Our approach is attractive for the marketing field, because the unobserved baseline sales, marketing promotion effects and other specific effects are estimated by simultaneously.

As a further research, we suggest the proposed method would achieve more accurate estimation results if the data size were larger. Due to the limited data, a large dataset was not available for this paper. We would like to investigate this problem in a future paper.
 Acknowledgement The author gratefully acknowledges the constructive sug-gestions of three anonymous referees. The author is also grateful to Dr. Akihiro, Inoue for his constructive com-ments. This study was supported in part by a Grant-in-Aid for Young Scientists (B) (No.18700273).

Table 1. The posterior means of the correlation matrix C =( c (type1), P2: packed lunches (type2), JE: jelly and YO: yogurt. distributional range is different from Figure 1.
 the distributional range is different from Figure 1 e ij  X  S and e ij  X  I , respectively. Here S = { e ij ; p  X   X  } consists of large values of posterior means levels were set to be  X  2 =0 . 35 and  X  1 =0 . 60 .
