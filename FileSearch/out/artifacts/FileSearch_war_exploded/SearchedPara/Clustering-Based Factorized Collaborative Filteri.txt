 Factorized collaborative models show a promising accuracy and scalability in recommendation systems. They employ the latent collaborative information of users and items to achieve higher accuracy of recommendation. In this pa-per, we propose a new approach to improve the accuracy of two well-known, highly scalable factorized models: SVD++ and Asymmetric-SVD++. These are cutting-edge factorized models that have played a key role in the Netflix prize win-ner X  X  solution. We first employ collaborative information to categorize the users and items. We then discover the shared interests between these categories. Including this new in-formation, we extend these cutting-edge models regarding two main goals: 1) to improve their recommendation ac-curacies; 2) to keep the extended models still scalable. Fi-nally, we evaluate our proposed models on two recommenda-tion datasets: MovieLens100k, and Netflix. Our experiment shows that adding the shared interests among categories into these models improves their accuracy while maintaining scal-ability.
 H.3 [ Information storage and retrieval ]: Retrieval mod-els, Information filtering, Clustering; H.2 [ Database man-agement ]: Database Applications X  Data mining Collaborative Filtering, Factorizing, Neighborhood-Aware
Between 2007 to 2009, Netflix 1 hold a competition on rec-ommendation systems for the best collaborative filtering al-gorithm that predicts users X  ratings on a collection of its movies. For details of the provided dataset by Netflix, see [4,
Charles X. Ling is the contact author of this paper. http://www.netflix.com function of a Biased Matrix Factorization (BMF) model is as follows: where q i  X  R k and b i  X  R are the corresponded vector and bias value of item i , and p u  X  R k and b u  X  R are the corresponded vector and bias value of user u .

There are two common approaches to include neighbor-hood information into factorization models: 1) item  X  item models which consider if user u is interested in item i and its similar items. 2) user  X  user models that consider if user u and its similar users are interested in item i . However, item-item models are usually preferable as their less space and time complexity. This is because of the typical larger num-ber of users in recommendation systems. Although, both models ignore the neighborhood information of possible cat-egories that items and users may belong to. Thus, we first try to find the possible categories and then apply the shared interests between these categories in a number of CF models.
We first apply BMF on the known ratings to learn the latent vectors of each user and item. Kmeans then is ap-plied on these latent vectors with different selection of K (number of clusters) to find possible categories of items and users. Rating matrices are typically sparse in recommenda-tion systems. Hence, using latent vectors helps to reduce the complexity of clustering these large and sparse datasets. After finding these clusters (categories), we then correspond each a latent vector. We consider the shared ratings between these categories in a new matrix R  X  . Lets assume C u and C i as the clusters that contain user u and item i . In this new rating matrix, every r  X  C u ,C i reflects the average rating of the users inside the category C u on the items inside the category C i . We define n 0 &lt; n and m 0 &lt; m as the number of categories for users and items respectively.
As discussed earlier, neighborhood aware models employ the similarities between users and items to improve the rec-ommendation accuracy. However, they usually need to com-pute all pairwise similarities between items or users, which its complexity grows quadratically with the input size [5]. Koren [4, 5] solves this limitation by factoring the neigh-borhood model, which scales both item-item and user-user implementations linearly with the size of the data [5]. Thus, he effectively integrates implicit and explicit neighborhood information about the users and items to extend the pure SVD model (the BMF model in 1). He assumes all the feed-backs from the users no matter what the feedbacks are, as the implicit information, and considers the ratings as the ex-plicit neighborhood information. He defines N ( u ) and R ( u ) as the sets of all implicit and explicit feedbacks from user u . However, N ( u ) is assumed equal to R ( u ) in his experiment on the Netflix dataset[4]. In SVD++, Koren corresponds each item i with two latent vectors q i ,y i  X  R k , and models each user with a corresponded latent vector p u  X  R k plus the sum of the latent vectors of all the items inside N ( u ). Thus, he defines the SVD++ X  X  predictor function as follows:
Employing these implicit feedbacks in the SVD model has shown a promising improvement of prediction accuracy in practice[5]. We expect that employing implicit information about the categories that users and items belong to is useful test sets. Netflix dataset contains over 100 million ratings from 480189 users who has rated 17770 movies. We run each algorithm 5 times on the datasets to remove the effect of random initialization of latent vectors on the predictions. Thus, our reported RMSE results are the average RMSEs of these 5 runs.
We start by applying BMF on both datasets to find their users X  and items X  latent vectors. These latent vectors (learned on the train sets) then are used for the clustering purpose. Kmeans is applied on the achieved latent vectors to find pos-sible categories of items and categories of users inside the datasets. It is expected that items (users) with similar la-tent vectors are similar in reality as well. We guess different selection of possible categories by changing in the number of clusters. It usually achieves in 5-10 tries. Finally, by trying different size of clusters on the proposed models, the number of clusters that achieves less RMSE (higher accuracy) on the validation set will be selected as the best choice of m 0 , and n .

Table 1 shows the movies inside a number of found clus-ters on the Netflix dataset. As shown, it seems that movies in same genre and almost similar years of production tend to be in same clusters. For instance,  X  X ategory 1499 X  in-cludes different versions of  X  X ord of the Rings X  and  X  X arry Potter X . These movies are both in  X  X dventure X  and  X  X antasy X  genres 2 and also have released between 2001 to 2004. Or,  X  X ategory 1028 X  contains a number of classical movies in the  X  X dventure X  genre. As no information about the users is pro-vided, so the clusters of users cannot be judged. Lets remind that the movies X  names (identities) are not used anywhere in this experiment. These names are only employed for better demonstration of the clusters. On the other hand, the qual-ity of the clusters is effective on the prediction accuracy of the extension models. For instance, the  X  X B-SVD++ X  model results a RMSE of 0.90564 for a random assignment of the clusters ( m 0 = n 0 = 100) on the MovieLens100k dataset. Comparing this value with the achieved RMSE of 0.89928 which is the result of employing the kmeans clusters of the latent vectors, it can be seen that the low quality of clusters will decrease the prediction accuracy of our extensions. Table 1: The table shows the movies inside a number of formed clusters on the Netflix dataset. As shown, it seems that movies in same genre and almost similar years of pro-duction tend to be in same clusters.
 http://www.imdb.com
The Table 2 shows the RMSE results of applying clustering-based extension on a number of factorized CF methods on the Netflix dataset. As the results show, with increasing k the extensions result better improvements. However, an-other factor which highly affects the accuracy of the neighbor-hood-aware methods is the neighborhood size that is applied on the model. Lets define the maximum number of employ-ing neighborhood as  X  . Figure 1 illustrates how increasing  X  results a better prediction accuracy. It also shows that em-ploying the deduced information about the categories that the items and users belong to, is independent from the ex-plicit and implicit feedbacks. Adding the deduced informa-tion about the shared interests among the categories im-proves the prediction quality for any neighborhood size in both datasets. For the MovieLens dataset, the clustering-based extension of  X  X VD++ X  ( X  X B-SVD++ X ) shows a bet-ter prediction accuracy than  X  X symmetric-SVD++ X  which employs the explicit feedbacks. For employing full set of neighbors, this advantage can be seen on the Netflix dataset too.

The extension models have almost the same complexity as the non-extended models. However, they add a preprocess-ing complexity in the clustering step. As Table 3 illustrates, the learning time of the extensions is less than twice of the non-extended models on the MovieLens100k dataset. The clustering was also not much time consuming because we perform the clustering on the low dimension latent vectors. For instance, the clustering of the Netflix X  X  users takes less than a hour using the Rapidminer 3 software in our PC with 3.30 GHz CPU. Both extended and non-extended models also take similar number of epochs for converging in the learning time. Thus, the extended models keep the scalabil-ity of those models which was our second goal.
Because of the disadvantages of the user-user and inte-grated models, in this paper we only focused on the item-item models. However, we have tried the clustering-based extension method on those models. A similar improvement of prediction results have been observed for those extensions. For the integrated model which is presented in [5], the im-provement was even slightly higher. For instance, the basic integrated model achieves a RMSE of 0.89558 on the Movie-Lens100k dataset. By applying our extension on this model, the RMSE falls to 0.89298. However, the space and time complexity of this model increases dramatically by select-ing larger number of  X  . It is really difficult to replicate the blended model of the Netflix prize winner X  X  solution. How-ever, based on the central role of SVD++ and Asymmetric-SVD++ in that blended model, we expect that applying our extensions will slightly improve its accuracy.

To summarize, we propose a new approach to improve the accuracy of two well-known highly scalable factorized mod-els: SVD++ and Asymmetric-SVD++. We first employ collaborative information to categorize users and items. We then track how users inside each category rate the other categories containing the items. Including this new infor-mation, we extend these cutting-edge models regarding two main goals: 1) to improve their recommendation accura-cies. 2) to keep the extended models still scalable. Finally, we evaluate our proposed models on two recommendation http://www.rapidminer.com
