 In this study, we formalize a multi-focal learning problem, where training data are partitioned into several different fo-cal groups and the prediction model will be learned within each focal group. The multi-focal learning problem is mo-tivated by numerous real-world learning applications. For instance, for the same type of problems encountered in a cus-tomer service center, the problem descriptions from different customers can be quite different. The experienced customers usually give more precise and focused descriptions about the problem. In contrast, the inexperienced customers usually provide more diverse descriptions. In this case, the examples from the same class in the training data can be naturally in different focal groups. As a result, it is necessary to identify those natural focal groups and exploit them for learning at different focuses. The key developmental challenge is how to identify those focal groups in the training data. As a case study, we exploit multi-focal learning for profiling problems in customer service centers. The results show that multi-focal learning can significantly boost the learning accuracies of existing learning algorithms, such as Support Vector Ma-chines (SVMs), for classifying customer problems. H.2.8 [ Database Management ]: Database Applications X  Data Mining ; I.5.2 [ Pattern Recognition ]: Design Method-ology X  Classifier Design and Evaluation Algorithms, Experimentation Multi-focal Learning, Customer Service Support
Customer service support is becoming an integral part of most companies. Many companies have a customer service department that provides inspection, installation, and main-tenance support for their world-wide customers. Problem ticket generation usually is the first step in today X  X  process services management. This step is responsible for describ-ing problem symptoms reported by customers and problem tickets are the link between customers and the services in-frastructure. Once a problem ticket is generated, it will be enqueued in the ticketing system and routed to an appro-priate service center or service people for problem determi-nation. Most existing large call centers collect service data that are then used to assess and improve the performances of their representatives. Typically, these problem records are stored in relational databases with both structured (e.g. current status, problem type, support person/group han-dling the problem, type of system and component related to the problem) as well as unstructured (e.g. free-format text descriptions of problems and solutions as entered by the support personnel) attributes.

Indeed, the increasing availability of problem logs cre-ates unprecedented opportunities to change the paradigm for risk management for avoiding/alleviating organizational crisis, product design, and product quality control. Cur-rently, these problem logs are mostly used for tracking, au-diting and reporting the problem management processes [4, 11, 3]. Most steps in these processes (e.g., problem diagno-sis, ticket routing, etc.) are still manually taken. However, a lot of subject knowledge and experiences that these manual steps rely on are embedded in the existing problem records (i.e. historical data) [14, 16]. It is expected that we develop the ability to automatically extract the expert experiences as the knowledge to improve process services management and identify early symptoms of defect products.

To this end, in this study, we aim to exploit large-scale problem logs for predicting problem category/determination automatically. This is a main aspect of customer service pro-filing [8]. If problems can be automatically determined, the problems can be routed to the right support group/personnel more efficiently. In turn, this can offer an organization tremendous benefit by, for instance, identifying sources of problem resolution error, delay, and optimization of the prob-lem management processes. Also, this can help to reduce the expense caused by manual processing. Furthermore, it is possible to facilitate customer service profiling if we have the ability to automatically categorize problems.
While it is appealing to automate the process of problem categorization/determination, it is very challenging to make use of the information and expert knowledge encoded in problem logs. For problems reported by customers, the best information we can use is the problem description provided by customers. If we treat the problem descriptions as train-ing samples and the problem result categories (determined by experts) as labels, it appears that existing off-the-shelf classification algorithms [17] can be used for problem cat-egorization. However, after carefully examining real-world problem logs, we have observed some unique characteris-tics inherent in problem logs. A key issue is that all the problem descriptions for the same problem are provided by customers with diverse background and these problem de-scriptions can be quite different. The experienced customers usually give more precise and focused descriptions about the problem. In contrast, the inexperienced customers usually provide diverse descriptions for the same problem. As an ex-ample, for a simple password problem, the description from experienced customers can be as simple as  X  X eed to reset password X . However, inexperienced customers provide much more diverse descriptions, such as  X  X annot connect to the network X  X nd X  X y computer does not work X . In other words, the training samples for the same class can be naturally in different focal groups. If we treat these problem descriptions as the same and fit into existing learning models, we may not be able to have desirable classification performances.
The above observations cast the light on the major body of this research. Specifically, we formalize a multi-focal learn-ing problem, where training data are partitioned into sev-eral different focal groups and the prediction model will be learned within each focal group. A key developmental chal-lenge is how to identify those focal groups in the training data. As mentioned above, for the same problem, the prob-lem descriptions from experienced customers are very precise and focused. Accordingly, the descriptions of problem solu-tions are also very precise and focused and highly correlated with the problem descriptions by experienced customers (if descriptions have been turned into vectors of words). In con-trast, the problem descriptions for the same problem from inexperienced customers are weakly correlated with the de-scriptions of their corresponding problem solutions. Viewed in this light, we propose a correlation method (CORRELA-TION) to partition problem descriptions within each class into two different groups: one for experienced customers and the other for inexperienced customer. In addition, to bet-ter capture the information encoded in problem logs, we also develop an ontology-enhanced correlation method (ON-TOLOGY) for identifying different focal groups. After the learning models are constructed for different focal groups, the new samples will be assigned to a learning model based on a nearest neighbor method; that is, a new sample will be assigned to a learning model if this sample is closer to the centroid of the train samples for this learning model than that of any other model.

To evaluate the performances of multi-focal learning, we present a theoretical risk analysis of multi-focal learning with the Na  X   X ve Bayes classifier and reveal that the risk of multi-focal learning with the Na  X   X ve Bayes classifier is smaller than the risk of the single Na  X   X ve Bayes learning model. More-over, we exploit the multi-focal learning model for catego-rizing problems using real-world problem logs. The exper-imental results show that multi-focal learning can signifi-cantly boost the learning accuracies of existing learning al-gorithms, such as SVMs and RIPPER [18]. Finally, we show that both CORRELATION and ONTOLOGY can lead to a better learning performance than other focal-group forma-tion methods, such as the methods based on clustering and random-partition. However, ONTOLOGY results in slightly better learning performances than CORRELATION.
We aim to develop a problem categorization model for facilitating customer service analysis. To achieve this, we build a prediction model based on the problem logs collected from customer service centers. While the problem logs used here are only related to IT Enterprise products and service functions, the developed prediction methodology and the prediction framework can be easily extended to deal with problem logs from broader business sectors.

Problem logs used in this paper were collected from IBM customer service centers. These problem logs are mainly IBM customer service texts describing the customer prob-lems and these texts were recorded during problem inci-dences. While these problem logs record issues dominated by IBM related products and services, there are some prob-lem logs which report problems from other vendors as well. All problem logs are stored in relational databases with both structured (e.g. problem ID, cause code, Person/group han-dling the problem, type of system and component related to the problem) as well as unstructured (e.g. free-text de-scriptions of problem and problem solution descriptions en-tered by the support personnel) attributes. Table 1 shows a sample problem log. In the table, we can observe some structured attributes as well as two unstructured attributes of this sample problem log. As can be seen, problem de-scriptions are about the descriptions of problems and were supplied by customers with diverse background. In contrast, the descriptions about problem solution were provided by IBM service people. Both problem descriptions and their problem solutions are in the free-text format.

In this study, we focus on the unstructured attributes, since the free-text descriptions of problems supplied by cus-tomers are original and essential for the solutions of the problems. Compared with structured data, unstructured free-text descriptions offer more original information that will reveal  X  X hat X  and  X  X hy X  aspects of the problems that a customer might have encountered. However, the analysis of unstructured text is extremely difficult because of the fol-lowing reasons. First of all, any unstructured text is usually very noisy with many irrelevant text contents [6]. Second, the problem descriptions usually reflect the problem percep-tions of customers and are given in customers X  own words. In other words, the same problem can be described in many different ways since the different customers have very differ-ent levels of domain knowledge.

Finally, before we can apply learning models on prob-lem logs for predicting problem categorization, we need to first do data preprocessing, which includes data cleaning and data transformation. For data transformation, we transform unstructured problem descriptions and problem solutions into structured vectors. This involves extracting keywords from text paragraphs and then representing each problem log as a vector with 0/1 values. This data pre-processing is similar to that in text categorization. Note that we have used the Porter word stemming algorithm [13] to reduce words to their base stem.
In this section, we first introduce the concept of multi-focal learning. Then, we explain how the multi-focal learn-ing model works by providing an illustrating example. In addition, we propose two methods for forming focal groups in problem logs. Finally, we provide a theoretic analysis to show the effectiveness of the multi-focal learning.
The idea of multi-focal learning is motivated by the ob-servation that there are inherent large variations in many real-world training data. For instance, problem descriptions in problem logs for the same problem can be quite differ-ent, since these descriptions may be from customers with different background. Some customers may be experienced people and they can provide more precise descriptions about the problems. In contrast, some inexperienced customers may provide diverse descriptions on the same problem. As a result, the learning performances can be significantly im-pacted by the diversity inherent in the training data. This is referred as the multi-focal property in this paper.
To deal with this multi-focal property, we provide a multi-focal learning framework as shown in Figure 1. As can be seen, there are three phases for the multi-focal learning. In the first and the most challenging phase, there is a need to identify different focal groups in a way such that training samples in the same focal group are more similar to each other. This focal-group formation process is challenging be-cause there is no simple and effective way to identify focal groups in different types of real-world data. The best focal-group formation method usually relies on the special charac-teristics inherent in the data. Here, we provide two methods for finding focal groups in problem logs in the following sub-sections. The second phase is focused on building learning models in each focal group. Any traditional learning models, such as Support Vector Machines (SVMs), Bayesian Learn-ing, and Decision Trees, can be applied here. Finally, in the third phase, the test samples will be first assigned to a focal group using a nearest neighbor method. Then, the learning model from the corresponding focal group will be used for the learning on this test sample.
Here, we exploit SVMs on a synthetic data set to illus-trate multi-focal learning. Specifically, we generate two-dimensional synthetic data with two classes as shown in Fig-ure 2 (a). In the figure, the objects of two classes are repre-sented by triangle and square symbols respectively and these objects are naturally located in two different focal groups: one dense group and one sparse group. Note that the SVMs tool we used here is LIBSVM [2] with the linear kernel.
First of all, we generate the learning model by directly ap-plying SVMs for the whole original data and the results are
Figure 1: The Multi-focal Learning Framework show in Figure 2 (b). In this figure, the solid line represents the maximal margin hyperplane (MMH) learned by SVMs. As can be seen, there are many classification errors. This is due to the multi-focal property of the original data. In-deed, even if we use non-linear kernels (i.e. the Radial Basis Function), the classification accuracy is still about 60%.
Instead, we exploit multi-focal learning methods. Along this line, we first partition the data into two groups. One is the dense group and the other is the sparse group as shown in Figure 2 (c). In this figure, we can see that samples from two classes co-exist in these two focal groups. Next, we ap-ply SVMs to build learning models in each group and the results are shown in Figure 2 (d). As can be seen, there is one MMH in each group and there are few classification errors compared to Figure 2 (b). Finally, to predict a test sample in the multi-focal learning framework, we first as-sign the test sample to a focal group based on the nearest neighbor methods. Then, the learning model from the cor-responding focal group will be used for the prediction of this test sample. The above example illustrates the multi-focal learning process and the reasons why it can lead to bet-ter performances for the data with the multi-focal property. However, in practice, a key developmental challenge is how to effectively identify the focal groups from the data. As a practice, in this subsection, we propose a CORRE-LATION method to generate focal groups in problem logs. This method is motivated by our observation that problem logs have been provided by customers with diverse back-ground. The experienced customers usually give more pre-cise and focused descriptions about the problems. These problem descriptions are highly correlated with the problem solutions provided by service people. In contrast, the in-experienced customers usually give diverse descriptions for the same problem and their descriptions usually have low correlation with the final problem solutions.
MMH
To measure the correlation between problem descriptions and their problem solutions, we need to first transform prob-lem descriptions and their solutions into vectors with 0/1 values. Specially, we first extract key words from the text descriptions of problems and their solutions and build a word vector to include all the key words. Then, a problem descrip-tion or a problem solution can be transformed into a vector with 0/1 values based on whether the corresponding word in the word vector is in the problem description/solution or not. In this way, we turn all the problem descriptions and their problem solutions into binary vectors. To measure the strength of the relationships among these vectors, we use the Jaccard Coefficient [17], as follows.

J ( X, Y ) = # of matching presences Where f ij is the number of attributes where X is i and Y is j (i = 0 or 1; j = 0 or 1). After we compute the semantic correlation between problem descriptions and their problem solutions, we partition problem logs into two focal groups: one with high correlation values and another one with low correlation values. Note that we empirically choose the cor-relation thresholds for partitioning.
After carefully examining the problem logs, we have no-ticed that the key words from problem descriptions/solutions can be naturally organized into a hierarchy of concepts. In the above CORRELATION method, all the key words are treated equally in the correlation computation. However, the significance of key words from different concept levels should be different. Thus, in this subsection, we propose an ontology-enhanced correlation method (ONTOLOGY) for focal group formation in problem logs.

Indeed, ontology is an effective tool to represent hierarchi-cal concepts within a domain [12] and it has been used for text classification [1]. In this study, we exploit ontology to improve focal group formation. Specifically, we construct an ontology with extracted concepts from problem logs. Fig-ure 3 shows a sample ontology. In this ontology, the key words at top levels are very general and the key words at bottom levels are very specific. Both experienced and inex-perienced customers are likely to use the key words from the top levels. However, the key words from the bottom levels (e.g. 3945ABG and Ticket#32639225) are usually the words hard-coded into the software system as error messages. Inex-perienced customers are more likely to copy these key words when they report problems. In addition, there are some key words which are synonyms, such as monitor and LCD. Dif-ferent customers may use different words for the same mean-ing. To capture these synonyms, we produce synonym bags which include all synonyms for the same concept. These synonym bags are integrated in the ontology.

With the help of the ontology, we know there is still room to better capture expert knowledge and improve focal group formation. Specifically, in ONTOLOGY, we first manually generate the ontology over all the key words. This pro-cess includes the generation of synonym bags. Then, we exploit a weighting scheme to assign small weights on the words at the top and the bottom levels and large weights on the words at the middle levels. Since the words at the middle levels are more likely used by experienced customers and the words at the top and bottom levels are more likely used by inexperienced customers, this weighting scheme can help to turn binary vectors into weighted vectors. In this case, we employ the cosine similarity to compute the cor-relations instead of the Jaccard measure, since the Jaccard measure can only handle binary vectors. Let X and Y be binary vectors of problem descriptions and solutions. Also, let W represent the weight vector obtained from ONTOL-OGY. Then the Ontology-Enhanced correlation can be com-length of vector X , is dot product and  X  is defined as X  X  W = [ x 1 w 1 , , x d w d ], where X , Y and W are both d dimension vectors.

Note that the ontology-enhanced correlation computing can increase the correlations between problem descriptions and their problem solutions for experienced customers and decrease the correlations between problem descriptions and their problem solutions for inexperienced customer, and thus better capturing two focal groups.
In this subsection, we present a theoretical risk analysis of multi-focal learning. For the illustration purpose, we use the Na  X   X ve Bayes classifier as the base learning model.
First, given the input variable x and output variable y , the expected prediction error ( EPE ) [15] is: where L ( y, f ( x )) is the loss function, such as squared loss or 0-1 loss. The goal of classification is to find f ( x ) so that EPE is minimized. In the Bayesian Classification terminology [7], EPE is also called Risk which is actually more widely used than EPE . Assume that we have prior probability for class H i as p i = p ( H i ) , i = 1 , 2 , ..., M . We can assign a loss func-tion ( L ij ) to each possible decision outcome; We also know the conditional/likelihood probability as p ( x | H i ). Then, the total risk in the Bayesian terminology can be rewritten as: Risk = where R j is the classification boundary. Since R j partitions the entire space, any x belongs to exactly one such R j . In fact, the Bayesian Classifier decides class j by maximizing the posterior probability; that is, j := argmax j p ( H j Then, the total risk can be simplified as If we choose 0-1 criterion for loss function, Equation (4) can be rewritten as: Since p ( x ) is the same value for all x , the total risk is actually the product of one constant term c and the probability of error. Next, we introduce the following Theorem.
 Theorem 1. The risk of multi-focal learning with the Na  X   X ve Bayes classifier is smaller than the risk of the single Na  X   X ve Bayes learning model.

Proof. Let Risk  X  be the risk of multi-focal learning with the Na  X   X ve Bayes classifier and Risk be the risk of the single Na  X   X ve Bayes learning. For a new object x , we assume that Class j  X  is predicted by the multi-focal learning model and Class j is predicted by the single learning model. According c P M i =1 ,i 6 = j p ( H i | x ), where c is one constant number. We need to prove  X  Risk ( X  Risk = Risk  X   X  Risk ) &lt; 0. Apparently, both p ( H j | x ) and p  X  ( H j  X  | x ) are maximums as the posterior probability with the Na  X   X ve Bayes Classifier. In-stead of p  X  ( H j  X  | x ), let us consider p  X  ( H j | x ) first. p will be bigger than p ( H j | x ) if p  X  ( H j | x ) &gt; p ( H p ( H j  X  | x ) is maximal posterior probability for multi-focal learning model. That is, if  X  Risk T = c ( p ( H j | x )  X  p try to prove  X  Risk T &lt; 0 . For the Na  X   X ve Bayes Classi-fier, each attribute x k , k = 1 , 2 , ..., D, of x is assumed to be independent. In other words, p ( H j | x )  X  p j p ( x | H p Q D k =1 p ( x k | H j ), where p j is the same value for each class. So we can write  X  Risk T as: where c  X  is also a constant number. Similar to the text classification problem, we use frequency ratio to estimate p ( x k | H j ) or p  X  ( x k | H j ). We have: where # of x k means the number of times of attribute x k Then, if x k 6 = 0, then x k only appears in one focal group(this can be enforced by focal group formation methods), thus (# of x k | givenH j ) in Equation (8) and (# of x k | givenH in Equation (9) should be equal. However, (# of training samples | givenH j )  X  in Equation (9) is smaller than (# of training samples | giveH j ) in Equation (8) for the whole train-ing data. So p  X  ( x k | H j ) is greater than p ( x k | H Also, if x k = 0, the corresponding attribute tends to be ir-relevant. For an irrelevant attribute, p ( x k | H j ) or p becomes almost uniformly distributed , thus it almost has no impact on the overall computation of posterior probabil-ity [17]; therefore, it has no impact on the value of  X  Risk As a result, we can conclude that Q D k =1 p  X  ( x k | H j than Q D k =1 p ( x k | H j ), thus  X  Risk T &lt; 0. So we can conclude  X  Risk &lt; 0. Thus, this theorem is held.
In this section, we provide an empirical study of the per-formances of multi-focal learning.
Real-world Problem Logs. In the experiments, we have used real-world problem logs collected from IBM cus-tomer service centers. A detailed description of problem logs has been given in Section 2. In the experiments, we have formalized two-class classification as well as multi-class classification problems. For the two-class classification prob-lem, we are focused on two categories of customer problems. One category includes the problems caused by the users, such as  X  X eset/forget password X . Another category includes the problems related to product quality, such as  X  X attery dead X  and  X  X ystem crash X . In contrast, to study the multi-class learning problem, we prepare three categories of prob-lems including user-caused problems, hardware problems, and software problems. All the problems were labeled by domain experts. Finally, to evaluate the focal group for-mation methods, problem descriptions were also labeled as  X  X xperienced X  or  X  X nexperienced X  by domain experts. These labels are used as benchmarks in the experiments.
Synthetic Data. Figure 4 shows four synthetic data sets including DS1,DS2,DS3 and DS4, which have the multi-focal property. Some data characteristics are shown in Table 2.
Table 2: Some Characteristics of Synthetic Data Experimental Tools. We employ four base classifiers, Support Vector Machines (SVMs), Naive Bayes classifier, decision tree, and rule-based classifiers (RIPPER [18]). Also, we use MFL to indicate multi-focal learning.
 To evaluate focal group formation methods, we compare CORRELATION and ONTOLOGY with clustering and ran-dom partitioning methods. For the clustering method, we employ Chameleon [5] in CLUTO [10], since we need to cap-ture clusters with different densities. Problem descriptions labeled by domain experts are used as the benchmark.
Evaluation Metrics. The classification accuracy and F-measure [17] have been used for the performance evaluation. For all the experiments, we did five-cross validation.
In this subsection, we show the performances of multi-focal learning on real-world problem logs.

Two-class Categorization. The goal is to group prob-lems into two categories: user-caused problems and product problems. Here, we use CORRELATION for generating fo-cal groups. Specifically, we measure the correlations between problem descriptions and their problem solutions. If the cor-relation is lower than 0.07, the corresponding problem log is placed in a sparse (inexperienced) group. If the correlation is larger than 0.1, we put the problem log in a dense (ex-perienced) group. The thresholds are empirically specified. Once we have two focal groups, we build learning models with some base classifiers on both focal groups.

Table 3 shows the comparison results of multi-focal learn-ing and traditional classification methods including SVMs, Ripper, C4.5, and Bayes. In the table, we can observe that multi-focal learning can improve the performances of these traditional classification methods with a significant margin.
Three-class Categorization. Here, we target grouping problem logs into three categories: user-caused problems , hardware problems , and software problems . In this exper-iment, we apply both CORRELATION and ONTOLOGY methods for generating focal groups. Table 4 shows the com-parison results of multi-focal learning and traditional clas-sification methods including SVMs and Bayes. As can be seen, multi-focal learning can improve the classification per-formances of both SVMs and Bayes. Also, we can observe that ONTOLOGY leads to slightly better classification per-formances compared to CORRELATION.
In this subsection, we evaluate the performances of several focal group formation methods including CORRELATION, ONTOLOGY, clustering methods, random partitioning on real-world problem logs. Here, we use SVMs as the base classifier and target two-class categorization problem, which has a similar experimental setting as the two-class catego-rization problem in Section 4.2.

For ONTOLOGY, we stratify the domain concepts into four levels. The weights on concepts on the top and bottom levels are set as one and the weights on concepts on the mid-dle two levels are set as three. Then, we measure weighted correlations between problem descriptions and their prob-lem solutions. If the correlation is lower than 0.13, the cor-responding problem log is placed in a sparse group. If the correlation is greater than 0.23, the problem log is placed in a dense group. These two thresholds are empirically specified. In addition, the clustering method we used is the Chameleon algorithm in CLUTO, since there are different densities in the data. The default parameters for running Chameleon in CLUTO were used except the number of neighbors (-nnbrs=80). Other parameters for Chameleon include the use of graph clustering method (-clmethod=graph) with correla-tion (-sim=corr) as the similarity and the use of agglomera-tion (agglofrom=30). Finally, we use the labels from domain experts (EXPERT) as the benchmark.

Table 5 shows the results. As can be seen, the performance of ONTOLOGY is slightly better than that of CORRELA-TION and is closer to the performance by domain experts as indicated by EXPERT in the table. Also, both ONTOL-OGY and CORRELATION can lead to a much better classi-fication performance compared to the clustering method and random partition. The above indicates that both CORRE-LATION and ONTOLOGY are effective methods for iden-tifying focal groups in problem logs.
In this subsection, we exploit some synthetic data to bet-ter illustrate the multi-focal property; that is, the impact of the diversity inherent in the data on the learning perfor-mance. For four synthetic data sets shown in Figure 4, we can see that there are simple linear-separable concepts as well as complex non-linear-separable concepts [9] in these data sets. Indeed, multi-focal learning is a natural solution to the data with complex non-linear-separable concepts, be-cause multi-focal learning allows for decomposing the com-plex concepts into simple linearly separable concepts by group-ing data objects into different focal groups.

Since two-dimensional synthetic data sets in Figure 4 can be easily decomposed by the clustering algorithms, we apply the clustering methods for generating focal groups. Specifi-cally, we use Chameleon [5] in CLUTO [10] with parameters: -clmethod=graph (graph clustering), -sim=corr (correlation similarity), and -nnbrs=60 (60 nearest neighbors).
Table 6 shows the results. Here, we use SVMs with both linear and non-linear kernels as the base classifiers. As can be seen, in terms of F-measure, the performances of multi-focal learning are much better than that of single SVMs no matter linear or non-linear kernels are used in SVMs. Note that we only show the results of SVMs with linear kernels on DS1 and DS2 data sets and the results of SVMs with non-linear kernels on DS3 and DS4 data sets. A similar trend has actually been observed on all four synthetic data sets. Due to the space limitation, we omit these results. In addition, Figure 5 shows the learning performances in terms of the classification accuracy. In the figure, we can see that the performances of both dense group and sparse group are improved significantly with multi-focal learning.
Another interesting observation in Figure 5 is that, while the clustering algorithms generate the same focal groups for DS3 and DS4, the distributions of their class objects are dif-ferent. Indeed, for SVMs with linear kernel, the single model has a much worse performance on DS4 than on DS3. This indicates that the complex concepts in DS4 have a negative impact on the performance of linear kernels. However, with multi-focal learning, the performance of SVMs with linear kernels on DS4 has been improved a lot.

Finally, we show the reasons why we choose Chameleon for data with different densities instead of widely-used K-means. Here, we use both K-means and Chameleon for generating focal groups on DS2 and DS4 data sets. Figure 6 shows the increased ratio of classification accuracies by multi-focal learning. As can be seen, for both linear and non-linear cases, Chameleon leads to much better performances than K-means, while K-means can also lead to an improved per-formance of multi-focal learning. Table 6: F-Measure Comparisons on Synthetic Data
Here, we provide a simple case study to show that multi-focal learning with a Naive Bayes classifier can lead to smaller classification errors. First, let us consider a binary classifi-cation problem, where y 1 and y 2 represent two classes and X represents objects. By Bayesian Theory, we have:
To make decision for classification, it is equal to com-pare the posterior probabilities of p ( y 1 /X ) and p ( y In Equation (10), p ( X ) is equal for all objects. Further-more, if we assume p ( y 1 ) is equal to p ( y 2 ), then p ( y/X ) in Equation (10) can be rewritten as p ( y/X ) = cp ( X/y ), where c = p ( y ) /p ( X ). Thus, we get p ( y 1 /X ) = cp ( X/y and p ( y 2 /X ) = cp ( X/y 2 ). Next, to classify objects, we only need to compare class conditional probabilities p ( X/y and p ( X/y 2 ). There are several ways to estimate these conditional probabilities by exploiting training data [17]. Here, we take the Gaussian Function for estimating con-ditional probability. To demonstrate the classification error, we present the class conditional probabilities and classifica-tion boundary in one dimension as shown in Figure 7, where x = h ( X = x in one dimension ) is the classification bound-ary for these two classes. The classification error is According to Figure 7 or Equation (11), we know that the classification error is proportional to the overlap area of these two Gaussian functions. As we know, the overlap area is determined by the means and variances of these two Gaus-sian functions. Similar to the use in Section 3.2, we use two-dimension Gaussian functions to estimate conditional probabilities of the synthetic data introduced in Section 3.2. Specifically, for single model we use two Gaussian functions, Gau 1 and Gau 2 , to estimate the conditional probabilities of two classes. For multi-focal learning, we need four Gaussian functions, Gau D 1 and Gau D 2 for the dense group and Gau and Gau S 2 for the sparse group. We show these Gaussian functions in Figure 8. As can be seen, there is more over-lap between Gau 1 and Gau 2 than that between Gau D 1 and Gau D 2 or Gau S 1 and Gau S 2 . Since this kind of overlap is an overlap across three dimensions, to make it more clear, we also show the projection of the overlap on the two-dimension space as shown in Figure 8. In this case, the classification er-ror can be computed by integrating over the two dimension area as the following: where, R 1 and R 2 are determined as Note that, for the dense group and the sparse group, both Equation (12) and Equation (13) have the same form. To this point, we can clearly see that classification error of multi-focal learning is much smaller than the error produced by the single model by either the Gaussian-function figure or the error computation in Equation (12).
In this paper, we formalized a multi-focal learning prob-lem, which was motivated by the observations of diversities of samples in training data. The key idea of the multi-focal learning is to divide training data into different focal groups and the learning models should be learned within each fo-cal group instead of building a single learning model using all the training data as a whole. The multi-focal learning allows the learning algorithms to mitigate the influence of the diversities inherent in training data, and thus leads to better learning performances.

As a practice, we have exploited the multi-focal learn-ing techniques for automatic problem categorization in real-world problem logs collected from customer service centers. A critical challenge in the multi-focal learning is how to identify focal groups in training data. To address this chal-lenge in problem logs, we proposed a correlation method (CORRELATION) to partition problem descriptions within each class into two different groups: one for experienced customers and the other for inexperienced customer. In ad-dition, to better capture the information encoded in prob-lem logs, we also developed an ontology-enhanced correla-tion method (ONTOLOGY) for identifying different focal groups. Experimental results show that both CORRELA-TION and ONTOLOGY have led to better learning per-formances than other focal-group formation methods, such as the methods based on clustering and random-partition, while the learning performance by ONTOLOGY is lightly better than that by CORRELATION.

Discussions. In this study, we have illustrated the con-cept of multi-focal learning by exploiting problem logs col-lected in real-world customer service centers. While the so-lution for forming multiple focal groups has made use of data characteristics that are unique to customer problem logs, the basic framework of multi-focal learning can be applicable in a much broader scope. For instance, let us consider a video surveillance system. There are different types of moving ob-jects, such as cars, bikes, and human beings. Those moving objects have different sizes, speed, and moving capabilities. To better capture abnormal moving patterns, it is expected to apply the multi-focal learning techniques to first group moving objects into different focal groups. The detection of abnormal moving patterns can then be performed within different focal groups. This will most likely lead to better performances for finding abnormal events.
This research was partially supported by an IBM 2008 In-novation Award and the National Science Foundation (NSF) of USA via grant number CNS 0831186. [1] S. Bloehdorn and A. Hotho. Text classification by [2] C.-C. Chang and C.-J. Lin. Libsvm: [3] J. Chu-Carroll and B. Carpenter. Vector-based natural [4] N. Gans., G.Koole., and A.Mandelbaum. Telephone [5] G.Karypis, E.-H.S.Han, and V.Kumar. Chameleon: [6] S. Godbole and S. Roy. An integrated system for [7] V. Goel and W. Byrne. Minimum bayes risk methods [8] P. Johansson and J. Olhager. Industrial service [9] J.Wu, H.Xiong, and et al. Local decomposition for [10] G. Karypis. Cluto: [11] L.Brown and et al. Statistical analysis of a telephone [12] M.Cristani and R.Cuel. A survey on ontology creation [13] M. Porter. An algorithm for suffix stripping. Program , [14] G. Riccardi., A. Gorin., A. Ljolje, and M. Riley. A [15] B. Sch  X  olkopf and A. J. Smola. Learning with Kernels . [16] I. W. V. Server. [17] P.-N. Tan, M. Steinbach, and V. Kumar. Introduction [18] W.Cohen. Fast effective rule induction. In ICML ,
