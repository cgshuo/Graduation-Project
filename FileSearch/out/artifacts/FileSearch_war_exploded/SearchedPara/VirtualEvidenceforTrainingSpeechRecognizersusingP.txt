 Current state-of-the-art speech recognizers use thou-sands of hours of training data, collected from a lar ge number of speak ers with various backgrounds in order to mak e the models more rob ust. It is well kno wn that one of the simplest ways of impro v-ing the accurac y of a recognizer is to increase the amount of training data. Moreo ver, speech recog-nition systems can benet from being trained on hand-transcribed data where all the appropriate word level segmentations (i.e., the exact time of the word boundaries) are kno wn. Ho we ver, with increasing amounts of raw speech data being made available, it is both time consuming and expensi ve to accurately segment every word for every given sentence. More-over, for languages for which only a small amount of training data is available, it can be expensi ve and challenging to annotate with precise word transcrip-tions  X  the researcher may have no choice but to use partially erroneous training data.

There are a number of dif ferent ways to label data used to train a speech recognizer . First, the most expensi ve case (from an annotation perspec-tive) is fully supervised training, where both word sequences and time segmentations are completely specied 1 . A second case is most commonly used in speech recognition systems, where only the word sequences of utterances are given, but their precise segmentations are unkno wn. A third case falls un-der the realm of semi-supervised approaches. As one possible example, a pre viously trained recog-nizer is used to generate transcripts for unlabeled data, which are then used to re-train the recog-nizer based on some measure of recognizer con-dence (Lamel et al., 2002 ).

The abo ve cases do not exhaust the set of possible training scenarios. In this paper , we sho w how the notion of virtual evidence (VE) (Pearl, 1988 ) may be used to obtain the benets of data with time seg-mentations but using only partially labeled data. Our method lies some where between the rst and sec-ond cases abo ve. This general frame work has been successfully applied in the past to the acti vity recog-nition domain (Subraman ya et al., 2006 ). Here we mak e use of the TIMIT phone recognition task as an example to sho w how VE may be used to deal with partially labeled speech training data. To the best of our kno wledge, this paper presents the rst system to express training uncertainty using VE in the speech domain. Figure 1 sho ws two consecuti ve time slices of a dy-namic Bayesian netw ork (DBN) designed for con-text independent (CI) phone recognition. All ob-serv ed variables are shaded, deterministic depen-dences are depicted using solid black lines, value specic dependences are sho wn using a dot-dash lines, and random dependencies are represented us-ing dashed lines. In this paper , given any random variable (rv) X , x denotes a particular value of that rv, D represents its cardinality .

In the abo ve model, P the phone variable, H sition within a phone, S acoustic observ ations, A and phone transitions respecti vely . Here, D D D
H t , D A t  X  { 0 , 1 , 2 } , D R t  X  { 0 , 1 } when all the conditions { c a conjunction over all the conditions). The distri-bution for H  X  plies that we always start a phone with H We allo w skips in each phone model, and A indicates no transition, A tion to the next state, A (
H t +1 = H t + 2 ). As the TIMIT corpus pro-vides phone level segmentations, P ing training. Ho we ver, for reasons that will be-come clear in the next section, we treat P den but mak e it the parent of a rv C 1 | p t ) =  X  l scriptions ( l exactly the same effect as making P setting it equal to l tails on other CPTs in this model may be found in (Bilmes and Bartels, 2005 ). We pro vide more de-tails on the baseline system in section 4.1 .
Our main reason for choosing the TIMIT phone recognition task is that TIMIT includes both se-quence and segment transcriptions (something rare Figure 2: Illustration sho wing our rendition of Vir-tual Evidence. for LVCSR corpora such as Switchboard and Fisher). This means that we can compare against a model that has been trained fully supervised. It is also well kno wn that conte xt-dependent (CD) mod-els outperform CI models for the TIMIT phone recognition task (Glass et al., 1996 ). We used CI models primarily for the rapid experimental turnaround time and since it still pro vides a rea-sonable test-bed for evaluating new ideas. We do note, howe ver, that our baseline CI system is competiti ve with recently published CD systems (Wang and Fosler -Lussier , 2006 ), albeit which uses man y fewer components per mixture (see Sec-tion 4.1 ). Given a joint distrib ution over n variables p ( x 1 , . . . , x n ) ,  X evidence X  simply means that one of the variables (w.l.o.g. x denote this by  X  x becomes p (  X  x An y conguration of the variables where x is never considered. We can mimic this beha vior by introducing a new virtual child variable c into the joint distrib ution that is always observ ed to be one (so c = 1 ), and have c interact only with x via the CPT p ( c = 1 | x P x 1 p ( c = 1 , x 1 , . . . , x n ) = p (  X  x 1 , . . . , x consider setting p ( c = 1 | x f () is an arbitrary non-ne gati ve function. With this, dif ferent treatment can be given to dif ferent assignments to x are not insisting on only one particular value. This represents the general notion of VE. In a certain sense, the notion of VE is similar to the prior distrib ution in Bayesian inference, but it is dif ferent in that VE expresses preferences over combinations of values of random variables whereas a Bayesian prior expresses preferences over combinations of model parameter values. For a more information on VE, see (Bilmes, 2004 ; Pearl, 1988 ).

VE can in fact be used when accurate phone level segmentations are not available. Consider the illus-tration in Figure 2. As sho wn, t start and end times respecti vely for phone p 1 , while t When the start and end times for each phone are given, we have information about the identity of the phone that produced each and every observ ation. The general training scenario in most lar ge vocab u-lary speech recognition systems, howe ver, does not have access to these starting/ending times, and the y are trained kno wing only the sequence of phone la-bels (e.g., that p 2 follo ws p 1 ).

Consider a new transcription based on Figure 2, where we kno w that p 1 ended at some time t and that p 2 started at sometime t region between t on the identity of the phone variable for each acoustic frame, except that it is either p 1 or p 2 . A similar case occurs at the start of phone p 1 and the end of phone p 2 . The abo ve information can be used in our model (Figure 1) in the follo wing way (here given only for t 1 | p t ) =  X  { p f Here f at time t in whether the value of P or p 2 . It is important to highlight that rather than the absolute values of these functions, it is their relati ve values that have an effect on inference (Bilmes, 2004 ). There are number of dif ferent ways of choosing these functions. First, we can set f ( p 1 ) = g t ( p 2 ) =  X ,  X  &gt; 0 . This encodes our uncertainty regarding the identity of the phone in this region while still forcing it to be either p 1 or p 2 , and equal preference is given for both (referred to as  X uniform over two phones X ). Alternati vely , other functions could tak e into account the fact that, in the frames `close' to t p 1 , whereas in the frames `close' to t 5 , it is more lik ely to be p 2 . This can be represented by using a decreasing function for f function for g or decreasing with time).

As more frames are dropped around transitions (e.g., as t of labeled data. In an extreme situation, we can drop all the labels ( t sequence and not segment information is available. Alternati vely , we can have t that only one frame is labeled for every phone in an utterance  X  all other frames of a phone are left un-transcribed. From the perspecti ve of a transcriber , this simulates the task of going through an utter -ance and identifying only one frame that belongs to each particular phone without having to identify the phone boundary . In contrast to the task of determin-ing the phone boundary , identifying one frame per word unit is much simpler , less prone to error or dis-agreement, and less costly (Greenber g, 1995 ). 4.1 Baseline System We trained a baseline TIMIT phone recognition sys-tem that made full use of all phone level segmen-tations (the fully supervised case). To obtain the acoustic observ ations, the signal was rst preem-phasized (  X  = 0 . 97 ) and then windo wed using a Hamming windo w of size 25ms at 100Hz. We then extracted MFCC' s from these windo wed features. Deltas and double deltas were appended to the abo ve observ ation vector . Each phone is modeled using 3 states, and 64 Gaussians per state. We follo w the standard practice of building models for 48 dif ferent phones and then mapping them down to 39 phones for scoring purposes (Halberstadt and Glass, 1997 ). The decoding DBN graph is similar to the training graph (Figure 1) except that the variable C mo ved when decoding. We test on the NIST Core test set (Glass et al., 1996 ). All results reported in this paper were obtained by computing the string edit (Le venshtein) distance between the hypothesis and the reference. All models in this paper were implemented using the Graphical Models Toolkit (GMTK) (Bilmes and Bartels, 2005 ). 4.2 VE Based Training and Results We tested various cases of VE-based training by varying the amount of  X dropped X  frame labels on either side of the transition (the dropped labels be-came the unlabeled frames of Figure 2). We did this until there was only one frame left labeled for ev-ery phone. Moreo ver, in each of the abo ve cases, we tested a number of dif ferent functions to gener -ate the VE scores (see section 3). The results of our VE experiments are sho wn in Figure 3. The curv es were obtained by tting a cubic spline to the points sho wn in the gure. The phone accurac y (PA) of our baseline system (trained in a fully supervised man-ner) is 61.4%. If the total number of frames in the training set is N the amount of unused data is given by U = N (the x-axis in the gure). Thus U = 0% is the fully supervised case, whereas U = 100% corresponds to using only the sequence information. Dropping the label for one frame on either side of every phone transition yielded U = 24 . 5% .

It can be seen that in the case of both  X uniform over 2 phones X  and linear interpolation, the PA ac-tually impro ves when we drop a small number (  X  5 frames) of frames on either side of the transition. This seems to suggest that there might be some in-herent errors in the frame level labels near the phone transitions. The points on the plot at U =84 . 7% cor -respond to using a single labeled frame per phone in every utterance in the training set (average phone length in TIMIT is about 7 frames). The PA of the system using a single label per phone is 60.52%. In this case, we also used a trapezoidal function dened as follo ws: if t = t phone p 1 , then f a linear interpolation function for the other values t during the transition to generate the VE weights. This system yielded a PA of 61.29% (baseline accu-rac y 61.4%). We should highlight that even though this system used only 15.3% of the labels used by the baseline, the results were similar! The gure also sho ws the PA of the system that used only the sequence information was about 53% (compare against baseline accurac y of 61.4%). This lends ev-idence to the claim that training recognizers using data with time segmentation information can lead to impro ved performance.

Given the procedure we used to drop the frames around transitions, the single labeled frame for ev-ery phone is usually located on or around the mid-point of the phone. This howe ver cannot be guaran-teed if a transcriber is ask ed to randomly label one frame per phone. To simulate such a situation, we randomly choose one frame to be labeled for every phone in the utterance. We then trained this system using the  X uniform over 2 phones X  technique and tested it on the NIST core test set. This experiment was repeated 10 times, and the PA averaged over the 10 trails was found to be 60.5% (standard deviation 0.402), thus sho wing the rob ustness of our technique even for less carefully labeled data. In this paper we have sho wn how VE can be used to train a TIMIT phone recognition system using partially labeled data. The performance of this sys-tem is not signicantly worse than the baseline that mak es use of all the labels. Further , though this method of data transcription is only slightly more time consuming that sequence labeling, it yeilds sig-nicant gains in performance (53% v/s 60.5%). The results also sho w that even in the presence of fully labaled data, allo wing for uncertainity at the tran-sitions during training can be benecial for ASR performance. It should howe ver be pointed out that while phone recognition accurac y is not al-ways a good predictor of word accurac y, we still expect that our method will ultimately generalize to word accurac y as well, assuming we have ac-cess to a corpus where at least one frame of each word has been labeled with the word identity . This work was supported by an ONR MURI grant, No. N000140510388.

