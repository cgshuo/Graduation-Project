 Diversity has been heavily motivated in the information re-trieval literature as an objective criterion for result set s in search and recommender systems. Perhaps one of the most well-known and most used algorithms for result set diver-sification is that of Maximal Marginal Relevance (MMR). In this paper, we show that while MMR is somewhat ad-hoc and motivated from a purely pragmatic perspective, we can derive a more principled variant via probabilistic infe r-ence in a latent variable graphical model. This novel deriva -tion presents a formal probabilistic latent view of MMR (PLMMR) that (a) removes the need to manually balance relevance and diversity parameters, (b) shows that specific definitions of relevance and diversity metrics appropriate to MMR emerge naturally, and (c) formally derives variants of latent semantic indexing (LSI) similarity metrics for us e in PLMMR. Empirically, PLMMR outperforms MMR with standard term frequency based similarity and diversity met -rics since PLMMR maximizes latent diversity in the results. H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms diversity, graphical models, maximal marginal relevance
Maximal marginal relevance (MMR) [2] is perhaps one of the most popular methods for balancing relevance and di-versity in set-based information retrieval and has been cit ed over 530 times 1 since its publication in 1998.

The basic idea of MMR is straightforward: suppose we have a set of items D and we want to recommend a small subset S k  X  D (where | S k | = k and k  X  | D | ) relevant to a given query q . MMR proposes to build S k in a greedy According to Google Scholar.
 manner by selecting s  X  j given S j  X  1 = { s  X  1 , . . . , s S j = S j  X  1  X  { s  X  j } ) according to the following criteria s = arg max where Sim 1 ( , ) measures the relevance between an item and a query, Sim 2 ( , ) measures the similarity between two items, and the manually tuned  X   X  [0 , 1] trades off relevance and similarity. In the case of s  X  1 , the second term disappears.
While MMR is a popular algorithm, it was specified in a rather ad-hoc manner and good performance typically relies on careful tuning of the  X  parameter. Furthermore, MMR is agnostic to the specific similarity metrics used, which inde ed allows for flexibility, but makes no indication as to the choi ce of similarity metrics for Sim 1 and Sim 2 that are compatible with each other and also appropriate for good performance.
In the next section, we address these concerns by taking a more principled approach to set-based information retriev al via maximum a posteriori probabilistic inference in a latent variable graphical model of marginal relevance (PLMMR). As an elegant and novel contribution, we note that natural relevance and diversity metrics emerge from this derivation (with no analogous manually tuned  X  parameter) and that these metrics also formally motivate variants of similarity metrics used in latent semantic indexing (LSI) [3].
We begin our discussion of PLMMR by introducing a graphical model of (marginal) relevance in Figure 1. Shaded nodes represent observed variables while unshaded nodes ar e latent; we do not distinguish between variables and their as -signments. The observed variables are the vector of query terms q and the selected items s 1  X  D and s 2  X  D . For the latent variables, let T be a discrete topic set; variables t  X  T and t 2  X  T respectively represent topics for s 1 and s and t  X   X  T represents a topic for query q . r 1  X  { 0 , 1 } and r  X  { 0 , 1 } are variables that indicate whether the respective selected items s 1 and s 2 are relevant (1) or not (0).
The conditional probability tables (CPTs) in this discrete directed graphical model are defined as follows. P ( t 1 | s P ( t 2 | s 2 ) represent topic models of the items and P ( t resents a topic model of the query. There are a variety of ways to learn these topic CPTs based on the nature of the items and query; for an item set D consisting of text docu-ments and a query that can be treated as a text document, a natural probabilistic model for P ( t i | s i ) and P ( t derived from Latent Dirichlet Allocation (LDA) [1]. Finall y, the CPTs for relevance r i have a very natural definition:
Simply, s 1 is relevant if its topic t 1 = t (the query topic). s is relevant with the same condition and the addition that if s 1 was irrelevant ( r 1 = 0), then topic t 2 for s 2 should also not match t 1 . Following the click-chain model [4], we assume the user only examines s 2 if s 1 was irrelevant ( r 1 = 0).
Let us assume that like MMR we use a greedy item set se-lection algorithm and we have already selected s 1 = s  X  1 given S 1 = { s  X  1 } , we want to select s 2 in order to maximize its marginal relevance w.r.t. q given S 1 , formally defined as MR ( S 1 , s 2 , q ) and derived as a query in the graphical model:
The basic insight leading to this fascinating result is the exploitation of the indicator structure of the relevance va ri-ables r 1 and r 2 to make convenient variable substitutions.
We note that in this special case for MR ( S 1 , s 2 , q ), a very natural mapping to the MMR algorithm in (1) when  X  = 0 . 5 has emerged automatically from the derivation that maxi-mized MR . This derivation automatically balances relevance and diversity without an analogous  X  and it suggests very specific (and different) relevance and diversity metrics, bo th effectively variants of similarity metrics used in latent se -mantic indexing (LSI) [3]. To make this clear, we examine the relevance metric Sim PLMMR 1 given by PLMMR where we let T  X  and T 2 be respective topic probability vectors for query q and item s 2 with vector elements T  X  i = P ( t  X 
A similar analysis gives diversity metric Sim PLMMR 2 ( s yielding a variant LSI similarity metric reweighted by the query topic probability P ( t  X  | q ). This points out the impor-tant correction to MMR that item set diversity should be Table 1: Weighted subtopic loss (WSL) of three methods using all words and first 10 words. Stan-dard error estimates are shown for PLMMR-LDA.
 Sim PLMMR 2 , we can now substitute these into the MMR al-gorithm defined in (1) to arrive at a definition of PLMMR.
We report experiments on a subset of TREC 6-8 data fo-cusing on diversity. We follow the same experimental setup as [6] who measure the weighted subtopic loss (WSL) of recommended item sets where in brief, WSL gives higher penalty for not covering popular subtopics. We do not com-pare directly to [6] as their method was supervised while MMR and PLMMR are inherently unsupervised.

Standard query and item similarity metrics used in MMR applied to text data include the cosine of the term frequency (TF) and TF inverse document frequency (TFIDF) vector space models [5]. We denote these variants of MMR as MMR-TF and MMR-TFIDF. PLMMR specifically suggests the use of LSI-based similarity metrics defined in the last section; thus, we use LDA to derive these models, refer-ring to the resulting algorithm as PLMMR-LDA. LDA was trained with  X  = 2 . 0 ,  X  = 0 . 5 , | T | = 15; we note the results were not highly sensitive to these parameter choices.
Average WSL scores are shown in Table 1 on the 17 queries examined by [6]. We use both full documents and also just the first 10 words of each document. For both MMR algorithms, the best performing  X  = 0 . 5 is shown. We note that due to the power of the latent topic model and derived similarity metrics, PLMMR-LDA is able to perform better than MMR with standard TF and TFIDF metrics and without a  X  parameter to be tuned. In addition, PLMMR-LDA works very well with short documents since intrinsic document and query similarities are automatically derived from the latent PLMMR relevance and diversity metrics. [1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [2] J. Carbonell and J. Goldstein. The use of MMR, [3] S. Deerwester, S. T. Dumaisand, G. W. Furnas, T. K. [4] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor, [5] G. Salton and M. McGill. Introduction to modern [6] Y. Yue and T. Joachims. Predicting diverse subsets
