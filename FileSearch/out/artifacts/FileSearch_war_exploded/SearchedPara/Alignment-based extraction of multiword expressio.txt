 Helena de Medeiros Caseli  X  Carlos Ramisch  X  Maria das Grac  X as Volpe Nunes  X  Aline Villavicencio Abstract Due to idiosyncrasies in their syntax, semantics or frequency, Multiword Expressions (MWEs) have received special attention from the NLP community, as the methods and techniques developed for the treatment of simplex words are not necessarily suitable for them. This is certainly the case for the automatic acquisition of MWEs from corpora. A lot of effort has been directed to the task of automatically identifying them, with considerable success. In this paper, we propose an approach for the identification of MWEs in a multilingual context, as a by-product of a word alignment process, that not only deals with the identification of possible MWE candidates, but also associates some multiword expressions with semantics. The results obtained indicate the feasibility and low costs in terms of tools and resources demanded by this approach, which could, for example, facilitate and speed up lexicographic work.
 Keywords Automatic identification Word alignment Machine translation Terminology Multiword expressions Lexical acquisition Statistical methods 1 Introduction A multiword expression (MWE) can be defined as any word combination for which the syntactic or semantic properties of the whole expression cannot be obtained from its parts (Sag et al. 2002 ).

Multiword expressions play an important role in Natural Language Processing (NLP) applications, which should not only identify the MWEs but also be able to deal with them when they are found (Fazly and Stevenson 2007 ). Failing to identify MWEs may cause serious problems for many NLP tasks, especially those involving some kind of semantic processing. Therefore, there is an enormous need for robust (semi-)automated ways of acquiring lexical information for MWEs (Villavicencio et al. 2007 ).

MWEs are language dependent and culturally motivated, which means that the translation of MWE occurrences is an important challenge for machine translation methods. Different approaches have been proposed for identifying MWEs in one language (Pearce 2002 ; Baldwin and Villavicencio 2002 ; Evert and Krenn 2005 ; Zhang et al. 2006 ; Villada Moiro  X  n and Tiedemann 2006 ; Villavicencio et al. 2007 ; Van de Cruys and Villada Moiro  X  n 2007 ). However, few have investigated this problem in the multilingual context of machine translation, more specifically within the task of automatic word alignment (mainly the models of Brown et al. ( 1993 )), which plays a vital role in corpus-based (example-based or statistical) MT approaches.

The automatic word alignment of two parallel texts X  X  text written in one (source) language and its translation to another (target) language X  X ries to identify for each word in a source sentence equivalences in the parallel target sentence. Therefore, if a word sequence S ( S = s 1 ... s n with n C 2) in one text is aligned to a word sequence T ( T = t 1 ... t m with m C 1) in its counterpart, i.e., S $ T , then we can assume that: (a) S and T share some semantic features, and (b) S may constitute a MWE. In other words, we state that the sequence S will be a MWE candidate if it is aligned with a sequence T composed of one or more words (a n : m alignment with n C 2 and m C 1). For example, the sequence of two English words academic world is a MWE candidate because these two words were joined to be aligned with the sequence of two words ambiente acade  X  mico (a 2:2 alignment) and also with the single Portuguese word academia (a 2:1 alignment).

Thus, notice that the alignment-based MWE extraction method does not rely on the conceptual asymmetries between languages since it does not expect that a source sequence of words be aligned with a single target word. The method indeed looks for the sequences of source words that are frequently joined together during the alignment despite the number of target words involved. These MWE candidates may then be automatically validated, and the noisy non-MWE cases among them removed. As a consequence, MWE extraction can benefit from automatic word alignment of parallel texts without prior MWE information.

In this paper, we investigate experimentally whether MWEs and their translations can be identified as a by-product of the automatic word alignment of parallel texts, with reasonable precision rates. We focus on English MWEs and their Portuguese translations. Another important result obtained by this paper is that the word alignment is able to attach semantic information to word and multiword units, by means of their target language counterparts. This approach can help to considerably reduce and accelerate lexicographic work by generating lists of MWEs with their translations, for the construction of bilingual resources, and/or with some semantic information for monolingual resources.
 The remainder of this paper is structured as follows. Section 2 briefly discusses MWEs and some previous works on methods for automatically extracting them. Section 3 describes the method proposed to extract MWEs and their translations as a by-product of an automatic word alignment process. Section 4 presents the evaluation methodology and analyses the results and Sect. 5 finishes this paper with some conclusions and proposals for future work. 2 Related work The term Multiword Expression has been used to describe a large number of distinct but related phenomena, such as phrasal verbs (e.g., come along ), nominal compounds (e.g., frying pan ), institutionalised phrases (e.g., bread and butter ), and many others. They are very frequent in everyday language and, in English, Jackendoff ( 1997 ) estimates the number of MWEs in a speaker X  X  lexicon to be comparable to the number of single words. This is reflected in several existing grammars and lexical resources, where almost half of the entries are Multiword Expressions.

However, due to their heterogeneous characteristics, MWEs present a tough challenge for both linguistic and computational work (Sag et al. 2002 ). Some MWEs are fixed, and do not present internal variation, such as ad hoc , while others allow different degrees of internal variability and modification, such as touch a nerve ( touch/find a nerve ) and spill beans ( spill several/musical/mountains of beans ). In terms of semantics, some MWEs are more opaque in their meaning (e.g., to kick the bucket as to die ), while others have more transparent meanings that can be inferred from the words in the MWE (e.g., eat up , where the particle up adds a completive sense to eat ). Therefore, providing appropriate methods for the automatic identifi-cation and treatment of these phenomena is a real challenge for NLP systems.
Previous works on MWE identification have often used statistical measures alone (Pearce 2002 ; Evert and Krenn 2005 ; Zhang et al. 2006 ; Villavicencio et al. 2007 ) or combined with some kinds of linguistic information such as syntactic and semantic properties (Baldwin and Villavicencio 2002 ; Van de Cruys and Villada Moiro  X  n 2007 ) or automatic word alignment (Villada Moiro  X  n and Tiedemann 2006 ). For instance, Evert and Krenn ( 2005 ) compare the use of some statistical measures for MWE identification, and find that the efficacy of a given statistical measure depends on factors like the type of MWEs being targeted for identification, the domain and size of the corpora used, and the amount of low-frequency data excluded by adopting a threshold.

Looking from a different perspective Villavicencio et al. ( 2007 ) investigate the use of statistical measures (mutual information, permutation entropy and v 2 ) for automatically identifying MWEs in general, discussing the influence of the corpus size and nature over the methods. Their results suggest that these different measures have a high level of agreement about MWEs, whether in carefully constructed corpora or in more heterogeneous web-based ones. Moreover, the application of these methods shows that grammar coverage can be significantly increased if MWEs are properly identified and treated.

Among the methods that use additional information along with statistics to extract MWE, the one proposed by Villada Moiro  X  n and Tiedemann ( 2006 ) seems to be the most similar to our approach. The main difference between them is the way in which word alignment is used in the MWE extraction process. In this paper, the word alignment is the basis of MWE extraction process while Villada Moiro  X  n and Tiedemann X  X  method uses the alignment just for ranking the MWE candidates which were extracted on the basis of association measures (log-likelihood and salience) and head dependence heuristic (in parsed data).

Our approach follows to some extent that of Zhang et al. ( 2006 ), that used error mining methods for the detection of missing lexical entries for MWEs and related constructions, as this paper focuses on the extraction of generic MWEs as a by-product of an automatic word alignment. Another related work is the automatic detection of non-compositional compounds (NCC) by Melamed ( 1997 ) in which NCCs are identified by analyzing statistical translation models trained in a huge corpus by a time-demanding process. Both approaches look for sequences of words that are translated as a unit but while our method takes as MWE candidates any two or more consecutive source words, regardless of whether they are translated as one or more target words, Melamed X  X  method does not detect phrases that are translated word-for-word.

To the best of our knowledge, this is the first work that investigates to what extent automatic word alignment can be used to extract MWEs, i.e., the first alignment-based MWE extraction method. In this way, cost-effective tools for the automatic alignment of texts can generate a list of MWE candidates with their appropriate translations, for bilingual lexicons, or without the translations, for monolingual lexicons. 3 Experimental methodology In order to verify how the alignment process can contribute to MWE extraction, we propose the following steps. First, a parallel corpus has to be pre-processed to be used as the input for our MWE extraction method. The parallel corpus is sentence-aligned, then PoS (Part-of-Speech) tagged, and finally word-aligned by automatic tools as explained in Sect. 3.1 . Then, for each language, a list of MWE candidates is created by extracting those sequences of two or more words that have the same alignment, i.e., that are linked to the same unit in the other language. Each list is filtered to remove unlikely candidates according to some empirical criteria. The extraction method is described in detail in Sect. 3.2 .

As a consequence, from a parallel corpus it is possible to obtain as products of the same process: (1) a list of MWEs for each language as well as (2) the corresponding translation(s) of each MWE. It is important to notice that the translation of a MWE in one language is not necessarily a MWE in the other language. Indeed, a MWE can be translated as a single word, e.g., eat up in English as comer ( eat )in Portuguese. Moreover, different occurrences of the same MWE can be aligned to distinct translations. For instance, the expression academic world in English may be translated (aligned) into Portuguese as academia or as ambiente acade  X  mico depending on the context. 3.1 Preprocessing of the corpus The corpus used in this experiment is composed of articles of the Brazilian scientific magazine Pesquisa FAPESP (journalistic genre and academic-scientific domain), 1 written in Portuguese ( pt ) and English ( en ). Table 1 contains the number of texts, sentences and tokens for each language in this test corpus.
 The pt  X  en corpus was sentence-aligned by a version of the Translation Corpus Aligner (TCA; Hofland 1996 ) called TCAalign . It relies on several alignment criteria to automatically find the correspondence between source and target sentences, such as a bilingual anchor word list, words with an initial capital (candidates for proper nouns), special characters (such as question and exclamation marks), cognate words and sentence lengths (Caseli et al. 2004 ). TCAalign achieved 97% precision and 98% recall in the sentence alignment of the test corpus. It is important to note that after the automatic alignment, all alignments different from 1:1 (only 6% of the total amount) were manually verified before being used in the next preprocessing steps.
The aligned parallel sentences were then PoS-tagged in each language using the corresponding morphological analysers and PoS taggers from Apertium 2 (Arment-ano-Oller et al. 2006 ). The morphological analysis provides one or more lexical forms or analyses (information on lemma, lexical category and morphological inflection) for each surface form (instance of a word in the text) using a monolingual morphological dictionary. The PoS tagger chooses the best possible analysis based on a first-order hidden Markov model (HMM). To improve the coverage of morphological analysis, the original dictionaries were enlarged with entries from Unitex 3 dictionaries as explained by Caseli et al. ( 2006 ). The number of surface forms covered by the original and the extended versions of morphological dictionaries are shown in Table 2 .

After PoS-tagging, the pairs of parallel sentences were word-aligned by GIZA ?? (Och and Ney 2000b ). GIZA ?? is a statistical word aligner that uses the IBM models (Brown et al. 1993 ) and the Hidden-Markov alignment model (Vogel et al. 1996 ; Och and Ney, 2000a ) to find the best correspondences between source and target tokens. GIZA ?? (version 2.0) was executed with standard parameters X  X ith iterations of IBM-1, IBM-3, IBM-4 and HMM X  X nd trained with the whole set of 17,397 pairs of pt  X  en parallel sentences.

The parallel sentences were aligned by GIZA ?? in source X  X arget and target X  source directions and, then, the alignments in both directions were merged using the union algorithm proposed by Och and Ney ( 2003 ). The alignment error rate of GIZA ?? in our test corpus after the union was 8.61% (Caseli et al. 2006 ).
Figure 1 shows an extract of a pt  X  en sentence pair in which each surface form (the word as it appears in the text, e.g., the underlined en word blood ) is followed by alignment produced by the word aligner (the position of the corresponding token on the other side, e.g., 23).
 pt en
Multiword unit alignments are formed by joining positions of the correspondent tokens, separated by a  X  X  X  X  X  character, as in the underlined alignment of Fig. 1 between the pt word pressa  X  o (the 23rd source token) and two en words: blood and pressure (the 27th and 28th target tokens). This 1:2 alignment connects a source single pt word pressa  X  o to the target en multiword unit blood pressure . If there are MWE entries in the morphological dictionaries, they can be recognized by the PoS taggers, as the single 34th en token heart _ attacks . Nevertheless, the MWE coverage of the morphological dictionaries is usually very limited so that the automatic extraction method proposed in this paper is crucial for and effective in extracting relevant MWEs that are not included in these dictionaries. 3.2 Extraction method The extraction of both MWEs and their translations from the word-aligned corpus was carried out in two steps. In the first step, MWE candidates are selected through the identification of special alignments as explained in Sect. 3.2.1 . In the second one, empirical rules are applied to discard unlikely candidates as described in Sect. 3.2.2 . The remaining units in the candidate list are considered to be MWEs. 3.2.1 Extraction of MWE candidates and their translations For each language, a list of sequences of two or more words (the MWE candidates) was created from the output of the aligner or the tagger, along with the target words aligned to them (the possible translations).

The candidates produced by the aligner are those in which two or more words have the same alignment, i.e., they are linked to the same target unit. For example, in Fig. 1 , the pt sequence derrames cerebrais (at positions 33 and 34 in the pt sentence) is aligned to the 36th en word strokes . In the other direction, the en sequence blood pressure (at positions 27 and 28 in the en sentence) is aligned to the 23rd pt word pressa  X  o .

The candidates produced by the PoS tagger are those in which the words are joined by a  X  X  X  X  X  character as defined in the morphological dictionary. In Fig. 1 , the en sequence heart_attacks (at position 34 in the en sentence) is an example of a sequence generated by the tagger. This en sequence is aligned to the 31st pt word enfarte . We make this distinction between the MWE candidates produced by the aligner or by the tagger in order to evaluate precisely the gain obtained by using the automatic word alignment in MWE extraction. The presence of manually defined MWEs (those contained in the dictionaries used by the tagger) would certainly add some noise to the evaluation process.

At the end of the first step, a list of MWE candidates is output along with their possible translations, i.e., the target units with which the candidates are aligned. In fact, our method produces, at once, two lists of MWE candidates: (1) the list of MWE candidates in pt along with their translations in en and (2) the list of MWE candidates in en along with their translations in pt .
 3.2.2 Filtering the candidates The list of MWE candidates created in the first step was then filtered to remove those candidates that: (a) match some sequences of PoS tags or words (patterns) empirically defined, or (b) whose frequency is below a certain threshold.

The filtering patterns are language dependent and were defined, in previous experiments, after a manual analysis of output candidates that did not correspond to true MWEs. Table 3 shows the set of eighth patterns used to filter the en candidates (1st column) and some examples of false positive MWEs filtered by them (2nd column). Since the sentences were PoS-tagged automatically, even the incorrectly tagged sequences can match these patterns. The filter is not error-free, so sequences that are true MWEs can be erroneously filtered (e.g., from A to Z , from day to day , would give anything , My God , his Majesty , I beg your pardon ) being considered false negatives.

Finally, a threshold of two occurrences was empirically defined to remove the infrequent candidates (that occur less than twice) in the parallel sentences. Table 4 shows some examples of en MWE candidates along with their frequencies and an indication of the tool that identified it (its source): the aligner (A) or the tagger (T). The possible pt translations for each candidate are also shown along with their frequencies in the test corpus. From this table it is possible to see that the PoS-tagger MWE candidates since the sequence a hundred is a false positive. The PoS patterns used for filtering may not be able to discard these false positives since their tags may not match the filtering patterns. In the example given, a hundred was tagged as num (numeral) in spite of beginning with a determiner.

Table 5 summarizes the number of en MWE candidates which were extracted in this experiment. From the first step (see Sect. 3.2.1 ), we obtained a list of 37,267 sequences of two or more words identified by the aligner or by the tagger. From this list of en candidates, 27,402 were filtered by the patterns of Table 3 . From the remaining candidates, 8,609 were excluded because their frequencies were lower than the minimum threshold (2). The 1,256 remaining candidates were evaluated as explained in the next section.
 4 Evaluation and results To evaluate the efficacy of the proposed method, an automatic comparison was performed using two reference dictionaries composed of multiword expressions, followed by an analysis by human experts. In this paper, we evaluated the 1,256 en MWE candidates extracted as described in Sect. 3.2 . The methodology consisted of the following steps: (1) Resource-based evaluation (2) Human analysis
To illustrate these results, Table 6 presents the same examples from Table 4 but now along with their respective evaluations given by the reference dictionaries (D) and by both judges (J1 and J2). We can see in this table the false positive a hundred marked as a false candidate (a non-MWE) by D, J1 and J2.

In order to calculate the percentage of true candidates among the 1,256, two approaches can be followed, depending on what criteria one wants to emphasize: precision or recall. To emphasize the precision, one should consider as genuine MWEs only those candidates classified as true by both judges, on the other hand, to emphasize the recall, one should consider also those candidates classified as true by just one of them . So, in the following tables both values are shown as the lower (the first value) and the upper (the second value) bounds of an interval, respectively.
Following Piao et al. ( 2006 ), Table 7 presents the set of candidates divided into frequency classes. This table shows the number (#) and the percentage (%) of MWE candidates classified as true by both (the lower bound) or at least one (the upper bound) human judge and also those candidates classified as true in the resource-based evaluation. Considering the 317 candidates classified as true during the resource-based evaluation, and the 302 candidates classified as true by both judges, and the 144 classified as true by at least one of them, the percentage of true candidates ranges from 49.28% (317 ? 302 = 619 out of 1,256) to 60.75% (619 ? 144 = 763 out of 1,256). The highest precision (71.71%) was obtained for the frequency range between 10 and 99. Examples of high-frequency (freq C 100) false MWEs are those output by the tagger X  as a (freq = 337) and as an (freq = 100) X  and by the aligner X  in a (freq = 174), in this (freq = 205) and years ago (freq = 169).
 These conclusions corroborate those by Piao et al. ( 2006 ) in which Chinese MWE are extracted using a statistical tool acheiving precisions ranging from 61.16 to 68.82% according to different search window lengths. The highest precision reached by their method was also in the frequency range between 10 and 99 (76.36%).

The next sections describe some experiments carried out to measure the precision of the proposed extraction method according to: (1) the output of the tagger or the aligner, (2) the types of MWE and (3) the possible translations of the true MWEs. In Sect. 4.4 , we make an attempt to compare the proposed method with the traditional MWE ranking methods.
 4.1 Tagger 9 Aligner According to Table 8 , the PoS tagger has the highest precision, outputting more true MWEs than the lexical aligner: 68 X 87% versus 47 X 58%. This result was expected since the MWEs output by the PoS tagger were defined manually in the morphological dictionaries. However, the tagger has a much lower recall as the number of true MWEs it identified (59 X 75) is nine times lower than the number of true MWEs extracted by the aligner (560 X 688).
 Moreover, we have found that 25 out of the 86 MWE candidates output by the PoS tagger (29%) can also be generated by the aligner. A total of 21 of these MWEs candidates were obtained from 1: n alignments (in which a single pt word is aligned to an en MWE) such as the MWEs according to , amino acid , away from and up to . Other four candidates were derived from 2:2 alignments (after the union of the pt  X  en and en  X  pt alignments output by GIZA ?? ): european union , great britain , traffic accident and united states . 4.2 Types of MWE Following Piao et al. ( 2006 ), we applied a post-PoS-filter to the set of MWE candidates to get the frequency distribution of some PoS patterns. Five PoS patterns were considered: (1) adjective ? noun (A ? N) (2) noun ? noun (N ? N) (3) verb ? preposition/particle (V ? P) (4) preposition ? determiner (P ? D) (5) some categories such as verb and preposition ? pronoun (. ? PN).

Table 9 shows that the first three patterns represent 41.48% (521) of the total amount of extracted candidates (1,256) and that they can be extracted with 75 X 89% of precision. On the other hand, the last two patterns (almost 9% of the total amount of extracted candidates) can be filtered during extraction since they are likely to be false MWEs.

Piao et al. ( 2006 ) have obtained 93.64 and 91.46% precision, respectively, for the first two types of MWEs extracted for Chinese. The other patterns presented in Table 9 were not considered by those authors. The high precision values for the V ? P class suggests that our method performs specially well in dealing with verb-particular language, English, in which V ? P constructions are very frequent. As future work, we will also look at other languages (like Portuguese, for example) to investigate specific PoS patterns for them.

Table 10 presents examples of MWE candidates classified as true or false for each pattern of Table 9 . In this table, the examples of true MWEs for the less accurate patterns (P ? D and . ? PN) were considered as such by the resource-based evaluation, since these examples were found in at least one reference dictionary.
 4.3 Translations The human judges also evaluated all the possible translations for the whole set of 1,256 candidates. Only the possible translations for the candidates classified as true MWEs were considered for this analysis. The evaluation was performed by (1) considering all the possible translations, and (2) considering only the most frequent translations. The results are shown in Table 11 .
 Since the number of possible translations changes when we only consider the true MWEs classified by both judges (the lower bound) or if we also include those by just one of them (the upper bound), in Table 11 , all figures are presented in relation to these bounds. As expected, the approach of selecting only the most frequent translations produced better results (58 X 66% of true translations) than the approach of considering all possible translations (46 X 54% of true translations). This confirms the feasibility of the approach to automatically assign a good translation for each MWE candidate. 4.4 Comparison with baseline As we described in Sect. 2 , current methods of MWE extraction usually try to rank a list of annotated candidates, so that genuine MWEs are ranked better than false candidates. Before going any further, we underline that, unlike the baseline method, our technique does not start from a pre-processed list, but tries to automatically identify true MWEs, extracting them directly from a corpus along with their translations. Therefore, a direct comparison with other measures that use standard metrics of precision and recall is not straightforward, since it would require the costly and time-consuming manual annotation of a potentially large corpus. Instead, the alternative that we adopt is to perform a dictionary-based evaluation. With respect to recall, we perform a subjective evaluation based on the judgments of the results obtained through both methods by a human annotator.

We use a set of standard statistical association measures as our baseline approach. In order to obtain comparable results, we first extract all the n-grams from the English part of the corpus, where we limited the evaluation to bigrams only (24,065 candidates). We then apply to these bigrams the same POS and threshold filters described in Sect. 3.2.2 . For each candidate bigram, the measures shown in Fig. 2 are used to estimate the degree of association between its words. 5 These measures compare the co-occurence frequency of two words with their individual frequencies, on the hypothesis that a genuine expression will present higher correlation between w 1 and w 2 than a random combination of words.

We compare the precision of the alignment-based extraction method with the precision of the association measures using the resources described in Sect. 4 , where only the candidate MWEs identified by the methods that are listed in the resources are considered to be true positives, following Baldwin and Villavicencio ( 2002 ). This provides an automatic basis for comparison that does not require a human annotator. It looks only at precision using a very strict gold-standard, as dictionaries have a limited coverage for MWEs. As a consequence, the results reported are likely to be an under-estimate, with many true MWEs being potentially evaluated as false cases if not listed in the resources. A threshold of 1,256 top candidates in the rank is defined as it is the same number of MWEs extracted by the alignment-based method from the corpus (this measure is also known as precision at N or simply P@N ). We note that 317 of the MWEs extracted by the aligner were attested in a dictionary, leading to a value of P @1,256 = 25.2%. The association measures achieved a value of P @1,256 ranging from 0.2% for MI to 8.9% for Dice . Since these values are under-estimated, they should not be interpreted as a performance measure (in which case our method would be three times more precise than the best association measure), but they help us to give an idea of the heterogeneity of these two underlying tasks: while related work shows that association measures perform well in filtering pre-processed MWE candidate lists, we propose a method that performs especially well in extracting MWEs directly from corpora.

Since we do not have manual annotation for the whole corpus, we cannot compare the recall of the baseline with the recall of our method. Instead, we manually compare a small sample of the output of both methods. Therefore, we ranked all the candidates according to each one of the measures and inspected (a) the rank of the example MWEs used in Table 4 and (b) the characteristics of the top retrieved candidates. For the former, we can see in Table 12 that none of the measures distinguishes the true and false instances in these examples, since the pair a hundred has both asymmetric translation and high statistical correlation between the terms. If we inspect the top candidates for MI and v 2 , we realize that they contain a function word (e.g. harmed the , advocating the , handles the ). On the other hand, PMI and Dice seem to prefer very rare MWEs, like proper names (e.g. eurico gaspar , e  X  rico vanucci ) or foreign names (e.g. epinephelus niveatus , cryptomeria japonica ).

Currently, we are unable to measure the recall of our method, so we acknowledge the fact that it could be relatively low. However, the previous analysis shows that the type of information captured by frequency-based methods and by our alignment-based method are of a different nature, suggesting that they should be combined together in order to improve the coverage of the resources build upon the extracted MWEs. Additionally, this preliminary analysis tells us that the baseline approach, when used to identify generic MWEs in corpora of limited size, is very sensitive to low and high frequencies and cannot correctly capture the MWEs in the text. Frequency-based methods are based on n-grams and are thus limited to little values of n , since for small corpora, higher values of n tend to introduce noise in statistical measures, besides being very time-consuming, as performance depends exponen-tially on n . The alignment-based extraction method proposed in this paper is able to identify and extract true MWEs and their translations without suffering from the problems of frequency-based methods and, given that enough parallel text is available, without constrains limiting the size of the extracted MWEs to a certain n-gram window.
 5 Conclusions and future work This paper presented a method for extracting multiword expressions and their translations as a by-product of automatic lexical alignment. A set of varied experiments obtained promising results.

For example, if we limit our extraction method to only those candidates that occur at least 10 and at most 99 times, in our test corpus, we obtain 152 English multiword expressions with an expected precision of 60.53 X 71.71%. Furthermore, these 152 MWEs are accompainied by 96 X 115 translations with an expected precision of 69.79 X 76.52% X  X hen we consider only the most frequent possible translations.
 Finally, if we are interested in only some types of MWEs, we can apply a post-PoS-filter to select those candidates that match some PoS patterns: adjec-tive ? noun (148 candidates with an expected precision of 65.54 X 87.16%), noun ? noun (165 candidates with an expected precision of 68.48 X 80.61%) and verb ? preposition/particle (208 candidates with an expected precision of 88.94 X  97.60%). The application of the post-PoS-filter also revealed some patterns that contribute to depreciate the performance of our method. These patterns are candidates to be excluded in future experiments.

In terms of evaluation, as with other methods, a full analysis of recall would require that the MWEs to be detected from the corpus were known beforehand, through manual annotation of the corpus. However, depending on the size of the corpora this becomes impracticably costly both in terms of labour and time. The alternative explored in this paper is based on MWE dictionaries and, even if the evaluation of the results is limited by the coverage of the lexical resource, we showed that our method is better than standard association measures in extracting MWEs directly from corpora.

Although the proposed method depends on the availability of parallel corpora, it provides a straightforward way of identifying MWE candidates, that traditional statistical based methods may not detect, as discussed in the previous section. Therefore, if such corpora are available these approaches can be combined together, complementing each other for more comprehensive results. In addition, as parallel corpora are becoming increasingly available for a larger number of languages, this requirement becomes less restrictive, as the applicability of this method for other languages also increases.

Future works include the repetition of this experiment with the same 17,397 pairs of pt  X  en parallel sentences, but without PoS tagging them. By doing this we aim at excluding completely the influence of incorrect tags for the method. Another proposal for future work is to evaluate the pt MWE candidates not considered in this first experiment. In relation to the MWE extraction algorithm, we would like to experiment with possible ways of combining standard statistical methods with alignment-based extraction, for instance using association measures to rank the MWEs candidates output by the lexical aligner.
 References
