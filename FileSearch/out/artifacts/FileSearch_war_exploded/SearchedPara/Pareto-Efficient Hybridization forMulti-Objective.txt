 Performing accurate suggestions is an objective of paramount im-portance for effective recommender systems. Other important and increasingly evident objectives ar e novelty and diversity, which are achieved by recommender systems that are able to suggest diversi-fied items not easily discovered by the users. Different recommen-dation algorithms have particular strengths and weaknesses when it comes to each of these objectives, motivating the construction of hybrid approaches. However, most of these approaches only focus on optimizing accuracy, with no regard for novelty and diversity. The problem of combining recommendation algorithms grows sig-nificantly harder when multiple objectives are considered simulta-neously. For instance, devising multi-objective recommender sys-tems that suggest items that are simultaneously accurate, novel and diversified may lead to a conflicting-objective problem, where the attempt to improve an objective further may result in worsening other competing objectives. In this paper we propose a hybrid rec-ommendation approach that combines existing algorithms which differ in their level of accuracy, novelty and diversity. We employ an evolutionary search for hybrids following the Strength Pareto approach, which isolates hybrids that are not dominated by others (i.e., the so called Pareto frontier). Experimental results on two recommendation scenarios show that: (i) we can combine recom-mendation algorithms in order to improve an objective without sig-nificantly hurting other objectives, and (ii) we allow for adjusting the compromise between accuracy, diversity and novelty, so that the recommendation emphasis can be adjusted dynamically according to the needs of different users.
 H.3.3 [ Information Storage and Retrieval ]: Information Filtering Hybridization, Pareto-Optimality, Diversity, Novelty
Recommender systems are increasingly emerging as enabling mechanisms devoted to overcoming problems that are inherent to information overload, providing intelligent information access and delivery, and thus potentially improving browsing and consump-tion experience. Historically, the typical goal of a recommender system is to maximize accuracy as much as possible in predicting and matching user information needs, often by considering indi-vidual delivered items in isolation [12]. More recently, however, it has become a consensus that the success of a recommender sys-tem depends on other dimensions of information utility, notably the diversity and novelty of the suggestions performed by the system [9, 19, 25, 33]. More specifically, even being accurate, obvious and monotonous recommendati ons are generally of little use, si nce they do not expose users to unprecedent experiences.

Increasing novelty and diversity by completely giving up on ac-curacy is straightforward -and meaningless, since the system will not meet the users needs anymore. In fact, there is an apparent trade-off between these dimensions, which becomes evident by in-specting the performance of existing top-N recommendation algo-rithms. An easy conclusion is that different algorithms may per-form distinctly depending on the dimension of interest (i.e., the best performer in terms of accuracy is not the best one in terms of novelty and diversity), and thus it is hard to point to a best per-former if all the dimensions are considered simultaneously. A con-clusion which is harder to reach is whether these algorithms are indeed complementary, so that the strengths of an algorithm may compensate the weaknesses of others. The potential synergy be-tween different recommendation algorithms is of great importance to multi-objective recommender systems, since they must achieve a proper level of each dimension (i.e., objective).

In this paper we hypothesize that it is possible to properly aggre-gate different recommendation algorithms, so that the resulting hy-brids balances the level of accuracy, diversity and novelty in its sug-gestions. In this case, each potential hybrid is given as a weighted combination of well-established recommendation algorithms (e.g., simple algorithms as well as representative of the state-of-the-art). Our proposed hybridization approach consists in finding appropri-ate weights for the constituent algorithms. By considering each dimension (i.e., accuracy, novelty and diversity) as a separate ob-jective, we reduce the hybridiza tion task to a multi-objective opti-mization problem, in which we search for the optimal combination of weights that maximizes accuracy, diversity and novelty.
Since the considered objectives are potentially conflicting, we employ an evolutionary search for optimal hybrids. Evolutionary algorithms denote a class of optimization methods that are char-acterized by a set of candidate solutions (aka individuals) called a population, which is maintained during the entire optimization process. The population of individuals evolves towards better (and potentially optimal) solutions by employing genetic operators, such as reproduction, mutation and crossover. In our context, each indi-vidual represents a possible combination of weights (i.e., a pos-sible hybrid). Optimal hybrids lie in the so-called Pareto frontier [37], and are optimal in the sense that no hybrid in the frontier can be improved upon without hurting at least one of its objec-tives. Therefore, the evolutionary algorithm evolves the population towards producing hybrids that are located closer to the Pareto fron-tier, and then a linear search returns the most dominant hybrid [37], which is likely to balance accuracy, novelty and diversity. Alter-natively, hybrids in the Pareto frontier can be selected according to a certain need, allowing the recommender system to adjust the compromise between accuracy, novelty and diversity, so that the recommendation emphasis can be adapted dynamically according to the needs of each user (i.e., new users may benefit more from more accurate suggestions, whereas older users may require more novel and diversified suggestions).

We conducted a systematic evaluation involving different rec-ommendation scenarios, with explicit user feedback (i.e., movies from the MovieLens dataset), as well as implicit user feedback (i.e., artists from the LastFM dataset). The experiments showed that it is possible to (i) combine different algorithms in order to produce bet-ter recommendations and (ii) control the desired balance between accuracy, novelty and diversity. In order to evaluate the baseline algorithms and our hybrids, we used the methodology for top-N evaluation proposed in [12] and measured novelty and diversity us-ing the framework proposed in [33].
In this section we review the main concepts about evolutionary algorithms and multi-objective optimization. Finally, we discuss related work on hybrid and multi-objective recommender systems.
Evolutionary algorithms are meta-heuristic optimization tech-niques that follow processes such as inheritance and evolution as key components in the design and implementation of computer-based problem solving systems [15, 20]. In evolutionary algo-rithms, a solution to a problem is represented as an individual in a population pool. The individuals may be represented as different data structures, such as vectors, threes, or stacks [26]. If the indi-vidual is represented as a vector, for example, each position in the vector is called a gene.

Typically, evolutionary algorithms employ a training and a val-idation set, as described in Algorithm 1. Initially, the population starts with individuals created randomly (line 6). The evolutionary process is composed of a sequence of solution generations. The process evolves generation by generation through genetic opera-tions (lines 7-12). The goal of this process is to obtain better solu-tions after some generations. A fitness function is used to assign a fitness value to each individual (line 9), which represents its perfor-mance on the training set or in a cross validation set. To produce a new generation, genetic operators are applied to individuals with the aim of creating more diverse and better individuals (line 12). Typical operators include reproduction, mutation, and crossover.
Since we are interested in maximizing three different objectives for the sake of recommender systems (i.e. accuracy, novelty, and di-versity), we use a multi-objective evolutionary algorithm. In multi-objective optimization problems there is a set of solutions that are superior to the remainder when all the objectives are considered together. In general, traditional approaches to multi-objective op-timization problems are very limited because they become too ex-Algorithm 1 Evolutionary Algorithm.
Let M be a training set
Let V be a validation set
Let N g be the number of generations
Let N I be the number of individuals
S X  X  X  X 
P X  X  X  initial random population of individuals
For each generation g of N g do 8 For each individual i  X  X  do 9 fitness  X  X  X  fitness ( i, M , V ) 10 S g  X  X  X N I top-ranked individuals of generation g 12 P X  X  X  New population created by applying genetic
BestIndividual  X  X  X  SelectionMethod( S ) pensive as the size of the problem grows [8]. Multi-objective evolu-tionary algorithms are a suitable option to overcome such an issue.
Typically, multi-objective evolutionary algorithms are classified as Pareto or non-Pareto [37]. In the non-Pareto optimization case, the objectives are combined into a single evaluation value that is used as fitness value (i.e., average of the objectives). In Pareto algo-rithms, on the other hand, a vector of objective values is used (i.e., the individual is given as an objective vector). The evaluation of Pareto approaches follows the Pareto dominance concept. An indi-vidual dominates another if it performs better in at least one of the objectives considered. Given two arbitrary individuals, the result of the dominance operation has two possibilities: (i) one individual dominates another, or (ii) the two individuals do not dominate each other. An individual is denoted as non-dominated if it is not dom-inated by any other individual in the population, and the set of all non-dominated individuals compose the Pareto frontier .
In this work we use a second version of the strength Pareto evolu-tionary algorithm (SPEA-2) [36, 37]. The aim is to find or approxi-mate the Pareto-optimal set for multi-objective problems. The main features of this algorithm are: (i) the fitness assignment scheme takes into account how many individuals each individual dominates or is dominated by, (ii) it uses a nearest neighbour density estima-tion technique to break ties in solutions with the same fitness, (iii) the size of the population of non-dominated solutions is a fixed value  X  . Thus, we have two situations. First, when the actual num-ber of non-dominated solutions is lower than  X  , the population is filled with dominated solutions; second, when the actual number of non-dominated solutions exceeds  X  , some of them are discarded by a truncation operator which pr eserves boundary conditions,even though we always keep the current Pareto Frontier in a list separate from the population, so we can later retrieve the individuals in it.
Traditionally, hybrid recommender strategies are the combina-tion of two different families of algorithms -namely, content-based and collaborative filtering [1]. In this work, we combine many (up to 8) recommendation algorithms -different content-based and col-laborative filtering algorithms that deal with explicit and implicit feedback, etc. We treat each recommendation algorithm as a black-box, so adding or removing recommendation algorithms is easy. Different hybridization strategies have been proposed to combine recommender methods, such as weighted approaches [10], voting mechanisms [30], switching between different recommenders [6, 24], and re-ranking the results of one recommender with another [7].
A prominent use of hybridization in recommender systems is the Belkor system that won the Netflix competition [4, 5]. Their method is a statically weighted linear combination of 107 collab-orative filtering engines. There are important differences between their work and ours: (i) their solution is single-objective (accuracy), (ii) they combine only collaborative filtering information, and (iii) the recommendation task is rating prediction, focused on RMSE -which makes the aggregation simpler, since all of the ratings are on the same scale and consist of the same items.

There has been an increasing consensus in the recommender sys-tems community about the importance of proposing algorithms and methods to enhance novelty and diversity [17, 33]. As showed in [35], user satisfaction does not always correlate with high recom-mender accuracy. Thus, different multi-objective algorithms have been proposed to improve user experience considering either diver-sity or novelty. For instance, in [35], the authors define a greedy re-ranking algorithm that diversifies baseline recommendations. An-other approach to improve diversity is presented in [34], where they suggest an optimization method to improve two objective functions reflecting preference similarity and item diversity.

On the other hand, novelty has been understood as recommend-ing long-tail items, i.e., those items which few users have accessed. In [33], the authors present hybrid strategies that combine collabo-rative filtering with graph spreading techniques to improve novelty. The authors in [9] take an alternative approach: instead of assess-ing novelty in terms of the long-tail items that are recommended, they follow the paths leading from recommendations to the long tail using similarity links. As far as we know, this is the first work that proposes a hybrid method th at is multi-objective in terms of the three metrics, i.e., accuracy, diversity and novelty.
Extensive research has also been performed exploiting the robust characteristics of genetic algorithms in recommender systems. For instance, in [28] the authors build a content-based recommender system and use genetic algorithms to assign proper weights to the words. Such weights are combined using the traditional IR vector space model [2] to produce recommendations. In [23] the authors use a genetic algorithm to build a recommender method that con-siders the browsing history of users in real-time. In contrast to our approach (which uses a GA to combine multiple recommender methods), they use GA to build a single-method.

In [22], the authors present an implementation of GA for opti-mal feature weighting in the multi-criteria scenario. Their appli-cation of GA consists in selecting features that represent users X  in-terest in a collaborative filtering context, in contrast to our method, which focuses on assigning weights to different recommendation algorithms in order to improve the overall performance in terms of accuracy, novelty and diversity.
In this section we introduce our search approach for Pareto-Opti-mal hybrids. We start by discussing how different recommenda-tion algorithms are combined, so that potential hybrids are created. Then we describe the evolutionary search for Pareto-Optimal hy-brids. Finally, we discuss an approach to deal with the compromise between accuracy, novelty and diversity, so that the system is able to adjust itsef for different user perspectives.
Our hybridization approach is based on assigning weights to each constituent algorithm. We denote the set of constituent al-gorithms as A and the score given by algorithm A j for an item i is represented by A j ( i ) . As the constituent algorithms may output scores in drastically different scales, a simple normalization proce-dure is necessary to ensure that all algorithms in A operate in the same scale. The aggregated score for each item i is calculated as: where W is a vector that represents the weight assigned to each constituent algorithm. The assignment of weights to each algorithm is formulated as a search problem which we discuss next.
Finding a suitable vector of weights W can be viewed as a search problem in which possible solutions are given as a combination of weights { w 1 ,w 2 ,...,w | A | } , such that each w i is selected in a way that optimizes a established criterion. We consider the application of evolutionary algorithms for searching optimal solutions. These algorithms iteratively evolve a population of individuals towards optimal solutions by performing operations based on reproduction, mutation, recombination, and selection [18]. This approach is in-teresting because we have no knowledge of the search space, since any number of different algorithms may be used, in different do-mains. Next, we precisely define an individual.
 Definition 1: An individual is a candidate solution, which is en-coded as a sequence of | A | values [ w 1 ,w 2 ,...,w | A w i indicates the weight associated with algorithm A i  X  A .
Each algorithm A i assigns scores to items using a cross-validation set. Finally, weights are assigned to each algorithm and their scores are aggregated according to Equation 1, producing an individual. A fitness function is computed for each individual in order to make them directly comparable, so that the population can evolve to-wards optimal solutions.
 Definition 2: An optimal solution is a sequence of weights W { w 1 ,w 2 ,...,w | A | } , satisfying: where  X  ( o i ) is a metric used to measure an objective, which can be either accuracy, novelty or diversity. These metrics are bet-ter discussed in Section 4. For now it suffices to notice that the performance of each individual is given by a 3-dimensional objec-tive vector, containing the average accuracy, novelty and diversity over the users in the cross validation set ( since different metrics may operate in different scales, we normalize each  X  ( o i 0-1 interval). Searching for optimal solutions, therefore, is a multi-objective optimization problem, in which the value of  X  ( be maximized for each of the 3 objectives that compose an optimal solution. Therefore, multiple optimal individuals are possible. It is worth noticing that different datasets and combinations of algo-rithms and A will generate different optimal individuals.
A general strategy for solving a multi-objective optimization prob-lem is to exploit the concept of Pareto dominance, which may be used to find solutions that are not dominated by others. These non-dominated solutions lie in the so-called Pareto frontier, and are op-timal in the sense that no solution in the frontier can be improved upon without hurting at least one of its objectives. Therefore, the evolutionary algorithm evolves the population towards producing individuals that are located closer to the Pareto frontier, and then a linear search returns the individual which simply maximizes the av-erage (or some other combination, as we see on the next section) of the three objectives. Under this strategy, we follow the well-known Strength Pareto Evolutionary Algorithm approach [36], which has shown to be highly effective and also because it provides more di-verse results when compared to existing approaches [11, 13, 32] for many problems of interest. Th e Strength Pareto approach iso-lates individuals that achieve a compromise between maximizing the competing objectives by evolving individuals that are likely to be non-dominated by other individuals in the population.
It is worth noticing that our approach does not depend on which recommendation algorithms are being aggregated, nor does it de-pend on the data domain. This makes adding or removing algo-rithms trivial, and allows the data to determine how each algorithm contributes to each of the objectives -an algorithm may be the most accurate when ratings are available, but not so accurate when only implicit feedback is used.

The Pareto-Optimal search is computationally expensive. How-ever, it can be performed in an off-line manner, and with low fre-quency. After the Pareto-Optimal weights are discovered, there is no need to perform the search repeatedly, unless a recommendation algorithm is added or removed, or a lot of new feedback data enters the system. Therefore, using this approach would not hinder the system X  X  online performance.
It is well recognized that the role that a recommender system plays may vary depending on the target user. For instance, accord-ing to [19], the suggestions performed by a recommender system may fail to appear trustworthy to a new user because it does not recommend items the user is sure to enjoy but probably already knows about. Based on this, a recommender system might prior-itize accuracy instead of novelty or diversity for new users, while prioritizing novelty for users that have already used the system for a while. This is made possible by our hybridization approach, by searching which individual in the Pareto frontier better solves the user X  X  current needs.

The choice of which individual in the Pareto frontier is accom-plished by performing a linear search on all of the individuals, in order to find which one maximizes a simple weighted mean on each of the three objectives in the objective vector, where the weights in the weighted mean represent the priority given to each objective. It is worth noting that fitness values are always calculated using the cross-validation set. Therefore, considering a 3-dimensional prior-ity vector Q , which represents the importance of each objective j , the individual in the Pareto frontier P is chosen as:
The testing methodology we adopted in this paper is similar to the one described in [12], which is appropriate for the top-N recom-mendation task. For each dataset, ratings are split into two subsets: the training set M and the test set T . The training set M necessary) be split into two subsets: the cross-validation training set C and the cross-validation test set V , which is used in order to tune parameters or adjust models. The test set T and the cross-validation test set V only contain items that are considered relevant to the users in the set. For explicit feedback (i.e., MovieLens), this means that the sets T and V only contain 5-star ratings.
In the case of implicit feedback (i.e., Last.fm), we normalized the observed item access frequencies of each user to a common rat-ing scale [0,5], as used in [33]. Namely, r ( u, i )= n  X  where frec u,i is the number of times u has accessed i and F = | j  X  u | f u,j &lt;f u,i | / | u | is the cumulative distribution function of frec u,i over the set of items accessed by the user u , denoted as u . In this case, the test set and the cross validation test set only contain ratings such that r ( u, i ) &gt; =4 , since the number of 5 star ratings is very small using this mapping of implicit feedback into ratings. It is worth noting that all the sets have a corresponding implicit feedback set, used by the recommendation algorithms that can deal with implicit feedback.

The detailed procedure to create M and T is the same used in [12], in order to maintain compatibility with their results. Namely, for each dataset we randomly sub-sampled 1.4% of the ratings from the dataset in order to create a probe set. The training set tains the remaining ratings, while the test set T contains all the 5-star ratings in the probe set (in the case of explicit feedback) or 4+ star ratings (in the case of implicit feedback mapped into ex-plicit feedback). We further divided the training set in the same fashion, in order to create the cross-validation training and test sets C and V . The ratings in the probe sets were not used for training.
In order to evaluate the algorithms, we first train the models us-ing M . Then, for each item in T that is relevant to user u :
Since the task is top-N recommendation, we form a top-N list by picking the N items out of the 1,001 that have the highest rank. If the test item i is among the top-N items, we have a hit .Otherwise, we have a miss . Recall and precision are calculated as follows:
In order to measure the novelty of the recommendations, we used a popularity-based item novelty model proposed in [33], so that the probability of an item i being seen is estimated as: where U denotes the set of users. Since the testing methodology supposes that most of the 1,000 additional unrated items are not relevant, we used the metrics in the framework proposed in [33] without relevance awareness. The novelty of a top-N recommenda-tion list from R presented to user u is therefore given by: nov ( R ( N )) = EPC ( N )= C where rd ( k ) is a rank discount given by rd ( k )=0 . 85 k  X  1 C is a normalizing constant given by 1 / i N i k  X  R rd ( this metric is rank-sensitive (i.e. the novelty of the top-rated items counts more than the novelty of other items). As is the case with precision and recall, we average the EPC@N value of the top-N recommendation lists over the test set.

We used a distance based model in order to measure the diversity of the recommendation lists. Once again, we used the metrics from [33] without relevance-awareness. The recommendation diversity, therefore, is given by: div ( R ( N )) = EILD ( N )= where rd ( l | k )= rd ( max (1 ,l  X  k )) reflects a relative rank discount between l and k ,and d ( i k ,i l ) is the cosine similarity between two items, given by: such that U i denotes the users that liked item i ,and U j users that liked item j .
We apply the methodology presented in Section 4 to two differ-ent scenarios, in order to evaluate our hybrid approach: movie and music recommendation. For movie recommendation, we used the MovieLens dataset [27]. This dataset contains 1,000,209 ratings from 6,040 users on 3,883 movies. For music recommendation, we used an implicit preference dataset from [9], which consists of 19,150,868 user accesses to music tracks on the website Last.fm This dataset involves 176,948 artists and 992 users, and we con-sidered the task of recommending artists to users. Mapping the implicit feedback into user-artist ratings yielded a total of 889,558 ratings, which were used by the algorithms that cannot deal with implicit feedback, and to separate the dataset into the training and test sets M and T .
We selected eight recommendation algorithms to provide the base for our hybrids. To represent latent factor models, we selected PureSVD with 50 and 150 factors ( PureSVD50 and PureSVD150 ), described in [12]. These were the only algorithms we used that are based on explicit feedback. To compute the scores for the items in the Last.fm dataset, we used the mappings of implicit feedback into ratings explained in Section 5.3.

As for recommendation algorithms that use implicit feedback, we used algorithms available in the MyMediaLite package [16]. We used WeightedItemKNN (WIKNN) and WeightedUserKNN (WUKNN) as representative of neighbourhood models based on collaborative data [14] (we only used WeightedItemKNN on the MovieLens dataset, as MyMediaLite X  X  implementation cannot yet handle datasets where the number of items is very large, which is the case in the Last.fm dataset). As a baseline, and to allow for comparison with [12], we used MyMediaLite X  X  MostPopular implementation, which is the same as TopPop in [12]. We also used WRMF  X  a weighted matrix factorization method based on [21, 29], which is very effective for data with implicit feedback. In order to represent content-based algorithms, we used ItemAt-tributeKNN (IAKNN), a K-nearest neighbor item-based collabo-rative filtering using cosine-similarity over the movie genres for MovieLens (we could not use this method in the Last.fm dataset, because it does not contain content data). Finally, we used UserAt-tributeKNN (UAKNN), a K-nearest neighbor user-based collabo-rative filtering using cosine-similarity over the user attributes, such as sex, age, etc. (which both datasets provide). As a baseline, we used a voting-based hybrid based on Borda-Count (BC) which is similar to [30], where each constituent algo-rithm gives n points to each item i such that n = | R | X  p |
R | is the size of the recommendation list and p i is the position of i in R . We also used STREAM as baseline, a stacking-based approach with additional meta-features [3]. We used the same ad-ditional meta-features as [3], namely, the number of items that a www.Last.fm certain user has rated and the number of users that has rated a cer-tain item (denoted as RM 1 and RM 2 in [3]). We tried the learn-ing algorithms proposed in [3], and Linear Regression yielded the best results, so the results presented for STREAM are generated using Linear Regression as the meta-learning algorithm. Our last baseline is the weighted hybrid we proposed in Section 3.1, using equal weights for each constituent algorithm. We called this base-line Equal Weights (EW).

As for our genetic approach, we combined all of the the rec-ommendation algorithms cited in the last subsection. We used an open-source implementation of SPEA2 [36, 37] from DEAP [31].We used a two points crossover operator [20], and a uniform random mutation operator with pr obability 0.05. SPEA-2 was con-figured with the following parameters:
The results achieved by each of the constituent recommendation algorithms can be seen in Tables 1 and 2. We show the accuracy results (recall and precision) over different values of N. Since both EPC(novelty) and EILD(diversity) are rank-sensitive metrics, we only presented their values for N =20 . There is a clear compro-mise between accuracy, novelty and diversity of these algorithms. For the MovieLens dataset (Table 1), the constituent algorithm that provides the most accurate recommendations is PureSVD50. The constituent algorithm that provides the most novel recommendation with an acceptable degree of accuracy is PureSVD150, but its ac-curacy is much worse than the accuracy obtained by PureSVD50, and its diversity is much worse than the other algorithms. TopPop provided the most diverse recommendations, although it performs significantly worse in accuracy and novelty. It is worth noting that ItemAttributeKNN is based only on genres, which explains its poor accuracy results.

On the Last.fm dataset, the constituent algorithm that provides the most accurate recommendations is WRMF. This is expected, as Last.fm is originally an implicit feedback dataset, to which WRMF is more suitable. Once again, PureSVD150 proved its capacity to suggest novel items, being the algorithm with the most novel rec-ommendations. WeightedUserKNN proved to be the algorithm that provided the most diverse recommendations, while maintaining a reasonable accuracy degree. In this dataset the compromise be-tween the three objectives is once again illustrated by the fact that there is no algorithm that dominates the others in every objective.
Regarding the performance of the baselines in the MovieLens dataset, STREAM performs worse then PureSVD50 on accuracy, maintaining the same level of novelty and performing better in terms of diversity. Borda Count performed poorly on accuracy and reasonably well in terms of novelty and diversity. Equal Weights performed poorly on accuracy and novelty and well on diversity. On the Last.fm dataset, STREAM performed slightly worse than WRMF in accuracy, while maintaining the same level of diversity and improving slightly on novelty. Once again, Borda Count per-formed poorly on accuracy and reasonably well on novelty and di-versity. Finally, Equal Weights performed poorly on accuracy and novelty, while performing well on diversity.

Now, with our evolutionary approach, we could reach any of the individuals in Figure 1, which represent the accuracy (in this case, Recall@10) and novelty (EPC@20) of the recommendations in x and y axes, and diversity (EILD@20) with a color scale. These graphics show the results in the test set for the individuals that rep-resented the Pareto frontier in the cross-validation. It is clear that there is a compromise between the three objectives: the individu-als with the most novel recommendations provide less accurate and diverse lists, and so on. This compromise can be adjusted dynami-cally with little extra cost, since the cost of reaching these individ-uals is as low as a linear search (for the individual that maximizes a weighted mean, as described on Section 3.2) over the Pareto fron-tier individuals X  scores on the cross validation set. The Pareto fron-tier consists of 1,418 individuals in the MovieLens dataset and of 1,995 individuals in the Last.fm dataset, so a linear search can be done very quickly. We chose to demonstrate a few of these indi-viduals in Tables 1 and 2. First, Pareto-Optimal-mean (PO-mean) represents the individual that optimizes the mean of the three nor-malized objectives, assuming each of them are equally important. This would be an option if personalization was not desired, or if the designers of the recommender systems did not know which com-bination of the three objectives would result in higher user satis-faction. However, in a more realistic situation, the recommender system would most likely want to select different individuals for different users. We selected as examples the following individuals, which were found by the process explained in Section 3.2 with the represented associated weighted vectors: We compared PO-acc and PO-acc2 with PureSVD50, which is the stand-alone algorithm with the most accurate recommendations. Both perform as well as PureSVD50 on accuracy, but PO-acc per-forms much better on diversity (and equally well on novelty), and PO-acc2 performs better on novelty while maintaining the diver-sity level. We compared PO-nov with Pure-SVD150, which pre-sented the most novel recommendations to the users, with reason-able accuracy. PO-nov performs slightly better on novelty than PureSVD150, but performs much better in terms of accuracy, and slightly on diversity. Finally, we compared PO-div with MostPopu-lar, the algorithm with the most diverse recommendations. PO-div loses very slightly on diversity, while improving on accuracy and novelty. We were able, therefore, to find individuals in the Pareto frontier that performed close or better than the best algorithms in each individual objective, but better on the other objectives. Once again, we could have chosen to compromise more accuracy and diversity if we desired more novelty, as is shown by Figure 1 (left).
As for the Last.fm dataset, we selected the following individuals:
For the Last.fm dataset, we compared PO-acc with WRMF, which is the most accurate stand-alone algorithm on this dataset. PO-acc is much more accurate than WRMF, while also improving on nov-elty and maintaining the diversity level. The individual PO-nov was compared with PureSVD150, and it performed equally well on accuracy, while delivering a much higher novelty, and only a slightly worse diversity. PO-div was compared against Weight-edUserKNN, and it faired equally well on diversity and novelty, while slightly improving on accuracy. It is worth noticing that the individual represented by PO-div is the same individual that max-imizes the mean with equal weight (PO-mean). Once again, we were able to find interesting individuals in the Pareto frontier, but we could have reached any of the individuals in Figure 1 (right) by tweaking the weight value for each objective.
In this paper, we propose a hybridization technique for combin-ing different recommendation algorithms, following the Strength Pareto approach. We show that different recommendation algo-rithms do not perform uniformly well when evaluated in accuracy, novelty and diversity, but our technique allows for the dynamic ad-justment of the compromise between these three aspects of user satisfaction. This can be very useful in different scenarios, one ex-ample being the personalization of recommendations according to the users. According to [25],  X  X ew users have different needs from experienced users in a recommender. New users may benefit from an algorithm which generates highly ratable items, as they need to establish trust and rapport with a recommender before taking advantage of the recommendations it offers. X  Therefore, our ap-proach could be used to provide new users with the most accurate recommendations as possible, even if the recommendations are not novel at all -so the users would have items to rate, and build trust in the system. The costly part of our technique (the evolutionary algorithm) is performed off-line, and the online cost of choosing an individual in the pareto frontier and weighting the results for differ-ent algorithms is very small, since the pareto frontier is comprised of few individuals.

We performed highly reproducible experiments on public datasets of implicit and explicit feedback, using open-source implementa-tions. In our experiments, we demonstrated our technique X  X  ability to balance each of the objectives according to the desired compro-mise, and we showed some examples of reached solutions that are competitive with the best algorithms according to each objective and almost always better on the other objectives.
This work was partially sponsored the Brazilian National Insti-tute of Science and Technology for the Web (grant MCT/CNPq 573871/2008-6), and by the authors X  individual grants from CNPq. [1] G. Adomavicius and A. Tuzhilin. Toward the next generation [2] R. Baeza-Yates and B. Ribeiro-Neto. Modern information [3] X. Bao, L. Bergman, and R. Thompson. Stacking [4] R. Bell, Y. Koren, and C. Volinsky. Chasing $1,000,000: [5] J. Bennett, S. Lanning, and N. Netflix. The netflix prize. In [6] D. Billsus and M. Pazzani. User modeling for adaptive news [7] R. Burke. Hybrid recommender systems: Survey and [8] R. Cecchini, C. Lo renzetti, A. Maguitman, and N. Brignole. [9] O. Celma and P. Herrera. A new approach to evaluating novel [10] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov, [11] D. Corne, J. Knowles, and M. Oates. The pareto [12] P. Cremonesi, Y. Koren, and R. Turrin. Performance of [13] K. Deb. Multi-objective genetic algorithms: Problem [14] C. Desrosiers and G. Karypis. A comprehensive survey of (95%).
 [15] A. Eiben and J. Smith. Introduction to evolutionary [16] Z. Gantner, S. Rendle, C. Freudenthaler, and [17] M. Ge, C. Delgado-Battenfeld, and D. Jannach. Beyond [18] E. Goldberg. Genetic Algorithms in Search, Optimization [19] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. [20] J. Holland. Adaptation in natural and artificial systems . [21] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for [22] C. Hwang. Genetic algorithms for feature weighting in [23] M. Jung, J. Oh, and E. Lee. Genetic recommend generating [24] G. Lekakos and P. Caravelas. A hybrid approach for movie [25] S. McNee, J. Riedl, and J. Konstan. Being accurate is not [26] Z. Michalewicz. Genetic algorithms+ data structures . [27] B. N. Miller, I. Albert, S. K. Lam, J. A. Konstan, and [28] J. Pagonis and A. Clark. Engene: A genetic algorithm [29] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, [30] M. J. Pazzani. A framework for collaborative, content-based [31] F. Rainville, F. Fortin, M. Gardner, M. Parizeau, and [32] N. Srinivas and K. Deb. Multiobjective optimization using [33] S. Vargas and P. Castells. Rank and relevance in novelty and [34] M. Zhang and N. Hurley. Avoiding monotony: improving the [35] C. Ziegler, S. McNee, J. Konstan, and G. Lausen. Improving [36] E. Zitzler, M. Laumanns, and L. Thiele. Spea2: Improving [37] E. Zitzler and L. Thiele. Multi-objective evolutionary
