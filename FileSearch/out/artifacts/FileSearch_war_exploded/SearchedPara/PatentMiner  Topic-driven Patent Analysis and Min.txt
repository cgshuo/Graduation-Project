 Patenting is one of the most important ways to protect com-pany X  X  core business concepts and proprietary technologies. Analyzing large volume of patent data can uncover the po-tential competitive or collaborative relations among com-panies in certain areas, which can provide valuable infor-mation to develop strategies for intellectual property (IP), R&amp;D, and marketing. In this paper, we present a novel topic-driven patent analysis and mining system. Instead of merely searching over patent content, we focus on studying the heterogeneous patent network derived from the patent database, which is represented by several types of objects (companies, inventors, and technical content) jointly evolv-ing over time. We design and implement a general topic-driven framework for analyzing and mining the heteroge-neous patent network. Specifically, we propose a dynamic probabilistic model to characterize the topical evolution of these objects within the patent network. Based on this mod-eling framework, we derive several patent analytics tools that can be directly used for IP and R&amp;D strategy plan-ning, including a heterogeneous network co-ranking method, a topic-level competitor evolution analysis algorithm, and a method to summarize the search results. We evaluate the proposed methods on a real-world patent database. The ex-perimental results show that the proposed techniques clearly outperform the corresponding baseline methods.
 H.3.3 [ Information Search and Retrieval ]: Text Mining; H.2.8 [ Database Management ]: Database Applications Algorithms, Experimentation Patent analysis, Competitor analysis, Company ranking, So-cial network
Patenting becomes one of the most important ways to pro-tect company X  X  core business concepts and proprietary tech-nologies. Before a company entering the market of a new field, a comprehensive patent landscape overview is always necessary, lest be faced with a flurry of third-party licens-ing opportunities or even lawsuits. Nowadays, the collec-tion and retrieval of patent publications is a critical compo-nent of a company X  X  intellectual property strategy. Within many companies (or organizations), patent analysts have the responsibility to determine how patent information is best made available and how it is best used within their organiza-tions in a strategic manner. From the technical perspective, patent, as one of the few real indicators of future product re-leases, carries out the technical details of research of different companies long before the product reaches the marketplace. Keeping being aware of novel technology development and competitors X  technological advancement also becomes more and more important for a company to make the decision on marketing and R&amp;D strategies.

However, patent analysts in the 21st century now face many challenges. They must search over the huge volume of patents to find relevant patents, to recognize potential com-petitors (or collaborators), and to identify inventors with significant impact. Despite a great deal of theoretical de-velopment in information retrieval and data mining tech-niques, advanced search tools for patent professionals are still in their infancy. Most existing patent analysis systems such as Google Patent 1 , WikiPatent 2 , FreePatentsOnline only focus on the search function. A few other systems such as Patents 4 , PatentLens 5 , and PriorArtSearch 6 provide more advanced analysis and mining capabilities. For exam-ple, the Patents system uses iBoogie to cluster the retrieved patents. It also provides a forum for people to discuss dif-ferent patenting related problems. PatentLens provides a function called Patent Landscapes, which lists a number of  X  X hite Papers X  discussing technologies relevant to life sci-entists. However, the Technology Landscapes require exten-sive searching and analytical work by people skilled in both science and intellectual property, thus infeasible to scale up to various topics. http://www.google.com/patents http://www.wikipatents.com/ http://www.freepatentsonline.com/ http://www.patents.com/ http://www.patentlens.net/ http://www.priorartsearch.com/
This paper reports the development of PatentMiner 7 , a novel topic-driven patent analysis and mining system. PatentMiner is designed for an in-depth analysis of patent activity at the topic-level. The main unique characteristics of the PatentMiner system that distinguish it from tradi-tional patent search systems are as follows: (1) topic-driven modeling; (2) heterogeneous network co-ranking; (3) intelli-gent competitive analysis; and (4) patent summarization. 1. Topic-driven modeling. The fundamental problem in 2. Heterogeneous network co-ranking. When a company 3. Competitive analysis. It would be very helpful for a 4. Patent summarization. It is always expensive to di-
We conducted empirical evaluations of the proposed meth-ods. Experimental results show that our methods clearly outperform the baseline methods for addressing the above issues. Our technical contributions in this paper include: (1) a proposal of a probabilistic topic modeling approach, (2) a proposal of a heterogeneous co-ranking method for search over the patent network, (3) a proposal of a topic-level com-petitive evolution analysis approach, and (4) a proposal of a maximum coverage model for patent summarization.
Figure 1 shows the architecture of the system. The system consists of five major components: 1. Patent Network Extraction : The patent data contains 2. Patent Network Storage : It provides storage and http://pminer.org 3. Probabilistic Topic Modeling : It utilizes a generative 4. Analysis and Mining : This is the most important com-5. Distributed Platform : The back-end system is built on
At present, we maintain an English patent database ex-tracted from USPTO.gov, which consists of nearly 4,000,000 patents, 2,000,000 inventors, and 400,000 companies. The system is very flexible and can be easily extended to multi-ple different sources.
 Preliminaries Assume that a patent d contains a vec-tor w d of N d words, in which each word w di is chosen from a vocabulary of size V ,andthepatent d is devel-oped by a group of inventors a d and is owned by company c , then a collection of M patents can be represented as patents D , we extract the inventor and company informa-tion from each patent, and derive a heterogeneous patent network.

Definition 1. Heterogenous Patent Network. The heterogeneous patent network can be represented as a graph centered by the patent G =( V d  X  V a  X  V c ,E da  X  E dc  X  E ac ) ,where V d includes all patents, V a includes all inven-tors, V c includes all companies, and the edge ( v d ,v a (or briefly e da ) suggests that there is a relationship between patent v d and inventor v a . Similarly we can define the other relationships e dc , e dd ,and e ac .

The heterogeneous patent network is comprised of three different types of objects: inventors, companies, and patents. Each object may be associated with different topics. For example, a patent may talk about  X  X eb search X  and  X  X ata mining X . The goal of topic modeling over the patent network is to discover the latent topics associated with each object. Each topic z is defined as a mixture of words and their probabilities belonging to the topic, i.e., { ( w 1 ,P ( w 1 | z )) ,  X  X  X  , ( w N 1 ,P ( w N 1 | z )) } be extended to other information sources. For exam-ple, we can extend the topic definition by companies, i.e., { ( c 1 ,P ( c 1 | z )) ,  X  X  X  , ( c N 1 ,P ( c N 1 | z )) } each object would be associated with a topic distribution, e.g.,aninventor a is associated with { P ( z | a ) } z . By further considering the time information, a patent network can be segmented into a network sequence GS =( G 1 ,G 2 ,  X  X  X  ,G according to the time-stamp associated with each object. Each sub network G t in the sequence is comprised of ob-jects in the time window t , e.g., patents published at time t . In this work, the time-stamp is defined as the published year of each patent. Table 1 lists the major notations.
Several topic models have been proposed and successfully applied to text mining tasks [1, 4, 9, 13, 18]. However, these models can only model patent contents and are not able to incorporate the company and inventor information, which contains valuable information for topic modeling. More-over, they cannot model the time information. In this sec-tion, we will first present an Inventor-Company-Topic model which leverages interdependencies between different objects to learn the topic model, and then describe an extension of the model by combining time information.
We present an Inventor-Company-Topic (ICT) model, which incorporates companies, inventors, and patents into a unified probabilistic model. The basic idea is to describe patent writing in a generative process. The generative pro-cess can be described as follows: when preparing a patent d ,eachinventor x  X  a d would suggest what topics to be included in patent according to his expertise (the associ-ated topic distribution P ( z |  X  x )or  X  xz ); then the word w is sampled from a suggested topic z di by the inventor ac-all the suggested topics specific to the patent d are relevant to the own company c d . Aggregating topics of all patents owned by company c d could constitute a topic distribution of the company P ( z |  X  c )or  X  cz . Formally, we use a uniform distribution to associate each patent with its inventors, use a multinomial distribution (with a prior  X  ) to associate each inventor with the topics, and use a similar multinomial dis-tribution (with a prior  X  ) to associate each topic with words. The company-topic distribution is represented as a mixture of topic distribution extracted from each patent (again can be considered as a multinomial distribution with a different prior  X  ). Finally, given a collection of patents D ,wecould write its generative log-likelihood as: where m xz is the number of times that topic z was associated with inventor x , n zw j is the number of times that word w is generated by topic z , n zc is the number of times that company c is generated by topic z , N d is the number of words in patent d ,and A d is the number of inventors for patent d .

Learning the ICT model is to estimate the unknown pa-rameters in the ICT model. There are two sets of unknown parameters: (1) the distribution  X  of A inventor-topics, the distribution  X  of K topic-words, and the distribution  X  of K topic-companies; and (2) the corresponding topic z di and inventor x di for each word w di . It is usually intractable to do exact inference in such a probabilistic model. A vari-ety of algorithms have been proposed to conduct approxi-mate inference, for example variational EM methods [1] and Gibbs sampling [7]. We chose Gibbs sampling for its ease of implementation. Specifically, we calculate the posterior distribution on z and then sample the topic for each word. Based on the sampling results, we could infer the distribu-tion  X  ,  X  ,and  X  . For the hyperparameters  X  ,  X  ,and  X  ,for simplicity, we take fixed values (i.e.,  X  =50 /K ,  X  =0 . 01, and  X  =0 . 01.
Though the ICT model incorporates companies, inventors, and patents together, it still cannot capture the temporal in-formation. We therefore propose a dynamic extension of the ICT model. The general idea is that topic distribution of an object (e.g., company) in adjacent time-stamps (e.g., two continuous years) should be similar. At each time-stamp, an ICT model is built, i.e., each object is associated with a topic distribution which will be used as a prior for the object in the next time-stamp. The prior has a smoothing effect to make the discovered topic models between adjacent time-stamps similar to each other. The new model is re-ferred to as Dynamic Inventor-Company-Topic (DICT). To summarize, there are three smoothing requirements for the dynamic modeling:
Now, the problem is how to combine the three smooth-ing hypothesis into the ICT model. One strategy is to use a regularization framework to describe the three smoothing factors as three regularization terms, and plug into the orig-inal log-likelihood function, thus we obtain a new objective function: where  X  1 ,  X  2 ,and  X  3 are three parameters to balance the importances of different smoothing factors.

It is intractable to solve the new objective function. In ex-isting literatures, there are a few attempts to deal with the constrained regularization framework using approximation algorithms such as [24] and [11]. However, these methods cannot guarantee a convergence. In this paper, we consider an alternative method to solve the problem. Instead of plug-ging the regularization terms into the log-likelihood func-tion, we use the learned topic model of previous time-stamp as the prior for the topic model of the current time-stamp. Specifically, we use the Gaussian distribution as the prior can also consider other prior distributions, such as Dirichlet distribution or Gamma distribution. We tested a few dis-tributions and found that the Gaussian distribution has the best performance. With a prior distribution, we can incor-porate the smoothing effect directly into the probabilistic generative process (as summarized in Algorithm 1). To learn the Dynamic ICT model, we can still use the Gibbs sampling algorithm for parameter estimation of the DICT model. In an analogous way, we first estimate the posterior probability of sampling the topic z t di for each word w di with time-stamp t , and then use the sampling results to infer  X  t ,  X  t ,and  X  t . Specifically, with the learned topic model at time t , we can estimate the probability of a topic given an inventor  X  t xz , the probability of a word given a topic  X  t zv , and the probability of a company given a topic  X  zc respectively by (Derivation is omitted for brevity.): where  X  is a parameter to control the influence of the topic model of the previous time on the topic model of to the current time.

Algorithm 1 : Probabilistic generative process in DICT.
The unique requirements of searching over the heteroge-neous patent network give rises to several challenging is-sues and make them different from general search engines. First, the information seeking practice [8] is not only about patents, but also about other information sources, such as companies and inventors. In this spirit, a good patent search engine should provide supports not only for patents, but also for these information sources. Second, search over the patent network typically requires much higher retrieval ac-curacy. Given a query, such as  X  X ata mining X , a user does not mean to find patents merely containing these two words. Her/his intention is to find patents on the data mining topic. Finally, these two issues are often intertwined.
Formally, given a heterogeneous patent network G = ( V,E ), and a query q = { w 1 ,  X  X  X  ,w n } ,ourobjectiveisto leverage the power of both textual content (patent content) and the network information (relationships between differ-ent types of objects) in the patent network to obtain accu-rate ranking results for companies, inventors, and patents.
To deal with the ranking problem over the patent network, a straightforward method is to first represent each object with a bag of words, and then calculate the relevance score of each object with a given query q by using methods such as language model [22] or vector space model [20]. We use language model as the example to explain how to calculate the relevance score. Language model is one of the state-of-the-art approaches for information retrieval. It interprets the relevance between a document and a query word as a generative probability: where N d is the number of words in document (patent) d , tf ( w,d ) is the word frequency (i.e., occurring number) of word w in d , N D is the number of words in the entire collection, and tf ( w, D ) is the word frequency of word w in the collection D .  X  is the Dirichlet smoothing factor and is commonly set according to the average document length in the collection [22]. Further, the probability of the document model d generating a query q can be defined as P ( q | d )= X  w  X  q P ( w | d ). For companies and inventors, we first combine all patents associated with each object and create a virtual document, and then use a similar formula to calculate the relevance score of company P ( q | c )andin-ventor P ( q | a ).

However, such a method is only based on keyword match-ing and cannot leverage the topic modeling information. To take advantage of the topic modeling results, we define an-other relevance score: where P ( w | z )=  X  zw , P ( z | x )=  X  xz ,and P ( x | d )= combining the two relevance scores, we have:
In practice, the learned topics by the topic model is usu-ally general to a given query while the language model is spe-cific to keywords in the query. Combining the two relevance scores achieves a balance between generality and specificity, thus could improve the ranking performance. However, this method still does not consider the network information. We therefore propose a heterogeneous co-ranking method to ad-dress this issue.

The basic idea of the heterogenous co-ranking method is to propagate the relevance score between the linked objects in the network. The intuition behind the method is as follows: (a) a patent applied by inventors with higher expertise de-grees on a topic (query) is more likely to have a higher qual-ity (or impact); (b) a company who owns many high quality patents on a topic is more likely to be ranked higher; (c) an inventor who applies many patents with high impacts should be ranked higher. Similar strategies have been also consid-ered in [23, 14] for academic search. Based on this intuition, we propose a two-stage method. In the first stage, we use Eq. 8 to calculate the relevance score of each object to the given query q and select the top-ranked objects as candidates. In the second stage, we use the candidates to construct a het-erogeneous subgraph and perform a score propagation on the subgraph. Finally, we use the new score to re-rank each type of objects. In the propagation, we calculate the new score by (here we use company as the example): where r k [ c ] is the ranking score of company c after the k -step propagation; the score is initialized by Eq. 8; V c a denotes a set of inventors related to company c and V c d denotes a set of patents owned by company c ;  X  1 and  X  2 are two parame-ters to control the propagation. The number of propagation steps reflects how we trust the network information. Setting k = 0 indicates that we only use the content information, thus the method degrades to Eq. 8; while setting k =  X  indicates that we only trust the network information, thus the algorithm obtains a result similar to that of PageRank [12] on the heterogenous network.
This component aims to quantitatively characterize the competitive relations between companies. Based on the modeling results of the DICT model, we define four mea-sures to quantify the competitive relations.
 Global competitor discovery If two companies compete in their major areas, we call these two companies global competitors of each other. For example, ExxonMobil and Shell Oil are two global competitors: they are two energy companies, competing in X  X il exploration X , X  X il refinery X , and  X  X hemical X . Given a company c , we define the following mea-sures to rank its global competitors: Topic-level competitor discovery Two companies may only compete in one or a few specific areas. For example, Apple and Amazon may not be global competitors, but they compete fiercely on X  X ablet PC X . Given a company c ,weaim to find its competitors on a specific topic z . The simplest way is to utilize the topic distribution associated with each company. For two companies c and c ,if | P ( c | z )  X  P ( c  X  ,thenwesaythat c and c are competitors on topic z . The method is referred to as distribution-based competitor finding (DBC). However, this method ignores the correlation between topics. For example, companies who compete on  X  X ata mining X  may also compete on  X  X eb search X , as the two topics have a strong correlation with each other. To incorporate the topic correlation, we define a hybrid measure (HBC) as follows: where  X  zz is the correlation between topic z and topic z , could be calculated as the negative Kullback-Leibler diver-gence [22]:  X  zz =  X  KL (  X  z ||  X  z ).
 Evolutionary competitor discovery Companies may change their IP and marketing strategies, thus the competi-tive relations between them would change over time as well. Based on the dynamic ICT model, we define the competitive degree between two companies c and c at time t as: where P ( z i | c ) can be obtained using Bayes rule based on  X  i c . We use the parameter  X  tt (defined as e model the historic information in the above equation, which means if two companies are competitors in a recent past time, it is also likely that they are competitors in the current time.

We can further extend the evolutionary competitor discov-ery to the topic level. The basic idea is to replace the inner summation in the above equation with the specific topic.
When a user performs a search in the patent mining sys-tem, a large number of objects (patents, companies, and inventors) may be returned. It is always expensive for the user to digest the large volume information. It is desirable that the system can automatically generate a concise and informative summary for the returned objects, so that the user can quickly grasp a global picture before  X  X lick-and-view X  each object. A high-quality summary should satisfy the following requirements: (1) cover the most important information in the returned objects, (2) be relevant to the query as well, and (3) minimize the redundancy in the gen-erated summary.

To solve the patent summarization problem, we propose a maximum coverage method. The idea is to choose a set of representative sentences as the summary from the returned objects for a query. The method consists of three major steps. First, when the user issues a query, it retrieves rele-vant patents for the query. Second, it extracts concepts from each sentence in the patents. All the extracted concepts form the knowledge space for the query and each sentence is also represented by the extracted concepts. Finally, it em-ploys integer linear programming to find a set of sentences whose concepts maximally cover the knowledge space. Concept extraction In our maximum coverage method, concept is the basic unit to represent the knowledge. A concept can be a word, a phrase, a named entity (e.g., Person or Location), or even a parsed syntax subtree of a sentence. Each concept has an importance score to the query. The schemes of concept scoring vary from simple term frequency to sophisticated machine learning methods. In our method, candidate concepts are selected using bi-grams and are weighted using TF  X  IDF . Specifically, all patents are preprocessed by (1) sentence splitting, (2) part-of-speech tagging, (3) stemming and phrase chunking. Then we collect all extracted noun phrases (obtained by phrase chunking) from the patents and further split them into bi-grams as candidate concepts. The next step is to score each candidate concept. In particular, we segment each patent into five fields: Title, Abstract, Claim, Background, and Other. Each field has a weight to reflect its importance (we empirically set the field-weights as 2, 1.5, 1.5, 1.0 and 0.5 respectively). Then, the importance score of each candi-date concept is defined as the sum of weighted frequencies, i.e., filed-weight  X  concept-frequency-in-the-field. Finally, we choose the top 50 candidate concepts with the highest scores to form the knowledge space of the given query.
 Summary generation An ideal summary should cover as many important and diverse concepts as possible. The problem can be formulated as a 0-1 knapsack problem. For-mally, it aims to maximize the total importance score of concepts that form the knowledge space. In addition, we need to consider several constraints. The first one is the summary length: a user would not want to read a long sum-mary. Thus, we define a maximal number of words in the extracted summary, i.e., MaxLength . Another constraint is to maintain the logical consistency between variables. For example, if the summary contains an important concept, then it at least includes one sentence which contains this concept. By combining the objective and the constraints together, we define the following constrained optimization problem: where C i is an indicator to represent whether the i -th con-cept is included in the summary ( C i =1)ornot( C i =0), and IS i is the importance score of the i -th concept. In the first constraint, L j is the number of words in the j -th sen-tence, and S i is an indicator of whether the j -th sentence is included in the summary. In the second and the third con-straints, Occ i,j is an indicator of whether the i -th concept occurs in the j -th sentence.

We solve the above optimization problem using integer linear programming (ILP). Specifically, we employ an open source software, LP-Solve (http://lpsolve.sourceforge.net/). The obtained result is an optimal solution that maximizes the objective function. Finally, we construct the summary by selecting sentences with S j =1.
We evaluated the proposed methods in the context of the PatentMiner system 7 , consisting of 3,880,211 patents, 2,134,211 inventors, and 421,032 companies. We conducted three experiments to evaluate the proposed methods: het-erogeneous co-ranking, competitor analysis, and patent sum-marization. Data Sets, Evaluation Measures, and Baselines To qualitatively evaluate the proposed methods and compare with existing methods, we collected a list of 50 popular queries (e.g.,  X  X ata mining X ,  X  X eb search X ). For each query, we independently request five annotators (two undergrad-uates, two PhD students, and one faculty) to provide hu-man judgement on the top (20) returned objects (compa-nies, patents, and inventors) by the system. The judgement is about relevant (Like) or irrelevant (DisLike). If there are more than two annotators saying that an object is irrelevant, we remove the object from the returned list. As it is really difficult to judge the expertise for inventors even for human, we only perform the evaluation for companies and patents. We conducted the evaluation in terms of P@N (Precision for top N results), mean average precision (MAP), and normal-ized discounted cumulative gain (NDCG) [2, 5].
 We used language model (LM) as the baseline method. For language model, we used Eq. 6 to calculate the relevance between a query term and a patent and similar equations for an inventor/company, where an inventor is represented by Table 2: Average ranking performance for the patents and companies. N@1 and N@5 indicate NDCG his/her published patents and a company is represented by its held patents. Our heterogeneous co-ranking method is referred to as HCR. We tried different settings for the propa-gation. For example, HCR-2 indicates the heterogeneous co-ranking method with 2-step propagation. We preprocessed each patent by (a) removing stopwords and numbers; (b) removing words that appear less than three times in the cor-pus; and (c) downcasing the obtained words. Moreover, we performed company name disambiguation (e.g., IBM versus IBM Corp.) based on a company name dictionary.
 Results and Analysis Table 2 shows the ranking perfor-mances for patents and companies. We see that the pro-posed HCR method (with all settings) clearly outperforms the baseline method using language model. In terms of MAP, the improvement of HCR-5 over language model is 5.3% for patent ranking and 5.01% for company ranking. Our method benefits from the topic modeling results which consider the companies, patents, and inventors in a unified model while the language model can only use the content in-formation. In addition, the propagation process in our HCR methods further leverages the network information.
We studied how the number of propagation step influences the ranking performance. Figure 2 shows the ranking per-formance in terms of MAP with varied propagation step. Increasing the propagation step from 1 to 5 results in im-proved performance. This is because that our methods in-tegrated more network information with more propagation steps. However, continuing to increase the propagation step make the network information an dominate factor for the final ranking results, thus hurts the relevance performance. Figure 2: Ranking performance with varied propa-gation step. Data Sets, Evaluation Measures, and Baselines It is difficult to obtain the ground truth for evaluating our method X  X  performance on competitor analysis. For a rel-atively fair comparison, we have obtained the competitor information from Yahoo! Finance 8 , which hosts informa-tion of all companies listed on NASDAQ, Dow Jones, S&amp;P, etc. For each company, it gives a list of competitors based on their business performance (such as revenue and employ-ees). It also provides the topic information for the competi-tors, such as Microsoft and Oracle compete on  X  X oftware X . In summary, we obtained 543 companies and their global competitor information, and 326 companies and their com-petitors on 18 different topics.

We used P@N, MAP, and NDCG to evaluate our method (referred to as TopCom), and to compare with two baseline methods. The first one (referred to as WBS) is to represent each company as a bag of words (by the vector space model [20]), and for a given company, its competitors are ranked according to the Cosine similarity of the company with each candidate. This method can identify the global but not topic-level competitors. The second baseline method is for topic-level competitors analysis. We used Latent Dirichlet Allocation (LDA) [1] to generate the topic-word distribution and then combine the language model (LM) for competitor discovery. Specifically, we used all the patent titles to learn the LDA model, and used language model to find the rel-evant patents for a given query. Finally we obtained the competitive companies by summing all the scores of their corresponding patents. Hereafter we will use  X  X M+LDA X  to denote this method. In addition, we compared our methods with different scoring measures (Cf. Section 5): Results and Analysis Table 3 shows the performance of different methods on global and topic-level competitor anal-ysis. We see that our method (TopCom) outperforms the baseline methods. For the global competitor analysis, our method with the probability-based correlation (PBC) scor-ing measure achieves the best performance in terms of P@1, P@5, N@1, and N@5. For the topic-level competitor analy-sis, the best performance is obtained by our method with the hybrid-based (HBC) scoring measure, which indicates that a scoring measure leveraging both topic and patent content in-formation can achieve a better performance than using only one of the information. The advantage of our method lies in that in the proposed DICT model, we simultaneously model the topic distribution of companies, inventors, and patents; http://finance.yahoo.com/ Table 3: Performance of competitor analysis. N@1 Table 4: Examples for topic-level competitor evolu-tion.
 while the two baseline methods only model the content in-formation (WBS) or only model the topic distribution of patents (LM+LDA).
 Case Study Table 4 shows example results of the topic-level competitor evolution analysis by our TopCom+PBC method. From the example, we have observed some inter-esting patterns. On topic  X  X etwork Devices X , Cisco X  X  early (1996-2000) competitors include IBM, Microsoft, Lucence, etc., but now it turns out to be 3Com, Juniper, and Broad-com, etc. Juniper seems to be a rising star in the  X  X etwork Device X  field; while a few other companies (such as AT&amp;T and Lucent) have passed their bloom on  X  X etwork Device X  since 2001. Instead, AT&amp;T and Lucent have become more focused in the  X  X ommunication X  field. Data Sets, Evaluation Metrics, and Baselines The patent summarization method was first tested on bench-mark data sets TAC 2008 and 2009 9 before being applied to patent data. TAC 2008 and 2009 datasets respectively contain 48 and 44 topics (queries). The document collection for each topic is given. The task is, similar to our problem, to generate a 100-word summary from the document collec-tion for each topic (query). Four human-written summaries are used as gold standard for each topic.

We compared our approach with two baseline methods that reported the state-of-the-art performance on this task. The baselines are: Maximal Marginal Relevance (MMR) [3] and Diversity Penalty (DP) [21]. We use ROUGE-1 and ROUGE-2, two commonly used evaluation metrics in docu-ment summarization, as the evaluation measures.
 Results and Analysis Table 5 lists the results of different summarization methods on the TAC datasets. Our approach clearly outperforms the baseline systems on both datasets. The relative improvements over the baselines are about 6% and 10% in terms of ROUGE-1 and ROUGE-2. We also http://www.nist.gov/tac/ Table 5: Summarization performance on the TAC datasets. ILP is our approach.

Figure 3: Demonstration system of PatentMiner. compared our generated results with the human-written re-sults. The last column in Table 5 is the average results of the four human-written summaries for all topics. Therefore, these scores in the last column can be considered as the up-per bound of the summarization task. As shown in Table 5, the average score of our approach (0.371/0.372 by ROUGE-1) reaches 86.63% of that of gold standard (0.414/0.444), 86.01% in terms of ROUGE-2, which further confirms the effectiveness of the proposed approach. We have developed a patent analysis and mining system: PatentMiner, and implemented the proposed methods in the system. Figure 3 shows the screenshot of the system. The top-left of is the profile page for  X  X icrosoft Corporation X . There are three plots respectively showing the patent appli-cation trend, topic trend, and major inventor trend. The right side is the results of competitor evolution analysis on topic  X  X obile phone X .
There are a few systems for patent search and analy-sis such as Google Patent, WikiPatent, FreePatentsOnline, Patents, PatentLens, and PriorArtSearch. However, most of these systems focus on search and provide limited macro-level analytic functions. Few systems provide the user with insights into the micro-level analysis of the patent network. No existing system studies the problem of dynamic topic modeling and the topic-level competitor analysis. Tseng et al. [19] introduce a series of text mining techniques for patent analysis, including text segmentation and summary extraction. However, they merely employ existing text min-ing techniques for patent analysis.
Arnetminer [18] is a  X  X ister X  system of PatentMiner. It uses a combination approach to build profiles for academic researchers [16] and provides topic-level expertise search over academic social networks [17]. Compared with these prior works, the PatentMiner system distinguishes itself in the following aspects: dynamic topic-driven modeling, heteroge-neous network co-ranking, competitive analysis, and patent summarization, where we propose new approaches to over-come the drawbacks that exist in the traditional methods.
Considerable work has been conducted for extracting top-ics from text. For example, Hofmann [9] proposes the prob-abilistic latent semantic indexing (pLSI) and applies it to information retrieval. Blei et al. [1] propose Latent Dirichlet Allocation (LDA) by introducing a conjugate Dirichlet prior for all documents. Several extensions of the LDA model have been proposed, for example, the Author model [10], the Author-Topic model [13], and the Author-Conference-Topic model [18]. The major difference of our ICT and DICT mod-els from existing models is that we simultaneously model dynamic topics of different objects in the patent network.
We introduce the architecture, algorithms, and main fea-tures of the PatentMiner system. We design and imple-ment a general topic-driven framework for analyzing and mining the heterogeneous patent network. Specifically, we first propose a dynamic probabilistic model to model the topical evolution of different objects in the heterogeneous network. We then present a heterogeneous co-ranking ap-proach to rank the multiple objects. We further propose an approach for topic-level competitor analysis. To help users digest the search result, we introduce a method to summa-rize the patent search results. We evaluate the proposed methods on a real-world patent database and the experi-mental results validate the effectiveness of our methods.
There are many directions of this work. It would be in-teresting to further study influence between companies [15]: how a company X  X  technology innovation influences another company X  X  marketing/R&amp;D strategy? Another challenge is how to integrate domain knowledge into the mining process. Acknolwedgements The work is supported by a research fund from ExxonMobil Corporation. Jie Tang has been sup-ported in part by the Natural Science Foundation of China (No. 61073073, No. 61170061), Chinese National Key Foun-dation Research (No. 60933013, No. 61035004). [1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [2] C. Buckley and E. M. Voorhees. Retrieval evaluation [3] J. Carbonell and J. Goldstein. The use of mmr, [4] D. Cohn and H. Chang. Learning to probabilistically [5] N. Craswell, A. P. de Vries, and I. Soboroff. Overview [6] J. Dean and S. Ghemawat. Mapreduce: Simplified [7] T. L. Griffiths and M. Steyvers. Finding scientific [8] M. Hertzum and A. M. Pejtersen. The [9] T. Hofmann. Probabilistic latent semantic indexing. In [10] A. McCallum. Multi-label text classification with a [11] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. [12] L. Page, S. Brin, R. Motwani, and T. Winograd. The [13] M. Steyvers, P. Smyth, and T. Griffiths. Probabilistic [14] J. Tang, R. Jin, and J. Zhang. A topic modeling [15] J. Tang, J. Sun, C. Wang, and Z. Yang. Social [16] J. Tang, L. Yao, D. Zhang, and J. Zhang. A [17] J. Tang, J. Zhang, R. Jin, Z. Yang, K. Cai, L. Zhang, [18] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. [19] Y.-H. Tseng, C.-J. Lin, and Y.-I. Lin. Text mining [20] C. van Rijsbergen. Information Retrieval .
 [21] X. Wan, J. Yang, and J. Xiao. Towards an iterative [22] C. Zhai and J. Lafferty. A study of smoothing methods [23] J. Zhang, J. Tang, and J. Li. Expert finding in a social [24] X. Zhu and J. Lafferty. Harmonic mixtures:
