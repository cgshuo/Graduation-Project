 The emergence of complex networks has led to a surge of research in graph data mining [1]. Graph classification is an important graph data mining task that aims to learn a discriminative model from training examples to predict class labels of test examples, where bot h training and test examples are graphs. Many real-world applications involve graph-represented data, such as chemical compounds, XML documents, and program flows. The essential challenge for graph classification is to extract features from graphs and represent graph data in instance-feature format to support model training. A variety of studies on substructure extraction (e.g., walks [2], p aths [3], and subtrees [4,5]) for describ-ing graphs have been proposed in the past decade. However, most of them only consider the learning problem of graph classification in batch mode (all data are available for training), which limits their applicability to large-scale and stream scenarios.

Due to the streaming nature of many real-world complex networks, such as social networks and sensor networks, graph stream classification has recently attracted increasing research interest [6,7,8,9]. Graph stream classification is de-fined on a complex network which comprises a massive universe of nodes, where the stream of graphs are represented as sets of edges on the underlying network. For example, co-authorships of research works continuously form graphs on a coauthor network (e.g., DBLP), dynamic communities of interest continuously form graphs on a social network (e.g., Facebook), and traffic flows continuously form graphs on a transportation network. Graph stream classification on a com-plex network with massive nodes is challenging, because  X  Subgraph Feature Generation: Graph stream is defined on a massive  X  Increasing Stream Volumes: The volumes of graph data are continuously  X  Changing Feature Distributions: The marginal distributions of Few studies have investigated the graph stream classification problem. To the best of our knowledge, only two works [9,11] may be applied to the considered problem. Both of them employ hashing techniques to sketch the graph stream for saving computational cost and controlling the size of the subgraph-pattern set. In [11], the authors proposed a hash kernel to project arbitrary graphs onto a compatible feature space for similarity computing, but it can only be applied to node-attributed graphs. Recently, Aggar wal [9] proposed a 2-D hashing scheme to construct an  X  X n-memory X  summary for sequentially presented graphs and used a simple heuristic to select a set of most discriminative frequent patterns to build a rule-based classifier. Although [9] has exhibited promising perfor-mance on graph stream classification, there are two inherent limitations: (1) The selected subgraph-patte rns are composed with disconnected edges, which may have less discriminative capability than connected subgraph-patterns due to a lack of semantic meaning. (2) The computational cost is high because an additional frequent pattern mining procedure is required to perform on the sum-mary table which comprises massive transactions.
 In this paper, we propose a fast graph stream classification method using DIscriminative Clique Hashing (DICH) to address the aforementioned chal-lenges. The main idea is to decompose a compressed graph into a number of cliques (fully connected subgraphs) to seq uentially extract clique-patterns over the graph stream as features. Two random hashing schemes are employed to compress the original edge set of the graph stream and map the unlimitedly in-creasing clique-patterns onto a fixed-siz e feature space, respectively. The hashed cliques are then used to update an  X  X n-memory X  fixed-size pattern-class table, which will be finally used to generate a rule-based classifier. Since DICH adopts connected subgraphs as features and needs no additional frequent pattern mining procedure, it can achieve very fast training speed for graph stream classification . The experimental results on two real-wo rld graph stream data sets clearly show that DICH outperforms the compared state-of-the-art [9] in both classification accuracy and training efficiency.

The remainder of this paper is organized as follows: Section 2 introduces the related work. The proposed framework for graph stream classification will be described in Section 3 and the detailed method of DICH will be presented in Section 4. We empirically evaluate ou r method to show its effectiveness and efficiency in Section 5 and con clude the paper in Section 6. The considered problem is closely related to graph classification. Most existing works focus on designing effective yet effi cient kernels for measuring graph sim-ilarity. A large number of graph kernel s have been proposed in the last decade, most of which are based on the similar idea of extracting substructures from graphs to compare their co-occurrences. Typical substructures for describing graphs include walks [2,12], paths [3], subtrees [4,5,13], and subgraphs (usually based on a frequent subgraph mining technique, e.g., [14]). In this paper, we extract cliques as features for describing a graph.

Our problem is also related to data stream mining. Mining high-speed data streams was first studied in [15] and the idea of using ensemble learning for data stream classification was proposed soon after [16]. A classical ensemble learning framework for addressing the concept-drift problem in data stream mining was proposed in [10]. In our graph stream classification problem, we employ a rule-based classification approach rather than the ensemble learning framework for faster processing speed and easier model updating.

The most relevant work to this paper is [9], which also considers graph stream classification on a complex network. It employs a 2-D hashing scheme to con-struct an  X  X n-memory X  summary for the sequentially presented graphs. The first random-hash scheme is used to reduce the size of the edge set. The second min-hash scheme is used to dynamically update a number of hash-codes (i.e., corre-sponding to random sorting samples), which is able to summarize the frequent patterns of co-occurrence edges in the graph stream observed thus far. Finally, a simple heuristic is used to select a set of most discriminative frequent patterns to build a rule-based classifier. In this paper, we propose a clique-based hashing scheme for solving the same problem with a better performance in both classi-fication accuracy and training efficiency as well as avoiding the the limitations of [9] discussed in Section 1. We first introduce the problem setting for graph stream classification. Suppose there is a complex network which compr ises a massive universe of nodes. The edges connecting these nodes are denoted by the edge set E . The stream of graphs { G 1 ,G 2 ,...,G i ,... } are presented continuously as subsets of E ,where the subscript i denotes the receiving order in the graph stream. In particular, the edge set of G i are denoted by { E 1 ,...,E e } X  X  ,where e denotes the number of edges in G i .Eachgraph G i has a class label L i  X  X  1 ,...,M } . We assume G i is received in the form i,E 1 ,...,E e ,L i . In this paper, we assume that each edge has a default weight 1 for simplicity. The underlying graph stream can only be accessed once and our goal is to learn a discriminative model from {
G 1 ,G 2 ,...,G i ,... } at a high efficiency to accurately predict the class label of atestgraph G test in the future graph stream.

We next give an overview of DICH for graph stream classification. The cor-responding framework, illustrated in Figure 1, comprises three modules. The graphs in the stream are r eceived and processed one by one. The first module is for clique detection from each graph in the stream. The incoming edges of G i are first randomly hashed to a compressed edge set and then we adopt a fast algorithm to decompose the compressed graph into a number of cliques (fully connected subgraphs) as the features of G i . Since the number of clique-patterns will unlimitedly increase as new graphs are fed in, the underlying feature space will keep expanding accordingly. Thus, in the second module, a clique hash-ing scheme is performed to map the unlimitedly emerged clique-patterns onto a fixed-size clique-pattern set. In the last module, an  X  X n-memory X  fixed-size pattern-class table is updated using the clique-pattern and class label informa-tion of G i ; and a rule-based classifier is constructed based on the pattern-class table by identifying frequent and discriminative clique-patterns associated to each class. To test a graph G test in the future graph stream, G test is processed in the first two modules and the obtained hashed clique-patterns are input to the rule-based classifier for class label prediction. The detailed approaches to the three modules are described in the following section. 4.1 Graph Clique Detection As shown in Figure 1, instead of relying on expensive frequent subgraph mining to discover graph features, we propose to use frequent and discriminative clique-patterns for clique-based classifier const ruction. So our first step is to detect all the cliques from each graph in the graph stream. Since the edge set of the graph stream on the complex network can be extremely large, it is necessary to sketch the graph stream as a preprocessing step. In particular, we use a random hash function to map the original edge set E onto a significantly compressed edge set  X  E of size N . That is to say, the edges in the compressed graph of G i will be indexed by { 1 ,...,N } . If multiple edges in G i are hashed onto the same index, the weight Algorithm 1. Clique Detection of the compressed edge is set to the number of the edges that get the same index. After hashing all the edges in G i , we obtain a compressed graph  X  G i for clique detection. We define this edge hashing scheme using  X  G i := Edge-Hash( G i ,N ). The leftmost two columns in Figure 2 illustrates this procedure.

Next we will employ a fast algorithm to detect cliques in each compressed graph. We adapt the graphlet basis estimation algorithm used in [17] to this end. The first step for clique detection is to threshold the compressed graph  X  G i at a where max(  X  G i ) and min(  X  G i ) denote the largest and the smallest edge weights in  X  denotes the indicator function and the resulting graph is denoted by  X  G ( t ) i .We use the Bron-Kerbosch algorithm [18] to identify all the cliques from  X  G ( t ) i at each threshold. The union set of the cliques found in {  X  G ( t ) i } max(  X  G i ) as the clique set for G i . This procedure is detailed in Algorithm 1.
An example of clique detection is illustrated in Figure 2. After edge hashing, we obtain the compressed graph of G i (2nd column). Then, four weight thresh-Note that  X  G (3) i is an empty graph which is not shown. The Bron-Kerbosch algo-rithm is applied to the three graphs and detect a set of cliques from each graph (4th column). Finally, the cliques detect ed at all weight thresholds are merged to form the clique set C i for G i as its feature representation (5th column). 4.2 Graph Clique Hashing The cliques extracted from each graph a re used to represent its features. To learn a classifier from the graph stream, it is required to make the features of all graphs be in the same feature space. In other words, we should count the occurrences of the same set of clique-pa tterns in all graphs in the stream. Since the number of clique-patterns will increase as new graphs are continuously fed in, the induced feature space will keep expanding accordingly. To address this problem, we adopt a feature hashing scheme used in [11] to randomly map the unlimitedly emerged clique-patterns onto a fixed-size set. In particular, we use an  X  X n-memory X  P  X  M pattern-class table  X  , which can be dynamically updated, to count clique-pattern and class label information from the graph stream. In  X  , P rows correspond to the indices of hashed clique-patterns while M columns correspond to all the classes of the graphs.

Given G i in the graph stream, we first use Algorithm 1 to collect the clique set C i . Then, for each clique in C i ,say C i,j , we apply a random hash function (  X  ) to the string of ordered edges in C i,j to generate an index H i,j  X  X  1 ,...,P } . If a clique with class label L i is hashed to an index H i,j ,weadd1totheentry  X  [ H i,j ,L i ], which means clique-pattern C i,j has a contribution to class L i .This fixed-size pattern-class table is continuously updated as new cliques are detected over the graph stream. This procedure is detailed in Algorithm 2.
 Algorithm 2. Clique Hashing 4.3 Clique-Based Classifier Given the  X  X n-memory X  pattern-class table  X  , we can construct a rule-based classifier by identifying frequent yet discriminative clique-patterns from  X  .To identify frequent clique-patterns, we first sum up the counts in each row of  X  and divide them by the number of graphs received thus far. The result for each row indicates the occurrence frequency of a set of cliques with the same hash value in the graph stream. Then we sort them in a descending order and set a threshold parameter  X  to select the clique-patterns whose frequencies  X   X  . These selected cliques are frequent clique -patterns which are also the candidates for the subsequent discriminati ve clique-pattern selection.

Next we can determine whether a frequent clique-pattern is also a discrimi-native one by comparing its occurrence ratios on the M classes (corresponding to the M columns in  X  ). For a candidate clique-pattern, the ratio in column j represents the probability that the clique-pattern belongs to class j .Ahigher probability on a certain class indicates a better discriminative capability. Sim-ilarly, we can set a thr eshold parameter  X  to select the clique-patterns whose maximum ratios  X   X  . Figure 3 gives a toy example for selecting the frequent and discriminative clique-patterns from a pattern-class table  X  .

Finally, based on the selected clique-p atterns, we can classify a test graph using majority voting based on the detected cliques in the test graph. In par-ticular, given a test graph G test , we detect its cliques C test using Algorithm 1 corresponding to a discriminative clique-pattern will contributes a class label L test,j := Find-Rule(  X ,H test,j ). The class label of the test graph L test is de-detailed in Algorithm 3. In this section, we will test the proposed DICH method for graph stream classifi-cation on two real-world data sets. In part icular, we will evaluate the effectiveness and efficiency of DICH by comparing it with the 2-D hash compressed stream classifier [9], which is the only state-of-the-art method applicable to graph stream classification. We use the following data sets in our experiments. Algorithm 3. Graph Classification  X  DBLP Data Set 1 : In this data set, authors are nodes and co-authorship  X  IBM Sensor Data Set 2 : This data set records the information from local 5.1 Effectiveness Evaluation In this experiment, we evaluate the effectiveness of DICH by comparing it with the 2-D hash compressed stream classifier proposed in [9]. We will investigate the classification performance and sensitivity of the two methods by varying 1) the frequent pattern threshold  X  , 2) the discriminative pattern threshold  X  ,and 3)thesizeofthecompressededgeset N .

First, we adjust the frequent pattern threshold 3  X  for performance evaluation and fix the other two parameters by setting N = 5000 and  X  =0 . 4. Figure 4 plots the classificat ion accuracy curves ( y -axis) w.r.t.  X  ( x -axis) on the two data sets. We can see that the classification performance of DICH is much higher than the 2-D hash compressed stream classifier on both data sets and in all values of  X  . The performance of both classifiers trends to decline as  X  becomes larger since more graph features will be eliminated and such information loss will affect classification performance. By comparing the curve slopes of two classifiers, the 2-D hash compressed stream classifier is more sensitive to  X  .Inthecaseof  X  =0 . 3, the classification accuracy of the 2-D hash compressed stream classifier is much lower. From this experiment, we can validate the effectiveness of DICH, which can clearly outperform the 2-D hash compressed stream classifier and is more insensitive to the frequent pattern threshold.

Second, we adjust the discriminative pattern threshold  X  for performance eval-uation and fix the other two parameters by setting N = 5000 and  X  =0 . 05. Figure 5 plots the classific ation accuracy curves ( y -axis) w.r.t.  X  ( x -axis) on the two data sets. On the DBLP data set, DICH was significantly superior to the 2-D hash compressed classifier in classific ation accuracy. The classification per-formance of both methods was insensitive to  X  , which may be due to the fact that the two classes (Database related conferences and Data mining related con-ferences) in DBLP data are extremely rar e, the identified frequent patterns have already had relatively high discriminative capability. On the IBM sensor data set, although DICH is somewhat more sensitive to  X  than the 2-D hash com-pressed classifier, it has much higher classification accuracy in all cases. This experiment further demonstrates that DICH has higher effectiveness than the 2-D hash compressed classifier in terms of the discriminative pattern threshold.
Third, we adjust the size of the compressed edge set N for performance eval-uation and fix the other two parameters by setting  X  =0 . 06 and  X  =0 . 3. Intuitively, the classification performance of both classifiers will increase at the expense of more space. Figure 6 plots the classification accuracy curves ( y -axis) w.r.t. N ( x -axis) on the two data sets. We can see that the 2-D hash compressed classifier is very sensitive to N , especially on the DBLP data set; while DICH is more steady on the DBLP data set but no clear performance improvement can be observed as N becomes larger. On the IBM sensor data set, the performance of both classifiers is improved as N becomes larger. Again, DICH outperforms the 2-D hash compressed classifier in all cases.
 5.2 Efficiency Evaluation In this experiment, we evaluate the efficiency of the two compared methods on the DBLP data set by adjusting the frequent pattern threshold  X  , the discrim-inative pattern threshold  X  , and the size of the compressed edge set N .The settings of these parameters are the same as those in the above effectiveness evaluation. All the experiments are conducted on a Linux Cluster which com-prises 24 nodes with 3.33GHz Intel Xeon CPU (64bit). Both DICH and the 2-D hash compressed stream classifier are implemented using R studio.

Figure 7 plots the training time curves of the two compared methods w.r.t.  X  ,  X  ,and N on the DBLP data set. We can see that the training time of DICH is significantly less than the compresse d hash-based classifier in all cases. The computational cost of the 2-D hash compressed classifier is much higher be-cause it requires an additional frequent pattern mining procedure to perform on the edge co-occurrence table which comprises massive transactions. In con-trast, DICH employs a fast clique detection algorithm, which can directly find cliques (connected subgraphs) from the gr aph stream as features for classifier construction, such that no additional frequent pattern mining procedure is re-quired to find connected subgraph patterns. This experiment shows that DICH clearly outperforms the 2-D hash compre ssed classifier in not only classification accuracy but also training efficiency. In this paper, we propose a fast graph stream classification method using DIs-criminative Clique Hashing (DICH). The main idea is to employ a fast algorithm to decompose a compressed graph into a number of cliques to sequentially ex-tract clique-patterns over the graph stream as features. Two random hashing schemes are employed to speed up the discriminative clique-pattern mining pro-cess and address the unlimitedly clique-p attern expanding problem. The hashed cliques are used to update an  X  X n-memory X  fixed-size pattern-class table, which is finally used to construct a rule-based classifier. We test DICH on two real-world graph stream data sets. Because DIC H directly extracts cliques (connected subgraphs) from the graph stream as features for classifier training, rather than mining unconnected co-occurrence edge s ets as that in the compared state-of-the-art method [9], DICH can significantly outperform [9] in both classification accuracy and learning efficiency.
 Acknowledgements. This work was supported in part by Australian Re-search Council (ARC) Discovery Project DP1093762, Australian Research Coun-cil (ARC) Future Fellowship FT100100971, and a UTS Early Career Researcher Grant.

