
The rest of this paper is organized as follows. In Section 2, we discuss related work in network anomaly detection. In 3, we describe nonstationary modeling in general, and then PHAD and 
ALAD. In 4, we describe the DARPA IDS evaluation data set. In 5, we test our IDS and describe the five types of anomalies found. 
In 6 we describe our implementation and its run time performance. In 7, we conclude and describe future work. 
Early work in anomaly detection was host based. Forrest et. al. [5] demonstrated that when software errors in UNIX servers or operating system services (suid root programs) are exploited in an 
R2L or U2R attack, that they deviate from the normal pattern of system calls. When compromised, these programs execute code on the behalf of the attacker (usually a shell), rather than the code intended by the developer (such as a DNS name server or print queue manager). Forrest detected these attacks by training an n-gram model (n = 3 to 6) as the system ran normally. More recent work has focused on better models, such as state machines [17], or neural networks [6]. Solaris makes system call information available through its basic security module (BSM) service for this purpose. 
Network intrusion detection is typically rule based. It is fairly straightforward to write a rule in SNORT [15] or BRO [12] for example, to reject any packet addressed to a nonexistent host or service, or to write rules restricting services to a range of trusted addresses. However, it is a little more challenging to relieve the network administrator of the task of keeping the rules updated by monitoring the traffic to determine normal usage patterns. 
However, systems such as ADAM [3], NIDES [1], and SPADE [18] do this. ADAM (Audit Data and Mining) is a combination anomaly detector and classifier trained on both attack-free traffic and traffic with labeled attacks. It monitors port numbers, IP addresses and subnets, and TCP state. The system learns rules destination port is Y with probability p". It also aggregates packets over a time window. ADAM uses a naive Bayes classifier, which means that if a packet belongs to some class (normal, known attack, or unknown attack), then the probabilities for each condition (such as IP address = X and port = Y) are assumed to be independent. ADAM has separate training modes and detection modes. NIDES [1], like ADAM, monitors ports and addresses. 
Instead of using explicit training data, it builds a model of long term behavior over a period of hours or days, which is assumed to contain few or no attacks. If short term behavior (seconds, or a single packets) differs significantly, then an alarm is raised. 
NIDES does not model known attacks; instead it is used as a component of EMERALD [11], which includes host and network based signature detection for known attacks. 
SPADE [18] is a SNORT plug-in that detects anomalies in network traffic. Like NIDES and ADAM, it is based on port numbers and IP addresses. SPADE estimates probabilities by counting incoming server requests (TCP SYN packets) in a way that favors newer data over old, and assigns high anomaly scores to low probability events. It uses several user selectable statistical models, including a Bayes classifier, and no explicit training period. It is supplemented by SNORT rules that use signature detection for known attacks. SNORT rules are more powerful, in that they can test any part of the packet including string matching the application payload. To allow examination of the the number of observations in training and dividing by the total number of observations. However, this may be incorrect. Paxson and Floyd [13] showed that many types of network processes, such as the rate of a particular type of packet, have self-similar or fractal behavior. This is a nonstafionary model, one in which no sample, no matter how short or long, can predict the rate of events for any other sample. Instead, they found that events tend to occur in bursts separated by long gaps on all time scales, from milliseconds to months. We believe this behavior is due to changes of state in the system, such as programs being started, users logging in, software and hardware upgrades, and so on. training counts to favor recent events, and many models do just that. One problem with this approach is that we have to choose either a decay rate (half life) or a maximum count in an ad-hoc manner. We avoid this problem by taking training decay to the extreme, and discarding all events (an attribute having some particular value) before the most recent occurrence. In our model, the best predictor of an event is the time since it last occurred. If an event x last occurred t seconds ago, then the probability that x will occur again within one second is lit. We do not care about any events prior to the most recent occurrence of x. those events that have the lowest probability. As a simplification, we assign anomaly scores only to those events that have never occurred in training, because these are certainly the least likely. We use the PPMC model of novel events, which is also used in data compression [2]. This model states that if an experiment is performed n times and r different outcomes are observed, then the probability that the next outcome will not be one of these r values is approximately r/n. Stated another way, the fraction of events that were novel in training is r/n, and we expect that rate to continue. This probably overestimates the probability that the next outcome will be novel, since most of the novel events probably occurred early during training. Nevertheless, we use it. test data (with attacks), we cannot simply assign an anomaly score of 1/P(x) = n/r. If we did, then a subsequent occurrence of x would receive the same score, even though we know (by our nonstationary argument) that a second occurrence is very likely now. We also cannot add it to our model, because the data is no longer attack-free. Instead, we record the time of the event, and assign subsequent occurrences a score of t/P(x) = tn/r, where t is the time since the previous anomaly. On the first occurrence of x, t is the time since the last novel observation in training. each of which can have many possible outcomes. For each attribute with a value never observed in training, an anomaly score of tn/r is computed, and the sum of these is then assigned to the message. If this sum exceeds a threshold, then an alarm is signaled. In the next two sections, we describe two models, PHAD and ALAD. In PHAD (packet header anomaly detection), the message is a single network packet, and the attributes are the fields of the packet header. In ALAD (application layer anomaly detection), the message is an incoming server TCP connection. The attributes are the application protocol keywords, opening and closing TCP flags, source address, and destination address and 
For most fields, we do not care what they are for, beyond their 
There is a wide range of C for which PHAD gives good 
The second component of our anomaly detection model is the 
We tested a large number of attributes and their combinations address of the client making the request, and dest IP is the local host address. This differs from PHAD in that the probability is conditional (a separate model for each local dest IP), only for TCP, and only for server connections (destination port &lt; 1024). In training, this model learns the normal set of clients or users for each host. In effect, this models the set of clients allowed on a restricted service. that there is a separate model for each server on each host. It learns the normal set of clients for each server, which may be differ across the servers on a single host. servers which normally receive requests. It should catch probes that attempt to access nonexistent hosts or services. normal TCP flag sequences for the first, next to last, and last packet of a connection. A normal sequence is SYN (request to open), FIN-ACK (request to close and acknowledge the previous packet), and ACK (acknowledge the FIN). The model generalizes across hosts, but is separate for each port 
PHAD, which we believe to be simulation artifacts. ~ (time to live) is an 8-bit counter decremented each time an IP packet is routed in order to expire packets to avoid infinite routing loops. 
Although small 'ITL values might be used to elude an IDS by expiring the packet between the IDS and the target [14], this was not the case because the observed values were large, usually 126 or 253. Such artifacts are unfortunate, but probably inevitable, given the difficulty of simulating the Internet [4]. A likely explanation for these artifacts is that the machine used to simulate the attacks was a different real distance from the inside sniffer than the machines used to simulate the background traffic. We did not count attacks detected solely by TTL. we detect 70 of 180 (39%) of attacks at 100 false alarms. Among the poorly detected attacks [9, Table 4], we detect 23 of 77 (30%), or 23 of 65 (35%) of the 180 detectable attacks in our data set, almost the same rate as for the well detected attacks. This is a good result because an anomaly detection system such as ours would not be used by itself, but rather in combination with other systems such as those in the original evaluation that use signature detection or host based techniques. In order for the combination to be effective, there must be a significant non-overlap, and our results show that. We should also point out that when we developed PHAD and ALAD, we did so with they goal of improving the overall number of detections rather than just the poorly detected attacks. 
Table 4 with the anomaly that led to its detection. In many cases, the two seem unrelated, or at the very least, the anomaly could plausibly occur in benign traffic. For example, there are several buffer overflow attacks that exploit poorly written programs that use C functions such as gets() or strcpyO to write into a buffer (fixed sized array of characters) without checking the length of the input. An attack will typically contain a long string that overflows the buffer and overwrites the return address on the stack of the target machine. When the executing function returns, it instead jumps to an address supplied by the attacker, typically a string of machine code supplied as part of the same attacking string. The code is executed with the privilege level of the target (often root), usually to open a shell or plant a backdoor. anomalies in the form of long strings of executable code where we would normally expect to find short strings of text. However, we do not have the appropriate attributes to detect this type of anomaly. Usually it is something else that makes the attack stand out. For example, ncftp and sendmail are caught because they use perfectly legal, but seldom used keywords, or the keyword is lower case when most clients use upper case. Many of the U2R attacks (which a network IDS would normally miss) are detected because the attacker uploads the exploit program using an FTP server that is normally used only for downloads. Other attacks are detected because the source IP address is new to the host or server under attack. not tell us much about it. For example, portsweep and queso are detected by identical anomalies, a TCP FIN packet (request to close connection) without an accompanying ACK flag set. in the reply. It is not always clear whether an anomaly is an error or part of the signature, so we use the principle that if the attack could be easily changed to hide it, then it is an error. For example, one apache2 attack is a malformed HTTP request: But the other instances, which do not generate the same anomaly, replace "x" with a normal "GET / HTrP/1.1". The attack succeeds either way, so we consider "x" to be an error instead of part of the signature. Table 5. Detected attacks classified by the type of anomaly, and the fraction of the 70 total detected attacks detected this way. Anomaly Det/70 Attacks Detected Learned 24 (34%) PROBE: ipsweep, tuscan, 2 ntinfoscan, 
Signature 3 quest, 2 satan; DOS: crashiis, 4 Induced 5 (7%) DOS: apache2, 3 arppoison, tcpreset Evasion 3 (4%) PROBE: 3 portsweep Attacker 10 (1`4%) DOS: apache2, 3 mailbomb, 2 Error udpstorm; R2L: 2 dict, phf; U2R: yaga User 38 (5,4%) PROBE: tuscan; DOS: 3 apache2, 5 
Behavior crashiis, mailbomb, processtable, evaluation. A few alarms were generated by more than one anomaly, so the total is more than 100. Table 6. The 100 top false alarms detected by PHAD and ALAD. Anomaly False alarms TCP source IP address 35 Keyword (7 SMTP, 4 FrP, 3 auth, 2 HTI'P) 16 TTL (time to live, simulation artifact) 9 TCP checksum (simulation artifact) 8 Outgoing TCP connection on server port 7 TOS (type of service) 7 Urgent data pointer or URG flags 7 Bad TCP connection (3 no SYN, no FIN, RST) 5 Destination address/port 5 Packet size (Ethernet, IP, UDP) 3 Other (2 IP fragments, 2 TCP options) . ,4 From table 6 we can see that the types of anomalies that generate false alarms are generally the same types that detect attacks. For example, source and destination addresses and outgoing TCP connections (FrP upload) which are responsible for the behavioral detections (about half of the total) are also responsible 
We found five categories of anomalies. By decreasing for example FI'P uploads of U2R exploits on a server normally used only for downloads. malformed IP fragments of pod and teardrop. udpstorm, or using lowercase text in sendmail and dict. as the unusual TCP options in reply to apache2. scanning by portsweep. 
Compared to signature detection, anomaly detection, which is 
We have made some progress on one aspect of the anomaly 
Second is the parsing problem. We had to hard code rules 
Tamaru, Alfonso Valdes, "Detecting unusual program behavior using the statistical component of the Next-generation Intrusion Detection Expert System (NIDES)", 
Computer Science Laboratory SRI-CSL 95-06 May 1995. http://www.sdl.sfi.com/papers/5/s/5sri/5sri.pdf 
Text Compression", ACM Computing Surveys (21)4, pp. 557-591, Dec. 1989. 
