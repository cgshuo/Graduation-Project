 Peilin Zhao  X  zhao0106@ntu.edu.sg Jialei Wang  X  jl.wang@ntu.edu.sg Pengcheng Wu  X  wupe0003@ntu.edu.sg Rong Jin  X  rongjin@cse.msu.edu Steven C.H. Hoi  X  chhoi@ntu.edu.sg The goal of kernel-based online learning is to sequen-tially update a nonlinear kernel-based classifier given a sequence of training examples ( Kivinen et al. , 2001 ; Cheng et al. , 2006 ; Crammer et al. , 2006 ; Jin et al. , 2010 ; Zhao et al. , 2011 ). Although it yields signifi-cantly better performance than linear online learning, the main shortcoming of kernel-based online learning is its potentially unbounded number of support vectors, which requires a large amount of memory for storing support vectors and a high computational cost per it-eration, both making it unsuitable for large-scale ap-plications. In this work, we address this challenge by developing a computationally efficient framework for budget online learning in which the number of support vectors is bounded by a predefined size (i.e., budget). In literature, several algorithms have been pro-posed for online budget learning. Crammer et al. ( Crammer et al. , 2003 ) proposed a heuristic ap-proach for online budget learning, which was further improved in ( Weston &amp; Bordes , 2005 ). The basic idea of these two algorithms is to remove the support vec-tor that has the least impact on the classification per-formance when the budget number of support vectors is reached. The main shortcoming of these two algo-rithms is that they are heuristic approaches and do not have solid theoretic supports (i.e., neither a mis-take bound nor a regret bound is proved).
 Forgetron ( Dekel et al. , 2005 ) is the first online budget learning algorithm that has guarantee on the number of mistakes. At each iteration, if the classifier makes a mistake, it conducts a three-step updating: it first runs the standard Perceptron ( Rosenblatt , 1958 ) up-dating; it then shrinks the weights of support vectors by a carefully chosen scaling factor; it finally removes the support vector with the least weight. Randomized Budget Perceptron (RBP) ( Cavallanti et al. , 2007 ) re-moves a randomly selected support vector when the number of support vectors exceeds the predefined bud-get. It achieves similar mistake bound and empirical performance as the Forgetron algorithm.
 Unlike the strategy that discards one of sup-port vectors to maintain the budget, Projec-tron ( Orabona et al. , 2008 ) adopts a projection strat-egy to bound the number of support vectors. Specif-ically, in each iteration when the training example is misclassified, it first constructs a new kernel classifier by applying the updating rule of Perceptron to the cur-rent classifier; it then projects the new classifier into the space spanned by all the support vectors except the new example received. The classifier will remain unchanged if the difference between the new classifier and its projection is smaller than a given threshold. Empirical studies show that Projectron usually out-performs Forgetron in classification but with signifi-cantly longer running time. One main shortcoming of Projectron is that although the number of support vectors of Projectron is bounded, it is however unclear the exact number of support vectors achieved by Pro-jectron in theory. In addition, its high computational cost makes it unsuitable for large-scale applications. All the existing algorithms for online budget learn-ing are based on the Perceptron algorithm, par-tially because they are mostly concerned with the mistake bound, not the regret bound. In this pa-per, we develop a  X  X ounded Online Gradient De-scent X  (BOGD) framework for online budget learn-ing algorithms, based on the online gradient descent algorithms ( Kivinen et al. , 2001 ; Zinkevich , 2003 ; Ying &amp; Pontil , 2008 ). Similar to the Random Budget Perceptron, the proposed algorithms randomly select one of the existing support vectors to discard when the buffer of support vectors overflows. However, unlike the Random Budget Perceptron that discards every support vector with equal probability, in one of our al-gorithms, the probability of discarding a support vec-tor depends on its weight, making it more effective for online budget learning. Different from most existing studies that can only obtain a guarantee on the mis-take bound, we derive regret bounds for the proposed algorithms, making it possible to convert the proposed algorithms into batch learning algorithms when the received examples are iid samples. Finally, it is im-portant to distinguish the proposed work from sparse online learning ( Langford et al. , 2009 ; Duchi &amp; Singer , 2009 ) whose goal is to learn a sparse linear classifier from a sequence of training examples. In contrast, we focus on learning a nonlinear kernel classifier. The rest of the paper is organized as follows. Section 2 introduces the basic setting of online budget learning, and presents both theoretical and algorithmic details of the proposed approaches for online budget learning. Section 3 discusses our empirical studies on six real world datasets. Section 4 concludes this work. We consider kernel-based online learning for classifica-tion. Our goal is to learn a function f : R d  X  R from a x t  X  R d , y t  X  Y = { X  1 , +1 } and [ T ] = { 1 , . . . , T } . We predict the class assignment for x by sgn( f ( x )), and measure the classification confidence by | f ( x ) | . Let  X  ( yf ( x )) : R  X  R be a convex loss function that is Lipschitz continuous with Lipschitz constant L . Let H be an RKHS endowed with a kernel func-tion  X  ( , ) : R d  X  R d  X  R . We assume  X  ( x , x )  X  1 for any x  X  R d . Similar to kernel-based online learn-ing ( Kivinen et al. , 2001 ; Zinkevich , 2003 ) and the Pe-gasos algorithm ( Shalev-Shwartz et al. , 2011 ), at each trial of online learning, given a received training ex-ample ( x t , y t ), we define the following loss function: We first describe an online learning algorithm, sim-ilar to kernel-based online learning ( Kivinen et al. , 2001 ; Zinkevich , 2003 ), that minimizes the regret of proach. At each trial t , given the classifier f t and training example ( x t , y t ), we update the classifier by where  X  is the stepsize and  X  &gt; 0 is the regularization parameter.
 Theorem 1. Let f t , t  X  [ T ] be a sequence of classifiers generated by the updating rule in ( 2 ). We have the following bound for any f  X  H , By setting  X T =  X   X  1 , we have which leads to O (1 / that we did not exploit the strong convexity of L t ( f ), which often leads to a better bound. This is because our goal is to bound addition, to exploit the strong convexity of L t ( f ), we have to vary the stepsize  X  over trials, making it diffi-cult to extend the analysis to online budget learning. We now modify the updating rule in ( 2 ) for online budget learning. The first modification is to introduce a domain to which the updated classifier will be pro-jected. Specifically, we define the domain  X  as:  X (  X  X  )= where  X  X  &gt; 0 specifies the maximum weight that can be assigned to any support vector. Using the domain  X (  X  X  ), we modify the updating rule in ( 2 ) as follows where  X   X (  X  X  ) ( f ) projects f into the domain  X (  X  X  ). Note that when  X   X  L , we have  X   X (  X  X  ) ( f ) = f be-cause the weights for support vectors never increase over trials and for any support vector, its initially as-signed weight is  X L .
 Let B &gt; 0 be a predefine budget. Our goal is to bound the number of support vector by B . When the number of the support vectors in f ( ) is less than B , we simply run the updating rule in ( 4 ) without any change. Without loss of generality, we consider a trial t where the number of support vectors in f t ( ) is B and we need to update f t ( ) with a new training example ( x t , y t ). Note that the gradient of L t ( f t egy is to approximate f t ( ) in  X  X  ( f ) with its un-biased estimator b f t ( ) so that the updated classifier f exactly B support vectors. More specifically, we ex-press the classifier f t ( ) as order to generate an unbiased estimator b f t ( ) for f t we randomly select one support vector according to a variable Z t i , with Z t i = 1 indicating that support vec-P sider the following general form for constructing the unbiased estimator b f t ( ) where a t i  X  0 and b t i are parameters that need to be determined. To ensure E[ b f t ( )] = f t ( ), we have the Using the unbiased estimator b f t ( ), we have the clas-sifier f t ( ) updated as In order to ensure that the number of support vectors in f t +1 ( ) is B , we need to have one of the coefficients in ( 7 ) set to zero, leading to the following condition Conditions ( 6 ) and ( 8 ) are the key for designing the support vector. Given p t , we have the following ex-a = As a result, the weight  X  t +1 i is updated as follows According to ( 10 ), the weight for the selected support vector (i.e., Z i t = 1) is set to zero in the updated clas-sifier f t +1 ( ), implying that the selected support vec-tor is discarded from the updated classifier. Finally, Algorithm 1 summarizes the proposed framework of Bounded Online Gradient Descent (BOGD) learning. Given the sampling probabilities p t , t  X  [ T ], we have the following theorem for Algorithm 1 .
 Theorem 2. Assume  X  ( x , x )  X  1 and  X  X   X  1 / 2 . Let f , t  X  [ T ] be the sequence of classifiers generated by Algorithm 1 . Then, for any f  X   X (  X  X  ) , we have in expectation the overall loss bounded as follows E " where V T = [ T ] /U T and U T = { t  X  [ T ] | | SV t | &lt; B or  X   X  ( y t f t ( x t )) = 0 } .
 Algorithm 1 A framework of Bounded Online Gra-dient Descent (BOGD)
Input : the maximum budget size B , stepsize  X  , reg-ularization parameter  X  &gt; 0, and maximum coeffi-cient  X  &gt; 0.

Initialize S 1 =  X  , f 1 = 0. for t = 1 , 2 , . . . , T do end for Proof. Using the standard analysis of gradient de-scent ( Kivinen et al. , 2001 ; Zinkevich , 2003 ), it is not difficult to show for any f  X   X (  X  X  ), We consider two scenarios: Case 1 : Consider the trial t  X  U T . Since no sampling is done in these trials, we thus have E t [ | b f t | 2 H Case 2 : Consider the trial t  X  V T , we have E [ | b f t | 2 H ] = k f t k 2 H  X   X  k f t k 2 H + [  X  X  ]  X  1  X  1 2 We complete the proof by substituting into ( 11 ) the above expression for k f k 2 H .
 Below, we discuss two different designs of sampling probabilities p t , i.e., (i) uniform sampling, and (ii) non-uniform sampling.
 Uniform Sampling. In this approach, we set p t i = 1 /B for any i  X  [ B ] and any t  X  [ T ]. According to The-orem 2, it is not difficult to have the following result for the loss bound.
 Theorem 3. For any classifier f  X   X (  X  X  ) , we have the following bound for Algorithm 1 using uniform sampling
E " + where A (  X  ) = (( C (  X  ) = Let  X  X T = 1 and  X  = 1 / f  X   X (  X  X  ) , that
E "  X  ( Remark. We have two comments for the above re-sults. First, by choosing different stepsize  X  , we make a tradeoff between A (  X  ) and C (  X  ). In particular, a small  X  will result in a small value for A (  X  ) but a large value for C (  X  ). This is because a small  X  reduces the size of hypothesis space  X (  X  X  ) and consequentially in-creases the overall loss large  X  will lead to large A (  X  ) but potentially small C (  X  ). Second, although ( 13 ) shows a regret bound of O (  X  analysis presented in ( Dekel et al. , 2005 ). This is be-cause we restrict the competitor f to the domain  X (  X  X  ) while the analysis in ( Dekel et al. , 2005 ) considers any hypothesis in RHKS H as a competitor. Observe that the projection  X   X (  X  X  ) ( f ) in ( 7 ) is no longer in effect if we set  X   X  L and  X  X   X  1 /B in our algorithm. As a result, under the conditions  X   X  L and  X  X   X  1 /B , for any classifier f  X  H , with appropriate choice of  X  and  X  , we have the following regret bound for the the sequence of classifier generated by Algorithm 1 using uniform sampling: As indicated by the regret bound in ( 14 ), if we con-sider any f  X  H as a competitor, unless we set B = T , we will not be able to obtain an O ( bound. Although this result may seem significantly worse than the one presented ( Dekel et al. , 2005 ), we emphasize that ( 14 ) is about regret bound while the re-sult in ( Dekel et al. , 2005 ) is about mistake bound. In general, deriving a good regret bound is usually more challenging than getting a similar mistake bound. Nonuniform Sampling. To fully exploit the in-formation we have about the classifier f ( ) = P i =1  X  i y i  X  ( x i , ), we consider a nonuniform sampling approach to BOGD by choosing the values of p as fol-lows: where s is the normalization factor. Given the expres-sion in ( 15 ), it is straightforward to derive p i as follows Before presenting the regret bound, we define function H ( f ) that measures the skewness of the coefficients for the support vectors used by f . More specifically, H ( f ) is defined as H ( f ) = B According to Cauchy-Schwarz inequality, we always have H ( f )  X  0 where the equality holds if and only if  X  1 = . . . , =  X  B .
 Theorem 4. Assume  X  ( x , x )  X  1 and  X  ( x , x  X  )  X  0 . Let f t , t  X  [ T ] be the sequence of classifiers generated by Algorithm 1 using the nonuniform sampling spec-ified in ( 16 ). Then, for any f  X   X (  X  X  ) , we have in expectation the loss experienced by { f t } T t =1 bounded as: where H t = H ( f t ) and V t is the set of trials where one of the support vector is discarded.
 Proof. The proof is almost identical to that of Theo-rem 2. The only difference is in bounding E t [ | b f t | 2 V , i.e., E [ | b f t | 2 H ]  X  k f t k 2 H +  X  k f t k 2 H + The rest of the proof follows almost the exactly same steps as that for Theorem 2.
 The above theorem clearly indicates that nonuniform sampling reduces the regret bound by taking advan-tage of the skewed distribution of coefficients assigned to support vectors. We note that although Theorem 4 does not give an explicit bound for the advantage of exploiting the skewed distribution of coefficients, it does show up significantly in our empirical study. In this section, we evaluate the empirical performance of the proposed algorithms for Bounded Online Gradi-ent Descent (BOGD) learning algorithms by compar-ing them to the state-of-the-art algorithms for online budget learning. 3.1. Experimental Testbed Table 1 shows the details of six binary-class datasets used in our experiments. All of these datasets can be downloaded from LIBSVM website 1 and UCI ma-chine learning repository 2 . These datasets were cho-sen fairly randomly to cover a variety of datasets of different sizes.
 3.2. Baseline Algorithms and Setup We refer to as  X  X OGD X  the proposed BOGD algo-rithm using uniform sampling, and as  X  X OGD++ X  the proposed BOGD algorithm using nonuniform sam-pling. We compare the two proposed BOGD algo-rithms with the following state-of-the-art algorithms for online budget learning: (i)  X  X BP X   X  the Ran-dom Budget Perceptron algorithm ( Cavallanti et al. , 2007 ), (ii)  X  X orgetron X   X  the Forgetron algo-rithm ( Dekel et al. , 2005 ), (iii)  X  X rojectron X   X  the Projectron algorithm ( Orabona et al. , 2008 ), and (iv)  X  X rojectron++ X   X  the aggressive version of Projec-tron algorithm ( Orabona et al. , 2008 ). We also com-pare the proposed algorithms to two non-budget on-line learning algorithms: (i)  X  X erceptron X   X  the clas-sical Perceptron algorithm ( Rosenblatt , 1958 ), and (ii)  X  X GD X   X  the Online Gradient Descent algo-rithm ( Kivinen et al. , 2001 ; Ying &amp; Pontil , 2008 ). To make a fair comparison, all the algorithms in our comparison adopt the same experimental setup. The loss function  X  is set as the hinge loss, i.e.,  X  ( yf ( x )) = max(0 , 1  X  yf ( x )). A Gaussian kernel is adopted in our study, for which the kernel width is set to 8 for all the algorithms and datasets. The regularization parameter  X  , stepsize  X  and parame-ter  X  in the proposed algorithm are selected using cross validation for all combinations of the datasets, algorithms and budgets(More specifically,  X  is chosen ent datasets are set as proper fractions of the sup-port vectors numbers of Perceptron, which are shown in Table 3 . All the experiments were conducted 20 times, each with a different random permutation of data points. All the results were reported by averaging over the 20 runs. For performance metrics, we evaluate the online classification performance by mistake rates and running time. Finally, all of the algorithms were implemented in C++, and all experiments were run in a linux machine with 2.5GHz CPU. 3.3. Evaluation of Non-budget Algorithms Table 2 summarizes the average performance of the two non-budget algorithms for kernel-based online learning. First, we find that OGD outperforms Per-ceptron significantly for all datasets according to t-test results, which implies that a budget OGD algorithm might be more effective than that based on the Per-ceptron algorithm. Second, the support vector size of OGD is in general much larger than that of Perceptron. Finally, the time cost of OGD is much higher than that of Perceptron, mostly due to the larger number of sup-port vectors. Both the large number of support vectors and high computational time motivate the need of de-veloping budget OGD algorithms. 3.4. Evaluation of Budget Algorithms Table 3 summarizes the results of different budget on-line learning algorithms. First, we observe that RBP and Forgetron achieve similar performance for almost all cases. In addition, we also find that Projectron++ achieves a lower mistake rate than Projectron for al-most all the datasets and for all budge sizes, which is similar to the results in ( Orabona et al. , 2008 ). Second, compared to the baseline algorithms for on-line budget learning, the proposed BOGD algorithm achieves comparable, sometimes better mistake rates, especially when the budget size is large, demonstrat-ing the effectiveness of our framework. Among all the compared algorithms for online budget learning, when the budget is large, we find that BOGD++ always achieves the lowest mistake rates for most the cases; when the budget is small, BOGD++ often achieves the best or close to the best results (except two datasets  X  X erman X  and  X  X pambase X ). These results indicate the importance of exploiting the skewed distribution of weights for support vectors. Moreover, it is interesting to find that on most datasets (e.g.,  X  X erman X ,  X  X 8a X ,  X  X jcnn1 X ,  X  X agic04 X  and  X  X odrna X ), BOGD++ can even achieve significantly lower mistake rates than Per-ceptron that does not a budget constraint.
 Finally, for the comparison of running time cost, the Projectron algorithms are the least efficient al-gorithms among all the budget online learning algo-rithms, mostly due to their costly projection step. For example, on the largest dataset  X  X odrna X  with the budget B=2000, Projectron++ on average took more than half an hour to run one experiment. For the pro-posed algorithms, the time costs of both BOGD and BOGD++ are in general comparable to those of RBP and Forgetron, and are significantly more efficient than those of Projectron algorithms. For example, on dataset  X  X odrna X  with the budget B=1000, BOGD++ is about 30 times faster than Projectron++, and is about 60 times faster than the original non-budget OGD algorithm. For the two proposed algorithms themselves, BOGD++ is slightly more time consuming than BOGD, due to the additional cost of computing the distribution p t towards non-uniform sampling. This paper presented a novel framework of bounded online gradient descent (BOGD) for scalable kernel-based online learning which requires the number of support vectors to be smaller than a predefined bud-get. The basic idea of maintaining the budget size is to remove one randomly selected support vector whenever the support vector size overflows. In par-ticular, we proposed two efficient BOGD algorithms: (i) BOGD by randomly discarding one support vec-tor using uniform sampling, and (ii) BOGD++ using non-uniform sampling. We conducted extensive empir-ical studies by comparing with several state-of-the-art algorithms, in which our results showed that the pro-posed algorithms achieve the promising performance in terms of both classification efficacy and computational efficiency. Future work will exploit different sampling strategies and extend our work to multi-class budget kernel-based online learning.
 This work was in part supported by MOE tier 1 grant (RG33/11), Microsoft Research grant (M4060936), National Science Foundation (IIS-0643494), and Of-fice of Navy Research (ONR Award N00014-09-1-0663 and N00014-12-1-0431).
 Cavallanti, Giovanni, Cesa-Bianchi, Nicol`o, and Gen-tile, Claudio. Tracking the best hyperplane with a simple budget perceptron. Machine Learning , 69(2-3):143 X 167, 2007.
 Cheng, Li, Vishwanathan, S. V. N., Schuurmans, Dale,
Wang, Shaojun, and Caelli, Terry. Implicit online learning with kernels. In NIPS , pp. 249 X 256, 2006. Crammer, Koby, Kandola, Jaz S., and Singer, Yoram. Online classification on a budget. In NIPS , 2003. Crammer, Koby, Dekel, Ofer, Keshet, Joseph, Shalev-
Shwartz, Shai, and Singer, Yoram. Online passive-aggressive algorithms. Journal of Machine Learning Research , 7:551 X 585, 2006.
 Dekel, Ofer, Shalev-Shwartz, Shai, and Singer, Yoram.
The forgetron: A kernel-based perceptron on a fixed budget. In NIPS , 2005.
 Duchi, John and Singer, Yoram. Efficient online and batch learning using forward backward splitting. JMLR , 10:2899 X 2934, December 2009.
 Jin, Rong, Hoi, Steven C. H., and Yang, Tianbao. On-line multiple kernel learning: Algorithms and mis-take bounds. In ALT , pp. 390 X 404, 2010.
 Kivinen, Jyrki, Smola, Alex J., and Williamson,
Robert C. Online learning with kernels. In NIPS , pp. 785 X 792, 2001.
 Langford, John, Li, Lihong, and Zhang, Tong. Sparse online learning via truncated gradient. Journal of Machine Learning Research , 10:777 X 801, 2009. Orabona, Francesco, Keshet, Joseph, and Caputo,
Barbara. The projectron: a bounded kernel-based perceptron. In ICML , pp. 720 X 727, 2008.
 Rosenblatt, Frank. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review , 65:386 X 407, 1958. Shalev-Shwartz, Shai, Singer, Yoram, Srebro, Nathan, and Cotter, Andrew. Pegasos: primal estimated sub-gradient solver for svm. Math. Program. , 127 (1):3 X 30, 2011.
 Weston, Jason and Bordes, Antoine. Online (and of-fline) on an even tighter budget. In AISTATS , pp. 413 X 420, 2005.
 Ying, Yiming and Pontil, Massimiliano. Online gra-dient descent learning algorithms. Found. Comput. Math. , 8:561 X 596, September 2008.
 Zhao, Peilin, Hoi, Steven C. H., and Jin, Rong. Dou-ble updating online learning. Journal of Machine Learning Research , 12:1587 X 1615, 2011.
 Zinkevich, Martin. Online convex programming and generalized infinitesimal gradient ascent. In ICML ,
