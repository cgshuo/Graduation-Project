 Novel applications such as recommender systems, uncertain databases, and multimedia databases are designed to pro-cess similarity queries that produce ranked lists of objects as their results. Similarity queries typically result in disk ac-cess latency and incur a substantial computational cost. In this paper, we propose an  X  X ctive caching X  technique for sim-ilarity queries that is capable of synthesizing query results from cached information even when the required result list is not explicitly stored in the cache. Our solution, the Cache Estimated Significance (CES) model, is based on shared-neighbor similarity measures, which assess the strength of the relationship between two objects as a function of the number of other objects in the common intersection of their neighborhoods. The proposed method is general in that it does not require that the features be drawn from a metric space, nor does it require that the partial orders induced by the similarity measure be monotonic. Experimental results on real data sets show a substantial cache hit rate when compared with traditional caching approaches.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  retrieval models, search process Performance
Caching made its first appearance in 1967 as a memory improvement in Model 85 of the IBM System/360 product line [20], and has seen many important applications since. A CPU cache helps expedite the access of data that would oth-erwise need to be fetched from main memory. A page cache, usually managed by the operating system kernel, helps to reduce the amount of fetching from disk. Database caching can substantially improve the throughput of database appli-cations. The caching of web content reduces network traffic, server load, and latency. More recently, semantic caching techniques have been developed to store the results of prior queries in order to reuse them fully or partially to answer related queries [4]. Semantic caching can improve the perfor-mance substantially when a series of semantically-associated queries are posed, provided that many of the queries have results that intersect (or are contained within) cached re-sults.

Caching strategies can be divided into two broad classes: traditional  X  X assive X  caching, and the more recent  X  X ctive X  caching. With passive caching, where the server query re-sult is retrieved either directly from the cache or from the disk, the effectiveness of the operation is guaranteed. Pas-sive cache management strategies generally seek to fill the cache with result lists for the most popular queries, and to utilize effective replacement strategies to maximize the overall performance. One example of a retrieval system for which passive caching may be effective is the Excite search engine  X  Markatos and Chronaki discovered a large number of frequently-posed queries in the retrieval logs that consti-tute excellent candidates for caching, with a hit rate of up to 25% [18]. In experiments involving Digital Equipment Cor-poration query traces, passive caching was able to reduce latency by 22% X 26% [13].

In general, only limited performance gains are possible with passive caching. Active caching techniques attempt to improve upon the performance of passive caching by syn-thesizing a query result from stored information whenever the sought-after result is not explicitly present. This form of caching is referred to as  X  X ctive X  since the cache can be con-sidered to function in a limited query-processing role [17].
The active caching techniques proposed in the research lit-erature to date are extensions of relational database caching strategies that aim to answer Boolean queries: the caching strategies attempt to make use of the stored results of past queries to generate a new result that satisfies the contain-ment criteria of the current query. For similarity queries re-turning a ranked list of the top-k relevant objects  X  as often arise in applications involving search engines, recommender systems, information retrieval and multimedia databases  X  this form of active caching cannot be applied. One reason is that for top-k similarity queries, rather than attempting to list all possible objects satisfying the containment criteria, search engines return only a relatively small proportion of relevant objects [24].

In this paper, we propose a more general active caching strategy for top-k similarity queries (also known as k -nearest-neighbor, or k -NN queries). The method is based on  X  X hared-neighbor X  similarity measures, which assess the similarity be-tween two objects in terms of the number of other objects in the common intersection of their neighborhoods. The inter-section size of neighborhood sets has been used as the basis of the merge criteria of several heuristics for data cluster-ing [5, 6, 8, 11], as well as the relevant-set correlation (RSC) clustering model of [9], which uses shared-neighbor informa-tion to directly assess the quality of cluster candidates, and to rank the members of clusters in order of relevance. Our active caching solution uses techniques developed for RSC to derive ranking functions for active caching that take into account potential variation in the sizes of cached neighbor lists, without any knowledge of the similarity values used in producing these lists.

The remainder of the paper is organized as follows. In the next section, we give an overview of existing active caching methods. In Section 3, we briefly describe the original RSC model for clustering as well as supporting terminology and notation. In Section 4, we list the most commonly-used measures of shared-neighbor information, and describe how secondary similarity measures can be derived using tech-niques developed under the RSC model. In Section 5, we show how these similarity measures can be efficiently im-plemented. Experiments on real data sets are presented in Section 6 that show how the proposed active caching formu-lations can be surprisingly effective in terms of both recall and hit rate, even for relatively small cache sizes. Finally, the discussion is concluded in Section 7.
One well-known example of an active caching strategy is semantic caching, which assumes that the queries submit-ted to information retrieval systems are Boolean, and that the partial results of previous queries can be reused in com-posing results for new queries, using Boolean algebra. When the user submits an intersection query, it is decomposed into two parts: a probe query that fetches the relevant portion of the answer set from the cache, and a remainder query that fetches the missing part of the result from the server [3]. For a containment query, on the other hand, a remainder query need never be generated. Semantic caching is particularly attractive for use in mobile computing platforms, due to the resource limitations associated with mobile clients [14, 21, 26]. It has also been used in web caching to handle conjunc-tive queries supporting the use of Boolean operators AND and NOT between query terms [3]. However, the operator OR could not be supported, due to the exponential com-plexity of the semantic containment and intersection prob-lem for full Boolean expressions. In [17], Luo, Naughton and Xue proposed an effective semantic caching scheme for Web search engines, and concluded that while answering cache-contained queries results in a significant performance gain, answering cache-intersecting queries is not worthwhile for top-k conjunctive term-based queries. The main limitation of semantic caching is that it can be applied only to Boolean queries, with the containment property being used to deter-mine which queries can be answered from the cache. For these reasons, semantic caching techniques are not applica-ble for similarity queries.

Several studies have focused on search engine models where the cache acts in a query processing role. Saraiva et al. [23] proposed the storage of inverted lists of query terms (key-words) to assist in the active caching query-handling process. The cache mechanism uses a two-level scheme that combines cached query results and cached inverted lists. The results of repeated identical queries are cached at the front end, whereas data for frequently-used query terms are cached at a lower level. The inverted lists for each term are accessed, and used to generate lists of result documents containing all terms. In [16] a three-level cache was proposed wherein an intermediate level is added to the design. The interme-diate level exploits frequently occurring pairs of terms by caching intersections or projections of the corresponding in-verted lists. Although these combined caching strategies can increase the throughput of the system, they are only able to handle keyword-based queries. In general, k -NN queries cannot be accommodated, as all attributes are generally re-quired for the computation of similarity values.
Before presenting the details of our proposed active caching strategy, we will introduce some of the required terminology, notation, and concepts.
Let S be a data set drawn from some domain D . For every object v  X  S , we assume the existence of a unique ordering ( v v is more relevant (or similar) to v than v j . With respect to v , the rank of object w ranges from 1 to | S | , and will be denoted by rank ( v, w ). In practical settings, the object most relevant to v is generally v itself. Nevertheless, unless otherwise stated, we will not require that rank ( v, v ) = 1.
The relevance ranking for v induces a collection of dis-tinct sets Q ( v,  X  ) = { v 1 , . . . , v } for each choice of set size 1  X   X   X | S | . With respect to the ranking, if a data set similarity query were to be based at object v , Q ( v, k ) would represent the top-k relevant set. Q ( v, k ) can also represent the result of a k -nearest neighbor ( k -NN) query for v with respect to some unknown distance measure dist : D  X  D  X  R  X  0 . However, we will make no explicit use of the actual val-ues of any distance function or other scoring function used to determine relevance rankings under the model.

Taken together over all v  X  S , the rankings also induce a collection of inverted relevant sets Q  X  1 ( u,  X  ) = { v Q ( v,  X  ) } for every choice of u  X  S and 1  X   X   X | S | . It should be noted that whereas j  X  =  X  implies that Q ( v, j ) and are distinct, it is possible that Q  X  1 ( u, j ) = Q  X  1 ( u,  X  ) for some choices of u  X  S and j  X  =  X  .
 Consider now the situation in which a main-memory cache C ( C,  X  )  X  = { Q ( v,  X  ) : v  X  C } of relevant sets of size  X  is available for each object in a given subset C  X  S , for some fixed  X   X  [1 , | S | ]. If each of the relevant sets is maintained as a list of objects sorted from most relevant to least relevant, the collection of relevant sets C ( C, j ) is also readily available for all 1  X  j  X   X  . We will accordingly refer to C ( C, j ) as a subcache of C ( C,  X  ).

For a given u  X  S , inverted relevant sets for u can also be defined with respect to the cache C ( C,  X  ), by restricting the membership of the lists to objects of C instead of S : The collection of all such inverted lists taken over all choices of u  X  S will be referred to as the inverted cache corre-sponding to C ( C,  X  ), and will be denoted by C  X  1 ( C,  X  ) {
Q  X  1 C ( v,  X  ) : v  X  C } . We will use the terms standard cache and standard relevant sets (or more simply, standard lists ) to refer to the original cache C ( C,  X  ) and its lists, and the term cache loosely to refer to the set C taken together with its standard and inverted relevant sets.
Set correlation can be regarded as a special case of the well-known Pearson correlation of variable pairs. Every ob-ject of some universal set  X  can be associated with a co-ordinate of a vector space whose dimension is equal to the size of S . A subset A of  X  can be represented by a zero-one characteristic vector in this space, where a coordinate value of 1 indicates that the corresponding object is a member of A , and a value of 0 indicates that the object does not belong to A . Even if no additional information is available regarding the nature of A and B , the relationship between A and B (and their underlying concepts) can be quantified in terms of the correlation between corresponding coordinates of their characteristic vectors.

For sequences of variables ( x 1 , . . . , x |  X  | ) and ( y with means  X  x and  X  y , respectively, the standard Pearson sam-ple correlation is given by the following formula [19]: Applying the formula to the characteristic vectors of sets A, B  X   X , and noting that whenever x i  X  X  0 , 1 } , we obtain the following set correlation formula [9]: where is the popular cosine similarity measure between A and B [19]. Note that when the sizes of A and B are fixed, the set correlation value tends to the cosine measure value as the universal set size |  X  | increases.
 Although the set correlation resembles to some extent the Spearman rank correlation and Kendall tau rank correla-tion coefficients appearing in the statistical literature [12], the latter two are fundamentally unsuited for application to relevant sets. Given two ranked lists of items drawn from a common domain, Spearman rank correlation assigns to each item an ordered pair of values equal to the rank of the item with respect to each ranked list. The Spearman rank cor-relation value is simply the Pearson correlation applied to the collection of variable pairs. Compared to the set correla-tion, however, the Spearman rank correlation ascribes great importance to the magnitude of the difference between the ranks of a given item with respect to each list. The Kendall tau coefficient, on the other hand, is formulated in terms of the sign of the difference between the ranks of the item with respect to the two lists. For situations such as caching in which the available ranked lists span only a local neigh-borhood (the relevant set) and not the entire database, it is often the case that an individual item appears in one list and not the other, precluding the exact calculation of both Spearman and Kendall tau coefficients.
With traditional caching strategies, in processing a top-k query object v for which results have not already been cached, the information is retrieved directly from disk. How-ever, if the query result for v can be reliably estimated us-ing only cached information and without performing expen-sive disk access operations, the computational savings may be considerable. In this section, we propose the Cache-Estimated Signi cance (CES) model for the estimation of top-k query results using cached information, where param-eters such as k , the cached neighbor list size  X  , and the cache size are all allowed to vary. The model includes shared-neighbor similarity measures that, given any object w  X  S , assesses the statistical significance of the relationship be-tween v and w using only the information available in the cache. Using one of these measures, an approximation to the top-k query result for v can be generated by determining the k objects of S most closely related to v .
Before presenting the details of the CES model and as-sociated similarity measures, we give a spatially-motivated argument concerning the potential of shared neighbor in-formation for indicating similarity relationships among data objects, even when the underlying distance values are un-known.
 Consider the situation in which the objects of a data set S are embedded in a metric space with distance function dist , from which the relevance ranking function Q is derived. Let x be any point in the space (not necessarily coincident with an object of S ). With respect to any object v  X  S , we can define rank ( v, x ) to be the rank that a new object would be assigned if it were inserted into S at location x , with any tied distances broken in favor of x . Point x would also determine a standard relevant set Q ( x,  X  ) and inverted relevant set Q  X  1 ( x,  X  ), with respect to S using dist .
If x were allowed to migrate towards the location of v , the memberships of Q ( x,  X  ) and Q  X  1 ( x,  X  ) would tend progres-sively toward those of Q ( v,  X  ) and Q  X  1 ( v,  X  ), respectively, until they coincided at x = v . The relationships between Q ( x,  X  ) and Q ( v,  X  ) on the one hand, and Q  X  1 ( x,  X  ) and Q  X  1 ( v,  X  ) on the other, can serve as the foundation of a rank measure of the similarity between x and v . Each ob-ject of Q ( x,  X  )  X  Q ( v,  X  ) would support the contention that x and v were similar, and each object of Q ( x,  X  ) \ Q ( v,  X  ) or
Q ( v,  X  ) \ Q ( x,  X  ) would work against it. The same would be true for inverted sets, with each of Q  X  1 ( x,  X  )  X  Q testifying as to the similarity of x and v , and each object of Q
For the cache entry estimation problem, let us assume that we wish to estimate the top-k relevant set Q ( v, k ) for some object v /  X  C . Even though only rank information is available and any spatial embedding and distance informa-tion is unknown, the spatial intuition described above can still be expected to apply in many (if not most) practical settings. The cached object set C would constitute a set of potential witnesses to the relationship between two ob-jects v and w in S . However, as the cache generally contains only a small fraction of the total possible standard relevant sets, any rank measure of similarity must rely primarily on the inverted relevant sets. The set of witnesses Q  X  1 C ( v,  X  ) would be non-empty provided that v appeared in at least one cached standard relevant set.

Just as different formulations of shared-neighbor criteria have been proposed for clustering applications, it is possible to devise many shared-neighbor similarity measures for our estimation problem. Given an inverted cache C  X  1 ( C,  X  ) and on the following three cache-estimated rank measures: The cosine measure is included here as a simplified alterna-tive to the set correlation measure  X  in practical settings, the value of  X  and the sizes of the witness sets Q  X  1 C ( v,  X  ) and Q
C ( w,  X  ) are very much smaller than S and C , and the dif-ference between SimCos C; and SimCorr C; is negligible.
For all three measures, a value of 1 indicates that all oc-currences of v in the cached top-k query result lists coincide with occurrences of w (and vice versa), and thus that the cache strongly supports the association of v and w . On the other hand, values approaching 0 indicate little support for the association of v and w . The set correlation and cosine measures are not well-defined whenever Q  X  1 C ( v,  X  ) = Q
C ( w,  X  ) = are taken to be 0. For the set correlation measure, note that Q
C ( v,  X  ) and Q characteristic vector descriptions take C to be the universal set, and not S .
The rank-based similarity measures SimInt C; , SimCos C; and SimCorr C; stated above may have different biases with respect to the cache size | C | , the relevant set size  X  , and the sizes of the inverted relevant sets involved. The in-tersection size measure SimInt C; potentially favors those objects w having the largest witness sets Q  X  1 C ( w,  X  ), as no penalty is applied when members of this set do not appear in Q
C ( v,  X  ). The other two rank-based measures compensate for this deficiency by normalizing the contributions with re-spect to the sizes of the witness sets. However, these two measures also admit the possibility of bias. In general, when making inferences involving Pearson correlation, a high cor-relation value alone is not considered sufficient to judge the significance of the relationship between two variables. When the number of variable pairs is small, it is much easier to achieve a high value by chance than when the number of pairs is large.

The RSC model for clustering was proposed as a way of correcting for the bias in shared-neighbor density measures of cluster quality [9]. The statistical significance of formulas involving set correlation values was tested against a  X  X ypoth-esis of randomness X   X  the assumption that each relevant set contributing to the density measure is independently gener-ated via uniform random selection from among the avail-able objects of S . In practice, of course, the relevant sets are far from random. However, the hypothesis serves as an appropriate reference point from which the significance of observed values of the measure can be assessed. Under the randomness hypothesis, the mean and standard deviation of the measure can be calculated, and standard scores (also known as Z -scores) [19] can then be generated and compared with one another. The more significant grouping would be the one whose standard score is highest  X  that is, the one whose correlation exceeds its expected value by the greatest number of standard deviations.

For the proposed cache entry estimation model of this paper, we will use the hypothesis of randomness to account for potential bias of SimInt C; and SimCorr C; due to the choice of standard cache list size  X  , and the variations in the size of the inverted relevant sets that accompany the choice of  X  . Here, we will test against the hypothesis that the relevant sets have been generated by random selection of objects, with each object selected independently with fixed probability.

Lemma 1. Let A be a set generated through independent random selection from the objects of set  X  , with each object present in A with probability 0 &lt; p &lt; 1 . Let B be a second set generated independently from  X  in the same manner as A . Then Proof. Omitted in this version due to space limitations.
Let SimInt C; ( v, w ) be a random variable representing the value of SimInt C; ( v, w ) that would be achieved if all cached standard relevant sets were independently generated via the uniform random selection of  X  objects from the data set S . Similarly, let SimCorr C; ( v, w ) be a random variable representing the value of SimCorr C; ( v, w ) that would be achieved under the same conditions. The probability p of an individual object u  X  C appearing in Q  X  1 C ( v,  X  ) would equal that of v appearing in Q ( u,  X  ), which is p = | S | . Lemma 1 can then be applied with  X  = C , A = Q  X  1 C ( v,  X  ), B = Q
C ( w,  X  ), and p = | S | to show that
Given a set of cache objects C , the cache-estimated corre-lation signi cance of w relative to query v is defined as the standard score for SimCorr C; ( v, w ) under the randomness hypothesis: where A = Q  X  1 C ( v,  X  ) and B = Q  X  1 C ( w,  X  ), and | SimInt C; ( v, w ). This indicates that as long as the cache size | C | is kept constant, the correlation significance of w relative to v is equivalent to the correlation itself for the purposes of ranking.

The cache-estimated intersection signi cance of w relative to query v is defined as the standard score for SimInt C; under the randomness hypothesis:
The use of standard scores as a measure of statistical significance can facilitate comparison across differing distri-butions. The cache-estimated significance measures, being standard scores, can thus be used to account for significance across such parameter choices as the data set size | S | , the number of cache entries | C | , the cached list size  X  , the query result size k , and the sizes of inverted sets. At query time, the parameters S and C can be considered to be fixed quan-tities, and the sizes of inverted sets vary according to the distribution of objects in the vicinity of the query object.
Under certain conditions, some of the secondary similar-ity measures proposed in this section turn out to be equiva-lent. Cache and data set sizes can greatly exceed the max-imum sizes of the standard and inverted relevant sets; in these situations, the value of the set correlation measure SimCorr C; tends to that of the cosine measure SimCos C; . When the cache size is considered to be fixed, ZCorr C; and SimCorr C; determine the same rankings of data set ob-jects, and can be used interchangeably. The latter measure is in fact more convenient to use as its values are restricted to the range [  X  1 , 1]. If the relevant set size  X  is also taken to be fixed, the measure ZInt C; determines the same ranking of data objects as SimInt C; . Similarly, the rankings due to ZInt C; ( v, w ) would be the same as those determined by the ratio between the inverted set intersection size and the average individual inverted set size: However, in general, neither of these equivalances hold if  X  is allowed to vary. It should be noted that unlike SimInt SimCos C; and SimCorr C; , the measure SimRatio C; may attain values exceeding 1.

If the values of SimInt C;j ( v, w ) are readily available for all 1  X  j  X   X  , each object w can be scored with respect to query v according to the query size j for which it is most significant. Treating both the data set size | S | and cache size |
C | as constants, for the experimental evaluation to follow we shall consider the following six ranking functions for the objects of S with respect to query object v : Figure 1: Cache data structures for a set of 20 ob-jects in the 2-D plane. Top-8 lists are cached for 5 objects, with the Euclidean distance as the underly-ing ranking function.
When standard cache C ( C,  X  ), its inverted cache C  X  1 ( C,  X  ), and their subcaches are all available in main memory, the in-tersection sizes SimInt C;j ( v, w ) can be efficiently calculated for all 1  X  j  X   X  . A practical assumption that lowers the computational cost is that w need only be evaluated if the in-tersection size SimInt C;j ( v, w ) is positive  X  otherwise, there query result are indicated by an asterisk. is no information supporting the contention that w should be included in the estimated query result for v . Moreover, even if the intersection size is positive, a negative value of the correlation measure MaxCorr (or SimCorr ) would in-dicate that the intersection between the inverted neighbor-hoods is less than what would be expected if the members of the original standard neighborhoods had been selected at random. Therefore, for any ranking function f chosen from among the six listed in the previous section, we assume that a threshold value  X  &gt; 0 has been supplied, and that only those w  X  S for which f ( v, w )  X   X  are eligible to appear in the estimated query result for v . If it turns out that fewer than the requested k objects are eligible, then the estima-tion is deemed to have failed, possibly necessitating an exact computation of the query result from information residing on disk. An example is provided in Figure 2.

The efficiency of the ranking process also depends on the storage of additional information with the witness sets: 1. For all v  X  C , with each object u  X  Q  X  1 C ( v,  X  ), the 2. The objects of Q  X  1 C ( v,  X  ) are listed in non-decreasing With these preparations, the objects of set Q  X  1 C ( v, j ) are simply those objects u  X  Q  X  1 C ( v,  X  ) with stored rank value rank ( u, v )  X  j , which can be read off from the head of the list in time proportional to the size of Q  X  1 C ( v, j ).
The proposed method for the cache-estimated ranking of all objects of S with respect to a query object v is sum-marized in Figure 12. In the pseudocode description, all objects are represented by IDs in the range [0 , . . . , | any object u  X  C , we denote by q ( u, j ) the ID of the object of rank j in the ranked list Q ( u,  X  ). Also, we denote by q 1 ( v, j ) = { u  X  C | v  X  Q ( u,  X  )  X  rank ( u, v ) = j IDs of objects of Q  X  1 C ( v,  X  ) having rank j . Note that the ob-jects IDs of Q  X  1 C ( v,  X  ) are assumed to be sorted in terms of these ranks (as illustrated in Figure 1), and thus the objects of q  X  1 ( v, j + 1) appear immediately after those of q  X  in Q  X  1 C ( v,  X  ).

In order to compute meaningful query result estimates, the cache size should be chosen so as to ensure that the in-verted relevant sets are sufficiently large. This implies that |
C | and  X  should be chosen so that the average inverted list size  X | C | | S |  X  the number of witnesses of the relationship be-tween the query and its estimated result objects  X  exceeds some supplied threshold  X  &gt; 0. Since  X   X | C | X   X   X | S | main memory must be sufficently large to be able to ac-commodate at least a constant amount of storage for every object in the data set.
 Computing the sizes of the intersections of witness sets SimInt C;j ( v, w ) for every possible w  X  S , if performed in the most straightforward manner, would be too costly an operation even with all necessary information resident in main memory. The computational cost is reduced by first observing that for the majority of points w  X  S , the inter-section between Q  X  1 C ( v, j ) and Q  X  1 C ( w, j ) is empty. As it is reasonable to assume that only positive values of SimInt C;j are meaningful, we limit the ranking effort to those w for those of the set N ( v, j )  X  = be constructed in time proportional to O ( j  X | Q  X  1 C ( v, j ) which is approximately  X  O ( j 2 ). However, the computation time is further reduced by computing the intersection sizes SimInt C;j ( v, w ) incrementally during the visitation of the members of N ( v, j ), by noting that |
Q  X  1 C ( v, j )  X  Q  X  1 C ( w, j ) | = |{ u  X  Q  X  1 C ( v, j ) : w The overall cost of ranking all objects is thus reduced to O ( j  X | Q  X  1 C ( v, j ) | + | N ( v, j ) | ), or approximately
The value SimInt C;j +1 ( v, w ) is calculated as the sum of | [
Q  X  1 C ( v, j + 1) \ Q  X  1 C ( v, j ) [
Q
C ( w, j + 1) first two expressions need be explicitly computed in the tran-sition from j to j + 1. The total time, therefore, for com-puting SimInt C;j ( v, w ) for all 1  X  j  X   X  is simply that of computing SimInt C; ( v, w ), which as mentioned earlier is O (  X   X | Q  X  1 C ( v,  X  ) | + | N ( v,  X  ) | ), or approximately
As already discussed in Section 2, existing active caching methods developed for Boolean queries cannot in general be applied to handle similarity queries, and thus a direct comparison between these methods and our proposed tech-niques is not possible. For this reason, to evaluate the ac-tive caching strategies for top-k similarity queries proposed in Section 4, we instead compare their performance against those of passive caching strategies in terms of two measures, the hit rate and the recall . Traditionally, given a schedule of queries, the hit rate of an active caching method is defined to be the proportion of queries for which the sought-after information resides in the cache. Here, we extend the def-inition to include those cases where a query result can be estimated using our active caching methods  X  for all of the proposed methods, an estimate can be returned whenever a non-empty cache inverted list is associated with the query item. A miss occurs when a query item is associated with neither a standard list nor an inverted list in the cache.
Consider now the item set retrieved by any given top-k query operating on the cache. The recall of the query is defined as the proportion of this result that would also appear in a top-k query applied to the full database. When the cache query and the database query have equal size k , this definition is equivalent to that of query precision. Note that when the top-k list is explicitly stored in the cache, the recall trivially equals 1, and when a cache miss occurs, the recall is 0. We will also be interested in assessing the overall estimation power of the proposed active caching methods. To do this, we report the recall that would be achieved for the query result estimated by the active caching method, without checking whether the true query result is explicitly stored in the cache. To distinguish the two interpretations of recall, we shall refer to this latter interpretation as the estimation recall , and the former (usual) interpretation as the cache recall .
 Four data sets were used in our experimentation: the ALOI data set (ALOI) [7] consisting of 110,250 images rep-resented as 641-dimensional feature vectors [2]; the Reuters Corpus Volume 1 (RCV1) news article data set [15] repre-sented as 802,352 document vectors; the Cover Type (CT) [1] set taken from the UCI Machine Learning Repository, con-taining 581,012 observations of forest cover type from U.S. governmental cartographic surveys; and a sample of 120836 instances from the KDD Cup 1999 (KDD) data set [1], each corresponding to a simulated intrusion event in a military network environment. For each set, 100-NN lists were com-puted using the SASH approximate similarity search struc-ture [10]. Euclidean distances were computed for each set except RCV1, for which vector angle distances were used.
For both the ALOI and RCV1 data sets, we conducted several k -nearest-neighbor retrieval experiments, over a va-riety of cache and list sizes, and of choices of k . For each experiment, subsets of the data objects were selected uni-formly at random for inclusion in the standard cache, at different proportions of the total data set size. The cached information consisted of the standard neighbor list for each cache item, and their associated inverted lists. After setting up the cache, each of the objects of the full data set was used as the basis of a k -nearest-neighbor query. In all the exper-iments that follow, experimental results are shown only for the SimCorr , MaxCorr , SimRatio and MaxRatio methods, as the values SimCos and MaxCos were virtually identical to those of SimCorr and MaxCorr for even the smallest of the cache sizes considered.
For the ALOI and RCV1 data sets, Figure 3 shows the Figure 3: Hit rate for active caching for ALOI (left) and RCV1 (right), plotted against the proportion of objects cached. hit rate achieved by the active caching strategy for differ-ent choices of the standard list size  X  . The proportion of items cached for this experiment varied between 2.5% and 100%. In all cases, the hit rates were much higher with ac-tive caching than for passive caching, increasing very quickly with increasing list size. When the space required by the in-verted lists is taken into account, the hit rates for all four data sets studied still greatly exceed those of traditional caching, as can be seen in Figure 4.

The CES solution can require more space than the tradi-tional caching approach due to the storage of inverted lists alongside standard result lists. For example, in a straightfor-ward implementation in which integer variables are stored using 4 bytes, each result item would be associated with up to 12 bytes of storage: an integer object ID in the stan-dard list, and an integer object ID plus (for MaxCorr and MaxRatio ) an integer rank in the corresponding inverted list entry. If traditional caching is performed with only ob-ject IDs being stored, only 4 bytes would be required for each result list entry, and thus active caching would require approximately 3 times as much storage as the traditional implementation. Nevertheless, it can be seen from Figure 4 that for cache sizes of approximately less than one-third of the data, our active caching solutions can answer substan-tially more queries than traditional caching even taking its potentially-increased memory requirements into account.
Figure 5 shows the cache recall values obtained over ac-tive caching hits for top-30 queries with standard list length  X  = 30. For all four data sets, the CES solutions achieved very high recall values across the range of cache sizes. To-gether with Figures 3 and 4, these results show that for sufficiently-large cache sizes, very effective recall rates can be achieved while only rarely needing to access information on disk. For example, for the ALOI set with 25% of the data items cached, the proposed active caching variants an-swered approximately 98% of the queries, with an average recall of 0.8 and above. Even for the smallest cache size studied, 50% of the queries were answered with recall rates above 0.65, whereas the traditional caching approach would answer only 2.5% of the queries (albeit with recall 1.0).
Next, a similar experiment was performed on the ALOI data set for one representative measure, SimRatio , this time varying the size of the query result k together with the cached standard list size  X  . Top-k queries were performed with k =  X  = 10, 30, 50 and 100. The results, shown in Figure 6, did not vary significantly for different settings of  X  ; however, the same general dependence on the cache size was observed as in the previous experiment.

For the remainder of the experiments in this section, we concentrate on the estimation power of our active caching 12  X  = 120 bytes ( MaxCorr and MaxRatio ). Figure 6: Average ALOI cache recall for top-k active caching hits using the SimRatio measure, with list sizes  X  = k , plotted against the proportion of objects cached. Figure 7: Average estimation recall values for active cache hits as a function of query inverted list size, for the ALOI data set with k =  X  = 30 and 25% of objects present in the cache. The higher list size values are omitted due to the small number of instances. The histogram shows the numbers of query items with inverted lists of a given size. methods, by forcing an active estimation in which the stan-dard list stored for the item at which the query is based is always ignored.

We conducted an experiment to show the relationship be-tween observed average estimation recall rates and the sizes of the witness lists associated with query items. In Figure 7 the average recall values for the ALOI data set are plot-ted as a function of query witness list size, together with a histogram showing the numbers of query items involved. Top-30 queries were performed based at all 110,250 ALOI images. 25% of the ALOI images were selected at random for inclusion in the cache, each having a standard list of size  X  = 30. The experimental results show consistently-high average estimation recall rates over all but the smallest witness list sizes, with MaxRatio and SimRatio performing slightly better than MaxCorr and SimCorr over most of the range. They suggest that better performances are achieved for larger query witness list sizes.

We next considered the effect on estimation recall when Figure 8: Average estimation recall rates of top-30 active cache hits for the ALOI data set, in which all items in the result list satisfy minimum thresholds on similarity measure values. minimum thresholds are applied to SimRatio , MaxRatio , SimCorr and MaxCorr scores. Again, top-30 queries were performed for the ALOI data set, with 25% of the images cached and  X  = 30. In this experiment, active caching was used to generate a result only when each item in the esti-mated top-k result list achieved a score higher than a spec-ified minimum threshold value. Figure 8 shows plots of the average recall for the four active caching methods, against a range of score threshold values. The results show a posi-tive influence between the minimum scores obtained and the recall rates achieved.

For each of the k -nearest-neighbor query experiments pre-sented above, the standard list size  X  was set equal to k . In order to provide insights into the effect of  X  and k on the performance of the proposed active caching methods, a further experiment was conducted in which  X  was varied while fixing k . Once again, a cache size of 25% was cho-sen from the ALOI data set, and k chosen to be 30. The results of the experiment are displayed in Figure 9. All of the caching methods performed best for the case  X  = k = 30. For smaller values of  X  , the performance degenerated markedly. For larger values, the recall rates remained high, although the SimRatio and SimCorr performances showed substantially more degradation than those of MaxRatio and MaxCorr . Although SimRatio performed marginally better than MaxRatio for the case  X  = k = 30, the latter method achieved the best overall performance when larger list sizes were used.
We tested our proposed solution for robustness by intro-ducing noise entries into the cached standard lists. In each test, ALOI cache lists were replaced by  X  X oise lists X  of the Figure 9: The effect of varying cache list size  X  on the average estimation recall rates of top-30 similarity query cache hits, for the ALOI data set with 25% of the objects cached. Figure 10: Average estimation recall rates for ALOI active cache hits, with 25% of the objects cached and with k =  X  = 30 , plotted against the proportion of noise lists. same length, generated by selecting objects from the full data set uniformly at random. The proportion of cache lists replaced by noise lists was varied between 0% and 100%. The experimental results in Figure 10 show a very strong linear relationship between the performance and the pro-portion of noise. The results indicate that relatively large amounts of noise can be tolerated while still providing very high recall rates.

It is possible that for some caching applications, the stored result lists may not all be of the same length, as has been assumed so far in our experimentation. Accordingly, we con-ducted an experiment on the ALOI data set in which top-30 query result estimation was performed, with a varying pro-portion of the standard cache list lengths selected uniformly at random between 1 and 100, and the remainder of the lists having lengths fixed at 30. The cache size was chosen to be 25%. The results of the experiment are shown in Figure 11. Although some degradation of performance was observed for the SimCorr and SimRatio measures, the estimation re-call rates of MaxCorr and MaxRatio were remarkably stable across the full range of proportions. The results confirm the ability of the CES model to correct for bias with respect to the sizes of standard lists, in particular for those variants in which the significance is maximized over a range of subcache sizes.

A final experiment was conducted to determine the in-fluence of the choice of k on the recall rate of top-k active cache queries, when the lengths of the cache standard lists is variable. In this test, the list lengths were selected uni-formly at random in the range 1 to 100. The cache size was again chosen to be 25%. Figure 11 shows a peak in perfor-mance for all methods for k between 30 and 40. When the standard list lengths differ greatly from k , the performance degrades due to the presence of irrelevant items in cached lists (when  X  &gt; k ) or the absence of relevant items (when  X  &lt; k ). For this experiment, with list lengths ranging be-tween 1 and 100, choices of k in the range 30 to 40 achieved the best tradeoff between these two sources of error. Figure 11: Average estimation recall rates of active cache hits for the ALOI data set, with 25% of the objects cached. The left plot shows the recall for top-30 queries against various proportions of stan-dard lists with length  X  ranging between 1 and 100, with the remainder of the lists having length 30. The right plot shows recall for different values of k with all standard lists having lengths randomly selected between 1 and 100. The paper proposed a general model, the Cache-Estimated Significance (CES), for the estimation of the results of top-k similarity queries using shared-neighbor similarity measures on cached information. The model does not assume any knowledge of the methods or similarity measures used, and as such can be applied even when non-metric and probabilis-tic approaches are used to produce query results.

The main contribution of the CES approach is to facilitate the design of shared-neighbor ranking formulae for active caching that allow for variation of (and comparison across) such parameters as the size of the cache, the length of ranked lists stored in the cache, and the number of items requested by the query. The experimental results of the previous section indicate that the performance of the CES-derived MaxRatio and MaxCorr ranking functions is significantly more stable than their counterparts SimRatio and SimCorr when cached list sizes were allowed to vary.

The very strong overall performance of the shared-neighbor ranking formulae for active caching provides an intriguing answer to the question of cache management for databases. Whereas the conventional approach is to fill the cache with those items most likely to be requested in future queries, our experimental results show that shared-neighbor active caching can instead support a form of data interpolation , in which the cache is selected so as to provide uniform cover-age of the data set from which most if not all query results are actively generated. For some applications, it may even suffice to answer all similarity queries actively, without ever referring to the original data. CES active caching could thus serve as a scalability technique, as it provides the basis of space-and time-efficient approximation of large databases.
