 SIGKDD Explorations . Volume 4, Issue 2  X  page 95 In this paper, we describe ou r app roach for add ressing Task 1 in the KDD CUP 2002 competiti on . The a pp roach is based on develop ing and u sing an improved automatic feature selection method in con jun ction with tradition al classifiers. The feature selection method u sed is based on capturing frequ ently occurring keyword combination s (or motifs) within sho rt segments of the text of a do cument and h as proved to p rodu ce more acc urate classification results than app roaches relyin g solely on u sing keyword -based features.
 Document Categorization , Feature Selection , SVM. The task add ressed in this paper is that of develop ing a system to automatically curate a database of scientific papers by analyzing a trainin g data set of past hu man curation d ecision s. Sub -tasks 1 and 2 o f this task (providing a ranking of the relevance of the papers and d eciding whether a paper shou ld b e c urated o r no t) can be hand led d irectly using a do cument categorization framework. With a littl e preprocessing, sub -task 3 (identifying whether a particular item m ention ed in a paper is related to a given con cept) can b e ea sily con verted into a ca tegorization qu estion . In this section we briefly describe the background to do cument categorizati on and ho w it fits to all t hree sub -tasks.
 Given a set of N training do cuments, a generic a pp roach to do cument categorization first con structs a feature vector table such as that sho wn in Figure 1 where eac h do cument i s represented b y a score in relation t o eac h o f the K features. The algorithm to generate a c lassification mod el. To classify an un seen paper, a feature vector is con structed u sing the same set of K features and then p assed as inpu t t o the c lassification mod el. Clearly, the succe ss of any do cument categorization method is closely tied to the selection o f the features to represent t he do cuments in qu estion , we a dd ress this issue in Section 2 . This generic do cument categorization app roach can b e directly app lied to sub -task 2 that simply requ ires classifying a do cume nt as belon ging to either class  X  X  X  or class  X  X  X . Furthermore, by choo sing a c lassifier that attaches a c on fidence value on the prediction (e.g. SVM light [1]), this generic a pp roach can b e directly used to p rovide a ranking of the relevance of all do cumen ts, and h ence provide a n answer to sub -task 1.
 The same do cument categorization app roach can also b e ea sily mod ified to add ress s ub -task 3. This s ub -task requ ires deciding whether for a particular gene mention ed in a paper there is evidence of any of two g iven types of gene produ cts (transcripts, and /or po lypeptides) also b eing mention ed in the same paper. If a do cument has n gene names, we ca n create n virtual do cuments (by dup licating the do cument n times in the feature vector table), and thu s eac h virtu al do cument relates to a single gene/do cument pair. We then treat the sub -task as two categorization p rob lems; the first is to p redict transcript association and the second is to predict po lypeptide a ssociation .
 The virtual do cument app roach will on ly work if the feature vectors for two virtual do cuments generated from the same ph ysical do cument are sufficiently distinct. Our final app roach to choo sing the feature vectors neatly hand les this issue. We started ou r investigation s in to all sub -tasks by generating feature vectors based on keywords and an SVM classifier. Two qu estion s arose in this case ho w shou ld the keywords be selected and ho w shou ld they be weighed in feature vector table. Our first attempt was to experiment with a simple tradition al automatic information retrieval app roach. All words app earing in the do cument set were passed throu gh a stop -word filter to eliminate c omm on words, and then throu gh a stemm ing algorithm to redu ce variants of the same word to a ca non ical form. The un iqu e terms remaining in the final ou tpu t li st were then u sed as the feature list. Our second and third attempts were based on u sing do main kno wledge to choo se on ly relevant keywords as a basis for con structing the feature vectors. We e xperime nted with lists of keywords s upp lied b y local do main experts (biology po stgradu ate stud ents). We a lso we used keywords extracted from evidence files s upp lied with the training data. These files con tain what the hu man curators who supp lied the training set perceived as evidence of the gene e xpression criteria for eac h p aper. Overall, for sub -task 2, we e xperimented with feature vectors ranging between 200 select keywords to abou t 60 ,000 words. In all experiments we used a tradition al app roach to weighing th e significance of eac h term using TFIDF (Term Frequ ency/Inverse Document Frequ ency) to score eac h word. Unfortun ately all experiments proved qu ickly to b e disappo inting g enerating poo r classifiers with acc uracy in the range of 60 % on the training data. SIGKDD Explorations . Volume 4, Issue 2  X  page 96 An alternative a pp roach to add ressing the c uration p rob lem is to develop techn iqu es based on n atural language processing (NLP) techno logies [2]. The use of NLP techn iqu es may offer a solution to the prob lems inh erent with the simple keyword -based app roach. These prob lems relate to the fact t hat t he generated features and con sequ ently the generated classification mod els do no t capture the semantic relation ship o r the a ssociation b etween the words app earing in a do cument. Rather than attempting an NLP app roach, we decided to u se a n app roach that captures the a ssociation b etween words app earing in eac h do cument. This is based in automatically identifying frequ ently co -occurring localized word p atterns or motifs. By restricting the sear ch for these patterns to localized p arts of eac h do cument (e.g. a sentence or neighbou ring sentences) ou r app roach mod els the a ssociation s between these words and generates classifiers based on these a ssociation s.
 Our patterns are defined u sing regular exp ression s on words automatically extracted from the do cuments. An example of on e of ou r patterns is: This patterns describes all sentences (or group s of sentences) having v ariants of the word  X  X nte ract X  followed b y any nu mber of words followed b y a  X  gene name X  followed b y any nu mber of words followed b y variants of the word  X  X ind  X . The first step in ou r app roach was thu s to automatically bu ild a database of patterns by scann ing the training data se t using a variant of an association rule indu ction algorithm. To redu ce the size of ou r pattern b ase we first filtered ou t from eac h do cument the sentences that do no t con tain either a gene name or a keyword extracted from the e vidence files. Note that whe n creating the virtual do cuments used in sub -task 3, we on ly keep the sentences related to the gene name in qu estion . This app roach n aturally leads to generating different feature vectors for virtual do cuments created from the same ph ysical do cument. Our i mplemented pattern extractor on ly con sidered p atterns that con tain up to three words. We c ou ld h ave e xtend ed this, bu t felt that t his was unn ece ssary given the e xecution time to generate the patterns. The second step in the a pp roach was to d ecide which p at terns are to b e kept within the pattern b ase a nd u sed as features. This can be decided either by an expert or automatically. The a dvantage of using a regular expression no tation is it allows the e nd u ser to review and upd ate the pattern b ase. In ou r final system we used a simple frequ ency thresho ld to remove infrequ ent patterns.
 The third step in ou r app roach was then to u se the patterns as features to con struct t he feature vector tables, score eac h do cument against the patterns and p ass the table a s inpu t to the classification algorithm.
 Our final classifier was based on 335 automatically extracted patterns and p rovided acc uracy in the range of 80 % for the training data a nd p roviding the following acc uracy results on the evaluation d ata: Ranked -list: 84 %, Y es/No curate paper: 58 %, Yes/No gene produ cts: 59 %. Throu ghou t ou r stud y, we used a mixture of custom -bu ilt t ext processing too ls, data mining too ls from the Kensington system [3], and a pub lically available too ls. We e xperimented with variou s text pre -processing app roaches, had to h and le a large nu mber of f iles, and managed a large nu mber of parameters. By the e nd o f the stud y we had d esigned a visual text mining system that i s compatible with the Kensington visual programm ing paradigm, where data processing and analysis rou tines are represented as acyclic task g raph s. We a re c urrently evaluating the fun ction ality of ou r system. [1] SVM light, http://svmlight.joachims.org/ [2] Found ation s of statistical natural l anguage preprocessin g. [3] Kensington Discovery Edition , http://www .inforsense.com Moustafa Ghanem is a Research Fellow at the Department of Compu ting, Imperial College a nd h as a PhD in High Perf ormance Compu ting.
 Yike Guo is Professor of Compu ter Science in the Department of Compu ting, Imperial College a nd Found er of InforSense Ltd.
 Huma Lodh i is a Research Associate a t t he Department of Compu ting, Imperial College a nd h as a PhD in machine learni ng. Yong Zhang is a Research Associate a t the Department of Compu ting, Imperial College a nd h as a PhD in statistics.

