 Department of EECS, Oregon State University, Corvallis, OR, 97330 USA In this paper, we consider active learning of classification functions. We are given an initial set of m labeled exam-ples D l = { ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,..., ( x m ,y m the target label for input x i . In addition, we are given a pool of n unlabeled inputs D u = { x 1 ,x 2 ,...,x n } for which the labels can be queried. The problem of active learning is to select the most informative examples (queries) from D u to be labeled, so that the accuracy of the classifier in-creases quickly as the set of labeled examples grows. Ac-tive learning typically works in iterations, where each it-eration builds a classifier based on the current training set, and then selects the examples to be labeled. The labeled examples will then be added to the training set and this procedure is repeated until we reach a good model or we exceed the labeling budget. Much existing active learning work has focused on a sequential instance of this frame-work where one example is selected to be labeled in each iteration. A number of sequential active learning methods have been developed that yield substantial empirical gains over their passive learning counterparts, including simple strategies such as the minimum margin and maximum un-certainty principles (Settles, 2009).
 Batch active learning differs from sequential methods by selecting a batch of k &gt; 1 examples to be labeled at each iteration (Hoi et al., 2006b; Brinker, 2003; Guo &amp; Schu-urmans, 2007). This batch-mode of active learning is of-ten preferable to sequential methods when each label takes substantial time but can be produced in parallel. Such sce-narios may arise when labels require running wet lab ex-periments, careful human analysis, or expensive computa-tional processes.
 A naive approach to batch active learning is to simply ap-ply an existing sequential selection rule k times to generate a batch, e.g. selecting the k minimum margin examples. This approach, however, will often perform poorly since it will tend to ignore redundancy among selected exam-ples. To address this issue, there has been a small amount of work on batch active learning, which provides differ-ent heuristic approaches for incorporating batch diversity into the selection method. For example, Brinker (2003) in-troduced an SVM-based batch approach, which selects a batch that minimizes the margin of the selected examples while maximizing their diversity. Hoi et al. (2006b; 2006a) chose a batch of examples that effectively maximizes the Fisher information of a classification model, which leads to a trade-off between uncertainty and diversity. Guo and Schuurmans (2007) posed batch active learning as a com-plex optimization problem that maximizes the discrimina-tive classification performance while taking into consider-ation the unlabeled examples. Unfortunately the resulting optimization problem is non-convex and requires heuris-tic fixes involving many parameters to work effectively. Recently, Guo (2010) introduced an approach that selects a batch of examples that maximizes the mutual informa-tion between unlabeled and labeled examples. The pro-posed combinatorial optimization problem is NP-hard and a heuristic algorithm is introduced to produce a solution. This paper considers a general approach for batch active learning, which we refer to as  X  X imulation matching X . We are motivated by the observation that sequential methods are generally more example-efficient than their batch coun-terparts, since each example is selected with more informa-tion. Indeed in theory the best sequential strategy will never be worse than the best batch strategy, since one could sim-ulate the batch approach and then select the examples se-quentially. Leveraging the availability of highly-effective sequential active learning methods, we view a given se-quential method as a gold-standard whose performance, in terms of label efficiency, we would like to approach using batch selection. That is, we aim to come close to the per-example accuracy improvement of the sequential method but in less time (fewer iterations) via batch selection. For this purpose, we use Monte-Carlo simulation to esti-mate the posterior distribution over examples selected by the sequential method, and then select a batch of k exam-ples that  X  X est matches X  this distribution. A key contribu-tion of our work is to instantiate the notion of  X  X est match X  by developing a novel matching objective called bounded coordinated matching . While we show that optimizing the objective is NP-Hard, we introduce an efficient greedy al-gorithm that optimizes the objective with an approximation bound. Our proposed algorithm is simple to implement and its scalability in terms of the number of unlabeled exam-ples is similar to the base sequential policy. Experiments on eight benchmark datasets with different batch sizes demon-strate that the proposed approach is highly effective. Given a dataset D l of labeled examples, we now consider how to select the next batch of k examples to be labeled. A key issue in making this choice is to manage the trade-off between selecting examples that individually look most informative for learning versus selecting a diverse set of ex-amples. For instance, a common measure of informative-ness is the margin, or class uncertainty, of an example with respect to the currently learned classifier. However, picking the top k most informative examples under such measures will often select clusters of nearby examples that are quite redundant. Previous work on batch active learning has con-sidered various objective functions for capturing this trade-off and then searches for batches that approximately opti-mize those objectives.
 In this work, we follow a different approach motivated by the fact that sequential active learning has been widely studied and a variety of computationally efficient and em-pirically effective sequential policies exist. For example, selecting the example with highest class uncertainty is of-ten a simple yet highly effective baseline approach. The main idea behind our batch approach is to leverage such se-quential policies by selecting a batch of k &gt; 1 samples that  X  X losely matches X  the sequential policy X  X  expected behav-ior. This idea has been explored recently for the very differ-ent problem of batch Bayesian optimization (Azimi et al., 2011). In that work, it was also the case that good sequen-tial policies were available. However, since that work was focused on function optimization, the notion of  X  X losely matching X  used there is not suitable for active learning. The main contribution of our work is to develop a principled adaptation of the approach to batch active learning and to demonstrate its effectiveness. 2.1. Sequential Policy Simulation Let  X  be a sequential active learning policy. Given a set of labeled examples D l and unlabeled examples D u ,  X  returns the next example x  X  D u to be labeled. We would like to  X  X losely match X  the behavior of  X  when applied for k steps. However, without the labels of the selected instance, we do not know how  X  would behave after the first example is selected. In particular, different label outcomes will likely lead  X  to select a different set of k examples. In this work, we assume the availability of a posterior distribution of the labels of any example x given D l , which can be estimated using a probabilistic classifier. A k -step executions of  X  will result in a set of k selected examples from D u . Let S  X  be the random variable denoting the set of k examples resulting from such a k -step execution of  X  , which has a well defined distribution P k  X  (  X  ) over the subsets of D Importantly, it is generally straightforward to use Monte-Carlo simulation to draw samples of S k  X  . For example, this can be done by starting with D l and selecting the first ex-ample x 1 using  X  . Then, we realize y 1 , the class label of x , by sampling from the label posterior distribution of x 1 This simulated labeled example is then added to D l and the process repeats for k  X  1 additional iterations to obtain a total of k examples. Our batch policy is based on generat-ing a number of samples of S k  X  , which are used to define an objective for optimizing a batch of k experiments. Below we derive this objective and describe its optimization. 2.2. Coordinated Matching Objective Our goal is to select a batch B of k unlabeled examples that best  X  X atches the behavior X  of a base sequential policy  X  conditioned on the currently labeled examples. More pre-cisely, we consider a batch B to be a good match if it has high probability (relative to other sets) under the dataset distribution P k  X  . Unfortunately, for all but trivial sequen-tial policies  X  , there will be no closed form for P k  X  , which makes it challenging to directly optimize the probability of B . Thus, our approach is to first approximate P k simpler distribution Q k that captures essential aspects of P  X  and then return the batch B that is optimized under Q Matching Mixture Model. One naive choice for Q k would be to represent it as a latent mixture model, e.g. a Gaussian mixture model, from which k i.i.d. examples are drawn in order to produce a batch. While estimating such a model based on samples of S k  X  would be relatively straightforward, e.g. via an EM algorithm, it would gen-erally produce poor results. In particular, the i.i.d. na-ture of the model would typically assign high probability to batches containing redundant examples arising from the most probable Gaussian component. This fails to capture the highly dependent nature of examples in S k  X  , which will typically avoid such redundancy.
 In order to partially capture the dependencies in S use a variant of the Gaussian Mixture Model (GMM), which we call the k -Matching Mixture Model ( k -MMM) . Similar to GMMs, a k -MMM model consists of a set of k n -dimensional Gaussian with mean vectors  X  = {  X  1 ,..., X  k } and covariance matrices  X  = {  X  1 ,...,  X  k } . In contrast to the i.i.d generative process assumed by GMMs, a k -MMM generates a set of k points by sampling one point from each of the k components.
 Given a k -MMM model and a set of k points S = { x 1 ,...,x k } , there are k ! possible ways that S can be gen-erated, each corresponding to one possible matching of the k points to the k components. Given such a matching m , let m ( i ) denote the index of the model component that is matched to point x i and let M denote the set of all possible matchings. Assuming a uniform prior over possible match-ings, the probability of observing S given a k -MMM Q k can be written as: where f is the Gaussian PDF.
 Importantly, unlike an i.i.d. model, the point sets generated by Q k can be highly dependent since there is a strict re-quirement that each component generates exactly a single point. In our application, this is useful in that it can cap-ture distributions that assign higher probability to diverse datasets, which is a typical characteristic of P k  X  . Estimating Q k . We now wish to select a k -MMM model Q k that best approximates our target distribution P k simplify this estimation problem, in this work, we limit our attention to models where the means are selected from the unlabeled examples D u and all of the  X  i are equal to a known  X  1 . Under these assumptions, we can view the problem of selecting Q k as a combinatorial problem of se-lecting the best subset of k points  X  = {  X  1 ,..., X  k } from D u to serve as the component means. We will let Q k  X  de-note our model for a particular set  X  . Our optimization objective is now to find the set  X  that minimizes the KL-divergence KL ( P k  X  || Q k  X  ) , which is equivalent to minimiz-ing the cross-entropy between the distributions given by H ( P k  X  ,Q k  X  ) = E  X  log Q k  X  ( S k  X  ) .
 The resulting minimization problem is intractable due to the complicated nature of P k  X  . However, we can sample from this distribution using simulation as described previ-ously and generate a set of samples S = { S 1 ,...,S N } , which can be used to approximate the expectation. Let U k be the set of all size-k subsets of unlabeled examples in D our optimization objective can be formulated as follows. arg min To further simplify the above objective, we note that for the purpose of maximizing over the means  X  , P max m  X  X  Q k  X  ( S i ,m ) . This is because the value of Q  X  ( S i ,m ) decays very quickly for non-optimal matchings, since such matchings will typically assign a data point in S to a component with a distant mean. Thus, our objective is approximated by: where x ij is the j -th example in set S i , and the distance Algorithm 1 Greedy Supermodular Minimization Algo-rithm Require: Set function g , Finite set A .
 Ensure:  X   X  X  such that |  X  | = k  X   X  X  while |  X  | &gt; k do end while return  X  d the cost of matching x 1 to x 2 . In our experiments, we use the identity matrix for  X  , resulting in Euclidean distance. The above objective corresponds to a novel optimiza-tion problem that we call Bounded Coordinated Match-ing (BCM) . Given a particular choice of  X  , we find the minimum cost matching between  X  and each set S i  X  S . The overall cost of  X  is the sum of all N costs, i.e. P ordinated matching problem involves finding the  X  that achieves minimum overall cost. Since minimum cost matchings between two sets can be found in polynomial time via the Hungarian algorithm, the overall cost for any  X  can be computed efficiently. Unfortunately, the problem of finding the optimizing set  X  is NP-complete.
 Theorem 1. BCM is NP-complete (see appendix for the proof).
 Fortunately, BCM allows for certain approximation guar-antees to be made for a simple greedy algorithm, which we present in Section 3.
 Summary of Approach. To summarize, our overall ap-proach is as follows. First, we use simulation to generate N independent sample trajectories S 1 ,  X  X  X  ,S N of a sequential active learning policy (we use the maximum entropy policy in our experiments). Second, we approximate the distribu-tion generating these trajectories by Q k  X  where the set  X  is found by approximately optimizing Objective ( 2 ) (see next section for the optimization approach). Finally, given Q we select a batch of k unlabeled data points B such that B = arg max B max m  X  X  Q k  X  ( B,m ) . Since we limited the choice of  X  to subsets of the unlabeled data, it is easily verified that B is simply equal to  X  , which is returned as the batch of examples for which to request labels. In this section we present a greedy approximation algo-rithm for BCM motivated by theoretical results on the min-imization of non-increasing, supermodular set functions. 3.1. Greedy Approximation Algorithm Definition 1. Given a finite set A , a function on subsets of A , g : 2 A  X  R + is supermodular if for all A 1  X  A 2  X  A and x  X  X \ A 2 , it holds that g ( A 1 )  X  g ( A 1  X  x )  X  g ( A g ( A 2  X  x ) .
 In other words, a supermodular function demonstrates  X  X i-minishing returns X  because adding an element to set A  X  A decreases the value of g (  X  ) by at most as much as adding the element to a subset of A . In addition, a set function is non-increasing if for any set A and element x we have g ( A )  X  g ( A  X  X  x } ) . It turns out that the problem of find-ing a size k subset of A that minimizes a non-increasing supermodular function g (  X  ) can be approximately solved via a simple greedy algorithm. Algorithm 1 outlines this approach, which simply starts with all elements of A and iteratively removes the element whose removal leads to the smallest increase in g (  X  ) until only k elements remain. We have the following known guarantee.
 Theorem 2. (Il X  X v, 2001) Let g (  X  ) be a monotonic non-increasing supermodular function over subsets of the finite set A , |A| = m and g ( A ) = 0 . Let  X  be the set of the elements returned by the greedy algorithm 1 s.t |  X  | = k , g (  X  )  X  where t is the steepness parameter of function g (  X  ) which is defined as: Notice that the approximation bound involves the steep-ness parameter t of g (  X  ) , which characterizes the rate of decrease of g (  X  ) . This is unavoidable because achieving a constant factor approximation guarantee is not possible unless P=NP (Nemhauser &amp; Wolsey, 1999). Furthermore, this bound has been shown to be tight for any t (Il X  X v, 2001). Note that this is in contrast to guarantees for greedy maximization of submodular functions (G. L. Nemhauser &amp; Fisher, 1978) for which there are constant factor guar-antees. In addition, the greedy algorithm we use is quali-tatively different from the one used for submodular maxi-mization, since it greedily removes elements from  X  rather than greedily adding elements to  X  .
 The objective function corresponding to the BCM opti-mization problem (2) is the following function over subsets  X  of the unlabeled data points D u : The BCM problem corresponds to minimizing this function subject to |  X  | = k . It is easily verified that this objective is a non-increasing supermodular function of  X  . Further, since the points x ij in the objective are elements of D u we have that g ( D u ) = 0 . Therefore, g (  X  ) satisfies all of the properties for Theorem 2 and the greedy algorithm pro-vides the corresponding guarantee. Thus, we use the above greedy algorithm applied to the function g (  X  ) and set D our BCM optimizer, i.e. A = D u in Algorithm 1 . 3.2. Accelerated Greedy Algorithm Each iteration of the greedy algorithm requires evaluat-ing the cost function (Equation 5) for removing each ele-ment x from the current set  X  , which is at most the size of D u . Each cost function evaluation involves finding N minimum cost matchings, between each of the S i and  X  \ x (when  X  \ x is larger than S i , some elements of  X  are un-matched), which can be done via N calls to the Hungarian algorithm. While polynomial, for a naive implementation, each iteration can be computationally expensive when D u is large. Fortunately, there are at least three ways to soundly speedup the computation, leading to drastic time reductions in our experience and allowing the computation to be inde-pendent of the size of D u .
 First, let  X  be the current set and  X  i  X   X  be the set of ele-ments in  X  that are matched to S i in the minimum match-ing. It is easy to verify that g (  X  ) = g (  X  i  X  i ) . This obser-vation implies that instead of initializing  X  to be the entire unlabeled data set D u , we can soundly initialize  X  to be  X  0 =  X  i S i since the minimum matching between S i and D u must be S i itself. Thus, the time complexity of the greedy algorithm under this initialization grows with the size of  X  0 (the number of data points generated during sim-ulation, which is at most N  X  k ), rather than the potentially much larger D u . In other words, the run time of the greedy algorithm is independent of the size of D u , which is often quite large.
 Second, for points x that are unpruned by the first rule, we can often avoid computing g (  X  \ x ) by exploiting the supermodularity property. This idea is analogous to a sim-ilar speedup approach used for submodular maximization (Krause et al., 2008). From Definition 1, we can directly conclude that for A 1  X  A 2  X  A , g ( A 1 \ x )  X  g ( A 1 g ( A 2 \ x )  X  g ( A 2 ) . We define the non-negative incremen-tal difference of an instance x with respect to a set  X  to be  X  (  X  ,x ) = g (  X  \ x )  X  g (  X  ) , which is the amount of increase of our objective function after removing a sample x from  X  . Normally this incremental difference must be computed for all x  X   X  in each iteration. However, by maintaining these incremental differences, we can often soundly avoid recomputing a large majority of them in any given itera-tion. The first iteration must compute the differences for all points in  X  . We then sort the points in increasing order based on their incremental differences, and remove the first point. For the following iteration, we move on to the next point in the sorted list and recompute its incremental differ-ence. If the value is still smaller than the remaining points, we can immediately remove this point from  X  and proceed to the next iteration without recomputing any other differ-ences. Otherwise, we proceed to evaluate the next points in the sorted list until finding one whose recomputed dif-ference is less than the other stored differences and remove the point. The supermodular property guarantees that this approach makes the same choices as the full greedy algo-rithm, but effectively avoids a large number of difference computations in practice.
 Finally, for any point x that we need to compute its differ-ence and hence evaluate g (  X  \ x ) , we can reduce the cost of this computation by storing the set of maximum matchings between  X  and the S i . In particular, rather than recom-puting the maximum matching between  X  \ x and each S i from scratch, we can start with the current matching to S If the current matching does not involve x , then no recom-puting is needed. Otherwise the matching can be updated with a single shortest path computation. This results in a reduction in time complexity at least by a factor of k com-pared to running the full Hungarian algorithm for each S i Details are described in the supplementary material. The computation of our batch selection approach can be divided into two stages: 1) Simulation of the sequential policy, and 2) Solving the resulting BCM problem. As the number of unlabeled data points n increases, the sim-ulation time will also increase, since each simulation step involves applying a sequential policy, which typically con-siders each unlabeled point. For typical sequential policies, including the one in our experiments, the time complexity will grow linearly in n . Fortunately, the N simulations gen-erated during the first stage are independent, which allows for easy parallelization, possibly resulting in a time reduc-tion of a factor of N . That is, with parallelization there need not be any time overhead compared to running a typ-ical sequential algorithm for k steps.
 Further, as described previously the time complexity of the second stage does not depend on n , but rather on N  X  k . Overall, the scalability of the combined two stages in terms of n is similar to the underlying sequential base policy. Datasets. In this section we evaluate our proposed batch active learning method using eight binary classification problems from the UCI machine learning repository (Asun-cion &amp; Newman, 2010) including (the number of sam-ples and attributes are shown in the parenthesis for each dataset): Breast(569, 32), Ionosphere(351, 34), Pima(768, 8), German(1000, 24), Haberman(306, 3), Sonar(208, 60), EF(1543, 16) and MN(1575, 16). The EF and MN datasets are subsets of the original multi-class letter dataset, created by retaining only letters E and F, M and N respectively. Baseline Algorithms. To evaluate the efficacy of the pro-posed algorithm, we compare our algorithm against four baseline methods. For the first baseline, we consider the Fisher Information approach by Hoi et al.(Hoi et al., 2006b), one of the state-of-the-art methods in batch active learning. This method selects a batch that maximizes the Fisher information of a classification model (we use Kernel logistic regression in our experiments). The second base-line, which we call Maximum Uncertain , simply selects the top k most uncertain (as measured by class entropy) ex-amples to form the batch. This simple batch algorithm is a commonly used baseline in batch active learning litera-tures. We further include the  X  X andom X  policy in our com-parison, which has demonstrated very competitive perfor-mance in prior batch active learning studies (Guo &amp; Schu-urmans, 2007). Finally, we also compare to the sequential policy that selects the example with the highest class en-tropy, which is also the base sequential method that our simulation matching algorithm tries to match. Note that we also compared our algorithm against SVM-D, which is another batch selection algorithm based on the minimum margin principle (Brinker, 2003). The results were not re-ported here since it was consistently worse than other base-line batch active learning approaches. Note that we were not able to compare results to two recent batch active learn-ing methods (Guo &amp; Schuurmans, 2007), and (Guo, 2010) because we were not able to acquire a working implementa-tion of these algorithms, and both algorithms involve com-plex optimization procedures that are non-trivial to imple-ment and tune.
 Experimental Setting. We use kernel logistic regression with an RBF kernel (kernel width = 0 . 05 ) as our classifier for all algorithms. We use N=20 simulated trajectories for each batch selection and consider batch sizes of 10 and 20. Each dataset is randomly divided into 70% training data and 30% testing data. Active learning is initialize with five random examples per class from train and iteratively se-lects batches of unlabeled examples in train to query. The classification accuracy is evaluated after each batch selec-tion on the test data. The entire process is repeated for 50 independent runs and the average results are reported. Evaluation. We show the classification accuracy of differ-ent methods on the eight datasets in Figure 1(the batch size is shown in the parenthesis for each dataset). The x  X  axis indicates the number of queries and the y  X  axis represents the classification accuracy. First, let us focus on comparing our proposed method with the baseline batch methods in-cluding Fisher Information and Maximum Uncertain . We observe that, for most datasets, the learning curves pro-duced by our method dominate the learning curves of the other batch methods. This is true for both batch sizes, but the improvements our method achieves is more significant and consistent for larger batch size of 20 . Interestingly, we observe that Fisher Information and Maximum Uncertain results are sometimes dominated by random . For example, this is the case for Pima and German, where both methods performed consistently worse than random for both batch sizes. While surprising, this is actually consistent with what have been observed in a previous batch active learn-ing study (Guo &amp; Schuurmans, 2007). This suggests that it is actually non-trivial to design a batch active learning method that performs competitively to random in a consis-tent fashion. Notably, our proposed approach is the only method in our comparison that demonstrated this robust-ness, which is a highly desirable property of our method. In addition, the variance of our approach is quite small in our experiments. This is likely due to the average effect of using a set of simulations, which are processed in aggre-gate by the greedy optimizer. Among all data sets, Breast data set has the highest variance which is 0 . 006 and 0 . 0074 for batch size 10 and 20 respectively.
 We also observe that the sequential method generally out-performs the batch methods (with a few exceptions) and more significantly for batch size 20 . This is aligned with our expectation because a sequential approach makes more efficient use of the labeled examples when making selec-tion choices. Interestingly, our proposed method is able to match the performance of sequential method reasonably well for many datasets, and even sometimes outperform se-quential (e.g., Ionosphere and Breast). We conjecture this is due to the fact that our proposed method aggregates the outcome of many simulations, which may reduce the vari-ance of the base sequential active learning procedure. Computational Time. We compute the CPU run time of selecting a batch of 20 examples in one of our largest data sets, MN, on a standard desktop computer with 2 . 13 GHz CPU (dual core) and 2 GB of memory. It takes less than 3 minutes using an un-optimized Matlab implementation. This time is reasonable for most applications of batch ac-tive learning, where labeling time is generally significant. As discussed previously, this time can be reduced via par-allelization and will grow reasonably with the size of D u In this paper, we introduce a novel method for batch ac-tive learning, which follows a recently proposed general approach named  X  X imulation matching X . The basic idea behind simulation matching is to design batches of queries by imitating the behavior of a high-quality sequential pol-icy via simulation. While this general approach has been successfully applied to the problem of batch Bayesian op-timization, the notion of  X  X atching X  used in prior work is not suitable for active learning. We put forth a principled adaptation of the simulation matching approach to batch active learning. In essence, we consider S k  X  , the set of k points selected by sequential policy  X  , to be a random variable. Because the distribution of S k  X  is too complex to directly estimate, we draw samples from this distribution via simulation and approximate the distribution using a k -Matching Mixture Model, which is then used to select the batch. This results in a combinatorial optimization prob-lem that we call  X  X ounded coordinated matching X  (BCM), and we present an efficient algorithm that provides approx-imation guarantees. We evaluate the proposed approach on eight UCI datasets and the results show that our method is highly competitive compared to baseline methods.
 Proof. Given S 1 ,...,S N , where each S i contains a set of k points { x ij } k j =1 , the BCM objective function is: Consider the following graph representation of the prob-lem. We define a weighted bipartite G = ( U,V,E ) where V = { S 1 ,S 2 ,  X  X  X  S N } , and U = D u representing the set of unlabeled examples. E  X  U  X  V is an edge set where the weight w ( u,v ) = d  X  ( u,v ) . A coordinated matching on G is a subset of edges E 0  X  E such that, for 1  X  i  X  t , ( U  X  S i )  X  E 0 is a matching. The weight of a coordinated matching E 0 is w ( E 0 ) = P ( u,v )  X  E 0 w ( u,v ) . Given G and some integer k  X  | U | , the bounded, coordinated matching problem (BCM) asks for a minimum weight coordinated matching such that the edges in the matching are, in to-tal, incident to at most k vertices from U . Below we will turn this minimization problem into an equivalent maxi-mization problem by replacing all the weights in G such that w 0 ( u,v ) =  X   X  w ( u,v ) , where  X  is a large constant to ensure all positive w 0 values. It is easy to see that the solution of this maximization problem of BCM is also the solution to the original minimization problem.
 Focusing on the maximization problem, the decision ver-sion of the problem augments G and k with a weight W and asks if there exists a bounded, coordinated matching with weight W . We show that the decision version of maximizing BCM is NP-hard. We reduce from the well-known 3-Dimensional Matching (3DM) problem which, given a set T  X  X  X  Y  X  Z where X , Y , and Z are disjoint and an integer k , asks if there exists a subset M  X  T of size at least k such that for any two distinct sets M i ,M j  X  M , M i  X  M j =  X  . 3DM remains NP-hard even when | X | = | Y | = | Z | = k (i.e. it becomes an exact-cover problem). The reduction is the natural one: create an unweighted, bipartite graph G = ( U,V,E ) where V = X  X  Y  X  Z and U = { u 1 ,...,u k } is a set of k nodes. For every t i  X  T where t i = { x i ,y i ,z i } add the edges { u 3-dimensional matching of size k if and only if  X  G,k  X  has a bounded, coordinated matching of weight 3 k .
 The authors acknowledge the support of the NSF under grants IIS-0812514, IIS-1055113, and IIS-0905678. Asuncion, A. and Newman, D.J. UCI machine learn-ing repository, 2010. URL http://archive.ics. uci.edu/ml .
 Azimi, J., Fern, A., and Fern, X.Z. Batch bayesian opti-mization via simulation matching. NIPS , 2011.
 Brinker, Klaus. Incorporating diversity in active learning with support vector machines. In ICML , 2003.
 G. L. Nemhauser, L. A. Wolsey and Fisher, M. L. An anal-ysis of the approximations for maximizing submodular set functions. Mathematical Programmingn , 14, 1978. Guo, Y. and Schuurmans, D. Discriminative batch mode active learning. NIPS , 6, 2007.
 Guo, Yuhong. Active instance sampling via matrix parti-tion. In NIPS , pp. 802 X 810, 2010.
 Hoi, Steven C. H., Jin, Rong, and Lyu, Michael R. Large-scale text categorization by batch mode active learning. In WWW , pp. 633 X 642, 2006a.
 Hoi, Steven C. H., Jin, Rong, Zhu, Jianke, and Lyu,
Michael R. Batch mode active learning and its appli-cation to medical image classification. In ICML , 2006b. Il X  X v, Victor P. An approximation guarantee of the greedy descent algorithm for minimizing a supermodular set function. Discrete Applied Mathematics , 2001.
 Krause, A., Singh, A., and Guestrin, C. Near-optimal sen-sor placements in gaussian processes: Theory, efficient algorithms and empirical studies. The Journal of Ma-chine Learning Research , 9:235 X 284, 2008.
 Nemhauser, G.L. and Wolsey, L.A. Integer and combina-torial optimization . 1999.
 Settles, Burr. Active learning literature survey. Com-puter Sciences Technical Report 1648, University of Wisconsin X  X adison, 2009.

