 Department of Electrical Engineering, Technion, Haifa 32000, Israel Many machine learning tasks involve models in the form of a matrix. As an important example, consider the prob-lem of linear metric learning where the dissimilarity be-tween a pair of samples is measured using the Mahalanobis distance, parametrized by a positive semi-definite matrix. A second important example is the matrix model obtained when learning multiple linear classifiers regularized jointly, like in the case of object recognition with many classes. Many algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009).
 While such linear matrix models are common for metric and multiclass learning, the broader class of  X  X ector X  lin-ear model are a popular choice in many domains since they provide a good balance between simplicity, scalabil-ity and performance. Methods to generate linear classi-fiers from data have flourished in the past decade, includ-ing SVMImportantly, when learning linear models, it was recently shown that modeling the second order information about the set of models (Crammer et al. (2009) and the ref-erences therein), or using this information during training (Duchi et al., 2010) improves the convergence rate of the learning algorithms as well as the performance of the re-sulting classifiers. These very effective methods were de-veloped primarily for handling vector models, and were not designed to handle matrix models.
 At first sight, problems that involve learning matrices could be handled directly using methods developed for learn-ing vectors, including the second order methods described above. In practice however, matrix models often pose a challenge to scalability, since both their memory and their runtime complexity scale quadratically with the data di-mensionality n . Modeling second order interactions be-tween features may therefore require n 4 parameters, limit-ing these methods to relatively low dimensional data. In this paper we study second-order methods for learning matrix models and test them in the context of similarity learning. We describe AROMA (Adaptive Regularization Of MAtrix models) an online algorithm that learns a distri-bution of matrix models. Since maintaining a full covari-ance matrix over the parameters would not be feasible for large dimensions, we describe models that capture part of the covariance structure. We first describe a simple model with a diagonal covariance matrix. While this model scales well to large matrices, it fails to model correlations between features which could be crucial in some applications. We further describe a factored model which is still linear in the number of parameters (quadratic in the dimension), yet captures some of the correlations between features. In the context of metric and similarity learning, AROMA can be used to learn a distribution over metrics, instead of a single metric. We evaluate AROMA in two tasks of retrieving images and documents by evaluating similarity between objects. We find that the two AROMA variants outperform competing methods by a large gap. Addition-ally, the more involved variant convergence faster than all other methods evaluated. As far as we know, this makes it the state-of-the-art method for the extensively studied task of linear similarity learning.
 Notation: In this work we often consider the bilinear form q &gt; W p where q  X  R m , p  X  R n and W  X  R m  X  n . Given such a matrix W , we denote by vec ( W )  X  R mn the vector generated by  X  X tacking X  the columns of the matrix W . Using this operator we can write the bilinear form as an inner product q &gt; W p = vec ( W )  X  vec pq &gt; . We de-note by x z the element-wise product of two vectors (or matrices) and by sum ( A ) the sum of the elements of the matrix or vector A . We denote by | x | 0 to be the number of non-zero elements of the vector x , known as ` 0 norm. Given two square matrices  X   X  R m  X  m and  X   X  R n  X  n we denote their Kronecker product by  X   X   X  . This is a matrix of size mn  X  mn that is composed of blocks, where the ( i,j ) th block is  X  i,j  X  . Finally, (Sx) refers to the equation x in a longer version of this manuscript provided online 1 We focus on the problem of learning a linear similarity measure between pairs of objects q  X  R m , p  X  R n , in the form of S W ( q , p ) = q &gt; W p . This similarity measure is related to metric learning models of the form ( q  X  p ) &gt; W ( q  X  p ) for square matrices W , and becomes equivalent to it when all vectors p and q have a constant W -norm. Interestingly, the similarity measure S W ( q , p ) does not have to be symmetric, and may even be defined for objects from with different dimensions m 6 = n (non-square W ). In general, it allows to learn a measure of relatedness between objects from different domains, like images and sounds or images and text (as in Grangier &amp; Bengio, 2008). Importantly, when the vectors representing both query and object are sparse and contain only few elements, | q | 0 = k | p | 0 = k p computing the similarity score takes only k q k p operations instead of mn for dense vectors.
 We address a weak-supervision setup where training is based on relative similarity . Here, we are allowed to sam-ple triplets of objects, each triplet containing a  X  X uery ob-ject X  q  X  R m and two candidate objects p + , p  X   X  R n , where it is known that the object p + is more related (or similar) to the query q than the other object p  X  . Importantly, the relative similarity learning setup does not assume that there exists an absolute numerical level of sim-ilarity between an object and a query, or that the learner has access to it. Training therefore assumes a weaker type of supervision, making it easier to collect labeled data either from human raters, or by collecting indirect data about as-sociation of object pairs. For example, two web pages can be ranked by their similarity to a third web page by the number of users visiting them within the same session. Formally, our goal is to learn a bi-linear similarity scor-ing function S W ( q , p ) = q &gt; W p parametrized by W  X  R m  X  n such that the total ordering induced by the similar-ity function over objects p would be consistent with the partial ordering information given about p  X  and a query q . A similar model was recently studied in different con-texts (McFee &amp; Lanckriet, 2012; Kulis et al., 2011; Weston et al., 2011).
 We formalize training as a constrained optimization prob-lem and require that this relation between the induced rank-ing and the partial information of ordering holds with a safety margin, More specifically, we develop an online algorithm that al-lows to rank objects by their similarity to a  X  X uery object X  q . Like online prediction algorithms, online retrieval algo-rithms work in rounds. On round i , the algorithm receives a triplet composed of a query q i  X  R m and two possible out-comes p + i , p  X  i  X  R n . The algorithm than outputs a single bit indicating which outcome is better for the given query. It then receives the correct answer and updates its model. To learn a scoring function that obeys (1), we define a hinge loss over the triplet ( q , p + , p  X  ) ` W ( q , p + , p  X  ) = max 0 , 1  X  q &gt; W ( p +  X  p In what follows, we describe two online algorithms to min-imize this loss while modeling the distribution of matrix models W . We first review previous work on learning such distributions for vector models. We first describe the AROW algorithm that was designed for binary classification of vector inputs x  X  R d and intro-duced by Crammer et al. (2009).
 The key idea of AROW (Dredze et al., 2008, and its prede-cessors), is that instead of maintaing a single vector w dur-ing learning, AROW maintains a distribution over possible models. Specifically, AROW maintains a Gaussian distri-bution over vectors denoted by N ( w ,  X ) , where w  X  R d and  X   X  R d  X  d . The mean w encodes the knowledge of the algorithm about the weight features (linear model), and is used to make predictions. The covariance  X  captures the notion of confidence in the weights, and is used during training to set an effective learning rate for features with different statistics. AROW was motivated by tasks in natu-ral language processing, where many features are very rare and a few features are frequent.
 AROW is an online algorithm that works in rounds. On the i -th round, the algorithm receives an input x i  X  R d and employs its current model to make a prediction  X  y i  X  X  X  1 } . It then receives the true label y i  X  { X  1 } and suffers a loss using the pair ( x i ,y i ) and proceeds to the next round. AROW updates its current model parameters w and  X  by minimizing the following objective function where D KL is the Kullback-Leibler divergence. This objec-tive aims to find a model that classifies the sample ( x i correctly, while keeping the distribution from changing abruptly at a single iteration.
 The minimum of the objective in Eq. (3) was shown by Crammer et al. (2009) to be obtained by the update rule: AROW was shown to attain state-of-the-art performance on many problems (Crammer et al., 2009; Duchi et al., 2010) and its performance is analyzed both for full covariance matrices (Crammer et al., 2009) and diagonal covariance matrices (Orabona &amp; Crammer, 2010). In the next section, and in this entire paper, we lift AROW to matrices, while maintaining both memory and speed efficiency. As with online classification learning, online retrieval algo-rithms work in rounds. At round i the algorithm receives a triplet composed of a query q i  X  R m and two possible out-comes p + i , p  X  i  X  R n . The algorithm than outputs a single bit indicating which outcome is better for the given query. It then receives the correct answer and updates its model. For simplicity, we assume that the first outcome is always preferable, namely, given q i the algorithm should rank p over p  X  i . We now consider the problem of modeling un-certainty over matrices, in the context of online-learning similarity measures that obeys (1), and describe algorithms to minimize the loss in (2).
 A naive approach to model uncertainty over matrices would be to to use the linearity of the ranking function S W ( q , p ) in W , and write S as an inner product between two vectors q &gt; W p = vec ( W )  X  vec pq &gt; . Here, learning over matri-ces of dimension m  X  n is viewed simply as learning over vectors of dimension 1  X  mn . After transforming the ma-trix model into a vector, then the original AROW algorithm for vectors can be applied.
 Unfortunately, this approach requires to maintain the mean parameters as a vector of of size mn and the full covariance matrix of size ( mn )  X  ( mn ) . Even for moderate dimen-sion values of m and n , the size of a full covariance ma-trix m 2 n 2 cannot be stored in memory. For instance, with m = n = 10 3 , the dimension of the vectorized model is mn = 10 6 and the full covariance matrix requires 10 12 pa-rameters. Designing second order algorithms for matrices thus requires to model the covariance in a more compact way. We now discuss and develop two such compact repre-sentations and learning algorithms: a diagonal covariance, and a factorized covariance. 4.1. Diagonal Covariance Our first algorithm restricts the covariance matrices to be diagonal, using only mn non-zero elements (the size of the similarity measure W ). Denote by  X   X  R mn the diagonal elements of the covariance matrix. The update (4) becomes and the covariance is, We denote by  X   X  R m  X  n the covariance matrix that main-tains one element per feature, and thus is diagonal-like, al-though it is rectangular in shape. We identify x i = q i p used for matrix-similarity measures, Input parameters A scalar r We call the algorithm d(iagonal)-AROMA for diagonal-Adaptive Regularization Of MAtrix models , and it is sum-marized in Fig. 1. The memory required for d-AROMA is  X ( mn ) -the space needed to store both W and  X  . The time complexity is  X ( mn ) as all operations involve component-wise operations between W and  X  ; and p and q .
 Before proceeding to describe the next algorithm we state a mistake bound for d-AROMA. Let M be the set of rounds for which the algorithm made a prediction mistake and let U be the set of example indices for which the algorithm made an update, yet no mistake occurred. Then, Theorem 1 Let V be any similarity matrix. Assume the algorithm is executed on any sequence then the total no. of mistakes it performs is bounded by, |M| X  X The proof is omitted due to lack of space and is similar in spirit to the analysis in section 4.3 of Orabona &amp; Cram-mer (2010). As in their, analysis we expect the bound to be small if either the combination of the k th feature of the query q i,k and of the l th feature of the output differ-this combination is not useful for prediction, that is, V is small. When most feature combinations fall under one of these two cases, we expect the second term in the first square-root term to be small and most of the values of the log function to be close to zero. Unlike the vector-variant of this analysis, here it is not required that the input features are sparse. Instead, we only require that for some inputs the query is sparse and for other inputs the difference between the objects is sparse, but not necessarily both. 4.2. Factored Covariance Our second approach to model the distribution of similar-ity matrices is based on factorizing the covariance matrix in a way that captures separately correlations in the  X  X n-put X  (right side of the similarity matrix) and in the  X  X utput X  (left side). To describe our second algorithm, we use the definition of a matrix-variate normal distribution (Gupta &amp; Nagar, 1999).
 Definition 1 A random matrix X  X  R m  X  n is said to have a matrix variate normal distribution with mean ma-trix W  X  R m  X  n and covariance matrix  X   X   X  where  X   X  R m  X  m and  X   X  R n  X  n are both symmetric and PSD, if vec ( X )  X  X  ( vec ( W ) ,  X   X   X ) . Matrix variate normal distributions are denoted by N ( W,  X   X   X ) .
 Gupta &amp; Nagar (1999) show (Thm. 2.2.1) that the proba-bility density of a matrix variate normal distribution is, p ( X | W,  X  ,  X ) = (2  X  )  X  1 2 mn det ( X )  X  1 2 n det ( X )  X  exp n  X  We derive our algorithm by revisiting the objective of AROW (3) and compute the three terms of that objective for our model. For the first term, we use (7) and obtain that the KL divergence between two matrix-variate normal distributions is (up to additive constants), = For the second term of (3), we use q &gt; W p = vec ( W )  X  vec pq &gt; as discussed above, to compute Finally, the third term is, where we used the identities vec ( AXC ) = C &gt;  X  A vec ( X ) and vec A &gt; &gt; vec ( C ) = Tr ( AC ) . Combining (8), (9) and (10) we get the optimization problem describing the update of the algorithm, 1 2 + + + The detailed derivation of the update steps is given in a long version 1 . It yields our second algorithm, named f(actored)-AROMA, which is summarized in Fig. 2. Using Woodbury identity it follows that both  X  i (13) and  X  i (14) are PSD. It is worth comparing the update for  X  (13) in Fig. 2 (S5) with the update of AROW for  X  (4). Both updates share the same formal structure, but use different constants. AROW uses the parameter r in the denominator of (4), while f-AROMA uses mr/ q &gt; i  X  i  X  1 q i . Assuming k q i k 2  X  m we of the update. In the extreme case if q &gt; i  X  i  X  1 q  X  i =  X  i  X  1 . Intuitively, the algorithm should decrease the total variance as more examples are observed. Yet, if the variance is already low due to low variance related to the query q &gt; i  X  i  X  1 q i then there is no need to reduce the vari-ance related to the output  X  , and vice versa. Following the symmetry between  X  and  X  , these observations also hold for the update of  X  (14) (S6). f-AROMA uses a total memory of mn + m 2 + n 2 to store the mean matrix W and the covariance matrices  X  ,  X  . The time complexity is also mn + m 2 + n 2 since it involves addition to all elements of these matrices. Note that if m  X  n both d-AROMA and f-AROMA have about the same asymptotic complexity, where the later requires stor-age and manipulation of one more matrix. When the di-mensions m and n differ significantly, m n or n m , the complexity of f-AROMA larger than that of d-AROMA because f-AROMA scales quadratically both with m and n , while d-AROMA scales linearly with either parameters. We conclude this section with a mistake bound similar to Theorem 1. Our analysis applies to the algorithm of Fig. 2 with two minor changes. First, it assumes a mistake driven version of the algorithm, namely, that the algorithm makes an update only when a mistake occurs. The condi-tion for an update is therefore 0 &gt; q &gt; i W i  X  1 p 1 &gt; q &gt; i W i  X  1 p i . Second, from (12) (S4) we get that the Input parameters: A scalar r update of the factored-AROMA can be written as, the analysis is for a version that uses the new matrices  X  and  X  i , that is, We are now ready to state the main theorem of this section. Theorem 2 Let V be any similarity matrix. Assume the algorithm is executed on any sequence of queries and ob-jects, then the total number of mistakes that the algorithm performs is bounded by |M| X  X To understand the theorem, the matrices  X   X  1 N and  X   X  1 be thought of as the second order moments of the objects p i and the queries q i respectively. From (13) (S5) and (14) (S6) we observe that these matrices are the sum of the identity matrix and a weighted sum of outer products of the objects and queries. The first term of the bound Tr V  X   X  1 N V &gt;  X   X  1 N is small if either the rows of V are aligned with eigenvectors of  X   X  1 N associated with small values or the columns of V are aligned with eigenvectors of  X   X  1 N , but not necessarily both. This property, (see Sec. 3.1 of Cesa-Bianchi et al., 2005) holds for the input space of AROW, and also for a second order perceptron. For f-AROMA, this property holds for any one of the subspaces, queries or objects.
 Next, the second term of the bound is small if either matri-ces  X   X  1 N and  X   X  1 N are skewed. This is because the log det function is concave. A similar property holds also for The-orem 1 where we required that features from either spaces would be sparse or non-informative. That is, a property is required to hold only for one of the spaces (queries or ob-jects) but not both.
 The proof of the theorem relies on the following lemma, which extends Lemma 4 used in the analysis of AROW (Crammer et al., 2009) Lemma 3 The following two bounds hold for the updates in (13) (S5) and (14) (S6), P i ( q i  X  i q i ) p &gt; i  X  nr log det  X   X  1 N Proof: We prove the first inequality. The second in-equality can be proved similarly. Using (14) (S6) we get, q p i  X  i p i and summing over i we get,
X = mr X = mr log det  X   X  1 N , where the first equality follows from Lemma D.1 of Cesa-Bianchi et al. (2005).
 Proof sketch: (of Theorem 2) We build on previous ap-proach (Orabona &amp; Crammer, 2010) and have the follow-ing inequality, which generalizes Corollary 2 of Orabona &amp; Crammer (2010) for matrices. |M| X  X The first sum in the second square-root term is non-positive, as for i  X  M we have q &gt; i W i  X  1 p i  X  0 . We use Lemma 3 to bound the second square-root term with, q r min { m log det  X   X  1 N ,n log det  X   X  1 N } , which concludes the proof. We evaluated diagonal and factored AROMA on two data sets. First, we learned a semantic similarity between pairs of images in the Caltech-256 dataset (Griffin et al., 2007). Second, we learned a similarity measure between pairs of text documents using the 20-newsgroups data collected by Lang (1995). In both tasks we used standard 5-fold cross validation and report the precision on the test set. 5.1. Image similarity in the Caltech256 dataset We first tested AROMA in an image similarity task using the Caltech256 dataset. This dataset consists of 30 , 607 images that were obtained from Google image search and from PicSearch.com . Images were assigned to 257 cat-egories and evaluated by humans in order to ensure image quality and relevance. To allow a direct comparisons with the previous literature, we only used here 50 classes. We represent each image using a sparse code based on a bag of patch descriptors. Specifically, features are extracted by dividing each image into overlapping square patches, and describing each patch with edge and color histograms. For edge histograms, we used uniform Local Binary Pat-terns (uLBPs) (Ojala et al., 2002), which estimate a texture histogram of a patch by considering differences in inten-sity at circular neighborhoods centered on each pixel. We used uniform LBP 8 , 2 patterns, which means that a circle of radius 2 is considered centered on each block, and bins corresponding to non uniform sequences are merged. LBP patterns were then concatenated with color histograms. To form a sparse code, patch descriptors were mapped into codewords using a dictionary that was trained over a large set of images using k-means. Then, patch representa-tions were collected to represent an image as a sparse code. Each local descriptor was represented as a discrete index, called visterm , and the image was represented as a bag-of-visterms vector, in which components p i are related to the presence or absence of visterm i in p . The assignment of the weight p i of visterm i in image p was according to tf-idf weights. This approach has been found successful (for a related task) by Grangier &amp; Bengio (2008) and Chechik et al. (2009). We used a 1000-sized codebook, with a me-dian of 27 non-zero values per image and a maximum of 129.
 We compared the performance of AROMA with five other approaches. (1) HIER: Hierarchical semantic indexing , an approach that cleverly uses the known hierarchy among class labels (Deng et al., 2011). (2) OASIS: An online sim-ilarity model based on a ranking cost across triplets, simi-lar to the setup studied here (Chechik et al., 2009). It can be used to estimate the added benefit of using the covari-ance of the distribution in addition to the mean as AROMA does. (3) ITML/LEGO An online approach that succeeds to maintain a proper metric during learning in an efficient way (Davis et al., 2007) (4) LMNN: Large Margin Near-est neighbor , one of the early large margin metric learn-ing methods (Weinberger et al., 2005). (5) Euclidean dis-tance: equivalent to using the identity matrix W = I . The left panel of Fig. 3 compares the precision obtained with d-AROMA and f-AROMA with all other competing methods. Diagonal and factorized AROMA perform very similarly, with a slightly higher performance for factored AROMA. Both methods are significantly better than all other methods at the head of the top ranked images. At the top ranked image, AROMA improves precision by 50% over the second best approach (OASIS, from 22% to 33%). The middle panel of Fig. 3 traces the precision over the test set during training showing that convergence is achieved after 200 K  X  500 K iterations. In the beginning d-AROMA was slightly better than f-AROMA, but later f-AROMA converged faster. The right panel of Fig. 3 demonstrates that AROMA is largely robust to the choice of the regularizer r , with less than 5% change in precision across three orders of magnitude of r . 5.2. Document similarity, the 20 Newsgroups dataset In a second set of experiments we studied the problem of learning a similarity measure between pairs of text docu-ments. This task has numerous applications, such as find-ing content on the web that is related to a given text docu-ment. In this dataset, documents are divided to 20 classes, with about 1 , 000 documents in each class. Two documents were considered similar iff they share the same class labels. We used the 20 newsgroups data set (Lang, 1995) and re-moved stop words but did not apply stemming. We se-lected 1 , 000 terms that conveyed high information about the identity of the class (over the training set) using the infogain criterion (Yang &amp; Pedersen, 1997). The selected features were normalized using tf-idf , and then represented each document as a bag of words.
 The 20 newsgroups website proposes a split of the data into a train and test sets. We repeated splitting 5 times based on sizes of the proposed splits (a train-to-test ratio of 65% / 35%). We evaluated the learned similarity measures using a ranking criterion. We view every document in the test set q as a query, and rank the remaining test documents p by their similarity scores q &gt; W p . We then computed the precision (fraction of positives) at the top r ranked docu-ments. We further computed the mean average precision (mAP), a widely used measure in the information retrieval community, which averages over different values of r . With this dataset. we only compared with OASIS and ITML, the methods that achieved higher precision on the Caltech256 data. HIER requires to use a known hierarchy of classes which is not available for the 20NG dataset. The left panel of Fig. 4 shows the precision at the top ranked similar document. Clearly both AROMA methods outperform ITML and OASIS by large. The middle panel of Fig. 4 traces precision as it progresses through the learn-ing iterations. f-AROMA achieves higher precision than diagonal AROMA during most of the learning iterations, and in fact converges faster. d-AROMA reaches the same level after 500 K iterations. Interestingly, AROMA learns much faster than OASIS: it takes OASIS ten times more steps to get to the same precision (this effect is also true for the mean average precision). This precision gain is pre-served across a large regime of r values, as shown in the right panel of Fig. 4. We presented two algorithms that learn distribution over matrices. Both outperform state-of-the-art methods in two tasks, and model the covariance of the matrix distribution using a linear number of parameters. Diagonal-AROMA is likely to be superior when the variance of individual fea-tures is large relative to feature dependencies, and factored-AROMA is expected to be superior when the data has strong correlations across features, as with the Caltech256 data. Factored-AROMA also converged faster.
 Acknowledgements: KC gratefully acknowledges par-tia support by an Israeli Science Foundation grant ISF-1567/10.
 Cesa-Bianchi, N., Conconi, A., and Gentile, C. A second-order perceptron algorithm. Siam Journal of Commuta-tion , 34(3):640 X 668, 2005.
 Chechik, G., Sharma, V., Shalit, U., and Bengio, S. An on-line algorithm for large scale image similarity learning. In NIPS , 2009.
 Crammer, K., Kulesza, A., and Dredze, M. Adaptive regu-larization of weighted vectors. In NIPS , 2009.
 Information-theoretic metric learning. In ICML , 2007. Deng, J., Berg, A.C., and Fei-Fei, L. Hierarchical semantic indexing for large scale image retrieval. In cvpr , 2011. Dredze, M., Crammer, K., and Pereira, F. Confidence-weighted linear classification. In ICML , 2008.
 Duchi, J., Hazan, E., and Singer, Y. Adaptive subgradient methods for online learning and stochastic optimization. In COLT , pp. 257 X 269, 2010.
 Grangier, D. and Bengio, S. A discriminative kernel-based model to rank images from text queries. IEEE tran. on pattern analysis and mach. intelligence , 30(8):1371 X  1384, 2008.
 Griffin, G., Holub, A., and Perona, P. Caltech-256 object category dataset. Technical Report 7694, California In-stitute of Technology, 2007.
 Gupta, A.K. and Nagar, D.K. Matrix Variate Distributions . Chapman and Hall/CRC, 1999.
 Jain, P., Kulis, B., Dhillon, I., and Grauman, K. Online metric learning and fast similarity search. In NIPS22 , volume 22, 2008.
 Kulis, B., K.Saenko, and T.Darrell. What you saw is not what you get: Domain adaptation using asymmetric ker-nel transforms. In CVPR , pp. 1785 X 1792, 2011.
 Lang, K. Learning to filter netnews. In ICML , pp. 331 X 339, 1995.
 McFee, Brian and Lanckriet, Gert. Learning multi-modal similarity. In JMLR , volume 12, pp. 491 X 523, 2012. Ojala, T., Pietikainen, M., and Maenpaa, T. Multiresolu-tion gray-scale and rotation invariant texture classifica-tion with local binary patterns. IEEE tran. on pattern analysis and mach. intelligence , 24(7):971 X 987, 2002. Orabona, F. and Crammer, K. New adaptive algorithms for online classification. In NIPS , 2010.
 Weinberger, Kilian Q., Blitzer, John, and Saul,
Lawrence K. Distance metric learning for large margin nearest neighbor classification. In NIPS , 2005. Weston, J., Bengio, S., and Usunier, N. Wsabie: Scaling up to large vocabulary image annotation. In IJCAI , 2011. Yang, Y. and Pedersen, J.O. A comparative study on feature selection in text categorization. In Machine learning-
