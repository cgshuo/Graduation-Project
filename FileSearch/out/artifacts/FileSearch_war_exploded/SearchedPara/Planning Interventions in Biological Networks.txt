 DANIEL BRYCE
Utah State University and MICHAEL VERDICCHIO and SEUNGCHAN KIM Arizona State University 1. INTRODUCTION
Biological systems maintain their functions via various interconnections and regulatory controls among genes and proteins, and their interaction with other molecules. Therefore it is critical to unravel such interactions in order to un-derstand biological systems. Mathematical modeling and computational simu-lation of biological systems, especially gene regulatory systems, has been the crux of computational systems biology and biomedical science in general. Once a model is constructed, it can be used to predict the behavior of a system un-der unusual conditions, to identify how a disease might develop, and/or how to intervene in such development to prevent the system from reaching undesir-able states. Such models can aid biologists to rule out or confirm hypotheses before expensive wet lab experiments. In this article, we address the problem of planning to intervene in biological processes, focusing on gene regulatory networks (networks describing only genes) and organism-wide networks (in-cluding genes, proteins, and molecules). Specifically, we find plans that change the phenotype (stable behavior) of a biological process, as we describe next.
Biological networks . A biological network describes a process by a set of genes, proteins, and other molecules, and their influences over each other. Mod-els of biological networks are either constructed by hand or are learned from microarray data [Kim et al. 2000]. Microarray experiments measure the activ-ity levels of thousands of genes from living tissue in terms of mRNA concentra-tions (the products of gene transcription used to code proteins). Correlations between observed gene activity levels, for example, help describe regulatory influences through predictor functions.

In all of the systems that we study, predictor functions characterize the reg-ulatory influences and provide a dynamic model (e.g., when g active, g 3 becomes inactive). The state models the activity levels of genes and other entities, and the predictor functions describe possible next states. Suc-cessive applications of the predictor functions leads to a state sequence that demonstrates repeated states (called an attractor); these repeated states cap-ture the stable behavior consistent with a phenotype. Outside interventions (e.g., using RNA interference to suppress a gene X  X  activity level) alter predictor functions to control the dynamics of the network, providing a natural planning problem; changing the phenotype is of primary interest. In a plan, each ac-tion is either a possible intervention or nonintervention that will change the state of the system. We study three systems: yeast cell cycle, human aging, and melanoma (referred to by the most important gene, Wnt5a). The first two are manually constructed, while the last is learned from microarray data. We provide a biological interpretation of the plans constructed within each net-work, but refer the reader to prior related work on the derivation details of each network.

Planning . Planning is the problem of synthesizing a sequence of actions to transform an initial state into a goal state. A number of assumptions (e.g., full state observability, atomic duration actions, deterministic actions, etc.) in the classical model, when relaxed, give rise to several alternative models and types of plans. There are many features of the intervention planning problem that affect our choice of AI planning model. First, intervention plans need only focus on horizons long enough to ensure the network will naturally transition to stable sets of states. Biological knowledge and computational simulation of networks tell us that biological processes, left to their own, transition to (or through) stable attractor states that represent phenotypes [Kim et al. 2002;
Kauffman 1969b]. Phenotypes characterize common behavioral patterns of bio-logical systems, such as the cell cycle, accelerated or normal aging, and disease, such as the metastasis of cancer. From abnormal phenotype states, planning interventions provides a method to direct the evolution of the system toward other, favorable phenotypes. Second, the network has an inherently hidden state because full observations are prohibitively costly and we have limited accessibility [Datta et al. 2004]. Planning with partial observability is impor-tant because biologists analyzing biological processes cannot be expected to understand nor obtain complete state information. Third, cellular processes are commonly viewed as stochastic [Elowitz et al. 2002]. Genes are typically regulated in many different ways, meaning networks must allow for the prob-abilistic selection of predictor function for each gene. Because state transitions are stochastic, provide only partial observations, and are only relevant over a limited horizon, we formulate our model as decision-theoretic planning in a finite-horizon Partially Observable Markov Decision Process (POMDP) .
This work is not the first to address the problem of planning interventions for biological networks, but it is the first to: (i) apply AI planning techniques (aside from our preliminary work [Bryce and Kim 2007]), and (ii) consider planning to change the phenotype of a system. Existing research [Datta et al. 2004] enumerates all possible plans and then uses a dynamic programming al-gorithm to find the optimal finite-horizon plan, and considers problems where goal includes the change of a single feature (rather than reaching a new stable behavior, or phenotype). Our planner is based on the AO  X  1980], which uses upper bounds on plan quality (reward) for pruning. We eval-uate our planner on several problems with different reward functions to see the benefit of pruning.

Our planner performs significantly better than the enumeration algorithm of Datta et al. [2004]. Our study formalizes this interesting planning domain as a finite-horizon POMDP and shows the gains of applying relatively standard
AI techniques. We also make predictions of interventions that can change each of the three systems studied; one prediction, in the yeast cell cycle, was inde-pendently verified [Ferrezuelo et al. 2010] after we completed our experiments.
We start by providing background on the methodology used to model biolog-ical networks, and then describe a simple example of planning interventions in a Gene Regulatory Network (GRN). We then briefly define the components of a finite-horizon POMDP and an intervention problem. With these definitions, we map the intervention problem to the POMDP. The solution to the POMDP is a conditional plan, for which we define the semantics and describe two solution algorithms: AO  X  and enumeration [Datta et al. 2004]. We compare both algo-rithms within several networks that are either hand-crafted or learned from actual microarray experiments. We end with related work, a conclusion, and discussion of future work.
 2. METHODS
In this section we provide a brief overview of Boolean networks, which will serve as our formalism for describing the behavior of a biological process. Boolean networks . A Boolean Network (BN) [Xiao 2009; Wuensche 1998;
Kauffman 1969b] is made up of a set of binary variables and a corresponding set of functions which determine the state of the variables at the next time-step based on their values at the current time step. Connecting variables based on the inputs and outputs of these functions creates a wiring diagram structure, a graphical representation of the Boolean network.

The state transition system induced by a Boolean network with n nodes is a directed graph with 2 n vertices. Each of the vertices represents one possi-ble configuration of the n variables in the network and each of the directed edges representing the transition between two states as Boolean functions are synchronously applied to all variables.

In the absence of interventions and beginning in any initial state, repeated application of the functions will bring the network to a finite set of states and cycle among them forever in fixed sequence. This set of states is known as an attractor , and corresponds to a phenotype. An attractor with just one state is called a point attractor and an attractor with more than one state is called a cyclic attractor. The complete set of states from which a network will eventually reach an attractor is known as the basin of attraction (or basin) for that attractor. Boolean networks may have anywhere from one cyclic attractor comprised of 2 n states to 2 n point attractors, although a network will normally have just a handful of singleton or short-cycle attractors.

A Probabilistic Boolean Network (PBN) [Shmulevich et al. 2002a; Xiao 2009] is a stochastic extension of a BN that induces a Markov chain [Kim et al. 2002].
PBNs are closely related to Bayesian networks, differing in how the parents of a node determine its value. Our formulation in Section 4 uses these robust networks to allow probabilistic selection between several predictor functions that determine the next value of a variable. The advantage of a PBN over a Bayesian network is mainly seen from the model formulation perspective, because it admits fewer parameters (one number for each predictor function versus one number for each joint assignment of parents). We maintain consis-tency with prior work on biological systems [Kim et al. 2000; Datta et al. 2003, 2004; Shmulevich et al. 2002a] by using (probabilistic) Boolean networks, but there is no technical reason prohibiting reliance on Bayesian network models.
We focus on Boolean networks because of their simplicity, forgoing alterna-tive models such as those based on differential equations (which allow contin-uous states and time), in favor of larger-scale, albeit more granular, reasoning about change. Despite their simplicity, Boolean networks have been found to display many properties critical to biological processes, such as homeostasis and switch-like behavior [Kauffman 1969a]. Recently, Boolean networks have been used to simulate the yeast cell cycle [Li et al. 2004; Davidich and Born-holdt 2008], and the expression pattern of the segment polarity genes in the fruit fly, Drosophila melanogaster [Albert and Othmer 2003].

Each basin has a set of attractor states which correspond to the steady-state behavior of the system in that basin. The other states, while part of the basin, represent transitory anomalous states (e.g., in response to environmen-tal stress); the existence of these states, and the fact that the system (of its own accord) will transition from these states to the attractor states, corresponds to the conventional knowledge that biological systems are self-regulating [Li et al. 2004]. Thus, transitions within a basin result from the natural dynamics of the system.

Interventions . Of interest to this work are unnatural responses in the bio-logical system, introduced by what we call interventions, that can transition the system between phenotypes. Planning sequences of interventions is nec-essary, as we will show, because a single intervention is not always enough to transition between basins. In the problems we study, we will assume that the biological system starts in one of the attractor states of a basin (however, we may not know which attractor state), and construct a plan to reach any state in another basin . The intuition is that the initial state in the source basin will be one of the attractor states because these are the steady states of the basin, and it is enough to reach any state of the destination basin because thereafter the natural dynamics of the system will transition the state to one of the attractor states of the basin. 3. INTERVENTION PLANNING EXAMPLE
To clarify intervention planning, consider a small Boolean network with two genes, where each gene g i is either active ( g i )orinactive( predictor functions { f g describe the system dynamics, and an intervention to activate g by the predictor function f g predictor function definitions (center), the state transition system under the natural dynamics (left), and the state transition system subject to g tion (right). The system, subject to the natural dynamics, has two phenotypes, each with a basin of attraction and attractor. The first basin of attraction in-cludes states { g 1 , g 2 } , { g 1 ,  X  g 2 } , { X  g 1 ,  X  comprise the basin X  X  cyclic attractor, and { g 1 , g 2 } is an anomalous transitory state that leads to the basin. The second basin of attraction includes state { X  g 1 , g 2 } , which is a point attractor.
 A plan to change from the first to the second phenotype is depicted by Figure 2. The plan starts in a belief state that assigns equal probability to the attractor states of the first basin (because we know that the system exhibits the first phenotype, but we are unsure of which attractor state it is in). The belief state includes arcs for state transitions (attained from the predictor functions) corresponding to the action applied in the belief state. The initial belief state (the leftmost belief state) denotes that the g 2 intervention action is applied in it. We allow the practitioner to observe g 1 , meaning that after applying the first action, there is a branch in the plan for each outcome of the observation. In both of the subsequent belief states the plan applies the nonintervention action.
The upper branch follows with the g 2 intervention action, and the lower with nonintervention because the goal (reaching the second phenotype) is attained.
At a horizon of three, the plan guarantees reaching the second phenotype in all plan branches. 4. DECISION-THEORETIC PLANNING
Unlike most work on POMDPs 1 , which find a policy over the belief state space, we find a policy (conditional plan) rooted at an initial situation. The finite-horizon POMDP problem P is defined as the tuple S , A , T where S is a set of states, A is a set of actions, T : S  X  is a transition function, R : S  X  A  X  X  X } X  S  X  X  X } X  R is the transition reward function, is a set of observations, O : S  X  A  X   X  [0 , 1] is the observation function, h is the planning horizon, and b I : S  X  [0 , 1] is the initial belief state. We overload the symbol  X  to denote both the terminal action and state signifying the end of the plan.

Our rationale for selecting this POMDP formulation is twofold: (i) focusing on a plan for an initial belief state allows us to plan to transition from the states consistent with a particular phenotype (with which we are uncertain which is the current state), and (ii) we can compare with the prior work of Datta et al. [2004]. While we could plan for all initial belief states using a more traditional
POMDP value iteration algorithm [Kaelbling et al. 1995], many of the initial belief states are irrelevant to biologists, making the additional overhead un-justified. As we show in the following, the POMDP model is a natural choice of planning framework for reasoning with probabilistic Boolean network models of biological processes (incorporating probabilistic state transitions and partial observability of the initial phenotype states).

Intervention planning problem . In the following we show how an intervention planning problem maps to the POMDP. The intervention problem is defined by the tuple G , Dom , F , X , W , Y , O , h , where G is a set of variables (genes, pro-teins, and/or molecules), Dom is the set of activity levels for variables, F isaset of predictor functions, X is a set of interventions, W is an initial situation, Y is a goal description, O is a set of observations, and h is the horizon. The variables and their activity levels describe states of the POMDP, the predictor functions and interventions describe actions, interventions and the goal description de-fine the reward function, and the initial situation, observations, and horizon map directly to their POMDP counterparts.

States . Each variable g  X  G has an activity level from the domain Dom of values, of which we will only illustrate Boolean domains inactive. A state s : G  X  Dom of the network maps each variable to a value d  X  Dom . The entire set of network states defines the POMDP states S .Our choice of Boolean-valued variables is based on the previously mentioned prior work in Boolean networks used to model the biological process.

Predictor functions and interventions . Given a state of the network, the predictor functions F describe states reachable after one step. Interventions rewrite predictor functions in F for specific variables to ensure the network transitions to specific states. Thus, each possible action in the POMDP is de-scribed by a set of predictor functions. A nonintervention simply uses F to describe the action, but an intervention action corresponding to an x places predictor functions in F to attain a new set F x . Each intervention x is a set of predictors { f g
Each predictor function f g is defined as the mapping f g activity levels of variables in G  X  G to the activity level of variable g .
The interventions we describe in this work contain a single predictor func-tion f g where G = X  , meaning that irrespective of the state, g has its activity level set deterministically. We select this class of interventions because they are simple; however, our framework does not in any way prohibit alternative definitions of intervention predictor functions (e.g., we allow for multiple pre-dictors to model a stochastic intervention, or conditional predictor functions).
The potential drawback of assuming deterministic, unconditional interven-tions is that the intervention may not have the desired effect on the system (due to missing information about the conditions or stochastic nature of the in-tervention). This mismatch between model and system can be overcome when practitioners use the resulting intervention plans to guide their refinement of the model to match expectations put forth in the literature or their data.
Since each variable may be predicted by several predictor functions, where each state transition selects one probabilistically, we assign a weight each. While we assume the predictor functions are given, we can also learn them from microarray experiments. In the empirical analysis we evaluate networks where the predictor functions and weights are taken from the literature or from microarray data.

While we do not explore the option in this article, some alternative mod-els are based on context-sensitive (probabilistic) Boolean networks [Pal et al. 2005; Dougherty et al. 2009]. A context-sensitive PBN or BN defines alter-native sets of predictor functions for different states, in a similar manner to which intervention actions define alternate predictor functions. Our framework can be extended in a straightforward manner to incorporate context-sensitive networks.

Each action a F defined by the set of predictor functions F (similarly F describes the transition function probability where w g = f
Observations . After each step, whether by intervention or nonintervention, we can observe the state of the network. The set O  X  G defines which variables are observable (by genetic markers, physiology, etc.). The set of observations ={ o | o  X  Dom | O | } is defined by all joint activity levels of variables in this work, we assume that observations are perfect and the same for each action, meaning that if a state s and observation o agree on the activity level of each variable, then the probability of the observation is one (i.e.,
O ( s , a , o ) = 1), otherwise zero (i.e., O ( s , a , o ) = 0). Observations can be noisy (i.e., 0  X  O ( s , a , o )  X  1) in general. We assume perfect observations because if an observation proves useful in our model, biologists can typically design effective measurements to minimize any observation noise.

Rewards . The goal Y is a function describing desirable states. We assume that the goal maps states to real values Y : Dom | G |  X  R for terminal actions and goal states is defined by the goal R ( s assume that the reward associated with actions is negative one for intervention actions (i.e., R ( s , a F 0). The goal reward for each problem studied is related to the states of a desired target phenotype.
 Initial situation . The initial situation W is a distribution over states
W : Dom | G |  X  [0 , 1]. This mapping to the POMDP initial situation is straight-forward, b I ( s ) = W ( s ). The initial belief state in each problem is a distribution over the states of a source phenotype X  X  attractor; it is not clear which is the current state of the phenotype (basin of attraction), but we are certain of the currently possible set of states within the attractor. The reasoning is that we assume the system starts in a stable situation (after an sufficiently large num-ber of applications of F ), allowing us to rule out any of the transitory states in the basin of attraction; this means the system is in one of the attractor states.
In the goal formulation given earlier, we assume that any state in the target phenotype X  X  basin of attraction is sufficient because after the plan terminates the system will continue to apply F indefinitely and eventually reach the target phenotype X  X  attractor states.
 5. SEARCH
This section describes our approach to solving a finite-horizon POMDP. We start by defining the semantics of conditional plans and the search space. We follow with two search algorithms to find plans. The first algorithm is 1980], and the second Datta is based on a competing approach [Datta et al. 2004] from the computational biology literature; the difference between the algorithms relates to how the belief state space is expanded. We employ because it is a natural choice when the POMDP model requires an initial belief state and a finite horizon (limiting search to those belief states reached from the initial belief state within an acyclic search graph).

Conditional plans . A solution to the problem P is a conditional plan horizon h , described by a partial function  X  : V  X  A  X  X  X } space graph G = ( V , E ). A subset of the vertices b  X  V (which are belief states) are mapped to a  X  X est X  action a , denoted  X  ( b ) = a . Each edge e from b to b o a is mapped to an action a  X  A and an observation o denoted e ( b , b o a ) = ( a , o ). If  X  ( b ) = a and e ( b to execute after executing a in b and receiving observation o . Throughout our discussion, we assume that the horizon is a feature of every state to ensure that the graph G is acyclic. Belief states where the horizon is equal to h have a single available action  X  to signify the end of the plan, leading to a terminal
If  X  ( b ) = a , and there exists an edge e ( b , b o a ) defined where  X  is a normalization constant. If for all s  X  S , b vation is consistent with the belief state b a , then the belief state is not added to the graph. Also, if all child belief states are identical to the parent, then we do not add the children to the graph (which can happen when reaching a point at-tractor state, i.e., applying a nonintervention action and following the biological process predictor functions F leads to the same belief state indefinitely).
The expected reward q ( b , a ) of a plan that starts with action a at belief state b is the sum of current and future rewards where the expected reward for a belief state is V ( b ). Terminal vertices are assigned the expected goal reward AO  X  algorithm . We solve the finite-horizon POMDP problem with [Nilsson 1980] in the space of belief states. The AO  X  algorithm, listed in Figure 3, takes the planning problem as input, and iteratively constructs the belief space graph G rooted at b I . The algorithm involves three iterated steps: expand the current plan with the ExpandPlan routine (line 3), collect the ancestors Z X  of new vertices Z (line 4), and compute the current best partial plan (line 5). The algorithm ends when it expands no new vertices. In the following we briefly describe the subroutines used by AO  X  .

The ExpandPlan routine recursively walks the current plan to find unex-panded vertices (lines 2 X 5). Upon finding a vertex to expand, it generates all successors of the vertex (lines 7 X 18). Generating successors involves assigning the  X  action if: (i) the vertex is at the max horizon or (ii) all nonzero proba-bility states in the belief state are goal states (line 10). Otherwise, the search constructs the vertices reached by all action and observation combinations (lines 12 X 17). Notice that each vertex has its value initialized with an upper bound on its expected reward. The upper bound plays a role in pruning vertices from consideration in the search.

After expanding the current plan, ExpandPlan returns the set of expanded vertices Z. In order for Update (Figure 4) to find the best plan, given the new vertices, AddAncestors adds to Z X  every ancestor vertex of a vertex in Z. The resulting set of vertices consists of every vertex whose value (and best action) can change after Update . The Update routine iteratively removes vertices from Z that have no descendent in Z and calls Backup until no vertices remain in Z.
The Backup routine computes the value of a vertex and sets its best action. The reason Update chooses vertices with no descendent in Z is to ensure each vertex has its value updated with the updated values of its children.

AO  X  can often avoid computing the entire belief space graph G , leading to significant savings in problems with large horizons. By initializing vertices with an upper bound on their value it is possible to ignore vertices that have a consistently lowest upper bound. For example, in Backup action whose q-value is always greater than the alternative actions, then the best action will never be set to one of the alternatives. Further, because the alternative actions are never considered best, ExpandPlan them. As we will explore in the empirical evaluation, the reward function has a significant effect on the number of vertex expansions. In the worst case, it is possible to expand the entire graph G ,aswould Datta .
 Enumeration algorithm . In order to compare our planner to the work of Datta et al. [2004], we provide a description of their algorithm, we call in Figure 5. Unlike the iterative AO  X  , Datta consists of two steps: expand G with
ExpandPlanD , and then update each vertex v  X  V with Update routine recursively expands G by either reaching a terminal vertex at the maximum horizon (line 2), or generating and recursing on each child of a vertex (lines 4 X 8). Following ExpandPlanD , Update computes the best action for each vertex in V .

Unlike AO  X  , Datta is unable to prune vertices from expansion, making it insensitive to the reward function. While the result of the two algorithms is identical, the time and space required can be very different. We implemented both algorithms within our planner and demonstrate their effectiveness on the intervention planning problems. 6. BIOLOGICAL NETWORKS
Each biological network represents a different system, has different proper-ties, and has several intervention problems of interest. In the following, we describe each network in detail after first defining some simple metrics used in evaluation.

Network metrics. The first metric that we use to characterize the variables is their popularity [Verdicchio and Kim 2010]. A popular variable, in a particular phenotype (basin of attraction), holds the same value in many of the phenotype states. Variables with high popularity are good candidates for intervention targets because they can often determine the difference between phenotypes.
Another metric, the coefficient of determination (CoD) [Kim et al. 2002], is used to quantify the strength of a predictor function learned from the microar-ray data. As described next, the CoD metric was used, in part, to construct the Wnt5A network. The CoD provides a method to interpret the interven-tions used in a network based on their predictive influence over other network variables.

Yeast cell cycle network . Li et al. [2004] manually construct a Boolean net-work modeling the yeast cell cycle using eleven of the most important genes out of the approximately 800 genes known to play a role in the process. The cell cycle is the process by which cells replicate and involves several phases, such as DNA replication and mitosis. This network, when simulated, results in seven basins of attraction, one of which is by far the largest and was stud-ied exclusively in prior work. In this basin of attraction, which included 1,764 states, Li et al. were able to trace the trajectory of the yeast cell cycle from one of the fringe, or  X  X arden of Eden X  [Wuensche 1998] states down to the eventual point attractor.
 The yeast cell cycle network is comprised of the variables summarized in
Table I. The table indicates the common name for each variable, whether it can be used as an intervention to set the variable to true  X  or false variable is observable, and a brief description. 2 The yeast network is determin-istic, using a single predictor function per variable. Each intervention planning problem involves the first basin, as either the source or destination. The ratio-nale is that the first basin is the most biologically significant (representing the complete cell cycle) and accounts for nearly 86% of the states in the network.
By finding intervention plans either to or from the first basin, we determine how to restore or disrupt the network X  X  nominal behavior. The goal assigns ten rewards for reaching any state in the destination basin.

Aging networks . The systems biology of human aging is a complex, quanti-tative process. Many theories regarding senescence involve the roles of cellular components, such as mitochondria and lysosomes, as well the transportation and accumulation of various entities. In recent years, work by Furber [2010] has amalgamated the research of many prominent biogerontologists into a large chart illustrating many of the leading theories on human aging. The chart is organized into cellular components and describes many intricate, quantitative processes, along with their input and output entities. 3 Prior work [Verdicchio and Kim 2010] converted a significant portion of Furber X  X  qualitative network into a formalized Boolean network, which is shown schematically in Figure 6. In the figure, the pointed edges indicate activating regulatory influence and those with blunted edges indicate inhibitory regulatory influence. For example, ndna is activated if ndnarep is active and ros is inactive.

This network, when simulated (repeatedly applying F from different initial states), partitions the 2 18 unique states into three basins of attraction. The first and largest basin leads to what is classified as the  X  X nhealthy X  attractor, with all variables being fixed in undesirable configurations in the single attrac-tor state. The second-largest basin leads to what is classified as the  X  X ealthy X  attractor, comprised of a 9-state cycle. The smallest basin leads to what is clas-sified as the  X  X iddle-of-the-road X  attractor, which could not be called  X  X ealthy X , but fairly represents a state of  X  X verage health X  in its 3-state cycle.
The aging network is comprised of the eighteen state variables summarized in Table II. The network is deterministic, meaning that there is a single pre-dictor per variable, and the number of variables per predictor varies from one to three. The goal assigns ten rewards to reaching the destination basin, as in the yeast network.

Wnt5a network . The Wnt5a network centers around the Wnt5a protein, a product of gene WNT5A, which is a member of the Wnt family of proteins.
The WNT gene family consists of structurally related genes which encode secreted signaling proteins. These proteins have been implicated in oncoge-nesis (malignant transformation leading to the formation of a tumor) and in several developmental processes, including regulation of cell fate and pattern-ing during embryogenesis (embryo development) [Weeraratna et al. 2002].
Specifically, the expression level of Wnt5a is closely related with metastatic status (spread from one organ to another) of melanoma [Bittner et al. 2000].
It was proven experimentally that increasing the level of Wnt5a protein can directly change the cell X  X  metastatic competence [Weeraratna et al. 2002; Sos-man et al. 2004]. It has been also suggested that controlling the influence of
Wnt5a in the regulation can reduce the chance of the melanoma metastasizing [Weeraratna et al. 2002].

We will focus on a model constructed via various previous studies [Bittner et al. 2000; Kim et al. 2002; Weeraratna et al. 2002]. The focus is the network of elements of the Wnt5a signaling pathway that deal with the phenotypic change from a less motile, less aggressive cell to a much more motile, more invasive cell. Early attempts at constructing mathematical models of the network of genes showing shared regulatory information with Wnt5a resulted in the iden-tification of an interesting relationship between Wnt5a and Mart-1 (MLANA) expression [Kim et al. 2002].

The Wnt5a network is comprised of seven state variables corresponding to genes, summarized in Table III. Each gene is predicted by two predictor functions, each constructed with the pair of genes with the respective high-est and second-highest CoD for the gene, as given by the microarray data.
Each initial state for the network is given with the probability that it is afforded by the data (microarrays measure the activity levels of genes ex-hibiting a particular phenotype). The goal is to ensure that Wnt5a is inac-tive, so as to prevent metastasis. This formulation is slightly different from the yeast and aging networks because we do not plan to transition between basins, and is used to recreate the problems studied by prior work [Datta et al. 2004], which does not rely on basins and attractors. Without an ex-plicit basin as the goal, we are not guaranteed that Wnt5a will remain sup-pressed, rather we simply reach a state where it is suppressed. However, a suppressed or activated Wnt5a is consistent with the major phenotypes of the network.

We reproduce two intervention problems studied by Datta et al. [2004], and add a third. The first (denoted WP) directly intervenes to suppress Wnt5a (which happens to be the goal) and observes the Pirin gene. The second (denoted
PW) attempts to indirectly control Wnt5a by Pirin (a predictor gene of Wnt5a) intervention. The third (denoted MPW) adds a possible interevention for
Mart-1 to the PW problem; the predictor with the highest CoD for Wnt5a involves both Pirin and Mart-1. 7. EMPIRICAL EVALUATION
To test the feasibility of using our planner to solve intervention problems, we experiment with the three networks described in the previous section.
There are two primary research questions that we address in this experimental evaluation.  X  X o AI planning and search techniques improve upon prior work that solves intervention planning problems by dynamic programming?  X  X o the intervention plans exhibit biological significance?
We continue by briefly describing the test environment and planner implemen-tation, and discuss the two research questions with respect to each network.
Environment and implementation . Our planner, POND [Bryce et al. 2006], ran on a 2.0 GHz Xeon Processor in the Linux OS. Due to the volume of exper-iments, 4 each problem was given a 20-minute time limit and a 2GB memory limit; these limits were selected from preliminary data collection runs that showed no variation from the results presented to follow when using more generous limits. Results denoted by  X - X  indicate a failed attempt due to ex-hausted time or memory; in all cases time was the most limiting constraint.
For each problem we report the total time in seconds to synthesize a plan and the expected reward of the plan.

POND is written in C++ and uses the following technologies to improve its efficiency over a naive implementation of the AO  X  and Datta algorithms.
The actions are represented by Dynamic Bayesian Networks (DBNs) [Murphy 2002] and both the DBN conditional probability tables and belief states are represented by algebraic decision diagrams [Bryant 1986]. The problem in-stances are encoded in a modified version of the Probabilistic Planning Domain
Description Language (PPDDL) [Younes et al. 2005] to allow for probabilistic initial belief states and observations. 7.1 Yeast Cell Cycle Network The results in the yeast cell cycle network demonstrate that the Datta algorithm, and that the interventions chosen in the problems are supported by prior biological knowledge of the yeast network.
 Scaling . Table IV demonstrates the runtime results of the algorithms (denoted by  X  X  X ) and the quality of the optimal intervention plan, in terms of the initial belief state X  X  value V ( b I ) (expected reward). The table groups results for each problem into sets of three rows, and the columns denote the algorithms or value, the problem, and the result for a specific horizon.
As expected, the enumerative algorithm does not scale well with the horizon, whereas AO  X  scales much better. There is one unsolvable problem given the interventions provided (it is not possible to reach basin seven from attractor one).

The reason that AO  X  scales much better in this set of problems is that there are many belief states where all possible states satisfy the goal (acquire a nonzero reward) and allow early (prior to the maximum horizon) termination of plan expansion under the belief state (refer to line 9 of the
The enumerative algorithm has the same benefit of this truncated expansion, but will continue to expand other belief states that are reached by other, lower reward plans. This is the benefit of AO  X  : it always expands the belief states corresponding to the current highest reward partial plan, and high reward plans reach the goal (allowing such early termination). For example, the first problem (transitioning from attractor one to basin two) reveals one intervention plan that achieves the goal in one step.

Biological significance . As previously mentioned, with over 86% of the yeast cell cycle network state space covered by basin 1, planning interventions in this network was less a question of healthy versus unhealthy, as in the aging network, but more a question of normal versus abnormal. As Li et al. [2004] show, the entire cell cycle can be found within basin 1, and we aim to find out how to transition to and from basin 1 in our intervention plans. As shown in Table V, the variables selected for intervention include SBF, MBF, MCM1, Cln1,2, and Swi5. In our previous study [Verdicchio and Kim 2010], SBF and
MBF were found to be variables with high popularity in basin 1. As such, their selection is quite warranted. Furthermore, the selection of MCM1 makes great sense as MCM1 has relatively high popularity in basin 1. However, the selection of Cln1,2 and Swi5 are slightly more puzzling, as they had low popularity reported in the same study.

We see a trend in the selection of unpopular variables for intervention plans involving rare basins (i.e., basins 4 X 7, when combined, total just over 1% of the total state space). This is because these unpopular variables separate the basins of such small size. In one case, namely intervening on basin 1 to get to basin 7, no solution was able to be found, even with the use of unpopular variables. For the converse case, from basin 7 to basin 1, we see the use of the low popularity Swi5 variable, as basin 7 is only one single state, to make the difference to basin 1. Finally, we see the widespread use of the high-scoring variables for intervention plans to and from the larger basins as those variables define the biggest differences between the basins.
 As shown in Table V, the variables selected for intervention include SBF,
MBF, MCM1, Cln1,2, and Swi5. In our previous study [Verdicchio and Kim 2010] SBF and MBF were found to be variables with high popularity in basin 1. As such, their selection is warranted mathematically. Nonetheless, a recent report states that SFB and MBF are driving the transition of the yeast cell cycle [Ferrezuelo et al. 2010], as predicted by our intervention plan. We note that our prediction was made prior to Ferrezuelo et al. X  X  publication. 7.2 Aging Network The experiments in the aging network demonstrate the scalability of pared to the enumerative algorithm and have intervention plans of biological significance.

Scaling . The algorithms demonstrate scaling similar to the yeast network in the aging network. The aging network problems are somewhat more difficult to solve because the initial belief state is consistent with multiple states in all problems, but the network is also deterministic. Thus, the intervention plans include branching over observations.

An interest aspect of the plans in the aging network is that as the horizon increases, it is possible to find higher reward plans. For example, in transition-ing from attractor 1 to basin 3, only at horizon ten is it possible to increase the reward by using fewer interventions; our interpretation of this result is that waiting, and allowing the network to change without intervention, provides the opportunity to strategically plan the interventions. In transitioning from attractor 2 to basin 3, the increasing horizon allows more of the possible initial states (source attractor states) to reach the destination basin.

Biological significance. In investigating all pairings of attractors and basins for planning interventions, we are able to create intervention plans which correspond to natural aging and deterioration. As mentioned, basin 1 is a col-lection of states which all lead to an attractor representing the worst-case scenario healthwise. However, one characteristic of this basin was that every one of the states had the variable for dietary antioxidants set to false; this fact was capitalized upon in all problems involving basin 1. While our previous study [Verdicchio and Kim 2010] showed that the importance of dietary antiox-idants was elevated by certain network topology characteristics, its importance was nonetheless recognized and utilized in the formulation of the intervention plans. In addition to dietary antioxidants, ROS was also suppressed in the intervention plan to get from basin 1 to basin 3. Since this is an intervention from the larger unhealthy basin to a smaller, healthier one, a more exact plan was required; that plan utilized the variable with the highest popularity in the target basin, namely, ROS. Biologically this also makes sense, as ROS and antioxidants are found to be at cross-purposes within the cell: as ROS are dam-aging cellular entities which accumulate with age and deterioration, dietary antioxidants work to neutralize their effects. Thus, it is quite biologically rele-vant to see these two variables used in various combinations to intervene both as treatment and as aging effects.

To transition between basins 2 and 3, which represents differing degrees of health, more creative intervention plans need to be devised. First, consider the transition from basin 3 (less healthy) to basin 2 (more healthy). In basin 3, ROS was the variable recognized again as a critical intervention target; it had complete variable popularity in basin 3, and was suppressed or activated to make those specific adjustments needed to get to basin 2, depending on the starting state. Second, we discuss the intervention to get from basin 2 to basin 3. Because this intervention moves from a larger basin to a smaller one, and because it moves to a mid-range health status, the interventions were more complex. A total of five plan branches were generated, and each involved the aforementioned ROS, but also mitochondrial DNA (mtdna) in both suppressing and activating interventions, and mitochondrial proteins (mtprot) in suppress-ing interventions. Both of these new variables carried proportional popularity in both basins 2 and 3, so their selection is to be expected mathematically, but biologically they also control the health of the mitochondria and its DNA. By controlling either oxidative stress or DNA health in different branches, the plan transitioned between basins 2 and 3. 7.3 Wnt5a Network
The Wnt5a network is markedly different from the other networks in that it is a probabilistic Boolean network (there is more than one predictor per gene), and does not benefit as much from early truncation due to achiev-ing the goal in all possible states. We experiment with six variations of the problem of making Wnt5a inactive by using different interventions and ob-servable variables, and by using different reward functions. There are three configurations of the interventions and observable variables, either intervene by suppressing Wnt5a and observe Pirin (WP), intervene by suppressing Pirin and observing Wnt5a (PW), or intervene by suppressing Mart-1 or Pirin and observing Wnt5a (MPW). There are two possible goals, either a positive ten reward for suppressing Wnt5a (WP, PW, and MPW), or a negative ten reward for activating Wnt5a (WP X , PW X , and MPW X ). While the two goals are related, they affect planner performance by changing the upper bound on the reward function. The significance of the two goal formulations is that both place bias on plans that suppress Wnt5a, but the latter leads to more favorable pruning in the AO  X  search (as discussed in Section 6); knowing which formulation is better can aid practitioners during problem formulation.

Scaling . Table VIII lists results similar to the aging and yeast networks, but with an additional column to indicate the goal reward. When the goal reward is ten, AO  X  performs worse than the enumerative algorithm because the upper bound on the reward is very loose (compared to the optimal value found), forcing the search to evaluate nearly the entire search space searching for a better solution. The repeated belief state evaluation method used by leads to more belief state evaluations than the enumerative method (which evaluates each belief state once), and hence larger search times. When the reward is negative ten (and the goal is to activate Wnt5a) in all problems except PW X  because in both PW and PW X  it is difficult to control Wnt5a by intervening with Pirin. However, by intervening to suppress both
Mart-1 and Pirin it is much easier to control Wnt5a (leading to higher value plans).

Biological significance . Like the yeast cell cycle set of variables, the set of variables in the Wnt5a network have been selected carefully from a much larger list [Kim et al. 2002], and so the inclusion of any one in a particular plan is bio-logically sound. Even as such, as the allowable interventions and observations are not only based upon existing biological knowledge of the Wnt5a signaling pathway, but also behave in accordance with it, we are able to justify each plan as biologically significant. We saw that allowing both Pirin and Mart-1 inter-ventions improved the chance of suppressing Wnt5a over the use of Pirin alone, which fits with how Pirin and Mart-1 are involved in a high CoD predictor for
Wnt5a. 8. RELATED WORK
Prior work related to our approach can be categorized into techniques for reasoning about and simulating biological systems as Boolean networks, approaches for controlling such biological systems, and algorithms within artificial intelligence.

Boolean networks . Studies of genetic regulatory networks can take many forms; some attempt to merely determine associative or predictive relations between genes, others seek to model network dynamics to the smallest biolog-ical nuance. A number of models have been proposed to study gene regulatory networks [de Jong 2002]. The complexity ranges from simplistic models such as
Boolean networks [Kauffman 1969b; Kauffman 1993] to more complete and in-tricate models based on differential equations [Goutsias and Kim 2004, 2006].
Evaluation of these models is done, as in this work, by examining how ac-curately the model reflects actual biology and the difficulty of inference in a specific instance of the model [de Jong 2002]. In general, the more low-level detail that is added, the more difficult to reconstruct the network from data.
Studies have shown that Boolean network models exhibit a number of bio-logically interesting properties [Kauffman 1969b]. Boolean networks primarily focus on determining gene-gene interactions at a qualitative level, instead of quantitative aspects. Additionally, Boolean networks can provide insight into cellular states. Both the steady state and switch-like behavior of cells can be captured and studied with a Boolean model [Kim et al. 2000]. The ability to model both of these behaviors allows the analysis of common functions of the cell such as cell growth and cell cycle, as well as the response to external stimuli. Beyond Boolean models, models can add a stochastic component, such as in PBNs and Bayesian networks [Murphy and Mian 1999; Friedman et al. 2000;
Hartemink et al. 2001]. The addition of the stochastic component attempts to model both intrinsic and extrinsic noise in gene regulatory networks [Elowitz et al. 2002]. In probabilistic Boolean networks, as in traditional Boolean networks, Boolean functions are used to determine the next state of the net-work. Unlike traditional Boolean networks, however, there is not a single func-tion corresponding to a network state. The next state of the network is deter-mined via selection of Boolean function from a set of valid Boolean functions based on the current state. PBNs have been studied using Markov chains and shown to demonstrate both homeostasis and the switch-like properties exhib-ited by actual biological systems [Kim et al. 2002].

Controlling biological systems . Planning interventions in biological systems has been previously studied within the context of control theory, specifically, controlling Markov chains. AI planning and control theory have rich connec-tions, and these similarities provide a common ground on which the empirical evaluations described herein are based. The primary approach of previous work [Datta et al. 2003, 2004] on formulating intervention planning as a control prob-lem was to characterize a dynamic programming operator that could identify the intervention to make in any state of the biological process. In this formal-ism, Datta et al. [2003] formulate the problem as a fully observable Markov decision process and explore finite-and infinite-horizon control. Datta et al. [2004] also explore an extension to partial observability with finite-horizon control. In both works, the underlying dynamics of the networks is based on probabilistic Boolean networks and the techniques are evaluated within the Wnt5a network.

Artificial intelligence approaches . Some recent works in the AI community have focused on simply representing biological processes. Khan et al. [2003] seek to discover signal transduction pathways with a deterministic classical planner. The actions in the plan represent various chemical reactions, and the goal of the plan is to establish that there is a sequence of actions leading to an event, such as transcription. This particular planning problem has received considerable attention due to its inclusion in a recent International Planning
Competition. The most significant differences from the work described in this article, are that the model is assumed deterministic, is at a finer level of gran-ularity (modeling many cellular products), and is primarily concerned with modeling the problem (versus exploring appropriate solution techniques). Further along this vein of improved models of change in biological processes,
Tran and Baral [2005] model change in biological processes as exogenous ac-tions, termed triggers. In the planning considered in this work, the plans con-tain actions that represent both intervention and nonintervention, where the actions respectively model how the GRN changes under outside influence or naturally. Tran and Baral factor out the model of natural change in the biolog-ical process, representing it as triggers which plans can only indirectly affect.
Actions become much simpler in that they describe only the change due to the intervention. 9. CONCLUSION AND FUTURE WORK
We have presented a formulation of biological network intervention as decision-theoretic planning. Our planner relies on several AI planning tools to perform efficient reasoning. As a result, we have improved the scalability of planning interventions over previous work.

We have shown that AO  X  is a viable approach to solving biological in-tervention problems. Where the Datta algorithm quickly exceeds our time limit as the horizon increases, AO  X  can scale to larger horizons. Using three biological networks of practical interest, we have seen that by pruning vertices based on upper bounds. Each of the networks studied led to biologically supported intervention plans that may have been otherwise chal-lenging to construct manually, supporting our claim that automated planning can supplement a biologist X  X  understanding of a system. The yeast network plans led to an interesting prediction of an intervention target that was inde-pendently verified after our experiments and prior to the publication of this work.

In the future, we would like to decouple the representation of cellular pro-cess dynamics from our intervention actions. We think the right approach is to use exogenous actions or processes. While recent work in deterministic planning [McDermott 2003] has discussed models for controlling exogenous processes and triggers [Tran and Baral 2005], less thought has been given to such processes in a probabilistic setting (with the exception of Blythe [1994]).
Alternatively, work on simulating cellular processes [Ramsey et al. 2005] has considered probabilistic exogenous processes, but not under the control of a planner.

We thank A. Choudhary and E. Dougherty for their helpful suggestions while preparing this work.

