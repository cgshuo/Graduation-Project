 In man y binary classification tasks, the aim of the classifi-cation is to sort the observ ations into a list so that the mi-nority class observ ations are concentrated towards the top of the list. That way, if, due to limited resources, only a small subset of all observ ations are acted upon, the sort-ing will enable a high percentage of the observ ations of interest (the minority class observ ations) to be included in this subset. In other words, for a given cut-of f, or decision threshold, it is desirable to have as man y as possible of the minority class observ ations abo ve the threshold (high true positi ve rate) together with as few as possible of the ma-jority class observ ations (lo w false positi ve rate). Graph-ing the true positi ve rate against the false positi ve rate as the decision threshold is varied yields the Recei ver Oper -ating Characteristic, or ROC curv e. The area under the ROC curv e, or the AUC, is a decision threshold indepen-dent measure of classifier goodness, and has often been used as such (Bradle y, 1997; Weiss &amp; Pro vost, 2001). Most binary classifiers, howe ver, have as their objecti ve function some other measure, such as mean square error , or one-sided linear or square penalty . When the real ob-jecti ve is to optimise the sorting order , such classifiers are actually solving the wrong problem. Hence the y are lik ely to perform sub-optimally when the performance measure is the AUC. This has been found to be the case empirically on a wide variety of datasets (Perlich et al., 2003). Similarly , if the classifier X  s objecti ve function is closely related to the AUC then it yields models with better AUC (Yan et al., 2003; Cortes &amp; Mohri, 2004).
 In this paper , we introduce RankOpt, an algorithm that op-timises the AUC directly . RankOpt searches for the linear model that is optimal for the AUC, using gradient descent to optimise the model coef ficients. It is compared with a number of other linear binary classifiers, namely: linear regression (used as a classifier), an SVM with one-sided linear penalty (SVM-L1) (Cristianini &amp; Sha we-T aylor , 2000), an SVM with one-sided square penalty (SVM-L2) (Joachims, 1998; Platt, 1998; Vapnik, 1998), and the cen-troid classifier (Rocchio, 1971).
 Section 2 describes RankOpt X  s objecti ve function. Sec-tion 3 discusses details of RankOpt X  s algorithm, and several issues of rele vance to gradient descent, including the pos-sible existence of local minima, and selection of a starting point. Section 4 describes the experimental procedure, and the datasets that RankOpt was tested on. It also includes the results. Related work is discussed in Section 5, follo wed by conclusions and future work in Section 6. Consider a rectangular dataset of iid observ ations, dra wn from a population. The dataset contains P minority class and Q majority class observ ations, x j j 1 P , and x k k 1 x i j i 1 m , where x i j is the j th instance of random variable X i . Lik ewise, x j is the j th instance of vector r.v. X . Equi valent definitions hold for the majority class. A single boolean valued tar get variable defines the class of any observ ation. Consider an observ ation pair , consist-ing of one observ ation chosen at random from each class x j x k . The AUC of a model on a given dataset can be expressed as the probability that for such a random ob-serv ation pair , the score of the minority class observ ation is greater than that of the majority class observ ation (Bam-ber , 1975). If the model is linear , with the coef ficients of the predictor variables given by vector  X  , then ignoring ties, This is simply the Mann-Whitne y statistic (Mann &amp; Whit-ney, 1947) scaled by 1 hea viside function defined as is an unbiased estimator of the AUC. 2.1. The Rank Statistic Since the hea viside function is undif ferentiable, it is re-placed by the sigmoid function s x 1 1 e x (Yan et al., 2003), in order to apply gradient descent. We refer to the resulting approximation to the AUC as the sigmoid rank statistic, or simply the  X  X ank statistic X , R  X  , defined as Note that lim x  X  s x g x , so that for lar ge  X  the sig-moid rank statistic is a good approximation to the AUC. It is everywhere dif ferentiable, and its first few deri vatives are all tightly bounded. It is straightforw ard to verify that The value of the AUC statistic, which is the true objecti ve function, depends on the direction of  X  only and not on its magnitude. The rank statistic, on the other hand, de-pends on both the magnitude and the direction of  X  . Ho w-ever, at lar ge  X  the rank statistic is a good approximation to the AUC, hence for  X  lar ge enough, the rank statis-tic is also nearly independent of  X  . Hence we may ap-proximate a classifier which optimises the AUC by opti-mising R  X  , constrained to the hypersphere  X  B , in  X  -space, with B fix ed and fairly lar ge. Formally we are af-ter  X  OPT argmax R  X  s.t.  X  B , where the value of B is determined as described in Section 3. 2.2. Computational Efficiency Note that the computational comple xity of the rank statistic R  X  is O n 2 in the number of observ ations. A calculation of this comple xity must be carried out at every step of the gradient descent algorithm, which is prohibiti ve. This calculation can be simplified as follo ws. Observ e that the arguments to the sigmoid function in R  X  have a high degree of interdependence. Specifically , for any two mi-nority class observ ations x j serv ations x k For the four observ ation pairs formed by combinations of x j x j 2 x k 1 , and x j 2 x k 2 , the argument to the sigmoid function for any one of these is fully determined by the other three. This means that using all PQ observ ation pairs to calculate the R  X  is wasteful. The follo wing alternati ve is therefore proposed.
 Randomise the order of the observ ations. Then balance the data by rec ycling the P minority class observ ations until both classes have Q observ ations. Then in the rank statis-tic, only consider observ ation pairs which consist of the k mod P -th minority class observ ation paired with the k -th majority class observ ation, k 1 follo wing linear rank statistic, which is O n in the number of majority class observ ations, Unlik e R  X  , in R l  X  no argument to the sigmoid function can be fully determined by any others. Note that R l  X  is not uniquely defined, as it depends on the ordering of the observ ations. Nonetheless for any random ordering, the ar-guments in the remainder of this section hold.
 Clearly , for any fix ed  X  , E R l  X  the variances compare? We would lik e to kno w how much greater the variance of R l  X  is than that of R  X  . Specif-ically , we are interested in the value of var we refer to as the  X  X f ficienc y loss X , L e . Consider firstly var R  X  . This sum of PQ 2 covariance terms consists of: i) PQ terms where j 1 j 2 and k 1 k 2 , for which the co-variance term simply reduces to var s  X  x j x k ii) PQ Q 1 terms where j 1 j 2 and k 1 the covariance is cov s  X  x j x k iii) PQ P 1 terms where j 1 covariance cov s  X  x j For all other terms j 1 nature of the data, these have zero covariance. This gives the follo wing expression for the total covariance. var R  X  PQ Assuming that P Q
V , this can be simplified to The validity of this last assumption has been verified em-pirically on several datasets used in experimentation. No w repeat this process for var R l  X  1 The calculation of this variance is similar to that of R  X  . This time we consider the 3 covariance components: i) k 1 k 2 , ii) k 1 mod P k 2 mod P but k 1 and iii) k 1 mod P Let us now consider the ratio of these variances, L e . For hea vily imbalanced data ( Q have V 2 L datasets used in our experimentation that V 1 assumption appears quite safe. So R  X  has no adv antage over R l  X  Consider , therefore, balanced data. For P Q , cancelling common terms lea ves the variance ratio to be V 1 V 2 V . For small  X  , the sigmoid is linear , so By symmetry , V 2 This lea ves only the case of balanced data, with lar ge  X  . For this case, we determine the efficienc y loss empirically . On several datasets used for experimentation, L e was mea-sured for a value of  X  near the gradient descent solution. In each case it was found to lie in the range 1 5 2 . This means that if we are using R l  X  instead of R  X  , one would need roughly 1.5 to 2 times as much data to get an estima-tor of the same variance. When one considers that R l  X  is P times more efficient to calculate, we have an overall gain in computational efficienc y of at least P 2. Since P is typ-ically at least in the hundreds, using R l  X  instead of R  X  affords an enormous efficienc y gain. The various components of the RankOpt algorithm are dis-cussed in detail in the follo wing subsections. Pseudocode is also sho wn in Table 1. 3.1. Gradient Descent To simplify notation, we define new random variables, Z nority and majority class r.v. X  X . Then using the definition of the gradient of the sigmoid from Section 2, and the defini-tion of R l  X  in Eq. 2, we have  X  R l  X   X  X  i Since the gradient descent algorithm is constrained to the hypersphere  X  i  X  2 i B , first calculate the unconstrained gradient using Eq. 4, and then calculate its component in the direction of the hypersphere surf ace (i.e. perpendic-ular to  X  ). Then tak e a small step in this direction, and rescale to mo ve back to the surf ace  X  i  X  2 i B . Iterate un-til a minimum is reached. (Since R l  X  is symmetric, i.e. R l  X  1 R l  X  , it is immaterial whether we talk in terms of minimisation or maximisation.) The step size, or learning rate, is increased slightly at each iteration so long as the new value of R l  X  is smaller than its current value. Otherwise, the learning rate is decreased until the new value of R l  X  that will result from taking the step will be smaller than its current value, and only then is the step actually tak en. Thus we guarantee that the value of R l  X  on training data will decrease at every iteration. 3.2. Selection of Hyperspher e Radius Value If the hypersphere radius, ments to the sigmoid function will generally be small, and the rank statistic will be a poor estimator of the true AUC. Alternati vely , if B is too lar ge, the rank statistic approaches a sum of step functions, and the rank surf ace starts to con-tain man y small regions that are nearly flat, connected by extremely steep inclines, much lik e steppes on a mountain-side. This tradeof f has been observ ed by Yan et al. (2003). Such a surf ace is hard to do gradient descent over. To avoid the problem of choosing a value for B , we use the data to calculate a series of increasing B values as follo ws. The rank statistic is a sum of sigmoids with dif ferent ar-guments, where the arguments depend on the data. De-fine  X  X aturation X  of the sigmoid function as being when the magnitude of its argument is 5. These are the almost flat extrema of the sigmoid function. (That is the sigmoid returns a value in the range 0 Then define the probability of sigmoid saturation as be-ing the probability that for a randomly chosen observ a-tion pair , x j x k , the sigmoid function saturates, i.e. Pr of B , such that each value of B corresponds to a probability of saturation (on the training data) from the increasing se-ries p . Typically p 0 1 0 3 0 5 0 7 0 75 0 8 we end with a probability of saturation R l  X  is very close to the true AUC.
 Ha ving generated the sequence of B -values, start with the smallest one, and perform gradient descent as described abo ve until the minimum R l  X  is reached. Then mo ve to the next smallest value of B , which will change the rank surf ace, and hence the position of the minimum. Continue gradient descent, starting with  X  such that its direction is the same as that of the  X  where the pre vious gradient de-scent stopped. Repeat this process iterati vely , increasing B at each iteration, until the sequence of B  X  X  has been ex-hausted. This way, by the time the problem of  X  X teppes X  begins to arise, almost all of the gradient descent has al-ready been done. 3.3. Local Minima In performing gradient descent, one must contend with the possibility of local minima on the error surf ace. In this section it will be demonstrated that for a wide variety of datasets local minima are unlik ely to play a significant role. By the standard definition of expectation E AUC  X  where f z is the joint p.d.f. of the Z i  X  X .
 Con vert cartesian to spherical co-ordinates where  X   X  1  X  2 m 1 -dimensional angle vectors. The inte gral becomes E AUC r  X  is the Jacobian for the change of co-ordinates and f s  X   X  is the p.d.f. of r  X  , expressed in the m -dimensional spherical co-ordinate system. Since only the sign of the argument to g matters,
E AUC  X  E AUC  X  mensions, as follo ws.
 h  X  is the mar ginal p.d.f. of the m 1 -dimensional solid angle  X  . Since g cos is a rectangle function, and con volution with a rectangle function has a smoothing ef-fect which will tend to eliminate local extrema, we can assert that if h  X  is unimodal, then E AUC  X  unimodal. Further , even if h  X  is multi-modal, the lo-cal extrema may well be eliminated by con volution with g cos .
 This, howe ver, holds for the expected rank error , which is what the surf ace AUC  X  approaches as the amount of data approaches infinity . In reality the amount of available data is finite, so some local minima may arise due to noise -i.e. AUC  X  fluctuates around its expected value. Given suf ficient data, these fluctuations will be small, and hence should be close to the location of the expected minimum, where the gradient of E AUC  X  verified empirically by graphing the error surf ace for a va-riety of three dimensional problems  X  as the amount of data increases, the local minima mo ve closer to one another and become fewer , until there is only one. 3.4. Starting Point Since local minima do not play a significant role, the se-lection of a starting point for gradient descent should have minimal impact on the final solution. It may howe ver have an impact on computational efficienc y. Hence it is desirable to find a starting point that is lik ely to be close to the final solution. Intuiti vely , if a predictor has a lar ge dif ference in class specific means, it should be an important predictor in the model. Also if the class specific variances for a given predictor are low, it should also be an important predictor in Table 1: Pseudocode for RankOpt algorithm with PSF for i = 1 to # of PSF sub-f olds (Section 3.7)
B (Section 3.1) calculate the final  X  value by avera ging  X  i over all i the model. Defining  X   X  i E X i E X i to be the dif fer -ence in class specific means, or the  X  X lass separation X  for predictor i , and V i var X i var X i to be the  X  X lass specific variance X . we select as a starting point In practice, we linearly scale every predictor variable x  X   X  i V i , so that in the scaled space our starting point be-comes simply  X  1 1 3.5. Plateaus Plotting the R l  X  surf ace for a wide variety of three dimen-sional datasets sho wed that indeed local minima only occur where the y are explainable by the finite nature of the data. Ho we ver the underlying minimum is often very broad, with a low gradient  X  X lateau X  around it. It is dif ficult to do gradient descent across these plateaus, since even a small amount of noise creates local minima. Handling these is a subject of its own, beyond the scope of this paper . For now we settle for developing a heuristic based linear rescaling, to partly eliminate plateaus. This is applied in addition to the scaling of Section 3.4. 3.6. Model Selection Rule Recall that in Eq. 2 an O n rank statistic was defined. Note that one could easily offset either the minority or majority class data relati ve to the other by a observ ations, a 1 R l a  X  has the same mean and variance for all values of a . For any a but it nonetheless yields a con venient validation set which is at least partly independent of the training set, and comes at no extra cost (in the sense that it comes wholly from within the training data). To see exactly to what extent this validation statistic is independent, we would lik e to find the value of cor r R l  X  R l a  X  where a 1 all a 1 a 2 , so simplify the abo ve expression as follo ws. var R  X  dividing by 1 P var R l  X  Given the range of values of L e found empirically in Sec-tion 2.2, we can safely assume that P L This gives values of cor r R l  X  R l a  X  Recall (Section 3.2) that training involv es a series of gra-dient descent runs with increasing values of B , each one con verging to its own local minimum. Which one of these minima do we select as being closest to optimal? A first guess might be that the  X  corresponding to the lar gest value of B should be selected, but this tends to cause overtrain-ing. So we select the  X  which minimises R l a  X  , for some arbitrarily chosen value of a . It was found empirically that despite the correlation between the training and validation statistics, such a selection rule usually results in a model that is very close to optimal on the test set. 3.7. Sub-F olds The existence of a semi-independent rank statistic, R goes beyond development of a model selection rule. It can be used to supply a second, albeit correlated, training set, which can be used to augment the training itself. One can execute two totally separate gradient descent train-ing runs, one in which the error surf ace is defined by the statistic R l  X  , and the other in which it is defined by R optimal  X  , which are at least partially independent. Intu-itively , averaging these two estimates is lik ely to yield a better test result, because any error components that are in opposite directions will cancel.
 We refer to this technique as pseudo sub-folding (PSF). PSF can be extended, of course, to more than two sub-folds. Two sets of experiments were performed. The first tests the performance of RankOpt with various settings of PSF , namely: no PSF; PSF with two sub-folds (PSF2); and PSF with three sub-folds (PSF3). The second set of experiments compares the best of these with the other linear classifiers. For the SVM classifiers and the centroid classifier , the scal-ing of the data can significantly impact the classifier X  s per -formance. Further , the SVM classifiers X  performance can be significantly affected by the penalty parameter of the er-ror term. The SVM X  s and the centroid classifier were there-fore run with both the same scaling as RankOpt, and with no scaling at all. Further , the SVM X  s were run with three dif ferent values of penalty parameter  X  10, 10 3 , and 10 5 . In each case the best result only is quoted. 4.1. Datasets Experiments were performed on eight datasets, from dif fer -ent domains and of dif ferent levels of dif ficulty . The minor -ity class was typically between 10% and 40% of the data. Forest Co ver Type (forest) : Data was downloaded from the UCI KDD repository . It classifies 30 forest into one of seven cover types based on the cell X  s dom-inant tree type. The two most populous classes (Spruce-Fir and Lodgepole Pine) were extracted, and the binary clas-sification task consisted of distinguishing between these classes. A total of 10 predictors were used, these being the 10 continuous predictors supplied for the data. Housing Mortgage (housing) : Data was downloaded from the U.S. Census Bureau 5% Public Use Microdata Sample (PUMS) containing indi vidual records of the characteris-tics of a 5% sample of housing units for the state of Florida. Amongst all housing units which had a mortgage, the bi-nary classification task was to distinguish between those for which the mortgage had been paid off and those for which it hadn X  t. The 12 continuous or ordinal predictor variables in-cluded the total household income, the room and bedroom counts, rate costs (electricity , water and gas), the property tax rate, insurance rate and property value.
 Telecommunications Chur n (chur n10 and chur n31) : Data on mobile phone customers of a lar ge telecommunica-tions carrier was used to learn to distinguish between those that churned to a competitor in the follo wing three months and those that didn X  t. After rebalancing, 1 the minority class was variables was used for prediction, including bill and prod-uct information. Further , a subset of 10 of these predictors was selected, none of which were particularly predicti ve, resulting in a dif ficult to learn task. This made up a second telecommunications binary classification task.
 Marital Status (married) : As for the housing mortgage dataset, data was downloaded from the U.S. Census Bu-reau PUMS. From this dataset a 1% sample of indi vidual records from the state of California was extracted. The bi-nary classification task was to distinguish between indi vid-uals who have been married (whether currently married or not), with indi viduals who have never been married. The predictors were 11 continuous variables, including ones re-lating to age, education level, income, and working hours. Intrusion Detection (intrusion) : This dataset consists of a random sample of the intrusion detection data used for the 1999 KDD Cup competition. The classification task was to distinguish between normal use and intrusion. The 10 predictors used were a subset of all continuous predic-tors available with the data, as certain continuous predictors were omitted to mak e the problem more challenging. Hand written Digit Recognition (digit) : Data was down-loaded from the MNIST handwritten digit database. Each observ ation in this dataset consists of a bitmap of 28 grayscale values, representing a handwritten digit. Each observ ation was con verted to lower resolution (7 to reduce the dimensionality of the problem. The classifi-cation task was to distinguish between the digit  X 0 X  and all other digits. To mak e the problem more challenging, only the top 3 rows of pix els (21 pix els) were used. Further , pix-els near the corners which contain almost no information were discarded. The result was a 17 dimensional dataset. Weather Season Pr ediction (weather) : There is a grid of weather buoys in the equatorial region of the Pacific Ocean. These tak e meteorological measurements, including wind speed and direction, air and sea temperature, and humidity at regular interv als. The resulting data is available at the website of the Tropical Atmosphere Ocean project. Hourly measurements for all buoys over the period from May 1999 to April 2000 were downloaded. The classification task was to distinguish meteorological readings made during the northern hemisphere Autumn months (October , No vember and December) from those made in other months. 4.2. Experimental Pr ocedur e To lend statistical significance to our results, it is desirable to apply each classification method to a lar ge number of independent training sets, and average the AUCs of the re-sulting models on the test sets. This necessitates that the training sets for multiple runs of each algorithm be mutu-ally exclusi ve of one another . Hence each dataset was split into n mutually exclusi ve folds, and in each run of each classifier , training was performed using one fold, and the resulting model was tested on the remaining n 1. With the exception of the digit dataset, which contains 60,000 observ ations, each of the datasets contains a minimum of 180,000 observ ations. So from each of these datasets 180,000 observ ations were randomly selected. These were split randomly into 60 mutually exclusi ve folds ( n 60), with 3000 observ ations each. 60 runs of each classification algorithm (RankOpt, linear regression, SVM-L1, SVM-L2, and centroid ) were then performed, each using a dif ferent one of the 60 folds for training (and hence validation), and the other 59 for testing, as described abo ve. This yielded 60 test results for each classifier for each dataset. This experimental procedure was then repeated using dif ferent amounts of training data  X  30 folds of 6,000 observ ations, 15 procedure for the digit dataset was identical except that the number of folds was divided by 3 in each case. 4.3. Effect of PSF Figure 1 sho ws the results of the first set of experiments, namely , measuring the effect of PSF on RankOpt X  s perfor -mance. We measure the mean of the AUC on the test sets (y-axis), at each training data quantity (x-axis), for all eight datasets, for all three PSF settings. Vertical bars sho w a one standard error confidence interv al. The standard error did not vary much with training set size, hence it is sho wn for one training set size only . It appears that PSF has a benefi-cial effect for all datasets except for churn10, intrusion, and perhaps weather , where it has no significant impact. Ho w-ever the dif ference between PSF2 and PSF3 is minimal for all eight datasets. Therefore, for the purposes of comparing with other classifiers, we select RankOpt with PSF2. 4.4. Comparison with Other Linear Classifiers Figure 2 sho ws how RankOpt with PSF2 compares with the other classifiers. The meaning of the axes is as in Fig-ure 1. The SVM-L1 algorithm is computationally inten-sive, and results could not be generated in reasonable time for any more than 6000 training observ ations, so only these are sho wn. Error bars are not sho wn as the y are mostly insignificant relati ve to the dif ference in classifier perfor -mance. For six of the eight datasets, RankOpt is a clear winner . For the forest data, linear regression is compara-ble to RankOpt, even outperforming it when the amount of training data is limited, and SVM-L1 performs only mar ginally worse than RankOpt. For the digit data, SVM-L2 performs only mar ginally worse than RankOpt. The simple centroid classifier is usually by far the worst, and often doesn X  t even mak e it onto the chart. Note that there is no clear  X  X unner up X  to RankOpt amongst the other clas-sifiers, with each being far worse than RankOpt at least oc-casionally  X  linear regression fails to mak e it on to the chart for the housing dataset, and the SVM X  s fail to mak e it on to the chart for the weather dataset.
 It is note worthy that the SVM and centroid classifiers are highly sensiti ve to how the original data are scaled. SVM X  s also have the dra wback that the y require a penalty parame-ter to be set, and results can be quite sensiti ve to this. For the churn dataset with 31 dimensions, the linear regression package occasionally reported a warning that the matrix was ill-conditioned, and hence results may be unreliable. It is expected that this problem would arise with increasing frequenc y as the number of predictors increases. In terms of computational efficienc y, it is worth noting that unlik e some other linear classifiers, RankOpt is linear in both the number of training observ ations and in the num-ber of predictors. Since neither the RankOpt code nor the SVM code used to this point has been optimised, it would be dif ficult to dra w any conclusions from a direct compari-son of execution times of the various classifiers. We note that other algorithms have been developed in which the objecti ve function closely approximates the AUC (Yan et al., 2003; Cortes &amp; Mohri, 2004). These dif fer from ours in several important ways. In particular , the y yield non-linear models, whereas RankOpt X  s models are strictly linear . Therefore, direct comparison between RankOpt and these other techniques would be appropriate only after ex-tending RankOpt to non-linear space. (Section 6). In Yan et al. (2003), the sigmoid approximation of the AUC is considered, but rejected in favour of a polynomial ap-proximation. The claim is made that the sigmoid approx-imation with a small  X  is not accurate enough, and with a lar ge  X  one creates too man y steep gradients. Although these observ ations are true, we have sho wn that by using a series of increasing  X  values, this trade off can be avoided. Cortes &amp; Mohri (2004) use boosted decision stumps to optimise the AUC. This method is quite dif ferent from RankOpt X  s gradient descent over the rank statistic surf ace. Comparison between their method and a non-linear exten-sion of RankOpt would be of interest. We have introduced RankOpt, a linear binary classifier which optimises AUC. RankOpt was compared to a num-ber of other linear binary classifiers, and in almost all cases was found to significantly outperform them.
 This work has focussed on prediction tasks in which the predictors are all either continuous or ordinal. It is planned that this will be extended to include binary valued predic-tors, enabling the development of a non-linear classifier via binarisation of continuous and ordinal predictors. Scaling of the data has been found to significantly affect RankOpt X  s performance. This is an issue that we plan to explore more thoroughly in the future.
 The permission of the Managing Director , Telstra Research Laboratories (TRL) to publish this paper is gratefully ac-kno wledged. The technical advice and feedback of Herman Ferra, TRL, is gratefully ackno wledged.
 Bamber , D. (1975). The area abo ve the ordinal dominance graph and the area belo w the recei ver operating charac-teristic graph. J. Math. Psyc h. , 12 , 387  X  415. Bradle y, A. P. (1997). The use of the area under the roc curv e in the evaluation of machine laerning algorithms. Pattern Reco gnition , 30(7) , 1145  X  1159.
 Cortes, C., &amp; Mohri, M. (2004). AUC Optimization vs. Er-ror Rate Minimization. In Advances in neur al informa-tion processing systems 16 . Cambridge MA: MIT Press. Cristianini, N., &amp; Sha we-T aylor , J. (2000). An intr oduc-tion to support vector mac hines and other kernel-based learning methods . Cambridge Uni versity Press.
 Joachims, T. (1998). Text Cate gorization with Support Vec-tor Machines: Learning with Man y Rele vant Features.
Proceedings of the Tenth Eur opean Confer ence on Ma-chine Learning ECML98 .
 Mann, H. B., &amp; Whitne y, D. R. (1947). On a test whether one of two random variables is stochastically lar ger than the other . Ann. Math. Statist. , 18 , 50  X  60.
 Perlich, C., Pro vost, F., &amp; Simonof f, J. S. (2003). Tree Induction vs. Logistic Re gression: A Learning Curv e
Analysis. Journal of Mac hine Learning Resear ch , 4 , 211 X 255.
 Platt, J. (1998). Fast training of support vector machines using sequential minimal optimization.
 Rocchio, J. J. (1971). Rele vance Feedback in Information Retrie val. The Smart System -Experiments in Automatic Document Processing (pp. 313 X 323). Engle wood Clif fs, N J: Prentice-Hall Inc.
 Vapnik, V. (1998). Statistical learning theory . Ne w York: Wiley.
 Weiss, G. M., &amp; Pro vost, F. (2001). The effect of class distrib ution on classifier learning: an empirical study (Technical Report). Rutgers Uni versity .
 Yan, L., Dodier , R., Mozer , M. C., &amp; Wolnie wicz, R. (2003). Optimizing classifier performance via approx-imation to the wilcoxon-mann-witne y statistic. Proceed-ings of the Twentieth Intl. Conf . on Mac hine Learning
 Hieu T. Nguyen TAT @ SCIENCE . UVA . NL sterdam, The Netherlands In recent years, research interest has been attracted to sem i-supervised learning or learning in the condition that only a small initial amount of data is labeled while the majority of the data remain unlabeled. While many methods focus to improve the supervised learning by using the informa-tion from unlabeled data (Seeger, 2001), another important topic is a good strategy in selecting the data to label, con-sidering that labeling data is a time-consuming job. The topic is known as active learning (Lewis &amp; Gale, 1994). Consider the problem of learning a binary classifier on a partially labeled database . Let bel , and . The active learning system comprises two parts: a learning engine and a se-lection engine. At every iteration the learning engine uses a supervised learning algorithm to train a classifier on . The selection engine then selects a sample from and re-quests a human expert to label the sample before passing it to the learning engine. The major goal is to achieve a good classifier as best as possible within a reasonable number of calls for labeling by human help.
 Current methods on active learning can be characterized by their base learning algorithms which include probabilisti c naive Bayes (Nigam et al., 2000; Roy &amp; McCallum, 2001), combination of naive Bayes and logistic regression (Lewis &amp; Gale, 1994), and the Support Vector Machine (SVM) (Campbell et al., 2000; Tong &amp; Koller, 2001; Schohn &amp; Cohn, 2000). The naive Bayes classifier suffers from two problems. First, the classifier assumes the independence between the component features of . This assumption is often violated. The second problem is that naive Bayes is a generative model for which training relies on the estima-tion of the likelihood . This estimation is inaccurate in the case of active learning since the training data are not randomly collected. The paper focuses on discriminative models including logistic regression and SVM. These mod-els aim to estimate the posterior probability . They are less sensitive to the way the training data is collected, and hence, are more suitable for active learning. A more theoretical consideration is given in (Zhang &amp; Oles, 2000). It is crucial to choose the most  X  X aluable X  training samples . Many methods choose the most uncertain samples which are closest to the current classification boundary. We name this approach the closest-to-boundary criterion. This sim -ple and intuitive criterion performs well in some applica-tions (Lewis &amp; Gale, 1994; Tong &amp; Chang, 2001; Schohn &amp; Cohn, 2000; Campbell et al., 2000). Some other crite-ria have been proposed specifically for SVM. In (Camp-bell et al., 2000), it is proposed to select the sample that yields the largest decrease of the margin between the two classes. The method of (Tong &amp; Koller, 2001) selects the sample that halves the permitted region of the SVM param-eters in the parameter space. Both (Campbell et al., 2000) and (Tong &amp; Koller, 2001) need to predict the values of the SVM parameters for every possible case where a can-didate sample might be added to the training set. Since it is hard to do this efficiently, the references finally resort t o the closest-to-boundary criterion.
 The closest-to-boundary methods ignore the prior data dis-tribution which can be useful for active learning. In (Cohn et al., 1996), it is suggested to select samples that minimiz e the expected future classification error: where is the true label of and is the classifier output. denotes the expectation over . Due to the complexity of the integral, the direct implementation o f eq. (1) is usually difficult. However, it shows that the data uncertainty should be weighted with the prior density . If is uniform or unknown, the expectation under the integral is the contribution by a sample into the classifica-tion error. The expectation can then be used to measure the value of the sample in the condition that the computation of the integral is complex. Under the assumption that the cur-rent classification boundary is good, it is easy to show that the error expectation is maximal for the samples lying on the classification boundary, see section 3.3. When is known and non-uniform, the information about the distri-bution can be used to select better data. In this paper is obtained via clustering which can be done offline without the interaction with human. The clustering information is then useful for active learning in two ways. First, the rep-resentative samples located in center of clusters are more important than the other, and should be selected first in la-beling. Secondly, samples in the same cluster are likely to have the same label, (Seeger, 2001; Chapelle et al., 2002). This assumption should be used to accelerate active learn-ing by reducing the number of labeling samples from the same cluster.
 The idea to combine clustering and active learning has ap-peared in previous work. In (McCallum &amp; Nigam, 1998), a naive Bayes classifier is trained over both labeled and unlabeled data using an EM algorithm. Under the con-dition that the overwhelming majority of the data is un-labeled, that training algorithm amounts to clustering the data set, and the role of the labeled data is for initializa-tion only. Clustering information also contributes to the selection where an uncertainty measure is weighted with the density of the sample. The referenced approach does not match, however, the objective of this paper to combine clustering with a discriminative model. Several other acti ve learning schemes also weigh the uncertainty with the data density (Zhang &amp; Chen, 2002; Tang et al., 2002). Some methods put more emphasis on the sample representative-ness by selecting cluster centers from a set of most interest -ing samples. In the representative sampling by (Xu et al., 2003), the algorithm uses the k-means algorithm to clus-ter the samples lying within the margin of a SVM classifier trained on the current labeled set. The samples at cluster centers are then selected for human labeling. The method of (Shen &amp; Zhai, 2003) has a similar idea, but applies the k-medoid algorithm for the top relevant samples. In general, heuristic methods have been proposed to balance between the uncertainty and the representativeness of the selected sample. They encourage the selection of cluster centers. However, no measure has been taken to avoid repeatedly labeling samples in same cluster. In addition, there are im-portant questions that remain open, namely, how to adapt the classification model for a training set that contains onl y cluster centers? and, how to classify samples that are dis-puted by several clusters? This paper presents a solution for these issues using a mathematical model that explicitly takes clustering into account.
 The organization of the paper is as follows. Section 2 de-scribes the incorporation of the clustering information in to the data model, and provides the theoretical framework for the data classification. Section 3 presents our active learn -ing algorithm. Section 4 shows the results of the algorithm for the classification of images in test databases. 2.1. Data model In the standard classification, data generation is describe d by the joint distribution of the data and the class label . The clustering information is ex-plicitly incorporated by introducing the hidden cluster la -bel , where is the number of clusters in the data. indicates that the sample belongs to the -th cluster. Assume that all information about the class label is already encoded in the cluster label . This implies that once is known, and are independent. The joint distribution is written as:
The simple Bayesian belief net representing the model is depicted in Figure 1.
 Before giving the specific form for the three distributions in eq. (2) we remark that a similar scheme has been pro-posed for the passive semi-supervised learning (Miller &amp; Uyar, 1996; Seeger, 2001). The conceptual difference, however, between their approach and ours is in the defi-nition of . In the references, is defined within individual clusters. As a consequence, the estimation of th e parameters of can be unreliable due to insufficient labeled data in a cluster. In our model, is defined for all clusters with the same parameters.
 We use logistic regression for : Here, is a representative of the -th cluster which is de-termined via clustering. and are the logistic regression parameters. In essence, is the label model for a representative subset of the database.
 In the ideal case where data is well clustered, once all the parameters of are determined, one could use this probability to determine the label of the cluster represent a-tives, and then assign the same label to the remaining sam-ples in the cluster. In practice, however, clustering can be inaccurate and we will have problems with classification of samples at border between the clusters. To achieve better classification for those samples, we use a soft cluster mem-bership which allows a sample to be connected to more than one clusters (representatives) with a probability. The noi se distribution is then used to propagate information of label from the representatives into the remaining major-ity of the data, see Figure 2. We use the isotropic Gaussian model: where is the variance assumed to be the same for all clusters. Let . Then, is a mixture of Gaussians with the weights .
 In the presented method, the parameters , , and are estimated from the data. The scale parameter is given initially. It can be changed during active learning when a different clustering setting is needed. 2.2. Data classification Given the above model, one calculates , the posterior probability of label of a sample as follows: where .
 Data are then classified using the Bayes decision rule: where denote the current estimates of the parameters. Observe from eq. (5) that the classification decision is a weighted combination of the classification decision for the representatives. Well clustered samples will be assigned the same label as the nearest representative. Samples dis-puted by several clusters, on the other hand, will be as-signed the label of the cluster, which has the highest con-fidence. Note that the weights are fixed unless the data are re-clustered whereas is updated upon the arrival of new training data. The parameters of the model proposed in section 2.1 are estimated via likelihood maximization. The data likelihoo d comprises two parts: the likelihood of the labeled data and the likelihood of the unlabeled data: where and denote the set of indices of labeled and unlabeled samples respectively. Expanding as the sum of and , the likelihood (7) can be written with explicit dependence on the parameters as follows: As the amount of the unlabeled data is overwhelming over the labeled data, the parameters and term in eq. (8). The maximization of each term can there-fore be done separately. The clustering algorithm maxi-mizes the likelihood of the data samples to obtain the clus-ter representatives and the cluster prior. The maximizatio n of the label likelihood follows to estimate the parameters and . The block scheme of the algorithm is illustrated in Figure 3. 3.1. Initial clustering In the presented algorithm, the goal of clustering is data representation rather than data classification. We therefo re use the -medoid algorithm of (Kaufman &amp; Rousseeuw, 1990). The algorithm finds representatives of the data set so as to minimize the sum of the distance from the data samples to the nearest representa-tive. See (Struyf et al., 1997) for the detailed implementa-tion.
 The -medoid algorithm is computationally expensive when either or is large. In practical applications both numbers are very large indeed. The following simplifi-cations are employed to reduce computations. First, the data set is split into smaller subsets. The -medoid algo-rithm is then applied to cluster every subset into a limited number of clusters. Clustering is continued by subse-quently breaking the cluster with the largest radius into two smaller ones with: where denotes the set of indices of the samples in the -th cluster. The process of cluster fission is completed when: where is a predefined constant. We have used .
 Thus, the cluster size and the final number of clusters is controlled by the scale parameter .
 Once the cluster representatives have been de-termined, the cluster prior is obtained by iterating the following two equations until stability: 3.2. The estimation of the class label model This section presents the estimation of the distribution in eq. (8). Fixing the cluster representatives , the likeli-hood depends only on the parameters and : From eq.(5), can be written as a mixture of logistic distributions with the weights .
 In case the dimensionality is higher than the number of the labeled samples, the optimization in (13) is numericall y unstable. The conventional approach to overcome the prob-lem is to add a regularization term where is a predefined parameter. This leads to the minimization of the following objective function: Remark that eq. (14) is the extension of the regularized logistic regression (Zhang &amp; Oles, 2001; Zhu &amp; Hastie, 2001) for the mixture of the logistic distributions. The minimization of is implemented using Newton X  X  al-gorithm which guarantees to find a local minimum. Fur-thermore, since is convex, it has only one local minimum which is also the global minimum.
 Starting with an initial guess and , the parameters and are updated iteratively. At each iteration, the param-eter increment in the steepest direction is: where is the Jacobian of , and is a positive definite approximation of the hessian matrix of . Using eq.(3), it can be shown that: where For the hessian matrix, the following approximation can be used: where is the identity matrix and: To get more insight into eq.(15), let: Here, is the matrix whose columns are the vectors If is high, it is efficient to invert using the Woodbury formula: If all are non-zero, the size of is . Since is large, the inverting of as in eq. (25) would be computa-tionally expensive still. However, remark that for a sample ent from zero, especially if is a cluster representative. In the latter case, the sample typically belongs to one cluster only. As will be seen in the next subsection, the presented algorithm tends to select the training data from the cluster representatives. The number of non-zero is then small, approximately the same as the number of labeled samples. The computation of in eq. (25) can then be done effi-ciently by suppressing the columns in which correspond to that equal to zero. 3.3. Criterion for data selection The selection criterion gives priority to two types of sam-ples: samples close to the classification boundary and sam-ples which are cluster representatives. Furthermore, with in the set of cluster representatives, one should start with th e highest density clusters first.
 We have noted that the computation of the future classifica-tion error in eq.(1) is complicated. So, instead of choosing the sample that produces the smallest future error, we se-lect the sample that has the largest contribution to the cur-rent error. Although such approach does not guarantee the smallest future error, there is a good chance for a large de-crease of the error. The selection criterion is: where denotes the index of the selected sample.
 The error expectation for an unlabeled is calculated over the distribution : It should be noted that the probability is un-known and needs to be approximated. An obvious choice is to use the current estimation , assuming it follows from eq. (5) that: Observe that if lies on the current classification bound-ary, the quantity is minimal, and hence the expected error is maximal.
 Eq. (26) becomes: where The resulting criterion indeed satisfies the demands put in the beginning of the subsection. The term gives priority to the samples at the boundary. Meantime, 3.4. Coarse-to-fine adjustment of clustering The labeling of high density clusters promises a substantia l move of the classification boundary. It is therefore advanta -geous to group the data into large clusters in the initial clu s-tering. This is achieved by setting a high value for the ini-tial scale parameter . When the classification boundary reaches the border between the global clusters, a finer clus-tering with smaller cluster size is better to obtain a more accurate classification boundary. The maximum in eq. (30) can be used as the indication for the need to adjust the clus-tering. If this quantity drops below a threshold : the scale parameter is decreased: where . The data set is then re-clustered. The parameters and are predefined. We have used and . Note that clustering the data set with different scales can be done offline. Furthermore, change of the scale takes place not in every iteration, but only few times during the learning process. We have performed two experiments to test the perfor-mance of the proposed algorithm. In the first experiment, the algorithm is applied to find human face images in a database containing 2500 images of size . See (Pham et al., 2002) for details on how the images were cre-ated. Example views of some images are shown in Figure 4. In the second experiment, a test database was made of im-ages of handwritten digits taken from the MNIST database (http://yann.lecun.com/exdb/mnist/). The size of images is digit against the other nine.
 In the experiments the following setting was used. The im-ages are considered as the vectors composed of the pixel grey values which range from 0 to 255. The initial train-ing set contains equal numbers of object and non-object images. The initial size of this set was and was in-creased to during active learning, where is the number of samples in the database. For clustering, the databases were split into subsets per 1250 samples. The -medoid algorithm was applied for each subset with the initial number of clusters . The initial value of was where is the number of pixels in one image. For the estimation of the class label distribution, w e use the regularization coefficient .
 Every time a new training sample is added, the classifier is re-trained and tested on the rest of the database. The classification error is calculated as the sum of the missed positives and false alarms relative to . The performance evaluation is based on the decrease of the classification er-ror as the function of the amount of training samples. For comparison, we have also implemented three other active learning algorithms. They use the standard linear SVM for classification. The first algorithm selects training data randomly. In the second algorithm, data are selected according to the closest-to-boundary criterion. The third algorithm uses the representative sampling of (Xu et al., 2003) which selects the medoid centers in the SVM margin. As we select one sample per iteration, this leads to selec-tion of the most representative sample among the samples in the margin.
 Figure 5 shows the result of the first experiment for differ-ent proportions between the numbers of face and non-face images in the database. Figure 6 shows the result of the second experiment for the different sizes of the database. Both figures show the average of the classification error obtained by repeating the experiments with three different initial training sets that are picked up randomly. The resul ts of Figure 6 are also an average over the ten digits. The proposed algorithm outperforms all three other algo-rithms. The most significant improvement is observed in Figure 5a with equal numbers for object and non-object samples in the database. The improvement decreases when the amount of the object samples is small relative to the non-object samples, see Figure 5c. In this case, since there are no clusters of the object class, the proposed algorithm is not advantageous over the closest-to-boundary algorith m in finding object samples. Nevertheless, the proposed algo-rithm remains better as it still benefits from the clustering of non-object samples. Representative sampling turns out to perform better only than random sampling. A possible reason could be the undervaluation of the uncertainty and the lack of a proper classification model. The paper has proposed a formal model for incorporation of clustering into active learning. The model allows to select most representative training examples as well as to avoid repeatedly labeling samples in same cluster, leading to better performance than the current methods. To take the advantage of the similarity between the class label of data in the same cluster, the method first constructs a clas-sifier over the population of the cluster representatives. W e use regularized logistic regression which is a discrimina-tive model with state-of-the-art performance and which is naturally fitted into a probabilistic framework. The gaus-sian noise model is then used to infer the class label for non-representative samples. New training data are selecte d from the samples having the maximal contribution to the current expected error. In addition to closeness to the clas -sification boundary, the selection criterion gives priorit y also to the representatives of the dense clusters, making th e training set statistically stable.
 The method was restricted to linear logistic regression as the main purpose of the paper is to show the advantage of using clustering information. We have succeeded in that goals for the given datasets.
 Campbell, C., Cristianini, N., &amp; Smola, A. (2000). Query learning with large margin classifiers. Proc. 17th In-ternational Conf. on Machine Learning (pp. 111 X 118). Morgan Kaufmann, CA.
 Chapelle, O., Weston, J., &amp; Scholkopf, B. (2002). Cluster kernels for semi-supervised learning. Advances in Neu-ral Information Processing Systems .
 Cohn, D. A., Ghahramani, Z., &amp; Jordan, M. I. (1996). Ac-tive learning with statistical models. Journal of Artificial Intelligence research , 4 , 129 X 145.
 Kaufman, L., &amp; Rousseeuw, P. (1990). Finding groups in data: An introduction to cluster analysis . John Wiley &amp; Sons.
 Lewis, D. D., &amp; Gale, W. A. (1994). A sequential algo-rithm for training text classifiers. Proceedings of SIGIR-94, 17th ACM International Conference on Research and Development in Information Retrieval (pp. 3 X 12). Springer Verlag.
 McCallum, A. K., &amp; Nigam, K. (1998). Employing EM in pool-based active learning for text classification. Proc. 15th International Conf. on Machine Learning (pp. 350 X  358). Morgan Kaufmann, CA.
 Miller, D., &amp; Uyar, H. (1996). A mixture of experts classi-fier with learning based on both labelled and unlabelled data. Advances in Neural Information Processing Sys-tems 9 (pp. 571 X 577).
 Nigam, K., McCallum, A., Thrun, S., &amp; Mitchell, T. (2000). Text classification from labeled and unlabeled documents using EM. Machine Learning , 39 , 103 X 134. Pham, T., Worring, M., &amp; Smeulders, A. (2002). Face de-tection by aggregated bayesian network classifiers. Pat-tern Recogn. Letters , 23 , 451 X 461.
 Roy, N., &amp; McCallum, A. (2001). Toward optimal active learning through sampling estimation of error reduction.
Proc. 18th International Conf. on Machine Learning (pp. 441 X 448). Morgan Kaufmann, CA.
 Schohn, G., &amp; Cohn, D. (2000). Less is more: Active learning with support vector machines. Proc. 17th In-ternational Conf. on Machine Learning (pp. 839 X 846). Morgan Kaufmann, CA.
 Seeger, M. (2001). Learning with labeled and unlabeled data (Technical Report). Edinburgh University.
 Shen, X., &amp; Zhai, C. (2003). Active feedback -UIUC
TREC-2003 HARD experiments. The 12th Text Re-trieval Conference, TREC .
 Struyf, A., Hubert, M., &amp; Rousseeuw, P. (1997). Inte-grating robust clustering techniques in s-plus. Compu-tational Statistics and Data Analysis , 26 , 17 X 37. Tang, M., Luo, X., &amp; Roukos, S. (2002). Active learning for statistical natural language parsing. Proc. of the Asso-ciation for Computational Linguistics 40th Anniversary Meeting . Philadelphia, PA.
 Tong, S., &amp; Chang, E. (2001). Support vector machine ac-tive learning for image retrieval. Proceedings of the 9th ACM int. conf. on Multimedia (pp. 107 X 118). Ottawa. Tong, S., &amp; Koller, D. (2001). Support vector machine active learning with applications to text classification. Journal of Machine Learning Research , 2 , 45 X 66. Xu, Z., Yu, K., Tresp, V., Xu, X., &amp; Wang, J. (2003). Rep-resentative sampling for text classification using support vector machines. 25th European Conf. on Information Retrieval Research, ECIR 2003 . Springer.
 Zhang, C., &amp; Chen, T. (2002). An active learning frame-work for content-based information retrieval. IEEE trans on multimedia , 4 , 260 X 268.
 Zhang, T., &amp; Oles, F. (2000). A probability analysis on the value of unlabeled data for classification problems. Proc. Int. Conf. on Machine Learning .
 Zhang, T., &amp; Oles, F. J. (2001). Text categorization based on regularized linear classification methods. Information Retrieval , 4 , 5 X 31.
 Zhu, J., &amp; Hastie, T. (2001). Kernel logistic regression and the import vector machine. Advances in Neural Informa-
 The amount of information on the World Wide Web is growing with an incredible speed nowadays. Every day approximate 60 terabytes of new content is added to the organizing the web content and people resort to web directories like Yahoo, ODP, and LookSmart etc. for browsing. Web page classification is the task of deciding whether perts. But due to the fast growth in online document data, this becomes more difficult with time. Automatic classification schemes can greatly facilitate the process of cate-gorization and many approaches have been proposed, such as K-Nearest Neighbor [2], Bayesian probabilistic models [3], deci sion trees [4], Support Vector Machine [5] and neural networks [6]. separable and non-separable data. In classical SVMs, the hard margin loss function is suitable for noise-free data sets. For other general cases, a soft margin loss function is also popularly used, which introduces slack variables to allow some misclassification. Our CS-SVM algorithm is based on the soft margin theory of SVM and deals with the dimensional or even infinite dimensional space to solve the non-linear problems and here we adopt the linear kernel for simplification. Many variant forms of SVM have been suggested. [8] introduced Transductive Support Vector Machines (TSVMs) for text classification, which took into account a examples. In [9], Least Square Support Vector Machine (LS-SVM) has been investi-respectively. 
However, previous work on SVM has not realized that each instance in a training data set should be treated differently. Especially in the application of web page classi-the infrequently visited web pages or desolate websites. The pages which have many algorithm based on the PageRank importance to improve the classification results. training errors to generate an optimized SVM hyperplane. This outperforms the exist-ing technique of the standard SVM. Besides, web pages have different effects on PageRank web pages but the relative high and topic focused ones, thus sampling these technique. troduced. In Section 3, an overview of SVM is provided. In Section 4, we present the Cost-Sensitive Support Vector Machine algorithm in and the experiment results are reported in Section 5. Finally we draw the conclusions and suggest some future work in Section 6. Web Page Classification categories according to their content. Previ ous work can be divided into two types: a) Text content based classification: A collection of keywords and their frequency documents would be presented as feature vect ors and classified into appropriate direc-tories using the KNN, Na X ve Bayes, or SVM etc. b) Link and Tag based classification: Hyperlinks clearly contained high-quality semantic clues that were lost upon a purely text classifier, but exploiting link informa-tion was non-trivial because it was noisy. Naive use of terms in the link neighborhood helpful as described in [18]. [19] used the URLs and table layout for web classifica-tion tasks. 
However, all the previous work has not considered combining the PageRank values different data. That X  X  what we have explored in our paper. SVM Variants and Weighted Methods account a particular test set and tried to minimize misclassifications of just those par-ticular examples. In [9], a Least Square Support Vector Machine (LS-SVM) was SVM based on manifold regularization, which exploited the geometry of the probabil-ity distribution and performed well in handwritten digit recognition and spoken letter recognition. [10] proposed a biased SVM to assign C+ and C-to weight positive and negative errors respectively. When the positive example set was homogenous, i.e. focusing on one topic, and they covered a rather smaller region in the vector space, it accurate classifier. 
There are many weighted methods as well. Weighted least squares regression [21] ciency of parameter estimation. [22] proposed a weighted dissimilarity measure in vectorial spaces to optimize the performance of the nearest neighbor classifier. Some cluster the web documents[19][23]. SVM was first bought forward by Cortes and Vapnik [12] as a learning algorithm for classification and regression. It tried to maximize the margin of confidence of classi-fication on the training data set, which could use the linear, polynomial or radial basis function (RBF) kernels. Now we will outline the main ideas of SVM. From these training examples the algorithm finds the parameters of the decision func-tion: where i w and b are the adjustable parameters of the decision function. The distance r between the hyperplane and training example x is |D(x)|/||w|| . Supposing that there is a margin M between the hyperplane and supporting vectors, so that The problem of classification equals to finding the maximum margin of SVM. As in ary 2 L are supporting vectors, which are closest to the hyperplane. 
The norm of w can be scaled so that the product of M and ||w|| amounts to 1, which means that the distances of all the training data are at least 1 from the hyperplane. Hence, maximizing the margin M is equivalent to minimizing the norm ||w|| . It turns out to be a quadratic optimization problem as follows: 
This solution involves contracting a dual problem where a Lagrange multiplier  X  is associated with every constraint in the primary problem: When the two classes are not linearly separable (e.g. due to noise), the condition (4) can be relaxed by adding the slack variables: function will become: minimize Here C is the trade-off between maximizing the margin and minimizing the train errors. Small-valued C tends to emphasize the margin; otherwise it tends to overfit the training data. In (8), every training example X  X  error is treated equally with the uniform parameter C, no matter it is the error of a highly important instance or of the less important one. As a matter of fact, we should distinguish different misclassification constraints of the data we will introduce our Cost-Sensitive SVM algorithm in detail. Generally, SVM doesn X  X  consider any weighted method for its soft margin error, which will result in mistakes on the important data instances. Supposing every train-ing instance has an importance value, there are two classes A and B , as can be seen in has the priority to be correctly classified. trary. As far as standard SVM concerned, 1 L is the optimal decision boundary, for it However, if we consider the importance of the data points, it is apparent that 2 L is the better choice as the decision hyperplane. 
Therefore, we propose a Cost-Sensitive SVM algorithm to promote the classifica-uses C to balance the margin and training error, which can be modified as: min pre-defined by users. For the reason of simplification, we set the power k of the slack variable as 1, and the corresponding Lagrange dual problem of CS-SVM becomes: SVM: Substituting (11), (12) and (13) into primal Lagrange (10), we X  X l get the dual formula-tion for 1-norm soft margin problem: The Karush-Kuhn-Tucker [13] conditions are That means the slack variable is not zero only when J. Platt [14] suggested a Sequential Minimal Optimization (SMO) for training SVM, which broke the large quadratic programming (QP) optimization problem like through the feasible region of the dual problem and maximizes the objective function. It works by optimizing two to CS-SVM, the optimization process would become as: 
Optimizing 1  X  , 2  X  from an old set of feasible solution: old tial old  X  is set to 0), because 
This confines the optimization to be on a deflective line, as shown in the following figure: their importance weights and the Lagrange multipliers will be updated after each loop. In the following two cases, the KKT condition are violated: 
The heuristic for picking two sweeping, i.e. the outer loop selects the first KKT conditions and inner loop looks for a non-boundary example that maxi-mizes 12 EE  X  . Because in CS-SVM there are different constraints on the two 134 W. Liu et al. their adjustment is biased compared with Standard SMO algorithm for SVM. Finally after many sweeps, CS-SVM will reach the optimal solution. In our experiment, we take the original integral PageRank values for each i imp . In this section, we provide the evaluation of CS-SVM algorithm on the 1,546,439 web pages of Open Directory Project. All of the experiments are done in two Intel X  Xeon X  CPU 3.06GHZ machines with 3.87 GB of RAM and 2.0GB of RAM respec-tively. CS-SVM is implemented based on SVM light [15]. 5.1 Data Set Our experiments are conducted on the 174 classes of ODP X  X  second level directory. In bers are less than 1,000 so that the training and testing data for each class in CS-SVM ments. The first one has three 15,000 web page subsets, each randomly chosen from the remaining 1,485,540 web pages. The second includes eleven groups, each of which has 100 web pages at a specified PageRank value (0~10) and the corresponding test sets are 100 web pages sets randomly selected from rest web pages. 5.2 Evaluation Metrics are used in our experiments. 5.3 Result Analysis First, we conduct an experiment on the first data set, i.e. three groups, each of which contains 15,000 random web pages from ODP. The results on CS-SVM and standard SVM with ten-fold cross validation are presented in Table 1. Compared with SVM, the MicroP, MicroR and MicroF1 has improved 6.8%, and MacroP has improved 39%, MacroR 47% and MacroF1 49% respectively.
 MicroRecall, MicroP = MicroPrecision, MicroR = MicroRecall). 
Next, we perform ten experiments to compare the effects of web pages with differ-into 90% training set and 10% testing set. Then 100 web pages are selected randomly set. The result is shown in Fig.5 as below. 
The web pages whose PageRank is equal to 7 plays the most important role in the 10 perform worse even than the low Page Rank ones. We analyze the corresponding web pages for PageRank 8~10, and find that most of them are homepages of popular length of paragraphs. For example, the 169055 th web page with PageRank 10 only has enough information because we use the TFID F feature vectors for classification. And low PageRank samples often contain many texts and somewhat can reflect the charac-teristics of the category that they belong to, hence, their performances are not so bad. The most contributive web pages are the ones with PageRank 7, because they are not only of high quality and popular but also contain adequate information. 136 W. Liu et al. 
During our experiments, we make further exploration to find which form of Pag-format etc. For both Micro and Macro measures, the logarithmic PageRank is the best choice as shown in Fig. 6 
Finally, we apply our importance based classification method to the sampling tech-nique. High PageRank web pages between 5 and 8 in a 15000 random set are sampled for training and the compared same size samples are randomly selected. The ten fold cross validation result is shown in Table 2: 
The web pages with PageRank(5~8) contain the most contributive information and their classification result exceeds the random sampling technique. In this paper, we improve the classification performance by using the Cost-Sensitive SVM algorithm, compared with the standa rd SVM. Considering the web pages have quirements in the soft margin of CS-SVM, which results in an optimized decision hyperplane. Experiments show that CS-SVM outperforms SVM in a great extent and sides, the best form of PageRank in CS-SVM is the logarithmic value. Finally, using can get better performance than the random sampling method. 
In future, we can further take advantage of the link structure of web in the various forms and combine them with SVM. Like the Laplacian method in [20], a link graph can be constructed with each edge differently weighted, which need more knowledge on manifold theory. Moreover, the importan ce based idea can be used in the tasks of web page clustering and other applications, too. 1. W.Roush. Search Beyond Google. MIT technology review, pages, (2004) 34-35. 2. Yiming Y., Xin L.: A Reexamination of Text Categorization Methods, In proceed ings of 3. McCallum, A., Nigam, K.: A Comparison of Event Models for Naive Bayes Text Classifi-4. Lewis, D.D., Ringuette, M.: A Classification of Two Learning Algorithms for Text Cate-7. Burges, C.:A Tutorial on Support Vector Machines for Pattern Recognition. Data Mining 9. Suykens, JAK. Vandewalle, J.:Least Squares Support Vector Machine Classifiers. Neural 12. Bernhard E., B., Isabelle M., G., Vladimir N., V.: A Training Algorithm for Optimal Mar-15. Joachims, T.: Making large-Scale SVM Learning Practical. Advances in Kernel Methods -16. Yiming, Y.: An Evaluation of Statistical Approaches to Text Categorization. Information 17. Chakrabarti, S., Dom, B., Indyk, P.:Enhanced Hypertext Categorization Using Hyperlinks. 22. Paredes, R., Vidal, E.: A Nearest Neighbor Weighted Measure in Classification Problems. 23. Shen, H., Gui-Rong, X., Yong, Y., Benyu, Z., Zheng, C., Wei-Ying, M.:. Multi-type Fea-
 Ov er the past decade, there has been tremendous progress on learning parsing models from treebank data (Magerman, 1995; Collins, 1999; Charniak, 1997; Ratnaparkhi, 1999; Charniak, 2000; Wang et al., 2005; McDonald et al., 2005). Most of the early work in this area was based on postulating gener ative probability models of language that in-cluded parse structures (Magerman, 1995; Collins, 1997; Charniak, 1997). Learning in this conte xt consisted of estimating the parameters of the model with simple lik elihood based techniques, but incor -porating various smoothing and back-of f estimation tricks to cope with the sparse data problems (Collins, 1997; Bik el, 2004). Subsequent research began to focus more on conditional models of parse structure given the input sentence, which allo wed discrimi-nati ve training techniques such as maximum con-ditional lik elihood (i.e.  X maximum entrop y X ) to be applied (Ratnaparkhi, 1999; Charniak, 2000). Cur -rently , the work on conditional parsing models ap-pears to have culminated in lar ge mar gin training approaches (Taskar et al., 2004; McDonald et al., 2005), which demonstrates the state of the art per -formance in English dependenc y parsing.

Despite the realization that maximum mar gin training is closely related to maximum conditional lik elihood for conditional models (McDonald et al., 2005), a suf ciently unied vie w has not yet been achie ved that permits the easy exchange of impro vements between the probabilistic and non-probabilistic approaches. For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al., 2005), and yet the y are not being used in current lar ge mar gin training algorithms. Another une xploited connec-tion is that probabilistic approaches pay closer at-tention to the indi vidual errors made by each compo-nent of a parse, whereas the training error minimized in the lar ge mar gin approach X the  X structured mar -gin loss X  (McDonald et al., 2005) X is a coarse mea-sure that only assesses the total error of an entire parse rather than focusing on the error of any par -ticular component. I have addressed both of these issues, as well as others in my work. Given a sentence problem of computing an accurate directed depen-denc y tree, , over . Note that consists of or-dered pairs of words in such that each word appears in at least one pair and each word has in-de gree at most one. Dependenc y trees are usually assumed to be projecti ve (no crossing arcs), which means that if there is an arc , then is an ancestor of all the words between and . Let trees that span .

From an input sentence , one would lik e to be able to compute the best parse; that is, a projecti ve tree, particular , I follo w Eisner (1996) and McDonald et al. (2005) and assume that the score of a complete spanning tree for a given sentence, whether prob-abilistically moti vated or not, can be decomposed as a sum of local scores for each link (a word pair). In where the score s can depend on any measurable property of and within the tree . This formulation is suf ciently general to capture most dependenc y parsing models, including proba-bilistic dependenc y models (W ang et al., 2005; Eis-ner , 1996) as well as non-probabilistic models (Mc-Donald et al., 2005; Wang et al., 2006).

For the purpose of learning, the score of each link can be expressed as a weighted linear combination of features where during training. To learn an accurate dependenc y parser from data, the rst approach I investigated is based on a strictly lexical parsing model where all the parameters are based on words (W ang et al., 2005). The adv antage of this approach is that it does not rely on part-of-speech tags nor grammatical cate gories. Further -more, I based training on maximizing the condi-tional probability of a parse tree given a sentence, unlik e most pre vious generati ve models (Magerman, 1995; Collins, 1997; Charniak, 1997), which focus on maximizing the joint probability of the parse tree and the sentence.

An efcient training algorithm can be achie ved by maximizing the conditional probability of each parsing decision, hence minimizing a loss based on each local link decision independently . Impor -tantly , inter -dependence between links can still be accommodated by exploiting dynamic featur es in training X features that tak e into account the labels of (some) of the surrounding components when pre-dicting the label of a tar get component. To cope with the sparse data problem, I use distrib utional word similarity (Pereira et al., 1993; Grefenstette, 1994; Lin, 1998) to generalize the observ ed fre-quenc y counts in the training corpus. The exper -imental results on the Chinese Treebank 4.0 sho w that the accurac y of the conditional model is 13.6% higher than corresponding joint models, while sim-ilarity smoothing also allo ws the strictly lexicalised approach to outperform corresponding models based on part-of-speech tags. The approach presented abo ve has a limitation: it uses a local scoring function instead of a global scor -ing function to compute the score for a candidate tree. The structured lar ge mar gin approach, on the other hand, uses a global scoring function by mini-mizing a training loss X the  X structured mar gin loss X  (McDonald et al., 2005) X which is directly coordi-nated with the global tree. Ho we ver, the training error minimized in the lar ge mar gin approach is a coarse measure that only assesses the total error of an entire parse rather than focusing on the error of any particular component. Also, smoothing meth-ods, which have been widely used in probabilistic approaches, are not currently being used in lar ge mar gin training algorithms. In the second approach, I impro ve structured lar ge mar gin training for pars-ing in two ways (W ang et al., 2006). First, I incor -porate local constraints that enforce the correctness of each indi vidual link, rather than just scoring the global parse tree. Second, to cope with sparse data and generalize to unseen words, I smooth the lexical parameters according to their underlying word sim-ilarities. To smooth parameters in the lar ge mar gin frame work, I introduce the technique of Laplacian regularization in lar ge mar gin parsing. Finally , to demonstrate the benets of my approach, I recon-sider the problem of parsing Chinese treebank data using only lexical features, as in Section 3. My re-sults impro ve current lar ge mar gin approaches and sho w that similarity smoothing combined with local constraint enforcement leads to state of the art per -formance, while only requiring word-based features that do not rely on part-of-speech tags nor grammat-ical cate gories in any way. Finally , I have recently demonstrated the some what surprising result that state of the art dependenc y parsing performance can be achie ved through the use of con ventional, local classication methods. In particular , I sho w how a simple form of structured boosting can be used to impro ve the training of stan-dard local classication methods, in the conte xt of structured predictions, without modifying the under -lying training method (W ang et al., 2007). The ad-vantage of this approach is that one can use off-the-shelf classication techniques, such as support vec-tor machines or logistic regression, to achie ve com-petiti ve parsing results with little additional effort.
The idea behind structured boosting is very sim-ple. To produce an accurate parsing model, one combines the local predictions of multiple weak pre-dictors to obtain a score for each link, which a parser can then use to compute the maximum score tree for a given sentence. Structured boosting proceeds in rounds. On each round a local  X link predictor X  is trained merely to predict the existence and orienta-tion of a link between two words given input fea-tures encoding conte xt X without worrying about co-ordinating the predictions in a coherent global parse. Once a weak predictor is learned, it is added to the ensemble of weak hypotheses, the training corpus is re-parsed using the new predictor , and the local training conte xts are re-weighted based on errors made by the par ser 's output. Thus, a wrapper ap-proach is used to successi vely modify the training data so that the training algorithm is encouraged to facilitate impro ved global parsing accurac y. Table 1: Comparison with State of the Art (Depen-denc y Accurac y) Table 1 compares my results 1 with those obtained by other researchers, on both English and Chinese data. 2 The English results are obtained using the same standard training and test set splits from En-glish Penn Treebank 3.0. The results on Chinese are obtained on two dif ferent data sets, Chinese Tree-bank 4.0 and Chinese Treebank 5.0 as noted. 3
Table 1 sho ws that the results I am able to achie ve on English are competiti ve with the state of the art, but are still behind the best results of (McDonald and Pereira, 2006). Ho we ver, perhaps surprisingly , Table 1 also sho ws that the structured boosting ap-proach actually surpasses state of the art accurac y on Chinese parsing for both treebank collections. Although the three pieces of my work abo ve look very dif ferent supercially , the y are actually closely related by the  X scoring X  formulation and, more specically , by the equations introduced in Sec-tion 2. In other words, the y all compute a linear classier . 4 The only dif ferences among them are: (1) What features are used? (2) Ho w are the param-eters
A general perspecti ve I bring to my investigation is the desire to delineate the effects of domain en-gineering (choosing good features for representing and learning parsing models) from the general ma-chine learning principles (training criteria, regular -ization and smoothing techniques) that permit good results. In fact, combined features have been pro ved to be useful in dependenc y parsing with support vec-tor machines (Yamada and Matsumoto, 2003), and I have already obtained some preliminary results on generating useful feature combinations via boosting. Therefore, I will consider combining all the projects I presented abo ve. That is, I plan to incorporate all the useful features, the morphological features and the combined features as discussed abo ve, into the training algorithms presented in Section 4 or Sec-tion 5, to train a dependenc y parser globally . Then I am going to augment the training with the exist-ing smoothing and regularization techniques (as de-scribed in Section 4), or new developed ones. I ex-pect the resulting parser to have better performance than those I have presented abo ve.

There are a lot of other ideas which can be ex-plored in my future work. First and most important, I plan to investigate new adv anced machine learning methods (e.g., structured boosting or unsupervised / semi-supervised algorithms (Xu et al., 2006)) and apply them to the dependenc y parsing problem gen-erally , since the goal of my research is to learn nat-ural language parsers in an ele gant and principled manner . Ne xt, I am going to apply my approaches to parse other languages, such as Czech, German, Spanish and French, and analyze the performance of my parsers on these dif ferent languages. Further -more, I plan to apply my parsers in other domains (e.g., biomedical data) (Blitzer et al., 2006) besides treebank data, to investigate the effecti veness and generality of my approaches.
