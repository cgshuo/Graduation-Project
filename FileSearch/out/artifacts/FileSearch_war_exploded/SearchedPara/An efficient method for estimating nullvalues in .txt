 REGULAR PAPER Jia-Wen Wang  X  Ching-Hsue Cheng Abstract Generally, a database system containing null value attributes will not operate properly. This study proposes an efficient and systematic approach for es-timating null values in a relational database which utilizes clustering algorithms to cluster data, and a regression coefficient to determine the degree of influence be-tween different attributes. Two databases are used to verify the proposed method: (1) Human resource database; and (2) Waugh X  X  database. Furthermore, the mean of absolute error rate (MAER) and average error are used as evaluation criteria to compare the proposed method with other methods. It demonstrates that the proposed method is superior to existing methods for estimating null values in re-lational database systems.
 Keywords Relational database systems  X  Null value  X  Degree of influence 1 Introduction Data mining has recently become a major field for research and applications devel-opment [ 14 , 18 ]. However, the handling of null values is the main task in prepro-cessing data as part of data mining. A basic problem with null values is existence of many plausible interpretations. However, many researchers agree that the vari-ous manifestations of null values can be reduced to two basic interpretations [ 25 ]: (1) the unknown interpretation in which a value exists but is unknown; and (2) the nonexistent interpretation in which a value does not exist. According to Han and Kamber [ 17 ], the null value may result from one of the five possibilities: (1) The data were not captured because of faulty equipment; (2) the data was inconsistent with other recorded data, and thus the application program may have deleted the data; (3) the data were not entered due to misunderstanding(s); (4) certain data may not have been considered sufficiently important at the time of entry; and (5) the data were not registered in the history or in the data changes. Sometimes null values represent important and critical data, and may need to be inferred and/or estimated.
 tional database systems [1, 4 X 10, 19, 22, 25]. Several approaches to this problem exist: (1) Ignoring objects containing null values; (2) filling the gaps manually; (3) substituting the null values with a constant; (4) using the mean of the objects for filling the null value; and (5) using the most probable value to fill in the null values.
 ferred and/or estimated, as in the case of customer information, which is important in enterprise marketing; and (2) the extant methods are not satisfactory ways for handling null value problems. Therefore, this study proposes the degree of influ-ence for estimating null values in relational databases, based on clustering and a regression coefficient. The proposed method can estimate null values in relational database systems more accurately than existing methods. Finally, two examples are used to verify and compare the results of this study with those of previous studies using MAER (means of absolute error rate (  X  e ) and average error (  X  e 2 ) . views the literature. A new approach for estimating null values is then proposed in Sect. 3 . Subsequently, Sect. 4 presents two examples to verify the proposed method and compares it with other methods. Finally, conclusions are presented. 2 Preliminary This section briefly reviews the related literature, including multiple linear regres-sion, clustering and estimating null value. 2.1 Multiple linear regression Multiple linear regression is an extension of the simple linear regression method-ology to multiple independent variables. That is, rather than using just one inde-pendent variable to explain the variation in y , multiple linear regression permits the simultaneous use of several independent variables.
 three or more variables. The multiple regression model is expressed as follows [ 11 ]: where y i denotes a typical value of the dependent variable Y from the pop-X , j , X 2 , j ,..., X k , j respectively. Moreover, e j is assumed to have a random and normal distribution N ( 0 , X  2 ), j = 1 , 2 ,..., n .
 The model parameters specified in Eq. (1) are the partial regression coefficients,  X  ,  X  1 ,..., X  k . The model is clearly linear because none of these regression coef-ficients is increased to a power exceeding 1.
 ing reason: the parameter  X  1 is interpreted as the expected change in Y per unit change in X 1 while the other X  X  X  are constant. The other  X   X  X  can be similarly interpreted. 2.1.1 Stepwise regression Stepwise regression is a popular and extremely effective method for establishing regression models. The most widespread stepwise regression procedure works as follows. The user first identifies the response, y , and the set of potentially im-portant independent variables, x 1 , x 1 ,..., x k ,where k is generally large. The re-sponse and independent variables are then entered into the software, and the step-wise procedure begins [ 21 ].
 erations. Each iteration involves one of the two procedures, namely either adding a variable to the model (referred to here as the selection procedure) or removing a variable from the model (elimination) [ 12 ] . The process of stepwise regression involves the following steps: 1. Consider all possible regressions using one explanatory variable. Select the 2. The next variable to enter is the one that makes the most significant contribu-3. Next, delete the variable that makes the smallest contribution. The deleted t -4. Repeat Steps 2 and 3 until all possible additions and deletions have been per-2.1.2 Beta coefficient The standardized coefficients are known as beta coefficients, and involve the fol-lowing steps of the beta coefficients are [ 13 ]:
Step 1 Standardize all the variables : y 1 = ( y  X   X  y ) / S y ,where y 1 denotes the Step 2 Assume z 1 is standardized value of X 1 , z 2 is standardized value of X 2 .
Step 3 The regression model can then be obtained as follows: are not standardized) is that the magnitude of these beta coefficients enables com-parison of the relative contribution of each independent variable to predicting the dependent variable. 2.2 Clustering method The grouping of sets of physical or abstract objects into classes of similar objects is called clustering. Clusters are collections of data objects that share similarities with one another and are dissimilar to objects in other clusters [ 17 ]. This study proposed the K -Means algorithm to build clusters based on attributes. K -Means and has been widely applied in various fields including data mining, statistical data analysis, and other business applications. The K -Means algorithm is per-forms partitioning based on the mean value of the cluster objects. MacQueen [ 20 ] suggested the term K -Means to describe an algorithm that assigns each item to the cluster with the nearest centroid (mean). The process comprises the following three steps: Step 1 The objects to be clustered into K initial clusters.

Step 2 Proceed through the list of objects; assigning an object to the cluster with Step 3 Repeat Step 2 until all reassigning is completed.
 Step 1, K initial centroids (seed points) were specified and then Step 2 was com-pleted. The final assignment of items to clusters is, to some extent, dependent to a degree upon the initial partition or the initial selection of seed points. Experi-ence suggests that most major changes in assignment occur as part of the first reallocation step. 2.3 A review on estimating null value Recently, many studies have focused on the estimation of null values in relational database systems [4 X 9]. Chen and Chen [ 5 ] presented an estimating null value method, where a fuzzy similarity matrix to build the fuzzy relations, a method that only deals with one null value in an attribute. Chen and Huang [ 7 ]usedge-netic algorithms to estimate null value in relational database systems. Chen and (EFCLS) algorithm for generating rules and estimating null values in relational databases. Furthermore, Chen and Yeh [ 4 ] presented an algorithm known as fuzzy concept learning system (FCLS) to generate fuzzy rules for estimating null val-ues in relational database systems. However, these methods are unsatisfactory for handling null value problems. This study proposes an efficient and systematic ap-proach for estimating null values in a relational database, which is more efficient than alternative methods.
 3 New approach for estimating null value This section presents a new approach to estimating null values in relational database systems based on clustering and the degree of influence, and proposes an algorithm for estimating null values in a relational database. 3.1 Proposed null value estimation process To estimate the null value, this study summaries the previous approach [ 9 , 17 ]and adds the concepts of the degree of influence shown as Fig. 1 . The steps of this proposed process are as follows:
Step 1 Data selection and transformation: Extract features (selection of inde-
Step 2 Clustering: Cluster analysis is a technique for grouping individuals or
Step 3 Degree of influence: Different independent variables exert different influ-Step 4 Estimated null value: Find the located cluster of null value, and then apply
Step 5 Evaluation: This study proposes MAER (  X  e ) and average error (  X  e 2 ) as the 3.2 Algorithm for estimating null values This section presents the algorithm for estimating null values in relational database systems based on the degree of influence of attributes. Table 1 lists a relational database system that includes four attributes: ID , Degree , Experience and Salary . Ta b l e 1 shows that the values of the attribute Salary depend on the values of the attributes Degree and Experience (that is, the attribute Salary is functionally de-pends on the attributes Degree and Experience ). That is, the attributes Degree and Experience are termed independent variables (IV) and the attribute Salary is termed a dependent variable (DV). For example, the tuple with the ID is O 2 in Ta b l e 1 can be represented by ( D 2 , E 2 , S 2 ) .
 follows: Step 1 Data transformation: Change the data into appropriate forms.

Step 2 Build clusters based on attributes (that is the null value variable): Ac-Step 3 Calculate the regression coefficient for measuring the degree of influence:
Step 4 Calculate the C i variation: Calculate the variation in the attribute S per
DS i =
ES i =
Step 5 Calculate the Euclidean distance between c i and null value: Let ( D , E ,  X  S )
Step 6 Calculate the estimated value  X  S of attribute S : 3.3 Numerical experiment The numerical experiment involves a database of human resources. Table 2 shows that the tuple whose ID is O 23 has a null value for the attribute Salary , where the attribute Salary is functionally dependent on the attributes Degree and Experience [ 4 ].
 Step 1 Data transformation: Because the ordering of the value of the attribute
Step 2 The values of the attribute Salary when clustered on the basis of the K -
Step 3 Compute the beta coefficient to measure the degree of influence. This
Step 4 From the algorithm proposed in Sect. 3.2 , calculate the value of ES i and
Step 5 Calculate the Euclidean Degree-Experience distance Dist 6 between O 23
Step 6: Calculate the estimated value  X  S of the attribute Salary , ID = O 23 tuple, Salary of each tuple listed in Table 8 and the estimation error of each tuple is compared with the existing methods shown in Table 9 .
 the listed methods. Figure 2 shows that the estimated error rate of the proposed method is smoother than that of the existing methods [4 X 9]. Restated, the proposed method is more accurate than the existing methods. 4 Verification and comparison To verify and compare with other methods, this study uses two databases to demonstrate its results. The results are presented in the human resource database in Sect. 4.1 and the Waugh database [ 23 ] in Sect. 4.2 . 4.1 Human resource database This study adopts a real human resource database for estimating null value from a regional hospital in Taiwan. The database contains a total of 609 records as listed in Table 10 . The value of the attribute Degree is ordered as follows: (Master) &gt; (Bachelor) &gt; (Junior college) &gt; (Senior high school) &gt; (Junior high school). student is assigned to the value of 1, junior college is assigned to the value of 2, Bachelor is assigned to the value of 3, and Master is assigned to the value of 4, where these assignments can facilitate the null value estimation.
 Salary of each tuples are shown in Table 11 . This study calculates MAER to eval-uate the estimated accuracy. Five methods can be used to estimate salary: (1) Use the mean of the objects; (2) cluster center by K -means; (3) cluster center by auto-cluster; (4) the method of Chen and Hsiao [ 9 ]; (5) the proposed method. Table 12 clearly shows that, the proposed method is more accurate than other methods. 4.2 Waugh X  X  database The database is a public source Waugh X  X  database . Waugh [ 23 ] conducted hedo-nic price analysis based on observation of different lots of tomatoes, asparagus and cucumbers in a Boston vegetable market. The data included 200 individual lots of asparagus in Boston over the period 6 May to 2 July 1927. Waugh used three criteria to predict price, (1) the number of inches of green color on the stalk (GREEN), (2) number of stalks per bunch, which indicates average size (NOS-TALKS), (3) uniformity, measured as the quartile coefficient of dispersion of the actual diameter of each stalk in a bunch (DISPERSE). This study uses the pro-posed method to estimate the null values. Furthermore, this study compares the effect of the different percentages of null value (5 and 10%) via repeated random sampling. Table 13 shows the results (the average error from random sampling). From Table 13 , the results of the proposed method are better than those of other methods under 5 and 10% null values. Furthermore, this study finds that MAER increases with the percentage of null values. 5 Conclusions This study has proposed an efficient approach for estimating null values in rela-tional databases. The results of analysis indicate that the proposed method outper-forms existing methods, i.e. the proposed method has better accuracy than the ex-isting methods. Currently, this study uses expert experience to discredit the value of the attribute Degree . In the future, if the value of the categorical attribute is unordered, other methods (for example Condorcet X  X  Criterion [ 24 ], and so on) can be added to handle categorical data in the proposed approach.
 References
