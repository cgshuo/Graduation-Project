 Matching person names plays an important role in many applications, including bibliogr aphic databases and indexing systems. Name varia tions and spelling errors make exact string matching problematic; therefore, it is useful to develop methodologies that can handle vari ant forms for the same named entity. In this paper, a novel person name matching model is presented. Common name varia tions in the English speaking world are formalized, and the concept of name transformation paths is introduced; name similarity is measured after the best transformation path has been selected. Supervised techniques are used to learn a similarity function and a decision rule. Experiments with three datasets show the method to be effective. H.3.3 [Information Systems]: Info rmation Search and Retrieval  X  search process, clustering.
 Algorithms, Performance, La nguages, Experimentation Name matching, String simila rity, String distance metrics In information retrieval and knowledge management, a user frequently encounters the problem of whether two strings refer to the same person. For example, a us er may be confused by similar strings for person names when sear ching scientific literature and citation indices. The same problem occurs when people analyze citation statistics to assess the im pact of various authors X  work. Due to the variety of formats used to cite the same author in different publications, the spelling variants of different languages, and the misspellings that people often make, it is important to develop methodologies that can effi ciently match names that refer to the same entity under these conditions. The task of matching entity names has been well explored. Cohen and his colleagues [6] made a comprehensive study of known techniques and conducted a compar ison of several string distance measures for the tasks of matchi ng and clustering lists of named entities. In their experiments, Soft -TFIDF [6], Jaro-Winkler [14] and Monge-Elkan [11] did well. Subsequently, many researchers focused on person name matc hing problems under different conditions. Piskorski et al. [12] focused on knowledge-poor methods for a person name matc hing task in Polish, a highly inflected language, and Arehart and Miller [1] performed experiments with a multicultural Romanized name data set. Each optimized the matching methods for characteristics of specific datasets. Person name va riation has also attracted the attention of characteristics of person names a nd presented potential sources of variations and errors. Galvez and Moya-Anegon [9] classified person name variants as valid or invalid and presented finite-state graphs to match person names. Form the above, we can see that person name matching and person na me variation have been well explored previously, but those two problems have to some extent been studied independently. In this paper, we aim to jointly study these problems by leveraging name variation features to perform name matching. Before introducing our model, we fi rst give a formal definition of person name and name format. In the English speaking world, a person name is a character string which can be tokenized into a token list. For each token in the list, it may be a single-character initial ( I ) or a multi-character  X  X on-initial X  token ( N ). We define Person Name ( Name ) and Name Format ( F (Name) ) as follows: For example, the name  X  X ichael Joe Penn X  can be defined as ( X  Michael X ,  X  X oe X ,  X  X enn X  ) and its name format F( X  X ichael Joe Penn X ) =( N,N,N ). Unlike traditional met hods, our model measures name similarity only after the na me pair has been transformed into the same format. Next, we describe our model in detail. In the English speaking world we can identify three main name variation types: abbreviation , omission and sequence changing . Abbreviation (A) : a non-initial name token is rewritten as an initial; Omission (O) : certain tokens in the full name are omitted; Sequence changing (S) : some publications put the given name first; others put the family name first. Given these name variation types, we define a Name Transformation Operation Set : V = { A, O, S }. A person name is transformed into a variant by applying a sequence of one or more operations from V ; the name format changes as a result of each operation. Figure 1 illustrates the process. With appropriate transformations, two names ( A, B ) can be transformed into the same name format; we call the final format the Matching Format (M) . We define the transformations applied to A and B in this process the Transformation Path ( TP ): Furthermore, the similarity be tween two transformed names can be calculated; we call this the Matching Similarity and denote it Sim(N A ,N B |TP). From the definition, it is clear that there can be multiple transformation paths between a pair of names. In Figure 2, the names  X  X ichael John Pfeng X  and  X  X . Joe Penn X  reach the matching format through multiple paths. Table 1 shows the corresponding transformation paths; the matching similarity is calculated with the Jaro metric [14]. NameA NameB Transformation Path Similarity Which path is optimal? We next present a method to estimate that. In Figure 2, the name variants and transformation paths compose a directed graph, which suggests that a good path can be selected using Dijkstra's algorithm [8]. We prefer the shortest path; when there are multiple shortest paths, we prefer the one with maximum string similarity between the fina l versions of the two names. Assigning a weight ( w i ) to each transformation operation v O, S ), we formulate path selection as: This method is based on the assumption that excessive transformation should be avoided wh en a pair of names is being compared. We call this method STP. The STP method calculates the sim ilarity of a person name pair after selecting the best name tr ansformation path. However, some name pairs that should not match nonetheless achieve high similarity after a sequence of name transformations. We therefore should also integrate supervised learning into our matching model. Some transformation paths are simply less reasonable than others. In order to estimate this, each transformation path is assigned a weight W ( TP ). We now define a new sim ilarity measure that takes transformation path weights into account: Let W 1 , ... W n denote the respective weights for the transformation paths TP 1 , ... TP n under consideration. To compute optimal weights { W i }, we formulate the follo wing optimization problem: where F_Value({ W i }) reflects how well our system outputs match up with the ground truth when using{ W i } as transformation path weights. The F-measure [5] (the harmonic mean of precision and recall) is often used to evaluate matching quality; maximizing the F-measure on the training data seeks to achieve similarly good results on the evaluation data. There are two main steps in our algorithm: the first is partitioning name pairs into blocks according to their TP and similarities so that we can operate on them in batches; the second is a multi-way merge sort so that we only have to calculate F_Value N(block) times to detect the best F-measure in training, where N(block) is the number of blocks. Figure 3 illustrates the process of partitioning name pairs into transformation path TP (and hence the same similarity, computed as in Table 1) and rank the name pairs in descending similarity order. We then define block precision as the number of positive name pairs in a block divided by the total number of pairs in the block, and we set a boundary betw een blocks whenever adding a new set of name pairs (i.e., pair s with the same TP) would reduce the block precision . Fi g ure 3. Partitionin g name p airs with same TP into blocks.
M. Joe Penn S O A M. J. Penn M. Penn ( I , N , N ) (I, N) M. J. Pfeng John Pfeng M. Pfen g M. J. Penn Joe Penn M. Penn Figure 4 shows the multi-way merge sorting process: there are three block lists for three name tr ansformation paths; these blocks are merged into the result list in descending order of block precision ; the F-measure (now calculated on pairs, not blocks) typically increases to a unimodal peak and then decreases as the size of result list grows. We search exhaustively to locate the maximum F-measure, and define the corresponding similarity value as the cut point, which we call TH transformation path ( TP i ) , we label the corresponding similarity (as calculated for Table 1) B i and we estimate a reasonable weight for that path as: W i = TH best / B i . We call this method STP+WT. Given a similarity value, we must decide whether two name strings refer to the same pers on. We train a Support Vector Machine (SVM) [7] to learn a decision rule. Our feature set includes the number of initials and non-initials in the matching format, the number of each type of transformation in the transformation path, and the matching similarity. Table 2 shows a decision table that illustrates this process. In our SVM, we use a radial basi s function; the kernel and penalty parameters are tuned following the instructions for libsvm [3]. We label the method STP+SVM for convenience. We evaluate on datasets from th ree sources. The first is the CiteSeer dataset containing citations from four areas in machine learning, originally created by Giles et al. [10]. It has 2,892 references to 1,165 authors. The second is significantly larger: Arxiv (HEP) contains papers from high-energy physics used in KDD Cup 2003. 1 It has 58,515 references to 9,200 authors. The third is from Reuther; it was built upon the Digital Bibliography &amp; Library Project (DBLP) [13]. There are three subsets defined for Reuther X  X  dataset; we use the largest, sub03, which contains 58,399 references to 21,688 author s. Author names were hand-labeled for co-reference in all three datasets. Table 3 summarizes the dataset characteristics. In our experiments, we evaluate matching quality using the F-measure. Coreferent name st ring pairs 798 4,923 2,020 Average characters per name 10.30 12.17 13.57 
Average tokens per name 2.43 2.41 2.50 In previous studies, good results have been reported for the Soft-TFIDF (STF), Jaro-Winkler (JW) , recursive JW (LJW), Monge-Elkan (ME), and recursive ME (LME ) string similarity metrics, so we adopt those as baselines. We implemented each using the Second String Project. 2 Training an SVM adds an additional source of variation, so for these initial experiments we report post-hoc optimal F-measure values based on ranking all candidates in decreasing order of similarity and then sweeping across all possible rank cutoffs to find an optimal (global) rank cutoff for each measure. Pairs above the rank cutoff are classified as matches. As Table 4 shows, for datasets with more unique name strings the task is noticeably harder. Ranging from the most difficult to least we have: DBLP &gt; Arxiv &gt; CiteSeer. STP achieves the highest post-hoc op timal F-measure for all three datasets. The post-hoc optimal F-m easure for the largest dataset, DBLP, is still undesirably low (~ 0.45), although STP did achieve a 25% relative improvement over the next best similarity measure (STF). This motivates our fo cus on supervised techniques. Table 4. Best F-measure on three datasets with six methods. For our experiments with supervis ed methods, we use a variant of three-fold cross-validation in which we split each dataset into three subsets, choosing one for training and the other two for evaluation. This process is rep eated three times, with each third being used as training data exactly once. The three resulting F-measures are averaged to produce the result plotted in Figure 5. CiteSeer is too small for cross-validation, so here we report http://www.cs.cornell.edu/projects/kddcup/ http://secondstring.sourceforge.net/ 
Figure 4. Multi-way merge sorting to calculate the F-measure. results only for Arxiv and DBLP . For STP and STP+WT we report post-hoc optimal F-measur es; for STP+SVM we report the F-measure for the decision rule learned by the SVM. In Figure 5, both supervised methods enhance the F-measure substantially (at least 45%) for DBLP, but far less improvement (about 1.5%) is evident for Arxiv. One possible explanation is that DBLP has a larger number of ambiguous name pairs than Arxiv, and thus perhaps has mo re room for improvement. DBLP is also considerably larger than Arxiv, which results in far more training data being available. The STP+SVM technique achieves results that are reassuringly close to the best post-hoc optimal F-measure with the STP+WT technique; the decision rule learned on the training data by our SVM is clearly quite good. Efficient name matching system is important since the number of name pairs can be very large. We build an index to retrieve similar tokens using the Flami ngo package, which then finds approximately matching strings effi ciently [2]. We also build a token-name inverted index to ra pidly associate tokens with the names that contain that token. Fi gure 6 illustrates this process. It takes only two minutes to build the two indices, and then three minutes to find all pairs that me rit further processing. All name pairs that share one or more sim ilar tokens are processed. For the DBLP dataset, there are 1,592,244 su ch pairs, which is just 0.7% of the total number of possible name pairs. We have introduced the concept of name transformation paths for person name matching. An unsupe rvised method (STP) and two supervised methods (STP+WT, STP+SVM) are proposed that leverage this idea to improve matching accuracy. Experiment results on three datasets show th at our methods perform well. Of course, many names fro m outside the English speaking world are also often present in English texts and in the future we plan to extend our approach to model transformations that are appropriate for those names as well. The authors would like to thank the dataset providers. This work was completed during a visit by th e first author to the UMIACS CLIP lab at the University of Maryland that was supported by National Natural Science Foundation of China Grant 70671007. [1] Arehart, M. D. and Miller, K. J. 2008. A Ground Truth [2] Behm,A., Ji,S., Li, C and Lu,J. 2009. Space-constrained [3] Chang, C.C. and Lin C.J. 2001. LIBSVM: a library for [4] Christen, P. 2006. A Comparison of Personal Name [5] Christen, P. and Goiser, K. 2006. Quality and complexity [6] Cohen, W. W., Ravikumar P ., and Fienberg S. 2003. A [7] Cristianini, N. and Shawe T. J. 2000. An Introduction to [8] Dijkstra, E. W. 1959. A note on two problems in connection [9] Galvez, C. and Moya-Ane gon, F. 2007. Approximate [10] Giles, C. L., Bollacker, K. and Lawrence, S. 1998. CiteSeer: [11] Monge, A. and Elkan, C. 1997. An efficient domain-[12] Piskorski, J., Wieloch, K., Pikula, M. and Sydow, M. 2008. [13] Reuther, P. 2006. Personal name matching: New test [14] Winkler, W. E. 1999. The state of record linkage and current Figure 5. Best F-measure on two larger datasets using STP, 
