 To overcome the training data insufficiency problem for dedi-cated model in topical ranking, this paper proposes to utilize click-through data to improve learning. The efficacy of click-through data is explored under the framework of preference learning. The empirical experiment on a commercial search engine shows that, the model trained with the dedicated la-beled data combined with skip-next preferences could beat the baseline model and the generic model in NDCG 5 for 4 . 9% and 2 . 4% respectively.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Relevance Feedback ; H.4.m [ Information Systems ]: Miscellaneous X  Machine learning Algorithms, Experimentation, Human Factors topical ranking, preference learning, click-through data
Topical ranking is to rank documents for a specific topic, which is usually for a category of queries, such as naviga-tional queries, news queries, product queries, etc. A topical ranking needs a dedicated model for the queries belonging to this category (topic); such a divide-and-conquer strategy is different from a generic model for the ranking of all queries [2]. The amount of training data dedicated to one topic is usually insufficient because human labeling is expensive and time-consuming. We propose to extract click-through data and incorporate it with dedicated training data to learn dedicated model. Specifically, pair-wise preference data, in-cluding skip-above pairs and skip-next pairs, is exploited. From the aspect of learning algorithm, we adopt GBrank algorithm [3] to learn the ranking model because GBrank algorithm has proved to be one of the most effective up-to-date learning-to-rank algorithms; furthermore, GBrank algorithm also takes preference pairs as inputs.

The contributions of this paper are: 1) exploitation of click-through data to improve dedicated model for topical Figure 1: framework of incorporating click-through data with training data to improve dedicated model for topical ranking imp impression, number of occurrence of the tuple cc number of occurrence of the tuple where two ncc number of occurrence of the tuple where url 1 cnc number of occurrence of the tuple where url 1 ncnc number of occurrence of the tuple where url 1 ranking; 2) exploration of the factors of click-through data in helping dedicated model learning.
Figure 1 illustrates the framework of incorporating click-through data with training data to improve dedicated model for topical ranking, for which we seek the best way to utilize click-through data.

We use heuristic rules to extract skip-above pairs and skip-next pairs, which are similar to Strategy 1 (click &gt; skip above) and Strategy 5 (click &gt; no-click next) proposed in [1]. To reduce the misleading effect of an individual click behavior, click information from different query ses-sions is aggregated before applying heuristic rules. For a tu-ple ( q, url 1 , url 2 , pos 1 , pos 2 ) where q is query, url are urls representing two documents, pos 1 and pos 2 are rank-ing positions for the two documents with pos 1  X  pos 2 mean-ing url 1 has higher rank than url 2 , the statistics for this tuple are listed in Table 1.

Skip-above pair extraction: if ncc is much larger than cnc , and cc imp , ncnc imp is much smaller than 1, that means, when url is ranked higher than url 2 in query q , most users click url but not click url 1 . In this case, we extract a skip-above pair, i.e., url 2 is more relevant than url 1 . In order to have highly accurate skip-above pairs, a set of thresholds are applied to only extract the pairs that have high impression and ncc is larger enough than cnc .

Skip-next pair extraction: if pos 1 = pos 2  X  1, cnc is much larger than ncc , and cc imp , ncnc imp is much smaller than 1, that means, in most of cases when url 2 is ranked just below url in query q , most users click url 1 but not click url 2 . In this case, we regard this tuple as a skip-next pair.
 Experiments : We do experiments using the data obtained from a commercial search engine, including training data, testing data and click-through data, which are called generic data. We apply a query classifier to detect dedicated data from generic data. The data details are described in Table 2. We use NDCG 5 to evaluate ranking model. Figure 2: NDCG comparison with different training data.

The experiments are designed to address two questions: 1) can a dedicated model outperform generic model on the predefined query category? 2) what is the empirical results using skip-above or skip-next preferences respectively?
Figure 2 demonstrates NDCG 5 comparison over different training data. Due to insufficiency of dedicated labeled data which is only 15% of the generic labeled data, the generic model is more than 2% better than the dedicated model in NDCG 5 . Another reason is data correlation among different query categories: although a larger portion of labeled data does not belong to the predefined category, they are also useful for training the dedicated model because both the dedicated and the generic model would share some common structure or common pattern. Keep them in the training data could improve generalization capability of a ranking model.

After adding click-through preferences extracted from click-through data, NDCG 5 observation is opposite: click-through based preferences only contributes 0 . 25% NDCG 5 improve-ment over the generic training data; however, combining the dedicated training data and the click-through based prefer-ences together could generate the best model, which show 4 . 91% NDCG 5 improvement over the dedicated model trained only with the dedicated labeled data, and it is also 2 . 44% over the generic model. In general, a dedicated model does outperform the generic model on the predefined query cate-gory. Those click-through based preferences under the query category do provide some novel information to improve the ranking. Figure 3: NDCG comparison with different prefer-ences.

Figure 3 shows NDCG 5 trends over 500 tree iterations of different models. We observe that using skip-next prefer-ences yields better model than using skip-next preferences. There are two reasons to explains this: 1) Essentially, skip-next preferences are consistent with baseline model while skip-above preferences are inconsistent with baseline model. As the dedicated training data is insufficient, the utility of extra consistent data is higher than the utility of extra in-consistent data. 2) There are 18% skip-above preferences which are inconsistent with human labeling, while there are only 4% skip-next preferences which are inconsistent with human labeling. The user click could be easily disturbed by many factors, such as snippet display, word highlight. As NDCG measurement is based on human labeling, the util-ity of skip-above pairs is hurt due to the high inconsistency with human labeling.
This paper has demonstrated the efficacy of utilizing click-through data to improve dedicated model learning for top-ical learning. There are quite a few promising directions along this research work, such as reduce the inconsistency between skip-above preferences and human labeling. [1] T. Joachims, L. Granka, B. Pan, and G. Gay.
 [2] T. Y. Liu. Learning to rank for information retrieval. [3] Z. Zheng, K. Chen, G. Sun, and H. Zha. A regression
