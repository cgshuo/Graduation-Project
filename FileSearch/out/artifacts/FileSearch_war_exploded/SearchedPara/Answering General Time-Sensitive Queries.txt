 Time is an important dimension of relevance for a large number of searches, such as over blogs and news archives. So far, research on searching over such collections has largely focused on locating topically similar documents for a query. Unfortunately, topic simi-larity alone is not always sufficient for document ranking. In this paper, we observe that, for an important class of queries that we call time-sensitive queries , the publication time of the documents in a news archive is important and should be considered in conjunction with the topic similarity to derive the final document ranking. Earlier work has focused on improving retrieval for  X  X ecency X  queries that target recent documents. We propose a more general framework for handling time-sensitive queries and we automatically identify the important time intervals that are likely to be of interest for a query. Then, we build scoring techniques that seamlessly integrate the temporal aspect into the overall ranking mechanism. We ex-tensively evaluated our techniques using a variety of news article data sets, including TREC data as well as real web data analyzed using the Amazon Mechanical Turk. We examined several alterna-tives for detecting the important time intervals for a query over a news archive and for incorporating this information in the retrieval process. Our techniques are robust and significantly improve re-sult quality for time-sensitive queries compared to state-of-the-art retrieval techniques.
 Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.m [Miscella-neous]: Processing Time-Sensitive Queries.
 General Terms: Algorithms, Performance, Experimentation.
 Keywords: Time-Sensitive Search.
Time is an important dimension of relevance for a large number of searches, such as over blogs and news archives. So far, research on searching over such collections has largely focused on retrieving topically similar documents for a query. Unfortunately, ignoring or not fully exploiting the time dimension can be detrimental for a large family of queries for which we should consider not only the docu-ment topical relevance but the publication time of the documents as well, as demonstrated by the following example: E XAMPLE 1. Consider the query [Madrid bombing] over the Newsblaster [ 6 ] news archive. Figure 1 zooms in on a portion of the histogram for the query results, reporting the number of matching queries by incorporating time into language models 1 in a principled manner. For a given time-sensitive query over a news archive, our approach automatically identifies important time intervals for the query. These intervals are then used to combine temporal relevance and topic similarity, to adjust the document relevance scores by boosting the scores of documents published within the important intervals. The goal is to return results that are both topically relevant to the queries and are also from the most  X  X mportant X  time periods for the queries.
 Incorporating Time into LM: The query likelihood model (QL) [ 8 ] estimates the relevance of a document d to a query q by computing the conditional probability p ( d | q ) that d is topically relevant to q , which is proportional to p ( d )  X  p ( q | d ) . To answer general time-sensitive queries such as [Madrid bombing] , we want to identify not just the relevant documents for the query, but also the relevant time periods. Craswell et al. [ 1 ] introduced a framework to complement the topical relevance of a document for a query with additional evidence (e.g., ClickDistance [ 1 ]). We build on this framework and conceptually  X  X ecouple X  each document d into a content component c as well as a temporal component t d . We can then express p ( d | q ) as p ( c d ,t d | q ) , which represents the probability that c d is topically relevant to q and that t d is a time period relevant to q , where c d is the content of document d and t d is the time when d was pub-lished. Assuming that topic similarity is conditionally independent of temporal relevance, given query q , we have: Note that c d is what we traditionally refer to as d in language models; our use of c d is to emphasize that a document in our modified model consists of the traditional textual content component c d and the temporal information t d . So, the document prior p ( c d ) is typically assumed to be uniform for all documents, considering that there is no document that is more likely to be relevant across all possible queries . The time prior p ( t d ) can be defined proportionally to the total number of documents published at time t d . The term p ( q | c d ) corresponds to the likelihood of generating query q from document c and can be computed using existing techniques, such as the QL model or the relevance language model (RM) [ 3 ]. Finally, p ( q | t d ) corresponds to the probability of  X  X bserving X  q in the documents published in time t d . We call this probability the temporal relevance of t d and we discuss how to estimate it next.
 Computing Temporal Relevance: We estimate p ( q | t ) for query q and time t by analyzing the number of documents matching query q over time. Our conjecture is that certain patterns of matching fre-quencies over time might help identify relevant time periods for the query. For example, an abrupt change in match frequency between consecutive days might signal a relevant event for the query. To incorporate time into the language models, we then estimate p ( q | t ) based on the distribution of query matches over time. Specifically, we propose to arrange all time periods into bins , such that each bin represents a  X  X riority level. X  We then assign estimated relevance values to the time periods in these bins accordingly. We have ex-plored alternate binning techniques based on different underlying hypotheses on how to identify the important time intervals. For example, our  X  X unning mean X  technique considers the average daily match frequency across the archive, to calibrate the  X  X opularity X  of a query, in terms of its document matches in the archive over time. For this, we  X  X educe X  the match frequency of a day by subtracting the average daily match frequency computed up to that day. We use the reduced frequencies to sort times into bins, so that bin b 0 will contain the days with the largest reduced frequency, b 1 will
We have also incorporated time into BM25 [ 7 ], but we omit the discussion because of space constraints.
