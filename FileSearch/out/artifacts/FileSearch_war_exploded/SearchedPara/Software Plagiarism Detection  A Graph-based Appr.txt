 As plagiarism of software increases rapidly, there are growing needs for software plagiarism detection systems. In this paper, we propose a software plagiarism detection system using an API-labeled control flow graph ( A-CFG ) that abstracts the functionalities of a program. The A-CFG can reflect both the sequence and the frequency of APIs, while previous work rarely considers both of them together. To perform a scalable comparison of a pair of A-CFG s, we use random walk with restart ( RWR ) that computes an importance score for each node in a graph. By the RWR, we can generate a single score vector for an A-CFG and can also compare A-CFG s by comparing their score vectors. Extensive evaluations on a set of Windows applications demonstrate the effectiveness and the scalability of our proposed system compared with existing methods. H.2.8 [Database Management]: Database Applications -Data Mining Security Software Plagiarism; Binary Analysis; Graph; Similarity Software plagiarism is to develop software using someone else X  X  source code or open source code without license and disguise as original software [1]. As software plagiarism increases rapidly, there have been serious economic losses in the software industry. According to the business software alliance ( BSA ) report, the financial damage of USA due to software plagiarism is about 95 million dollars, and that of China is about 77 million dollars in 2010 [1]. To mitigate such economic losses, software plagiarism detection systems are in great needs. Especially, detecting plagiarism by comparing two executable files (hereafter, we call these as programs) without having their source code has been recently studied since the source codes of suspicious programs are typically unavailable. A software plagiarism detection system may include two functions: representative feature extraction from two programs and similarity computation using the extracted features. Feature extraction methods can be divided into two categories: static analysis and dynamic analysis . Static analysis methods extract features without executing a program, while dynamic analysis methods focus on the runtime behavior of the program [2]. Dynamic analysis methods may extract different features in different conditions of execution environments. Moreover, the features extracted through dynamic analysis methods may reflect only a small part of the program since a single execution path may cover only a small part of the program [2-4]. In contrast, static analysis methods make it possible for features to inherit overall characteristics of a program. One of the problems with static analysis methods is that encrypted or compressed programs cannot be analyzed. However, contrary to malicious programs, commercial programs usually are not applied with encryption or compression techniques. Therefore, in our proposed system, we use a static analysis method to extract features from a program and compute similarities using them. Existing plagiarism detection methods can be categorized into three types based on the form of the extracted features: set-based approaches, frequency-based approaches, and sequence-based approaches. Set-based approaches, for example, use a set of API calls used in a program [2]. Thus, the set-based features ignore the sequence or frequency of APIs. Frequency-based approaches count call frequencies for each API and then generate a frequency vector [3]. These approaches also cannot reflect the sequence of APIs. Sequence-based approaches use the full sequence of API calls [4] or instructions [5] from execution traces of a program. However, these approaches may suffer from high time complexity in a similarity computation phase because the number of execution traces may increase exponentially as the number of branches in a program increases. For this reason, these approaches are applicable to only small-size programs [5]. In this paper, we propose a software plagiarism detection system which uses both sequence and frequency of APIs and also computes a similarity using these two features in reasonable costs. To achieve these goals, we first use API-labeled control flow graphs ( A-CFGs ). An A-CFG is a graph representation of a program, which consists of APIs as vertices and call sequences of APIs as edges. Since the degree of a node indicates the call frequency of the API and each edge indicates the sequence between APIs, an A-CFG includes both sequence and call frequency of APIs while previous work rarely considers both of them together. The A-CFG not only inherits unique characteristics of a program but also is robust to plagiarism because it is difficult for a plagiarist to manipulate the call frequency or the sequence of APIs or to replace APIs with something else while maintaining the program X  X  original semantics [2-4]. Secondly, we employ random walk with restart ( RWR ) [6] to generate a single score vector for an A-CFG . Since most of graph comparison algorithms such as graph isomorphism or maximum common sub-graph are known as NP-complete and the size of the A-CFG is huge, it is infeasible to compare two A-CFG s in the practice [10]. Instead of comparing two graphs directly, we generate score vectors representing the topologies of A-CFG s and compare the two vectors using cosine similarity [7]. Since the scores computed by RWR reflect the global structure of a graph [6], the RWR score vectors can be used as a representative feature of A-CFG s. As a result, it is possible to measure a similarity between two massive graphs in short time using these vectors. Based on the similarity between two A-CFG s, our proposed system finally determines plagiarism. In our proposed system, we use invocations of application programming interfaces (APIs) as unique and robust features of a program. API invocations are a common way for a program to request services provided by operating systems. Because resources and services used by a program are highly related to the program X  X  main functionalities, APIs called in the program to access the resources and services are also highly related to the main functionalities of the program. Moreover, it is difficult to replace API invocations with other instructions, while preserving the program X  X  original semantics. In this paper, we define a novel feature of the program named A-CFG , which is able to reflect both sequence and call frequency of APIs. The definition of A-CFG is as follows: Definition 1 ( A-CFG: API-labeled control flow graph ) The API-labeled control flow graph of a program p is a 2-tuple graph A-CFG = ( N,E ), where  X  N is a set of nodes, where a node n N corresponds to an API called in p.  X  E N  X  N is a set of edges, where an edge n 1 n 2 corresponds to a possible sequence between nodes n 1 and n To capture all the possible sequences of API calls, we use control flow graph s (CFG). A CFG is a graph representation of a procedure in which each node represents a basic block . A basic block is a maximal sequence of instructions without a change of control flows. Directed edges are usually used to represent control flows of a program [11]. We build the A-CFG through the following processes: (1) bringing all CFGs together in one graph based on the program X  X  inter-procedure-call relationship, and then (2) labeling basic blocks with API calls in the block. In the process (1), the basic blocks which have procedure-call instructions are split into two blocks at the position of the instruction, and the target procedure X  X  CFG is located between two split blocks. In the process (2), basic blocks that do not include an API-call instruction are labeled as  X  X mpty X  and the blocks that call more than two APIs are recursively split until one block has a single API call instruction. Figure 1 shows simple examples of CFGs of a program which consists of three procedures , , and . Figure 2 shows the A-CFG of the program. Based on the process (1), basic blocks b and c in the CFG are split into two blocks, and the CFG and the CFG are located between split blocks, respectively. After all CFGs are combined, each block is labeled as the name of the API if a block has an API call, as the case of the block a in the CFG , or labeled as  X  X mpty X  if the block does not have any API calls. Since an A-CFG usually has tens of thousands or millions of nodes, most of graph comparison algorithms such as graph isomorphism or maximum common sub-graph are infeasible to be employed in practice [10]. To deal with this scalability problem, we exploit random walk with restart (RWR) [6] as a way of extracting an n -dimensional vector from the A-CFG and compute the similarity between the two vectors. The vector of an A-CFG , named RWR score vector , is defined as follows: Definition 2 ( RWR score vector ) The vector of an A-CFG , named RWR score vector is an n -dimensional vector, where  X  n is the number of APIs defined by MSDN [8].  X  An RWR score is a score of each node calculated by the RWR method.  X  The value of each dimension is the summation of RWR scores that the corresponding API gets in the A-CFG . If one API may exist multiple places in an A-CFG , we aggregate all RWR scores that one API gets. RWR is widely used to calculate each node X  X  importance in a graph [13, 14, 15]. By Equation 1, RWR calculates the probabilities that a random walker reaches each node at step t +1. In Equation 1, A is an adjacency matrix that represents the relationships between APIs. R ( t+1 ) and R ( t ) are vectors that indicate the probability of the random walker reaches each node at t+1 and t steps, respectively. The initial values of the vector R assigned with the same value, 1/n , where n is the number of nodes. A restart vector, w represents the probability that the random walker jumps to each node, not traversing through the edges of the graph. a is a weight that determines how often the random walker jumps to other nodes rather than following the edges. A-CFG , elements in R ( t ) indicate the importance of corresponding APIs in a program. Additionally, our proposed system modifies the restart vector in Equation (1) to avoid being unreliable due to common APIs . Since the common APIs perform essential tasks such as exception handling or memory management, they are used not only in most of programs but also frequently in a program. If these APIs get high scores, it would be difficult to differentiate programs. To reduce the effect of common APIs , the restart vector is modified as in Equation (2). Let PF (program frequency) be the number of programs using the API, and CF (call frequency) be the number of the API-call in each program. Then, let w (API) be the value of the element corresponds to the API in the vector w , PF(API) and CF(API) be the PF and CF of the corresponding API, respectively. Then, we give a value to each element in the vector w as follows: This modification finally reduces the RWR scores of common API s and increases those of APIs uniquely called in a specific program. It helps capture accurately the unique characteristics of each program. As a similarity measure between two RWR score vectors , we use the cosine similarity , which is widely used to calculate the similarity between two vectors [8]. The similarity between two vectors ranges between 0 and 1. Following [3] and [7], the proposed system classifies two programs as follows: in Equation (3) denotes the plagiarism threshold. When the similarity between two programs is in the range of [ , 1.0], our proposed system decides the two programs to be classified as  X  plagiarized  X . Otherwise, it decides them to be  X  independent  X . We analyze the accuracy of our proposed system according to the threshold in Section 4. This section shows our experimental results on a set of Windows application programs comparing A-CFG against the state-of-the-art systems for software plagiarism detections. We evaluate our proposed system against 56 benchmark programs shown in Table 1. There are 28 kinds of different programs and each program has two different versions. Because it is difficult to get plagiarized samples, we assume that a recent version of a program is a  X  plagiarized  X  sample of the program. Since a program update is mostly processed by modifications of the original program, it can be also viewed as a plagiarism [2-3]. SC in Table 1 denotes an existence of the source code of the corresponding program. We implemented our proposed system using A-CFG , the set-based system proposed by Choi [2], and the frequency-based system proposed by Chae [3]. As another baseline, we implemented a system using an API set as a feature and Jaccard coefficient as a similarity measure. We also implemented the sequence-based system proposed by Lim [5], but we excluded it from the evaluations because of its extremely high computational costs. Its computational overhead on the similarity computation phase is extremely high because the number of sequences from a program is exponential to the number of branches in the program. For example, 83,104 sequences are extracted from Foobar2000 and 58,492 sequences from WinSCP , and it takes about 5.4 hours for the feature extraction and similarity computation while our proposed system takes only 35 seconds. To evaluate the systems, we used three measures: area under the F-measure curve ( AUC ), average similarity ( AS ), and correlation with source code similarity ( CSS ). Detailed introductions of each measure are explained in the following sections. In this experiment, we evaluate the proposed system in terms of AUC. AUC is widely used to represent how a system performs over the entire space of threshold [5]. The higher AUC indicates that the system can provide high accuracy insensitive to threshold . We draw an F-measure curve for each system and calculate their AUC s respectively. To draw an F-measure curve for each system, each system computes similarities between all pairs of the benchmark programs shown in Table 1 and detects  X  plagiarized  X  samples with changing the threshold between 0 and 1. Figure 3 shows the F-measure curves and Table 2 shows AUC values of each system. Each system provides its own maximum F-measure value on a specific threshold . However, our proposed system X  X  interval which provides high accuracy is wider than that of all the others. Table 2 also shows our proposed system outperforms all the other systems. AS evaluates how similarities driven from a system are reasonable. In this experiment, we measure two kinds of AS : AS among all pairs of the same program with different versions ( ASP ) and AS among all pairs of the different programs ( ASD ). The higher ASP indicates that the ability to detect plagiarism is good. Similarly, the lower ASD indicates that the ability to distinguish a program with a different program is good. Figure 4(a) shows the results of ASP and Figure 4(b) shows those of ASD . The results in Figure 4(a) show that all the systems provide similar ASP . Jaccard provides the highest ASP and our proposed system follows it. However, the results in Figure 4(b) show that Jaccard has a potential to cause more false alarms because of the high ASD . Both set-based and freq-based systems provide lower AS Ps and higher AS Ds than that of our proposed system. Our proposed system provides a much lower AS D compared to the other systems while providing a sufficiently high ASP . It implies that our proposed system distinguishes different programs most credibly as well as is very competitive enough to detect plagiarism. In this experiment, we evaluate the trustworthiness of the systems by measuring correlations between the program similarity and the source code similarity. The higher CSS indicates that the similarity driven from the system provides the trustable similarity between programs. To calculate CSS , we compute similarity between source codes of open source programs shown in Table 1. At this step, we employ MOSS [9] which is widely used for comparing source codes, and we measure the CSS with Pearson correlation coefficient [7]. Table 2 shows the CSS results of different systems. Even though all the systems show high CSS, but our proposed system provides the highest result. This indicates that our proposed system provides the most trustable similarity between programs. We have proposed a software plagiarism detection system using an API-labeled control flow graph ( A-CFG ). The A-CFG can represent both the sequences and the frequencies of APIs, which are hardly changed by semantic-preserving transformation attacks. We also have performed a scalable comparison between A-CFG s by representing each A-CFG as a single score vector through RWR . The experimental results show that our proposed system outperforms existing methods in terms of both accuracy and credibility in a reasonable computation time. This research was supported by (1) Ministry of Culture, Sports and Tourism (MCST) and from Korea Copyright Commission in 2013, (2) Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology (No. 2012R1A1A2007817), and (3) MSIP (the Ministry of Science, ICT and Future Planning), Korea, under the IT-CRSP (IT Convergence Research Support Program) (NIPA-2013-H0401-13-1001) supervised by the NIPA (National IT Industry Promotion Agency). 
