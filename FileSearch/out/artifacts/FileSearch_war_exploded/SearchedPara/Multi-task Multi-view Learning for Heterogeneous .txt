 Multi-task multi-view learning deals with the learning sce-narios where multiple tasks are associated with each other through multiple shared feature views. All previous works for this problem assume that the tasks use the same set of class labels. However, in real world there exist quite a few applications where the tasks with several views corre-spond to different set of class labels. This new learning scenario is called Multi-task Multi-view Learning for Hetero-geneous Tasks in this study. Then, we propose a Multi-tAsk MUlti-view Discriminant Analysis (MAMUDA) method to solve this problem. Specifically, this method collaboratively learns the feature transformations for different views in dif-ferent tasks by exploring the shared task-specific and prob-lem intrinsic structures. Additionally, MAMUDA method is convenient to solve the multi-class classification prob-lems. Finally, the experiments on two real-world problems demonstrate the effectiveness of MAMUDA for heteroge-neous tasks.
 I.2.6 [ Artificial Intelligence ]: Learning X  Machine Learn-ing Multi-task Learning; Multi-view Learning; Heterogeneous Tasks; Discriminant Analysis; Multi-class Classification
Many real-world problems exhibit dual-diversity. Indeed, it is often to see that a single learning task has features in multiple views. This is known as multi-view learning. Also, there are multi-task learning scenarios, where differ-ent learning tasks might be related with each other through one or more shared views (features). For example, the task of classifying web pages from Yahoo 1 is related with the http:/ /www.yahoo.com/ task to classify web pages from Open Directory Project 2 . Meanwhile, we can obtain three views of features for a given web page including the content of the web page, the an-chor text attached to hyperlinks pointing to this we bpage, and the link structure of all linked web pages. Another example is the music classification problem. As we know, classifying English songs and Chinese songs are two related tasks, and both tasks have audio features. However, these two tasks also have task-specific features, such as Chinese song lyric and English song lyric. Such type of problems are widely known as Multi-task Multi-view (MTMV) learning problems [14, 26, 16].

The traditional multi-task learning (MTL) [5, 6, 7, 22] or multi-view learning (MVL) [4, 8, 21] methods are not designed for the MTMV problem. There are MTMV learn-ing methods [14, 26, 16], which can make a good use of the information contained in multiple tasks and multiple views. However, they all have the assumption that the mul-tiple classification tasks have the same set of class labels, and they are designed for binary classification problems. In many real-world applications, multiple tasks often do not share the same set of labels. For example, in the web page classification problem, the categories in Yahoo and the Open Directory Project are not the same. In other words, each task has a task-specific class label set. Similarly, for the mu-sic classification problem, English songs usually have differ-ent categories from Chinese songs because of the difference between western and eastern culture. In this paper, we call this type of problem as the MTMV problem with heteroge-neous tasks. In contrast, the traditional MTMV problem, in which all tasks share the same label set, is treated as the MTMV problem with homogeneous tasks. Figure 1 shows the difference of these two types of problems.
 (a) Homogeneous Tasks http:/ /www.dmoz.org/
Existing MTMV learning methods [14, 26, 16] are not de-sign ed for MTMV problems with heterogeneous tasks, since they assume all the tasks have the same class label set and they share knowledge among multiple tasks by sharing some class-dependent model parameters. Also, they are binary classification methods, which require nontrivial extensions in order for them to handle multi-class problems, especially when the number of classes is large.

To this end, in this paper, we propose a Multi-tAsk MUlti-view Discriminant Analysis (MAMUDA) learning method. Since multiple views of features exist in the problem, it is difficult to directly share knowledge through the original fea-ture space. To facilitate information sharing, this paper ex-tends the classical LDA method [12] and collectively learns the feature transformation matrices for all the views from each task. The classical LDA model tries to transform a feature vector x (row vector) in the original feature space into a vector x  X  in the discriminant feature space , through which the data become more separable. This process is ex-plicitly shown in Figure 2, which also can be written in the equation xW = x  X  . Here, W is the matrix for feature trans-formation.
 Figure 2: LDA Feature Transformation Process Figure 3: MAMUDA Feature Transformation Pro-ces s
In our method, the transformation is divided into two steps, which is shown in Figure 3. First, through the trans-formation matrix Q v t , a data sample x from the view v in task t is transformed into an intermediate latent space . { Q are dependent on the views and tasks, thus they are different for different views and tasks. Through { Q v t } , all the views from all the tasks are transformed into a common interme-diate latent space that is shared by all the views from each task. Then, through { R v t } , an instance from each view of each task is transformed from the common intermediate la-tent space into their corresponding discriminant space. R contains two parts of information. One is R , which is shared by all the views from every task. The other part R t is shared by the views for a specific task t . They help the knowledge sharing among tasks and views.

With these assumptions we formulate an optimization prob-lem which collaboratively learns the feature transformations of the data from each view and each task. An alternating optimization algorithm is proposed to solved the problem, where each subproblem can be guaranteed to achieve global optimality. With the transformation matrices Q v t and R v the data can be transformed into the discriminant space. Namely, for a data vector x from the view v and task t , its corresponding discriminant space representation is xQ v t Then, the nearest neighbor classifier is used to make predic-tion in the discriminant feature space.

In summary, our method has several advantages. First, it does not require that multiple tasks share the same class label set and can solve the MTMV problem with hetero-geneous tasks. Second, by using a simple nearest neighbor classifier in the final discriminant feature space, it is very convenient to solve multi-class classification problems. Fi-nally, it can deal with the scenarios when some views may be missing in some tasks.
Here, we first define the MTMV problem with heteroge-neous tasks. Then, we introduce some preliminaries.
Notations. Let [ N : M ] ( M &gt; N ) denote a set of integers in the range of N to M inclusively, tr( X ) be the trace of matrix X , X  X  1 be the inverse of X , kk denote the Frobenius norm of a matrix, and I l be the l  X  l identity matrix. Unless specified otherwise, all vectors are column vectors.
The MTMV problem definition is very similar to [26, 16], except that our formulation is more flexible as we do not restrict that all the tasks have the same set of class labels. Assume that the problem includes T tasks and V views in total. For each task t  X  [1 : T ], there are n t labeled exam-ples, thus we have N = P t n t . Let d v be the number of features in the view v  X  [1 : V ], and the total number of features D = P v d v .
 samples in task t for view v , each row represents a sample. Let Y t  X  [1 : C t ] n t  X  1 be the label vector of the labeled ex-amples in task t , where C t is the number of classes in task t . In the ideal situation, every task has features from all the V views. However, in reality, it is common that, in some applications, not all tasks have features available from all the V views, so an indicator matrix I id  X  { 1 , 0 } T  X  V to mark which view is missing from which task; that is, if the task t contains view v then I id ( t, v ) = 1, and 0 other-wise. Using this notation, we only consider the  X  X tructured X  missing views [26] in the sense that, if a view is present in a task, it is present in all the samples in the task; if a view is missing from a task, it is missing in all the samples in the task. Throughout the paper, we use subscripts to denote tasks and superscripts to denote views.

The goal of this paper is to leverage the information from all the tasks and all the views to help each other classify the unlabeled test samples in each task.
Linear Discriminant Analysis (LDA) [12] is a popular su-pervised dimensionality reduction technique in pattern recog-nition and machine learning. Traditionally, LDA is used for single learning tasks with single view data. Assume that there are N labeled training samples, represented by feature matrix X  X  R N  X  d and label vector Y  X  [1 : C ] N  X  1 , where each row vector x i in X denotes a sample and its label y the i -th element of vector Y , d is the number of features and C is the number of classes. There are N c samples in c -th class, i.e., P C c =1 N c = N . Let us define between-class scat-ter matrix S b = P C c =1 N c N (  X  m c  X   X  m )  X  (  X  m scatter matrix S w = P C c =1 P y total scatter matrix S h = P N i =1 1 N ( x i  X   X  m )  X  ( x  X  m = ( P N i =1 x i ) /N is the sample mean for the whole training set and  X  m c = ( P y class. It can be easily verified that S h = S b + S w . There are two types of objective functions for LDA that are widely used. The first one is the ratio trace form [12]: and the second one is in the trace ratio form [23]: w here l is the reduced dimensionality of the trace ratio form, W  X  R d  X  l is the transformation matrix for dimension re-duction. The solution of the ratio trace form can be ob-tained by computing the eigenvectors of the matrix S  X  1 w while the trace ratio form has no analytical solution and has to resort to an iterative method to obtain the optimal solution. However, the trace ratio form has a much clearer physical meaning. The numerator and denominator of the objective function in the trace ratio form represent the av-erage between-class distance and average total distance in the low-dimensional space, respectively, which is consistent with the aim of LDA that tries to maximizing the within-class similarity and minimizing the between-class similarity simultaneously. In this paper, the trace ratio form is used.
For classification problems, after obtaining the transfor-mation matrix W , the data sample x in the original feature space can be transformed into the discriminant space by computing xW . Then, nearest neighbor classifier can be used to make predictions in the discriminant space.
For Multi-task Multi-View (MTMV) learning, if we do not consider the relationships between multiple views and multiple tasks, a naive way to use LDA is as follows. For each view v in each task t , as described in Section 2.1, we can compute its corresponding between-class scatter matrix S v and total scatter matrix S v t,h . Using the trace ratio form, the optimization problem can be formulated as: w here l is the reduced dimensionality of the trace ratio form, W t  X  R d v  X  l is the transformation matrix for dimensional-ity reduction for view v in task t , and d v is the number of features in view v .

When multiple tasks with multiple views are available, it is better to share knowledge among them to obtain im-proved results compared to learning them separately. In-stead of directly sharing some class-dependent model param-eters among multiple tasks, we propose a multi-task multi-view discriminant analysis (MAMUDA) method to take ad-vantage of the common structure representing some char-acteristics of the application. By solving the optimization problem, the transformation matrices can be obtained and a simple nearest neighbor classifier can be used to perform classification in the transformed lower-dimensional discrim-inant space.
When multiple related tasks are available, it is better to learn them together and share some knowledge among them to get better results. So, based on Eq. (3), combining all the tasks and all the views X  optimization problems into a unified form, we have the following optimization problem: T he purpose of the optimization problem is to find the trans-formation matrices { W v t } that transform the data from the original feature space into a discriminant space, where the data become more separable. Further, to facilitate the in-formation sharing among multiple tasks, the transforma-tion process is divided into two steps: (a) the data from all the tasks are transformed from their corresponding orig-inal feature space into a common intermediate latent se-mantic space, which reflects the intrinsic characteristics of the applications; (b) data from each view of each task are transformed from the common intermediate latent space into their corresponding discriminant space. Along this line, the optimization problem can be explicitly described as: w here { Q t } are dependent on the views and tasks. Through ma-trices { Q v t } , the original data from all the views in every task, which have different feature representations, are trans-formed into a common intermediate latent semantic space. In addition, since the multiple tasks are from the same ap-plication, there will exist a common structure that is shared by all the tasks representing some characteristics of the ap-plication itself. The common structure can be used to fa-cilitate the learning process of { R v t } , by taking advantage of the common intermediate latent space. Meanwhile, each task will have some specific characteristics that are only con-tained in this task. So, multiple views of this task can be used to jointly learn these task-specific structures. As a result, the transformation matrix R v t can be divided into two parts: one part is for the common structure shared by multiple tasks corresponding to the common discriminant components, while the other part learns the task-specific discriminant components that is shared by different views of this task. Different tasks and different views can share knowledge through the common structures. The optimiza-tion problem can be described as: where
It must be noted that the number l  X  of shared discrim-inant components can be adjusted to accommodate to the relatedness of different tasks. For closely related tasks, we may use a large l  X  even equal to the total discriminant di-mension l , and for loosely related tasks, we may use a small l even equal to zero which is equivalent to no knowledge shared between different tasks.
When the transformation matrices { Q v t } and { R v t } are obtained, it is very straightforward to transform the data samples from the original feature space into low-dimensional representation in the discriminant space. Indeed, for each task, different views of features are available, and we can obtain the new representation for each view. For the i -th data sample with view v in task t , denoted by x v t,i , its new different views in a specific task, which means different views are transformed into a same discriminant space. Each view X  X  data may have noises. So, average different views X  represen-tations for each task and obtain the final representation is a better choice. The final representation can be written can be used to make predictions in the discriminant feature space.
It is difficult to solve the optimization problem (6) with respect to { Q v t } , { R t } and R jointly. In the following, an al-ternating optimization algorithm is presented. Specifically, we optimize the objective function with respect to each vari-able while the other variables are fixed. This procedure is repeated until convergence.
Note that tr([ R, R t ]  X  Q v t  X  S v t,b Q v t [ R, R t ]) = tr( R Q fixed, the optimization problem (6) becomes: where a and b are constants: According to the constraints in Eq.(6), R  X  R = I l  X  , so tr( R l . So Eq.(7) can be rewritten as: w here The problem in Eq.(9) has the same formulation as the trace ratio form of LDA, so a similar iterative method as in [23] is given in Algorithm 1 to solve it. As proved in [23], this algo-rithm will converge and return the globally optimal solution. Algorithm 1 Comp utation of R with Fixed { Q v t } and { R Input:  X  S b ,  X  S h Output: R Metho d: 1: Initialize R (0) that satisfies R (0)  X  R (0) = I l  X  ; 2: for k = 1 to maxIteN um do 3: Compute the trace ratio value as: 4: Construct the trace difference problem as: 5: Solve the trace difference problem using the eigenvalue 7: Let R ( k ) be the eigenvector matrix of S tmp corre-9: end for 10: return R = R ( k ) .
When R , { Q v t } and { R i } ( i 6 = t ) are fixed, the optimization problem (6) becomes: where a t and b t are constants: According to the constraints in Eq.(6), R t  X  R t = I l  X  l  X  tr( R t  X  R t ) = l  X  l  X  . Then, Eq.(11) can be rewritten as: where The problem in Eq.(13) has the same formulation as the problem in Eq.(9), so it can be solved by a very similar iter-ative method as in Algorithm 1. Also, the globally optimal solution can be obtained. When R , { R t } and { Q j i } ( i 6 = t, j 6 = v ) are fixed, and R t = [ R, R t ], the optimization problem in Eq. (6) becomes: where a v t and b v t are constants: According to the constraints in Eq. (6), Q v t  X  Q v t = I R Q  X  Q v t R v t ) = l . The optimization problem in Eq. (15) can be rewritten as: where We further rewrite it as: where A v t = R v t R v t  X  . This problem has the same formulation as Eq.(7) in [27], the optimization procedure of it is given in Algorithm 2.
 The solution of the trace difference problem in Step 5 of Algorithm 2 is given by the Theorem 1 [27]. The algorithm will return the globally optimal solution of problem (19). Theorem 1. Let A be a real p  X  p symmetric matrix and B be a real q  X  q positive semidefinite matrix where p &gt; q . Then where  X  i ( A ) denotes the i -th largest eigenvalue of matrix A . The optimal solution satisfies W  X  = U a U b  X  Q , where U is the eigenvector matrix of A corresponding to the top q eigenvalues, U b is the eigenvector matrix of B , and Q is any q  X  q orthogonal matrix.
 Algorithm 2 Comp utation of Q v t with Fixed R , { R t } and { Q Output: Q v t Method: 2: for k = 1 to maxIteN um do 3: Compute the trace ratio value as: 4 : Construct the trace difference problem as: 5: Solve the trace difference problem: Let Q v ( k ) t 7: Let Q v ( k ) t be the eigenvector matrix of S tmp corre-9: end for
In ma ny real world problems, multiple tasks do not have the same set of views. Some tasks may miss some views of features that are existing in other tasks. It is straightfor-ward to deal with the problems that have structured missing views using the methods described in the above sections. If view v is missing from task t , then the variables concerning this view in this task will be eliminated in the computation process. It is obvious that the structured missing views do not affect the formulation of calculation formula of other variables, thus the proposed optimization problem in Eq.(6) can be regarded as a general framework for dealing with MTMV problems.
In this section, we systematically evaluate the effective-ness of the proposed Multi-tAsk MUlti-view Discriminant Analysis (MAMUDA) method. The classification results for problems with both complete views and missing views are given to show the performances of MAMUDA.
Two applications have multiple tasks with multiple views are considered in this paper, some statistics of them are summarized in Table 1, where T1 represents the first task in a problem, V1, V2 and V3 denotes three different views of features. Originally, every task in the two applications has all the views of features. We also consider the missing view problems by randomly eliminating some views. Miss-ing views are shown in Table 1 using the symbol  X   X   X  and existing views using  X  in a problem have different number of classes, i.e., they do not share the same set of class labels. Thus, they are MTMV problems with heterogeneous tasks. The specific character-istic s of these two problems are given below.

Leaves: The leaves data set [11] includes leaves from one hundred plant species that are divided into 32 differ-ent genuses, and 16 samples of leaves for each plant species are presented. For each sample, three views of features are available, including shape descriptor, fine scale margin and texture histogram, and each view has 64 features. 4 genuses that have 4 or more plant species are selected to form 4 tasks, and the aim of the problem is to discriminate differ-ent species in a genus, which is a multi-class classification problem. Overall, the problem has 4 tasks with 3 views, and different tasks have different number of classes. Some views are randomly eliminated from the data to form its corresponding missing view problem, as shown in Table 1.
Face: In the face recognition problem, we use 3 face data-bases: PIE [19], Yale 3 and ORL [3]. PIE contains facial images for 68 persons. We choose the Pose C09 from PIE, which contains 24 images for each person. Yale contains 165 images for 15 individuals. There are 11 images for each individual, and each one with different facial expression or configuration. ORL contains 400 face images of 40 persons, each having 10 images. These face images have significant variations in pose and scale. Before the experiment, each image is converted to gray scale and normalized to two dif-ferent sizes of 32  X  32 pixels and 28  X  28 pixels, which pro-vides two different views of features for the image. The face recognition problem for each database can be seen as a task, so there are 3 tasks with 2 views in total. Each task cor-responds to a multi-class classification problem where the number of classes in each task is equal to the number of persons in each database. After randomly eliminating some views, the missing view problem is shown in Table 1. Problem T V1 V2 V3 clas s # sample # (Mis sing (Mis sing
Since most previous methods [14, 26, 16] assume that mul-tiple tasks in a problem should be similar and share the same set of class labels, and they are formulated for binary classification problems, they cannot be directly applied to the application scenarios in Section 4.1. Therefore, we first compare MAMUDA with several methods that can solve the MTMV problems with heterogeneous tasks. For all these al-gorithms, they learn discriminant space representations and http:/ /cvc.yale.edu/projects/yalefaces/yalefaces.html a simple nearest neighbor is used to perform classification in the lower-dimensional space. These algorithms are described as follows:
Second, previous MTMV algorithms are designed for bi-nary classification problems. To further compare our algo-rithm with the previous MTMV algorithms, we need to con-vert the multi-class classification problem into a set of binary classification problems using the one-against-all method for previous algorithms. Two MTMV algorithms are used:
In the experiments, different numbers of samples are ran-domly selected for each class to investigate the effect of vary-ing the size of training set on classification performances. For each configuration, we perform 10 random trials and the average error rates are reported. The average error rate is the percentage of wrongly classified samples among all the test samples from all tasks.
For the Leaves problem, we randomly select n  X  { 2 , 3 , 4 , 5 } samples for each class as training set and the rest as the test set. Here we do not set n = 1, since in this case there is only one labeled sample in each class, the between-class scatter matrix is equal to the total scatter matrix and we cannot build a meaningful optimization problem. The parameters used are:  X  l = 50, l = 100 and l  X  = 50. Each experiment is re-peated 10 times, and the average error rates of all the tasks are shown in Figure 4, where for LDA algorithm the average error rates of the three views from multiple tasks are given. For MTDA algorithm, each view X  X  results are given sepa-rately, and MTDA-i represents the results of MTDA algo-rithm using the i -th view data. It can be seen that there are great distinctions on different views X  X  ability for classifica-tion using MTDA algorithm. MAMUDA obtains the best re-sults for all the different numbers of training samples. LDA algorithm does not perform well as it does not share knowl-edge among multiple tasks or multiple views. MAMUDA is better than MTDA and MVDA, which demonstrates MA-MUDA can benefit from sharing knowledge among both multiple tasks and multiple views. MAMUDA is also better than MAMUDA-s algorithm, which shows that MAMUDA can take advantage of the task-specific structures to obtain additional improvement.

For the Face problem, we also randomly select n  X  { 2 , 3 , 4 , 5 } samples for each class as training set and the rest as the test set. The parameters used are:  X  l = 300, l = 300 and l = 200. Each experiment is repeated 10 times, the aver-age error rates of all the tasks are shown in Figure 5. The results are very similar to those of Leaves. LDA algorithm is the worst among all the algorithms. MAMUDA obtains the best results for all the different numbers of training sam-ples. MAMUDA is also better than MAMUDA-s algorithm, which does not consider the task-specific information.
For both Leaves and Face problems with missing views, as shown in Table 1, we randomly select n  X  { 2 , 3 , 4 , 5 } samples for each class as the training data and the rest as the test data. Each experiment is repeated 10 times, the average error rates of all the tasks are shown in Figure 6 and 7. Again, MAMUDA obtains the best results for all the different numbers of training samples. This shows that MAMUDA can solve the problems with missing views.
We also compared the results of MAMUDA algorithm for problems with missing views and complete views, which are shown in Figure 8. It can be seen that, for both Leaves Problem and Face problem, when some views are missing, the results become worse than the problems with complete views. So, MAMUDA can take advantage of multiple views and leverage them to obtain good results. Figure 8: Comparison of Results from Missing Views and Complete Views Problems
Existing MTMV algorithms [14, 26] are designed for bi-nary classification problems. To compare with them, we need to convert the multi-class problems into binary classi-fication problems. As each task in our problems is a multi-class problem, for each class, a new binary classification task is constructed according to the one-against-all method. Thus, task 1 in the Leaves problems is converted into 11 bi-nary tasks and the Leaves problem contains 58 binary clas-sification tasks in total. The average error rate for each algorithm is shown in Table 2. It must be noted that, for regMVMT and IteM 2 algorithms, the results shown in the table are the error rates of the transformed binary classifica-tion problems. The results need to be mapped to the results of multi-class problems, which will become much worse as the binary results is already too poor. It is observed that, MAMUDA substantially outperforms existing MTMV algo-rithms. Similarly, using this method, the Face problem can be converted into a new problem with 123 binary classifica-tion tasks. Unfortunately, regMVMT algorithm [26] cannot solve this problem due to this algorithm X  X  high time com-plexity and space complexity 4 . Thus only IteM 2 is compared with our algorithm, which also does not obtain acceptable results for our heterogeneous problems.
 Table 2: Classification Error Rates for Previous MTMV Algorithms (Reesults of the Transformed Binary Problem)
It can be seen that MAMUDA achieves the best results, and both the state-of-the-art MTMV algorithms can not perform well for our problems. We conjecture that there are two reasons: (1) They need to transform the multi-class problem into a number of binary classification problems, which may lead to the class-unbalance and degrade the per-formance. (2) They do not consider the special requirement that the tasks are heterogeneous. Indeed, they are not very suitable for the problems considered in this paper, as they assume all the tasks are similar.
In fa ct, the authors of regMVMT have explicitly stated in their paper that  X  Due to the limit of the matrix size in most computer systems, our algorithm can only handle up to tens of tasks, and learning problems with hundreds of tasks or more are hence beyond the scope of this paper . X 
To check the effect of varying the number of dimensions  X  of the common intermediate latent space, the total number of discriminant dimensions l and the number of shared dis-criminant dimensions l  X  in Eq.(6), we vary them in a wide range of values.

First, for Leaves data set, we vary  X  l from 10 to 60, and in Fig.9(a). We can find that when the value of  X  l is larger than 50, the results are stable. So the default value of  X  set as 50 for Leaves problem. Similarly, for Face data set, we vary  X  l from 200 to 600, the results are shown in Fig.9(b). It can be seen that the results are good when  X  l are not too small or too large. So,  X  l need to be tuned by the users to obtain good result. Also, this parameter is not difficult to be set, as the results are good in a wide range of parameter settings.

Then, while  X  l are fixed with the best parameter, we vary l from 10 to 100 and correspondingly set l  X  = 1 2 l . Th e results for Leaves problem are given in Fig.9(c). Similarly, the re-sults for Face problem with different l values are shown in Fig.9(d). It can be observed that, for both the two data sets, the results are relatively stable with not too small values of l . Therefore, the default value of l for Leaves problem is set as 100 and 300 for Face problem.

Finally, we fix  X  l = 50 and l = 100, and vary l  X  from 0 to 50 for Leaves problem. The results are shown in Fig.9(e). Similarly, while other parameters are fixed, Face problem X  X  results are in Fig.9(f). For both of the two problems, the results are stable with not too small l  X  values. So, we set l = 50 for Leaves problem and l  X  = 200 for Face problem.
Generally speaking, related works can be grouped into the following three categories.

The first category includes the studies of Multi-task learn-ing (MTL), which conducts multiple related learning tasks simultaneously so that the label information in one task can be used for other tasks. The earliest MTL method Figure 9: Prediction Accuracy with respect to Dif-ferent Dimension Settings [5] learns a shared hidden layer representation for different tasks. Multi-task feature learning learns a low-dimensional representation which is shared across a set of multiple re-lated tasks [2, 15]. The methods to learn predictive struc-tures on hypothesis spaces from multiple learning tasks are also proposed [1, 6]. These methods can learn some shared features or shared structures between different task, but they based on the original feature and can only use information from the same view data, which means they cannot share information among different views. Supposing that all the tasks are similar, a regularization formulation is proposed for MTL [9]. MTL can be modeled by stochastic process methods, such as [22, 25]. To deal with outlier tasks, a ro-bust multi-task learning algorithm is proposed [7]. These methods share knowledge by placing a common prior on the model parameters of each task in hierarchical Bayesian models and explicitly share some model parameters or model structure among tasks, which requires that multiple tasks in the problem are similar and have the same set of class labels. So, they cannot be used for problems with heterogeneous tasks. MTDA algorithm [27] is a single view multi-task learning algorithm that can deal with learning tasks with different data representations. It can be seen as a special case of our MAMUDA method, which does not share infor-mation among different views of a same task. Also, MTDA only uses the shared structure among tasks and does not consider the task-specific structures.
 The second category includes the works on Multi-view Learning (MVL). The basic idea of MVL is to make use of the consistency among different views to achieve better per-formance. One of the earliest works on multi-view learning is co-training algorithm [4], which uses one view X  X  predic-tor to enlarge the training set for other views. Nigam and Ghani compared co-training, EM and co-EM methods, and showed that co-EM algorithm is the best among the three approaches [18]. Some improvements of co-training algo-rithm are also proposed [17, 24]. Other methods are based on co-regularization framework. Sindhwani et al. [20] pro-posed a learning framework for multi-view regularization. SVM-2K [10] is a method which uses kernels for two views learning. Sindhwani and Rosenberg [21] constructed a single Reproducing Kernel Hilbert Spaces (RKHSs) with a data-dependent  X  X o-regularization X  norm that reduces MVL to standard supervised learning. Chen et al. [8] presented a large-margin learning framework to discover a predictive la-tent subspace representation shared by multiple views. All these methods are designed for single task learning.
Finally, the third category includes the efforts on multi-task multi-view (MTMV) learning with homogeneous tasks. He and Lawrence [14] proposed a graph-based framework which takes full advantage of information among multiple tasks and multiple views, and an iterative algorithm (IteM was developed to optimize the model. However, multiple tasks share information by directly sharing some class-depen-dent model parameters. This requires multiple tasks have the same class label set and the classes in different tasks have an one-to-one relationship. So, it can not solve prob-lems with heterogeneous tasks. Also, it can only deal with problems with nonnegative feature values. regMVMT [26] uses co-regularization to obtain functions that are consis-tent with each other on the unlabeled samples for different views. Across different tasks, additional regularization func-tions are utilized to ensure the learned functions are similar for multiple tasks, which implies that it can not solve prob-lems with heterogeneous tasks. CSL-MTMV [16] is a shared structure learning framework, which can learn shared pre-dictive structures on common views from multiple related tasks, and use the consistency among different views to im-prove the performance. Also, it is a binary classification algorithm and is not convenient for multi-class problems.
In this paper, we formulated a new type of multi-task multi-view (MTMV) learning problem, i.e., MTMV with heterogeneous tasks, and a Multi-tAsk MUlti-view Discrim-inant Analysis (MAMUDA) method is proposed to solve it. In MAMUDA, both the shared structure that represents the characteristics of the application and the task-specific struc-tures can be combined into a unified formulation to facilitate the learning process. Furthermore, an alternating optimiza-tion algorithm is developed to solve the problem. Finally, experiments on several real world problems, with both com-plete views and missing views, demonstrate the effectiveness of the proposed method.
 To solve the MTMV problem, we ingeniously extended LDA methods to the multi-task multi-view setting, and the framework is very general and useful. It is worth mentioning that many other dimension reduction models (e.g., canonical correlation analysis model [13]) can also be optional for our general framework, which will be further investigated in the future. This work is supported by the National Natural Science Foundation of China (No. 61175052, 61203297, 61035003, 61473273, 61473274), National High-tech R&amp;D Program of China (863 Program) (No. 2014AA012205, 2013AA01A606, 2012AA011003). [1] R. K. Ando and T. Zhang. A framework for learning [2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task [3] P. Belhumeur, J. Hespanha, and D. Kriegman.
 [4] A. Blum and T. Mitchell. Combining labeled and [5] R. Caruana. Multitask learning. Machine learning , [6] J. Chen, L. Tang, J. Liu, and J. Ye. A convex [7] J. Chen, J. Zhou, and J. Ye. Integrating low-rank and [8] N. Chen, J. Zhu, and E. P. Xing. Predictive subspace [9] T. Evgeniou and M. Pontil. Regularized multi-task [10] J. D. Farquhar, D. R. Hardoon, H. Meng, [11] A. Frank and A. Asuncion. UCI machine learning [12] K. Fukunaga. Introduction to statistical pattern [13] D. R. Hardoon, S. Szedmak, and J. Shawe-Taylor. [14] J. He and R. Lawrence. A graph-based framework for [15] A. Jalali, P. Ravikumar, S. Sanghavi, and C. Ruan. A [16] X. Jin, F. Zhuang, S. Wang, Q. He, and Z. Shi. Shared [17] I. Muslea, S. Minton, and C. A. Knoblock. Active + [18] K. Nigam and R. Ghani. Analyzing the effectiveness [19] T. Sim, S. Baker, and M. Bsat. The CMU pose, [20] V. Sindhwani, P. Niyogi, and M. Belkin. A [21] V. Sindhwani and D. S. Rosenberg. An rkhs for [22] G. Skolidis and G. Sanguinetti. Bayesian multitask [23] H. Wang, S. Yan, D. Xu, X. Tang, and T. Huang. [24] S. Yu, B. Krishnapuram, R. Rosales, and [25] S. Yu, V. Tresp, and K. Yu. Robust multi-task [26] J. Zhang and J. Huan. Inductive multi-task learning [27] Y. Zhang and D.-Y. Yeung. Multi-task learning in
