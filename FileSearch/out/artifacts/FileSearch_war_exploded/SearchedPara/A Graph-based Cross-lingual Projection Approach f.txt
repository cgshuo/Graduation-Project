 Relation extraction aims to identify semantic rela-tions of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Ze-lenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they re-quire a sufficient number of training examples to ob-tain good extraction results. Several datasets that provide manual annotations of semantic relation-ships are available from MUC (Grishman and Sund-heim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, includ-ing English, Chinese, and Arabic. Although these datasets encourage the development of relation ex-tractors for these major languages, there are few la-beled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resource-poor languages is very expensive, we instead con-sider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the rela-tion extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a cru-cial role in obtaining good extractions.

Recently, some researchers attempted to use ex-ternal resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed exam-ples. We previously proposed to leverage parallel corpora as a new kind of external resource for rela-tion extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation pro-jection by propagating annotations that were gener-ated by a relation extraction system in a resource-rich source language. In this approach, projected annotations were determined in a single pass pro-cess by considering only alignments between entity candidates; we call this action direct projection .
In this paper, we propose a graph-based projec-tion approach for weakly supervised relation extrac-tion. This approach utilizes a graph that is con-stucted with both instance and context information and that is operated in an iterative manner. The goal of our graph-based approach is to improve the ro-bustness of the extractor with respect to errors that are generated and accumulated by preprocessors. Relation extraction can be considered to be a classi-fication problem by the following classifier: f e i , e j = where e
Cross-lingual annotation projection intends to learn an extractor f out significant effort toward building resources for a resource-poor target language L that goal, the method automatically creates a set of annotated text for f f allel corpus of L ple of annotation projection for relation extraction with a bi-text in L English sentence, an instance h Barack Obama, Hon-olulu i is extracted as positive. Then, its translational counterpart h beo-rak-o-ba-ma, ho-nol-rul-ru i in the Korean sentence also has a positive annotation by projection.

Early studies in cross-lingual annotation projec-tion were accomplished for various natural lan-guage processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These stud-ies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected an-notations.

For relation extraction, the direct projection strat-egy can be formularized as follows: f f s A ( e i t ) , A ( e of e unreliable because of source text mis-classification and word alignment errors; thus, it can cause a criti-cal falling-off in the annotation projection quality.
Although some noise reduction strategies for pro-jecting semantic relations were proposed (Kim et al., 2010), the direct projection approach is still vulner-able to erroneous inputs generated by submodules. We note two main causes for this limitation: (1) the direct projection approach considers only align-ments between entity candidates, and it does not consider any contextual information; and, (2) it is performed by a single pass process. To solve both of these problems at once, we propose a graph-based projection approach for relation extraction. The most crucial factor in the success of graph-based learning approaches is how to construct a graph that is appropriate for the target task. Das and Petrov (Das and Petrov, 2011) proposed a graph-based bilingual projection of part-of-speech tagging by considering the tagged words in the source lan-guage as labeled examples and connecting them to the unlabeled words in the target language, while re-ferring to the word alignments. Graph construction for projecting semantic relationships is more com-plicated than part-of-speech tagging because the unit instance of projection is a pair of entities and not a word or morpheme that is equivalent to the align-ment unit. 3.1 Graph Vertices To construct a graph for a relation projection, we define two types of vertices: instance vertices V and context vertices U .

Instance vertices are defined for all pairs of en-tity candidates in the source and target languages. Each instance vertex has a soft label vector Y = [ y + y  X  ] , which contains the probabilities that the instance is positive or negative, respectively. The larger the y + value, the more likely the instance has a semantic relationship. The initial label values of an instance vertex v ij the source language are assigned based on the con-fidence score of the extractor f target language, every instance vertex v ij the same initial values of 0 . 5 in both y + and y  X  .
The other type of vertices, context vertices, are used for identifying relation descriptors that are con-textual subtexts that represent semantic relationships of the positive instances. Because the characteristics of these descriptive contexts vary depending on the language, context vertices should be defined to be language-specific. In the case of English, we define the context vertex for each trigram that is located be-tween a given entity pair that is semantically related. If the context vertices U sentences are defined, then the units of context in the target language can also be created based on the word alignments. The aligned counterpart of each source language context vertex is used for generat-ing a context vertex u i Each context vertex u y + and y  X  , which represent how likely the context is to denote semantic relationships. The probability values for all of the context vertices in both of the languages are initially assigned to y + = y  X  = 0 . 5 . 3.2 Edge Weights The graph for our graph-based projection is con-structed by connecting related vertex pairs by weighted edges. If a given pair of vertices is likely to have the same label, then the edge connecting these vertices should have a large weight value.

We define three types of edges according to com-binations of connected vertices. The first type of edges consists of connections between an instance vertex and a context vertex in the same language. For a pair of an instance vertex v i,j and a context vertex u k , these vertices are connected if the context sequence of v i,j contains u k as a subsequence. If v ij is matched to u k , the edge weight w v i,j , u k ) is assigned to 1. Otherwise, it should be 0.
Another edge category is for the pairs of context vertices in a language. Because each context vertex is considered to be an n-gram pattern in our work, the weight value for each edge of this type represents the pattern similarity between two context vertices. The edge weight w ( u k , u l ) is computed by Jaccard X  X  coefficient between u k and u l .

While the previous two categories of edges are concerned with monolingual connections, the other type addresses bilingual alignments of context ver-tices between the source language and the target lan-guage. We define the weight for a bilingual edge connecting u k alignments, as follows: w ( u k s , u l t ) = count u k s , u l t / X where count ( u between u To induce labels for all of the unlabeled vertices on the graph constructed in Section 3, we utilize the label propagation algorithm (Zhu and Ghahramani, 2002), which is a graph-based semi-supervised learning algorithm.

First, we construct an n  X  n matrix T that rep-resents transition probabilities for all of the vertex pairs. After assigning all of the values on the ma-trix, we normalize the matrix for each row, to make the element values be probabilities. The other input to the algorithm is an n  X  2 matrix Y , which indi-cates the probabilities of whether a given vertex v positive or not. The matrix T and Y are initialized by the values described in Section 3.

For the input matrices T and Y , label propagation is performed by multiplying the two matrices, to up-date the Y matrix. This multiplication is repeated until Y converges or until the number of iterations exceeds a specific number. The Y matrix, after fin-ishing its iterations, is considered to be the result of the algorithm. To demonstrate the effectiveness of the graph-based projection approach for relation extraction, we de-veloped a Korean relation extraction system that was trained with projected annotations from English re-sources. We used an English-Korean parallel cor-glish and Korean. We obtained 155,409 positive in-stances from the English sentences using an off-the-al., 2011).
The English sentence annotations in the parallel corpus were then propagated into the correspond-ing Korean sentences. We used the GIZA++ soft-ments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the tions of 10 for each execution.

Projected instances were utilized as training ex-amples to learn the Korean relation extractor. We built a tree kernel-based support vector machine we adopted the subtree kernel method for the short-est path dependency kernel (Bunescu and Mooney, 2005). The experiments were performed on the manu-ally annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Ac-quisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive in-stances.

The first experiment aimed to compare two sys-tems constructed by the direct projection (Kim et al., 2010) and graph-based projection approach. Table 1 shows the performances of the relation extraction of the two systems. The graph-based system achieved better performances in precision and recall than the system with direct projection for all of the four re-lation types. It outperformed the baseline system by an F-measure of 3.63.

To demonstrate the merits of our work against other approaches based on monolingual external re-sources, we performed comparisons with the fol-lowing two baselines: heuristic-based (Banko et al., 2007) and Wikipedia-based approaches (Wu and Weld, 2010). The heuristic-based baseline was built on the Sejong treebank corpus (Kim, 2006) and the Wikipedia-based baseline used Korean Wikipedia two baseline systems and our method. Our proposed projection-based approach obtained better perfor-mance than the other systems. It outperformed the heuristic-based system by 47.21 and the Wikipedia-based system by 9.51 in the F-measure. This paper presented a novel graph-based projection approach for relation extraction. Our approach per-formed a label propagation algorithm on a proposed graph that represented the instance and context fea-tures of both the source and target languages. The feasibility of our approach was demonstrated by our Korean relation extraction system. Experimental re-sults show that our graph-based projection helped to improve the performance of the cross-lingual anno-tation projection of the semantic relations, and our system outperforms the other systems, which incor-porate monolingual external resources.

In this work, we operated the graph-based pro-jection under very restricted conditions, because of high complexity of the algorithm. For future work, we plan to relieve the complexity problem for deal-ing with more expanded graph structure to improve the performance of our proposed approach. This research was supported by the MKE(The Ministry of Knowledge Economy), Korea, un-der the ITRC(Information Technology Research Center) support program (NIPA-2012-(H0301-12-3001)) supervised by the NIPA(National IT Industry Promotion Agency) and Industrial Strategic technol-ogy development program, 10035252, development of dialog-based spontaneous speech interface tech-nology on mobile platform, funded by the Ministry of Knowledge Economy(MKE, Korea).

