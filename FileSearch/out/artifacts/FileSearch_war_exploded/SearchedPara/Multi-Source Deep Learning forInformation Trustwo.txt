 In recent years, information trustworthiness has become a serious issue when user-generated contents prevail in our information world. In this paper, we investigate the im-portant problem of estimating information trustworthiness from the perspective of correlating and comparing multiple data sources. To a certain extent, the consistency degree is an indicator of information reliability{Information unani-mously agreed by all the sources is more likely to be reliable. Based on this principle, we develop an e ective computa-tional approach to identify consistent information from mul-tiple data sources. Particularly, we analyze vast amounts of information collected from multiple review platforms (mul-tiple sources) in which people can rate and review the items they have purchased. The major challenge is that di erent platforms attract diverse sets of users, and thus information cannot be compared directly at the surface. However, latent reasons hidden in user ratings are mostly shared by multiple sources, and thus inconsistency about an item only appears when some source provides ratings deviating from the com-mon latent reasons. Therefore, we propose a novel two-step procedure to calculate information consistency degrees for a set of items which are rated by multiple sets of users on dif-ferent platforms. We rst build a Multi-Source Deep Belief Network (MSDBN) to identify the common reasons hidden in multi-source rating data, and then calculate a consistency score for each item by comparing individual sources with the reconstructed data derived from the latent reasons. We con-duct experiments on real user ratings collected from Orbitz, Priceline and TripAdvisor on all the hotels in Las Vegas and New York City. Experimental results demonstrate that the proposed approach successfully nds the hotels that receive inconsistent, and possibly unreliable, ratings.
 H.4 [ Information Systems Applications ]: Algorithms Deep Learning, Multiple-Source, Information Trustworthi-ness With the booming of Internet applications and mobile de-vices, it is now much easier for people to access, create and publish contents than ever before, which leads to great in-formation exposure for almost everyone in the world. Since everyone is able to generate contents online, as the side ef-fect of freedom of speech, information trustworthiness has become a serious problem for many applications including Ebay [16], Twitter [10] and Amazon [7,12]. One of the fun-damental diculties in analyzing user-generated data is that information is massive, yet can be noisy, incorrect and mis-leading. It is hard to infer reliable knowledge from massive data with low data quality, and there exists no universal oracle that can tell us which information source is reliable and which piece of information is trustworthy. Therefore, we seek to infer information trustworthiness from the data by cross checking multiple data sources. Trustworthiness of contents cannot be inferred purely based on its information alone, but rather by exploring consensus and commonalities in multiple sources simultaneously. A piece of information is more likely to be reliable if it is supported by many inde-pendent sources while high inconsistency across sources may suggest potentially unreliable information. In this paper, we propose to infer the consistency degree of information across multiple sources as an e ective indicator for informa-tion trustworthiness.

Applications. Information trustworthiness is an impor-tant issue for numerous applications, but in this paper, we particularly focus on online recommendation systems, which typically involve overwhelming amounts of user-generated data. Nowadays, there are many places where people can leave their opinions for their experiences with products or services, in the form of ratings and reviews. Those ratings and reviews exert great in uence on people before they make their decisions about their potential purchases. In fact, more and more people rely on such websites (e.g., Yelp) to nd an apartment, book a hotel and reserve a table in a restau-rant, etc. However, people are bothered by the existence of unreliable and misleading information especially when there exist fake reviews or ratings posted by spammers. Although some endeavors have been made to detect and prevent spam reviews and ratings [7, 9, 12, 13], people are still struggling with untruthful information.

In reality, people will check multiple websites for unbiased opinions before they make decisions because they are fully a ware of the biases and noises embedded in a single source. Intuitively, consensus opinions across multiple sources about an item should be valued more, but high discrepancy may indicate that the information is suspicious. However, the huge volume of data makes the task of manually checking multiple review websites time-consuming and sometimes im-possible. Motivated by this observation, we propose to de-velop an e ective and ecient approach to compare multiple sources of information about the same item and calculate a consistency score for each item to assist users in decision making. In this paper, we focus on identifying consistent information from user rating matrices collected from multi-ple platforms. The framework can be extended in the future to incorporate other information, such as user pro les and review comments.

Challenges. One major challenge in consistency degree computation is that di erent platforms attract di erent sets of users. It is impossible to simply compare ratings at the user level because users may leave ratings only at one place. Even if there are overlapping users, we are unable to align them due to the lack of users' information. On the other hand, comparing rating statistics or summary obtained by aggregating ratings in individual sources can also be prob-lematic because users have quite diverse tastes and prefer-ences. As users with di erent backgrounds all contribute to the ratings and reviews, the di erence between the rat-ing summaries of multiple sources could well re ect user preference diversity rather than information inconsistency. To accurately estimate consistency degrees, we must iden-tify subtle commonalities shared among sources embedded in multiple rating matrices.

Observations. In regard to the challenges discussed above, we have the following observations that shed some lights on the problem.

Summary. These observations motivate us to propose a novel two-step procedure to estimate information consis-tency across multiple sources given multiple rating matrices collected from di erent platforms. The key idea is to connect multiple sources by learning their shared latent hierarchy of rating reasons and then compare multiple sources at the la-tent reason layer to obtain the consistency scores. First, we develop a Multi-Source Deep Belief Network ( MSDBN ) to learn a joint model that represents the common hidden rea-sons underlying the observed ratings across sources. Since the latent space for each source forms a hierarchical struc-ture, a deep network can be used to extract latent structure from each source. We connect multiple sources by linking the deep network structures through a joint consensus layer which represents the common hidden reasons embedded in multiple data sources. At the second step, we reconstruct latent representations for each source from the joint repre-sentation of multiple sources. The reconstructed data sim-ulates users' rating behavior in each source if the source follows the common latent reasons. By comparing recon-structed data based on common reasons and each source's own representation, we can successfully derive information consistency for each item, which can be further used to sug-gest the trustworthiness of an item's information. Note that our work di ers from existing deep learning approaches in that we develop an approach to compute information consis-tency across multiple sources while existing work focuses on single data source and targets at di erent problems (classi -cation, clustering, etc.). To demonstrate the e ectiveness of the proposed approach, we crawled real ratings of hotels in two big cities from three travel websites: Orbitz, Priceline and TripAdvisor. Experimental results on this multi-source data set show that the proposed method provides veracious estimation of information consistency to help users identify trustable information from massive, con icting and biased data. We also design experiments on synthetic data to per-form a thorough quantitative analysis illustrating the strong abilities of the proposed approach in distinguishing consis-tent from inconsistent information.
 To sum up, the contributions of this paper are: In this section, we present the details of the proposed method. We rst present the description of the problem formulation in Section 2.1. Section 2.2 discusses how to represent the la-tent reasons for a single source. The two-step procedure of information trustworthiness estimation is presented in Sec-tions 2.3 and 2.4. The rst step is to train a Multi-Source Deep Belief Network (MSDBN) so that the common latent reasons across sources are captured. The consistency score is calculated accordingly in the second step. We discuss some practical issues of training MSDBN in Section 2.5. 2.1 Problem Formulation Suppose we are interested in K items (each item could be a hotel, a book, a restaurant or any entity of interests). There are S sources that we can obtain ratings about the K items. The s -th source is characterized by a rating ma-trix V s , which denotes ratings of K items from N s users. Note that the users are di eren across sources. The goal is to derive a consistency score vector R , where each entry r denotes the consistency score of the k -th item. The gen-eral intuition is that an item will receive high score if its ratings are consistent across multiple sources. The consis-tency score denotes our recognition that information unan-imously agreed by all the sources is most likely to be re-liable. Due to noise, sparsity and alignment issues, it is impossible to determine the consistency of items by directly comparing their ratings. However, latent reasons hidden in user ratings are mostly shared by multiple sources and in-consistency about an item can only be revealed when some source provides ratings deviating from the common latent reasons. Therefore, we propose a Multi-Source Deep Belief Network to extract common reasons underlying the observed rating matrices V 1 ,..., V s . The trained MSDBN is used to re-construct data for each source and the reconstructed data simulate the ratings following the common latent reasons. The consistency score for each item can thus be obtained by calculating the similarity between the original data and the reconstructed data across multiple sources. The ow of the proposed method is shown in Figure 1. Table 1 lists the notation used throughout this paper.
 Figure 2: A Restricted Boltzmann Machine and A 2-Layer Deep 2.2 Single Source Representation As we discussed in Section 1, there are many possible latent reasons to explain users' rating behavior. Therefore, given a rating matrix V s for s -th source, how to represent the latent reasons underlying V s is our rst problem.

A common approach to represent the latent reasons is us-ing clustering techniques [2,3,21] where V s is modeled by the product of matrix P N s C and Q C K . Such model performs clustering on the input space where P is the clustering indi-cation matrix and Q is the cluster level feature ( C clusters are obtained). Users in the same cluster in P share simi-larity in terms of their rating behavior, and the aggregated rating of the cluster is captured by Q . One limitation of the clustering techniques is that it usually forms a coarse rep-resentation of the latent reasons. Users in the same cluster are similar because of combinations of several latent reasons. For example, the reason that users belong to the same clus-ter may be because they are all family travelers who like bargain hotels and free wi . Increasing the number of clus-ters doesn't usually get a ner representation, because it will usually create a lot of trivial clusters with very few users in them.

To have a ner representation of latent reasons for a sin-gle source, we propose to use Restricted Boltzmann Machine (RBM). RBM is an undirected graphical model with visible units v and stochastic binary hidden units h . The visible units v denote the observed data (in our case, V s ) and the hidden units h denote the latent reasons that generate the observed data. There are symmetrically weighted connec-tions W between each visible unit and each hidden unit. There is no connections between visible units and between hidden units. Therefore, RBM forms a bipartite graph be-tween visible and hidden units as illustrated in Figure 2 (a).
The probability distribution of RBM is as follows: where the partition function Z is given by summing over all possible pairs of visible and hidden vectors: Z = The energy function of visible and hidden units is where a i , b j are biases for hidden and visible units and w is the weight between them. The purpose of RBM is to nd a con guration of ( v; h ) so that the energy function achieves its lowest level.

Since RBM takes the shape of a bipartite graph, with no direct connections between hidden units and between visi-ble units, the hidden units are mutually independent given A lgorithm 1 MSDBN Training Algorithm For Two Sources th e visible units and vice versa. The individual activation probabilities of a hidden and a visible unit are given by where denotes the logistic sigmoid function. Considering Eq. 2, suppose h j is one latent reason for ratings in V s price), the activation probability P ( h j = 1 j v ) shows how \important" this reason is given the observed data. Given many hidden units (e.g., 500) that represent the latent rea-sons, the learning of RBM could be understood as tuning up the importance of all latent reasons given the observed data set so that the hidden units could get close to the true latent reasons as much as possible. For RBM, exact maximum like-lihood learning is intractable. In practice, ecient learning is performed using Contrastive Divergence (CD) [4].
The advantage of RBM is that it discovers a richer repre-sentation of the input data than clustering techniques. Each hidden unit in RBM creates a 2-region partition of the input space and n hidden units can represent up to 2 n di erent regions in input space. This indicates that given L latent reasons in input space, clustering techniques will take L pa-rameters (e.g., number of clusters) to capture that many rea-sons, RBM only need log 2 ( L ) hidden units. Since there are many possible latent reasons underlying V s for s -th source, we choose RBM instead of clustering techniques to represent each single source.

RBM can represent many possible underlying reasons of each source, such as reasons about hotels and reasons about location as we discussed in Section 1. Within each type of reasons, there exist many reasons about the detailed as-pects. For example, one may choose a hotel due to its room service, sta quality, or internet services. We can go even further down the hierarchy for more detailed reasons that contribute to users' ratings. Therefore, these reasons form a hierarchical structure, and we can thus add more layers into RBM to form a Deep Belief Network (DBN) to repre-sent such complicated latent reasons. A DBN with l layers models the joint distribution between observed variables v and l hidden layers h ( k ) , k = 1 ; :::; l as follows: Denoting b ( k ) the bias vector of layer k and W ( k ) the weight matrix between layer k and k + 1, we have A two-layer DBN is shown in Figure 2 (b). The training of DBN follows a greedy layer-wise CD strategy [4]. 2.3 Multi-Source Deep Belief Network Although we extract latent reasons of each source using DBN, we can't obtain the consensus reasons by directly com-paring them because 1) The latent reasons of each source may contain their source-speci c bias, making them hardly comparable across sources. 2) For the common latent rea-sons each source contain, they are not properly aligned. Therefore, to nd the common latent reasons across sources, we propose the Multi-Source Deep Belief Network (MSDBN).
We illustrate the construction of a MSDBN using two sources as a running sample. Note that it can be easily extended to accept inputs from multiple sources. Consider modeling each source using a two-layer DBN. The energy function P ( v; h (1) ; h (2) ) is given by Eq. 4. To form a MS-DBN, we combine the two DBNs by adding an additional layer of binary hidden units on top of them. The resulting graphical model is shown in Figure 3. The joint distribution over the multiple sources can be written as: P ( v 1 ; v 2 ; h ) = P ( h (2) 1 ; h (2) 2 ; h ) P ( v 1 where P ( h (2) 1 ; h (2) 2 ; h ) can be written as follows: where U and V are the weight matrix connecting the top hidden layer of DBN for each source. a , b and c are the cor-responding bias vectors. Given the MSDBN, the conditional distribution is derived as follows: where is logistic sigmoid function. The learning of MS-DBN is to tune up the top hidden layer h (Eq. 8) so that it can better generate the input sources (Eq. 6 and Eq. 7). In this way, MSDBN tries to nd the shared latent reasons that underly multiple sources.

The training of MSDBN using two sources is shown in Al-gorithm 1. In Algorithm 1, lines 5 to 19 prepares ingredients for CD [4]. Speci cally, lines 5 to 8 compute the activation probability of hidden units of MSDBN based on two input sources; lines 9 to 16 reconstruct source 1 and 2 based on hidden units; and lines 17 to 19 calculate the activation prob-ability of hidden units based on two reconstructed sources. Lines 21 to 25 update parameters U; V; a; b; c accordingly. The algorithm stops when all parameters are converged. 2.4 Consistency Score Calculation At the rst step, we obtain the consensus latent reasons un-derlying multiple sources. Consequently, at the second step, based on the learned consensus hidden reasons, we estimate the information trustworthiness by calculating a consistency score for each item. The higher the score, the more consis-tently the item behaves across multiple sources, the more likely that the information about the item is reliable.
Once the MSDBN is trained, we have the top layer of hid-den units that represents the consensus reasons. Next, we reconstruct each source using Eq. 6 and Eq. 7. The recon-structed data are sampled from P ( h (2) 1 j h ) and can be viewed as the data generated from the consensus reasons in each source. Therefore, for a given source s and item i , we have its original data and its reconstructed data. We calculate their distance using Root Mean Square Error (RMSE) to form a matrix D of size S K where d sk represents the dis-tance between original data and reconstructed data of item k on source s .

Ideally, if an item behaves consistently across sources, the distance between its reconstructed data and its origi-nal data should be small since both of them are driven by the same consensus reasons. However, the reconstruction of each source by MSDBN is not perfect, i.e., there is recon-struction error for each source. The existence of reconstruc-tion error for each source severely prohibits us to simply measure consistency scores using distance aggregated upon multiple sources. An item that has a large overall distance between original and reconstructed data doesn't necessarily mean that the information it receives is inconsistent.
To tackle this challenge, we will examine the distance ma-trix D to nd the consensus patterns as a basis for con-sistency score computation because majority of the items receive consistent user ratings across sources. Figure 4 plots the distance between the original data and reconstructed data for 20 hotels in Las Vegas from three sources: Orbitz, Priceline and TripAdvisor. As we can see, for the majority of items, the distance between original data and reconstructed data follows a similar shape. This shape has close relations with reconstruction error of each source, which can be seen as the re ection of the bias of each source in terms of the consensus latent reasons. For items that have a di erent shape than that of the majority items (e.g., items 3 and 13), we believe it is highly possible that some inconsistency resides among them.

Since the majority of items are consistent, we thus derive the Consistency Score r k of each item k by following: where Eq. 9 takes the median of each column in D , and thus p stands for the distance between original data and reconstructed data for the majority of consistent items. The consistency score r k for each item k is consequently obtained by calculating the similarity between each row of D with p . In this work, we use Pearson Correlation as the similarity measure as it focuses on the shape similarity rather than the absolute distance. The lower the score, the further the item is away from consistent items, which indicates a higher possibility that the item receives inconsistent information. Since the major part of the proposed method lies in the construction of Multi-Source Deep Belief Network, we name our method MSDBN . 2.5 Practical Issues In MSDBN, DBN for each source has binary visible units yet the rating matrix is count data whose range is from 0 to N . As suggested in [18], one simple and e ective way is to make N copies of binary visible units and give them all the same weights and biases. Using this weight-sharing to synthesize count data out of binary units will keep the mathematics underlying binary-binary DBN unchanged. MSDBN accepts inputs from DBN of each source. The DBN of each source could contain several layers of hidden units. The number of layers and the number of hidden units are strongly related to the representational power of MS-DBN. Increasing the number of layers can also reduce the number of parameters used in the model. However, there is a trade-o between the performance and time of training in terms of the hidden number of units and the number of lay-ers. In this work, we maintain the number of layers of DBN for each source to be 2 and the number of hidden units on the top layer of MSDBN to be 500.

There are some issues involved in training MSDBN in Al-gorithm 1 including choosing the learning rate  X  , initializa-tion of the weights and biases and stopping criteria. A de-tailed guide on these issues can be found in [5]. In this section, we apply the proposed method on the real hotel rating data sets and show how the proposed approach issues meaningful alerts on unreliable information. Fi gure 7: The distance between original data and recon-structed data for Carriage House and consistent hotels in Las Vegas 3.1 Data Sets The two data sets are the ratings of hotels crawled from three popular travel websites in United States: Orbitz, Priceline and TripAdvisor. Two popular cities, Las Vegas and New York City are chosen in our experiments because there are plenty of hotels being reviewed. The three websites have di erent numbers of hotels in the two cities and we crawl all the ratings of the common hotels among the three websites. The data sets are crawled between March 7 and March 9, 2012. The rating scale is between 1 and 5. Tables 2 and 3 show the characteristics of the two real data sets. 3.2 Results and Evaluation The output of MSDBN is a consistency score vector R . Since it is more interesting to present some inconsistent informa-tion, we compute the Inconsistency Score for each item as I ( k ) = r k where is the maximal value in R . We apply the MSDBN on the above data sets and calculate the inconsistency score for each hotel. Figures 5 and 6 show the inconsistency score distribution of hotels in Las Vegas and New York City.

There are several observations that can be drawn from the gures. First, most hotels in Las Vegas and New York city receive low inconsistency scores, indicating that the informa-tion about most hotels in three websites are consistent. If ratings about a hotel are consistent across multiple sources, we can usually claim that the information about this hotel are reliable. Second, the inconsistency score for some ho-tels are signi cantly higher, indicating that there exist large inconsistency about the information of these hotels across sources. This usually requires further investigations about these hotels to determine if their information are reliable or not. Next, we present two case studies to show that there in-deed exist unreliable information in their ratings. Although we don't have ground truth for this task, we nd substantial evidence to support the ndings of the proposed method.
Case Study I: In the rst cast study, we pick the hotel that has the highest inconsistency score in Las Vegas: the Carriage House hotel. Figure 7 shows the distance between original data and reconstructed data for Carriage House and consistent hotels in Las Vegas from three sources. From the gure, it seems that the information about this hotel on the third source (TripAdvisor) rings a bell.

From TripAdvisor's perspective, Carriage House is a real nice hotel. It ranked 12-th of all 282 hotels in Las Vegas. More than 80% of users gave rating more than 4. How-ever, other sources tell a di erent story. In Yelp, 50% of guests gave ratings less than 3. In Booking, 24.4% people gave ratings less than 4. Other than ratings, we summarize some of the reviews about the Carriage House from vari-ous sources in Table 4. As shown in the table, the Carriage Hotel shows many unattractive features and those features (e.g., loud, rude and dirty) are unfortunately quite consis-tent across multiple sources. This case study shows that the proposed method successfully detects the large inconsistency of information between TripAdvisor and other sources and can warn potential customers on the information trustwor-thiness of the ratings.
 C ast Study II: MSDBN discovers that the Double Tree Hilton Hotel near Time Square in New York city has the highest inconsistency score. Figure 8 shows the distance be-tween original data and reconstructed data for Double Tree Hotel and consistent hotels in New York city. As we can see, in this case, information on TripAdvisor causes the high in-consistency again. Priceline lists this hotel as 11-th of the 357 hotels in New York city. In Booking, the overall rate is 8 : 5 out of 10 and it is considered very good among hotels in New York city. However, TripAdvisor ranks this hotel as as 256-th of 432 hotels in New York city and 40% of the rating are less than 3. Such huge contrasts between TripAd-visor and other sources remind us to be cautious about the information about this hotel.

The two case studies both point out that TripAdvisor is more likely to receive unreliable information from users. This makes sense in that TripAdvisor are totally open to anyone who is able to register, which is much easier to at-tract spam information. Note that the above results do not indicate that TripAdvisor is always less reliable compared with other sources, rather, it provides less reliable informa-tion on the hotels in the case studies. In Section 3, we present case studies on the real hotel rating data sets to show that the proposed method is e ective in estimating the information trustworthiness in recommenda-tion systems. In this part, we conduct experiments on the synthetic data sets to perform quantitative analysis on the proposed method. 4.1 Data Generation and Evaluation Metric The synthetic data are generated based on the observation that the latent reasons across multiple sources are consis-tent. We generate three sources and mandate that they share a mixture of three rating distributions. For a given item, its ratings in each source are drawn from one of the distributions. t items are randomly chosen to be the items receiving inconsistent information, and their ratings are ran-domly shued. All the generated ratings are padded with random noises to simulate the fact that users have diverse preference.

The evaluation metric of this experiment is F-measure, de-ned as 2( precision recall ) = ( precision + recall ). precision de nes the percentage of correctly identi ed items that re-ceive inconsistent information among all the top t items re-turned by the method, and recall is the percentage of cor-rectly identi ed items that receive inconsistent information among the true top t items generated by the data generator. 4.2 Performance Comparison To illustrate the power of the proposed model, we rst intro-duce some baseline methods. As discussed in Section 1, the ratings from individual users can't be compared directly, yet we can consider the method which compares ratings statis-tics. The rst baseline method is Normalized Histogram Comparison (NHC) as follows. For a source s and item k , we compute the percentage of users who give rating to item k from 1 to N (the maximum rating), and thus we have a rating summary vector of length N for each item in each source. Then we compute the inconsistency score as the min-imum of the mutual distance among those summary vectors and pick up the top t items as items that receive the most inconsistent information. Note that mutual distance could be any distance measurement that ts the application. In this work, we use the commonly used Euclidean distance as the distance measure.

The second baseline method is from [3], which targets at the similar problem using Joint Matrix Factorization (JMF). JMF nds the consistent groups across multiple sources us-ing joint matrix factorization and retrieves the inconsistent items by comparing items at group level.

In this experiment, we compute the inconsistency score the same way as in Section 3. Figure 9 shows the perfor-mance comparison between NHC, JMF and MSDBN. It is obvious that NHC fails to detect some items receiving in-consistent information. It only compares high-level statis-tics, thus vulnerable to noises and has limited discrimina-tive power. JMF performs better mainly because it consid-ers group-level information. However, comparing with the proposed MSDBN, some inconsistent items are still unde-tected by JMF. This gap in performance between JMF and MSDBN is mainly due to the di erence in representational power between clustering techniques and MSDBN, i.e., MS-DBN explores a much ner representation of common latent reasons than clustering techniques. 4.3 Various Learning Scenarios In this part, we show how MSDBN performs in various learn-ing scenarios by tuning four variables: 1) the number of users, 2) the number of items, 3) the number of hidden units on the top layer of MSDBN, and 4) the number of layers in MSDBN. The rst and second variables are used in synthetic data generation while the latter two are parameters used in MSDBN algorithm. We set the default settings of the four variables as follows. There are 4000 users and 60 items in each of the 3 sources. The rating scale is 1 to 5. Also we set number of inconsistent items t = 7, the number of hidden units h = 500 and the number of layers l = 1. Note that l is the layer of DBN for each source. When l = 1, DBN is reduced to RBM. While we vary one variable or parameter, we maintain others the same as in the default setting. We present the experimental results in the following way. We partition the items into two sets: items that receive consistent and inconsistent information (referred to as con-sistent and inconsistent sets ), which we know from data generation. Then in each gure, the bar represents the av-erage inconsistency score for each set, and the vertical line denotes the variance of the scores in each set. The method performs well if the di erence of scores in the two sets is big , which indicates its capability of separating items that have consistent and inconsistent ratings in multiple sources.
Number of Users and Items. When we vary the num-ber of users, Figures 10 (a) and (b) show the performance comparison between MSDBN and JMF. As we can see, MS-DBN exhibits great power of distinguishing inconsistent and consistent items in that the score di erence in the two sets is rather signi cant. On the other hand, the performance of JMF is clearly inferior to that of MSDBN in that there exist overlapping of scores between inconsistent items and consistent items in some experiments of JMF. In addition, in Figure 10 (a) we notice that the variance is reduced when the number of users increases, which indicates that the MS-DBN produces better results. The improvement is due to the fact that when the number of users increases, the consen-sus latent reasons are becoming more and more dominant, rendering it easier to be captured by the MSDBN.

As for the number of items, Figures 10 (c) and (d) show the performance of MSDBN and JMF. Similar to the ex-periments with the number of users, inconsistent items are easily detected by the proposed MSDBN and the di erence between consistent item set and inconsistent item set is sig-ni cantly larger than that of JMF, indicating MSDBN out-performs JMF.

Number of Hidden Units and Layers. The number of hidden units on the top layer of MSDBN is closely re-lated to the representational power of MSDBN. Figure 11 (a) shows the performance of the MSDBN in terms of the number of hidden units. As we can see from the Figure, when the number of hidden units is small, e.g., 10, the per-formance of MSDBN is poor in that the scores for consistent and inconsistent items are overlapping. When we increase the number of hidden unit to 40, MSDBN is able to dis-tinguish inconsistent items from consistent items. When we further increase the number of hidden units, the performance is stable. This indicates that for the synthetic data, having hidden units over 40 is sucient to model the variants in the input space and thus nd the inconsistent items. Note that real-life data is more complicated than the synthetic data, so a larger number of hidden units should be chosen. However, there is a trade-o between the performance increase and training time in terms of the number of hidden units in that large number of hidden units implies long training time. For the number of layers, Figure 11 (b) shows the performance of the MSDBN in terms of the layers. As we can see, the performance is rather stable, indicating for synthetic data, one-layer of MSDBN is enough. However, in the real rating d ata, we notice the hierarchical structure in the latent space and a two-layer MSDBN is thus chosen. The proposed model is built on Restricted Boltzmann Ma-chines, which, in recent years, have attracted many atten-tions [6,14,18,19] (to name a few). The detailed introduction can be seen in [1]. Our work shares similarity with Multi-modal Deep Learning [8,15,20], where deep belief networks are trained on the image and text inputs to learn a joint rep-resentation to perform generative and discriminative tasks. Di erent from these studies, in our work, the learnt joint representation denotes the consistent latent reasons that un-derly users' ratings from multiple sources. We thus utilize the common latent reasons to calculate consistency score for each item.

The work in [3] targeted the similar problem that esti-mates the local information trustworthiness and proposed a Joint Matrix Factorization (JMF) method to connect multi-ple sources. JMF useed clustering techniques to capture the variances of multiple sources which forms a coarse represen-tation of the input space and thus has inferior discriminative power to the proposed method.

Information trustworthiness is a serious problem in vari-ous applications such as online auction website (e.g., Ebay) [16], social networks (e.g., Twitter) [10], and product reviews (e.g., Amazon) [7,12]. Most of the work detect spammer or spam information based on single source of data. Moreover, some studies formulate the problem of information trustwor-thiness into a supervised task where labeled information are required for training. Our work focus on the information trustworthiness estimation from multiple sources and works in a pure unsupervised manner.

In the truth discovery eld [11,17,22] , people work on the problem of detecting the truth about some questions or facts given multiple con icting sources. In these studies, truth is considered as the fact that is told by many reliable sources and sources that often tell the truth is considered as reliable. Di erent from these truth discovery approaches, the goal of our work is to give a consistency score for each item across sources, indicating the trustworthiness of information about each item. In this paper, we proposed to tackle the problem of infor-mation trustworthiness estimation by modeling the common latent reasons across multiple sources and computing a score for each item to quantify the degree of inconsistency in the information it receives. A novel two-step procedure was pro-posed to solve the problem: A Multi-Source Deep Belief Network (MSDBN) is rst constructed to learn a joint repre-sentation that underlies ratings across multiple sources, and then each source is reconstructed based on the joint repre-sentation and an item's consistency score is computed based on the degree to which its actual ratings are aligned with re-constructed data. In real datasets collected from three pop-ular travel planning websites on Las Vegas and New York city hotels, we showed that the proposed method discovered hotels that receive inconsistent and possible unreliable in-formation. Quantitative analysis on synthetic data demon-strated the superior performance of the proposed method compared with other baseline methods in distinguishing in-consistent from consistent information.

Note that time factors play an important role in informa-tion trustworthiness analysis. In the hotel review example, hotels' conditions, users' preferences and spammers' strate-gies all change over time, so information quality of sources also changes. In the future, we plan to consider the e ect of time and estimate the information trustworthiness as time evolves. Furthermore, we hope that our information trust-worthiness analysis tool can help in agging spam reviews. To achieve this goal, we should utilize ne-grained text anal-ysis in the model and this is the other research direction we want to explore.
