 Dong-Chul Park Abstract A multiresolution-based bilinear recurrent neural network (MBLRNN) is proposed in this paper. The proposed MBLRNN is based on the BLRNN that has robust abilities in modeling and predicting time series. The learning process is further improved by using a multiresolution-based learning algorithm for training the BLRNN so as to make it more robust for the prediction of time series data. The proposed MBLRNN is applied to the problems of network traffic prediction and electric load forecasting. Experiments and results on both practical problems show that the proposed MBLRNN outperforms both the traditio-nal multilayer perceptron type neural network (MLPNN) and the BLRNN in the prediction accuracy.
 Keywords Wavelet transform  X  Recurrent neural network  X  Time series prediction  X  Network traffic  X  Load forecasting 1 Introduction Predicting a chaotic time series is equivalent to approximating an unknown nonlinear function mapping of a chaotic signal. Various models have been proposed to model and predict the future behavior of time series [ 8 ]. Statical models such as moving average and exponential smoothing methods, linear regression models, autoregressive models (AR), autoregressive movingaverage(ARMA)models,andKalmanfiltering-basedmethodshavebeenwidelyused However, the use of a linear analysis technique to approximate a nonlinear function may lead toinaccuratepredictionofatimeseries.Therefore,modelsbasedonlinearanalysistechniques may not be suitable for modeling and predicting time series.

Various nonlinear models have been proposed for time series prediction. One group of models that has garnered strong interest is neural networks(NN)-based models, because of applications,NN-basedmodelshavebeensuccessfullyappliedandwellacceptedinnumerous practical problems. Among these NN-based models, the feed-forward neural network, also known as the multilayer perceptron type neural network (MLPNN), is the most popularly used, and has been applied to solve many difficult and diverse problems [ 21 ]. While the MLPNN, which forms a static input X  X utput mapping, is suitable for modeling stationary systems, it shows limited performance in modeling dynamical systems with a time series characteristic. A recurrent neural network (RNN) model with consideration of the internal feed-back was proposed to overcome the inherent limitations of the MLPNN [ 5 , 6 ]. The RNN has been shown to be more efficient than the MLPNN in modeling dynamical systems and has been widely used for time series prediction [ 5 ].

In this paper, a multiresolution-based bilinear recurrent neural network (MBLRNN) is proposed for time series prediction problems. The MBLRNN is based on the BLRNN that has been shown to have robust abilities in modeling and predicting time series [ 17 , 18 ]. The learning process is further improved by utilizing a multiresolution-based learning algorithm. The multiresolution-based learning algorithm employs wavelet transform to decompose the time series into a multiresolution representation. The learning process is then performed at each representation to learn the most important correlation structures that are hidden in the original time series. Therefore, the multiresolution-based learning algorithm can learn the underlyingrelationshipbetweentheinputandoutputofthetimeseriessystemmoreefficiently than the traditional single resolution-based algorithm. Furthermore, complex learning tasks from the originally complex signal can be simplified by learning a simpler sub-signal at each representation. The proposed MBLRNN is evaluated through applications to network traffic prediction and electric load forecasting.

The remainder of this paper is organized as follows: Sect. 2 presents a review of multireso-lution analysis with a wavelet transform. A brief review of the BLRNN is given in Sect. 3 .The proposed MBLRNN is presented in Sect. 4 . Section 5 presents some experiments and results on a network traffic data set and an electric load data set including a performance comparison with the traditional MLPNN and BLRNN models. Section 6 concludes the paper. 2 Multiresolution wavelet analysis Thewavelettransform[ 14 ],anoveltechnologydevelopedinthesignalprocessingcommunity [ 4 , 15 ], has received much attention from neural network researchers in recent years. Several NN models based on a multiresolution analysis using a wavelet transform have been proposed analysis is to analyze a signal at different frequencies with different resolutions. It produces a high quality local representation of a signal in both the time domain and the frequency domain. In order to conduct a time series analysis, use of the discrete wavelet transform has been proposed [ 20 ]. More recently, the so-called ` a trous wavelet transform has been proposed. This approach produces  X  X mooth X  approximation by filling the  X  X ap X  caused by decimation, using redundant information from the original signal [ 2 ].

The calculation of the ` a trous wavelet transform can be described as follows: first, a low-pass filter is used to suppress the high-frequency components of a signal while allowing the low-frequency components to pass through. The scaling function associated with the low-pass filter is then used to calculate the average of elements, which results in a smoother signal.

The smoothed data c j ( t ) at given resolution j can be obtained by performing successive convolutions with the discrete low-pass filter h , where h is a discrete low-pass filter associated with the scaling function and c 0 ( t ) is the
From the sequence of the smoothing of the signal, the wavelet coefficients are obtained by calculating the difference between successive smoothed versions:
By consequently expanding the original signal from the coarsest resolution level to the and the scaling coefficients as follows: where J is the number of resolutions and c J ( t ) is the finest version of the signal. Equation ( 3 ) also provides a reconstruction formula for the original signal. 3 Bilinear recurrent neural networks The BLRNN is a simple recurrent neural network, which has a robust ability in modeling dynamically nonlinear systems and is especially suitable for time-series data. The model was initially proposed by Park and Zhu [ 18 ]. It has been successfully applied in modeling time-series data [ 17 , 18 ].

Figure 1 shows an example of a BLRNN with one hidden layer. For a one-dimensional input/output case, the output value of a bilinear recurrent neuron is computed by the following equation: where x [ i ] is the input, y [ i ] is the output, and N is the order of recursion.
In the following, we explain about a simple BLRNN that has N input neurons, M hidden neurons and where K = N  X  1 degree polynomials is given. The input signal and the nonlinear integration of the input signal to hidden neurons are: where T denotes the transpose of a vector or matrix and the recurrent term is a M  X  K matrix And where w p is the weight of bias neuron. A p is the weight vector for the recurrent portion, B p is the weight matrix for the bilinear recurrent portion, and C p is the weight vector for the feedforward portion and p = 1 , 2 ..., M .Let  X  be the activation function of the hidden neuron, the output of p th hidden neuron is then:
More detailed information on the BLRNN and its learning algorithm can be found in [ 17 , 18 ]. 4 Multiresolution-based learning algorithm Most of the NN-based models use a learning algorithm in a supervised manner to update their weights in their iteration procedure. The error back-propagation algorithm is a highly popular learning algorithm based on the gradient descent method. The gradient descent method is a local search method that often results in a local optimal solution. Therefore, this algorithm is often not suitable for training a very complicated and chaotic signal.

The multiresolution-based learning algorithm attempts to improve the learning process by decomposing the original signal into a multiresolution representation. As stated in Sect. 2 , the original signal is decomposed into a multiresolution representation using the wavelet transform. The representation of the signal at a resolution level j can be calculated as follows: levels, c J is the scaling coefficients at resolution level J , x is the original signal, and w j is the wavelet coefficients at resolution level j . Figure 2 shows an example of different representations of a signal obtained using the wavelet transform, where r 0 is the original respectively. The figure plots 100 samples from each representation of the signal for easy visualization.

The learning process is performed through J learning phases according to the number of resolution levels J : where L j ( r j ) denotes the learning phase at resolution level j using representation r j .
The learning phase at each resolution level j , L j ( r j ) , uses the representation signal r j to update the network weights. The first learning phase L J ( r J ) begins with randomly ini-tialized network weights and the subsequent learning phase L j ( r j ) begins with the updated BLRNN model is employed to learn the information from the representation at different reso-lution levels. Figure 3 shows the learning process using the multiresolution-based learning algorithm. 5 Experiments and results 5.1 Network traffic prediction problem TheproposedMBLRNNisexaminedandevaluatedintermsofitsapplicationtotheprediction of network traffic. Real-world Ethernet traffic data sets collected at Bellcore in August 1989 [ 11 ] are used to conduct experiments. The Ethernet traffic data set is network traffic data measured at each 0.01(s) over two normal hours of traffic corresponding to 10 6 samples of data. The data were downsampled with a time scale of 1(s), resulting in 10,000 data samples. Figure 4 shows the first 1,000 samples from the network traffic data.

In order to render the data suitable as input to a neural network model, the data are norma-process, the data are further expressed to multiresolution by means of the wavelet transform. Figure 5 shows an example of different representations of the network traffic data used in the experiments.
For measuring the prediction performance, the normalized mean square error (NMSE) is employed in this experiment. The NMSE is calculated by the following formula: where x n represents the true value of the sequence,  X  x n represents the predicted value, and  X  represents the variance of the original sequence over the prediction duration N . Note that NMSE is one of the most widely used performance measures for measuring the accuracy of a electric load forecast model.

The input X  X utput relation for this experiment is as follows: where x [ n ] denotes the traffic at the time n and = 1.

In experiments, on-line training and test are performed: at time n ,  X  x [ n + 1 ] is predicted of  X  x [ n + 2 ] . In this on-line training procedure, the number of training epoches are set to be 3. Learning curves of different neural networks are given in Fig. 6 . As can be noticed from the learning curves, MBLRNN converges after few epochs with very low training error while other neural networks converges after far more epochs with much higher training error levels than MBLRNN. Note that the training time for one epoch is much longer in MBLRNN than the training time in MLPNN or BLRNN. Even though the convergence speed may not be an issue, final training errors can be a major indicator of the prediction accuracy in testing neural networks.

Experiments on single-step predictions ( value=1inEq.( 10 ) ) were carried out for eva-luating the prediction capability of MBLRNN. The performance of the MLPNN is obtained using a MLPNN model with the structure of 24-10-1, where 24, 10, and 1 are the number of input neurons, hidden neurons, and output neurons, respectively. The performance of the BLRNN is obtained using a BLRNN model with a structure of 24-10-1 and 3 recursion lines. The result of the proposed MBLRNN is obtained using a MBLRNN model with a structure of 24-10-1, 3 recursion lines, and 3 resolution levels. The NMSEs for MLPNN, BLRNN, and the proposed MBLRNN in this one-step ahead prediction are 1.24, 0.91 and 0.74, respectively.

Furthermore, for evaluating the generalization capability of MBLRNN-based predictor, multi-step predictions ( values in Eq. ( 10 ) are up to 100) were also carried out. In multi-step predictions, the predicted output is fed back as an input for the next prediction and all other network inputs are shifted back multi-step time units. The same network architecture and training parameters used in the previous experiment are also used in this experiment. The NMSEs of the iterated multi-step prediction are summarized in Fig. 7 for MLPNN, BLRNN, and the proposed MBLRNN. As can be seen from Fig. 7 , the proposed MBLRNN outperforms both the traditional MLPNN and the BLRNN. Moreover, when the number of steps increases, the performance of the traditional MLPNN and the BLRNN degrades significantly while the proposed MBLRNN suffers from a minor degradation of performance. This implies that the proposed MBLRNN is more robust than the traditional MLPNN and the BLRNN for predictions of time series.

In order to investigate the effect of resolution levels on the performance of the MBLRNN-based predictor, additional experiments were performed by varying the resolution levels up to 4. Figure 8 shows the prediction performance of the proposed MBLRNN using different numbers of resolution levels. As can be seen from Fig. 8 , the performance of the proposed MBLRNN increases when the number of resolution levels is increased from 2 to 3. However, upon increasing the number of resolution levels from 3 to 4, the improvement is minor. This implies that using 3 resolution levels for multiresolution representation of signal is sufficient for this problem. 5.2 Electric load forecasting problem Electric load forecasting plays a very important role in many operating decisions for power systems such as optimum generating unit commitment, economical load dispatch, the need to maintain scheduling, and fuel constraints [ 9 , 16 ]. However, load forecasting is a difficult and challenging problem because of the variability and nonstationarity of the electric load data. Therefore, the development of accurate load forecasting models receive a considerable attention from many researchers for decades. Various nonlinear-based models have been proposed for load forecasting. Among these models, neural network (NN)-based models are the favored choice for load forecasting because of their universal approximation abilities. Neural networks have the capacity not only to model time series load curves but also to model an unspecified nonlinear relationship between a load series and weather variables [ 16 ].
Comprehensive reviews of the application of neural networks to load forecasting show that neural network-based models give usable results and have been well accepted in practice by many utilities [ 9 ].

The performance of the MBLRNN load forecasting model is evaluated and compared with other conventional models on the North-American Electric Utility (NAEU) data set. The NAEU data set consists of load and temperature data provided by the University of Washington at the following web site: http://www.ee.washington.edu/class/559/2002spr .
The temperature and load data were recorded at every hour of the day from January 1, 1985 to October 12, 1992, rendering 2,834 days of load and temperature data. Figure 9 shows the hourly load demands from October 14, 1991 to October 12, 1992.

As can be seen from Fig. 9 , the load demand has seasonal patterns such as daily and weekly periodicity: high demand in daytime and low demand at night time or high demand on weekdays and low demand on weekends. The load demand also has a strong correlation with the temperature. Based on these temperature patterns and the correlation analysis, the input variables for load forecasting models are selected as shown in Table 1 .
The load forecasting for 1 X 24-h ahead is performed using the recursive forecasting method ( values in Eq. ( 10 ) are up to 24). Unlike the network prediction problem, the future tempe-rature is not available in practice when the recursive forecasting is performed. Therefore, it is necessary to estimate the temperature. In our experiments, the temperature was estimated from an average of the past temperature data.

The MBLRNN model used in this experiment is the same one used in the network traffic prediction problem : the structure of 24-10-1, 3 recursion lines, and 3 resolution levels. The conventional MLPNN and BLRNN were also employed in order to provide a comparison of the performance. All the above models utilized the input variables, as shown in Table 1 . All the models were retrained at the end of each day to incorporate the most recent load information. All of the data used in our experiments were treated as normal working days. Note that the special adjustments by the yearly load growth, Holidays, and anomalous days were not the scope of this paper and were not considered in this paper. The performance of the load forecasting models was evaluated in terms of the following Mean Absolute Percentage Error (MAPE): where x n and  X  x n represent the actual load value and the forecasted load, respectively.
Figures 10 and 11 show the performance over 1 X 24-h ahead for the short-term load fore-casting using different models during December 1991 and January 1992. As can been seen from Figs. 10 and 11 , the MBLRNN model achieves significant improvement when compa-red with the conventional MLPNN and the BLRNN models. This implies that the MBLRNN employing the wavelet-based neural architecture has robust capacity for load forecasting problems. Figure 12 a shows the forecasting results from January 11, 1992 to January 17, 1992, which has a typical winter load profile. Figure 12 b plots the corresponding errors of forecasting results. 6Conclusion A multiresolution-based bilinear recurrent neural network (MBLRNN) for time series pre-diction is proposed in this paper. The proposed MBLRNN employed the wavelet transform to decompose the signal into a multiresolution representation. The learning process based on the multiresolution-based learning algorithm is performed by learning from each repre-sentation of the signal at each level of resolution. The proposed MBLRNN is applied to the network traffic prediction and electric load forecasting. The experiments and results verified that the proposed MBLRNN is more efficient than the traditional MLPNN and the BLRNN with respect to the prediction of time series. The promising results from this paper provide motivation to utilize the proposed MBLRNN in other practical applications. Further work will focus on investigating other time-series data and the resolution level.
 References Author biography
