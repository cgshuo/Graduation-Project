 A set of words is often insufficient to express a user X  X  infor-mation need. In order to account for various information needs associated with a query, diversification seems to be a reasonable strategy. By diversifying the result set, we in-crease the probability of results being relevant to the user X  X  information needs when the given query is ambiguous. A di-verse result set must contain a set of documents that cover various subtopics for a given query. We propose a graph based method which exploits the link structure of the web to return a ranked list that provides complete coverage for a query. Our method not only provides diversity to the re-sults set, but also avoids excessive redundancy. Moreover, the probability of relevance of a document is conditioned on the documents that appear before it in the result list. We show the effectiveness of our method by comparing it with a query-likelihood model as the baseline.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval] General Terms: Algorithms Keywords: information retrieval, diversity, webgraphs. Users express information needs using a set of keywords. Current retrieval systems fail to capture the different infor-mation needs that could be expressed by users using the same set of keywords. Clearly this leads to multiple in-terpretations for a given query. For example, consider the query kcs . There are multiple interpretations for this query, one being the Kansas City Southern railroad; another, be-ing Kanawha County Schools in West Virginia; one more interpretation is information on KCS Energy, Inc.

In order to maximize the user experience it appears rea-sonable to diversify the result set. Diversify means to ex-amine the query with a broader perspective and account for the multiple information needs for the query. This diver-sification would provide complete coverage of subtopics for a given query to the user. Ranking with diversity requires moving away from the assumption that documents are in-dependently relevant to the query. Each document must be ranked based not just on its similarity to the query but also based on the documents retrieved before it.
 Table 1: Diversity results for varied number of eigenvectors and 50 terms.

For each eigenvector we construct a language model us-ing the documents corresponding to the k greatest values. Therefore, the m language models constructed from the doc-uments correspond to the k greatest values in each of the first m eigenvectors. The intuition is that the link structure clus-ters the documents into subtopics, therefore these language models provide a hypothetical set of subtopic models. The language model corresponding to each subtopic is evaluated against the query and then we take the document with the greatest score. This produces a set of documents (possibly fewer than m ) which are the highest scoring for the hypoth-esized subtopics that are then ranked in decreasing order of the original query-likelihood scores. We iterate in this way, taking the highest-scoring set of documents remaining, until we rank the top 200 documents in the original ranking. This method of iterating to obtain the final ranking is similar to the one described by Cartertte et al [3].
In our experiments, we used the ClueWeb09 dataset con-sisting of one billion web pages (5 TB compressed, 25 TB uncompressed), in ten languages, crawled in January and February 2009. We indexed the smaller set of  X  X ategory B X  which consists of 50 million web pages in English. We used the webgraphs in the dataset which has about 428,136,613 unique URLs and 454,075,638 outlinks. This test collection was used for the diversity task at TREC X 09. A total of 50 queries were evaluated and the subtopics for each query ranged from 3 to 8. We used the Lemur Toolkit and the Indri search engine in our experiment. The query-likelihood result set with Dirichlet smoothing (  X  = 2000) was used as our baseline results for reranking.

Our method was evaluated using the two measures which reward novelty and diversity, namely  X  -normalized discounted cumulative gain (  X  -nDCG) and intent-aware precision (P-IA). All our methods were evaluated at rank 10 with  X  = 0.5 in  X  -nDCG. To see whether the setting of parameters such as m (the number of eigenvectors) and n (number of terms) may affect the performance, we compare the results for a range of values.

By comparing the results of the two parameters in Fig-ure 1 we see that in general the performance increases and reaches a maximum at 50 eigenvectors and starts to decrease again. The number of terms in the model has less effect on the results. We report the diversity results by varying the number of eigenvectors along the Indri baseline model in Ta-ble 1. This table shows that our method did considerably well in diversifying the results set for all parameter values according to the  X  -nDCG measure although for the P-IA measure the results were below the baseline.
