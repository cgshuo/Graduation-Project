 Rua Passo da P X tria, 156  X  Bloco E In this report we provide a summary of the Second I nternational Workshop on Utility-Based Data Mining (UBDM-06) hel d in conjunction with the 12 th ACM SIGKDD International Confer-ence on Knowledge Discovery and Data Mining. The wo rkshop was held on August 20, 2006 in Philadelphia, PA, US A. As was the case for the first UBDM workshop, this workshop brought together researchers who currently investigate how to incorporate economic utility aspects into the data mining proce ss and practi-tioners who have real-world experience with how the se factors influence data mining applications. Cost-sensitive learning, active learning, active in formation acqui-sition, utility-based data mining Early work in data mining rarely addressed the comp lex circum-stances in which knowledge is extracted and applied . It was as-sumed that a fixed amount of training data was avai lable and only simple objectives, such as predictive accuracy in t he case of pre-dictive models and support/confidence in the case o f association rules, were considered. Over time, it became clear that these as-sumptions were unrealistic and that economic utility had to be considered and incorporated into the data mining pr ocess. This realization has led to research on active information acquisition , which focuses on methods for cost-effective acquisi tion of infor-mation for the training and test data, and research on cost-sensitive learning , which considers the costs and benefits associ-ated with using the learned knowledge and how these costs and benefits should be factored into the data mining pr ocess. Other utility considerations that are relevant in the dat a mining context include the running time of the data mining algorit hm as well as the costs and benefits associated with cleaning the data, trans-forming the data and constructing new features. In most previous work, these different types of uti lity considera-tions have been studied in isolation, without much attention to how they interact. As had been the case for the UB DM-05 work-shop, one goal of this workshop was to bring togeth er researchers who currently consider different economic utility a spects in data mining to continue to promote an examination of the impact of economic utility throughout the entire data mining process. This workshop again encouraged the field to go beyond wh at has been accomplished individually in the areas of active in formation ac-quisition and cost-sensitive learning. The workshop organizers further suggested that all of utility-based data mi ning could be viewed using a common framework, with a key questio n being whether such a framework would be beneficial to rea l-world ap-plications. Past research which has addressed the role of econo mic utility in data mining has mostly focused on predictive classi fication tasks. An additional goal of this workshop was to explore methods for incorporating economic utility considerations into descriptive data mining tasks such as association rules mining. The workshop received a strong response from the da ta mining community which was reflected in the quality and br eadth of the accepted papers. Each submitted paper was reviewed by two or three members of the program committee. In total, n ine regular papers were accepted for inclusion in the workshop. In addition, the workshop featured two invited talks and one pan el discussion. All of the papers are available from the workshop w eb page at http://www.ic.uff.br/~bianca/ubdm-kdd06.html. The nine accepted papers can be broadly categorized into three distinct topics: information acquisition, utility a spects of descrip-tive data mining, and cost-sensitive learning and i ts applications. The workshop featured two invited talks. The first invited talk, which opened the workshop, was Budgeted Learning of Probabil-istic Classifiers by Russell Greiner from the University of Alberta. The talk introduced and discussed challenges and se veral ap-proaches for solving the budgeted learning problem. Budgeted learning involves induction where unknown feature v alues can be acquired individually for each training example at a cost, and where the total cost must not exceed a predefined b udget. The goal is to acquire the feature values that maximize classifier per-formance given the budget. The speaker contrasted t his problem with other related fields such as active learning, optimum experi-mental design and online learning. The speaker pres ented a Bayesian framework for this active model selection, analyzed the hardness of the problem, presented several heuristi cs strategies and evaluated their performance for a variety of se tting. Empirical evaluations showed that while different policies pe rform better for different scenarios, one policy, Biased Robin, perf orms consis-tently well even though it does not employ informat ion about the budget. The Biased Robin (BR) policy suggests to  X  play the win-ner X , i.e., to continue selecting feature values of a given attribute as long as it continues to improve the model X  X  perf ormance. The speaker also discussed the budgeted learning proble m for learning a Na X ve Bayes classifier where it is necessary to d etermine not only the feature but also the class value for which a feature value is acquired. Empirical results on synthetic and UCI data sets show that SFL and BR successfully reduce the cost of obt aining a Na X ve Bayes classifier with a given generalization perfor mance, because they effectively identify discriminate features. SF L acquires val-ues for the feature for which the expected regret i s lowest when the entire budget is spent to acquire values of thi s features. Em-pirical results were also presented for learning a bounded active classifier in which the induction algorithm conside rs a classifica-tion budget for acquiring feature values at inferen ce time. The procedure that performed significantly better was a Randomized SFL (RSFL). Rather than using the SFL scores of the expected loss from an acquisition deterministically, RSFL ac quires features of a given class from a distribution, where the wei ght assigned to each acquisition is inversely proportional to its l oss score. The speaker discussed various directions for future wor k. These in-cluded more general problems, where class labels as well as fea-ture values are missing and more complex costs mode ls, such as non-uniform costs, or the case where some feature v alues must be purchased in bundles. Algorithmic challenges, such as developing policies with guarantees on performance were also d iscussed. The second invited talk, which opened the afternoon session, was Reinforcement Learning and Utility-Based Decisions by Michael Littman from Rutgers University. In this talk, the speaker drew a parallel between Reinforcement Learning (RL) and Ut ility-Based Data Mining. In RL the goal is to act so as to maxi mize the utility of behavior, while minimizing experience and comput ational costs. In UBDM, the goal is to act so as to maximi ze the utility of using the mined knowledge while minimizing the cost s of acquir-ing and mining the data. Therefore, the two framewo rks have a similar structure and, in particular, require a joi nt optimization which is computationally intractable to perform exa ctly. The speaker pointed out that, because of this intractab ility, recent trends in RL literature suggest the appropriateness of a PAC ( X  probably approximately correct  X ) style of analysis for RL. In the case of RL, this can lead to algorithms able to obtain near-optimal utility with polynomial-bounded amounts of experience and computation. The speaker gave examples of PAC a lgorithms for RL beginning with algorithms for the simplest c lass of RL problems, the k-Armed Bandits problem. Then, he mov ed on to PAC algorithms for model-based RL, where the learne r has access to a model of the environment. He presented the Mod el Based Interval Estimation (MBIE) algorithm and compared i t with two previous approaches: E 3 and R MAX . Finally, he discussed recent work that could potentially lead to PAC-based model -free RL algorithms. The speaker also showed two practical e xamples of the application of RL algorithms: a robotic example , where a car had to learn to maintain constant speed while going up a ramp, and a network repair example, where the goal was to recover from a corrupted network interface configuration. The sp eaker con-cluded the talk by saying that the PAC idea of keep ing costs within bounds instead of performing a joint minimiz ation could also lead to practical algorithms for UBDM. Nine contributed papers were presented at the works hop. These papers are briefly described in this section. The p apers that ad-dress similar topics were presented contiguously at the workshop and are discussed together here. Much of the work on data mining ignores information acquisition costs. In Maximizing Classifier Utility when Training Data is Costly , Gary Weiss and Ye Tian investigate the impact on the data mining process when training examples are not free, but rather have a fixed cost. They introduce a utility measure that factors in the cost of the training examples and the cost of m isclassification errors and then use this measure to analyze the per formance of ten data sets as the training set size is varied. This analysis is then used to identify the optimal training set size for each data set. A progressive sampling strategy is then evaluated and empirically shown to identify a near-optimal training set size X  with near-optimal classifier utility. This is the first work to extend research on progressive sampling to take the cost of trainin g data into ac-count. The other paper related to information acquisition was a position paper by Omid Madani entitled Prediction Games in Infinitely Rich Worlds . The paper introduces the challenges and advantage s of learning in infinitely information-rich worlds s uch as the World Wide Web, the visual/physical world, and people's a ctions. Ma-dani proposes the learning process of playing predi ction games toward making powerful massive unsupervised learnin g possible. The games are played by a system that takes its seq uence of inputs from the world, or actively searches and acquires t hese experi-ences to generate learning episodes. The utility of such systems can be defined in terms of the operationality of th e prediction system: coverage, depth, accuracy, and speed. Madan i views the prediction system as consisting of a number of inte racting compo-nents driven by multiple algorithms. The system lea rns, adapts, self-organizes and grows in its functionality over time. He out-lines the desiderata for such a system which includ e (a) use of online algorithm that are time and memory efficient to enable prediction games with unbounded data that are proc essed and discarded online, (b) handling large number of feat ures, (c) han-dling large numbers of categories, and (d) robustne ss to imperfec-tions, uncertainty, and variety. The paper discusse s several direc-tions for future research including to research to efficiently learn and recognize myriad categories and the need to bet ter understand natural systems that perform similar tasks such as the animal brain which uses experiences for massive learning that is not explicitly supervised. Four of the nine papers included in the workshop co nsidered util-ity in the context of descriptive data mining tasks . The first two papers are concerned with finding high utility item sets. This work is an extension of the work on finding frequent ite msets, which is the critical first step in association rule mining. High utility item-sets differ from frequent itemsets in that the util ity of the items in each itemset are taken into account (e.g., the prof it associated with an item may be considered). The first paper related to descriptive data mining, Efficient Mining of Temporal High Utility Itemsets from Data Streams by Vincent Tseng, Chun-Jung Chu and Tyne Liang, focused on the problems associated with finding temporal high-utility items ets in data streams. This is the first work to tackle this spec ific problem. The algorithm developed by the authors is notable becau se it generates relatively few temporal high-utility 2-itemsets and thus limits the memory space and CPU I/O time that is needed, meeti ng the criti-cal time and space efficiency requirements for mini ng data streams. The second paper, A Unified Framework for Utility Based Meas-ures for Mining Itemsets , by Hong Yao, Howard Hamilton and Liqiang Geng, focuses on the measures used for util ity-based itemset mining. It begins be reviewing the various utility-based measures available for itemset mining and describes ten such measures. These measures must factor in the interes tingness and frequency of the itemset. The authors formalize the semantic sig-nificance of utility measures and classify existing measures into one of three categories: item level, transaction le vel and cell level. A unified framework is then proposed for incorporat ing utility-based measures into the data mining process via a u nified utility function. Three mathematical properties (anti-monot one, con-vertible and upper-bound) of utility-based measures , which im-pact the time and space costs of itemset mining wer e then identi-fied and each of the ten utility measures were then analyzed with respect to these properties. This work provides an excellent intro-duction to utility-based measures for itemset minin g and a coher-ent way of organizing and comparing these measures.
 The topic of utility measures, which was addressed in the previous paper, is also addressed in the third paper on desc riptive data mining, Assessing the Interestingness of Discovered Knowled ge Using a Principled Objective Approach by Robert Hilderman. In this case, however, the primary focus is on interes tingness (which can be viewed as a type of utility) and the goal is to rank the pat-terns, or summaries, generated by data mining in or der to aid the user by highlighting the most interesting patterns. This work theo-retically and empirically evaluates twelve diversit y measures as heuristic measures of interestingness. Five princip les are identi-fied that a measure of interestingness must satisfy to be useful for ranking summaries, and seven of the twelve interest ingness meas-ures are shown to satisfy all of these properties. This work thus addresses the important task of evaluating utility measures for the purpose of ranking the results from descriptive dat a mining. Privacy is a very serious concern associated with d ata mining, especially when microdata X  X aw data that has not bee n summa-rized X  X s involved. The fourth paper, Utility-Based Anonymiza-tion for Privacy Preservation with Less Information Loss by Jian Xu, Wei Wang, Jian Pei, Xiaoyuan Wang, Baile Shi an d Ada Wai-Chee Fu addresses this issue. A common approach for ensur-ing privacy involves generalizing or suppressing at tributes that can be used to identify specific individuals. This work extends recent research by considering the utility of the a ttributes during the anonymization process, such that the amount of useful infor-mation preserved in the data is maximized. Two simp le but effi-cient heuristic local recoding methods for utility-based anonymi-zation are described and evaluated on real and synt hetic data sets and shown to boost the quality of analysis using an onymized data, when compared to existing methods. Note that becaus e this pre-processing step is concerned with how best to modif y the descrip-tions of the data, we associate this work with desc riptive data mining. Three of the nine papers presented at the workshop considered the costs and benefits associated with using a predicti ve model and how these costs and benefits should be factored int o the data min-ing process of learning the model. The first paper, entitled Beyond Classification and Ranking: Constrained Optimizatio n of the ROI by Lian Yan and Patrick Baldasare, proposes an algo rithm for learning a classifier that directly optimizes the r eturn on invest-ment (ROI), a common measure used in financial serv ices applica-tions such as predicting collectability of accounts receivable and predicting defection of mutual funds accounts. This problem is different from standard cost-sensitive learning or standard ranking problems because there is a budget constraint as we ll as example-dependent misclassification costs. The paper formu lates this problem as a constrained optimization problem, conv erts into an unconstrained optimization problem and solves it us ing a gradient descent method. Experiments on two financial datase ts comparing the proposed method to standard classification, wei ghted classifi-cation, ranking and regression show that the method leads to a substantial improvement of financial impact. The second paper on cost-sensitive learning, entitl ed Pricing Based Framework for Benefit Scoring by Nitesh Chawla and Xiangning Li, also addresses a financial applicatio n of predictive data mining. The paper presents a method for derivi ng a pricing scheme that maximizes the total profit that can be obtained from using a probabilistic classifier. They illustrate t he use of the method for a loan practice based on credit scoring models and a benefit matrix. The framework enables pricing the l oan for each individual customer based on the loan amount and th e corre-sponding interest rate, as well as the probability of defection pre-dicted by the credit scoring model. Preliminary exp eriments on UCI Machine Learning repository datasets show that there is a strong relationship between the quality of the prob ability esti-mates and the resulting profits from the model. The third and last paper on cost-sensitive learning , entitled Maxi-mum Profit Mining and Its Application in Software D evelopment by Charles Ling, Victor Sheng, Tilmann Bruckhaus an d Nazim Madhavji, proposes a data mining solution to the pr oblem of pre-dicting escalation risks of software defects to ass ist human experts in the review process of software. Like in many bus iness applica-tions, the ultimate goal of software defect escalat ion prediction is to maximize the net profit, i.e., the difference in the profit before and after introducing the data mining solution. Not e that this in general depends on the current policy for choosing which soft-ware defects to correct. The paper presents a novel and simple method for converting the maximum net profit proble m into a cost-sensitive classification problem. This is done by expressing the net profit as a linear formula of false positiv es, false negatives, true positives and true negatives. After this trans formation, it is possible to apply any existing cost-sensitive learn ing method to this problem. The paper compares a number of differ ent cost-sensitive learning methods (Undersampling, Costing, MetaCost, Weighting and CSTree) on a real dataset from the so ftware defect escalation domain and show that many of the methods can achieve large positive net profits. In particular, the resu lts show that CSTree can produce a large positive net profit whil e providing comprehensible results, which is important for depl oying data mining solutions in industry. The workshop was concluded with a panel discussion. The par-ticipants were Russell Greiner of the University of Alberta, Nitesh Chawla of the University of Notre Dame, Gerald Fahn er, Analytic Science Director at Fair Isaac Inc., and Dragos D. Margineantu of The Boeing Company. There was wide agreement among panel members and workshop participants that UBDM work as reflected in the research contributions in the field includes a set of chal-lenging theoretical problems of significant practic al implications. Participants and panelists noted that it is useful to pursue future UBDM meetings. It was noted that UBDM is related to some work in Experimental Design and Game Theory. Thus r esearchers were encouraged to examine work in these fields for relevant ref-erences and for inspiration. In light of the potential practical implications of Utility-Based Data Mining research, panelists noted the striking lack of real-world, publicly available data which include real c osts and utility information. In order to fill in the gap, researche rs often generate random costs and benefits for publicly available da ta sets. This is not an ideal approach because it makes it difficult to compare methods and because it is never a good idea for a r esearcher to generate the evaluation data for his/her own work. To promote and further the impact of UBDM research, the paneli sts agreed that it would be beneficial to devise a set of well defined tasks and corresponding data sets (with cost/benefit informat ion). The pan-elists discussed potential venues for obtaining rel evant data as well as the creation of a simulated environment in which different tasks can be defined and from which data can be gen erated. It was noted that the flexibility of such a platform would support coordi-nated efforts to advance research progress in a var iety of emerging practical tasks. It was noted that the platform cou ld also help de-vise competitions similar to the Trading Agent Comp etition to help advance work in the field. This discussion con cerning the need for cost and benefit information, and the reco gnition that this information will not always be available, led to a discussion about the need to develop robust methods that exhibit con sistent per-formance for different utilities and data sets . We feel that the workshop was a success and achieve d our goals. The majority of attendees stayed for the full-day w orkshop and participated very actively in the discussions, demo nstrating a growing interest among data mining researchers and practitioners in Utility-Based Data Mining. The discussions were lively and suggested interesting areas for future research as well as ideas for how to better coordinate and promote research effor ts in the field. One of our goals for this workshop was to broaden t he scope of utility-based data mining to include descriptive da ta mining tasks. We believe this goal was successfully reached, sinc e four of the nine papers addressed utility considerations in des criptive data mining tasks. This is notable because most of the p revious work in utility-based data mining has focused on predictive tasks. We have also seen the community move away from addr essing pure cost-sensitive learning or information retriev al tasks to ad-dress basic issues that can help establish the foun dations of UBDM. For example, two of the papers, A Unified Framework for Utility Based Measures for Mining Itemsets and Assessing the Interestingness of Discovered Knowledge Using a Pri ncipled Objective Approach are concerned with providing a general framework for describing and analyzing utility meas ures, and each of the papers reviews a large number of existing ut ility measures in this context. The work described in these papers can clearly aid researchers who introduce new utility measures. We aimed for the workshop to facilitate interaction among re-searchers and practitioners and to promote the tran sfer of ideas among problems previously addressed in isolation an d in this regard we think we were successful. Part of this su ccess is due to the fact that we allocated significantly more time than last year to discussion. We thank the authors, guest speakers, p rogram com-mittee members and attendees for their contribution s towards this end. We are indebted to Sunita Sarawagi, the KDD-06 Workshop Chair, and to the SIGKDD for organizational and fun ding assis-tance. We also thank our anonymous workshop proposa l review-ers for their insightful suggestions and encouragem ent. Bianca Zadrozny is an Assistant Professor in the Computer Sci-ence Department of Federal Fluminense University in Brazil. Her research interests are in the areas of applied mach ine learning and data mining. She received her B.Sc. in Computer Eng ineering from the Pontifical Catholic University in Rio de J aneiro, Brazil, and her M.Sc. and Ph.D. in Computer Science from th e University of California at San Diego. She has also worked as a research staff member in the data analytics research group at IBM T.J. Watson Research Center. (http://www.ic.uff.br/~bianca) Gary Weiss is an Assistant Professor in the Computer and Info r-mation Science Department at Fordham University. Hi s research interests include machine learning and data mining and the fun-damental issues that arise when tackling complex, r eal-world problems. Specific topics he has worked on include utility-based data mining, learning from rare classes and cases, event prediction and data mining applications in the telecommunicati ons industry. He received his B.S. from Cornell University, his M .S. from Stan-ford University and his Ph.D. in Computer Science f rom Rutgers University. He has worked at Bell Labs and AT&amp;T Lab s, includ-ing five years in a marketing analysis group where he applied data mining methods to complex business problems. (http://storm.cis.fordham.edu/~gweiss) Maytal Saar-Tsechansky is an Assistant Professor in the McCombs School of Business, The University of Texas at Austin. She received her Ph.D. from New York University and obtained her B.S and M.S from Ben Gurion University, Israel. Her research focuses on economic machine learning and data minin g methods for data-driven business intelligence. (www.mccombs.utexas.edu/faculty/Maytal.Saar-Tsechan sky) 
