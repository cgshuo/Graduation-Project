 1. Introduction
In Web pages written in East Asian languages, such as Chinese, Korean, Japanese and Vietnamese (referred to as native ticularly true for technical articles containing new concepts (Fig. 1). Apparently, an English term and its native translation really refer to the same concept. Therefore, a search service user should have the option of treating them equivalently.
For instance, there can be three kinds of Web pages in Chinese containing information about the  X  X  X iterbi Algorithm ( ) X , i.e. those containing  X  X  X iterbi Algorithm X  but not its Chinese translation  X  X   X , those contain-ing  X  X   X  but not  X  X  X iterbi Algorithm X , and those containing both (see Fig. 3 ). A user may expect that a query made with either  X  X  X iterbi Algorithm X  or  X  X   X  should retrieve all of the above three types of pages. Otherwise, some potentially useful information can be missed. However, this is not the case for current search services. As another example, at the time of writing this article, the Google search engine indexes around 2,220,000 Web pages in Korean con-taining the Korean term  X  X   X  but not its English counterpart  X  X  X amsung X , about 46,000,000 pages containing  X  X  X amsung X  but not  X  X   X , and about 183,000 containing both.

To solve such a problem, a query issued by a user can be expanded before the final submission to a search engine. Such a search engine. Fig. 2 illustrates a schematic architecture of the first configuration. In this configuration, the expander is trained off-line and invoked by a Web agent as needed. For example, a query of  X  X  X amsung X  will be expanded to  X  X  X amsung
Construction of a query expander is non-trivial in such an application context for a few reasons. First, the conventional use of cross-language dictionaries is not immediately applicable due to the large number of out-of-vocabulary (OOV) words.
This is especially problematic for technical articles, where new terms emerge frequently. While some of these OOV words may have standardized translations later, many of them are day-to-day creations of ordinary users of the Web. Second, a term in English may have multiple popular translations in the native language documents but not all of them can be found in well-defined dictionaries. For instance, Korean words  X  X   X ,  X  X   X , and  X  X   X  are commonly found in Web pages, and all of them correspond to the English word  X  X  X igital X  because of different phonetic interpretations. In addition, an acronym in English may have various meanings but only a small number of them can be found in an existing dictionary.
Therefore, we need to construct and maintain a mechanism to represent these unified concepts for better Web search ser-vices. This is essentially an automated learning process using materials from the Web.

In this paper, we propose a concept unification mechanism in order to facilitate query expansion to retrieve pages in mul-tiple languages. We place such a functionality on the client side as a module of a Web agent to utilize what a search engine can offer as-is. This could be placed on the server side but the change of the system would be much more significant. An advantage of a client side implementation is that unification can be customized to each user X  X  needs. After all, whether two words in the same or different languages are equivalent or not can be subjective more than often. In our proposal, we only process document snippets in search result pages returned by a search engine. By processing these snippets using a model combining statistical, phonetic, and semantic features of a native language, we are able to effectively unify terms of different languages referring to the same concept. Our experimental results indicate that the retrieval accuracy is well im-proved using such a dynamically maintained mechanism. In this work, we focus on the Chinese and Korean languages, but the same idea can be applied to Japanese and Vietnamese that share some linguistic similarities.
 The rest of the paper is organized as follows. We first summarize some of the linguistic characteristics of the Chinese and
Korean languages (Section 2). This is by no means a comprehensive treatment but just to familiarize readers with the rele-vant features so that the translation model in this work can be better understood. Next in Section 3, we briefly review the innovations in using the Web as text corpus for translating OOV words in CLIR. There, we highlight some of the important features of our proposed synthetic model. The details of the model are explained in Section 4. The effectiveness of our model has been investigated by extensive experiments as detailed in Section 5 before we conclude this article. 2. Background in the Chinese and Korean languages In order to facilitate understanding of the model presented in this paper, we provide some background knowledge of the
Chinese and Korean languages needed. This includes romanization using Latin alphabet,  X  X  X ords X  as semantic units, and loan-words from other cultures.

The Chinese written language employs Chinese characters, or logograms, written in imaginary rectangular blocks. Each character represents a semantene or morphteme and a syllable. For example, the Chinese character  X  X   X  carries semantene, morphteme, and a syllable at the same time. It uses a graphic representation to mean  X  X  X ill X  with a single-syllable pronun-ciation  X  X  X han X .

Similarly, the Korean written language employs Hanguls, the Korean characters, and optionally Chinese characters writ-the 51 jamo currently used in Korean, 24 of them are equivalent to letters of the Latin alphabet. The other 27 are clusters of two or more of these simple letters. Therefore, due to its phonetic nature, the Korean language can be transcribed using Latin letters relatively easily. The case of Chinese language is a bit more complicated in that Chinese written characters are blocks of morphtemes. To transcribe written Chinese using Latin alphabet, each character is decomposed phonetically using a  X  X  X omanization X  system. In Mainland China and Singapore, the system is called  X  X  X anyu pinyin X , or simply  X  X  X inyin X ; while of Latin letters, and an intonation mark. Usually, the intonation mark is ignored in romanization.

Although Chinese characters are both semantenes and morphenes, strictly speaking, the Chinese language is not  X  X  X ono-syllabic X . In modern Chinese, the nouns, adjectives and verbs are largely di-syllabic. There are also a good number of tri-syl-labic or even tetra-syllabic words, especially proper names, in Chinese today. That is, a word usually consists of two or more Chinese characters, which is regarded as one form of agglutination in linguistics. More often than not, the romanization of a
Chinese word is usually written as a single-word looking group of Latin letters to indicate that the corresponding Chinese characters essentially form one word. The case for the Korean language is similar, multiple Hangul characters can form a stable group, i.e. a word, collectively. Such grouping is especially important for disambiguation in Korean due to the phonetic nature of the language. In written documents in Chinese and Korean, however, there are not any delimiters between words in the same sentence. As a result, an important step in natural language processing for these languages is word-segmentation , where a sentence is first segmented into words before further treatment.

During the evolution of the Chinese and Korean languages, they have absorbed a sizeable number of loanwords, also called foreign words, from other languages and cultures, e.g. English. Two forms of such borrowing are transliteration and translation. Transliteration is transcription of a foreign word according to its pronunciation using Chinese or Korean charac-ters with similar pronunciations. It is also fairly common to use Chinese or Korean characters to coin new words in order to literated while part of it is translated. For example, in the loanword  X  X   X  (hamburg bun),  X  X   X  (pinyin:  X  X  X anbao X ) is a transliteration of hamburg and  X  X   X  is a translation of bun.
 3. Related work Concept unification of terms in different languages shares a common essence with query translation for Cross-Language
Information Retrieval (CLIR). Such essence is data-driven machine translation especially for new words that do not exist in bilingual dictionaries, i.e. OOV words. Since any collection of corpus for OOV translation, manual or automated, will neces-sarily lag behind the emergence of new words, it has been proposed that documents on the World Wide Web can be used to minimize such a gap. There are two typical routes to achieve this purpose. In the first approach, there have been efforts in identifying documents in two languages that are on the same topic. With correspondence of some sort, texts in these two documents can be used to translate OOV words. Alternatively, as more language mixing has been observed in Web docu-ments, it has been proposed to mine such documents by themselves rather than along with companion documents. In such efforts, these mixed-language documents are returned by a search engine with a mixed-language query. We will review these approaches briefly in the sequel.

The idea of using Web documents for machine translation has been around for a while. A central mechanism for OOV translation is to identify a pair of documents in the two relevant languages that are on the same topic. Most such translation methods have been studied for the purpose of query translation in CLIR. Documents with strong correspondence are called parallel corpus and the acquisition of such documents from the Web was first put forward in the seminal work of Resnik (1999) . Shortly, Fung and Yee observe that a weaker mapping between a pair of documents enables us to find a larger num-ber of such document pairs to alleviate the corpus size limitation (Fung &amp; Yee, 1998 ). These documents are referred to as comparable corpus . In a later work of Lu, Chien, and Lee (2004) , HTML anchors are used to deduce a correspondence between the residing and target documents. These investigations are innovative explorations of using Web documents for machine translation, and the task of identifying document pairs is non-trivial and is usually a performance bottleneck.
Mixed use of English and a native language in a single Web document has been a trend especially for East Asian languages such as Chinese, Korean and Japanese. In the meantime, as the search engine technology advances, the pages returned by a search engine reveal higher and higher relevance to the query. These facts allow us to use a search engine to return mixed-language Web pages for machine translation without building an explicit correspondence between documents. This idea was translator queries a search engine with Japanese terms to be translated, and downloads the top-100 Web pages returned by the search engine to find English translations. In order to choose the proper English translation, statistics such as co-occur-rence frequency and distance between the English translation candidates and Japanese term are used. The reported transla-tion accuracy is about 62%. The tests indicate that about 42% of the 1,082,594 Japanese technical terms in the Japanese X 
English bilingual dictionary NOVA can find at least one Web page containing both the term and its English translation. It is encouraging to see that mining the Web pages can help to reduce about 50% intensive manual work in constructing a bilin-gual thesaurus. Compared to the common words in the thesaurus, specialized terms (proper nouns) in popular queries are easier to be translated by bilingual Web pages because these terms typically appear along with their original English terms in news reports or technical documents. Cheng, extend the previous idea to further expedite translation using only the Web document snippets in the returned search result pages without downloading and processing the actual documents ( Cheng the Chinese and Korean languages. Note that, as a pre-processing step to translate English terms to Chinese, a word-segmen-tation algorithm is used to extract translation candidates from texts in Chinese. In an independent simultaneous work of
Zhang and Vines, word-segmentation is avoided by selecting candidates from all sequential combinations of words collating with target specialized terms in a fixed windows size (Zhang &amp; Vines, 2004 ). Recently, Zhang, Huang, and Vogel (2005) ex-plore using a synthetic model that employs machine transliteration and translation models, combined with the frequency and distance information in the texts, in order to translate OOV Chinese terms into English.

In this work, we attack the problem in an opposite direction of Zhang et al. (2005) with a more sophisticated and power model. It has the following unique features that have not been attempted in previous work:
We observe that unified concepts are very effective in MLIR. And this can be done efficiently via machine translation by automated Web mining.

We translate OOV English terms emerging from the Web into a native East Asian language, particularly Chinese and Kor-ean. Due to the agglutinative nature of the target languages (see Section 2), it is necessary to extract translation candidate terms out of the Web documents. To do that, we consider all consecutive substrings in the search result snippet in a native language under a certain size. Thus, we are able to process much longer key terms without any limitation from a word segmenter. For example, in the statistic component of our synthetic model, the length of a translation candidate is con-sidered as a contributing factor to provide a type of  X  X  X upport X  in scoring. Note that, compared to Zhang and Vines (2004) , we consider longer such substrings to accommodate complex compound phrases, which leads to the next feature of our model.

In the semantic X  X honetic mapping component of our model, we exploit a bipartite matching between a long English key term and a complex translation candidate. This is especially powerful and effective to translate long terms between Eng-lish and Chinese or Korean (see Section 4.4.2). The reason is that, for a long compound term, not only can each component in one language match a component in the other language through a different channel, such as via translation or via trans-literation, but also these matching components may appear at completely different positions in the compound terms in these two languages. This is a significant extension over the assumption of an alignment between terms in two languages (Zhang et al., 2005 ). 4. Concept unification  X  design details
In order to generate unified concepts to facilitate Web information retrieval, the client side query expander uses raw Web pages and search result pages returned by search engines via a model that integrates the statistical, phonetic, and semantic information of English and a native language. The process can be decomposed into the following four steps, each correspond-ing to a solid rectangle in Fig. 4 . The terminology for the relevant notions in this paper is summarized in Table 1 . (1) Key term extraction X  We first determine the concepts that we wish to unify by identifying English key terms of interest (2) Term enhancement  X  To obtain the most updated translations of an English key term, we query a search engine with (3) Translation candidate generation  X  From the result pages returned by the search engine, we obtain a set of candidate (4) Candidate ranking  X  Out of the translation candidates, we keep the top matches of a key term to form a uniform con-
In this section, we present the details of these four steps. 4.1. Key term extraction
An English key term ,or key term for short, is an English word or phrase embedded in Web pages in a native language. Typ-ically, these terms are either OOV or IV but with incomplete or out-of-date translations in an English-native (-Korean or -Chinese) dictionary. These terms are the centers around which we will unify a concept in English and a native language.
To obtain the English key terms, we process raw Web pages in a native language. Here, we only include the key terms based on a set of criteria to be more or less selective instead of considering all embedded Western language text strings. For exam-ple, we are particularly interested in terms indicated by certain punctuation marks, such as quotation marks and parenthe-ses, because such punctuation indicates the importance of these terms in information representation to some extent. On the tioned for example purposes.

In a piece of earlier work by Jeong, Myaeng, Lee, and Choi (1999) on unifying concepts in Korean and English, the authors extract transliterated Korean loanwords from documents in Korean using, among other things, statistical information within these documents. They assume that the English equivalents of these Korean loanwords are in the same set of documents processed. This is usually not the case for our purpose when we process short, rapidly changing Web pages. Therefore, here, we resort to a larger scope of available documents and enlist a dedicated step to extract terms of interest for further treatment. 4.2. Key term enhancement
With each English key term, we need digests of Web pages in a native language containing this key term. This can be done by querying a search engine using the key term along with some enhancement information in the native language. That is, we submit the English key term with some  X  X  X elevant terms X , called their friends in Fig. 4 , for a broader context of the key term in the native language. Two things should be noted here. First, the query is executed among Web documents in the native language to focus on the appearance of this English key term only in the native corpus. Second, the  X  X  X elevant words X  can be the translations of the key term in an English-native dictionary if it is an IV word. Otherwise, for an OOV word, they are the translations of a set of hint words of the key term. As introduced earlier, a hint word of a key term is an English word with which it has a high co-occurrence probability in an English corpus.

To obtain a set of hint words of a key term, we utilize the result pages returned by a search engine from a query submitted using the key term, i.e. pseudo-relevance feedback (PRF), instead of building and maintaining a co-occurrence frequency data-base of the English vocabulary. This is realized by processing the document snippets contained in the search result pages to generate the most relevant words using simple statistics like tf idf . In our experiment, we select hint words from the first 100 snippets returned by the search engine if the number of returned results is greater than 100. Otherwise, all the returned snippets are considered.

We confine the output here to IV words so that we can translate them to the native language using a dictionary. For exam-ple, suppose that key term  X  X  X aust X  is submitted to query the search engine for its hint words. The top-3 hint words are  X  X  X oe-the X ,  X  X  X ntroduction X , and  X  X  X iterature X . The Korean translations of these hint words are  X  X   X ,  X  X   X , and  X  X   X , respectively. Then the English key term is  X  X  X aust X  is enhanced to  X  X  X aust OR OR  X , where  X  X  X R X  is the union operator for search queries. The idea of enhancing a key term using multiple translations of the key term X  X  hint words or of the key term itself is to disambiguate these words mutually. A similar idea is used by an earlier proposal. Zhang et al. (2005) expand a key word by one translation or hint word at a time. Compared to their method, our one-shot key word enhance-ment is more efficient and usually less ambiguous. 4.3. Translation candidates
We use the enhanced English key term, i.e. the key term and its native friends, to query a search engine in order to obtain an extensive context of the English key term in the native corpus. Out of the document snippets in the result pages returned by the search engine (see Fig. 5 for a continued example), we intend to obtain the most updated translations of the key term ean in the figure) interspersed by punctuation marks. Due to the agglutinative nature of the native language (Section 2), we term using the integrated model (Section 4.4). The motivation of processing the highly succinct but informative document digests returned by the search engine is to generate a set of high quality translations of the English key word. The process of grouping characters in a sentence is usually called word-segmentation in East Asian language processing.
There are two representative methods for this. One relies on the co-occurrence frequency information in a native document
The other is to consider a window of texts of a given size n centered at an occurrence of the key term, and to employ all we take the second approach because the context of the key word provided by the search return pages is invaluable infor-mation for our purpose. The reason is that these pages of document digests are much more updated than a monolithic co-occurrence table as in the first approach. For example, if we limit the maximum word length (i.e. number of characters there-in) to four, then for a clause in a document snippet  X  X  ... , , ...  X , the translation candidates should include  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X , and  X  X   X . If the number of the occurrences of the key term in the snippets in the search result pages is k , the number of translation candidates output here is bounded from above by n m k . 4.4. Integrated statistical, semantic and phonetic model
The translation candidates from the previous step need to be ranked to reflect the relevance to the English key term, and only the top ones will be used as the real equivalents in the unified concept. To do that, we resort to a model that integrates not only statistical correlation but also semantic and phonetic similarities between a candidate and the key term.
In traditional natural language processing, statistics such as co-occurrence, v 2 , and mutual information, are typically used to determine the most suitable translation. For example, in the v 2 method of Cheng et al. (2004) , the probability of finding the correct translation of an English key term is around 30% for the case of top-1 most correlated candidate and 70% for the ignores some of the important inherent connections between a key term and its translations, i.e. the semantic and phonetic ties. For example, for the OOV English key term  X  X  X ttack of the clones X , the v 2 method of Cheng places  X  X   X , the correct Korean translation, well after the top-10 most correlated candidates. However, if semantic and phonetic matching was used, with  X  X   X  and  X  X  X ttack X  matching by meaning and  X  X   X  and  X  X  X lones X  matching by sound, we can additionally infer that  X  X   X  is a better translation for  X  X  X ttack of the clones X  than predicted solely using the v 2 model. The same idea applies to the Chinese translation  X  X   X , where  X  X   X  is a phonetic match of  X  X  X lones X  and  X  X   X  a semantic match of  X  X  X ttack X .

In this subsection, we provide the detailed design of our translation model, which integrates statistical, semantic and pho-netic information available in the set of translation candidates. We first use a statistical model to trim down the candidate set. Then we apply a semantic and phonetic matching between the remaining candidates against the key term to determine the final winners for concept unification. 4.4.1. Statistical trimming Statistical information in natural language processing usually deals with aspects such as: Co-occurrence frequency  X  The occasion where two or more words appear together may suggest that they are correlated. This is the most fundamental and effective measure.

Distance in document  X  The closer two words appear in the same document, the more likely they are related. This is espe-cially true for machine translation applications, where in the corpus a term is typically followed by its translation imme-diately. For example,  X  X  ... (FBI) ...  X  suggests that the string between the parentheses is a translation of the preceding term.
 is probable that they are proper names.

These principles have been explored in related studies. For example, Nagata et al. (2001) and Zhang et al. (2005) utilize the first two rules simultaneously, assuming that the more often two terms appear and the closer they are when they do, the more likely they are related. The work of Zhang and Vines (2004) adopts the first and third rules.

In our statistical model, we incorporate all these principles when trimming the translation candidates. This is achieved by considering, in each window of the key term occurrence, the character distance between the English key term e and a par-occurrences of c and e among the returned snippets, i.e. the set of all occasions where c appears in the window of e  X  X  occur-formula: where a is a weight adjustment factor, l  X  c  X  is the length of candidate c ; m is the maximum length of all candidates, and 2. 4.4.2. Weighted phonetic and semantic matching
The previous statistical trimming leaves us the top portion of the translation candidates of an English key word, i.e. the candidates with high correlation. Here, we further rank the remaining candidates according to the phonetic and semantic similarities with regard to the key word.

When processing an English key term and its native translation candidates, a candidate can be a compound from multiple simpler  X  X  X ords X . Here, each such word in a native language has a similar linguistic function as a word in the English lan-guage. To obtain these words, we resort to word-segmentation once more. Note that, even within the same translation can-didate, each native word may correlate to an English word through a different channel, such as sound and meaning.
Furthermore, the orders in which these matching simpler words are put together are usually different in English and in tomed to use a trailing proposition phrase as a modifier. For example,  X  X   X , a translation candidate of  X  X  X ttack of
The Clones X , is a compound noun phrase, where  X  X   X  is transliterated from  X  X  X lones X ,  X  X   X  a translation of  X  X  X ttack X , and  X  X   X  is  X  X  X f X . Apparently in this case, a sequential mapping between the candidate  X  X   X  against the key word  X  X  X ttack of The Clones X  is infeasible. In addition, the mapping should incorporate both phonetic and semantic information.
Here, our objective is to assign each translation candidate a metric  X  X  X SP X , Score of Semanteme and Phoneme, which is the maximum phonetic and semantic similarity between a key term and all permutations of the candidate X  X  consisting words.
Thus, we can rank the translation candidates using such a score. To do that, we employ a graph notation as in Fig. 6 . Assume that the English key term e can be decomposed into a sequence of words h w loss of generality, we assume that a P b .If a &gt; b , we add a b dummy vertices to the smaller side to change the graph to an  X  a ; a  X  bipartite graph. We consider all edges possible in between, i.e. a complete bipartite graph. Each edge  X  w ; w 0 j  X  X  1 6 i ; j 6 a ) is associated with a weight r  X  w words. (The detailed definition of these weights is presented in Section 4.4.3.) The SSP of candidate c with regard to key term e is calculated as p Permutation of index set r Phonetic and semantic weight between two words r r Algorithm (also known as Hungarian Algorithm) within polynomial time (Munkres, 1957) .

We rank the translation candidates of a key term in the decreasing order of their SSP scoring. The final translations of the from the rest of the list. To locate such a gap automatically in a total of Q candidates, we can find an index q such that both the top-q and bottom-( Q q ) candidates present small SSP variance of some sort. That is, we find q that is where  X  i  X  is the eccentricity of the i -th candidate from the mean of its own half of the list. 4.4.3. Weight assignment
Given an English word w and a native word w 0 , the phonetic and semantic weight is defined as where r p and r s are the phonetic weight and semantic weight between the two words, respectively, and kk is a normal-ization operator. That is, we quantize and normalize the phonetic and semantic similarities between the two words, and take the dominant one as the phonetic and semantic weight between these words. The details are to follow.
 research, utilizing phonetic information has been explored in processing transliterated loanwords in the Korean language (Kang &amp; Choi, 2002; Jeong et al., 1999 ). A goal in this setting is to identify Korean words borrowed from other languages by analyzing their pronunciations and matching them against the English vocabulary phonetically. Here, we base our pho-netic weight definition on the method in Jeong et al. (1999) . We first break a word into a sequence of phonetic tokens. In the case of English, a word w is decomposed to h t 1 ; t 2 ; ... ; t combination of letters. In the case of Korean, a word w 0 is decompose to h t 0  X  X  X amo X . For Chinese, the phonetic tokens are the elements of  X  X  X inyin X  (romanization). With some pre-processing, we con-sider only words w and w 0 that can be decomposed into the same number of phonetic tokens. Otherwise, we assign a zero weight to them because it is unlikely for w 0 to be transliterated from w . Assuming that h  X  h
Here, we utilize two transition probabilities in the bi-gram HMM (Hidden Markov Model) from our training corpus. ditioned co-occurrence of the corresponding bi-grams in the two languages. The logarithm signifies the order of magnitude
The semantic weight r s  X  w ; w 0  X  between words w and w 0 reflects the translation hit rate using bilingual dictionaries. The bilingual dictionaries employed here are the Korean X  X nglish WordNet and the LDC Chinese X  X nglish dictionary with some amendments. By looking up a dictionary, an English word w has a set of native translations f ~ w multiple entries, i.e. j I j P 1. The semantic weight indicates the maximum overlap between w 0 and all translations ~ w
Specifically, r s  X  w ; w 0  X  is defined as the maximum length, over all translations f ~ w w 0 and ~ w i divided by the length of ~ w i . For example, consider English word w  X   X  X  X nformation X  and native word w 0  X   X  X   X .  X  X  X nformation X  can be translated into  X  X   X  and  X  X   X  using our bilingual dictionary. That is, f ~ w { X  X  ,  X  X . Here, the overlap is 0.5 and 0 for the two translations, respectively. Therefore, the semantic weight, r of  X  X  X nformation X  and  X  X   X  is 0.5. Note that the range of r
Due to the range difference between r p and r s , we must normalize them before we can determine which one is more tween English key term e  X h w 1 ; ... ; w a i and translation candidate c  X h w 0 term for concept unification. 5. Experimental evaluation
The goal of this work is to study the effectiveness of concept unification for both Mono-Lingual and Cross-Language Infor-mation Retrieval, where accuracy of concept unification has a direct effect on the performance. In this section, we first study the accuracy of concept unification, also known as translation precision. Then we investigate to what extent MLIR effective-ness can be improved when relevant terms in different languages are treated as unified concept. Last, we study its effective-ness for CLIR. 5.1. Accuracy of concept unification
Before studying the effect of concept unification on information retrieval, we first look into the accuracy of our proposed approach for concept unification. In particular, we crawl the web pages of specific domains (universities and research insti-tutes) using the WIRE crawler by Center of Web Research, University of Chile (http://www.cwr.cl/projects/WIRE/ ). Currently, we have downloaded 140 sites with 25,587 Korean Web pages and 230 sites with 45,765 Chinese Web pages. From these pages, 4232 and 8536 English key terms are extracted, respectively. We select 200 terms from them for both native lan-guages in our experiments. Among these 200 terms, 50 belong to the foreign loanword category, 50 are in the compound word category, 50 are abbreviations, and 50 are arbitrary words. By doing this, we can have a better understanding of the performance of our approach in different settings.
 The accuracy of unifying semantically identical words in different languages is dependent on the translation performance.
The overall concept unification performance is shown in Table 3 . The evaluation metric is whether the term can be correctly translated into a native language. As indicated in the table, 81.5% English key terms from the Chinese Web pages and 82% English key terms from the Korean Web pages can be correctly translated into accurate Chinese and Korean, respectively.
Another 11.5% and 7% terms X  translations contain at least one correct Chinese and Korean translation, respectively. We ob-serve that the translation errors usually come from incomplete translation. An example for incomplete translation is English term  X  X  X IGIR2005 X , which can only be translated to  X  X  (international conference of computer Information Retrieval) X , ignoring the year.

We also compare our approach to two other well-known translation systems,  X  X  X iveTrans X  and  X  X  X oogle X . Tables 4 and 5 show the results in terms of the top-1, 3, and 5 inclusion rates word translation system based on Web mining. This system has two ways for translation. The faster approach with lower pre-cision is based on the  X  X  X hi-squared X  method ( v 2 ) and the slower one with higher precision is based on the  X  X  X hi-squared X  and tic plus phonetic and semantic model, respectively. Even though the overall performance of LiveTrans X  combined method ( v 2 + CV) is better than the simple method ( v 2 ) as in both Tables 4 and 5, the context-vector (CV) may sometimes mislead the selection, and can negatively affect the translation performance. For instance, in our experiments, the Korean word  X  X   X  is the translation of English key term  X  X  X ordan X , which is ranked 2nd and 5th in v 2 and v 2 + CV, respectively. In mance. It also can be observed that  X  X  X T + PS X  shows best performance among all tested methods.

Table 6 shows the translation performance based on word categories. Here,  X  X  X orrect X  and  X  X  X artially correct X  translations are all treated as correct. It can be observed that the highest accuracy occurs to the foreign loanword category because the phonetic characteristics of these words filter out much noise. For instance, the candidates for English key term  X  X  X iterbi X  based on statistical information are  X  X   X ,  X  X   X ,  X  X   X , ... , X  X   X . Considering the phonetic information of these candidates, the correct translations  X  X   X  and  X  X   X  are adopted. For compound words such as  X  X  X ttack of the clones X , both the phonetic and semantic information contributes to obtain the correct translation. For terms in the abbreviation and others categories, such as  X  X  X TO X ,  X  X  X BA X , and  X  X  X bscess X , the phonetic and semantic information is usually not useful but the statistical information is helpful. 5.2. Mono-Lingual Information Retrieval  X  MLIR
Here, we study on the contribution of concept unification to MLIR, which treats relevant terms in different languages as one unified entry in indexing.

Before reporting our experimental results using certain effectiveness measures (precision and recall), we provide a sig-nificance test to show that the observed differences is not identical. The Wilcoxon signed-rank test and t -test are commonly used for the significance test in Information Retrieval experiments Sanderson (2005) . In a nutshell, both take a pair of equal-sized sets of per-query effectiveness values, and assign a confidence value to the null hypothesis: that the values are drawn from the same population. If confidence in the hypothesis (reported as a p -value) is less than 0.05 ( jected. Although such tests only consider the null hypothesis, it is common to assume rejection implies that values are most likely drawn from different populations, which means that the results of experiments are statistically significant.
Among the assumptions of the Wilcoxon signed-rank test and the t -test are that the values being tested  X  in our case, per-query effectiveness  X  are distributed symmetrically and normally, respectively (Sanderson, 2005 ). However, effectiveness rarely follows either distribution. Countering such caution, Hull (1993) points out that the t -test can be reliable even when data being tested are not distributed normally. Therefore, we applied paired t -test to find out whether the observed differ-ences is identical. In the sequel, we present results of both effectiveness measure and significance test.

Here, we run retrieval experiments to examine the impact of our concept unification on MLIR. The retrieval system is based on a vector space model with our own indexing scheme added with concept unification. We employ the standard tf idf scheme for index term weighting and idf for query term weighting. Our experiment is based on the KT-SET test col-collection of abstracts in the field of computer and information science with 30 queries together and relevance judgements for them. Although the Korean corpus of NTCIR-3 test collection was also available, we still choose the KT-SET because the queries for the NTCIR-3 Korean corpus containing fewer specific lexemes than KT-SET. A detailed description of dataset is shown in Table 7 .

The baseline against which we compare our approach adopts a relatively simple bilingual dictionary to identify index terms. The effectiveness of the baseline scheme is comparable with other indexing methods, e.g. Lee etal. (1996) . While there is a possibility that an indexing method with a full morphological analysis may outperform our rather simple method, it would also suffer from the same problem of using different terms to refer to the same concept, which can be alleviated by concept unification. In our scheme, we extract the key English term from the Korean texts, and translate them. Each Eng-lish term and its equivalent(s) in Korean are treated as one unit via query expansion. A paired t -test shows that using the mean average 11-point precision as performance measure, our approach performed significantly better than the best base-line method, at p  X  0 : 002. In addition, we have t -tests using MAP and P@5 as performance measure, respectively, and the p -in Fig. 7 and Table 8 , we obtain 14.9% improvement based on the mean average 11-point precision, 13.5% on MAP, 16.8% on
P@5. Note that these results are obtained even with the errors made by the previous unification of semantically identical terms in different languages. 5.3. Cross-Language Information Retrieval  X  CLIR
For CLIR, one of the major hindrances to achieving retrieval performance at the level of MLIR is the translation of OOV words ( Zhang et al., 2005 ). Our Korean X  X nglish CLIR experiments are based on the NTCIR-3 English corpus associated with 32 training topics. Each topic has four parts: title, description, narrative and keywords relevant to the topic. In our experi-ment, only the title was used as queries to retrieve texts from the English document collection because the average length of the titles, about 3 terms, is close to the practical size of user queries. The bilingual dictionary we used is Korean X  X nglish
WordNet with additional entries (Korean X  X nglish translation pairs) added. With this dictionary, 9 out of the 32 Korean que-ries can not find the English translation for at least one term. Since the Korean terms in the query may have many meanings, some of the translations are not relevant to the intended meaning of the query. We use mutual information ( Jang, Myaeng, &amp;
Park, 1999 ) to alleviate this translation ambiguity problem. Last, we search for the documents relevant to a translated Korean query as well as an original English query using Okapi BM25 (Robertson &amp; Walker, 1999 ). The primary metric is the inter-polated 11-point average precision, precision at 10 (P@10), and mean average precision (MAP).

Four runs are compared to investigate the contribution of translating OOV words correctly in CLIR. Since not all of these 32 queries contain OOV words, we report our experimental results in two different cases. In the first case, all of the 32 que-ries are used to simulate a typical scenario in user applications. In the second case, only 9 queries containing OOV words are used. This is to investigate our method X  X  effectiveness in extreme cases where many OOV words are present.
 RUN1 (Without OOV)  X  Korean queries are translated using a dictionary look-up ignoring the OOV words.

RUN2 (Google)  X  We use the Google Translation module to translate the Korean queries into English in order to provide a baseline for our test.
 RUN3 (With OOV)  X  Korean queries are translated using a dictionary look-up while applying our method to OOV words.
RUN4 (Mono-lingual)  X  We retrieve the English documents with the corresponding English queries (titles) provided for those Korean titles by NTCIR for a comparison with the  X  X  X deal X  case.

NTCIR has two different criteria to evaluate retrieval performance. The first is called rigid relevance , where  X  X  X ighly rele-vant X  and  X  X  X elevant X  documents are regarded as relevant documents. The second is called relaxed relevant , where  X  X  X ighly are shown in Figs. 8 X 11 based on these two criteria. The performance on all queries is shown in Figs. 8 and 9 and Tables 9 and 11 . Regardless of which criteria are used, paired t -tests ( Tables 10 and 12 ) shows that RUN3 (With OOV) exhibits better performance than RUN1 (Without OOV) and RUN2 (Google). Also observe that the commercial translation product provided by Google performs almost the same as the RUN1 (Without OOV), where the terms containing OOV words are ignored during the query translation.

We further conduct experiments only on the 9 queries containing OOV words. The results of this series of experiments are shown in Figs. 10 and 11 and Tables 13 and 15 . Paired t -tests ( Tables 14 and 16 ) show that translating the OOV terms using our approach in CLIR (RUN3) outperforms the mono-lingual case (RUN4).

In order to better understand this situation, we calculate the average precision per query. As shown in Fig. 12 and Fig. 13 , most queries except queries 13, 20, and 27 present similar retrieval performance across RUN3 (With OOV) and RUN4 (Mono-lingual). Query 13 ( , X  X  X oomsday thought X ) is translated into  X  X  X schatology X  by our approach. Although it is different from the correct translation  X  X  X oomsday thought X  provided by NTCIR, it is still fairly acceptable. Since only a few documents contain  X  X  X oomsday thought X  and no documents contain  X  X  X schatology X , the retrieval performance is affected negatively.
In addition, the performance enhancement before 5-point is much higher than the 6 X 10-point area. That is, our approach performs well especially for highly ranked documents. For query 27 (  X  X  X acau returns X ), it shows better performance in RUN3 (With OOV) than RUN4 (Mono-lingual) for both two relevance metrics. The corresponding English query of topic 27 ( ) provided by NTCIR is  X  X  X acau returns X , but our returned translation is  X  X  X acau macou return X . Since  X  X  X acau X  and  X  X  X acou X  are both correct translations of  X  X   X , this query yields a better result. By applying our approach, the average precision of these 9 queries is increased by about 113% from 0.15 (without OOV) to 0.32 (with OOV) based on rigid relevance (Fig. 12 ) and about 100% from 0.16 to 0.32 based on relaxed relevance (Fig. 13).
From our experiments, we notice that OOV words should not be ignored in CLIR and the translation accuracy of our con-cept unification mechanism can effectively alleviate the OOV symptons in CLIR. 6. Conclusion and future research
In this article, we investigate unifying semantically identical terms in different languages for Information Retrieval, espe-cially in Chinese and Korean with English embeddings. This is based on a trend of language mixing in East Asian documents that include terms in English directly. We have shown that it is effective to treat an English term and its corresponding Chi-nese or Korean translation as a single unit for Information Retrieval. Apparently, this idea can be extended to unify a concept in multiple languages. An interesting feature of this work is to use the search result pages returned by a search engine as small corpus to train an association model. We observe that, even using only the document snippets returned by an intel-ligent search engine such as Google, a rather sophisticated model (statistic, phonetic and semantic in our case) can be suf-ficiently tuned to satisfy the purpose of Mono-Lingual and Cross-Language Information Retrieval.

As the search engine technology advances, and also with wider adoption of Web 2.0, automated interactions with search engines will become a promising approach for online knowledge discovery. Compared to traditional knowledge discovery in large databases, the Web provides a much more voluminous and more updated corpus to exercise this idea. Search engines are an excellent interface to distill information relevant to a query. Such a Web-based information retrieving paradigm can be applied to a wide spectrum of applications. For example, we can label a product on the Web using a set of known tags by simply issuing a query containing this product and processing the result pages, either following the returned links or merely processing the document snippets therein. This is an interesting extension of data classification in data mining. Or alterna-tively, we can estimate the  X  X  X emantic distance X  between two terms using a similar technique. This is analogous to data clus-tering in traditional knowledge discovery. From this point of view, the concept unification mechanism studied in this work is an analogy of conventional data association. However, these are a few relatively straightforward applications of the above Web-based knowledge discovery paradigm; and there will be many more exciting applications ahead for us to explore. Acknowledgements
This research is supported by the IT R&amp;D program of MKE/IITA 2008-F-047-01, Development of Urban Computing Mid-dleware, National Natural Science Foundation of China Grant 60803106, and Discovery Grants of NSERC Canada (303958). References
