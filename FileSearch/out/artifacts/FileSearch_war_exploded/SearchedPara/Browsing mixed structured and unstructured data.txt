 1. Introduction
Browsing an adaptive database system with both structured and unstructured data can be achieved through simplifying data structures and using subject carrying indexing information to order the data.
The indexing terms or metadata may be assigned probabilities, costs, and benefits, and a system then may adapt its internal organization and its output to these user-based probabilities or costs, as well as to other metaphors (e.g., information theoretic) for user needs and interests. Information retrieval systems have been developed that can manipulate structured data, as have relational and object oriented database systems that manipulate text fragments or multimedia ( Borkar, Deshmukh, &amp; Sarawagi, 2001; Sabin &amp;
Yap, 1998; Vasanthakumar, Callan, &amp; Croft, 1996; Yan &amp; Annevelink, 1994 ), as well as XML encoded media ( Blanken, Grabs, Schek, Schenkel, &amp; Weikum, 2003 ). Our system integrates the information in a structure that can be optimally ordered for browsing, regardless of the type of source and the type of data, e.g., structured, semi-structured, or unstructured.
Facts may be retrieved and presented consistent with minimizing the dissimilarity between adjacent facts, as well as the degree to which the facts match with the query. If we conceptualize the output of a structured database as a table of rows and columns, a system can learn the characteristics of rows and col-umns of interest of a user or group of people and display a table consistent with the user  X  s or users  X  pref-erences. Similarly, if the user wishes to retrieve documents or other media, the data can be arranged to reflect the user  X  s expressed interests as a table for browsing or retrieval. Our purpose here is to integrate these structured and unstructured models to provide integrated output that might contain, for example, fac-tual numeric data about the population and average temperature for a country, along with a picture of the capitol building, an audio recording of the country  X  s national anthem, and a journal article about that country  X  s economy.

In the case of an adaptive database system with stored information, the organization of the data for ulti-mate use by a query producer is the primary means of optimizing the data for a given user or group of users. By allowing systems to adapt to these user-preference-based aspects of structured, semi-structured, or unstructured data, a system may improve the user  X  s experience in a variety of ways. We integrate data for the user, with data being organized and presented based on the user  X  s needs, not on the type of database structure used to store the information, e.g. a relational database or a set of HTML web pages. 2. Representing data
Surrogates for documents or facts may be consistent with any of a number of representational methods ( Cover &amp; Thomas, 1991; Hamming, 1986; Losee, 1990 ). Assigning indexing representations and metadata features may have several inconsistent goals: to best represent the author  X  s intent; to best represent the needs of the individual user or a group of users; or to best represent what is most special or unique about the data ( Losee, 1998 ).

The representations of data may be viewed as structured , semi-structured ,or unstructured . Structured data is organized in a highly regular way, such as in tables and relations, where the regularities apply to all the data in a particular dataset. Semi-structured data would contain this same information, but instead of having regular structures applying to all items in the dataset, data might be interpreted with structural information supplied as tags, such as name =  X  X  X ob X  X , city =  X  X  X hapel Hill X  X , state =  X  X  X orth
Carolina X  X  . In such a case, one can move the name, city, and state components around as one moves from information about one person to another. The structural regularity across data items is gone.
Missing data may be represented by the presence of a label with a null attribute or an attribute indi-cating  X  X  X issing X  X , or the label may be omitted completely. Unstructured data, such as text or images, contain information but contain no explicit structuring information, such as tags. However, these tags may be assigned using manual or automatic techniques, converting the unstructured data to semi-struc-tured data.

Tags representing index terms or metadata may be assigned by humans, or may be produced or selected through automated procedures. The term metadata is often applied to index features that are part of a for-mal indexing system that is meant to be used beyond a single academic or institutional environment. Meta-data is a more recent term than indexing, being applied most frequently to recent systems for representing characteristics of entities, often based on the Dublin Core or RDF (Resource Description Framework) ( Greenberg, 2002; McCray, Gallagher, &amp; Flannick, 1999; Moens, 2000; Salminen, Tague-Sutcliffe, &amp; McClellan, 1995 ).

The metadata used to describe a topic, fact, relation, or an entire document may be produced from com-bining the individual metadata items assigned to specific features. Index terms or metadata may be ar-ranged a number of ways to represent a single topic. A simple linear list includes all index terms and can be used to indicate whether the data being indexed is or is not about the topic in question.
A different, hierarchical , arrangement is used in many topical classification systems. If the books in a library were divided into history and non-history books, with history being the primary binary feature, the second feature for history books might represent something historically specific, such as pre-or post-1950, or northern or southern hemispheres. The second feature for non-history books may be some-tems with context-sensitive feature meanings. This hierarchical method is used in CART ( Duda, Hart, &amp;
Stork, 2001 ). Each feature may represent a different level in a decision or regression tree or the output from a similar technique, with many of our features having multiple semantic values corresponding to the set of features at a particular regression tree level. In the case where meaning depends upon context, the proba-bilistic feature ordering techniques described below will perform at a lower level than would occur if all features were unambiguous and their values were independent of their context. User preferences may be treated as factors (e.g. economic) in the feature selection algorithms within procedures such as regression trees, producing user oriented classification and ordering.

For applications below, we assume a simple linear arrangement ( Gaede &amp; Gunther, 1998; Jagadish, 1990 ), or feature vector, for browsing ( Cover &amp; Walsh, 1988; Hearst, English, Sinha, Swearingen, &amp;
Yee, 2002; Losee, 1992; Losee, 1993; Losee, 1997a; Morse, 1970 ) or retrieval ( Kowalski, 1998; Losee, 1998 ) purposes. In most cases, the presence or absence of a feature is indicated in the representation with a 1 or a 0. This may be enhanced by using statistical techniques such as Latent Semantic Indexing (LSI) ( Deerwester, Dumais, Furnas, Landauer, &amp; Harshman, 1990; Hull, 1994; Manning &amp; Schutze, 1999 )tore-duce the dimensionality of the feature space and to produce statistically independent features. A wide range of systems have been developed that assume binary independent features and that perform successfully ( Lewis, 1998 ), and we continue with this assumption. A system using all available characteristics is expected to outperform a system using a limited set of human developed (and more intuitive) index terms or metadata. 3. Representing facts Representing and organizing data is an important factor in effectively storing and retrieving information.
The choice of an organizing principle that supports both structured and unstructured data and that also inherently adapts to user preferences will allow for the development of a more general model for data stor-age systems.

Attributes can represent values from a domain of all possible values. Attributes and key attributes, those attributes that serve as the entry points to relations, are described more fully in traditional database and information retrieval texts, to which the reader is referred if they are unfamiliar with these topics. We as-sume that structured and semi-structured data is organized for our purposes consistent with best practice in relational manipulation, so that there are no insertion, update, or deletion anomalies occur, and the rela-tions are fully normalized ( Arenas &amp; Libkin, 2003; Lee, 1987 ). Such anomalies would have little direct im-pact upon browsing, but are considered desirable features in database design for management purposes.
The availability of properly normalized data would make it much easier to extract key-attribute pairs for ordering below.

We denote a minimal fact as the representation of the relationship between two informational represen-tations, one referred to as the key, K , and the other referred to as the attribute, A . The key is the repre-sentation of an attribute about whose referent the non-key attribute provides information ( Losee, 1997b ).
The key and the attribute are representations, and themselves may be described or represented by indexing or metadata. The metadata representations for the key and attribute are denoted as M tively. Each metadata set M contains a vector of n individual metadata items m to be binary for this analysis, although more complex systems are available for non-binary representations ( Losee, 2003 ).
 The representation or code for a factual representation is the 5-tuple the metadata associated with the union of the metadata for the relation, M the key, M K ; the key  X  s value, K ; the metadata associated with the attribute, M
A . The structure of a factual representation contains: the Gray code for the logical union of the relation  X  s metadata vectors (key and attribute), the Gray code for the factual representation  X  s key vector, the key (often text), the Gray code for the factual representation  X  s attribute vector, the factual representation attribute (often text).

When we refer to the Gray code for an application, we refer to the binary representation of the metadata vector, e.g., the presence or absence of each feature, with the Gray code providing an ordering for the vec-tors. This ordering is discussed below and examples are given in the next section. The proposed ordering provides a different and superior ordering for browsing purposes than that obtained with traditional binary ordering (e.g., 00,01,10,11). 4. Organizing data as factual representations for browsing and display applications
Using the structures suggested above for factual representations, we may place existing structured and unstructured data into a common data structure suitable for integrated browsing and retrieval.
Structured data may be easily represented using factual representations, although complex relations may need to be decomposed into a series of  X  key , attribute  X  2-tuples. Possibly the simplest data structure for structured data consists of a 2-tuple containing a single key and a single attribute. For example, cats are of particular type, suggesting the relationship ( cat _ identifier , cat _ type ), with one instantiation being the attribute (in this instance, of Tigger )is Tortie .

When storing a structured relation as a factual representation, it might be stored as before with the meta-data for the key, the metadata for the non-key attribute, and the union of these two metadata sets in a fac-tual representation. The 5-tuple relation described above might then appear as {( cat , identifier , type ), ( cat , identifier ), Tigger ,( cat , type ), Tortie }, where sets of metadata are shown here in parentheses.
In the case where there are multiple attributes for a single key, the relationship between each attribute and the key is stored as a separate factual representation. In the case of a compound attribute, a synthetic and unique identifier is placed as the attribute, and new compound facts are developed so that the unique identifier is the key for each attribute in the original compound attribute in the new factual representations.
Ideally, these unique identifiers shouldn  X  t be presented on a display, being replaced with the compound attributes, or placed into a fuller version of the relation, as described later in this paper.
As an example, consider the case where Caitlyn is the key and her father  X  s first name is Bob and his last name is Losee. The compound attributes could be represented as two different compound facts: that Caitlyn has a father whose first name is Bob and a second fact, that Caitlyn has a father whose surname is Losee.
The preferred method here is to assign a unique identifier to Bob Losee and indicate that Caitlyn has father 12345, while there are two relationships, one indicating that father 12345 has the first name of Bob and a second relation indicating that father 12345 has the surname of Losee. One can also represent this unique identifier for notational purposes by combining the attribute fields, e.g., using Bob _ Losee instead of 12345.
We may find the following factual representations: {(name,daughter,father,firstname,surname), (name,daughter), Caitlyn, (name,father,firstname,sur-name), Bob_Losee} {(name,father,firstname,surname), (name,father,firstname,surname), Bob_Losee, (name,father,first-name), Bob} {(name,father,firstname,surname), (name,father,firstname,surname), Bob_Losee, (name,father,sur-name), Losee}
Unstructured data are stored with the image, document text, or other binary large objects ( X  X  X lobs X  X ) being a single large attribute, and the metadata associated with the attribute being derived automatically or manually from the attribute. Other attributes about the document, such as title, author, etc., can be trea-ted as additional attributes in added factual representations with the same key as the factual representation containing the document.

Consider an audio file of cat howls stored at a particular URL. The factual representation for this would
We propose that structured, semi-structured, and unstructured data be converted into factual represen-tations and then organized using the Gray code so as to achieve an interleaved ordering of data of all ori-ginal types. 5. Ordering metadata with the Gray code
Information and factual representations may be represented using binary forms, as discussed above. The information may then be sorted using any of a number of techniques. The Gray code to be discussed here is a binary representation system: we use it because it has several desirable techniques for ordering data.
Ordering consistent with the Gray code allows binary data to be placed near similar data ( Faloutsos, 1988; Losee, 1992; Losee, 1997a ). When the traditional Gray code is combined with probabilistic or eco-nomic conditions, adaptive systems may be developed consistent with particular circumstances, reflecting particular characteristics of users, as well as specific utilities for a user or group of users.
The binary Gray code is an ordering system by which, when counting, one number  X  s representation dif-fers from the next number  X  s representation (adjacent to it) by one bit position. When using the binary
Gray code (all Gray codes are assumed below to be binary codes to simplify discussion), the Hamming dis-tance, or number of bits by which two adjacent representations differ, is always one when enumerating.
Similarly, when ordering existing data using the Gray code, the distance between adjacent representations will be 1 when all possible representations are present once. When there are missing representations, order-ing by the Gray code may not be optimal (although it is still likely to be highly effective and may still be optimal).

Considering Table 1 , we can see that the Gray code does allow for each representation to differ from its immediate neighbors by one position. Counting using the Gray code can be envisioned as moving from 0 to 1 for the first two lines of Table 1 , and then placin ga1inthe second (the  X  X  X wo X  X  X ) column as the Gray code representation for the decimal numbers 2 and 3 reflect (as would a mirror) the Gray code representation for the decimal numbers 0 and 1. The Gray code representation for 4 through 7 then reflect the numbers for 0 through 3 with a 1 in the  X  X  X our  X  s X  X  column, and so forth. This reflected Gray code is the most commonly discussed Gray code, but there may be times when a non-reflective Gray code may be useful ( Losee, 2002 ). An example of a non-binary non-reflective Gray code is provided in the following order for Base 3 numbers: (00,01,02,22,21,11,12,10,20).
Factual representations may be ordered by using the Gray code. The key used in sorting is the concat-enation of the data as presented in the structure of a factual representation: f M has the effect of placing all 2-tuples of the same type, i.e., with the same metadata, together. Then, within tuples of the same type, those with the same metadata for the key and the same key value are placed together. Then, among the F s of the same type and with the same key, the 5-tuples are ordered so that similar types of attributes are placed together, and then within those, 5-tuples are ordered by the value of the attribute.

Once the factual representations have been ordered this way, users may browse through data, both inte-grated structured, semi-structured and unstructured data, by beginning at a starting point, usually the point that is most relevant or closest to the original information need or expressed query. Users can then move around the dataset, both in terms of columns and rows in a traditional display of the data. Browsing may support the same ordering for everybody, as is done in most libraries with static classification systems. Dy-namic classification allows for the ordering of data based on individual preferences, such as will be discussed below.

Retrieval can be implemented by beginning at the starting point and then retrieving those F s that have the highest probability of relevance, given the query treated as providing information about a Bayesian prior, with relevance feedback being incorporated when available ( Losee, 1988 ). This is what occurs in probabilistic information retrieval. Information needs and facts may also be treated as vectors, and the facts that are most similar to the expressed information need, as measured by the cosine between the two vectors, are retrieved ( Salton &amp; McGill, 1983 ). 6. Expected distance between adjacent facts
The distance between two adjacent facts may be computed, consistent with the measurement of the information of an event x as logPr( x ). We suggest that the expected information dissimilarity , denoted as E  X  I 6  X   X  , is the expected information associated with a feature times an indicator variable showing the presence or absence of a difference between features. For two metadata vectors, this is computed as where m i , k is the value for metadata feature k in metadata vector M occurring. The differences in values for E  X  I 6  X   X  for a single feature are shown in Fig. 1 .
Metadata features may be ordered within each column  X  s metadata feature vector so as to help minimize the expected distance between features ( Losee, 1992 ). Features may be ordered randomly, but this leads to suboptimal ordering of facts. Consider a situation where, given a list of foods, the closer a food was to the beginning of the list, the more likely you were to prefer that type of food. Clearly, a random ordering of food will result in the suboptimal (in terms of preferences) serving of food. If, however, the list was ordered by decreasing relative preference of the food, the ordering would be optimal in terms of preference. We minimize the expected information dissimilarity E  X  I 6  X  placing those individual features in each metadata vector with the lowest expected information dissimilarity tions. Thus, the features with the greatest expected information similarity (as changes occur) are changed most frequently, rather than the features whose changes would cause an overall decrease in expected infor-mation similarity.

Metadata features on the right (least significant digit) side change most frequently when counting or tra-versing a list ordered by an enumerating principle, as can be seen informally by counting in the decimal number system and noting how often changes occur in the rightmost column and how often changes occur in the column to its left.

When all the metadata features occur with p &lt; .5, E  X  I i and j when the rarer terms (with the lower dissimilarity values) are on the right side of the vector and it is most likely that the difference between the neighboring metadata features will be due to a smaller difference on the right rather than a larger difference on the left. 7. Costs of data organization
We may optimize feature ordering consistent with economic considerations. A cost, denoted by C ,is associated with features having different values in metadata features that are located more than an arbi-trarily chosen distance apart. The economic loss of having a 0 for a feature value in the metadata feature m i , k in metadata M i and a 1 for that feature in a M j is denoted as C feature k in M i having a value of 1 and M j having a value of 0. We suggest that the expected cost of feature k being different in two metadata vectors may be computed as the expected cost of dissimilarities associated with feature k . We assume that C
C The cost of placing metadata vectors M i and M j adjacent to each other, each of length n ,is assuming that features are independent of each other. This represents the sum of costs for metadata fea-tures that differ in value between m i and m j . For notational simplicity, we have denoted the loss C
C for feature k .
 The relationships between different costs and probabilities are shown in Fig. 2 .

When features were ordered within a metadata vector based on the feature  X  s E  X  I metadata vectors consistent with the Gray code minimized the expected information dissimilarity between the vectors. If we similarly order features by the expected cost associated with dissimilar metadata features
E  X  C 6  X   X  so that metadata features with the lowest E  X  C metadata vectors, with features with the highest E  X  C 6  X  that the expected cost of the arrangement has been minimized.

When using the information theoretic expected information dissimilarity, E  X  I be easily inferred from the existing data. Costs, however, reflect user values and preferences, and must be obtained directly or inferred from user input to the system. Users might, for example, state that cost for feature i is greater than the cost for feature j . One may also infer user costs by retaining information about user preferences, such as which screen icon was clicked-on first. By averaging these preferences and ordering over time, the preference ordering of the user may be inferred. 8. Measuring ordering performance
To study the effectiveness of browsing and retrieval when using ordering, consistent with the Gray code, it is desirable to be able to evaluate the ordering in a repeatable and objective manner. One method of eval-uating browsing is to study Average Browsing Distance (ABD), the average distance from one relevant item to the next relevant item going in one direction on the browsing path. If we assume that the person is ratio-nally moving in an optimal fashion on the shortest path, the ABD is computed from the length of the browsing path minus the longest gap between relevant items. If we can imagine the 4 letters C, O, K, and E on a single logo on a can or bottle of soda and the distance between the letters, we are ignoring the longest distance, which is probably from the E, around the back of the bottle or can, to the C. This is much longer than the other inter-letter distances between C and O, between O and K, and between K and E. ABD is thus the entire length of the browsing path minus the longest distance between relevant items on the path, divided by one less than the number of items on the path.

One can also examine the dissimilarity between adjacent documents using the techniques for computing expected dissimilarity described earlier. The Average Dissimilarity (AD) represents the average of the dis-similarity between pairs of factual representations around the entire browsing path, with the dissimilarity measured as the Hamming distance. Smaller average dissimilarities indicate that adjacent documents are more alike, providing better browsing performance.

Related to this, we have the Average Information Dissimilarity (AID) which represents the average information difference between adjacent documents, computed over the set of documents. The Average
Cost of Dissimilarity (ACD) represents the average economic value associated with the differences between adjacent documents, computed over the set of documents. 9. An example
Integrating data may be best understood by considering an example showing both structured and non-structured data. The numeric results have been produced from software developed in Mathematica which has the ordering capabilities for the probabilistic, information theoretic, and economic models de-scribed in the paper. While the data is stored in the Mathematica program, data could be stored in
XML format ( Blanken et al., 2003 ) as it is in the author  X  s Nyltiac system ( http://Nyltiac.com or http://ils. unc.edu/nyltiac ), that allows Gray code based browsing for a variety of uses, such as retrieval, digital libraries, and question answering.

In Table 2 we provide some sample structured data containing two relations. The first has persons  X  names, their cats  X  names, and the number of years owner and pet have been together. There is also a second relation containing the cats  X  names and their favorite foods. Table 3 show the same data placed into the form for factual representations, as discussed above. The metadata are shown within parentheses. The metadata for the union ( M U ) is not shown but is simply the union of M
The feature vector being used here contains the following features: owner, author, textblob (binary large object), name, person, cat, yearstogether, favoritefood, and SBN (standard book number). The features author and textblob are used for a following example, and are included here to provide compatibility across examples so that we can merge structured and unstructured data below.
 We may add some unstructured data by including the data in Table 4 into the data produced from Table 2 .

The browsing performance may be computed using this data and the measures described earlier. The probabilities for features are used to order the features for placement in the feature vector, which becomes (with associated probabilities): name (0.625), cat (0.53125), person (0.4375), owner (0.34375), sbn (0.125), yearstogether (0.09375), favoritefood (0.09375), textblob (0.0625), and author (0.0625). When ordering features by their probability, the Average Browsing Distance, ABD, is 1 and the Average
Dissimilarity, AD, is 1.125 when the variables are placed in descending order of probability. When the order of features is changed to ascending, the performance drops so that the ABD is 1.07 and the AD is 1.375. In this situation, ordering features in descending order of probability (from left to right) is superior to ordering features in ascending order of probability, supporting the arguments above.
 When using the information theoretic model suggested above, features may be ordered consistent with
Eq. (1) so as to improve performance. The ABD is 1 and the Average Information Dissimilarity, AID, is 0.748 bits when features are ordered consistent with the information theoretic ordering principle suggested above. When the features are placed in ascending order, performance drops and we find an ABD of 1.07 and an AID of 0.988 bits.

Costs were arbitrarily assigned to the features so that author was assigned a cost of 10 and all other fea-tures were assigned a value of 1. We find that the ABD is 1 when the features are ordered in terms of descending weight and 1.29 when placed in ascending order. The Average Cost of Dissimilarity, ACD, is 2.25 when features are in descending order and an ACD of 2.625 when in ascending order.

In all the cases above, we have found that ordering features based on the principles suggested earlier results in superior organization; placing features in descending order of the appropriate weight produces better browsing. 10. The adaptive display of data
What information should be displayed on a screen? Clearly, the information most likely to be relevant to a user should be displayed, whether the data are facts, images, or movies. By accepting positive or negative user preferences about specific data items, e.g. Tigger from Table 2 , or preferences about metadata items, e.g., a greater interest in favorite pet foods than in the number of years a pet and owner have been together, systems may adapt their output to present those items most likely to be of interest to an individual user or group of users.

Which material would be preferred by a given user may be inferred from economic feedback, such as that gathered for the purposes above. Using this, specific fields may be seen as being of greater or lesser benefit to the user. If we assume that metadata items are statistically independent of each other, it is rea-sonable to use economic information about the benefit or cost of each individual metadata item to estimate the relative benefit of an attribute with a specific set of metadata characterizing the attribute. Similarly, changes in databases may provide information theoretic feedback to update collection statistics and feature ordering.

Displays may be viewed as m by n elastic tables. The tables may be generated dynamically, with factual representations being placed appropriately in adjacent rows or columns. Larger images and textual units may be displayed in a thumbnail form or by using a surrogate, with a  X  X  X lick X  X  on the thumbnail or surrogate producing the full object. The table may be resized based on expressed user preferences, as well as the sys-tem  X  s estimate of those preferences.

The system needs to choose either the best n columns for display or choose the single best column as the center column, with those columns placed next to the center column being those that are the successors and predecessors (in the Gray code enumeration) of the best column, or some combination of these two meth-ods. Columns chosen for display may be those with metadata having the highest economic benefit, or those that have the highest probability of being used by the individual or by members of a group to which the individual belongs (an organization). For example, the ordering with the displayed columns shown between the vertical bars, might be changed to when E is assigned a different location in the second, preference-based ordering because of user feedback, effectively changing what is shown in the display window as E is removed (from this display), with D and F becoming adjacent and E shifting to the left between A and B . By arranging columns consistent with the
Gray code based ordering, related information may be displayed, both information specifically requested by users as well as information related to a request, as determined by Gray code ordering ( Losee, 2003 ).
Rows chosen for display may be those that the user has indicated to be of relevance because at this point, person , are of interest. Several factual representations may be joined and placed onto a single line for dis-play; those items whose placement in the table is consistent with the Gray code ordering should be inserted into the table.

Through the ordering of rows and columns for display, a table may be generated from those rows and columns with the highest usability values, along with other related columns. Further research will be needed to determine the exact nature of user preferences for adaptive displays. While the focus of this work is on what we have referred to as an elastic table, users may prefer to have a single fact from a table displayed, joining other related facts from other tables for display, rather than those facts that are most similar. 11. Summary and conclusions
Placing factual representations into an order consistent with the Gray code and model-determined fea-ture ordering enables us to organize data for browsing. This order decreases the amount of browsing nec-essary to examine a given amount of information from that consistent with random feature ordering. By using factual representations, structured, semi-structured, and unstructured data can be browsed or dis-played together. This technique also allows for the integration of various kinds of solely structured data or solely unstructured data, enabling a number of different tuples to be integrated into a single conceptual linear ordering of all tuples.

Features used in a system which orders factual representations consistent with the Gray code may be placed into different orders. Different criteria for ordering features have been suggested, including proba-bilistic, information theoretic, and economic. Empirical evidence has been derived from the ordering of the sample data provided in Tables 2 and 3 . We were able to show that, when using this data, and for the eco-nomic and information theoretic models, placing features in descending order of their weights, as suggested by the arguments earlier, produces the best Average Browsing Distance, ABD, the Average Dissimilarity, AD, the Average Information Dissimilarity, AID, and the Average Cost of Dissimilarity, ACD, values. Acknowledgement The author wishes to acknowledge the useful, constructive comments of an anonymous referee. References
