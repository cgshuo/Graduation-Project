 Byron Boots bboots@cs.washington.edu Geo  X  rey J. Gordon ggordon@cs.cmu.edu In range-only SLAM, we are given a sequence of range measurements from a robot to fixed landmarks with known correspondences, and possibly a matching se-quence of odometry measurements. We then attempt to simultaneously estimate the robot X  X  trajectory and the locations of the landmarks. Popular approaches to range-only SLAM include EKFs and EIFs ( Kantor &amp; Singh , 2002 ; Kurth et al. , 2003 ; Djugash &amp; Singh , 2008 ; Djugash , 2010 ; Thrun et al. , 2005 ), multiple-hypothesis trackers (including particle filters and mul-tiple EKFs/EIFs) ( Djugash et al. , 2005 ; Thrun et al. , 2005 ), and batch optimization of a likelihood func-tion ( Kehagias et al. , 2006 ).
 In all the above approaches, the most popular repre-sentation for a hypothesis is a list of landmark loca-tions ( m n,x ,m n,y ) and a list of robot poses ( x t ,y Unfortunately, both the motion and measurement models are highly nonlinear in this representation, leading to computational problems: inaccurate lin-earizations in EKF/EIF/MHT and local optima in batch optimization approaches. Much work has at-tempted to remedy this problem, e.g., by changing the hypothesis representation ( Djugash , 2010 ) or by keep-ing multiple hypotheses ( Djugash et al. , 2005 ; Dju-gash , 2010 ; Thrun et al. , 2005 ). While considerable progress has been made, none of these methods are ideal; common di culties include the need for an ex-tensive initialization phase, inability to recover from poor initialization, lack of performance guarantees, or excessive computational requirements.
 We take a very di  X  erent approach: we formulate range-only SLAM as a matrix factorization problem, where features of observations are linearly related to a 4-or 7-dimensional state space. This approach has several desirable properties. First, we need weaker assump-tions about the measurement model and motion model than previous approaches to SLAM. Second, our state space yields a linear measurement model, so we lose less information during tracking to approximation er-rors and local optima. Third, our formulation leads to a simple spectral learning algorithm, based on a fast and robust singular value decomposition (SVD) X  X n fact, our algorithm is an instance of a general spectral system identification framework, from which it inherits desirable guarantees including statistical consistency and no local optima. Fourth, we don X  X  need to worry as much as previous methods about errors such as a consistent bias in odometry, or a receiver mounted at a di  X  erent height from the transmitters: in general, we can learn to correct such errors automatically by expanding the dimensionality of our state space. As we will discuss in Section 2 , our approach to SLAM has much in common with spectral algorithms for sub-space identification ( Van Overschee &amp; De Moor , 1996 ; Boots et al. , 2010 ); unlike these methods, our focus on SLAM makes it easy to interpret our state space. Our approach is also related to factorization-based struc-ture from motion ( Tomasi &amp; Kanade , 1992 ; Triggs , 1996 ; Kanade &amp; Morris , 1998 ), as well as to recent dimensionality-reduction-based methods for localiza-tion and mapping ( Biggs et al. , 2005 ; Ferris et al. , 2007 ; Yairi , 2007 ). Unlike the latter approaches, which are generally nonlinear, we only require linear dimen-sionality reduction. Finally, the simplest version of our method (Sec. 3.1 ) is related to multidimensional scaling (MDS). In MDS, there is no distinction be-tween landmark positions and robot positions: we have all-to-all range measurements for a set of landmarks, and must recover an embedding of the landmarks. Our smaller set of measurements introduces additional challenges, and forces changes compared to MDS. There are three main pieces of relevant background: first, the well-known solutions to range-only SLAM us-ing variations of the extended Kalman filter and batch optimization; second, recently-discovered spectral ap-proaches to identifying parameters of nonlinear dy-namical systems; and third, matrix factorization for finding structure from motion in video. Below, we will discuss the connections between these areas, and show how they can be unified within a spectral learn-ing framework. 2.1. Likelihood-based Range-only SLAM The standard probabilistic model for range-only lo-calization ( Kantor &amp; Singh , 2002 ; Kurth et al. , 2003 ) represents robot state by a vector s t =[ x t ,y t ,  X  t ] robot X  X  (nonlinear) motion and observation models are Here v t is the distance traveled, ! t is the orientation change, d t,n is the estimate of the range from the n th landmark location ( m n,x ,m n,y ) to the current location of the robot ( x t ,y t ), and  X  t and  X  t are noise. (Through-out this paper we assume known correspondences, since range sensing systems such as radio beacons typically associate unique identifiers with each read-ing.) To handle SLAM rather than just localization, we extend the state to include landmark positions: where N is the number of landmarks. The motion and measurement models remain the same. Given this model, we can use any standard optimization al-gorithm (such as Gauss-Newton) to fit the unknown robot and landmark parameters by maximum likeli-hood. Or, we can track these parameters online using EKFs, EIFs, or MHT methods like particle filters. EKFs and EIFs are a popular solution for localiza-tion and mapping problems: for each new odometry input a t =[ v t , ! t ] T and each new measurement d t ,we propagate the estimate of the robot state and error co-variance by linearizing the non-linear motion and mea-surement models. Unfortunately, though, range-only SLAM is notoriously di cult for EKFs/EIFs: since range-only sensors are not informative enough to com-pletely localize a robot or a landmark from a small number of readings, nonlinearities are much worse in range-only SLAM than they are in other applications such as range-and-bearing SLAM. In particular, if we don X  X  have a sharp prior distribution for landmark po-sitions, then after a few steps, the exact posterior be-comes highly non-Gaussian and multimodal; so, any Gaussian approximation to the posterior is necessarily inaccurate. Furthermore, an EKF will generally not even produce the best possible Gaussian approxima-tion: a good linearization would tell us a lot about the modes of the posterior, which would be equiva-lent to solving the original SLAM problem. So, prac-tical applications of the EKF to range-only SLAM attempt to delay linearization until enough informa-tion is available, e.g., via an extended initialization phase for each landmark. Finally, Djugash et al. pro-posed a polar parameterization to more accurately rep-resent the annular and multimodal distributions typ-ically encountered in range-only SLAM. The result-ing approach is called the ROP-EKF, and is shown to outperform the ordinary (Cartesian) EKF in several real-world problems, especially in combination with multiple-hypothesis tracking ( Djugash &amp; Singh , 2008 ; Djugash , 2010 ). However, the multi-hypothesis ROP-EKF can be much more expensive than an EKF, and is still a heuristic approximation to the true posterior. 2.2. Spectral System Identification System identification algorithms attempt to learn dy-namical system parameters such as a state space, a dynamics model (motion model), and an observation model (measurement model) directly from samples of observations and actions. In the last few years, spec-tral system identification algorithms have become pop-ular; these algorithms learn a state space via a spec-tral decomposition of a carefully designed matrix of observable features, then find transition and observa-tion models by linear regressions involving the learned states. Originally, subspace identification algorithms were almost exclusively used for linear system iden-tification ( Van Overschee &amp; De Moor , 1996 ), but re-cently, similar spectral algorithms have been used to learn models of partially observable nonlinear dynam-ical systems such as HMMs ( Hsu et al. , 2009 ; Siddiqi et al. , 2010 ) and PSRs ( Rosencrantz et al. , 2004 ; Boots et al. , 2010 ; Boots &amp; Gordon , 2010 ; Boots et al. , 2011 ). This is a powerful and appealing approach: the result-ing algorithms are statistically consistent ,unlikethe popular expectation maximization (EM) algorithm, and they are easy to implement with e cient linear algebra operations. As we will see in Section 3 ,we can view the range-only SLAM problem as an instance of spectral state space discovery. And, the Appendix (Sec. C ) discusses how to identify transition and mea-surement models given the learned states. The same properties that make spectral methods appealing for system identification carry over to our spectral SLAM algorithm: computational e ciency, statistical consis-tency, and finite-sample error bounds. 2.3. Orthographic Structure From Motion In some ways the orthographic structure from motion (SfM) problem in vision ( Tomasi &amp; Kanade , 1992 )is very similar to the SLAM problem: the goal is to re-cover scene geometry and camera rotations from a se-quence of images (compare with landmark geometry and robot poses from a sequence of range observa-tions). And in fact, one popular solution for SfM is very similar to the state space discovery step in spec-tral state space identification. The key idea in spectral SfM is that is that an image sequence can be repre-sented as a 2 F  X  P measurement matrix W , contain-ing the horizontal and vertical coordinates of P points tracked through F frames. If the images are the result of an orthographic camera projection, then it is possi-ble to show that rank( W ) = 3. As a consequence, the measurement matrix can be factored into the prod-uct of two matrices U and V ,where U contains the 3d positions of the features and V contains the cam-era axis rotations ( Tomasi &amp; Kanade , 1992 ). With respect to system identification, it is possible to in-terpret the matrix U as an observation model and V as an estimate of the system state. Inspired by SfM, we reformulate range-only SLAM problem in a similar way in Section 3 , and then similarly solve the problem with a spectral learning algorithm. We start with SLAM from range data without odome-try. For now, we assume no noise, no missing data, and batch processing. We will generalize below: Sec. 3.2 discusses how to recover robot orientation, Sec. 3.3 dis-cusses noise, and Sec. 3.4 discusses missing data and online SLAM. In the Appendix (Section C )wediscuss learning motion and measurement models. 3.1. Range-only SLAM as Matrix Consider the matrix Y 2 R N  X  T of squared ranges, with N 4 landmarks and T 4timesteps: where d n,t is the measured distance from the robot to landmark n at time step t . The most basic version of our spectral SLAM method relies on the insight that Y factors according to robot position ( x t ,y t ) and land-mark position ( m n,x ,m n,y ). To see why, note d If we write C n =[( m 2 n,x + m 2 n,y ) / 2 ,m n,x ,m n,y X d C 2 R N  X  4 contains the positions of landmarks, and X 2 R 4  X  T contains the positions of the robot over time: If we can recover C and X , we can read o  X  the solu-tion to the SLAM problem. The fact that Y  X  X  rank is only 4 suggests that we might be able to use a rank-revealing factorization of Y , such as the singular value decomposition, to find C and X . Unfortunately, such a factorization only determines C and X up to a linear transform: given an invertible matrix S , we can write Y = CX = CS 1 SX . Therefore, factorization can only hope to recover U = CS 1 and V = SX .
 To upgrade the factors U and V to a full metric map, we have two options. If global position estimates are available for at least four landmarks, we can learn the transform S via linear regression, and so recover the original C and X . This method works as long as we know at least four landmark positions. Figure 1 A shows a simulated example.
 On the other hand, if no global positions are known, the best we can hope to do is recover landmark and robot positions up to an orthogonal transform (trans-lation, rotation, and reflection). It turns out that Eq. ( 7 ) provides enough additional geometric con-straints to do so: in the Appendix (Sec. A )weshow that, if we have 8 time steps and 8 landmarks, we can compute the metric upgrade in closed form. The idea is to fit a quadratic surface to the rows of U , then change coordinates so that the surface becomes the function in ( 7 ). (By contrast, the usual metric up-grade for orthographic structure from motion ( Tomasi &amp; Kanade , 1992 ), which uses the constraint that cam-era projection matrices are orthogonal, requires a non-linear optimization.) 3.2. SLAM with Headings In addition to location, we often want the robot X  X  global heading  X  . We could get headings by post-processing our learned positions; but in practice we can reduce variance by learning positions and head-ings simultaneously. We do so by adding more fea-tures to our measurement matrix: di  X  erences between successive pairs of squared distances, scaled by veloc-ity (which we can estimate from odometry). Since we need pairs of time steps, we now have Y 2 R 2 N  X  T 1 : As before, we can factor Y into a state matrix and a landmark matrix. The key observation is that we can write the new features in terms of cos(  X  ) and sin(  X  ): d From Eq. 5 and Eq. 9 it is easy to see that Y is rank 7: we have Y = CX ,where C 2 R N  X  7 contains func-tions of landmark positions and X 2 R 7  X  T contains functions of robot state, As with the basic SLAM algorithm in Section 3.1 ,we can factor Y using SVD, this time keeping 7 singular values. Then we can do a metric upgrade as before to get robot positions (see Appendix, Sec. A for details); finally we can recover headings as angles between suc-cessive positions. 3.3. A Spectral SLAM Algorithm The matrix factorizations of Secs. 3.1 and 3.2 suggest a straightforward SLAM algorithm, Alg. 1 : build an Algorithm 1 Spectral SLAM In : i.i.d. pairs of observations { o t ,a t } T t =1 ; optional: measurement model for 4 landmarks C 1:4 Out : measurement model (map) b C , robot locations b X (the t th column is location at time t ) 1: Collect observations and odometry into a matrix 2: Find the the top 7 singular values and vectors: 3: Find the transformed measurement matrix empirical estimate b Y of Y by sampling observations as the robot traverses its environment, then apply a rank k = 7 thin SVD, discarding the remaining singular values to suppress noise. Following Section 3.2 , the left singular vectors b U are an estimate of our transformed measurement matrix CS 1 , and the weighted right singular vectors b  X  b V &gt; are an estimate of our transformed robot state SX . We can then perform metric upgrade as before. Statistical Consistency and Sample Complex-ity Let M 2 R N  X  N be the true observation covari-ance for a randomly sampled robot position, and let c M = 1 T b Y b Y &gt; be the empirical covariance estimated from T observations. Then the true and estimated measurement models are the top singular vectors of M and c M . Assuming that the noise in c M is zero-mean, as we include more data in our averages, we will show below that the law of large numbers guarantees that c M converges to the true covariance M . That is, our learning algorithm is consistent . (The estimated robot positions will typically not converge, since we typi-cally have a bounded e  X  ective number of observations relevant to each robot position. But, as we see each landmark again and again, the robot position errors will average out, and we will recover the true map.) In more detail, we can give finite-sample bounds on the error in recovering the true factors. For simplicity of presentation we assume that noise is i.i.d., although our algorithm will work for any zero-mean noise pro-cess with a finite mixing time. (The error bounds will of course become weaker in proportion to mixing time, since we gain less new information per observa-tion.) The argument (see the Appendix, Sec. B , for de-tails) has two pieces: standard concentration bounds show that each element of our estimated covariance approaches its population value; then the continuity of the SVD shows that the learned subspace also ap-proaches its true value. The final bound is: where is the vector of canonical angles between the learned subspace and the true one, c is a constant de-pending on our error distribution, and is the true smallest nonzero eigenvalue of the covariance. In par-ticular, this bound means that the sample complexity is  X 
O (  X  2 ) to achieve error  X  . 3.4. Extensions Missing data So far we have assumed that we re-ceive range readings to all landmarks at each time step. In practice this assumption is rarely satisfied: we may receive range readings asynchronously, some range readings may be missing entirely, and it is often the case that odometry data is sampled faster than range readings. Here we outline two methods for over-coming this practical di culty.
 First, if a relatively small number of observations are missing, we can use standard approaches for factor-ization with missing data. For example, probabilistic PCA ( Tipping &amp; Bishop , 1999 ) estimates the miss-ing entries via the EM algorithm, and matrix comple-tion ( Cand`es &amp; Plan , 2009 ) uses a trace-norm penalty to recover a low-rank factorization with high probabil-ity. However, for range-only data, often the fraction of missing data is high and the missing values are struc-tural rather than random.
 The second approach is interpolation: we divide the data into overlapping subsets and then use local odom-etry information to interpolate the range data within each subset. To interpolate the data, we estimate a robot path by dead reckoning. For each point in the dead reckoning path we build the feature representa-tion [1 , x, y, ( x 2 + y 2 ) / 2] &gt; . We then learn a linear model that predicts a squared range reading from these features (for the data points where range is available), as in Eq. 5 . Next we predict the squared range along the entire path. Finally we build the matrix b Y by av-eraging the locally interpolated range readings. This linear approach works much better in practice than the fully probabilistic approaches mentioned above, and was used in our experiments in Section 4 .
 Online Spectral SLAM The algorithms developed in this section so far have had an important drawback: unlike many SLAM algorithms, they are batch meth-ods not online ones. The extension to online SLAM is straightforward: instead of first estimating b Y and then performing a SVD, we sequentially estimate our et al. , 2011 ).
 Robot Filtering and System Identification So far, our algorithms have not directly used (or needed) a robot motion model in the learned state space. How-ever, an explicit motion model is required if we want to predict future sensor readings or plan a course of action. We have two choices: we can derive a motion model from our learned transformation S between la-tent states and physical locations, or we can learn a motion model directly from data using spectral sys-tem identification. More details about both of these approaches can be found in the Appendix, Sec. C . We perform several SLAM and robot navigation exper-iments to illustrate and test the ideas proposed in this paper. For synthetic experiments that illustrate con-vergence and show how our methods work in theory, see Fig. 1 . We also demonstrate our algorithm on data collected from a real-world robotic system with sub-stantial amounts of missing data. Experiments were performed in Matlab, on a 2.66 GHz Intel Core i7 com-puter with 8 GB of RAM. In contrast to batch non-linear optimization approaches to SLAM, the spectral learning methods described in this paper are very fast, usually taking less than a second to run.
 We used two freely available range-only SLAM bench-mark data sets collected from an autonomous lawn mowing robot ( Djugash , 2010 ), shown in Fig. 2 A. 1 These  X  X laza X  datasets were collected via radio nodes from Multispectral Solutions that use time-of-flight of ultra-wide-band signals to provide inter-node ranging measurements and the unique ID of the radio nodes. (Additional details can be found in ( Djugash , 2010 ).) In  X  X laza 1, X  the robot travelled 1.9km, occupied 9,658 distinct poses, and received 3,529 range measurements. The path taken is a typical lawn mowing pattern that balances left turns with an equal number of right turns; this type of pattern minimizes the e  X  ect of heading er-ror. In  X  X laza 2, X  the robot travelled 1.3km, occupied 4,091 poses, and received 1,816 range measurements. The path taken is a loop which amplifies the e  X  ect of heading error. The two data sets were both very sparse, with approximately 11 time steps (and up to 500 steps) between range readings for the worst land-mark. We first interpolated the missing range readings with the method of Section 3.4 . Then we applied the rank-7 spectral SLAM algorithm of Section 3.3 ;the results are depicted in Figure 2 B-C. Qualitatively, we see that the robot X  X  localization path conforms to the true path.
 In addition to the qualitative results, we quantita-tively compared spectral SLAM to a number of dif-ferent competing range-only SLAM algorithms which have been used on the benchmark data sets. The lo-calization root mean squared error (RMSE) in meters for each algorithm is shown in Figure 3 . The baseline is dead reckoning (using only the robot X  X  odometry information). Next are several standard online range-only SLAM algorithms, including the Cartesian EKF, FastSLAM ( Montemerlo et al. , 2002 ) with 5,000 parti-cles, and the ROP-EKF algorithm ( Djugash &amp; Singh , 2008 ), which achieved the best prior results on the benchmark datasets. These previous results only re-ported the RMSE for the last 10% of the path, which is the best 10% of the path (since it gives the most time to recover from initialization problems). The full path localization error can be considerably worse, par-ticularly for the initial portion of the path X  X ee Fig. 5 (right) of ( Djugash &amp; Singh , 2008 ).
 We also compared to batch nonlinear optimization, via the quasi-Newton BFGS method as implemented in Matlab X  X  fminunc (see ( Kehagias et al. , 2006 ) for details). 2 This approach to solving the range-only SLAM problem can be very data e cient, but is sub-ject to local optima and is computationally intensive. We followed the suggestions of ( Kehagias et al. , 2006 ) and initialized with the dead-reckoning estimate of the robot X  X  path. For Plaza 1 and Plaza 2, the algorithm took roughly 2.5 hours and 45 minutes to converge respectively.
 Finally, we ran our spectral SLAM algorithm on the same data sets. In contrast to BFGS, spectral SLAM is statistically consistent , and much faster: the bulk of the computation is the fixed-rank SVD, so the time complexity of the algorithm is O ((2 N ) 2 T )where N is the number of landmarks and T is the number of time steps. Empirically, spectral SLAM produced re-sults that were comparable to batch optimization in 3-4 orders of magnitude less time (see Figure 3 ). Spectral SLAM can also be used as an initializa-tion procedure for nonlinear batch optimization. This strategy combines the best of both algorithms by al-lowing the locally optimal nonlinear optimization pro-cedure to start from a theoretically guaranteed good starting point. Therefore, the local optimum found by nonlinear batch optimization should be no worse than the spectral SLAM solution and likely much better than the batch optimization seeded by dead-reckoning. Empirically, we found this to be the case (Figure 3 ). If time and computational resources are scarce, then we believe that spectral SLAM is clearly the best ap-proach; if computation is not an issue, the best results will likely be found by refining the spectral SLAM so-lution using a nonlinear batch optimization procedure. We proposed a novel solution for the range-only SLAM problem that di  X  ers substantially from previous ap-proaches. The essence of this new approach is to for-mulate SLAM as a factorization problem, which allows us to derive a local-minimum free spectral learning al-gorithm that is closely related to SfM and recent spec-tral methods for system identification. Additionally, we discuss how to contend with missing data and how to derive an online algorithm. We are able to prove statistical consistency and sample complexity bounds for our algorithm, while getting competitive error in practice compared to methods like full batch optimiza-tion of the likelihood on several benchmark data sets. Finally, we show that our algorithm is fast : we analyze the time complexity and demonstrate empirically that our algorithm can be orders of magnitude faster than competing nonlinear batch optimization procedures. Acknowledgements Byron Boots and Geo  X  rey J. Gordon were supported by ONR MURI grant N00014-09-1-1052. Byron Boots was supported by NSF grant EEEC-0540865.
 Method Plaza 1 Plaza 2 Dead Reckoning (full path) 15.92m 27.28m Cartesian EKF (last, best 10%) 0.94m 0.92m FastSLAM (last, best 10%) 0.73m 1.14m ROP EKF (last, best 10%) 0.65m 0.87m Batch Opt. (worst 10%) 1.04m 0.45m Batch Opt. (last 10%) 1.01m 0.45m Batch Opt. (best 10%) 0.56m 0.20m Batch Opt. (full path) 0.79m 0.33m Spectral SLAM (worst 10%) 1.01m 0.51m Spectral SLAM (last 10%) 0.98m 0.51m Spectral SLAM (best 10%) 0.59m 0.22m Spectral SLAM (full path) 0.79m 0.35m Spectral + Batch Optimization (worst 10%) 0.89m 0.40m Spectral + Batch Optimization (last 10%) 0.81m 0.32m Spectral + Batch Optimization (best 10%) 0.54m 0.18m
