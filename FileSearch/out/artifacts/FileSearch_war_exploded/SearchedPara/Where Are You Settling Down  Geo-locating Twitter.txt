 system to push better local advertising, highlight points of interest, show local news, gines understand users X  search intentions better. In this paper we build textual models geographic coordinates in the profile. 
Living in close geographical proximity may enable people to share common cha-live in close geographic proximity. 
In this paper, we propose hybrid probabilistic models combining textual models with social network models to estimate a user X  X  location, and propose two local word filters. In the social networks model, we also consider the 2-hop of a use following X  X  nally we predict a user X  X  location using a hybrid probabilistic model by combining the two dimensions. 
The remainder of this paper is organized as follows: In Section 2, we review related experiments and estimation metrics in the paper. We introduce our models as well as present the experimental results in Section 5. Finally, conclusions and future work are discussed in Section 6. serves and hears in a local place. Lee et al. [18] proposed a geo-social event detection method to monitor the geographical regularities of local crowd behavior. Yardi et al. zens. Vieweg et al. [19] and Lee et al. [12] both discussed event broadcasting by local people. places with category tags. Lin et al. [9] investigated the factors that influence people people X  X  daily and weekly patterns, urban neighborhood conditions, and recurrent transitions between different activities. photographs originated using user tags and image-textual content. Popescu et al. [16] photos. 
The aspects of geo-location users using tweet content in Twitter posts have become proposed a probabilistic framework for estimating a Twitter user X  X  city-level location based purely on the content of the user X  X  tweets. Hecht et al. studied user behavior in learning techniques to guess users X  locations on the country and state levels. Kinsella et al. [5] created language models of locations using coordinates extracted from geo-tagged tweets and model locations on varying levels of granularity from ZIP code to country level to geo-locate user and single tweets. 
Backstrom et al. [3] used the social network structure of Facebook to predict loca-tion. Scellato et al. [7] described a supervised learning framework which exploits two friends-of-friends and place-friends. Li et al . [11] and Kwak et al. [2] studied the geo-graphic features in Twitter. 3.1 Textual Model The textual model is a probabilistic estimator based on a user X  X  tweets to estimate the location where the user settles down. Typically, the tweets posted by the user contain a great quantity of irrelevant information for location prediction. We next describe our local words filter algorithm and smoothing method. 
Local Words Filter Algorithm. In Twitter, many words which appear in tweets provide very little power at distinguishing the location of a user, this even provides a words in their tweets because of the small population of the registered Twitter users or the small number of people updated their status in these locations. In order to im-prove the estimation accuracy, we must identify these local words in tweets and over-come the tweets X  scarcity. Afterward, we are committed to the local words X  identifica-tion and, at the same time, to overcome the data sparseness. 
Before using a filter algorithm to identify local words, we preprocessed the content of the tweets. First, we eliminated the repeat tweets by string matching since we ob-tweet using the regular expression, eliminated all occurrences of a standard list of 429 stop words, as well as screen names which start with @ and single-letter words. Final-ly, we excluded punctuation in the tweets using Lucene Tool 1 and stemmed the word using Snowball 2 . By calculating word frequency, we only considered words that occur base set of 521,103 distinct words. 
Inverse Location Frequency: The first filter algorithm is the Inverse Location Fre-collection of locations. The more locations that a word occurs in, the less discriminat-ing the word is between locations, and consequently, the less useful it will be in loca-tion estimation. The form of ILF filter is defined as follow: application of the ILF filter, 19,424 local words were left from 46,369 words. 
We used the Remote Words filter, which we called the RW filter, to filter out these remote words. In RW, we calculated the average distance of a location with all other threshold in a specific iteration. When the average distance of all locations is less than NER. The formula of average distance is calculated as follows: Named Entity Recognition. We processed each tweet, applying NER and location-entity disambiguation to identify the relate d locations for the fo cus location. For each tweet, we exploited the named entity recogni zer [21] to extract a location entity men-latitude and longitude; it was then calculated for the distance of location of the entity 40 miles of the focus location. There were 10229 entities being recognized, and after veal in their profiles are place names, we put the words in location entities. Textual Model Estimator. We used the Maximum Likelihood Estimation to geo-locate the users where they are settling down. Given the set of words U w and location being located in city l i as: other group parameters,  X  and  X  , are the weight for which the portion is more impor-location number where the word w occurs, count i ( w ) donates the count of word w in Circular-Based Neighborhood Smoothing. There is a problem in that some loca-of user location estimation. Circular-based neighborhood smoothing considers all geographic neighbors from which the distance is 40 miles to the centre of a location. The circular probability of a word w can be formalized as: replaced with p ( r i | w ). 3.2 Social Network Model training data) to estimate the location where he/she settles down. We can write down the likelihood of a particular location l i as: N users in location l i of user u X  X  followers and followings. 
Generally, users do not add friendship connections at random with all other users, but, instead, they tend to prefer other users who are  X  X lose" to them in social network. For instance, many links do appear between in dividuals at closer social distance from new ties [7][22]. In Twitter, this phenomenon may be weaker, but it still can be con-followers. We take into account this portion based on an assumption that the fewer of ship between them, the greater the contributi on to the prediction. The formula of the likelihood is represented as follows: also considered the follower X  X  social networks and the following X  X  followings, but the result is lower. 3.3 Hybrid Model We proposed a hybrid probabilistic model of combining a textual model with a social normalized the resulting values of the two models into values in the range [0, 1]. | U ) respectively for all the estimated locations. Then the hybrid probabilistic is where  X  is the balancing coefficient in the range [0, 1]. 4.1 Data Collection Twitter offers an open API that is easy to crawl and collect data. However, we used Twitter. The commonality of the CHENG and KWAK is that they have the same user training set contains 115,886 Twitter users and 3,844,612 updates from the users. All the locations of the users are self-labeled in United States. The test set contains 5,136 Twitter users with over 1000 tweets each of user and the total updates are 5,156, 047 from these users. All the locations of users are uploaded from their smart phones with the form of "UT: Latitude, Longitude"[1]. The data of KWAK contain social graphs, 10,000 followers) which are collected from July 6th 2009 to July 31th 2009 in Twit-billion social relations (still calling social graphs KWAK). 4.2 Metrics of Evaluation The other metric is Accuracy which considers the percentage of users with their error when x is equal to 100 as mentioned in [1] and [10]; when x is equal to 25, it is town distance to the actual location which the ErrDist(u) is lower x . 4.3 Estimation Methods 1. ILF filter (ILF).We estimated the location of users using the ILF filter to filter the local words in the training set. 2. RW combines with ILF (RW+ILF). An approach that combined the remote word filter with the ILF to select local words in the training set to predict user location. location in social networks using the content. 4. Named Entity Recognition augments the two filters (NER+Fs). In this method, we identified the locations from the training set as local words and merged the two lo-cal word filters aforementioned. ing to estimate user location in Twitter before the local words filter. 5. Social network predict (SN). For each user , locations were ranked according to the probability that most of their friends are settling down. 6. 2-hop social network (2-hop). We estimated user location using his/her followings X  followers and his/her friends. 7. Hybrid estimation (Hybrid_SN, Hybrid_2-hop). Predicting the user X  X  locations used hybrid models combining the two dimensions of textual and social networks. 4.4 Geo-locating on the City Level users in the test set within 100 miles of their actual locations and that the AvgErrDist traditional location prediction method of NER also is treated as baseline. 
First, when we did not use the local word filters, our system only estimated about 8% of 5119 users in their actual locations corresponding to 10% of Cheng X  X  baseline. word filter ILF alone, we reached an Accuracy of 0.437 which is more than five times as high as the Accuracy without using the local word filter. The filter removed noise because the local words, filtered through IL F, were removed from the local focus. The which is lower than the 535-mile baseline. The result also outperforms the baseline of reached 0.5098 which is almost identical wi th the baseline of 0.510. Meanwhile, the mated error was significantly lower, and the ACC@2, which at most having one loca-tion was correct in the first two locations, is 0.635, exceeding the baseline of 0.624. users can be geo-located within 100 miles of their actual locations (we do not count However, we did not compare the SN model and 2-hop model with other models, for followings (whose followers is less than 300) simultaneously and, in the 2-hop model, the user whose followers and followings are more than five are 1421. We still found that the power of using one X  X  social network to estimate the actual locations is strong; to some extent, its ability has exceeded the st andard model, purely based on content to predict the user actual location. 
Now, let us look at the predictive power of the hybrid model in Table 1. In hybrid zero (the Accuracy is about 42% of removing the users whose at least first two esti-mated locations X  score are the same) and set  X  =0.501 based on measures when com-bined with the model of NER_Fs. We also observe the positive impact of combining merged with a textual model result in better user-location estimations than only using one dimension. By observing Table 1, we found that the best Accuracy achieved 0.566, which means placing 56.6% of users within 100 miles of their actual location, with an AvgErrDist of all users of 442 miles. If the first two locations are considered, 68.3% of 5119 users can predict actual locations. 4.5 Geo-locating on the Town Level Kinsella et al. [5] considered the users X  se lf-reported location which is extracted from their profiles and tweets using the Yahoo! Placemaker estimated user location on the town level. We treated it, which the Accuracy is 0.362, as our baseline on town-level predicting accuracy outperform the baseline and NER method. The combining of two location entities have a negative impact on town-level location predictions. The result of estimating user actual location, in which the Accuracy reaches 50.1% of 760 users using the user X  X  followers and following of more than five respectively, is encourag-ing. It also shown that the hybrid model provided attractive results that 45.2% of 5119 users could be estimated town level actual location. 4.6 Impact of the Num b In order to understand the i actual location, we investi g lowings is in continuous g to observe the influence o f lowers is growing but ign o creases without followers ( same time (Friends); and meanwhile, the following X  s ried out this experiment ba s large scale in Twitter, he / s h
From Fig.1, we can see t same variation in different the estimation of Accuracy followers is growing but i g tion effect is the same an d 42. For the most users, w h wise to not consider their f o In this paper, we investiga t mate user X  X  actual location s vice of Twitter. Based on t filter methods to filter out n and Remote Words (RW). distribution and non-local f are occasionally mentione d considered the place name m
Simultaneously, we attempted to estimate the user X  X  location via where the friends accuracy. Finally, we combined the two dimensions of textual and social networks to showed that our hybrid estimator can place 56.6% of 5119 users in Twitter within 100 miles of their actual location, 45.2% users geo-located within 25 miles of their actual location. 
Next, we plan to investigate users X  interactions with each other to refine the accura-cy of the estimator, and we are also interested in mining local information from user X  X  self-label tags in futures. Acknowledgment. This work is partially supported by grant from the Natural Science Foundation of China (No.60673039, 60973068, 61277370), the National High Tech Research and Development Plan of China (No.2006AA01Z151), Natural Science Foundation of Liaoning Province, China (No.201202031), State Education Ministry (No.20090041110002). 
