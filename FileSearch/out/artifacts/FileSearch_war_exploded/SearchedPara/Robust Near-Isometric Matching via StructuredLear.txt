 Matching shapes in images has many applications, including image retrieval, alignment, and reg-istration [1, 2, 3, 4]. Typically, matching is approached by selecting features for a set of landmark points in both images; a correspondence between the two is then chosen such that some distance measure between these features is minimised. A great deal of attention has been devoted to defining complex features which are robust to changes in rotation, scale etc. [5, 6]. 1 An important class of matching problems is that of near-isometric shape matching. In this setting, it is assumed that shapes are defined up to an isometric transformation (allowing for some noise), and therefore distance features are typically used to encode the shape. Recent work has shown how the isometric constraint can be exploited by a particular type of graphical model whose topology encodes the necessary properties for obtaining optimal matches in polynomial time [11]. Another line of work has focused on structured learning to optimize graph matching scores, however no explicit exploitation of the geometrical constraints involved in shape modeling are made [12]. In this paper, we combine the best of these two approaches into a single model. We produce an exact, efficient model to solve near-isometric shape matching problems using not only isometry-invariant features, but also appearance and scale-invariant features. By doing so we can learn the relative importances of variations in appearance and scale with regard to variations in shape per se . Therefore, even knowing that we are in a near-isometric setting, we will capture the eventual variations in appearance and scale into our matching criterion in order to produce a robust near-isometric matcher. In terms of learning, we introduce a two-stage structured learning approach to address the speed and memory efficiency of this model. 2.1 Shape Matching  X  X hape matching X  can mean many different things, depending on the precise type of query one is interested in. Here we study the case of identifying an instance of a template shape ( S  X  T ) in a target scene ( U ) [1]. 2 We assume that we know S , i.e. the points in the template that we want to query in the scene. Typically both T and U correspond to a set of  X  X andmark X  points, taken from a pair of images (common approaches include [6, 13, 14]).
 For each point t  X  X  and u  X  X  , a certain set of unary features are extracted (here denoted by  X  ( t ) ,  X  ( u ) ), which contain local information about the image at that point [5, 6]. If y : S  X  X  is a generic mapping representing a potential match, the goal is then to find a mapping  X  y which minimises the aggregate distance between corresponding features, i.e. (here k X k 2 denotes the L 2 norm). For injective y eq. (1) is a linear assignment problem, efficiently solvable in cubic time. In addition to unary or first-order features, pairwise or second-order features can be induced from the locations of the unary features. In this case eq. (1) would be generalised to minimise an aggregate distance between pairwise features. This however induces an NP-hard problem (quadratic assignment). Discriminative structured learning has recently been applied to models of both linear and quadratic assignment in [12]. 2.2 Graphical Models In isometric matching settings, one may suspect that it may not be necessary to include all pairwise relations in quadratic assignment. In fact a recent paper [11] has shown that if only the distances as encoded by the graphical model depicted in figure 1 are taken into account (nodes represent points in S and states represent points in U ), exact probabilistic inference in such a model can solve the isometric problem optimally. That is, an energy function of the following form is minimised: 3 In [11], it is shown that loopy belief propagation using this model converges to the optimal assign-ment, and that the number of iterations required before convergence is small in practice. We will extend this model by adding a unary term, c 1 ( s i ,y ( s i )) (as in (eq. 1)), and a third-order 2.3 Discriminative Structured Learning In practice, feature vectors may be very high-dimensional, and which components are  X  X mportant X  will depend on the specific properties of the shapes being matched. Therefore, we introduce a parameter,  X  , which controls the relative importances of the various feature components. Note that  X  is parameterising the matching criterion itself. Hence our minimisation problem becomes ( y is a mapping from S to U ,  X  is a third-order feature vector  X  our specific choice is shown in section 3). 4 In order to measure the performance of a particular weight vector, we use a loss func-tion ,  X ( X  y,y i ) , which represents the cost incurred by choosing the assignment  X  y when the correct assignment is y i (our specific choice of loss function is described in section 4). To avoid overfitting, we also desire that  X  is sufficiently  X  X mooth X . Typically, one uses the squared L 2 norm, k  X  k 2 2 , to penalise non-smooth choices of  X  [15].
 Learning in this setting now becomes a matter of choosing  X  such that the empirical risk (average loss on all training instances) is minimised, but which is also sufficiently  X  X mooth X  (to prevent over-fitting). Specifically, if we have a set of training pairs, S 1 ... S N , U 1 ... U N , with labelled matches y 1 ...y N , then we wish to minimise Here  X  (the regularisation constant) controls the relative importance of minimising the empirical risk against the regulariser. In our case, we simply choose  X  such that the empirical risk on our validation set is minimised.
 Solving (eq. 5) exactly is an extremely difficult problem and in practice is not feasible, since the loss is piecewise constant on the parameter  X  . Here we capitalise on recent advances in large-margin structured estimation [15], which consist of obtaining convex relaxations of this problem. Without going into the details of the solution (see, for example, [15, 16]), it can be shown that a convex relaxation of this problem can be obtained, which is given by (where Y is the space of all possible mappings). It can be shown that for the solution of the above problem, we have that  X   X  i  X   X ( f ( S i , U i ;  X  ) ,y i ) . This means that we end up minimising an upper bound on the loss, instead of the loss itself.
 Solving (6) requires only that we are able, for any value of  X  , to find In other words, for each value of  X  , we are able to identify the mapping which is consistent with the model (eq. 3), yet incurs a high loss. This process is known as  X  X olumn generation X  [15, 16]. As we will define our loss as a sum over the nodes, solving (eq. 7) is no more difficult than solving (eq. 3). Figure 2: Left: the (ordered) set of points in our template shape ( S ). Centre: connections between immediate neighbours. Right: connections between neighbour X  X  neighbours (our graphical model). Although the model of [11] solves isometric matching problems optimally, it provides no guarantees for near -isometric problems, as it only considers those compatibilities which form cliques in our graphical model. However, we are often only interested in the boundary of the object: if we look at the instance of the model depicted in figure 2, it seems to capture exactly the important dependencies; adding additional dependencies between distant points (such as the duck X  X  tail and head) would be unlikely to contribute to this model.
 With this in mind, we introduce three new features (for brevity we use the shorthand y i = y ( s i ) ):  X   X   X  transformations (rotation, reflection, and translation);  X  2 and  X  3 capture triangle similarity, and are thus also invariant to scale. In the context of (eq. 4), we have In practice, landmark detectors often identify several hundred points [6, 17], which is clearly im-practical for an O ( |S||U| 3 ) method ( |U| is the number of landmarks in the target scene). To address this, we adopt a two stage learning approach: in the first stage, we learn only unary compatibilities, exactly as is done in [12]. During the second stage of learning, we collapse the first-order feature vector into a single term, namely (  X  0 is the weight vector learned during the first stage). We now perform learning for the third-order model, but consider only the p  X  X ost likely X  matches for each node , where the likelihood is simply A consequence of using this approach is that we must now tune two regularisation constants; this is not an issue in practice, as learning can be performed quickly using this approach. 6 Figure 3: Left: The adjacency structure of the graph (top); the boundary of our  X  X hape X  (centre); the topology of our graphical model (bottom). Right: Example matches using linear assignment (top, 6/30 mismatches), quadratic assignment (centre, 4/30 mismatches), and the proposed model (bottom, no mismatches). The images shown are the 12 th and 102 nd frames in our sequence. Correct matches are shown in green, incorrect matches in red. All matches are reported after learning. 4.1 House Data In our first experiment, we compare our method to those of [11] and [12]. Both papers report the performance of their methods on the CMU  X  X ouse X  sequence  X  a sequence of 111 frames of a toy house, with 30 landmarks identified in each frame. 7 As in [12], we compute the Shape Context features for each of the 30 points [5].
 In addition to the unary model of [12], a model based on quadratic assignment is also presented, in which pairwise features are determined using the adjacency structure of the graphs. Specifically, if a which is 1 if there is an edge between p 1 and p 2 in the template, and an edge between q 1 and q 2 in the target (and 0 otherwise). We also use such a feature for this experiment, however our model only considers matchings for which ( p 1 ,p 2 ) forms an edge in our graphical model (see figure 3, bottom left). The adjacency structure of the graphs is determined using the Delaunay triangulation, (figure 3, top left).
 As in [11], we compare pairs of images with a fixed baseline (separation between frames). For our loss function,  X ( X  y,y i ) , we used the normalised Hamming loss, i.e. the proportion of mismatches. Figure 4 shows our performance on this dataset, as the baseline increases. On the left we show the performance without learning, for which our model exhibits the best performance by a substantial margin. 8 Our method is also the best performing after learning  X  in fact, we achieve almost zero error for all but the largest baselines (at which point our model assumptions become increasingly violated, and we have less training data). In figure 5, we see that the running time of our method is similar to the quadratic assignment method of [12]. To improve the running time, we also show our results with p = 10 , i.e. for each point in the template scene, we only consider the 10  X  X ost likely X  matches, using the weights from the first stage of learning. This reduces the running time by more than an order of Figure 4: Comparison of our technique against that of [11] ( X  X oint matching X ), and [12] ( X  X inear X ,  X  X uadratic X ). The performance before learning is shown on the left, the performance after learning is shown on the right. Our method exhibits the best performance both before and after learning ( note the different scales of the two plots ). Error bars indicate standard error. Figure 5: The running time and performance of our method, compared to those of [12] (note that the method of [11] has running time identical to our method). Our method is run from 1 to 20 iterations of belief propagation, although the method appears to converge in fewer than 5 iterations. magnitude, bringing it closer to that of linear assignment; even this model achieves approximately zero error up to a baseline of 50.
 Finally, figure 6 (left) shows the weight vector of our model, for a baseline of 60. The first 60 weights are for the Shape Context features (determined during the first stage of learning), and the final 5 show the weights from our second stage of learning (the weights correspond to the first-order features, distances, adjacencies, scaled distances, and angles, respectively  X  see section 3). We can provide some explanation of the learned weights: the Shape Context features are separated into 5 radial, and 12 angular bins  X  the fact that there are peaks around the 16 th and 24 th , features indicates that some particular radial bins are more important than the others; the fact that several consecutive bins have low weight indicates that some radial bins are unimportant (etc.). It is much more difficult to reason about the second stage of learning, as the features have different scales, and cannot be compared directly  X  however, it appears that all of the higher-order features are important to our model. 4.2 Bikes Data For our second experiment, we used images of bicycles from the Caltech 256 Dataset [18]. Bicycles are reasonably rigid objects, meaning that matching based on their shape is logical. Although the images in this dataset are fairly well aligned, they are subject to reflections as well as some scaling and shear. For each image in the dataset, we detected landmarks automatically, and six points on the frame were hand-labelled (see figure 7). Only shapes in which these interest points were not occluded were used, and we only included images that had a background; in total, we labelled 44 Figure 6: Left: The weight vector of our method after learning, for the  X  X ouse X  data. The first 60 weights are for the Shape Context features from the first stage of of learning; the final 5 weights are for the second stage of learning. Right: The same plot, for the  X  X ikes X  data.
 Figure 7: Top: A selection of our training images. Bottom: An example match from our test set. Left: The template image (with the shape outlined in green, and landmark points marked in blue). Centre: The target image, and the match (in red) using unary features with the affine invariant/SIFT model of [17] after learning (endpoint error = 0.27). Right: the match using our model after learning (endpoint error = 0.04). images. The first image was used as the  X  X emplate X , the other 43 were used as targets. Thus we are learning to match bicycles similar to the chosen template.
 Initially, we used the SIFT landmarks and features as described in [6]. Since this approach typically identifies several hundred landmarks, we set p = 20 for this experiment (i.e. we consider the 20 most likely points). Since we cannot hope to get exact matches, we use the endpoint error instead of the normalised Hamming loss, i.e. we reward points which are close to the correct match. 9 Table 1 reveals that the performance of this method is quite poor, even with the higher-order model, and furthermore reveals no benefit from learning. This may be explained by the fact that although the SIFT features are invariant to scale and rotation, they are not invariant to reflection. In [17], the authors report that the SIFT features can provide good matches in such cases, as long as landmarks are chosen which are locally invariant to affine transformations. They give a method for identifying affine-invariant feature points, whose SIFT features are then computed. 10 We achieve much better performance using this method, and also observe a significant improvement after learn-ing. Figure 7 shows an example match using both the unary and higher-order techniques. Finally, figure 6 (right) shows the weights learned for this model. Interestingly, the first-order term during the second stage of learning has almost zero weight. This must not be misinterpreted: during the second stage, the response of each of the 20 candidate points is so similar that the first-order fea-tures are simply unable to convey any new information  X  yet they are still very useful in determining the 20 candidate points. Table 1: Performance on the  X  X ikes X  dataset. The endpoint error is reported, with standard errors in parentheses (note that the second-last column,  X  X igher-order X  uses the weights from the first stage of learning, but not the second).
 We have presented a model for near-isometric shape matching which is robust to typical additional variations of the shape. This is achieved by performing structured learning in a graphical model that encodes features with several different types of invariances, so that we can directly learn a  X  X om-pound invariance X  instead of taking for granted the exclusive assumption of isometric invariance. Our experiments revealed that structured learning with a principled graphical model that encodes both the rigid shape as well as non-isometric variations gives substantial improvements, while still maintaining competitive performance in terms of running time.
 Acknowledgements: We thank Marconi Barbosa and James Petterson for proofreading. NICTA is funded by the Australian Government X  X  Backing Australia X  X  Ability initiative, and the Australian Research Council X  X  ICT Centre of Excellence program.

