 Principal component analysis (PCA) has been extensively us ed for data analysis and processing. It provides a closed-form solution for linear unsupervised dimensionality reduction through singu-lar value decomposition (SVD) on the data matrix [8]. Probab ilistic interpretations of PCA have also been provided in [9, 16], which formulate PCA using a lat ent variable model with Gaussian distributions. To generalize PCA to better suit non-Gaussi an data, many extensions to PCA have been proposed that relax the assumption of a Gaussian data di stribution. Exponential family PCA is the most prominent example, where the underlying dimensi onality reduction principle of PCA is extended to the general exponential family [4, 7, 13]. Pre vious work has shown that improved quality of dimensionality reduction can be obtained by usin g exponential family models appropri-ate for the data at hand [4, 13]. Given data from a non-Gaussia n distribution these techniques are better able than PCA to capture the intrinsic low dimensiona l structure. However, most existing non-Gaussian dimensionality reduction methods rely on ite rative local optimization procedures and thus suffer from local optima, with the sole exception of [7] which shows a general convex form can be obtained for dimensionality reduction with exponential family models.
 Recently, supervised dimensionality reduction has begun t o receive increased attention. As the goal of dimensionality reduction is to identify the intrinsic st ructure of a data set in a low dimensional space, there are many reasons why supervised dimensionalit y reduction is a meaningful topic to study. First, data labels are almost always assigned based o n some important intrinsic property of the data. Such information should be helpful to suppress noi se and capture the most useful aspects of a compact representation of the data. Moreover, there are many high dimensional data sets with label information available, e.g., face and digit images, a nd it is unwise to ignore them. A few su-pervised dimensionality reduction methods based on expone ntial family models have been proposed in the literature. For example, a supervised probabilistic PCA (SPPCA) model was proposed in [19]. SPPCA extends probabilistic PCA by assuming that both features and labels have Gaussian distributions and are generated independently from the lat ent low dimensional space through linear transformations. The model is learned by maximizing the mar ginal likelihood of the observed data using an alternating EM procedure. A more general supervise d dimensionality reduction approach with generalized linear models (SDR GLM) was proposed in [12]. SDR GLM views both features and labels as exponential family random variables and optim izes a weighted linear combination of their conditional likelihood given latent low dimensional variables using an alternating EM-style procedure with closed-form update rules. SDR GLM is able to deal with different data types by using different exponential family models. Similar to SDR GLM, the linear supervised dimension-ality reduction method proposed in [14] also takes advantag e of exponential family models to deal with different data types. However, it optimizes the condit ional likelihood of labels given observed features within a mixture model framework using an EM-style optimization procedure. Beyond the PCA framework, many other supervised dimensionality reduc tion methods have been proposed in the literature. Linear (fisher) discriminant analysis (LDA ) is a popular alternative [5], which max-imizes between-class variance and minimizes within-class variance. Moreover, a kernelized fisher discriminant analysis (KDA) has been studied in [10]. Anoth er notable nonlinear supervised dimen-sionality reduction approach is the colored maximum varian ce unfolding (MVU) approach proposed in [15], which maximizes the variance aligning with the side information (e.g., label information), while preserving the local distance structures from the dat a. However, colored MVU has only been evaluated on training data.
 In this paper, we propose a novel supervised exponential fam ily PCA model (SEPCA). In the SEPCA model, observed data x and its label y are assumed to be generated from the latent variables z via conditional exponential family models; dimensionality re duction is conducted by optimizing the conditional likelihood of the observations ( x , y ) . By exploiting convex duality of the sub-problems and eigenvector properties, a solvable convex formulation of the problem can be derived that pre-timization algorithms to be devised. Moreover, by introduc ing a sample-based approximation to exponential family models, SEPCA does not suffer from the li mitations of implicit Gaussian as-sumptions and is able to be conveniently kernelized to achie ve nonlinearity. A training algorithm is then devised based on a subgradient bundle method, whose s calability can be gained through a coordinate descent procedure. Finally, we present a simple formulation to project new testing data into the embedded space. This projection can be used for othe r supervised dimensionality reduction approach as well. Our experimental results over both synthe tic and real data suggest that a more global, principled probabilistic approach, SEPCA, is bett er able to capture subtle structure in the data, particularly when good label information is present.
 The remainder of this paper is organized as follows. First, i n Section 2 we present the proposed supervised exponential family PCA model and formulate a con vex nondifferentiable optimization problem. Then, an efficient global optimization algorithm i s presented in Section 3. In Section 4, we present a simple projection method for new testing points . We then present the experimental results in Section 5. Finally, in Section 6 we conclude the pa per. We assume we are given a t  X  n data matrix, X , consisting of t observations of n -dimensional feature vectors, X observation X their empirical means are zeros. We aim to recover a d -dimensional re-representation, a t  X  d matrix Z , of the data ( d &lt; n ) . This is typically viewed as discovering a latent low dimens ional manifold in the high dimensional feature space. Since the label infor mation Y is exploited in the discovery process, this is called supervised dimensionality reducti on. For recovering Z , a key restriction that one would like to enforce is that the features used for coding , Z that is, one would like to enforce the constraint Z  X  Z = I , which ensures that the codes are expressed by orthogonal features in the low dimensional representati on.
 Given the above setup, in this paper, we are attempting to add ress the problem of supervised dimen-sionality reduction using a probabilistic latent variable model. Our intuition is that the important intrinsic structure (underlying feature representation) of the data should be able to accurately gener-ate/predict the original data features and labels.
 In this section, we formulate the low-dimensional principa l component discovering problem as a conditional likelihood maximization problem based on expo nential family model representations, which can be reformulated into an equivalent nondifferenti able convex optimization problem. We then exploit a sample-based approximation to unify exponen tial family models for different data types. 2.1 Convex Formulation of Supervised Exponential Family PC A As with the generalized exponential family PCA [4], we attem pt to find low-dimensional represen-tation by maximizing the conditional likelihood of the obse rvation matrix X and Y given the latent representation, a regularized version of this maximizatio n problem can be formulated as = max where W is a d  X  n parameter matrix for conditional model P ( X | Z ) ;  X  is a d  X  k parameter matrix for conditional model P ( Y | Z ) and b is a k  X  1 bias vector; 1 denotes the vector of all 1s; A ( Z and A ( Z where 1 logistic regression. That is why we have incorporated an add itional bias term b into the model. Theorem 1 The optimization problem (1) is equivalent to where E is a t  X  t matrix with all 1s; U x is a t  X  n matrix; U y is a t  X  k matrix; A  X  ( U x can be recovered by taking the top d eigenvectors of M ; and the model parameters W,  X  , b can be recovered by Proof: The proof is simple and based on standard results. Due to spac e limitation, we only provide a summarization of the key steps here. There are three steps. The first step is to derive the Fenchel conjugate dual for each log partition function, A ( Z, . ) , following [18, Section 3.3.3]; which can be used to yield that is equivalent to the original problem (1). The second st ep is based on exploiting the strong min-max property [2] and the relationships between differe nt constraint sets which allows one to further show the optimization (4) is an up per bound relaxation of (5). The final equivalence proof is based on the result of [11], which sugge sts the substitution of ZZ  X  with matrix M does not produce relaxation gap.
 Note that (4) is a min-max optimization problem. Moreover, f or each fixed M , the outer minimiza-tion problem is obviously convex, since the Fenchel conjuga tes, A  X  ( U x pointwise supremum over an infinite set of convex functions. Thus the overall min-max optimization is convex [3], but apparently not necessarily differentiab le. We will address the nondifferentiable training issue in Section 3. 2.2 Sample-based Approximation In the previous section, we have formulated our supervised e xponential family PCA as a convex optimization problem (4). However, before attempting to de vise a training algorithm to solve it, we have to provide some concrete forms for the Fenchel conjugat e functions A  X  ( U x different exponential family models, the Fenchel conjugat e functions A  X  are different; see [18, Table 2]. For example, since the y variable in our model is a discrete class variable, it takes a multinomial distribution. Thus the Fenchel conjugate function A  X  ( U y The specific exponential family model is determined by the da ta type and distribution. PCA and SPPCA use Gaussian models, thus their performances might be degraded when the data distribution is non-Gaussian. However, it is tedious and sometimes hard t o choose the most appropriate expo-nential family model to use for each specific application pro blem. Moreover, the log normalization function A and its Fenchel conjugate A  X  might not be easily computable. For these reasons, we pro-pose to use a sample-based approximation to the integral (2) and achieve an empirical approximation to the true underlying exponential family model as follows. If one replaces the integral definition (2) with an empirical definition, A ( Z can be given by With this sample-based approximation, problem (4) can be ex pressed as One benefit of working with this sample-based approximation is that it is automatically kernelized, K = XX  X  , to enable non-linearity to be conveniently introduced. The optimization (8) we derived in the previous section is a c onvex-concave min-max optimization problem. The inner maximization of (8) is a well known proble m with a closed-form solution [11]: denotes the matrix formed by the top d eigenvectors of D . However, the overall outer minimization problem is nondifferentiable with respect to  X  x and  X  y . Thus the standard first-order or second-order optimization techniques that rely on the standard gra dients can not be applied here. In this section, we deploy a bundle method to solve this nondifferen tiable min-max optimization. 3.1 Bundle Method for Min-Max Optimization The bundle method is an efficient subgradient method for nond ifferentiable convex optimization; it relies on the computation of subgradient terms of the object ive function. A vector g is a subgradient specific min-max problem, we need to first address the critica l issue of subgradient computation. Proposition 1 Consider a joint function h ( x , y ) defined over x  X  X  and y  X  X  , satisfying: (1) and q ( x subgradient of f ( x ) at x = x Proof: f ( x ) = max Thus g is a subgradient of f ( x ) at x = x According to Proposition 1, the subgradients of our outer mi nimization objective function f in (8) over  X  x and  X  y can be given by where M  X  is the optimal inner maximization solution at the current po int [ X  x ,  X  y ] . Algorithm 1 illustrates the bundle method we developed to so lve the infinite min-max optimiza-tion (8), where the linear constraints (9) over  X  x and  X  y can be conveniently incorporated into the quadratic bound optimization. One important issue in this a lgorithm is how to manage the size of the linear lower bound constraints formed from the active set B (defined in Algorithm 1), as it incremen-tally increases with new points being explored. To solve thi s problem, we noticed the Lagrangian dual parameters  X  for the lower bound constraints obtained by the quadratic op timization in step 1 is a sparse vector, indicating that many lower bound constra ints can be turned off. Moreover, any constraint that is turned off will mostly stay off in the late r steps. Therefore, for the bundle method we developed, whenever the size of B is larger than a given constant b , we will keep the active points of
B that correspond to the first b largest  X  values, and drop the remaining ones. 3.2 Coordinate Descent Procedure An important factor affecting the running efficiency is the s ize of the problem. The convex opti-mization (8) works in the dual parameter space, where the siz e of the parameters  X  = {  X  x ,  X  y } , dimensional small data sets ( n  X  t ), our dual optimization is certainly a good option. However , large to handle for the quadratic optimization step of the bu ndle method.
 one equality constraint in (9) involves only one row of the  X  ; that is, the  X  can be separated into rows without affecting the equality constraints. Based on t his observation, we develop a coordinate descent procedure to obtain scalability of the bundle metho d over large data sets. Specifically, we put an outer loop above the bundle method. Within each of this outer loop iteration, we randomly separate the  X  parameters into m groups, with each group containing a subset rows of  X  ; and  X  parameters while keeping the remaining rows of  X  fixed. Although coordinate descent with a nondifferentiable convex objective is not guaranteed to co nverge to a minimum in general [17], we have found that this procedure performs quite well in practi ce, as shown in the experimental results. One important issue for supervised dimensionality reducti on is to map new testing data into the dimensionality-reduced principal dimensions. We deploy a simple procedure for this purpose. After Algorithm 1 Bundle Method for Min-Max Optimization in (8) Input:  X   X  &gt; 0 , m  X  (0 , 1) , b  X  IN ,  X   X  IR Initial: Find an initial point  X   X  satisfying the linear constraints in (9); compute f (  X   X  ) . repeat until maximum iteration number is reached training, we obtain a low-dimensional representation Z for X , where Z can be viewed as a linear projection of X in some transformed space  X  ( X ) through a parameter matrix U; such that Z = Then a new testing sample x  X  can be projected by In order to evaluate the performance of the proposed supervi sed exponential family PCA (SEPCA) approach, we conducted experiments over both synthetic and real data, and compared to supervised dimensionality reduction with generalized linear models ( SDR GLM), supervised probabilistic PCA (SPPCA), linear discriminant analysis (LDA), and colored m aximum variance unfolding (MVU). The projection procedure (11) is used for colored MVU as well . In all the experiments, we used  X  = 1 for Algorithm 1, and used  X  = 0 . 0001 for SDR GLM as suggested in [12]. 5.1 Experiments on Synthetic Data Two synthetic experiments were conducted to compare the five approaches under controlled con-ditions. The first synthetic data set is formed by first genera ting four Gaussian clusters in a two-dimensional space, with each corresponding to one class, an d then adding the third dimension to each point by uniformly sampling from a fixed interval. This e xperiment attempts to compare the performance of the five approaches in the situation where the data distribution does not satisfy the Gaussian assumption. Figure 1 shows the projection results for each approach in a two dimensional space for 120 testing points after being trained on a set with 80 points. In this case, SEPCA and LDA outperform all the other three approaches.
 The second synthetic experiment is designed to test the capa bility of performing nonlinear dimen-sionality reduction. The synthetic data is formed by first ge nerating two circles in a two dimensional space (one circle is located inside the other one), with each circle corresponding to one class, and then the third dimension sampled uniformly from a fixed inter val. As SDR GLM does not provide a nonlinear form, we conducted the experiment with only the r emaining four approaches. For LDA, we used its kernel variant, KDA. A Gaussian kernel with  X  = 1 was used for SEPCA, SPPCA and KDA. Figure 2 shows the projection results for each approach in a two dimensional space for 120
Figure 1: Projection results on test data for synthetic expe riment 1. Each color indicates one class.
Figure 2: Projection results on test data for synthetic expe riment 2. Each color indicates one class. testing points after being trained on a set with 95 points. Ag ain, SEPCA and KDA achieve good class separations and outperform the other two approaches. 5.2 Experiments on Real Data To better characterize the performance of dimensionality r eduction in a supervised manner, we con-ducted some experiments on a few high dimensional multi-cla ss real world data sets. The left side of Table 1 provides the information about these data sets. Ou r experiments were conducted in the following way. We randomly selected 3  X  5 examples from each class to form the training set and used the remaining examples as the test set. For each approac h, we first learned the dimensionality reduction model on the training set. Moreover, we also train ed a logistic regression classifier us-ing the projected training set in the reduced low dimensiona l space. (Note, for SEPCA, a classifier was trained simultaneously during the process of dimension ality reduction optimization.) Then the test data were projected into the low dimensional space acco rding to each dimensionality reduction model. Finally, the projected test set for each approach wer e classified using each corresponding set for each approach. To better understand the quality of th e classification using projected data, we also included the standard classification results, indicat ed as  X  X ULL X , using the original high dimen-sional data. (Note, we are not able to obtain any result for SD R GLM on the newsgroup data as it is inefficient for very high dimensional data.) The results rep orted here are averages over 20 repeated runs, and the projection dimension d = 10 . Still the proposed SEPCA presents the best performance among the compared approaches. But different from the synth etic experiments, LDA does not work well on these real data sets.
 The results on both synthetic and real data show that SEPCA ou tperforms the other four approaches. This might be attributed to its adaptive exponential family model approximation and its global opti-mization, while SDR GLM and SPPCA apparently suffer from local optima. In this paper, we propose a supervised exponential family PC A (SEPCA) approach, which can be solved efficiently to find global solutions. Moreover, SEP CA overcomes the limitation of the Gaussian assumption of PCA and SPPCA by using a data adaptive approximation for exponential family models. A simple, straightforward projection metho d for new testing data has also been constructed. Empirical study suggests that this SEPCA outp erforms other supervised dimensionality reduction approaches, such as SDR GLM, SPPCA, LDA and colored MVU.
 Dataset #Data #Dim #Class FULL SEPCA GLM SPPCA LDA MVU Yale 165 4096 15 65.3 64.4 58.8 51.6 31.0 21.1
YaleB 2414 1024 38 47.0 20.5 19.0 9.8 6.2 2.8 11 Tumor 174 12533 11 77.6 88.9 63.5 63.0 23.7 40.2 Usps3456 120 256 4 82.1 79.7 77.9 78.5 74.3 75.8 Newsgroup 19928 25284 20 32.1 16.9  X  6.9 10.0 10.4 [1] A. Belloni. Introduction to bundle methods. Technical r eport, MIT, 2005. [2] J. Borwein and A. Lewis. Convex Analysis and Nonlinear Optimization . Springer, 2000. [3] S. Boyd and L. Vandenberghe. Convex Optimization . Cambridge U. Press, 2004. [4] M. Collins, S. Dasgupta, and R. Schapire. A generalizati on of principal component analysis to [5] R. Fisher. The use of multiple measurements in taxonomic problems. Annals of Eugenics , [6] Y. Guo and D. Schuurmans. Convex relaxations of latent va riable training. In Advances in [7] Y. Guo and D. Schuurmans. Efficient global optimization f or exponential family PCA and [8] I. Jolliffe. Principal Component Analysis . Springer Verlag, 2002. [9] N. Lawrence. Probabilistic non-linear principle compo nent analysis with gaussian process [10] S. Mika, G. Ratsch, J. Weston, B. Scholkopf, and K. Mulle r. Fisher discriminant analysis with [11] M. Overton and R. Womersley. Optimality conditions and duality theory for minimizing sums [12] I. Rish, G. Grabarnilk, G. Cecchi, F. Pereira, and G. Gor don. Closed-form supervised dimen-[13] Sajama and A. Orlitsky. Semi-parametric exponential f amily PCA. In Advances in Neural [14] Sajama and A. Orlitsky. Supervised dimensionality red uction using mixture models. In Pro-[15] L. Song, A. Smola, K. Borgwardt, and A. Gretton. Colored maximum variance unfolding. In [16] M. Tipping and C. Bishop. Probabilistic principal comp onent analysis. Journal of the Royal [17] P. Tseng. Convergence of a block coordinate descent met hod for nondifferentiable minimiza-[18] M. Wainwright and M. Jordan. Graphical models, exponen tial families, and variational infer-[19] S. Yu, K. Yu, V. Tresp, H. Kriegel, and M. Wu. Supervised p robabilistic principal component
