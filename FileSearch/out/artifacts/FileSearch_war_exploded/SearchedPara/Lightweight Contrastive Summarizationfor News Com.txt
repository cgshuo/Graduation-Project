 We develop and discuss a news comment miner that presents distinct viewpoints on a given theme or event. Given a query, the system uses metasearch techniques to find rel-evant news articles. Relevant articles are then scraped for both article content and comments. Snippets from the com-ments are sampled and presented to the user, based on theme popularity and contrastiveness to previously selected snippets. The system design focuses on being quicker and more lightweight than recent topic modelling approaches, while still focusing on selecting orthogonal snippets. Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Information filtering; I.2.7 [Nat-ural Language Processing]: Language Models General Terms: Algorithms, Experimentation Keywords: Summarization, Comments, Opinion
The study of blogs and other news sources has proved use-ful for both governments and companies looking to improve the quality of their services[3]. News sources, however, draw from a small set of expert users who drive all the discus-sion in an area. Thus, these sources may not necessarily represent public opinion. Recently, microblogging sites have provided a rich source of user opinion which has been heav-ily researched. Unfortunately, this data can be noisy due to length restrictions, which limit what can be expressed.
Alternatively, news portals may provide the ability to comment on articles directly from their websites. These comments are attached to an article and are relatively unre-stricted, allowing for a much wider range of opinion. Com-mentors also highlight both errors and interesting facets about articles on any given topic. However, on a highly debated topic it becomes time consuming to read all the comments and to understand the distinct perspectives.
Thus, the problem of multidocument comment ranking or comment mining requires some attention. Our goal should be to create a system that, given a set of articles and com-ments on those articles, extracts a set of interesting snippets from the comments. These snippets should be representative of the different views of the commentors.
The problem of comment mining is somewhat similar to the concept of review summarization, in which the goal is to generate summaries of the opinions on a given product. In contrastive review summarization we wish to also highlight the differences in multiple products. The work in contrastive review summarization largely focuses on extracting senti-ment and opinion[4]. The problem of extracting sentiment is somewhat eased by the fact that reviews are often asso-ciated with a rating system that provides supervised data. Furthermore, for news stories, sometimes sentiment extrac-tion may add unnecessary overhead, and highlight unimpor-tant aspects, as the objective facts of the story may be more interesting.

General multidocument summarization has also provided a rich source of tools for comment mining. However, much of this work focuses on creating a single overall summary, which may not be plausible with comments representing a lengthy discussion or argument. Furthermore, this work of-ten attempts to create natural language models that are able to stitch together information in order to ensure that sum-maries are human readable and coherant[6]. This overhead is unnecessary and expensive for individuals wishing to get an overall understanding of user opinion. Topic modeling approaches employing PLSA have also been used to extract latent themes within a set of articles[5], however this ap-proach is heavyweight and may incorrectly cluster important terms causing them to be missed. For example, in our data it was shown that conservatives preferred writing  X  X arrack Hussein Obama X  over the liberal  X  X bama X .

Some work has recently been invested into comment sen-tence extraction[2]. This work focuses on extracting inter-esting sentences from a single blogs comments using models that explicitly model different types of comments and topic mixtures. The term-term graph was deemed too heavy-weight for the multidocument snippet extraction.

Our final algorithm takes a lightweight approach to re-view captioning building on simple language models. This approach attempts to explicitly extract orthogonal sentences that represent the most discussed points, and is explained in section 3. This lightweight approach was taken due to its ability to process our corpus containing over 5 million com-ments and over 2 million distinct terms within an hour. In contrast, implementations on PLSA discuss 50,000 by 8,000 term-doc matrices, and execute in about half an hour[1].
In order to understand the data analyzed, we briefly de-scribe the framework used to implement the lightweight com-ment summarizer.

The input of the system is a query and a date range, for example  X  X OPA 01/2012 02/2012 X . The system then uses metasearch techniques to extract the hundred most relevant articles from each of over forty-five different news portals. An associated rule scraper is then used to extract news ar-ticle and comment data from each link. The comments and articles are fed to a snippet extractor that attempts to ex-tract a finite set of interesting sentences from the corpus.
The primary innovation comes from applying a known al-gorithm to a different domain, and the implementation of a lightweight comment extraction framework.
To illustrate the scoring algorithm, we present the results of extracting four snippets from articles about the inter-net regulatory legislation nicknamed  X  X OPA X . The snippets highlight multiple opinions such as the existence of compet-ing laws, and perceived copyright infringement by Google.
Initially, we assume a background set of comments C and a target set of comments C q  X  C , that are commenting about articles relevant to the query q . C is generated by executing the comment mining engine on as many different queries as time allows, twenty seven in our case. We can estimate a language model for each term t in the collection as follows: p q ( t ) = number of comments in C q containing t +  X  Here we use the additive smoothing parameter  X  , with  X  = 1 for our tests. Given this model we can use the K-L divergence to calculate score(t) We select snippets using the following algorithm. 1. Find a snippet S of at least l contigious words, round-2. Compute a snippet score as follows: 3. Present the highest scoring snippet S X  to the user. 4. Set score ( t ) = 0  X  t  X  S 0 5. Repeat step 1-4 while the score is above a threshold .
The ability to quickly and effectively extract comments from articles opens up a large corpus of data for analyz-ing and extracting opinion. By using K-L divergence and a bag of words model we are able to quickly isolate inter-esting opinions and present analysts X  feedback on how users generally feel about a given topic. As ongoing research, we are comparing the results with more heavyweight topic mod-elling approaches to summarization. Using the current work as a baseline, we hope to evaluate both algorithms and com-pare the benefits of each method. [1] M. Blondel. LSA and pLSA in Python, June 2010. [2] M. Hu, A. Sun, and E.-P. Lim. Comments-Oriented [3] L.-W. Ku, L.-Y. Lee, and H.-H. Chen. Opinion [4] K. Lerman and R. McDonald. Contrastive [5] Y. Lu and C. Zhai. Opinion Integration Through [6] D. R. Radev and K. R. McKeown. Generating Natural
