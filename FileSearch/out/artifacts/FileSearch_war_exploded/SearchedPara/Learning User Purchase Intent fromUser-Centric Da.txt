
Rajan Lukose 1 ,JiyeLi 2 ,JingZhou 3 , and Satyanarayana Raju Penmetsa 1 Clickstream data collected across all the different websites a user visits reflect the user X  X  behavior, interests , and preferences more comp letely than data collected from one site. For example, one would expect that it would be possible to better model and predict the intentions of users who we knew not only searched for a certain keyword on a search engine S but also visited website X and the website Y , than if we knew only one of those pieces of information. Th e complete data set is termed user-centric data [8], which contains site-centric data as a subset. Most existing research on clickstream data analysis is based on site-centric data.
For the important task of personalization we seek to demonstrate rich, predic-tive user models induced from user-centric data, and quantify their advantages to site-centric approaches. We use a dataset supplied by a major audience mea-surement company that represents a comp lete user-centric vi ew of clickstream behavior. The main contribution of our work is the first demonstration that ac-curate product category level purchase prediction modeling (regardless of the site of purchase) can be done from user-centric data. Using the supplied product purchase metadata to set up a prediction problem, we learn models of the user X  X  probability of purchase within a time window for multiple product categories by using features that represent the user X  X  behavior on all websites. Our model outperforms a reasonable and commercially meaningful baseline model learned from site-centric data restricted to a m ajor search engine. We also propose a novel behaviorally (as opposed to syntactically) based search term suggestion algorithm which was an effective part of the feature selection strategy we used. Additionally, we explicitly consider the issue of prediction latency and show that even when predictions are made with long lead times, effective predictions can still be made. Finally, our models are not privacy invasive and we propose the idea of  X  X mart cookies X  motivated by our results. The success of our clickstream modeling approach should point the way to more personalization applications driven by clickstream modeling.

We first review the related backgro und work in clickstream modeling and current research on personalization in Section 2. We then introduce our proposed online product purchase model and describe our experimental data in Section 3. Section 4 provides the exper imental design and results. In the computer science literature, two main motivations have driven research on clickstream analysis: personalization and caching. Caching and prefetching to im-prove web server performance is obviously an important task and so site-centric clickstreams from web server logs have b een analyzed to improve performance [4]. This line of work has emphasized the use of Markov models to predict page ac-cesses. Despite a broad and deep intere st, little direct work has been done on mining user-centric clickstream data for personalization. Site-centric personal-ization efforts have used clickstream analysis to cluster users [1,2] which enables site-specific content recommendation with in user clusters. Additional work has been done in the marketing science literature [6] and [7]. User-centric clickstream data has been used in web personalization tasks such as personalized search [10], where clickstream data was part of the data used to help re-rank search results. Padmanabhan, et al. [8] demonstrated the predictive value of user-centric data versus site-centric data. Their work attempted to provide predictions of  X  X ur-chase X  or  X  X o-purchase X  at a given website (regardless of specific product cate-gory) based on user or site-centric data as inputs. In our work, we focus on the more widely useful and more difficult task of predicting specific product category purchases at any website. Furthermore, we consider search data as an important feature whose value as a prediction variable we are able to quantify and which was not used in this prior work.
 This work focuses on developing general models that can effectively learn and predict users X  online purchase intent. In these models, user-centric data is col-lectedandstoredinadataba se. After data preprocessing, features reflecting user online purchase intentions are constructed. The search terms that users input into general search engines, and the search terms they use on the leading online shopping stores are considered as indications of their purchasing interests (see [5] for more details). Then algorithms, such as decision trees, regression pre-diction algorithms are applied for predicting online purchase intent for various product categories on the processed data composed of the constructed features. We further explain the experimental dataset used, a search term suggestion algo-rithm, data preprocessing, feature construction and evaluations for the modeling process in the rest of this section. 3.1 Experimental Data Nielsen Online MegaPanel data 1 is used as our testbed for purchase intent mod-eling. Nielsen is an online audience me asurement company, which is a premier provider of high-quality internet data. The MegaPanel data is raw user-centric clickstream data, which includes, for example, online search behavior on leading search engines (such as Google, Yahoo) and shopping websites (such as Ama-zon, BestBuy). The data co llection is processed to mak e the average customer X  X  online behaviors consistent with a representative sampling of internet users. All personally identifying data is filtered from our dataset by Nielsen.

The data collected over 8 months amoun ted to approximately 1 terabyte from more than 100 , 000 households. For each URL there are time stamps for each internet user X  X  visit. Retailer transaction data (i.e. purchase metadata) contains more than 100 online leading shopping destinations and retailer sites. These data records show for a given user who makes a purchase online, the product name, the store name, the timestamp, the price and so on. Users X  search terms can also be inferred from the URL data, which are collected from top search engines and comparison shopping sites (more details are given in [5]). 3.2 Behavior Based Search Term Suggestion Algorithm Automatic discovery of relevant search terms can help construct features to dis-tinguish buyers from non-buyers given a product category. The search terms users input into websites are indications of their purchasing intent, but it is a challenge to determine auto matically which terms are r elevant for a given prod-uct category. Current keyword suggestion tools are syntactically based, typically suggesting variations of queries that include a given seed search term. For ex-ample, for the purchase of  X  X aptop X , suggested keywords may include  X  X aptops X . Our approach is behaviorally based, does not use any information about syntactic variation of queries, and does not even r equire seed terms. For example, related keywords under this method may include brand names such as  X  X P laptop X ,  X  X ell X  and  X  X enovo X  with no syntactic relationship to  X  X aptop X .

We used the following algorithm to automatically generate a set of represen-tative search terms. First, given a product category, we counted the frequencies of all the search terms observed from buyers over a certain period of time. Then we found which search terms are significan tly different in frequency within the buyer population of our training data from the search terms which appear in the general population of buyers and non-buyers by using a Z-value test on each of the 26 product categories.

December 2005 data is used as our experimental data. We list the top 10 significant terms for sample product categories 2 in Table 1(a). This algorithm [5] was used for constructing useful featur es for our models in an automated way, but is also effective as a search term suggestion algorithm in more general contexts. For example, as can be seen in Table 1(a), this method identifies terms that do not include, and have no syntactic similarity to the word  X  X atch X  such as simple brand names like X  X eiko X ,  X  X ovado X , and  X  X imex X  as well as misspellings such as  X  X atche X  and even other terms like  X  X ecklace X . 3.3 Feature Construction We focus on constructing features that can reflect the users X  browsing and search-ing behaviors across multiple websites using user-centric data. There are 26 on-line product categories available in our experimental data. In this experiment, we consider the online purchasing product category to be personal computers, including both desktops and laptops.

We construct 28 features that are used in the following experiments for pre-dicting purchase of personal computers. Such features include  X  X hether searched laptop keywords before purchasing on Google X ,  X  # of sessions this user searched laptop keywords before purchasing X ,  X  X hether this user made a purchase (of any product category) in the past month X  and so on (all features are listed in [5]). December 2005 data is used for this experiment. We discuss briefly the input data, experimental design, and evaluation metrics for the classification algorithms.
 Input Data for Prediction. December 2005 data is used for this experiment. We consider the 28 features as condition attributes, and whether a person is a buyer or non-buyer for personal computers as the decision attribute. For a decision table T =( C, D ), C = { 28 features } , D = { buyer, non-buyer } .With 83 , 635 users and 28 features, we create a decision table as shown in Table 1(b) as input to prediction algorithms for discovering users purchasing intent. Experiment Design. For the complete data in the form of a decision table 83635  X  29 as shown in Table 1(b), we performed 10-fold cross validation through all the experiments.
 Evaluation Metrics. We use the following evaluation metrics to evaluate clas-sification performance. An individual can be classified as a buyer (denoted as P) or non-buyer (denoted as N). A classific ation is either co rrect (denoted as T) or false (denote as F). Thus, an individual who is an actual buyer but is clas-sified as non-buyer is denoted by FN; an actual buyer and classified as a buyer is denoted as TP; an actual non-buyer but classified as buyer is denoted as FP; an actual non-buyer and classified as non-buyer is denoted as TN. Therefore, we have Recall = TP TP + FN , P recision = TP TP + FP , T rueP ositiveRate = TP TP + FN , and F alseP ositiveRate = FP FP + TN . 4.1 Classification Experiments In order to accomplish the prediction task, we conducted the following experi-ments using classification algorithms including decision trees, logistic regression and Na  X   X ve Bayes.
 Decision Tree. Decision trees can be used to con struct classifiers for predic-tions. We assume only buyer or non-buyer as the two classes in our discussion. C4.5 decision tree [9] implementation is used for classification rule generation. We obtained precision 29 . 47%, and recall 8 . 37% for decision tree learning. Logistic Regression. We use Weka X  X  3 logistic regression implementation for creating the classifier. By measuring the capabilities of each of the independent variables, we can estimate the probability of a buyer or non-buyer occurrence. The default cutoff thresho ld of predicting a buyer is p = 0.5. The precision is 18 . 52% and recall is 2 . 23%. Figure 1(a) shows the precision and recall curve for the user-centric classifier gener ated by logistic regression.

Figure 1(b) shows the ROC curve for the user-centric cla ssifier generated by logistic regression. Figure 2(a) shows the tradeoff between the cutoff threshold and precision/recall for the us er-centric classifier generat ed by logistic regression. This plot can be used for determining the suggested cutoff threshold in order to reach a satisfied precision and recall toward s certain classification applications. Na  X   X ve Bayes. Previous studies have shown that a simple Na  X   X ve Bayesian clas-sifier has comparable classification perfo rmance with decision tree classifiers [3]. We use Weka X  X  Na  X   X ve Bayes classifier implementation for our experiments [11]. We obtained the classification results as precision 3 . 52% and recall 23 . 2%. Discussions. The classification experimental results demonstrate effective prod-uct level prediction. Classifiers can be c reated based on user-centric features to predict the potential buyers. From our experiment on predicting product pur-chases, we observed that decision tree al gorithm can obtain the highest predic-tion precision. The branching nodes in the tree splitting a potential buyer and non-buyer can be detected and used for sugge sting personalized relevant content. Logistic regression can be used as a flexible option to adjust the precision and recall for the classifiers. 4.2 Site and User-Centric Comparison Experiments To help quantify the benefits of user-centr ic classifiers for this task, we compare the performance of a decision tree classi fier based on 28 user-centric features to the best site-centric featur e as a single classifier from a major search engine (i.e.  X  X sers who searched laptop keywords on Google before purchasing and searched more than one session X ). The precisions for the user-centric and site-centric classifiers are 26 . 76% vs. 4 . 76%, and recall are 8 . 48% vs. 0 . 45%. The comparison figures is shown in Figure 2(b).

The result indicates that user-centric classifiers provide a much higher predic-tion precision (without loss of recall) than site-centric classifiers for predicting purchasing intent. Indeed, our discussions with industry experts indicate that even  X  5% precision is an extremely good number in online marketing cam-paigns executed through search advertising. The fact that our models can in-crease precision, often with an increase in recall as well, demonstrates the rich value contained in user-centric data for widely applicable prediction problems. 4.3 Prediction Latencies A key question for models of user intent is the prediction latency, defined as the period of time before the intended actio n that a prediction can be made. It may not be useful for many applications if good predictions can only be made over very short latent periods (e.g., a purchase prediction 10 seconds before it hap-pens). To address this concern we perform ed latency experiments using Novem-ber and December 2005 data. We used the feature  X  X hether searched laptop keywords on all NNR before purchasing a personal computer X , to make predic-tions using SQL aggregations. The experimental results indicate that 20 . 15% of computer transactions can be predicted by this feature. Among these pre-dicted transactions, only 15 . 59% transactions have the l atent period less than one day (we call this same-day-purchase) and 39 . 25% transactions have 1-7 days of latent period (we call this first-week -purchase). This experiment shows that online-shopping customers usually do not just come and immediately buy. They spend some time (mostly, more than one day) doing research before their fi-nal purchase decisions, which gives time to detect purchasing i nterests based on behaviors, make predictions, and suggest information. 4.4 Smart Cookies Our results indicate that useful models of intent can be learned from offline panel data and could be deployed client-side through simple classification algorithms. Client-computed outputs such as  X  X he probability that the user will purchase product type P within the next month X  could be used as intentional signals for a variety of personalization tasks such as personalizing search or serving relevant advertising in a variety of contexts. Th ese models need not be privacy invasive. A dynamic, intentionally expressive  X  X mart cookie X  could be one mechanism to deploy our models on the client-side. Whereas browser cookies often contain simple information such as identities, etc., we imagine an implementation using models such as the ones we have demonstrated which can augment the cookie data with intentional data. (See [5] for more details).
For example, Google now employs a feature called  X  X eb history X , which auto-matically collects and stores on central servers the en tire clickstream of partic-ipating users. Presumably, some users would be more comfortable than others, and our methods show how to learn useful models from such data which can be deployed client-side on users who do not participate in such collection. We demonstrated very effective product cat egory level purchase prediction mod-els (regardless of the site of purchase) fo r user-centric clic kstream data. Com-parison experiments show that the such m odels strongly outperform site-centric models, and predictions can be made ahead of time. Our models are fully au-tomatable, and can be thought of as key enabling functionality for a  X  X mart cookie X  mechanism which could be deployed client-side and therefore would mit-igate privacy concerns. It is worth noting that the baseline we established, the site-centric view of the search engine Google, was, by industry standards, quite good at predicting. Nevertheless, the u ser-centric models we created were able to outperform that important baseline by wide margins.

