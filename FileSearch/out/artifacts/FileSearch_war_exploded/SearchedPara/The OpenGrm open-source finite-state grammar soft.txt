 The OpenGrm libraries 1 are a (growing) collec-tion of open-source software libraries for build-ing and applying various kinds of formal gram-mars. The C++ libraries use the OpenFst library 2 for the underlying finite-state representation, which allows for easy inspection of the resulting grammars and models, as well as straightforward combination with other finite-state transducers. Like OpenFst, there are easy-to-use command line binaries for fre-quently used operations, as well as a C++ library interface, allowing library users to create their own algorithms from the basic classes and functions pro-vided.

The libraries can be used for a range of com-mon string processing tasks, such as text normal-ization, as well as for building and using large sta-tistical models for applications like speech recogni-tion. In the rest of the paper, we will present each of the two libraries, starting with the Thrax grammar compiler and then the NGram library. First, though, we will briefly present some preliminary (infor-mal) background on weighted finite-state transduc-ers (WFST), just as needed for this paper. A weighted finite-state transducer consists of a set of states and transitions between states. There is an initial state and a subset of states are final. Each tran-sition is labeled with an input symbol from an input alphabet; an output symbol from an output alpha-bet; an origin state; a destination state; and a weight. Each final state has an associated final weight. A path in the WFST is a sequence of transitions where each transition X  X  destination state is the next transi-tion X  X  origin state. A valid path through the WFST is a path where the origin state of the first transition is an initial state, and the the last transition is to a final state. Weights combine along the path according to the semiring of the WFST.

If every transition in the transducer has the same input and output symbol, then the WFST represents a weighted finite-state automaton. In the OpenFst library, there are a small number of special sym-bols that can be used. The symbol represents the empty string, which allows the transition to be tra-versed without consuming any symbol. The  X  (or failure) symbol on a transition also allows it to be traversed without consuming any symbol, but it dif-fers from in only allowing traversal if the symbol being matched does not label any other transition leaving the same state, i.e., it encodes the semantics of otherwise , which is useful for language models. For a more detailed presentation of WFSTs, see Al-lauzen et al. (2007). The Thrax grammar compiler 3 compiles grammars that consist of regular expressions, and context-dependent rewrite rules, into FST archives (fars) of weighted finite state transducers. Grammars may be split over multiple files and imported into other grammars. Strings in the rules may be parsed in one of three different ways: as a sequence of bytes (the default), as utf8 encodings, or accord-ing to a user-provided symbol table. With the --save symbols flag, the transducers can be saved out into fars with appropriate symbol tables.
The Thrax libraries provide full support for dif-ferent weight (semiring) classes. The command-line flag --semiring allows one to set the semiring, currently to one of: tropical (default), log or log64 semirings. 3.1 General Description Thrax revolves around rules which, typically, con-struct an FST based on a given input. In the simplest case, we can just provide a string that represents a (trivial) transducer and name it using the assignment operator: pear = "pear"; In this example, we have an FST consisting of the characters  X  X  X ,  X  X  X ,  X  X  X , and  X  X  X  in a chain, assigned to the identifier pear :
This identifier can be used later in order to build further FSTs, using built-in operators or using cus-tom functions: kiwi = "kiwi"; fruits = pear | kiwi; # union In Thrax, string FSTs are enclosed by double-quotes ( " ) whereas simple strings (often used as pathnames for functions) are enclosed in single-quotes (  X  ).
Thrax provides a set of built-in functions that aid in the construction of more complex expres-sions. We have already seen the disjunction  X  |  X  in the previous example. Other standard regular op-erations are expr* , expr+ , expr? and expr { m,n } , the latter repeating expr between m and n times, inclusive. Composition is notated with  X  X  X  so that expr1 @ expr2 denotes the composition of expr1 and expr2 . Rewriting is denoted with  X : X  where expr1 : expr2 rewrites strings that match expr1 into expr2 . Weights can be added to expres-adds weight 2.4 to expr . Various operations on FSTs are also provided by built-in functions, includ-ing Determinize , Minimize , Optimize and Invert , among many others. 3.2 Detailed Description A Thrax grammar consists of a set of one or more source files, each of which must have the extension .grm . The compiler compiles each source file to a single FST archive with the extension .far . Each grammar file has sections: Imports and Body, each of which is optional. The body section can include statements interleaved with functions, as specified below. Comments begin with a single pound sign (#) and last until the next newline. 3.2.1 Imports
The Thrax compiler compiles source files (with the extension .grm ) into FST archive files (with the extension .far ). FST archives are an Open-Fst storage format for a series of one or more FSTs. The FST archive and the original source file then form a pair which can be imported into other source files, allowing a Python-esque include system that is hopefully familiar to many. Instead of working with a monolithic file, Thrax allows for a modular con-struction of the final rule set as well as sharing of common elements across projects. 3.2.2 Functions
Thrax has extensive support for functions that can greatly augment the capabilities of the language. Functions in Thrax can be specified in two ways. The first is inline via the func keyword within grm files. These functions can take any number of input arguments and must return a single result (usually an FST) to the caller via the return keyword: func DumbPluralize[fst] { } Alternatively, functions can be written C++ and added to the language. Regardless of the func-tion implementation method (inline in Thrax or subclassed in C++), functions are integrated into the Thrax environment and can be called directly by using the function name and providing the necessary arguments. Thus, assuming someone has written a function called NetworkPluralize that retrieves the plural of a word from some web-site, one could write a grammar fragment as follows: 3.2.3 Statements
Functions can be interleaved with grammar state-ments that generate the FSTs that are exported to the FST archive as output. Each statement consists of an assignment terminating with a semicolon:
Statements preceded with the export keyword will be written to the final output archive. Statements lacking this keyword define temporaries that be used later, but are themselves not output.
 The basic elements of any grammar are string FSTs, which, as mentioned earlier, are defined by text enclosed by double quotes ( " ), in contrast to raw strings, which are enclosed by single quotes (  X  ). String FSTs can be parsed in one of three ways, which are denoted using a dot (.) followed by ei-ther byte , utf8 , or an identifier holding a symbol ta-ble. Note that within strings, the backslash character ( \ ) is used to escape the next character. Of partic-ular note,  X  \ n X  translates into a newline,  X  \ r X  into a line feed, and  X  \ t X  into the tab character. Literal left and right square brackets also need escaping, as they are used to generate symbols (see below). All other characters following the backslash are unin-terpreted, so that we can use \  X  and \  X  to insert an actual quote (double) quote symbol instead of termi-nating the string.

Strings, by default, are interpreted as sequences of bytes, each transition of the resulting FST corresponding to a single 1-byte character of the input. This can be specified either by leaving off the parse mode ( "abc" ) or by explicitly using the byte mode ( "abc".byte ). The second way is to use UTF8 parsing by using the special keyword, e.g.:
Finally, we can load a symbol table and split the string using the fst field separator flag (found in fst/src/lib/symbol-table.cc ) and then perform symbol table lookups. Symbol ta-bles can be loaded using the SymbolTable built-in function:
One can also create temporary symbols on the fly by enclosing a symbol name inside brackets within an FST string. All of the text inside the brackets will be taken to be part of the symbol name, and future encounters of the same symbol name will map to the same label. By default, la-bels use  X  X rivate Use Area B X  of the unicode ta-ble (0x100000 -0x10FFFD), except that the last two code points 0x10FFFC and 0x10FFFD are reserved for the  X  X BOS] X  and  X  X EOS] X  tags discussed below. 3.3 Standard Library Functions and Built-in functions are provided that operate on FSTs and perform most of the operations that are available in the OpenFst library. These include: closure, con-catenation, difference, composition and union. In most cases the notation of these functions follows standard conventions. Thus, for example, for clo-sure, the following syntax applies: fst* (accepts fst 0 or more times); fst+ (accepts fst 1 or more times); fst? (accepts fst 0 or 1 times) fst { x,y } (accepts fst at least x but no more than y times).

The operator  X  X  X  is used for composition: a @ b denotes a composed with b . A  X : X  is used to de-note rewrite , where a : b denotes a transducer that deletes a and inserts b . Most functions can also be expressed using functional notation:
The delimiters &lt; and &gt; add a weight to an expres-sion in the chosen semiring: a &lt; 3 &gt; adds the weight 3 (in the tropical semiring by default) to a .
Functions lacking operators (hence only called by function name) include: ArcSort , Connect , Determinize , RmEpsilon , Minimize , Optimize , Invert , Project and Reverse .
 Most of these call the obvious underlying OpenFst function.

One function in particular, CDRewrite is worth further discussion. This function takes a transducer and two context acceptors (and the alphabet ma-chine), and generates a new FST that performs a context dependent rewrite everywhere in the pro-vided contexts. The context-dependent rewrite algo-rithm used is that of Mohri and Sproat (1996), and see also Kaplan and Kay (1994). The fourth argu-ment ( sigma star ) needs to be a minimized ma-chine. The fifth argument selects the direction of rewrite; we can either rewrite left-to-right or right-to-left or simultaneously. The sixth argument selects whether the rewrite is optional.

For context-dependent rewrite rules, two built-in symbols  X  X BOS] X  and  X  X EOS] X  have a special mean-ing in the context specifications: they refer to the beginning and end of string, respectively.

There are also built-in functions that perform other tasks. In the interest of space we concentrate here on the StringFile function, which loads a file consisting of a list of strings, or tab-separated pairs of strings, and compiles them to an acceptor that represents the union of the strings.
 While it is equivalent to the union of the individual string (pairs), StringFile uses an efficient algo-rithm for constructing a prefix tree (trie) from the list and can be significantly more efficient than com-puting a union for large lists. If a line consists of a tab-separated pair of strings a , b , a transducer equiv-alent to Rewrite[a, b] is compiled.

The optional keywords byte (default), utf8 or the name of a symbol table can be used to specify the parsing mode for the strings. Thus would parse a sequence of tab-separated pairs, using utf8 parsing for the left-hand string, and the symbol table my symtab for the right-hand string. The OpenGrm NGram library contains tools for building, manipulating and using n -gram language models represented as weighted finite-state trans-ducers. The same finite-state topology is used to en-code raw counts as well as smoothed models. Here we briefly present this structure, followed by details on the operations manipulating it.
 An n -gram is a sequence of n symbols: w 1 ...w n . Each state in the model represents a prefix history of the n -gram ( w 1 ...w n  X  1 ), and transitions in the model represent either n -grams or backoff transi-tions following that history. Figure 1 lists conven-tions for states and transitions used to encode the n -grams as a WFST.
 This representation is similar to that used in other WFST-based n -gram software libraries, such as the AT&amp;T GRM library (Allauzen et al., 2005). One key difference is the implicit representation of &lt; s &gt; and &lt; /s &gt; , as opposed to encoding them as symbols in the grammar. This has the benefit of including all start and stop symbol functionality while avoiding common pitfalls that arise with explicit symbols.
Another difference from the GRM library repre-sentation is explicit inclusion of failure links from states to their backoff states even in the raw count files. The OpenGrm n -gram FST format is consis-tent through all stages of building the models, mean-ing that model manipulation (e.g., merging of two (a) (b) models or count files, or pruning them) can be pro-cessed by the same operations. By convention, all counts and probabilities are stored as negative logs, and the FSTs are in the Tropical semiring. The sym-bol table provided during counting is kept with the model FSTs. 4.1 N-gram Counting The command line binary ngramcount takes as input an FST archive (far) consisting of a collection of acyclic WFSTs and outputs an n -gram WFST of the specified order. The acyclic WFSTs can be linear automata representing strings from a corpus  X  easily compiled using the farcompilestrings com-mand of OpenFst  X  or weighted word lattices output from, say, a speech recognition or machine transla-tion system. In such a way, expected frequencies of n -grams can be counted. To count all trigrams, bi-grams and unigrams in the compiled (far) corpus:
For example, counting with the -order=2 flag (bigrams) from a corpus consisting of a single string  X  a b a b b a  X  yields the FST in Figure 2(a). Each state represents a prefix history: the leftmost tory; the central state is the unigram state, represent-ing the history; the topmost state represents the his-tory  X  X  X ; and the bottom state represents the history  X  X  X . Since this is a bigram model, histories consist of at most one prior symbol from the vocabulary. Dou-ble circles represent final states, which come with a final weight encoding the negative log count of end-ing the string at that state. Only the  X  X  X  history state and the unigram state are final states, since our ex-ample string ends with the symbol  X  X  X . (The unigram state is always final.) The transitions are backoff transitions, and the weights on each n -gram transi-tion are negative log counts of that symbol occurring following the history that the state represents. Hence the bigram  X  b b  X  occurs once, yielding a negative log of zero for the transition labeled with  X  X  X  leaving the state representing the history  X  X  X . 4.2 N-gram Model Parameter Estimation Given counts, one can build a smoothed n -gram model by normalizing and smoothing, which is ac-complished with the ngrammake command line binary. The library has several available smooth-ing methods, including Katz (1987), absolute dis-counting (Ney et al., 1994), Kneser-Ney (1995) and (the default) Witten-Bell (1991). See Chen and Goodman (1998) for a detailed presentation of these smoothing methods. Each of these smoothing meth-ods is implemented as a relatively simple derived subclass, thus allowing for straightforward exten-sion to new and different smoothing methods. To make a smoothed n -gram model from counts:
Figure 2(b) shows the model built using the de-fault Witten-Bell smoothing from the count FST in 2(a). The topology remains identical, but now the n -gram transition weights and final weights are neg-ative log probabilities. The backoff transitions (la-beled with ) have the negative log backoff weights, which ensure that the model is correctly normalized.
Models, by default, are smoothed by interpolat-ing higher-and lower-order probabilities. This is even true for methods more typically associated with backoff (rather than mixture) smoothing styles, such as Katz. While the smoothing values are estimated using interpolation, the model is encoded as a back-off model by pre-summing the interpolated proba-bilities, so that the backoff transitions are to be tra-versed only for symbols without transitions out of the current state. While these backoff transitions are labeled with , see Section 4.4 for discussion of ap-plying them as failure transitions. 4.3 N-gram Model Merging and Pruning Two n -gram count FSTs or two model FSTs can be merged into a single FST using ngrammerge , with command line flags to allow for scaling of each of the two, and to indicate whether to carry out full nor-malization. This approach allows for various sorts of MAP adaptation approaches for the n -gram models (Bacchiani et al., 2006). To merge two input FST models with no scaling:
N-gram model pruning is provided with three dif-ferent methods: count pruning based on a threshold; the method from Seymore and Rosenfeld (1996); and relative entropy pruning of Stolcke (1998). Like smoothing, each of these pruning methods is imple-mented as a relatively simple derived subclass, thus allowing for straightforward extension to new and different pruning methods. To prune a smoothed n -gram model: 4.4 N-gram Utilities In addition to the above detailed core operations on language models, the OpenGrm NGram library has a number of utilities that make building and using the models very easy. There are utilities related to input and output, including ngramsymbols , which produces a symbol table from a corpus; ngramread , which reads in textual count files and models in ARPA format and encodes them as an FST; ngramprint which prints n -gram counts or ARPA format text files; and ngraminfo which displays information about the model, such as number of n -grams of various orders. There are also utilities related to the use of the models, including ngramapply , which applies the model to an input FST archive (far); ngramrandgen which randomly generates strings from the model; and ngramperplexity which calculates the per-plexity of a corpus given the model. Note that ngramapply includes options for interpreting the backoff transitions as failure transitions.
 This work was supported in part by a Google Fac-ulty Research Award, NSF grant #IIS-0811745 and DARPA #HR0011-09-1-0041. Any opinions, find-ings, conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the NSF or DARPA.
