 Zhengyu Ou, Ge Yu, Yaxin Yu, Shanshan Wu, Xiaochun Yang, and Qingxu Deng applications, such as traffic monitoring, production controlling, military commanding, worthless. In this paper, we focus on deadline scheduling problem dealing with such applications. in query processing [3,4]. However, those approaches will introduce great scheduling overheads, especially when dealing with bursty streams. minimizing the number of tasks that miss their deadlines. These strategies commonly based on task at a time; thus, they also have the deficiency of high system overheads. adaptive batch maintenance mechanism is deployed for such adaptivity. the conclusion is given in Section 6. definition of tick . Finally, we present the performance metric. data stream as follows. bound is U Q , the deadline of the tuple processed by query Q is  X  x + U Q . 
Here, a tuple processed by a query Q is called to be a task. We assume each query has an input tuple queue, hence, each query corresponds to a task queue. Moreover, in a DSMS, queries are continuous where a query is executed whenever new data applications is to process as many tasks as possible within the deadlines. rapid speed of data stream, different data may be generated in the same time interval  X  same query. We call the data generated in the same interval a tick batch and partition query are called tick queues. hence, each tick batch in the tick queues correspond to a batch of tasks. measured by deadline-missed ratio ( DMR ) in traditional real-time systems. The DMR is defined as the ratio: the number of tasks missed their deadlines to the total number of the tasks. And the total number of the tasks is usually a known constant. However, as we discussed above, an unbounded continuous query corresponds to an unbounded task stream. Therefore we will define DMR over stream as follows:  X  query, the larger w i . result, the less DMR , the better the system performance. Figure 1 illustrates the architecture of TS scheduler, which includes mainly four components: tick queues , tick monitor, adaptive maintenance , and TBS ( tick -based batch scheduling) scheduler . 
We now describe the tick -based batch scheduling (TBS) strategy designed in TBS scheduler. 3.1 TBS Strategy As we can see from Figure 1, TBS scheduler include three components: batch task queues , DMR , priority computation . However, statistic computation and load shedder are also components of TBS scheduler. deficiency to system performance and are excluded by the scheduler. As we discussed above, tuples in the same tick of the tick queues has the same deadline. We timestamp every ticks in the tick queues with their deadlines and obtain batch task queues. The main steps of the tick -based batch-scheduling algorithm can be described as follows. Step1: Call the priority computation to compute the highest priority batch task. tasks in the batch task could be processed before the deadline and sample the batch task accordingly. Step3: Send the batch task to the query engine. 
Step4: After the batch task is processed, modify DMR, delete the batch task and inform the tick queues. from the batch queues and inform the tick queues. Step6: If new ticks insert the tick queues, modify the batch task queues. reduces the system overheads such as scheduling overhead (including maintenance of Section 1, statistic computation is ill suit to precise deadline scheduling. Hence, TBS* strategy is designed to address the problem. 3.2 TBS* Strategy tasks, the deadline comes. We call the k is the critical point of the batch task. point scheduling (in other words, process exactly the tasks in the batch task before the need to check the currently existing batch tasks at the very beginning of every second. miss the deadline during the second. At the very beginning of every tick, tick monitor scheduler is the combination of tick monitor and TBS scheduler. batching, as will greatly cutt down the DMR . 3.3 TS Strategy all the tasks in the coming batch task arrives. In other words, although there may exist strict system resources are wasted, especially when dealing with time-varying, bursty data streams. We propose adaptive maintenance mechanism to solve the problem. Here, TS scheduler is the combination of adaptive maintenance and BTS scheduler. The main steps of adaptive maintenance are as follows: Take the arrived tasks in each batch task queue as whole batch tasks (to make difference, namely fragment batch task). And then call BTS* algorithm to process the fragment batch tasks. Loop until there exist batch tasks in the batch task queues or the tick monitor is activated. As a result, TS strategy can make full use of strict system resources, and shows great adaptivity to the changing characteristics of data streams. In this section, we propose experimental results to compare the performance between the deadline scheduling strategies over data streams including task at a time (TAAT) policy, TBS, TS. Due to lack of space, we only give the experiments that highlight the efficiency and effectiveness of the TS strategy. 4.1 Experimental Setup and the Implementing Details In our experimental evaluation, we simulated the execution of a continuous query as in [9]. Where the query is specified by two parameters: depth and fan-out. The depth of the query specifies the number of levels in the query tree and the fan-out specifies Intel machine with P4 2.0GHz CPU, 512MB main memory. 4.2 Performance Evaluation system overhead. Besides, the overhead of TS is a bit more than TBS owning to the of scheduling overhead. overheads of the three methods may decrease accordingly. This is because the average tuple arrival rate increases together with the increasing skewness. And when the rate exceeds the capacity of the system, the tasks missing the deadlines are dropped. While accordingly, the overhead over the tasks meeting their deadline will decrease. Hence, before the skewness increases to 0.4, the TAAT has underlined overheads in that the increasing rate does not saturate system load unless the skewness is larger than 0.4. processing, which contributes more to the DMR than their difference of the overhead policy. Hence, TBS and TS policies are more adaptive to high load. continuous queries pose great challenges to the existing data processing techniques. In this paper, we address the fixed time scheduling problem over data streams. For the goal of adapting to the time varying data arrival-rate, we further improve TS proposed TS policy.

