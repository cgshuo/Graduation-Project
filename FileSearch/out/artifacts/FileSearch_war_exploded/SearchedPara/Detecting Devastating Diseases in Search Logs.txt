 Web search queries can o  X  er a unique population-scale win-dow onto streams of evidence that are useful for detecting the emergence of health conditions. We explore the promise of harnessing behavioral signals in search logs to provide advance warning about the presence of devastating diseases such as pancreatic cancer. Pancreatic cancer is often diag-nosed too late to be treated e  X  ectively as the cancer has usually metastasized by the time of diagnosis. Symptoms of the early stages of the illness are often subtle and nonspe-cific. We identify searchers who issue credible, first-person diagnostic queries for pancreatic cancer and we learn mod-els from prior search histories that predict which searchers will later input such queries. We show that we can infer the likelihood of seeing the rise of diagnostic queries months be-fore they appear and characterize the tradeo  X  between pre-dictivity and false positive rate. The findings highlight the potential of harnessing search logs for the early detection of pancreatic cancer and more generally for harnessing search systems to reduce health risks for individuals.
 Health screening; Search logs; Behavioral data; Digital dis-ease detection; Pancreatic cancer; Temporal analysis
Web search is a primary resource for people concerned about the significance of health-related symptoms [16]. Re-searchers have studied symptom and illness-related searches in pursuit of insights about how people search about health concerns, including patterns of querying and review of in-formation in pursuit of diagnoses [54], healthcare utilization signals [55], traces of therapeutic decision making for chal-lenging illnesses [40], and identification of new adverse ef-fects of medications [56, 57]. Prior studies have examined how population-level signals in social media can be used to detect the emergence of diseases [10, 19].  X  Figure 1: Venn diagram depicting sets of users employed in analyses: pancreatic cancer searchers ( A ), pancreatic cancer searchers exhibiting experiential diagnostic queries ( B ), and those who search for the symptoms of pancreatic cancer ( C ). | A [ C | (i.e., number of users in original, pre-filtered dataset) is 9.2 million. Positives and negatives are sourced from B \ C and C \ A , respectively. Relative set sizes are not to scale.
We explore the prospect of harnessing anonymized long-term sequences of health-related search queries to yield in-formation that could provide valuable signals for detection of illness in advance of traditional diagnosis. Leveraging on-line behavioral data to provide earlier detection of a disease or of the raised risk of illness on a large scale can make sig-nificant contributions to healthcare. Better outcomes can be achieved by earlier confirmation of illnesses and risks via gaining access to more timely diagnoses, treatments, and other proactive interventions. As an example, such capabil-ities might help to identify those at significant risk of suf-fering the onset of advance of chronic disease processes such as diabetes or heart disease or the rise of acute processes such as atrial fibrillation or more severe cardiac arrhyth-mias. Interventional programs ranging from changes in diet or exercise to taking (or avoiding) certain medications can yield significant health benefits.

The diagnosis for certain medical conditions can be par-ticularly devastating if the chances of survival are typically low at the time of diagnosis. Survival rates may be improved significantly via earlier detection and treatment. With many cancers, screening methods can be e  X  ective for early de-tection and therapy [41], but they involve explicit testing prompted by policies around risk factors such as family his-tory [33] or medical history [14, 32]. Ideally, health screen-ing systems would be able to observe people passively as they engage in their normal activities and alert them (per their preferences on vigilance) to potential health risks with-out requiring the investment of time and e  X  ort in special screening activities. Individual-level postings on social me-dia have been mined for this purpose [10, 46], but may not have representative coverage of symptoms associated with social stigma [11].

We present a study of the feasibility of doing early de-tection of devastating diseases based on large-scale logs of health-related Web search activity. We consider the content of queries over time, and the prospect that temporal rela-tionships and patterns among queries over multiple sessions over several months provide subtle fingerprints of lurking illness. We focus on the early detection of the presence of pancreatic cancer, a devastating diagnosis given the typical progression of the disease to an inoperable situation by the time it is found. Our work showcases the potential value of innovative approaches for speeding up the time to diagnosis of this deadly disease.

Pancreatic cancer is the fourth leading cause of cancer death in men and women in the United States and the sixth leading cause in Europe [36]. The illness is widely known as being di cult to detect and is frequently diagnosed too late to be treated e  X  ectively [22, 30]. A recent study found that the progression of pancreatic cancer from stage I to stage IV happens in just over one year [59]. Approximately 75% of pancreatic cancer patients die within a year of di-agnosis, and only about 4% survive for five years post di-agnosis. Exploration of the possibility that a patient has pancreatic cancer involves a careful and costly considera-tion of history, labwork, and imaging studies (in contrast to the passive screening methods described in this paper) [45]. Screening is largely performed to detect the disease at an early phase (pre-invasive or early invasive) when it is still curable by surgical intervention and chemotherapy. Earlier diagnosis of pancreatic cancer improves the feasibility of dis-covering the illness at an earlier stage [7]. For patients diag-nosed early who undergo curative surgery (e.g., a Whipple procedure), five-year survival rate is higher, but it remains less than 25% [58].

We take as a proxy for ground truth of a diagnosis of pan-creatic cancer the detection of experiential diagnostic queries issued by searchers. Experiential queries show strong evi-dence of being linked to the actual presence of symptomatol-ogy or conditions versus less directly involved, more distant exploratory queries seeking information about symptoms or diseases [40]. Experiential diagnostic queries for pancreatic cancer are identified via consideration of the structure of queries and of patterns of information gathering over mul-tiple users in search logs. Experiential queries often include first-person assertions such as [ iwasjustdiagnosedwithpan-creatic cancer ], which when associated with prior queries about symptoms identifies the positive cases.

We construct models to predict the future rise of experi-ential queries from longitudinal search data. Figure 1 shows the di  X  erent subsets of users in our analysis, including peo-ple who search for pancreatic cancer ( A ), the subset of these searchers who issue experiential diagnostic queries ( B ), and those who search for a set of symptoms linked to pancreatic cancer ( C ). Those who only search for one or more related symptoms with no evidence of pancreatic cancer searching constitute the negative cases. We find that our methods can detect cases where people show evidence of being diagnosed with pancreatic cancer many months in advance of their ex-periential diagnostic queries.

We make the following contributions with this research:  X  Introduce early detection of diseases as a promising new  X  Present a case study on the early detection of pancre- X  Forecast with significant lead times that users will later  X  Explore the influence of di  X  erent factors, such as the We now describe related research in this important area.
Related research in a number of areas is relevant to our work. These include (i) health searching; (ii) large-scale analysis of search behavior; and (iii) methods for the early detection of disease, with a focus on pancreatic cancer.
The Web is an important source of health-related infor-mation for many people. To better understand how peo-ple pursue health information, studies have examined online health search using a variety of methods, including inter-views [42], surveys [49], and analyses of large-scale search log data [2, 5]. According to a 2013 survey, 59% of Amer-ican adults had used the Web to find health information in the year preceding the survey, 35% of those adults en-gaged in self-diagnosis, and over half of these self-diagnosing searchers then discussed the matter with a clinician follow-ing the search [16]. Despite the potential benefits, concerns have been raised about the quality of online health infor-mation [8]. In a large-scale survey of the use of search for self-diagnosis, White and Horvitz [53] found that almost 40% of participants experienced increased anxiety from searching health information online. Studies have characterized prob-lems with symptom search, including the influence of poor accounting for base rates of diseases and people X  X  bias to focus on results covering serious illnesses versus more likely benign explanations. Such biases can lead to inappropriate anxiety [28, 53] and highlight the criticality of studying how patients use the Web, including the nature and dynamics of queries, and content delivered in response.

There has been a large amount of research on the analy-sis of search behavior from search engine logs. Log analysis provides insights to understand how people engage in in-formation seeking in online settings [51], while also having applications for tasks such as result ranking [1, 24], query suggestion [25], prediction of future search actions and in-terests [13, 27], and detection of real-world events and ac-tivities [44]. Given access to population-scale data on how people search for health information, this can be applied for important tasks such as the detection of influenza [19], the detection of adverse drug reactions [56], population-scale studies of nutrition [50], epidemiology [19], and studies of chronic medical conditions such as pregnancy [15]. Related to this research, but focused on activity post-diagnosis, are studies of cancer-related searching [3, 6, 21], some of which have revealed strong similarities between temporal patterns in search logs and those in practice [38, 40]. Studies have leveraged online behavioral signals for early disease detec-tion at the population level [19], and individually [11, 46].
Screening high-risk individuals for pancreatic cancer is the only practical approach to detect precancerous or cancerous changes in the pancreas at the phase in which surgical in-tervention will have a high chance of cure [26]. Risk level can be determined by factors such as race [9], family his-tory [33], and a history of pancreatitis [32]. Imaging studies via methods such as endoscopic ultrasound, computer to-mography scans, and magnetic resonance imaging [35, 37] have been useful to diagnose pancreatic cancer once the tumor is large enough to cause unusual, salient symptoms that induce people to seek medical attention (e.g., yellow eyes, changes in stool), but at this point the disease is more likely to be at an advanced and unresectable stage (i.e., lo-cally advanced or metastatic, when it cannot be removed by surgery) [29]. Common, seemingly innocuous symptoms such as back pain, abdominal pain, itchy skin, unexplained weight loss and nausea (and combinations and temporal pat-terns of these and other symptoms) may also be observed in the query stream. Such symptom searches can provide pat-terns of symptoms that might one day be employed in new kinds of health surveillance systems. Such systems could be used to alert people who would otherwise not feel moved to see a healthcare professional.

Active, explicit screening for early signs of pancreatic can-cer is not cost e  X  ective unless there is a reasonable proba-bility of detecting invasive or pre-invasive disease (at least 16% according to one study [45]). A log-based methodology provides scale that is not achievable with more traditional epidemiological studies, which tend to be on the order of tens or hundreds of participants, e.g., [23, 43].
We now describe the data used, starting with a description of the logs (Section 3.1). We then discuss the creation of an ontology with symptoms commonly experienced by people with pancreatic cancer (Section 3.2) and provide details on extracting pancreatic cancer and symptom searchers (Sec-tion 3.3). We review the augmentation, tagging, and filter-ing steps for our dataset (Section 3.4). Finally, we summa-rize the creation of query timelines for the positive cases (i.e., experiential diagnostic searchers who also search for pancre-atic cancer symptoms) and the negative cases (i.e., those who only search for the symptoms) (Section 3.5). Since re-liable labels cannot be determined for the non-experiential pancreatic cancer searchers, we exclude them to create a cleaner dataset for training and testing. We show later (see Section 5.6) that predictive performance is largely un-changed if these searchers are included as negative examples during the application of the model in a realistic scenario.
Search engines track various characteristics during their interaction with users so as to better capture information needs, improve their responses, and personalize the content. Every such interaction corresponds to a log entry that in-cludes a unique, anonymized user identifier based on a Web browser cookie. This enables the extraction of the search history comprising queries and clicks from an identifier for up to 18 months. Note that the identifier may comprise the search activity of multiple users on shared machines and does not consolidate activity from a user across multiple machines. We use the logs of a randomly-selected subset of Bing search engine users in the English-speaking United States locale from October 2013 to May 2015 inclusive.
Warning signs and symptoms for pancreatic cancer usu-ally include generic, subtle signs and symptoms, such as abdominal and back pain, loss of appetite, and unexplained weight loss. We performed an extensive review of possible signs, symptoms, and risk factors associated with pancre-atic cancer and developed an ontology with 21 categories of symptoms. This manually-curated ontology consists of two levels. The first level includes the names of the symptoms and the second level includes multiple names, synonyms, and expressions with which the corresponding symptom in the first level may appear in our data. We performed multiple iterations of refinements of this ontology to remove noise and to minimize erroneous query matches. Table 1 presents the 21 symptom categories with some representative examples of associated query expressions. Also shown are 12 risk fac-tors and associated synonyms, derived from the literature (e.g., [31]), describing attributes, characteristics, or expo-sures that may increase the likelihood of pancreatic cancer. The symptoms and the risk factors are featurized in predic-tive models, and they are also used in policies to determine when predictive models should be applied (see Section 5.5).
In order to identify positive and negative cases for the generation of our learned model, we built a dataset com-prising two groups of users (Figure 1). The pancreatic can-cer searchers group, denoted as A in the figure, includes all searchers with at least one query explicitly on pancreatic cancer (i.e., a query matches this expression [( X  X ancreas X  OR  X  X ancreatic X ) AND  X  X ancer X  X ). The symptom searchers group, denoted as C , includes all users with at least one query re-lated to symptoms linked to pancreatic cancer, as captured by the symptoms and synonyms described in Section 3.2.
Having unique identifiers for each user in the union of A and C (i.e., A [ C ) permits the extraction of the full query histories of 9 . 2 million searchers. We first sought to remove searchers who are likely healthcare professionals (HCPs). To do this, we employed a proprietary Bing classifier that iden-tifies health-related queries to remove users from the study for whom 20% or more of queries are health related. This threshold was based on a prior analysis of identifying health professionals in search logs [52].
Age and gender are important factors associated with de-veloping pancreatic cancer [31, 36]. As such, we augmented the dataset with demographic information from proprietary search engine classifiers that estimate age (discretized as &lt; 18, 18 X 24, 25 X 34, 35 X 50, or 50 X 85) and the gender for each user. The classifiers are trained on data where ground truth of demographic details are provided explicitly by users. The predictions are based on signals derived from searchers X  long-term search activity, including their search queries and Web domains of their clicked results. Since pancreatic cancer in-cidence rates vary by geographic location, we also annotated searchers with the U.S. state from which they searched most (based on reverse Internet provider (IP) lookup data).
Beyond the demographic information, we are also inter-ested in the subject matter of the queries and results that were visited over searchers X  timelines. We augmented each query and corresponding clicked websites with their esti-mated Open Directory Project (ODP, dmoz.org) category. We used a text-based classifier, similar to [4], that uses lo-gistic regression to predict the ODP categories. When op-timized for the score in each category, this classifier has a micro-averaged F1 score of 0 . 60. For queries, the ODP cat-egory is that of the top-ranked search result. The remaining users after the augmentation and filtering steps total 7 . 4mil-lion, from which 479 , 787 are pancreatic cancer searchers.
We create query timelines for experiential pancreatic can-cer searchers and experiential symptom searchers which we then featurize for the early detection task. Figure 2 summa-rizes the strategies for identifying positives and negatives. To avoid including users with very short histories, we filter out all users with less than five search sessions 1 spanning five di  X  erent days. This reduced the population to 6.4 million users, with a mean total duration (time from first to last query for a user) of 210.32 days, standard deviation (SD) of 182.93 days, and interquartile range of 120 days. Positive Cases: To identify experiential pancreatic cancer users, we created a set of first-person diagnostic queries for pancreatic cancer (denoted Exp 0 ). Some examples of such diagnostic queries are [ just diagnosed with pancreatic can-cer ], [ why did i get cancer in pancreas ], and [ iwastoldi have pancreatic cancer what to expect ].

From the set of 479 , 787 pancreatic cancer searchers, 3 , 203 match the pattern of diagnostic queries. In order to consider them as experiential users, we require them to have searched at least for one symptom prior to the diagnosis query. This Figure 2: Schematic illustration of the query timelines used in the selection of positive and negative cases. S 0 refers to the first symptom query and Exp 0 is the first experiential diagnostic query.  X  is the duration of the symptom lookup period, which was approximately equal in the aggregate for the positives and negatives. is the duration of the period of diagnosis, set to one week in this study. step generates a set of 1 , 072 query timelines of experiential searchers that contain periods of symptom lookup followed by the diagnostic query. The symptom lookup period starts when the first symptom is detected as matching terms rep-resented in the symptom ontology. For positive cases, the symptom lookup period completes at least one week before diagnosis (i.e., we consider the week before the diagnostic query as the period of diagnosis in real life and do not count queries in that time since they may be polluted with ground truth signals). For reliability, especially given the need to compute Temporal features (Section 4.2), the minimum time period for which our features are computed is four weeks. Negative Cases: To generate the negative set, we sample from the users who searched for pancreatic cancer symptoms but did not search for pancreatic cancer anywhere in their timeline (i.e., C \ A ), either before or after the symptom lookup period. Performing this additional check on data Table 2: Summary statistics, namely, mean ( M ), standard deviation ( SD ), and number of cases ( N ), of durations and numbers of queries in positive and negative datasets. from outside the lookup period is required to increase the likelihood that the negative cases are indeed negative. Users who searched for pancreatic cancer and its symptoms, but did not issue an experiential query (the gray subset in Fig-ure 1 representing ( A \ C ) \ B ), were excluded since a label could not be reliably determined. In Section 5.6 we describe an additional experiment where pancreatic cancer searchers were included during model testing.

We were concerned that rudimentary behavioral di  X  er-ences that may reflect artifacts in the data could invalidate the learning task. For example, if our experiential users were just more active generally, then a feature that computed the total number of queries would have strong predictive value, yet would be uninteresting scientifically. We sought to ad-dress this by downsampling the negative cases to attain a similar distribution of symptom lookup periods in terms of the temporal duration and query volume as observed for the positive cases. 2 We did this by selecting users with a symptom lookup period duration within three standard de-viations of the mean of the positive cases. This reduces the number of negative cases to 3,025,046. Table 2 presents the summary statistics on the symptom lookup periods in terms of the number of days and the number of queries in the two datasets. The table shows that the distributions for positive and negative cases (in terms of number of days and number of queries) are similar. The distributions are statistically in-distinguishable using two-sample Kolmogorov-Smirnov tests for temporal duration ( D =0 . 005; p =0 . 7017) and number of queries ( D =0 . 003; p =0 . 7681), even though the latter was not a filtering criterion. We note that query timelines are not aligned: the absolute point in time where people is-sue the experiential diagnostic query, and the accompanying symptom lookup period can di  X  er between searchers.
We now present the problem, summarize features extracted from query timelines, and review the prediction model.
We address the problem of early detection of experien-tial searchers for pancreatic cancer via anonymized Web search engine logs. We cast this as a binary classification task, where the model is trained on features extracted from search log query timelines of experiential pancreatic cancer searchers and symptom-only searchers. We focus on main-taining very low false-positive rates (i.e., 1 misprediction in 100k correctly identified cases) while keeping high the imbal-ance ratio of positive and negative cases (i.e., one thousand positives vs. millions of negative cases); these properties are important for potential future large-scale real-world appli-cations such as an alerting mechanism in search engines.
We now describe the features extracted from query time-lines. We group our features into five di  X  erent categories: (i) demographic information about the user; (ii) characteris-tics about user sessions, query classes, and URL classes; (iii) characteristics about symptoms; (iv) features that capture the temporal dynamics, and (v) risk factors.
 Demographics: Cancer statistics from the U.S. National Cancer Institute 3 show that pancreatic cancer is more com-mon with increasing age, is slightly more common in men than in women, and varies by geographic location. As such, we develop features related to the demographics of the users. In particular, we use the estimated age bucket and gender (see Section 3.4) along with the classifier X  X  probabilities as confidence values. The dominant location (U.S. state) of a searcher is also included as a feature.
 Search Characteristics: People express their information needs and preferences through queries and click behavior (i.e., the website visits). We extract various features to cap-ture these search and retrieval activities. As we discussed previously, the queries, as well as the visited websites, were tagged with their ODP category in an attempt to identify domains of interest (see Section 3.4). A first set of fea-tures SearchHistory contains several generic statistics, such as counts, ratios, and percentages, which are characteristics of the global behavior of the user. For example, we compute the number of queries, sessions, and clicks, as well as ratios of clicks per query for each user. Then, we compute a large number of features with respect to the ODP categories of queries QueryTopic , clicked search results URLTopic , and the combination QueryURLTopic . These include compute counts and percentage of queries and sessions in each ODP category, the average time until queries appear in the same category, as well as the time of the day that queries appear in each category. Similar features are also computed for each category of the visited websites (e.g., counts, ratios, and per-centages of visited websites that belong to each category). We additionally compute features to characterize the user sessions, including features that capture the click behavior of users associated with queries. For example, we compute counts and percentages of all the combinations of query cat-egories that led to visits in website categories. Symptoms: Features described above attempt to capture generic characteristics from user sessions. However, for the problem of interest, we seek to also leverage features from queries containing terms captured in the symptom ontology for pancreatic cancer (Section 3.2). The symptom features are divided into two classes: (i) SymptomGeneric and (ii) SymptomSpecific . Generic symptom features contain counts and percentages for the queries and sessions matching symp-toms in our ontology, the average time between symptom queries, as well as the average number of symptom queries that are issued daily. Specific symptom features are gener-ated per symptom category. For example, for each symptom, we compute counts and percentages of appearance, the time between distinct symptoms, and the time of day such symp-tom queries are issued. As with the user session features, we combine symptoms to capture the click behavior and, hence, we compute counts and percentages of each symptom query leading to a visit on a website belonging to particular ODP categories. Finally, we define features that capture the se-Table 3: Performance at four-week intervals for users where features can be computed from Exp 0  X 1weekto Exp 0  X  21 weeks. Values averaged across the ten folds of cross-validation. The significance of di  X  erences in AUROC and TPR using paired t -tests for each week versus Exp 0  X 1 indicated * p&lt; 0 . 01, ** p&lt; 0 . 001, and *** p&lt; 0 . 0001. Weeks denote lead time before Exp 0 ( in Figure 2). quence in which symptoms appear in query timelines. Temporal: All previous features produce aggregated statis-tics over the full time window under consideration. Follow-ing [34], we include a set of features to capture the temporal variation of these statistics over misaligned query timelines with noise and missing values. For every feature, we gen-erate a time series with points that represent aggregated values for intervals of the time window. For example, each feature can be computed per month, per week, or per day, depending on the level of granularity we seek to capture. Since the occurrence of specific features can be sparse, we set the time window to four weeks for temporal features. For features that are not percentages or ratios, we also compute the cumulative time series. For each time series, we use the first coe cient of the linear least-square estimates to devise features that capture the trend (i.e., increasing, decreasing, and unchanged) and the rate of change (i.e., slope). Risk Factors: This class contains features related to the presence of terms representing risk factors in the symptom lookup period. For each risk factor, we note its presence or absence, and also the number of queries containing that risk factor and the fraction of all queries from that user that these risk factor queries represents. Total number of distinct risk factors in the symptom lookup period is also a feature.
The prediction model uses the features outlined in the previous section, computed for each searcher, to make pre-dictions about the future occurrence of experiential diag-nostic searches in each searcher X  X  query timeline. We use gradient boosted trees [17], which employ an ensemble of decision trees to construct a better learned model. Advan-tages include the ability to capture non-linear relationships, model interpretability (e.g., a ranked list of important fea-tures is generated), facility for rapid training and testing, and robustness against noisy labels and missing values. We experimented with di  X  erent learning algorithms, but gradi-ent boosted trees yielded superior accuracy.
We now present the findings of our experiments. We re-port the overall performance in Section 5.1 and the per-formance as we increase the lead time before the first ex-periential diagnostic query (Section 5.2). We then inspect the model to understand the contributions that each fea-ture makes towards early detection (Section 5.3) and the performance of di  X  erent feature classes (Section 5.4). We examine the e  X  ect on model performance of conditioning on symptoms and risk factors (Section 5.5) and consider a re-alistic deployment scenario (Section 5.6). We use the area Figure 3: Average partial ROC curves in the FPR range 0 X 0.01, for models learned using data up to 21 weeks before the first experiential diagnostic query (error bars excluded for clarity). Variance in FPR and TPR is minor. under the receiver operating characteristic curve (AUROC) and recall (TPR, true positive rate) at fixed, extremely low false positive rates (FPRs) as our primary evaluation met-rics. We applied 10-fold cross validation, stratified by user to evaluate the generalizability of the model when applied to new users. Significance level is p&lt; 0 . 05 unless stated.
The overall performance of the classifier in making pre-dictions based on data up to the beginning of the period of diagnosis (i.e., Exp 0  X 1week)inAUROCis0.9003.Given that low error rates would be vital in practice to avoid un-necessary patient alarm, we focus on the true positive rate (fraction of all positives that are recalled by the model) at low false positive rates (FPR). Focusing on FPR in the range 0.00001 X 0.01, the model is able to recall 5 X 30% of the posi-tive cases, depending on the specific FPR. We see this perfor-mance as promising given the limited information (primarily search-related activity) available to the model.
A key part of early detection is being able to predict the emergence of the disease well in advance. To understand how prediction performance changed as we move further back in time before the first experiential diagnostic query we se-lected the set of 337 positive searchers and 945,394 negative searchers who were still observed in the logs many weeks prior to the experiential diagnostic query. We report results from one week before the experiential diagnostic query, all the way up to 21 weeks before the diagnostic query. To count as being present at Exp 0  X  21 weeks, a searcher needs to have symptom queries extending back at least four weeks before that point (i.e., to Exp 0  X  25 weeks, or approximately six months before the first experiential diagnostic query).
We trained a model for these users in the same way as we did for Section 5.1. The ratio between positive and neg-ative searchers remains similar to that for all users (i.e., approximately 1:3000). Table 3 reports the TPR at di  X  er-ent false positive rates for this same set of users at di  X  erent four-week increments, as well as the AUROC. The general trend is that the performance drops fairly consistently as we increase the lead time, but even 20 or so weeks before the first experiential diagnostic query the predictive perfor-Table 4: Top 10 features by evidential weight relative to the top feature.  X  X ositive X  or  X  X egative X  direction means that a feature correlates positively or negatively, respectively, with the rise of experiential queries.
 mance is still quite strong (AUROC=0.8315, TPR=6.528% at FPR=0.00001). Assuming that pancreatic cancer pro-gresses steadily from stage I to stage IV in just over one year (as has been previously reported [59]), accurate predic-tions 20 weeks in advance of the diagnostic period could lead to a sizable increase in the five-year survival rate (e.g., mov-ing the point of diagnosis from Stage III to Stage II could increase the survival rate from 3% to 5 X 7% [47]).
Focusing on the FPR region from 0 to 0.01 (i.e., false pos-itives occur less than 1 in 100 times) and visualizing that part of the ROC curve (Figure 3) we observe some clear di  X  erences in the performance of the models in this impor-tant region. The average normalized partial AUROC ranges from 0.292 ( Exp 0  X 1week)to0.231( Exp 0  X 21weeks).All di  X  erences in AUROC for Exp 0  X  5 or more weeks versus Exp 0  X  1 week are significant ( p&lt; 0 . 01 using paired t -tests).
In addition to understanding the overall performance, we are also interested in understanding the features that are most important in the learned model for predicting the fu-ture issuance of experiential queries. Table 4 shows the top 10 features with the highest weight, along with their weight relative to the top-ranked feature ( NumOfDistinct-Symptoms ) and the feature class. The direction is based on the correlation between the feature value and the labels in the training data, using Pearson biserial correlation or the phi coe cient, depending on whether or not the fea-ture data is binary. Table 4 shows that there is a broad range of features. The number of distinct pancreatic cancer symptoms was the most important feature. Temporal fea-tures representing changes over time and sequence ordering of symptom pairs are also important. Age is important, and it is positively correlated if the searcher is older and is neg-atively correlated if they are younger. Individual symptom features related to back pain and indigestion are important but have a negative influence on predicting future experien-tial queries, likely because (i) there are many explanations for why these symptoms appear in a query timeline, and (ii) they are positive for many negative cases (16.7% of negatives search for back pain, 7.4% search for indigestion).
Beyond the individual features, we can also consider the accuracy of the models based on feature classes. This can be particularly important when some classes of features are easy to obtain in practice, e.g., the demographic features may be available for all searchers without the need to per-form temporal modeling of query patterns. Table 5 presents the AUROC for models trained on each of the feature classes. The findings show that the Temporal class is particularly im-portant, signifying the key role of temporal dynamics for this prediction task. The model is still accurate solely with access Table 5: Performance of individual feature classes (as AU-ROC and TPR at a FPR of 0.00001) averaged across the 10 experimental folds. The performance di  X  erences against the Overall performance are statistically significant using paired t -tests at * p&lt; 0 . 01, ** p&lt; 0 . 001, and *** p&lt; 0 . 0001. to demographics and basic features about general searching. However, performance improves considerably if we consider the specifics of the symptoms searched ( SymptomSpecific )or the topics of the queries and results clicked ( QueryTopic ).
We also considered the impact of the presence of symp-toms and risk factors on the performance of the model.  X  Symptoms : We filtered the positive and negative cases to  X  Risk factors : These are risk factors corresponding to the Recall that our cross-validation was stratified by user. Dur-ing cross validation, we learned a model on the users in the training folds and then for testing we limited to users with evidence of the specific symptoms or risk factors in their search history prior to the experiential diagnostic query. In each case the number of positives and negatives is less than the full set. 4 Table 6 presents statistics on the performance for each model where the number of positive examples was at least 10 (to help ensure that AUROC calculations were meaningful). The table also presents TPRs at di  X  erent false positive rates, as well as the percentage of positive or neg-ative cases that have the symptom or risk factor searches. Finally, the last three columns shows the estimated num-ber of true positives (capture) and false positives (cost) that would be observed, assuming a FPR of 0.00001, and the as-sociated capture-cost ratio. Ideal targets for rates of capture versus cost in a deployed service can be derived via a deci-sion analysis that considers the net expected value of the early detection and the expected costs of unnecessary anxi-ety. Such an optimization would leverage a careful charac-terization of the value of early intervention and details of designs of methods for engaging people.

Table 6 shows that focusing on users who search for risk factors such as smoking, hepatitis, and obesity leads to bet-ter overall performance. There were fewer than ten users searching for each of the cancer syndromes (e.g., hereditary nonpolyposis colorectal cancer) and, hence, they were ex-cluded from Table 6. Focusing on the percentage of posi-tives and negatives that contain each of the symptoms or risk factors, we observe that there are some that are much more likely to occur in positives (e.g., pancreatitis and smok-ing are 5.9 and 3.6 times as likely, respectively). Focusing on the utility, we find that if we set the FPR to 0.00001, overall we would find 52 positives in the union of positives and negatives at the expense of 30 negatives, who would be altered mistakenly. There are some symptoms and risk factors for which the capture-cost is more favorable. For ex-ample, in the case of alcoholism or obesity, we would find 20 X 30 times as many TPs as FPs. There are others symp-toms such as nausea or vomiting, or chills or fever, where the costs in mistakenly alerting users equal or outweigh the ben-efits. Presence of symptoms or risk factors could help decide whether to apply early detection models for a searcher.
Up to now, our model considers experiential diagnostic users as positives and symptom-only users as negatives. This is a clean dataset for algorithm training and testing but it ignores the symptom searchers who issue non-experiential pancreatic cancer searches (gray region in Figure 1). These users may have been diagnosed or may simply be exploring. Regardless, they should be considered in practice.
We perform an additional experiment on a separate set of symptom searchers that included non-experiential pancre-atic cancer searchers as negatives. We trained a model on all data described thus far and applied it to identify (i) expe-riential and (ii) experiential+treatment users in a new held out dataset in advance of their first experiential diagnostic query. We generated the test set from logs of a separate randomly selected subset of Bing users, over an 18-month period from August 2014 to January 2016 inclusive. There was no overlap in users with the set used for training. We identified positive cases as earlier and expanded the defi-nition of negatives to include pancreatic cancer searchers. This resulted in 2.9 million negatives, including 48,221 non-experiential pancreatic cancer searchers, and 945 experien-tial searchers with preceding symptom searches. To help target the identification of cases where experiential queries are issued, we created a subset of the positives who issued treatment-related queries following Exp 0 (e.g., whipple pro-cedure, 5-fu); in total, 494 users (52%) met this requirement. Table 7: Average AUROC and average TPR (as %) at FPR=0.00001 for identifying experiential users and experi-ential+treatment users from held out dataset. Di  X  erences in AUROC and TPR between Exp 0  X  1 week and other weeks noted (*** p&lt; 0 . 001, ** p&lt; 0 . 001, and * p&lt; 0 . 01). The symptom lookup durations for positives and negatives were similar to Section 3.5. We randomly split the test data into ten equally-sized subsets for significance testing. Table 7 reports the predictive performance at di  X  erent lead times.
Table 7 shows that the performance of the model remains strong on this held-out set and is comparable to that re-ported in the earlier sections. The performance decreases with increased lead time as noted previously (see Table 3). Interestingly, the performance in identifying the subset of experiential diagnostic users who subsequently searched for treatments is higher than for the experiential-only set. This is promising confirmatory evidence as these users are as-sumed to have experienced a cancer diagnosis, per defini-tions of experiential queries [40]. 5
We studied the potential feasibility of learning from search engine logs to predict future issuance of experiential queries about pancreatic cancer at a low error rate. The success of these methods has implications for online methods that would provide passive screening of searchers to provide early warning about potential signs of pancreatic cancer and other devastating diseases. We discovered that conditionalization on di  X  erent symptoms and risk factors can enhance predic-tive power. We found capture-cost tradeo  X  s associated with di  X  erent symptoms and risk factors in terms of the total number of truly positive cases identified versus the number of searchers who would be mistakenly alerted. We charac-terized model performance as we increase lead time and we found that we can attain a TPR in region of 5 X 30%, while controlling the FPR to 0.00001 X 0.01 months before a di-agnostic query is observed. Looking forward, we seek to un-derstand the costs and clinical significance of these methods, including how they might o  X  er early warning of devastating disease onset to enhance outcomes (e.g., quality of life).
Despite the promising findings, we note several important limitations. First, we lack explicit ground truth about di-agnoses per the anonymity of our logs. We rely on models of self-reporting in queries. We have found that streams of queries following the experiential queries can provide confir-matory evidence of pancreatic cancer diagnoses. Indeed, in the weeks immediately following the experiential diagnostic query, over 40% of searchers queried for treatment options, with many using sophisticated terminology (e.g., Whipple procedure, pancreaticoduodenectomy, neoadjuvant therapy) and over 20% of searchers searched for pancreatic cancer medications (e.g., gemcitabine, 5-fu). In contrast, only 0.5% and 0.02% of searchers in our negative set searched for treat-ments and medications, respectively, at any point in their query timeline. We need to work with diagnosed patients to understand (i) the relationship between experiential search-ing and diagnosis; and (ii) the model performance with the use of traditional data as ground truth about diagnoses (e.g., medical records). We also need to understand the role of factors such as race [9], family history [33], medical his-tories [32], diabetes [14], and other factors (e.g., smoking [18]). Some of these can be crudely estimated from geo-graphic and census data (race), whereas others (family and medical histories) are best sought from searchers directly. To reflect anticipated performance in a natural setting, we fo-cused on our imbalanced dataset. We re-ran the analysis with a balanced set, with highly similar results. Finally, we note that this is a retrospective analysis for model train-ing/testing and we need to consider its representativeness for real-time screening, e.g., identifying negative cases in the retrospective study relies on symptom lookup durations. Po-tential additional analyses include explorations of predicting on fixed dates versus at the end of the observation period.
We are interested in several research directions. We be-lieve it would be valuable to collect ground truth data, e.g., via targeted surveys, where responses and electronic health records could be linked (given consent) to long-term search activity. There is opportunity to develop more sophisticated time-series models and with applying our methods to other diseases. We leave to future reflection and e  X  orts the de-sign of methods for fielding the methods. We seek to engage with the medical community on directions for deploying the technology. In a recent sister publication, we shared these findings with practicing oncologists [39]. For real-world de-ployment, we need to consider whether online services would wish to provide individuals with early warnings about un-diagnosed diseases given false positive rates, anxiety and associated costs of ruling out illness, privacy implications, and liability concerns. Beyond alerting searchers, a system could provide summaries of symptom searches as talking points for dialog with a medical professional, or contact a physician on the individual X  X  behalf. One could imagine ser-vices enabling users to opt-in to such screening programs with appropriate education and caveats about false-positive rates and their associated costs. In another approach, mod-els could be trained from anonymized data yet fielded in a private manner, e.g., as an application on a searcher X  X  smartphone. Future work should consider the value of the search-centric analyses in the context of more traditional screening methods such as direct (active) cancer screening. Larger designs would consider how the search-based meth-ods could be integrated with traditional screening to develop a more cost-e  X  ective screening program. Such work would require a careful consideration of the accuracies and costs of pre-screening and screening and the expected benefits of increased rates of survival associated with di  X  erent policies. [1] E. Agichtein, E. Brill, and S. Dumais. Improving web [2] S. L. Ayers and J. J. Kronenfeld. Chronic illness and [3] J. L. Bader and M. F. Theofanos. Searching for cancer [4] P. Bennett, K. Svore, and S. Dumais. Classification [5] E. V. Bernstam, J. R. Herskovic, and W. R. Hersh. [6] K. Castleton et al. A survey of internet utilization [7] S. T. Chari et al. Early detection of sporadic [8] R. J. Cline and K. M. Haynes. Consumer health [9] S. S. Coughlin et al. Predictors of pancreatic cancer [10] M. De Choudhury, S. Counts, and E. Horvitz.
 [11] M. De Choudhury, M. R. Morris, and R. W. White. [12] E. R. DeLong, D. M. DeLong, and D. L.
 [13] D. Downey, S. T. Dumais, and E. Horvitz. Models of [14] J. Everhart and D. Wright. Diabetes mellitus as a risk [15] A. Fourney, R. W. White, and E. Horvitz. Exploring [16] S. Fox and M. Duggan. Health online 2013, 2013. [17] J. H. Friedman. Greedy function approximation: A [18] C. S. Fuchs et al. A prospective study of cigarette [19] J. Ginsberg et al. Detecting influenza epidemics using [20] A. M. Goldstein et al. Increased risk of pancreatic [21] P. R. Helft. Patients with cancer, internet information, [22] R. H. Hruban et al. Progression model for pancreatic [23] R. Huxley et al. Type-II diabetes and pancreatic [24] T. Joachims. Optimizing search engines using [25] R. Jones et al. Generating query substitutions. [26] J. Klapman and M. P. Malafa. Early detection of [27] T. Lau and E. Horvitz. Patterns of search: Analyzing [28] C. Lauckner and G. Hsieh. The presentation of [29] P. Legmann et al. Pancreatic tumors: comparison of [30] D. Li et al. Pancreatic cancer. The Lancet ,363(9414): [31] A. B. Lowenfels and P. Maisonneuve. Epidemiology [32] A. B. Lowenfels et al. Pancreatitis and the risk of [33] H. T. Lynch et al. Familial pancreatic cancer: A [34] K. McKeown et al. Predicting the impact of scientific [35] H. R. Mertz et al. EUS, PET, and CT scanning for [36] D. Michaud. Epidemiology of pancreatic cancer. [37] M. M  X  uller et al. Pancreatic tumors: Evaluation with [38] Y. Ofran et al. Patterns of information-seeking for [39] J. Paparrizos, R. W. White, and E. Horvitz. Screening [40] M. J. Paul, R. W. White, and E. Horvitz. Search and [41] M. S. Pepe et al. Phases of biomarker development for [42] G. Peterson, P. Aslani, and K. A. Williams. How do [43] A. G. Renehan et al. Body-mass index and incidence [44] M. Richardson. Learning about the world from [45] S. J. Rulyak et al. Cost-e  X  ectiveness of pancreatic [46] A. Sadilek, H. Kautz, and V. Silenzio. Modeling spread [47] American Cancer Society. Staging pancreatic cancer. [48] G. Talamin et al. Alcohol and smoking as risk factors [49] M. I. Trotter and D. W. Morgan. Patients X  use of the [50] R. West, R. W. White, and E. Horvitz. From cookies [51] R. White and S. Drucker. Investigating behavioral [52] R. W. White et al. Toward enhanced [53] R. W. White and E. Horvitz. Cyberchondria: Studies [54] R. W. White and E. Horvitz. Studies of the onset and [55] R. W. White and E. Horvitz. From health search to [56] R. W. White et al. Web-scale pharmacovigilance: [57] R. W. White et al. Early identification of adverse drug [58] C. J. Yeo et al. Pancreaticoduodenectomy for [59] J. Yu et al. Time to progression of pancreatic ductal
