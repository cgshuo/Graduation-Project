
Information Engineering Building, Dept. of Eng. Science, P arks Road, Oxford, OX1 3PJ, UK Multi-frame image super-resolution refers to the process b y which a group of images of the same scene are fused to produce an image or images with a higher spa tial resolution, or with more visible detail in the high spatial frequency features [7]. Such prob lems are common, with everything from holiday snaps and DVD frames to satellite terrain imagery pr oviding collections of low-resolution images to be enhanced, for instance to produce a more aesthet ic image for media publication [15], or for higher-level vision tasks such as object recognition or localization [5].
 Limits on the resolution of the original imaging device can b e improved by exploiting the relative sub-pixel motion between the scene and the imaging plane. No matter how accurate the registration estimate, there will be some residual uncertainty associat ed with the parameters [13]. We propose a scheme to deal with this uncertainty by integrating over the registration parameters, and demonstrate improved results on synthetic and real digital image data.
 Image registration and super-resolution are often treated as distinct processes, to be considered se-quentially [1, 3, 7]. Hardie et al. demonstrated that the low-resolution image registration c an be updated using the super-resolution image estimate, and tha t this improves a Maximum a Posteriori (MAP) super-resolution image estimate [5]. More recently, Pickup et al. used a similar joint MAP approach to learn more general geometric and photometric re gistrations, the super-resolution image, and values for the prior X  X  parameters simultaneously [12]. Tipping and Bishop X  X  Bayesian image super-resolution work [16] uses a Maximum Likelihood (ML) point estimate of th e registration pa-rameters and the camera imaging blur, found by integrating t he high-resolution image out of the registration problem and optimizing the marginal probabil ity of the observed low-resolution images directly. This gives an improvement in the accuracy of the re covered registration (measured against known truth on synthetic data) compared to the MAP approach.
 The image-integrating Bayesian super-resolution method [ 16] is extremely costly in terms of com-putation time, requiring operations that scale with the cub e of the total number of high-resolution pixels, severely limiting the size of the image patches over which they perform the registration (they use 9  X  9 pixel patches). The marginalization also requires a form of prior on the super-resolution image that renders the integral tractable, though priors su ch as Tipping and Bishop X  X  chosen Gaus-sian form are known to be poor for tasks such as edge preservat ion, and much super-resolution work has employed other more favorable priors [2, 3, 4, 11, 14].
 It is generally more desirable to integrate over the registr ation parameters rather than the super-resolution image, because it is the registration that const itutes the  X  X uisance parameters X , and the super-resolution image that we wish to estimate. We derive a new view of Bayesian image super-resolution in which a MAP high-resolution image estimate is found by marginalizing over the uncertain registration parameters. Memory requirements a re considerably lower than the image-integrating case; while the algorithm is more costly than a s imple MAP super-resolution estimate, it is not infeasible to run on images of several hundred pixels i n size.
 Sections 2 and 3 develop the model and the proposed objective function. Section 4 evaluates re-sults on synthetically-generated sequences (with ground t ruth for comparison), and on a real data example. A discussion of this approach and concluding remar ks can be found in section 5. The generative model for multi-frame super-resolution ass umes a known scene x (vectorized, size then added to y ( k ) , Photometric parameters  X   X  for each low-resolution pixel, in the frame of the super-res olution image [2, 3, 16]. The PSF is usually assumed to be an isotropic Gaussian on the imaging pl ane, though for some motion models ( e.g. planar projective) this does not necessarily lead to a Gauss ian distribution on the frame of x . For an individual low-resolution image, given registratio ns and x , the data likelihood is When the registration is known approximately, for instance by pre-registering inputs, the uncertainty can be modeled as a Gaussian perturbation about the mean esti mate  X   X  ( k ) for each image X  X  parameter set, with covariance C , which we restrict to be a diagonal matrix, A Huber prior is assumed for the directional image gradients Dx in the super-resolution image x (in the horizontal, vertical, and two diagonal directions) , where  X  is a parameter of the Huber potential function, and  X  is the prior strength parameter. This belongs to a family of functions often favored over Gaussian s for super-resolution image priors [2, 3, 14] because the Huber distribution X  X  heavy tails mean ima ge edges are penalized less severely. The difficulty in computing the partition function Z as in [16], though for the MAP image estimate, a value for this scale factor is not required. Regardless of the exact forms of these probability distribu tions, probabilistic super-resolution algo-rithms can usually be interpreted in one of the following way s.
 The most popular approach to super-resolution is to obtain a MAP estimate, typically using an iterative scheme to maximize p x y ( k ) ,  X  ( k ) ,  X  ( k ) with respect to x , where and the denominator is an unknown scaling factor.
 Tipping and Bishop X  X  approach takes an ML estimate of the reg istration by marginalizing over x , then calculates the super-resolution estimate as in (9). Wh ile Tipping and Bishop did not include a photometric model, the equivalent expression to be maximiz ed with respect to  X  and  X  is Note that Tipping and Bishop X  X  work does employ the same data likelihood expression as in (3), which forced them to select a Gaussian form for p ( x ) , rather than a more suitable image prior, in order to keep the integral tractable.
 Finally, in this paper we find x through marginalizing over  X  and  X  , so that a MAP estimate of x can be obtained by maximizing p x y ( k ) directly with respect to x . This is achieved by finding and  X   X  from image points [6], and the diagonal matrix C is constructed to reflect the confidence in each parameter estimate. This might mean a standard deviation of a tenth of a low-resolution pixel on image translation parameters, or a few gray levels X  shift on the illumination model, for instance. The integral performed is where  X  T =  X  (1) T ,  X  (2) T , . . . ,  X  ( K ) T and all the  X  and  X  parameters are functions of  X  as in (4). Expanding the data error term in the exponent for each lo w-resolution image as a second-order Taylor series about the estimated geometric registration p arameter yields Values for F , G and H can be found numerically (for geometric registrations) or a nalytically (for the photometric parameters) from x and n y ( k ) ,  X  ( k ) ,  X  ( k ) f , becomes where the omission of image superscripts indicates stacked matrices, and H is therefore a block-diagonal nK  X  nK sparse matrix, and V is comprised of the repeated diagonal of C .
 Finally, letting S =  X  The objective function, L , to be minimized with respect to x is obtained by taking the negative log of (12), using the result from (18), and neglecting the const ant terms: This can be optimized using Scaled Conjugate Gradients (SCG) [9], noting that the gradient can be expressed where derivatives of F , G and H with respect to x can be found analytically for photometric pa-to the geometric parameters. 3.1 Implementation notes Notice that the value F from (16) is simply the reprojection error of the current est imate of x at the mean registration parameter values, and that gradients of this expression with respect to the  X  parameters, and with respect to x can both be found analytically. To find the gradient with resp ect to a geometric registration parameter  X  ( k ) scheme involving only the k th image is used.
 Mean values for the registration are computed by standard re gistration techniques, and x is initialized using around 10 iterations of SCG to find the maximum likeliho od solution evaluated at these mean parameters. Additionally, pixel values are scaled to lie be tween  X  1 bounded to lie within these values in order to curb the severe overfitting usually observed in ML super-resolution results.
 In our implementation, the parameters representing the  X  values are scaled so that they share the same standard deviations as the  X  parameters, which represent the sub-pixel geometric regis tration shifts, which makes the matrix V a multiple of the identity. The scale factors are chosen so th at one standard deviation in  X  values by around 10 gray levels at mean image intensity. The first experiment takes a sixteen-image synthetic datase t created from an eyechart image. Data is generated at a zoom factor of 4, using a 2D translation-only m otion model, and the two-parameter global affine illumination model described above, giving a t otal of four registration parameters per low-resolution image. Gaussian noise with standard deviat ion equivalent to 5 gray levels is added to each low-resolution pixel independently. The sub-pixel perturbations are evenly spaced over a grid up to plus or minus one half of a low-resolution pixel, gi ving a similar setup to that described in [10], but with additional lighting variation. The ground truth image and two of the low-resolution images appear in the first row of Figure 1.
 Geometric and photometric registration parameters were in itialized to the identity, and the images were registered using an iterative intensity-based scheme . The resulting parameter values were used to recover two sets of super-resolution images: one using th e standard Huber MAP algorithm, and the second using our extension integrating over the registr ation uncertainty. The Huber parameter  X  was fixed at 0 . 01 for all runs, and  X  was varied over a range of possible values representing rati os between  X  and the image noise precision  X  .
 The images giving lowest RMS error from each set are displaye d in the second row of Figure 1. Visually, the differences between the images are subtle, th ough the bottom row of letters is better defined in the output from the new algorithm. Plotting the RMS E as a function of  X  in Figure 2, we see that the proposed registration-integrating approac h achieves a lower error, compared to the ground truth high-resolution image, than the standard Hube r MAP algorithm for any choice of prior strength,  X  in the optimal region. Figure 1: (a) Ground truth image. Only the central recoverab le part is shown; (b,c) low-resolution images. The variation in intensity is clearly visible, and t he sub-pixel displacements necessary for multi-frame image super-resolution are most apparent on th e  X  X  X  characters to the right of each im-age; (d) The best ( X .e. minimum MSE  X  see Figure 2) image from t he regular Huber MAP algorithm, having super-resolved the dataset multiple times with diff erent prior strength settings; (e) The best result using out approach of integrating over  X  and  X  . As well as having a lower RMSE, note the improvement in black-white edge detail on some of the letter s on the bottom line.
 The second experiment uses real data with a 2D translation mo tion model and an affine lighting model exactly as above. The first and last images appear on the top row of Figure 3. Image regis-tration was carried out in the same manner as before, and the g eometric parameters agree with the provided homographies to within a few hundredths of a pixel. Super-resolution images were created Figure 2: Plot showing the variation of RMSE with prior stren gth for the standard Huber-prior MAP super-resolution method and our approach integrating over  X  and  X  . The images corresponding to the minima of the two curves are shown in Figure 1 for a number of  X  values, the equivalent values to those quoted in [3] were fou nd subjectively to be the most suitable.
 experiments. Finally, Tipping and Bishop X  X  method was exte nded to cover the illumination model and used to register and super-resolve the dataset, using th e same PSF standard deviation ( 0 . 4 low-resolution pixels) as the other methods.
 The three sets of results on the real data sequence are shown i n the middle and bottom rows of Figure 3. To facilitate a better comparison, a sub-region of each is expanded to make the letter details clearer. The Huber prior tends to make the edges unna turally sharp, though it is very suc-registration-integrating approach, the text appears more clear in our method, and the regularization in the constant background regions is slightly more success ful. It is possible to interpret the extra terms introduced into t he objective function in the derivation of this method as an extra regularizer term or image prior. Co nsidering (19), the first two terms are identical to the standard MAP super-resolution problem using a Huber image prior. The two additional terms constitute an additional distribution ov er x in the cases where S is not dominated by V ; as the distribution over  X  and  X  tightens to a single point, the terms tend to constant values . The intuition behind the method X  X  success is that this extra prior resulting from the final two terms of (19) will favor image solutions which are not acutely sens itive to minor adjustments in the image registration. The images of figure 4 illustrate the type of so lution which would score poorly. To create the figure, one dataset was used to produce two super-r esolved images, using two independent sets of registration parameters which were randomly pertur bed by an i.i.d. Gaussian vector with a standard deviation of only 0 . 04 low-resolution pixels. The checker-board pattern typical of ML super-resolution images can be observed, and the differenc e image on the right shows the drastic contrast between the two image estimates. Figure 3: (a,b) First and last images from a real data sequenc e containing 10 images acquired on a rig which constrained the motion to be pure translation in 2D . (c) The full super-resolution output from our algorithm. (d) Detailed region of the central lette rs, again with our algorithm. (e) Detailed region of the regular Huber MAP super-resolution image, usi ng parameter values suggested in [3], which are also found to be subjectively good choices. The edg es are slightly artificially crisp, but the large smooth regions are well regularized. (f) Close-up of l etter detail for comparison with Tipping and Bishop X  X  method of marginalization. The Gaussian form o f their prior leads to a more blurred 5.1 Conclusion This work has developed an alternative approach for Bayesia n image super-resolution with several advantages over Tipping and Bishop X  X  original algorithm. T hese are namely a formal treatment of registration uncertainty, the use of a much more realistic i mage prior, and the computational speed The results on real and synthetic images with this method sho w an advantage over the popular MAP approach, and over the result from Tipping and Bishop X  X  m ethod, largely owing to our more favorable prior over the super-resolution image.
 It will be a straightforward extension of the current approa ch to incorporate learning for the point-spread function covariance, though it will result in a less s parse Hessian matrix H , because each row and column associated with the PSF parameter(s) has the p otential to be full-rank, assuming a common camera configuration is shared across all the frames.
 Finally, the best way of learning the appropriate covarianc e values for the distribution over  X  given the observed data, and how to assess the trade-off between it s  X  X rior-like X  effects and the need for a standard Huber-style image prior, are still open questions .
 Acknowledgements The real dataset used in the results section is due to Tomas Pa jdla and Daniel Martinec, CMP, Prague, and is available at http://www.robots.ox.ac.uk/ Figure 4: An example of the effect of tiny changes in the regis tration parameters. (a) Ground truth image from which a 16-image low-resolution dataset was gene rated. (b,c) Two ML super-resolution estimates. In both cases, the same dataset was used, but the r egistration parameters were perturbed by an i.i.d. vector with standard deviation of just 0.04 low-resolution pixels. (d) The difference between the two solutions. In all these images, values outsi de the valid image intensity range have been rounded to white or black values.
 This work was funded in part by EC Network of Excellence PASCA L.
 [1] S. Baker and T. Kanade. Limits on super-resolution and ho w to break them. IEEE Transactions [2] S. Borman. Topics in Multiframe Superresolution Restoration . PhD thesis, University of Notre [3] D. Capel. Image Mosaicing and Super-resolution (Distinguished Diss ertations) . Springer, [4] S. Farsiu, M. Elad, and P. Milanfar. A practical approach to super-resolution. In Proc. of the [5] R. C. Hardie, K. J. Barnard, and E. A. Armstrong. Joint map registration and high-resolution [6] R. I. Hartley and A. Zisserman. Multiple View Geometry in Computer Vision . Cambridge [7] M. Irani and S. Peleg. Super resolution from image sequen ces. ICPR , 2:115 X 120, June 1990. [8] M. Irani and S. Peleg. Improving resolution by image regi stration. Graphical Models and [9] I. Nabney. Netlab algorithms for pattern recognition . Springer, 2002. [10] N. Nguyen, P. Milanfar, and G. Golub. Efficient generali zed cross-validation with applications [12] L. C. Pickup, S. J. Roberts, and A. Zisserman. Optimizin g and learning for super-resolution. [13] D. Robinson and P. Milanfar. Fundamental performance l imits in image registration. IEEE [14] R. R. Schultz and R. L. Stevenson. A bayesian approach to image expansion for improved [15] Salient Stills. http://www.salientstills.com/. [16] M. E. Tipping and C. M. Bishop. Bayesian imge super-reso lution. In S. Thrun, S. Becker, and
