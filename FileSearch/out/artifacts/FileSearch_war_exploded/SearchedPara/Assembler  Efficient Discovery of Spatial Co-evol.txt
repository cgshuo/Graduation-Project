 Recent years have witnessed the wide proliferation of geo-sensory applications wherein a bundle of sensors are deployed at different locations to cooperatively monitor the target condition. Given mas-sive geo-sensory data, we study the problem of mining spatial co-evolving patterns (SCPs), i.e. , groups of sensors that are spatially correlated and co-evolve frequently in their readings. SCP mining is of great importance to various real-world applications, yet it is challenging because (1) the truly interesting evolutions are often flooded by numerous trivial fluctuations in the geo-sensory time series; and (2) the pattern search space is extremely large due to the spatiotemporal combinatorial nature of SCP. In this paper, we propose a two-stage method called Assembler . In the first stage, Assembler filters trivial fluctuations using wavelet transform and detects frequent evolutions for individual sensors via a segment-and-group approach. In the second stage, Assembler generates SCPs by assembling the frequent evolutions of individual sensors. Leveraging the spatial constraint, it conceptually organizes all the SCPs into a novel structure called the SCP search tree, which fa-cilitates the effective pruning of the search space to generate SCPs efficiently. Our experiments on both real and synthetic data sets show that Assembler is effective, efficient, and scalable. H.2.8 [ Database Applications ]: Data Mining Sensor network, spatiotemporal data, co-evolving pattern
Wireless sensor network (WSN) has been serving as an indis-pensable tool for our society ever since its advent in the 1970s. In a typical WSN, a bunch of sensors are deployed at different geo-graphical locations to continuously and cooperatively monitor the target condition ( e.g. , air pollution, temperature, traffic volume).
The research was done when the first author was an intern in Mi-crosoft Research under the supervision of the second author. c  X  Spurred by the recent development of urban computing [25], mod-ern geo-sensory applications, ranging from traffic monitoring to environment control, often involve hundreds of sensors, and each sensor can potentially generate millions of records  X  depending on the sampling rate and duration.

While the massive geo-sensory data can be informative multi-facetedly, one particularly important and challenging problem is, how to discover a group of sensors that are spatially correlated and co-evolve frequently in their readings? Let us consider a real-life scenario in Figure 1. As shown, a number of air quality sensors are deployed in Beijing, and every hour, each sensor measures the real-time air quality index (AQI 1 ) around it. The AQI measured by each sensor is stable most of the time, but does change substan-tially during some time intervals  X  which we call evolving inter-vals . During the three evolving intervals marked in Figure 1, one can observe that sensor s 1 , s 2 , and s 3 exhibit a recurring behavior: the AQIs of s 2 and s 3 increase substantially, while the AQI of s drops sharply. Since s 1 ,s 2 , and s 3 are spatially close, it is likely the air pollution is dispersed from s 1 to s 2 and s 3 . According to an investigation into this pattern, the road traffic largely flows from s to { s 2 ,s 3 } during off-work hours, deteriorating the air quality there with heavy emissions.

Given a set S of sensors and their records over n timestamps, we are interested in discovering groups of spatially correlated sen-sors from S , along with their co-evolving behaviors that occur fre-quently in the n timestamps. We call such frequent behaviors spa-tial co-evolving patterns (SCPs for short). The discovery of SCPs has significant impacts on a wide spectrum of applications. Con-tinuing with the above air quality monitoring example, the pattern s 1  X  { s 2 ,s 3 } indicates that air pollution is frequently dispersed from s 1 to s 2 and s 3 . By analyzing the contexts ( e.g. , traffic, weather, social activities) in which the dispersions occur, we can identify the major factors that cause such behaviors and come up with effective strategies to alleviate air pollutant diffusion through-out the city. Another example application is traffic analysis. As-sume we have deployed sensors to monitor the traffic volumes in different regions within a city. If severe traffic jams are often ob-served in a region r , the SCPs among different regions can help us discover the regions from which the traffic tends to flow into r and cause the traffic jam. Such an understanding is very useful for improving road network design and urban planning.

Considering the sheer size of modern geo-sensory systems, min-ing all SCPs from massive geo-sensory data is by no means a triv-ial problem. First, interesting evolutions are often flooded by trivial fluctuations . In practice, each sensor constantly generates measure-ments no matter the condition changes or stays stable, hence the time series is overwhelmed by numerous uninteresting fluctuations.
Larger AQI means more air pollutants and thus worse air quality. Figure 1: The air quality sensors in Beijing and the measurements of sensor s mark three evolving intervals during which the measurements of s ,s , and s 3 change significantly.
 For example, the histogram in Figure 2(a) is obtained from one-year AQI data of the sensor s 1 in Figure 1, by computing the AQI change of every pair of consecutive measurements. We can see the change is highly concentrated on small values. While many of the small values result from random fluctuations and redundant sam-pling, some are caused by slow but long-lasting evolutions (Figure 2(b)). It is important yet challenging to filter uninteresting fluctu-ations and identify evolving intervals in the time series. Second, the pattern search space is extremely large . An SCP can contain an arbitrary number of sensors, and the matching time intervals of an SCP can have quite different durations. The combinatorial na-ture of SCP leads to an exponential pattern search space, calling for novel and efficient pattern search methodologies.
Although multi-dimensional motif discovery techniques [20, 13, 16] have been developed to retrieve recurring subsequences in a bundle of time series, none of them are applicable to SCP min-ing. First, since geo-sensory data typically suffers from redundant sampling, applying motif discovery can only retrieve trivial mo-tifs where the condition shows little change. Second, the matching subsequences of a motif must have the same length, whereas the matching intervals of an SCP usually differ in length due to dura-tion variation of the change. Last, motif discovery overlooks the spatial correlations among the sensors and typically obtains pat-terns that span across all the dimensions. In contrast, SCP mining requires discovering groups of sub-dimensions ( i.e. , sensors) that are spatially correlated and co-evolve frequently.

In this paper, we present Assembler , a two-stage method that can effectively and efficiently discover SCPs from massive geo-sensory data. Assembler first extracts frequent evolutions for each individual sensor, and then finds SCPs by merging the fre-quent evolutions of individual sensors. Our main contributions are summarized as follows. 1. In the first stage of Assembler (Section 3.1), we decom-2. In the second stage of Assembler (Section 3.2), we prove 3. We have conducted extensive experiments on both real-life
Let S = { s 1 ,s 2 ,...,s m } be a set of sensors in a geographical region. Each sensor s i  X  S (1  X  i  X  m ) is deployed at a loca-tion l i to periodically measure the target condition around it. All the sensors in S have synchronized measurements over the time domain T =  X  t 1 ,t 2 ,...,t n  X  , where each t j (1  X  j  X  n ) is a timestamp and all t j  X  X  are equally spaced. The measurement of sensor s i at timestamp t j , denoted by s i [ t j ] , is a real value.
As mentioned earlier, the time series of each sensor often suffers from redundant sampling, i.e. , the time domain T includes many trivial intervals in which the monitored condition shows random and small fluctuations. To obtain meaningful patterns, we are not interested in the entire time domain T , but only demand the inter-vals in which the condition exhibits evident changes.

D EFINITION 1. [Evolving Interval] For sensor s i , a length-l evolving interval I =  X  t j ,t j +1 ,...,t j + l  X  is a consecutive subse-quence in T where the measurement of s i has evident change. The timestamps t j ,...,t j + l  X  1 are called evolving timestamps for s
D EFINITION 2. [Change Rate] Given a sensor s i  X  S and an evolving timestamp t j , the change rate of s i at timestamp t
Note that: (1) Definition 1 provides an informal and intuitive de-scription of evolving interval. Later in Section 3.1.1, we will elabo-rate this definition and show how we define  X  X vident X  changes. (2) Each sensor can have multiple evolving intervals, and the evolving intervals of two different sensors do not necessarily overlap.
One may wonder why not just examine the change rate for ev-ery timestamp in T and extract the timestamps having large change rates to define evolving intervals. The reason is that such a defini-tion tends to miss slow but long-lasting changes: as shown by the example in Figure 3, while both slow and sharp changes are inter-esting evolutions, change rate alone only identifies sharp changes and fails to distinguish slow changes from trivial fluctuations. Figure 3: Trivial fluctuation, slow change, and sharp change in a geo-sensory time series: (1) in [ t 0 ,t 4 ] , the measure shows ran-dom and trivial fluctuations; (2) in [ t 4 ,t 11 ] , the measure shows slow but long-lasting increase; and (3) in [ t 20 ,t 21 ] , the measure increases sharply.

Given the set S of sensors, our goal is to discover a group of sensors from S that are spatially correlated and meanwhile ex-hibit frequent co-evolutions. We define spatial connectivity and co-evolution as follows.

D EFINITION 3. [Spatial Connectivity] Given a distance thresh-old h and a subset of sensors G  X  S , G is spatially connected if  X  s  X  G,  X  s 0  X  G  X  X  s } s.t. dist ( s,s 0 )  X  h where dist ( s,s is the geographical distance between s and s 0 .

D EFINITION 4. [Co-evolution] Let G = { s 1 ,s 2 ,...,s g set of spatially connected sensors. A co-evolution E G over G has the form { R 1 ,R 2 ,...,R g } where each R i = [ lb i ,ub g ) specifies a range of change rate for sensor s i  X  G .
Now we proceed to define the matching relationship between a co-evolution and a timestamp, based on which we define the sup-port of a co-evolution.

D EFINITION 5 (M ATCH ). Let G = { s 1 ,s 2 ,...,s g } be a set of spatially connected sensors and E G = { R 1 ,R 2 ,...,R co-evolution on G . A timestamp t j matches E G , denoted as t E
G , if t j satisfies  X  1  X  i  X  g : (1) t j is an evolving timestamp for sensor s i ; and (2) the change rate of s i at t j falls in the range R i = [ lb i ,ub i ] , namely lb i  X  r i [ t j ]  X  ub i .
 D EFINITION 6 (S UPPORT ). The support of a co-evolution E is the number of its matching timestamps in the time domain T , i.e. , Sup ( E G ) = |{ t j | t j  X  X   X  t j ; E G }| .

If a co-evolution appears frequently in the time domain, we call it a spatial co-evolving pattern (SCP).
 be a co-evolution defined over a set G of spatially connected sen-sors. Given a minimum support  X  , E G is a spatial co-evolving pattern if Sup ( E G )  X   X  .

E XAMPLE 1. In Figure 1, let G = { s 1 ,s 2 ,s 3 } be a set of spa-tially connected sensors. An example co-evolution over G is E
G = { [  X  20 /h,  X  15 /h ] , [+15 /h, +20 /h ] , [+15 /h, +20 /h ] } , meaning the AQI of s 1 is decreasing by 15 to 20 per hour, while the AQIs of s 2 and s 3 are increasing by 15 to 20 per hour. Given a minimum support  X  = 10 , E G is a frequent pattern as it matches 24 evolving timestamps in the 100-hour period.

We are now ready to describe the SCP mining problem: given the sensory data of S over the time domain T , a minimum support  X  , and a distance threshold h , find the groups of spatially connected sensors from S along with their co-evolutions that have support no less than  X  . In this section, we present our two-stage SCP mining method Assembler . In what follows, we describe the detailed two stages in Section 3.1 and 3.2, respectively. Then we discuss the cost of Assembler and its parameter setting in Section 3.3.
In this subsection, we present the first stage of Assembler . It first extracts evolving intervals using wavelet transform, and then detects frequent evolutions for individual sensors.
As mentioned earlier, geo-sensory time series is usually over-whelmed by numerous trivial fluctuations due to redundant sam-pling. To find meaningful SCPs, one first needs to filter uninter-esting fluctuations and identify the evolving intervals, otherwise the result pattern set will be dominated by the trivial fluctuations. However, the condition change can occur with quite different rates and durations: some changes are sharp and short, while some are slow and long-lasting (Figure 3). How can we effectively capture those multi-scale changes in the long geo-sensory time series?
To address this problem, we use wavelet transform to obtain a multi-resolution representation of the time series. As we will see, multi-scale changes appear clearly at different levels in the wavelet space and thus can be easily identified.
 Wavelet transform. Wavelet transform [5] is a multi-resolution signal decomposition tool that provides time and frequency local-ization simultaneously. To decompose the geo-sensory time series, we choose the Haar wavelet transform due to its simplicity and practical effectiveness. Haar wavelet transform relies on a scaling function  X  ( t ) and a mother wavelet function  X  ( t ) :  X  ( t ) =
Given an input signal defined over the range [0 , 1] , the scaling function  X  ( t ) models the average strength of the signal, while the mother wavelet  X  ( t ) models the detailed change of the signal. The mother wavelet function  X  ( t ) can be scaled and shifted to gener-ate a set of orthogonal bases, which capture changes that occur at different resolutions and locations. As a concrete example, Figure 4 shows the Haar wavelet bases for length-8 signals: (1) at level 1,  X  1 , 1 models the change from [ t 1 ,t 4 ] to [ t 5 ,t  X  2 , 1 models the change from [ t 1 ,t 2 ] to [ t 3 ,t 4 ] , and  X  the change from [ t 5 ,t 6 ] to [ t 7 ,t 8 ] ; and (3) at level 3,  X  the change from t 1 to t 2 ,  X  3 , 2 models the change from t
With the Haar wavelet bases, an arbitrary time series s i represented as a linear combination of them, namely where l is the total number of levels, k i is the number of mother wavelets at level i , and c ij is the wavelet coefficient for basis  X  The wavelet coefficients can be efficiently obtained using pair-wise average-difference computation. Specifically, given a length-2 m every two adjacent values ( v 2 j  X  1 ,v 2 j )(1  X  j  X  m ) and compute Here, c j is returned as the wavelet coefficient for interval j at cur-rent level, and the average a j is fed to the next higher level for fur-ther average-difference computation. For instance, Table 1 shows the process of computing the Haar wavelet coefficients for a length-8 signal (1 , 1 , 6 , 8 , 9 , 11 , 15 , 25) .
 Table 1: An illustration for wavelet coefficient computation. Extracting evolving intervals. In the wavelet representation of a signal, the coefficient c ij measures the signal X  X  strength of change in the j -th interval at level i : (1) a large positive c nal decreases significantly in the interval; (2) a large negative c means the signal increases significantly in the interval; and (3) a small absolute value of c ij means the signal does not change much. The level i determines the resolution of observation; while the po-sition j captures where the change occurs.

The above observation leads to our strategy for filtering trivial fluctuations and preserving multi-resolution changes in the geo-sensory time series. As shown in Algorithm 1, given a signal s we obtain its wavelet coefficients and compare them with a change threshold  X  . Specifically, we examine whether the absolute value of c ij is larger than  X  (line 5). If true, we add the corresponding timestamps into the results set T (line 6). The pre-specified thresh-old  X  has a clear physical meaning as it measures how much change reflects a significant and unusual behavior.

It is worth mentioning that, when extracting the evolving inter-vals, we only consider the levels larger than min _ level . This is because the evolving behaviors of sensors are usually caused by external events ( e.g. , air pollutions mostly result from heavy traf-fic, wind, manufacturing activity, etc .) and do not span a very long time period. Our goal is to capture such short-term but frequently occurring changes, not the long-term trend in the geo-sensory data. Hence, we ignore the levels that are too coarse.
Once the evolving intervals have been identified for each sensor s , next task is to detect evolving behaviors that frequently occur. Our observation is that, the evolution of a sensor may experience several different stages during each evolving interval. If we treat each evolving interval as a basic unit, we may not easily observe similar behaviors. However, if we break each interval into several segments,  X  X imilar X  segments from different intervals can consti-tute frequent behaviors.
 Algorithm 1: Evolving interval extraction.
 Input : Geo-sensory time series s i , change threshold  X  .
Output : The set of evolving timestamps in s i .
C  X  Haar wavelet coefficients of s i ;
T  X   X  ; for i = min_level to l do 4 for j = 1 to k i do 5 if | c ij | X   X  then 6 Add into T the timestamps in interval j of level i ; return T ;
As an example, Figure 5 shows two evolving intervals, I 1 I , of a sensor. I 1 and I 2 are clearly dissimilar if we treat each one as a whole. However, suppose we break I 1 into five line segments and I 2 into four, the clusters C 1 ,C 2 ,C 3 ,C 4 become evident. The line segments in each cluster are  X  X imilar X  in the sense that they have very similar slopes.
 Value A segment-and-group approach. The above observation moti-vates us to first partition the evolving intervals into line segments, and then group similar line segments to detect frequent evolutions.
The segmentation of each evolving interval can be done with the widely adopted bottom-up approach [8]: for each evolving in-terval, we start from the smallest segments, and iteratively merge two neighboring segments into a larger one that has the minimum approximation error. The segmentation process terminates when every possible merge leads to an error larger than a threshold .
After segmenting each evolving interval, we obtain a set of result line segments that have different slopes. Our goal is to divide them into groups such that the segments in the same group have similar slopes. How do we do this without knowing the number of groups beforehand? Below, we design a grouping strategy based on mean shift [4], a non-parametric clustering method based on kernel den-sity estimation. Compared with other classic clustering methods like K-means and DBSCAN, mean shift has several nice proper-ties for our purpose. First, it does not assume any prior knowledge about the number of clusters or the data distribution. Thus it can effectively discover arbitrarily shaped clusters in a complex data space. Second, it has only one parameter, namely the bandwidth, which has a physical meaning as the scale of observation.
For a line segment l i over the sub-interval [ t s ,t e ] , we consider l as a data point x i , where the value x i is the slope of l from the start timestamp t s and the end timestamp t e ). Meanwhile, each x i is associated with a weight w i , which is the length of l namely t e  X  t s . With the weighted mean shift method [24], we can cluster the data points by detecting modes (density maxima) and grouping the points that share the same mode. Specifically, for each data point, we find its mode by iteratively shifting a length-2  X  window. The window is called the kernel window and the radius  X  is called the bandwidth. In each iteration, let y ( k ) be the center of the current window, and { x 1 ,x 2 ,...,x m } be the m data points in-side the window, then the window center is shifted to the weighted mean of { x 1 ,x 2 ,...,x m } , resulting in the maximum increase of density for y ( k ) . The shifting operation leads to a new kernel win-dow located at the weighted mean of { x 1 ,x 2 ,...,x m } , namely
As shown in Figure 6, for each point x , we start with an initial kernel window centered at y (0) = x , and iteratively shift the win-dow according to Equation 1. The sequence { y ( k ) } will converge to the mode that x belongs to. After performing the mean shift pro-cess for every point, we group the points that have the same mode into one cluster. Frequent evolution discovery. Now we have obtained the clusters of similar segments, along with the matching evolving timestamps for each cluster. We consider each cluster as an evolution behavior, where the change rate range is derived from its matching times-tamps, and the support is the number of the matching timestamps. Recall that we want to find frequent evolutions of the sensor. With the minimum support  X  , we eliminate the clusters that have support lower than  X  , then the remaining clusters are returned as frequent evolutions for the sensor.
For each sensor s , we now have a set P s of its frequent evolu-tions, along with the matching timestamps for each pattern p  X  X  In the second stage of Assembler , we assemble the frequent evo-lutions of individual sensors into SCPs.
T HEOREM 1. Let G = { s 1 ,s 2 ,...,s g } be a set of spatially connected sensors, and E G = { R 1 ,R 2 ,...,R g } be an SCP on G . For any G 0 = { s i 1 ,s i 2 ,...,s i k } X  G that is spatially connected, the co-evolution E G 0 = { R i 1 ,R i 1 ,...,R i k } is an SCP on G
P ROOF . The proof is obvious because the matching timestamps of E G must also match E G 0 , hence the support of E G 0 smaller than the minimum support  X  .

Theorem 1 amounts to saying that, if there are no SCPs over a set G 0 of sensors, then no supersets of G 0 can have any SCPs. This property ensures that, if we generate SCPs on large sensor sets by assembling the SCPs on small sensor sets, we effectively prune the search space without missing any patterns.

The pattern assembling operation is achieved via timestamp in-tersection. As shown in Figure 7, suppose we have extracted a frequent evolution P 1 for sensor s 1 , and P 2 for sensor s s are spatially connected, then we merge P 1 and P 2 to generate a co-evolution over { s 1 ,s 2 } , namely P 12 . The matching timestamps of P 12 is simply the common timestamps of P 1 and P 2 . With the derived matching timestamps, it is trivial to compute the support of P 12 and determine whether it is frequent or not. Note that Fig-ure 7 is only an example for assembling one pair of patterns, when there are multiple patterns on both s 1 and s 2 , we need to perform pairwise pattern assembling to obtain all the SCPs on { s Figure 7: Find SCP by intersecting matching timestamps.

Based on the assembling operation and the anti-monotonicity property, one idea is to use the Apriori rule [1] to find SCPs in a bottom-up manner: starting with the single frequent evolutions, we examine pairs of spatially connected sensors to generate size-2 SCPs. Once the size-k SCPs have been discovered, we join ev-ery possible pair of size-k SCPs to generate size-( k + 1 ) candi-date SCPs, and judge whether each candidate is frequent. Such a bottom-up process is terminated when no more SCPs exist for the current size.

Unfortunately, the Apriori-based mining process suffers from two problems: (1) to generate large-size SCPs, it needs to gener-ate a huge number of small-size SCPs as candidates and keep them in memory, which incurs substantial space overhead; and (2) when generating size-( k + 1 ) candidates from size-k patterns, it need to examine every pair of size-k patterns and determine whether they are joinable. It fails to take advantage of the spatial constraint and leads to a huge number of unnecessary comparisons.
We design a novel structure called the SCP search tree to facili-tate more efficient SCP generation. We first introduce the concept of connectivity graph .

D EFINITION 8 (C ONNECTIVITY G RAPH ). Given a set S of sensors and a distance threshold h , the connectivity graph G constructed as follows: (1) each vertex in G corresponds to a sen-sor in S ; and (2) there is an edge between two vertices if their corresponding sensors have a distance no larger than h .
Figure 8 is an example of the connectivity graph. Recall that we want to find groups of spatially connected sensors to form SCPs. The connectivity graph well models the spatial constraint, because each set of spatially connected sensors in S uniquely corresponds to one connected component in the graph G S . Our problem is then reduced to finding all the connected components in G S that have SCPs. However, since S can consist of hundreds of sensors, it is prohibitively expensive to enumerate all the connected components in G S and search for the SCPs. Below, we introduce the neighbor and parent relations between two connected components.

D EFINITION 9 (N EIGHBOR ). Given a connectivity graph G , let X be a size-k connected component in G , and Y a size-( k + 1) one. Y is a neighbor of X if Y includes all the members of X .
D EFINITION 10 (P ARENT ). Let Y be a size-( k +1) connected component in a connectivity graph G . Given a vertex ordering V , the roll-up operation on Y removes one vertex s from Y such that: (1) the result set X = Y  X  X  s } is still connected; (2) s is the first possible vertex in V on the premise of satisfying Condition (1). We say X is the parent of Y , and Y is a child of X .
 Clearly, any connected component Y has one unique parent. Hence, from any connected component Y , if we progressively per-form the roll-up operation, we will reach the empty set  X  .
E XAMPLE 2. Consider the graph G S in Figure 8(b). Suppose the vertex ordering is V = 1  X  2  X  3  X  4  X  5  X  6 . The roll-up operation on the connected component { 245 } generates { 25 } , because sensor s 4 is the first possible one in V that ensures the remaining sensors are still connected. Similarly, the roll-up opera-tion on { 25 } generates its parent { 5 } . Finally, the roll-up operation on { 5 } outputs  X  .

With the roll-up operation, all the connected components in the connectivity graph actually form a tree structure, with the empty set  X  as the root. We call such a structure the SCP search tree . Each node in the tree stores a set of spatially connected sensors, as well as the SCPs occurring on them. Figure 9 show the SCP search tree for the sensors in Figure 8(a).
The SCP search tree effectively organizes all the connected com-ponents into a tree structure based on the spatial constraint. The remaining concern is, how do we obtain the vertex ordering V in order to define the SCP search tree? Actually, V is only used to en-sure the roll-up operation on any connected component generates a unique parent. Any choice of V can lead to a valid SCP search tree, and the cost of SCP generation is not sensitive to the specific choice of V . In our implementation, we simply obtain V based on sensor id.
Note that the SCP search tree organizes the connected compo-nents only conceptually . To generate SCPs, we do not need to construct the entire tree structure beforehand. Instead, we perform depth-first construction from the root node  X  , and only visit the nodes that have SCPs. Specifically, for any node N in the tree, if N does not have any SCPs, then no descendants of N can have SCPs (Theorem 1), and the subtree rooted at N can be safely pruned.
Algorithm 2 sketches the depth-first SCP search process. To ob-tain all SCPs, we just need to feed Algorithm 2 with X =  X  , i.e. , searching from the root  X  . As shown, given node X , we output the SCPs on X if X contains no less than one sensor. Then we start depth-first search from X . First, we find all the neighbors of X in the SCP search tree (line 3), which can be easily done by adding a new sensor that is adjacent to X in G . For each neighbor Y , we perform the roll-up operation to verify whether Y is indeed a child of X . 2 If true and Y contains SCPs (lines 5-7), we recursively per-form depth-first search on Y (line 8), otherwise we safely prune all the subtree rooted at Y .
 Algorithm 2: Search( G,X ) Input : Connectivity graph G , connected component X  X  G .
Output : The SCPs on X . if | X | X  1 then 2 Output the SCPs on X ;
NS ( X )  X  neighbors of X in the SCP search tree; foreach Y  X  NS ( X ) do 5 if roll_up( Y ) = X then 6 P Y  X  the SCPs on Y ; 7 if P Y is not empty then 8 Search( G,Y ); Time Complexity. The cost of the first stage involves two parts: (1) wavelet transform, and (2) the segment-and-group process. For each sensor, the wavelet transform takes O ( m ) time where m is the length of the time series. Now consider the segment-and-group pro-cess. For each sensor, let n e be the number of evolving intervals, l be the average length of the evolving intervals, and l s the segment length, then the segmentation takes O ( n e  X  l e  X  l s ) time for each sensor. Since n e  X  l e &lt; m and l s is usually small, the segmentation time complexity is O ( m ) . For mean shift clustering, assume the number of segments is n l and the average number of shifting oper-ations is k , the time cost of mean shift is then O ( n l Hence, the total time complexity of the first stage is O ( nm ) .
For the second stage, let n G be the number of connected compo-nents in G that have SCPs. During the depth-first search, Algorithm 2 are called n G times. For each call of Algorithm 2, the time cost is determined by line 3, line 5, and line 6. Denote by | E number of edges in G . For any connected component X in G , its neighbors can be obtained in O ( | E G | ) time (line 3). For line 5, each roll-up operation takes O ( | E G | ) time. For line 6, let n maximum number of SCPs on a connected component and n s be the maximum support of an SCP. Since the SCPs of Y are derived by intersecting the timestamps of the SCPs on X and the SCPs on the sensor Y  X  X , the time cost of line 6 is O ( n 2 p n loop outside line 5 iterates at most n times as X can have at most n neighbors. Hence, the total time complexity of the second stage is O ( n G ( n | E G | + n 2 p n s )) .
Note that not every neighbor Y is necessarily a child of X . Space Complexity. The space complexity of the first stage is O ( m ) as the space cost of both wavelet transform and the segment-and-group process is linear in input size. For the second stage, since Assembler performs depth-first search and examines one path at a time, there are at most n connected components maintained in memory. For each connected component, we need to maintain its SCPs along with the matching timestamps. Hence, the space com-plexity of the second stage is O ( n  X  n p  X  n s ) .
 Parameter Setting. There are four parameters in Assembler : (1) the minimum support  X  ; (2) the distance threshold h ; (3) the change threshold  X  ; and (4) the mean shift bandwidth  X  . The first three paramters are easy to set based on application need, because it is intuitive to determine: (1) how many occurrences can be consid-ered frequent enough; (2) what distance makes two sensors reach-able w.r.t. the monitored condition; and (3) how much change in the reading reflects a significant and unusual behavior. The bandwidth parameter  X  comes with the mean shift algorithm, and various tech-niques have been proposed to specify it. For example, the Scott X  X  rule of thumb [18] and the data-driven selection [3] are two popular approaches for this purpose. In this section, we evaluate the empirical performance of the Assembler method. All the algorithms were implemented in JAVA and the experiments were conducted on a computer with Intel Core i7 2.4Ghz CPU and 8GB memory. Data Sets. Our experiments are based on two real geo-sensory data sets and multiple synthetic data sets: 1. Air 3 is the air quality data collected by 180 air quality sen-2. Bike is the Citi Bike rental data set 4 . For the 332 rental docks 3. Syn-Sensor is a collection of 4 synthetic data sets used to 4. Syn-Length is a collection of 4 synthetic data sets used to Compared Method. To the best of our knowledge, no existing methods can be directly used for SCP mining in geo-sensory data. In order to compare with Assembler , we design a baseline method called WaveApriori . It is also a two-stage method and shares the same first stage with Assembler . However, in the second stage, WaveApriori uses the Apriori rule for SCP search (Sec-tion 3.2.1) instead of the SCP search tree. http://web.engr.illinois.edu/%7Eczhang82/data/air.zip https://www.citibikenyc.com/
In this subsection, we report our experimental results. Below, we first examine several illustrating SCPs discovered by Assembler on the two real data sets. Then, we study the efficiency and scala-bility of Assembler under various parameter settings.
For SCP mining, four parameters need to be specified: (1) the minimum support  X  , (2) the connectivity distance h , (3) the change threshold  X  , and (4) the mean shift bandwidth  X  . On Air , we set  X  = 200 ,h = 30 km , X  = 30 ,w = 10 . Note that the AQI change of 30 (  X  = 30 ) indicates quite evident increase/decrease of air qual-ity. Under such a setting, Assembler obtains 8328 SCPs in total, we are particularly interested in the SCPs that involve a large num-ber of sensors. Hence, we demonstrate in Figure 10 two size-10 patterns. We can see that the first pattern P 1 is a more localized pattern that occur on the sensors in Beijing. In P s ,s 2 ,s 3 in the periphery of Beijing have evident AQI decrease, while the sensors s 4 ,...,s 10 in downtown Beijing shows evident AQI increase. We have also investigated the time and the wind di-rection when P 1 occurs. Interestingly, the occurring hours of P show clear peaks in two intervals: [6am-9am] and [8pm-10pm]. During these hours, the traffic may move from the periphery area to the downtown area for work and nightlife activities, thus deteri-orating the air quality in downtown. For the pattern P 2 of the sensors s 1 ,...,s 4 decrease while the AQIs of s 5 crease. As shown in Figure 10, the occurring hours of this pattern seem to be randomly distributed, but the wind direction is mostly West when this pattern occurs. It is quite likely the wind carries the air pollutants from s 1 ,...,s 4 to s 5 ,...s 10 and causes this pattern.
Figure 11 shows two example patterns on the Bike data set, with the parameters  X  = 150 ,h = 1 km , X  = 10 ,w = 3 . Both pat-terns occur mostly in the morning. For P 1 , the number of bikes decreases for the docks ( s 4 ,...,s 7 ) around the ferry station; while the number of bikes increases for the docks ( s 1 ,s 2 ,s zone. This pattern is probably because people arrive at Manhattan by ferry in the morning, and then rent bikes to ride to their offices. The situation is similar for the pattern P 2 , the docks s located in a residence area, while the docks s 1 ,...,s 4 town Manhattan. Many people may choose to rent bikes to go to work due to the heavy traffic in the morning.
In this subsection, we compare the efficiency of Assembler and WaveApriori . Since Assembler works in two stages, we break its cost into two parts: Assembler-1 for the first stage, and Assembler-2 for the second. WaveApriori is also a two-stage method and has the same first stage as Assembler , we use Apri-ori to denote the cost of its second stage.

As aforementioned, there are four parameters for SCP mining:  X  , h ,  X  , and  X  . In the following, we study the effect of each parameter while the other parameters are fixed at their default values. Table 2 shows our parameter settings on the Air and Bike data sets, where the numbers in bold denote the default values.
 Table 2: Parameter settings on the Air and Bike data sets. Varying  X  . In the first set of experiments, we examine the effect of the minimum support  X  on the performance of Assembler and WaveApriori . As shown in Figure 12(a), the running time of both methods decreases with  X  on the Air data set. The de-crease comes from the second stage for both methods. With larger  X  , fewer sets of spatially connected sensors can have SCPs and the pattern search space is smaller for both methods. This phe-nomenon can be observed in Figure 12(b), where the number of SCPs decreases rapidly with  X  on the Air data set. Comparing the running time of the two methods, we can see the second stage of Assembler is much faster than that of WaveApriori . This is because Assembler effectively leverages the spatial constraint when generating SCPs from single frequent evolutions. Figure 13(a) shows the running time of the two methods on the Bike data set, where similar trends are observed. Figure 12: Varying minimum support  X  on the Air data set. Varying h . In the second set of experiments, we evaluate the performance of Assembler and WaveApriori as the distance threshold h varies. Figure 14(a) and 13(b) show the running time of the two methods on the Air and Bike data sets, respectively. The first stage of the two methods is not affected by h , while the cost of the second stage increases with h for both methods. This is
Figure 13: Running time comparison on the Bike data set. expected. As h increases, the number of spatially connected sen-sor set becomes larger, leading to more SCPs and a larger pattern search space. As shown in Figure 14(b), the number of SCPs in-creases roughly linearly with h on the Air data set. Meanwhile, one can observe again the second stage of Assembler is much more efficient than that of WaveApriori . The performance gap is particularly significant when h is very small. This phenomenon suggests that the SCP search tree indeed effectively utilizes the dis-tance constraint to largely prune the search space.

In practice, h should be determined with the guidance of domain knowledge. On the Air data set, we set h to 5km -30km because air pollution can be dispersed faraway due to factors such as wind and traffic. In contrast, on the Bike data set, we set h to 0.5km -3km, as people usually take short trips by bike.
 Varying  X  . We proceed to study the effect of the change thresh-old  X  . Figure 15(a) and 15(b) give the results on the Air data set. When extracting evolving intervals using wavelet transform, we set min _ level to l  X  3 , namely we only concern about the three most detailed levels. From Figure 15(a), we see that, the running time of
Figure 14: Varying distance threshold h on the Air data set. both methods becomes larger when  X  is smaller, and this trend is especially obvious for WaveApriori . Recall that  X  specifies how much change we think is significant. When  X  is small, many small evolutions are also extracted, and thus the number of result SCPs becomes much larger (Figure 15(b)). Figure 15: Varying change threshold  X  on the Air data set.
The performance gap between the two methods is extremely large when  X  is small. This is because WaveApriori generates numer-ous small candidate patterns for a small  X  , the pair-wise candidate comparison incurs substantial computation overhead, deteriorating its performance rapidly. Similar results are observed on the Bike data set, we omit them due to the space limit.
 Varying  X  . Finally, we study the performance of the two meth-ods when the mean shift bandwidth  X  varies. Note that  X  controls the clustering granularity, when  X  is large, more data points are grouped together and thus the co-evolutions on spatially connected sensors have better chances to exceed the minimum support  X  . Fig-ure 16(a) and 16(b) show that the running time and the number of SCPs increase for both methods. Specifically, the running time of the first stage increases slightly with  X  , while the cost of the second stages grows more rapidly. In this subsection, we study the scalability of Assembler and WaveApriori using the two collections of synthetic data sets. The four data sets in Syn-sensor have the same time series length m but different numbers of sensors n . Figure 17(a) shows the running time of Assembler and WaveApriori as n increases, with  X  = 1000 and h set to the average distance between the sen-sors. As shown, the cost of the first stage increases linearly with n for both methods, which is expected according to our theoreti-cal analysis in Section 3.3. For the second stage, the cost of both methods increases super-linearly with n . This is due to the com-binatorial nature of SCP: when n increases, the number of spa-tially connected sensor set increases rapidly, resulting in larger cost for SCP search. That said, we notice that the running time of Assembler increases more slowly than WaveApriori . It is because Assembler more effectively leverages the spatial con-straint to prune the search space. (a) Time v.s. number of sensors n .
For the other collection Syn-length , the four data sets have the same number of sensors n , but different time series length m . Fig-ure 17(b) shows the running time of the two methods as m varies, with  X  = 0 . 01  X  m and h set to the average distance of the sensors. As shown, the first stage of both methods still increases linearly with m , while the second stages increases sub-linearly. This sug-gests that Assembler scales well with the length of time series and suitable for massive geo-sensory data in practice. Generally, our work is related to the following topics.
 Motif discovery. Motif discovery in time series has been stud-ied extensively. Given a distance threshold  X  and a length l , two length-l time series subsequences form a motif if their distance is smaller than  X  . The top-K motif discovery problem aims at find-ing the K subsequences that have the largest number of matches in the time series. Lin et al. [10] first introduced this problem and used hash-based counting to find motifs. Chiu et al. [2] developed an algorithm that finds approximate motifs in linear time. The key idea is to maintain a collision matrix and use random projection to map subsequences into the collision matrix. Mueen et al. [14] pro-posed a method that fast finds exact motifs with the linear ordering heuristic and the early abandoning strategy.

Motif discovery in multi-dimensional time series has also been studied. Tanaka et al. [20] first transformed the multi-dimensional time series using principal component analysis, and then used ran-dom projection [2] to find motifs in the transformed signal. Minnen et al. [13] studied the problem of mining sub-dimensional motifs that span across only a subset of the dimensions. Patel et al. [16] introduced lag patterns to capture the invariant ordering of the mo-tifs extracted from multiple time series. Unfortunately, as discussed in Section 1, none of these techniques are capable of mining SCPs because of the redundancy problem of geo-sensory data, as well as the duration variation and combinatorial nature of SCP.
 Time series segmentation and change detection. Sliding win-dow, top-down, and bottom-up approaches [8] are popular methods to partition a time series into line segments. Wang et al. [22] pro-posed the pattern-based hidden Markov model that can segment a time series as well as learn the relationships between segments. Methods have also been proposed [9, 6] to obtain piecewise poly-nomial approximations and/or perform on-line segmentation.
Change detection aims to find the time points where the statis-tical property of the time series changes significantly. It is closely related to time series segmentation as such points can be considered as the boundaries of different segments. Yamanishi et al. [23] uni-fied the problems of change detection and outlier detection based on the on-line learning of an autoregressive model. Sharifzadeh et al. [19] used wavelet footprints to find the points where the polynomial curve fitting coefficients show discontinuities. Kawa-hara et al. [7] judged whether a point is a change by computing the probability density ratio of the reference and test intervals.
While Assembler uses the bottom-up segmentation approach due to its simplicity and practical effectiveness, it can be easily adapted to other segmentation algorithms. It is also worth mention-ing that, the segmentation of Assembler is performed on short evolving intervals instead of the original long time series, which renders the segmentation process really fast.
 Co-evolving time series analysis. Papadimitriou et al. [15] intro-duced SPIRIT for multi-sensory time series, with a focus on discov-ering the hidden variables and summarizing the key trends for the entire time series collection. Sakurai et al. [17] studied the problem of detecting all pairs of time series that have strong lag correlations. Ma et al. [11] designed a system for analyzing the sensory data in water distribution systems. One component in the system evaluates the correlations among the co-evolving multi-sensory data. It con-tinuously computes the Pearson X  X  correlations between two sensors to find sensors that have similar trends. In contrast, the member sensors in our SCP do not necessarily have similar trends.
Trasarti et al. [21] studied the problem of finding regions that show similar deviations in population density using mobile phone data. They assume the condition has periodicity, i.e. , the daily pop-ulation densities in a region are similar in different days. While this assumption is reasonable for population density, it does not hold in many geo-sensory applications like air quality monitoring. Moreover, they extract vertical changes in population density by comparing the same hour of different days. In contrast, we extract the horizontal changes, i.e. , comparing the condition in current time interval with the previous time interval.

Matsubara et al. [12] proposed a model to summarize the global-level ( i.e. , country-level) and the local-level ( i.e. , state-level) prop-erties of different diseases. However, it is designed specifically for epidemic data instead of general geo-sensory data.
We introduced the problem of mining spatial co-evolving pat-terns from geo-sensory data. We designed the two-stage method, Assembler , for effective and efficient SCP mining. It first de-tects frequent evolutions for individual sensors and then assembles single patterns into SCPs. Our experimental results demonstrate that Assembler is effective, efficient, and scalable. We note that Assembler also enjoys the nice property that both its two stages can be easily parallelized to achieve even better efficiency. For the first stage, the wavelet transform and the segment-and-group pro-cess are performed independently for the sensors. For the second stage, the branches from the single sensors in the SCP search tree are mutually independent, and thus can be searched in parallel. For future work, we plan to leverage the discovered SCPs to improve the air quality prediction task in different cities in China perform a thorough study on the correlation between AQI SCPs and the traffic patterns in Beijing. http://urbanair.msra.cn/
We thank the reviewers for their insightful comments. This work was sponsored in part by the U.S. Army Research Lab. under Co-operative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov), and MIAS, a DHS-IDS Cen-ter for Multimodal Information Access and Synthesis at UIUC. Xi-uli Ma is supported by the National Natural Science Foundation of China under Grant No.61103025 and China Scholarship Council.
