 With the wide applications of large scale graph data such as social networks, the problem of finding the top-k shortest paths attracts increasing attention. This paper focuses on the discovery of the top-k simple shortest paths (paths without loops). The well known algorithm for this problem is due to Yen, and the provided worst-case bound O ( kn ( m + nlogn )) , which comes from O ( n single-source shortest path discovery for each of k shortest paths, remains unbeaten for 30 years, where n is the number of nodes and m is the number of edges. In this paper, we observe that there are shared sub-paths among O ( kn ) single-source shortest paths. The basic idea behind our method is to pre-compute the shortest paths to the target node, and utilize them to reduce the discovery cost at running time. Specifically, we transform the original graph by encoding the pre-computed paths, and prove that the shortest path discovered over the transformed graph is equivalent to that in the original graph. Most importantly, the path discovery over the trans-formed graph can be terminated much earlier than before. In ad-dition, two optimization strategies are presented. One is to reduce the total iteration times for shortest path discovery, and the other is to prune the search space in each iteration with an adaptively-determined threshold. Although the worst-case complexity cannot be lowered, our method is proven to be much more efficient in a general case. The final extensive experimental results (on both real and synthetic graphs) also show that our method offers a significant performance improvement over the existing ones.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms This work was supported in part by the National Natural Science Foundation of China under Grant No.60873062, the National High Technology Research and Development Program under Grant No. 2009AA01Z150, and Key Projects in the National Science &amp; Tech-nology under Grant No. 2009BAK65.
 Graphs, shortest-paths, top-k
The top-k shortest paths problem, which is to discover k shortest paths between a pair of nodes in a graph in non-descending order of their costs [19, 5], is attracting more and more attention. The top-k shortest paths are highly desired for the reason that one may wish to find more than one path between two nodes. Take the example of finding paths between two sensitive accounts in a large social network, end users may be interested in all accounts in the top-k shortest paths. Although many approaches have been proposed to solve this problem, the existing methods have to be continuously improved in order to handle big graphs efficiently.

The top-k shortest paths problem can be classified into two cate-gories[12], the problem of finding the top-k general shortest paths (paths allowing loops)[5], and the problem of finding the top-k simple shortest paths (paths without loops)[19, 10]. Although the two problems are very similar at the first glance, they face different complexities. In a positive-weighted graph, the very shortest path between the given pair of nodes is obviously loopless. However, it is possible that the k -th( k  X  2 ) shortest path has loops. The top-k simple shortest paths problem therefore is significantly harder than the former one due to additional cost for loop detection as well as more search space.
 The well known method for the top-k general shortest paths is Eppstein X  X  algorithm [5]. To find the top-k shortest paths, the algo-rithm builds a shortest path tree rooted at the target node first, then properly selects certain edges outside the shortest path tree to con-nect different parts of this tree, forming the paths to be discovered. To aid choosing edges outside the shortest path, the sideCost is annotated on each edge e in the original graph, which indicates the extra cost compared with the shortest one if e is selected in the fi-nal path. The algorithm takes O ( m + nlogn + k ) time cost, which is also the lowest bound of the top-k general shortest paths prob-lem[12]. Here and throughout the paper, n is for the number of nodes, and m is for the number of edges.

The classic method for the top-k simple shortest paths is Yen X  X  algorithm [19]. This method first computes the very shortest path from the source node to the target node as the first path. Then, it an-alyzes each node in the newly discovered shortest path p as the de-viation node to generate candidates for the next shortest path using a single-source shortest path discovery. The next shortest path is chosen from all the candidates with the minimal cost. The process continues until k different shortest paths are finally determined. The total time cost of Yen X  X  algorithm is thus O ( kn ( m which comes from O ( n ) single-source shortest path discovery for each of the k shortest paths. Several attempts have been made to improve the performance of Yen X  X  algorithm. However, the worst-case complexity cannot be re-duced. Ernesto et al reduced the cost in candidate path generation by discovering the shortest paths incrementally [15]. John Hersh-berger et al generated the candidate paths with the edge-replacement strategy in O ( m + nlogn ) for each of the k candidates paths. Un-fortunately, their algorithm may fail in some cases for directed graphs. In a recent paper [10], they use the fast replacement al-gorithm to discover the candidate paths, and switch to a slow but correct method when a loop in the generated path is detected.
In this paper, a fast approach is proposed to address the problem of top-k simple shortest paths. We do not expect to lower the worst-case time complexity O ( kn ( m + nlogn )) of Yen X  X  algorithm, but focus on the reduction of each factor. The basic idea is to reduce the redundant computation cost of each candidate path generation with the precomputed paths. More specifically, the contributions of this paper can be summarized as follows.

First, we design a fast approach to find the top-k simple short-est paths. Our approach differs from existing ones mainly in the candidate path generation. First, we pre-compute the shortest path tree rooted at the target node as that in Eppstein X  X  algorithm, and annotate the interval encodings on each node in the tree to speed up the loop detection in candidate paths. Then the transformed graph is constructed by annotating each edge e with sideCost .We prove that the shortest path discovered on the transformed graph is equivalent to that on the original graph. Most importantly, the shortest path discovery can be terminated much earlier than be-fore. In our method, the shortest path can be the concatenation of two sub-paths, of which only the first sub-path needs running time discovery, and the second sub-path can be directly located in the pre-computed shortest path tree. (See Section 3)
Second, we propose two optimization techniques to further im-prove the performance. When the existing candidate paths have already contained k different ranked shortest paths, no more iter-ations are needed even if the number of iterations is less than k . In addition, we stop the candidate path discovering when its length exceeds a threshold. Under such a case, the path will be not in the final results even if it is fully generated. We also design two policies, named lazy and eager policy, to determine the threshold adaptively. (See Section 4)
Third, we make extensive experiments on both real and synthetic data. Compared with Yen X  X  algorithm [19] and the replacement-based method [11], our method achieves considerably higher ef-ficiency with good scalability. For example, when the number of nodes exceeds 100k, our method is at least two orders of magni-tude faster than the competitors. (See Section 5)
The remainder of the paper is organized as follows: Section 2 outlines the notations and reviews two representative methods. Section 3 proposes our basic approach. Section 4 designs two op-timization strategies. Section 5 reports the experimental results. Section 6 surveys the related work and Section 7 concludes the pa-per and discusses the future work.
In this section, we first introduce some related notations, then review two existing representative methods.
Let G =( V, E ) denote a weighted directed graph, where V is the set of nodes and E is the set of edges. Each edge e is represented by e =( u, v ) , u, v  X  V . Each node v  X  V has a unique node id v.id , and each edge e  X  E has a non-negative weight e.weight . The edge from node u to v is u  X  X  outgoing edge or v  X  X  incoming edge.

A path is a sequence of nodes and edges u 0 ,e 0 ,...e x  X  1 where u i ( 0  X  i  X  x )  X  V and e i =( u i ,u i +1 )  X  E (0  X  i&lt;x ) . Without loss of generality, we replace the edge in the path denotation with symbol  X  . The number of nodes in the path p is denoted as nodes ( p ) and the i -th (0  X  i&lt;nodes in the path is referred to as p [ i ] . The path is simple iff there is no repeated node, or formally, p [ i ] .id = p [ j ] .id (0  X  nodes ( p )) .Thecost cost ( p ) of a path p is the sum of the weight of its constituent edges. Let P ( u i ,u j ) represents the set of simple paths with the starting node u i and the ending node u j . The shortest distance between node u i and node u j , denoted as  X  ( u defined as the minimal cost of all the paths in P ( u i ,u j as an example, the path s  X  d  X  c  X  s contains a repeated node s and thus is not a simple one.  X  ( s, t ) is 14, achieved by the path s  X  b  X  e  X  g  X  t .

The top-k simple shortest path sequence P k = { p 1 ,...,p a source node s and a target node t meets the following require-ments: i).  X  p  X  P k , p is a simple path from s to t ; ii). cost cost ( p i +1 ) ,forany i in [1 ,...,k  X  1] ; iii).  X  p e p  X  P k , cost ( p e )  X  cost ( p k ) .

Before further discussing our method, we list some basic nota-tions. From now on, we use s to denote the source node and t to denote the target node. To simplify the presentation, we use p to represent the concatenation of path p 1 and p 2 , if the ending node of p 1 is the same to the starting node of p 2 . Given a directed graph G =( V, E ) , G  X  X represents the remaining graph with the re-moval of X (a node or edge set). Unless specified otherwise, the shortest path in our paper means the simple shortest path.
Yen X  X  algorithm is the classic method to yield top-k simple short-est paths [19], while Eppstein X  X  algorithm can be used to efficiently handle the top-k general shortest paths problem [5]. In what fol-lows, we review these two representative methods. To be more illustrative, the graph data depicted in Fig.1 is used as an example. Yen X  X  Algorithm. Yen X  X  algorithm first locates the shortest path p = s  X  b  X  e  X  g  X  t from s to t using Dijkstra X  X  algorithm as the first shortest path, and initializes the pseudo result tree. The pseudo result tree is a compact structure to store the discovered paths, which also plays an important role in the generation of other paths. Formally, it can be defined as follows:
D EFINITION 1. Pseudo Result Tree. Given the top-k simple shortest path sequence P k from s to t , the pseudo result tree T (
V ,E ,s ) stores all paths in P k in a tree structure. When k the tree is formed by the shortest path itself. Suppose the pseudo re-sult tree for P i is T i , T i +1 is defined by adding to T the sub-path of p i +1 from d to t ,where d is the farthest node from s in T i (considering the number of internal nodes) such that the path from s to d in T i is also in p i +1 .
Intuitively, all paths in P k are merged into the pseudo result tree with the maximal shared prefix. We illustrate a pseudo result tree for the top-3 simple shortest paths in Fig.2. It is called pseudo since the node with the same ID, such as node f in Fig.2, may appear more than once in the tree.

The next ranked shortest path can be viewed as a deviation of its previous paths. After a path p i is selected as the i -th shortest path, each node p i [ j ] in p i is analyzed as the deviation node to generate a new simple candidate path (denoted as c ij )to t . We introduce the ignored node set to avoid loops in c ij and the ignored edge set to make c ij different from the existing paths.

D EFINITION 2. Ignored node set and edge set. Let T be the pseudo result tree for the top-i simple shortest path sequence P path p i be the i -th shortest path. If p i [ j ](0  X  j &lt; nodes used as the deviation node, the ignored node set IgN ij includes all nodes from p i [0] to p i [ j ] in p i ; the ignored edge set IgE all edges in T with p i [ j ] as the starting node.

With the notations above, the location of the next shortest path can be described as follows: for each node p i [ j ](0  X  j&lt;nodes in the i -th shortest path p i , we generate the candidate path c p [ j ] as the deviation node. c ij is composed by two sub-paths s and s 2 . s 1 is the sub-path in p i from s to p i [ j ] ,and s path from p i [ j ] to t when IgN ij and IgE ij are removed from G . In other words, s 2 is discovered on the graph G  X  IgN ij The ( i +1) -th shortest path is selected with the minimal cost from all candidate paths.

A simple optimization strategy is that we need not generate all the candidate paths with each node in p i as the deviation node. Sup-pose b is the branching node in p i nearest to the leaf node (or is the root node when there is no branching node), the candidate paths for the nodes from s to b have already been computed previously. We only handle the nodes from b to the leaf node in p i as the deviation nodes, without any impact on the completeness of the results.
The worst-case bound for Yen X  X  algorithm takes O ( kn ( m It results from O ( n ) times computation of single-source shortest path discovery for each of the k shortest paths. With modern data structures such as Fibonacci heaps, each of O ( kn ) shortest path discovery can be implemented in O ( m + nlogn ) .

The replacement-based method [10] is an extension to Yen X  X  al-gorithm. It takes the similar framework to that of Yen X  X  but uses a different edge-replacement strategy to generate candidate paths. Given the i -th shortest path p i , for each edge e j (0  X  in p i , it finds the candidate path as the shortest path from s to t on the graph G  X  X  e j } . O ( n ) times candidate path generation re-lated to one shortest path can be implemented in O ( m + nlogn using Fibonacci Heap. It is more efficient compared with Yen X  X  O ( n ( m + nlogn )) . However, the main problem of the replace-ment algorithm is that the generated path may contain loop in some cases. Therefore, the approach requires a loop detection after the candidate path generation, and switches to a correct but slow algo-rithm, such as Dijkstra X  X  algorithm when a loop is found. Eppstein X  X  Algorithm. Eppstein X  X  algorithm aims to find the top-k general shortest paths. The candidate paths are also deviations of currently discovered shortest paths. Since all candidate paths target for the same destination, it builds the shortest path tree rooted at the target node first to reduce the redundant cost during the path generation.

D EFINITION 3. Shortest Path Tree (SPT). A shortest path tree rooted at a node r on the outgoing edges, denoted as spt out is a tree T =( V ,E ,r ) ,where V  X  V , E  X  E , r  X  V ,such that: i) V is the set of nodes reachable from r in G ; ii) for any v  X  V , the path from r to v in T is the shortest one from r to v in G , and v.cost is the shortest distance from r to v . And similarly, spt in ( r, G ) can be defined on the incoming edges.

Eppstein X  X  algorithm determines how to derive the candidate paths from the existing discovered ones with the sideCost on each edge. Given each edge e =( u, v ) in G , the side cost of e is defined as e.sideCost = v.cost + e.weight  X  u.cost ,where u.cost and v.cost are recorded in spt in ( t, G ) , representing the distance from u and v to t , respectively. The sideCost intuitively measures how much extra cost is introduced by being  X  X idetracked" along e in-stead of taking the shortest path to t . It is easy to know that the side cost for any edge in spt in ( t, G ) is 0. The graph G side Transformed Graph with Side Cost if the sideCost of each edge in G has been assigned.

Take Fig.3 as an example, the shortest path tree spt in ( illustrated with bold lines. Note that all edges in spt in from the child node to its parent. The number in the bracket in each node represents the distance from this node to t , and the number an-notated on the edge is the sideCost . For example, e.sideCost for e =( s, d ) , which means the cost added for the deviation path when  X  X idetracking" e instead of taking the shortest one. By calcu-lating the cost of the deviation path s  X  d  X  c  X  e  X  g  X  which is 21, and the shortest distance from s to t , which is 14, we can easily verify this claim.
 After the transformed graph with side cost has been constructed, Eppstein X  X  algorithm introduces a sophisticated data structure called heap tree, converts the graph into another graph G which contains all paths from s to t , and locates the top-k shortest paths with a breadth-first search on G in time O ( m + nlogn + k ) . It achieves the lowest bound of time complexity for the top-k general shortest paths problem[12].
We give details about our basic method in this section. First, we sketch the framework of our algorithm. Then the two parts of our method are discussed, namely graph preprocessing and candidate path generation. Finally, we provide analysis on the correctness and performance of our method.
Our algorithm can be split into two steps: i) graph preprocessing and ii) candidate path generation. The goal of the first step is to do some preparations on the graph which will speed up the top-k shortest path generation. It mainly consists of three jobs: building the shortest path tree spt in ( t, G ) rooted at the target node, con-structing the transformed graph with side cost G side , and encoding the shortest path tree spt in ( t, G ) with structural labels. The sec-ond step generates the top-k shortest paths. Different from Yen X  X  method which computes the paths on G , our algorithm runs the sec-ond step on G side . By utilizing the shortest path tree spt and the structural labels derived in the first step, our method shows significant improvements from existing works on this bottleneck step. In what follows, we describe each step in detail.
In order to reduce the redundant cost in the top-k path genera-tion, the first job is to build the shortest path tree spt tree is actually the intermediate result of Dijkstra X  X  algorithm. Each node is labeled with cost for the distance to t and parent for the successor node in the shortest path to t . t.cost =0 . spt can be constructed as follows: An active node list Q is initialized with t and iterations start. The node x with the minimal cost is selected from Q and finalized in the iteration. Each neighbor node c of x is handled. When c is not in the active node list Q , c is added into Q with c.cost and c.parent initialized. When c is in L , its cost and parent may be adjusted when the path via x to c is shorter than the current one. The processing repeats until all nodes have been finalized. The nodes along with the parent link inside them compose the shortest path tree spt in ( t, G ) .

Based on spt in ( t, G ) , the second job, constructing the trans-formed graph with side cost, can be easily performed. We only need to set e.sideCost of each edge e =( u, v ) to v.cost u.cost .

The third thing is to encode the shortest path tree spt in with the structural labels. We use interval labels [9] since they support the detection of ancestor/descendant relationship between nodes efficiently. The interval labels can be assigned on each node in one time traversal of the tree. Specifically, an interval label on node u is a triad in the form of ( u.pre, u.post, u.parent u.pre and u.post are node u  X  X  preorder and postorder number re-spectively (with regard to spt in ( t, G ) ), u.parent is the preorder number of u  X  X  parent in spt in ( r, G ) . The interval labels are as-signed in such a way that: for a node u and its descendant node v in spt in ( t, G ) , u.pre &lt; v.pre and u.post &gt; v.post ; for a node u and its right sibling v , u.post &lt; v.pre ; for a node u and its par-ent v , u.parent = v.pre . We exploit such a property of interval labels to speed up the loop detection in the second step. We illus-trate the transformed graph in Fig.4. Three numbers on each node between "[" and "]" in the figure are for the pre , post and parent respectively.
The problem handled in this step is described as follows: for the latest discovered i -th shortest path p i ,let d be p i [ node, we attempt to locate the shortest path from d to t over G IgN ij  X  IgE ij . In order to simplify the expression, G  X  IgE ij is represented by G  X  X for short. The path can be found with the building of spt out ( d, G  X  X ) until t is finalized. This is a key task, since we need to discover O ( nk ) candidate paths before the final results are produced.

We achieve the performance improvement at this task. We ob-serve that there may be redundant computations among the can-didate path generation. For instance, consider two selected short-est paths in Fig.2, p 2 = s  X  b  X  e  X  g  X  f  X  t ,and p = s  X  b  X  e  X  d  X  f  X  t . Although starting from different deviation nodes, they occur to end with the same suffix path f Hence, we attempt to reduce the redundant computation cost with the precomputed shortest path tree spt in ( t, G ) , and stop the dis-covery earlier. In order to avoid might-be loops in the discovered paths, we utilize the structural labels on each node to detect loops without the recovery of the full path.

Different from the existing work, we discover the shortest path from the deviation node d to t in the transformed graph with side cost G side  X  X , instead of in G  X  X . The equivalence of two discovered paths are proven as follows:
L EMMA 1. The shortest path p from d to t discovered in G x is identical with the shortest path p in G side  X  X using the sideCost as the edge weight.

P ROOF .Let l be the length of the shortest path p discovered on the graph G  X  X .Since p is the shortest path, the extra cost added to p is minimal compared with the shortest path in G . In addition, the sum l of sideCost in p is also minimal. l = l +  X  ( d, t Hence, the node sequences in p and p are identical.
 More importantly, the shortest path discovery from d to t on G side  X  X can be terminated earlier before t is finalized. Recall that the sideCost for each edge in spt in ( t, G ) is 0. We can exploit the path p in spt in ( t, G ) as a part in the final path from d to t .At the same time, we should ensure that p has no intersection with IgN ij or IgE ij . Our early termination strategy can be illustrated in Fig.5. The grey nodes are the ignored nodes. d 2 is the current deviation node. We start building spt out ( d 2 ,G side  X  the edge from d 2 to l is with the minimal sideCost and it is not the ignored edge, we finalize l . However, since l is the descendant of an ignored node i , the path from l to t in spt in ( t, G which will lead to a loop. Hence, we need search for the next node. Suppose it is u , and we can see u is not the descendant node of any ignored node. Under such a case, we can stop searching at u .The path from u to t in spt in ( t, G ) is used as the part of the shortest path from d 2 to t . Specifically, during the building of spt out ( d, G side  X  take the similar idea of Dijkstra X  X  algorithm. We introduce an ac-tive node list Q . costExt and parentExt are annotated on each node for the sum of the sideCost from d and the preceding node respectively. d.costExt =0 and d is added into Q first. Then we iteratively select node u with the minimal costExt , finalize u ,and handle u as follows: 1. Terminate Immediately. The searching can be terminated im-2. Detect Further. If none of the terminating conditions is sat-
We can notice the role of the interval labels annotated during the graph preprocessing. In order to accelerate the loop detection with interval labels, we sort the ignored nodes by their pre ,and remove the nodes which are the descendants of other nodes before iteration. For each finalized node u in the iteration, we can detect the relationship between u and ignored nodes in O ( logn ) a binary searching.

L EMMA 2. When the terminating node u is discovered, the con-catenation s 2 of the sub-path s 21 from d to u in spt out X ) and the sub-path s 22 from u to t in spt in ( t, G ) is the shortest path from d to t on the graph G  X  X .

P ROOF . First, s 2 does not contain any ignored node or ignored edge. During the location of s 21 , s 21 does not contain any ignored node or ignored edge, which is guaranteed by the rules above. Sec-ond, s 2 has the minimal sum of sideCost .Since s 21 is generated with the Dijkstra X  X  algorithm over G side  X  X ,thesumof sideCost is minimal. In addition, the sum of sideCost of edges in s 0. Thus, the sum of total sideCost of s 21 and s 22 is the mini-mal. Therefore, s 2 is the shortest path from d to t on the graph G  X  X .
 The candidate path generating process is outlined in Algorithm.1. The costExt of each node is set to the maximum and the parentExt links are all cleared in line 1. Then we sort the nodes in IgN and remove the nodes which are the descendant of other ignored node in line 2 and line 3. It is easy to know that the removal does not impact on the result of the loop detection. We use an active list Q to store all candidate nodes. Q is initialized with only d ,and d.costExt =0 (line 4 and line 5). For each iteration from line 8 to line 22, the node u with the smallest costExt in Q is ex-tracted and checked if any ignored nodes are on its shortest path to t . If no such a node is found, we can terminate the searching im-mediately, as discussed previously (from line 10 to line 13). Oth-erwise, each neighbor v of u is added into Q if v is not finalized. Also, we need to neglect those neighbors in IgN or those edges in IgE (line 15 to 17). From line 18 to line 21, v.costExt is set to u.costExt + e.sideCost if v can get a smaller costExt ,where e =( u, v ) . After the loop from line 8 to line 22, either a new path is found ( found is true ) or no candidate paths can be generated from d .if found is true , the concatenation of s 21 and s 22 is the shortest path in G side  X  X . s 21 can be recovered in spt out ( d, G with parentExt links; and s 22 can be recovered in spt in with parent links(from line 23 to line 26).

Algorithm 1 : the shortest path location locate ( IgN,IgE,d,t,G side )
Input : The ignored node set IgN , the ignored edge set IgE , Output : the shortest path from d to t on G side  X  IgE  X  IgN .
Initialize each node v in G with v.costExt  X  +  X  and v.parentExt  X  null ;
Sort nodes in IgN with the order of pre into IgN ;
Remove node a if it is a descendant of another node b in IgN ; d.costExt  X  0 ;
Initialize active node list Q and insert d into Q ; found  X  false ; s 2  X  null ; while ( Q is not empty and not found ) do if found then
Return s 2 ;
We use the example in Fig.6 to demonstrate the process. After the first shortest path p 1 is located from s to t , suppose e is the cur-rent deviation node, we want to generate a candidate path from e to t . The ignored node set IgN 13 and the ignored edge set IgE are { a, b, e } and { ( e, g ) } , respectively. During the candidate path searching, e is added into the active node list Q .As g is in IgE we do not add g into Q .Weadd d into Q with status Detect Fur-ther since d is a descendant node of e in spt in ( t, G ) add c and f into Q . Suppose c is handled next, there is no action since the neighbor nodes of c are in IgN 13 . We further process f , and terminate searching intermediately, since there is no ances-tor/descendant relationship between f and any node in IgN recover the entire candidate path, we first locate the sub-path from s  X  b  X  e in the pseudo result tree. Then, we explore the short-est path tree rooted at e on G side  X  X to get s 21 , and terminate searching at f . Finally, the third part f  X  t can also be derived di-rectly from spt in ( t, G ) . The labels inside the circle have the same meaning as those in Fig.4.
In this sub-part, we prove the correctness of our algorithm, an-alyze its computational complexity, and give the reasons why our method outperforms existing methods.
T HEOREM 1. Our method can yield the correct top-k shortest paths.

P ROOF . Since the output of Yen X  X  algorithm has been proven to be the correct top-k simple shortest paths, we verify the correctness of our method by showing the paths discovered in our method equal those of Yen X  X .

The candidate path generation procedure in our method is differ-ent from that in Yen X  X  method. In Yen X  X  method, for each node d in the i -th shortest path p , the candidate path is the concatenation of two sub-paths, s 1 and s 2 ,where s 1 is from s to d ,and s shortest path from d to t on the graph with the ignored node and edge set removed. In our method, the first sub-path is the same as that of Yen X  X . The second sub-path s 2 is the concatenation of the sub-path s 21 from d to the terminating node u and the sub-path s 22 from u to t . We need to prove the shortest distance and the looplessness of s 2 .

First, from Lemma.2, we already know that s 2 in our method is also the shortest path from d to t on the graph G side  X  X with the removal of the ignored node and edge set. From Lemma.1, the path discovered over G side  X  X equals the path discovered on G The sum of the extra cost of s 2 is the minimal.

Second, we prove each of the three sub-paths, s 1 , s 21 and s does not contain loops inside itself. s 1 is from s to the devia-tion node d . It does not contain any loop since s 1 is a sub-path of the recently discovered loopless path. s 21 is in the shortest path tree spt out ( d, G side  X  X ) ,and s 22 is in the shortest path tree spt in ( t, G ) . They do not contain the loop either.

In addition, we prove that all three sub-paths do not intersect with each other. From Lemma.2, s 1 does not intersect with s We prove s 21 does not intersect with s 22 by contradiction. If the concatenated path s 2 of s 21 and s 22 contains a loop, there will be a node u in both s 21 and s 22 ,where u is not the terminating node u . Since u is the ending node of s 21 , u must have been encountered before u when generating s 21 . Similarly, since u is the starting node of s 22 , u must lie after u in s 22 .If u meets the condition for the termination node, u should also be a valid termination node, and the construction of s 21 should have been terminated at u rather than u . Thus, it is impossible that s 21 and s 22 form a loop. Finally, we prove that s 1 does not intersect with s 22 by contradiction. If there is a node u in both s 1 and s 22 , the starting node of s be the descendant node of u (an ignored node). In other words, the terminating node is the descendant of u , which contradicts the definition of the termination node.

T HEOREM 2. Our method requires O ( kn ( m + nlogn )) time in the worst-case.

P ROOF . Our method can be roughly divided into the graph pre-processing phase and the path generation phase. As for the first phase, the shortest path tree spt in ( t, G ) is built in time O nlogn ) with Dijkstra X  X  algorithm. The interval labels are assigned on each node in one time traversal in time O ( n ) . The transformed graph with the side cost is constructed in time O ( m ) . The data preparation phase takes O ( m + nlogn ) time cost.

As for the path generation phase, O ( k ) iterations are required for different shortest paths. For each time of the shortest path dis-covery, at most O ( n ) nodes are considered as the deviation node for the candidate path enumeration. In the shortest path discovery from the deviation node to the target node, there are at most O ignored nodes. We need to determine the relationship between the currently finalized node and any ignored node. In order to speed up the determination, we can sort the ignored nodes with their pre label in time cost O ( nlogn ) , and remove the ignored nodes which are also the descendant of other ignored nodes in time cost O Then applying the binary searching in the remaining ignored nodes, we can make the loop detection in O ( logn ) . Since the location of a node with the minimal costExt also requires O ( logn ) time cost in Dijkstra X  X  algorithm, the loop detection does not worsen the time complexity
The final time complexity is O ( m + nlogn + kn ( m + nlogn nlogn )) ,or O ( kn ( m + nlogn )) . The worst case remains the same as that of Yen X  X .
 T HEOREM 3. Our method visits fewer nodes than Yen X  X .

P ROOF . Although our method shares the same framework and time complexity in the worst case with those of Yen X  X , our method visits fewer nodes than Yen X  X  method. It is mainly due to the early termination strategy in the shortest path discovery from the devia-tion node to target node over G side  X  X .

We quantitatively represent the visited nodes in our method. Let spt in ( t, G ) be the shortest path tree rooted at the target node and p the shortest path from s to t . For each node d in p and the ignored node set IgN from s to d in p , the covered nodes Covered is the union of Desc ( i ) ,where i  X  IgN and Desc ( i ) is the de-scendant node set of i in spt in ( t, G ) .When d is selected as the deviation node, we need to discover the shortest path from d to t . With the rules discussed above, we continue searching when the newly finalized node is in Covered ( d ) . However, when the newly finalized node, such as u , is not in Covered ( d ) , the status of u will be assigned with Terminated Intermediately . Therefore, for each deviation node d , the location of the shortest path only handles the nodes in Covered ( d ) . As for the i -th path p i , we need to dis-cover nodes ( p i ) candidate paths. The number of nodes visited is the number of nodes visited in Yen X  X  algorithm is nodes ( Since the size of Covered ( p i [ j ]) is smaller than n , our method runs faster than Yen X  X . The previous section focuses on the candidate path discovery. In this section, we introduce two optimization techniques, one to reduce the total iteration times for the shortest path discovery, and the other to prune the search space for each of the iterations.
One important observation is that the cost of the i -th shortest path has a high probability to be same as that of ( i +1) increases. We confirm this on two real graphs Add32 ,and Gupta3 ( Section.5 gives more information about the graphs ). We randomly select two nodes, compute the top-1000 shortest paths on them, and investigate the cost distribution. The result is plotted in Fig.7. From Fig.7(a), we can see the cost of the 200-th shortest path is approximately 270, and that of the 800-th is about 350. Thus for each cost in the range (270,350), there are averagely 3 paths of the same cost. The property is reflected more obviously in Fig.7(b). There are approximately 200 paths with their costs in the range (35,38).
As for the reason to this observation, the paths between two given nodes can be viewed as permutation and combination of edges. On the one hand, the distribution of their costs often shows a com-mon pattern: there are few paths with extremely small or large costs, and the majority of the paths have costs close to the aver-age value. On the other hand, their number is really massive for large graphs. Even if the graph takes a DAG(Directed Acyclic Graph) form, the number of different paths can be exponential to the number of nodes in the graph. Therefore, for a k in real-life applications, cost ( p k ) can hardly reach an extremely large value. It converges to the average length as k increases relatively.
Our first optimization strategy takes advantage of such a prop-erty. All the candidate paths are maintained in a minimum heap L with the path cost as the key. When a path with the currently mini-mal cost is selected from L as the k 1 -th shortest path, our algorithm gets all other candidates of the same cost at the same time. Suppose there are k 2 such candidates, if k 1 + k 2 &gt;k , we can then termi-nate searching immediately. We call this strategy k reduction .It can greatly reduce the candidate discovery times when k is relative large without impacting the correctness of the results.
Our second optimization aims to reduce the cost for candidate path generation in each iteration. As discussed before, in each iteration, a candidate path from the selected deviation node will be generated, and there are O ( n ) nodes acting as deviation nodes. Therefore total O ( n ) single-source shortest path discovery is re-quired for each newly discovery path. Consider the fact that no matter how many candidate paths we find, there will be no more than k in the final results. We can stop exploring early if it is im-possible for the currently handled candidate to rank in the top k .
One solution to carry out such an idea is that, we keep an es-timated cost for the k -th shortest path, denoted as cost stop searching for the current candidate path when its cost exceeds cost est ( k ) in G  X  X . In this way, a lot of unnecessary discov-eries are avoided, and only part of the original graph is searched, which we call Searching Sub-Graph . We illustrate the processing in Fig.8. Suppose the currently deviation node is d ,and u is the newly finalized node. The searching sub-graph is made up by all the nodes explored, as the grey circle depicted. When searching on G side  X  X , the threshold cost thd is derived as cost est ( The construction of the shortest path tree spt out ( d, G be terminated immediately the costExt of the newly finalized node is larger than cost thd .

The next key problem comes to the determination of the thresh-old cost thd . It is clearly that the optimal threshold can be achieved when cost est ( k )= cost ( p k ) . However, it is not trivial to obtain this tight bound. We have no idea of cost ( p k ) when the algorithm runs, thus we decide the threshold based on the top-k seen shortest paths. In this paper, we design two policies, namely eager and lazy policy, to the determine the threshold cost thd .

When taking the eager policy, instead of generating only one candidate path from each deviation node, we try to generate as many paths as possible from each deviation node, until there are k paths. Then, cost est ( k ) is set to the largest cost among all these k paths. The advantage of this policy is that, the threshold can be determined as early as possible and used in the following candidate paths generation to restrict search space. However, the disadvan-tage is also obvious: it needs to search some extra paths to get the threshold.

When taking the lazy policy, we still compute only one candidate path for each deviation node. The threshold can be determined after the first k candidate paths are generated. The advantage of this policy is that no extra searching is involved. The disadvantage is that the first k candidate paths are generated without using any valid threshold.

In both strategies, after k candidates have been found, a k -sized maximum heap is used to record the currently seen top-k paths with their costs as keys. cost est ( k ) is set to the cost of the path at the heap-top. When a new candidate path is generated with its cost smaller than that of the heap-top, we replace the heap-top with it, sift the heap, update cost est ( k ) to the new value on heap-top and refine the threshold accordingly.
In this section, we conduct extensive experiments on both real and synthetic data sets, to demonstrate the efficiency and scalabil-ity of our method. We are mainly interested in the following pa-rameters: i) n or | V | , the number of nodes in the graph; ii) k ,the number of paths to be discovered; iii) d , the density of the graph. Three of our methods are tested: the algorithm with the k reduction strategy described in 3.1 (denoted as KR), the one using k reduc-tion along with the pruning searching on the threshold determined in an eager(lazy) way (denoted as KRE(KRL)). We compare our methods with two other algorithms namely: Yen X  X  algorithm (de-noted as YEN) and the replacement-based algorithm proposed by John Hershberger et al[10](denoted as JH).
The real networks used in our experiments include Add32 , Crack Gupta3 2 and FLA 3 . Some statistics of them are gathered in Table 1. The synthetic graphs are generated by Barabasi Graph Generator v1.4 4 , developed by Derek Dreier. It can create graphs possessing power laws associated with the outdegree of the nodes.

The implementations of Yen X  X  and Hershberger X  X  method were complied with Microsoft Visual C++ 6.0. The codes are provided http://staffweb.cms.gre.ac.uk/ wc06/partition/ http://www.cise.ufl.edu/research/sparse/matrices/Gupta/ http://www.dis.uniroma1.it/ challenge9/download.shtml http://www.cs.ucr.edu/ ddreier/barabasi.html by John Hershberger. All of our methods were implemented in JAVA with JDK 1.6. Considering the fact that JAVA codes gener-ally run slower than C codes, we can show the efficiency of our method by comparing our implementation in JAVA and theirs in C. All the tests are carried out on a server with 8 AMD Opteron(TM) 865, 1.80GHz Processors, running over an operating system of Mi-crosoft Windows Server 2003 Enterprise x64 Edition, Service Pack 1. Our method roughly requires 2G of RAM during runtime.
In this sub-section, we study the impact of graph size, graph den-sity and different k on the top-k algorithms.
 Impact of graph size. We begin by studying the impact of the graph size. This set of experiments are conducted on a group of synthesized graphs. For each graph, we fix the graph density to 3 and increase the graph size from 10k to 100k nodes.

Figure 9(a) and Figure 9(b) summarize the time consumed by the five methods finding the top 100 and top 1000 shortest paths, respectively. The efficiency of our methods is conspicuous. Take the discovery of the top 100 paths in a graph with 100k nodes as an example, JH needs more than half an hour and YEN consumes as long as two hours. Instead, our methods only take less than two seconds to do the same job. The reasons are as follows: first, JH still needs much time cost in the edge-replacement based candidate path generation; second, the switch cost is really expensive when a loop is detected. Furthermore, from these figures we can see that, the curves representing our methods are almost horizonal, while the running time of the other two is much longer and increases drastically. This could be due to that in JH, many old edges must be deleted from their tree structure and new edges have to be added each time the candidate path is computed. Also, we can notice the role of the optimization strategies used in our method in Table 2. When k is set to 100, KR runs fastest of all, while in the case where k=1000, the other two pruning strategies have more advantage, with KRE being the most efficient.
To further analyze the scalability of our methods, we measure the proportion of the time for constructing the shortest path tree to the total time based on this group of graphs. More formally, we introduce a ratio SPTTimeRatio = t 1 /t 2 ,where t 1 is the time for building the shortest path tree spt in ( t, G ) ,and t time cost.

Figure 9(c) compares SPTTimeRatio over graphs of different size when k = 1000. We can see that, with the increase of time for setting up the shortest path tree remains about the same proportion of the total time, which means the relationship between shortest path tree construction time and paths discovery time is al-most linear. This fact shows the scalability of our methods as the data grows larger.
 Impact of k . We measure the efficiency of the five algorithms when k increases. We carry out this set of experiments on four real graphs. They are Add32 , Crack , Gupta3 and FLA . Table 3 shows the overall performance. Since YEN and JH would take un-endurably long time to process FLA , we omit there running time.
Since YEN is a comparatively old algorithm and always takes very long time, in the following charts we omit its curve in order to have a clear comparison between the other four methods. Figure 9(d) and Figure 9(e) illustrates the experimental results on Crack and Gupta3 varying k from 10 to 100, respectively. Gupta3 is more denser than Crack . Generally, our methods show a good efficiency as well as scalability. From Figure 9(d), we can see that, our methods are at least one order of magnitude faster than JH. Besides, with the increase of k , the time cost of JH increases dra-matically while those of our methods rise slightly. The advantages are more obviously on Gupta3 , as illustrated in Figure 9(e). We can see, our methods run at least two orders faster than JH, and the scal-ability regarding k is even apparent. Further analyze the three our methods, we can find on this data set that, KRE runs incredibly fast compared with the other two. That X  X  because in such a dense graph, it is easier for KRE to obtain a strict threshold through exploring the first node.
 Figure 9(f) plots the SPTTimeRatio on Gupta3 varying k . Since the shortest path tree rooted at the target node is built one time, the other time cost comes from the computation of k paths. From the figure, we can observe that the SPTTimeRatio de-crease nearly in a linear way with the increase of k . It indicates that the time cost for each shortest path is nearly the same. We also notice the role of the different optimization strategies. Generally, KR needs more time to discover top-k paths after the shortest path tree is constructed. KRL X  X  ratio is much higher than KR X  X , and the time ratio of KRE is the highest of all.
 Impact of Graph Density. Next we examine the impact of graph density on the query performance. Two other synthetic graph groups are used, in one of which we fix the node number at 10 K while in-crease the density from 2 to 10, and in the other, the node number is fixed at 100 K with the same density range. Test results with k = 1000 are presented in Table 4.
Figure 10(a) and 10(b) show the query time results on these two graph groups when | V | = 10 K and 100 K , respectively. The result is quite similar to that of the previous experiment. We can not only see the great advantage of our methods with regard to the overall time consumption, but also conclude that the running time of our methods increases very slowly with the increase of graph density.
Figure 10(c) shows the SPTTimeRatio on graphs with 100k nodes with the varying of the density. It can be observed that the SPTTimeRatio does not reduce significantly with the increase of density. From all three experiments related with SPTTimeRatio , it seems that the time cost of our method is related with O nlogn )) over the test set, although we cannot reduce the worse-case time complexity of Yen X  X .

Density | V | YEN JH KR KRE KRL 3 10k 1321 557.4 2.251 0.657 1.969 6 10k 2986 1129 2.485 0.953 2.392 9 10k 5982 2048 2.437 0.993 2.280 3 100k 21621 5872 2.923 1.688 2.734 6 100k 41092 12323 3.469 2.110 3.297 9 100k 55342 16887 4.048 2.469 3.938 Summary. To sum up, from the empirical results, we can draw the following conclusions: i) Our methods provide high efficiency. Generally speaking, they are often at least two or three orders of magnitude faster than the existing two. ii) Our methods show good scalability w.r.t. the number of paths to discover, the number of nodes and graph density. iii) All the optimization strategies im-prove the performance of our algorithm. The threshold method with the eager determination strategy always works well when the graph is large or with a great density.
The problem of shortest path discovery has been studied for a long time by the graph theory community. Well known algorithms for this problem include Dijkstra X  X  algorithm[6], which solves the single-source shortest path problem, and Floyd-Warshall algorithm[8], which solves the all-pairs shortest paths problem. The current ver-sion of our method is based on Dijkstra X  X  algorithm and all the other improved algorithms provide us a way to optimize our approach.
Different kinds of graph queries receives high attention from the database community. Reachability query reports whether there is a path between two given nodes, and distance query yields the short-est distance between two given nodes. Many methods have been proposed [18, 14, 3, 4] to solve these problems and several at-tempts have been made to improve the runtime performance over large graphs. However, none of them can be extended directly to cope with the top-k shortest paths problem.

The top-k shortest path problem can be divided into two cate-gories according to whether loops are allowed in the discovered paths. The top-k general shortest paths problem [2, 13, 5] is rel-atively easy compared with the simple path version. Eppstein X  X  algorithm offers the best performance for the general problem. It pre-computes the shortest path tree rooted at the target node and an-notates each edge with side cost. With sophisticated data structure, it achieves the time complexity of O ( m + nlogn + k ) . The well known algorithm for finding the top-k simple shortest paths is due to Yen [19]. It considers each node in the newly generated shortest path as the deviation node, and executes a single-source shortest path discovery to generate one candidate path. Thus, total O shortest path computation is needed, resulting in a worst-case time complexity of O ( kn ( m + nlogn )) .

There have been several practical improvements to Yen X  X  algo-rithm[15, 11]. Martins et al proposed an incremental method to reduce the shared computation cost [15]. Hershberger et al pro-posed a method to generate candidate paths based on the fast re-placement of edges. The advantage of such a method is that the generation time to handle each newly discovered path can be re-duced to O ( m + nlogn ) , although it may fail in some cases. A recent study [10] proposes a method to use the fast replacement as the default method, and switch to a slower but correct method when a looped path is erroneously selected. Matins et al [16] suggest a method to build the shortest path tree rooted at the target node, and discover the extra costs for each edge. However, they only discuss one edge extension from the deviation node rather than a valid sub-path. What X  X  more, they do not consider the loop detection and there are no experimental results, either.

The top-k query processing is extensively studied in the applica-tions with potentially huge answers. To solve this problem, efficient stopping strategies are carefully designed, such as TA [7], BPA[1], etc. Usually, a bounded threshold will be selected and adaptively refined to prune the search space. Our optimization strategy takes a similar idea to generate the threshold adaptively and incorporate it into the original method seamlessly.

On the other side of the related work is the structural encoding for XML document. The interval encoding can be used to deter-mine the ancestor/descendant relationship in a constant time with-out the traversal of the entire tree[9]. The Dewey encoding[17] is another kind of structural encoding, which consumes more space but can support update in an easier way than interval encoding. Our method chooses the interval encoding due to the less space cost re-quired. In addition, the dynamic update of graph is not our main concern, since we build the shortest path tree for each query.
In this paper, we proposed a new method for efficiently generat-ing the top-k simple shortest paths. With the early termination strat-egy in the shortest path discovery over the transformed graph, our method dramatically reduces the cost in the candidate path genera-tion. Also, we provide two optimization strategies to further speed up the discovery. The extensive experiments demonstrate that our method outperforms other methods significantly.

The future work involves a list of interesting directions: First, we will study the approximate top-k shortest paths problem. Since the worst-case time complexity of our method is still O ( nlogn )) , approximate results with the guaranteed error bound will be acceptable in some applications. Second, we will investigate the "kernel" of graphs for the top-k shortest paths. Based on the observation that the nodes in the top-k shortest paths only occupy a small percentage of total nodes, we plan to find a more com-pact structure to incorporate all the computed paths. Actually, the searching sub-graph in our method provides an alternative. Third, it is also a promising direction to extend the current top-k shortest paths between two nodes to the paths between two node sets. We would like to thank John Hershberger for kindly providing us the code of their top-k shortest paths algorithm. [1] R. Akbarinia, E. Pacitti, and P. Valduriez. Best position [2] R. Bellman and R. Kalaba. On kth best policies. Journal of [3] J. Cheng and J.X. Yu. On-line exact shortest distance query [4] J. Cheng and J.X. Yu. On-line exact shortest distance query [5] David Eppstein. Finding the k shortest paths. SIAM J. [6] Dijkstra E.W. A note on two problems in connexion with [7] R. Fagin, A. Lotem, and M Naor. Optimal aggregation [8] Floyd and Robert W. Algorithm 97: Shortest path.
 [9] Torsten Grust. Accelerating xpath location steps. In [10] J. Hershberger, M. Maxel, and S. Suri. Finding the shortest [11] J. Hershberger and S. Suri. Vickrey prices and shortest paths: [12] J. Hershberger, S. Suri, and A. Bhosle. On the difficulty of [13] W. Hoffman and R. Pavley. A Method for the Solution of the [14] R. Jin, Y. Xiang, N. Ruan, and H. Wang. Efficiently [15] E.Q.V. Martins and M.M.B. Pascoal. A new implementation [16] E.Q.V. Martins, M.M.B. Pascoal, and J.L.E.D. Santos. [17] I. Tatarinov, S.D. Viglas, and et al. Beyer. Storing and [18] S. Tril and U. Leser. Fast and practical indexing and querying [19] J. Y. YEN. Finding the k shortest loopless paths in a network.
