 Abbreviations (also referred to as short-forms of words or phrases) are widely used in current articles. Abbreviations form a special group of unknown words that mainly originate from technical terms and named entities. Consequently, expanding information extraction and information retrieval systems [1][2][3]. 
Over the past years, much progress has been achieved in English abbreviation resolution and various methods have been proposed for the identification and expansion of abbreviation in English, including rule-based methods[1], statistically -based methods [2] and machine learning methods [3][4]. However, the study of some studies been reported on the expansion of abbreviations in Chinese [5][6]. In this paper, we propose an n-gram language model (LM) based approach to Chinese abbreviation expansion. In this study, we distinguish reduced abbreviations from non-reduced abbreviations that are created by elimination or generalization, and apply different strategies to expand them to their respective full-forms. For a reduced long-words, and a bigram based Viterbi algorithm is then applied to decode a proper combination of long-words as its full-form. For a non-reduced abbreviation that is created by elimination or generalization, a dictionary of abbreviation/full-form pairs is further employed to select a proper expansion based on bigram word segmentation. Evaluation on an abbreviation-expanded corpus built from the Peking University (PKU) corpus shows that our system is effective for different Chinese abbreviations. In general, Chinese abbreviations are created using three major methods, namely reduction, elimination and generalization. Corresponding to these methods, there are three types of abbreviations in Chinese, namely reduced abbreviation, eliminated abbreviation and generalized abbreviation [6][7]. 
Given a full-form let ) 1 ( m i f one component of the relevant short-form, then the above three types of Chinese ab-breviations can be formally redefined as follows: 
If m n = and (namely for 1 = i to n , created by reduction. 
If m n &lt; and ) 1 ( n j F s implies that each component of an elim inated abbreviation should be a remaining part of its original full-form even though some parts of the full-form are eliminated during abbreviation. 
If m n &lt; and ) 1 ( n j F s some additional morphemes or words are usually needed to abbreviate an expression with generalization. 
With the above formal definitions, we can distinguish reduced abbreviations from non-reduced abbreviations and deal with them in different ways. Here, non-reduced abbreviation is a general designation of the latter two types of abbreviations. 
Table 1 presents a survey of Chinese abbreviations on the Peking University (PKU) corpus. The original PKU Corpus contains six month (Jan to Jun, 1998) of segmented and part-of-speech tagged news text from the People X  X  Daily [8], in which the tag  X  j  X  is specified to label abbreviations. In this survey, the first two month is se-manually paired with their respective full-forms. Among a total of more than two million words, there are only about twenty thousand abbreviations. However, these abbreviations are widely distributed in different sen-tences. As can be seen in Table 1, more than 14% of sentences have abbreviation(s). In addition, about 60% of abbreviations are observed to be reduced abbreviations. This demonstrates in a sense that reduction is the most popular method among the three methods for creating Chinese abbreviations. 
Corpus No. words No. sentences Reduced
February 1.15M 48,095 6,655 (59.7%) 4,498 (40.3%) 11,153 7,137 (14.8%) Chinese abbreviations may be created either by the method of reduction or by the method of non-reduction (viz. elimination or generalization). However, we do not know exactly how a given abbreviation is created before expansion. To ensure any abbreviation can be expanded, we assume that a given abbreviation could be created the three methods and develop a statistically-based expansion system for Chinese. 
Fig. 1 illustrates an overview of our system for expansion, which works in three first assumed to be a reduced abbreviation. Then, a mapping table between short-words and long-words is applied to map each short-word within the abbreviation to a set of long-words. Finally, a decoding algorithm is employed to search an appropriate combination of long-words as its full-form based on n-gram language models (LMs). viewed as a non-reduced abbreviation. Then, a dictionary of non-reduced abbreviation n-gram word segmentation is employed to select a proper expansion if any. (3) If the above two steps come out with two different expansions, a final disambiguation is used to make a choice between the two expansions by comparing their respective n-gram scores. The one with a higher score is chosen as the resulting expansion. 3.1 Expanding Reduced Abbreviations 3.1.1 Generating Expansions with a Mapping Table characteristics of a reduced abbreviation: each character or word in a reduced abbre-viation must match a word in its original full-form. In this study, characters or words consisting of an abbreviation are designated as short-words while the constituent words in a full-form are referred as long-words hereafter. Given a reduced abbrevia-candidates can be thus determined by combing exhaustively the relevant long-words. duced abbreviations to a set of long-words. With this mapping table, expansion can-didates for a reduced abbreviation can be generated as follows: First, the reduced ab-dictionary of normal Chinese words. Then, each segmented short-word is mapped to a set of long-words by consulting the mapping table. All the generated long-words and their matching short-words are stored in a lattice structure. Obviously, any combina-tion of the relevant long-words forms an expansion candidate. 
Short-words Full-words English translation ... ... ... 3.1.2 Disambiguation as N-Gram Decoding The disambiguation of reduced abbreviations is actually a process of decoding in that the expansion candidates for a given reduced abbreviation are implicitl y involved in a lattice of long-words. Obviously, each path from the beginning to the end of the abbreviation. Consequently, the goal of disambiguation for a reduced abbreviation is to decode a best path from the lattice. In our system, an n-gram based Viterbi algorithm is applied to perform this task. 
Given a reduced abbreviation S , let of long-words generated with the above mapping table, L and R stand for the respective left and right context around the abbreviation. Expansion decoding aims to the n-gram probability, namely Where ) | ( contextual words. With a view to the problem of data sparseness, a bigram LM is em-ployed in our system, namely 2 = N . Let the left and right of the abbreviation, we have ) | ( ) | ( 3.2 Expanding Non-reduced Abbreviations 3.2.1 Generating Expansions with a Dictionary of Abbreviations According to the definition in Section 3, a one-to-one mapping relationship no longer exists between constituent words of a non-reduced abbreviation and the component words within its full-form. The above mapping table is therefore not workable in generating expansions for a non-reduced abbreviation. In order to address this problem, a dictionary of abbreviation/full-form pairs is applied here, which maps each non-reduced abbreviation to a set of full-forms and can be manually compiled or automatically compiled from an abbreviation-expanded corpus. Table 3 presents some pairs of non-reduced abbreviations and their full-forms extracted from the abbreviation-expanded corpus in Table 1. Short-forms Full-forms English translation ... ... 3.2.2 Disambiguation as N-Gram Word Segmentation In contrast to a reduced abbreviation whose expansion candidates are underlying in a lattice of long-words, a non-reduced abbreviation is directly mapped to a set of expansion candidates during expansion generation. Consequently, disambiguating a sequence of words using bigram LMs. The one whose segmentation has the maximum score will be identified as the most probable expansion. In evaluating our system, we conduct two experiments on the abbreviation-expanded corpora in Table 1, in which the first month is used for training while the second month is for open test. The results are summarized in Table 4 and Table 5, respectively. Recall (%) 56.5 69.4 71.0 82.9 Precision (%) 65.9 77.5 75.1 85.5 Table 4 presents the evaluation results for different training data and n-gram LMs. Both the mapping table and the abbreviation dictionary used in this evaluation are ex-tracted from the training corpus only. As can be seen from this table, our system is ef-fective for a majority of abbreviations in Chinese. A recall of 82.9% and a precision of 85.5% are achieved on average for different abbreviations if a bigram LM trained with the expanded corpus is applied. Furthermore, an abbreviation-expanded corpus is of significance in developing a high-performance expansion system for Chinese. both recall and precision can be substantial improved by using an abbreviation-expanded which all abbreviations remain unexpanded. Table 4 also shows that bigram LMs out-perform unigram LMs, which proves that higher-order LMs are usually more power-ful than lower-order LMs in Chinese abbreviation disambiguation. dictionary are Recall Precision Recall Precision from the training corpus only 71.0 75.1 82.9 85.5 from both the training corpus and the test data 76.9 80.1 87.3 88.7 
Table 5 presents the results for different mapping tables and abbreviation dictionaries improved from 82.9% and 85.5% to 87.3% and 88.7% for bigram LMs if all the dictionary is of great value to Chinese abbreviation expansion. However, acquiring such produced in Chinese text and their identification remains unresolved at present. In this paper, we presented an n-gram based approach to Chinese abbreviation abbreviations, we distinguish reduced abbreviations from non-reduced abbreviations. In our system, a given abbreviation is expanded as a reduced abbreviation and a non-cases, the one with higher score is selected as the resulting expansion. Evaluation on an abbreviation-expanded corpus built from the PKU corpus showed that our system achieved a recall of 82.9% and a precision of 85.5% on average for different abbreviations in Chinese news text. For future work, we hope to improve our system by exploring and acquiring dynamically more features for expansion disambiguation. This study was supported in part by Hong Kong Research Grants Council Competitive Earmarked Research Grant 7271/03H. We also would like to thank the Institute of Computational Linguistics of the Peking University for their corpus. 
