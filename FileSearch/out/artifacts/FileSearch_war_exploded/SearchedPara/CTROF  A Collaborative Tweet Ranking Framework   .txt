 In recent years, microblog such as Weibo and Twitter becomes very popular, because it allows users to post a short message named tweet or status for sharing viewpoints and acquiring knowledge in real time. According to statistics, more than 400 million tweets are generated per day in Twitter. As a result, the rich information in microblog not only expands our horizon, but also has wide applications in public opinions su-pervision, natural disaster prediction and political upheaval detection. 
Microblog facilitates our life, but the information overload problem prevents it from developing further. A user usually follows many interested users such as friends, updates. So the users are hard to consume so much content instantly in an effective way. In some cases, as for those with limited time to read, it X  X  necessary to filter out those irrelevant and boring tweets by online recommending expected content. 
There are several challenges to be tackled for online personalized tweet recom-mendation. Firstly, although some latent factor models such as CTR [1] (Collabora-tive Tweet Ranking) have been proposed, yet they show poor performance as the da-taset grows larger. Secondly, online algorithms can shorten the processing time, but they also reduce prediction quality. Thirdly, most online algorithms are generally based on recent data, and don X  X  consider the history records which are relevant with users X  customs and preferences. All the problems above have posed severe challenges for online tweets recommendation. 
In this paper, we propose a Collaborative Tweet Ranking Online Framework (CTROF). Figure 1 below shows the algorithm process. Suppose we have some tweet history data in advance, we build an initial model called Optimized Collaborative Tweet Ranking model CTR+. For recommendin g the interested tweets in real time, we sample the tweet stream to update Double Reservoir for capturing the  X  X ketch X  of the stream. Then the training set is sampled and the initial CTR+ base model can be updated incrementally. Eventually, we get an online model for recommending inter-ested tweets to users. 
To the best of our knowledge, this work is the first experimental study to integrate tweet content (past and online), social structure and personal profile into collaborative filter model, and demonstrate a practical online personalized tweet recommendation framework. To summarize, the main contributions of our work are as follows. (1) We propose a novel CTROF for online personal tweet recommendation. The novelty lies in a complete stream processing framework for real-time tweet ranking. (2) We improve the performance of state-of-the-art tweet recommendation model CTR [1] by introducing personal hashtags to optimize BPR (Bayesian Personalized Ranking) [2], and creatively apply the model into online scenario. (3) We use Reservoir Sampling algorithm for acquiring the  X  X ketch X  of incoming tweet stream dataset, which considers both the historical and the changing prefe-rences. (4) Finally, our algorithm considers the performance of time and space, and is able to balance the recommendation quality and the complexity of time and space well. 
The structure of the rest of the paper is as follows. Related work is discussed brief-ly in Section 2. In Section 3, we briefly review CTR and propose a novel CTR+ rec-ommendation model. In Section 4, we introduce the collaborative tweet ranking on-line framework CTROF. Section 5 introduces the classification of explicit features in detail. Section 6 compares CTROF with the other baseline models. In Section 7, we make a conclusion and point out the directions for our future work. CF (collaborative filtering) technique behind RS (recommender system) has been developed for years and kept to be a hotspot in academic and industrial field. Real applications include goods at Amazon, news at Google, movies at Yahoo and CDs at Netflix. In recent years, latent factor model proposed by Simon Funk has been widely applied in CF. Koren [3,4] and Xiang &amp; Yang [5] improved it by considering neigh-borhood or time. Besides explicit feedback (rating), abundant implicit feedback [6] was also used. In high-order setting, Tensor Decomposition models [7,8] were stu-died. In addition, some learning methods were studied, such as Stochastic Gradient Descent (SGD), Alternating Least Squares [9] and Markov Chain Monte Carlo [10]. 
RS in microblog generally contains six categories factors in content: followee, follower, hashtag, tweet, retweet and URL. In recommendation pattern, it includes offline and online RS. In offline RS, [11] ranked incoming tweets by using author profile, syntactic feature, content and followee feature. Hong et al. [12] proposed a co-factorization machine to model interest and recommend relevant tweets. Chen et al. [1] proposed CTR model with high precision, however extra user preference signs, i.e. labels, were not considered. In addition, offline models are not suitable in online scenario with large continuous incoming data. In online RS, Diaz-Aviles et al. [13] proposed a RMFX online framework, however it had complex sampling algorithm and just considered hashtags of tweet. Work for ranking tweets also includes [14,15]. 
In this paper, we focus on recommending tweets in real time by integrating offline model and stream sampling algorithm together. We propose a novel CTROF frame-work by improving the drawbacks of Chen and Diaz-Aviles X  X  work and absorbing their advantages. For this purpose, we first review CTR model briefly and propose an innovative CTR+ model by considering content, social relation and hashtags in Section 3. And then we utilize Reservoir Sampling [16] algorithm and propose a CTROF algorithm framework for ranking tweet stream in Section 4. 3.1 Notations Definition any two entities, which shows the degree of interest. Then we get an interactive ma-trix X : U  X  I , and each element x ui  X  X represents an observation value. Predicting ui x  X  value can be seen as the task of estimating X  X  . As we aim to get a personalized total Ranking for estimating X  X  , instead of Root Mean Square Error (RMSE). As for any 
After above modeling process, a basic offline model is built. Based on the model, we give out an optimized collaborative tweet ranking model CTR+ in offline scenario. 3.2 Optimizing Offline CTR to CTR+ Model CTR [1] is an excellent offline RS, consider s content, social relation, and explicit fea-tures simultaneously. In view of data sparsity and expandability, each tweet is de-composed into several words at topic level. All words from tweet set I constitute bag of words. Therefore, let u  X  U and i  X  I , CTR model is described as follows: word bias, and Z is normalization term which equals | W i | 1/2 in general. 
In addition, social relations are also important because users are more likely to ret-weet favorite publisher X  X  tweets. As for any incoming tweet i , it can be mapped into corresponding publisher p ( i ). So the formula can be further rewritten as: and  X  is an adjustable weighting parameter indicating publisher X  X  importance relative to content. 
In this paper, we introduce personal hashtags, a profile of personal interests and hobbies, into CTR model. Suppose users with similar interests are more likely to ret-hashtag set H p ( i ) . So we rewrite Formula (2) and represent CTR+ as: an adjustable weighting parameter indicating hashtags X  importance relative to the con-
Besides the above latent features, information such as tweet quality can also be in-weighted linear combination of bias  X  X  and explicit feature biases. In the final CTR+ offline model, we get Formula (4) shown below: where b j is any latent or explicit feature bias and r j is weighting parameter represented set 1 by default. Details about explicit feature classification are discussed in Section 5. 
Different from rating prediction, users just need to be recommended a list of sorted tweets. Similar to [1,12], retweet represents users X  preference. Slightly different from Root Mean Square Mean in rating prediction, a BPR method is used instead. 
Given a tweet set I , we should transform I into training set D in the form of tuples  X  D denotes a training instance, where i  X  R u has been retweeted and j  X  R u not. Thus, D follows normal distribution N (0,  X   X  ), in which diagonal matrix  X   X  =  X   X  E, E is a unit diagonal matrix and  X   X  is a constant, we aim to maximize the formula below: where  X  is sigmoid function. For convenience, Formula (5) is transferred as equivalent Formula (6) below by maximizing logarithm of posterior probability: 
In general, SGD is used for estimating parameter space  X  , and  X   X  ||  X  || 2 is a L2 re-gularization term. The training process of CTR+ model is shown below. 4.1 Building Online CTROF Model In Section 3, we discussed CTR+ with tweet training set D . CTR+ is an offline model, because D is a static training set. As for new incoming tweet i + , we calculate ui x  X  + by rio, which update model dynamically every time new tweets arrive. In social network (such as Facebook) or microblogging service (like Twitter and Sina Weibo), messages are updated rapidly. A flow of messages constitutes data stream, called tweet stream in Twitter or Weibo. Diaz-Aviles [13] proved that Reser-voir Sampling outperformed Single Pass, User Buffer, and captured the  X  X ketch X  of history under the constraint of fixed space quite well. CTROF uses it and achieves online model by training CTR+ incrementally without retraining model completely. 
Under the background of tweet stream, we use S to represent incoming tweet weet stream S ret and non-retweet stream S nret . Our algorithm maintains two fixed size Reservoirs R + and R  X  , which contains random samples from S ret and S nret . So the key is t =| R  X  |. For subsequent t , we will decide whether a new incoming tweet will be put in reservoirs or not, and in which the old record will be replaced instead. The process of Collaborative Tweet Recommendation Online framework CTROF is shown below. In above process, we selectively update two fixed-size reservoirs R + and R  X  by Reservoir Sampling algorithm every time a new tweet arrives. For convenience, let R * Above Reservoir Sampling ensures that each tweet is selected with equal probability. 4.2 Updating Online CTROF Model In Algorithm CTROF Framework, updateCTR+Model (Line 11) updates the model incrementally by sampling training instances from R * . We design a simple but effec-tive sampling strategy by computing time distance between retweet and nonretweet. stance pairs as TrainSet , and perform model update based on it. 
Here notation o + denotes parameter vector of pair ( u , i ), while o  X  for ( u , j ). We use =+ for convenience. Given new reservoirs R + and R  X  , we update model incrementally. Therefore, CTROF captures the history  X  X ketch X  and the current inter-est, and can overcome the problem of short-memory and avoids retraining model. In Section 3, we introduce CTR+ integrating linear combination of explicit features for capturing users X  interests. Although [1,12] have defined different categories re-spectively, yet we will propose a more complete solution including four categories. 8 K. Song et al. 1) User Relationship Features: User relationship feature refers to the relationship between target user u and his/her friend v . It makes an assumption that: The more familiar with each other, the more likely to retweet his/her messages.  X  Co-Friends Score: The similarity between u  X  X  followee set and v  X  X .  X  Co-Follow Score: The similarity between u  X  X  follower set and v  X  X .  X  Mention Score: The number of times u mentions v .  X  Retweet Score: The number of times u retweets v .  X  Reply Score: The number of times v replys to u .  X  Mutual Friend Score: If u and v follow each other, it is 1, else 0. 2) Content Features: The features are the relevance between new incoming tweet i status data, RP( u ) as word set of u  X  X  retweet data, LP( u ) as hashtag set of u  X  X  profile, NP( u ) =SP( u )  X  RP( u )  X  CP( u ), and  X  ( w 1 , w 2 ) as similarity between two term sets.  X  Relevance to Status:  X  ( w ( i ), SP( u )) is the similarity between w ( i ) and SP( u ).  X  Relevance to Retweets:  X  ( w ( i ), RP( u )) is similarity between w ( i ) and RP( u ).  X  Relevance to Hash Tags:  X  ( w ( i ), LP( u )) is similarity between w ( i ) and LP( u ).  X  Relevance to Neighborhood:  X  ( w ( i ), NP( u )) is similarity of w ( i ) and NP ( u ). 3) Tweet Features: Tweet features refer to the attributes of tweet, including gener-al tweet length, hash tag count, URL count, reply count, retweet count. In addition, we add another two new features, that is, thumb up score and view score.  X  Thumb Up Score: The number of times that tweet i is favorable or agreed.  X  View Score: The number of times that tweet i is viewed. 4) Publisher Features: Publisher features represent the influence power of corres-ponding publisher of i , including not only mention, followee, follower and status count in [1], but also activity degree and loyalty degree. Let time ui be the time u pub-lish tweet i ,  X  u =max{ time ui -time uj }( i  X  j ) as the period from first status to the last.  X  Loyal activity: The feature measures how long the publisher u is active in RS. In general, we use  X  u to show the degree of loyalty.  X  Activity Degree: The feature shows the activity of publisher and we may use NT( u )/  X  u to measure it, NT( u ) is the number of tweets that u has published. 6.1 Experiment Setup Our experiments are based on Sina Weibo platform and utilize the API tool [17]. Our work focuses on real-time personal tweet recommendation in Chinese microblog sce-nario and we use ICTCLAS [18] to handle word segmentation. For getting dataset, we randomly select a user and adopt user-based breadth-first traversal method by follow-ing followers and followees X  links. Different from [1], our dataset includes tweet content, retweet action, personal hashtags and social relation. Retweeted and non-retweeted tweets are named positive and negative samples respectively. The dataset includes 46385 users X  profile (user id, tags, followees) and their publishing historical data (tweet id, content, time, repost number). We select 675 users with more than 20 retweets, and others as their followees. Then tweets flood continuously from follo-wees into corresponding followers in chronological order. Three fifths of dataset is as training set and the others as testing set. Finally, training set for offline training con-tains 171,937 positive samples and 1,124,840 negative ones. Testing set contains 113,941 positive samples and 458,104 negative ones for offline testing. For testing stream dataset, we set parameters c r and c nr for controlling update frequency, and test-ing set can be further divided into tweet stream set S ={ s 1 , s 2 ... s 11 } by parameters, of which s n (1  X  n  X  10) is for incremental online training, and s n+ 1 for online testing. The experiment shows that the crawled dataset coincides with our proposed model. 
FM (Factorization Machines) [19] and SVD Feature [20] are generic factorization models tools. Considering coding workload an d algorithm efficiency, we use the later. 
Different from rating prediction, we focus on ranking tweets. So we measure rec-ommendation precision by P @ N and recommendation quality by MAP metric. Let n in list, averaging precision ( AP u ) is the average precision of each user: | R |  X  N . And p u @ n measures the precision of top n tweets. 6.2 Experiment Result In Section 3, we have proposed CTR+ model for offline tweet recommendation sys-tem modeling. CTR+ includes necessary components (explicit factor, term factor, social factor and hash tag factor). For studying components X  influence, we make a comparison by s 1  X  S in Figure 2. We compare MAP by N =15 and P @ N by setting N to 5, 10 and 15. The number of iterations and factors is set to 40 and 64 respectively. Relative weight parameters  X  and  X  are set 0.8 uniformly. CTR performs well (MAP=0.8074~0.8114) when  X  is around 0.8, so we choose best parameter 0.8. Given fixed  X  , we randomly select  X  =0.8 because MAP remains stable when  X  ranges from 0.7 to 1. As large training dataset rarely encounter the over-fitting problem, the regu-larization parameter  X  is set 0.005. For approaching optimal value, the learning rate  X  is set small value 0.004, despite a certain loss in convergence rate. 
Figure 2 shows the precision of CTR+ is always higher than CTR, and reflects the importance of single component and their combination. Chronological method X  X  pre-cision is shown for reference. For simplicity, we just choose explicit features (Text Length, Retweet Score, and Relevance to Hash Tags) as global features. We find that explicit features, term, hash tag, and social component improve MAP by 54%, 70%, 86% and 92% respectively relative to chrono logical method, which indicates all com-ponents are necessary and effective. CTR co ntains all components except hash tag, and outperforms any single component. However, CTR+, compared with CTR, im-proves precision by 12.3%, which indicates that our model is better. 
Figure 3 shows that runtime convergence of different models. All models have dif-ferent convergence rate and converge to steady values after 30 rounds. So our offline base model is reasonably set to 40 rounds. In addition, we calculate P @5 value by 10 K. Song et al. setting factor number to 32, 64, 80, 96, and 112. Term Feature (0.4438~0.4439), Tag Feature (0.6644~0.6752), Social Feature (0.8114~0.8124), CTR (0.8219~0.8229) and CTR+ (0.8637~0.8641) remains stable. Therefore, we set 64 factors reasonably. We imitate tweets flow into our framework in chronological sequence continually. size of reservoirs R + and R  X  to 10,000 and 40,000 respectively for reflecting real data distribution. Therefore, we won X  X  update our base model until 10,000 retweets and 40,000 non-retweets arrive. In order to verify prediction precision of top-N items in recommendation list, N is set to 5, 10 and 15 respectively. We compare our stream framework CTROF with two offline models CTR and CTR+. The MAP for each me-thod, in different list size, is shown in Figure 4 below. Figure 4 shows that online model CTROF achieves better performance over offline CTR, and slightly below than offline CTR+ model. Compared with CTR+, CTROF just capture information sketch by sampling, so precision is slightly lower. In addi-tion, additional hash tag factor represents personal preference and makes CTROF outperform CTR model. As online recommendations focus more on comprehensive performance of runtime, space and precision, our method saves lots of runtime and space and precision is close to best offline model CTR+. Next, we further discuss time, space and recommendation precision comparison of CTROF and CTR+, which are implemented by SVDFeature tool in C++. We ran CTR+ and CTROF on an Intel Core i7-2600 3.4GHz CPU and 2G memory virtual machine with Linux 32bit operating system. As none of the methods is parallel, we run the program on a single CPU. As the platform and implementation technique in-fluence the performance greatly, so the setting can be used as a reference indicator. 
The performance of CTROF is not only related to the number of factors and itera-tions, but also related to the training set size of the initial base model and the reservoir size. If we train base model with a very big training set about 1.3 million tweets, then the size of reservoir has little impact on the recommendation quality. That X  X  because long-term accumulated dataset may include almost all possible situations in terms, retweet relation and tags, so a small amount of tweet stream will not change the mod-el greatly. So we just choose about 0.4 million training instances, and set different sized reservoirs. The experiment comparison result is shown below. tweets. Time is the runtime sum of six tests, and Space is the disk space of training text. CTR+ [Baseline] 464s 100% 0.802 100% 
Table 1 shows that the reservoir size can influence the final recommendation qual-ity obviously. Offline model CTR+ is used as a reference. When reservoir is big enough, the data distribution is much more appropriate and close to real data distribu-R =20,000), and T 3 =( R + =10,000: R  X  =40,000) respectively. By comparison, we find T 2 is close to T 3 in recommendation quality, but faster than T 3 by 28.2%. In addition, T 2 outperforms T 1 by 2.5% within the scope of tolerable time. So we can draw a conclu-sion that recommendation quality is good enough when 5,000  X  | R + |  X  10,000 and R =4| R + |. In this paper, we propose an offline ranking model CTR+ which considers explicit feature, content, social relation and personal hashtags. Moreover, we propose a novel tweet ranking online framework CTROF for real-time personalized recommendation. CTROF integrates Reservoir Sampling algorithm and CTR+ together, which captures  X  X ketch X  of tweet historical data, and absorbs new preference change from incoming tweet stream in the meantime. By experiments, we show that CTR+ outperforms CTR offline model and CTROF can capture real data distribution and achieve quite good precision, which demonstrates that our proposed method is effective and efficient. 12 K. Song et al. 
Future work includes further analyzing semantics of content and studying more ac-curate and efficient sampling methods for improving the recommendation quality. We will consider more media factors in tweet such as images and videos. In addition, the tensor factorization for tweet recommendation is also our future direction. Acknowledgements. This work is supported by the State Key Development Program for Basic Research of China (Grant No. 2011CB302200-G), State Key Program of National Natural Science of China (Grant No. 61033007), National Natural Science Foundation of China (Grant No. 61100026, 61370074), and Fundamental Research Funds for the Central Universities (N100704001, N120404007, N100304004). 1. Chen, K., Chen, T., Zheng, G., Jin, O., Yao, E., Yu, Y.: Collaborative personalized tweet 2. Rendle, S., Freudenthaler, C., Gantner, Z., Schmidt-Thieme, L.: BPR: Bayesian Persona-3. Koren, Y.: Factorization meets the neighborhood: A multifaceted collaborative filtering 4. Koren, Y.: Collaborative filtering with temporal dynamics. In: KDD 2009, pp. 447  X 456 (2009) 5. Xiang, L., Yang, Q.: Time-Dependent Models in Collaborative Filtering Based Recom-6. Oard, D.W., Kim, J.: Implicit Feedback for Recommender Systems. In: Proc. 5th DELOS 7. Rendle, S., Marinho, L.B., Nanopoulos, A., Schmidt-Thieme, L.: Learning optimal ranking 8. Symeonidis, P., Nanopoulos, A., Manolopoulos, Y.: Tag recommendations based on ten-9. Pil X szy, I., Zibriczky, D., Tikk, D.: Fast als-based matrix factorization for explicit and im-10. Salakhutdinov, R., Mnih, A.: Bayesian probabilistic matrix factorization using Markov 11. Uysal, I., Croft, W.B.: User oriented tweet ranking: A filtering approach to microblogs. In: 12. Hong, L., Doumith, A.S., Davison, B.D.: Co-factorization machines: Modeling user inter-13. Diaz-Aviles, E., Drumond, L., Schmidt-Thieme, L., Nejdl, W.: Real-time top-n recom-14. Feng, W., Wang, J.: Retweet or not?: Personalized tweet re-ranking. In: WSDM 2013, pp. 16. Vitter, J.S.: Random Sampling with a Reservoir. ACM TOMS 11(1), 37 X 57 (1985) 19. Rendle, S.: Factorization Machines with libFM. ACM TIST 3(3), 57 (2012) 20. Chen, T., Zhang, W., Lu, Q., Chen, K., Zheng, Z., Yu, Y.: SVDFeature: A Toolkit for Fea-
