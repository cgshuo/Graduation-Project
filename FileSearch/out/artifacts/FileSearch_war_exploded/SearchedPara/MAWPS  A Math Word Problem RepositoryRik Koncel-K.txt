 Automatically solving math word problems has proved a difficult and interesting challenge for the AI research community (Feigenbaum et al., 1995). Math word problems serve as a testbed for algo-rithms that build a precise understanding of what is being asserted in text. Consider the following: To solve such a problem, an algorithm must model implicit and explicit quantities in the text and their relationships through mathematical operations.
Many researchers have taken on this challenge to design data-driven approaches to solve different types of math word problems (Hosseini et al., 2014; Kushman et al., 2014; Roy and Roth, 2015; Zhou et al., 2015; Koncel-Kedziorski et al., 2015). Treat-ments of this task range from template-matching to narrative-building, and methods including integer linear programming, factorization, and more appear in the literature. As a result of the variety of ap-proaches, several datasets have emerged. The va-riety of math word problems in these datasets is such that researchers have already begun specializ-ing in the types of problems that their systems are able to successfully solve. Additionally, in some datasets one may find significant repetition of com-mon words, a small set of equation templates used again and again, or problem texts which map to highly degraded grammatical structures. Therefore, designing general algorithms that can address dif-ferent problem types while still being robust to the variations across datasets has remained a challenge.
In response to the burgeoning interest in this task, we present M AWPS (MAth Word ProblemS, pro-nounced mops ), a framework for building an on-line repository of math word problems. Our frame-work includes a collection of varying types of math word problems, their answers, and equation tem-plates, as well as interfaces which allow researchers to dynamically update and add more problem types. Additionally, in light of the problematic features of the current datasets cited above, our framework pro-vides the possibility for customizing a dataset with regard to considerations such as lexical and template overlap or grammaticality, allowing researchers to choose how many of the difficulties of open do-main web-sourced word problem texts they want to tackle. We report the important characteristics of the current available data as well as the perfor-mance of some state-of-the-art systems on various subsets of the data. M AWPS is located at http: //lang.ee.washington.edu/MAWPS . Recently, automatically solving math word prob-lems has attracted several researchers. Specific topics include number word problems (Shi et al., 2015), logic puzzle problems (Mitra and Baral, 2015), arithmetic word problems (Hosseini et al., 2014; Roy and Roth, 2015), algebra word prob-lems (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015), and geometry word problems (Seo et al., 2015).
 A few recent works, Kushman et al. (2014) and Zhou et al. (2015) focus on solving math word prob-lems by matching quantities and variables (nouns) extracted from the problem text to templates appear-ing in the training data. These methods have a broad scope, but they rely heavily on overlap between tem-plates in the training and test data. As shown in our experiments, when that overlap is reduced, the per-formance of the systems drops significantly.
Other work has focused on more limited domains, but aims to reduce the reliance on data overlap. Hosseini et al. (2014) solve addition and subtrac-tion problems by learning to categorize verbs for the purpose of updating a world representation de-rived from the problem text. Roy and Roth (2015) treat arithmetic word problem templates as equa-tion trees and introduce a method for learning the least governing node for two text quantities. Koncel-Kedziorski et al. (2015) focus on single equation problems and use typed semantically-rich equation trees where nodes correspond to numbers and an as-sociated type derived from the problem text, and ef-ficiently enumerate the space of these trees using in-teger linear programming.

Our work is also inspired by the recent work in introducing datasets to evaluate question answering and reading comprehension tasks that require rea-soning and entailment. In contrast to Richardson et al. (2013), our work is focused on making a dataset for math word problems to evaluate robustness, scal-ability, and scope of algorithms in quantitative rea-soning. In contrast to Weston et al. (2015), our work has more natural text and a larger vocabulary, does not use synthetic data, and is only focused on math word problems which is an extension of the counting sub-category introduced in that work. We compile a dataset of arithmetic and algebra word problems of varying complexity from different web-sites. This data extends the published word problem datasets used in Hosseini et al. (2014), Kushman et al. (2014), Koncel-Kedziorski et al. (2015), and Roy and Roth (2015). In addition to this strong founda-tion, the M AWPS repository provides interfaces for adding new word problems, allowing for its exten-sion and development.

Noting that word problem datasets have varied with regard to noisiness and repetition, we define several data characteristics to capture these proper-ties below. We then allow a user of the repository to select a subset of the data that optimizes these char-acteristics. The three data characteristics that can be automatically manipulated by M AWPS are: Lexical Overlap. Lexical overlap describes the reuse of lexemes among problems in a dataset. For example, several problems may describe tickets be-ing sold for a play, with only the number of adult and child tickets changed among them. These problems would have high lexical overlap. Previous work has shown that lexeme reuse in a dataset allows for spurious associations between the problem text and a correct solution (Koncel-Kedziorski et al., 2015). Researchers have sought to reduce this characteris-tic in their data so as to facilitate the development of more robust methods.
 Template Overlap. By template we mean an equation where numerical values are replaced by a consistent, ordered set of constant variables. For ex-ample, the equations (12  X  2)+7 = x and (6  X  15)+ 105 = x have the same template, ( a  X  b )+ c = x . As shown in Roy and Roth (2015) and elsewhere, the appearance of a similar template in the training data is a requirement for some systems at test time. More general math word problem solvers have been intro-duced that reduce or eliminate this reliance. M AWPS provides for the automatic construction of a dataset with minimized template overlap.
 Grammaticality. Many math word problems for use in AI research are drawn from user-submitted online sources. Some problems from these sources contain grammatical errors including morphologi-cal agreement failures, misspellings, and other more complicated ungrammaticalities (for example,  X  X oan paid $8.77 on a cat toy, and a cage cost her $10.97 with a $20 bill. X ). While some researchers wish to develop methods robust to these kind of errors, oth-ers would focus on the subset of the data that adheres to a high-precision, expertly developed grammar of English. To facilitate both lines of research, we al-low for the selection of only those problems which meet this judgment, or the full data. The goal of the M AWPS repository is to provide an extendable collection of math word problems which allows researchers to select the portion of the data that meets their needs. To facilitate the growth of the collection, our framework allows for easily adding a single word problem or a whole dataset to the repository. We design backend tools which allow researchers to select a dataset with reduced lexical overlap, minimized template overlap, or improved grammaticality characteristics even as the repository continues to grow through community contribution. Figure 1 shows an outline of the M AWPS system. 4.1 Reduce Lexical Overlap We consider the lexical overlap of a dataset D to be the average of the pairwise lexical overlap between each pair of problems in D . First, let W ( p ) denote the set of unique unigrams and bigrams in a problem pairwise lexical overlap between problems p and q . We formally define the lexical overlap of a dataset D as in D . Given a dataset D and a target subset size k , M
AWPS automatically finds a subset D 0 of reduced lexical overlap by solving the following optimiza-hard. As a result, we resort to a greedy strategy which gives an approximation ratio of 2 (Birnbaum and Goldman, 2007). We define f lex ( p, D 0 ) = P between a problem p and dataset D 0 . The greedy method to generate subset D 0 of D is as follows: we iteratively add a problem p from D \ D 0 to D 0 which minimizes the value of f lex ( p, D 0 ) . That is, at each step, we add a problem which has the least average pairwise lexical overlap with the problems already in initialized singleton set, until a set of k problems is created. 4.2 Minimize Template Overlap The template overlap of a dataset D is defined anal-ogously to lexical overlap as the average of the pair-wise template overlap between each pair of prob-lems of D . Let PairTempl ( p, q ) be 1 if p and q have the same template (corresponding to the gold equa-tion), and 0 otherwise. We then define the template overlap of a dataset D as a target subset size k , the template overlap re-duced subset of D is generated by the following:
This again is an instance of remote clique prob-lem, and we follow a similar greedy strategy. We de-describes the overlap between a problem p and dataset D 0 . The greedy method to generate subset D 0 of D is as follows: we iteratively add a prob-lem p from D \ D 0 to D 0 which minimizes the value of f tmpl ( p, D 0 ) . In other words, the algorithm itera-tively chooses problem p from D \ D 0 and adds it to D 0 such that (if possible) p adds a new template to a p whose template is least frequent among those of k problems. 4.3 Template/Lexical Interaction Given a dataset and a target subset size k , we would like a subset with the best lexical and template over-lap characteristics. As an approximation, we reduce the arithmetic mean of the two overlap values. This mean can be expressed as H ( D ) = 1 Tmpl( D )) . A similar greedy iterative approach as before generates the required dataset with the afore-mentioned approximation guarantee. 4.4 Grammaticality Given a dataset, M AWPS can automatically remove ungrammatical word problems, resulting in a sub-set with improved grammaticality. Our system uses the broad-coverage, linguistically precise En-glish Resource Grammar (ERG) (Flickinger, 2000; Flickinger, 2011) for determining grammaticality. The ERG is a continually-developed implemen-tation of the grammatical theory of Head-Driven Phrase Structure Grammar that covers an increas-ingly wide variety of phenomena. Moreover, the ERG makes binary decisions for sentence accept-ability: if it cannot find a valid parse among its rules, it returns no parse for that sentence. This contrasts with statistical parsers whose utility for this task is limited by the difficulties of tuning a cutoff confi-dence threshold for acceptability. We allow for fil-tering problems with ungrammatical sentences. We initialize our repository by extending the pub-licly available datasets. We list them below in order of increasing complexity of the final equation form.  X  AddSub : Collection of addition, subtraction problems (Hosseini et al., 2014).  X  SingleOp : Collection of single operation arith-metic problems (Roy et al., 2015).  X  MultiArith : Collection of multi-step arithmetic problems (Roy and Roth, 2015).  X  SingleEq : Single equation problems from (Koncel-Kedziorski et al., 2015).  X  SimulEq-S : Single and two equation word prob-lems from (Kushman et al., 2014).  X  SimulEq-L : Collection of single and multiple equation word problems, superset of SimulEq-S .
Table 1 shows the characteristics of the datasets under various conditions of grammaticality, lexi-cal and template overlap. Template overlap varies greatly across datasets, and decreases sharply with increase of complexity of target equation. Lexical overlap, on the other hand, does not show much variation, with most datasets having overlap value of around 7% . Our system effectively reduces over-lap, obtaining around 20% reduction in most cases (going from k = | D | to k = | D | / 2 ). In the case of template overlap, this reduction varies greatly based on the complexity of target equation, ranging from 2 . 8% for SingleOp to 97% for SimulEq-L.

As no current system can process SimulEq-L , we report the performance of the two most general sys-tems (Koncel-Kedziorski et al., 2015; Kushman et al., 2014) on SingleEq and SimulEq-S under differ-ent overlap and grammaticality properties in Table 2. We use a 5-fold cross validation setup and report average accuracy across folds. We include perfor-mance on a randomly selected dataset of the same size to analyze the effect of decreased data-size on performance.

Both systems gain from the pruning of grammati-cally incorrect problems from the dataset. Our re-sults support the findings of Koncel-Kedziorski et al. (2015) regarding the diminishing performance of systems when faced with reduced lexical and tem-plate overlap. We expect, as that work showed, that further reducing these characteristics would result in even lower performance. The results on a random subset of the data show that data set size does not have as strong of an effect on algorithm performance as lexical or template overlap. In this paper, we introduced M AWPS , a repository of math word problems. M AWPS offers a large collec-tion of data from new and published datasets, pro-vides interfaces for adding data, and includes data optimization tools. As current results show, de-signing general algorithms that can address different problem types while still being robust to the tem-plate or lexical variations has remained a challenge. We hope that our framework will help facilitate com-parison between results while allowing researchers to focus on targets such as all grammatical problems or all single equation problems. We also include an official 80/20 test/train split of all problems available at the time of this publication.
 Acknowledgments: This research was supported by the Allen Institute for AI (66-9175), Allen Dis-tinguished Investigator Award, NSF (IIS-1352249), DARPA (FA8750-13-2-0008) and a Google research faculty award. We thank the anonymous reviewers for their helpful comments.

