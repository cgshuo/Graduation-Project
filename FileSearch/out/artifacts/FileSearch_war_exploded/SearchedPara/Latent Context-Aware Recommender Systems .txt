 The emergence of smart mobile devices has given rise to the development of context-aware systems that utilize sensors to collect available data about users. Th is data, in turn, is used in order to improve various services for the user. The development of such applications is inherently complex, since these applications adapt to changing context information, such as: physical context, computational context, and user tasks. Context information is gathered from a variety of sources that differ in the quality of information they produce and that are often failure-prone. Our study is part of a growing research effort that examines how data collected from mobile devices can be utilized to infer users' behavior and environment. We propose novel approaches that use a rich set of mobile sensors in order to infer unexplored users' contexts in personal models. We also suggest utilizing these high dimensional sensors, which represent users' context for a CARS (context-aware recommender system). For this purpose, we suggest several methods for reducing the dimensionality space by extracting latent contexts from data collected by mobile device sensors. Latent contexts are hidden context patterns, modeled as numeric vectors that are learned for each user automatically, by utilizing unsupervised deep learning techniques on the collected data. We also describe a novel latent context recommendation technique that uses latent contexts and improves the accuracy of state-of-the-art CARS. A preliminary analysis reveals encouraging insights regarding the feasibility of latent contexts and their utilization for context-aware recommendation systems. H.2.8 [Database Management] : Database Applic ations -Data Mining; H.4.0 [Information Systems Applications] : General Recommendation, Context, Context Aware Recommendation, Matrix Factorization Context-awareness is used by a wide variety of ubiquitous applications for discovering the dynamic contextual information and adapting their behaviors accord ingly [4]. A wide spectrum of context-aware systems has been pr oposed over the last decade, as the number of sensors deployed around the world is growing at a rapid pace. These sensors continu ously generate enormous amounts of data. However, in order to obtain added value from raw sensor data, it should be engineered a nd analyzed [10]. Collection, modelling, reasoning, and distributio n of context, in relation to sensor data, plays a critical role in this challenge. We present a new approach for m odeling users' context, which is defined as the user situation, as mentioned at Hull et al. (1997). While previous studies used explic it labeled context and supervised machine learning algorithms [12,13], we suggest an unsupervised approach to infer latent context in order to reveal multiple behaviors of a user and to deal wi th the cold start problem, namely new users with no training data in the system. Our unsupervised approach for modeling context uses latent contexts, which are extracted from a hidden layer in a deep neural network. Unlike supervised contexts [7,8] which are modeled by a relatively small set of explicit contexts (e.g., r unning, walking, standing) and cannot model dynamic and complex behavi or of a user, our approach utilizes high dimensional sensor data (i.e. 600 sensor features) that represents users' environment and circumstances. By exploiting sensors in wearables and smartphones, many applications are exposing users to new experiences that have the potential to change the way users live and interact with each other. Context-aware recommender systems (CARS) have been demonstrated to be able to enhance recommendations by adapting users X  preferences to different contextual situations. For example, the types of points of interest (POIs) that users like can differ significantly depending on whether they are visited on a cold day or a sunny day, and by the user's current situation (e .g., at work, at leisure, etc.). In recent years, several CARS algorithms have been developed to incorporate context into the recommender systems. Adding context to the recomme ndation system is known to be challenging due to the addition of various environmental contexts to the recommendation process, which result in the expansion of its dimensionality. This implies that every rating of an item must relate to each category of context, thus sparsity is increased as training is required for every triple of &lt;user, item, context&gt;. Then, labeled data regarding users' contexts and their preferences in each context must be collected to train the system for supervised learning. This is of course almost infeasible, and implies a sparsity challenge. In order to resolve this problem, the dimensionality of the context representation must be reduced. Ba ltrunas [1,2] and others [13,14] modeled situations and circumstances as explicit specific contexts in order to limit the dimensionality space. These specific contexts describe the circumstances of the information collection, e.g., weather conditions, or high-leve l location conditi ons ("at home", "at work", etc.). However, while th e set of contexts is small enough to handle in order to prevent sparsity, it may not take into consideration other important environmental features and does not necessarily represent an optimal set of features for the recommendation process. In order to address these problems, we present a novel context-aware recommendation algorithm that utilizes latent contexts and show that our approach improves state-of-the-art CARS. In future work, in order to improve the accuracy of user context prediction, we intend to develop a new algorithm for unsupervised feature selection based on neural networks and investigate the possible combination of unsupervised context across time ("short term" vs. "long term"). This will allow us to reduce the dimensional ity space of the original sensors and to improve users' context accuracy. We intend to further improve the performance, especially for new users, by incorporating collaboration in context among user s. We will use deep learning, which is a strong candidate for pr ocessing mobile sensor data [9]. Such representation can be obtaine d directly from the raw data and will discover and disentangle all underlying and a priori unknown factors of variations that the data may hold, making the final representation much more reliable. As context refers to aspects of the users' immediate location, activity or circumstances [3], there is a need to model context attributes efficiently by reducing the dimensionality space. Li, Fei, et al. [11] proposed a hybrid process, combining activity classification with subspace cluste ring, in order to analyze high dimensional and heterogeneous cont ext data. The output of their clustering approach was a set of user preferences presented as subspace clusters. Although clustering has the potential to group similar contexts at some level, it does not reveal the relations among the features. In our approach , which is proven on real-world sensor data, we aim to learn these relations by unsupervised techniques such as deep learning. Few researchers have tried to infer the physical activity of the user (activity recognition) by unsupe rvised learning techniques. Trabelsi et al. [15] proposed an unsupervised approach for human activity recognition from raw accel erometer data, recorded from wearable sensors. They used an HMM model and assumed that the number of activities is pre-defined and known. Activity recognition is inferred by a relatively sm all amount of sensors (e.g. accelerometers) and expresses only th e physical activity of the user (e.g. running, walking, etc.). Sin ce we define context as any user situation (physical, environmental or emotional) and use other environmental features from the us ers' mobile phone (e.g. sound, light, location) in order to extrac t latent contexts, context is not predefined. We assume that there are many contextual types that differ from one to another and thus , the inference and modeling task of latent contexts is more complicated and challengeable. Exploiting deep learning for a contex t inference task is a relatively new and underexplored area of research; inferring many important behaviors from mobile sensor data under real-world conditions remains brittle and unreliable (e.g., [5]). However, there have been some attempts to use deep learning in order to recognize human physical actions. Foggia et al. [6] proposed a method for recognizing human actions by exploiting a multi-layer representation based on Deep Belief Network (DBN) that was trained using a Restricted Boltzman Machine (RBM). A set of global descriptors was extracted from depth images and classification was performed by a feed-forward neural network. Although an unsupervised approach from raw images was used, no environmental features were collected. The researchers assumed that the raw data represented users' supervised actions, such as jumping in place and standing up. In our approach, we use a rich set of mobile sensors aiming to model users' contexts with an unsupervised approach of deep l earning. Since latent context is unsupervised and often consists of sensor data (such as location, accelerometer data, light, etc.) which is relatively correlated, we apply autoencoding in order to discover correlations between the different features and extract them in low-dimensional representation. Specifically, the deep layers reveal the long-term patterns of the user that can be translated to latent context. Existing context-aware recommendation systems are faced with many context acquisition challenges and rely on manual input from users [16]. Baltrunas [1,2] suggested an extended context-aware rating model that tags explicit contextual information about the given ratings, termed conditional factors . These factors describe the circumstances and surroundings on which the data was collected. Defining these factors is a demanding task, since it requires input from users, knowle dge from a domain expert, or collecting labeled contextual information. On the other hand, obtaining latent context is consid erably less demandi ng, since it can be extracted from unlabeled data and does not require an explicit input from the user. We believe that requesting an involvement from end-users may significantly ha mper the uptake of context-aware recommendation for learning. Thus, we suggest utilizing unsupervised contexts in a reco mmendation system. Our suggested rating model extends Baltrunas [1] context-aware rating model with a new set of latent contextual variables which expresses a large set of environmental sensors. Those latent attributes are learned automatically by utilizing unsupervised learning techniques on available raw data. In this section, we introduce some of the current research progress on the latent context modeling an d extraction, by using deep learning techniques. Secondly, we s how how to utilize these latent contexts and describe a novel r ecommendation technique that uses latent contexts and improves the accuracy of state-of-the-art CARS. Latent context attributes are the key elements in our new suggested models. Those unsupervised contexts are extracted automatically and represent the users' context. Obtaining latent contexts is performed in three steps: first, ra w data is collected from available data sources (e.g., m obile sensors such as microphone, GPS, WiFi, accelerometer, active applications, etc.). Second, feature engineering is applied and features are extracted from the collected raw data (this process includes calculating statistics such as average, standard deviation, entropy, dominant values, etc.) as presented in Figure 3. Third, an unsupervised model is trained in order to capture relationships be tween the features and discover hidden patterns in the raw data. Specifically, we apply autoencoding for generating latent contexts. An Autoencoder neural network is an unsupervised learning algorithm that applies backpropagation, setting the target values to be equal to the inputs. For example, if we have only unlabeled training examples aim at setting  X   X   X   X   X  X   X  X  X  X  . An illustration of an autoencoder network structure is presented in Figure 1. Since context often consists of se nsor data which is relatively correlated, we apply autoencoding in order to discover correlations between the different features and extract them in low-dimensional representation. Specifically, the deep layers reveal the long-term patterns of the user that can be translated to latent context. In the training phase, the autoencoder tries to learn a function  X   X  , where W and b are the weights on the network's edges. In other words, it tries to learn an approximation to the identity function, to output  X  X  that is similar to the input x . All input values are normalized numeric va lues to the range of {0..1}. By putting constrains on the neural network, we can discover the interesting structure of the data. This structure is composed of limited numbers of hidden units on each layer, that force the network to learn a compressed representation of the context input which is called latent values . We propose a novel approach that uses a rich set of mobile sensors for the recommendation process. We incorporate all these environmental features in the recommendation engine in order to represent various types of unsupe rvised contexts. The steps of the proposed method for extracting latent contexts and utilizing them to enrich recommendation system are illustrated in Figure 2. First, we collect and extract context feat ures from mobile sensors in order to represent users' context, as explained in 3.1. The second step of "User-Item Data Collection" is a standard process in every recommendation system, which is re lated to collecting information regarding the preferences (e.g., ra tings) of users towards the items the system wishes to recommend. The third step "Explicit Context Extraction" refers to a process of collecting information where the collection circumstances are well defined, e.g., the weather condition. This is a standard process, which is optional in the presented solution. The fourth step refers to "Latent Context Extraction", as described in 3.1. This is a unique process which is responsible for discovering latent or hidden contextual patterns. The outputs of all these processes are merged to construct a rating model schema (i.e. "Rating Mode l") which captures the user-item interactions, latent contexts and explicit contexts. The final step in the proposed solution is building a unique matrix factorization recommendation model, which takes as an input the merged rating model schema. A single rating in stance in our data has the following structure:  X   X , X , X  score from a given range (e.g.: 1-5);  X  X  X  is the user ID of m users;  X  X  X  is the item's ID of n items; c1...ck are a set of explicit contextual conditions, where  X   X   X  X   X  is a nominal variable from a finite set of possible values, e.g.,  X   X  X  X  X  X  X  X  X , X  X  X  X  X  X  X  X  X , X  X  X  X  X  X  X  ; and finally a set of numeric latent context attributes l1... l d . As a case study, we analyzed data obtained from mobile devices' sensors, and examined the effect s on the accuracy of existing CARS. We are attempting to demonstrate a contribution to a system that recommends points of interest (POIs), e.g., restaurants, entertainment centers, etc. For this purpose, we developed an application which monitors th e user's mobile sensors and recommends the top 10 POIs nearby. The application displays recommendations on the device, allowing the user to provide feedback about them. Possible fe edback includes "like" and "dislike" and the ability to "check in". For all provided feedback, the application records various mobile sensors (e.g., microphone, light, WiFi networks etc.) as shown in Figure 3. The online recommendation algorithm was a popu larity-based algorithm, with a roulette wheel mechanism: for each POI, the algorithm calculated its popularity index (based on the number of likes and check-ins of the POI). The idea was to model the context for which the POIs are relevant, and to use it in the recommendation process. 60 undergraduate students from Ben-Gurion University participated in the experiment for 4 weeks. The average age of the participants was 25 years and the majority of them owned Samsung Galaxy S4, Nexus 5 or LG G2 mobile devices. We collected data about 227 POIs in the town where the university is located. Overall, the system recorded 4,471,848 raw sensor records and 7,416 events (3327 likes, 3778 dislikes and 311 check-ins). In order to test the proposed methods, we conducted a series of offline simulations with the da ta collected from the field experiment. We performed a random based splitting evaluation on each user profile, applying 80:20 splitting ratio for train and test respectively. We repeated this process 10 times with different splits. We compared four recommendation models: 1) Matrix Factorization (MF). 2) Explicit Context Matrix Factorization (ECMF)  X  the contextual modeling approach, suggested by Baltrunas et al. [1,2]. This model extends traditional matrix factorization and learns for each item, rating bias under different explicit context conditions. For explicit context conditions, we chose the time of a day, time of a week and weather. 3) Latent Context Matrix Factorization (LCMF)  X  our proposed latent model, considering latent context attributes. 4) Hybrid Context Matrix Factorization (HCMF)  X  our proposed model, taking into consideration both explicit and latent contexts. We evaluate the accuracy of the above models using two prediction accuracy measures and two measures regarding the quality of the ranking of the results, as shown in Table 1. We use RMSE (root mean square error) and Hit@K metric, which measures the percentage of hits among the top-K recommendations. In addition, we evaluated the performances of the model with two ranking methods: average metric, which calculates the average position indexes among the top-K recommendations and NDCG (Normalized Discounted Cumulative Gain) which is a weighted average on the position indexes among the top-K list. Table 1. Learning from Positive Feedback (Random Split) 
Model RMSE ECMF 0.104 0.138 0.502 3.133 0.761 LCMF 0.022* 0.101* 0.519* 3.093* 0.769* HCMF 0.019* 0.102* 0.571* 3.220 0.754 
Figure 1. Extracting Latent Contexts using an Autoencoder We propose unsupervised methods for inference and modeling of user situations and circumstances, aiming at increasing the prediction accuracy of the user's context. Unlike supervised contexts, which are modeled by relatively small set of explicit contexts (e.g., running, walking, and standing), and cannot model dynamic and complex behavior of a user, we suggest an unsupervised approach to infer latent contexts. Latent contexts are extracted using deep autoencoders, which can be obtained directly from the raw data. This deep neural network discovers and disentangles all underlying an d a priori unknown factors of variations that the data may hold , making the final representation much more reliable. This approach allows inferring unexplored contexts and modeling high dimensiona l sensor data that represents users' behavior and environment. Using this unsupervised approach, we can handle the cold start problem, namely new users with no training data in the system. Our second goal is to utilize thes e methods for a new context-aware recommender algorithm. We presen t a novel CARS that utilizes latent contexts and s how that our approach improves state-of-the-art CARS. In future work, in the area of context inference, we intend to develop a new algorithm for unsupervised feature selection based on neural networ ks and investigate the possible combination of unsupervised cont ext across time ("short term" vs. "long term"). This will allow us to reduce the dimensionality space of the original sensors and to improve user's context accuracy. We intend to further improve the performance, especially for new users, by incorporating collaboration in context among users. In the area of CARS, we intend to design a new CARS by a deep belief network trained using Restricted Boltzman Machine (RBM) in order to resolve the sparsity pr oblem and improve the performance of state-of-the-art CARS. Special thanks to Prof. Bracha Shapira and Ariel Bar for their support, guidance and valuable feedback. [1] Baltrunas, L., Ludwig, B., &amp; Ricci, F. (2011, October). [2] Baltrunas, L., &amp; Ricci, F. (2014). Experimental evaluation of [3] Billsus, D., Brunk, C. A., Evans, C., Gladish, B., &amp; Pazzani, [4] Chen, G., &amp; Kotz, D. (2000). A survey of context-aware [5] Consolvo, S., McDonald, D. W ., Toscos, T., Chen, M. Y., [6] Foggia, P., Saggese, A., Strisc iuglio, N., &amp; Vento, M. (2014, [7] K X nig, I., Klein, B. N., &amp; Da vid, K. (2013, September). On [8] Kwapisz, J. R., Weiss, G. M., &amp; Moore, S. A. (2011). [9] Lane, N. D., &amp; Georgiev, P. (2015, February). Can Deep [10] Lane, N. D., Miluzzo, E., Lu, H., Peebles, D., Choudhury, T., [11] Li, F., Rasch, K., Sehic, S., Du stdar, S., &amp; Ayani, R. (2013, [12] Santos, A. C., Cardoso, J. M., Ferreira, D. R., Diniz, P. C., &amp; [13] Savage, N. S., Barans ki, M., Chavez, N. E., &amp; H X llerer, T. [14] Sun, F., Zhang , J., Tu, L., &amp; Huang, B. (2013, December). [15] Trabelsi, D., Mohamme d, S., Chamroukhi, F., Oukhellou, L., [16] Verbert, K., Manouselis, N. , Ochoa, X., Wolpers, M., 
