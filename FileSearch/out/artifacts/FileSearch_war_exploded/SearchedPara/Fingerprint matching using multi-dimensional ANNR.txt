 1. Introduction
Biometrics is a technology that uniquely identifies a person based on his physiological or behavioral characteristics. Some of the biometrics which have excellent potential for identification matching is one of the oldest and trusted biometric for identification ( Lee and Gaensslen, 1991 ). The manual classifica-tions of the fingerprints were time consuming and prone to errors, hence it was not possible to promote it on a commercial scale.
The first scientific paper on fingerprint was given by English morphologist N. Grew in 1684, in which he had reported his study on the ridge, furrow and pore structures in the fingerprint. In 1823, Purkinje developed the first fingerprint classification scheme in which the fingerprints were classified into nine categories according to the ridge configuration ( Lee and Gaensslen, 1991 ).
Sir F. Galton after an extensive study of fingerprints introduced the minutiae features for the fingerprint classification in the year 1888. The minutiae points are the local discontinuities in the ridge flow pattern. The FBI invested a lot of effort since the early 1960s in the development of the AFIS ( Federal Bureau of Investigation, 1984 ). Ever since the Automatic Fingerprint
Identification System (AFIS) was developed in 1991, rapid progress has been made in improving the recognition rates. This development has greatly improved the scope of using fingerprint for identification purposes and in reducing the cost of hiring and training human experts for fingerprint matching. The current works in this field focus on mainly reducing the computation time for feature extraction and matching and improving the accuracy of the results. Today, with the crime rates increasing everyday there is an urgent need for a system which is safe and fast.
The general fingerprint recognition system comprises of two broad steps namely: (i) feature extraction and (ii) classification of the image using the features extracted. Some of the important feature extraction methods include: (i) filter based approach (ii) structure based approach (iii) statistical based approach which also comprises the method of extracting the minutiae points ( Ern and Sulong, 2001 ). The methods of matching the fingerprint using the features extracted is carried out by using one of the many approaches namely: (i) syntactics, (ii) singularities based, (iii) structural, or (iv) neural network based ( Ern and Sulong, 2001 ).
Some of the recent work in the field of fingerprint matching includes the chain coded string matching technique ( Paul et al., 2007), use of the combination of fast Fourier transform (FFT) and
Gabor filters for the enhancement of the captured image ( Aguilar et al., 2007 ) which have the potential of improving the speed and the performance of feature extraction and matching.

One of important methodology used in the fingerprint recognition system is the use of minutiae points for matching the fingerprints. Some of the popular minutiae matching techniques are: (i) using the Delaunay triangulation method (Bebis et al., 1999), (ii) using local structural similarity ( Ratha et al., 2000 ), (iii) using neural networks or a combination of neural and fuzzy logic ( Arantus et al., 2002 ; Hong and Hua, 2003 ). In this paper, we propose to use the MDANN in which the 2-D resized minutiae image is taken as an input directly and this method involves the training of the entire pattern at once as against the other earlier works of training, in which the whole image is either divided into a number of small images and then trained one by one or use the 1-D feature vector for training. This method is proposed as it uses the comprehensive data of the fingerprint and hence the chances of failure to recognize the authentic finger-prints are very remote.

The rest of the paper is organized as follows: Section 2 describes the image enhancement techniques along with the binarization and thinning techniques. Section 3 explains the minutiae extraction and its authentication method. Section 4 introduces the resizing algorithm briefly. Section 5 introduces the concept of MDANN and its algorithm. The results are presented in
Section 5 and the concluding remarks are presented in Section 6. 2. Image enhancement
The quality of the fingerprint ridge structure is very important as they possess the necessary information for the extraction of minutiae points. Ideally the ridges and valleys should alternate with a clear demarcation and flow in a locally constant direction.
Due to a number of factors, the obtained fingerprints may not have well defined ridge/valley structures and might contain a lot of disturbance in the image ( Jain et al., 1997). So the fingerprint image is first enhanced before further processing and comprises of the following steps: (i) segmentation, (ii) normalization, (iii) orientation estimation, (iv) ridge frequency estimation, (v) Gabor filtering (vi) binarization, (vii) thinning ( Jain et al., 1999 ). 2.1. Segmentation
Segmentation is the process of distinguishing the background region from the foreground regions. It is observed that the background regions have a low gray-scale variance value as compared to the foreground region. So a method based on variance thresholding is used for segmentation ( Mehtre, 1993 ). V  X  k  X  X  1 n 2 where V ( k ) is the variance and M ( k ) is the mean gray-level value of the block k . I ( i,j ) is the pixel value at the pixel ( i,j ). 2.2. Normalization
Normalization is done in order to standardize the dynamic variation in the gray-level values.

N  X  i ; j  X  X  M o  X 
M and variance of I ( i,j ) respectively and  X  M o  X  and  X  V mean and variance values respectively. 2.3. Orientation estimation
The orientation field of a fingerprint defines the local orientation of the ridges and is necessary for the Gabor filtering stage to effectively enhance the image ( Jain et al., 1997). The local by using the following equations.
 O  X  i ; j  X  X  O  X  i ; j  X  X  y  X  i ; j  X  X  1 2 tan 1 O x  X  i ; j  X  O
The orientation image is converted into a continuous vector respectively. The Gaussian smoothing is then performed and the equations for the process are as under, f  X  i ; j  X  X  cos  X  2 y  X  i ; j  X  X   X  7  X  f  X  i ; j  X  X  sin  X  2 y  X  i ; j  X  X   X  8  X  f  X  i ; j  X  X  f  X  i ; j  X  X  where  X  G X  is a Gaussian low pass filter of size q n q and the final smoothened orientation field  X  O X  at pixel ( i,j ) is given by O  X  i ; j  X  X  1 2 tan 1 f 0 x  X  i ; j  X  f 0 2.4. Ridge frequency estimation
Along with the orientation field, the ridge frequency is also required for the construction of Gabor filter. This represents the local frequency of the ridge in the fingerprint ( Jain et al., 1997 ). 2.5. Gabor filtering
The orientation and the ridge frequency information is used to design the even-symmetric Gabor filter ( Daugman, 1985 ). An even-symmetric Gabor filter is defined in the spatial domain as G  X  x ; y ; y ; f  X  X  exp 1 2 x 2 y s 2 x  X  x cos y  X  y sin y  X  13  X  y  X  x sin y  X  y cos y  X  14  X  where y and f refer to the orientation and the frequency of the Gabor filter, while s x and s y refer to the standard deviation of the Gaussian envelope. The application of the Gabor filter to the image is performed as follows.
 E  X  i ; j  X  X  where E , O , F , N are the enhanced, orientation, ridge frequency and normalized fingerprint images respectively. M x , M y being the width and height of the Gabor filter mask. The range of frequency to which the filter responds is determined by the parameters s and s y and this is chosen to be a function of the ridge frequency.  X  k x F  X  i ; j  X  X  16  X   X  k y F  X  i ; j  X  X  17  X 
In order to enable the filter to accommodate the majority of the Gabor waveform information, the filter size is allowed to vary according to the bandwidth of the Gabor waveform.

M  X  6 s x  X  18  X 
M  X  6 s y  X  19  X  where k x and k y are constants for s x and s y respectively. 2.6. Binarization
Binarization is performed to convert the gray-scale image into a binary image having either zero or one as the pixel intensity value using a certain threshold ( Aguilar et al., 2007 ). 2.7. Thinning
This is the final stage of image enhancement. This is a morphological process which corrodes the image successively until a skeletal image of the fingerprint which is one pixel wide is obtained ( Aguilar et al., 2007 ). This image is in turn used for the minutiae extraction process. 3. Minutiae extraction and its authentication
The enhanced image is used to extract the minutiae points of the fingerprint. There are a number of features that could be used for the identification of fingerprints, but mostly the minutiae points are restricted to two types namely the ridge ending and the ridge bifurcation. Ridge endings are the point where the ridge curve terminates and the ridge bifurcations are the points where the ridge curve splits from a single path to two on a Y-junction. 3.1. Minutiae extraction
The minutia points are extracted from the enhanced finger-print image by using the Crossing Number ( CN ) concept (Amengual et al., 1997; Mehtre, 1993; Kasaei and Boashash, 1997). The CN value for a ridge pixel P is given by the equation. CN  X  1 2
The value of the CN number is used to differentiate between the types of minutiae. The ridge ending will have a CN value of one while the ridge bifurcation will have a value of three. 3.2. Authentication of the minutiae points
The minutiae points extracted by using the CN concept might contain some false minutiae points. The spurious minutiae points may be due to either a loop in the ridge structure which could be classified as a bifurcation point or a few isolated points may be assumed to be ridge endings ( Tico and Kuosmanen, 2000 ). 4. Resizing of the minutiae image
The minutiae image obtained from the previous stage clearly depicts the pattern of the fingerprint minutiae points. This pattern is to be trained on a MDANN. Since, the normal image size of 512 n 512 cannot be used to train the network as it will be highly time consuming and moreover it is not possible to train an image of this size on a system with a 512 MB RAM. So it is mandatory to reduce the size of the image without losing the necessary information from the image. This is performed by dividing the minutiae image into 225 (15 n 15) matrices and then add up the pixel intensity values of every individual matrix. Now we will be left with a 15 n 15 matrix, in which the pixel intensity value is given a maximum of one and the rest are given a value of zero.
This smaller matrix retains the minutiae pattern and hence can be used to train the network. 5. Recognition by MDANN
In the neural networks, learning is easy because it is dependent only on the locally available information, but since the information is mixed together at the storage elements, unambiguous retrieval of stored information is not simple.
Recognition involves knowing whether or not a new input has been presented before and stored in memory. The gradient descent is generalized of to a non-linear, multi-layer feed forward network called backpropogation. This is a supervised learning algorithm that learns by first computing an error signal and then propagates the error backward through the network by assuming the network weights are the same in both the backward and forward directions. Backpropogation is a very popular and widely used network learning algorithm ( Anderson, 1995 ).

In this paper, we explain our work on training the minutiae images on the ANN by using the backpropogation algorithm and then matching the fingerprint for recognition from the database.
The MDANN used here consists of 20 neurons and was designed to take the matrix inputs. Fig. 1 shows the network structure of
MDANN but the connections between the input and the hidden layer are not shown completely for the purpose of clarity and the complete structure is obtained by extending the connections to the entire image.

The inherent advantage of using a multidimensional ANN in this system is that the entire matrix containing the minutiae points can be used to train the network which means that the relative orientation of the minutiae points are automatically used in the recognition. 5.1. Algorithms for the MDANN
Here, S 1 and S 2 are structures containing n layers and k elements in each field and comprise of the internal weights
W the image to neuron connection and the components A w , A
A , A d , A d 1 are single row matrices denoting the weights of the connection of the neurons with the image pixel points, their differential values, the bias values for the neurons, their differential values.
 Step 1: calculation of the derivatives:
Now  X  i X  refers to the number of patterns we are trying to train on the network.  X  j X  refers to the number of regresses which is given by one in excess of the number of neurons and  X  k X  refers to the dimension of the input matrix.  X  n X  refers to the number of neurons. D  X  actual output required output  X  21  X  For the weights:
A  X  j  X  X  A d  X  j  X  X  D ; if j  X  1 ;  X  22  X 
A  X  j  X  X  A d  X  j  X  X  D matrix input to the network. The values are calculated for all values of j . Now  X  as X  refers to the activation signal value and is given by the equation: as  X  2 For the internal weights :
W dl 1  X  j ; k  X  X  W dl 1  X  j ; k  X  X  X  A w  X  j  X  D as  X  S 0 j 2
W dr 1  X  j ; k  X  X  W dr 1  X  j ; k  X  X  X  A w  X  j  X  D as  X  S j 1 column of the matrices W dl 1 and W dr 1 respectively.
I ( i, k, : ) refers to the k th row elements of the i th input in the input in the structure. These values are calculated for all the coordinates ( j, k ) .
 For the bias values:
A d 1  X  j  X  X  A d 1  X  j  X  X  X  D as A w  X  j  X  X   X  27  X 
Step 2: updating the weights and bias values and setting their derivatives back to zero: For all values of j For the weights
A  X  j  X  X  A w  X  j  X  X  X  alpha A dw  X  j  X  X  X  eta A d  X  j  X  X  X  28  X 
A dw  X  j  X  X  X  alpha A dw  X  j  X  X  X  eta A d  X  j  X  X   X  29  X 
A  X  j  X  X  0  X  30  X  For the bias values
A  X  j  X  X  A b  X  j  X  X  X  alpha A db  X  j  X  X  X  eta A d 1  X  j  X  X  X  31  X 
A  X  j  X  X  A db  X  j  X  X  eta A d 1  X  j  X  X  X  32  X 
A d 1  X  j  X  X  0  X  33  X  where eta and alpha refer to the initial learning rate and the momentum factor respectively.

Step 3: updating the internal weights and setting the derivatives back to zero: For all the coordinates ( j,k )
S jk 1  X  S jk 1  X  X  alpha W dl  X  j ; k  X  X  X  eta W dl 1  X  j ; k  X  X   X  34  X 
W dl  X  j ; k  X  X  X  alpha W dl  X  j ; k  X  X  X  eta W dl 1  X  j ; k  X  X   X  35  X 
W dl 1  X  j ; k  X  X  0  X  36  X 
S jk 2  X  S jk 2  X  X  alpha W dr  X  j ; k  X  X  X  eta W dr 1  X  j ; k  X  X   X  37  X  W dr  X  j ; k  X  X  X  alpha W dr  X  j ; k  X  X  X  eta W dr 1  X  j ; k  X  X   X  38  X  W dr 1  X  j ; k  X  X  0  X  39  X  structure S 1 and S 2 respectively
Step 4: calculating the output values after the training output  X  A w  X  j  X  ; for j  X  1 ;  X  40  X  output  X  A w  X  1  X  X  for j 4 1  X  41  X 
During the training stage of the network with the fingerprint images, each fingerprint image is assigned a distinct arbitrary value. Now the different images of the same fingerprint are trained on the network with the same arbitrary value as the target value. The iteration goes on until the value calculated in Step 4 is the target value that was assigned to the image. This value is unique for every distinct fingerprint image and when a random fingerprint is tested on the network, this value concludes as to whether the image is already present in the database or not and if present the exact image to which it corresponds to.

The fingerprint images were collected from the institute student data bank using paper and ink and then scanned to give an image that can be used for processing and matching. Each fingerprint was collected three times and was collected from a total of 3500 individuals. Out of these images, fingerprints of 500 individuals were reserved just for the test purposes and were not used for the training of the MDANN. The other fingerprint images (two each) from the 3000 individuals were used for training the MDANN. These images were firstly subjected to image enhance-ment process wherein the discontinuities and the disturbances in the image were removed and subsequently the resized image was obtained from the minutiae image. The resized image was then trained on the MDANN as mentioned earlier.

Now the trained MDANN is subjected to a test to evaluate if the network is capable of recognizing a fingerprint image that was already trained on it and also to evaluate if it can reject a fingerprint image that was not trained on it. So the images that are used for the test purpose are: (a) the 500 images that were isolated initially and reserved only for the test purposes and (b) out of the three images each collected from the 3000 individuals, one image each from these 3000 individuals which had not been used during the training of the network.

Now the test images are subjected to the same process of image enhancement, minutiae extraction and resizing and then applied to the MDANN. The value obtained from Eq. 40 for the test image is compared with the values that were assigned earlier during the training of the 3000 unique fingerprint images. If the values are found to match, then the image is concluded to be present in the database and the value of Eq. 40 will exactly indicate as to which image it is in the database. If the values are not matched, then the image is said to be not present in the database. 6. Result
The actual image was first enhanced in order to enable the proper extraction of the minutiae points. The segmented image which separates the background from the foreground area is shown in Fig. 2 (a). The normalized image where the dynamic intensities are standardized so that the values are in a specific range is shown in Fig. 2 (b).

The enhanced image is shown in Fig. 3 (a) and this is better in terms of the continuity of the ridge structure and Fig. 3 (b) shows the binarized image which has a better clarity and continuity of the ridge. This binarized image has only two level of intensity values namely zero and one and clearly distinguishes between the ridges and the valleys.

The thinned image obtained from the binarized enhanced image is shown in Fig. 4 (a) and is used for calculating the CN values and then for extracting the minutiae points. The minutiae points obtained after the authentication of these points obtained from the CN method is shown in Fig. 4 (b).

The resized image is shown in Fig. 5 and when this image is trained on the multi-dimensional neural network by using the gradient descent training procedure gave the following performance curve, where performance is defined as square of the difference between the target value and the actual value obtained during simulation. The performance curve has been plotted against the number of iterations. It is observed that the performance is steadily improving and leading to a value around zero.

The rate of learning curve has been shown in Fig. 6 , and this refers to the rate at which the network is learning. This rate is altered continuously in the algorithm every time the network is subjected to iteration (see Fig. 7 ).

The algorithm was tested on a database of 3000 fingerprints and was found to give better recognition result as compared to other algorithms as shown in Table 1 . It was observed that with an increase in the number of unique fingerprints in the database to values above 3500, the recognition rate started declining considerably.

It was also observed that, with a bigger resized minutiae image instead of 15 n 15, this limit of 3500 was increased to support a larger database but with a decline in the speed of the recognition.
The simulations were carried out on MATLAB 7.02 version on a 512 MB RAM, 1.7 GHz processor. The trained network was able to give the exact value every time an image which was one of those which had been trained earlier was given as input. The results were given fast and were observed to have good rate of recognition for a database of 3000 fingerprint inputs. 7. Conclusion
The fingerprint matching technique that uses the minutiae points to identify fingerprints have been presented in this paper.
Preprocessing techniques were first applied to enhance the image and then obtain a thinned binary fingerprint ridge structure that can be used for minutiae extraction. The extracted minutiae images of the fingerprints from the database are then trained on a multi-dimensional artificial neural network which takes in the two-dimensional minutiae image matrix as an input and a target output. The trained network can then be used for the purpose of matching the fingerprints from the database. This method relies on portraying the pattern in two-dimensions and hence retains the details about the pattern of the minutiae in an image in the best possible way. This method is found to give results that are comparable in terms of efficiency of recognition with the other pattern recognition techniques and hence the results are encouraging to work on improving the MDANN for better matching capabilities. This neural based technique was also found to support fast fingerprint classification rates. Moreover further work in this field could be in optimizing the trade-off between the speed of recognition and the size of the database that can be supported by the network.
 References
