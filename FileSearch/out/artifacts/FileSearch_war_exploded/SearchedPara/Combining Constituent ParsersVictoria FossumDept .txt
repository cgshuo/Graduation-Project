 Parse quality impacts the quality of downstream ap-plications such as syntax-based machine translation (Quirk and Corston-Oliver, 2006). Combining the output of multiple parsers can boost the accuracy of such applications. Parses can be combined in two ways: parse selection (selecting the best parse from the output of the individual parsers) or parse hybridization (constructing the best parse by recom-bining sub-sentential components from the output of the individual parsers). 1.1 Related Work (Henderson and Brill, 1999) perform parse selec-tion by maximizing the expected precision of the selected parse with respect to the set of parses be-ing combined. (Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents. 1.2 Our Work In this work, we propose three ways to improve upon existing methods for parser combination.

First, while constituent recombination (Hender-son and Brill, 1999; Sagae and Lavie, 2006) gives a significant improvement in f-score, it tends to flatten the structure of the individual parses. To illustrate, Figures 1 and 2 contrast the output of the Charniak parser with the output of constituent recombination on a sentence from WSJ section 24. We recombine context-free productions instead of constituents , pro-ducing trees containing only context-free produc-tions that have been seen in the individual parsers X  output (Figure 3).

Second, the parse selection method of (Hender-son and Brill, 1999) selects the parse with maxi-mum expected precision ; here, we present an effi-cient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini-mum Bayes Risk (MBR) framework.

Third, we extend these parser combination meth-ods from 1 -best outputs to n -best outputs. We present results on WSJ section 23 and also on the English side of a Chinese-English parallel corpus. In the MBR framework, although the true reference parse is unknown, we assume that the individual parsers X  output forms a reasonable distribution over possible reference parses. We compute the expected f-score of each parse tree p where f ( p respect to parse p ability of parse p lows: pr ( p where parser set pr ( parser tences in the development set for which the 1 -best output of parser any individual parser, breaking ties randomly.
When n = 1 , pr ( p when n &gt; 1 we must estimate pr ( p distribution over parses in the n -best list output by any given parser. We estimate this distribution us-ing the model score, or log probability, given by parser k to each entry p j in its n -best list:
We tune  X  on a development set to maximize f-f-score.
 Computing exact expected f-score requires O ( m 2 ) operations per sentence, where m is the number of parses being combined. We can compute an approximate expected f-score in O ( m ) time. To do so, we compute expected precision for all parses in O ( m ) time by associating with each unique constituent c plus the total probability q each parse p associated with c expected precision of that parse by q computation yields the same result as the O ( m 2 ) algorithm. We carry out a similar operation for expected recall. We then compute the harmonic mean of expected precision and expected recall, which closely approximates the true expected f-score. (Henderson and Brill, 1999) convert each parse into constituents with syntactic labels and spans, and weight each constituent by summing pr ( parser over all parsers k in whose output the constituent appears. They include all constituents with weight above a threshold t = m +1 of input parses, in the combined parse. (Sagae and Lavie, 2006) extend this method by tuning t on a development set to maximize f-whose weight meets the threshold, and use a CKY-style parsing algorithm to find the heaviest tree, where the weight of a tree is the sum of its con-stituents X  weights. Parsing is not constrained by a grammar; any context-free production is permitted. Thus, the combined parses may contain context-free productions not seen in the individual parsers X  out-puts. While this failure to preserve the structure of individual parses does not affect f-score, it may hin-der downstream applications.

To extend this method from 1 -best to n -best lists, we weight each constituent by summing pr ( parser erated by parser To ensure that all context-free productions in the combined parses have been seen in the individual parsers X  outputs, we recombine context-free produc-tions rather than constituents. We convert each parse into context-free productions, labelling each con-stituent in the production with its span and syntac-tic category and weighting each production by sum-ming pr ( parser p pears. We re-parse the sentence with these produc-tions, returning the heaviest tree (where the weight of a tree is the sum of its context-free productions X  weights). We optimize f-score by varying the trade-off between precision and recall using a derivation length penalty, which we tune on a development Table 1 illustrates the 5 parsers used in our combi-nation experiments and the f-scores of their 1 -best output on our data sets. We use the n -best output of the Berkeley, Charniak, and Soricut parsers, and the 1 -best output of the Bikel and Stanford parsers. All parsers were trained on the standard WSJ train-ing sections. We use two corpora: the WSJ (sec-tions 24 and 23 are the development and test sets, re-spectively) and English text from the LDC2007T02 Chinese-English parallel corpus (the development and test sets contain 400 sentences each). Results are shown in Tables 2, 3, and 4. On both test sets, constituent recombination achieves the best f-score (1.0 points on WSJ test and 2.3 points on Chinese-English test), followed by context-free pro-duction combination, then parse selection, though the differences in f-score among the combination methods are not statistically significant. Increasing the n -best list size from 1 to 10 improves parse se-lection and context-free production recombination, though further increasing n does not, in general, boost from combination than WSJ test set f-score, perhaps because the best individual parser X  X  baseline f-score is lower on the out-of-domain data.

We have presented an algorithm for parse hy-bridization by recombining context-free produc-tions. While constituent recombination results in the highest f-score of the methods explored, context-free production recombination produces trees which better preserve the syntactic structure of the indi-vidual parses. We have also presented an efficient linear-time algorithm for selecting the parse with maximum expected f-score.
 We thank Steven Abney, John Henderson, and Kenji Sagae for helpful discussions. This research was supported by DARPA (contract HR0011-06-C-0022) and by NSF ITR (grant IIS-0428020).
