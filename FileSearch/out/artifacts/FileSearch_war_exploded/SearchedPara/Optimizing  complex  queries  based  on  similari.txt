 erature (Chaudhuri 1998; Graefe 1993; Jarke and Koch 1984).

However, the database field is a rapidly growing one. As database technology is applied to more and more application domains, user queries become more and more query structure (e.g. snowflake queries). The query optimization techniques adopted in the existing DBMSs cannot cope with the new challenges. the query, which is an important decision specified in a QEP, two types of algorithms are adopted in the current DBMSs. The first type of algorithm is based on dynamic programming or other exhaustive search techniques. Although such an algorithm can guarantee to find an optimal solution, its worst-case time complexity is exponential, algorithm has a polynomial time complexity, it often yields a suboptimal solution. In traditional database applications, queries involving more than 15 joins were consid-are acceptable to a certain degree.
 optimize such queries. For an algorithm with an exponential complexity, it may take a heuristic-based algorithm takes less tim e to find a join order for a complex query, the efficiency difference between a good solution and a bad one can be tremendous a bad solution.
 cient plan for a complex query. Note that the general query optimization problem has been proven to be NP-complete (Ibarake and Kameda 1984). Hence, it is generally been reported to find a good plan for a large query (i.e. involving many joins) within lated annealing (SA) (Ioannidis and Wong 1987), Tabu Search (TS) (Matysiak 1995),
AB algorithm (AB) (Swami and Iyer 1993), and genetic algorithm (GA) (Bennett et al. 1991). These algorithms represent a compromise between the time the optimizer techniques are mostly based on the randomization method. One advantage of such an approach is that it is applicable to general queries, no matter how simple or complex queries.
 mon subqueries that appear in a complex query to optimize the query. This technique subqueries in a query, its application is limited.
 queries) although they may not be exactly the same (i.e. common). This phenomenon ated. The more complex the query is, the more similar subqueries there will possibly materializing the view, a DBMS usually pushes down the dimension tables into the view, resulting in similar UNION ALL branches (subqueries). Another more concrete real-world query example is given in the Appendix.

Based on the above observation, we introduce a new similarity-based approach to reducing optimization time for a complex query by exploiting its similar subqueries subqueries in a given query. For each group of subqueries that are similar to a rep-similar subquery is replaced by its (estimated) result table obtained by using the cor-responding execution plan in the original query, the revised query is then optimized in the second phase. Because the complexities of similar subqueries and the revised dynamic programming) or a randomization approach (e.g. AB).

Although our work has some similarity with multiple-query optimization (Ches-
Papadias 2003; Krolikowski et al. 2000; Mistry et al. 2001; O X  X orman et al. 2002), optimize multiple user queries collectively instead of individually. Such typical tech-mization time) rather than share their results. Although different parts of a complex query that contain similar subqueries sharing an execution plan can be logically con-beneficial similar subqueries are identified. In other words, we cannot split the given a given query without any predefined boundaries. To our knowledge, no similar work has been reported in the literature.

The rest of this paper is organized as follows. Section 2 introduces the definitions of a query graph and its similar subquery graphs, which are the key concepts used in our technique. We then present an efficient ring network representation to implement a query graph. Section 3 gives the details of an algorithm that is the kernel for our needed to extend the previous algorithm. Section 5 shows some experimental results.
Section 6 summarizes our conclusions.
In this section, we introduce the definitions of a query graph and its similar subquery a query graph for our technique.
Most practical queries consist of a set of selection ( X ) that  X  is usually processed together with other operations ( eration following each  X / operation to filter out the columns that are not needed tion is a conjunction of simple predicates of the following forms: R
R . a the domain of R . a . For example, EMP.salary &gt; 20000 and EMP.dno predicates. Another assumption made in our paper is that joins are executed by the nested-loop method. Under this assumption, we can simply consider one cost model.
However, our technique can be extended to include other join methods by adopting multiple cost models.
P ={ p reference in Q a table instance. The logical structure of query Q can be represented by a query graph, based on the following rules:  X  Each table instance in Q is represented by a vertex (node) in the query graph G  X  For any table instances (vertices) x and y , if there is at least one predicate in P component defined as above. For the rest of the paper, we use the following notation: x = y , edge ( x , x ) is denoted by self -loop ( x ) . sizeof represented by x , sel ( e ) denotes the selectivity of conjunction of all the simple predicates in  X ( e ) . Without loss of generality, we assume our query graph is connected in this paper.
Otherwise, each isolated component graph can be optimized first and a set of Carte-
Let V  X  V be a subset of vertices in the query graph G ( V Let E | V ={ e | e  X  E and vertices ( e )  X  V } ,
T |
P | V ={ p | p  X  P and p  X  w and w is the set of predicates labeled  X  |  X  |
We call E | V , T | V , P | V ,  X  | V and  X  | V the restrictions of E , T , P , subset V of vertices in G , respectively. Clearly, G ( is a subgraph of G .If G is connected, we call it a subquery graph in G .Thecor-responding query is called a subquery of Q . Note that a subquery graph is uniquely determined by the subset V of vertices in G . An edge edge x and y in G is called an interconnecting edge of subquery graph G if one of x and y is in V and the other is not.
 Let G ( V , E | V , T | V , P | V , X  | V , X  | V ) and G ( we regard them as a pair of similar subquery graphs with respect to the error bounds r and r s , denoted as G  X  X  ( r t , r s ) G :  X 
There exists a one-to-one mapping f between V and V , such that, for any x  X  V and f ( x )  X  V ,wehave  X  t ( x , f ( x )) &lt; r t  X 
There exists a one-to-one mapping g between E and E , such that, for any e  X  E and g ( e )  X  E ,if vertices ( e ) ={ x , y } ,then vertices and  X  s ( e , g ( e )) &lt; r s ,where  X  s ( e , g ( e )) = table represented by each node and the sel ectivity of the predicates on each edge are marked in parentheses), using error bounds r t = r s = 0 . shown in the dashed-line circles marked as G and G . (The light dotted-line circles the corresponding edges in the pair are within error bounds r
Note that the size of a table and the selectivity of a query condition are the two most parameters with respect to their given error bounds. in this paper, we introduce a data structure called the ring network representation to represent a query graph.
 a node x . Assume that node x has a set of adjacent nodes, y a closed link list (i.e. a ring): x  X  y 1  X  y 2  X  ...  X  y , y which is subquery graph G in Fig. 1, its ring network is shown in Fig. 4. technique and analyze the complexity of the algorithm.
The basic idea of this technique is as follows:  X 
Identify pairs of similar subqueries in a given query with respect to given error bounds r t and r s .  X 
Optimize one subquery in each similar pair and map and apply the resulting optimization time by sharing the same (mapped) plan between two similar sub-queries.  X 
Replace similar subqueries with their (estimated) result tables in the query graph and optimize the resulting revised query. As the number of vertices in the query graph is reduced, less overhead is needed to optimize the revised query compared with the original query.

Because the error bounds r t and r s are adjustable, by setting r get a pair of larger similar subqueries (that is, with more vertices in each subquery), vertices and edges in two similar subqueries is worse, and therefore, the optimization quality (the performance) after sharing the plan may be worse. We will discuss this issue in more detail in Sect. 5.
 more than two similar subqueries for query optimization in Sect. 3.5.
A high-level description of the algorithm for our technique is given below. Note that, self-loops are removed in such a way for a given query graph. Algorithm 3.1. Query optimization based on similar subqueries
Input : Ring network representation of query graph G query Q, and error bounds r t and r s .
 Output : Execution plan for query Q.

Method : 1. begin 3. Initialize the sets of identified pairs of similar subquery graphs 4. while there are unselected node pairs with similar table sizes within 5. Pick up the pair of nodes x and y by following the rules for choosing start 7. record one-to-one mapping f : x  X  y ; /* i.e., y = f ( 8. Let selected ( x ) = selected ( y ) = 1; 9. while V 1 and V 2 have unexpanded nodes do 10. Pick the next pair x  X  V 1 and y  X  V 2 based on FIFO order for expanding; 11. for each member x 1 with selected ( x 1 ) = 0 in the ring owned by x do 12. for each member y 1 with selected ( y 1 ) = 0and y 1 = 13. if  X  t ( x 1 , y 1 )&lt; r t and 14. [ edge ( x 1 , x ) exists for any x  X  V 1 if and only if 15. and  X  s ( edge ( x 1 , x ), edge ( y 1 , y )) &lt; r s 16. then V 1 = V 1  X  X  x 1 } ; V 2 = V 2  X  X  y 1 } ; 17. selected ( x 1 ) = selected ( y 1 ) = 1; 18. record one-to-one mapping f : x 1  X  y 1 ; 19. record one-to-one mapping g : edge ( x 1 , x )  X  edge 20. break; 21. end if 22. end for 23. end for 24. end while ; 25. Evaluate the resulting pair of similar subquery graphs 26. if it is worth to accept &lt; G 1 , G 2 &gt; 27. then Remove any &lt; G 1 , G 2 &gt; from S hold that shares some nodes 29. else if it is worth to hold &lt; G 1 , G 2 &gt; 30. then Reset selected ( x ) = 0 for all x in G 1 and G 32. else Reset selected ( x ) = 0 for all x in G 1 and G 33. Discard &lt; G 1 , G 2 &gt; ; 34. end if ; 35. end while ; 36. while S hold = X  do /* accept some held similar subquery pairs */ 37. Remove the largest pair &lt; G 1 , G 2 &gt; from S 38. if &lt; G 1 , G 2 &gt; does not share any node with any pair in S 40. end while ; 41. for each similar subquery pair &lt; G 1 , G 2 &gt;  X  42. Optimize G 1 and share the execution plan with G 2 43. Replace G 1 and G 2 in the original query graph G with their (estimated) 44. end for ; 45. Optimize the revised G to generate an execution plan; 47. end.

Lines 4 X 35 search for all pairs of similar subquery graphs in query Q .Lines 46 returns the execution plan for the given query.

More details of some steps and the reasons why some decisions in the algorithm were made are discussed in the following subsections. Choosing starting nodes
For a given query Q , when we construct its ring network, we also construct a set of table in the query, which has a header containing the base table name R sublists X  X ne, OL i , contains all its instances (nodes) in the query and the other, SL contains other table instances whose sizes are within error bound r showninFig.6.
 the similar subquery graphs in a pair, the more the optimization work can be shared between them, and, therefore, the more time is saved for query optimization. of starting nodes. Hence, a greedy approach is adopted. We attempt to choose a pair represented by the adjacent node pair are within the given error bound r stance vertex in the given query graph and R i be a base table. Array element O indicates how many current adjacent nodes representing base table R are within the given error tolerance with respect to R an example of indicator arrays O and S .
 nodes x and y selected from a similarity starting list, we can calculate the following value: where  X ( x , y , i ) is defined as follows: other table instances whose table sizes ar e within the given error bound, formula (2) gives the total number of such matchings for the current base table. Note that arrays
O and S need to be updated every time when matched nodes are removed from
Formula (1) essentially gives the total number of matching pairs of adjacent nodes for the pair of starting nodes x and y in a matching way described above. Our heuris-value of formula (1). If there is a tie, we pick up a pair with the smallest difference of table sizes. If there is still a tie, a random pair is chosen. Searching for similar subquery graphs the first-in first-out (FIFO) fashion for further expansion. This procedure is repeated until no pair of nodes can be expanded.

We use a nested-loop method to check all the unselected nodes ( x of this new pair of nodes x 1 and y 1 are within error bound r nodes that are already in similar subquery pair V 1 y
There are two cases in which the similarity of G 1 we add x 1 and y 1 into them: (i) There exists a pair of x  X  V 1 and y = f ( x )  X  V 2 such that edge (ii) There exists a pair of x  X  V 1 and y = f ( x )  X  Selecting similar subquery graphs optimization, their nodes cannot participate in other possibly larger similar subquery graph by setting their  X  X elected X  flag to 1.
 ones. Otherwise, we will still use the held similar subquery graphs. we use two threshold values, c 1 and c 2 ,where c 1 &lt; nodes in a similar subquery graph (note that G 1 and G 2  X  If n  X  c  X  If c  X  If n &lt; c graphs.
 Optimizing query that is generated from optimization to the one for its partner. For example, consider lationship for the nodes: x 1  X  y 1 , x 2  X  y 2 , x 3  X  y , y mapped plan for G 2 is (( y 1 y 2 ) y 3 ) .
 query graph, we reduced the number of nodes in it. Because the complexities of the than a chosen small constant), a dynamic-programming-based optimization technique can also be used to find a truly optimal plan for it.
By counting the number of operations requi red by each line in Algorithm 3.1, it is not difficult to see that the worst-case time complexity of the algorithm is O query Q ,and T ( n ) is the complexity of the optimization technique used to optimize the similar subqueries and the revised final query. As mentioned before, unless n is queries in each pair. Sharing work among more than two similar subqueries in each subqueries, &lt; G 1 , G 2 &gt; , first. Other subqueries (other than G subqueries in this similar group share the same execution plan generated for G representative subquery for the group. A trade-off should be made between the size of each similar subquery and the size of the similar group (i.e. the number of similar subqueries in the group). In general, the more similar subqueries in each group and saved.
 subqueries in the rest of the discussion in this paper. for the corresponding vertices and the sel ectivities for the corresponding edges from selectivities of two join conditions and the sizes of corresponding operand tables are of the similarity between subqueries into multiple levels.
Let symbol G  X  X  k ( r
Sect. 2.3 is for the one at level 1, i.e. G  X  X  1 are recursively defined as follows.
 Let G 1 ( V 1 , E | V 1 , T | V 1 , P | V 1 , X  | V 1 , X  | their result table and rearrange the edges of the related tables in G result table, we get a new graph G 1 . We call this operation a by  X ( G
Let G and G be two subquery graphs in query graph G . r satisfy the following condition, we regard them as a pair of similar subquery graphs at similarity level k ,i.e. G  X  X  k ( r  X 
For  X  e  X  E and g ( e )  X  E ,wehave G  X  X  k  X  1 ( r  X ( G , g ( e )) .
 the same, and if we join any corresponding 2 , 3 ,... corresponding selectivities are within their given error bounds, r in Fig. 1, a pair of 2-level similar subquery graphs using error bounds r are shown in the light dotted-line circles. optimize a complex query by exploiting its k -level similar subqueries.
T |  X (
G 1 , x ) .If x  X  V 1 ,thatis, x is a node in subquery graph G
Otherwise,  X ( G 1 , x ) = FALSE. We will use this function in describing the algorithm graph G 1 .
 lines 11 X 23 in Algorithm 3.1 by the following code:
Algorithm 4.1. Revised code segment for Algorithm 3.1 1 . for each member x 1 with selected ( x 1 ) = 0 in the ring owned by x do 2 . for each member y 1 with selected ( y 1 ) = 0and y 1 3 .flag = 1; 4 . V 1 = V 1  X  X  x 1 } ; V 2 = V 2  X  X  y 1 } ; 5 . record one-to-one mapping f : x 1  X  y 1 ; 6 . for i from 1 to k do 7 . for each G 1  X  X  G | G is a subquery graph of G 1 , 8 . follow the one-to-one mapping relationships (for vertices and 9 .Let res 1 and res 2 be the result tables for G 1 and G 10 . if  X  t ( res 1 , res 2 )  X  r t or {  X  x  X  V 1  X  V 1 and y 11 . then flag = 0; break; end if ; 12 . end for ; 13 . if flag = 0 then break; end if ; 14 . if i = 1 then 15 . record one-to-one mapping g : edge ( x 1 , x )  X  edge 16 . end if ; 17 . end for ; 18 . if flag = 1 /* k-level similar */ 19 . then selected ( x 1 ) = selected ( y 1 ) = 1; break; 20 . else V 1 = V 1  X  X  x 1 }; V 2 = V 2  X  X  y 1 } ; 21 . if i &gt; 1 then 22 . unrelate the mapping relationships g : edge ( x 1 , 23 . end if ; 24 . unrelate the mapping relationship f : x 1  X  y 1 ; 25 . end if 26 . end for 27 . end for ; complexity of the above algorithm segment is O ( k  X  more similar the two corresponding subquery graphs. Hence, a good execution plan other hand, if the similarity level is very high, the chance to find similar subqueries
Therefore, we assume k n . Note that, to search for identical (common) subqueries, et al. 2002).
In the last section, we have shown that our technique is an efficient polynomial time technique, which is suitable for optimizing complex queries. Although our technique execution plan for a complex query than others because it takes some complex query the execution plans generated by our technique.

In the experiments, we chose to compare our technique with the most promising randomization technique, i.e. the AB algorithm, for optimizing complex queries. We
For simplicity, we call our technique based on the i -level similarity the i -level 1 , 2 The experiments were run on a PC with PIII 500 MHz CPU and 512 MB RAM. periments, which is described as follows.
 The experimental database consists of 80 tables with their sizes shown in Table 1.
This database has the following characteristics:  X 
The table sizes cover a wide range from 1 to 19,521,020 rows.  X  ( | R cantly different/dissimilar) in these two groups. This feature allows us to include some dissimilar tables in test queries. Note that the database contains both small group) to increase the diversity.  X  query: R 11  X  R 75 . The relative error between the sizes of two consecutive tables in the group is from 1.5% (near R 75 ) to 27.5% (near R closer the two tables, the more similar they are. For example, tables R
Clearly, the above synthetic database allows us to have some controllable parameters, such as the number of similar/dissimilar table instances in a query, the error bounds for similarity and selectivities for query conditions in our experiments. Hence, we can lows.  X  Determining the tables in each pair of similar subqueries query Q . This process is repeated until all tables in subqueries Q determined.  X 
Determining the join edges (connections) for each pair of similar subqueries &lt; Q its adjacency matrix A [ 1 .. m , 1 .. m ] .Thatis,if A between the i th table and the j th table (1  X  i , j  X  m )in Q upper triangular part of matrix A due to its symmetry. To ensure subquery Q upper triangular part of A , its elements are determined as follows. We randomly pick a number k from the range [0, m  X  ( m  X  1 )/ 2] as the additional number of edges (besides m edges for the first row of A ) in subquery Q pick a number from the range [1, m  X  ( m  X  1 )/ 2], map this number into a position in the upper triangular part of A and set the element at this position to be 1. This process is repeated until k additional join edges are chosen. Once the join edges for Q 1 are determined, the corresponding join edges for Q  X  icate with selectivity S and associate (label) it to the edge. To avoid having an ex-within the range (0, 0.3]. For the corresponding join edge in Q choose a join predicate with a sel ectivity within the range (max{ tivities for the given test query Q .  X 
Determining the tables that are not in any similar subquery .Todoso,were-peatedly choose a table (randomly) from R 1  X  R 10 and R 76 tables in the given query are determined.  X  not in any similar subquery . To do so, we consider each similar subquery deter-mined previously in the given query Q as one single (merged) table. We then apply the above adjacency matrix method to determine the join edges among the (merged and unmerged) tables. If an end of join edge e is connected to a merged table representing a similar subquery Q ,atable R within Q is randomly cho-sen to connect to that end of edge e in the original (unmerged) query. For each join edge, a join predicate is randomly chosen for it.
 nique.
 reject a pair of identified similar subqueries (subgraphs) in our technique: c c tables (nodes) are put on a hold list.

As mentioned before, both the AB algorithm and our technique have a poly-time to try more random plans. If we let the stand-alone AB and the AB used within took about 26.6%  X  68.5% (47.7% on average) more time to optimize a large 4 ments.
 execution plans generated by different tec hniques for a set of test queries. The error bounds used to search for similar subqueries in the experiments were r to 20%.
From the experimental result, we can see that the performance of execution plans is better than the performance of execution plans generated by the AB algorithm. In fact, our 1-level, 2-level and 3-level similarity methods improve the performance of the queries (on average) by 82.2%, 69.0% and 65.7%, respectively. This observation performance of its execution plan.

The experimental result also demonstrates that increasing the similarity level usu-duces this benefit (because using a good execution plan for a small subquery may not have a significant impact on the performan ce of the overall execution plan, compared with a large subquery).

We also conducted experiments to examine the effect of error bounds on the per-formance of query execution plans generated by our technique for different similarity levels. Figure 7 shows the typical experimental result for a large query with similar subqueries at different levels for different error bounds (assuming r figure, we can get the following observations:  X 
Very small error bounds cannot yield good pe rformance, because, the smaller the error bounds, the smaller the similar subqueries found.  X 
Moderate error bounds (e.g. 0.3  X  0.5) yield the best performance because similar subqueries with reasonable sizes can be found.  X 
Large error bounds degrade the performance because subqueries are less similar in such cases, which means that shari ng execution plans among them may be inappropriate.
  X  When the error bounds are sufficiently large (e.g.  X  When the error bounds are large, similarity at a higher level helps to improve the similar subqueries. For each percentage, we a pplied our technique (1-level as a rep-mental result.
 more the performance improvement achieved by our technique. When the percentage of tables outside the similar subqueries in a query is very large (e.g. suitable for queries without or with little similarity among its subqueries. level is needed to ensure reasonable performance.
As database technology is applied to more and more application domains, user queries become more and more complex. Query optimization for such queries becomes very a given query is still unsatisfactory because these techniques do not take the special characteristics of a complex query into consideration.

In this paper, we propose a new technique for optimizing complex queries based representation to represent a complex query, search for similar subqueries, optimize queries, reduce the original query by replacing each similar subquery with its result table and then optimize the revised final query. Any efficient technique such as AB structure characteristics of a query into account and divides a large query into small the original query with a large number of operand tables.

Our experimental results demonstrate that the technique is quite promising in
AB algorithm. Experimental results also show that different situations need different similarity levels to obtain the best performance for our technique. future in order to completely solve the query optimization issues for complex queries.
In this appendix, we show an example of a complex (large) query with similar sub-query structures from a real-world user application. To protect the user X  X  information, we have masked the real names of the tables and attributes in the example. The com-plex query is expressed in SQL as follows.
 SELECT SUM(F.R_CMS) AS CMS, SUM(F.R_MPY) AS MPY, SUM(F.R_NCD) AS NCD, SUM(F.R_SPI) AS SPI FROM FR_7 F, DR_7 D7, S_CLA S1, S_CLA S2, S_CLA S3, S_CLA S4, S_CLA S5, DR_2 D2, SCARE S6, DR_5 D5, SCUSR S7, SCUSR S8, SCUSR S9, SCUSR S10, SCUSR S11, SCUSR S12, SCUSR S13, DR_U DU, SUNIT S14, DR_T DT, SDATE S15, SCMON S16, SCQUA S17, SCWEK S18, SCYER S19, DR_B DB, SCSMR S20, DR_8 D8, SCTYP S21, SCRCY S22, DR_1 D1, SCUPC S23, SMATR S24, SPLT S25, DR_A DA, SR_BAC S26, SR_BKY S27, DR_C DC, SR_CDF S28, SR_CSR S29, SR_CSN S30, SR_CNB S31, SR_CTP S32, SR_COD S33, SR_CON S34, SR_COT S35, DR_6 D6, SR_CTR S36, SR_CDF S37, SR_PDR S38, SR_PME S39, SR_PON S40, DR_9 D9, SR_PPR S41, DR_D DD, SR_PMO S42, DR_4 D4, SR_RCN S43, SR_SGR S44, SR_SNO S45, DR_3 D3, SR_SHR S46, SR_STP S47, SR_SER S48, SUNIT S49, STIME S50, SWDY1 S51, DR_P DP WHERE F.KC_1=D1.DID AND D1.ENP=S23.SID AND D1.MAT=S24.SID AND F.KC_2=D2.DID AND D2.CUS1=S6.SID AND D2.PLT=S25.SID AND F.KC_3=D3.DID AND D3.SHR=S46.SID AND D3.TIME=S50.SID AND F.KC_4=D4.DID AND D4.RCN=S43.SID AND F.KC_5=D5.DID AND D5.CUS2=S7.SID AND D5.CUS3=S8.SID AND D5.CUS4=S9.SID AND D5.CUS5=S10.SID AND D5.CUS6=S11.SID AND D5.CUS7=S12.SID AND D5.CUS8=S13.SID AND D5.SGR=S44.SID AND D5.SNO=S45.SID AND F.KC_6=D6.DID AND D6.CTR=S36.SID AND D6.PON=S40.SID AND F.KC_7=D7.DID AND D7.CLA1=S1.SID AND D7.CLA2=S2.SID AND D7.CLA3=S3.SID AND D7.CLA4=S4.SID AND D7.CLA5=S5.SID AND D7.CSR=S29.SID AND D7.CSN=S30.SID AND F.KC_8=D8.DID AND D8.C_TYP=S21.SID AND D8.COD=S33.SID AND D8.CON=S34.SID AND D8.COT=S35.SID AND F.KC_9=D9.DID AND D9.PPR=S41.SID AND D9.STP=S47.SID AND F.KC_U=DU.DID AND DU.B_UOM=S14.SID AND DU.D_CRY=S22.SID AND DU.S_UNI=S49.SID AND F.KC_T=DT.DID AND DT.CDAY=S15.SID AND DT.CMON=S16.SID AND DT.CQUA=S17.SID AND DT.CWEK=S18.SID AND DT.CYER=S19.SID AND DT.WDY1=S51.SID AND F.KC_A=DA.DID AND DA.BAC=S26.SID AND DA.BKY=S27.SID AND F.KC_B=DB.DID AND DB.CSM=S20.SID AND DB.CDF=S37.SID AND F.KC_C=DC.DID AND DC.CDF=S28.SID AND DC.CNB=S31.SID AND DC.CTP=S32.SID AND DC.PDR=S38.SID AND DC.PME=S39.SID AND DC.SER=S48.SID AND F.KC_D=DD.DID AND DD.PMO=S42.SID AND
F.KC_P=DP.DID AND ((((DP.RQD&lt;=81)) AND ((S1.C_CLA BETWEEN  X  X 0 X  AND  X  X 6 X )))) GROUP BY S1.C_CLA, S2.C_CLA, S3.C_CLA, S4.C_CLA, S5.C_CLA, S6.CUSR, S7.CUSR, S8.CUSR, S9.CUSR, S10.CUSR, S11.CUSR, S12.CUSR, S13.CUSR, S14.UNIT, S15.DAT, S16.CMON, S17.CQUA, S18.CWEK, S19.CYER, S20.CSMR, S21.CTYP, S22.CRCY, S23.CUPC, S24.MATR, S25.PLT, S26.R_BAC, S27.R_BKY, S28.R_CDF, S29.R_CSR, S30.R_CSN, S31.R_CNB, S32.R_CTP, S33.R_COD, S34.R_CON, S35.R_COT, S36.R_CTR, S37.R_CDF, S38.R_PDR, S39.R_PME, S40.R_PON, S41.R_PPR, S42.R_PMO, S43.R_RCN, S44.R_SGR, S45.R_SNO, S46.R_SHR, S47.R_STP, S48.R_SER, S49.UNIT, S50.TIME, S51.WDY1 .

This query involves 68 tables. To process this query, a database management system typically performs a join of all tables using the condition in the WHERE clause first.
It then processes the GROUP BY clause. The join structure for this query is shown in Fig. 9, which demonstrates a snowflake structure. Similar subqueries exist among the snowflakes in the query.

