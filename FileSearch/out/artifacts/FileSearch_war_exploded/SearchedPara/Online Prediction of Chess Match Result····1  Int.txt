 Chess is a well structured game as the states and moves of the games are well defined. Unlike the games such as soccer, basketball and the like, where the position of the players, movement of the ball, etc. are not predefined, chess has predefined set of states (although very large) and moves. Our goal is to investigate that with the help of machine learning, how well the outcome of such a structured game can be predicted before the game ends just by examining the moves made by each player. We believe that the results from this research will motivate building prediction models for other structured or semi-structured games, such as other board games, cricket and baseball. This prediction system will be a useful application for spectators, players as well as trainers for various purposes. For example, spectators may use this system to understand the status of each opponent X  X  hold in the game, players can use it to get an early warning before a move is made, and trainers can use it during the post analysis of the match to identify the turning points and bad moves in the match.
 Computers have been programmed to play chess using AI based search tech-niques since the second half of the 20th century. IBM X  X  Deep Blue was the first computer to defeat World Chess Champion Garry Kasparov in 1997 [ 6 ]. Since then, powerful chess engines have been evolving rapidly and now many com-mercial chess playing software are available. However, in this work, rather than proposing another smart chess playing agent, we focus on predicting the outcome of a chess match before the game ends.
 There has been several attempts in the past to predict chess game outcomes [ 3 , 4 ]. These predictions are static, meaning, they don X  X  consider the dynamism of the game, and predict the outcome before the game has started. On the contrary, our proposed system dynamically updates the winning (or drawing) probabilities after each move of the game. In our system, an ensemble training and classification approach is used for the prediction task. We use a profiling technique to separate chess games into different profiles based on the number of moves in the games. Then we extract move-based features from each chess game and develop feature vectors. These feature vectors are used to train a classifier for each profile. We use an ensemble of the classifiers to predict the outcome of a new game. We show both analytically and empirically that the ensemble based classifier is superior to a single classifiers trained with all the historical data. To the best of our knowledge, this is the first approach to dynamically predict chess match outcome with the help of machine learning using only the informa-tion obtained form the moves of the game. Our contributions are as follows. First, we propose a learning technique that extracts move based features from the games. Second, we have proposed a novel technique for training classifi-cation models by carefully choosing and segmenting the training data with our profiling-segmentation technique and applying the trained models to predict new games. Third, we have proposed an online and adaptive ensemble classification technique for improving the prediction accuracy. Finally, we have applied our technique on a large corpus of real chess matches and obtained higher prediction accuracy than traditional classification techniques.
 The rest of the paper is organized as follows. Section 2 discusses the work closely relevant to our work. Section 3 and 4 describe the proposed method in details and Section 5 reports the experiments, results, and analyzes the results. Finally, Section 6 concludes with direction to future works. Several works have been proposed for chess game prediction using machine learn-ing or data mining techniques. A Chess Game Result Prediction System was proposed by Fan et. al. [ 3 ]. Their project was to train a classifier with the World Chess Federation (FIDE) rating system using a training dataset of a recent eleven-year period, which ranges from year 2000 to 2011, and then use their system to predict the outcome of chess games played by the same players in the following half year. Their success rate of the prediction was 55.64%. tion model trained on the outcomes of chess games in past few years and used to predict future games played by the same players. The model was trained iter-atively, and it contained several parameters for tuning. However, it is not clear what was the prediction accuracy of the proposed method. In another interest-ing work, Ferreira [ 5 ] proposed a technique to determine the strength of a chess player based on his actual moves in a game.
 we do not use any information of the player (i.e. Elo rating) for training, and second, we use an ensemble based classification technique. Finally, our approach is dynamic, meaning, the prediction is updated as the game progresses. On the contrary, all previous approaches are static prediction, meaning, the predictions are fixed and computed before the game is played.
 semble classification models have been effectively used in recent years for classify-ing large data evolving data streams [ 1 , 8 ]. Ensemble classification models consist of an ensemble (collection) of classifiers. When classifying an unknown instance, each individual classifier outputs its own prediction and a majority vote is taken to choose the winning class. This winning class is the predicted class for the ensemble. There are different majority voting techniques available, namely, sim-ple majority and weighted majority. The ensemble approaches mentioned above are good in handling dynamic data stream, where the data are always evolv-ing. However, as per our observation, the problem of predicting chess matches is rather noisy data than evolving data. So we propose our own noise reduction technique to achieve high prediction accuracy.
 In this paper, we propose a general framework for the prediction system. The high level design of the system is shown in figure 1 . The chess database is a collection of past chess games (Section 3.1 ). From this database, we extract and select features (Section 3.2 ) to generate the training data, which is used to train a classification model (Section 4.1 ). Finally, when a new game is played, the probabilities of win/loss/draw are predicted after every move using the trained classifier (Section 4.2 ). Following sections detail each component of the system. 3.1 Chess Database There are many chess databases available online. However, we choose the data-base from ChessOK.com [ 2 ] because of several reasons. First, the database is free. Second, it contains the games of all major tournaments from the year 2011. Finally, the games in the database are well organized -month by month basis, which is useful for our purpose.
 The games in the database are stored in PGN format. Each month X  X  games are divided into smaller chunks of games, each chunk containing approximately 1,900-2,000 games. Each game in the database contains several information about the match, such as date, tournament name, players X  names and ratings. Then the actual moves of the game are listed. An example of a PGN file is shown in figure 2 .
 3.2 Feature Extraction and Selection For each game we utilize the move-based information for the training and pre-diction. We extract two types of features from the moves, namely, split-move and n-ply features, as explained below.
 Split-move Features: These features are generated by splitting each ply (a move by one player) into five nominal features, namely, piece, column, row, check and capture, which are explained below: Piece type , having six possible values: { P, R, N, B, Q, K Rook, Knight, Bishop, Queen, and King, respectively.
 Column (column or file of the chess board), having 8 possible values: Row (row of the chess board), having 8 possible values: { Capture (captured opponent X  X  piece or not)= { 0, 1 } Check (checked opponent X  X  King or not) = { 0, 1 } For each game, we convert each ply into these five nominal features and generate the feature vector. Therefore, if the game consists of 21 moves, meaning 42 plies, then there will be 42 * 5 = 210 nominal features, arranged in the same order as the moves appear in the game. For example, for the game in figure 2 , the split-move features (comma separated) will be as follows: { N,f,3,0,0,N,f,6,0,0,P,c,4,0,0,P,g,6,0,0,.... } .
 A game may have any number of moves. Therefore,this feature-based app-roach generates different number of features for different games. However, most machine learning techniques require fixed size feature vector (i.e., same number of features for all data). This issue is discussed in details in the next section (Section 4 ). The advantage of this approach is that that the order of moves are preserved in the feature vector. n-ply Features: These features are generated by considering each ply (e.g.  X  X f6+ X ) as a feature. There are two steps in generating the feature vector for these features. In the first step, we scan the whole database of games and collect all possible features from all games. Let S be the set of all such features obtained from all the games. The next step is to generate a feature vector for each game. The feature vector will be a vector of bits, where bit i =0 of the i -th feature S is absent in the game and bit i =1, if the i -th feature S in this approach is that the number of features, i.e., the size of S may be very large. In this case, we apply a feature selection technique based on information gain, and choose the best K features to be used in the feature vector. Algorithm 1. PROSEGEN The training process consists of two stages: i) profiling and segmentation (PRO-breakSEG) and ii) building the ensemble (EN) of classifiers. The prediction involves using the ensemble classifier for predicting results of new games. 4.1 Profiling and Segmentation of Data As mentioned earlier, variable number of moves in the games lead to variable number of split-move features, which is problematic for learning techniques that rely on vector-based features. However, we can manipulate the feature vectors to keep them equal. For example, suppose we choose vector size to be 200 moves. Therefore, a game having only 20 moves will have to be padded by 180 null or default values. This introduces noise in the training data, reducing the perfor-mance of the trained classifier. To solve this problem, we propose a profiling (PRO) and segmentation (SEG) technique, implemented with algorithm 1 . Description of Algorithm 1 : It takes as input the training data T , and the number of segments n to created. Let N be the dataset size, i.e., total number of games in T . First, we create separate bins and keep all games having i moves into bin i (lines 3-5). Then we create each segment by joining the adjacent bins in a way such that each segment contains approximately the same number of games (lines 9-16). This is done to avoid dominance by any data segment. Besides, since we are going to build an ensemble of classifiers, we also need to ensure that each classifier gets equal amount of training data so that all classifiers achieve same quality (i.e., prediction power). Finally, we train one classifier from each data segment. In the experiments (Section 5 ), we show a detailed analysis of the bin sizes and performance of the ensemble on each bin.
 Noise Reduction by Segmentation: Now we show that the segmentation reduces noise in the training data. Let m be the maximum number of moves considered in building the unsegmented training data, T . As mentioned earlier, all instances (i.e., games) in the feature vector must have equal length. Therefore, games having less than m moves must be padded with default feature values (e.g. zero) to make the feature vectors equal length. Therefore, the padded values can be considered as noise added to the features. For simplicity of representation, suppose we divide the training data into two equal segments, T T = T 1  X  T 2 and | T 1 | = | T 2 | , such that T 1 contains all the games having m less moves and T 2 contains all the games having m 1 + 1 or more (upto m ) moves. Also, let f i = number of instances (i.e., games) having i moves. Therefore, Let  X  ( T ) = Added noise in T = Total padded moves in T . Note that a game having i&lt;m moves is padded with m  X  i moves. Therefore, Where  X  ( T 1 ) is the added noise in the segment T 1 . The same proof is applicable to segment T 2 . Therefore, equation (2) concludes that the added noise in segmented training data is less than that of the combined training data. If we keep dividing the segments into smaller and equal segments, the noise reduction will continue upto a point where this advantage in noise reduction will be outweighed by insufficient amount of training data. This trade-off between noise reduction and diminished training data must be considered during training. 4.2 Ensemble Classification The ensemble of classifiers is then used to classify new games. The classification process is shown in algorithm 2 .
 Algorithm 2. Classification Description of Algorithm 2 : The input to the algorithm are the ensemble ( E ) and the game to classify ( x ). The game x may be an ongoing game (i.e., not finished yet). First, based on the number of moves already made in the game, we find the appropriate segment where the game fits in (line 1). Then we predict the game using the corresponding classifier (line 2). This classification is analogous to an weighted ensemble classification, where the weight for the classifier corresponding to x  X  X  segment is 1, and the weight of all other classifiers in the ensemble is 0. This is done to minimize feature noise in the test data. In this section we describe the datasets, experimental environment, and discuss and analyze the results. 5.1 Data Sets and Experimental Setup The dataset [ 2 ] contains a collection of more than 300,000 chess games dated from October 2011 upto August 2014. The data are divided into approximately equal sized batches of about 2000 games, organized in a single PGN file. For each month, there are 4-6 such batches. We use the games from 2011-2013 as training and the games from 2014 for testing, i.e., evaluating the trained prediction model. Competing Approaches: B C: The traditional batch learning classifier, which is trained with all the training data.
 E E: An ensemble classifier with equal weight given to each individual classifi-cation model in the ensemble. The predicted class is the class that has majority vote. Each such individual model is trained from one segment of the training data, segmented using the proposed segmentation technique.
 P E: This is the PROSEGEN ensemble model, which is an weighted ensemble with highest weight (1) given to the individual classification model that belongs to the same bin as the test instance. Other classifiers are given zero weight. Base Classifiers: We have experimented with several classifiers. For each classi-fier, we used the WEKA machine learning API [ 9 ]. The classifiers are NaiveBayes (NB), Decision Tree (J48 in WEKA) Random Forest (RF), and Support Vector Machine (SVM).
 Besides these classifiers, we have also experimented with sequence-based clas-sifiers by considering the game as a sequence of moves. The classifiers are: Hid-den Markov Model (HMM) classifier and Bounded Coordinate-Descent sequence classifier [ 7 ]. However, their prediction accuracies are far below the others and so,wedonotreportthem.
 Feature Set: We have used both the split-move and n-ply features in our exper-iments but due to space limitation, we report only the results for split-move features because they achieve higher prediction accuracy.
 Parameter Settings: The only parameter in our approach is the number of segments (i.e., n ), which also decides the ensemble size. In all experiments, we keep 12 &lt;n&lt; 16 as we obtain the best results for these values. For the classifiers used in WEKA, we use the default parameter values provided by the API. Hardware and Software: The experiments were done on a standalone work-station having Intel Core i5 2.4GHz processor with 8GB RAM and 750GB Hard Drive. The OS was Windows 7. All programs have been developed with Java with NetBeans IDE, and Weka API [ 9 ] has been used for the base classifiers. 5.2 Evaluation Unless mentioned otherwise, we use prediction accuracy (Acc %) as the evalu-ation metric, which is the percentage of instance correctly classified. Here the classification problem is considered multi-class because there are three classes, namely, white winning, black winning, and draw. Also, unless mentioned other-wise, the accuracy are obtained by evaluating complete games (i.e., all moves are considered). Also, in all the evaluations, the training data are the games played in the years 2011 to 2013, and the evaluation (i.e., test) data are the games played in year 2014.
 Effect of Varying Training Data: First, we evaluate the effectiveness of the learn-ing techniques by varying the size of training data. Figure 3(a) shows the effect for decision tree (J48) classifier. Similar effect is obtained for other classifiers. We vary the training data from 33,000 to 270,000, where 33,000 dataset contains only the games from year 2011 and 270,000 dataset contains all the games from 2011 to 2013 obtained from [ 2 ]. We see that all competing approaches show the similar trend, i.e., increasing training data increases the classification accuracy. For example, for 33K training data, the accuracies of PE, EE, and BC are 59.8, 36.4, and 51.6, respectively, whereas for 270K training data, the values are 65.6, 40.8, and 59.8, respectively. In all cases, PE has the highest accuracy being at least 5% higher than that of BC, and 15% higher than that of EE.
 Feature Set Size vs Accuracy: We varied the size of feature sets by capping the number of moves to a lower value and this effect is shown in figure 3(b) for Naive Bayes, using the 270,000 training dataset. The X axis shows the number of moves chosen as features and the Y axis shows the accuracy for each complet-ing approach. For example, X=40 means we choose only the first 40 moves of each game as features and ignore the remaining moves. For this value of X, we obtain accuracies of PE, EE, and BC as 57.8%, 51.4%, and 43.3%, respectively. The general trend here is that with increasing size of feature set, the accuracy increases. This is because as more moves are considered for features, more infor-mation are obtained from the game, which facilitates achieving higher accuracy. Also, here in all cases, PE has the highest accuracy.
 Summary on All Datasets, Classifiers, and Competitors: Table 1 shows the sum-mary of the results for each competing methods using each classifier and datasets. The columns under  X  X raining data size X  report the accuracy for different sizes of training data, ranging from 33K to 270K. Also, the rows corresponding to each classifier report the classification accuracy of each competing approach when trained with different sizes of training data. Note that in all cases, the test data is the same, which is the set of 23,000 games played in 2014. As an example, the row headed by  X  X 48 X , and  X  X E X  shows the accuracy of PE using decision tree (J48) classifier when trained with training data having sizes ranging from 33,000 to 273,000. Note that the highest accuracy (65.6%) is obtained with J48 and PE for 273,000 training data. We are only able to train the SVM with 33,000 train-ing data, and with the 90,000 training data for PE and EE, because for larger datasets, SVM crashed due to insufficient memory (we used upto 6GB memory for JVM). Therefore, we are unable to report the accuracies for SVM for larger training datasets. Also, note that in all settings, PE has the highest prediction accuracy. The main reason of PE having higher accuracy than BC is because of the noise reduction using profiling-segmentation and ensemble classification. The reason for PE having higher accuracy than EE is because PE assigns proper weight to the classifiers, whereas EE assigns equal weights, without judging the relative importance of the classifiers in the ensemble.
 How Early Can We Predict? In this experiment, we answer the question, i.e., how early can we correctly predict the outcome of the game? We answer this in the number of moves, i.e., we say, we predict K move early, meaning, we correctly predict the outcome of the chess match K moves before the game ended. Figure 4(a) shows the summary on the same test dataset, with PE using Naive Bayes and 270,000 training data.
 Figure 4(a) reports only the games that are correctly predicted. Note that out of 23,000 games in the test data, about 14,500 were correctly predicted. Each segment of the pie chart shows two values: the number of moves, and a percentage. For example, consider the segment: 1 move, 9%. This means 9% of the correctly predicted games (about 1,300 games) had the correct prediction 1 move before the game ended. Similarly, the segment 4-5 moves, 15% means 15% of the correctly predicted games (about 3,500 games) had the prediction 4 or 5 moves before the game ended. If we examine carefully, we would notice that about one third (31%) of the correctly predicted games (about 7,000 games) obtained the correct prediction at least 16 moves before the game ended, which is really promising. This means that with this data mining technique, we have a good chance to predict correctly long before the game ends. In order to demonstrate the effectiveness of this prediction system, we apply it on the so called  X  X ame of the century X , played between Donald Byrne (white) and 13-year-old Bobby Fischer (black) in 1956. The probabilities of white winning, draw, and black winning after each move is shown in the graphs in figure 4(b) . At the beginning of the game ( &lt; 10 moves), the chances of draw is high. Between 10 and 16, we observe a seesaw between white and black but white seems to have the upper hand. However, note that from move 17 and onward, winning probability of black is raised to near 100%. This reflects the brilliant counter made at the 17th move by Fischer, which is sometimes called the  X  X ounter of the century X . We see that after this move, black is always on the top and black winning has highest probability (some fluctuations between draw and black is observed between 30-40 moves but the final outcome is correct). Therefore, our system could detect well the turning point in the game and also predict the final outcome about 22 moves earlier than the game ended.
 Other Statistics: We also report several statistics about the games and predic-tions. In figure 5(a) , we report the number of games having a particular number of moves and how many of these games are correctly predicted in the test data. The X-axis shows the number of moves. For a particular value of X, say 40, the Y values indicate how many games have exactly 40 moves, which is 550, according to the graph (the higher line); and how many games out of these 550 are correctly predicted by our approach (the lower line), which is 335 in this case. From these two histograms we can come to two conclusions. First, most of the games have 30-60 moves. We observe similar distributions in the training data. The correct predictions are also similarly distributed, i.e, the prediction accuracy does not depend on number of moves in the game.
 winning, black winning, and draw) in the test data, and the distributions are similar to the training data. Note that these three outcomes have almost the same probabilities, therefore, the datasets have balanced class distribution. Also, about 70% of the white winning (6293/8860) or black winning (4829/6938) games are correctly predicted. However, this accuracy is lower (43% = 3212/7370) for the games ending with draw. This happens because of the higher uncertainty involved in these games compared to the deciding games.
 Table 2 shows the running times (training + testing, in seconds) of different techniques when trained with 33,000 training data and tested with 23,000 test data. It is evident that PE is the fastest approach. PE is faster than BC because BC uses all training data together to build the classifier, whereas PE divides the data into n approximately equal segments and builds one classifier out of each segment. Therefore, training of PE is faster than that of BC. Also, PE has lower running time than EE because PE uses only one classifier for prediction, whereas EE uses all classifiers and takes the majority. In this paper we proposed an online and dynamic prediction system for early prediction of chess match results. To the best of our knowledge, this is the first approach to use the move-based features, profiling-segmentation based ensem-ble training for building the prediction models, and dynamic prediction of chess game while the game is in progress. We have applied our technique on a large corpus of real chess matches and obtained higher prediction accuracy than bench-mark contemporary techniques. In the future we would like to investigate more on retrieving deeper domain knowledge and experiment with other features, such as sequence of moves and sequence of states, and use relevant sequence or time series classification techniques.

