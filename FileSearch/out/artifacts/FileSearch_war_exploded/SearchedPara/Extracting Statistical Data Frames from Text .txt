 We present a framework that bridges the gap between natural language processing (NLP) and text mining. Central to this is a new approach to text parame terization that captures many interesting attributes of text us ually ignored by standard indices, like the term-document matrix. By storing NLP tags, the new index supports a higher degree of knowledge discovery and pattern finding from text. The index is relatively compact, enabling dynamic search of arbitr ary relationships and events in large document collections. We can export search results in formats and data structures that are transparent to statistical analysis tools like S-PLUS X . In a number of experiments, we demonstrate how this framewo rk can turn mountains of unstructured information into in formative statistical graphs. Text mining, natural language pro cessing, NLP, statistical data frames, data analysis, visualization Human language is one of the most complex processes that data miners and statisticians have ever attempted to model. Yet, many commercial applications for te xt mining, categorization and search today rely on very simp le parameterizations of text content. The most common example of a text index is the term document matrix, which captures wo rd frequency distributions in a corpus of documents. This index representation does not do justice to the complexity of hum an language, but is dictated by the practical difficulty of storing more informative objects, such as constituency or dependency tr ees, in a compact and searchable form. In this paper we demonstrate how an indexing framework that includes NLP tags can benefit text mining and greatly increase the power of information discovery from text. The text mining and computational linguistic communities have coexisted for many years with limited interaction [1]. The aim of text mining is similar to data mining in that it attempts to analyze texts to discover interesting patterns such as clusters, associations, deviations, similarities, and differe nces across large collections of text documents [3]. Data mining researchers come from one of the statistics, database and machine learning communities. They are more familiar with structured data representations such as relational tables or statistical data frames. Often, the starting point for their analyses is a simple and shallow representation of text [11] that does not use NLP tags. For instance, many machine learning models can be trained on si mple text attributes, such as word co-occurence, proximity, sequence or order. The potential to apply NLP or co mputational linguistics to obtain a richer representation of text has existed for decades [2]. However, NLP tends to focus on one document or piece of text at a time and be rather computati onally expensive. It includes techniques like lexical analysis, multiword phrase grouping, sense disambiguation, part-of-speech ta gging, anaphora resolution, and role determination. The arguments against NLP are that it is error-prone, and NLP output (i.e. pars e trees) contains too much linguistic detail, noise and uncertainty to provide a working knowledge base for data analysis or mining. Failure to account for semantic and syntactic variati ons across a document collection has led to disappointing results wh en trying to use fine indexing structures derived from a linguistic parser. Information Extraction (IE) is a methodology employed as a precursor to text mining especially in bioinformatics [4] [5]. IE applies NLP techniques to extract predefined sets of entities, relationships, and patterns of interest from documents. IE systems, like those developed in the MUC [6] and ACE [7] programs, are limited in their pow er of information discovery. First, they employ pre-determined templates or rule sets. Second, they do not index everything in a corpus, but only what they are preprogrammed to find. The aim of text mining should be to find novel patterns rather than predefined ones. In addition, because of the time involved in reprogramming extraction rules and reprocessing large volumes of text, it is difficult to iteratively apply mining processes to the output of IE tools [12]. We have developed a proof of c oncept based on a new system for text analysis and search called InFact. The major innovation in InFact is a new indexing process that combines the flexibility and efficiency of keyword indexing with the knowledge of grammatical or syntactic roles. A major difference between our approach and other existing technologies for IE is that, during indexing, we are not restricted by any rigid, pre-determined templates or patterns. InFact indexes every clause of every sentence of every document in a large corpus, whether or not the clause contains certain named entitie s or trigger words. It follows that we can interactively query a large database of text documents for all kinds of relationships and events. We can also output all search results into formats and data structures that are transparent to statistical analysis tools such as S-PLUS X . The remainder of this paper is organized as follows. Section 1 presents an overview of our indexing approach. Section 3 describes the data frame export module. Section 4 demonstrates data analyses on a variety of extracted data frames. These include: InFact consists of an indexing a nd a search module. With reference to Figure 1, indexing pe rtains to the processing flow on the left of the diagram, while search is on the right. InFact models text as a complex multivariate object using a unique combination of deep parsing, linguistic norma lization and efficient storage. The storage schema addresses the fundamental difficulty of reducing information contained in parse trees into generalized data structures that can be queried dynamically. In addition, InFact handles the problem of linguistic variation by mapping complex linguistic structures into semantic and syntactic equivalents. Our long-term objec tive is to provide a unified knowledge representation for stru ctured and unstructured data sources. This representation shoul d supports dynamic relationship and event search, information extraction and pattern matching from large document collections in real time. Unlike traditional models that store only word distributions, InFact performs clause level indexing and captures syntactic roles, constructs, relationships, a nd inter-clause relationships that enable it to understand events. Another strong differentiator of our approach is that we create these indices automatically, without using predefined extraction rules, and we capture all information, not just predefined patterns. Our parser performs a full constituency and dependency analysis, extracting part-of-speech (POS) tags and grammatical roles from every clause. The raw output of a deep parser usually does not lead to a tractable indexing schema for cross-document analysis. Therefore, we have developed a set of rules for converting an augmented tree representation into a scalable data storage structure. The basic idea involves collapsing selected nodes in the parse tree to reduce the overall complexity of the dependency structures. The result is a set of inter-linked subject-action-object triplets, as shown in Figure 2. The subject-action-object triples can express most types of synt actic relations between various entities within a sentence. With this parameterization in mind, we apply transformational rules (e.g. transformational grammar) that encode specific linguistic variations , and equate structures derived from different surface forms. We apply normalization rules at the syntactic, semantic, or even pragmatic level. InFact stores the normalized trip lets into a proprietary, patent-pending index that: The InFact index stores  X  X oft ev ents X  instead of fitting textual information into a rigid relational schema that may result in information loss.  X  X oft events X  are data structures that can be recombined to form events and relationships.  X  X oft events X  are pre-indexed to facilitate thematic retrieval by action, subject, and object type. For instance, a sentence like  X  X he president of France visited the capital of Tunisia X  contains evidence of 1) a presidential visit to a country  X  X  capital and 2) diplomatic relationships between two countries. Our storage strategy maintains both interpretations. In other words, we allow more than one subject or object to be associated with the governing verb of a sentence. The tuples stored in the database are therefore  X  X oft events X , as they may encode alternative patterns and relationships found in each sentence. Typically, only one pattern is chosen at search time, in res ponse to a specific user request (i.e. request #2: gather all instances of  X  X Country] &lt;&gt; any_action &lt;&gt; [Country] X  ). Unlike keyword search engines, InFact employs a highly expressive query language that combines the power of grammatical roles with the flexibility of Boolean operators, and allows users to search for ac tions, entities, relationships, and events. InFact represents the basic relationship between two entities with an expression of the kind: We can optionally constrain this expression by specifying modifiers or using Boolean logic. The arrows in the query refer to the directionality of the action, which could be either one direction or bi-directional. For example, will retrieve all relationships involving Entity 1 and Entity 2 , regardless of their roles as subject or object of the action. With the InFact query langua ge, we can search for: Note that in InFact we can represent and organize entity types using taxonomy paths, e.g.: The taxonomic paths can encode  X  X  s-a X  relation (as in the above examples), or any other relations defined in a particular ontology (e.g.  X  X art-of X  relation). When querying, we can use a taxonomy path to specify an entity type, e.g. [Location/Country] , [City] , [Location] , etc., and the entity type will automatically include all subpaths in the taxonomic hierarchy. InFact X  X  query syntax supports Boolean operators (i.e. AND, OR, NOT). For example, the query: Clinton NOT Hillary &gt; visit OR travel to &gt; [Location] is likely to retrieve the travels of Bill Clinton , but not Hillary Clinton . We can further constrain actions with modifiers, which can be explicit entities or entity types, e.g. Paris or [location] . For example, the query [Organization/Name] &gt; buy &gt; [Organization/Name]^[money] will only return results where a document mentions a specific monetary amount along with a corporate acquisition. Similarly, in the query Bush &lt;&gt; meet&lt;&gt; Clinton ^[location] will return results restricted to actions that occur in an explicit geographical location. We can also filter search results by specifying document-level constraints, including: InFact can also support synonyms and query expansion via custom ontologies. In this cas e, InFact will automatically recognize the equivalence of entities or actions that belong to the same ontology node. We provide a Java API to e xport events and relationships extracted by the Search and Retrieval module into data mining tools like S-PLUS  X  and I-Miner X . The data frame export facility converts information from free text to data frames and matrices, on which we can perform statistical data analyses. We support two basic data types: The data frame export module is flexible and configurable, and allows any combination of entities, actions, types, and document metadata. It is also interactive, and hyperlinks observations to the original source documents for quick validation. A Data Frame is a data table that, for each observation (rows), stores a list of variables or attr ibutes (columns). In our case, observations are relationship tuples. That is, each observation is an InFact relationship or event, and the variables could be any properties associated with the particular relationship or event, like date. There are two steps in exporting relationship-based data frames: We can add a variable by specifying: We can also select any subset of document metadata tags to export as document attributes. For example, we may search "[Organization/name] &gt; purchase &gt; [Organization/name] ^[Money] OR [Date]" and select the following 5 variables to export for each event InFact finds: Variable V1 Buyer Subject [organization/name] String V2 Target Object [organization/name] String 
V3 Money-
V4 Date Action-V5 Creation-In another example, we may want to find all interactions between Al Qaeda and any particular person: and select variables as listed below: Variable-V1 Person Subject 
V2 Action-V3 Document V4 Doc URL Document A frequency matrix is a two-dimensi onal array of data of the same mode. The simplest example is a document-term matrix, where the rows are documents, the columns are terms, and the cells are frequency counts of document-term pairs. InFact goes far beyond conventional term-document matri ces. For example, a user of InFact can produce a person-action matrix, where the rows are all persons in a corpus that are the subject of an action, the columns are all actions, and the cell values are the frequency counts of a person performing a particular acti on. In other words, we extend the classic term-document inde xing framework of information retrieval to index matrices that have a notion of entities and syntactic roles, such as entity-entity, and action-entity matrices. We generate frequency matrix, where each cell (r, c) contains the Given a frequency matrix, it is straightforward to apply any weighting scheme, such as the st andard tf.idf function that is commonly used in information retr ieval and text categorization. To create a frequency matrix, we: Example 1-Document-Entity Matrix: In a document-entity matrix, the row must be documents (i.e. Document IDs), and the column could be one of the following: To create a document-entity matrix, we: In this mode, a single document becomes effectively a bag of structural relationships or even events that can be modeled and linked across a collection. Example 2 -Entity-Entity Matrix: To create an entity-entity matrix, we: The table below shows a person-action frequency matrix, where each row is a person entity and columns are actions performed by each given person, such as Elements in the resulting pers on-action matrix represent co-occurrences of persons and actions. We describe a few data analysis experiments based on a variety of exported data frame objects. In these experiments, we perform analyses on event patterns extracted from 810,000 news stories in the Reuters Corpus (August 1996-August 1997) [14] In the first experiment, we look for the activity patterns of presidents, ministers and chairmen as a function of day of the week. In a few seconds, InFact returns a 35,557 row travel/non-travel data frame from which S-PLUS X  produces the (normalized) comparative dot chart of Figure 3. Next, we execute the query [organization/Name]&gt;acquire &gt;[organization/Name]^[money] and retrieve a set of relationships involving corporate acquisitions. We produce data frames with the following event variables: In a few seconds, InFact return s a 10,409 action (row)-data frame that we feed to S-PLUS X . In Fi gure 4a, we show time series plots of the number of company acquisitions per month that happened in the US vs. the rest of the world. In Figure 4b, we plot the total monetary amounts involved in the acquisitions as a function of time. Next, (Figure 5) we select the 6 countries that have the largest number of acquisitions and produce Trellis graphs showing the number of acquisitions as a function of time. Trellis Graphics X  are designed to display da ta in a series of panels using a conditioning variable (COUNTRY, in this case). Each panel contains a subset of the original data corresponding to values of the conditioning variable. Relationship searches on large corpora can quickly yield thousands of results, if they are based on sole word co-occurence. It is difficult to display networks of such size and visually detect interesting subnetworks or patte rns in them. However, with InFact, we can filter relationship based on contextual information, like types of entities, types of actions, action directionality, action modifiers, metadata or Boolean c onstraints, etc. Next we apply relational graph methods [21] in which we represent entities as the graph nodes and their relationships as the edges between such nodes. Each node is labeled with the corresponding entity name. Edges are labeled with the pairwi se relationships between entities and the corresponding degrees for these relationships. In this experiment, we visualize actions that imply hostile relationships between countries. Firs t we extract a data frame of relationships from the Reuters Corpus with the query and export data frames with the fo llowing relationship attributes: Figure 6 shows the resulting graph. The vertices (shown in different colors) are grouped into subgraphs of interconnected country nodes. Colors are automa tically assigned on the basis of the strength of semantic relations hips. The edges within clusters are painted in black, and edges outside clusters are painted in gray. The clusters are computed using the JUNG [8] implementation of the Edge-B etweenness clustering algorithm [9]. This method uses properties calculated from the whole graph, which makes it robust against false positives and negatives. In this section we employ the statistical data frame functionality to classify entities according to their action patterns. In this scenario, sets of entities, each re presented by an M-dimensional vector, can be viewed as a matrix. One device that is particularly effective for event clustering and classification is LSR (Latent Semantic Regression), an algorithm that belongs to the class of Latent Semantic Analyses (LSA). Insightful holds three patents on LSR [18], [19], [20]. LSR constitutes an alternative to the classical approach to Latent Se mantic Indexing (LSI) [16], which is based on Singular Value Decomposition (SVD) of a term-document matrix. LSR overcomes the scalability and speed limitations of LSI by casting the measurement of the distance between queries and document cluste rs as an inverse optimization problem [18]. Our proprietary algorithm can establish semantic links and learn patterns and associations from hundreds of thousands of index terms in a fe w seconds [17]. LSR alleviates the variability and reduces noise in term usage, while providing an explicit mechanism to explore latent terms and information. Another interesting capability of LS R is that the nature of the feature matrix is irrelevant, thus allowing handling of more complex linguistic descriptors than just keyword counts or inverse document frequencies. The ability to establish latent semantic relationships at the syntactic or semantic level across hundreds of thousands of documents in a few seconds will enable more robust cross document and event tracking than is currently possible. Table 1 shows how, given a pers on, LSR can find other persons with similar action patterns. In this experiment, we first produce a person-action frequency matrix as described in Section 5. Then, we apply a standard TF.IDF we ighting function to the matrix elements. We show that LSR can cluster together individuals that fit similar action profiles and uncover unexpected patterns of activity. Using any person name as query (left column), we return a ranked list of people that have similar activity pattern in the corpus. For instance, the query  X  X ndre Agassi X  returns a list of tennis players, while the query  X  X teve Young X  returns a list of football quarterbacks. The corpus used for this last experiment was TIPSTER [15]. We have developed a system for fl exible extraction of statistical data frames from large text collec tions. We have demonstrated the feasibility and benefit of this text-to-data framework, by performing a number of statistical analysis and visualization experiments on sample data frames and matrices. Our approach rests on a sophisticated multivariate parameterization of text content, which enables interactive search representation makes use of natura l language tags to (1) achieve a deeper level of knowledge discovery and (2) promote integrated storage and analysis of unstructured and structured sources of information. This work was partially supported by Dr. Joseph Psotka of the US Army Institute under contract No. W74V8H-05-C-0016. We also acknowledge many helpful disc ussions with Carsten Tusk, Navdeep Dhillon, and Matt Brown at Insightful. [1] Kao, A. and Poteet S. Report on KDD Conference 2004 [2] Manning, C.D., and Schutze H. Foundation of Statistical [3] Hearst, M. Untangle Text Data Mining. Proceedings of ACL [4] Hirschman, L., Park, J.C., Tsu jii, J., Wong, L. and Wu, C.H. [5] Cohen, K.B., and Hunter, H. Natural language processing [6] Proceedings of the Seventh Message Understanding [7] NIST. Automatic Content Extraction (ACE) program. [8] JUNG, Java Universal Network/Graph Framework. [9] Girvan M, Newman MEJ. Community Structure in Social [10] Tan, A. H. 1999, Text mining: The state of the art and the [11] Montes-Y-Gomez, M. Gelbukh, A. Lopez-Lopez, A. Baeza-[12] Uramoto, N., Matcuzawa, H ., Nagano, T., Murakami, A. [13] Nasukawa T. and Nagano, T. Text analysis and knowledge [14] Reuters Corpus, Volume 1, E nglish language news stories, [15] Tipster Corpus. Available at LDC: http://www.ldc.upenn.edu [16] Deerwester, S., Dumais, S., Furnas, G.W., Landauer, T.K., [17] Marchisio, G. and Liang, J. Experiments in trilingual cross-[18] Marchisio, G., Inverse infere nce engine for high performance [19] Marchisio, G. Extended f unctionality for an inverse [20] Marchisio, G. Internet navi gation using soft hyperlinks. [21] Messmer, B. T. and Bunke, H. Efficient subgraph Jisheng Liang is a research scientist at Insightful Corporation. His research interests include na tural language processing, text mining, and document analysis. He earned a Ph.D. in 1999 from the Department of Electrical Engineering, University of Washington. Krzysztof Koperski is a research scientist at Insightful Corp. He is doing research on interactive classification models, Bayesian information retrieval, data fusi on, data modeling for very large databases, and query optimization. He received his Ph.D. degree in Computer Science from Simon Fraser University. Thien Nguyen is a senior software developer with 20 years of experience. He has a Master X  X  degree in Software Engineering from Seattle University. Giovanni Marchisio is the Director of the Text Analysis and Search business unit at Insightful Corp. He has 15 years of experience in commercial software development related to search, computational linguistics, image mining, and multimedia information retrieval. He holds a Ph.D. degree in Geophysics and Planetary Physics from University of California, San Diego. Person Name Person names with similar actions Common actions nelson mandela yasser arafat, lech walesa, john paul ii, hussein, andre agassi steffi graf, john mcenroe, monica seles, martina rupert murdoch donald trump, campeau, carl c. icahn, robert clint eastwood tom cruise, oliver stone, arnold schwarzenegger, steve young montana, jim ever ett, jim mcmahon, steve bono, dan rather tom brokaw, peter jennings, bryant gumbel, ted barbara bush dan quayle, nancy reagan, charles, raisa 
