 Most of the machine learning literature on classification is abstracted away from considerations of an underlying communication-theoretic infrastructure, constraints from which may prevent an algorithm from aggregating all rel-evant data at a central site. In many real-life applications, however, resource limitations make it necessary to transmit only partial descriptions of data. Examples include sen-sor networks, in which each sensor operates under power or bandwidth constraints, and human decision-making, in which high-level executive decisions must often be based on lower-level summaries. Assessing losses in classifica-tion accuracy, and developing methods to mitigate their im-pact, is essential if machine learning algorithms are to make inroads in such problem domains.
 There is a significant literature on decentralized decision-making that formally states the problem and characterizes possible solutions (Tsitsiklis, 1993). It is noteworthy, how-ever, that this literature focuses almost entirely on the prob-lem when the relevant probability distributions are known in advance (Blum et al., 1997). Consider, for example, a classification problem (i.e., a binary hypothesis-testing problem), in which each of a set of S sensors observe a single component of a vector X . Assume that these sensors must make a local decision to convert its observation into the corresponding component of a vector Z , and that a final decision regarding the value of a binary variable Y is to be made on the basis of Z . While most of the extant literature assumes the distribution P ( X, Y ) is known, it is clearly of interest to consider decentralized decision-making when only samples from this distribution are available. 1 In this paper, we address this empirically-based de-centralized decision-making problem from the perspec-tive of recent developments in the field of kernel meth-ods (Scholkopf &amp; Smola, 2002). As we will show, kernel methods are particularly natural for solving this problem. In particular, a key component of the methodology that we propose involves the notion of a marginalized kernel , where the marginalization is induced by the transformation from measured values X to local decisions Z .
 The paper is organized as follows. Section 2 provides a for-mal statement of the decentralized decision-making prob-lem. We show how the problem can be cast as a learning problem in Section 3, and in Section 4, we present a kernel-based algorithm for solving the problem. We also present error bounds for our algorithm in Section 4. In Section 5 we present the results of empirical experiments, and in Sec-tion 6 we present our conclusions. The problem of decentralized classification can be suc-cinctly stated as follows. Suppose Y is a discrete-valued random variable, representing a hypothesis about the envi-ronment, and that a set of S sensors collect observations. These signals are represented by a S -dimensional random vector X =( X 1 ,...,X S ) , drawn from the conditional distribution P ( X | Y ) . In the decentralized setting, each sensor t =1 ...,S transmits a message Z t =  X  t ( X t ) to the fusion center, which in turn applies some decision rule  X  to compute Y =  X  ( Z 1 ,...,Z S ) . Suppose that each X t is discrete-valued, taking one of M possible val-ues. The key constraint, giving rise to the decentralized nature of the problem, is that the messages Z t may take on only L possible values where L M . The problem is to find the decision rules  X  1 ,..., X  S for each sensor, and a rule  X  for the fusion center so as to minimize the Bayes risk P ( Y =  X  ( Z )) . The joint distribution P ( X, Y ) is un-known, and we are given n i.i.d. data samples ( x i ,y i ) Although the Bayes-optimal risk can always be achieved by a deterministic decision rule (Tsitsiklis, 1993), considering the larger space of stochastic decision rules confers some important advantages. First, such a space can be compactly represented and parameterized, and prior knowledge can be incorporated. Second, the optimal deterministic rules are often very hard to compute, and a probabilistic rule may provide a reasonable approximation in practice. Accord-ingly, we represent the rule for the sensors t =1 ,...,S by a conditional probability distribution Q ( Z | X ) . The fu-sion center makes its decision by computing a determin-istic function  X  ( z ) of z . The overall decision rule ( Q,  X  ) consists of the individual sensor rules and the fusion center rule.
 The decentralization requirement for our detec-tion/classification system X  X .e., that the decision rule for sensor t must be a function only of the observation x  X  X an be translated into the probabilistic statement that Z ,...,Z S be conditionally independent given X : In fact, this constraint turns out to be advantageous from a computational perspective, as will be clarified in the sequel. We use Q to denote the space of all factorized conditional distributions Q ( Z | X ) , and Q 0 to denote the subset of fac-torized conditional distributions that are also deterministic. Let X denote the signal vector ( X 1 ,...,X S ) , and sup-pose that we have as our training data n pairs ( x i ,y i i =1 ,...,n . Note that x i is an S -dimensional signal vec-tor, x i =( x 1 i ,...,x S i ) . Let P be the unknown underly-ing probability distribution for ( X, Y ) . The probabilistic set-up makes it simple to estimate the optimal Bayes risk, which is to be minimized. Although our framework can be applied to general multi-class classification and regression problems, in this paper we focus on binary classification, that is, Y =  X  1 .
 For each collection of decision rules made at the sensors and represented by Q ( Z | X ) , the optimal Bayes risk is de-fined by: Here the expectation is with respect to the probability distribution P ( X, Y, Z ):= P ( X, Y ) Q ( Z | X ) . It is well known that no decision function made at the fusion cen-ter (which is a function of z ) has Bayes risk smaller than R opt . In addition, the Bayes risk R opt can be achieved by using the decision function Of course, this decision rule cannot be computed, because P ( X, Y ) is not known, and Q ( Z | X ) is to be determined. Thus, our goal is to determine the rule Q ( Z | X ) that mini-mizes an empirical estimate of the Bayes risk based on the training data ( x i ,y i ) n i =1 . In Lemma 1, we show that the following is one such unbiased estimate of the Bayes risk: In addition,  X  opt ( z ) can be estimated by the decision func-tion  X  emp ( z ) = sign n i =1 Q ( z | x i ) y i . Since Z is a dis-crete random vector, the optimal Bayes risk can be esti-mated easily, regardless of whether the input signal X is discrete or continuous.
 Lemma 1. (a) Assume that P ( z ) &gt; 0 for all z . Define Then lim n  X  X  X   X  ( z )= P ( Y =1 | z ) . (b) As n  X  X  X  , R emp and  X  emp ( z ) tend to R opt and  X  opt ( z ) , respectively.
 This lemma 2 motivates the goal of finding a rule Q ( Z | that minimizes R emp . It is equivalent, using eqn. (2), to maximize subject to the natural constraints on a probability distribu-tion (i.e., Q ( z | x )= S t =1 Q t ( z t | x t ) ; z t Q and Q t ( z t | x t )  X  [0 , 1] ). The major computational diffi-culty in this optimization problem lies in the summation over all L S possible values of z . One way to avoid this obstacle is by maximizing instead the following function: where the final line follows after expanding the square and summing. Note that the constraints (1) on Q allow us to compute C 2 ( Q ) in O ( SL ) time, as opposed to O ( L S While this simple strategy is based directly on the empiri-cal risk, it does not exploit any prior knowledge about the class of discriminant functions for  X  ( z ) . As we discuss in the following section, such knowledge can be incorpo-rated into the classifier using kernel methods. Moreover, the kernel-based decentralized detection algorithm that we develop turns out to have an interesting connection to the simple approach based on C 2 ( Q ) . In this section, we shall apply Mercer kernels (Scholkopf &amp; Smola, 2002) to our decentralized classification problem, focusing on the case of binary labels Y =  X  1 . Kernel-based methods for discrimination entail choosing a dis-criminant function f from within a function class F de-fined by a feature space {  X ( x ) } . This space is equipped with an inner product K ( x, x )=  X ( x ) ,  X ( x ) , which defines the kernel function K . As a reproducing kernel Hilbert space, any function f  X  X  expressed as an in-ner product f ( x )= w,  X ( x ) , where w has the form w = n i =1  X  i  X ( x i ) . Equivalently, we can write f as a lin-ear combination of kernel functions as follows: In the framework of empirical risk minimization, the pa-rameters  X  i are chosen so as to minimize a cost func-tion given by the sum of the empirical  X  -risk  X  E  X  ( Yf ( X )) with a suitable regularization term (e.g., 2 -regularization), where  X  denotes an appropriate loss function. The function  X  is typically a convex surrogate for the 0-1 loss. The final decision rule is then given by y := sign( f ( x )) . It has been shown (Zhang, 2004; Bartlett et al., 2003) that a function f with small  X  -risk E  X  ( Yf ( X )) also has small Bayes risk P ( Y = sign( f ( X ))) . 4.1. Fusion center and marginalized kernels With this background, we first consider how to design the decision rule  X  at the fusion center for a fixed setting Q ( Z | X ) of the sensor decision rules. Since the fusion cen-ter rule can only depend on z =( z 1 ,...,z S ) , our starting point is a feature space {  X  ( z ) } with associated kernel K We consider fusion center rules defined by taking the sign of linear discriminants  X  ( z ):= w,  X  ( z ) . We then link the performance of  X  to another kernel-based discriminant function f that acts directly on x =( x 1 ,...,x S ) , where the associated kernel K Q is defined as a marginalized ker-nel in terms of Q ( Z | X ) and K z .
 The relevant optimization problem is to minimize (as a function of w ) the following regularized form of the em-pirical  X  -risk associated with the discriminant  X  where  X &gt; 0 is a regularization parameter. In its current form, the objective function (5) is intractable to compute (because it involves summing over all L S possible values of z of a loss function that is generally non-decomposable). However, exploiting the convexity of  X  allows us to com-pute it exactly for deterministic rules in Q 0 , and also leads to a natural relaxation for an arbitrary decision rule Q  X  X  as formalized in the following: Proposition 2. Define the quantities
 X  Q ( x )= For any convex  X  , the optimal value of the following opti-mization problem is a lower bound on the optimal value in problem (5) : Moreover, the relaxation is tight for any deterministic rule Q ( Z | X ) .
 Proof. Applying Jensen X  X  inequality to the function  X  yields  X  ( y i f ( x i ; Q ))  X  z  X  ( y i  X  ( z )) Q ( z | i =1 ,...n , from which the lower bound follows. Equality for deterministic Q  X  X  0 is immediate.
 A key point is that the modified optimization problem (7) involves an ordinary regularized empirical  X  -loss, but in terms of a linear discriminant function f ( x ; Q )= w,  X  Q ( x ) in the transformed feature space {  X  Q ( x ) fined in eqn. (6). Moreover, the corresponding marginal-ized kernel function takes the form: where K z ( z, z ):=  X  ( z ) ,  X  ( z ) is the kernel in {
 X  ( z ) } -space. From a computational point of view, we have converted the marginalization over loss function val-ues to a marginalization over kernel functions. While the former is intractable, the latter marginalization can be car-ried out in many cases (see Section 4.2) by exploiting the structure of the conditional distributions Q ( Z | X ) . From the modeling perspective, it is interesting to note that the class of marginalized kernels, exemplified by eqn. (8), un-derlie much recent work that aims to combine the advan-tages of graphical models and kernel methods (Jaakkola &amp; Haussler, 1999; Tsuda et al., 2002).
 As a standard kernel-based formulation, the optimization problem (7) can be solved by the usual Lagrangian dual for-mulation (Scholkopf &amp; Smola, 2002), thereby yielding an optimal weight vector w . This weight vector defines the de-cision rule for the fusion center by  X  ( z ):= w,  X  ( z ) .By the Representer Theorem, the optimal solution w to prob-lem (7) has an expansion of the form w = where  X  is an optimal dual solution, and the second equal-ity follows from the definition of  X  Q ( x ) given in eqn. (6). Substituting this decomposition of w into the definition of  X  yields Note that there is an intuitive connection between the dis-criminant functions f and  X  . In particular, using the definitions of f and K Q , it can be seen that f ( x )= E [  X  ( Z ) | x ] , where the expectation is taken with respect to Q ( Z | X = x ) . The interpretation is quite natural: when conditioned on some x , the average behavior of the dis-criminant function  X  ( Z ) , which does not observe x ,is equivalent to the optimal discriminant f ( x ) , which does have access to x . 4.2. Computation of marginalized kernels When Q ( Z | X ) is not deterministic, the computation of K
Q ( x, x ) entails marginalizing over Z , resulting gener-ally in O ( L S ) computational cost. In such a case, we have to resort to an approximation of K . However, when the ker-nel function K z ( z, z ) is decomposed into local functions, the computation becomes feasible. Here we provide a few examples of computationally tractable kernels.
 Perhaps the simplest example is the linear kernel K z ( z, z )= to derive K Q ( x, x )= S t = l E [ z t | x t ] E [ z t | example, natural for applications in which X t and Z t are multinomial, is the count kernel . Each multinomial value u is represented as a vector (0 ,..., 1 ,..., 0) , whose u -th coordinate takes value 1. If we define the first-order count kernel K z ( z, z ):= S t =1 I [ z t = z t ] , then the resulting marginalized kernel takes the form A natural generalization is the second-order count kernel K z ( z, z )= for the pairwise interaction between coordinates z t z . For this example, the associated marginalized kernel K
Q ( x, x ) takes the form: 2 Remarks: First, note that even for a linear base kernel K z , the kernel function K Q inherits additional (non-linear) structure from the marginalization over Q ( Z | X ) . As a con-sequence, the associated discriminant functions (i.e.,  X  and f ) are certainly not linear. Second, our formulation allows any available prior knowledge to be incorporated into K Q in at least two possible ways: (i) The base kernel repre-senting a similarity measure in the quantized space of z can reflect the structure of the sensor network, or (ii) More structured decision rules Q ( Z | X ) can be considered, such as chain or tree-structured decision rules. 4.3. Joint optimization Our next task is to perform joint optimization of both the fusion center rule, defined by w or equivalently  X  (as in eqn. (9)), and the sensor rules Q . Observe that the cost function (7) can be re-expressed as a function of both w and Q as follows: G ( w ; Q ):= Of interest is the joint minimization of the function G in both w and Q . It can be seen easily that (a) G is convex in w with Q fixed; and (b) moreover, G is convex in Q t , when both w and all other { Q r ,r = t } are fixed. These observa-tions motivate the use of blockwise coordinate descent to perform the joint minimization.
 Optimization of w : As described in Section 4.1, when Q is fixed, then min w G ( w ; Q ) can be computed efficiently by a standard dual reformulation. Specifically, using stan-dard results from convex duality (Rockafellar, 1970), we can show that a dual reformulation of min w G ( w ; Q ) is given by max where  X   X  ( u ):=sup v  X  R u  X  v  X   X  ( v ) } is the conjugate dual of  X  ; [ K Q ] ij := K Q ( x i ,x j ) is the empirical kernel matrix; and  X  denotes Hadamard product (Nguyen et al., 2004). Any optimal solution  X  to problem (12) defines the optimal primal solution w ( Q ) to min w G ( w ; Q ) via As a particular example, consider the case of hinge loss function  X  ( u ):=(1  X  u ) + , as used in the SVM algo-rithm (Scholkopf &amp; Smola, 2002). A straightforward cal-culation yields Substituting this formula into (12) and yields the familiar dual formulation for the SVM: Optimization of Q : The second step is to minimize G over Q t , with w and all other { Q r ,r = t } held fixed. Our approach is to compute the derivative (or more generally, the subdifferential) with respect to Q t , and then apply a gradient-based method. A challenge to be confronted is that G is defined in terms of feature vectors  X  ( z ) , which are typically high-dimensional quantities. Indeed, although it is intractable to evaluate the gradient at an arbitrary w , the following result establishes that it can always be evaluated at the point ( w ( Q ) ,Q ) for any Q  X  X  .
 Lemma 3. Let w ( Q ) be the optimizing argument of min w G ( w ; Q ) , and let  X  be an optimal solution to the dual problem (12) . Then the following element at ( w ( Q ) ,Q ) .
 Observe that this representation of the (sub)gradient in-volves marginalization over Q of the kernel function K z , and therefore can be computed efficiently in many cases, as described in Section 4.2.
 Overall, the blockwise coordinate descent algorithm takes the following form: (a) With Q fixed, compute the optimizing w ( Q ) by solv-(b) For some index t ,fix w ( Q ) and { Q r ,r = t } and take Remarks: It is interesting to note that if we fix w such that all  X  i are equal to 1, and the base kernel K constant X  X nd thus uninformative X  X ernel, then the opti-mization of G with respect to Q reduces to the optimization problem underlying the simple algorithm in Section 3. 4.4. Estimation error bounds We now turn to the analysis of the statistical properties of our algorithm. In particular, we relate bounds on the  X  -risk E  X  ( Y X  ( Z )) to the  X  -risk E  X  ( Yf ( X ) for functions f (and f  X  X  0 ) that are computed by our algorithm. The lat-ter quantities are well-studied objects in statistical learning theory. In general, the  X  -risk for a function f in some class F is bounded by the empirical  X  -risk plus a complexity term that captures the richness of F .
 We first need to isolate the class of functions over which we optimize. Define, for a fixed Q  X  X  , the function space F x  X  w,  X  Q ( x ) = Note that F Q is simply the class of functions associ-ated with the marginalized kernel K Q . We then define F =  X  Q  X  X  F Q , which corresponds to the function class over which our algorithm optimizes. Finally, we let F 0 de-note  X  Q  X  X  0 F Q , corresponding to the union of the function spaces defined by marginalized kernels with deterministic Q . Of particular interest in the current context is the growth in the complexity of F and F 0 with respect to the number of training samples n , as well as the number of quantization levels L and M .
 Any discriminant function f , defined by a vector  X  , induces an associated discriminant function  X  f via eqn. (9). Rele-vant to the performance of the classifier  X  f is the expected  X  -loss E  X  ( Y X  f ( Z )) (or its empirical version), whereas the algorithm actually minimizes (the empirical version of) E  X  ( Yf ( X )) . The relationship between these two quan-tities is expressed in the following proposition.
 Proposition 4. (a) We have E  X  ( Y X  f ( Z ))  X  E  X  ( Yf ( X )) , with equality when Q ( Z | X ) is deterministic. (b) Moreover, there holds The same statement also holds for empirical expectations. Proof. Applying Jensen X  X  inequality to the convex function  X  yields E  X  ( Y X  f ( Z )) = E XY E [  X  ( Y X  f ( Z )) | XY ] where we have used the conditional independence of Z and Y given X . This establishes part (a), and the lower bound (13b) follows directly. Moreover, part (a) also im-plies that inf f  X  X  0 E  X  ( Y X  f ( Z )) = inf f  X  X  0 E  X  ( Yf ( X )) , and the upper bound (13a) follows since F 0  X  X  .
 Our next step is to relate the empirical  X  -risk for f (i.e., E ( Yf ( X )) ) to the true  X  -risk (i.e., E ( Yf ( X )) ). Recall that the Rademacher complexity of the function class F is defined (van der Vaart &amp; Wellner, 1996) as where  X  1 ,..., X  n are independent and uniform on { X  1 , +1 } , and X 1 ,...,X n are i.i.d. samples selected ac-cording to distribution P . In the case that  X  is Lipschitz with constant , the empirical and true risk can be re-lated via the Rademacher complexity (Koltchinskii &amp; Panchenko, 2002) as follows. With probability at least 1  X  with respect to training samples ( X i ,Y i ) n i =1 , drawn accord-ing to the empirical distribution P n , there holds sup . Moreover, the same bound applies to F 0 .
 Combining the bound (14) with Proposition 4 leads to the following theorem, which provides generalization er-ror bounds for the optimal  X  -risk of the decision function learned by our algorithm in terms of the Rademacher com-plexities R n ( F 0 ) and R n ( F ) : Theorem 5. Given n i.i.d. labeled data samples ( x i ,y i ) n i =1 , with probability at least 1  X  2  X  , inf To make use of this result, we need to derive upper bounds on the Rademacher complexity of the function classes F and F 0 . The following proposition derives such bounds for F 0 , exploiting the fact that the number of 0-1 condi-tional probability distributions Q ( Z | X ) is a finite number ( L
MS ) . While this rate is not tight in terms of the number of data samples n , the bound is nontrivial and is relatively simple (depending directly on the kernel function K and n, L, S , and M ).
 Proposition 6.
 We can also provide a more general and possibly tighter up-per bound on the Rademacher complexity based on entropy numbers. In general, define the covering number N ( , S,  X  ) for a set S to be the minimum number of balls of diame-ter that completely cover S according to a metric  X  . The -entropy number of S is then log N ( , S,  X  ) . It is well known (van der Vaart &amp; Wellner, 1996) that for some ab-solute constant C , there holds: Of particular interest is the increase of the entropy num-ber for F over the supremum of the entropy number for a restricted function class F Q .
 Proposition 7. log N ( , F ,L 2 ( P n ))  X  sup +( L  X  1) MS log Moreover, the same bound holds for F 0 .
 This proposition guarantees that the increase in the entropy number is only O (( L  X  1) MS log( L S / )) , which results in only an O ([ MS 2 ( L  X  1) log L/n ] 1 2 ) increase in the up-per bound (15) for R n ( F ) (respectively R n ( F 0 ) ). The Rademacher complexity increases with the square root of L log L of the number L of quantization levels. We evaluated our algorithm by testing with both simulated sensor networks and real-world data sets. We consider three types of sensor network configurations: Naive Bayes networks: In this example, the observations X 1 ,...,X S are independent conditional on Y , as illus-trated in Figure 1. We consider networks with 10 sen-sors ( S =10 ), each of which receive signals with 8 levels ( M =8 ). We applied the algorithm to compute decision rules for L =2 . In all cases, we generate n = 200 training samples, and the same number for testing. We performed 20 trials on 20 randomly generated models P ( X, Y ) . Chain-structured dependency: While widely used, the conditional independence assumption underlying the naive Bayes set-up is often unrealistic. For instance, consider the problem of detecting a random signal in noise (van Trees, 1990), in which Y =1 represents the hypothesis that a cer-tain random signal is present in the environment, whereas Y =  X  1 represents the hypothesis that only i.i.d. noise is present. Under these assumptions X 1 ,...,X s will be conditionally independent given Y =  X  1 , since all sensors receive i.i.d. noise. However, conditioned on Y =+1 (i.e., in the presence of the random signal), the observations at spatially adjacent sensors will be dependent, with the de-pendence decaying with distance. In a 1-D setting, this set-up can be modeled with a chain-structured dependency, and the use of a count kernel to account for the interaction among sensors. More precisely, we consider a set-up in which five sensors are located in a line such that only adja-cent sensors interact with each other, i.e., X t  X  1 and X are independent given X t and Y (see Figure 2). We imple-mented KQ with both first-and second-order count kernels. The loss function used is the hinge loss as in the SVM al-gorithm. The second-order kernel is specified in eqn. (10) but with the sum taken over only t, r such that | t  X  r | Spatially-dependent sensors: As a third example, we consider a 2-D layout in which, conditional on the random target being present ( Y =+1 ), all sensors interact but with the strength of interaction decaying with distance. Thus P ( X | Y =1) is of the form: Here the parameter h represents observations at individual sensors, whereas  X  controls the dependence among sen-sors. The distribution P ( X | Y =  X  1) can be modeled in the same way with observations h , and setting  X  =0 so that the sensors are conditionally independent. In simula-tions, we generated  X  tr ; uv  X  N (1 /d tr , 0 . 1) , where d the distance between sensor t and r , and the observations h and h are randomly chosen in [0 , 1] S . We consider a sensor network with 9 nodes (i.e., S =9 ), arrayed in the 3  X  3 lattice illustrated in Figure 2(b). Since computation of this density is intractable for moderate-sized networks, we generated an empirical data set ( x i ,y i ) by Gibbs sampling. We compare the results of our algorithm to an alternative decentralized classifier based on performing likelihood-ratio (LR) test at each sensor. Specifically, for each sensor likelihood-ratio are sorted and grouped evenly into L bins. Given the quantized input signal and label Y , we then con-struct a naive Bayes classifier at the fusion center. This choice of decision rule provides a reasonable comparison, since thresholded likelihood ratio tests are optimal in many cases (Tsitsiklis, 1993).
 As we show in Figure 3, the kernel-based quantization (KQ) algorithm developed in Section 4 generally yields better classification results than the likelihood-ratio based algorithm. The figure provides scatter plots of LR versus KQ test error for four different set-ups, using L =2 lev-els of quantization. Panel (a) shows the naive Bayes set-ting and the KQ method with first-order count kernel. Note that the KQ error is below the LR error for the large ma-jority of examples. Panels (b) and (c) show the case of chain-structured dependency, as illustrated in Figure 2(a), using a first-and second-order count kernel respectively. Again, the KQ error improves significantly on the LR error. Finally, panel (d) shows the fully-connected case of Fig-ure 2(b) with a first-order kernel. The performance of KQ is somewhat better than LR, although by a smaller amount than the other cases.
 UCI repository data sets: We also applied our algorithm to several data sets from the UCI repository. In contrast to the sensor network setting, in which communication con-straints must be respected, the problem here can be viewed as that of finding a good quantization scheme that retains information about the class label. Thus, the problem is sim-ilar in spirit to work on discretization schemes for classifi-cation (Dougherty et al., 1995). However, in our case, we assume that the data have already been crudely quantized (to M =8 levels) and we retain no information on the rel-ative magnitudes of the levels, thus rendering classical dis-cretization algorithms inapplicable. The problem is one of hierarchical decision-making, in which a second-level de-cision follows a first-level set of decisions concerning the features.
 We used 75% of the data set for training and the remain-der for testing. The results for L =2 , 4 , 6 quantization levels are shown in Table 1. Note that in several cases the quantized algorithm actually outperforms a naive Bayes al-gorithm (NB) with access to the real-valued features. This result may be due in part to the fact that our quantizer is based on a discriminative classifier, but it is worth noting that similar improvements over naive Bayes have been re-ported in earlier empirical work using classical discretiza-tion algorithms (Dougherty et al., 1995). We have presented a new approach to the problem of de-centralized decision-making under constraints on the num-ber of bits that can be transmitted by each of a distributed set of sensors. In contrast to most previous work in an ex-tensive line of research on this problem, we assume that the joint distribution of sensor observations is unknown, and that only a set of data samples is available. We have proposed a novel algorithm based on kernel methods, and shown that it is quite effective on both simulated and real-world data sets.
 This line of work can be extended in a number of directions. First, although we have focused on discrete observations X , it is natural to consider continuous signal observations. Doing so would require considering parameterized distri-butions Q ( Z | X ) . Second, our kernel design so far makes use of only rudimentary information from the sensor ob-servation model, and could be improved by exploiting such knowledge more thoroughly.

