  X  Subgraph search is very useful in many real-world applica-tions. However, users may be overwhelmed by the masses of matches. In this paper, we propose subgraph skyline search problem, denoted as S 3 , to support more complicated anal-ysis over graph data. Specifically, given a large graph G and a query graph q , we want to find all the subgraphs g in G , such that g is graph isomorphic to q and not dominated by any other subgraphs. In order to improve the efficiency, we devise a hybrid feature encoding incorporating both struc-tural and numeric features. Moreover, we present some op-timizations based on partitioning strategy. We also propose a skylayer index to facilitate the dynamic subgraph skyline computation. Extensive experiments over real dataset con-firm the effectiveness and efficiency of our algorithm. H.2.8 [ Information Systems ]: Database Applications Subgraph Skyline; Feature Encoding; Skylayer
Due to the schema-relaxable nature [12], graph has at-tracted increasing attention these years. A lot of real-world data (e.g., social network [17], knowledge graph [5], het-erogenous information network [22], and semantic web [26]) can be represented by graph model. As we know, various types of researches over graphs have been investigated, such as shortest path query [2], subgraph search [24], and reach-ability query [6]. However, effectively and efficiently con-ducting advanced analysis on graphs, particularly subgraph  X  corresponding author: Lei Zou, zoulei@pku.edu.cn skyline analysis as will be addressed in this paper, remains an open problem.

As a well-known research problem, subgraph search is meaningful and useful in many applications. For example, answering SPARQL queries in Semantic Web is actually e-quivalent to conducting subgraph isomorphism match over graphs [26]. However, users may be overwhelmed by the enormous matching results of some queries. Owing to the different requirements in varieties of applications, it is non-trivial to design a generic function to measure the X  X oodness X  of these matches. In this paper, we propose subgraph sky-line (Def. 5) on large graphs. To the best of our knowledge, there is no existing study to address this problem.
A knowledge graph is a heterogeneous open-domain re-source that integrates lots of information in various fields, such as person, sport, movie, music and so on. Fig. 1 shows a small fraction of a knowledge graph, where the hollow ver-tices and their adjacent attributes are numeric vertices and numeric attributes, respectively. Using a knowledge graph, we can conduct many interesting subgraph skyline analyses as follows.

Motivating Example 1. For example, we may find excellent NBA player partners over the knowledge graph. Specifically, one player is a X  X uard X  X ith excellent techniques in  X  X ssists X  and  X  X teals X . The other one is a  X  X orward X  with excellent techniques in  X  X ebounds X  and  X  X locks X . What is more, these two players are expected to serve in the same team. This query can be represented by the graph in Fig. 2, vertices labeled with  X  *  X  are their respective technical s-tatistics, i.e., the numeric attributes. That is, we want to find all the partners who are no worse than other partners in terms of these attributes. Answering this query over the knowledge graph can find meaningful results. More analyses using real NBA game records will be reported in Section 6.
Motivating Example 2. As another example, with the knowledge graph we can also explore the American excel-lent actors/actresses who are singers as well. Specifically, the gross of the film that the actor/actress starred in and the copies of his/her album are expected to be large. Fig. 3 illustrates this query graph. In general, subgraph search may return lots of matches without considering the numer-ic values. Hence, subgraph skyline analysis is useful and interesting over knowledge graph. *
Motivated by the examples above, we propose the problem of S ubgraph S kyline S earch over large graphs (denoted as S ). Specifically, given a large graph G and a user specified query graph q which has several numeric attributes, an S 3 query returns all the subgraphs in G that are isomorphic to q and not dominated by any other isomorphic subgraphs in terms of numeric attributes in q (formally defined in Def. 5). There are two possible methods to solve the S 3 problem. The first method is to utilize the traditional skyline tech-niques designed for relational data. However, the input of these techniques are relational tables, which are non-trivial to update, i.e., data addition, deletion, and refreshing. In comparison, the numeric attributes of S 3 skyline are online extracted from subgraphs. More importantly, due to sub-graph isomorphism constraint of S 3 problem, the existing pruning techniques for traditional skyline may not be em-over the numeric attributes specified in the query q . But no subgraph containing v 1 is isomorphic to q .Whereas,entity a subgraph g containing v 2 is isomorphic to q .Thus,the subgraph g should be an answer. Furthermore, the previous methods for skyline join do not consider any structure con-straint or the corresponding structural optimization. Hence, these techniques dedicated to the relational skyline compu-tation are oblivious to support S 3 queries.
 The other method resorts to the graph-based strategy. Although there have been many studies on subgraph queries [20, 4, 12, 24, 26], none of these works considers the skyline constraint. A naive idea is to enumerate all subgraphs in G that are isomorphic to the query graph q , i.e., obtaining all the candidate subgraphs with the existing techniques. Then, we can check the dominating relationship and return true answers. Obviously, this method is inefficient in terms of response time, because it may generate a large number of intermediate results, that is, many redundant isomorphic subgraphs not belonging to the skyline will be exhausted at the cost of expensive subgraph isomorphism checking.
Considering the observations above, we address three chal-lenges to answer S 3 queries efficiently, and carefully design the corresponding solutions.

Challenge 1: Dynamic skyline computation. To answer S 3 queries, a crucial task is to compute skyline ac-cording to the numeric attributes specified in query graphs. In the worst case, we need to exhaust all the numeric entities to find the skyline if there is no any optimization measures. More importantly, when we cannot find any answer with the current skyline entity v (i.e., v does not satisfy the structural constraint), we need to dynamically compute skyline enti-ties, which is computationally expensive.

Challenge 2: Efficient querying on graphs. As dis-cussed above, we need to check the structural constraint before reporting the true answers. In order to improve the time efficiency, we should reduce the search space and avoid the costly subgraph isomorphism checking as much as pos-sible. Thus, it is better to consider the structural feature as well as the numeric feature.

Challenge 3: Reducing expensive storage cost. S-ince there may be a mass of numeric features (e.g., the nu-meric attributes) and structural features (e.g., path, tree, and subgraph) especially when the knowledge graph G is very large, we should carefully select these features to en-hance the pruning power and organize them in an efficient way so as to reduce the overall storage cost.

In order to tackle these challenges, we propose to partition the data space into grids so that we can compute skyline grid by grid instead of entity by entity. We also carefully devise a hybrid encoding incorporating both structural and numeric features at low storage cost. To achieve better pruning ef-fectiveness, we discuss optimizations on how to adaptively find a good partitioning strategy. Furthermore, we maintain the grids using skylayer that facilitates the dynamic compu-tation of skyline entities. More importantly, exploiting the encoding and partitioning strategies we prune the unpromis-ing grids that cannot generate the true results. Beyond that, we also utilize skylayer index to guide the S 3 query process-ing. Thus, to a large extent the search space is reduced.
In summary, we make the following contributions.
There are two related researches to be reviewed, i.e., sky-line computation and subgraph search.

Skyline Computation. Most existing skyline literature focus on multi-dimensional relational data. Their inputs are relational tables. BNL [1] is the first proposed to compute the skyline. Instead of going over the entire dataset, Bitmap [16] represents a data point p using an m -bit vector, and compute the skyline points progressively. In order to answer subspace skyline queries, SUBSKY [18] converts each multi-dimensional point to 1D values, and index these converted values by a single B-tree. Jin et al. [8] group pairs that share the same subspaces into maximal space index. In practice, this method still suffers from expensive storage cost.
To compute the join-based skyline efficiently, several tech-niques have been proposed [7, 21, 11]. Jin et al. [7] inte-grate state-of-the-art join methods, such as sort-merge join and nested loop join, with single-relation skyline algorith-m. SFSJ (sort-first-skyline-join) [21] computes the skylines by accessing only a subset of the input tuples. Instead of performing tuple-to-tuple dominance checks, S 2 J (skyline-sensitive join) [11] employs a layer/region pruning strategy. There are some other works aiming to compute the join-based skyline, such as FlexPref [10], SKIN [13], and Prefjoin [9].

Notice that an important pruning principle of the exist-ing algorithms is: tuples that do not belong to group sky-lines [21] cannot contribute to the join skyline. However, the group skyline is very hard to compute in the graph s-cenario. Furthermore, not being devised for S 3 problem, they do not consider any structural feature to facilitate the query process. In contrast, we integrate numeric pruning with structural pruning based on the grid-based partition of data space.

Subgraph Search. Subgraph search problem has been extensively studied in the past decades [20, 4]. Ullmann [20] and VF2 [4] are the two early efforts to verify the sub-graph isomorphism between two graphs. In order to improve the efficiency in subgraph search, most of the proposed al-gorithms follow filtering-and-verification framework. In the filtering phase, some structural features, including frequent paths [19], trees [23], and subgraphs [3], are chosen as basic index units. Also, some non-feature-based methods are pro-posed, such as GCodeing [25] and SPath [24]. Most of them employ the neighborhood structures of vertices. Based on the indexes, we can first prune some data graphs that are impossible to be results. Then, we verify each candidate da-ta graph by employing the subgraph isomorphism algorithm, such as Ulluman [20], VF2 [4], and QuickSI [14].
In this section, we first formally define the subgraph sky-line, and then give a naive method to solve S 3 problem.
S 3 runs queries over knowledge data graphs, which is for-mally defined as follows.

Definition 1. ( Knowledge Graph ). A knowledge graph is defined as G =( V, E, L ), where each vertex v  X  V rep-resents an entity or a numeric value, each e =( v i ,v j ) represents a directed edge from vertex v i to vertex v j ,and L ( v )(resp. L ( e )) is the label of vertex v (resp. edge e ).
Fig. 1 shows an example of knowledge graph. Note that, if entity v has some numeric attributes, v is called numeric entity .Let v.d denote the value on numeric attribute d for entity v .

Definition 2. ( Graph Isomorphism ). Given two sub-graphs g 1 and g 2 in graph G , g 1 is graph isomorphic to g 2 iff there exists a bijective function f ( . ) such that (1) for each vertex v  X  g 1 (excluding the numeric values), f ( v )  X  L ( v )= L ( f ( v )); (2) for each e =( v i ,v j )  X  g 1 ,wehave f ( e )=( f ( v i ) ,f ( v j ))  X  g 2 ,and L ( e )= L ( f ( e )).
Definition 3. ( Dominant/Equivalent Entity ). Giv-en two numeric entities v 1 and v 2 in a knowledge graph G and their numeric attribute set D , v 1 dominates v 2 , denoted entity v 1 dominates or is equivalent to entity v 2 . Definition 4. ( Subgraph Dominating Relationship ). Given two subgraphs g 1 and g 2 in G , g 1 dominates g 2 if where f ( . ) is the mapping function defined in Def. 2.
Definition 5. ( Subgraph Skyline ). A subgraph g  X  G is in the subgraph skyline, if g is graph isomorphic to the query graph q and not dominated by any other subgraphs g  X  G , on those specified numeric attributes in q . S ubgraph S kyline S earch Problem (denoted as S 3 ). Given a large graph G and a query graph q containing nu-meric attributes, the S 3 problem is to compute the subgraph skyline on G .

In real applications, the query graphs are given by users, and the numeric attributes can be specified according to the ad-hoc requirements.
Before giving the naive method, we briefly review the bitmap [16] method. Its main idea is representing an object o using m -bit vector. Then we can progressively determine whether o is in the skyline by performing bitwise operations over the corresponding bitmaps.

High-level idea: In the offline phase, we store all the bitmaps of numeric entities. In the online phase, we first compute the candidates for the numeric entities in q ,and then find skyline entities from these numeric entities. Final-ly, we verify the structure constraint to obtain S 3 answers employing bitmaps.

Obviously, this naive method is inefficient, since there is no any guidance to find the skyline vertex. Furthermore, its storage cost is O ( n 2  X | D | ), where n and | D | are the num-ber of numeric entities and numeric attributes, respectively. Hence, we propose an efficient method exploiting hybrid fea-ture encoding in the following section.
The rationale of partitioning the data space (i.e., the space consisting of numeric entities) is that: if we can compute the skyline entities grid by grid instead of exhausting them one by one, the time efficiency will improve a lot. Moreover, we can only maintain the numeric encoding of grids rather than all numeric entities, which reduces the storage cost considerably. Thus, we propose to partition the data space into grids (Def. 6) in this paper.

Definition 6. (Grid). Given a data space D consisting of the numeric entities, grids are obtained by partitioning each dimension d i  X  D using hyperplanes.

After partitioning the data space into grids, each grid can be represented by its minimal corner (given in Def. 7).
Definition 7. ( Minimal Corner ). Given a grid B in the multi-dimensional data space D = { d 1 ,...,d | D | } minimal corner is the point whose value on each dimension  X  D is the minimum.
Example 1. As shown in Fig. 4, the 2-dimensional space is partitioned into 12 grids. Each grid can be represented by its minimal corner (i.e., the bottom left point of the grid). For instance, the grid B 2 consisting of entities v 3 , v and v 6 can be represented by point c 2 .

Utilizing the minimal corners, we can compute the sky-line entities grid by grid instead of point by point. Before presenting the technical details, we introduce the definition of  X  X trict dominance X  relationship.

Definition 8. ( Strict Dominance ). Given two corners c 1 and c 2 and a specified numeric attribute set D ,wesay
The strict dominance imposes more stringent restrictions upon two objects. Clearly, if c 1 &lt;c 2 , it holds that c 1 Moreover, we can derive the following properties.

Lemma 1. Given a grid B and its minimal corner c ,it holds that c dominates each numeric entity v  X  B .
Proof. It is straightforward according to the definition of minimal corner (Def. 7).

Lemma 2. Given two minimal corners, c 1 of grid B 1 and c 2 of grid B 2 ,if c 1 &lt;c 2 , then all the entities in B dominate the minimal corner c 2 .

Proof. This lemma can be proved by using the contra-contradicts with the prescriptive regular partition (i.e., par-tition each dimension respectively).

With the two lemmas above, we can obtain a useful the-orem, which is the critical principle of pruning.

Theorem 1. Given two minimal corners, c 1 of grid B 1 and c 2 of grid B 2 ,if c 1 &lt;c 2 , then all the entities in the grid
Proof. Assume v 1 and v 2 are two entities in grids B 1 and B 2 , respectively. According to Lemmas 1 and 2, we
It is obvious that given the number of grids, there are many different partitions which may result in different ef-fects. We will discuss optimizations on how to adaptively find a good partitioning strategy later in Section 4.3.
Based on the space partition, we present the hybrid fea-ture encoding which consists of structural features (Section 4.2.1) and numeric features (Section 4.2.2).
Structural encoding for entities. Provided that the entities in q and G are encoded in the same method, we can check the match according to their encodings.
 Local Structural Encoding. Since bit operation (e.g., AND, OR, and NOT) is easy and time efficient, we hash the local structure of an entity v to a bitstring, denoted by lbStr ( v ), which is similar to but different from the previous work [26]. The differences are listed as follows.
Definition 9. (Connecting Edge). Given a vertex v 1 and its two neighbor vertices v 2 and v 3 ,theedge e =( v 2 ,v 3 ) between v 2 and v 3 is v 1  X  X  connecting edge.

The bitstring of v  X  X  local structure lbStr ( v ) has two parts: notes the 1-hop path labels ( v  X  X  adjacent edge label combin-ing the corresponding neighbor vertex label), and the second part lbStr ( v ) .c denotes the connecting edge labels.
Bitstring Generation. Given a neighbor vertex v of v and the corresponding edge e between v and v , we combine e.Label and v .Label together to get the label ( p.Label )of v  X  X  1-hop path. We generate the bitstring for p.Label , i.e., functions to set m out of M 1 bits in lbStr ( v ) .p to be  X 1 X . All the other bits are set to be  X 0 X . Similarly, we can obtain the other part lbStr ( v ) .c .

Example 2. Fig. 5(a) shows the local structure of entity v (Tom Hanks). It has 4 adjacent edges and 2 connecting edges. As shown in Fig. 5(b), lbStr ( v ) consists of lbStr ( v ) .p and lbStr ( v ) .c , which are the unions of the bitstrings for v  X  1-hop paths and connecting edges, respectively. (a) local structure Figure 5: The local structure of v and its encoding
Global Structural Encoding. Given a numeric entity v in graph G , we collect the set of numeric entities NS h (v) ,such that dist ( v, v )  X  h for each v  X  NS h ( v ), where dist ( v, v ) is the shortest path distance between v and v .

We first generate the bitstring for v i .Id ( v i  X  NS h ( v )), denoted as bStr ( v i )( | bStr ( v i ) | = M 3 ). Then, we utilize m different hash functions to set m out of M 3 bits in bStr ( v i ) to be  X 1 X . All other bits are to be  X 0 X . Then gbStr ( v ) is gener-ated by performing bitwise OR operation over the bitstrings of v i  X  NS h ( v ), i.e., gbStr ( v )= bStr ( v 1 ) | ... Figure 6: The global numeric encoding of entity v 1 shown in Fig. 6, we generate the bitstring for each entity in NS 3 ( v 1 ) , and then perform the OR bitwise operation over these bitstrings to obtain gbStr ( v 1 ) .

Structural encoding for grids. The intuition for en-coding grids lies in that we can check the minimal corner of a grid B before accessing the entities in B . If a minimal corner cannot match any entity in the query graph, we can safely prune the whole grid without exploring the corresponding entities.

The structural encoding for a grid B , i.e., lbStr ( B ), is formed by performing the bitwise OR operation over the local structural bitstrings of the entities in B . Formally, lbStr ( B )= lbStr ( v 1 ) | ... | lbStr ( v m ), where v i m ). Then we have the following theorem.

Theorem 2. If lbStr ( u )&amp; lbStr ( B ) = lbStr ( u ) , any nu-meric entity in grid B does not match u ,where u is a nu-meric entity in query graph q .

Proof. It is straightforward according to definition of lbStr ( B ).

Based on Theorem 2, we first examine the structural en-coding of a grid B before exploring the entities in B .For aqueryentity u in q ,if lbStr ( u )&amp; lbStr ( B ) = lbStr ( u )we can determine that all the entities in grid B do not match u . Thus, the whole grid B is filtered out.
The previous method Bitmap [16] can progressively de-termine whether a point is in the skyline. However, as dis-cussed earlier, it is costly to maintain the Bitmap in terms of storage cost.

The numeric encoding nbStr ( B ) in this paper is distinct from Bitmap [16]:
We maintain a bitstring for each grid B , i.e., nbStr ( B ), which consists of | D | parts: nbStr ( B ) .d 1 , ...,nbStr ( B ) .d
Take an example, we generate the numeric encoding for grid B on dimension d i , i.e., nbStr ( B ) .d i ( | nbStr ( B ) .d i K ), where K is the number of grids. For each grid B j if B j  X  X  value on dimension d i is better than B  X  X  value on dimension otherwise it is set to 0.
Example 4. Consider the partition in Fig. 4. The nu-meric encoding of grid B 5 is shown in Fig. 7.

Obtaining the numeric encoding for grid B ,wecandeter-mine whether B is in the skyline on dimensions d 1 ,...,d m where  X &amp; X  represents the bitwise AND operation. If the re-sult of the operation, X , is a non-zero value, we can conclude that there must be a certain grid strictly dominates B .
As defined in S 3 problem, a true answer should satisfy both the skyline and structural constraints. Thus, even if the numeric entities are in the skyline, the corresponding subgraph is not a true answer on condition that the struc-tural constraint is not satisfied. In this case, entities that are not in the skyline originally may become skyline enti-ties without considering their dominating entities. Hence, we utilize an invalid skyline vector, ISB , to support the dynamic skyline queries. More details will be discussed in Section 5.2.1.
As presented in Section 4.1, different partitions may result in different pruning effects. In this subsection, we discuss what a good partition is and how to partition the data space efficiently.
Obtaining the minimal corners in the skyline, we need to check whether all the entities in the corresponding grids are valid skyline entities (Def. 13). Thus, the less false positives are generated, the better the partition will be.

Observation 1 : A good partition should generate less false positives.

To make it clear, we introduce X  X ominating edge X  between two entities in the data space.
Definition 10. (Dominating Edge) . Given two enti-edge starting from v 1 to v 2 is added. This directed edge is called a dominating edge, denoted as e ( v 1 ,v 2 ).
Example 5. As shown in Fig. 8(a),entity v 1 dominates entity v 3 , there is a directed edge between v 1 and v 3 larly, we can obtain other dominating edges.
 Fig. 8 shows two different partitions for a data space. Although both these two partitions destroy 10 dominating relations, the partition in Fig. 8(b) is better than that in Fig. 8(a), because the grid consisting of v 1 and v 2 only prunes one entity (i.e., v 6 ) in Fig. 8(a). In contrast, the grid consisting of v 1 and v 2 in Fig. 8(b) can prune three entities, i.e., v 4 , v 6 ,and v 7 . (a) less common destructions
Therefore, we find that in order to prune an entity v ,all the incoming dominating edges of v should be destroyed on every attribute. Thus, we have the following observation.
Observation 2 : An effective partition should destroy as many common dominating edges as possible.

For instance, the partition lines in Fig. 8(a) destroy 2 dom-inating edges in common. The partition lines in Fig. 8(b) destroy 6 dominating edges in common. Therefore the latter partition has stronger pruning power than the former one.
In real applications, we can determine the number of grids based on the storage cost. For simplicity, we assume that the number of partition lines on each dimension is given in this discussion. According to the aforementioned observations, we define the  X  X aximum common partition X  below.

Definition 11. ( Maximum Common Partition )(de-noted as MCP ). Given the number of partition lines on each dimension and a partition P , the number of dominat-ing edges destroyed on all dimensions is denoted as | P | there exist no other partition P such that | P | &lt; | P tition P is the maximum common partition.

Given a set of data, it is better to find the maximum common partition to obtain the strongest pruning power. However, we have proven that it is an NP-hard problem.
Theorem 3. Given a set of data, computing the maxi-mum common partition is NP-hard.

Proof. (Proof sketch). We can reduce the minimum set cover problem to an instance of MCP. Provided that D = { d 1 ,d 2 } , the number of partition lines on d 2 dimension is 1. We construct a dataset in which all dominating edges are destroyed on dimension d 2 . Then any destroyed dom-inating edges on dimension d 1 are the common destroyed dominating edges on both dimensions d 1 and d 2 .

Thus, we only focus on d 1 . Assume that there are K partition lines on dimension d 1 . It is obvious that any given minimum set cover instance can be reduced to an instance of MCP. The theorem can be reached.
Since computing the maximum common partition is NP-hard, we design an efficient greedy algorithm with the time complexity O ( n  X  k  X | D | ), where k is the average number of partition lines on each dimension.

Assume that there are n numeric entities ( v 1 , ... v n ), dominating edges on dimension d i form a universe set E .A a number of dominating edges. These destroyed dominating edges form a subset of E . Thus, computing the MCP on of subsets that cover as many elements as possible.
Example 6. Considering Fig. 8(a), there are 6 option-al partition lines ( k 1 ,...,k 6 ). The partition line k between v 1 .d 1 and v 3 .d 1 destroys 4 dominating edges, i.e., e ( v 1 ,v 4 ) } . Similarly, we can also obtain the other 5 subsets.
The main idea is that we greedily select k i sets on dimen-sion d i , and store the union of these selected sets, denoted as U . When considering the next dimension d j , we greedily select k j sets whose intersections with U is the largest, and update set U . The intuition is that: Since it requires de-stroying more common edges (edges that are destroyed on all dimensions), we should intersect the selection union on dimension d with the current selected sets U . More details are presented in Alg. 1.

Specifically, the algorithm consists of three steps.
Time complexity . Assume there are n distinct numeric entities. The number of different partition lines on a dimen-sion is ( n  X  1) at most. For each partition line, it is triv-ial to obtain the corresponding destroyed dominating edges. Hence, the time complexity of the first step is O ( n  X | D the second step, the time complexity of selecting the largest sets is O ( n ). Thus, the time complexity of selecting k sets is O ( n  X  k ). Similarly, the time complexity of computing on each dimension is O ( n  X  k ). Therefore, the time complexity of Alg. 1 is O ( n  X  k  X | D | ). Algorithm 1 Greedy Partition Input: A set of numeric entities; Dimensions D = { d 1 ,... Output: A partition of the data space. 1: for Each dimension d i  X  D do 3: U  X  X  X  , s  X  0 4: while s&lt;k 1 do 5: Select the largest set E  X  F 1 6: for Each E j  X  F 1 do 7: Remove all the elements e  X  E from E j 8: U  X  U  X  E j , s  X  s +1 10: for Each dimension d i  X  D  X  i =1 do 11: s  X  0, R  X  X  X  12: while s&lt;k i do 13: Select the set E  X  F i  X  E  X  U is the largest 14: for Each E j  X  F i do 15: Remove all the elements e  X  E from E j 16: R  X  R  X  E j , s  X  s +1 17: Remove E j from F i 18: U  X  U  X  R
In this section, we present the index designed for grids first, and then give the query processing of subgraph skyline based on the feature encoding and grid index.
To answer S 3 queries efficiently, a critical task is to obtain the skyline entities dynamically before checking the expen-sive subgraph isomorphism.

Since we partition the numeric dataset to grids and use grids to represent the entities, the computation of skyline entities is conducted over these grids. In general, we need to exhaust these grids to obtain the skyline. Next, we pro-pose skylayer to avoid traversing all the grids at the time of computing skyline.
Definition 12. (Skylayer) . Given a set of minimal cor-ners, we organize the corresponding grids in the several lay-ers such that every minimal corner c i does not strictly dom-inate any other minimal corner c j in the same layer.
Example 7. Fig. 9 shows a skylayer example of the dataset in Fig. 4. There are four layers: L 1  X  L 4 ,where L i main-tains the grids that do not strictly dominate each other.
Given the set of minimal corners, C , its skylayer is easy to be built by recursively employing any existing skyline algorithms [1, 18, 15]. Specifically, we compute the skyline grids over C to obtain the first layer L 1 .Thenweremove these grids (in L 1 )from C to obtain a new set C ,i.e., C = C over C to get L i ( i&gt; 1) until C =  X  .

Lemma 3. Each grid B 1 in the i th ( i&gt; 1 )layermust has at least one grid B 2 in the ( i  X  1) th layer such that B 2 strictly dominates B 1 , i.e., B 2 &lt;B 1
Proof. It can be proved by contradiction. Assume that one grid B in i th layer has no dominating grids in the ( i 1)th layer. Thus, grid B should have been discovered in the ( i  X  1)th layer, which contradicts the assumption.

Given a numeric entity v and the grid B that v belongs to, if v is in the skyline, the minimal corner c of B must be in the first skylayer. Similarly, we have the following lemma.
Lemma 4. Any entity v in the layer L j does not domi-nate any entity v in the layer L i ,where i&lt;j . Proof. It is straightforward according to Def. 12 and Lemma 3.

Lemma 4 guarantees that accessing the skylayers one by one will not miss any skyline entities.

Obtaining a skyline grid B , we need to compute the sky-line entities in B . Notice that, some numeric entities in the query may only involve only a part of the dimensions, i.e., it is a subspace query. Here, we employ the bitmap technique [16] to determine whether entity v ( v  X  B ) is in the skyline.
Different from the work in [16], we generate the bitmaps online instead of maintaining all the bitmaps with expen-sive storage cost. Moreover, it is probable that not all the entities need to be examined, that is, it may only involve a subset of the entities. Hence, it is unnecessary to generate bitmaps for all the entities. In the offline phase, entities are sorted on each dimension, based on which the bitmap gener-ation is very simple (the generation is similar to the numeric encoding for grids in Section 4.2.2).
In this section, we give the query algorithm based on fea-ture encoding and grid index aforementioned. Since a query graph may contain one or multiple numeric entities, we deal with these two cases in the following discussion.
Since we have partitioned the numeric dataset to grid-s, and utilize skylayers to maintain these grids, the query process starts from the skylayers.

Intuitively, it is the simplest case that there is only one numeric entity in query graph q . Alg. 2 presents the details, which has three steps: high-level pruning, skyline computa-tion, and structure verification.

High-level Pruning. Given a query graph q which con-tains one numeric entity u , we generate the local structural encoding for each vertex in q . Then the high-level pruning (structural pruning and numeric pruning) is performed.
Structural Pruning. Specifically, we first generate the local structural encoding of u is lbStr ( u ). For each grid B in skylayer L , we check whether u can match B . Based on Thm. 2, if lbStr ( u )&amp; lbStr ( B ) = lbStr ( u ), we can conclude that any numeric entity in grid B can not match u . Algorithm 2 Single Numeric Entity Query Input: A knowledge graph G , the feature encoding for Output: The subgraph skyline in G . 1: for Each skylayer L do 2: for Each grid B in L do 3: perform structural pruning over B 4: perform numeric pruning over B 5: if B is a valid skyline grid then 6: for Each entity v in B do 7: perform structural pruning over v 8: perform numeric pruning over v 9: if v is a valid skyline entity then 10: perform structure verification 11: if agraph g containing v is isomorphic to q 12: report g as a result 13: pruning entities and grids
Numeric Pruning. If grid B matches u in terms of the structure constraint, we need to check whether grid B is in the valid skyline (Def. 13) over the query space.
 Definition 13. (Valid Skyline.) An entity v (or grid B ) is in the valid skyline iff v (or B ) satisfies the structural constraint specified in query graph q , and all the entities dominating v (or B ) do not satisfy the structural constraint. For instance, assume that grid B 1 dominates B 2 ,whereas no other grids dominating B 2 .Thus, B 2 is in the valid skyline. Conversely, grid B 1 is an invalid skyline grid.
In order to determine whether grid B is in the valid sky-line, we utilize a vector, ISB ( | ISB | = K ), to record the invalid skyline grids. At the beginning, each bit of ISB is set to be 1. When we find an invalid grid, the corre-sponding bit is set to be 0. If ISB &amp; X =0,grid B is a candidate in the valid skyline at the moment, where in the valid skyline, which indicates that grid B is not need to be explored further.

Skyline Computation. For a valid skyline grid B ,we need to compute the valid skyline entities in B . Similar to the computation of grids, we conduct the structural pruning and numeric pruning to filter out the unpromising entities as early as possible.

Structural Pruning. Given a numeric entity v in grid B and the numeric entity u in query graph q ,accordingtothe we can conclude that v does not match u .

Numeric Pruning. If entity v passes the structural prun-ing, we should determine whether v is a valid skyline entity. As discussed in Section 5.1, we only maintain the sorted entities on each dimension, based on which the bitmaps, nbStr ( v ), can be generated easily.

Analogous to that of grids, we maintain a vector whose all bits are 1, ISV ( | ISV | = n ), to record the invalid skyline entities. Once we find that a skyline entity is invalid due to the structure constraint, the corresponding bit is set to be 0. If ISV &amp; Y =0,entity v is in a valid skyline entity candi-Otherwise, v is not in the valid skyline.

Structure Verification. Passing the first two pruning techniques, it requires to verify whether there exists a sub-graph containing v that is graph isomorphic to query graph q . The state-of-the-art algorithms such as Ullmann [20] and VF2 [4] can be employed to achieve this verification.
Supposing that we find a subgraph containing v that sat-isfies both the skyline and structural constraints, we can prune all the entities that are dominated by v .Specifically, the entities in B that are dominated by v and the grids that are strictly dominated by B can be filtered out safely, where entity v belongs to grid B .

It is easy to obtain the grids that are dominated by B based on the numeric encoding of B . Regarding dimension d i , we reverse each bit of nbStr ( B ) .d i , and set the bit corre-the new encoding nbStr ( B ) .d i .Let Z = nbStr ( B ) .d 1 &amp; ... &amp; nbStr ( B ) .d m . The grids corresponding to non-zero bits in Z are dominated by B . Thus, these numeric entities in these grids can be filtered out.
In general, there may be multiple numeric entities in query graph q . To handle this case, we propose joint pruning in this subsection. For ease of presentation, we assume that there are two numeric entities u 1 and u 2 in query graph q . The main idea is that: we select one numeric entity u 1 to match and then we compute the candidates for entity numeric entity v 1 ( v 1  X  G ) is a candidate for u 1 .
In order to find the candidate for u 1 , we perform structural and numeric pruning which are analogous to that discussed for one single numeric entity as shown in Section 5.2.1.
Obtaining the candidate v 1 for u 1 , we need to compute the candidates for u 2 . Besides the high-level pruning and skyline computation, we also propose two joint pruning techniques: shortest-path-distance pruning and skyline join pruning.
Shortest-path-distance Pruning. Provided that the short-est path distance between u 1 and u 2 , dist ( u 1 ,u 2 ), is no larger than h ,where h is a predefined threshold based on which the global structural encoding is generated. Entity mine whether v 2 is in NS h ( v 1 ) using the global structural encoding of v 1 , gbStr ( v 1 ).

If gbStr ( v 1 )&amp; bStr ( v 2 ) = bStr ( v 2 ), we can conclude that bStr ( v 1 ) is the bitstring of v 2 .Id . Since it avoids the costly graph isomorphism checking, the query efficiency may im-prove a lot.

Skyline Join Pruning. The graph isomorphism algorithm should be invoked to verify these entity pairs that pass all the pruning techniques above. If there exists a subgraph g containing entity pair v 1 and v 2 such that g is graph isomor-phic to query graph q , g is in the subgraph skyline. Hence, we prune all the subgraphs that are dominated by graph g .
Actually, instead of enumerating all these pruned sub-graphs, we just need to filter out the entity pairs in dom ( v and dom ( v 2 ), where dom ( v 1 )and dom ( v 2 )representsthe entities dominated by v 1 and v 2 , respectively. Notice that, since we utilize grids to store entities, the join space is rela-tively small compared with joining entities directly.
In order to deal with more than two numeric entities, we can take them into consideration one by one. We omit more details due to the space limitation.
In this section, we study our proposed method through extensive experiments. Section 6.1 introduces the experi-ment setting, followed by the effectiveness evaluation and efficiency evaluation in Sections 6.2 and 6.3, respectively.
We use Freebase dataset 1 which integrates NBA 2 and IMDB to evaluate our method. It contains 12,130,534 vertices, 232,671,328 edges, 7,634,315 numeric entities, and 35 nu-meric attributes.

Regarding the queries, we generate some query graphs to study the effectiveness of our method. More examples will be present in Section 6.2. In order to study the efficiency, we randomly extract some subgraphs containing numeric enti-ties, and vary the size of these query graphs.
 All the experiments were conducted on a PC with 2.9GHz CPU and 16GB main memory running Linux operating sys-tem. For comparison, we implement the simple method p-resented in Section 3.2, denoted as  X  X aive X  , which does not employ partition and feature encoding techniques. The par-tition and encoding based method is denoted as  X  X arCode X . Both the two programs were implemented in C++.
In order to verify the effectiveness of our method, we focus on the case studies of S 3 queries in this subsection, and check whether the results returned by our method are reasonable. To this end, we artificially generate some queries. Here, we present two case studies as follows.

Golden Basketball Partner Finding. AsmentionedinSec-tion 1, assume that we want to find one guard and one for-ward who play in the same team. The guard is expected to be excellent in techniques  X  X ssists X  and  X  X teals X . The for-ward is expected to be excellent in techniques  X  X ebounds X  and  X  X locks X . The query graph is shown in Fig. 2. Fig. 10 presents a subset of the results. As expected, we find several great partners, such as Gasol Pau and Bryant Kobe.
Excellent Versatile Artist Finding. We want to seek Amer-ican outstanding artist who is a singer and an actor/actress as shown in Fig. 3. Specifically, the gross of the film that the actor/actress starred in and the copies of his/her album are expected to be large. Fig. 11 gives a fraction of the results. For example, Michael Jackson is in the skyline.
In this subsection, we evaluate the performance of our proposed method and compare it with the naive method.
Since we partition the data space into grids and utilize the feature encoding techniques in offline phase, the storage http://www.freebase.com/ http://databasebasketball.com. http://www.imdb.com/interfaces.
 cost is acceptable. Tab. 1 shows the space cost and index building time (T.time) of the two methods. It is obvious that  X  X aive X  consumes more space, since it encodes all the numeric entities. In contrast, instead of encoding each enti-ty,  X  X arCode X  just encodes the minimal corner of each grid. What is more, the time consumed by  X  X arCode X  is much less than that consumed by  X  X aive X .

In order to study  X  X arCode X  in depth, Tab. 1 also depicts the time consumed by partition step (P.time) and encoding step (E.time), respectively. It indicates that the main time cost results from the partition process. Hence, a good and efficient partition method is pretty important.
In this subsection, we adopt two metrics, i.e., the query response time and pruning power, to evaluate the online performance, where the pruning power is the ratio of candi-dates that are filtered out, i.e., the number of pruned entities divided by all candidates.

Evaluate the effect of K . K is the number of grids. We fix the query size (the number of vertices) of q to be 8, and vary the number of grids. Each query may contain one or multiple numeric entities. Both the query response time and pruning power are averaged results.

Figs. 12(a) and 12(b) investigate the query response time of the two algorithms with respect to NBA and artist analy-ses, respectively. It shows that when K is too small or large, theresponsetimeincreases.Extremely,if K =1or K = n , it is equivalent to the case without any partition in actual. According to this experiments, it indicates that K is better to be about of the partition, its query response time is a horizontal line.
Evaluate the effect of N q . We fix the number of grids, and vary the number of numeric entities, N q ,in q from1to5. As depicted in Fig. 13,  X  X arCode X  outperforms  X  X aive X  in terms of time efficiency. Moreover, the performance gap be-tween  X  X arCode X  and  X  X aive X  X ecomes larger when the num-ber of numeric entities in q increases. The reason is that the  X  X aive X  method computes skyline entities in the manner of entity by entity. In comparison,  X  X arCode X  computes sky-line entities in grid level and integrates numeric feature with structural feature to produce much fewer candidates.
In order to study the pruning power of  X  X arCode X , we evaluate the ratio of entities (or entity pairs) that are filtered out by grid-level pruning ( filter B ) and entity-level pruning ( filter V ). As shown in Fig. 14, most of the candidates are pruned without invoking subgraph isomorphism verification, which contributes to the efficiency of our method.
Evaluate the effect of | V ( q ) | . Fig. 15 presents the query response time with respect to the number of vertices in query graph q . As shown in Fig. 15, both the time efficiency of  X  X arCode X  and  X  X aive X  decrease with increasing | V ( q ) | is obvious that if there are more vertices in q , the time con-sumed by subgraph isomorphism checking will increase.
In this paper, we formalize the problem of subgraph sky-line search (denoted as S 3 ) over large graphs and propose an algorithm to answer S 3 queries. To improve the efficien-cy, we propose to partition the data space into grids, based on which we carefully design feature encoding to facilitate the query process. The experimental results on real datasets validate the effectiveness and efficiency of our method. As future work, there are several issues to be addressed, such as handling high dimensions, incremental updates, and the effect of data distributions. This work was supported by China 863 Project under Grant No. 2012AA011101, Nation al Science F oundati on of China (NSFC) under G rant No. 61370055 and 61272344, and CCF-Tencent Open Research Fund.
