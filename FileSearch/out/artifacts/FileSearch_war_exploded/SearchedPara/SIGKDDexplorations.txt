 The goal of this position paper is to contribute to a clear understanding of the commonalities and differences between subspace clustering and text clustering. Often text data is foisted as an ideal fit for subspace clustering due to its high dimensional nature and sparsity of the data. Indeed, the ar-eas of subspace clustering and text clustering share similar challenges and the same goal, the simultaneous extraction of both clusters and the dimensions where these clusters are de-fined. However, there are fundamental differences between the two areas w.r.t object feature representation, dimension weighting and incorporation of these weights in the dissim-ilarity computation. We make an attempt to bridge these two domains in order to facilitate the exchange of ideas and best practices between them.
 high dimensional data, subspace clustering, text clustering Subspace Clustering is a new research area receiving a lot of attention from the community [23; 18; 19; 8]. In contrast to traditional clustering that partitions objects in the full dimensional feature space, the subspace clustering methods simultaneously partition both objects and dimensions. A subspace cluster is defined in terms of both its members and the dimensions where these members are grouped together. As with traditional full dimensional clustering, subspace clustering is not confined to specific data types or appli-cation domains. Related work often mentions text data as a candidate application for subspace clustering [23; 8] due to the high dimensionality and sparsity of the text data [26]. Typically, documents are represented as vectors in a very high dimensional space where the entries of this vector rep-resent words appearing in the document collection. Text data have been studied extensively in the fields of In-formation Retrieval and Text Mining. The text clustering domain [4] is among the most important ones with a lot of applications like organization, summarization and indexing of document content. Nowadays, it is a very active research field due to the abundance of textual data.
 Both subspace clustering and text clustering domains face the challenge of high dimensionality and aim at extracting both clusters and the dimensions upon which these clusters are defined. To this end, both domains evaluate the impor-tance of the dimensions for the clustering task and appro-priately incorporate this importance in the distance function and consequently, in the clustering algorithm. Besides the common goal and the similar approach though, there are fundamental differences between the two domains. To the best of our knowledge, no work that elaborates on how the two areas are related has been proposed so far. Our goal of this work is to serve as a point for fruitful exchange of ideas and techniques between the two domains.
 The rest of the paper is organized as follows: A short overview of subspace clustering and text clustering domains is presented in Sections 2 and 3, respectively. The differ-ences and commonalities between the two domains are dis-cussed in Section 4 and refer to the following aspects: object-feature representation (Section 4.1), dimension weighting (Section 4.2) and incorporating dimension weights in the similarity/distance function (Section 4.3). In Section 5, we overview a few existing approaches that make use of con-cepts from both domains. Section 6 concludes our work. The area of subspace clustering has lately emerged as a solu-tion to the problem of high dimensional data, as it is difficult to find meaningful clusters in hundreds or even thousands of dimensions. Different features might be relevant for differ-ent clusters and therefore, the goal of subspace clustering is to find both the cluster members and the dimensions upon which these members form a cluster.
 This is in contrast to traditional clustering that searches for clusters in the full dimensional feature space [15; 13]. Also, this is different from global dimensionality reduction tech-niques like PCA [16] that reduce the dimensionality of the feature space and search for clusters in the reduced (though still full) dimensional space. Several subspace clustering methods have been proposed in the literature so far (for a comprehensive overview of the area see e.g., [23], [18], [21]). A crucial point in subspace clustering is the decision about the relevant dimensions that should be considered for clus-tering. Given a d -dimensional data set, the number of possi-ble subspaces is 2 d  X  1, therefore it is infeasible to examine all possible subspaces for clusters. The solution is to efficiently navigate through the search space of all possible subspaces; to this end, two different approaches have been proposed in the literature [18]: Top-down subspace clustering methods are closer to the text clustering methods since they simultaneously search for the best non-overlapping partitioning of the data and the best subspace for each partition. Therefore, we refer to the top-down subspace clustering methods from now on. The goal of text clustering is to organize documents into clusters of similar content, the so-called topics. Documents are typically represented in terms of their component words, through the vector space model [27]. Usually, no information about the order of the words is considered in this model and thus this model is also known as the bag of words representa-tion model. Although more elaborate representations have been proposed such as multi-word terms and N-Grams [28], the vector space model remains the most popular one. This representation though results in a high dimensional feature space, where features correspond to words appearing in the document collection. Moreover, only a small subset of all words appearing in the collection appears in each document. As a result, the document representation is very sparse . Typically, before applying any mining technique in the text collection, preprocessing takes place in order to remove non X  X nformative words. Preprocessing consists of several steps [7]:  X  Filtering: Special characters and punctuation are re-moved since they are considered not to hold any discrim-inative power.  X  Stemming: The words are reduced to their base form or stem or root with the goal of eliminating multiple occur-rences of a word (e.g., the words  X  X ish X ,  X  X ishing X ,  X  X isher X ,  X  X ished X  are all derived from the same root  X  X ish X ). Stem-ming is language dependent. The Porter X  X  algorithm [24] is the best known stemmer for the English language.  X  Stopword removal: A stopword is a word which is not thought to convey any meaning as a dimension in the vector space (i.e., without context), e.g., the words  X  X he X ,  X  X nd X . Usually the document words are compared with respect to a known list of stopwords and the detected stopwords are removed from the document.  X  Rare words removal: Rare words, i.e., words that ap-pear in very few documents are usually removed since they are considered not to capture much information about some category of documents [30]. A threshold on the num-ber of documents is used that determines whether a word is rare and should be removed from the feature space as an outlier.
 Although preprocessing results in some sort of dimensional-ity reduction, the number of dimensions remains very high (hundreds or thousands of keywords 1 ). To deal with this problem several dimensionality reduction techniques have been proposed which can be distinguished into feature trans-formation and feature selection techniques. The feature transformation techniques try to reduce the dimensional-ity to a fewer new dimensions which are combinations of the original dimensions. In this category belongs methods like Principal Component Analysis (PCA) [16] and Latent Se-mantic Indexing (LSI) [20]. Because they are global meth-ods though, they might be problematic for topics defined upon different keywords. Feature selection methods aim at removing dimensions which seem irrelevant for modeling, e.g., words appearing very often in a collection or very rarely, aka outliers. Nevertheless, the resulting feature space is still high dimensional and therefore dimensions X  weighting takes place as we will explain in the following sections. Typical examples of distance-based text clustering algo-rithms are hierarchical clustering and k -Means [4], while cosine similarity is the commonly used similarity function. In the previous sections, we presented a short introduction to the areas of subspace clustering and text clustering. Here-after, we show how the two areas are related by pointing out their commonalities and differences.
 As already mentioned, both areas deal with high dimen-sional data: Subspace clustering targets high dimensional data, though not focusing on specific application domains or data types. The data instances are described in terms of all dimensions, in the full (high) dimensional feature space. The vast majority of the algorithms does not deal with miss-ing values, though recently fault tolerant subspace cluster-ing [12] has been proposed to accommodate data with miss-ing values. From a text clustering perspective, the keywords of a document comprise the dimensions of the feature space and documents are points or vectors in this space. There are hundreds or thousands of keywords (thus, high dimen-sional space) and the vectors describing each document are very sparse (most of the entries are null). A null entry in this case might mean that the corresponding keyword is ir-relevant (e.g., consider the word  X  X kraine X  in a document
The terms  X  X ord X ,  X  X eyword X   X  X erm X  are used inter-changeably.
 about the importance of vegetables in our daily diet) or the corresponding word might be missing because it is im-plied by the context (e.g., in a document about  X  X reece X  the word  X  X ountry X  might not be reported since it is known that Greece is a country).
 Note also that both areas share the same goal, namely the simultaneous partitioning of the data points and the di-mensions (points/ instances and dimensions/ features, re-spectively according to the subspace clustering terminology; documents and keywords, respectively according to the text clustering terminology). In both cases, the notion of a clus-ter includes, except for the cluster members, and the dimen-sions where these members are similar enough to form the cluster. In subspace clustering, these clusters are known as subspace clusters, whereas in text clustering as topics. The problem of simultaneously partitioning both the data and the dimensions is tackled in a similar way by both sub-space clustering and text clustering areas. In particular, the solution involves an appropriate weighting of the dimensions according to their relevance for the clustering task and the incorporation of these weights in the dissimilarity function and consequently, in the clustering algorithm.
 We present the commonalities and differences between the two domains with respect to the following aspects: (i) the object X  X eature representation (Section 4.1), (ii) the weight-ing of the dimensions (Section 4.2) and (iii) the incorpora-tion of dimensions X  weighting in the dissimilarity functions and consequently, in the clustering algorithms (Section 4.3). Let D = { p 1 ,p 2 ,...,p n } be a dataset of n objects and let A =( A 1 , A 2 , ..., A d ) be the d -dimensional feature space. Let V be a |D| X | A | matrix, referred hereafter as the object X  feature value matrix , where the rows are the objects and the columns are the dimensions. Each entry v i,j in this matrix corresponds to the value of the object p i  X  X  in the dimension A j  X  A . We explain hereafter what these values are for each domain. In subspace clustering, each object is considered to have val-ues for all dimensions 3 . So, the construction of the object X  feature value matrix V is rather straightforward. The rows correspond to the objects in the database and the columns correspond to the dimensions. Each entry v i,j in the matrix contains the value of the object p i  X  X  in dimension A j  X  A . The original values of the dimensions may refer to different scales of reference. To prevent attributes with initially large ranges (e.g., salary) from outweighing attributes with ini-tial smaller ranges (e.g., age), a normalization process takes place prior to clustering. In this way, different dimensions can be compared meaningfully. In text clustering, the database D corresponds to a collec-tion of documents and the dimensions A correspond to the distinct keywords in this collection. We assume that the pre-processing step (c.f., Section 3) has been already applied.
We use the term  X  X issimilarity X  to refer to either distance or similarity function.
Recently, subspace clustering over data with missing values has been considered [12].
 The matrix V is the result of the vector space model rep-resentation, called document X  X erm matrix in this settings. Each entry v i,j in the matrix corresponds to the value of keyword A j  X  A in document p i  X  D . Usually v i,j equals the number of times that keyword A j appears in document p . To prevent biasing towards longer documents, the num-ber of occurrences of a keyword in a document is normalized with respect to the total number of keyword occurrences in the document, resulting in the so-called term frequency: Definition 1. Term Frequency (TF) The term frequency of a term/keyword A j  X  A in a docu-ment p i  X  X  is defined as follows: where the numerator represents the number of occurrences of keyword A j in document p i and the denominator repre-sents the occurrences of all keywords A k  X  A in p i . The TF score expresses how important a keyword is within a document. Its values lie in the [0 , 1] range with larger values indicating more important keywords. Hereafter, we consider the entries of matrix V to be the TF values of the keywords in the documents of the collection. Note that since not all keywords in the collection appear in each single document, there are a lot of null entries in this matrix corresponding to non-appearing words in a document. There is a crucial difference in the object-feature represen-tation of the two domains. In subspace clustering, there are no semantics on the values of the dimensions and all values are considered to be of the same importance. On the contrary, in text clustering greater values indicate more important dimensions/keywords. For example, consider a keyword A 1 appearing in two documents p 1 ,p 2 with term frequencies 0 . 8 , 0 . 2, respectively. Since 0 . 8 &gt; 0 . 2, A sidered to be more important for document p 1 compared to document p 2 . Such a value differentiation though does not take place in the subspace clustering domain.
 Although, as already mentioned, recently subspace cluster-ing over missing data has been proposed [12], missing data are conceptually different from non X  X ppearing words in a document. A missing value in subspace clustering indicates a value that is unknown rather than a value that is not im-portant for the description of a document or redundant w.r.t. already existing words in the document (as it is usually the case for non appearing words in a document). Both subspace clustering and text clustering domains rely on some notion of weighting for the different dimensions based on their importance for the clustering task.
 In subspace clustering, the important dimensions are learned either for an instance/object ( instance X  X ased approaches ) or for a cluster ( cluster X  X ased approaches ). Representative weighting schemes for both approaches are presented in Sec-tion 4.2.1 . In text clustering, the most well known weight-ing schema is inverse document frequency (IDF) described in Section 4.2.2 .
 We can model the dimension weighting in terms of a matrix W referred to hereafter as the object X  X eature weight matrix . In the general case, W is a |D| X | A | matrix where the rows correspond to objects and the columns correspond to dimen-sions. Each entry w i,j in this matrix represents the weight (or importance) of the dimension A j  X  A for the object p  X  X  . We explain hereafter how these entries are filled for each domain. The importance of a dimension is evaluated either with re-spect to some instances (instance X  X ased approaches) or with respect to some cluster (cluster X  X ased approaches). Both approaches rely on the so called  X  X ocality assumption X  ac-cording to which, the subspace preference for an object or a cluster can be learned from its local neighborhood in the full dimensional space. We describe each case below. (i) Dimension weighting in instance X  X ased approaches
The preferred dimensions subspace is defined per instance and is learned by evaluating the local neighborhood of the instance/object in the full dimensional feature space. The definitions and details below are from the algorithm PreDeCon [9].

Locality of an instance: For an object p  X  X  , its locality or neighborhood ( N  X  ( p )) consists of all objects that fall within distance from p in the full dimensional space.
Preferred dimensions of an instance: Roughly speak-ing, an object prefers a dimension if it builds  X  X om-pact X  neighborhoods, i.e., neighborhoods of small variance, across this dimension. The variance in the neighborhood of p along some dimension A j is defined as follows:
Let p  X  X  and  X   X  R . The variance in the neighborhood of p N  X  ( p ) along a dimension A j  X  X  is given by: where dist A j ( p,q ) is the distance of p,q in dimension A
A small variance, with respect to a given variance thresh-old  X  , indicates a preferable dimension. For each p  X  D , its subspace preference vector  X w p is built [9] which distin-guishes between preferable and non-preferable dimensions. Let p  X  D ,  X   X  R and  X   X  R be a constant with  X  1.
The subspace preference vector of p is defined as: where:
The values of the subspace preference vector are the entries of the object X  X eature weight matrix W : k -value entries in-dicate preferable dimensions while 1-value entries indicate non-preferable ones. (ii) Dimension weighting in cluster X  X ased approaches
The subspace of the preferred dimensions is defined per cluster and is learned by evaluating the local neighbor-hood of the cluster in the full dimensional space. The number of clusters k is given as input to the algorithms of this category. The definitions and details below are from the algorithm PROCLUS [3]. Each cluster (called projected cluster ) is represented by its medoid and it is assigned a subspace of preferred 4 dimensions. Let
C = { c 1 ,c 2 ,...,c k } be a set of k medoids (for more details on the initial selection and refinement of this set, please refer to [3]).

Locality of a cluster: The locality L i of a cluster c i  X  C is defined as the set of objects in D that are within distance  X  i from its medoid c i . The distance is computed in the full dimensional space, whereas the distance threshold  X  i is the minimum distance of c i from any other medoid c j  X  C , i.e.,  X  i = min { dist ( c i ,c j ) } , i 6 = j .

Preferred dimensions of a cluster: For each medoid c , the average distance between c i and the objects in its locality L i is computed along each dimension A j  X  A , de-noted by X i,j . If this value is as small as possible w.r.t. the statistical expectation, then A j is a preferred dimen-sion for cluster c i . The statistical expectation is evaluated in terms of the mean Y i and the standard deviation  X  the average distance between cluster c i and its locality L in dimension A j is related to the average distance in all dimensions. The lowest Z i,j values are picked leading to a total of k  X  l dimensions, where l is the average dimension-ality per cluster given as input to the algorithm.
After the weighting, each cluster in C is assigned a sub-space of preferred dimensions. Usually a bitvector of all dimensions is used to model the preferences and to distin-guish between preferred (value 1) and non preferred (value 0) dimensions for a cluster [2].

The objects assigned to a cluster  X  X nherit X  the subspace preferences of the cluster, therefore each object can be as-sumed to have a bitvector of dimension preferences. This way, we can fill the entries of the object X  X eature weight ma-trix W with values 1 and 0 indicating preferred and non X  preferred, respectively, dimensions for an object. Note that this way the objects belonging to the same cluster, would have the same bitvectors of subspace preferences. In text clustering, the importance of a keyword is evalu-ated in terms of the whole collection of documents, rather than per document or per topic/cluster. Usually, the Inverse Document Frequency (IDF) is employed towards this end. Definition 4. Inverse Document Frequency (IDF) The inverse document frequency of a keyword A j in a col-lection of documents D is given by: where the denominator represents the number of documents in D which contain the specific keyword/dimension A j and | D | is the cardinality of the collection.
 The basic intuition behind IDF is that common keywords (i.e., keywords appearing very often in the collection) have no discriminative power and thus, they are assigned a small
We use both terms  X  X referred X  and  X  X rojected X  to describe a dimension that is important.
 IDF score. Larger IDF scores indicate more discriminative keywords.
 Using the IDF scores of the keywords we can fill the entries of the object X  X eature weight matrix W . Note that since IDF is defined per keyword, each column of the matrix correspond-ing to a single keyword would be filled with the same IDF value. Although, the weighting of the dimensions is performed in both subspace clustering and text clustering domains, there are core differences in the weighting schemes.
 In subspace clustering, the dimension weighting is local re-lying on the neighborhood of each object or cluster. In text clustering, the weighting of the keywords is global and is based upon the whole collection of documents.
 Also, the dimension weights in subspace clustering act mainly as a filter in order to distinguish between preferred and non X  X referred dimensions. For example, PreDeCon [9] uses the dimension weights  X  and 1 to model preferred and non-preferred dimensions, respectively. Similarly, PRO-CLUS [3] employs two dimension weights, 0 and 1 with 1 in-dicating a preferred dimension. That is, the actual weights of the dimensions are not considered in subspace clustering, but rather the information about which dimension is pre-ferred or not. This is in contrast to IDF weighting in text. The weighting of the dimensions is incorporated in the dis-similarity function in both subpsace clustering and text clus-tering domains. We model this contribution in terms of a generic dimension X  X eighted dissimilarity function. Definition 5. Dimension X  X eighted dissimilarity Let p,q  X  X  . We denote by V [ p,A j ] ( V [ q,A j ]) the value of object p ( q , respectively) with respect to dimension A j by W [ p,A j ] ( W [ q,A j ]) the importance of A j for the object p ( q , respectively). The dissimilarity between p and q is a combination of their values and dimensions X  weights: diss ( p,q ) = Aggr A j  X  A f( V [ p,A j ] ,V [ q,A j ] ,W [ p,A The function f() combines the value and weights in each dimension. The total score is an aggregation of the cor-responding dimensions X  scores, through some aggregation function Aggr ().
 We already discussed what the object values and dimension weights stand for in each domain and how the object X  X eature value matrix V and the object X  X eature weight matrix W are filled. We explain hereafter how the diss () function is instantiated per domain. We distinguish between instance X  X ased and cluster X  X ased approaches, as with the weighting of dimensions case (cf., Section 4.2). (i) Dissimilarity in instance X  X ased approaches We adapt the distance function of PreDeCon [9] to the generic diss () function notation.

Let p,q  X  D , then their preference weighted distance is given by:
The above formula considers only the preferences of p . The symmetric version is: spectively) in dimension A j and W [ p,A j ] ( W [ q,A j ]) is the weight of A j for point p ( q , respectively).

Note, that the dimension weights are either 1 or  X  (  X  &gt;&gt; 1). Therefore, the similarity function weights attributes with low variance (dimension weight  X  ) considerably lower (by a factor 1 / X  ) than attributes with a high variance (di-mension weight 1). (ii) Dissimilarity in cluster X  X ased approaches We adapt the distance function of PROCLUS to the generic diss () function notation.

Let p,q  X  D with q being the medoid of a cluster. The projected distance of p with respect to the medoid q is given by:
W [ q,A j ] is the importance of dimension d for the cluster represented by the medoid q . Note that in this case, weights take values in { 0 , 1 } . That is, the non important dimen-sions are not considered at all during distance computation and the important ones are equally taken into account. TF  X  IDF is the most common schema for combining key-word weights and their values across different documents. According to this schema, the value of a keyword in a doc-ument (TF) is multiplied by the importance of the keyword in the whole collection (IDF).
 Definition 8. TF  X  IDF score Let p  X  D be a document and let A j  X  A be one of its keywords. The TF  X  IDF score of A j in p is given by: Typically, the dissimilarity function is applied upon the TFIDF values of the documents. A commonly used dissimi-larity function is the cosine similarity that finds the cosine of the angle between the two documents. It becomes 1 if the documents are identical and 0 if there is nothing in com-mon between them (i.e., the vectors are orthogonal to each other).
 The cosine similarity can be re-written in terms of the generic formula diss () as follows: Definition 9. Cosine similarity
Let p,q  X  X  be two documents. Their similarity is defined as: Note that the weight of a keyword A j is defined over the whole collection D thus, documents p and q share the same weight for this keyword, i.e., W [ p,A j ] = W [ q,A j ] = IDF Although, both domains consider objects X  values and dimen-sions X  weights for dissimilarity computation, there is a clear difference between the two domains. The difference lies in the fact that in text clustering the value of a dimension/ keyword in a document, i.e.,TF, also expresses some notion of importance for the keyword in the document. This is in contrast to subspace clustering where all values are treated similarly and there is no importance discrimination. This fact is also reflected in the chosen dissimilarity func-tions. In subspace clustering, where the values carry no semantics on their importance, the value difference in each dimension (e.g.,, absolute as in PROCLUS [3] or squared as in PreDeCon [9]) is considered. In text clustering, though, the widely used cosine similarity function multiplies the ac-tual object values at each dimension, so that higher values result in higher scores. For example, if we consider two ob-jects with values 0.8 and 0.6 for a specific dimension (case 1), the contribution of this dimension to the dissimilarity score will be 0 . 8  X  0 . 6 = 0 . 2 for PROCLUS and (0 . 8  X  0 . 6) for PreDeCon, whereas for the cosine similarity it will be 0 . 8  X  0 . 6 = 0 . 48. For two other objects, with values 0 . 4 , 0 . 2 in the same dimension (case 2), the result would be the same for PROCLUS and PreDeCon since they rely on their value difference which is again 0.2, however it will be different for cosine similarity; the contribution of this dimension this time would be: 0 . 4  X  0 . 2 = 0 . 08 counting for the fact that the actual object values are lower in case 2 than in case 1. Also, in subspace clustering the dimension weighting pre-dominantly indicates whether the corresponding object val-ues should be considered or not. For example, in PRO-CLUS [3] only projected dimensions (having weight 1) are considered during dissimilarity assessment and there is no special weighting per preferred dimension. In PreDeCon [9] also, the value differences in the preferred dimensions (those having weight  X  ) are down-weighted by 1 / X  , but again this holds for all preferred dimensions. On the contrary, in text clustering the actual weights of the dimensions as expressed by their IDF values over the whole collection of documents are considered and contribute proportionally to the dissim-ilarity score. In the previous section, we elaborated on the differences and commonalities between subspace clustering and text cluster-ing domains with respect to data representation, dimension weighting and incorporation of these weights in the dissim-ilarity functions. In this section, we overview approaches that make use of concepts from both domains.
 In [1], the authors study the problem of semi-supervised text classification and use clustering to create the set of cat-egories for the classification of documents. To improve clus-tering quality, they use a modified version of K X  X eans where they iteratively refine both the clusters and the dimensions inside each cluster. In particular, at each iteration they filter out some of the words of the feature space ensuring that only words that frequently occur within the cluster are used for the assignment process. The number of words, i.e.,projected dimensions for each cluster, is reduced at each iteration by a geometric factor. In their experiments, they started with a projected dimensionality of 500 words which was finally reduced to 200 words. This work introduces subspace clus-tering concepts to text clustering, in particular, the local (within each cluster) weighting of the words and selection of the most prominent ones for cluster centroid representa-tion. The proposed algorithm resembles PROCLUS [3] (c.f., Section 4.2.1 ), however the distance function and the selec-tion of projected dimensions at each iteration is adopted to the text domain. In particular, cosine function is used for dissimilarity assessment and the selection of projected di-mensions is done on the basis of their occurrences in each cluster.
 In [14], the authors propose a modification of W X  X  X  Means [10], that calculates cluster specific weights for each feature during the clustering process, for text documents. Totally m  X  k weights are produced by the algorithm where m is the number of features and k the number of clusters. The initial weights are randomly generated and refined dur-ing the iteration phase, similarly to K X  X eans. Based on these weights, the subset of keywords that can serve as clus-ter label can be identified. In their experiments, the pro-posed subspace method performed better than standard K X  Means and Bisecting X  X Means [29].
 There are also methods that extract an initial clustering with respect to the whole feature space of documents (usu-ally through TF  X  IDF weighting) and refine the cluster-ing result by applying clustering again inside each extracted cluster but using a refined feature space. For example, in [31] the authors propose the extraction and maintenance of a two level hierarchy of global and local topics: the global topics are extracted by applying clustering over the whole collection of documents in the feature space derived from the whole collection through TF  X  IDF . To extract the local topics, clustering is applied again inside each global clus-ter using the cluster population to generate the new cluster specific feature space (the IDF scores are based on the clus-ter population, rather than on the whole collection), instead of using the generic feature space extracted from the whole dataset. This way, the feature space is refined per cluster. Discussion Although there are some methods for text clustering that make use of subspace clustering concepts, like [1], [14] and methods that refine the feature space through global and local weighting like [31], there are still many things that the two domains could exchange and ben-efit from each other, like for example a concurrent incorpo-ration of both global and local weighing of features in the clustering process. There is a bunch of subspace clustering algorithms in the literature, a thorough report on their per-formance over text data would be very useful as a starting point. Of course, the weighting of the dimensions and the distance function should respect the peculiarities of the text data as discussed in Section 4. There are also other fields which resemble the semantics of the data values in text; for example, in recommendation applications higher ratings indicate more desired items,e.g.,movies or restaurants. Sub-space clustering is relevant to such kind of data too, since groups of users with different item preferences might exist, however as with text, the data semantics should be also taken into account.
 We outlined the differences and commonalities between sub-space clustering and text clustering and we argued that text data is not a straightforward application domain for sub-space clustering as it is often suggested in the literature. Although both domains share the same goal, the concurrent extraction of clusters and dimensions where these clusters are formed, and deal with similar challenges, high dimen-sional and sparse data, there are key differences between the two domains which we summarize bellow: Our goal of this work is to point out the differences be-tween the two domains and show their commonalities. Text clustering is an established area of research with a bulk of applications and an increased interest nowadays due to the web and the digitization of information. On the other hand, the subspace clustering area grows fast as high dimensional-ity comprises one of the basic features of nowadays data. A few works combine concepts from both domains and could serve as a starting point for further exchange of ideas and best practices between these domains that would be fruitful for their further development. The authors would like to thank Arthur Zimek for useful comments and suggestions to improve the quality of the pa-per. [1] C. Aggarwal, S. Gates, and P. Yu. On using par-[2] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A [3] C. C. Aggarwal, C. M. Procopiuc, J. L. Wolf, P. S. Yu, [4] C. C. Aggarwal and C. Zhai. A survey of text clustering [5] R. Agrawal, J. Gehrke, D. Gunopulos, and P. Ragha-[6] R. Agrawal and R. Srikant. Fast algorithms for mining [7] N. O. Andrews and E. A. Fox. Recent developments in [8] I. Assent. Clustering high dimensional data. Wiley In-[9] C. B  X ohm, K. Kailing, H.-P. Kriegel, and P. Kr  X oger. [10] E. Y. Chan, W. K. Ching, M. K. Ng, and J. Z. [11] J. H. Friedman and J. J. Meulman. Clustering objects [12] S. G  X unnemann, E. M  X uller, S. Raubach, and T. Seidl. [13] J. Han and M. Kamber. Data Mining: Concepts and [14] J. Z. Huang, M. K. Ng, H. Rong, and Z. Li. Auto-[15] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clus-[16] I. T. Jolliffe. Principal Component Analysis . Springer, [17] K. Kailing, H.-P. Kriegel, and P. Kr  X oger. Density-[18] H.-P. Kriegel, P. Kr  X oger, and A. Zimek. Clustering [19] H.-P. Kriegel, E. Ntoutsi, M. Spiliopoulou, [20] T. K. Landauer, D. S. McNamara, S. Dennis, and [21] E. M  X uller, S. G  X unnemann, I. Assent, and T. Seidl. Eval-[22] H. Nagesh, S. Goil, and A. Choudhary. Adaptive grids [23] L. Parsons, E. Haque, and H. Liu. Subspace clustering [24] M. F. Porter. An algorithm for suffix stripping. Pro-[25] C. M. Procopiuc, M. Jones, P. K. Agarwal, and T. M. [26] M. Radovanovic, A. Nanopoulos, and M. Ivanovic. On [27] G. Salton. Automatic Text Processing: The Trans-[28] M. Shafiei, S. Wang, R. Zhang, E. Milios, B. Tang, [29] M. Steinbach, G. Karypis, and V. Kumar. A compar-[30] Y. Yang and J. O. Pedersen. A comparative study on [31] M. Zimmermann, E. Ntoutsi, and M. Spiliopoulou. Ex-The large amount of text data which are continuously pro-duced over time in a variety of large scale applications such as social networks results in massive streams of data. Typ-ically massive text streams are created by very large scale interactions of individuals, or by structured creations of par-ticular kinds of content by dedicated organizations. An example in the latter category would be the massive text streams created by news-wire services. Such text streams provide unprecedented challenges to data mining algorithms from an efficiency perspective. In this paper, we review text stream mining algorithms for a wide variety of problems in data mining such as clustering, classification and topic modeling. A recent challenge arises in the context of social streams , which are generated by large social networks such as Twitter . We also discuss a number of future challenges in this area of research. Text streams have become ubiquitous in recent years be-cause of a wide variety of applications in social networks, news collection, and other forms of activity which result in the continuous creation of massive streams. Some specific examples of applications which create text streams are as follows: An example would be the Google News service.
 Text streams create a huge challenge from the perspective of a wide variety of mining applications, because of the massive volume of the data which must be processed in online fash-ion. Data streams have been studied extensively in recent years not just in the text domain, but also in the context of a wide variety of multi-dimensional applications such as nu-merical and categorical data. A detailed discussion of min-ing algorithms for stream data may be found in [3]. While many of the techniques proposed for multi-dimensional data [3] can be generalized to text data at the high level, the de-tails can be quite different because of the very different for-mat and lack of structure of text data. Since stream mining techniques are generally dependent upon summarization, it follows that methods for online summarization need to be designed which work well for the unstructured nature of text data.
 In the case of multi-dimensional and time-series data, such summarization often takes the form of methods such as his-tograms, wavelets, and sketches which can be used to create a structured summary of the underlying data [3]. However, the unstructured nature of text makes the use of such sum-maries quite challenging. While sketches have been used to some effect in the text domain [27], it has generally been difficult to generalize wavelet and histogram methods to the text domain. As we will see later in this section, the summa-rization methods designed for text streaming problems may vary a lot, and may often need to be tailored to the problem at hand. One of the goals of this paper is to provide a broad spectrum of the different methods which are used for text mining, which can provide an overview of the tools which can be most effectively used for the text stream scenario. We will also present the future challenges and research di-rections associated with text stream mining.
 This paper is organized as follows. In section 2, we will present a variety of the well known algorithms for cluster-ing text streams. This includes popular methods for topic detection and tracking in text stream. This is because the process of event detection is closely related to the clustering problem. The methods for classification of text streams are reviewed in section 3. Section 4 presents methods for evo-lution analysis of text stream. Social streams are discussed in section 5. The conclusions and summary are presented in section 6. The problem of clustering text streams has been widely stud-ied in the context of numerical data [3; 6; 15]. Other popular methods which have been studied in the machine learning literature include the COBWEB and CLASSIT methods [24; 29]. The COBWEB algorithm assumes nominal attributes, whereas the CLASSIT algorithm assumes real-valued at-tributes. Many of these methods [6; 15] are extensions of the k -means method as extended to the stream scenario. This trend has also been applied to the case of text streams. One of the earliest methods for streaming text clustering is discussed in [63]. This technique is referred to as the On-line Spherical k -Means Algorithm (OSKM) , which reflects the broad approach used by the methodology. This tech-niques divides up the incoming stream into small segments, each of which can be processed effectively in main mem-ory. A set of k -means iterations are applied to each such data segment to cluster them. The advantage of using a segment-wise approach for clustering is that since each seg-mentcanbeheldinmainmemory,wecanprocesseachdata point multiple times as long as it is held in main memory. In addition, the centroids from the previous segment are used in the next iteration for clustering purposes. A decay factor is introduced to age-out the old documents, so that the new documents are considered more important from a clustering perspective. This approach has been shown to be extremely effective in clustering massive text streams in [63]. The method in [63] is designed as a flat clustering algorithm, in which there is a single level to the clustering process. In many applications, it is useful to design hierarchical clus-tering algorithms in which different levels of the clustering can be explored. In the context of text data, this implies that different levels of topics and subtopics can be explored with the use of a hierarchical clustering process. A distribu-tional modeling method for hierarchical clustering of stream-ing documents has been proposed in [44]. The method ex-tends the COBWEB and CLASSIT algorithms [24; 29] to the case of text data. The work in [44] studies the different kinds of distributional assumptions of words in documents. We note that these distributional assumptions are required to adapt these algorithms to the case of text data. The ap-proach essentially changes the distributional assumption so that the method can work effectively for text data. A different method for clustering massive text and categor-ical data streams is discussed in [5]. The method discussed in [5] uses an approach which examines the relationship be-tween outliers, emerging trends, and clusters in the underly-ing data. Old clusters may become inactive, and eventually get replaced by new clusters. Similarly, when newly arriv-ing data points do not naturally fit in any particular cluster, these need to be initially classified as outliers. However, as time progresses, these new points may create a distinctive pattern of activity which can be recognized as a new cluster. The temporal locality of the data stream is manifested by these new clusters. For example, the first web page belong-ing to a particular category in a crawl may be recognized as an outlier, but may later form a cluster of documents of its own. On the other hand, the new outliers may not neces-sarily result in the formation of new clusters. Such outliers are true short-term abnormalities in the data since they do not result in the emergence of sustainable patterns. The approach discussed in [5] recognizes new clusters by first recognizing them as outliers.
 This approach works with the use of a summarization method-ology that is motivated by the micro-clustering approach proposed in [6]. While the concept of micro-clustering was designed for numerical data, it can also be extended to the case of text and categorical data streams. This methodology essentially creates summaries from the data points which are used to estimate the assignment of incoming data points to clusters. The concept of micro-clusters is generalized to that of condensed droplets in [5].
 To ensure greater importance of more recent data, a time-sensitive weightage is assigned to each data point. It is as-sumed that each data point has a time-dependent weight defined by the function f ( t ). The function f ( t )isalsore-ferred to as the fading function . The fading function f ( t ) is a non-monotonic decreasing function which decays uni-formly with time t . To formalize this concept, we will define the half-life of a point in the data stream.

Definition 2.1. The half life t 0 of a point is defined as the time at which f ( t 0 )=(1 / 2) f (0) .
 Conceptually, the aim of defining a half life is to quantify the rate of decay of the importance of each data point in the stream clustering process. The decay-rate is defined as the inverse of the half life of the data stream. We denote the decay rate by  X  =1 /t 0 . We denote the weight function of each point in the data stream by f ( t )=2  X   X   X  t .From the perspective of the clustering process, the weight of each data point is f ( t ). It is easy to see that this decay function creates a half life of 1 / X  . It is also evident that by changing the value of  X  , it is possible to change the rate at which the importance of the historical information in the data stream decays. The higher the value of  X  , the lower the importance of the historical information compared to more recent data. For more stable data streams, it is desirable to pick a smaller value of  X  , whereas for rapidly evolving data streams, it is desirable to pick a larger value of  X  .
 When a cluster is created during the streaming process by a newly arriving data point, it is allowed to remain as a trend-setting outlier for at least one half-life. During that period, if at least one more data point arrives, then the cluster becomes an active and mature cluster. On the other hand, if no new points arrive during a half-life, then the trend-setting outlier is recognized as a true anomaly in the data stream. At this point, this anomaly is removed from the list of current clusters. We refer to the process of removal as cluster death . Thus, a new cluster containing one data point dies when the (weighted) number of points in the cluster is 0 . 5. The same criterion is used to define the death of mature clusters. A necessary condition for this criterion to be met is that the inactivity period in the cluster has exceeded the half life 1 / X  . The greater the number of points in the cluster, the greater the level by which the inactivity period would need to exceed its half life to meet the criterion. This is a natural solution, since it is intuitively desirable to have stronger requirements (a longer inactivity period) for the death of a cluster containing a larger number of points. Next, we describe the process of creation of a condensed-droplet from the underlying text stream. An important point to remember is that a text data set can be treated as a sparse numeric data set. This is because most docu-ments contain only a small fraction of the vocabulary with non-zero frequency. For a cluster of documents C at time t , we denote the corresponding condensed droplet by D ( t, C
Definition 2.2. A cluster droplet D ( t, C ) for a set of text Each tuple component is defined as follows: The concept of cluster droplet has some interesting prop-erties that will be useful during the maintenance process. These properties relate to the additivity and decay behavior of the cluster droplet.

Observation 2.1. Consider the cluster droplets D ( t, C 1 ( DF 2 1 , DF 1 1 ,n 1 ,w ( t ) 1 ,l 1 ) and D ( t, C 2 )= ( DF 2 2 , DF 1 2 ,n 2 ,w ( t ) 2 ,l 2 ) . Then the cluster droplet C ) is defined by the tuple ( DF 2 1 + DF 2 2 , DF 1 1 + DF 1 n ,w ( t ) 1 + w ( t ) 2 , max { l 1 ,l 2 } ) .
 The cluster droplet for the union of two clusters is the sum of individual entries. The only exception is the last entry which is the maxima of the two last-update times. We note that the additivity property provides considerable convenience for data stream processing since the entries can be updated efficiently using simple additive operations.
 The second observation relates to the rate of decay of the condensed droplets. Since the weights of each data point decay with the passage of time, the corresponding entries also decay at the same rate. Correspondingly, we make the following observation:
Observation 2.2. Consider the cluster droplet D ( t, C )= ( DF 2 , DF 1 ,n,w ( t ) ,l ) . Then the entries of the same cluster droplet C at a time t &gt;t are given by D ( t , C )=( DF 2 2 The second observation is critical in regulating the rate at which the cluster droplets are updated during the clustering process. Since all cluster droplets decay at essentially the same rate (unless new data points are added), it follows that it is not necessary to update the decay statistics at each time stamp. Rather, each cluster droplet can be updated lazily, whenever new data points are added to it.
 The overall algorithm proceeds as follows. At the begin-ning of algorithmic execution, we start with an empty set of clusters. As new data points arrive, unit clusters contain-ing individual data points are created. Once a maximum number k of such clusters have been created, we can begin the process of online cluster maintenance. Thus, we initially start off with a trivial set of k clusters. These clusters are updated over time with the arrival of new data points. When a new data point X arrives, its similarity to each cluster droplet is computed. In the case of text data sets, the cosine similarity measure [21; 47] between DF 1and X is used. The similarity value S ( X, C j ) is computed from the incoming document X to every cluster C j . The cluster with the maximum value of S ( X, C j )ischosenastherelevant cluster for data insertion. Let us assume that this cluster is C mindex . We use a threshold denoted by thresh to determine whether the incoming data point is an outlier. If the value of S ( X, C mindex ) is larger than the threshold thresh ,then the point X is assigned to the cluster C mindex .Otherwise, we check if some inactive cluster exists in the current set of cluster droplets. If no such inactive cluster exists, then the data point X is added to C mindex . On the other hand, when an inactive cluster does exist, a new cluster is created containing the solitary data point X .Thisnewlycreated cluster replaces the inactive cluster. We note that this new cluster is a potential true outlier or the beginning of a new trend of data points. Further understanding of this new cluster may only be obtained with the progress of the data stream.
 In the event that X is inserted into the cluster C mindex need to perform two steps: In the event that the newly arriving data point does not naturally fit in any of the cluster droplets and an inactive cluster does exist, then we replace the most inactive cluster by a new cluster containing the solitary data point X .In particular, the replaced cluster is the least recently updated cluster among all inactive clusters. This process is contin-uously performed over the life of the data stream, as new documents arrive over time. The work in [5] also presents a variety of other applications of the stream clustering tech-nique such as evolution and correlation analysis.
 A different way of utilizing the temporal evolution of text documents in the clustering process is described in [30]. Specifically, the work in [30] uses bursty features as mark-ers of new topic occurrences in the data stream. This is because the semantics of an up-and-coming topic are often reflected in the frequent presence of a few distinctive words in the text stream. A specific example illustrates the bursty features in two topics corresponding to the two topics of  X  X S Mid-Term Elections X  and  X  X ewt Gingrich resigns from House X  respectively. The corresponding bursty features [30] which occurred frequently in the newsstream during the pe-riod for these topics were as follows: US Mid-term Elections (Nov. 3, 1998 burst): election, voters, Gingrich, president, Newt, ...
 Newt Gingrich resigns from house (Nov 6, 1998 burst): House, Gingrich, Newt, president, Washington ...
 It is evident that at a given period in time, the nature of relevant topics could lead to bursts in specific features of the data stream. Clearly, such features are extremely important from a clustering perspective. Therefore, the method dis-cussed in [30] uses a new representation, which is referred to as the bursty feature representation for mining text streams. In this representation, a time-varying weight is associated with the features depending upon its burstiness. This also reflects the varying importance of the feature to the clus-tering process. Thus, it is important to remember that a particular document representation is dependent upon the particular instant in time at which it is constructed. Another issue which is handled effectively in this approach is an implicit reduction in dimensionality of the underlying collection. Text is inherently a high dimensional data do-main, and the pre-selection of some of the features on the basis of their burstiness can be a natural way to reduce the dimensionality of document representation. This can help in both the effectiveness and efficiency of the underlying al-gorithm.
 The first step in the process is to identify the bursty fea-tures in the data stream. To achieve this goal, the approach uses Kleinberg X  X  2-state finite automaton model [31]. Once these features have been identified, the bursty features are associated with weights which depend upon their level of burstiness. Subsequently, a bursty feature representation is defined to reflect the underlying weight of the feature. Both the identification and the weight of the bursty feature are de-pendent upon its underlying frequency. A standard k -means approach is applied to the new representation to construct the clustering. It was shown in [30] that the approach of us-ing burstiness improves the cluster quality. Once criticism of the work in [30] is that it is mostly focussed on the issue of improving effectiveness with the use of temporal charac-teristics of the data stream, and does not address the issue of efficient clustering of the underlying data stream. In general, it is evident that feature extraction is important for all clustering algorithms. While the work in [30] focusses on using temporal characteristics of the stream for feature extraction, the work in [37] focusses on using phrase extrac-tion for effective feature selection. This work is also related to the concept of topic-modeling, which will be discussed somewhat later. This is because the different topics in a collection can be related to the clusters in a collection. The work in [37] uses topic-modeling techniques for clustering. The core idea in the work of [37] is that individual words are not very effective for a clustering algorithm because they miss the context in which the word is used. For example, the word  X  X tar X  may either refer to a celestial body or to an entertainer. On the other hand, when the phrase  X  X ixed star X  is used, it becomes evident that the word  X  X tar X  refers to a celestial body. The phrases which are extracted from the collection are also referred to as topic signatures . The use of such phrasal clarification for improving the qual-ity of the clustering is referred to as semantic smoothing because it reduces the noise which is associated with se-mantic ambiguity. Therefore, a key part of the approach is to extract phrases from the underlying data stream. After phrase extraction, the training process determines a trans-lation probability of the phrase to terms in the vocabulary. For example, the word  X  X lanet X  may have high probability of association with the phrase  X  X ixed star X , because both re-fer to celestial bodies. Therefore, for a given document, a rational probability count may also be assigned to all terms. For each document, it is assumed that all terms in it are gen-erated either by a topic-signature model, or a background collection model.
 The approach in [37] works by modeling the soft probability p ( w | C j )forword w and cluster C j . The probability p ( w is modeled as a linear combination of two factors; (a) A max-imum likelihood model which computes the probabilities of generating specific words for each cluster (b) An indirect (translated) word-membership probability which first deter-mines the maximum likelihood probability for each topic-signature, and then multiplying with the conditional proba-bility of each word, given the topic-signature. We note that we can use p ( w | C j )toestimate p ( d | C j ) by using the product of the constituent words in the document. For this purpose, we use the frequency f ( w, d )ofword w in document d . We note that in the static case, it is also possible to add a background model to improve the robustness of the estima-tion process. This is however not possible in a data stream because of the fact that the background collection model may require multiple passes to build effectively. The work in [37] maintains these probabilities in online fashion with the use of a cluster profile , that weights the probabilities with the use of a fading function. We note that the concept of cluster profile is analogous to the concept of condensed droplet introduced in [5]. The key algorithm (denoted by OCTS) is to maintain a dynamic set of clusters into which documents are progressively assigned with the use of similar-ity computations. It has been shown in [37] how the cluster profile can be used to efficiently compute p ( d | C j )foreachin-coming document. This value is then used to determine the similarity of the documents to the different clusters. This is used to assign the documents to their closest cluster. We note that the methods in [5; 37] share a number of simi-larities in terms of (a) maintenance of cluster profiles, and (b) use of cluster profiles (or condensed droplets) to com-pute similarity and assignment of documents to most similar clusters. (c) The rules used to decide when a new singleton cluster should be created, or one of the older clusters should be replaced.
 The main difference between the two algorithms is the tech-nique which is used to compute cluster similarity. The OCTS algorithm uses the probabilistic computation p ( d | C j )tocom-pute cluster similarity, which takes the phrasal information into account during the computation process. One obser-vation about OCTS is that it may allow for very similar clusters to co-exist in the current set. This reduces the space available for distinct cluster profiles. A second al-gorithm called OCTSM is also proposed in [37] that allows for merging of very similar clusters. Before each assignment, it checks whether pairs of similar clusters can be merged on the basis of similarity. If this is the case, then we allow the merging of the similar clusters and their corresponding clus-ter profiles. Detailed experimental results on the different clustering algorithms and their effectiveness are presented in [37].
 Another method [49] uses a combination of a spectral par-titioning and probabilistic modeling method for novelty de-tection and topic tracking. This approach uses a HITS-like spectral technique within a probabilistic framework. The probabilistic part is an unsupervised boosting method that is closer to semi-parametric maximum likelihood methods. A closely related area to clustering is that of topic model-ing, which is a problem closely related to that of clustering. In the problem of topic modeling, we perform a soft clus-tering of the data in which each document has a member-ship probability to one of a universe of topics rather than a deterministic membership. A variety of mixture modeling techniques can be used to determine the topics from the un-derlying data. Recently, the method has also been extended to the dynamic case which is helpful for topic modeling of text streams [13]. A closely related topic is that of topic detection and tracking , which is discussed below. Recently, a variety of methods for maintaining topic mod-els in a streaming scenario have been proposed in [58]. The work evaluates a number of different methods for adapt-ing topic models to the streaming scenario. These include methods such as Gibbs sampling and variational inference. In addition, a method is also proposed that is based on text classification. The latter has the advantage of requiring only a single matrix multiplication, and is therefore much more efficient. A method called SparseLDA is proposed that is an effective method for evaluating Gibbs sampling distribu-tions. The results in [58] show that this method is 20 times faster than traditional LDA.
 In some applications, it is desirable to have clusters of ap-proximately balanced size, in which a particular cluster is not significantly larger than the others. A competitive on-line learning for determining such balanced clusters have been proposed in [11]. The essential approach in [11] is to design a model in which it is harder for new data points to join larger clusters. This is achieved by penalizing the im-balance into the objective function criterion. It was shown in [11] that such an approach can determine well balanced clusters. A closely related problem to clustering is that of topic de-tection and tracking [7; 14; 28; 55; 56; 60]. In this prob-lem, we create unsupervised clusters from a text stream, and then determine the sets of clusters which match real events. These real events may correspond to documents which are identified by a human. Since the problem of online topic detection is closely related to that of clustering, we will dis-cuss this problem as a subsection of our broader discussion on clustering, though not all methods for topic detection use clustering techniques. In this subsection, we will discuss all the methods for topic detection, whether they use clustering or not.
 The earliest work on topic detection and tracking was per-formed in [7; 56]. The work arose out of a DARPA initiative [64] which formally defined this problem and proposed the initial set of algorithms for the task. An interesting tech-nique in [56] designs methods which can be used for both retrospective and online topic tracking and detection. In ret-rospective event detection, we create groups from a corpus of documents (or stories), and each group corresponds to an event. The online version is applicable to the case of data streams, and in this case, we process documents sequentially to determine whether an incoming document corresponds to a new event. An online clustering algorithm can also be used to track the different events in the data in the form of clusters. For each incoming document X we compute its similarity to the last m documents Y t  X  1 ... Y t  X  m .Thescore for the incoming document X is computed as follows: A document is considered novel, when its score is above a pre-defined threshold. In addition, a decay-weighted version is designed in which the weight of documents depends upon its recency. The idea here is that a document is considered to be a new event when the last occurrence of a similar document did not occur recently  X  X nough X . In this case, the corresponding score is designed as follows: We note that each Y i need not necessarily represent a sin-gle document, but may also represent a cluster or a larger grouping. We also note that the method for detecting a new event can be combined with a cluster tracking task. This is because the determination of a new event is indicative of a new event (or singleton cluster) in the data.
 The work in [7] addressed the problem of new event detec-tion by examining the relationship of a current document to the previous documents in the data. The key idea is to use feature extraction and selection techniques to design a query representation of the document content. We determine the query X  X  initial threshold by comparing the document con-tent with the query, and set it as the triggering threshold. Then, we determine if the document triggers any queries from the previous documents in the collection. If no queries are triggered, then the document is deemed to be a new event. Otherwise, this document is not a new event. One general observation about the online topic detection and tracking problem [8; 57] is that this problem is quite hard in general, and the performance of first event detec-tion can degrade under a variety of scenarios. To improve the effectiveness of first event detection, the work in [57] proposes to use the training data of old events to learn use-ful statistics for the prediction of new events. The broad approach in [57] contains the following components: Clearly such an approach has the tradeoff that it requires prior knowledge about the collection in the form of training data, but provides better accuracy. More details on the approach may be found in [57].
 A method proposed in [14] is quite similar to that proposed in [56], except that it proposes a number of improvements in how the tf X  X df model is incrementally maintained for com-putation of similarity. For example, a source-specific tf X  X df model is maintained in which the statistics are specific to each news source. Similarly, the approach normalizes for the fact that documents which come from the same source tend to have a higher similarity because of the vocabulary conventions which are often used in the similarity compu-tation. To achieve this goal, the approach computes the average similarity between the documents from a particular pair of sources and subtracts this average value while com-puting the similarity between a pair of documents for the purpose of new event detection. A number of other tech-niques for improving the quality of event detection (such as using inverse event frequencies) are discussed in [14]. A method for online topic detection and tracking is presented in [60] as an application of stream clustering. This work uses a probabilistic LDA model to create an online model for estimating the growing number of clusters. The general approach in this work is similar to the concepts already pro-posed in [56]. The main novelty of the work is the design of an online approach for probabilistic clustering.
 Another method for fast and parameter-free bursty event detectionisproposedin[28]. Thisapproachfocusseson finding bursty features which characterize the presence of an event. In order to achieve this goal, the technique in [28] proposes a feature-pivot clustering that groups features on the basis of bursty co-occurrence. The approach is de-signed to be parameter-free, which gives it an advantage in a number of scenarios.
 The problem of event detection has also been studied with the use of keyword graphs in [46]. The work in [46] builds a keywords graph from a text stream in which a node corre-sponds to a keyword, and an edge is added to the keyword graphs when a pair of words occur together in the document. Events are characterized as communities of keywords in this network. This broad approach is used in the context of a window-based technique for the case of social streams. In the context of social network streams, a natural question arises, as to whether one can use any of the social dimen-sions of the underlying stream to improve the underlying event detection process. Such an approach has been pro-posed in [62], in which events are determined by combin-ing text clustering, social network structure clustering, and temporal segmentation. In addition, a multi-dimensional visualization tool is provided, which discusses ways of visu-alizing the relationships between the events along the three dimensions. In this case, an event is defined as a set of text documents which are semantically coherent, and are structurally well connected both in terms of social network structure and time. These three different characteristics are used in the following ways: Another method [43] has been proposed in the context of the Twitter social network data set. In this paper, a local-ity sensitive hashing method (LSH) is used to keep track of the different documents. The idea in LSH [17] is to use a hashing scheme in which the probability of hashing two documents into the same bucket is proportional to the co-sine of the angle between the two documents. For a given query document, we check all the documents in the same bucket, and then perform the similarity calculation explic-itly with all documents in the same bucket. The closest document is returned as the nearest neighbor. We note that the problem of first-story detection can be considered an application of repeated nearest neighbor querying in which an incoming document is comp ared to the previously seen documents from the data stream. While LSH can be used directly in conjunction with a nearest neighbor search for first story detection, such an approach typically leads to poor results. This is because LSH works effectively only if the true nearest neighbor is close to the query point. Oth-erwise, such an approach is unable to find the true nearest neighbor. Therefore, the approach in [43] uses the strategy of using LSH only for declaring a document to be sufficiently new on an aggregate basis. For such cases, the document is compared against a fixed number of the most recent doc-uments. In the event that the corresponding distance is above a given threshold, we can declare the underlying story as novel. The main advantage of this technique over many of the aforementioned techniques is that of speed ,whichis especially important, when dealing with social streams of very high volume. This speed is achieved because of the use of the LSH technique, though there is some loss in accu-racy because of the approximation process. This technique was compared [43] against the UMass system [9], and it was found that more than an order of magnitude improvement in speed was obtained with only a minor loss in accuracy. Most of the work in text stream mining and topic detec-tion is performed in the context of a single news stream .In many cases, we have multiple text streams [53], which are indexed by the same set of time points (called coordinated text streams). For example, when a major event happens, all the news articles published by different agencies in dif-ferent languages cover the same event in that period. This is referred to as a correlated bursty topic pattern in the dif-ferent news article streams. In some cases, when the cor-related streams are multi-lingual, they may even have com-pletely different vocabulary. The discovery of bursty topic patterns can determine the interesting events and associa-tions between different streams. Such an approach can also determine interesting local and stream-specific patterns by factoring out the global noise which is common to the dif-ferent streams.
 To achieve this goal, the technique in [53] aligns the text samples from different streams on the basis of the shared time-stamps. This is used to discover topics from multi-ple streams simultaneously with a single probabilistic mix-ture model. The approach of constructing independent topic models from different streams is that the topic models from the different streams may not match each other very well, or at least, create a challenge in matching the different topic models, if it is done at the end of the process of model con-struction. Therefore, it is important to make the mixture models for the different streams communicate with one an-other during the modeling process, so that a single mixture model is constructed across the different streams. To achieve this goal, the stream samples at a given point are merged to-gether, while keeping the stream identities. To achieve this, we align the topic models from different streams while keep-ing their identities. While the topic models from different streams are separate, the global mixture model is designed for the overall text stream sample. Such a mixture model is coordinated, because it would emphasize topics which tend to occur across multiple streams. Once the coordinated mix-ture model is obtained, the topical models for the different streams can be extracted by fitting the mixture model to the different streams. As the topic models for the differ-ent streams ate aligned with one another, we can obtained a correlated bursty topic pattern, when the corresponding topic is bursty during the same period. A key aspect of this approach is that it does not require the different streams to share vocabulary. Rather it is assumed the topics involved in a correlated bursty topic pattern tend to have the same distribution across streams, and this can be used to match topics from different streams. More details on the approach may be found in [53]. Methods for clustering text streams can be used for novelty detection, as illustrated in [5; 60]. In all these methods, the formation of a new cluster corresponds to a new pat-tern in the underlying data. This represents a novelty with respect to the previous history of the stream. Eventually, this novelty may become a normal pattern, as more data points are added to this cluster. This cluster therefore rep-resents a sudden change in the nature of the data stream, such as a newsworthy event or other cluster. In other cases, the novelty may be isolated, and may not turn into a new pattern. This issue has been discussed in detail in [5]. Such an approach for detecting novelties is not specific to the text domain, but can also be used for other data domains. The problem of classification of data streams has been widely studied by the data mining community in the context of dif-ferent kinds of data [3; 4; 52; 59]. Many of the methods for classifying numerical data can be easily extended to the case of text data, just as the numerical clustering method in [6] has been extended to a text clustering method in [5]. In particular, the classification method of [4] can be extended to the text domain, by adapting the concept of numerical micro-clusters to condensed droplets as discussed in [5]. With the use of the condensed droplet data struc-ture, it is possible to extend all the methods discussed in [4] to the text stream scenario. Similarly, the core idea in [52] uses an ensemble based approach on chunks of the data stream. This broad approach is essentially a meta-algorithm which is not too dependent upon the specifics of the under-lying data format. Therefore, the broad method can also be easily extended to the case of text streams.
 The problem of text stream classification arises in the con-text of a number of different IR tasks. The most important of these is news filtering [34], in which it is desirable to au-tomatically assign incoming documents to pre-defined cate-gories. A second application is that of email spam filtering [10], in which it is desirable to determine whether incoming email messages are spam or not. We note that the problem of text stream classification can arise in two different con-texts, depending upon whether the training or the test data arrives in the form of a stream: The first scenario is usually easy to handle, because most classifier models are compact and classify individual test in-stances efficiently. On the other hand, in the second sce-nario, the training model needs to be constantly updated to account for changes in the patterns of the underlying train-ing data. The easiest approach to such a problem is to incor-porate temporal decay factors into model construction algo-rithms, so as to age out the old data. This ensures that the new (and more timely data) is weighted more significantly in the classification model. An interesting technique along this direction has been proposed in [45], in which a tempo-ral weighting factor is introduced to modify the classification algorithms. Specifically, the approach has been applied to the Naive Bayes, Rocchio, and k -nearest neighbor classifica-tion algorithms. It has been shown that the incorporation of temporal weighting factors is useful in improving the classi-fication accuracy, when the underlying data is evolving over time.
 A number of methods have also been designed specifically for the case of text streams. In particular, the method dis-cussed in [27] studies methods for classifying text streams in which the classification model may evolve over time. This problem has been studied extensively in the literature in the context of multi-dimensional data streams [4; 52]. For ex-ample, in a spam filtering application, a user may generally delete the spam emails for a particular topic, such as those corresponding to political advertisements. However, in a particular period such as the presidential elections, the user may be interested in the emails for that topic, it may not be appropriate to continue to classify that email as spam. The work in [27] looks at the particular problem of classifi-cation in the context of user-interests. In this problem, the label of a document is considered either interesting or non-interesting . To achieve this goal, the work in [27] maintains the interesting and non-interesting topics in a text stream together with the evolution of the theme of the interest-ing topics. A document collection is classified into multiple topics, each of which is labeled either interesting or non-interesting at a given point. A concept refers to the main theme of interesting topics. A concept drift refers to the fact that the main theme of the interesting topic has changed. The main goals of the work are to maximize the accuracy of classification and minimize the cost of re-classification. To achieve this goal, the method in [27] designs methods for de-tecting both concept drift as well as model adaptation .The former refers to the change in the theme of user-interests, whereas the latter refers to the detection of brand new con-cepts. To detect concept drifts, the method in [27] measures the classification error-rates in the data stream in terms of true and false positives. When the stream evolves, these error rates will increase, if the change in the concepts are not detection. To determine the change in concepts, tech-niques from statistical quality control are used, in which we determine the mean  X  and standard deviation  X  of the error rates, and determine whether this error rate remains within a particular tolerance which is [  X   X  k  X   X ,  X  + k  X   X  ]. Here the tolerance is regulated by the parameter k . When the error rate changes, we determine when the concepts should be dropped or included. In addition, the drift rate is mea-sured to determine the rate at which the concepts should be changed for classification purposes. In addition, methods for dynamic construction and removal of sketches are discussed in [27].
 Another related work is that of one-class classification of text streams [61], in which only training data for the posi-tive class is available, but there is no training data available for the negative class. This is quite common in many real applications in which it easy to find representative docu-ments for a particular topic, but it is hard to find the rep-resentative documents to model the background collection. The method works by designing an ensemble of classifiers in which some of the classifiers corresponds to a recent model, whereas others correspond to a long-term model. This is done to incorporate the fact that the classification should be performed with a combination of short-term and long-term trends.
 A rule-based technique that can learn classifiers incremen-tally from data streams is the sleeping-experts systems [19; 25]. One characteristic of this rule-based system is that it uses the position of the words in generating the classifica-tion rules. Typically, the rules correspond to sets of words which are placed close together in a given text document. These sets of words are related to a class label. For a given test document, it is determined whether these sets of words occur in the document, and are used for classification. This system essentially learns a set of rules (or sleeping experts) that can be updated incrementally by the system. While the technique was proposed prior to the advent of data stream technology, its online nature ensures that it can be effec-tively used for the stream scenario.
 One of the classes of methods which can be easily adapted to stream classification is the broad category of neural net-works [48; 54]. This is because neural networks are essen-tially designed as a classification model with a network of perceptrons and corresponding weights associated with the term-class pairs. Such an incremental update process can be naturally adapted to the streaming context. These weights are incrementally learned as new examples arrive. The first neural network methods for online learning were proposed in [48; 54]. In these methods, the classifier starts off by setting all the weights in the neural network to the same value. The incoming training example is classified with the neural net-work. In the event that the result of the classification process is correct, then the weights are not modified. On the other hand, if the classification is incorrect, then the weights for the terms are either increased or decreased depending upon which class the training example belongs to. Specifically, if class to which the training example belongs is a positive in-stance, the weights of the corresponding terms (in the train-ing document) are increased by  X  .Otherwise,theweightsof these terms are reduced by  X  .Thevalueof  X  is also known as the learning rate . Many other variations are possible in terms of how the weights may be modified. For example, the method in [22] uses a multiplicative update rule, in which two multiplicative constants  X  1 &gt; 1and  X  2 &lt; 1areused for the classification process. The weights are multiplied by  X  1 , when the example belongs to the positive class, and is multiplied by  X  2 otherwise. Another variation [35] also allows the modification of weights, when the classification process is correct. A number of other online neural network methods for text classification (together with background on the topic) may be found in [20; 26; 40; 42]. A Bayesian method for classification of text streams is discussed in [16]. The method in [16] constructs a Bayesian model of the text which can be used for online classification. The key compo-nents of this approach are the design of a Bayesian online perceptron and a Bayesian online Gaussian process that can be used effectively for online learning. A key problem in the case of text is to determine evolution-ary patterns in temporal text streams. An early survey on the topic of evolution analysis in text streams may be found in [32]. Such evolutionary patterns can be very useful in a wide variety of applications, such as summarizing events in news articles and revealing research trends in the scientific literature. For example, an event may have a life cycle in the underlying theme patterns such as the beginning, duration, and end of a particular event. Similarly, the evolution of a particular topic in the research literature may have a life-cycle in terms of how the different topics affect one another. This problem was defined in [38], and contains three main parts: (a) Discovering the themes in text; (b) creating an evolution graph of themes; and (c) studying the life cycle of themes.
 A theme is defined as a semantically related set of words, with a corresponding probability distribution that coher-ently represents a particular topic or sub-topic. This corre-sponds to a model that is represented by  X  .The span of such a theme represents the starting and end point of the corre-sponding theme in terms of the time-interval ( s, t ). Thus, the theme span is denoted by the triple  X  =(  X ,s,t ). As time passes, a particular theme  X  1 may perform a transition into another theme  X  2 .Atheme  X  1 is said to have evolved into another theme  X  2 , if there is sufficient similarity be-tween their corresponding spans. It is possible to create a theme evolution graph G =( N,A ), in which each node in N corresponds to a theme, and each edge in A corresponds to a transition between two themes. The overall approach requires three steps: In addition, a method is proposed in [38] for analyzing the entire theme life cycle by measuring the strength of the theme over different periods. A method based on HMM is proposed to measure the theme-shifts over the entire period as well.
 The problem of tracking new topics, ideas, and memes across the Web has been studied in [33]. This problem is related to that of the topic detection and tracking discussed ear-lier. However, the rate of evolution in the web and blog scenario is significantly greater than the models which have been discussed in earlier work. In the context of the web and social networks, the content spreads widely and then fades over time scales on the order of days. The work is [33] develops a framework for tracking short, distinctive phrases that persistently appear in on-line text over time. In addi-tion, scalable algorithms were proposed for clustering tex-tual variants of such phrases. In addition, the approach is able to perform local analysis for specific threads. This in-cludes the determination of peak intensity and the rise and decay in the intensity of specific threads. The relationship between the news cycle and blogs is examined in terms of how events propagate from one to the other, and the corre-sponding time-lag for the propagation process. In the next section, the notion of social streams is discussed, which are often used in the context of online analysis. In recent years, large networks such as Facebook and Twitter have produced massive streams that can be analyzed for a wide variety of insights [1; 39; 46]. Such streams are referred to as social streams . Social streams are particularly rich in terms of the amount of content that they can produce over time. Typically, the kind of data that can be tracked in such streams is massive, and can evolve over time. According to the official Twitter blog, the average number of tweets sent per day was 140 million in 2011, which was around 1620 tweets per second. Analogously, there are about 2 million new friend requests and 2 million messages sent every 20 minutes in Facebook . Clearly, the analysis of data on such a scale poses numerous challenges that are unique in streaming text analysis. 1. The data often contains structural information, such as 2. Text stream is usually quite noisy, and the documents 3. The patterns in the data may evolve significantly over The analysis of social streams are important applications to key problems such as event detection [1; 46]. Many im-portant news stories are often presented in social media, long before they appear in traditional news media. Unfor-tunately, the information in social media is untrustworthy, and noisy and methods are required to analyze the trust-worthiness of the data in streaming fashion [51].
 Recently, a significant amount of work has been performed in the social streaming scenario. These pieces of work are as follows. 1. The problem of event detection has been studied in [1; 2. The work in [36] shows how online topic analysis may 3. The problem of performing recommendations in so-4. The problem of topic-based browsing of social text 5. The problem of influence analysis in social streams has A survey from the perspective of network data may be found in [2], though the notion of content-centered analysis is some-what different from network-centered analysis. Neverthe-less, a section of this survey discusses how evolving content streams arise in the context of dynamic and evolving net-works. The area of social streams is still in its infancy and a significant scope exists in designing methods for different kinds of social streaming applications. This will be discussed in the next section. This paper studies the problem of mining text streams. The challenge in the case of text stream arises because of its tem-poral and dynamic nature in which the patterns and trends of the stream may vary rapidly over time. The determina-tion of the changes in the underlying patterns and trends is very useful in the context of a wide variety of applications. A variety of problems in text stream mining are examined such as clustering, classification, evolution analysis, and event de-tection. In addition, we studied the applications of some of these techniques in the context of new applications such as social networks. A lot of interesting avenues for research remain in the context of social media analytics, and the use of social dimensions to enhance text stream mining. In particular, the incorporation of network structure into the mining of social streams such as Twitter remains a relatively unexplored area, which can be a fruitful avenue for future research. [1] C. C. Aggarwal, and K Subbian. Event Detection in [2] C. C. Aggarwal, and K. Subbian. Evo lutionary Net-[3] C. C. Aggarwal. Data Streams: Models and Algo-[4] C. C. Aggarwal, J. Han, J. Wang, P. Yu. On Demand [5] C. C. Aggarwal, P. S. Yu. On Clustering Massive Text [6] C. C. Aggarwal, J. Han. J. Wang, P. Yu. A Framework [7] J. Allan, R. Papka, V. Lavrenko. On-line new event [8] J. Allan, V. Lavrenko, H. Jin. First story detection in [9] J. Allan, V. Lavrenko, D. Malin, R. Swan. Detections, [10] I. Androutsopoulos, J. Koutsias, K. V. Chandrinos, C. [11] A. Banerjee, J. Ghosh. Competitive learning mecha-[12] M. S. Bernstein, B. Suh, L. Hong, J. Chen, S. Kairam, [13] D. Blei, J. Lafferty. Dynamic topic models. ICML Con-[14] T. Brants, F. Chen, A. Farahat. A system for new event [15] L. O X  X allaghan, A. Meyerson, R. Motwani, N. Mishra, [16] K. Chai, H. Ng, H. Chiu. Bayesian Online Classifiers for [17] M. Charikar. Similarity Estimation Techniques from [18] J. Chen, R. Nairn, and E. Chi. Speak little and well: [19] W. Cohen, Y. Singer. Context-sensitive learning meth-[20] K. Crammer, Y. Singer. A New Family of Online Algo-[21] D. Cutting, D. Karger, J. Pedersen, J. Tukey. Scat-[22] I. Dagan, Y. Karov, D. Roth. Mistake-driven learning [23]A.P.Dempster,N.M.Laird,D.B.Rubin.Maximum [24] D. Fisher. Knowledge Acquisition via incremental con-[25] Y. Freund, R. Schapire, Y. Singer, M. Warmuth. Using [26] Y. Freund, R. Schapire. Large Margin Classification us-[27] G.P.C.Fung,J.X.Yu,H.Lu.Classifyingtextstreams [28] G. P. C. Fung, J. X. Yu, P. Yu, H. Lu. Parameter Free [29] J. H. Gennari, P. Langley, D. Fisher. Models of incre-[30] Q. He, K. Chang, E.-P. Lim, J. Zhang. Bursty feature [31] J. Kleinberg, Bursty and hierarchical structure in [32] A. Kontostathis, L. Galitsky, W. M. Pottenger, S. Roy, [33] J. Leskovec, L. Backstrom, J. Kleinberg. Meme Track-[34] D. Lewis. The TREC-4 filtering track: description and [35] D. Lewis, R. E. Schapire, J. P. Callan, R. Papka. Train-[36] J. Lin, R. Snow, and W. Morgan. Smoothing techniques [37] Y.-B. Liu, J.-R. Cai, J. Yin, A. W.-C. Fu. Clustering [38] Q. Mei, C.-X. Zhai. Discovering Evolutionary Theme [39] M. Naaman, J. Boase, and C. H. Lai. Is it really about [40]H.T.Ng,W.B.Goh,K.L.Low.Featureselection, [41] A. Ritter, O. Etzioni, and S. Clark. Open domain event [42] F. Rosenblatt. The perceptron: A probabilistic model [43] S. Petrovic, M. Osborne, V. Lavrenko. Streaming First [44] N. Sahoo, J. Callan, R. Krishnan, G. Duncan, R. Pad-[45] T. Salles, L. Rocha, G. Pappa, G. Mourao, W. Meira [46] H. Sayyadi, M. Hurst, A. Maykov. Event Detection in [47] H. Schutze, C. Silverstein. Projections for Efficient Doc-[48] H. Schutze, D. Hull, J. Pedersen. A comparison of clas-[49] A. Surendran, S. Sra. Incremental Aspect Models for [50] K. Subbi an, C. Aggarwal and J. Srivastava. Content-[51] D. Wang, T. Abdelzaher, L. Kaplan, and C. Aggarwal. [52] H. Wang, W. Fan, P. Yu, J. Han, Mining Concept-[53] X. Wang, C.-X. Zhai, X. Hu, R. Sproat. Mining Cor-[54] E. Wiener, J. O. Pedersen, A. S. Weigend. A Neural [55] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B. T. [56] Y. Yang, T. Pierce, J. Carbonell. A study on retrospec-[57 ] Y.Yang, J. Carbonell, C. Jin. Topic-conditioned Nov-[58] L. Yao, D. Mimno, A. McCallum. Efficient methods for [59] K. L. Yu, W. Lam. A new on-line learning algorithm for [60] J. Zhang, Z. Ghahramani, Y. Yang. A probabilistic [61] Y. Zhang, X. Li, M. Orlowska. One Class Classification [62] Q. Zhao, P. Mitra. Event Detection and Visualization [63] S. Zhong. Efficient Streaming Text Clustering. Neural [64] http://projects.ldc.upenn.edu/TDT/ The increasing popularity of social media encourages more and more users to participate in various online activities and produces data in an unprecedented rate. Social me-dia data is big, linked, noisy, highly unstructured and in-complete, and differs from data in traditional data mining, which cultivates a new research field -social media mining. Social theories from social sciences are helpful to explain so-cial phenomena. The scale and properties of social media data are very different from these of data social sciences use to develop social theories. As a new type of social data, social media data has a fundamental question -can we ap-ply social theories to social media data? Recent advances in computer science provide necessary computational tools and techniques for us to verify social theories on large-scale so-cial media data. Social theories have been applied to mining social media. In this article, we review some key social theo-ries in mining social media, their verification approaches, in-teresting findings, and state-of-the-art algorithms. We also discuss some future directions in this active area of mining social media with social theories. Social media greatly enables people to participate in online activities and shatters the barrier for online users to share and consume information in any place at any time. So-cial media users can be both passive content consumers and active content producers, and generate data at an unprece-dented rate. The nature of social media determines that its data significantly differs from the data in traditional data mining. Social relations are pervasively available in social media data, and play important roles in social media such as mitigating information overload problem [38; 51] and pro-moting the information propagation process [4; 67]. Social media data is big, noisy, incomplete, highly unstruc-tured and linked with social relations. These unique proper-ties of social media data suggest that naively applying exist-ing techniques may fail or lead to inappropriate understand-ings about the data. For example, social media data is linked via social relations and contradicts with the underlying in-dependent and identically distributed (IID) assumption of the vast majority of existing techniques [23; 57]. This new type of data calls for novel data mining techniques for a bet-ter understanding from the computational perspective. The study and development of these new techniques are under the purview of social media mining, which is the process of representing, analyzing, and extracting actionable patterns from s ocial media data [70].
 There are many social theories developed from social sci-ences to explain various types of social phenomena. For example, the homophily theory [40] suggests how individ-uals connect to each other, while balance theory suggests that users in a social network tend to form into a balanced network structure [17]. The scale of the data social scien-tists employ to develop these social theories is very different from that of social media data. It is easy for social me-dia data to include the actions and interactions of hundreds of millions of individuals in real time as well as over time. Therefore there is a fundamental question for this new type of social data -can we apply some social theories to social media data? . If we can apply social theories to social me-dia data, social theories can help us understand social media data from a social perspective, and combining social theories with computational methods manifests a novel and effective perspective to mine social media data as shown in Figure 1. Social theories help bridge the gap from what we have (so-cial media data) to what we want to understand social media data (social media mining).
 Integrating social theories with computational models be-comes an interesting direction in mining social media data and encourages a large body of literature in this line. The goal of this article is to provide a review of some key social theories in mining social media data. The contributions and organization of this article are summarized as below: Social relations are pervasively available and the social prop-erty of social media data determines that social media data is substantially different from data in traditional data min-ing and social sciences. In this section, we discuss some unique properties of social media data. Before details, we first introduce some notations used in this article. Let U = { u 1 , u 2 , . . . , u n } and P = { p 1 , p 2 , . . . , p m users and m items (or pieces of user generated content). We use S  X  R n  X  n , R  X  R n  X  m and C  X  R m  X  K to denote user-user relation, user-content interaction and content-feature matrices where we extract a set of K features F to repre-sent the content set P .
 Big: In social media, we have little data for each specific individual. However, the social property of social media data links individuals X  data together, which provides a new type of big data. For example, more than 300 million tweets are sent to Twitter per day; more than 3,000 photos are uploaded to Flickr per minute, and more than 153 million blogs are posted per year.
 Linked: The availability of social relations determines that social media data is inherently linked [52]. An illustration example is shown in Figure 2 where user generated content (or p 1 to p 8 ) are linked via social relations among users ( u to u 4 ). Linked social media data is patently not indepen-dent and identically distributed, which contradicts one of the most enduring and deeply buried assumptions of tradi-tional data mining and machine learning methods [23; 57]. Noisy: A successful data mining exercise entails extensive data preprocessing and noisy removal as  X  X arbage in and garbage out. X  However, social media data can contain a large portion of noisy data. Users in social media can be both passive content consumers and active content produc-ers, causing the quality of user generated content to vary drastically [1]. The noisy issues of social media data are not stop here. The social networks in social media are also noisy. First some social media users work as spammers to spread malicious or unwanted messages [47]. Second, the low cost of link formation leads to acquaintances and best friends mixed together [65]. Unstructured: U ser generated content in social media is often highly unstructured. Nowadays more and more users use their mobile devices to publish content such as updating statuses in Facebook, sending tweets in Twitter and com-menting on posts, which results in (1) short texts and (2) ty-pos and spacing errors occurring very frequently [25]. Free-from languages are widely adopted by social media users in the online communication such as ASCII art (e.g., :) and :( ) and abbreviations (e.g., h r u?) [46]. The short and highly unstructured social media data challenges the vast majority of existing techniques.
 Incomplete: Users X  attributes are predictable with their personal data [26]. To address such privacy concerns, social media services often allow their users to use their profile settings to mark their personal data such as demographic profiles, status updates, lists of friends, videos, photos, and interactions on posts, invisible to others. For example, a very small portion of Facebook users ( &lt; 1%) make their per-sonal data public available [41]. The available social media data could be incomplete and extremely sparse. For exam-ple, for social recommendation, more than 99% of entities in the user-content interaction matrix R are missed [51]. Social theories from social sciences are useful to explain vari-ous types of social phenomena. In social media, it is increas-ingly possible for us to observe social data from hundreds of millions of individuals. Given its large-scale size and social property, a natural question is -can we apply social theories to social media data? . More and more social theories have been proven to be applicable to social media data. In this section, we concentrate on three important social theories with basic concepts, ways to verify them and key findings. Social correlation theory is one of the most important social theories and it suggests that there exist correlations between behaviors or attributes of adjacent users in a social network. Homophily, influence and confounding are three major social process to explain these correlations as shown in Figure 3. To help us verify the applicability of social correlation the-ory to social media data, essentially we need to answer the following question -are users with social relations more sim-ilar than these without? To answer this question, for each social relation from u i to u j , we calculate two similarities s and r ik where s ij is the similarity between u i and u j r ik is the similarity between u i and a randomly chosen user u k who does not connect to u i . Let S be the set of s ij s, which denotes the set of similarities of pairs of connected users. Let R be the set of r ik s, which represents the set of similarities of pairs of randomly chosen users. We perform a t-test on S and R . The null hypothesis is that similarities with social relations are no larger than these without, i.e., H 0 : S  X  R ; the alternative hypothesis is that the simi-larities with social relations are larger than these without, i.e., H 1 : S &gt; R . If there is strong evidence to reject the null hypothesis, we verify that social correlation theory is applicable to social media data.
 Via above verification process, social correlation theory has been proven to be applicable to various social media sites. Twitter users with following relations are likely to share similar topics or opinions [63; 20]. Users in Epinions with trust relations are likely to rate same items with similar scores [49]. In [52], we shows that users in Digg and Blog-Category with social relations are likely to joint groups of similar interests. In location-based social networks such as Foursquare, users with social relations are likely to do check-ins in the same locations [69; 14]. In general, balance theory implies the intuition that  X  X he friend of my friend is my friend X  and  X  X he enemy of my en-emy is my friend X  [17]. Basically, it considers the balance of signs on a triad involving three users in a social network with positive and negative links [28; 27]. We use s ij to de-note the sign of the relation between u i and u j where s (or s ij =  X  1) if we observe a positive relation (or a negative relation) between u i and u j . Balance theory suggests that a triad h u i , u j , u k i is balanced if For a triad h u i , u j , u k i , there are four possible sign combina-tions A (+,+,+), B (+,+,-) C (+,-,-) and D (-,-,-) as shown in Figure 4, while only A (+,+,+) and C (+,-,-) are balanced. The way to verify balance theory is straightforward. We examine all these triads h u i , u j , u k i and then to check the ratio of A (+,+,+) and C (+,-,-) among all four possible sign combinations. A high ratio suggests that balance theory is applicable to social media data We check the distributions of four possible sign combinations on the three widely used social media datasets (i.e., Epin-ions, Slashdot and Wikipedia) with signed networks in [27]. The ratios of A (+,+,+) and C (+,-,-) among all four possi-ble sign combinations are 0.941, 0.912, and 0.909 in Epin-ions, Slashdot and Wikipedia, respectively. More than 90% of triads are balanced. Similar observations on other social media datasets are reported by [68; 56]. Note that balance theory is developed for undirected social networks and we usually ignore their directions when applying balance theory to directed social networks [27]. Different from balance theory, status theory is developed for directed social networks [28]. Social status refers to the po-sition or rank of a user in a social community, and represents the degree of honor or prestige attached to the position of each individual. In status theory, a positive link from u to u j indicates that u i has a higher status than u j ; while a negative link from u i to u j indicates that u i has a lower status than u j . For a triad, status theory suggests that if we take each negative relation, reverse its direction, and flip its sign to positive, then the resulting triangle (with all positive edge signs) should be acyclic.
 In [28], contextualized links are introduced to verify sta-tus theory. A contextualized link is defined to be a triple h u i , u j , u k i with the property that a link forms from u after each of u i and u j already has a link either to or from u . The link between u k and u i can go in either direction and have either sign yielding four possibilities, and simi-larly for the link between u k and u j ; hence overall there are 4  X  4 = 16 different types of contextualized links. Figure 5 demonstrates 4 of 16 types of contextualized links where ( A ) and ( D ) satisfy the status theory, while ( B ) and ( C ) do not satisfy the status theory. For each of these types of contex-tualized links, we can count frequencies of positive versus negative links for the links from u i to u j and then calculate the ratio of contextualized links satisfying status theory. In [53], it is reported that 99% of triads in the Enron email social network and the advisor-advisee social network satisfy status theory. Similar patterns are observed on Epinions and Wikipedia datasets in [28]. The scale and properties of social media data substantially Figure 5: An Illustration of Four Out of Sixteen Types of Contextu alized Links for Status Theory. Note that  X + X ( or  X - X ) denotes the target node has a higher (or lower) status than the source node. differ from these of data used by social sciences to develop social theories. Since social media data is a new type of social data, it is possible to apply some social theories to explain phenomena in social media data. The verification of social theories in social media data not only paves a way for us to understand social media data from a social perspec-tive but also suggests that it is highly possible to facilitate social media mining tasks by integrating social theories with computational methods. Social media mining is an emerging discipline under the um-brella of data mining and grows rapidly in recent years [70]. The verification of some social theories in social media data suggests that we should put  X  X ocial X  in social media mining and encourages a large body of literature to model and ex-ploit social theories to advance social media mining tasks. In general, there are three types of objects in social me-dia data -users, social relations and user generated content, which allows us to roughly classify social media mining tasks to three groups based on the mining objects -user-based tasks, relation-based tasks and content-based tasks. Next we elaborate each group with representative tasks with their definitions, challenges and the start-of-the-art algorithms to apply social theories to these specific tasks. For individuals, a better understanding of their social net-works can help them share and collect reliable informa-tion more effective and efficient. For social media service providers, a better understanding of their customers can help them provide better services. User-related tasks pro-vide necessary and effective means to understand social me-dia users. In this subsection, we review social theories in some key user-related tasks. Communities in social media can be explicit such as Yahoo! Groups. However, in many social media sites, communities are implicit and their members are obscure to social media users. Community detection is proposed to find these im-plicit communities in social media by identifying groups of users that are more densely connected to each other than to the rest of the network [55]. Detecting implicit commu-nities can benefits many social media mining tasks such as social targeting and personalization. The major difference between clustering in data mining and community detection is that in community detection, individuals are connected to others in social networks; while in clustering, data points are not embedded in a network and they are assume to be independent and identically distributed. Formally, for a so-cial network G ( U , S ), community detection is to find a set of communities C where users are more densely connected within a community than to the rest of users.
 Homophily suggests that similar users are likely to be linked, and influence indicates that linked users will influence each other and become more similar. The suggestions from so-cial correlation theory in creating new ties based on the similarity gives rise to macro patterns of associations, also known as communities [7]. Two users in the same commu-nity have higher similarity [44]. The modularity maximiza-tion method is to maximize the sum of the actual number of social relations between two users minus expected num-ber of social relations between them since two users in the same community should have a higher probability to estab-lish a relation than two randomly chosen users [43]. Wang et al. [60] find that users within the community are likely to share similar tags in social tagging systems and they take advantage of the bipartite network between users and tags in social tagging systems to discover these overlapping com-munities. In [66], a density-based framework is proposed with the intuition that users in the same community should interact more frequently with each other.
 Recently applying balance theory to detect communities from signed networks has attracted increasing attention. In [11], a generalized balance theory is proposed where a network is k-balanced iff users can be partitioned in to k-subsets such that positive links lie within the sets and the negative links between them. Balance theory suggests that the assignment of users related by negative links should be done the oppo-site way of positive links, with negative links sparse within and more dense between communities therefore the potts model is extended to incorporate both positive and negative links to detect communities in signed network [58]. In [2], a two-objective approach is proposed for community detec-tion in signed networks based on balance theory. One is that the partitioning should have dense positive intra-connections and sparse negative interconnections, and the other is that it should have as few as possible negative intra-connections and positive inter-connections. Due to privacy concerns, social media users tend to hide their profiles. For social media service providers, users X  pro-file information is useful for them to customize their services to the users in many ways such as friend and content rec-ommendations and personalized search. More they know about users and their preferences, better they can serve them. Given a social network and some user information (attributes, preferences or behaviors), user classification is designed to infer the information of other users in the same network [15]. In the user classification problem, users in U are partially labeled as U = [ U L , U U ] where U L and U the sets of labeled and unlabeled users, respectively. For-mally the task of user classification is to label users from a finite set of categorical values in U U with the social network G ( U , S ) and U L .
 Social correlation theory suggests that the labels of linked users should be correlated, which is the major reason why re-searchers believe that the labels of U L can be predicted with the network structure and the partially labeled users [15]. Social correlation theory is the underlying assumption of most of existing user classification methods, which design al-gorithms for collective classification. A typical user classifi-cation algorithm includes parts of the three components [37]: In [36], a weighted-vote relational neighborhood classifier wvRN is introduced for user classification. wvRN is like a lazy learner and estimates the labels of users as the weighted mean of their neighbors. In [34], the proposed framework first creates relational features of one user by aggregating the label information of its neighbors and then a relational classifier can be constructed based on labeled data. Neville and Jensen in [42] propose to use clustering algorithms to find out the cluster memberships of each user first, and then fix the latent group variables for later inference. Xiang et al. [64] propose a novel latent relational model based on cop-ulas. It can make predictions in a discrete label space while ensuring identical marginals and at the same time incor-porating some desirable properties of modeling relational dependencies in a continuous space. A community-based framework is proposed in [54]. It first extracts overlapping communities based on social network structure, then uses communities as features to represent users and finally a tra-ditional classifier such as SVM is trained to assign labels for unlabeled users in the same network. Social media has become an important and efficient way to disseminate information. Given its popularity and ubiquity, social spammers create many fake accounts and send out unsolicited commercial content [62]. Social spammers have become rampant and the volume of spam has increased dra-matically. For example, 83% of the users of social networks have received at least one unwanted friend request or mes-sage [47]. This not only causes misuse of communication bandwidth, storage space and computational power, but also wastes users X  time and violates their privacy rights. There-fore developing effective social spammer detection techniques is critically important in improving user experience and pos-itively affecting the overall value of social media services [47]. Given a social network G ( U , S ), social spammer detection is to find a set of spammers U S from U with U S  X  U . Based on social correlation theory, there are two observa-tions for normal users and spammers [73]. First normal users perform similarly with their neighbors. Second, spam-mers perform differently from their neighbors since most of their neighbors are normal users. Therefore a social regu-larization term is proposed under the matrix factorization framework to model these observations where two connected normal users should be close in the latent space since they share similar interests and may perform similar social activ-ities, while spammers should be far away from their neigh-bors in the latent space. In Twitter, users have directed following relations and spammers can easily follow a large number of normal users within a short time. In [19], we di-vide user-user following relations in Twitter into four types -[spammer, spammer], [normal, normal], [normal, spam-mer], and [spammer, normal]. Since the fourth relation can be intentionally faked by spammers, we only consider the first three types of relations. Specifically we introduce a graph regularization term to model social correlation the-ory in the directed social relations, which is integrated into the standard Lasso formulation to train a linear classifica-tion for social spammer detection. Spammers and normal users have very different social behaviors. Normal users are likely to form a group with other normal users, while spam-mers are likely to from spammer groups [29]. In [6], the authors incorporate community-based features of users with basic topological features to improve spammer classifiers. It first finds overlapping community structure of users and then extracts features based on these communities such as the features which express the role of a user in the commu-nity structure like a boundary node or a core node and the number of communities it belongs to. A social network is usually represented by a binary adjacent matrix. First the matrix is extremely sparse since there are many pairs of users with missing relations. Second, social networks in social media are more complicated. For ex-ample, strengths of relations might be heterogeneous such as acquaintances and best friends, while a social network may a composite of various types of relations such as fam-ily, classmates and colleagues. Relation-Related tasks focus on mining relations among users and aim to reveal a fine-grained and comprehensive view of social relations. Signed networks arise in social network with various ways when users can implicitly or explicitly tag their relationship with other users as positive or negative. In this section, we review social theories in some key relation-related tasks on signed and unsigned networks. It is critical for social media sites to provide services to en-courage more user interactions with better experience such as expanding one X  X  social network. One effective way is to automatically recommend connections since it is hard for users to figure out who is available on social media sites. Most social media sites provide friend recommendation ser-vices to their customers such as Facebook, Twitter and LinkedIn. The essential problem of friend recommendation is known as link prediction [30]. When there is no relation between u and u j , S ij = 0. The task of link prediction is to predict which pairs of users u i and u j without relations S ij = 0 are likely to get connected given a social network G ( U , S ). Unsigned Networks : Homophily in social correlation the-ory suggests that similar users are likely to establish social relations. In [30], various similarity measurements such as common neighbors based on the network structure are re-viewed for link prediction. One challenging problem in link prediction is the sparsity problem -some users may have very few or even no links. In [49], a low-rank matrix factor-ization framework with homophily effect hTrust is proposed to predict trust relations. Homophily coefficients are de-fined to measure the strength of homophily among users. The stronger homophily between two users is, the smaller distance between them in the latent space is. Homophily regularization is then defined to model homophily effect by controlling users X  distances in the latent space with the help of homophily coefficients. Through homophily regulariza-tion, trust relations can be suggested to users with few or even no relations and mitigate the sparsity problem in link prediction. The confounding effect in social correlation the-ory s uggests that people who share high degree of overlap in their trajectories are expected to have a better likelihood of forming new links. In [59], the effect of confounding is inves-tigated for link prediction. Specifically, it leverages mobility information to extract features which can capture some de-gree of closeness in physical world between two individuals. Status theory suggests new links are more likely to be at-tached from users with low statuses to these with high stat-ues and the preferential attachment models are widely used to predict link prediction based on status measures such as the degree of nodes and PageRank [5].
 Signed Networks : In [27], local-topology-based features (or 16 triad types) based on balance theory and status theory are extracted to improve the performance of a logistic re-gression classifier in signed relation prediction. In [13], the authors use a probabilistic treatment of trust combined with a modified spring-embedded layout algorithm to classify a relation based on balance theory. Instead of having all users repel, the model adds a repelling force only between users connected with a negative relation to capture balance the-ory. For example, one is friends with an enemy of the other; the forces will push them in different locations. In [10], the authors show how any quantitative measure of social imbal-ance in a network can be used to derive a link prediction algorithm and extend the approach in [27] by presenting a supervised machine learning based link prediction method that uses features derived from longer cycles in the network. The motivation to derive features from longer cycles is that higher order cycles in a signed network yield a  X  X easure of imbalance X  suggested the balance theory. In [18], it shows that the notion of weak structural balance in signed net-works naturally leads to a global low-rank model for the network. Under such a model, the sign inference problem can be formulated as a low-rank matrix completion problem. Social networks in social media can be a composite of various types of relations. For example, the relation types in Face-book could be family, colleagues, classmates and friends. However, in most online networks such as Facebook, Twit-ter and LinkedIn, such type information is usually unavail-able [56]. Different types of relations may influence people in different ways. For example, one user X  X  work style may be mainly influenced by her/his colleagues; while the daily life habits may be strongly affected by her/his family. It is nec-essary and important to reveal these different types of social relations therefore we ask whether we can automatically in-fer the types of social relations for social networks in social media. A novel task of social tie prediction is designed to answer the above question, which aims to predict the type of a given social relation. A non-zero value of S ij suggests that there is a connection between u i and u j . Formally social tie prediction is to predict the type of a social relation between u and u j with S ij 6 = 0 from a finite set of categorical types such as { family, classmates, colleagues and friends } . In [53], a framework is proposed to classify the type of so-cial relationships by learning across heterogeneous networks. The framework incorporates social theories such as balance theory and status theory into a factor graph model, which effectively improves the accuracy of inferring the type of social relationships in a target network by borrowing knowl-edge from a different source network. Balance theory and status theory should be general over different types of net-works. To learn knowledge from the source network to the target network, transfer features are extracted based on bal-ance theory and status theory, which are shared by different types of networks. In particular, from social balance, the paper extracts triad based features to denote the propor-tion of different balanced triangles in a network; and from status theory, it defines features over triads to respectively represent the probabilities of the seven most frequent forma-tions of triads. Different from [53], approaches are suggested by [68] to model balance theory and status theory math-ematically. To model the balance theory, it introduces an one-dimensional latent factor  X  i for each user u i and defines the sign between u i and u j as s ij =  X  i  X  j . To model status theory, it introduces a global user-independent parameter  X  to capture the partial ordering of users.  X  maps the latent user profile of u i  X  i to a scalar quantity  X  i =  X  X  i , which reflects the corresponding user u i  X  X  social status. According to status theory, it characterizes social ties from u i to u by modeling the relative status difference between them as  X  Social media users can have hundreds of social relations. However, a recent study shows that Twitter users have a very small number of friends compared to the number of fol-lowers and followees they declare [21]. The low cost of link formation in social media can lead to networks with het-erogeneous relationship strengths (e.g., acquaintances and best friends mixed together) [65]. Pairs of users with strong strengths are likely to share greater similarity than those with weak strengths; therefore a better understanding of strengths of social relations can help social media sites serve their customers well such as better recommendations and more effective friend management tools, which arises the problem of tie strength prediction. In the binary relation presentation, once there is a connection between u i and u S ij = 1. The task of tie strength prediction is to predict a connection strength between 0 and 1 for u i and u j with S ij = 1. After tie strength prediction, the binary relation representation matrix S ij  X  { 0 , 1 } will be converted into a continuous valued relation representation matrix S ij  X  [0 , 1]. In [24], guided by social correlation theory, four different categories of features, i.e., attribute similarity, topological connectivity, transactional connectivity, and network trans-actional connectivity, are extracted from sources including friendship links, profile information, wall postings, picture postings, and group memberships. Then various classifiers are trained to predict link strength from transactional infor-mation based on these extracted features. A unsupervised latent variable model is proposed to predict tie strength in online social network [65] with user profiles and interactions. One key underlying assumption of the proposed model is social correlation theory. Homophily in social correlation theory postulates that users tend to form ties with other people who have similar characteristics, and it is likely that the stronger the tie, the higher the similarity. Thus the proposed framework models the tie strength as homophily effect of nodal profile similarities. The relationship strength directly influences the nature and frequency of online inter-actions between a pair of users. The stronger the relation-ship, the higher likelihood that a certain type of interaction between the pair of users. Therefore the propose framework models the relationship strength as the hidden cause of in-fluence among users. Numerous techniques are developed for various content min-ing tasks such as classification and clustering in the last decade. User generated content in social media is usually linked, noisy, highly unstructured and incomplete, which de-termines that existing techniques become difficult when ap-plying these mining tasks on user generated content in social media. Before the popularity of social media, researchers have already noticed that exploiting link information can improve content classification [72] and clustering [32]. The popularity of social media makes social relations pervasively available, which encourages the exploitation of social rela-tions in more and more mining tasks. Social theories can help us understand social relations better and in this subsec-tion, we review how social theories help some representative content-related tasks. The pervasive use of social media generates massive data in an unprecedented rate and the information overload problem becomes increasingly serve for social media users. Recom-mendation has been proven to be effective in mitigating the information overload problem and presents its significance to improve the quality of user experience, and to positively impact the success of social media. Users in the physical world are likely to seek suggestions from their friends before making a purchase decision and users X  friends consistently provide good recommendations [45], we have similar obser-vations in the online worlds. For example, 66% of people on social sites have asked friends or followers to help them make a decision and 88% of links that 14-24 year olds clicked were sent to them by a friend and 78% of consumers trust intuitions motive a new research direction of recommenda-tion social recommendation, which aims to take advantage of social relations to improve the performance of recommen-dation. Formally, a social recommender system is to pre-dict missing values in the user-content interaction matrix R based on information from the user-user relation matrix S and the observed values in R [51].
 The major reason why people believe that social relations are helpful to improve recommendation performance is evi-dence from social correlation theory, which suggests that a user X  X  preference is similar to or influenced by their directly connected friends [51]. Therefore social media users rarely make decisions independently and usually seek advice from their friends before making purchase decisions. Social re-lations may provide both similar and familiar evidence for users, MoleTrust uses socially connected users to replace similar users in traditional user-based collaborative filtering method for recommendation in [39]. Social correlation the-ory indicates that a user X  X  preference should be similar to her/his social network. Ensemble methods predict a miss-ing value for a given users as a linear combination of ratings from the user and her/his social network based on tradi-tional matrix factorization CF method with the intuition that users and their social networks should have similar rat-ings on the same items [50]. While regularization methods add regularization terms to force the preference of a user close to that of users in her/his social network under the matrix factorization CF method. For example, SocialMF defines a regularization term to force the preference of a user to be close to the average preference of the user X  X  social network [22], and SoReg uses social regularization to force the preferences of two connected users close [35]. 1 http:// w ww.firebellymarketing.com/2009/12/social-search-statistics-fromses-chicago.html One characteristic of user generated content in social me-dia is high-dimensional such as there are tens of thousands of terms in tweets or pixels for photos in Flickr. Tradi-tional data mining tasks such as classification and cluster-ing may fail due to the curse of dimensionality. Feature selection has been proven to be an effective way to han-dle high-dimensional data for efficient data mining [31]. As mentioned above, user generated content is linked due to the availability of social relations and poses challenges to traditional feature selection algorithms which are typically designed for IID data. The formal definition of feature se-lection for user generated content in social media is stated as [52] -we aim to develop a selector which selects a sub-set of most relevant features from F on the content-feature matrix C with its social context S and R .
 LinkedFS is proposed as a feature selection framework for user generated content with social context based on social correlation theory in [52]. Four types of relations, i.e., co-Post, coFollowing, coFollowed and Following, are extracted from social context S and R of user generated content C . Social correlation theory suggests that linked users are likely to share similar topics. Based on social correlation theory, LinkedFS turns these four types of relations to four corre-sponding hypotheses that can affect feature selection with linked data. For example, following hypothesis assumes that one user u i follows another user u j because u i share u interests, and their user generated content is more likely similar in terms of topics; hence LinkedFS models following relations mathematically by forcing topics of two users with following relations close to each other. LinkedFS jointly incorporates group Lasso with the regularization term to model each type of relations for feature selection. Nowadays social media services such as Twitter and Face-book are increasingly used by online users to share and exchange opinions, providing rich resources to understand public opinions. For example, in [3], a simple model ex-ploiting Twitter sentiment and content outperforms market-based predictors in terms of forecasting box-office revenues for movies; public mood as measured from a large-scale col-lection of tweets obtains an accuracy of 86 . 7% in predicting the daily up and down changes in the closing values of the DJIA [8]. Therefore sentiment analysis for such opinion-rich social media data has attracted increasing attention in recent years [46; 20]. Formally sentiment analysis for user generated content with social relations is to obtain a predic-tor from the content-feature matrix C with its social context S and R , which can automatically label the sentiment po-larity of an unseen post.
 Social correlation theory indicates that sentiments of two linked users are likely to be similar. In [48], graphical mod-els are proposed to incorporate social network information to improve user-level sentiment classification of different top-ics based on two observations -(1) user pairs in which at least one party links to the other are more likely to hold the same sentiment, and (2) two users with the same senti-ment are more likely to have at least one link to the other than two users with different sentiment. Social correlation theory suggests that social relations are kinds of sentiment correlations. In [46], the authors propagate sentiment la-bels of tweets via user-user social relations S and user-tweet relations R to assign sentiment labels to unlabeled tweets. In [20], tweet-tweet correlation network are built from S and R based on social correlation theory. For example, tweets from users with following relations should be correlated as sugges ted by social correlation theory. Two tweets linked in the tweet-tweet correlation network are likely to share sim-ilar sentiments; hence the proposed framework SANT adds a graph regularization term in the Lasso classifier to force the sentiments of two correlated tweets close to each other. In reviewing state-of-the-art algorithms that exploit social theories in mining social media, we understand that they aim to find mathematical explanations of social theories for computational models. We notice that algorithms share sim-ilar ways in applying social theories such as feature engineer-ing, constraint generating and objective defining. Instead of brute-force search, social theories can guide us to extract relevant features via feature engineering, to gen-erate constraints via constraint generating, and to define objectives via objective defining for computational models. The algorithms reviewed earlier that exploit social theories in various social media mining tasks are summarized in Fig-ure 6. We notice that for the same task, social theories can be exploited in different ways. For example, for link predic-tion, social theories are explained via feature engineering, constraint generating and objective defining. Some social theories have been proven to be applicable to social media data, which encourages us to put  X  X ocial X  in social media mining. Integrating some social theories with computational models advances various social media mining tasks and has attracted increasing attention. The exciting progress not only proves that the direction of integrating social theories in mining social media data is appealing but also suggests that we should put more  X  X ocial X  in social me-dia mining. In this article, we review the state-of-the-art al-gorithms that employ social correlation theory, balance the-ory and status theory in various social media mining tasks. These theories are just illustrative examples and there could be more social theories to be applicable and employed such as small world theory [74] as shown in recent efforts to inves-tigate and verify more social theories for social media data. Some of these efforts have already made initial progress such as structural hole theory [9] and weak tie theory [16]. A per-son is said to span a structural hole in a social network if he or she is linked to people in parts of the network that are otherwise not well connected to one another [9]. Tang et al. [56] employ structural hole theory in the problem of social tie prediction; while Lou and Tang confirm the importance of structural hole in information diffusion with social media data, and show that mining structural hole can benefit vari-ous social media mining tasks such as community detection and link prediction [33]. Weak tie theory suggests that more novel information flows to individuals through weak rather than strong ties [16]. Recently researchers find that weak ties of a user are helpful to predict the preference of the user for user classification [54] and social recommendation [71]. No doubt that social media data is a new type of social data and is much more complicated than the data social sci-ences use to study social theories. It is highly possible that new social theories can be discovered from social media data to make meaningful progress on important problems in so-cial media mining, however, that progress requires serious engagement of both computer scientists and social scien-tists [61]. Data availability is still a challenging problem for social scientists. The data required to address many prob-lems of interest to social scientists remain difficult to assem-ble and it has been impossible to collect observational data on the scale of hundreds of millions, or even tens of thou-sands, of individuals [61]. Social media provides a virtual world for users X  online activities and makes it possible for social scientists to observe social behavior and interaction data of hundreds of millions of users. However social media data is too big to be directly handled by social scientists. On the other hand, computer scientists can employ data mining and machine learning techniques to handle big social media data; but, we lack necessary theories to help us understand social media data better. For example, without a better un-derstanding of social media data, computer scientists may waste a lot of time in feature engineering, which is the key to the success of many real-world applications [12]. Therefore engagement of both computer scientists and social scientists in social media data is truly mutually beneficial. Computer scientists can take advantage of social theories to mine so-cial media data and provide computational tools that are of great potential benefit to social scientists; while social sci-entists can make use of computational tools to handle social media data and develop new social theories to help computer scientists provide better computational tools. The social nature of social media data calls for new tech-niques and tools and cultivates a new field -social me-dia mining. Social theories from social sciences have been proven to be applicable to mining social media. Integrating social theories with computational models is becoming an interesting way in mining social media data and makes ex-citing progress in various social media mining tasks. In this article, we review three key social theories, i.e., social cor-relation theory, balance theory and status theory, in mining social media data. In detail, we introduce basic concepts, verification methods, interesting findings and the state-of-the-art algorithms to exploit these social theories in social media mining tasks, which can be categorized to feature en-gineering, constraint generating and objective defining. As future directions, more existing social theories could be em-ployed or new social theories could be discovered to advance social media mining. [1] E. Agichtein, C. Castillo, D. Donato, A. Gionis, and [2] A. Amelio and C. Pizzuti. Community mining in signed [3] S. Asur and B. A. Huberman. Predicting the future [4] E. Bakshy, I. Rosenn, C. Marlow, and L. Adamic. [5] A.-L. Barab  X asi and R. Albert. Emergence of scaling in [6] S. Y. Bhat and M. Abulaish. Community-based features [7] H. Bisgin, N. Agarwal, and X. Xu. Investigating ho-[8] J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts [9] R. S. Burt. Structural holes: The social structure of [10] K.-Y. Chiang, N. Natarajan, A. Tewari, and I. S. [11] J. A. Davis. Clustering and structural balance in [12] P. Domingos. A few useful things to know about ma-[13] T. DuBois, J. Golbeck, and A. Srinivasan. Predicting [14] H. Gao, J. Tang, and H. Liu. Exploring social-historical [15] L. Getoor and C. P. Diehl. Link mining: a survey. ACM [16] M. Granovetter. The strength of weak ties. JSTOR , [17] F. Heider. Attitudes and cognitive organization. The [18] C.-J. Hsieh, K.-Y. Chiang, and I. S. Dhillon. Low rank [19] X. Hu, J. Tang, Y. Zhang, and H. Liu. Social spammer [20] X. Hu, L. Tang, J. Tang, and H. Liu. Exploiting so-[21] B. Huberman, D. M. Romero, and F. Wu. Social net-[22] M. Jamali and M. Ester. A matrix factorization tech-[23] D. Jensen and J. Neville. Linkage and autocorrelation [24] I. Kahanda and J. Neville. Using transactional informa-[25] D. Kim, D. Kim, E. Hwang, and S. Rho. Twittertrends: [26] M. Kosinski, D. Stillwell, and T. Graepel. Private traits [27] J. Leskovec, D. Huttenlocher, and J. Kleinberg. Pre-[28] J. Leskovec, D. Huttenlocher, and J. Kleinberg. Signed [29] F. Li and M.-H. Hsieh. An empirical study of cluster-[30] D. Liben-Nowell and J. Kleinberg. The link-prediction [31] H. Liu and H. Motoda. Computational methods of fea-[32] B. Long, Z. M. Zhang, X. Wu, and P. S. Yu. Spec-[33] T. Lou and J. Tang. Mining structural hole spanners [34] Q. Lu and L. Getoor. Link-based classification. In [35] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King. Recom-[36] S. A. Macskassy and F. Provost. A simple relational [37] S. A. Macskassy and F. Provost. Classification in net-[38] P. Massa. A survey of trust use and modeling in real [39] P. Massa and P. Avesani. Trust-aware collaborative fil-[40] M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds [41] A. Mislove, B. Viswanath, K. P. Gummadi, and P. Dr-[42] J. Neville and D. Jensen. Leveraging relational auto-[43] M. E. Newman and M. Girvan. Finding and evaluating [44] S. Papadopoulos, Y. Kompatsiaris, A. Vakali, and [45] R. R. Sinha and K. Swearingen. Comparing recommen-[46] M. Speriosu, N. Sudan, S. Upadhyay, and J. Baldridge. [47] G. Stringhini, C. Kruegel, and G. Vigna. Detecting [48] C. Tan, L. Lee, J. Tang, L. Jiang, M. Zhou, and P. Li. [49] J. Tang, H. Gao, X. Hu, and H. Liu. Exploiting ho-[50] J. Tang, H. Gao, and H. Liu. mtrust: discerning multi-[51] J. Tang, X. Hu, and H. Liu. Social recommendation: a [52] J. Tang and H. Liu. Feature selection with linked data [53] J. Tang, T. Lou, and J. Kleinberg. Inferring social ties [54] L. Tang and H. Liu. Relational learning via latent social [55] L. Tang and H. Liu. Community detection and mining [56] W. Tang, H. Zhuang, and J. Tang. Learning to infer [57] B. Taskar, P. Abbeel, M.-F. Wong, and D. Koller. Label [58] V. Traag and J. Bruggeman. Community detection [59] D. Wang, D. Pedreschi, C. Song, F. Giannotti, and A.-[60] X. Wang, L. Tang, H. Gao, and H. Liu. Discovering [61] D. J. Watts. Computational social science: Exciting [62] S. Webb, J. Caverlee, and C. Pu. Social honeypots: [63] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: [64] R. Xiang and J. Neville. Collective inference for network [65] R. Xiang, J. Neville, and M. Rogati. Modeling relation-[66] X. Xu, N. Yuruk, Z. Feng, and T. A. Schweiger. Scan: [67] J. Yang and J. Leskovec. Modeling information diffu-[68] S.-H. Yang, A. J. Smola, B. Long, H. Zha, and [69] M. Ye, X. Liu, and W.-C. Lee. Exploring social in-[70] R. Zafarani, M. A. Abbasi, and H. Liu. Social Media [71] X. Zhang, J. Cheng, T. Yuan, B. Niu, and H. Lu. [72] S. Zhu, K. Yu, Y. Chi, and Y. Gong. Combining content [73] Y. Zhu, X. Wang, E. Zhong, N. N. Liu, H. Li, and [74] D. Watts, and S, Steven. Collective dynamics of  X  X mall-Following the recent advances in neuroimaging technology, the research on brain network analysis becomes an emerging area in data mining community. Brain network data pose many unique challenges for data mining research. For ex-ample, in brain networks, the nodes (i.e., the brain regions) and edges (i.e., relationships between brain regions) are usu-ally not given, but should be derived from the neuroimaging data. The network structure can be very noisy and uncer-tain. Therefore, innovative methods are required for brain network analysis. Many research efforts have been devoted to this area. They have achieved great success in various ap-plications, such as brain network extraction, graph mining , neuroimaging data analysis. In this paper, we review some recent data mining methods which are used in the literature for mining brain network data.
 Brain networks, Graph mining, Functional magnetic reso-nance imaging, Subgraph Patterns Recent advances in neuroimaging technology has unleashed a torrent of neuroscience data. The data give us an unprece-dented opportunity to look into the activity and connectivity of the human brain non-invasively and in vivo. Brain tis-sue is generally described according to the broad classes of gray matter and white matter. This distinction has a his-torical basis in the appearance at dissection, reflecting the preponderance of cell bodies and dendrites (gray matter, e.g. cortex) and of myelinated axons, which have a fatty, whitish appearance (white matter, e.g. corpus callosum) [29]. The activity of the brain, however, is organized according to vast and complex patterns of connectivity involving multifocal distributed neural networks and white matter pathways that are considered critical to an understanding of higher order cognitive function and dysfunction [42].
 The last several decades have witnessed explosive expansion in knowledge concerning the structure and function of the human brain. This can be attributed in part to advances in Magnetic Resonance (MR) imaging capabilities. Techniques such as diffusion tensor imaging (DTI), for example, that can be used for in vivo interrogation of the brain at levels that approximate cellular dimensions, have enabled tractog-raphy of the vast network of white matter fiber pathways, yielding fundamental insights into structural connectivity [5; 8; 27; 28; 2]. Functional magnetic resonance imaging (fMRI) has been used to identify localized patterns of brain activation on the basis of cerebral blood flow and the BOLD response [30; 31; 6]. Strategies, such as resting state fMRI (rs-fMRI) have been used to map functional connectivity  X  networks defined on the basis of correlated activity in low frequency oscillations between gray matter regions [6; 17; 33].
 Brain networks have been studied extensively in recent years [36; 11], because of potential application to detection of a wide variety of brain diseases [43]. A detailed book on this topic may be found in [35]. Conventional research on brain networks focuses on connectivity derived from vari-ous neuroimaging modalities, such as electroencephalogra-phy (EEG), fMRI and DTI. These approaches emphasize creating a network among brain regions (or ROIs) and de-tecting changes in connectivity related to brain diseases. Conventional strategies often use either equally sized re-gions or anatomical landmarks (e.g., gyral and sulcal-based regions) as nodes of the network with unclear relationship to the underlying functional and structural organization of the brain. The links among these regions (e.g., functional connections or structural connections) are extracted based on neuroimaging data to form a network.
 Data mining has already made significant impacts in many real-world applications in industry and science, such as so-cial network analysis, web mining. However, brain network data pose many unique challenges for data mining commu-nity. For example, in conventional network analysis, the nodes (e.g., webpages) and edges (e.g., hyperlinks) are usu-ally clearly defined. In brain networks, however, the nodes (i.e., the brain regions) and edges (i.e., relationships between brain regions) are not given, but need to be derived from the neuroimaging data. Different parcellation of the brain re-gions can result in significantly different network structures. The edges of brain networks are also highly uncertain due to the noise in imaging signals. Conventional data mining methods can seldom be directly applied to brain network data. A wide variety of new questions can also be asked in context of the brain network analysis.
 In this paper, we focus on reviewing some recent data mining methods for (1) direct mining of neuroimaging data; (2) ex-tracting brain networks from neuroimaging data; (3) mining subgraph patterns from brain networks.
 Imaging-based Approaches : Neuroimaging data can nat-urally represented as tensor data [47; 14; 18], which gen-Publication Target Disease Imaging Data Mining Task Information Sources KDD X 09 [37] Alzheimer X  X  FDG-PET Region Connectivity Neuroimage NIPS X 09 [19] Alzheimer X  X  PET Region Connectivity Neuroimage KDD X 11 [20] Alzheimer X  X  FDG-PET Effective Connectivity Neuroimage NIPS X 11 [22] Alzheimer X  X  PET, MRI Region Identification Neuroimage KDD X 13a [14] Alzheimer X  X  fMRI Network Discovery Neuroimage
SDM X 14 [18] AD, ADHD, HIV fMRI Supervised Tensor Learning Neuroimage eralize the conventional vector/matrix data models. An MRI sample corresponds a 3D-array, or three-mode ten-sor. An fMRI sample can be represented as (3D  X  time) a 4-dimensional array, or four-mode tensor. Other imaging data, such as DTI, can be represented as tenors with even higher modes. Ideal data mining methods for neuroimaging data should be able to handle the extremely high dimension-ality within the data, while preserving the tensor structure in the model [18].
 Brain Network Extraction : Another important chal-lenge in brain network analysis is that the network structure is very difficult to extract. In order to extract a meaning-ful brain network, the nodes and the edges of the networks should both be carefully extracted from neuroimaging data. Many research efforts are devoted to mining important brain regions [22; 14] and connection estimation [37; 19; 20]. Brain Network Analysis : Once the brain networks are constructed from the neuroimaging data, the next step is to analyze the networks. The challenges are that conventional network measures are optimally suited for binary/certain networks and are less well suited for weighted, uncertain, signed networks. Ideal data mining methods for brain net-work analysis should be able to take the unique properties on the edges (e.g., uncertainty, weights) into consideration. In some applications, we need to extract important connectiv-ity patterns from brain networks. For example, in the clas-sification task of brain networks, we need to extract discrim-inative subgraphs from the brain networks to figure out the differences among different groups of subjects: Alzheimer X  X  patient (AD) and normal controls (NC). These subgraphs are expected to be most discriminative and reliable in the uncertain brain networks.
 To summarize, we create a table of the different methods, and the different properties such as target disease, mining tasks or what type of information sources were used. This is provided in Table 1.
 The rest of the paper is organized as follows. We review tensor-based neuroimaging analysis in Section 2. The net-work extraction is presented in Section 3. We discuss brain network analysis in Section 4. Finally, we conclude the pa-per in Section 5. Neuroimaging data can naturally represented as tensor data [47; 14; 18]. A tensor is a high order generalization of a vector (first-order tensor) and a matrix ( second-order ten-sor), which is also known as multidimensional array. An m -th order tensor can be represented as A = ( a i 1 ,i 2 ,  X  X  X  ,i R In the context of neuroimaging data, each fMRI sample can be represented as (3D  X  time) a 4-dimensional array, or four-mode tensor. An MRI sample corresponds a 3D-array, or three-mode tensor. Other imaging data, such as DTI, can be represented as tenors with even higher modes.
 Based on the above definition, inner product, tensor norm, and tensor product can be defined as follows: Inner product : the inner product of two same-sized ten-Tensor norm : the norm of a tensor A is The norm of a tensor is a generalization of the Frobenius norm for matrices and of the l 2 norm for vectors. Tensor product : the tensor product A  X  B of tensors where each element is A m th-order tensor is a rank-one tensor if it can be defined as the tensor product of m vectors: A = a (1)  X  a (2)  X  X  X  X  X  X  a ( m ) . For rank-one tensors A = a (1)  X  a (2)  X  X  X  X  X  X  a ( m ) CP factorization : given a tensor A  X  R I 1  X  I 2  X  X  X  X  X  I an integer R , if it can be expressed as We call it a CP factorization of A .
 Major Challenges: Different from conventional data in vector space, the major research challenges of mining tensor data are as follows: High dimension : In neuroimaging tensor data, each sam-ple is usually represented as a high-dimensional multi-mode (also known as multi-way) array. One straightforward so-lution to tensor data mining is to reshape the tensors into vectors. However, the number of features will be extremely high. For example, a typical MRI image of size 256  X  256  X  256 voxels contains 16 , 777 , 216 features [49]. This makes traditional data mining methods prone to critical issues, such as overfitting, especially with a small or moderate-sized dataset.
 Tensor structure : Different from conventional vector data, tensor data can preserve the structural information of the high-dimensional space, such as the spatial relationships among different voxels in a 3-D image. These structural informa-tion can be very important in neuroimaging applications. For example, in MRI data, the values of adjacent voxels are usually correlated with each other. When converting tensors into vectors, such structural information will be lost. Suppose we have a training set of n pairs of samples { ( X for binary tensor classification problem. X i  X  R I 1  X  X  X  X  X  I the input of the neuroimaging sample, which is represented as a tensor of m -mode. y i  X  { X  1 , +1 } is the correspond-ing class labels of X i . For example, if the i -th subject has Alzheimer X  X  disease, the subject is associated with a positive label, i.e. , y i = +1. Otherwise, if the subject is in the con-trol group, i.e. the normal people, the subject is associated with a negative label, i.e. , y i =  X  1.
 Brain image classification tasks can be defined as a super-vised tensor learning problem [18]. The optimization prob-lem of supervised tensor learning is where W is the weight tensor of the separating hyperplane. b  X  R is the bias. C is the trade-off between the classification margin and misclassification error. The above optimization problem is a generalization of the standard SVM from vector data to tensor data.
 Nonlinear separability : In many neuroimaging applica-tions, the data is usually not linearly separable in the in-put space. Conventional supervised tensor learning methods which can preserve tensor structures are often based upon linear models. Thus these methods cannot efficiently solve nonlinear learning problems on tensor data.
 In the work [18], He et. al. studied the problem of su-pervised tensor learning with nonlinear kernels which can preserve the structure of the tensor data.
 into a Hilbert space The optimization problem becomes where  X  i are the Lagrangian multipliers and  X   X  ( X i ) , X  ( X are the inner product between the mapped tensors of X i and X j in the Hilbert space. Based on a suitable tensor kernel function  X  ( X i , X j ), the decision function can be written as Dual Tensor Kernel (DuSK): In order to preserve the tensor structure in both original space and feature space, we can use CP factorizations to define the tensor kernels. Similar to other kernel functions in vector space, the feature space of tensor data is a high-dimensional tensor space. We can factorize tensor data directly in both the feature space and the original space, which is equivalent to performing the following mapping: The function can be considered as the operation of mapping the original data into tensor feature space and then conduct-ing the CP factorization in the feature space. It is called the dual-tensorial mapping function (see Figure 1).
 Suppose we have the CP factorization of X , Y  X  R I 1  X  I tively. Then the CP factorization of the data can be mapped into the tensor product feature space, The DuSK is an extension of the kernels in the vector space to tensor space. Thus DuSK kernel can be applied to any kernel-based learning methods to solve supervised tensor learning problems. Brain networks are very different from conventional net-works, such as social networks or Web, where the nodes and edges of the networks are predefined, e.g., the users/friendship or the webpages/hyperlinks. In brain networks, either the nodes or the edges are defined beforehand, but derived from neuroimaging data.
 For the nodes of brain networks, it is essential to parcel-late cerebral cortex into a set of disjoint regions and to use these brain regions as the nodes. Depending on the scale-levels, the specific brain regions represented by nodes can Figure 2: Different brain parcellation methods and their functional networks [13]. (a) AAL (automated anatom-ical labeling) [41]. (b) Harvard Oxford (HO) derived from anatomical landmarks (sulci and gyral) [15]. (c) EZ (Eickhoff-Zilles) [16]. (d) TT (Talariach Daemon) [26]. (e) CC200 and CC400 are derived from functional parcellations [12]. The functional networks were derived from all pairwise correlations between ROIs. range from the small patches of cortex contained in indi-vidual MRI voxels to larger brain areas (e.g., dorsolateral prefrontal cortex). The structures of brain networks depend greatly on how the nodes are defined. Different parcellation methods will result in different network structures. For ex-ample, in Figure 2, we show six existing methods for brain parcellation, where the brain regions are partitioned differ-ently according to different criteria. We can see that the structures of brain networks are also quite different when different parcellation methods are used.
 For the edges of brain networks, it is essential to estimate different relationships among the brain regions [7; 35]. Ex-amples include functional connectivity [44; 14], structural connectivity, effective connectivity [21], etc. Different types of connectivity will result in totally different networks, and can capture different types of relationships among brain re-gions. Early work in brain parcellation focused on anatomical at-lases. Although much has been learned from these anatom-ical atlases, no functional or structural connectivity infor-mation was used to construct them. Thus an anatomically parcellated region (e.g., the anterior cingulate cortex) can contain subregions that are each characterized by dramat-ically different functional and structural connectivity pat-terns. These can significantly limit the utility of the con-structed networks. The reasons are as follows: when we construct a brain network based upon a brain parcellation, we need to integrate (e.g., average) the data (e.g., functional activities) within individual regions in order to reduce the noises. We also need to integrate the connections between each pair of regions in order to reduce the uncertainty of connections. Ideally, each of the brain regions should con-tain subregions of homogeneous connectivity patterns, in order to preserve the utility of the network. For example, in Figure 3(a), we show the connectivity patterns of four subregions, represented as nodes 1  X  -4  X  . We can see that nodes 1  X  and 2  X  share similar connectivity patterns, which are very different from those of nodes 3  X  and 4  X  . If we merge subregions with similar connectivity patterns into a larger region, as in Figure 3(b), the connectivity patterns are well preserved, because the network constructed can accu-rately represent the connectivity patterns of the subregions. However, if we merge subregions of different connectivity patterns into a larger region, as in Figure 3(c), the connec-tivity patterns can be distorted, because different patterns are integrated in the process of network construction. Defining the nodes for brain networks, which corresponds to the community detection problem of network data, is a challenging task. The reasons are as follows: In this direction, Huang et. al. [22] studied the problem of identifying brain regions that are related to Alzheimer X  X  disease from multi-modality neuroimaging data. Specially, MRI and PET are used to jointly identify disease related regions. MRI images can capture the structure information of the brain, while PET can capture the functional informa-tion of the brain. Both types are images can compensate each other. A sparse composite linear discriminant analysis model was proposed to identify brain regions from multiple types of imaging data.
 Several works exist for parcellating the brain into a set of brain regions for connectivity analysis. Early efforts on brain parcellation use anatomical atlases [38] through postmortem architectonic measurements, e.g., cell morphology. Such at-lases may contain subregions of heterogeneous functional or structural connectivity patterns. For resting-state func-tional connectivity analyses, different criteria have been used for evaluating the quality of a set of regions. (1) Function-ally homogeneity: the regions should be functionally homo-geneous [39]. The regionss voxels should have similar time courses [48] or produce similar functional connectivity pat-terns [10]. (2) Spatial contiguity: the regions should be spatially contiguous to preserve the interpretability of the parcellated regions [4; 33]. Spatial contiguity can also help identifying anatomically homogeneous regions, and hence preserve the interpretability of the connectivity results [39]. There are idiosyncratic differences among different types of edges that can be extracted from neuroimaging data. Graph Representation : Functional brain networks are typically undirected and weighted [34]. The edge weights can be positive or negative [32]. Effective connections are directed, from source region to target region. Structural networks can be unweighted (binary tractography [1]) or weighted (in probabilistic tractography [3]) and are strictly nonnegative.
 Interpretation : Structural networks can be thought of as the physical pathways along which the information flows. But functional connections cannot be interpreted in the same way, but can be thought of as the pair of regions that need to work together in order to perform a certain function. While effective connections corresponds to the causal relationships between the activities of different brain regions. Functional connections : For functional connections, many of the research efforts focus on using sparse learning meth-ods to derive a sparse network from functional neuroimaging data [37; 19]. In the work [37], the nodes of the brain net-work are given, which correspond to a set of brain regions. Then the functional activities within each region are aggre-gated by averaging the signals. In this way, the functional activity within the brain regions can be modeled as follows: Suppose we have n samples which are drawn from a multi-variate Gaussian distribution independently, x 1 ,  X  X  X  , x N (  X  ,  X ). The n samples correspond to the n time frames in functional imaging data, such as fMRI or PET. These n samples are assumed to be independent from each other, though this assumption may not always hold in neuroimag-ing data with high temporal resolutions. But for fMRI, this assumption usually hold pretty well in practice. Assume  X   X  R p , where we have p different brain regions.  X   X  R is the covariance matrix to be estimated. In order to induce sparsity in the inverse covariance matrix  X  =  X  1 , l 1 norm regularization was used in the estimation process. where S is the empirical covariance matrix, and  X  is a reg-ularization parameter. This was solved using a block coor-dinate descent method.
 Effective connections : For effective connections, many of the research works focus on using structure learning method for Bayesian Networks to derive a directed network from functional neuroimaging data. In the work [20], effective connections among brain regions are modeled as a Bayesian Network (BN). The nodes of the BN corresponds to the brain regions, while the directed arcs between two nodes corresponds to the effective connections. The brain network extraction problem in this scenario becomes the structure learning problem for BN. Similar to functional connections, l norm was also used to induce the sparsity within the net-work. Once the brain networks are constructed from the neuroimag-ing data, the next step is to analyze the networks. The challenges are that conventional network measures are opti-mally suited for binary networks and are less well suited for weighted and signed networks. This often necessitates the conversion of weighted and signed networks to binary and unsigned networks. Such conversions are made by limiting the scope of studies to only positively weighted edges and defining a weight threshold to convert weighted networks into binary networks. These binarizing and simplifying ma-nipulations are associated with great loss of information. (1) The threshold is often arbitrarily made. (2) Positively and negatively weighted edges are quite dif-An ideal method for brain network analysis should be able to overcome the above methodological problems by gener-alizing the network edges to positive and negative weighted cases.
 Conventional pattern mining research on brain networks can be divided into two schemes. (1) The first scheme is usually called a bag of edges, where (2) The second scheme is usually call graph invariants In brain network analysis, the ideal patterns we want to mine from the data should combine the two schemes to-gether. On the one hand, the pattern should be able to model the network connectivity patterns around the nodes, just like graph invariants methods. On the other hand, the pattern should be able to capture the changes in local areas, just like bag-of-edges methods. Subgraph patterns are more suitable for brain networks, which satisfy both of the above requirements. To determine whether a brain network functions normally or not, we can view the brain network derived from fMRI/PET data or DTI data as a graph and apply graph classification techniques which have been used in various applications, in-cluding drug discovery, i.e., predicting the effectiveness of chemical compounds on diseases [25]. Each graph object corresponds to the brain network of a subject in the study, which is associated with a label based upon certain proper-ties of the subject. For example, if a subject has Alzheimer X  X  disease, the graph object corresponding to the subject can be associated with a positive label. Otherwise, if the subject is in the control group, i.e. the normal people, the graph object is associated with a negative label.
 Mining discriminative subgraph patterns for graph objects has attracted much attention in data mining community due to its important role in selecting features for graph classi-fications, generating graph indices, etc. [46; 23; 9; 25; 40]. Much of the past research in discriminative subgraph feature mining has focused on certain graphs, where the structure of the graph objects are certain, and the binary edges repre-sent the  X  X resence X  of linkages between the nodes. However, in brain network data, there is inherent uncertainty about the graph linkage structure. Such uncertainty information will be lost if we directly transform uncertain graphs into certain graphs.
 Specially, in the work [24], the brain networks are modeled as uncertain graphs, where the edges are assigned with an probability of existence. Suppose we are given an uncertain graph dataset e D = { e G 1 ,  X  X  X  , e G n } that consists of n uncer-tain graphs. y = [ y 1 ,  X  X  X  ,y n ] &gt; corresponds to their class labels, where y i  X  X  +1 ,  X  1 } is the class label of e G
Definition 1 (Certain Graph). A certain graph is an undirected and deterministic graph represented as G = ( V,E ) . V = { v 1 ,  X  X  X  ,v n v } is the set of vertices. E  X  V  X  V is the set of deterministic edges.

Definition 2 (Uncertain Graph). An uncertain graph is an undirected and nondeterministic graph represented as e G = ( V,E,p ) . V = { v 1 ,  X  X  X  ,v n v } is the set of vertices. E  X  V  X  V is the set of nondeterministic edges. p : E  X  (0 , 1] is a function that assigns a probability of existence to each edge in E . p ( e ) denotes the existence probability of edge e  X  E . Consider an uncertain graph e G ( V,E,p )  X  e D , where each edge e  X  E is associated with a probability p ( e ) of being present. As in other works [51; 50], it is assumed that the uncertainty variables of different edges in an uncertain graph are independent from each other. All uncertain graphs in a dataset e D share a given set of nodes V , which corresponds to a parcellation of the brain regions.
 Each possible outcome of an uncertain graph e G corresponds to an implied certain graph G . Here G is implied from un-certain graph e G (denoted as e G  X  G ), iff all edges in E ( G ) are sampled from E ( e G ) according to their probabilities of existence in p ( e ) and E ( G )  X  E ( e G ). We have
Pr h e G  X  G i = Y The possible instantiations of an uncertain graph dataset e D = { e G 1 ,  X  X  X  , e G n } are referred to as worlds of each world corresponds to an implied certain graph dataset D = { G 1 ,  X  X  X  ,G n } . A certain graph dataset D is called as being implied from uncertain graph dataset e D (denoted as e D  X  D ), iff |D| = | e D| and  X  i  X  { 1 ,  X  X  X  , |D|} , e dataset e D , denoted as W ( e D ) = {D | e D  X  X } . An uncertain graph dataset e D corresponds to a probability distribution over W ( e D ). The probability of each certain graph dataset D  X  X  ( e D ) being implied by e D is Pr( e D  X  X  ). By assuming that different uncertain graphs are independent from each other, we have The concept of subgraph is then defined based upon certain graphs.

Definition 3 (Subgraph). Let g = ( V 0 ,E 0 ) and G = ( V,E ) be two certain graphs. g is a subgraph of G (denoted as g  X  G ) iff V 0  X  V and E 0  X  E . We use g  X  G to denote that graph g is a subgraph of G . We also say that G contains subgraph g .
 For an uncertain graph e G , the probability of e G containing a subgraph feature g is defined as follows: which corresponds to the probability that a certain graph G implied by e G contains subgraph g .
 Uncertain Graphs Subgraph Features Figure 2: Di ff erent types of subgraph features for uncertain graph classification classification. Accordingly, g 3 is the best subgraph fea-ture for uncertain graph classification.
 E ffi ciency &amp; Robustness: There are two additional problems need to be considered when evaluating fea-tures for uncertain graphs: 1) In an uncertain graph dataset, there are an exponentially large number of pos-sible instantiations of a graph dataset [17]. How can we e ffi ciently compute the discrimination score of a sub-graph feature without enumerating all possible implied datasets? 2) When evaluating the subgraph features, we should choose a statistical measure for the proba-blity disctribution of discrimination scores which is ro-bust to extreme values. For example, given a subgraph feature with (score, probability) pairs as (0 . 01 , 99 . 99%) and (+  X  , 0 . 01%), the expected score of the subgraph is +  X  , although this value is only associated with a very tiny probability.
 pose a general framework for mining discriminative sub-graph features in uncertain graph datasets, which is called Dug (Discriminative feature selection for Uncer-tain Graph classification). The Dug framework can ef-fectively find a set of discriminative subgraph features by considering the relationship between uncertain graph structures and labels based upon various statistical mea-sures. We propose an e ffi cient method to calculate the probability distribution of the scoring function based on dynamic programming. Then a branch-and-bound algo-rithm is proposed to search for the discriminative sub-graphs e ffi ciently by pruning the subgraph search space. Empirical studies on resting-state fMRI images of dif-ferent brain diseases (i.e., Alzheimer X  X  Disease, ADHD and HIV) demonstrate that the proposed method can obtain better accuracy on uncertain graph classification tasks than alternative approaches.
 Figure 4: A toy example of uncertain brain networks, and different types of subgraph features [24].
 The key issues of discriminative subgraph mining for un-certain graphs can be described as follows: The evaluation of discrimination scores for subgraph features in uncertain graphs is different from conventional subgraph mining prob-lems. For example, in Figure 4, we show an uncertain graph dataset containing 4 uncertain graphs e G 1 ,  X  X  X  , e G 4 class labels, + or  X  . Subgraph g 1 is a frequent pattern among the uncertain graphs, but it may not relate to the class labels of the graphs. Subgraph g 2 is a discriminative subgraph features when we ignore the edge uncertainties. However, if such uncertainties are considered, we will find that g 2 can rarely be observed within the uncertain graph dataset, and thus will not be useful in graph classification. Accordingly, g 3 is the best subgraph feature for uncertain graph classification.
 The work in [24] proposed a method based on dynamic pro-gramming to compute the probability distribution of the discrimination scores for each subgraph feature within an uncertain graph database. Then each of these probability distributions is aggregated to form a certain score based upon different statistical measures, including expectation, median, mode and  X  -probability, to select discriminative subgraphs. This paper provides an overview of the emerging area of brain network analysis, which has seen increasing attention in data mining communities in the recently years. Many research works on mining brain network data in the litera-ture are not recognized as such in a formal way. This paper provides an understanding of how these works related to different data mining problems and methods. We provided different ways to categorize the data mining problems in-volved, such as subgraph pattern mining, supervised tensor learning and network extraction. We discussed the issue of mining brain regions that are relevant to certain diseases and the connectivities among these regions.
 While brain networks are very challenging for data mining analysis, the problems are not unsurmountable. Many re-cent research efforts have been devoted to this area, which result in significant improvements in various dimensions. Data mining on brain networks seems to be an emerging area, which can be a fruitful research direction. [1] P. Basser, S. Pajevic, C. Pierpaoli, J. Duda, and A. Al-[2] P. Basser and C. Pierpaoli. Microstructural and phys-[3] T. Behrens, H. Berg, S. Jbabdi, M. Rushworth, and [4] P. Bellec, V. Perlbarg, S. Jbabdi, M. Pelegrini-Issac, [5] D. L. Bihan, E. Breton, D. Lallemand, P. Grenier, [6] B. Biswal, F. Yetkin, V. Haughton, and J. Hyde. Func-[7] E. Bullmore and O. Sporns. Complex brain networks: [8] T. Chenevert, J. Brunberg, and J. Pipe. Anisotropic [9] H. Cheng, D. Lo, Y. Zhou, X. Wang, and X. Yan. Iden-[10] A. Cohen, D. Fair, N. Dosenbach, F. Miezin, D. Dierker, [11] R. Craddock, G. James, P. Holtzheimer, X. Hu, and [12] R. Craddock, G. James, P. Holtzheimer, X. Hu, and [13] R. Craddock, S. Jbabdi, C. Yan, J. Vogelstein, [14] I. Davidson, S. Gilpin, O. Carmichael, and P. Walker. [15] R. Desikan, F. Segonne, B. Fischl, B. Quinn, B. Dick-[16] S. Eickhoff, K. Stephan, H. Mohlberg, C. Grefkes, [17] M. Fox and M. Raichle. Spontaneous fluctuations in [18] L. He, X. Kong, P. Yu, A. Ragin, and Z. Hao. Dusk: [19] S. Huang, J. Li, L. Sun, J. Ye, K. Chen, and T. Wu. [20] S. Huang, J. Li, J. Ye, A. Fleisher, K. Chen, T. Wu, [21] S. Huang, J. Li, J. Ye, A. Fleisher, K. Chen, T. Wu, [22] S. Huang, J. Li, J. Ye, T. Wu, K. Chen, A. Fleisher, [23] N. Jin, C. Young, and W. Wang. GAIA: graph classi-[24] X. Kong, P. Yu, X. Wang, and A. Ragin. Discriminative [25] X. Kong and P. S. Yu. Semi-supervised feature selection [26] J. Lancaster, M. Woldorff, L. Parsons, M. Liotti, [27] M. McKeown, S. Makeig, G. Brown, T. Jung, S. Kin-[28] M. Moseley, Y. Cohen, J. Kucharczyk, J. Mintorovitch, [29] J. Nolte. The human brain: an introduction to its func-[30] S. Ogawa, T. Lee, A. Kay, and D. Tank. Brain mag-[31] S. Ogawa, T. Lee, A. Nayak, and P. Glynn. [32] M. Rubinov and O. Sporns. Weight-conserving charac-[33] S. Smith, P. Fox, K. Miller, D. Glahn, P. Fox, [34] S. Smith, D. Vidaurre, C. Beckmann, M. Glasser, [35] O. Sporns. Networks of the Brain . MIT Press, 2010. [36] O. Sporns, G. Tononi, and R. Kotter. The human con-[37] L. Sun, R. Patel, J. Liu, K. Chen, T. Wu, J. Li, [38] J. Talairach and P. Tournoux. Co-planar stereotaxic [39] B. Thirion, G. Flandin, P. Pinel, A. Roche, P. Ciuciu, [40] M. Thoma, H. Cheng, A. Gretton, J. Han, H. Kriegel, [41] N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, [42] X. Wang, P. Foryt, R. Ochs, J. Chung, Y. Wu, T. Par-[43] X. Wang, P. Foryt, R. Ochs, J. Chung, Y. Wu, T. Par-[44] X. Wang, P. Foryt, R. Ochs, J. Chung, Y. Wu, T. Par-[45] S. Xiang, L. Yuan, W. Fan, Y. Wang, P. Thompson, and [46] X. Yan, H. Cheng, J. Han, and P. Yu. Mining significant [47] J. Ye, K. Chen, T. Wu, J. Li, Z. Zhao, R. Patel, M. Bae, [48] Y. Zang, T. Jiang, Y. Lu, Y. He, and L. Tian. Regional [49] H. Zhou, L. . Li, and H. Zhu. Tensor regression with [50] Z. Zou, H. Gao, and J. Li. Discovering frequent sub-[51] Z. Zou, J. Li, H. Gao, and S. Zhang. Frequent subgraph Data mining, the discovery of knowledge from data, bridges several disciplines such as database management, artificial intelligence, statistics, visualization and the domain of the data, e.g., biology or engineering. Knowledge discovered by mining the data can be used for various purposes such as developing decision support systems and intelligent tutors. In this paper we present such a data mining problem in the mechanical engineering domain where knowledge discov-ery from the data is performed using statistical approaches, to conduct predictive analysis for decision support. More specifically, we focus on the engine health problem which consists of using existing data on the behavior of an engine in order to predict whether the engine is capable of func-tioning well (i.e., it is healthy) and to offer suggestions on preventive maintenance. The data we use for this predic-tive analysis consists of graphs that plot process parameters such as the vibration and temperature of the engine with respect to time. In this paper we define the problem in de-tail, propose a solution based on statistical inference tech-niques, summarize our experimental evaluation and discuss the applications of this work in various fields from a decision support angle.
 H.2.8 [ Database Management ]: Database Applications-data mining, scientific databases Design, Experimentation, Human Factors Decision-making, Estimation, Statistical Techniques In various scientific domains data on process parameters ob-tained from laboratory experiments is often used to discover knowledge for assisting decision-making in corresponding real industrial processes. In this paper, we deal with such data from the domain of Mechanical Engineering pertaining to the behavior of an engine. The term engine refers to a machine for converting any of various forms of energy into mechanical force and motion that can be used within various devices such as cars, trains and airplanes [1]. When an en-gine is in use, there are process parameters associated with it that control its behavior such as vibration, noise, carbon dioxide level and temperature. These are briefly explained below. The behavior of the engine is typically depicted by plotting these process parameters with respect to time. The result of plotting each such parameter is a time-series graph, i.e., the x-axis represents time and the y-axis represents one of the parameters. An example of such a graph is shown in Figure 1. Here, the vibration of the engine is observed over a given time interval. This enables scientists to visualize engine be-havior with respect to how frequently it vibrates. Likewise, graphs of other process parameters provide visualization of the respective phenomena pertaining to the engine. The engine data on process parameters serves an excel-lent source of knowledge that can be discovered to predict whether the engine is good enough to be used in the real world or whether it needs to be repaired to avoid damage. Accordingly, the term engine health characterizes the re-liability or goodness of an engine for use in various applica-tions. The process of repairing an engine for avoiding future damage is known as preventive maintenance .
 Scien tists are interested in knowledge discovery from engine data in order to answer questions posed by users such as: 1. Is a given engine healthy? 2. What can be stated about future engine health? 3. Does an engine depict anomalous behavior? 4. What could be the causes of potential faults? 5. What preventive maintenance is needed? This is precisely the problem addressed in this paper. Given the data on process parameters for a particular engine, in the form of time series graphs, the goal is to predict whether the engine is healthy, answer related questions and make rec-ommendations accordingly. It is called the engine health problem and falls within the general realm of predictive analysis , i.e., the process of predicting or estimating ten-dencies in advance based on analyzing existing data. This can assist in making decisions about the engine use in cor-responding applications. We propose an approach to solve the engine health prob-lem deploying classical techniques in the area of statistical inference that are found to be useful in estimation-related problems. More specifically, we consider concepts such as tolerance limits and survival probability, which will be elab-orated in the next section. Furthermore, we develop suit-able heuristics as needed for the analysis based on domain knowledge, statistical concepts and visual inspection. The significant tasks in this work include: We evaluate our proposed solution using data from the do-main of Mechanical Engineering. The evaluation presented in this paper is conducted with data obtained from diesel en-gines in particular. We consider snapshots of the time-series data consisting of process parameter graphs after extract-ing individual parameters. The results of our analysis are summarized in this paper and are corroborated by domain experts.
 The applications of this work include automobile manufac-turing, locomotive design, aircraft monitoring and advance warning systems. In all these applications it is useful to an-swer questions pertaining to engine health and preventive maintenance in order to assist in making crucial decisions about engine use. The predictive analysis plays an impor-tant role in decision support in such applications as elabo-rated later in this paper. The rest of this paper is organized as follows. Section 2 de-scribes our proposed solution approach for the engine health problem. Section 3 summarizes the experimental evalua-tion. Section 4 discusses the targeted applications of this work considering a decision support perspective. Section 5 outlines the related work in the area. Section 6 gives the conclusions. The solution we propose for the engine health problem is built heuristically based on techniques in the area of statis-tical inference . The aim of statistical inference is to use the information contained in the sample data to increase our knowledge about the sampled population. Inferential statis-tics can be subdivided into two major regions, namely, esti-mation (point and interval) and hypothesis testing. In this paper we have deployed some estimation techniques such as tolerance and prediction limits for predictive analysis of engine health.
 We describe our predictive analysis approach with reference to the data on the vibration parameter. This is considered to be the most important of all the parameters that affect engine health as gathered from domain knowledge. Simi-lar ideas for predictive analysis can be applied to the other parameters. We use the statistical inference techniques of tolerance limits, prediction limits and survival probability to conduct the predictive analysis as elaborated below. The concept of tolerance limits in statistical inference can be explained as follows. Tolerance intervals cover a fixed proportion of the population with a stated confidence. Let  X  denote the cont ent and  X  denote the confidence level of a tolerance interval. Then a (  X ,  X  ) tolerance interval in con-structed in such a way that the interval is to contain a pro-portion of at least  X  of the population with 100  X  % confi-dence. More details on this especially in the context of the normal distribution can be found in [9].
 is a (  X  ,  X  ) upper tolerance limit based on  X  X and S 2 and w here z  X  is the  X  th quantile of the standard normal distribution, and t m, X  (  X  ) denotes the  X  th quantile of a non-central t distribution with df = m and noncentrality param-eter  X  . The quantity k is referred to as a tolerance factor. Similarly, a lower tolerance limit (LTL) can be obtained by replacing the + sign by the  X  sign. Note that a (  X ,  X  ) upper tolerance limit also provides a 100  X  % upper confidence limit for the  X  th quantile and in a similar manner a (  X ,  X  ) lower tolerance limit also provides a 100  X  % lower confidence limit for the (1  X   X  )th quantile.
 An exact two-sided tolerance interval for the normal distri-bution is given by  X  X  X  kS x , where k is the tolerance fac-tor. Odeh (1978) computed the exact tolerance factor k for n = 2(1)98 , 100,  X  = .75, .90, .95, .975, .99, .995, .999 and  X  = . 5 , . 75 , . 90 , . 95 , . 975 , . 99 , . 995. A FORTRAN program to compute the values of k is given in [2]. Prediction limits serve to make estimations about the future based on current data. We define upper and lower prediction limits as follows. The 1  X   X  Upper Prediction Limit (UPL) for a future measurement is given by whe re t m,c denotes the c th quantile of Student X  X  t distribu-tion [19] with df = m .
 The Lower Prediction Limit (LPL) can be obtained by re-placing the + sign in the above equation with the  X  sign. Thus, a 1  X   X  lower prediction limit for a future measurement is given by whe re t m,c denotes the c th quantile of Student X  X  t distribu-tion with df = m [19]. Survival probability helps to determine how reliable a par-ticular measure is. Hence it is also referred to as reliabil-ity. It is explained below [12]. Suppose we want to esti-mate the survival probability at time t based on a sample X , ..., X n from a normal distribution. The survival proba-bility is given by S = P ( X &gt; t ). The lower confidence limit for S can be found out using the concept of one-sided toler-ance limits mentioned above. For example, if a (  X ,  X  ) lower tolerance limit for the Normal(  X ,  X  ) distribution is greater than t , then we can conclude that S is at least  X  with confi-dence  X  . Therefore, an approximate one-sided 100  X  % lower confidence limit for S is given by So , a lower limit for survival probability denoted as LSP can be obtained as the solution (with respect to  X  ) of the equation The concepts of tolerance interval, prediction interval and survival probability applied to the time-series graphs for en-gine data serve as the basis for heuristically predicting the engine health and making recommendations for preventive maintenance accordingly. (Note that a heuristic by defini-tion is a rule-of-thumb likely to lead to the right answer but not essentially proven theoretically).
 The tolerance interval calculates the range which should con-tain a certain proportion of each individual measurement in the population. There are two different proportions associ-ated with the tolerance interval, namely, a coverage percent-age and a degree of confidence. Based on these, we propose the following heuristic.
 Tolerance Limit Heuristic: If the (0 . 99 , 0 . 95) tolerance interval for the vibration data from a given engine falls within the (  X  3 . 5 , 3 . 5) range, then that given engine is likely to be healthy .
 This means that, if we measure 100 data points for vibration from the time-series graphs 100 times, 95 of those times we expect to catch at least 99 of those data points inside the limits (  X  3 . 5 , 3 . 5). This should give us an idea about what vibration values to expect for a healthy engine. If we notice that during a certain time the vibration values are exceeding these two limits, we can check the engine for faults. Unlike the tolerance interval, the prediction interval pro-vides estimates about the future values based upon past or present background samples. For example, for a healthy en-gine, the prediction limits enable us to estimate the future vibration values with a certain degree of confidence with-out actually carrying out the experiment. We propose the prediction limit heuristic here as follows.
 Prediction Limit Heuristic: If the 95% lower prediction limit for a sample signal from a given engine exceeds 2 . 5 , then it can be used to estimate future engine health . Furthermore, reliability or survival probability gives us an idea about the consistency of one X  X  measures. In our prob-lem of engine maintenance, we can estimate the chance of occurrence of an anomalous vibration data point with re-spect to a sample of vibration data obtained from a healthy engine. We thus propose the survival probability heuristic as follows.
 Survival Probability Heuristic: If the lower limit for the survival probability of a given sample of engine data matches that of a known healthy engine at least 90%, with confidence 95%, then the given sample is not anomalous .
 These heuristics can be used in conjunction with each other for predicting the health of current and future engines based on the analysis of existing data. All the heuristics have been determined by using visual inspection, domain knowledge and statistical concepts. Although not proven in theory, they a re found to yield good results in practice, as evident from our evaluation. It is to be noted that these heuris-tics may need to be adapted with modifications for other domains based on the nature of the data. However, the fundamental logic used in the predictive analysis, i.e., using statistical inference guided by heuristics, is still applicable. There are different parameters involved in engine health, namely, vibration, noise, carbon dioxide level and tempera-ture. Correlations are likely to exist between these parame-ters which poses a challenge in individual analysis. However, in order to conduct analysis to determine the impact of each individual parameter on engine health, we assert that it is desirable to isolate each parameter. This is done in order to single out the causes of specific problems in relation to a particular parameter.
 Hence, the individual parameter impact is analyzed as fol-lows. Note that the engine is built so as to allow each piece to be tested for its signature. When the engine is assembled each piece is therefore equipped with a sensor. By collect-ing the relevant signature, we extract the individual graph of a given parameter with respect to time. Using this infor-mation, we execute the process of extracting the individual parameter data rather than directly using the output from the engine which could contain a mixture of parameters. This extracted data on individual process parameters forms the basis of our predictive analysis. There is no specific formula available in the domain that allows us to make a distinction between a healthy and a faulty engine. Hence, one of the issues we deal with is to determine suitable threshold levels for engine health. Three main criteria are involved here as follows: Hence, by using all the three criteria above, engine health thresholds have been proposed in the form of heuristics to guide the predictive analysis as outlined in the previous sub-section. These have been used experimentally and have been found to yield good results (as presented in Section 3). A false alarm is a situation where a system may give a warn-ing of being faulty even though it is not. An example with respect to our work is the case of an automobile running over an irregular road. The engine in such a case may be nor-mal. However, the corresponding time-series graphs may still show an abnormal trend due to external factors. We identify the possibility of such false alarms occurring in our system.
 While conducting the predictive analysis we consider the ef-fect of such situations by taking into account how often the engine data crosses the thresholds in the concerned graphs. If for example, this happens only once in a particular graph, this is attributed to be a potential false alarm, i.e., the en-gine could still be considered healthy. However, if abnormal behavior occurs repeatedly, it is reported that the engine is not healthy. This reasoning is based primarily on observa-tion.
 This sets the stage for proposing a solution to avoid false alarms in the future. Upon discussions with domain ex-perts, we suggest the following method to help alleviate the false alarm problem. We recommend that an analyzer be mounted within the engine itself such that when it senses abnormal behavior it gives a direct warning. This would reduce the chances of signaling abnormal behavior due to external factors thereby helping to minimize the effect of false alarms. Based on the discussion so far, we present our fundamen-tal algorithms. Algorithm 1 is for engine health estimation and Algorithm 2 is for anomaly detection. These serve to conduct the predictive analysis setting the stage for decision support.
 Given these algorithms, we address some of the anticipated questions that users could pose with respect to decision sup-port. These have been listed earlier and can be answered as follows. 1. Is a given engine healthy? The answer to this ques-2. What can be stated about future engine health? 3. Does an engine depict anomalous behavior? The 4. What could be the causes of potential faults? Algorithm 1 Engin e Health Estimation Require: Given engine signal data X (For each parameter: Vibration, Noise, CO 2 level, Temperature) Require:  X  : for (1  X   X  ) prediction,  X  : content,  X  : confi-dence OUT P UT 1: Estimation for given engine OUT P UT 2: Estimation for future engines H g : Given engine healthy (0/1) H f : Future engine healthy (0/1) UT L : Upper tolerance limit LT L : Lower tolerance limit UP L : Upper prediction limit
LP L : Lower prediction limit while (  X   X  0 . 99)  X  (  X   X  0 . 95) do end while while  X   X  5 do end while if H g = 1 then else end if if H f = 1 then else end if PRINT OUT P UT 1, OUT P UT 2 Algorithm 2 Anoma ly Detection Require: Given engine signal data X (For each parameter) Require: Healthy engine signal data H (From Algorithm 1) Require:  X  : content,  X  : confidence OUT P UT : Anomaly detection for engine LSP : Lower limit for survival probability
A g : Anomaly in given engine (0/1) while (  X   X  . 90)  X  (  X   X  . 95) do end while if A g = 0 then else end if
PRINT OUTPUT 5. What preventive maintenance is needed? The While answering these and other questions for prospective users, it is important to note that there is a range between engine health and engine failure. It is analogous to the dif-ference between a healthy person and someone on the verge of death. A healthy engine is highly suitable for use in cor-responding applications while a failed engine is not at all usable. The range in between is for engines that can be used but are not very healthy and thus could cause prob-lems. Our predictive analysis approach targets the safer end of this range, geared towards keeping the engine as healthy as possible. Hence, the approach is useful for decision sup-port in targeted applications where it is helpful to make decisions in advance considering various possible scenarios. We conducted experiments on our predictive model using engine data from the domain of Mechanical Engineering. This data consisted of graphs that plot vibration versus time. Thus, the impact of the vibration parameter on en-gine health was evaluated. The data used for evaluation, i.e., Figure 2: Graph of Vibration (Signal with Gaussian noise) versu s Time test data was distinct from the data used for building the model, i.e., training data. A summary of our experimental evaluation is presented below. Figure 2 shows an example of the vibration graph used in our experimental evaluation. The term signal in this graph refers to the vibration signal which is time-series data. The vibration data that was used in the experiments contained Gaussian noise 1 . (This is however different from the Noise parameter in the engine data which refers to the combustion of the engine). We define this experimental noise data as X i = 1 , ..., 41. A quantile-quantile plot showed an excellent fit of these data to a normal distribution. The mean is given by  X  X = 0 . 00964 and the standard deviation by S x = 1 . 24181. We obtain the following plots for the vibration data shown in Figure 2. The summary plot depicted in Figure 3 summa-rizes the distribution of the data indicating where most of the data is concentrated. The normal probability plot that appears in Figure 4 checks how closely the data fits normal distribution.
 Tolerance Limits : In Table 1, we present 95% one-sided upper tolerance limits and the two-sided tolerance interval along with the corresponding tolerance factors.
 Prediction Limits : Usin g the formula (3), we computed the 90% prediction limit as 1.647 and 95% prediction limit as 2.126. movement of electricity in the line is called Gaussian noise. It is similar to white noise, but confined to a narrower range of frequencies. You can actually see and hear Gaussian noise you tune your TV to a channel that is not operating. Figure 4: Normal Probability Plot for Vibration Data Probability of Exceeding a Threshold Value : Supp ose we want to find a 95% lower limit for the probability that a sample signal exceeds 2.5, that is, P ( X &gt; 2 . 5). Using (5), we get So lving for the noncentrality parameter, we get z  X   X  15 . 6637 . This implies that z  X  =  X  2 . 4463 or  X  = . 0072. Thus, the probability that the signal exceeds 2.5 in a sample is at least 0.0072 with confidence 95%. The (0 . 95 , 0 . 95) two-sided tolerance interval for the engine vibration data is given by (  X  3 . 02 , 3 . 04) which can be inter-preted to mean that the engine is healthy using the tolerance limit heuristic (See Algorithm 1).
 We can expect 95% of the values for engine vibration to fall under the lower (-3.02) and upper (3.04) limits with 95% confidence. Figure 5 provides the time-series plot of engine vibration data with the two bands representing the lower and upper limits of the (0 . 95 , 0 . 95) tolerance limits. Initially, the vibrations are under the tolerance limits which signifies that the engine is healthy but after a certain amount of time an aberrant behavior is noticed since the vibrations are increasingly exceeding the tolerance limits. This should tell the experimenter that a change in the process has oc-curred which means that the engine is behaving abnormally. Hence, preventive measures should be taken, i.e., the engine should be fixed in order to prevent it from going to a faulty stage.
 The experimental observations can be discussed in a real world context as follows. Suppose, we are interested in studying the anomalous behavior of the diesel engine. We let the engine run for a long time and collect the data for signal vibration against time. The time series plot of the vibration data along with the ( . 95 , . 95) two-sided tolerance limits is presented in Figure 5. The term signal + noise in this plot denotes the vibration signal with Gaussian noise while the two horizontal lines denote the tolerance limits. From the figure, we can notice a change in the process given by the fact that vibrations are exceeding the limits on an average during the latter stages. This work can be useful in decision support in the areas of manufacturing, engineering design and aerospace technol-ogy. For example, our predictive analysis approach can be used in automobile manufacturing, locomotive design, air-craft monitoring and advance warning systems. We discuss these targeted applications below. Automakers face the challenge of making appropriate de-cisions to create the best-in-class vehicles and maintain a corporate reputation for performance and value [4]. A tech-nique often used in the making of cars is predictive process engineering that develops measurements and standards for accurately predicting the outcome of production processes so that parts are made right the first time. For example, or-ganizations such as NIST (National Institute of Standards and Technology, USA) provide inputs to the automobile in-Figure 5: Vibration Data with Tolerance Limits (The two horiz ontal lines are the upper and lower limits of the two-sided tolerance interval) dustry in order to enhance manufacturing processes using predictive process engineering.
 Consider this in the context of engine vibration. The vi-bration of a moving part represents the balance of the part. This relates to wear and tear and hence to the life of the part. Interpreting the time-related changes in vibration am-plitude and frequency provides information about the state of elements in a gas turbine [4]. Therefore, our approach which includes predictive analysis of vibration data from an engine can be useful to interpret such information and give suggestions to support decisions about the manufacturing of the automobile in order to yield a better product. In the design of locomotives, crucial decisions need to be made about certain factors that can be controlled in order to improve its operation. One such factor is crashworthiness. A study on locomotive crashworthiness has been conducted as presented in [22]. This deals with a range of collision scenarios. It supports the efforts of the Locomotive Crash-worthiness Working Group of the Federal Railroad Admin-istration of USA. Crashworthiness itself can be related to other factors such as engine health.
 Predictive analysis can be of help here. Computer auto-mated modal testing of a rotating component can be em-ployed. Also, since engines control systems and compo-nents, the vibrational environment of this equipment can be measured by a scanning vibrometer. This can be used to predict factors such as crashworthiness with suitable tech-niques. Our approach can be used here to assist in decision-making about the development of other models such as those for crashworthiness estimation during locomotive design. In recent years there have been developments in airborne and ground monitoring of aircraft gas turbine engines [5]. A device called the piezoelectric accelerometer along with enhanced electronic processing technology leads to the uni-versal employment of an aircraft system that deploys vi-bration analysis. The storage of vibration data at several in-fli ght engine conditions aims to enable ground crew to balance the fan without a ground engine run.
 Our approach for predictive analysis of engine health thus finds a potential application here. Flight simulators could be developed that predict in advance the capability of an aircraft in performing its required operation thereby provid-ing decision support in the ground and airborne monitoring of the engines. This could for example be used to train pilots and ground crew in aircraft monitoring. In the engines used in vehicles today, there are chips pro-grammed to signal engine failures [10]. These chips typi-cally raise an alarm when the engine is close to breakdown. Several cars, for example, would flag a low battery signal when the engine appears as though will cease to function soon. This happens in other vehicles too such as aircrafts and locomotives. As stated earlier, there is obviously a range between engine health and engine failure and our approach useful in decision support heads towards safer end of this range.
 It could therefore be potentially useful to signal an alarm when the engine reaches a level such that it is no longer con-sidered very healthy. This does not mean that it is on the verge of breakdown. However, it require preventive main-tenance to avoid future problems. Thus our approach can potentially be used to build advance warning systems in ve-hicles to notify of possible engine failure well in advance rather than waiting for the stage when the engine is close to breakdown. Such systems would be complementary to existing warning systems in current vehicles [17]. Data mining techniques in conjunction with those in re-lated fields allow a search for valuable information in large volumes of data. The explosive growth in databases has created a need to develop technologies that use informa-tion and knowledge intelligently. Thus, data mining ap-proaches present increasingly important research areas in various fields. The last decade saw a very strong growth in this arena and novel methods have been developed in neu-ral networks, algorithm architecture, dynamic prediction-based, analysis of systems architecture, intelligence agent systems, modeling, knowledge-based systems, system opti-mization and information systems, with their applications in research and practical domains [13].
 Statistical techniques have often been used in data mining. In [6] an overview of the common issues between data min-ing and statistics is presented. It can be thought of au-tomated exploratory data analysis of large complex data sets. These include decision trees, rule induction, near-est neighbors, feature extraction and visualization. These methods have a major impact on variety of fields such as biology, healthcare and business as big data analytics is on the forefront. Our work falls in this general category, fo-cusing specifically on the use of statistical inference in data mining.
 In [3] the topic of visual data mining is discussed with ref-erence to current research areas of interest. Issues addressed are high-dimensional visualization, pixel-oriented techniques, clustering and classification, visual frameworks, combining visualization and data mining and domain-specific applica-tions. We consider one more paradigm, namely, statistical techniques in visual data mining. This is particularly in the context of scientific analysis.
 Computational statistics is used in areas such as exploratory graphics [23]. While presentation graphics usually summa-rize information to be displayed, exploratory graphics are used to look for results. For example, exploratory graphics may be drawn to support the data investigations of an an-alyst. They are typically fast and informative rather than slow and precise. The problem discussed in our paper is also of this nature. We explore engine data to conduct predictive analysis. Thus, our goals also involve providing estimated answers with efficiency.
 In [15] they propose a time-series analysis approach which combines wavelet analysis with visualization tools such as SiZer and SiNos. Although wavelets can be used for com-parison when the data being analyzed involves time series, this process is computationally intensive. Our proposed ap-proach provides efficient analysis. Moreover, our goals are catered towards predictive analysis which goes a step beyond just visually comparing the data.
 Microarray data analysis for gene expressions using statisti-cal inference is presented in [14]. They consider variation of ratios between measured fluorescent intensities at differ-ent spots in a microarray. We can draw an analogy here since we use methods based on statistical inference in our analysis. However, the nature of our data is different. We analyze graphical plots of engine parameters dealing with issues such as parameter correlations, tolerance limits and false alarms. Hence, the specific inference-based methods need to be adapted accordingly.
 Developments in IT and high performance computing make huge data sets available in scientific domains, e.g., a simula-tion can produce TBs of data in a few hours which humans could take weeks to analyze. Other examples are data from medical imaging, bioinformatics, and remote sensing. Thus, there is tremendous interest in scientific communities to ex-plore emerging data mining approaches in conjunction with related domains. The work of [8] provides supercomputing professionals an insight into several scientific and engineer-ing domains, including astrophysics, medical imaging, com-putational fluid dynamics, structural mechanics, and ecol-ogy. They present discovery-driven (instead of traditional hypothesis-driven) approaches to automatically extract pat-terns from data, especially useful in scientific domains for large data sets. Our work fits in this realm as we consider statistical techniques along with domain-driven approaches in scientific fields for knowledge discovery with respect to specific problems, in our case, predictive analysis of engine health.
 Data mining approaches are suitably deployed in scientific domains for decision support problems. Pawlish et al. [16] address the issue of decision support in environmental man-agement. They aim to make data centers more sustainable with greater efficiency, cost-effectiveness and greenness while maintaining productivity. They mine real data on scien-tific parameters, e.g., temperature, humidity, CPU utiliza-tion and server sprawl and analyze the results of their ex-periments to propose strategies for optimizing performance. For example, they propose migrating some data center oper-ations to the cloud, by conducting analysis with case-based reasoning and decision trees incorporating various scenarios. They head towards a hybrid model, considering privacy, se-curit y, availability etc. Some carefully selected operations are executed using cloud services while other major ones re-side on host servers. Their proposed strategies are useful in decision support for data centers, helping to green the planet. We can draw a parallel here, with respect to de-cision support for engine health which helps in preventive maintenance. This is analogous to maintaining a green en-vironment for a healthy planet. These scientific issues head towards prevention which is better than cure, where domain-driven data mining is are useful.
 Prognostic health monitoring (PHM) technologies have found an ever expanding array of applications in the industrial en-vironments. In particular, robust detection of mechanical damage in an engine has been demonstrated via processing of high-speed, one-dimensional accelerometer (vibration due to damaged parts) data. Such data collected with and with-out the damaged parts shows distinctive signatures that are quantitatively and qualitatively separable. Pattern Recog-nition techniques drive the signature generation and abnor-mality detection process through the use of data-driven tech-niques that estimate deviation of the engine from normal behavior [7].
 The ability to measure these signatures in real-time has many applications in auto industry product and function op-timization. Due to the immense effect of rough environment and corruptive parameters of engine, it is often impossible to collect and evaluate the parameters required for health monitoring. However, there are algorithms that are capable of performing this task analytically and quantitatively at a low computational cost (real-time) and high efficiency. An example of such algorithms [20] works based on a heuristic analysis of similar parameters to assess an image and quan-tify the quality of the image by characterizing important aspects of human visual quality.
 Our work in this paper is orthogonal to such approaches. In the context of the problems described here, the issue of engine health is important. It caters to one end of the spec-trum, of maintaining healthy behavior as opposed to waiting for the other end, where failure occurs. Data mining ap-proaches overlapping with statistical methods and domain-specific analysis in engineering are very helpful here in draw-ing conclusions for decision support and related applications. These also present the potential for future work in these ar-eas in conjunction with each other.
 Future work obviously comes with further challenges. Han et al. have presented a list of challenges that provide the potential for further research in data mining for science and engineering domains in their work [11]. These include spa-tiotemporal and multimedia data mining; knowledge discov-ery from moving object data, RFID data and sensor network data; multidimensional online analytical mining oriented to-wards data cubes; mining from data streams; knowledge discovery from text, Web and other unstructured data; and analyzing information networks.
 We agree and emphasize that these challenges can be viewed in the light of conducting research in data mining along with its related fields encompassing database management, artifi-cial intelligence, statistics and visualization in addition to a detailed study of the respective science and engineering do-mains, with the involvement of domain experts. This mul-tidisciplinary research would continue to present interesting and exciting opportunities to the data mining community. In this paper, we deal with the problem of engine health. Given time-series graphs on process parameters depicting the behavior of an engine, we conduct predictive analysis to find out whether an engine is healthy and to make sug-gestions on preventive maintenance useful in decision sup-port. We deploy concepts from statistical inference that we perceive as being pertinent to domain-driven data mining. These concepts are tolerance limits, prediction limits and survival probability and we them to heuristically estimate engine health. Upon running experiments with diesel en-gine data from the domain of Mechanical Engineering, it is found that our approach is feasible in the context of this domain and its targeted applications. This work is useful in decision support for automobile manufacturing, locomotive design, aircraft monitoring and advance warning systems. Future work involves the correlated analysis of multiple pa-rameters together. We hope this will yield even more inter-esting results. This work started while all the authors were at Virginia State University. It has been partly supported by the sources of each author. We acknowledge the startup funds at Mont-clair State University for Aparna Varde and the respective support to the other authors. We particularly thank the NASA NSTI grant for the financial and NASA GSFC for the scientific support of this research. [1] Brotherton, T., Chadderdon, G. and Grabill, P.  X  X uto-[2] Eberhardt, K., Mee, R. and Reeve, C.  X  X omputing Fac-[3] Eick, S. and Keim, D.  X  X isual Data Mining: KDD [4] Fine, C., St. Clair, R., Lafrance, J. and Hillebrand, D. [5] Ford, T.  X  X ngine Vibration Analysis X . Aircraft Engi-[6] Friedman, J.  X  X ata Mining and Statistics: What is The [7] Getman, A., Cooper, C.D., Key, G., Zhou, H., Fran-[8] Grossman, R., Kamath, C., Kumar, V. Data M ining [9] Guttman, I. Statistical Tolerance Regions: Classical [10] Katsumi, A. Failure Warning System of Electric Power [11] Han, J., Gao, J.  X  X esearch Challenges for Data Min-[12] Krishnamoorthy, K. Mathew, T., Mukherjee, S. [13] Liao, S.H., Chu, P.H., Hsiao, P.Y.,  X  X ata mining tech-[14] Newton, M., Kendziorski, C., Richmond, C., Blattner. [15] Park, C., Godtliebsen, F., Taqqu, M., Stoev, S. [16] Pawlish, M., Varde A., Robila, S.,  X  X ecision Support [17] Rahman, A. Motor Vehicle Early Warning System . [18] Sandia Fluid Mechanics Group. Engine Combustion [19] Student (Gosset, W. S.).  X  X he Probable Error of a [20] Sheybani, E., Garcia-Otero, S., Adnani, F., Javidi, G., [21] Toyota Motor Sales. Emission Analysis . Technical Re-[22] Tyrell, D., Severson, K., Marquis, B., Martinez, E., [23] Unwin, A., Chen, C. and Hardle, W. Handbook of Com-[24] Zheng, G. and Leung, A.  X  X nternal Combustion Engine  X  X  X  X  X  X  X  X  X  X  X  X  X  Dr. Shubhabrata Mukherjee is a Research Assistant Pro-fessor of Medicine at University of Washington. He ob-tained his Ph.D. and M.S. in Statistics from University of Louisiana, Lafayette, M.S. in Mathematics from IIT Kharag-pur and B.S. in Mathematics from University of Calcutta. His papers have been published in reputed journals such as the Technometrics, PLoS One. Dr. Mukherjee has authored a chapter in an edited book  X  X iomathematics: Modelling and Simulation X  published by World Scientific. His current research areas are psychometrics and statistical genetics. Dr. Aparna Varde is an Associate Professor of Computer Science at Montclair State Univ, NJ, with her PhD and MS (Comp. Sci.) from WPI, Massachusetts, and BE (Comp. Eng.) from Univ of Bombay, India. She was an Assistant Professor (Comp. Sci.) at Virginia State Univ, Visiting Senior Researcher at Max Planck Institute for Informat-ics, Germany, and Software Engineer at Lucent and Citi-corp. Dr. Varde has around 60 publications (IEEE, ACM, AAAI etc.), 2 software trademarks, research grants from NSF and PSEG, and is a research advisor / committee member for PhD, MS and BS students. She has been a panelist in NSF X  X  IIS, reviewer for journals (TKDE, TKDD, DMKD, VLDBJ, DKE, AIEDAM etc.), co-chair of IEEE and ACM PhD Workshops, and PC Member at conferences, e.g., ICDM, EDBT, SDM, DEXA. Her teaching and research spans Data Mining, Databases and Artificial Intelligence. Dr. Giti Javidi is an Associate Professor in Computer Sci-ence at Virginia State University. She obtained her Ph.D. in IT and M.S. in Computer Science from University of South Florida and a B.S. in Computer Science from University of Central Oklahoma. Dr. Javidi has software trademarks, journal articles and conference papers (IEEE, ACM, and ASEE). In addition to teaching, her main research interests are in the field of new information technologies applied to collaborative learning, virtual learning, information visual-ization, usability engineering and human-computer interac-tion. Dr. Javidi is the recipient of NSF/ITEST grant for a three years (2007-2010) Digispired project.
 Dr. Ehsan Sheybani is a Full Professor in Computer En-gineering at Virginia State University, VA. He obtained his Ph.D., MS, and BS in Electrical Engineering from University of South Florida, Florida State University, and University of Florida, respectively. Dr. Sheybani has journal articles and conference papers (IEEE, ACM, ASEE, SPIE). His pro-fessional activities include serving as a PI/Co-PI for NSF, NIH, NASA, DoD, and DEd grant proposals, reviewer for several IEEE transactions, track-chair of IEEE/ACM WTS 2006 and 2007 symposia, and reviewer for NIH and DoD. His teaching and research areas are Digital Signal Process-ing and Wireless Sensor Networks.
 Many sciences have made significant breakthroughs by adopt-ing online tools that help organize, structure and mine infor-mation that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collabo-rate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, indi-vidual scientists, as well as students and practitioners. When Galileo Galilei discovered the rings of Saturn, he did not write a scientific paper. Instead, he wrote his discovery down, jumbled the letters into an anagram, and sent it to his fellow astronomers. This was common practice among respected scientists of the age, including Leonardo, Huygens and Hooke.
 The reason was not technological. The printing press was well in use those days and the first scientific journals already existed. Rather, there was little personal gain in letting your rivals know what you were doing. The anagrams ensured that the original discoverer alone could build on his ideas, at least until someone else made the same discovery and the solution to the anagram had to be published in order to claim priority.
 This behavior changed gradually in the late 17th century. Members of the Royal Society realized that this secrecy was holding them back, and that if they all agreed to publish their findings openly, they would all do better [19]. Under the motto  X  X ake nobody X  X  word for it X , they established that scientists could only claim a discovery if they published it first, if they detailed their experimental methods so that results could be verified, and if they explicitly gave credit to all prior work they built upon.
 Moreover, wealthy patrons and governments increasingly funded science as a profession, and required that findings be published in journals, thus maximally benefiting the public, as well as the public image of the patrons. This effectively created an economy based on reputation [19; 28]. By pub-lishing their findings, scientists were seen as trustworthy by their peers and patrons, which in turn led to better collab-oration, research funding, and scientific jobs. This new cul-ture continues to this day and has created a body of shared knowledge that is the basis for much of human progress. Today, however, the ubiquity of the internet is allowing new, more scalable forms of scientific collaboration. We can now share detailed observations and methods (data and code) far beyond what can be printed in journals, and interact in real time with many people at once, all over the world. As a result, many sciences have turned to online tools to share, structure and analyse scientific data on a global scale. Such networked science is dramatically speeding up discov-ery because scientists are now capable to build directly on each other X  X  observations and techniques, reuse them in un-foreseen ways, mine all collected data for patterns, and scale up collaborations to tackle much harder problems. Whereas the journal system still serves as our collective long-term memory, the internet increasingly serves as our collective short-term working memory [29], collecting data and code far too extensive and detailed to be comprehended by a sin-gle person, but instead (re)used by many to drive much of modern science.
 Many challenges remain, however. In the spirit of the jour-nal system, these online tools must also ensure that shared data is trustworthy so that others can build on it, and that it is in individual scientists X  best interest to share their data and ideas.
 In this paper, we discuss how other sciences have succeeded in building successful networked science tools that led to important discoveries, and build on these examples to in-troduce OpenML, a collaboration platform through which scientists can automatically share, organize and discuss ma-chine learning experiments, data, and algorithms.
 First, we explore how to design networked science tools in Section 2. Next, we discuss why networked science would be particularly useful in machine learning in Section 3, and de-scribe OpenML in Section 4. In Section 5, we describe how OpenML benefits individual scientists, students, and ma-chine learning research as a whole, before discussing future work in Section 6. Section 7 concludes. Networked science tools are changing the way we make dis-coveries in several ways. They allow hundreds of scientists to discuss complex ideas online, they structure information from many scientists into a coherent whole, and allow any-one to reuse all collected data in new and unexpected ways. In this section we discuss how to design such online tools, and how several sciences have used them to make important breakthroughs.
 Nielsen [29] reviews many examples of networked science, and explains their successes by the fact that, through the interaction of many minds, there is a good chance that some-one has just the right expertise to contribute at just the right time: Designed serendipity Because many scientists have com-Dynamic division of labor Because each scientist is es-Designed serendipity and a dynamic division of labor occur naturally when ideas, questions, data, or tools are broadcast to a large group of people in a way that allows everyone in the collaboration to discover what interests them, and react to it easily and creatively. As such, for online collaborations to scale, online tools must make it practical for anybody to join and contribute any amount at any time. This can be expressed in the following  X  X esign patterns X  [29]: Still, even if scientists have the right expertise or skill to contribute at the right time, they typically also need the right incentive to do so.
 As discussed, scientists actually solved this problem cen-turies ago by establishing a reputation system implemented using the best medium for sharing information of the day, the journal. Today, the internet and networked science tools provide a much more powerful medium, but they also need to make sure that sharing data, code and ideas online is in scientists X  best interest.
 The key to do this seems to lie in extending the reputation system [29]. Online tools should allow everyone to see ex-actly who contributed what, and link valuable contributions to increased esteem amongst the users of the tools and the scientific community at large. The traditional approach to do this is to link useful online contributions to authorship in ensuing papers, or to link the reuse of shared data to citation of associated papers or DOI X  X . 1 Moreover, beyond bibliographic measures, online tools can define new measures to demonstrate the scientific (and so-cietal) impact of contributions. These are sometimes called altmetrics [35] or article-level metrics 2 . An interesting ex-ample is ArXiv 3 , an online archive of preprints (unpub-lished manuscripts) with its own reference tracking system (SPIRES). In physics, preprints that are referenced many times have a high status among physicists. They are added to resumes and used to evaluate candidates for scientific jobs. This illustrates that what gets measured, gets re-warded, and what gets rewarded, gets done [29; 30]. If scholarly tools define useful new measures and track them accurately, scientists will use them to assess their peers. Online tools can scale up scientific collaborations to any number of participants. In mathematics, Fields medalist Tim Gowers proposed 4 to solve several problems that have eluded mathematicians for decades by uniting many minds in an online discussion. Each of these Polymath projects state a specific, unsolved math problem, is hosted on a blog or wiki 6 , and invites anybody who has anything to say about the problem to chip in by posting new ideas and partial progress.
 Designed serendipity plays an important role here. Each idea, even if just a hunch, may spark daughter ideas with those who happen to have just the right background. In-deed, several polymaths  X  X ound themselves having thoughts they would not have had without some chance remark of an-other contributor X . 7 There is also a clear dynamic division of labor, with many mathematicians throwing out ideas, crit-icizing them, synthesizing, coordinating, and reformulating the problem to different subfields of mathematics. Blogs and wikis are ideally suited as tools, because they are designed to scale up conversations. They ensure that each contribution is clearly visible, stored and indexed, so that anybody can always see exactly what and how much you contributed. 8 Moreover, everyone can make quick, small contributions by posting comments, all ideas are organized into threads or pages, and new threads or pages can be opened to focus on subproblems. In addition, anybody can quickly scan or search the whole discussion for topics of in-terest.
Digital Object Identifiers can be cited in papers. See, for instance, DataCite (http://www.datacite.org). http://article-level-metrics.plos.org/alm-info/ http://arxiv.org http://gowers.wordpress.com/2009/01/27/is-massively-collaborative-mathematics-possible http://polymathprojects.org http://michaelnielsen.org/polymath1 http://gowers.wordpress.com/2009/03/10/polymath1-and-open-collaborative-mathematics/
Similarly, open source software development tools also al-low anyone to see who contributed what to a project. Protected by a set of ground rules, individual scientists also receive rewards for sharing their ideas: Authorship Each successful polymath project resulted in Visibility Making many useful contributions may earn you Productivity A scientist X  X  time and attention is limited. It Learning Online discussions are very engaging. Nascent Online tools also collect and organize massive amounts of scientific data which can be mined for interesting patterns. For instance, the Sloan Digital Sky Survey (SDSS) is a col-laboration of astronomers operating a telescope that system-atically maps the sky, producing a stream of photographs and spectra that currently covers more than a quarter of the sky and more than 930,000 galaxies. 9 Although for a limited time, the data is only available to members of the collaboration, the SDSS decided to share it afterwards with the entire worldwide community of astronomers through an online interface [39]. 10 Since then, thousands of new and im-portant discoveries have been made by analysing the data in many new ways [7].
 These discoveries are again driven by designed serendipity. Whereas the Polymath projects broadcast a question hoping that many minds may find a solution, the SDSS broadcasts data in the belief that many minds will ask unanticipated questions that lead to new discoveries. Indeed, because the telescope collects more data than a single person can com-prehend, it becomes more of a question of asking the right questions than making a single  X  X orrect X  interpretation of the data. Moreover, there is also a clear dynamic division of labor: the astronomers who ask interesting questions, the SDSS scientists who collect high quality observations, and the astroinformaticians who mine the data all work together doing what they know best.
 Moreover, making the data publicly available is rewarding for the SDSS scientists are well.
 Citation Publishing data openly leads to more citation be-http://skyserver.sdss3.org
The data is also used in Microsoft X  X  WorldWide Tele-scope (http://www.worldwidetelescope.org) and Google Sky (http://www.google.com/sky).
 Funding Sharing the data increases the value of the pro-The evolution towards more open data is not at all limited to astronomy. We are  X  X apping and mining X  just about every complex phenomenon in nature, including the brain [21; 15], the ocean [18], gene sequences, genetic variants in humans [12], and gene functions [31]. In many of these projects, the data is produced piece by piece by many different scientists, and gathered in a central database which they all can access. Online tools are also enhancing the relationship between sci-ence and society. In citizen science [36], the public is actively involved in scientific research. One example is Galaxy Zoo [24], where citizen scientists are asked to classify the galax-ies from the SDSS and other sources such as the Hubble Space Telescope. Within a year, Galaxy Zoo received over 50 million classifications contributed by more than 150,000 people. These classifications led to many new discoveries, and the public data releases are cited hundreds of times. Once again, designed serendipity occurs naturally. Unex-pected observations are reported and discussed on an online forum, and have already resulted in the serendipitous dis-covery of the previously unknown  X  X reen pea X  galaxies [9],  X  X assive red spirals X  [26], and other objects such as  X  X anny X  X  Object X  [23], named after the volunteer who discovered it. Moreover, in a dynamic division of labor, citizen scientists take over tasks that are too time-consuming for professional astronomers. In fact, the overall classifications proved more accurate than the classifications made by a single astronomer, and obtained much faster. More engaged volunteers also participate in online discussions, or hunt for specific kinds of objects.
 Galaxy Zoo and similar tools are also designed for scala-bility. The overall task is split up in many small, easy to learn tasks, each volunteer classifies as many galaxies as she wants, and classifications from different users are combined and organized into a coherent whole.
 Finally, there are many different reasons for citizen scien-tists to dedicate their free time [36]. Many are excited to contribute to scientific research. This can be out of a sense of discovery, e.g., being the first to see a particular galaxy, or because they believe in the goal of the project, such as fighting cancer. Many others view it as a game, and find it fun to classify many images. Some citizen science projects explicitly include a gamification component [11], providing leaderboards and immediate feedback to volunteers. Finally, many volunteers simply enjoy learning more about a specific subject, as well as meeting new people with similar interests. Citizen science is being employed in many more scientific endeavors 11 , including protein folding [11], planet hunting [37], classifying plankton 12 , and fighting cancer 13 . Many of them are collecting large amounts of valid scientific data, and have yielded important discoveries. https://www.zooniverse.org/ http://www.planktonportal.org/ http://www.cellslider.net Machine learning is a field where a more networked approach would be particularly valuable. Machine learning studies typically involve large data sets, complex code, large-scale evaluations and complex models, none of which can be ad-equately represented in papers. Still, most work is only published in papers, in highly summarized forms such as ta-bles, graphs and pseudo-code. Oddly enough, while machine learning has proven so crucial in analysing large amounts of observations collected by other scientists, such as the SDSS data discussed above, the outputs of machine learning re-search are typically not collected and organized in any way that allows others to reuse, reinterpret, or mine these results to learn new things, e.g., which techniques are most useful in a given application. This makes us duplicate a lot of effort, and ultimately slows down the whole field of machine learning [43; 14]. Indeed, without prior experiments to build on, each study has to start from scratch and has to rerun many experiments. This limits the depth of studies and the interpretability and gen-eralizability of their results [1; 14]. It has been shown that studies regularly contradict each other because they are bi-ased toward different datasets [20], or because they don X  X  take into account the effects of dataset size, parameter op-timization and feature selection [33; 17]. This makes it very hard, especially for other researchers, to correctly interpret the results. Moreover, it is often not even possible to rerun experiments because code and data are missing, or because space restrictions imposed on publications make it practi-cally infeasible to publish many details of the experiment setup. This lack of reproducibility has been warned against repeatedly [20; 38; 32], and has been highlighted as one of the most important challenges in data mining research [16]. Many machine learning researchers are well aware of these issues, and have worked to alleviate them. To improve repro-ducibility, there exist repositories to publicly share bench-marking datasets, such as UCI [2], LDC 14 and mldata Moreover, software can be shared on the MLOSS website 16 . There also exists an open source software track in the Jour-nal for Machine Learning Research (JMLR) where short de-scriptions of useful machine learning software can be sub-mitted. Also, some major conferences have started checking submissions for reproducibility [25], or issue open science awards for submissions that are reproducible. 17 Moreover, there also exist experiment repositories. First, meta-learning projects such as StatLog [27] and MetaL [8], and benchmarking services such as MLcomp 18 run many algorithms on many datasets on their servers. This makes benchmarks comparable, and even allows the building of meta-models, but it does require that code be rewritten to run on their servers. Moreover, the results are not organized to be easily queried and reused.
 Second, data mining challenge platforms such as Kaggle [10] http://www.ldc.upenn.edu http://mldata.org http://mloss.org http://www.ecmlpkdd2013.org/open-science-award/ http://www.mlcomp.org and TunedIT [44] collect results obtained by different com-petitors. While they do scale and offer monetary incentives, they are adversarial rather than collaborative. For instance, code is typically not shared during a competition. Finally, we previously introduced the experiment database for machine learning [6; 43], which organizes results from different users and makes them queryable through an online interface. Unfortunately, it doesn X  X  allow collaborations to scale easily. It requires researchers to transcribe their exper-iments into XML, and only covers classification experiments. While all these tools are very valuable in their own right, and we will build on them in this paper, they fail many of the requirements for scalable collaboration discussed above. It can be quite hard for scientists to contribute, there is often no online discussion, and they are heavily focused on benchmarking, not on sharing other results such as models. OpenML 19 is a place where machine learning researchers can automatically share data in fine detail and organize it to work more effectively and collaborate on a global scale. It allows anyone to challenge the community with new data to analyze, and everyone able to mine that data to share their code and results (e.g., models, predictions, and evalu-ations). 20 OpenML makes sure that each (sub)task is clearly defined, and that all shared results are stored and organized online for easy access, reuse and discussion.
 Moreover, OpenML links to data available anywhere online, and is being integrated [41] in popular data mining platforms such as Weka [13], R [5; 40], MOA [4], RapidMiner [42] and KNIME [3]. This means that anyone can easily import the data into these tools, pick any algorithm or workflow to run, and automatically share all obtained results. The OpenML website provides easy access to all collected data and code, compares all results obtained on the same data or algorithms, builds data visualizations, and supports online discussions.
 Finally, it is an open source project, inviting scientists to extend it in ways most useful to them. OpenML offers various services to share and find data sets, to download or create scientific tasks , to share and find im-plementations (called flows ), and to share and organize re-sults. These services are available through the OpenML website, as well as through a REST API for integration with software tools. 21 Anyone can challenge the community with new data sets to analyze. Figure 1 shows how this is done through the website. To be able to analyse the data, OpenML accepts a limited number of formats. For instance, currently it re-quires the ARFF 22 format for tabular data, although more formats will be added over time.
OpenML is available on http://www.openml.org
In this sense, OpenML is similar to data mining challenge platforms, except that it allows users to work collaboratively, building on each other X  X  work.
In this paper, we only discuss the web interfaces. API details can be found on http://www.openml.org/api http://www.cs.waikato.ac.nz/ml/weka/arff.html The data can either be uploaded or referenced by a URL. This URL may be a landing page with further information or terms of use, or it may be an API call to large reposi-tories of scientific data such as the SDSS. 23 OpenML will automatically version each newly added data set. Option-ally, a user-defined version name can be added for reference. Next, authors can state how the data should be attributed, and which (creative commons) licence they wish to attach to it. Authors can also add a reference for citation, and a link to a paper. Finally, extra information can be added, such as the (default) target attribute(s) in labeled data, or the row-id attribute for data where instances are named. For known data formats, OpenML will then compute an array of data characteristics. For tabular data, OpenML currently computes more than 70 characteristics 24 , includ-ing simple measures (e.g., the number of features, instances, classes, missing values), statistical and information-theoretic measures (e.g., skewness, mutual information) and land-markers [34]. Some characteristics are specific to subtypes of data, such as data streams. These characteristics are useful to link the performance of algorithms to data characteristics, or for meta-learning [43] and algorithm selection [22]. OpenML indexes all data sets and allows them to be searched through a standard keyword search and search filters. Each data set has its own page with all known information. This includes the general description, attribution informa-tion, and data characteristics, but also statistics of the data distribution and, for each task defined on this data (see be-low), all results obtained for that task. As will be discussed below, this allows you to quickly see which algorithms (and parameters) are best suited for analysing the data, and who achieved these results. It also includes a discussion section where the data set and results can be discussed.
In some cases, such as Twitter feeds, data may be dynamic, which means that results won X  X  be repeatable. However, in such tasks, repeatability is not expected.
A full list can be found on http://www.openml.org/a See, for instance, http://www.openml.org/d/1
Figure 2: An OpenML task (of task type classification). Obviously, a data set alone does not constitute a scientific challenge. We must first agree on what types of results are expected to be shared. This is expressed in task types : they define what types of inputs are given, which types of output are expected to be returned, and what scientific protocols should be used. For instance, classification tasks should in-clude well-defined cross-validation procedures, labeled input data, and require predictions as outputs. 26 OpenML currently covers classification, regression, learning curve analysis and data stream classification. Task types are created by machine learning (sub)communities through the website, and express what they think should ideally be shared. In some cases, additional support may be required, such as running server-side evaluations. Such support will be provided upon request. Complete description: http://www.openml.org/t/type/1 If scientists want to perform, for instance, classification on a given data set, they can create a new machine learning task online. Tasks are instantiations of task types with specific inputs (e.g., data sets). Tasks are created once, and then downloaded and solved by anyone.
 Such a task is shown in Figure 2. In this case, it is a clas-sification task defined on data set  X  X nneal X  version 1. Next to the data set, the task includes the target attribute, the evaluation procedure (here: 10-fold cross-validation) and a file with the data splits for cross-validation. The latter en-sures that results from different researchers can be objec-tively compared. For researchers doing an (internal) hyper-parameter optimization, it also states the evaluation mea-sure to optimize for. The required outputs for this task are the predictions for all test instances, and optionally, the models built and evaluations calculated by the user. How-ever, OpenML will also compute a large range of evaluation measures on the server to ensure objective comparison. 27 Finally, each task has its own numeric id, a machine-readable XML description, as well as its own web page including all runs uploaded for that task, see Figure 2. Flows are implementations of single algorithms, workflows, or scripts designed to solve a given task. They are uploaded to OpenML as shown in Figure 3. Again, one can upload the actual code, or reference it by URL. The latter is especially useful if the code is hosted on an open source platform such as GitHub or CRAN. Flows can be updated as often as needed. OpenML will again version each uploaded flow, while users can provide their own version name for reference. Ideally, what is uploaded is software that takes a task id as
The evaluation measures and the exact code can be found on http://www.openml.org/a.
 input and then produces the required outputs. This can be a wrapper around a more general implementation. If not, the description should include instructions detailing how users can run an OpenML task (e.g., to verify submitted results). Attribution information is similar to that provided for data sets, although with a different set of licences. Finally, it is encouraged to add descriptions for the (hyper)parameters of the flow, and a range of recommended values.
 It is also possible to annotate flows with characteristics, such as whether it can handle missing attributes, (non)numeric features and (non)numeric targets. As with data sets, each flow has its own page which combines all known information and all results obtained by running the flow on OpenML tasks, as well as a discussion section.
 Figure 5: Portion of the page for data set  X  X nneal X . It com-pares, for a classification task, the results obtained by differ-ent flows on that data set, for multiple parameter settings. Runs are applications of flows on a specific task. They are submitted by uploading the required outputs (e.g. predic-tions) together with the task id, the flow id, and any pa-rameter settings. There is also a flag that indicates whether these parameter settings are default values, part of a pa-rameter sweep, or optimized internally. Each run also has its own page with all details and results, shown partially in Figure 4. In this case, it is a classification run. Note that OpenML stores the distribution of evaluations per fold (shown here as standard deviations), and details such as the complete confusion matrix and per-class results. We plan to soon add graphical measures such as ROC curves. Runtimes and details on hardware are provided by the user.
 Moreover, because each run is linked to a specific task, flow, and author, OpenML will aggregate and visualize results accordingly.
 For instance, Figure 5 shows a comparison of results ob-tained on a specific classification task. Each row represents a flow and each dot represents the performance obtained in a specific run (for different parameter settings). Hovering over a dot reveals more information, while clicking on it will pull up all information about the run. Users can also switch between different performance metrics.
 Conversely, Figure 6 shows a comparison of results obtained by a specific flow on all tasks it has run on. Each row rep-resents a task (and data set), and each dot the obtained performance. Additionally, it is possible to color-code the results with parameter values. Here, it shows the number of trees used in a random forest classifier from small (blue, left) to large (red, right). Again, clicking each dot brings up all run details. As such, it is easy to find out when, how, and by whom a certain result was obtained.
 OpenML also provides several other task-specific visualiza-tions such as learning curves. Moreover, it provides an SQL endpoint so that users can (re)organize results as they wish by writing their own queries. All results can be downloaded from the website for further study, and all visualizations can be exported. The database can also be queried programmat-ically through the API.
 Figure 6: Portion of the page for flow  X  X eka.RandomForest X . It compares, for classification tasks on different data sets, the results obtained by this flow for different parameter set-tings. Here, colored by the number of trees in the forest. As stated above, OpenML features an API so that scientific software tools can connect to it to download data or up-load new results. However, existing tools can also connect to OpenML by simply adding a few lines of code, and with-out any knowledge of the API. Indeed, OpenML provides language-specific libraries that take care of all server com-munication. For instance, software written in Java would use the OpenML Java interface to download tasks and up-load results. More precisely, a method getTask(id) will re-turn a Java object containing all data to run the task, and a method submitRun(outputs) will take the obtained re-sults and submit them to OpenML. We also aim to provide command-line tools for connecting to OpenML.
 On top of that, OpenML is being integrated in several popu-lar machine learning environments, so that it can be used out of the box. These plugins can be downloaded from the web-site. Figure 7 shows how OpenML is integrated in WEKA X  X  Experimenter [13]. After selecting OpenML as the result destination and providing your login credentials, you can add a number of tasks through a dialogue (or simply pro-vide a list of task id X  X ), and add a number of WEKA algo-rithms to run. Behind the scenes, the plugin will download all data, run every algorithm on every task (if possible) and automatically upload the results to OpenML. The results will also be locally available in WEKA for further analysis. For data stream mining, one can use the MOA [4] plugin as shown in Figure 8. Similarly to WEKA, users can select OpenML tasks, and then run any algorithm on them while uploading all runs to OpenML in the background.
 Finally, researchers that use R can use the openml package as shown in Figure 9. One first downloads a task given a task id, then runs the task by providing a learner, and finally uploads the run by providing the task, learner, results and user authentication. While we do plan to integrate OpenML into other environments as well, at the time of writing these are still in development.
 Through OpenML, we can initiate a fully networked ap-proach to machine learning. In this section we compare OpenML to the networked science tools described before, and describe how it helps scientists make new discoveries, how it allows collaborations to scale, and how it benefits individual scientists, students and a more general audience. By sharing and organizing machine learning data sets, code and experimental results at scale, we can stimulate designed serendipity and a dynamic division of labor. Similar to the SDSS, by organizing and  X  X roadcasting X  all data, code and experiments, many minds may reuse them in novel, unforeseen ways.
 First, new discoveries could by made simply by querying all combined experiments to answer interesting questions. These question may have been nearly impossible to answer before, but are easily answered if a lot of data is already available. In addition, with readily available data, it be-comes a routine part of research to answer questions such as  X  X hat is the effect of data set size on runtime? X  or  X  X ow important is it to tune hyperparameter P? X  With OpenML, we can answer these questions in minutes, instead of having to spend days setting up and running new experiments [43]. This means that more such questions will be asked, possibly leading to more discoveries.
 Second, we can mine all collected results and data charac-teristics for patterns in algorithm performance. Such meta-learning studies could yield insight into which techniques are most suited for certain applications, or to better understand and improve machine learning techniques [43].
 Third, anyone could run into unexpected results by brows-ing through all collected data. An example of this is shown in Figure 10, which is a continuation of the results shown in Figure 6: while the performance of a random forest classi-fier should increase (or stagnate) when more trees are added to the forest (red dots), it sometimes happens that it de-creases. As in Galaxy Zoo, such serendipitous discoveries can be discussed online, combining many minds to explore several possible explanations.
 Finally, beyond experiments, data sets and flows can also be reused in novel ways. For instance, an existing technique may prove extremely useful for analysing a new data set, bringing about new applications. OpenML also enables a dynamic division of labor: large-scale studies could be undertaken as a team, or hard ques-tions could be tackled collaboratively, with many scientists contributing according to their specific skills, time or re-sources.
 Figure 10: An unexpected result: the performance of a ran-dom forest descreases as more trees are added to the forest. Scientists, possibly from other domains, can focus the atten-tion of the community on an important problem. This can be done by adding new data sets (and tasks) to OpenML and collaborating with the machine learning community to analyse it. Some may suggest techniques that would oth-erwise not be considered, while others are especially skilled at designing custom-built workflows, running large-scale ex-periments, or improving code. Conversely, the scientists that contributed the data can provide direct feedback on the practical utility of suggested approaches, interpret the generated models, and otherwise guide the collaboration to the desired outcome. Such collaborations can scale to any number of scientists. OpenML also helps to coordinate the effort, e.g., by organizing all results per task (see Figure 6), so that everybody can track each other X  X  progress, and discuss ideas and results online.
 Another case is that of benchmark studies. While it is im-portant that a new algorithm be compared against the state of the art, it is often time-consuming to hunt down their implementations and to figure out how to run them. On OpenML, each researcher that invents a new algorithm can focus on experimenting with that algorithm alone, knowing best how to apply it on different tasks. Next, she can in-stantly reuse the results from all other shared algorithms, ran by their original authors. As such, a very complete overview of the state of the art emerges spontaneously. Finally, students and citizen scientists can also contribute to research simply by using the OpenML plugins to experiment while they learn about machine learning techniques. As discussed in section 2.1, these benefits emerge faster if online collaborations are allowed to scale.
 First of all, it is easy to make small contributions to OpenML. When using any of the OpenML plugins, you can easily import a task, run any algorithm or workflow, and auto-matically export the results to OpenML. You can just per-form a single run, a few, or thousands without much ef-fort. Moreover, scientists who know of new interesting data sets or algorithms can easily add them through the website, and watch how others start experimenting with them. It is even easier to browse through the discussions running on OpenML, and leave a comment or suggestion. Alternatively, one can browse the results shared on the website, and draw attention to unexpected results that are worth investigating. Even contributing a single run, data set or comment can be valuable to the community, and may stimulate more work in that direction. More committed scientists can contribute in many other ways, such as creating new tasks and task types, adding new data characterizations or evaluation measures, and integrating OpenML in new tools and environments. Moreover, OpenML tasks naturally split up complex stud-ies into tasks which can be run independently by many scientsists according to their skills, as discussed in Section 5.1. Tasks also split the machine learning community into smaller subcommunities (e.g., clustering) which focus on a single task type, or subgroups focusing on a single task (e.g. galaxy clustering). Designed serendipity and dynamic divi-sion of labor also occur in small but active subcommunities. They are not held back if other communities are less active. Next, OpenML constructs a rich and structured information commons , building a database of all data sets, flows, tasks, runs, results, scientists, and discussions. OpenML also ag-gregates results in different ways, e.g., visualizing results per task and flow (see Figures 5 and 6). Keyword searches and filters make it easy to find resources, and more complex questions can be answered through the SQL interface, or by downloading data and analysing it using other tools. As a result, all information is also open but easily filtered . The website organizes all results per task, data set and flow, so that researchers can focus on what interests them most, without being distracted by the activity of other scientists. In future work, we also aim to filter results by their authors. Finally, OpenML establishes, and in some cases enforces, a scientific approach to sharing results. Indeed, OpenML tasks set a certain standard of scientific quality and trust-worthiness by defining how experiments must be run and what must be reported. Because the code is shared when uploading runs, it is possible for others to verify results, and the server-side evaluations makes results objectively compa-rable. OpenML also makes clear who contributed what (and when), and how it is licenced. Every shared algorithm, flow, run or comment can be attributed to a specific person, and this information is always shown when someone views them online. How do you, as an individual scientist, benefit from sharing your experiments, data and code on OpenML? First, you gain more time. OpenML assists in most of the routine and tedious duties in running experiments: finding data sets, finding implementations, setting up experiments, and organizing all experiments for further analysis. More-over, when running benchmark experiments on OpenML, you can directly compare them with the state of the art, reusing other, comparable results. In addition, you can an-swer routine research question in minutes by tapping into all shared data, instead of losing days setting up new exper-iments. Finally, having your experiments stored and orga-nized online means they are available any place, any time, through any browser (including mobile devices), so you can access them when it is convenient. Second, you gain more knowledge. Linking your results to everybody else X  X  has a large potential for new discoveries. This was discussed in Section 5.1: you can answer previously impossible questions, mine all combined data, and run into unexpected results. It also makes it easy to check whether certain observations in your data are echoed in the observa-tions of others. Next, with OpenML you can interact with other minds on a global scale. Not only can you start discus-sions to answer your own questions, you can also help others, and in doing so, learn about other interesting studies, and forge new collaborations. Finally, by reusing prior results, you can launch larger, more generalizable studies that are practically impossible to run on your own. Third, OpenML helps you build reputation by making your work more visible to a wider group of people, by bringing you closer to new collaborators, and by making sure that others know how to credit you if they build on any of your work.
 Citation OpenML makes sure that all your contributions, Altmetrics OpenML will also automatically track how of-Productivity OpenML allows you to contribute efficiently Visibility You can increase your visibility by contributing Funding Open data sharing is increasingly becoming a re-No publication bias Most journals have a publication bias: OpenML can also substantially help students in gaining a better understanding of machine learning. Browsing through organized results online is much more accessible than brows-ing through hundreds of papers. It provides a clear overview of the state of the art, interesting new techniques and open problems. As discussed before, students can contribute in small or big ways to ongoing research, and in doing so, learn more about how to become a machine learning researcher. Online discussions may point to new ideas or point out mis-takes, so they can learn to do it better next time. In short, it gives students and young scientists a large playground to learn more quickly about machine learning and discover where they can make important contributions. In this section, we briefly discuss some of the key sugges-tions that have been offered to improve OpenML, and we aim to implement these changes as soon as possible. In fact, as OpenML is an open source project, everyone is welcome to help extend it, or post new suggestions through the web-site. One typically runs experiments as part of a study, which ideally leads to a publication. Scientists should therefore be able to create online studies on OpenML, that combine all relevant info on one page. Such studies reference all runs of interest, either generated for this study or imported from other OpenML studies, and all data sets and flows under-lying these runs. Additionally, textual descriptions can be added to explain what the study is about, and any sup-plementary materials, such as figures, papers or additional data, can be uploaded and attached to it.
 If the study is published, a link to this online study can be added in the paper, so that people can find the original experiments, data sets and flows, and build on them. As such, it becomes the online counterpart of a published paper, and you could tell people to cite the published paper if they reuse any of the data. An additional benefit of online studies is that they can be extended after publication.
 Moreover, based on the underlying runs, OpenML can au-tomatically generate a list of references (citations) for all underlying data sets, flows and other studies. This helps authors to properly credit data that they reused from other OpenML scientists. Similar to arXiv, OpenML can also au-tomatically keep track of this so that authors can instantly view in which studies their contributions are being reused. Finally, similar to the polymath projects, such studies could be massively collaborative studies, aimed at solving a hard problem, and driven by many people providing ideas, ex-periments, data or flows. As such, each study should have a discussion section where questions can be asked, sugges-tions can be made and progress can be discussed. Similar to the polymath studies, it also makes sense if studies link to other studies that tackle specific subproblems, and if the study was linked to a wiki page for collaborative writing. To keep focus on the results of a given study, it can act as a filter, hiding all other results from the website so that only the contents of that study are visible. There may be cases where you want all of OpenML X  X  bene-fits, but do not want to make your data public before pub-lication. On the other hand, you may want to share that data with trusted colleagues for collaboration or feedback, or allow friends to edit your studies, e.g., to add new runs to it. It therefore makes sense if, for a limited amount of time, studies, data sets or flows can be flagged as private or  X  X riends only X . Still, scientists should agree that this is a temporary situation. When you wish to be attributed for your work, you must first make it publicly available. In addition, in highly experimental settings, most results may not be interesting as such. Scientists are always able to delete those results or mark them as deprecated. When many scientists work together to design a flow for a specific task, it is useful to show which flows are currently performing best, so that others can build on and improve those flows. However, it is also important to show which contributions had the biggest impact while such a flow was constructed collaboratively. In those cases, it is useful to implement a leaderboard that does not only show the cur-rent best solution, but instead credits the authors who con-tributed solutions that were in, say, the top 3 at any point in time. Alternatively, this can be visualized in a graph of performance versus time, so that it is clear who caused the bigger performance  X  X umps X . This is useful to later credit the people who made the most important contributions. To build a well-structured information space, OpenML needs to be able to correctly interpret the uploaded data. For in-stance, to calculate data characteristics and build train-test splits, more information is needed about the structure of data sets. Therefore, we have initially focused on ARFF data. However, many types of data, such as graphs, can not always be adequately expressed as ARFF, and we will add support for new data types according to researchers X  needs. Moreover, for some types of tasks, additional types of results (run outputs) may need to be defined so that OpenML can properly interpret them.
 In the short term, we aim to add support for Graph Min-ing, Clustering, Recommender Systems, Survival Analysis, Multi-label Classification, Feature selection, Semi-Supervised Learning, and Text Mining. Moreover, we will extend the website to make it easy to propose and work collaboratively on support for new task types. In many sciences, networked science tools are allowing scien-tists to make discoveries much faster than was ever possible before. Hundreds of scientists are collaborating to tackle hard problems, individual scientists are building directly on the observations of all others, and students and citizen sci-entists are effectively contributing to real science. To bring these same benefits to machine learning researchers, we introduce OpenML, an online service to share, organize and reuse data, code and experiments. Following best prac-tices observed in other sciences, OpenML allows collabora-tions to scale effortlessly and rewards scientists for sharing their data more openly.
 We believe that this new, networked approach to machine learning will allow scientists to work more productively, make new discoveries faster, be more visible, forge many new col-laborations, and start new types of studies that were prac-tically impossible before. This work is supported by grant 600.065.120.12N150 from the Dutch Fund for Scientific Research (NWO), and by the IST Programme of the European Community, under the Harvest Programme of the PASCAL2 Network of Excel-lence, IST-2007-216886.
 We also wish to thank Hendrik Blockeel, Simon Fisher and Michael Berthold for their advice and comments. [1] D. W. Aha. Generalizing from case studies: a case [2] A. Asuncion and D. Newman. UCI machine learning [3] M. Berthold, N. Cebron, F. Dill, T. Gabriel, T. Kotter, [4] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer. [5] B. Bischl. mlr: Machine Learning in R. , 2013. R pack-[6] H. Blockeel and J. Vanschoren. Experiment databases: [7] T. A. Boroson and T. R. Lauer. A candidate sub-[8] P. Brazdil, C. Giraud-Carrier, C. Soares, and R. Vilalta. [9] C. Cardamone, K. Schawinski, M. Sarzi, S. P. Bamford, [10] J. Carpenter. May the best analyst win. Science , [11] S. Cooper, F. Khatib, A. Treuille, J. Barbero, J. Lee, [12] K. A. Frazer, D. G. Ballinger, D. R. Cox, D. A. Hinds, [13] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-[14] D. Hand. Classifier technology and the illusion of [15] M. J. Hawrylycz, E. S. Lein, A. L. Guillozet-Bongaarts, [16] H. Hirsh. Data mining research: Current status and fu-[17] V. Hoste and W. Daelemans. Comparing learning ap-[18] A. R. Isern. The ocean observatories initiative: Wiring [19] T. Kealey. Sex, science and profits . Random House, [20] E. Keogh and S. Kasetty. On the need for time se-[21] E. S. Lein, M. J. Hawrylycz, N. Ao, M. Ayres, [22] R. Leite, P. Brazdil, and J. Vanschoren. Selecting [23] C. J. Lintott, K. Schawinski, W. Keel, H. Van Arkel, [24] C. J. Lintott, K. Schawinski, A. Slosar, K. Land, [25] I. Manolescu, L. Afanasiev, A. Arion, J. Dittrich, [26] K. L. Masters, M. Mosleh, A. K. Romer, R. C. Nichol, [27] D. Michie, D. Spiegelhalter, and C. Taylor. Machine [28] M. Nielsen. The future of science: Building a better [29] M. Nielsen. Reinventing discovery: the new era of net-[30] E. Ostrom. Collective action and the evolution of social [31] H. Parkinson, M. Kapushesky, M. Shojatalab, N. Abey-[32] T. Pedersen. Empiricism is not a matter of faith. Com-[33] C. Perlich, F. Provost, and J. Simonoff. Tree induction [34] B. Pfahringer, H. Bensusan, and C. Giraud-Carrier. [35] J. Priem, P. Groth, and D. Taraborelli. The Altmetrics [36] M. J. Raddick, G. Bracey, P. L. Gay, C. J. Lintott, [37] M. E. Schwamb, C. J. Lintott, D. A. Fischer, M. J. [38] S. Sonnenburg, M. Braun, C. Ong, S. Bengio, L. Bot-[39] A. S. Szalay, J. Gray, A. R. Thakar, P. Z. Kunszt, [40] L. Torgo. Data Mining with R: Learning with Case [41] J. N. van Rijn, B. Bischl, L. Torgo, B. Gao, [42] J. N. van Rijn, V. Umaashankar, S. Fischer, B. Bis-[43] J. Vanschoren, H. Blockeel, B. Pfahringer, and [44] M. Wojnarski, S. Stawicki, and P. Wojnarowski.
