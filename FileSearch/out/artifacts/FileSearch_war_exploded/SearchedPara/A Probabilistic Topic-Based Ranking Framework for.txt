 It has been observed that many queries submitted to search engines are location-sensitive. Traditional search techniques fail to inter-pret the significance of such geographical clues and as such are unable to return highly relevant search results. Although there have been efforts in the literature to s upport location-aw are information retrieval, critical challenges still remain in terms of search result quality and data scalability. In t his paper, we propose an inno-vative probabilistic ranking framework for domain information re-trieval where users are interested in a set of location-sensitive top-ics. Our proposed method recognizes the geographical distribution of topic influence in the process of ranking documents and models it accurately using probabilistic Gaussian Process classifiers. Ad-ditionally, we demonstrate the effectiveness of the proposed rank-ing framework by implementing it in a Web search service for NBA news. Extensive performance evaluation is performed on real Web document collections, which confirms that our proposed mechanism works significantly better (around 29 . 7% averagely us-ing DCG 20 measure) than other popular location-aware informa-tion retrieval techniques in ranking quality.
 H.4.m [ Information Systems ]: Miscellaneous; D.2 [ Software ]: Software Engineering; H.3.3 [ Information Systems ]: Information Search and Retrieval X  Retrieval models Algorithms, Design. Search engines are useful tools for Web users to acquire relevant information from Internet. Via workload studies, it has been no-ticed that a great portion of queries sent to search engines con-tain geographical interests. These queries, which we denote as spatial queries in this paper, either explicitly encode geographical  X 
This work was supported in part by NSF Award No. IIS-0534343 and CNS-0626709 . Dik Lee X  X  work was supported by HKSAR Research Grant Council GRF No. 615806 .
 constraints or implicitly refer to local events. Traditional informa-tion retrieval techniques lack necessary support to exploit such geo-graphical information of spatial queries because they rely solely on textual attributes to evaluate a document X  X  relevance w.r.t. a query. Therefore, there are growing interests in the spatial aspects of Web search in the past few years, associating geographical information with Web documents ( spatial search ) [1, 2, 6, 9, 17, 22].
Generally speaking, both spatial queries and candidate docu-ments can be expressed as lists of extracted location names as well as their original texts. In previous efforts to support spatial queries, spatial relevance and textual relevance are both considered but eval-uated separately, by assuming they are independent from each other. These relevance scores are then merged into a hybrid score for ranking documents in accordance with the query. Additionally, most existing approaches assume Euclidean distance in evaluation of spatial relevance, ranking documents nearer to the referenced query location higher in the returned results. To facilitate the eval-uation of spatial relevance, spatial indices (e.g., R-Tree [17]) are utilized along with inverted indices.

The aforementioned query processing strategy has several limi-tations. First, the ranking function, which is usually a linear com-bination of spatial relevance and textual relevance, is given with-out sufficient justification. Actually, the function can be in any form, which is difficult to obtain without prior knowledge. Sec-ond, as suggested by empirical studies on real Web search logs [2], the geographical distribution of query issuers to a specific event is highly variant. Actual impact of an event can be tightly concen-trated or widely spread. In other words, physical distance is not always a good metric in measuring spatial relevance. Finally, the introduced spatial indices lack the flexibility required in evaluating sophisticated spatial relevance if the Euclidean distance measure is replaced. In addition, the data structure difference between a spatial index and an inverted index makes it difficult to merge them into a hybrid data structure, which in return requires extra I/O scans in the ranking process and thus deteriorates the ranking efficiency.
In this paper, we aim at addressing the above-mentioned prob-lems by taking a different approach for domain information re-trieval where users are interested in location-sensitive topics, de-noted as SDIR (Spatial-relevant Domain Information Retrieval). Unlike generic information retrieval, SDIR is more focused and often is associated with a limited number of topics. Therefore, in-stead of evaluating documents directly with queries, we propose a flexible probabilistic framework to rank spatial queries based on topical similarity. In our framework, each topic is associated with a topic model , represented as a distribution over features (terms, lo-cations, etc), which is trained supervisedly given a training set of documents with topic labels. After the topic models are learned, both spatial queries and documents are analyzed in the framework to infer their topic distributions, which are then used to predict the topical similarity between a spatial query and a candidate docu-ment in order to obtain its ranking score. To better characterize the geographical aspect of the topic model, Gaussian Process is uti-lized as a probabilistic multi-class topic classifier in this work. As a kernel machine , Gaussian Process is highly flexible and config-urable. Meanwhile, unlike discriminative classifiers, it generates probabilistic classification results, which work seamlessly with the proposed spatial query ranking framework.

In summary, the contribution of this paper is four-fold: 1. We propose a probabilistic topi c-based ranking framework 2. Instead of utilizing distance as the metric to predict spatial 3. To make the proposed spatial query ranking framework fea-4. The proposed ranking mechanism is compared with a num-
The remainder of this paper is organized as follows. In Section 2 we give a literature review of spatial search techniques. In Section 3 we present our topic-based ranking framework. We introduce our modeling strategy in Section 4. Extensive evaluation is performed on real datasets, whose results are presented in Section 5. Finally, Section 6 concludes the paper and gives future research directions. In this section, we review the state-of-the-art in the domain of spa-tial search. Specifically, we analyze the approaches proposed for geographical influence modeling and spatial query processing. 2.1 Geographical Influence Modeling The study to the geographical features of Web documents starts from geographical signature extraction [6], which tries to assign location stamps to Web documents based on their geographical in-formation contained in texts as well as network locations. Addi-tional information sources, such as telephone numbers as well as email addresses, are also considered in generating geographical sig-natures in follow-up works [17]. With the geographical locations available, researchers start to study the distribution of geographical influence of Web pages. [9] presents their efforts in defining the power as well as the spread of a Web page, which can be used to describe the scope of a topic or an event. On the other hand, [2] further proposes a probabilistic model, which can not only find the boundary of a topic, but also suggest the distribution of the influ-ence. However, it only uses simple statistical distributions to model the geographical influences without sufficient justification. 2.2 Spatial Search Processing It is a common practise in the literature to take textual relevance and spatial relevance as two independent measures in processing spatial queries. For example, SPIRIT [14] breaks the whole geographical area into smaller cells and uses special spatio-textual keys to as-sociate terms with the cells where they belong. Such an indexing scheme and query processing strategy, although simple to be im-plemented, requires much extra storage overhead. Recently, many spatial search services utilize popular spatial database index struc-tures such as R-tree [17]. To answer a spatial query, visits to both spatial indices and textual indices are necessary, which significantly deteriorates the search performance. Observing this problem, hy-brid index structures are proposed [22], which try to minimize the size of indices and reduce the I/O overheads. However, these hy-brid approaches are mainly based on R-trees and inverted indices, which still makes the calculation of textual relevance and spatial relevance independent tasks. KR*-tree [10] is another hybrid index structure, which stores keyword lists in the internal nodes of R*-trees [3]. However, the functionality of KR*-tree indices is limited as it does not contain textual information such as term frequency and position that are critical in calculating textual relevance. It is noted that all the aforementioned spatial indices, which are based on tree structures, take advantage of the geographical clustering effects, which are based on the assumption of Euclidean distance metric. Therefore, they all lack the flexibility to be extended to support more sophisticated spatial relevance metrics.

In addition to efficiency, generating highly relevant ranking re-sults for spatial queries is another challenging research problem. For generic Web search applicati ons, geographical contexts are of-ten used as an implicit information source for query disambigua-tion [7]. Location information is also utilized to group users for query expansion to location-sensitive queries [12]. As stated in [8], ranking functions implemented in spatial search engines need to be evaluated as a monotone combination of a term-based measure (textual relevance), a global score (e.g. PageRank [5]) and a geo-graphical score. This principle is actually followed by most current spatial search services. However, this form of ranking functions is difficult to be tuned and optimized. In addition, the separation be-tween textual relevance and spatial relevance lacks necessary justi-fication, making it an arbitrary design. In this section, we introduce our efforts in better interpreting users X  information need implied in spatial queries. Section 3.1 gives a formal problem definition. We introduce our topic-based spatial query ranking framework in Section 3.2. 3.1 Problem Definition To start, we try to give a generalized definition to spatial queries. In fact, a spatial query sent to a search engine includes the user X  X  geo-graphical requirement for information. For example, "San Fran-cisco restaurant" can be taken as a spatial query because a city name can be parsed from the query. Usually, location names are contained in the searched terms, which require search services to parse and interpret them in the search process on-the-fly. This task can be done via invoking gazetteer lookups. However, it should be noticed that sometimes the geographical conditions are not explic-itly provided in the queries. On the other hand, by analyzing search contexts and terms it can be determined that the user is interested in location-sensitive topics. In such circumstances, the location of the query issuer is then used to expand the original query into a spatial query because the user is interested in local information. Regard-less the explicitness of geographical requirement, a spatial query can be formally defined with Definition 1.
 D EFINITION 1. A spatial query is expressed as q =( q S ,q in which q S represents the geographical condition implied by q and q
T represents the search terms that exclude location names.
Correspondingly, a document that a spatial query is evaluated against can be defined as the combination of texts and affiliated locations names, as shown in Definition 2. The location names w.r.t. a document are parsed from the document X  X  text as well. It should be noted that usually a doc ument is associated with multiple locations.

D EFINITION 2. When evaluated against spatial queries, a doc-ument can be viewed as d =( d S ,d T ) ,inwhich d S is the list of location names found in d and d T represents document texts.
With q and d given, the spatial query ranking process tries to obtain a score for d w.r.t. q , which is a function that takes both q and d as the input parameters. Generally speaking, we can define the ranking function as:
Eq. 1 gives a generalized form for the scoring function. Most existing spatial query processing approaches assume that spatial relevance and textual relevance are independent metrics, which in-terprets Eq. 1 as: in which  X  represents an arithmetic operator. Usually a linear com-bination is used, as suggested in [8]. Textual relevance is usually evaluated using generic information retrieval metrics such as tf-idf , supported by inverted lists. On the other hand, Euclidean distance is usually taken as the spatial relevance metric, based on which spa-tial index structures such as R*-Tree and Quad-Tree are utilized. 3.2 Topic-Based Ranking Framework for SDIR It should be noted that documents are generated by their authors to convey information regarding specific topics. Meanwhile, users X  information needs, as expressed in term of queries, are typically requesting on relevant topics as well. Recently, there have been a wide range of discussion regarding latent topic variables in model-ing documents [4, 11, 16, 18, 20] as well as their applications [12] (such as query expansion, ranking, etc).

The introduction of topics can reveal many implicit information and latent geographical interests. For example, assume that there is an NBA match review regarding the match between L.A. Lakers and Golden State Warriors (from San Francisco), in which some other teams such as Boston Celtics are mentioned briefly. This piece of news is relevant to basketball fans who issue a spatial query q "Los Angeles basketball". As well, it is relevant to the query q "San Francisco basketball" but not relevant to q 3 "Boston basket-ball". Although traditional spatial query processing algorithms can process q 1 very well because the location name L.A. is found in the document. It will be difficult for them to process q 2 without domain knowledge because the name "San Francisco" is not explicitly available. Accordingly, q 3 cannot be well interpreted since "Boston" is found in the document. However, if we can cor-rectly recognize the relevant topics of the document, which are Lak-ers and Warriors in this example, all the three queries mentioned above can be well answered.

Observing this, we argue that the current ranking model for spa-tial queries is inaccurate in interpreting users X  information need and lacks sufficient flexibility . Therefore, we introduce a topic layer into the ranking framework to bridge queries with documents. For SDIR, the topic layer contains the topics given in the application domain. Compared with generic latent topics, explicit topics in a domain have the following advantages: 1) Domain topics are given other than learned, making them easy to be interpreted and understood. 2) It is easy to determine if a domain topic is location-sensitive or not. 3) For location-sensitive topics, it is easy to estab-lish their geographical centers, which we denote as topic centers . Take the NBA news search as an example, we can take the 30 NBA teams as domain topics, which are believed to be location-sensitive because usually fans are interested in local teams. In addition, we can take the city of each team as the topic center.

In our proposed ranking framework, each topic in the topic layer is associated with a topic model, defined in Definition 3.
D EFINITION 3. In the topic-based ranking framework for spa-tial queries, each topic model i ncludes a multi nomial p robability distribution over term vocabulary W t i = p ( w j | t i ) as well as an influence distribution over the working geographical area L p ( l k | t i ) ,inwhich w j represents a term in the vocabulary, whereas l represents a geographical location.

Both p ( w j | t i ) and p ( l k | t i ) in the topic model of t from empirical data given topic labels. We will discuss the model-ing methodology in Section 4. Given the topic model for t easily obtain the topic distribution for a query q or a document d , which can be shown conceptually in Figure 1.
 Figure 1: A hierarchical representation of the topic model.
With the introduction of the topic layer, when a query q arrives, in order to obtain the relevance of a document d w.r.t. q ,weevaluate the topical similarity implied by q and d in addition to the raw tex-tual similarity between q and d (  X  t ( q, d ) ). To do it, we first check the relevance between a potential topic t and q , which we denote as Query-Topic Relevance  X  ( q, t ) . Afterwards, for each topic t ,we give a topical relevance score for each document d , which we call Document-Topic Relevance  X  ( d, t ) . As shown in Figure 1, the newly added topic layer separates queries from documents, which assumes that the  X  ( q, t ) and  X  ( d, t ) are independent of each other. In addition, as we will see in Section 4.2, instead of using a uni-form textual relevance measure,  X  t ( q, d ) is parameterized to topic t to reflect the impact of t on textual relevance.

If we assume the independence between topics, which is usually true for SDIR, Eq. 1 can be rewritten as:
According to Definition 3, here we take a probabilistic view into the problem. Therefore,  X  ( q, t ) can be taken as the probability of observing t given query q , whereas  X  ( d, t ) can be taken as the probability of generating document d given topic t . Thus, Eq. 3 can be reformatted as: Following the Bayes X  theorem, Eq. 4 can be further written into: from which we can see the calculation of F ( q, d ) is dependent on given the fact that q can be taken as a small document. Specifically, we utilize both W t j and L t j in the topic model to calculate p ( t and p ( t j | d ) . By assuming the independence between textual top-ical likelihood and geographical topical likelihood, Eq. 5 can be written as: F ( q, d )  X 
In Eq. 6,  X  t j ( q, d ) is the textual relevance and p ( t directly obtained from the training set. In the following discussion, we focus on evaluating the topical probabilities w.r.t. q and d .
Generally speaking, Eq. 6 is fundamentally different from Eq. 2 with the introduction of the topic layer. Our proposed topic-based ranking framework is more flexible as the topic model can be of any form. As we will see in Section 4, it works like a ker-nel machine in evaluating relevance and is thus much configurable. Simultaneously, by taking a probabilistic approach, the topic-based ranking framework can be easily extended to incorporate additional attributes and works consistently with other useful information re-trieval techniques. As we have seen in Eq. 5, in our proposed ranking framework, the relevance between a document and a query can be delegated to the problem of evaluating the topical likelihood given a document p ( t j | d ) or a query p ( t j | q ) , which relies on the topic model defined in Definition 3. In this section, we introduce our met hod in learning topic models from training data collections. Section 4.1 provides our modeling strategy for L t i from collected user feedback data. Section 4.2 proposes our methodology in training W t i as well as evaluating textual relevance. Finally, Section 4.3 discusses practi-cal implementation designs to make the proposed ranking frame-work feasible to large-scale information systems. 4.1 Inferring Topics Using Geographical Influence Analysis In this section, we present our method in modeling geographical in-fluence distribution of a specific topic. Here we assume that every topic has a geographical topic center. Previous Web log analysis [2] studies real search engine logs and tries to model the geographical distributions of topic influences using the exponential distribution model. In Section 4.1.1, we evaluate the goodness-of-fit for a series of representative distribution models against our collected datasets. Our results suggest that such simple distribution models are not al-ways good choices because the underlying distributions are highly diversified. Observing this, in Section 4.1.2, we propose to use Gaussian Process (GP) to characterize them. 4.1.1 Goodness-of-Fit Tests The best approach to analyze geographical influence of topics is through query log analysis [2]. However, to the best of our knowl-edge, there is no available large-scale query logs that contain ex-plicit geographical or IP information due to privacy concerns. There-fore, we took a different approach by crawling the Web for ge-ographical information regarding fans of specific topics. Specifi-cally, we worked on an NBA domain information service and took the 30 NBA teams as topics. Several well-supported NBA fan fo-rums (from NBA official site 1 , ESPN 2 , and Yahoo! Sport explicitly show geographical information or IP addresses of regis-tered fans in their discussion threads, were crawled. Our crawled NBA fan forums provide discussion boards for each NBA team. By collecting geographical information of fans who published or replied to threads in corresponding team boards, we collected a list of at least 10 , 000 geographical records of fans for each team. Here we assume that the users who dis cussed in the board of a specific team are fans of that team, whose locations were then studied to analyze the geographical distribution of the team X  X  influence.
To give a direct impression of the geographical distributions of team-specific fans, we select several popular teams and plot their fan distributions in Figure 2, in which each mark on the map rep-resents a city that observes at least ten different fans for the corre-sponding team.
From Figure 2 we can easily find the geographical locality of fans, e.g., the fans of Chicago Bulls are mostly centered around the Great Lakes. However, consistent with [2], usually multiple centers of interest are observed, which make the simple form statistical distribution models unsuitable for characterizing such distributions.
To test our arguments, we performed goodness-of-fit analysis to the collected geographical data. To start, we need to decide what distributions are considered as possible candidates for our modeling process. After studying previous suggestive studies, four represen-tative distribution models were selected in the subsequent analysis: 1) exponential (modeling high variance), 2) normal (modeling low variance), 3) pareto (modeling bursty/heavy-tailed behaviors), and 4) weibull (flexible to model wide diversity of streams).
For each candidate statistical model, a predefined set of param-eters needs to be determined. We used the Maximum Likelihood Estimation (MLE) method to calculate these parameters, based on a collection of training records. Due to the limit of pages, we do not include the trained parameters in this paper. After obtaining the candidate distribution parameters, we need to assess which one is the most fit with the training dataset. Kolmogorov-Smirnov (K-S) test, which uses the empirical cumulative distribution function as a tool for testing, was adopted to test the goodness-of-fit. To be more specific, K-S test returns the maximum distance between the cumulative distribution function of a model and the empirical data. The smaller is the distance, the better is the goodness-of-fit.
Using the aforementioned steps, w e observe dramatically variant results in the teams we analyzed. We give a portion of the team analysis results in Table 1, in which the best K-S result is written in bold font.

The K-S results suggest that exponential, weibull and normal dis-tributions are possible good candidates in describing the geograph-ical distributions of NBA team fans. Among all ten listed teams, named from T 1 to T 10 in Table 1, six teams can be best character-ized using weibull distributions. At the same time, two out of ten fit normal distributions well and two can be described using exponen-tial distributions. This finding contradicts with what is assumed in [2], which uses exponential distributions all the time. Table 1 also suggests that sometimes exponential distribution is a bad modeling choice, whose K-S scores can reach as high as 0 . 260 . 4.1.2 Use Gaussian Process to Model Geographical Distribu-The analysis results shown in Section 4.1.1 indicate that simple statistical distribution models are not good candidates to charac-terize the geographical distribution of topics without decent prior knowledge regarding data characteristics. On the other hand, using clustering methods or mixed distribution models to find geograph-ical clusters of topic influences is not a good choice because: 1) it is very difficult to set the proper parameters for clustering; 2) the bordering areas between clusters cannot be well explained; and 3) scalability concern remains as a problem for large areas. Addition-ally, due to the sparseness of training sets as well as the limited number of features, typical classification mechanisms cannot train good topic classifiers for suc h multi-topic scenarios.

Observing the aforementioned limitations, we use a GP-based modeling strategy to model the geographical aspect of topic mod-els ( L t i ). Compared with the previously mentioned approaches, GP has the following advantages: 1) GP classifiers return proba-bilistic results for class labels, which fit perfectly with our ranking purposes. 2) GP is non-parametric and does not place prior assump-tions regarding the form of functions. 3) GP is a kernel machine, which is highly flexible and configurable.

Generally speaking, a GP is defined as a collection of random variables, any finite number of which have (consistent) joint Gaus-sian distributions. Specifically, a GP is fully specified by its mean function m ( x ) and covariance function k ( x, x ) . The covariance function k ( x, x ) is a crucial ingredient for a GP because it en-codes the notion of similarity between data points. The adoption of the covariance function makes GP a kernel machine, which is very flexible in defining nearness or similarity. A commonly used co-variance function is the squared exponential (SE) covariance func-tion, defined as: in which l and  X  are denoted as hyper-parameters . A wide range of covariance functions can be chosen according to [19].
GP is usually used for regression, which tries to map an input x to a predicted output f ( x ) , given some observations. In our work, we utilize GP for multi-class classification, which tries to predict possible class label y  X   X  X  1 , ..., C } for an unseen input x suming there exist C classes. Like other classification schemes, we are given with a training set D = { ( x i ,y i ) | i =1 , ..., N y  X  X  1 , ..., C } . For our case, each training data record x as x  X  ,isa 2 -dimensional feature vector which represents the lati-tude and longitude of a data entry. For classification, we use GP first to obtain continuous latent functions f ( x ) , which is afterwards employed to infer class labels. Following the convention in [19], we predict the latent function f  X  at x  X  with p ( f  X  | f trained from the given training data.

Here we give a brief introduction to the GP classifier training process. First, we can compute the posterior of the latent function f given the training set, using the Bayes X  theorem: in which we assume that p ( f | X )  X  X  (0 , K ) ,where K is the co-variance matrix obtained from the covariance function k ( x, x ) .In Eq. 8, p ( y i | f i ) can be obtained using a variety of functions (e.g. the multiple logistic function ).

Next, the trained latent functions f are utilized to infer the latent function f  X  for the unseen data x  X  ,
Finally, we obtain the predicted label y  X  by integrating out f
By taking the approximation method proposed in [15, 21], the process can be finished in O ( NM 2 ) ,where M informative data records are selected from N training data ( M N ). 4.2 Mixing with Textual Relevance Section 4.1 proposes our method in learning L t i , which is used to tion, we present our methodology to learn W t i as well as  X 
Actually, as shown in Eq. 5, our proposed ranking mechanism can accept a variety of topic model forms. In this section and the following evaluations, we choose to use the bag-of-words assump-tion in modeling W t i . Thus, given a set of labeled training docu-ments, we can calculate the probability of term observation given a specific topic: in which n j i denotes the number of observing w j in documents that are labeled t i .

With topic vocabulary distribution trained from Eq. 11, given a test document d  X  = { w 1 ,w 2 , ..., w n } ,
Topic-specific textual relevance,  X  t i ( q, d ) , is different from the aforementioned topic models in that it works directly between the query and the document, trying to adjust the ranking of documents within specific topics. Popular information retrieval metrics, such as tf-idf and cosine similarity, can all be applied here. However, we define it to be parameterized by t i to reflect the topic influence. For example, in our implementation, we use an extended version of the tf-idf measurement, defined as: in which D t represents the collection of documents that are labeled with topic t . From Eq. 13 it is clear that the idf value can be different across topics based on the topic-level term distributions. 4.3 Implementation In this section, we discuss some practical issues related to the pro-posed topic-based ranking framework for spatial queries to make it scalable and compatible with most information retrieval systems.
To make the proposed ranking mechanism feasible, we try to minimize the overhead in the search process for spatial queries as much as possible. Our study to traditional spatial queries process-ing mechanism suggests that it i s the multiple I/O scans to het-erogeneous index structures that incur extra overhead in evaluating queries. Our approach does not suffer from this problem as we do not need to maintain a separate spatial index, whose functionality is replaced with the geographical topic model L t i we trained using GP. It is only necessary to access inverted lists to evaluate  X  We modified the internal design of textual index so that it can re-member topic-based idf t values for each term. In addition, to avoid the overhead in evaluating Document-Topic Relevance  X  ( d, t the-fly using topic model W t i and L t i , we generate the topic dis-tributions for all indexed documents offline and store them in the textual index, known as the Document-Topic Lookup Table ,asa data source so that it can be easily fetched by the search process.
Moreover, since queries are sent from online users, whose top-ical relevance scores cannot be pre-computed, we maintain two data structures, Geographical Influence Lookup Table ( LT S Term-Topic Lookup Table ( LT T ), in the main memory for efficient lookups. Suppose we are given m topics, LT S divides the entire geographical area into small square grids with same sizes. For each such geographical grid g , LT S maintains a topic vector to repre-sent p ( t i | g ) ,i =1 , ..., m using L t i . Similarly, topic distribution p ( t i | w ) for each term w from W t Once a query arrives, its geographical condition q S is analyzed to find its affiliated grid in LT S , whose topic distribution is fetched. Simultaneously, q T is sent to LT T to retrieve the textual topical relevance. The topical relevance scores are later combined with the  X  i ( q, d ) score returned by inverted indices as well as  X  ( d, t rank documents. The whole ranking process can be explained by Figure 3.
 Figure 3: The topic-based ranking process and involved data structures for spatial queries. 5.1 Experimental Settings To perform performance evaluation, we develop an information retrieval search service for NBA-relevant documents. Three ma-jor US sport websites, same as what we used in Section 4.1.1 to test model assumptions, are crawled for NBA news pages and re-view pages. The crawled documents are parsed and indexed. Basic statistics about our testing dataset is given in Table 2. Table 2: Basic statistics regarding the experimental dataset.
Among the crawled documents, we find all documents that are reached from ESPN NBA team pages 4 . These documents are taken as labeled with corresponding teams, which are used in learning topic vocabulary distribution W t i . For example, we label a docu-ment to be related to Boston Celtics if we find it is crawled from the team X  X  ESPN homepage. Meanwhile, similar with the method-ology presented in Section 4.1.1 we crawled the affiliated fan fo-rums of the aforementioned websites to collect fan locations (at least 10 , 000 per team), which are used to train the geographical distribution of topics L t i using GP. Squared exponential covari-ance function is adopted in the training process by default, if not mentioned otherwise in the following discussions. In the model, we select the hyper-parameter l to be a small positive value ( 0 . 5 by default) to capture the geographical locality. We cut the en-tire US main territory into smaller square grids, each of which is e.g. http://sports.espn.go.com/nba/local/team?team=bos for Boston Celtics 0 . 2  X   X  0 . 2  X  . We take the center of each grid cell as the testing data and feed it to the GP model. The predicted topic distributions are kept in LT S for query evaluation. Finally, the trained topic models are kept in the data structures we presented in Section 4.3. Our queries sent to the search service comprise two parts, a tex-tual string as well as a user location, which are sampled from our collected vocabulary repository and fan location repository. We conduct all experiments on a Linux server with dual AMD Opteron Processor 252 CPUs ( 1 G Hz), 4 GB main memory. 5.2 Evaluation Results 5.2.1 Case Study To start, we first give an exemplary study to our GP classifiers because the performance of our proposed ranking mechanism is highly dependent on the quality of the topic models. Since we are working with location-sensitive topics, the accuracy of our proba-bilistic geographical topic classification results dictates the ranking result quality. Thereafter, we first evaluate the geographical topic models returned by GP in a general sense.
 First, we only select two teams (Boston Celtics vs. Chicago Bulls) and ask GP to work as a binary classifier. The locations of the fans for the two teams are used as the training set. After training, we ask the GP classifier to predict the topic distribution for each 0 . 2  X   X  0 . 2  X  geographical grid for US mainland territory. We label Boston Celtics as +1 and Chicago Bulls as  X  1 . The clas-sification results are plotted in Figure 4 as a contour map. Figure 4: Contour plot for the binary topic prediction between Boston Celtics and Chicago Bulls across the area from 32 . 82 to 46 . 02  X  N ,from 67 . 93  X  W to 117 . 13  X  W .

Figure 4 depicts the topic label prediction results across main-land US territory, from which we can easily find the Boston area (the northeastern corner) has a hig h topical likelihood for the Celtics. Simultaneously, the fans for the Bulls are centered in the upper center of the figure, which is the corresponding area of the Great Lakes. It suggests that the GP can well capture the geographical distribution of topic influences from the training sets and predict accurately. Meanwhile, it gives a probabilistic result.

Next, we increase the number of teams to see how well GP works for multiple topics. In this case, five well-supported teams are stud-ied, including Boston Celtics, L.A. Lakers, Chicago Bulls, Houston Rockets, and Phoenix Suns. We supply our training set, which in-cludes 10 , 000 records for each team, to GP to train a multi-class classifier. Afterwards, we tell the classifier to predict the topic dis-tributions for 200 US cities. We place a colored mark which repre-sents the most likely team for the basketball fans of that city on the map in Figure 5, which is rendered using Google Maps API 5
Although it is difficult to evaluate the accuracy of the GP predic-tion results shown in Figure 5 in a general sense, we can still tell http://code.google.com/apis/maps/ Figure 5: The five-team prediction results for 200 US cities, in which red markers represent Boston Celtics, green markers represent L.A. Lakers, blue markers represent Chicago Bulls, pink markers represent Houston Rockets, and orange ones rep-resent Phoenix Suns. that the geographical model labels accurately because the neighbor-ing areas for all the five teams are labeled with their corresponding colors. For example, fans of Boston Celtics are mostly centered around the northeastern area of US, whereas Houston Rockets fans are mainly located in Texas. However, a special case is the fans of L.A. Lakers. Although the team has much influence in California, its fans are spread widely across US. GP does well in recognizing such complex distributions and interprets well.

Further, we demonstrate the effect of our proposed topic-based ranking mechanism by issuing some location-sensitive queries to the search service. Here, we supply a query "MVP" (Most Valuable Player) into the search service and use the proposed topic-based ranking mechanism to answer it. In this scenario, we simulate a user from Boston, Miami, L.A. respectively, each of which hosts a native NBA team. Additionally, we also simulate a user from Pitts-burgh, where no NBA team is located. The top-5 returned docu-ments are listed in Table 3, in which document titles for local teams are given in bold font.

As predicted, the introduction of topic models reshuffles the rank-ing list dramatically based on where the user comes from. Actu-ally, since the query text remains unchanged, the critical part here is the geographical topic model trained using GP. Apparently, fans from cities like Boston, Miami, and L.A. favor their local basket-ball players. Interestingly, for a fan from Pittsburgh, the most likely basketball team he is interested in is not Cleveland Cavaliers, which does not show up in the list, even though Cleveland is closer to Pittsburgh than any other team in NBA. On the other hand, Boston Celtics is a more favorite team for Pittsburgh basketball fans, con-tributing the 3 rd , 4 th ,and 5 th document. It again suggests in such cases physical geographical distance is not a good measure in rank-ing spatial queries. 5.2.2 Ranking Quality In this section, we check the quality of returned ranked documents to specific queries. Before we directly compare ranking qualities, we first give a precision analysis to different spatial relevance pre-diction models. In addition to the proposed GP classification mech-anism, we also implement two methods: 1) distance-based ,which always labels a user with the nearest NBA team; and 2) SVM-based , which uses an SVM classifier to classify users based on his latitude and longitude. We supply user locations into the classifiers un-der study, whose results are compared with the user X  X  actual label to evaluate the classification precision. We change the number of classes and plot the results in Figure 6.

From the results we can see that although SVM does well for the binary case, its precision decreases significantly when the class number reaches 5 because the number of features is too limited. Meanwhile, the distance-based approach yields consistent results, remaining above 25% for all cases. However, the GP-based topic Figure 6: Classification precision comparison between differ-ent spatial relevance prediction models. model always produces the best precision, which remains at 47% for the 30 -class test.

To evaluate the quality of returned documents w.r.t. a spatial query, we used a well-known metric, the Discounted Cumulated Gain ( DCG 20 ) [13]. We sample 10 queries randomly in the evalu-ation. Top 20 documents returned by each ranking mechanism are merged in a single list, shuffled and submitted for judgment. Two human judges provide feedback. Numerical scores of 0 , 1 , 2 ,and 3 are collected to reflect the judges X  opinion with regard to whether a document should be ranked in the top 20 .

First of all, we compare our topic-based method with 1) the tradi-tional textual ranking mechanism, 2) a hybrid ranking function that takes textual relevance and Euclidean distance, as well as 3) a pure topic-based ranking strategy that neglects the topic-specific textual relevance  X  t ( q, d ) . The results for ten queries are given in Figure 7, in which we found basically our proposed ranking mechanism outperforms other approaches. To be specific, our proposed topic-based ranking method outperforms the distance-based approach by 29 . 7% on average. Figure 7: DCG 20 comparison results for different ranking techniques for spatial queries.

Next, we stick to the proposed topic-based ranking mechanism for spatial queries. In this experiment, we change the kernel func-tion we used in inferring geographical distribution of topic influ-ences. Also, we change the hyperparameters needed for some ker-nel functions we used in the experiment to see their tuning effects. We still use DCG 20 as the evaluation metric, whose results are given in Figure 8. In the figure, we can notice the high flexibil-ity introduced by the kernel functions of GP used to learn topic influence distributions. Basically, geographical distribution of fan interests for sport clubs has high locality, which recommends co-variance functions that can give high scores to close target objects and decrease their scores quickly with distance increase. Figure 8: DCG 20 comparison results for different kernel func-tionsusedinGP. 5.2.3 Ranking Overhead In this section, we continue to evaluate the response time it takes for a user to wait for the result. In our study, we compare our proposed ranking mechanism with some popular spatial query pro-cessing schemes. Three ranking policies are implemented. 1) Tex -tual ranking , which considers only text information in ranking and uses tf-idf as the scoring metric. It works as the baseline because it requires minimal computation. 2) Hybrid index , which is pro-posed in [22]. It combines inverted lists and spatial indices. We use the inverted-list-first scheme because it yields better performance. And 3) dynamic distance , which is similar with the hybrid index approach. However, it does not maintain a separate spatial index. Each document stores its locations in the index, which are fetched in the running time and compared against user locations. The metric we use to compare performance is the response time. To remove bias, for each test we first warm-up the indices with 100 random searches. Afterwards, another 100 queries are sent to the search service, whose average response time is taken as the result.
To start, we first analyze the scalability of the discussed search methodologies against document set sizes. We modify the size of the document set from 100 K documents to 1 M documents by in-troducing generic pages we crawled from the Web, whose result is shown in Figure 9(a). In the figure, we can observe that textual ranking is the most efficient because it neglects the geographical information. On the other hand, our proposed topic ranking works similarly with the dynamic distance ranking approach, which needs approximately 40 ms to rank documents. Due to possible extra I/O requests to multiple index str uctures, the hybrid index method yields worse overhead.

Second, we change the complexity of queries by changing the length of queries to test the temporal performance of the proposed ranking mechanism. Here we change the number of terms ex-pressed in a query. The results are given in Figure 9(b), in which we can find the best case happens when only one term is contained in the query. On the other hand, as the length of queries increases, the overheads for the studied ranking mechanisms do not necessarily increase. They become very flat with the number of terms, which can be explained by the fact that some unpopular terms are ob-served in the query, which dramatically limit the size of the candi-date documents in the ranking priority queue. Similarly, the topic-based ranking yields similar overhead with the dynamic approach, whereas the hybrid ranking scheme produces the longest latencies. In this paper, we present a highly flexible probabilistic topic-based framework for location-sensitive domain information retrieval. In-stead of using geographical heuristics such as Euclidean distance as the spatial relevance metric, Gaussian Process is utilized to char-acterize the geographical influence distributions of topics, which are highly dynamic and difficult to be modeled using simple sta-tistical distributions. Experimental results from empirical datasets suggest that our proposed ranking method works better than other popular ranking techniques for around 29 . 7% on top-ranked docu-ment quality. As of future work, we are investigating to incorporate additional contextual information to answer other query types.
