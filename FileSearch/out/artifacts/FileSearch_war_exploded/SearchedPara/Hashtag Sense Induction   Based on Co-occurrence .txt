 it also may refer to the US TV series. [1]. There are three main types of methods [2]: 1. Cluster Approaches. ployed by computing the similarity of words. 2. Graph-based Approaches. graph. 3. Translation-Oriented Approaches. Translation-Oriented Approaches ar e for bilingual sense induction. ularity optimization [3]. 
We are facing two challenges: ate our result. there is no existing golden standard for hashtag. future work is presented in Section 7. algorithm. state of art result but a large number of parameters need to be tuned. ferent levels of sense granularity [5]. multiple senses and sense granularity into consideration [6]. media. 3.1 Rules to Use Hashtags 3.2 Features of Hashtag Usage of Hashtags #PissedOff, #LateForWork. ple: #obama, #Japan, #AppleMacBook, #NBA. 3. Used to describe an event, for instance: #WordCup2014, #UTAvsCHA. tom). Temporal Property talking about it, so the hashtags related to Christmas are used extensively. Type of Sense of Hashtag temporal property. There are four types of senses due to our observation: sense is inherited from natural language and it won X  X  disappear. be for years or scores of years. ingly the use of the hashtag also comes to an end. that frequency. Algorithm 1. Hashtag Sense Induction Input: tweets T, Wikipedia disambiguation list articles W 
Output: MappingMatrix 7. for each m ij in MappingMatrix do 8. m ij  X  Score(article i , ContextWordGroup j ) 9. end for 11. for each column m j in MappingMatrix do 12. if DispersionRatio(m j ) &lt; threshold 13. then delete m j from MappingMatrix 14. Update (MappingMatrix) 15. end for 16. for any two columns m a , m b in MappingMatrix do 17. if Mapping(m a )= =Mapping(m b ) 18. then Merge(ContextWordGroup a ,ContextWordGroup b ) 19. Update (MappingMatrix) 20. end for 22. return MappingMatrix 4.1 The Outline of Our System proposed by Vincent D. Bl o ties and represented in the f 4.2 Data set We can collect tweets by t tweets for each hashtag a n half are used to evaluate th e feature, it is unnecessary a n 4.3 Data Preprocessin g Tweets are different from n has unique elements like a Also because of the lengt h twitter acronyms such as words such as cooooool ( w information and emotion i n
Because retweets do no t retweeted quite a large nu m We apply the following s
The tweets are tokenize d hashtags, punctuation), wh i transformed into their low e speech) tagging for each w POS being noun are kept. After preprocessing: photo chief ebola survivor k 4.4 Construction of H a We define a hashtag co-oc c union of hashtag set V h a n pendent, but they are trea t they are the keywords of t tweets, so accordingly we s
For each word or hashta the frequency of the node quency as 1. The weight o f the hashtag node is calcula t frequency. sense induction. Furthermore, a pruned graph reduces the computation cost. 4.5 Community Detection and Sense Induction community. maximum of modularity is attained [3]. formula (1). used very much, it cannot explain the sense of a hashtag very well. 5.1 Wikipedia Disambiguation List as Sense Inventory However it does improve the precision of the result. quite often. words, such as #rose. 5.2 Mapping to Disambiguation List the winning sense. ipedia article. The similarity score is calculated by formula (2). filter unwanted senses by formula (3) merge them into one group of context words. 4. Repeat 2 and 3 until there is no change. In the sense matrix the highest scores are selected as the winning sense. portion of the results are showing in Table 2. 6.1 Discussions media:  X  ble that people want to share when they see a sunset with orange sky.  X  friends or families.  X  Because Wikimedia di s induce elementary sense ipedia are not the same, mapped to. 6.2 Evaluation We evaluate our method i n context words extracted fr o Tweet is ranked by the sc words existing in it. Then l top K tweets matches the s e
This evaluation method each sense is polarized. If the mapping is poor, it cou l the two senses is 100%, w correctly. If the precision i disambiguation list or the e x
Resolution is a key par a from co-occurrence graph. average precision when res 1, the induced senses decr e when resolution is set 1. F settings. For the case that, when we set K as 10. The n a precision of 74.56% whe n or new things are coming into being. 
