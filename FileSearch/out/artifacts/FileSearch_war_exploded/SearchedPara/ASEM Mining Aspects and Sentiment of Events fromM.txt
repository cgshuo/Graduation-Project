 Microblogs contain the most up-to-date and abundant opin-ion information on current events. Aspect-based opinion mining is a good way to get a comprehensive summariza-tion of events. The most popular aspect based opinion mining models are used in the eld of product and ser-vice. However, existing models are not suitable for event mining. In this paper we propose a novel probabilistic gen-erative model (ASEM) to simultaneously discover aspects and the speci ed opinions. ASEM incorporate a sequence labeling model(CRF) into a generative topic model. Addi-tionally, we adopt a set of features for separating aspects and sentiments. Moreover, we novelly present a continuous-ly learning model. It can utilize the knowledge of one event to learn another, and get a better performance. We use ve real world events to do experiment. The experimental re-sults show that ASEM extracts aspects and sentiments well, and ASEM outperforms other state-of-art models and the intuitive two-step method.
 H.3.3 [ Information Search and Retrieval ]: Text Mining Topic Model; Aspect Extraction; Aspect-Speci c Sentiment Analysis; Event Extraction  X  Co rresponding author.
 c  X 
Aspect-based opinion mining has been an active research area in natural language processing and Web mining in re-cent years. Many works have been proposed to do the summarization of products and services. Meanwhile, it is also very important to extract aspects and sentiments in events. For example, in the event of \Occupy Wall Street", demonstrators held multifarious signs and the contents of the appeal are varied. How to understand the reasons of the demonstration is a very important issue. In this paper we gure out this problem by extracting aspects and the spec-i ed sentiments in events. In our work, event aspect means the most commonly discussed topics in event. The aspect-speci c sentiment represents the social emotions toward the aspects. Consider the following tweet of Twitter \Repub-licans very concerned about human rights abuses". In this tweet, \republicans" and \human rights" are two aspects, and the respective speci ed sentiments are \concerned" and \ abuses".

An intuitive method to solve this problem is dividing it into two steps. Firstly, extract aspects in events with aspec-t extraction or clustering methods. Secondly, analyse the sentiment distribution of these aspects. However, extract-ing aspects and opinion words simultaneously can enhance the performance both of them.

Many works have been proposed to identify aspect and sentiment words in the eld of products or services. Many of them use frequent itemset mining[1][4] to extract aspects. The main limitation of these methods is that they do not group related aspects together.

Some researchers use topic models to identify aspect-speci c opinion words in the eld of product. However, these exist-ing models are not suitable for event mining for the fol-lowing two reasons. Firstly, microblogs are more noisy and diversi ed, and the aspects of events are not constant while the aspects of products are relatively constant. As a result supervised learning models, weaken supervised models and models with seeds, such as [6][9], cannot be used in event ex-traction. On the other hand, many researchers use LDA as a purely unsupervised model[3][8]. However, Lin and He[5] su ggested that fully unsupervised topic models are unable to identify opinion words well. Secondly, the count of senti-ment words is far less than aspect words in events. And the previous models has not consider this factor.

In this paper, we propose an unsupervised probabilistic generative model (ASEM), which can simultaneously extrac-t aspects and aspect-speci c opinion words of events. And it can group related aspects together. A novelty of ASEM is the integration of CRF model with the LDA model. We use a general dataset 1 to train the CRF model only once. We use the CRF model to label the latent aspects, and in-put its result to ASEM as an important feature. Moreover, we observed that the distribution of aspect and sentiment words is consistent with the distribution of POS tags. So we introduce POS tags as features to help separate aspect and sentiment words. So that our model is not only unsu-pervised, but also can separate aspect and sentiment words very well.
 What's more, we discover an important feature of event. That events of the same type may have many aspects in com-mon. For example, there are over 40% words of \CIA" event show in \NYPD" event too, not including stop words. With this observation, we propose a novel model to keep learning between events. We use ve real data sets of hot events to do experiment, and the result veri es our assumption.
ASEM is an extension of LDA which can jointly extract aspects and sentiment words. Follow [2][7] we give two as-sumptions:(1) There are K aspects in a given collection of microblogs from one event, and microblogs are mixture of topics. (2) Each word is assigned to a single aspect. The graphical representation of ASEM is shown in Fig.1. Let V be the vocabulary size, S be the number of microblogs, N s be the number of words in one microblog s and K denote the number of topics. In each topic, there are both aspects and the aspect-speci c sentiments. For word distributions, we set three multinomial from three di erent Dirichlet pri-or : a background model  X  B with parameter  X  B , K aspect models  X  A k =1  X  X  X  K with parameter  X  A , and K sentiment mod-els  X  O k =1  X  X  X  K with parameter  X  O . Then for each microblog s , we draw a topic distribution  X  s  X  Dir (  X  ).

For each word w in microblog s , we draw an aspect as-signment z s;n  X  M ulti (  X  s ). We further introduce a switch h ttp://www.cnts.ua.ac.be/conll2000/chunking/ variable r s;n  X  X  B, A, O } for the nth word w s;n to indi-cates whether it is a background, aspect or sentiment word.  X  s;n denotes the distribution of aspects and sentiments in microblogs. Let T denote the number of di erent types of word. In our model there are ve types in total, one is CRF labeled words and the other four are syntactic roles: nouns , adjectives , verbs , others . Some sentiment words are mislabeled in CRF, so in our model, the type of adjectives and verbs are prior to CRF labeled type. We use X s;n as features, which is the POS tag of current word. We only use the single POS tag as feature, not including the con-textual words and POS tags as in [9]. It is because that tweet is much more irregular with bad spellings or abbrevi-ation. After data cleaning many words are deleted, and the structures of sentences are broken. We cannot use the de-pendence between words, as a compromise we use the POS tag independently as features.
We use Gibbs Sampling to inference the model. Due to the space limit, we leave out the derivation details and only show the sampling formulas. The sampling formula of latent variables z and r are follow: where C s;k is the number of words assigned to topic k in sentence s . C A k;v is the number of times that word v is assigned to topic k as an aspect, C O k;v is the number of times that word v is assigned to topic k as a sentiment word, and C v is the number of times that word v is assigned to be a background word.  X  s;n denotes counts excluding sentence s . t represents the type of word v , it is equal to X s;n .
We observed that aspects of two events from the same type may have similarities. For example, CIA and NYPD are two political events, and obama is an aspect in both of them. So we propose an continuous learning model, which can keep learning from events in the same kind.

The learning process is show in Fig.2. E is the group of events, all of them belong to a same kind, such as: political events , sports events , entertainment events .  X  A is the a spect model in ASEM. Firstly, we use ASEM to learn the event 1, save its aspect model  X  A . Then we use the  X  A to initialize our model to learn event 2. And then the same way to learn event 3 and so on.

By utilizing the result of previous event, our model can usually have a better performance. Empirical evaluation on real world data sets shows that continuous learning have a better performance than single event.
To evaluate our model we use two kinds of real-world events: political events and sports events . We crawl al-l data sets from Twitter with it's Search AP I 2 . We set parameter q to species the key word to retrieve tweets. The Search AP I provides max id an d since id p arameter, so that we can get tweets continuously.

We crawl ve hot events occured from December 2014 to January 2015.(1) CIA event : U.S. Senate released it-s report on the CIA's use of "harsh interrogation" tactic-s against prisoners. (2) Cuba event : Obama and Castro announced to reestablish diplomatic relations. (3) N Y P D event : A gunman shot dead two police ocers in New York. (4) Bengals event : The Cincinnati Bengals win the Pitts-burgh Steelers.(5) Rajon event : Rajon Rondo full highlights vs Lakers. Detail statistics are shown in Table 1.
After data preprocessing, we use CRF++ 3 model to la-bel latent aspects by identifying our own features, including: T oken , P OS and N amed Entity . To quantitatively eval-uate our model, we randomly select 200 tweets from Cuba and Bengals event separately. We label each word to back-ground, aspect and sentiment word.

For our hybrid model, we run 500 iterations of Gibbs sam-pling. We set K to be 20 and the Dirichlet priors  X  as 0.01. Following [9], we xed  X  A =  X  O =  X  B = 0 . 01. We set up the value of  X  by cross validation with an optimal group of values which is shown in the rst three rows of Table 2.
In Table 3 we show the sample results identi ed by ASEM model. Due to space limit, we only show three aspects of the Cuba and NYPD event. For each aspect we list top 10 aspect words and the related sentiment words. We can see h ttp://apiwiki.twitter.com/ http://crfpp.googlecode.com/svn/trunk/doc/index.html ?source=navbar Table 3: Example Aspects and Sentiments Extracted by ASEM th at generally aspects and sentiment words are separated, and opinion words correspond to aspects very well. For ex-ample, \torture" is an aspect in \Human Rights" and the speci c sentiment words are \worst", \awkward". In top-ic \relations" of Cuba, \relations" and \rapprochement" are related aspects. Correspondingly the sentiment words are \good", \diplomatic" and \free".
We use manually annotated data sets of Cuba and Benjals event to do experiment. Precision( P ), Recall( R ) and the F 1 value to be the metrics. ASEM is a probabilistic model, we run 10 times for each experiment, and list the average P and R in Table 4. Our standard result named ASEM.

To evaluate the advantage of using CRF labeled data, we remove the CRF labeled data from ASEM. The result is shown in Table 4 named as ASEM NC. We can see that without CRF labeling, the average F 1 has dropped about fteen percentage points, and F 1 of sentiment have no in u-ence. Which is consistent with our expectation, as the CRF labeled data are latent aspects which a ect aspects only.
In order to prove the importance of POS tag features, we do contrast experiments ASEM NB . We weaken the in u-ence of POS tags by setting up  X  with the value of  X   X  A ,  X  ,  X 
B in Table 2. We can see that both the performance of aspect and sentiment extraction have a big decline. Moreover, we choose ME-LDA [9] as the compared method. ME-LDA can also extract both aspects and aspect-speci c opinion words. We follow this paper and use six features: { w annotated tweets to train the model. The results are demon-st rated in column ME LD A of Table 4. It can be seen that our model has a higher P and R value than ME LD A, es-pecially in the sentiment extraction.
 In addition, we compare our model with two step methods. CRF Labeling is a famous method to extract aspects. We use CRF++ to extract aspects. Then use POS tags and a sentiment word dictionary to extract sentiment words. The results are demonstrated in column TwoStep of Table 4.
In this section, we prove the continuous learning char-acter of our model. We have three political events: CIA, Cuba and NYPD, and two Sport events: Bengals and Ra-jon. Firstly we learn the CIA event and then use its  X  A to initialize NYPD event, and save the combined  X  A of these two events as  X   X  A . Cuba/S represents the single Cuba event, while Cuba/L means the Cuba event with  X   X  A initialization. As parameter  X  A is mostly in uence the extraction of as-pects, we just list the metrics of aspects in Table 5.
We can see that with the knowledge of previous event, our model can have a better performance with 2.5% improve-ment. The promotion of sport event is tiny, because Rajon is about basketball and Bengals is about football. The words they shared is 16% of Bengals, while the shared words of the three political events is 38% of Cuba.

Moreover, we compare the model labeled data with our manual annotations. We nd many aspect words that do not discovered in Cuba/S, were discovered in the Cuba/L. For example, in tweet \agriculture big appetite cuba trade honolulu", \honolulu" was labeled as background in Cuba/S while it is labeled as aspects in Cuba/L. What's more, in NYPD event \honolulu" is an aspect discovered by our mod-el. Which is the reason why our model can have a better performance in the continuous learning model.

In this paper, we propose a topic model (ASEM), which can simultaneously extract aspects and aspect-speci c opin-ion words of events. With the utilization of CRF model to do pre-extraction, we could leverage syntactic features to help extract aspect better. In addition, we introduce the POS tags as features to separate the aspect and sentimen-t words. We evaluate our model in ve real world events, and compare it against an existing approach. The experi-ments give promising results. Most importantly, we propose a continuously learning model which can utilize the knowl-edge of one event to learn another. And the continuously learning model have a better performance than single event extraction.

Timeliness is a very important information in events. In the future, we plan to add time information into our model, so that we can identify the development trend of events.
This research is supported by the Natural Science Foun-dation of China (Grant No. 61300003), Specialized Research Fund for the Doctoral Program of Higher Education(Grant No. 20130001120001) and Ministry of Education &amp; China Mobile Joint Research Fund Program (MCM20130361). [1] S. Blair-Goldensohn, K. Hannan, R. McDonald, [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] S. Brody and N. Elhadad. An unsupervised [4] M. Hu and B. Liu. Mining and summarizing customer [5] C. Lin and Y. He. Joint sentiment/topic model for [6] A. Mukherjee and B. Liu. Aspect extraction through [7] M. Steyvers and T. Griths. Probabilistic topic [8] I. Titov and R. T. McDonald. A joint model of text [9] W. X. Zhao, J. Jiang, H. Yan, and X. Li. Jointly
