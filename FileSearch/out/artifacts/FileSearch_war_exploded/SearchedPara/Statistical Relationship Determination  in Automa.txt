 key issues in automatic thesaurus construction. We systematically analyze existing relevant approaches based on their underlying probabilistic assumptions, and propose a combined approach that overcomes their limitations. H.3.1 [I nformation Retrieval and Storage ]: Content Analysis and Indexing  X  abstraction methods, thesauruses. Keywords: Statistic relationship determination, automatic thesaurus construction This work focuses on determining term relationships for the purpose of automatic thesaurus construction, assuming that the approaches as described in [1]. common context, with each being quantified by means of conditional probabilities. Because all notions have individual strengths and weaknesses, we suggest a similarity measure that conjunctively combines the evidence provided by each notion of context. We propose a formalization for measuring the similarity between terms based on conditional probabilities, which can be applied to Intuitively, the degree of relationship between two terms depends how likely the individual contexts imply a common context. This conditional probability P(t 1 |t 2 ) measures the probability of term t given term t 2 . This probability can be determined in the usual way and t 2 with the probability P(t 2 ) for a context of t 2 t . Thus, To measure how strongly the two terms imply each other, the conditional probabilities in both directions can be multiplied with each other to give the mutual conditional probability: Statistical relationship determination between terms is usually context. The occurrence context of a target term t can be defined as the set or a part of a document, e.g. a paragraph, a sentence, or a window use text segments consisting of n terms to the left and the right of achieved the best performance in exploratory tests. context_occ(t) = { text segment txtseg | t  X  txtseg} The common context of two terms t 1 and t 2 can be defined as the distance of at most n terms. context_occ(t 1 ,t 2 ) = {txtseg | t 1 , t 2  X  txtseg) According to the conditional probablity model, the relationship as: = One drawback of occurrence based approaches is that they do not problem that multiple co-occurrences of terms t 1 and t similar content increase the similarity of t 1 and t One approach to overcome this is to look at the actual terms in the content context: context_con(t) = {terms t con | t con with t} where the expression  X  X  i with t j  X  means that t i co-occurs with t occurrence context. The common content context of two terms t 1 and t 2 can be defined as the intersection of the individual context of t 1 and t context_con(t 1 ,t 2 ) = context_con(t 1 )  X   X   X   X  context_con(t The content context based similarity measure rel_con(t 1 ,t conditional probability model. In our experiments, however, the purely content based approach does not perform very well. This appears to be mainly due to the do not indicate some specific aspects of these generic terms. Many of these context terms will also occur with both generic terms. But used for inferring a meaningful relationship. To overcome the problems of occurrence context and content context we combine them to a notion of common context based on co-occurrence and common content: context_occ_con(t 1 ,t 2 ) = {terms t con | t con with t with t 2 ) } the content in the common text segments, while from another two target terms, i.e. t 1 and t 2 , co-occur in the same text segment. Compared with the purely occurrence based common context, this common context based on occurrence and content gives equal importance to all distinct context terms t con used with t matter how many such co-occurrences are. Thereby, multiple co-of these terms less strongly. Compared with purely content based common context, it considers only context terms t con significant common aspect of these terms. This notion of common context can be used to measure two kinds of conditionality probabilities, one that normalizes this common context by occurrence context, and one that normalizes it by common content context. The first conditional probability rel_occ_con(t 1 calculated in a similar way as rel_occ(t 1 ,t 2 ) and rel_con(t based on the new common context: = aspect_ratio and deals with the problem of spurious common occur in context_occ_con(t 1 ,t 2 ). determination, we combine them in one similarity measure to achieve optimal performance. rel_combined(t 1 ,t 2 )= rel_occ(t 1 ,t 2 )  X  rel_occ_con(t aspect_ratio(t 1 ,t 2 ) We automatically evaluate existing measures (including cosine coefficient, dice coefficient [3], pointwise mutual information [2] etc.) and our measures by comparing the automatically determined relationships with a gold standard thesaurus, whereby the F-measure [3] is adopted to combine precision and r ecall. Results show that approaches based on occurrence context generally outperform approaches based on content context. conditional probability model tend to generally outperform those deviating from the model. The combined similarity measure, i.e. determination, achieving an improvement of nearly 70% at the best F-measure value compared with the traditional document based co-occurrence analysis [4]. framework for relationship determination. Base on formal type of common context and a combined similarity measure combining different kinds of probabilistic evidence have been proposed for better relationship determination. Experimental results confirm our analysis. [1] Libo Chen, Ulrich Thiel, "Language Modeling for Effective [2] K.W. Church and P. Hanks. 1990. Word association norms, [3] C. J. Van Rijsbergen. Information Retrieval, 2nd edition, [4] Gerard Salton. Automatic Information Organization and 
