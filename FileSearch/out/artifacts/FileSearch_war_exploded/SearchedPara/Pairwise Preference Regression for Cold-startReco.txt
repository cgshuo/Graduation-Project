 Recommender systems are widely used in online e-commerce applications to improve user engagement and then to in-crease revenue. A key challenge for recommender systems is providing high quality recommendation to users in  X  X old-start X  situations. We consider three types of cold-start prob-lems: 1) recommendation on existing items for new users; 2) recommendation on new items for existing users; 3) rec-ommendation on new items for new users. We propose predictive feature-based regression models that leverage all available information of users and items, such as user de-mographic information and item content features, to tackle cold-start problems. The resulting algorithms scale effi-ciently as a linear function of the number of observations. We verify the usefulness of our approach in three cold-start settings on the MovieLens and EachMovie datasets, by com-paring with five alternatives including random, most popu-lar, segmented most popular, and two variations of Vibes affinity algorithm widely used at Yahoo! for recommenda-tion.
 H.1.0 [ Models and Principles ]: General; H.3.3 [ Information Search and Retrieval ]: Information filtering; H.3.5 [ Online Information Services ]: Web-based services Algorithms, Experimentation, Measurement, Performance Recommender System, cold-start problems, user and item features, ranking, normalized Discounted Cumulative Gain  X  This work was conducted while Seung-Taek Park was at Yahoo! Labs.

Recommender systems automate the familiar social pro-cess of friends endorsing products to others in their commu-nity. Widely deployed on the web, such systems help users explore their interests in many domains, including movies, music, books, and electronics. Recommender systems are widely applied from independent, community-driven web sites to large e-commerce powerhouses like Amazon.com. Recommender systems can improve users X  experience by per-sonalizing what they see, often leading to greater engage-ment and loyalty. Merchants, in turn, receive more explicit preference information that paints a clearer picture of their customers. Two different approaches are widely adopted to design recommender systems: content-based filtering and collaborative filtering .

Content-based filtering generates a profile for a user based on the content descriptions of the items previously rated by the user. The major benefit of this approach is that it can recommend users new items, which have not been rated by any users. However, content-based filtering cannot provide recommendations to new users who have no historical rat-ings. To provide new user recommendation, content-based filtering often asks new users to answer a questionnaire that explicitly states their preferences to generate initial profiles of new users. As a user consumes more items, her profile is updated and content features of the items that she consumed will receive more weights. One drawback of content-based filtering is that the recommended items are similar to the items previously consumed by the user. For example, if a user has watched only romance movies, then content-based filtering would recommend only romance movies. It often causes low satisfaction of recommendations due to lack of diversity for new or casual users who may reveal only small fraction of their interests. Another limitation of content-based filtering is that its performance highly depends on the quality of feature generation and selection.

On the other hand, collaborative filtering typically asso-ciates a user with a group of like-minded users, and then recommends items enjoyed by others in the group. Col-laborative filtering has a few merits over content-based fil-tering. First, collaborative filtering does not require any feature generation and selection method and it can be ap-plied to any domains if user ratings (either explicit or im-plicit) are available. In other words, collaborative filtering is content-independent. Second, collaborative filtering can provide  X  X erendipitous finding X , whereas content-based filter-ing cannot. For example, even though a user has watched only romance movies, a comedy movie would be recom-mended to the user if most other romance movie fans also love it. Collaborative filtering captures this kind of hidden connections between items by analyzing user consumption history (or user ratings on items) over the population. Note that content-based filtering uses a profile of individual user but does not exploit profiles of other users.

Even though collaborative filtering often performs better than content-based filtering when lots of user ratings are available, it suffers from the cold-start problems where no historical ratings on items or users are available. A key challenge in recommender systems including content-based and collaborative filtering is how to provide recommenda-tions at early stage when available data is extremely sparse. The problem is of course more severe when the system newly launches and most users and items are new. However, the problem never goes away completely, since new users and items are constantly coming in any healthy recommender system. We consider three types of cold-start setting in this paper: 1) recommending existing items for new users, 2) recommending new items for existing users, and 3) recom-mending new items for new users.

We realize that there are additional information on users and items often available in real-world recommender sys-tems. We can request users X  preference information by en-couraging them to fill in questionnaires or simply collect user-declared demographic information (i.e. age and gen-der) at registration. We can also utilize item information by accessing the inventory of most on-line enterpriser. These legally accessible information is valuable for both recom-mending new items and serving new users. To attack the cold-start problem, we propose new hybrid approaches which exploit not only user ratings but also user and item features. We construct tensor profiles for user/item pairs from their individual features. Within the tensor regression frame-work, we optimize the regression coefficients by minimiz-ing pairwise preference loss. The resulting algorithm scales efficiently as a linear function of the number of observed ratings. We evaluate our approach with two standard movie data sets: MovieLens and EachMovie. We cannot use the Netflix data since it does not provide any user information. Note that one of our goals is providing reasonable recom-mendation to even new users with no historical ratings but only a few demographic information.

We split user ratings into four partitions. We randomly select half of users as new users and the rest as existing users. Similarly, we randomly split items as new and existing items. Figure 1 illustrates data partition. Then we use partition I for training and partition II, III, and IV for test. We summarize available techniques for each partition in the following: Existing items Figure 1: Data partition: We randomly select 50% users as new users and the rest as existing users. Similarly half of items are randomly selected as new items and the others as existing items. We use the partition I for training and the partition II, III, and IV for test.
We evaluate performance of recommender systems based on the correctness of ranking rather than prediction accu-racy, the normalized Discounted Cumulative Gain (  X  X  X  X  X  X  ), widely used in information retrieval (IR), as performance metric. We compare against five recommendation approaches including Random, Most Popular (MP), Segmented Most Popular (SMP), and two variations of Vibes Affinity algo-rithm (Affinity) [21] widely used at Yahoo!.

The paper is organized as follows: We describe our algo-rithm in Section 2; We review related work in Section 3; We report experimental results with comparison against five ex-isting competitive approaches in Section 4; We conclude in Section 5.
In this section, we propose a regression approach based on profiles (TR) for cold-start recommendation. In many real recommender systems, users sometimes declare their demo-graphical information, such as age, gender, residence, and etc., whereas the recommender systems also maintain infor-mation of items when items are either created or acquired, which may include product name, manufacturer, genre, pro-duction year, etc. Our key idea is to build a predictive model for user/item pairs by leveraging all available information of users and items, which is particularly useful for cold-start recommendation including new user and new item recom-mendation. In the following, we describe our approach in three subsections. The first subsection presents profile con-struction, and the last two subsections cover algorithm de-sign.
It is crucial to generate and maintain profiles of items of interest for effective cold-start strategies. For example, we collect item contents (i.e. genre, cast, manufacturer, pro-duction year etc.) as the initial part of the profile for movie recommendation. In addition to these static attributes, we also estimate items X  popularity/quality from available his-torical ratings in training data, e.g. indexed by averaged scores in different user segments, where user segments could be simply defined by demographical descriptors or advanced conjoint analysis.

Generally we can construct user profiles as well by col-lecting legally usable user-specific features that effectively represent a user X  X  preferences and recent interests. The user features usually consist of demographical information and historical behavior aggregated to some extent.

In this way, each item is represented by a set of features, denoted as a vector z , where z  X   X   X  and  X  is the number of item features. Similarly, each user is represented by a set of user features, denoted as x , where x  X   X   X  and  X  is the number of user features. Note that we append a constant feature to the user feature set for all users. A new user with no information is represented as [0 ,..., 0 , 1] instead of a vector of zero entries.

In traditional collaborative filtering (CF), the ratings given by users on items of interest are used as user profiles to evaluate commonalities between users. In our regression ap-proach, we separate these feedbacks from user profiles. The ratings are utilized as targets that reveal affinities between user features to item features.

We have collected three sets of data, including item fea-tures, user profiles and the ratings on items given by users. Let index the  X  -th user as x  X  and the  X  -th content item as z , and denote by  X   X  X  X  the interaction between the user x  X  and the item z  X  . We only observe interactions on a small subset of all possible user/item pairs, and denote by  X  the index set of observations {  X   X  X  X  } .
A predictive model relates a pair of vectors, x  X  and z  X  the rating  X   X  X  X  on the item z  X  given by the user x  X  . There are various ways to construct joint feature space for user/item pairs. We focus on the representation via outer products, i.e., each pair is represented as x  X   X  z  X  , a vector of  X  X  X  entries {  X   X , X   X   X , X  } where  X   X , X  denotes the  X  -th feature of z and  X   X , X  denotes the  X  -th feature of x  X  .

We define a parametric indicator as a bilinear function of x  X  and z  X  in the following: where  X  and  X  are the dimensionality of user and content features respectively,  X , X  are feature indices. The weight variable  X   X  X  X  is independent of user and content features and characterizes the affinity of these two factors  X   X , X  and  X  in interaction. The indicator can be equivalently rewritten as where W is a matrix containing entries {  X   X  X  X  } , w denotes a column vector stacked from W , and z  X   X  x  X  denotes the outer product of x  X  and z  X  , a column vector of entries {  X   X , X 
The regression coefficients can be optimized in regulariza-tion framework, i.e. where  X  is a tradeoff between empirical error and model complexity. Least squares loss coupled with 2-norm of w , is widely applied in practice due to computational advan-tages. 1 The optimal solution of w is unique and has a closed form of matrix manipulation, i.e. where I is an  X  X  X  by  X  X  X  identity matrix. By exploiting the tensor structure, the matrix preparation costs  X  (  X  X  X   X  X  2  X  2 ) where  X  and  X  are the number of items and users respectively. The matrix inverse costs  X  (  X  3  X  3 ), which be-comes the most expensive part if  X  &lt;  X  X  X  and  X  &lt;  X  X  2
The tensor idea can be traced back to the Tucker family [33] and the PARAFAC family [16]. Recently exploratory data analysis with tensor product has been applied to im-age ensembles [34], DNA microarray data intergration [22] and semi-infinite stream analysis [32] etc. To our best knowl-edge, tensor regression hasn X  X  been applied to cold-start rec-ommendation yet.

In recommender systems, users may enjoy different rat-ing criteria. Thus the ratings given by different users are not comparable due to user-specific bias. We can lessen the effect by introducing a bias term for each user in the above regression formulation, however it not only enlarges the problem size dramatically from  X  X  X  to  X  X  X  +  X  where  X  denotes the number of users and usually  X   X   X  X  X  , but also increases uncertainty in the modelling. Another concern is that the least squares loss is favorable for RMSE metric but may result in inferior ranking performance. Pairwise loss is widely used for preference learning and ranking, e.g. RankRLS [23] and RankSVM [17], for superior performance.
In this paper, we introduce a personalized pairwise loss in the regression framework. For each user x  X  , the loss function is generalized as where  X   X  denotes the index set of all items the user x  X  rated,  X   X  =  X   X   X   X  the number of ratings given by the user x , and  X   X  X  X  is defined as in eq(1). Replacing the squares loss by the personalized pairwise loss in the regularization framework, we have the following optimization problem: min where  X  runs over all users. The optimal solution can be
Other loss functions could be applied as well, e.g. the hinge loss in support vector machines, while advanced quadratic programming has to be applied. computed in a closed form as well, i.e. The size in matrix inverse is still  X  X  X  and the matrix prepa-ration costs  X  (  X  X  X  2 +  X  X  2  X  2 ) same as that of the least squares loss.

When matrix inversion with very large  X  X  X  becomes com-putationally prohibitive, we can instead apply gradient-descent techniques for a solution. The gradient can be evaluated by Aw  X  B . There is no matrix inversion involved in each eval-uation, and the most expensive step inside is to construct the matrix A once only. Usually it would take hundreds of iterations for a gradient-descent package to get close to the minimum. Note that this is a convex optimization problem with a unique solution at the minimum.
Two different approaches have been widely used to build recommender systems: content-based filtering and collabo-rative filtering. Content-based filtering uses behavioral data about a user to recommend items similar to those consumed by the user in the past while collaborative filtering compares one user X  X  behavior against a database of other users X  be-haviors in order to identify items that like-minded users are interested in. The major difference between two approaches is that content-based filtering uses a single user information while collaborative filtering uses community information.
Even though content-based filtering is efficient in filter-ing out unwanted information and generating recommenda-tions for a user from massive information, it often suffers from lack of diversity on the recommendation. Content-based filtering requires a good feature generation and selec-tion method while collaborative filtering only requires user ratings. Content-based filtering finds few if any coinciden-tal discoveries while collaborative filtering systems enables serendipitous discoveries by using historical user data. Hun-dreds of collaborative filtering algorithms have been pro-posed and studied, including K nearest neighbors [30, 18, 28], Bayesian network methods [10], classifier methods [9], clustering methods [35], graph-based methods [4], proba-bilistic methods [19, 26], ensemble methods [13], taxonomy-driven [36], and combination of KNN and SVD [8].

Although collaborative filtering provides recommendations effectively where massive user ratings are available such as in the Netflix data set, it does not perform well where user rating data is extremely sparse. Several linear factor mod-els have been proposed to attack the data sparsity. Singular Value Decomposition (SVD), Principal Component Analysis (PCA), or Maximum Margin Matrix Factoriation (MMMF) has been used to reduce the dimensions of the user-item matrix and smoothing out noise [9, 27, 14]. However, those linear factor models do not solve the cold-start problems for new users or new items. Several hybrid methods, which of-ten combine information filtering and collaborative filtering techniques, have been proposed. Fab [5] is the first hybrid recommender system, which builds user profiles based on content analysis and calulates user similarities based on user profiles. Basu et al. [7] generated three different features: collaborative features (i.e. users who like the movie X), con-tent features, and hybrid features (i.e. users who like comedy movies). Then, an inductive learning system, Ripper, is used to learn rules and rule-based prediction was generated for the recommendation. Claypool et al. [12] built an online news-paper recommender system, called Tango, that scored items based on collaborative filtering and content-based filtering separately. Then two scores are linearly combined: As users provide ratings, absolute errors of two scores are measured and weights of two algorithms are adjusted to minimize er-ror. Good et al. [15] experimented with a number of types of filterbots, including including Ripper-Bots, DGBots, Genre-Bots and MegaGenreBot. A filterbot is an automated agent that rates all or most items algorithmically. The filterbots are then treated as additional users in a collaborative filter-ing system. Park et al. [24] improved the scalability and performance of filterbots in cold-start situations by adding a few global bots instead of numerous personal bots and applying item-based instead of user-user collaborative fil-tering. Melville et al. [20] used content-based filtering to generate default ratings for unrated items to make a user-item matrix denser. Then traditional user-user collaborative filtering is performed using this denser matrix. Schein et al. [29] extended Hofmann X  X  aspect model to combine item contents and user ratings under a single probabilistic frame-work. Even though hybrid approaches potentially improve the quality of the cold-start recommendation, the main focus of many hybrid methods is improving prediction accuracy over all users by using multiple data rather than directly attacking the cold-start problem for new users and items. Note that all above approaches only lessen the cold-start problem where a target user has rated at least few ratings but do not work for new user or new item recommendation.
There are a few existing hybrid approaches which are able to make new user and new item recommendation. Pazzani [25] proposed a hybrid method that recommends items based on vote of four different algorithms: user-user collaborative filtering, content-based, demographic-based, and collabora-tion via content. This approach can provide new user recom-mendation by assembling several independent models. Our approach provides a unified framework of learning user-item affinity from all heterogeneous data simultaneously. Basilico and Hofmann [6] proposed an online perceptron algorithm coupled with combinations of multiple kernel functions that unify collaborative and content-based filtering. The result-ing algorithm is capable of providing recommendations for new users and new items, but the performance has not been studied yet. The computational complexity in the proposed kernel machine scales as a quadratic function of the num-ber of observations, which limits its applications to large-scale data sets. Agarwal and Merugu [3] proposed a sta-tistical method to model dyadic response as a function of available predictor information and unmeasured latent fac-tors through a predictive discrete latent factor model. Even though the proposed approach can potentially solve the cold-start problems, its main focus is improving quality of recom-mendation in general cases and its performance in cold-start settings is not fully studied yet. Chu and Park [11] proposed a predictive bilinear regression model in  X  X ynamic content environment X , where the popularity of items changes tem-porally, lifetime of items is very short (i.e. few hours), and recommender systems are forced to recommend only new items. This work suggests to maintain profiles for both con-tents and users, where temporal characteristics of contents, e.g. popularity and freshness, are updated in real-time. In their setting, only tens of items are available at each mo-ment and the goal is recommending the best among these active items to users. In our setting, item space is rather static but the number of items available at any moment is much larger (i.e. few thousands), and the user attributes are limited to demographic information only. Recently, Stern et al. [31] proposed a probabilistic model that combines user and item meta data with users X  historical ratings to pre-dict the users X  interaction on items. Agarwal and Chen [2] also independently proposed a regression-based latent factor model for cold-start recommendation with the same spirit. In these models, dyadic response matrix Y is estimated by a latent factor model such as Y  X  U  X  V , where latent fac-tor matrices, U and V , are estimated by regression such as U  X  FX and V  X  MZ . X and Z denote user attribute and item feature matrices, and F and M are weight ma-trices learnt by regression. These approaches have similar spirit to our model, while the key difference lies on method-ology to estimate the weights. In our approach, we estimate the weight matrix W as in eq(2) by solving a convex op-timization, whereas in the above works the weight matrix is approximated by a low-rank matrix decomposition, such as W  X  F  X  M , and latent components are then estimated by either approximate Bayesian inference or expectation-maximization techniques. We note the latent components are rotation-invariant in their own space, that means there are numerous local minima in the solution space which may make the estimation complicated.
In this section we report experimental results on two movie recommendation data sets, MovieLens and EachMovie. We first describe existing competitive algorithms we implemented for comparison purpose. Then we describe our testing pro-cedure and report empirical results with the MoiveLens and EachMovie data.
We implemented three alternative recommendation ap-proaches for comparison.
Most Popular (MP) provides the same recommendation to all users based on global popularity of items. The global popularity of an item is measured as following: where the average rating  X   X  is defined as 1  X  support  X   X  =  X   X   X   X  is the number of users who have rated the  X  -th item,  X  denotes the average of all ratings and  X  denotes a shrinkage parameter which is inspired by [8]. Here  X  = 3 . 6 for the MovieLens data and  X  = 4 . 32 for the EachMovie data, which were measured in the partition I, shown in the figure 1. When  X  = 0,  X   X  is purely based on its average rating  X  . When  X  &gt; 0,  X   X  will be close to the overall average  X  if only few users have rated the item  X  . We set  X  = 2 both on MovieLens and EachMovie, which yields the best performance in validation.
Segmented Most Popular (SMP) divides users into several user segments based on user features (i.e. age or gender) and computes predictions of items based on their local popularity within the user segment which a target user belongs to: where  X   X  X  X  and  X   X  X  X  denote the average rating of an item  X  within a user segment  X  and the number of users who have rated the item  X  within the user segment  X  . We have tested three different segmentation methods based on gen-der only, age only, and the combination of age and gender (age*gender). There are two gender groups, male and female (one additional age group  X  X nknown X  for EachMovie due to missing entries), and seven age groups, i.e. under 18, 18-24, 25-34, 35-44, 45-49, 50-55, and above 56 (one additional  X  X nknown X  age group for EachMovie). The parameter  X  was determined by validation. We found the best SMP model is with  X  = 9 on MovieLens and  X  = 5 for EachMovie.
The Vibes Affinity algorithm [21] is used at several Yahoo properties including Yahoo! Shopping, Yahoo! Auto and Yahoo! Real Estate. The algorithm computes item-item affinity based on conditional probability such as where  X   X  and  X   X  X  X  denote the number of users who consumed (e.g. clicked) an item  X  and the number of users who con-sumed the item  X  and  X  . Then preference score of each item  X  for a user  X  is computed as following: where  X   X  denotes a set of items the user  X  has consumed.
To provide cold start recommendation we slightly modi-fied the algorithm. For the partition II (existing item rec-ommendation for new users), we modified the equation (13) and (14) to measure user attribute-item affinity such as where  X   X  X  X  denotes the number of users who have an at-tribute  X  and have consumed an item  X  .  X   X  is a set of attributes the user  X  has.  X   X  X  X  ;  X  X  X  X  X  X  denotes the number of users who like  X  among the users who have an attribute  X  and have consumed an item  X  . We consider that a user like an item if she rated it higher than the average rating, shown in the Table 1. We call this variation of the affinity model as Affinity1 hereafter. For the partition III and IV, we measure user attribute-item feature affinity such as Table 1: Basic statistics of the MovieLens and Each-Movie data.
 where  X   X  denotes a set of features the item  X  has.  X   X  X  X  is a number of user-item pairs in the training data, which contain both a user attribute  X  and an item feature  X  .  X   X  X  X  ;  X  X  X  X  X  X  denotes the number of positive preference pairs (e.g. rating higher than the average rating) in  X   X  X  X  . We call this variant affinity model as Affinity2 hereafter. We used two movie rating data sets: MovieLens and Each-Movie. In the EachMovie data, we first removed all  X  X ounds awful X  ratings since those ratings (which have a weight less than one) were not real ratings but represented users X  im-pressions on items. In addition to rating data, both data sets also contain some user attributes and movie informa-tion. As described in Section 2.1, we collected user and movie features for the MovieLens and EachMovie datasets respectively. The features we collected are summarized in Table 2. The age/gender categories are same as those de-fined in Segmented Most Popular, see Subsection 4.1.2. In MovieLens, there are 21 occupation categories for users and 18 genre categories for movies. The movie-released year was categorized into 13 groups, { &gt; =2000, 1999, 1998, 1997, 1996, 1995, 1994-1990, 80 X  X , 70 X  X , 60 X  X , 50 X  X , 40 X  X , &lt; 1940 } . In EachMovie, there are two  X  X tatus X  categories for movies,  X  X heater-status X  and  X  X ideo-status X . We also grouped users into three location categories based on zip code, including  X  X S X ,  X  X nternational X  and  X  X nknown X .

In addition to item features from data, we used fourteen filterbots [24] as item features for our proposed approach. These bots rate all or most of the items algorithmically ac-cording to attributes of the items or users. For example, an actor bot would rate all items in the database according to whether a specific actor was present in the movie or not. The MPBot rates items based on their global popularity computed by the equation (11). The VTBot rates items ac-cording to their  X  X ser support X  such as  X   X  = log  X   X  / X  , where  X  is the number of users who have rated an item  X  (or user support on the item  X  ) and  X  is a normalization factor that caps ratings at the maximum rating (5 for MovieLens and 6 for EachMovie). The GenreBot first calculates average rat-ings of each genre. Then it rates items based on the average rating of the genre which a movie belongs to. If a movie has more than one genre, GenreBot rates the item based on aver-age of genre ratings. We also built eleven SMPBots, which rates items based on their popularity in eleven segments (three gender and eight age-group segments) computed by the equation (12).

We split user ratings into four partitions. We randomly selected half of users as new users and the rest as existing users. Similarly, we randomly split items as new and exist-ing items. Figure 1 illustrates data partition. Then we used partition I for training and partition II, III, and IV for test. Table 2: User attributes and movie features in MovieLens and EachMovie we used.
 We generated 20 partitions with different random seeds. We used the following test procedure: for each user in the parti-tion II, III, and IV, we clustered items based on ratings given by each user. For example, if a user rated an item  X  and  X  five and  X  and  X  three, then the user would have two item clusters; one containing  X  and  X  and the other containing  X  and  X  . We considered only the items rated by each user. Then we randomly sampled one item for each cluster. We filtered out users who have only one item cluster. In such a way, each test user is associated with a set of sampled items with size from two to five and with different ratings. Then we measured  X  X  X  X  X  X   X  as following: where  X   X  X  X  ,  X   X  , and  X  X  X  X  X  X   X   X  are defined as the real rating of a user  X  on the  X  -th ranked item, a set of users in the test data, and the best possible  X  X  X  X   X   X  for the user  X  . We measured  X  X  X  X  X  X   X  where  X  = 1 and 5 and observe similar results.

One potential question might be why not to measure  X  X  X  X  X  X  1 for all items that a user has rated in the test data. The rea-son is that there might be lots of 5 rated items for certain users in the test data and any algorithm that places one of those 5 rated items at the first place would have the best possible performance. If the number of 5 rated items for a user is larger, then the test becomes easier since algorithms just need to place one of those many 5 rated items at the first place. To remove performance bias to heavy or gen-erous users, we sampled one item for each rating cluster to have only one best item in the test item set. For each of 20 partition sets, we sampled 500 times for each user and average  X  X  X  X  X  X  1 over those 500 runs. Then we reported the mean  X  X  X  X  X  X  1 and the standard deviations over 10,000 runs. All fourteen filterbots were imported as item features when our approach was tested on the partition II (existing item recommendation for new users). For the partition III and IV, only GenreBot was imported.
We conducted experiments on three types of cold-start recommendation tasks: (1) recommendation on existing items for new users, (2) recommendation on new items for exist-ing users, and (3) recommendation on new items for new are tested on three cold-start settings. Bold-face represents the best. 1 STD  X  X  X  X  X  X  1 STD users. The first type of cold-start recommendation task is executed when new users request recommendation at any system while the second and third cold-start recommenda-tion usually happens in News domain or newly-launched sys-tems where a recommender is always forced to recommend new items.

In the first recommendation task, we compared our ap-proach to five alternative recommendation methods: Ran-dom, Most popular, Segmented Most Popular, and two vari-ations of the Affinity algorithm. We found that SMP and our approach perform better than others but performance differences among MP, SMP, Affinity1 and our approach are not significant. Our results show that item popularity fea-tures such as global popularity (MP) or popularity within a segment (SMP) provide much stronger signals than any other item features and it makes MP and SMP hard-to-beat baselines, which is also shown in [1, 11].

In the second and third tasks, since all items we can rec-ommend are new items without any historical ratings, MP, SMP, and Affinity1 cannot work. With absent of item pop-ularity features, we clearly see our approach significantly outperforms over random and Affinity2. We would like to note that our approach can be used to estimate initial guess of item popularity for new items in online recommender sys-tems such as Yahoo! Front Page Today Module [1].
In many real recommender systems, great portion of users are new users and converting new users to active users is a key of success for online enterprisers. We developed hybrid approaches which exploit not only user ratings but also fea-tures of users and items for cold-start recommendation. We constructed profiles for user/item pairs by outer product over their individual features, and built predictive models in regression framework on pairwise user preferences. The unique solution is found by solving a convex optimization problem and the resulting algorithms scale efficiently for large scale data sets. Although the available features of items and users are simple and sometimes incomplete in our experiments, our methods performed consistently and sig-nificantly better than two baseline algorithms, random and Affinity2, on new user and new item recommendation. As for future work, we would like to extensively compare with other existing variants along the direction of feature-based modeling on ranking quality in cold-start situations. We thank our colleagues, Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Liang Zhang for many use-ful discussions. We thank MovieLens and EachMovie for publishing their valuable data. [1] D. Agarwal, B. Chen, P. Elango, N. Motgi, S. Park, [2] D. Agarwal and B.-C. Chen. Regression based latent [3] D. Agarwal and S. Merugu. Predictive discrete latent [4] C. C. Aggarwal, J. L. Wolf, K.-L. Wu, and P. S. Yu. [5] M. Balabanovic and Y. Shoham. Fab: content-based, [6] J. Basilico and T. Hofmann. A joint framework for [7] C. Basu, H. Hirsh, and W. W. Cohen.
 [8] R. Bell, Y. Koren, and C. Volinsky. Modeling [9] D. Billsus and M. J. Pazzani. Learning collaborative [10] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [11] W. Chu and S.-T. Park. Personalized recommendation [12] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov, [13] D. DeCoste. Collaborative prediction using ensembles [14] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [15] N. Good, J. B. Schafer, J. A. Konstan, A. Borchers, [16] R. A. Harshman. Parafac2: Mathematical and [17] R. Herbrich, T. Graepel, and K. Obermayer. Support [18] J. L. Herlocker, J. A. Konstan, A. Borchers, and [19] T. Hofmann and J. Puzicha. Latent class models for [20] P. Melville, R. Mooney, and R. Nagarajan.
 [21] B. Nag. Vibes: A platform-centric approach to [22] L. Omberg, G. H. Golub, and O. Alter. A tensor [23] T. Pahikkala, E. Tsivtsivadze, A. Airola, T. Boberg, [24] S.-T. Park, D. M. Pennock, O. Madani, N. Good, and [25] M. J. Pazzani. A framework for collaborative, [26] D. Pennock, E. Horvitz, S. Lawrence, and C. L. Giles. [27] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [28] B. M. Sarwar, G. Karypis, J. A. Konstan, and [29] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. [30] U. Shardanand and P. Maes. Social information [31] D. H. Stern, R. Herbrich, and T. Graepel. Matchbox: [32] J. Sun, D. Tao, and C. Faloutsos. Beyond streams and [33] L. R. Tucker. Some mathematical notes on three-mode [34] H. Wang and N. Ahuja. Efficient rank-r approximation [35] G. Xue, C. Lin, Q. Yang, W. Xi, H. Zeng, Y. Yu, and [36] C. Ziegler, G. Lausen, and L. Schmidt.

