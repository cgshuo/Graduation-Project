 1. Introduction
The agile development process breaks down the software development lifecycle into a number of consecutive iterations that increases communication and collaboration among stakeholders. This type of process focuses on the rapid production of processes have been extended to offer more techniques, e.g. describing the requirements with user stories [2]. Instead of a manager estimating developmental time and effort and assigning tasks based on conjecture, team members in agile processes use objective measurement of software size is crucial in the planning and management of agile projects.
 gives the project manager confidence about future courses of action, since many of the decisions made during development depend on the initial estimations. Better estimation of size and effort allows managers to determine the comparative cost of a project, improve process monitoring, and negotiate contracts from a position of knowledge.
 The above has led the industry to formulate several methods for functional size measurement (FSM) of software. In 1979,  X 
Function Point (FP)  X  . His idea of effort estimation was then validated by many studies, like [6,7], and, thus, measuring the by different organisations on FSM methods, following the concepts presented in Albrecht's FPA method. Four of these standards have been accepted as ISO standards: they are IFPUG [8], Mark II [9], NESMA [10] and COSMIC [11].

In recent years, many studies (e.g. [12  X  14]) have attempted to automate the process of different functional size measurement methods, but, to our knowledge, none has addressed this problem by taking the textual requirements as input to start the automatic measurement process. In addition, all these work depended on extracting manually the conceptual modeling artifacts documented in this paper aims to develop a tool that would automatically perform a quicker approximation of COSMIC size without requiring the formalisation of the requirements. This is in response to the high industrial demands of performing size estimation during agile development processes, where formalisation of requirements are regarded as costly manipulation, and, thus, ignored during size estimation. Our methodology extends the idea presented in the Estimation by Analogy approach [15] approach in COSMIC was manually demonstrated by [17]. 2. Background 2.1. COSMIC For the purpose of this research, we have chosen to use the COSMIC FSM method developed by the Common Software
Measurement International Consortium (COSMIC) and now adopted as an international standard [11]. We chose this method in particular, because it conforms to all ISO requirements [18] for FSM, focuses on the phase compared to the other FSM methods is demonstrated by the study of [19]. Also, COSMIC does not rely on subjective decisions by the functional size measurer during the measurement process [11]. Thus, its measurements, taken from well-specified requirements, tend to be same among multiple measurers. This is particularly important for validating the performance of our automatic size measurements.

In COSMIC, size is measured in terms of the number of Data-movements , which accounts for the movement of one or more
COSMIC, is an independently executable set of data-movements that is triggered by one or more triggering events . A triggering measured. Thus, a functional process holds the similar scope of a use case scenario, starting with the triggering event of a perspective, presented in the COSMIC standard [11].

As shown in Fig. 1 , the data-movements can be of four types: Entry, Exit, Read and Write. An Entry moves a data-group from a user across the boundary into the functional process, while an Exit moves a data group from a functional process across the moves a data group from persistent storage to the functional process.

COSMIC counts each of these data-movements as one CFP (COSMIC Function Point) of functional size, and measures the size of system to be measured.
 development, where documentation of requirements using formalisms and templates is required. However, over the years, the IT industry has recognised the traditional processes to cause many problems including delays and is now increasingly moving towards agile development processes [20], such as Scrum [2], an agile approach that does not impose documentation templates or formalisms on requirements. 2.2. Size measurement in agile development processes
Agile development processes are driven by the motto of delivering releases as quickly as possible [1]. Planning an iteration in agile.
 although, do not provide detailed description of the scenarios like those found in use cases, they must hold perform the size estimation [2]. Size measurement methods in agile development processes include story-points [3] and smart estimation [21], and depend on the subjective judgment of human experts, and, therefore, are prone to biases and errors [3].
In an agile development process, the lack of formalism in requirements restricts FSM methods, like COSMIC, to be applied for of data-groups, which is necessary to be known to carry out COSMIC FSM, cannot be identified by the measurer from a set of requirements statements alone unless he/she is supplied with a complete list of available data-groups that requires formalising the requirements with conceptual model (e.g. a domain model).

Our work presents an alternative solution to estimate the COSMIC functional size in agile that does not require the use of formalism in requirements; instead, it proposes an objective way of approximating the COSMIC functional size of a functional size estimation. 3. Related work
One of the leading work done in the area of automating COSMIC FSM is by Diab et al. [13], where the authors developed a comprehensive system called,  X  cROSE, which accepts state charts as inputs to measure the functional size of real-time systems
COSMIC components, and also require C++code segments to be attached with the state transitions and supplied as input too, so system against one case study only, where, according to the authors, it resulted in some erroneous measurement outputs.
Another related work is that of Condori-Fern X ndez et al. [12], who presented step by step guidelines to first derive manually the UML modeling artifacts, e.g. the use case models and system sequence diagrams from the requirements, and then, apply their set of rules for measuring the COSMIC functional size of the system from the UML models. Their approach was validated on 33 uses an automated tool, called OOmCFP . However, it also depends on conceptual requirements models to be manually prepared, so that COSMIC functional size can be automatically measured.

Most of the related work in this field has attempted to perform a precise measurement of COSMIC functional size that rely on approximation of COSMIC size from textual requirements without extracting COSMIC modeling artifacts. It first classifies past projects into fuzzy size classes (e.g. Small, Medium, Large, Very Large, software belonging to the same size class, and, finally, allows a human measurer to discover similar traits in the new software component, so that the measurer can estimate its COSMIC size by drawing analogy with past projects. We find a good potential of this work to be applied in the environment of agile process that demand quicker size estimation.

The goal of our work described in this article is to develop a fully automated tool that would do quicker estimation of COSMIC size using textual requirements written in unrestricted natural language as input, making it favorable for agile processes. We extend the idea of [17] by finding common traits, or  X  features linguistic features within the textual requirements, and use supervised text mining methods to automate the process. 4. Methodology
Our methodology requires the historical data of an organisation to be stored for the purpose of generating a dataset for training and testing our application. The historical dataset needs to contain sets of textual user requirements written in any quality, where each set corresponds to a unique functional process, along with their respective functional size in COSMIC to be recorded by human measurers. We present our detailed methodology in the following sections. 4.1. CFP measurement
In the cases where a historical database is not available or is not in the form required by our approach, our first step would then be to build the historical database by manually measuring the size of the functional processes in units of CFP (COSMIC
Function Point) and storing these measurements in the database. The available textual description of the user requirements process, the human measurer first identifies how many different types of data-movements are expressed by the statement, and then, how many data-groups participate in each of the types of data-movements present in the statement. Following COSMIC, the sum of number of data-groups for each type of data-movements indicates the total CFP size of one requirements statement. The measurer repeats this step for the rest of the requirements statements within the functional process and summing up their sizes with a hypothetical example of a system consisting of two functional processes.

Our approach requires these measurement data to be saved in the historical database for the past completed projects. For this work, we will need the CFP count for each of the functional processes that have been measured, along with the set of textual requirements associated to each on them. Fig. 3 illustrates the steps of building a historical database, when it is not already available. 4.2. Class annotation of functional processes ranges of these classes.
 would divide the dataset by 50%, and the upper quartile cuts off the highest 25% of the dataset.

These four sets of ranges allow us to annotate the textual requirements belonging to each of the functional processes automatically into four fuzzy size classes. In our class ranges, we keep the minimum and the maximum values as 0 and respectively, instead of the sample minimum or the sample maximum, like in an actual box-plot analysis. Thus, if the new unseen sample is an outlier compared to samples stored in the database, it would still get classified, either as Small or as Complex .
After annotating the textual requirements automatically into the four classes, we then calculate the median, the minimum and of automatic class annotation described in this section.
 4.3. Text mining
Our next step consists of randomly selecting a subset of the annotated textual requirements as our training dataset and textual requirements belonging to a functional process into one of the classes defined earlier (i.e. Small , Medium , Large or
Complex ). The classifier will then simply provide the approximate size of each functional process by outputting the median CFP value of the class it belongs to, along with the minimum and the maximum CFP value seen for that class to indicate possible requirements that are not formalised and can be written in any quality. Fig. 5 shows the steps of this process. 5. Preliminary study As a proof of concept, we performed a preliminary experiment with four different case studies: two industrial projects from
SAP Labs, Canada, and two university projects. They are all completed projects and are from different domains. Their requirements documents vary in size (from about 2000 words to 11,000 words) and contain from 3 to 32 distinct functional processes, along with detailed descriptions of the problem domains. Table 3 shows some characteristics of these case studies.
We manually pre-processed these requirements to extract sets of requirements sentences, each belonging to a distinct functional process.

We used five human measurers, all graduate students in Software Engineering, thoroughly trained for applying the COSMIC standard, to measure the CFP of these 61 functional processes, in the same way to what is shown in Table 1 . The textual requirements of the 61 functional processes, each tagged with its corresponding CFP value, built our historical dataset. The the sample minimum and the sample maximum, and also indicates that the median size is 6 CFP in our historical database. 5.1. The annotated corpus
As mentioned in Section 2 , in order to define the ranges of our four size classes, we performed a box-plot analysis on the CFP values of our historical database. The resulting boundary points are: Median 6 CFP Lower Quartile 5 CFP Upper Quartile 8 CFP Sample Minimum 2 CFP Sample Maximum 19 CFP
Therefore, according to the ranges defined in Table 2 in Section 3.2, the actual CFP ranges for the four size classes for our historical database are: Small : [0, 5 ) Medium :[ 5 , 6 ) Large :[ 6 , 8 ) Complex :[ 8 ,  X  )
We then followed these ranges to automatically annotate the sets of textual requirements belonging to the 61 functional processes into the four size classes  X  where 9 (15%) functional processes were annotated as Small , 15 (25%)were Medium ,21 (34%) were Large , and 16 (26%) were annotated as Complex .

We then collected from our historical database the class data, i.e. the mean, the minimum and the maximum sizes for each of by its class data. The resultant class data are shown in Table 4 .

It should be noted that due to the small number of functional processes that we currently have collected in our historical median size of these classes, would will be more precise and introduce much less error. For example, when a functional process make the task of discriminating between close classes harder than discriminating between widely-varying classes. 5.2. Syntactic features
In this regards, we used the Stanford Parser [23] (equipped with Brill's POS tagger [24] and a morphological stemmer) to morphologically stem the words and extract many linguistic features, e.g. the frequency of words appearing in different their correlation with the CFP values. The ten highest correlated features are listed in Table 5 .

The correlation shows the ten syntactic features that influence COSMIC functional size the most. The intuitive reasons for them are explained below. 5.2.1. Frequency of noun phrases (#1)
No matter how poorly a requirement is described, the involvement of a data-group in a particular data-movement is typically indicated by the presence of a noun phase. Therefore, if a functional process contains more noun phrases, chances are that its data-movements involve more data-groups and its size is larger. 5.2.2. Frequency of parentheses (#2) and number of tokens inside parentheses (#4)
When complex functional processes are described as textual requirements, parentheses are often used to provide brief explanations in a limited scope, or to include references to additional information that are, otherwise, not included in the description. Thus, a higher number of parentheses or number of tokens inside parentheses can sometimes indicate a complex functional process. 5.2.3. Frequency of active verbs (#3) and verb phrases (#7)
Verbs in active form are frequently used to describe actions and, hence, are often used in larger numbers in textual requirements to explain data-movements, as data-movements result from actions carried out by the user or the system or an external system. 5.2.4. Frequency of pronouns (#6)
A longer description in textual requirements for a functional process often indicates its complexity, and requires the use of more pronouns and other referring expressions within the functional process to maintain cohesion. 5.2.5. Number of words (#8), conjunctions (#5), sentences (#9) and uniques (#10)
In general, lengthy descriptions of the requirements (hence, a higher frequency of words, sentences and unique words) often indicate a more complex functional process.

In addition to the above syntactic features, we also looked at possible keywords that can be used in our classification task. 5.3. Keyword features
Studies (e.g. [25,26] ) have shown that using keywords grouped into particular part-of-speech categories can help to obtain good results in various text mining problems, especially for learning the domain-specific terminology. In our case, textual requirements tend to use certain keywords frequently to describe functionality within particular problem domains. We have, therefore, considered lists of keywords as additional features for our work.

Here, each keyword list belongs to a given part-of-speech category to isolate some senses to the keywords. For example, this process would differentiate between the word  X  open  X  as a verb (that designates the action to open) from the word these keywords to be selected. They are: Noun-keywords (coded as: NN_keyword ), Verb-keywords (coded as: VB_keyword ), and Adjective-keywords (coded as: JJ_keyword ).

We generate finite lists of these keywords based on two different probabilistic measures, as described in ref. [25], that take generated by this process from our training set during a single fold of 10-fold-cross-validation are shown in Table 6 .
These three lists constituted three additional features for our classification task. Thus, when we extract the features, we counted one of the keyword feature, for example, as how many times words from its keyword-list appears in the set of requirements of a functional process, and appearing in the same part-of-speech class.
 5.4. Feature extraction and classi fi cation
To classify the sets of textual requirements belonging to different functional processes, we developed a Java-based text
Weka (as J48), setting its parameter for the minimum number of instances allowed in a leaf to 6 to counter possible chances of classifier [30]. The C4.5 decision tree-based classifier performed the best in comparison to the other classifiers with more consistent results during 10-fold-cross-validation. 6. Results and analysis
In this article, we evaluated performance mostly in terms of the degree of agreement, measured by the Kappa statistic [31], between the actual classes and the classes predicted by our classifier for all the test instances. The Kappa index, denoted by refers to the following ratio: put forth by Landis and Koch [33] is shown in Table 7 .

The results attained by our classifier were moderate when using the whole dataset for training and testing. Since the dataset was not very large, we could not use a separate dataset for testing, and we could only use cross-validation, which can be very shows a summary of the results.

The resultant decision tree after training on the complete dataset is shown in Fig. 7 . As the figure shows, the tree came out well-formed and of desirable characteristics  X  not sparse, and also not flat. Also, none of its branches are wrongly directed.
Although the kappa results of Table 8 shows stable and moderate results in terms of performance with the 10-fold-cross-the Medium sized functional processes are mostly because it confused them as Large (shown in darker shade, in Table 8 ,it understood by the fact discussed in Section 1 , where, in Table 4 , we see that our box-plot analysis automatically chose zero them in making fine-grained distinction and render better results.
 random folds, which can significantly reduce the number of training instances for a particular class during a single fold in a skewed corpus. In our case, for example, during one fold, the number of training instances for the Small class went minimum of only 2 instances, which were inadequate for the learning algorithm to discover the thresholds of most of the discriminating linguistic features that we selected for this work.

The phenomena discussed above are also reflected in the precision and recall results shown in Table 10 . Moreover, Table 10 our previous work [25], we showed the applicability of using similar a approach for requirements classification, where we had a classifier attained a much higher level of accuracy (0.98 for precision, and 1.0 for recall, during 10-fold-cross-validation).
Thus, although we believe that the results presented in this article would improve with the introduction of more instances in instances per class in our current dataset would have been higher to perform a more realistic classification task.
To show what would happen if we had increased the number of training instances per class, we developed a two-class size processes into Small , Medium and Large classes). Thus, the number of instances per class in our dataset increased, compared to how we originally had it for our four-class classifier. We used the same dataset, the same methodology and the same sets of of 0.802 and 0.746 for the 2-class and the 3-class classifiers respectively during 10-fold-cross-validation. The summary of the results of performing 10-fold-cross-validation using both the classifiers is shown in Table 11 .

The results in Table 11 shows that a similar classification technique when applied on the same dataset, which now contains class. 7. Conclusions and Future Work
In this article, we have shown that classification of textual requirements in terms of their functional size is plausible using by manually measuring the COSMIC functional size from textual requirements, we could not train and test our system with a large number of samples (only 61 in total). Yet, the results that we were able to gather by cross-validating on such small number of samples show a promising behavior of the classifier in terms of its performance. Using our methodology, we have also been able to identify automatically a set of highly discriminating features that can effectively help together with a classifier in approximating the size of functional processes.

It should be mentioned that we have not yet tested this approach as to be used with requirements written in variable level of quality. Therefore, we believe that this approach would be organisation-specific, where textual requirements saved in the
We are currently in the process of building larger datasets for training and testing our system. Our future work includes implementing a full-fledged prototype to demonstrate its use and a complete integration to the READ-COSMIC project [34], which is our umbrella project on software development effort estimation from textual requirements. We are also working on predicting the impact of non-functional requirements on the functional size for better precision in software effort estimation. Acknowledgements
The authors would like to thank SAP Labs, Canada for providing the requirements documents used in the experiments presented in this article, and the anonymous reviewers for their valuable comments on its earlier version.
References
