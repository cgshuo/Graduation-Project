 In many domains, such as social networks and chem-informatics, data can be represented naturally in graph model, with nodes being data entries and edges the relationships between them. We study the application requirements in these domains and find that dis-covering Constrained Acyclic Paths (CAP) is highly in demand. In this paper, we define the CAP search problem and introduce a set of quantitative metrics for describing keyword-based constraints. We propose a series of algorithms to efficiently evaluate CAP queries on large-scale graph data. Extensive experiments illustrate that our algorithms are both efficient and scalable.
 H.3.3 [ Information Systems ]: Information Storage and Retrieval X  Information Search and Retrieval (Search process) Algorithms Keyword-based Association Discovery, Search Algorithm, Cover-age, Relevance
RDF (Resource Description Framework) [13] is a W3C recom-mended language for describing linked data of the Semantic Web in the form of triples. RDF data can be represented by node and edge labeled graphs. The simplicity and flexibility of the graph-based data representation model facilita te the wide adop tion of Semantic Web technologies in domains such as social network and chemin-formatics. Applications in these domains pose challenges and op-portunities for managing and searching data on the Semantic Web, as witnessed by new technologies proposed in semantic association discovery [4] and keyword search [11, 15].

The semantic association discovery problem aims to answer ques-tions such as "what are possible relationships between X and Y" and the results are usually paths connecting the two nodes corre-sponding to the two en tities in the grap h [4]. The keyword search problem aims to answer questions such as "how do the data entities that match keywords X, Y and Z relate to each other" and the re-sults are usually trees/sub-graphs with the labels of their nodes and edges covering all of the keywords [8, 11, 15].

Discovering acyclic paths betw een data entitie s under constraints, such as appearance of nodes, edges and patterns, and the length of paths, is at the core of many applications, such as drug discovery [7, 14] in cheminformatics and research/social networks [18]. How to express such search queries precisely and how to answer such search queries efficiently are critical problems, but are yet fully studied in the literature.

E XAMPLE 1. Figure 1 shows the graph representation of a sam-ple RDF data representing the relationships among people in the social networks. Let X  X  consider the following search requests: case1. Find how Azriel connects to Ben through Chris or Dan ; case2. Find how Azriel connects to Ben through at least two people from Chris , Dan and Ida within four steps. case3. Find Azriel  X  X  close (within 4 steps) professional connections (e.g. relationships such as workfor , coworker , coauthor )to Ben ; case4. Find Azriel  X  X  close semi-professional connections to Ben (i.e. half of the relationships in any tie should be professional);
Query languages, such as SPARQL [16], have been proposed to query data on the Semantic Web. Later, the notions of seman-tic association [4], label-constraint reachability [17], and semantic keyword search [11, 15] were proposed. Extending SPARQL with regular expressions [3] enhances it with the capability to express complex patterns satisfying strictly defined constraints, e.g. cases 1 &amp; 3. However, search requests as those in cases 2 &amp; 4 cannot be expressed by any existing language or language extension.
Significant amount of research has been done in RDF data stor-age, indexing and query evaluation for answering SPARQL queries efficiently [2, 10]; however, the focus was on accelerating graph pattern matching, rather than finding arbitrary paths between data entries. Many graph searching algorithms were proposed for an-swering keyword searches in grap h data [11, 15]; but they are search-ing for trees whose node/edge labels cover all keywords and cannot be applied to answering CAP queries efficiently. Traversal-based approaches such as DFS, BFS, and bidirectional search [12] were proposed for finding paths satisfying given regular expressions be-tween two end nodes [3]. These algorithms, trailed by a filtering process, can be used to answer CAP queries in Exp. 1, but inef-ficiently, due to their poor scal ability with respect to the size and complexity of the graph data.
We study and tackle the problem of precisely specifying and ef-ficiently answering CAP queries. Particularly,  X  we introduce the notions of coverage and relevance for precisely describing the correlation between a resultant path and a keyword set in a CAP query (Sec. 2);  X  we propose a set of efficient CAP query answering algorithms, including a family of DFS-based algorithms, which takes advan-tage of the keyword-based constraints to eliminate unpromising search branches (Sec. 3.1), and a novel Search-and-Join algorithm in which a CAP search is broken into a sequence of mini-searches and their results are joined to answer the CAP query and its effi-ciency is guaranteed by carefully designing bookkeeping and prun-ing (Sec. 3.2);  X  we conduct extensive empirical study to understand the strengths and limits of our algorithms (Sec. 4); and  X  we explore the application of CAP search queries, in stand-alone domain-specific applications, and in a new SPARQL extension, cSPARQL (Sec. 5). In this section, we formally define the Constrained Acyclic Path Discovery problem whose applications have been illustrated in Sec. 1. Let L be an infinite set of literals and U be an infinite set of URIs disjoint with L . We represent RDF data as a node and edge labeled directed graph G =( V,E, X  ) where V is a set of nodes, E  X  V  X  V is a set of edges, and  X  is a labeling function that maps items in V  X  E into a finite set of labels and literals.
We represent a path between two nodes of graph G as a sequence of interleaving nodes and edges. Frequently, we are interested in partial paths, which we call fragments . In particular, we are in-terested in two types of fragments: e -fragment (denoted f starts and ends with an edge, and en -fragment (denoted f starts with an edge and ends with a node.

Given source and destination nodes, n s ,n d  X  V of G , in search queries looking for paths from n s to n d , frequently only acyclic paths are of interest to users. In the rest of the paper, we will focus only on acyclic paths, and as the two end nodes are known, we fo-cus on the e -fragments and use F e ( n s ,n d ) to represent all acyclic e -fragments from n s to n d in G .

To facilitate the discussion of constraints on paths, we use nodes ( edges ( f ) ) to represent the set of nodes (edges) in fragment f ,and | f | the length of f ,definedas | edges ( f ) | . We overload the map-ping function  X  to map a set of nodes (edges) to their corresponding labels.
As shown in Exp. 1, when users search for paths between a pair of nodes, it is frequently the case that the constraints are expressed in the form of a keyword set (denoted S ), where a keyword is a label in U . Keyword-based constraints as discussed in [5, 17] are quite limited in terms of what can be in the keyword set and how the results are regulated by it. We generalize the keyword set to include keywords that can be mapped to labels of both nodes and edges and extend how the results are confined by the keyword set.
Definition 1. Given a finite keyword set S X  X  and an e -fragment f  X  X  e ( n s ,n d ) , 1. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) ,wesay f 2. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) ,wesay f 3. if S X  (  X  ( nodes ( f e ))  X   X  ( edges ( f e ))) =  X  ,wesay f
Using this definition, we can express the search request in Exp. 1 case1 as "find e -fragments from Azriel to Ben that satisfy the inter-section constraint w.r.t. keyword set { Chris,Dan } ".
Among a possible large number of resultant e -fragments of a search request, shorter ones tend to express stronger and more mean-ingful relationship between the two end nodes than the longer ones do [4, 11]. The length constraint which restricts the length of the resultant e -fragments has been studied in [3, 5], and can be used to express the search request in Exp. 1 case 2 &amp; 3. However cases 2 &amp; 4 require a more subtle description of the relationship between an e -fragment and a keyword set than the all-or-nothing set-based constraints described in Def. 1. For this purpose, we introduce quantitative metrics coverage and relevance .

Intuitively, coverage describes the fraction of the keyword set that appears in the label set of an e -fragment, while relevance de-scribes the fraction of the labels of an e -fragment that are in the keyword set. In an RDF graph, each node has its unique label, while more than one edge may have the same label. Therefore, we refine coverage and relevance further into node-coverage and node-relevance for keyword sets to be applied only on nodes, edge-coverage and edge-relevance for edges, and use coverage and rele-vance for the constraints in which keywords can be mapped to both nodes and edges.

Definition 2. Given a graph G , two nodes n s ,n d  X  V and a finite keyword set S X  X  ,foran e -fragment f e  X  X  e ( n s ,n cntE ( l, f e ) is the total number of edges in f e with label l .
The coverage and relevance for only nodes or edges can be easily inferred.

Now, taking advantage of the quantitative metrices defined above, we are able to express all constrains in Exp. 1. For example, case 4: { f e | f e  X  X  e ( Azriel, Ben )  X  EdgeRelevance ( f e coworker,coauthor})  X  0 . 5 } .

All the constraints we defined in Def. 1 can be expressed using the quantitative metrics defined in Def. 2.
 Similarly, we can define the node/edge version of these functions. We define the Constrained Acyclic Path (CAP) search query: In this paper, we tackle the problem of efficiently evaluating CAP searches, and discuss the a pplications of CAP searches.
We will first focus on the evaluation of a critical subset of CAP queries, core CAP queries, in which  X  contains conjunctive pred-icates featuring only one keyword set. We use S to represent the single keyword set in  X  , and use  X  l ,  X  c ,  X  r ,  X  nc ,  X  to represent the length, coverage, relevance, node/edge coverage, node/edge relevance constraints respectively, each of which is de-fined as an interval, for example,  X  l =[  X  l min , X  l max
Certainly one solution, which we call Search-and-F ilter appr oach (S&amp;F), is to first find all acyclic e -fragments in F eliminate those not satisfying  X  . However this approach is not prac-tically efficient because generating F e ( n s ,n d ) is very time and space consuming and the search cost is mostly wasted since the CAP query results are usually a very small subset of CAP (
Depth First Search (DFS) is a commonly adopted approach for generating paths between two nodes. In DFS, to generate an e -fragment, en -fragments are generated one step at a time. To mini-mize the DFS search space in answering core CAP query, we want to stop the expansion of an intermediate result f en if we are certain that the expansion will not lead to any final results. The basic idea is to calculate projected value ranges of the quantitative metrics X  values by considering the best and worst cases of f e  X  X  e which has f en as prefix. If the projected value ranges of the quan-titative metrics do not overlap with those in  X  , we can safely stop the expansion of f en .
 L EMMA 1. Given an en -fragment f en generated in the DFS of CAP ( n s ,n d ,  X  ) and a keyword set S , for any e -fragment f F ( n s ,n d ) having f en as prefix,
We then propose two DFS-based algorithms: constraintDFS (cDFS) and enhanced-cDFS (ecDFS). constraintDFS (cDFS) is based on the non-recursive DFS. In cDFS, we start a DFS from the source node n s . At each step of the DFS process, we (1) identify a resultant e -fragment when the destina-tion node n d is reached; (2) detect loops in a fragment generated and eliminate the fragment in question; and (3) calculate projected value ranges of the quantitative metrics by applying the formulae of Lemma 1 and eliminate a fragment if its projected value ranges do not overlap with those specified in  X  .
 Enhanced-cDFS (ecDFS) overcomes the extra overhead brought by the cDFS algorithm, in which the projected value ranges of the quantitative metrics are computed and compared with  X  for every en -fragment generated. In ecDFS, at the time when the project value ranges are estimated for an en -fragment, we also estimate, under the worst-case scenario, for how many more steps the gen-erated en -fragments can remain promising. This allows us to skip the calculation and comparison for the en -fragments generated in these search steps, hence further improve the performance.
Targeting an important class of CAP queries, in which the keyword-based constraints are specified on nodes, we propose the Search&amp;Join (S&amp;J) algorithm. It leverages the local information around the nodes containing the keywords to calculate more accurate projected value ranges, and thus conducts more efficient pruning.

We first introduce a few notions th at are critical for this algo-rithm. We use S k to denote a set of nodes containing keywords in S .Wedefine query nodes as S k  X  X  n s ,n d } .A query node sequence (QNS) is a sequence of query nodes which always starts with n ends with n d , and consists of a subset of S k . We are interested in a special type of e -fragment, exclusive e -fragment ( xe -fragments), which links two query nodes but does not go through any query node. The constrained sequence join operation takes as input  X  from a CAP query, a set of QNSs based on the keywords in  X  ,and sets of exclusive e -fragments between every pairs of query nodes, and computes the e -fragments that satisfy the CAP query by con-catenating the xe -fragments with the guidance from the QNSs and validating the constraints  X  .

The Search &amp; Join (S&amp;J) algorithm has two phases: the search phase takes as input the data graph G and the query CAP ( computes the QNSs, and issues mini-searches on pairs of query nodes to find the set of xe -fragments for each pair of query nodes; the join phase then produces the query results by conducting con-strained sequence join on the QNSs and xe -fragment sets generated in the search phase.

Clearly, not all QNSs lead to valid e -fragments that satisfy  X  .In addition, given a QNS qns that yields non-empty results, not all the xe -fragments between all pairs of adjacent query nodes in qns contribute to the final results. Following the "selection-push-down" scheme widely used in database system design, it is critical to min-imize the cardinality of the participants of constrained sequence join. We accomplish so by (1) identify and eliminate invalid QNSs, e.g. QNSs whose con-strained sequence join result is empty; and (2) for each QNS that may generate non-empty constrained se-quence join results, identify and eliminate the xe -fragments that have no chance contributing to the results.

Given a QNS qns , qns is guaranteed to be invalid if there is no xe -fragment between a pair of adjacent nodes in qns ,orthesum of the minimum lengths of the xe -fragments of adjacent node pairs in qns exceeds  X  l max , or the combined projected value ranges of the node coverage or relevance are guaranteed to fall outside of the ranges specified in  X  . When a QNS is deemed invalid, it can be pruned immediately.

Beside generating minimal QNSs and xe -fragment sets, we also aim at exploiting minimum number o f data nodes/edges in the search phrase in order to limit the search space, hence improving the per-formance. We accomplish this by carefully design the search steps and bookkeeping mechanism: (1) For all node pairs that share the same starting node, one single BFS search is issued for generating the xe -fragments for all these node pairs. (2) After each BFS expansion, the QNSs are evaluated to have the invalid ones pruned, and the newly generated intermediate e -fragments are leveraged to tighten constraints for all mini-searches. (3) Each time, one BFS is picked to expand its intermediate e -fragments. The criteria is that we always pick the BFS search such that the expansion has the potential to prune the maximum number of invalid QNSs and restricts the search ranges of the BFSs of itself and other query nodes most sharply.
We conducted extensive experiments to study the performance of our algorithms, constraintDFS ( cDFS ), enhanced-constraintDFS ( ecDFS ), and Search-and-Join( S&amp;J ), as well as existing Search-and-Filter algorithms based on Depth First Search ( S&amp;F-DFS )and Bi-directional Search ( S&amp;F-BIS [12]). The experiments were car-ried out on a desktop PC running Red Hat 4.1.2 with dual Intel(R) Core(TM)2 2.40GHz CPU and 4GB memory.

Our experiments were conducted on two RDF datasets: DBpedia (1504K nodes, 5.4M edges) [1] and Chem2Bio2RDF (139K nodes, 1.8M edges) [7]; both have been widely used in the literature. We tested the algorithms on many randomly generated CAP queries, varying source and destination nodes, keyword sets and constraints. Same trends were observed. Due to space limitation, we will re-port our experimental results only on the Chem2Bio2RDF dataset, as the paths in this dataset are much longer, putting significantly more stress on our algorithms and highlighting the impact of var-ious parameters to the algorithms, and with only queries in which the parameters on node coverage and node relevance vary. Please note that queries in each category shares the same  X  l max
We compared the hot run of the algorithms and measured the elapsed time in ns . Please note that as our algorithms improve the performance over the S&amp;F algorithms by several orders of magni-tude, to better illustrate the difference, we plot the results in loga-rithmic scale.

As shown in Fig. 2(a) and 2(b), keyword-based constraints have no impact to the S&amp;F algorithms. Our algorithms, which take advantage of such constraints, significantly outperform them, es-pecially when the constraint is strict, e.g.  X  nc min (or  X  close to 1, as more intermediate results are pruned. Even when the constraint is loose, the performance of the S&amp;J algorithm is sig-nificantly better than others, as it has much smaller search scope, thanks to the local information it takes into account. It is also worth pointing out that our DFS-based algorithms and S&amp;J algorithm re-act differently when  X  nc min changes: when the node constraint be-comes tighter, e.g. closer to 1, cDFS and ecDFS are very efficient, due to their strong pruning power and small overhead; but when able to take advantage of local information around the query nodes to limit the search space and thus is much more efficient (by two orders of magnitude) than cDFS and ecDFS.
CAP search can be used as a stand-alone search tool in domain-specific applications, such as drug discovery, as well as integrated into a high level query language to enhance its expressiveness.
In cheminformatics, a drug could affect a disease by affecting proteins and genes in a treatment process. By examining the paths from a drug to a disease, domain experts can assess the effective-ness of the drug before conducting chemical experiments [7]. Ex-isting path discovery tools on Chem2Bio2RDF [7] can only find all paths between drug and disease, leaving the domain experts do-ing the filtering manually or relying on other tools to do so, ren-dering them impractical in dealing with the large data set and the subtle constraints demanded by the domain experts. Based on the research presented in this paper, we developed a tool that features CAP search queries [20], which enables the domain experts to com-pose CAP search queries, execute it, get results instantly, and adjust the constraints to alter the results as the research leads them.
If a drug is considered to be effective in treating certain disease, its side-effect should also be considered [14]. As such data entries do not appear directly on the paths between drug and disease, more complex pattern matching is required in addition to path finding to integrate constraints about side-effects into the CAP search queries for drug discovery. We propose cSPARQL to integrate the CAP search into the structured search of SPARQL [16] by introducing (1) path variables for expressing arbitrary e -fragments in a graph pattern; and (2) a set of quantitative metrics functions as defined in Sec. 2 for specifying the length and keyword-based constraints. More details about cSPARQL can be found in [19].
In this paper we identify the problem of discovering acyclic paths between two given nodes in a directed graph under keyword-based constraints (CAP). We introduce the notions of coverage and rel-evance for specifying subtle relationship between paths and the keyword set. We propose algorithms, including cDFS, ecDFS and S&amp;J, to efficiently evaluate CAP queries. Our empirical evaluation proved that our algorithms outperform existing Search-and-Filter algorithms using both DFS and bidirectional search and improve the performance by several orders of magnitude. We further dis-cuss the applications of CAP queries and propose cSPARQL, an extension of SPARQL, to integrate CAP queries and the structured search on graph data.
