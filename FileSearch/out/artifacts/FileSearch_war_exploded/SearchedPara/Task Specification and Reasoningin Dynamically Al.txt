 George Chatzikonstantinou, Michael Athanasopoulos, and Kostas Kontogiannis Complex software systems are prone to continuous change and re-configuration. Software maintenance, hardware upgrades, and dynamic provision of resources in elastic or autonomic systems, are just a few of the factors that drive the need for designing systems that assist administrators to compile action plans. In this context, the focus is to devise a ) models that represent system goals; b )models that associate such goals with tasks and actions ; and c ) reasoning methodologies that allow for the selection of tasks and actions in order to form coherent plans. The software engineering community has responded with models to represent system-wide functional and non-functional properties as well as, formalisms to associate such functional properties with design decisions, tasks, actions, and stakeholder views. These models include i* [1], KAOS [2,3], the Goal-oriented Requirements Language (GRL) [4], the Extended Enterprise Modeling Language (EEML), and the Unified Modeling Language, to name a few. Similarly, reason-ing on these models has emerged as a key problem in order for useful logical and sound conclusions to be reached. Such reasoning approaches are based on logic deductions (rules), propagation of labels, domain specific heuristics or, SAT solvers. SAT solvers in particular have been a focal point of the research con-ducted in this area. However, there are st ill open issues to be investigated when the goal models themselves are modified as a result of changes in the operating environment or, as a result of the actions incurred so far.

In this paper, we investigate the use of local search algorithms and boolean expression evaluators to reason with Deci sion Task Models introduced in Section 3, when labels related to cost and benefit values, for actions and tasks, are altered as a result of context changes. Experimental results indicate that the approach allows for obtaining a solution that is within 90% range of the optimal value at a fraction of time that is required by a Weighted Partial MAX-SAT algorithm to compute the optimal solution for the problem at hand. Applications of such reasoning include the formation of plans to re-configure autonomic systems, plan for software and hardware upgrades in a large scale where the administrators must conform to specific guidelines (e.g . ITIL), or devise alternative plans to meet specific goals and requirements. We illustrate the approach by a running example depicted in Fig. 2, that focuses on a goal model that denotes how high quality of service can be maintaine dinanelasticcloudbasedsystem.The approach has been evaluated on a large number of sizeable goal models that have been compiled by an automated construc tion process with positive results.
The paper is organized as follows: Section 2 provides an outline of the proposed approach. Section 3 introduces the elements of Decision Task Models (DTMs) and discusses their semantics. In Section 4 a formalization for DTMs is pro-vided along with a process for the transformations of DTMs to CNF formulas. Subsequently, in Section 5 two reasoning approaches are discussed based on op-erating environment for the task model and in Section 6 experiment results are discussed to provide an evaluation for the proposed framework and algorithms. Finally, related work is discussed in Section 7 and Section 8 concludes the paper. The outline of the proposed framework process is depicted in Fig. 1. Initially, certain tasks and actions, along with the relationships that exist between them are modeled in a Decision Task Model (DTM) like the one presented in Fig. 2, which describes what tasks and actions can be performed in order to maintain the QoS to a required level. Given such a m odel, we are interested in determining the optimal (or at least, suboptimal) plan to accomplish the root task while the weights assigned to each node change dyna mically as a consequence of contextual changes. For example, for the model of Fig. 2, the weights of A5 and T11 change from C 1and B 1to C 2and B 2 respectively, leading to different optimal solutions as this is summarized in Tables 3 and 4. An impossible low negative weight value (i.e. high cost) deems an action unachievable, while a high positive weight value (i.e. high benefit) deems a task achievable.

The first step towards plan determination is to extract a CNF formula that fully captures the logical dependencies modeled by the DTM. This enables the reduction of plan determination to the SAT problem, and as a consequence allow the use of a SAT solver. Moreover, as nodes in DTMs are annotated with weights which may change as a consequence of certa in context changes, we are interested in finding an assignment that not only satisfies the CNF formula but also has the best score, in terms of node weights. This optimization problem, referred to as optimal plan determination , can be reduced to an instance of Weighted Partial Max-SAT problem, hence a Max-SAT solver can be utilized to solve it. The steps required for the determination of the optimal plan are depicted as dashed rectangles in Fig. 1.

However, as the context (and thus node weights) may change dynamically, computing an approximate solution may be a preferable alternative to optimal plan determination, as Max-SAT is a known NP-hard problem. In this paper, we propose the use of a local search algorit hm as an effective technique for efficient plan determination. The steps required for the determination of an effective plan are depicted as bold rectangles in Fig. 1. In order to model the actions that realize certain tasks, and to express se-mantic and temporal relationships th at exist between tasks and actions, we propose a metamodel which borrows notions from the goal model theory. The proposed DTM metamodel, an instance of which is illustrated in Fig. 2, retains the AND/OR-decomposition schema used in goal models. However, additional modeling elements are used to capture logical and temporal relationships, in-creasing thus the expressiveness of the proposed notation. In the rest of this section we briefly describe the semantics of the various modeling artifacts. Nodes: DTM nodes may be either Tasks or Actions .Theformermaybe AND/OR decomposed and represent a collection of actions or subordinate tasks, where either more than one subtasks or actions should be combined together, or one or more subtasks or actions may be alternatively selected to accomplish the task. In contrast, action nodes represent atomic activities. In the example DTM of Fig. 2, tasks are depicted as ellipses and Actions as hexagons.
 Links: The DTM metamodel contains three types of links between nodes namely, Logical Preconditions ( lp  X   X  ), Temporal Preconditions ( tp  X   X  ), and Contributions . The former two links interconnect task and action nodes and express temporal dependencies. More specifically, lp  X   X  links resemble precedence links originally introduced in [5], and indicate the fact that the target node can only be per-formed as long as the source node has already been performed. In contrast, tp  X   X  links denote a weaker notion of precondition, which implies that in case both the target and the source node participate in a plan (i.e. a sequence of actions), then the target task/action must performed after the source task/action.
Finally, in a similar manner as in [6], we consider four types of contributions namely, ++ S /  X  X  X  S meaning that the target node is satisfied/denied when the source node is satisfied, and; ++ D /  X  X  X  D meaning that the denial of the source node leads to the denial/achievement of the target node. However, in the context of this paper, contribution links can terminate only to task nodes as an action is only satisfied when the corresponding atomic activity is performed and it cannot be fulfilled otherwise. In this section we are going to introduce a process that transforms DTMs into CNF formulas that fully capture the constraints modeled by the DTM. This reduces the problem of plan determination to an instance of the SAT problem, and allows for the use of SAT solvers. However, before going into the details of CNF formula generation, we are going to formally define DTMs. 4.1 DTM Formal Definition A DTM contains a set of task or action nodes which are connected with each other through decomposition rules or rules that describe binary relations on the set of nodes i.e. binary rules such as Precondition ,and Contribution links. Hence, we formulate the following definition for DTMs: Definition 1. A Decision Task Model is a tuple of the form N,R d ,R ,where N = N t  X  N a with N t and N a denoting the sets of task and action nodes respec-tively, R d is the set of decomposition rules, and R the set of binary rules.
In the above definition, a decomposition rule r d  X  R d describes the way a parent task node p is AND/OR decomposed to a set { c 1 ,c 2 ,  X  X  X  c n } of child task or action nodes. There must be one decomposition rule for each task node p , which is formally written as: For example, task node T 7 ( X  X chieve throughput below threshold X ) in Fig. 2 is AND-decomposed to action nodes A 10 ( X  X ssign VM X ) and A 11 ( X  X igrate Jobs X ), so the corresponding decomposition rule is AND ,T 7 , { A 10 ,A 11 } .
A binary rule r  X  R between source node s and target node t is denoted as: where as discussed above, for contribution rules the target node t  X  N t .Inthe example DTM in Fig. 2, task node T 7 participates as the target node of three binary rules, namely ++ S, T 9 ,T 7 ,  X  X  X  S, A 17 ,T 7 and lp ,T 10 ,T 7 .
Finally, given a DTM N,R d ,R and a node b  X  N , we can define for each type T of binary rule the following set of nodes:
N [ T ] ( b )= { s  X  N | X  r = T,s,b  X  R } where T  X  X  lp , ++ S/D,  X  X  X  S/D } , which includes the source nodes of all rules of type T for which node b is the target node. Given the DTM of Fig. 2, the following sets can be defined for node T 7: N ++ S ( T 7) = { T 9 } , N  X  X  X  S ( T 7) = { A 17 } ,and N lp ( T 7) = { T 10 } . 4.2 Boolean Rules and CNF Formula Extraction Given a DTM, a corresponding set of Boolean rules that capture all the con-straints in the model can be generated. T hesemanticsofthoserulesaswellas their mappings to CNF clauses are originally presented in [7], and for the sake of presentation completeness summari zed in Table 2. The required CNF for-mula can then be easily extracted by taking the conjunction of the CNF clauses corresponding to each individual Boolean rule.

The generation of Boolean rules starts by extracting set N lp ( p ), and also the following two sets for each task node p  X  N t of the DTM : which, along with the decomposition rule r d = T,p, { c 1 ,c 2 ,  X  X  X  ,c n } for node p , determine the set of Boolean rules that must be generated for this node. According to whether some or all of those sets are empty, a different set of rules is generated as this is illustrated in Table 1. Additionally, the following apply for the pseudo-variables p c pos (contributions that positively affect the target node p ), p c neg (contributions that negatively affect the target node p ), and p d (decomposition rule for node p )thatappearinTable1: p c pos  X  OR( e 1 ,  X  X  X  ,e k ,  X  f 1 ,  X  X  X  ,  X  f l ) p c neg  X  OR( g 1 ,  X  X  X  ,g m ,  X  h 1 ,  X  X  X  ,  X  h o ) where T is the type of the decomposition rule and nodes e i , f i , g i and h i corre-spond to the ones in equations (1) and (2). It is important to note that p c pos ( p c neg ) is substituted by e 1 or  X  f 1 ( g 1 or  X  h 1 )incase k =0or l =0( m =0or o = 0) respectively, while if both of k and l ( m and o ) are equal to zero, set N pos ( N neg ) is empty, and the pseudo-variable p c pos ( p c neg ) does not appear in the rules. For example, given task node T 7ofFig.2forwhich N lp ( T 7) = { T 10 } , N pos ( T 7) = N ++ S ( T 7) = { T 9 } ,and N neg ( T 7) = N  X  X  X  S ( T 7) = { A 17 } ,thefol-lowing Boolean rules are generated based on the last case of Table 1: which can be directly mapped to CNF clauses as this is illustrated in Table 2. For example the following CNF formula corresponds to rule (5): Finally, Boolean rules are also generated for action nodes when they are the target of lp  X   X  links. This case is also presented in Table 1 (second row). The extracted CNF formula for the DTM provides a formal model of logical rela-tionships between the DTM nodes. Such a model can be used to apply reasoning techniques in order to identify possible DTM model resolutions as combinations of actions, that if performed in coordination, can realize the root task of the DTM model. In this respect, finding such a task resolution equals to solving the SAT problem for the extracted CNF which would assign truth values to both tasks and actions, and then executing all actions assigned as true . However, as discussed above, DTM nodes may be annotated with weights indicating either benefit (for task nodes) or cost (for action nodes). So we are not only interested in finding an assignment that satisfies the CNF formula, but also an assignment that has the best score taking into account the cost/benefit of each true node.
Given the nature of the problem, differ ent strategies can be utilized based on whether the model resides in static or dynamic environments. The former are characterized by absent or extremely rare changes of assigned benefits and costs to DTM nodes, while the latter by frequent context changes that lead to changes for the weights associated to all or to a subset of the model X  X  nodes. 5.1 Reasoning in Static Environment Optimal plan determination is an optimization problem that can be reduced to an instance of Max-SAT problem called Weighted Partial Max-SAT (WP-MAXSAT). In WP-MAXSAT we have two sets of clauses namely, hard and soft clauses. The former are the clauses that a solution assignment must satisfy, while the latter are clauses that have weights and the solution must satisfy only those that ensure the maximum total weight. In our case, the generated CNF corresponds to the hard constraints of the WP-MAXSAT, while the weight-node pairs are used to build the soft constraints of the problem. For example, given the weights illustrated in Table 3 two single literal soft clauses namely, ( T 2) and ( A 8) with weights 97 and -412 respectively are generated for nodes T 2and A 8. 5.2 Reasoning in Dynamic Environment An exhaustive WP-MAXSAT algorithm can be applied to get an optimal plan determination; however, having to apply such an algorithm for each context change can limit significantly the applicability of the approach, especially when working with task models of significant size and complexity in dynamically alter-ing environments. In such cases, computing an approximate to optimal solution may be a preferable alternative instead of attempting to compute the optimal solution, for two primary reasons. First, the average time between any two con-text changes may be less than the average time required to compute the optimal solution, making the application of typical WP-MAXSAT algorithms impracti-cal. Secondly, even when the time betw een any two context changes is adequate for WP-MAXSAT, the extra time required to compute the optimal solution may ultimately impose higher aggregate cos ts than utilizing a good-enough, approx-imate solution to perform the task right after the context change occurs. Before examining a search process to approximate optimal solutions for task models, we introduce certain concepts required for the definition and application of a local search algorithm that can efficiently explore the solutions space. Boolean Rules Evaluation. Boolean rules, which have been introduced in the previous section, consist of a set of input variables (i.e. variables denoted as i 1 to i in Table 2) and a single output parameter (i.e. variable o in Table 2). Given a Boolean rule B r , we are going to use the notations In [ B r ]and Out [ B r ]tosignify the input variables and the output parameter of rule B r respectively. Definition 2. We say that a Boolean rule B r a directly requires rule B r b ,de-noted as B r a req  X   X   X  B r b iff Out [ B r b ]  X  In [ B r a ] .
 For example, for the rules presented in the previous section, rule (4) directly requires rule (6) as variable T 7 d appears in the input variables of the former and is also the output parameter of the latter rule.
 Definition 3. We say that a Boolean rule B r a requires rule B r b , denoted as B B Rule (3) req previously mentioned.

Furthermore, the req sequences of Boolean rules in which every rule depends only on rules that appear earlier in the sequence. More precisely: Definition 4. We say that a sequence of Boolean rules B r 1 , B r 2 ,  X  X  X  , B r n is a proper one if for every pair B r i , B r j of Boolean rules in the sequence, B r i appears earlier than B r j in case B r j req Hence, sequence (6)(5)(4)(3) is a proper sequence of Boolean rules, while se-quence (3)(6)(5)(4) is not, as (3) req mer in the sequence. If circular dependencies exist in a set of Boolean rules, no proper sequence of those rules exists. H owever, as the DTMs used have no cycles because of the validation phase illustrated in Fig. 1, we ensure that no circular dependencies exist in the Boolean rules sets generated from DTMs, and so there is always a proper sequence for them. Proper sequences of Boolean rules can be computed at definition-time through typical topological sorting algorithms.
Additionally, given a set B = { B r 1 ,B r 2 ,  X  X  X  ,B r n } of Boolean rules we define the following two sets of variables: where the former contains the variables that appear only as input while the latter those that appear as output parameters in the Boolean rules of set B . We call variables in L [ B ]and I [ B ] leaves and inner respectively and we assign weights to them as follows: those that correspond to nodes of the initial model have the same weight as the node, while those that correspond to pseudonodes (i.e. nodes added during CNF generation) have a zero weight. Finally, using a proper sequence of Boolean rules and an assignment on L [ B ]elementswecan propagate the truth assignment to I [ B ] elements, and by adding the weights of all true variables we can calculate th e total weight of the given sequence. Local Search on DTM Leaves. Motivated by the above scenarios, we propose a parameterized local search algorit hm that can be applied as soon as context changes occur and provide solutions wh ose quality genera lly converge to the optimal after a number of iterations. The iterations of the search algorithm can be configured through input parameters so that the search process can be tunned to run within acceptable execution times. The defined search algorithm operates on L [ B ] and attempts to rapidly reach solutions of improving quality. It should be noted that while a WP-MAXSAT algorithm has to be applied to the whole weighted model (that is, variables corresponding to both inner and leaf nodes) to compute the optimal solution, the proposed search algorithm constructs truth assignments for leaves only by mutating previous ones. In this way, the search space is considerably smaller, particularly for task models of significant depth and complexity (i.e. high inner to leaf nod es ratio). The search process begins by examining a fixed size pool of cached solutions that fulfill the model X  X  hard constraints, and selects the best-perform ing one. For the process to start even one cached solution suffices, and this soluti on can be obtained with low computation cost by utilizing a simple SAT solver applied once and offline. The solutions pool is enriched with new solutions as th ese are discovered at execution-time. By keeping the solution pool with a fixed size we allow for better computation Algorithm 1. Leaves Local Search complexity for seed selection when a cont ext change occurs. Once such a solution is selected, the local search algorithm is applied on L [ B ] in order to gradually reach better solutions.

The proposed Leaves Local Search (LLS) algorithm begins with setting as current solution the one provided and p roceeds by computing an initial leaves truth assignment based on the provided solution (lines 1-2). Then, the algorithm applies a set of assignment mutating steps for a fixed number of times which is equal to a specified flips factor parameter ( FF ) times the number of leaves. During the mutating steps, the assignment X  X  values are flipped in random pairs, for up to a different number of pairs in each iteration which is equal to a specified neighborhood factor ( NF ) parameter times the number of leaves (lines 5-8). The new leaves truth assignment is evaluated against a precomputed proper sequence of Boolean rules to examine whether it leads to a solution of the model, i.e. root R is satisfied (line 9). If the new leaves assignment leads to a solution for the model, then the respective DTM solution X  X  weight is compared to the currently selected solution and provided that the former is better, it becomes the selected solution, while the next iteration of the mutating process will be applied to the leaves assignment that led to the new solution (lines 10-15). Finally, the algorithm returns the best solution met throughout the search. 5.3 Reasoning Example To illustrate the application of the WP-MAXSAT algorithm and the execution of the LLS algorithm for different contexts (i.e. different weights t 1 , t 2 )andfor different FF values, we use the DTM presented in Fig. 2. In this respect, Table 3 contains two weight assignments ( t 1 and t 2 ) in the DTM example, where the second assignment ( t 2 ) reflects changes in the initial weights ( t 1 )ofnodes A 5and T 11 as a result of a context change. As discussed before, task nodes are annotated with positive weight values indicating the benefit included in fulfilling the task while action nodes are annotated with negative values reflecting the associated cost for executing the activity. The model X  X  nodes that are not included in Table 3 have weights that are equal to zero. Based on the above weight annotations, we apply WP-MAXSAT and compute an optimal solution for the problem with total weights equal to 1757 for context t 1 and 2255 for context t 2 . In order to apply the LLS algorithm we utilize a solution computed by a SAT solver which will be used as a seed. Table 4 presents the results of the LLS algorithm with different FF values for both the initial weight assignment as well as the one after the context change. As the number of iterations increases the acquired solution converges to the optimal one. Also, the LLS algorithm required less iterations ( FF  X  3 for context t 2 vs. FF  X  6 for context t 1 ) in order to reach the optimal solution during the second run. This relationship between the rate of context changes and the solution quality performance of LLS is examined in the next section. In this respect, in order to evaluate and assess the performance of the algorithm with regard to solution quality, as well as the computational requirements we discuss a series of experiments in the following section. In order to evaluate the applicability and the performance of the proposed frame-work we conducted a series of experiments with randomly generated task models of varying size and complexity. Using these models we evaluated the application of a WP-MAXSAT algorithm with regards to execution time required for models of different size. Additionally, using the same models, we evaluated and compared the performance of the search process pre sented in the previous section with re-gard to the execution time required as well as the quality of acquired solution for different FF values.

In order to evaluate the proposed framework we implemented a random task model generation mechanism which, given certain parameters, such as model size, task vs. actions ratio, AND vs. O R decompositions ratio and maximum binary rules coverage returned a rando mly generated task model. Due to space limitations, the results presented and discussed in this paper were acquired with the following task model generation configuration: a ) model size ( | N | ): 20 -300, with an interval of 20 nodes b ) task vs. actions ratio: 1 c ) AND vs. OR decom-position ratio: 1 d ) Maximum binary rules coverage: 30% (percentage of nodes participating in on or more binary rules) We used the above configuration and acquired 10 randomly generated models per model size, for 15 model sizes. For each model, we simulated five context c hanges each of which assigned different weight values to 10 percent of the nodes and for each context change we ran the WP-MAXSAT algorithm to get the optimal solution, as well as the WP-MINSAT algorithm to get the worst solution for the model with regard to total weight. In order to evaluate and compare the search process performance vs. the WP-MAXSAT results, we used the following measures:  X  t wp  X  maxsat : WP-MAXSAT algorithm execution time,  X  t FF lls : LLS algorithm execution time with flips factor FF ,and where W S is the total weight of the solution, and W optimal and W worst being the total weights of the solutions computed by WP-MAXSAT and WP-MINSAT al-gorithms respectively. For each generat ed model the search process was executed and average values were com puted for the above measures. 6.1 Results The presentation of the results is split into: (a) evaluation of time performance through considering t wp  X  maxsat and t FF lls , and (b) evaluation of solution quality through computing Q S for different model sizes and flips factor values. Time Performance. Fig. 3 depicts the average t wp  X  maxsat versus model size. The execution time required by the WP-MAXSAT algorithm scales exponen-tially with regard to model size, which is expected due to the nature of the problem. Additionally, Fig. 3 depicts the average t 5 lls as well as the average t 40 lls for all examined model sizes ( FF =5and FF = 40 are the minimum and maximum flips factor values considered in our experiments) while results for all intermediate FF values lie between the results for the two extreme values de-picted. t 5 lls is generally proportionate to FF ; however, independent of the FF value, the average t lls scales almost linearly to the number of nodes. For large models, LLS is significantly faster compared to applying WP-MAXSAT. For in-stance, for model size equal to 300 nodes and flips factor value equal to 40, LLS required on average 1 1000 of the time that WP-MAXSAT required and compute solutions of high quality ( Q S =0 . 938) as will be discussed in the next section. Solution Quality. Fig. 4 presents how Q S varies versus FF values for model sizes of 100 and 300 nodes. The quality of the initial solution is depicted for FF = 0 and it is around 0.5 for both model sizes. From that point on, as FF increases, the quality converges asymptotically to the optimal solution getting its maximum value for FF = 40 (0.961 for size = 100 and 0.938 for size = 300).
Finally, Fig. 5 depicts the average solution quality for the proposed search process, with regard to the number of cons ecutive context changes using average values from 3 models of 200 nodes and 30 context changes. As the number of consecutive context changes in a dynam ic environment increases and the LLS algorithm is applied more times, the solution quality provided by the algorithm is improved for each run. Also, the lower the FF, the more evident the improvement effect is. This effect can be explained by th e fact that context changes are gradual, allowing for the algorithm X  X  seed solutions that originate from the solutions X  cache to be of higher quality. In this respect, as the starting point for each application of the algorithm gets better, the outcome with regard to solution quality is improved, indicating thus in environments with high rates of gradual context changes, using the proposed search technique can provide further benefit. Decision support and action selection for a given context and a given set of goals is a key problem that still motivates researchers and practitioners to de-vise solutions for. There are two main facets to this problem, namely decision support for static environments, and dynamic decision support for dynamic en-vironments. In the first category, [8] discusses a qualitative approach as well as a numerical approach for reasoning with goal models. In [9] an approach of eval-uating qualitative or quantitative satisfaction levels of goals and tasks through the propagation of appropriate values via the goal model links, is presented.
A variation to these approaches are utility based decision support approaches that aim also to maximize or minimize a utility function such as benefit or cost for each task and action, or the number of constraints that are satisfied for each possible plan. Assuming that a goal or other type of model can be represented as logic formulas a number of reasoning approaches based on SAT reasoners are applicable. In [10] an algorithm that implements Weighted Partial MAX-SAT by successively invoking a SAT solver and by attempting to minimize the penalty for not satisfying soft-constraints, is presented.
 In [11], GRASP a search algorithm for propositional satisfiability is proposed. The search algorithm is based on the concept of identification of assignments that cause conflicts at a given level, and then non-chronologically backtrack to earlier levels to improve pruning of the search space. In [12] an extension of the GRAPSP algorithm augmented with path re-linking that attempts to intensify and focus the search around good-quality isolated solutions that have been originally computed by the GRASP algorithm is presented. The basic difference of the GRASP and also the path re-linking augmented GRASP algorithms from the approach here is that, in our approach we do not utilize backtracking or a and we are solely based on mutations of the possible assignments of truth values to the variables in the given set of clauses. The quality of the produced solution is based on the num-ber of mutations (i.e. iterations) and the size of possible mutations in each flip. The augmented GRASP algorithm guarantees a better approximate solution to the Weighted MAX-SAT than ours, as it already starts from known good (elite) solutions, but on the other hand requires the use of GRASP as its initial input.
In the second category, the environment is considered dynamic in the sense that actions of a plan may become impossible once the plan is devised and started being enacted because the envi ronment is dynamically altered. Work in this category relates to approaches proposed in autonomous agents and au-tonomic software systems. In [13] an approach that allows for reasoning about partial satisfaction of soft-goals is discussed. The approach is based on the anno-tation of softgoals with reward (e.g. benefit), and penalty (e.g. cost) functions. The approach utilizes Dynamic Decision Ne tworks (DDN) in order to identify a selection of softgoals that provide an optimal decision with respect to softgoal satisfaction and the utility functions used. The difference from our approach is that we do not require the compilation of intermediate models such as a DDN, and we allow for utility functions (rewards, and penalties) to vary dynamically as the system operates. In [14] a framework that implements an adaptation manager for autonomic systems is proposed. The framework is based on the Goal-Attribute-Action model and allows for a decision to be reached regarding the selection of actions in order to adapt or re-configure an autonomic system according to specified goals that need be reached. In this paper, we investigated the use of local search algorithms and boolean expres-sion evaluators to reason with DTMs when labels related to cost and benefit values for actions and tasks are altered as a result of context changes. The approachallows for obtaining a solution that is within 90% of the optimal value at a fraction of time that is required by a Weighted Partial MAX-SAT algorithm to compute the opti-mal solution for the problem at hand. The applicability and the performance of the proposed frameworkwas evaluated with promising results by conducting a series of experiments with randomly generated task models of varying size and complexity. Acknowledgment. The research of G. Chatzikonstantinou is co-funded by the European Union (European Social Fund ESF) and Greek National funds through the Operational Program  X  X ducation and Lifelong Learning X  of the National Strategic Reference Framework (NSRF) -Research Funding Program: Heracleitus II. Investing in knowledge society through the European Social Fund. The research of M. Athanasopoulos is supported by IBM Canada CAS Research under the Research Fellowship Project No. 754.

