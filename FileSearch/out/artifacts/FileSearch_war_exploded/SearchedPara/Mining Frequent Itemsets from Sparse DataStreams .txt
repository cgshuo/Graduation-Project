
Juan J. Cameron 1 , Alfredo Cuzzocrea 2 , Fan Jiang 1 , and Carson K. Leung 1 Over the past two decades, numerous frequent itemset (FI) mining algorithms have been proposed [5,6,11,15,17,18,20] . For example, FP-growth [10] uses an extended prefix-tree structure called Frequent Pattern tree ( FP-tree )tocapture the content of the database (DB). Although there are some works [2,9] that use disk-based structure for mining, they mostly mine FIs from static DBs. As a preview, we mine FIs from dynamic data streams.

The automation of measurements and data collection, together with the in-creasing development and use of a large number of sensors, have also led to streams of data [12,14,21]. To make sense of the streaming data, stream mining algorithms are needed. Mining from dynamic data streams (cf. static DBs) is more challenging due to the following properties of data streams: Property 1: Data streams are continuous and unbounded. To find FIs from streams, we no longer have the luxury of performing multiple data scans. Once the streams flow through, we lose them. Hence, we need some data structures to capture the important contents of the streams (e.g., recent data X  because users are usually more interested in recent data than older ones).
 Property 2: Data in the streams are not necessarily uniformly distributed; their distributions are usually changing with time. A currently infrequent itemset may become frequent in the future, and vic e versa. So, we have to be careful not to prune infrequent itemsets too early; otherwise, we may not be able to get complete information such as frequencies of certain itemsets (as it is impossible to retract those pruned itemsets).

Algorithms for mining FIs from data streams have been proposed. For exam-ple, approximate algorithms (e.g., FP-streaming [8]) focus mostly on efficiency. Due to the approximate nature, these algorithms may find some infrequent item-sets or miss frequency information of some FIs (i.e., some false positives or neg-atives). An exact algorithm mines truly FIs (i.e., no false positives and no false negatives) by (i) constructing a Data Stream Tree ( DSTree ) [16] to capture global contents of the streaming data and then ( ii) recursively building FP-trees locally for projected DBs based on the information extracted from the DSTree. Such an algorithm works well for situations where these global DSTree and local FP-trees can fit into main memory. When facing si tuations where not all local FP-trees can fit into memory, Data Stream Projected trees ( DSP-trees ) [13] can be built for x -projected DBs (where x is an item) as alternatives to local FP-trees built for  X  -projected DBs (where  X  is an itemset, i.e.,  X   X  x ).

Although memory is not too expensive nowadays, the amount of data gener-ated in data streams also keeps growing at a much rapid rate. Algorithms for mining FIs with limited memory are still in demand. Preliminary results of our recent study [3] showed the feasibility of stream mining with limited memory. Our key contribution of the current paper is our simple yet powerful on-disk data structure called DSTable for capturing and maintaining relevant data found in the data streams. The DSTable is designed for stream mining of FIs using the window-sliding model [4,7,19]. When the streams flow through, a fixed-size win-dow (i.e., a window containing the interesting portion of the streams X  X sually, recent data) slides and our DSTable is pro perly updated. Although we design the DSTable for environments with limited memory, it can be used as an alternative structure to the DSTree for environments with sufficient memory as well.
This paper is organized as follows. Next section presents our DSTable for cap-turing important information from data streams and describes how our DSTable can efficiently mine Fis from (sparse) data streams. Evaluation results and con-clusions are shown in Sections 3 and 4, respectively. Recall from the previous section, FIs can be mined using (i) global DSTree, local FP-trees when these trees can fit into main memory and (ii) global DSTree, local DSP-trees where the memory is so limited that local FP-trees cannot fit. Here, we deal with situations where the memory is so limited that neither the global DSTree nor local DSP-trees can fit. Specifically, we propose a new (tabular) structure called Data Stream Table (DSTable) for mining data streams with limited memory environments.

Given (i) a stream of uncertain data and (ii) a limited memory environment, our proposed DS-Table structure captures the important contents of the stream-ing data onto the disk. Specifically, the DSTable is a two-dimensional table that captures the contents of transactions in all batches in the current sliding window. Each row of the DSTable represents a domain item. Due to the dynamic nature and Property 2 of data streams, frequencies of items are continuously affected by the insertion of new batches (and removal of old batches) of streaming data. Arranging the items (i.e., rows of the DSTable) in frequency-dependent order may require frequent rearrangement. He nce, in the DSTable, items are arranged according to some canonical order (e.g., alphabetical order), which can be spec-ified by the user prior to the construction of the DSTable. Consequently, the DSTable can be constructed using only a single scan of the data stream.
Each table entry is a pointer that points to the location of the table entry (e.g., itemID and column number) for the  X  X ext X  item on the same transaction. As we are dealing with streaming data, we need to be able distinguish transactions in one batch from those in another batch. When the window slides, transactions in the old batch need to be removed and transactions in the new batch need to be appended. Representation 1: Transaction IDs. A natural solution is to add a transac-tion ID to each table entry (i.e., TID, itemID, column number ). By keeping track of all transactions belonging to each batch, one can identify the transac-tions that are in the oldest batch when the window slides.
 Representation 2: Batch IDs. One potential concern observed from Exam-ple 1 is that one needs to keep extra mappi ng information between transaction IDs and batch IDs (e.g., t 1  X  t 3 belong to B 1 ). Hence, another representation is to use a batch ID. In other words, each table entry is of the form batchID, itemID, column number . By so doing, we can easily identify all transactions belong to the oldest batch and we do not need to keep extra mapping information. Representation 3: Pointers. On the positive side, Representation 2 saves us from keeping track of the mapping between batch ID and transaction ID. On the negative side, each table entry is still a triplet, which takes up lots of disk space. A better solution is not to store any transaction ID or batch ID. Instead, the DSTable stores pointers that point to the entries at the end of the batch (i.e., indicating the boundaries). When the window slides, one can easily remove every table entries between the previous (or the first) and this pointer. Mining with the Global DSTable and Local DSP-Trees. Since items are arranged in canonical ord er, we extract transactio ns (which we have shown in the above examples) during the mining process by locating the first frequent domain item y , extracting appropriate entries from Row y of the DSTable, and inserting these entries into a DSP-tree for y . Based on the user-defined minsup threshold, we can determine which item is frequent. An item is frequent if its frequency or support value  X  minsup . So, during the path extraction and DSP-tree construction process, we just skip in frequent items. Afterwards, we repeat the same process for other frequent domain items.
 Analytical Results. Mining with the DSTable uses a  X  X elayed X  mode (i.e., actual mining of FIs is delayed until it is needed to return to user the FIs). Hence, for S =100 batches, we only need to build a global DSTable and updates it 95 (= S  X  w = 100  X  5) times. Afterwards, we have an updated DSTable capturing the 96th to the 100th batches, and we build only O( m ) DSP-trees, where m is the number of frequent domain items in the domain, to find FIs X  X .e., only one set of the updated a global FP-tree and m DSP-trees (cf. building 100 sets of a global tree and O( f  X  d ) FP-trees by FP-str eaming [8], one set for each of the 100 batches). Note that the number of frequent domain items is usually much less than the number of FIs: m f  X  2 m  X  1. At any time during the mining process, only the global FP-tree and o ne DSP-tree are needed to be present (cf. one global FP-tree + O( d ) subsequent FP-trees ar e needed to be present in FP-streaming).

Moreover, as the DSTable can reside on disk (thus, serving as an alternative to FP-tree when memory is limited), the size of the DSTable is independent of minsup . Hence, it is useful for interactive mining, especially when users keep adjusting minsup . Please note that the DSTable captures the transactions in the current sliding window. During the mining process, the algorithm skips infre-quent items (i.e., items having support lower than minsup ) and only includes frequent items when building DSP-trees. When users adjust minsup during the interactive mining process, we do not need to rebuild the DSTable.
 Experimental Results. We used different datasets such as IBM synthetic data, which are generated by the program developed at IBM Almaden Research Cen-tre [1]. The data contain 1M records with an average transaction length of 10 items, and a domain of 1,000 items. We set each batch to be 0.1M transactions and the window size w =5 batches. All experiments were run in a time-sharing environment in a 1 GHz machine. The reported figures are based on the average of multiple runs. Runtime includes CPU and I/Os; it includes the time for both tree construction and FI mining steps. In the experiments, we mainly evaluated the accuracy and efficiency of the DSTable.
 First, we measured the accuracy of the three mining options: (i) global DSTree, local FP-trees , (ii) global DSTree, local DSP-trees , and (iii) global DSTable, local DSP-trees options. Experimental results show that mining with any of these three options give the same mining results.
 Then, we measured the space and time efficiency of our proposed DSTable. Fig. 1(a) shows that the DSTable, DSP-trees option required the smallest main memory space because our proposed DSTable is a disk-based structure. Fig. 1(b) shows the DSTable, DSP-trees option took slightly longer because it needs to read from disk whereas the former two just read from main memory. However, reading from disk would be a logical choice in a limited main memory environ-ment.

Then, we tested with the usual experiment (e.g., the effect of minsup ). As shown in Fig. 1(b), the runtime decreased when minsup increased. Moreover, mining with our proposed DSTable was scalable with respect to the number of transactions. A key contribution of this paper is to provide the user with a simple yet powerful alternative structure for efficient FI mining from sparse data streams in limited memory environments using sliding windows. Our DSTable captures the contents of transactions in a window, and arranges items according to some canonical order that is unaffected by changes in item frequency when the window slides. To avoid the recursive construction of trees during the mining process, DSP-trees are built from the DSTable.

