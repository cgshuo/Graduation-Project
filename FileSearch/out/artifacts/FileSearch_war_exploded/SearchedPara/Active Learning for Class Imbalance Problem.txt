 The class imbalance problem has been known to hinder the learn-ing performance of classification algorithms. Various real-world classification tasks such as text categorization suffer from this phenomenon. We demonstrate that active learning is capable of solving the problem.
 H.3 [ Information Storage and Retrieval ]: Miscellaneous; I.2.6 [ Artificial Intelligence ]: Learning X  concept learning, induction Algorithms, experimentation Active learning, imbalanced data, support vector machines
A dataset is called imbalanced if at least one of the classes are represented by significantly less number of instances than the others. In imbalanced data classification, the class bound-ary learned by the standard machine learning algorithms can be severely skewed toward the positive class. Thus, the false-negative rate can be excessively high. One major research direction to overcome the class imbalance problem is to resample the original training dataset, either by oversampling the minority class and/or undersampling the majority class until the classes are represented in a more balanced way. Undersampling may discard useful data causes longer training time and inefficiency in terms of memory due to the increased number of training instances and it suffers from high computational costs for preprocessing the data. The underlying motivation for resampling methods is to provide the learner with a training set having more balanced classes. We show that Active Learning (AL) strategy can be a more efficient alternative to resampling methods to form a balanced training set for the learner in early stages of the learning. We also propose an efficient Support Vector Machine (SVM) active learning strategy which queries a small pool of data at each iterative step instead of querying the entire dataset. We present that active learning with early stopping can achieve a faster and scalable solution without sacrificing prediction performance.
The basic SVM based active learning selects the closest instance to the current hyperplane from the unseen training data and adds it to the training set to retrain the model. In classical active learning [3], the search for the most informative (closest) instance is done through the entire unseen dataset. Each iteration of active learning involves the recomputation of the distances of each instance to the new hyperplane. Thus, for large datasets, searching the entire training set is very time-consuming and computationally expensive.
We propose a selection method which will not necessitate a full search through the entire dataset but locates an approximate most informative sample by examining a small constant number of randomly chosen samples. The method picks L (L # training instances) random training samples in each iteration and selects the best (closest to the hyperplane) among them. Suppose, instead of picking the closest instance among all the training samples X ( x 1 ,x 2 ,  X  X  X  ,x N ) at each iteration, we first pick a random subset X
L , L N and select the closest sample x i from X L based on the condition that x i is among the top p % closest instances in X
N with probability (1  X   X  ) . Any numerical modification to these constraints can be met by varying the size of L , and is independent of N . To demonstrate, the probability that at least one of the L instances is among the closest p % is 1  X  (1  X  p %) L . Due to the requirement of (1  X   X  ) probability, we have which follows the solution of L in terms of  X  and p
For example, the active learner will pick one instance, with 95% probability, that is among the top 5% closest instances to the hyperplane, by randomly sampling only log( . 05) / log( . 95) = 59 instances regardless of the training set size. This approach scales well since the size of the subset L is independent of the training set size N , requires significantly less training time and does not have an adverse effect on the classification performance of the learner. In our experiments, we set L =59 .

Early Stopping: In SVM learning the classification boundary (hyperplane) is only determined by support vectors. This means that there is no point of adding new instances to the model after the Table 1: The running time of SMOTE is composed of the preprocessing time and the training time. There are 7,770 and 6,593 training instances in Reuters and CiteSeer respectively. number of support vectors saturates. A practical implementation of this idea is to count the number of support vectors during the active learning training process. If the number of the support vectors stabilizes, it implies that all possible support vectors have been selected by the active learning method and the rest of the training instances are redundant. Therefore, we choose our stopping point where the number of support vectors saturates.
We compare the active learning method (AL) with several other strategies. Among them undersampling (US) and oversampling method (SMOTE [2]) are examples of resampling techniques. DC is the method which uses different costs (higher for the positive class) for misclassification penalties. As a classification algorithm, we used LASVM [1], an online SVM tool for all the experiments. Online SVMs suits the nature of active sample selection strategy better than the batch SVMs due to their incremental learning steps. We also show random sample selection of LASVM (RS) on the original training set to form the baseline. LASVM is also run in random sample selection mode with US, SMOTE and DC. We conducted the experiments on two text datasets: Reuters-21578 and CiteSeer. Due to space constraints, we only show results for some categories of those datasets.

We use the g-means metric which is a common practice in the performance evaluation of algorithms in imbalanced data classi-fication. g-means is denoted as g = where sensitivity and specificity are the accuracies on the positive and negative instances respectively.

Figure 1 depicts the g-means performance of the different methods. For completeness we did not cut the active learning experiments at the early stopping point but allowed them to run on the entire training set. AL g-means curves saturate after using small portion of the training data. Those graphs support the idea that adding more training data after seeing the informative samples does not remarkably change the model and consequently the prediction performance. The values of AL curves on the vertical lines in Figure 1 show the g-means of AL at the early stopping points.
The training times for AL in Table 1 show the time till the early stopping point. The results for the other methods present the training times at the end of the curves. We did not apply early stopping criteria to the other methods because as observed from Figure 1 the other methods converge to similar levels of g-means when nearly all training instances are used. Thus, no early stopping criteria would achieve a comparable training time with that of ALs without a significant loss in their prediction performance based on convergence time. We also give the imbalance ratios of the positive and negative classes in the training sets for each category, and the imbalance ratios of the negative and positive support vectors in the final models. Those more balanced models are achieved in much earlier steps of the learning in AL while the other methods have to see the entire training dataset. Data efficiency of AL in Table 1 shows what percentage of the training instances are used in the model to achieve the balanced model. Since other methods use all the training instances, data efficiency is not applicable for those.
Experimental results on text datasets show that our method can achieve a significant decrease in the training time, while maintaining the same or achieving even higher g-means values by using less number of training instances in the SVM model. The efficient method for active selection of informative instances from a randomly picked small pool of samples removes the need for making a search through the entire dataset. This strategy makes active learning scalable to large datasets. Combined with the early stopping heuristics, active learning can be an alternative method for solving the class imbalance problem. [1] A. Bordes, S. Ertekin, J. Weston, and L. Bottou. Fast kernel [2] N. V. Chawla, K. W. Bowyer., L. O. Hall, and W. P.
 [3] S. Tong and D. Koller. Support vector machine active learning
